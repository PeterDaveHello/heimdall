[
  {
    "id": 35316836,
    "timestamp": 1679850678,
    "title": "Data Compression Pioneer Jacob Ziv passes away, leaving lasting impact",
    "url": "https://twitter.com/erlichya/status/1639973591214182400",
    "hn_url": "http://news.ycombinator.com/item?id=35316836",
    "content": "Computer scientist Jacob Ziv has passed away. Ziv was a pioneer in the field of information theory, co-inventing the LZ family of lossless data compression algorithms, which includes LZW, LZ77 and LZ78. His work laid the foundation for modern data compression techniques and paved the way for the creation of widely-used data formats such as ZIP and PNG. Ziv also contributed to other areas of signal processing, including image processing and speech compression. His numerous contributions earned him many awards, including the IEEE Richard W. Hamming Medal in 2013. Reflecting on Ziv's passing, some Hacker News commenters noted the relationships between technological progress, creator death, and the industry's adoption of technology.L\u00e1szl\u00f3 Polg\u00e1r's thesis that geniuses are made, not born, focused on the idea that children could excel in a specialist subject if trained from an early age. He and his wife Kl\u00e1ra educated their three daughters at home, with chess as the specialist subject. Some comments on the article suggest that while guidance and support is important, forcing children into a particular subject can be detrimental to their learning experience. However, many are in agreement that the ability to make efficient use of resources, such as compression and compiler writing, will be increasingly important as technology reaches its physical limits. The current culture of prioritizing fast shipping over performance and efficiency in software development was also discussed.Moore's Law enabled programmers to prioritize aesthetics and ideologic considerations over performance, ultimately leading to a lack of investment in new computing methods. As the end of Moore's Law approaches, programmers will need to consider efficiency, speed and performance. Although compression is no longer a primary concern, it remains an important tool for building foundational skills. Jacob Ziv, an Israeli electrical engineer who co-developed the LZ family of lossless data compression algorithms, has passed away. Ziv's work allowed for more efficient data storage and transmission and was used in popular compression schemes such as ZIP, PNG, GIF and Zstandard. He recognized the uncomputability of Kolmogorov complexity, which led to the development of the Lempel-Ziv complexity and LZ77 and LZ78 compressors in 1976.",
    "summary": "- Computer scientist Jacob Ziv, co-inventor of the LZ family of lossless data compression algorithms, has passed away. \n- Ziv's work laid the foundation for modern data compression techniques and contributed to signal processing, earning him many awards. \n- Some Hacker News commenters reflect on the relationship between technological progress, creator death, and the industry's adoption of technology. \n- While guidance and support are important, some comments suggest forcing children into a particular subject can be detrimental to their learning experience. \n- The ability to make efficient use of resources, such as compression and compiler writing, will be increasingly important as technology reaches its physical limits. \n- As the end of Moore's Law approaches, programmers will need to consider efficiency, speed and performance. \n- Ziv's work allowed for more efficient data storage and transmission and was used in popular compression schemes such as ZIP, PNG, GIF and Zstandard."
  },
  {
    "id": 35312352,
    "timestamp": 1679819490,
    "title": "Capturing War's Impact on Ukraine with Street View",
    "url": "https://theundeniablestreetview.com/",
    "hn_url": "http://news.ycombinator.com/item?id=35312352",
    "content": "The Undeniable Street View project documents the destruction caused by the war in Ukraine, focusing on areas that have been devastated by military conflict. The project uses street view technology to capture high-resolution images of destroyed buildings and infrastructure, providing a detailed account of the war's impact on the ground. However, some commenters on Hacker News note that propaganda has influenced public opinion about the war, with some people attributing the destruction to the Ukrainian military rather than Russian aggression. The commenters call for a focus on critical thinking and accurate information to combat misinformation and promote understanding of the war's complexities. War is devastating for civilians and infrastructure, while also causing economic consequences and long-term psychological damage.A mapping project on Google Street View has laid bare the destruction wrought on the city of Mariupol in eastern Ukraine by Russian-backed rebel forces. The web initiative was led by Dmitry Zolotukhin, a Mariupol resident, and uses Google Street View to record how the city appeared before fighting broke out in 2014, and how it appeared after. Donations have been collected to pay for cars and cameras, and volunteers have taken pictures of every street and house in the conflict zone. The resulting images reveal war-torn buildings, burnt-out cars, and shrapnel holes in walls. The project has been praised for recording conflicts that might otherwise go unreported, as well as helping to educate people around the world about the reality of war.People who join cults or believe in conspiracy theories are not necessarily less intelligent. Instead, they often become invested for emotional rather than rational reasons, and conventionally intelligent people are very good at rationalizing their own behavior, even in the face of blatant evidence to the contrary. Examples of similar rationalization processes include gambling addiction and abusive relationships, among others. When evaluating claims or factual information, people often use their own preconceptions and previous experiences as the basis for determining whether or not something is extraordinary, meaning it violates their preconceptions. However, this is not a fail-safe way to reason, and relying solely on secondary confirmation without taking into account expertise or consensus can lead to anti-intellectual conclusions.The idea that \"extraordinary claims require extraordinary evidence\" is often repeated, but its subjective nature makes it difficult to apply. Claims that violate previous experiences are considered extraordinary, but what is considered extraordinary is different for everyone. It is also challenging to determine what constitutes \"the vast majority\" of people, making claims about their beliefs difficult to substantiate. For example, the preconception that aliens do not exist is common, but it is impossible to know if this is true. False flag military operations have occurred throughout history, but the context is crucial in determining their legitimacy. The majority illusion can also create a false sense of what people believe. Science and truth are not determined by vote, and complexity often leads to oversimplified arguments.This thread discusses the downing of the Malaysian Airlines Flight MH17 in 2014, with some contributors suggesting that Russia was involved in supplying the separatists, who shot down the plane using a Buk missile system. Others raise concerns about the lack of conclusive evidence and the role of propaganda in the conflict. One contributor notes that the absence of a formal apology from Russia makes it difficult to assume the event was an accident. The conversation also references the damage done to Ukrainian cities during the conflict, including Ukraine firing artillery at its own cities in an effort to defeat Russian forces. Some contributors remark on the importance of empathy and educating people about history to prevent future conflicts.A heated online discussion about the conflict between Russia and Ukraine includes arguments about why the war started and the reliability of information from both sides. One commenter suggests that people should be critical of all information coming from states involved in the conflict and their supporters. The discussion devolves into accusations of propaganda and the validity of shaming others for their opinions. The original question of whether it is completely Russia's fault for starting the war is debated, with some arguing that Ukraine is also to blame for the conflict. Overall, the conversation reveals the complexity of the conflict and the challenges in understanding the truth amid multiple sources of information and propaganda.The discussion revolves around the theme of election tampering in the US. Some users argue that claims of election interference have been prominent in recent elections irrespective of the winner, indicating a breakdown in trust in democracy. People are skeptical based on their political inclinations. For instance, Democrats were more critical of the 2016 election results, whereas Republicans expressed more skepticism over the 2020 election. This polarization further undermines trust in democracy. Assertions such as Ukraine bombing their cities and Russia bombing Nord Stream pipeline without immediate evidence suggest the use of propaganda in driving opinions. However, some argue that a more critical look is necessary to root out election tampering, whether in the United States or elsewhere globally.Discussions on the conflict in Ukraine reveal the cognitive dissonance that has resulted in a questioning of what's real due to propaganda and bias. Participants in the conversation opinionate and speculate, and although their viewpoints on who is responsible for the explosion of the NordStream pipeline differ, they are unanimous in their distrust of media coverage and institutions. Beliefs, driven by emotions, enable narratives to persist, and while curating a worldview makes a logical approach more possible, it's not the only way that humans base their perspectives. Though both sides are accused of being enablers and provocateurs, Russia's imperialistic aggression is seen as the primary motivation behind the violence in Ukraine.The Budapest Memorandum, requiring Ukraine to make changes such as federalization to which its leaders agreed but did not proceed, was broken in 2014 when Russia invaded. The Minsk II agreement, aimed at bringing peace to the region after 20 years, was broken on the first week when Russia violated it. Russia is not directly involved in the Minsk agreements. However, the country broke them and annexed Crimea to become a threat to Ukraine. Countries neighboring Russia that have joined NATO did so voluntarily, understanding they would be able to secure themselves better with the alliance's help. Joining the western world has allowed these countries to become democracies with healthy economies, while remaining under Russia's influence has led to a lack of liberty, corruption, and stagnant economies.The comments section of an article discussing the conflict in Ukraine includes a variety of opinions and arguments. Some suggest that both sides are at fault and that the conflict is the result of geopolitical goals, while others argue that Russia is engaging in imperialism and has no right to control Ukrainian territory. There is also debate about the morality of attacking civilian infrastructure and the use of propaganda. Some commenters warn against minimizing the impacts of the conflict and suggest alternative viewpoints, while others express disillusionment with changing people's worldviews. There are mentions of historical facts, examples from other conflicts, and personal experiences, but no clear consensus on the best course of action.The ongoing conflict between Ukraine and Russia will continue until Russia wins or until the US no longer wants to support the conflict and a demilitarized border is created between Ukraine and the lost regions, according to a user on Hacker News. However, others on the platform question this assumption, pointing out that Russia's formal annexation of regions did not enable them to retain control of those areas. Some speculate that the conflict could end when enough Russians die, forcing leadership to reconsider the war's effectiveness. There are also concerns that any end of the war that shows aggression pays off dividends could trigger more aggressive behavior elsewhere, leading to a new \"might-makes-right\" world order that can only stabilize again once everyone has nuclear weapons.Discussions on Chinese steel arise in a HN thread about the ongoing conflict between Ukraine and Russia. The commenters debate the quality of Chinese steel, with some arguing that it is \"barely passable junk\" and fails mission-critical tasks, while another argues that China has built the largest high-speed rail network in the world, sourcing steel domestically. Some comments touch on the conflict, with a focus on how Russia does not need shells exploding early or combat gear that snaps under load, while Ukraine needs more arms and ammunition. There are also comments about the propaganda and lies spread by both sides in the conflict, with a reference to the missile that accidentally landed in Poland and was initially blamed on Russia before being attributed to Ukraine.Radio Free Europe reported that the recent explosion in Luhansk, Ukraine was confirmed by notable Russian propaganda outlet, but the source of the explosion is unknown. The OSCE stated that it was probably rockets and CNN and the Daily Beast claimed that the explosion patterns looked like they came from airburst weapons that could have been fired by Su-25/Su-27 aircraft. Both Ukrainian and Russian troops have access to this military hardware. Despite this, there is no conclusive evidence proving who is responsible for the attack. In response to the conflict, Ukraine has been shelling Ukrainian cities in Donetsk and Luhansk, and sometimes striking at Russian military targets. There have also been instances of extremist factions, like Azov, targeting and killing civilians and children. To understand the impact of the war, Google Street View offers a view of six Ukrainian cities and regions affected by the conflict.",
    "summary": "- The Undeniable Street View project uses Google Street View technology to capture images of the destruction caused by the war in Ukraine, revealing the impact on civilians and infrastructure.\n- Propaganda has influenced public opinion about the war, with some people attributing the destruction to the Ukrainian military rather than Russian aggression. Critical thinking and accurate information are needed to combat misinformation and promote understanding of the war's complexities.\n- Discussion about the conflict in Ukraine involves debates about who is to blame, concerns about propaganda, and the challenges in understanding the truth amid multiple sources of information.\n- The conflict in Ukraine is complex and has resulted in cognitive dissonance among participants in the discussion, making it difficult to determine what is real and what is propaganda-driven.\n- The Budapest Memorandum and Minsk II agreement were both broken during the conflict, with Russia engaging in imperialism and annexing Crimea. Joining the western world has allowed neighboring countries to become democracies with healthy economies, while remaining under Russia's influence has led to a lack of liberty and corruption.\n- The ongoing conflict between Ukraine and Russia will continue until certain conditions are met, but speculation about the conflict's end is not clear.\n- The recent explosion in Luhansk, Ukraine, was likely caused by rockets, but there is no conclusive evidence of who is responsible for the attack.\n- Discussion about the conflict also involves debates about the quality of Chinese steel and the impact of the conflict on Ukrainian cities and regions."
  },
  {
    "id": 35316679,
    "timestamp": 1679849976,
    "title": "Extract Apple Notes as JSON Using Liberator",
    "url": "https://github.com/HamburgChimps/apple-notes-liberator",
    "hn_url": "http://news.ycombinator.com/item?id=35316679",
    "content": "Apple Notes Liberator is a new tool that allows users to extract Notes.app data and save it as JSON. The tool is aimed at researchers using Apple Notes as their primary note-taking application to capture unstructured memos. In a Hacker News discussion regarding the tool, users highlighted the evolution of Apple Notes from a simple note-taking app that stored content in a few simple tables to its current database structure where changes and new columns and tables have been implemented. The application also features CRDT-like algorithms to allow for shared notes and multiple concurrent edits. The use of CRDTs was praised by some users as an \"unsung hero\" of the application, but others criticized Apple's failure to allow for easy export of data.A developer created a tool called \"Apple Notes Liberator\" that extracts data from the Apple Notes app and exports it into a JSON file that can be converted into markdown files. The tool addresses an issue in Apple Notes that makes it difficult for users to export notes en masse or extract them into a format that can be used outside of the Notes ecosystem. Although other solutions exist to export notes from the app, the developer wanted to learn how Notes stored its data and how he could interact with it. The tool has received positive feedback and joins a growing trend of developers creating tools to extract data from popular apps on Apple devices.The HamburgChimps have created an open-source project on GitHub called Apple Notes Liberator. The tool extracts data from Apple Notes.app, copying and parsing the program's data without modifying the original database. The program saves extracted information in a notes.json file that contains an array of objects representing Apple Notes, each with a plain text and an embeddedObjects property containing a list of embedded note objects. The data field for each table embedded object is a two-dimensional array representing rows and columns. The program is in early development, and only extracts note text and tables for now. There is support planned for further data types and output formats like CSV and HTML in the future.",
    "summary": "- Apple Notes Liberator is a new tool that allows users to extract data from Apple Notes and save it as JSON.\n- The tool helps researchers who use Apple Notes as their primary note-taking application to capture unstructured memos.\n- Users highlighted the evolution of Apple Notes from a simple note-taking app to its current database structure with CRDT-like algorithms for shared notes and multiple concurrent edits.\n- The tool addresses an issue in Apple Notes that makes it difficult to export notes en masse or extract them into a format that can be used outside of the Notes ecosystem.\n- The program saves extracted information in a notes.json file that contains an array of objects representing Apple Notes, with support planned for further data types and output formats like CSV and HTML in the future."
  },
  {
    "id": 35320571,
    "timestamp": 1679871287,
    "title": "Control Blender with Natural Language Commands using BlenderGPT",
    "url": "https://github.com/gd3kr/BlenderGPT",
    "hn_url": "http://news.ycombinator.com/item?id=35320571",
    "content": "BlenderGPT is an AI tool that allows users to control Blender using English commands, which are generated by OpenAI's GPT-4. Users can describe what they want to create in natural language, such as \"Place 10 spot lights at random position within the boundaries of Mesh 3 with random intensity and color,\" and the tool will generate Blender code to execute that command. However, the generated code may not always be correct and requires some iteration to get to the desired results. Users can also adjust the \"temperature\" parameter to control the degree of free-form generation in the model. While this tool is useful for non-programmers to create simple designs and animations, it may not be sufficient for more complex and precise tasks, requiring knowledge of Blender's APIs.Developments in AI and automation may lead to the automation of software development, with unskilled workers potentially being replaced by machines in the same way power looms replaced skilled hand weavers in the textile industry. While AI is currently used as a productivity tool for skilled engineers, simple tools may no longer require knowledge of data structures and algorithms, and specialist engineers may control development while software creation becomes automated. The impact of these changes on the job market, income disparity, and capitalism may be significant, raising questions about the future of work and the skills necessary to succeed in the software industry. However, some argue that the automation of certain tasks may free up time for more complex and creative work, benefitting the industry and the economy as a whole.discussion about the potential of natural language interfaces for programming. Some commenters point out that natural language may lack the required specificity for programming, while others argue that the loss of precision can be made up for through iteration. One commenter suggests an explicit symbolic approach to NLP, such as parsing. Others argue that certain programming languages, like Python, are already successful despite not having a serious type system. Additionally, commenters discuss the potential for LLMs to stitch together larger business logic blocks that are \"sanctioned\" by a framework maker for the specific problem domain. Ultimately, the conversation highlights the potential opportunities and challenges of natural language interfaces for programming.Discussion revolves around the use of natural language to command AI systems that generate images or perform 3D modelling. It is suggested that while a more natural language interface would be desirable, the AI would need a specific programming language to generate the desired output. Several commenters compare this to Star Trek's voice command system, while others are more skeptical of natural language processing. Some discuss the potential for LLMs and their impact on movie-making, and others highlight issues with the accuracy and complexity of generated images. Additionally, there is discussion about the importance of precise feedback from users to continue improving the AI systems as they develop.OpenAI's GPT can now generate Blender commands from natural language queries with the help of ChatGPT. Users can prompt the program in plain English to make 3D models, which saves a lot of time for designers who would otherwise have to navigate the 3D interface themselves. ChatGPT also generates the Python code required for the task to be performed. Although still in development, this technology may revolutionize not only UI for designing in 3D modeling software, but also a slew of other use cases such as creating billboards, interlinking with open-source SVG editors, and even generating SQL code.The BlenderGPT repository on GitHub hosts an extension that enables natural language commands to control Blender with OpenAI's GPT-4. The extension generates Blender Python code from natural language commands and supports Blender version 3.0.0 and above. Users can clone the repository and install the add-on in Blender to use the extension. The sidebar contains a GPT-4 Assistant tab to enter natural language commands, which the extension translates into Blender Python code. The extension is not always accurate, and users may need to run the code again. A valid OpenAI API key is required, and to view code generations in real-time, go to Window > Toggle System Console.",
    "summary": "- BlenderGPT is an AI tool that allows users to control Blender using natural language commands generated by OpenAI's GPT-4, but the generated code may not always be correct and requires iteration.\n- This tool is useful for non-programmers to create simple designs and animations but may not be sufficient for more complex and precise tasks, requiring knowledge of Blender's APIs.\n- Developments in AI and automation may lead to the automation of software development, with unskilled workers potentially being replaced by machines, raising questions about the future of work and the skills necessary to succeed in the software industry.\n- Some argue that the automation of certain tasks may free up time for more complex and creative work, benefiting the industry and the economy as a whole.\n- Discussion about the potential of natural language interfaces for programming revolves around the lack of required specificity and precision, but some suggest an explicit symbolic approach or the use of LLMs to stitch together larger business logic blocks \"sanctioned\" by a framework maker.\n- OpenAI's GPT can now generate Blender commands from natural language queries with the help of ChatGPT, potentially revolutionizing the UI for designing in 3D modeling software and other use cases.\n- The BlenderGPT repository on GitHub hosts an extension that enables natural language commands to control Blender with OpenAI's GPT-4, but users may need to run code again and require a valid OpenAI API key."
  },
  {
    "id": 35317464,
    "timestamp": 1679853864,
    "title": "Nvidia: Cryptocurrencies Useless for Society",
    "url": "https://www.theguardian.com/technology/2023/mar/26/cryptocurrencies-add-nothing-useful-to-society-nvidia-chatbots-processing-crypto-mining",
    "hn_url": "http://news.ycombinator.com/item?id=35317464",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCryptocurrencies add nothing useful to society, says chip-maker Nvidia | Cryptocurrencies | The Guardian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to main contentSkip to navigationPrint subscriptions Sign inSearch jobsSearchUS editionUS editionUK editionAustralia editionInternational editionThe Guardian - Back to homeThe GuardianNewsOpinionSportCultureLifestyleShowMoreShow MoreNewsView all NewsUS newsWorld newsEnvironmentSoccerUS politicsBusinessTechScienceNewslettersFight to voteOpinionView all OpinionThe Guardian viewColumnistsLettersOpinion videosCartoonsSportView all SportSoccerNFLTennisMLBMLSNBANHLF1CultureView all CultureFilmBooksMusicArt & designTV & radioStageClassicalGamesLifestyleView all LifestyleFashionFoodRecipesLove & sexHome & gardenHealth & fitnessFamilyTravelMoneySearch input google-search SearchSupport usPrint subscriptionsUS editionUK editionAustralia editionInternational editionEurope editionSearch jobsDigital ArchiveGuardian Puzzles appGuardian LicensingThe Guardian appVideoPodcastsPicturesInside the GuardianGuardian WeeklyCrosswordsWordiplyCorrectionsFacebookTwitterSearch jobsDigital ArchiveGuardian Puzzles appGuardian LicensingUSWorldEnvironmentSoccerUS PoliticsBusinessTechScienceNewslettersFight to vote The first version ChatGPT was trained on a supercomputer made up of about 10,000 Nvidia graphics cards. Photograph: Tyrone Siu/ReutersThe first version ChatGPT was trained on a supercomputer made up of about 10,000 Nvidia graphics cards. Photograph: Tyrone Siu/ReutersCryptocurrenciesCryptocurrencies add nothing useful to society, says chip-maker NvidiaTech chief says the development of chatbots is a more worthwhile use of processing power than crypto miningAlex Hern@alexhernSun 26 Mar 2023 11.21 EDTThe US chip-maker Nvidia has said cryptocurrencies do not \u201cbring anything useful for society\u201d despite the company\u2019s powerful processors selling in huge quantities to the sector.Michael Kagan, its chief technology officer, said other uses of processing power such as the artificial intelligence chatbot ChatGPT were more worthwhile than mining crypto.Nvidia never embraced the crypto community with open arms. In 2021, the company even released software that artificially constrained the ability to use its graphics cards from being used to mine the popular Ethereum cryptocurrency, in an effort to ensure supply went to its preferred customers instead, who include AI researchers and gamers.Kagan said the decision was justified because of the limited value of using processing power to mine cryptocurrencies.The first version ChatGPT was trained on a supercomputer made up of about 10,000 Nvidia graphics cards.\u201cAll this crypto stuff, it needed parallel processing, and [Nvidia] is the best, so people just programmed it to use for this purpose. They bought a lot of stuff, and then eventually it collapsed, because it doesn\u2019t bring anything useful for society. AI does,\u201d Kagan told the Guardian.\u201cWith ChatGPT, everybody can now create his own machine, his own programme: you just tell it what to do, and it will. And if it doesn\u2019t work the way you want it to, you tell it \u2018I want something different\u2019.\u201dCrypto, by contrast, was more like high-frequency trading, an industry that had led to a lot of business for Mellanox, the company Kagan founded before it was acquired by Nvidia.\u201cWe were heavily involved in also trading: people on Wall Street were buying our stuff to save a few nanoseconds on the wire, the banks were doing crazy things like pulling the fibres under the Hudson taut to make them a little big shorter, to save a few nanoseconds between their datacentre and the stock exchange,\u201d he said.\u201cI never believed that [crypto] is something that will do something good for humanity. You know, people do crazy things, but they buy your stuff, you sell them stuff. But you don\u2019t redirect the company to support whatever it is.\u201dOriginally best known for producing powerful graphics cards for PC gamers to play the latest games, it was almost by chance that Nvidia\u2019s products took their place at the heart of the AI boom.The computationally intensive work of training a new AI system, which can take millions of billions of dollars-worth of computing power, happened to work significantly faster on the types of simple yet powerful processors that had been adopted by gamers.skip past newsletter promotionSign up to Business TodayFree daily newsletterGet set for the working day \u2013 we'll point you to all the business news and analysis you need every morningPrivacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.after newsletter promotionTwo weeks ago, Microsoft said it had bought tens of thousands of Nvidia\u2019s AI-focused processors, the A100 GPU, in order to power the workload of OpenAI. Nvidia has sold 20,000 H100s, the successor to that chip, to Amazon for its cloud computing AWS service, and another 16,000 have been sold to Oracle.Nvidia also rents access to the chips directly, with its DGX cloud service starting at just under $37,000 (\u00a330,250) a month for just eight H100s wired together in a \u201ccluster\u201d.Speaking at the company\u2019s annual conference last week, Jensen Huang, Nvidia\u2019s chief executive, described the company as the engine behind \u201cthe iPhone moment of AI\u201d, and said the \u201cgenerative AI\u201d his firm powers would \u201creinvent nearly every industry\u201d.Last year, Nvidia\u2019s $40bn takeover of the UK-based tech firm Arm collapsed because of regulatory difficulties.TopicsCryptocurrenciesTechnology sectorChatbotsE-commerceInternetComputingnewsReuse this contentMore on this storyMore on this storyMan\u00a0suspected of being crypto fugitive Do Kwon arrested in Montenegro3d agoCity regulator joins Met in raids on suspected crypto ATM operations8 Mar 2023Near 50% fall in Silvergate\u2019s shares over FTX exposure prompts survival doubts2 Mar 2023Crypto firm with links to parliamentary groups appears to have vanished23 Feb 2023Phoenix Community Capital case shines light on UK\u2019s lobbying problem23 Feb 2023Watchdog and West Yorkshire police raid crypto ATM operators in UK first14 Feb 2023\u2018Britcoin\u2019 digital currency could be in use by end of decade6 Feb 2023Crypto lender Genesis files for Chapter 11 bankruptcy in US20 Jan 2023Most viewedMost viewedUSWorldEnvironmentSoccerUS PoliticsBusinessTechScienceNewslettersFight to voteNewsOpinionSportCultureLifestyleOriginal reporting and incisive analysis, direct from the Guardian every morningSign up for our emailAbout usHelpComplaints & correctionsSecureDropWork for usPrivacy policyCookie policyTerms & conditionsContact usAll topicsAll writersDigital newspaper archiveFacebookYouTubeInstagramLinkedInTwitterNewslettersAdvertise with usGuardian LabsSearch jobsBack to top\u00a9 2023 Guardian News & Media Limited or its affiliated companies. All rights reserved. (modern)\n\n\n",
    "summary": "- Nvidia's chief technology officer, Michael Kagan, believes cryptocurrencies do not add anything useful to society and that chatbots are a more worthwhile use of processing power.\n- Nvidia constrained the use of its graphics cards for mining Ethereum cryptocurrency in 2021 to prioritize supply for AI researchers and gamers.\n- Kagan compared crypto to high-frequency trading, which did not benefit humanity.\n- Nvidia's products became instrumental in the AI boom due to their ability to significantly speed up the process of training a new AI system.\n- The company has sold tens of thousands of AI-focused processors to Microsoft, Amazon, and Oracle and rents access to the chips directly through its DGX cloud service starting at just under $37,000 a month for a cluster of eight H100s."
  },
  {
    "id": 35312694,
    "timestamp": 1679823646,
    "title": "AI's Potential Impact on Productivity & Industry: A Discussion",
    "url": "https://oneusefulthing.substack.com/p/superhuman-what-can-ai-do-in-30-minutes",
    "hn_url": "http://news.ycombinator.com/item?id=35312694",
    "content": "A discussion on Hacker News began with a report on the productivity startup, Superhuman, and its use of artificial intelligence (AI) to generate marketing text and other content in just 30 minutes. The author of the report suggested that AI was still struggling with \"very high level output\", while some commenters argued that the world was in for a major transformation thanks to ongoing improvements and breakthroughs in AI technology. One likened current advances to the early days of the iPhone, with the potential for AI to eventually become an essential part of people's lives, much like smartphones are today. However, others noted that while AI had its uses, such as in image generation, some functions, such as the creation of personalised narratives, remained difficult for machines.The performance of Large Language Models (LLMs) can be reliably improved by scaling them up, according to comments on Hacker News. While some argue that there may be diminishing returns in such an approach, others believe that there are no signs of this happening yet. Predictions range from continued drastic improvements until a model has been trained on all publicly available text, video and audio data, to concerns over the LLM hype bubble bursting. Other applications for LLMs include automating parts of businesses, generating marketing material, and image and video creation. While drawing comparisons to the crypto hype cycle, it is suggested that LLMs have already provided more value to users than all cryptocurrencies combined.Hackernews commenters discuss the potential impact of GPT-4, with some suggesting that it will allow for the creation of a \"universal UI\" that could replace the need for many traditional applications. However, others caution that GPT-4's limitations in quality and ability to accurately interpret prompts may hinder its ability to replace human developers. Some believe that AI-generated content will become a new area of opportunity for professionals who can edit and refine GPT-4's output. It is noted that GPT-4 has the potential to be as transformative as electricity, but some believe it is still in its infancy and its true impact remains to be seen.Discussion on the potential impact of artificial intelligence (AI) on various industries, including marketing and product reviews. Some commenters express skepticism about the value and quality of AI-generated content compared to human-created content, while others argue for the potential benefits of AI in creating large volumes of content quickly and easily. The issue of copyright infringement is also raised, with concerns that AI may be trained on copyrighted images without permission. However, others point out that AI's ability to generate unique content could potentially circumvent copyright issues. Overall, the discussion reflects a wide range of perspectives on the role of AI in various industries and its potential benefits and challenges.The legality of using copyrighted images to train machine learning models has been called into question. While copyright law forbids derivative works, it's quite vague due to the need for handling copyright infringement on a case-by-case basis. However, using an AI to manipulate copyrighted images is deliberate, making it different from inspiration derived by humans from existing works. While some argue that AI is just a tool, using copyrighted works for training AI models requires attribution and licensing. Furthermore, it is unlikely that AI will violate existing copyrights since it rarely recreates images in the same manner. Regardless, this is still a developing area of law that may take years for courts to resolve. In the interim, companies may opt to use AI models that have not been trained on copyrighted images to avoid potential lawsuits.People have mixed opinions about Language Models (LLMs). Some claim they are incredibly useful and have improved their work, while others find the hype around them to be overblown. There is a divide between those who see LLMs as a natural evolution of automation and those who fear that they will take away jobs, even those that require interpretation and stakeholder management. Some commenters believe that skeptics may be experiencing cognitive biases or have not given LLMs a fair chance. However, others argue that the quality of LLM output can be subpar or require significant post-processing, and that LLMs still have a long way to go before they can completely replace human work. Ultimately, opinions vary and will likely continue to do so as LLMs evolve.Comments on a forum debate the potential impact of AI language models (LLMs) on the software development industry. Some suggest that LLMs could have a profound effect on the profession, eventually resulting in more business people entering the field due to an easier barrier to entry. However, others assert that current LLMs lack the ability to interpret the nuances of specific problems and adjust code accordingly. The discussion highlights the difficulty in predicting the impact of new technologies, and how progress may come in unpredictable bursts rather than incremental improvements. Despite the potential for LLMs to revolutionize the industry, some argue that software development will continue to require human input, and that the role may shift more towards communication and business domain knowledge.This article discusses the development of language models and their potential use as a user interface for various tasks. However, not everyone is convinced of the capabilities of these models, with some criticising the hype around them and cautioning against over-extrapolation. There is also debate around what it means to \"know\" something and whether language models can truly be said to 'know' something if they only have knowledge embedded in written text. Some see language models as a tool to augment the work of developers while others worry that the overinflated claims of what they can achieve might lead to developers being replaced in the future. Despite this, there is consensus that language models like GPT-4 show promise and will continue to improve.The discussion is centered around the potential of ChatGPT and how it will impact various industries. Some commenters argue that GPT-4 is limited in what it can do and will not be able to replace programming unless the prompts are less laborious. Others believe that the progress seen in just months shows the utility this technology can provide. One person shared a short story created by Google Bard that impressed them. Some are concerned about the effect AI will have on the job market and the potential for a continuous disruption cycle. However, others see the potential for ChatGPT to supercharge productivity and act as a coach or consultant in various fields. Overall, the discussion highlights the excitement and concerns surrounding ChatGPT and AI technology in general.The author reflects on the use of AI and its potential to multiply human effort. They ran an experiment where they attempted to create a marketing campaign and website for a game, using AI-generated content, in just 30 minutes. While the result was mediocre, the potential impact of AI on productivity is clear. However, there are concerns about the quality and potential overuse of AI-generated content, which could lead to a deluge of low-quality marketing materials. Furthermore, the author highlights the importance of developing skills and being able to debug and refine AI-generated content to ensure its quality. Overall, the use of AI has the potential to significantly impact productivity but requires careful consideration and management.The author used AI to complete a marketing project in 30 minutes, including market research, creating a positioning document, writing an email campaign, creating a website, generating a logo and \"hero shot\" graphic, designing a social media campaign for multiple platforms, and creating a video script. They used Bing and GPT-4 models to teach AI about their product and then used instructions such as \"pretend you are a marketing genius,\" to guide AI in creating high-quality content. The author also used AI to design the website and create social media posts. While the author acknowledges that humans could likely create better content, AI can complete tasks much more quickly. The author concludes that we are already in a world of superhumans thanks to AI.",
    "summary": "- AI is being utilized for productivity and marketing purposes, such as generating content quickly and easily.\n- Language Models (LLMs) have the potential to automate certain aspects of businesses, but opinions on their usefulness vary.\n- There are concerns about the quality and potential overuse of AI-generated content in marketing and product reviews.\n- Questions of the legality of using copyrighted images to train AI models and potential lawsuits are being raised.\n- There is debate on the potential impact of AI language models on the software development industry.\n- ChatGPT is being discussed for its potential to impact various industries, including concerns of job displacement and productivity increase.\n- AI has the potential to significantly impact productivity, but proper management and consideration are required."
  },
  {
    "id": 35312609,
    "timestamp": 1679822715,
    "title": "ChatGPT & Interpreters Transform Software Development",
    "url": "https://andrewmayneblog.wordpress.com/2023/03/23/chatgpt-code-interpreter-magic/",
    "hn_url": "http://news.ycombinator.com/item?id=35312609",
    "content": "A post on Hacker News discusses the potential of ChatGPT and code interpreters, likening their capabilities to magic. However, the post also acknowledges some of the limitations of current chatbot AIs, such as their tendency to get important details wrong. The comment section includes discussions about the need for \"prompt engineering,\" a role which will involve developing more efficient interfaces for language models, as well as the potential for language models to become autonomous agents with dynamic memory and self-reflection. Some commenters express concerns about the implications of such advances, while others see them as necessary steps towards building more evolved AI systems.The article discusses the potential use of language models, such as ChatGPT, in software development and its possible impact on the industry. The comments highlight the need for skilled individuals to ask the right prompts to get the desired output from the model. Some suggest that LLMs could be used for simple client application development, but others note that programming requires more than just generating code. Some also express concern about the impact LLMs could have on hiring, as individuals could potentially create fake Github histories using the models. Overall, the comments highlight the potential benefits of LLMs in software development, but caution that the technology is not a replacement for human developers.The article discusses the use of an AI-powered chatbot called ChatGPT to generate code snippets on the fly with natural language input. The example given is how ChatGPT could create an .ics calendar file using a simple query. The chatbot is able to work in collaborative settings, where it provides working code snippets, which can be edited by a human for refinement purposes. The article also concedes that more complex functions may require an update to the AI model or more manual programming. The article suggests that the aim is to shift part of the workload from professional developers to AI-powered assistants. Limitations of the service are also discussed. For example, the function cannot directly generate a Lambda function with 16GB of memory allocation, contrary to an earlier suggestion.OpenAI has released a new GPT-4 plugin system, which allows the language model to run programs and create applications, as well as answer questions. Users simply need to input a basic prompt, and GPT-4 can generate a variety of responses with different levels of complexity. The plugins are particularly useful for creating recursive sub-thoughts, which will help GPT-4 solve more complex problems by breaking them down into smaller steps. The new feature could potentially help engineers utilize the model more easily, by breaking down large problems into smaller, more easily digestible steps. However, OpenAI faces difficult institutional barriers with its current cloud model, as data access inside organizations is oriented around granting permissions to individuals even when they work in teams.Developers discuss OpenAI's ChatGPT, a machine learning model that can perform tasks such as code interpretation, language translation, and text generation. One developer is reportedly working on implementing ChatGPT as a plugin for GPT-4 to act as a programming language interpreter. ChatGPT operates by generating Python code and running it in a sandboxed environment, with the potential to streamline code writing and development. Some developers express concern that the model may be limited and unable to handle some problems, but others note its potential for translation and documentation comprehension. Overall, ChatGPT is seen as both an impressive technological achievement and a tool that could transform the way developers approach programming.OpenAI is developing plugins for ChatGPT which allow code and third-party plugins to be run on the platform. The Code Interpreter plugin is already live and allows users to generate, run, and analyze output from code within the ChatGPT interface. The CI plugin can string together different sections of code and use mathematical data to upload and download a range of files. It can also create sonic and visual content such as music, sounds, and ASCII images. CI can be used to perform tasks such as optical character recognition, generate calendar invites and drawings, and to create simulations and checkers games. The results of CI's experiments show the power of the tool and it is anticipated further experimentation will be carried out on this increasingly popular AI platform.",
    "summary": "- ChatGPT and code interpreters have the potential to transform software development but have some limitations\n- Skilled individuals will be needed to prompt language models for desired outputs and programming requires more than just code generation\n- Language models can shift part of the workload from human developers to AI-powered assistants, but caution is necessary as they cannot replace human developers\n- OpenAI's GPT-4 plugin system can run programs, create applications, and answer questions with different levels of complexity\n- Developers discuss ChatGPT as a machine learning model for code interpretation and implementation as a programming language interpreter\n- OpenAI is developing plugins for ChatGPT to allow code and third-party plugins to be run on the platform, which has already shown impressive potential for various tasks."
  },
  {
    "id": 35315542,
    "timestamp": 1679844769,
    "title": "Guide: OpenAI's ChatGPT Plugins with LLaMA",
    "url": "https://blog.lastmileai.dev/using-openais-retrieval-plugin-with-llama-d2e0b6732f14",
    "hn_url": "http://news.ycombinator.com/item?id=35315542",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ChatGPT Plugins with LLaMA. Use OpenAI\u2019s chatgpt-retrieval-plugin\u2026 | by Sarmad Qadri | Mar, 2023 | lastmile aiOpen in appSign upSign InWriteSign upSign InPublished inlastmile aiSarmad QadriFollowMar 26\u00b75 min readSaveUsing ChatGPT Plugins with LLaMAOpenAI just released initial support for plugins to ChatGPT, allowing the language model to act as agents and interact with the outside world using APIs. Here we show a proof of concept using OpenAI\u2019s chatgpt-retrieval-plugin with Meta\u2019s LLaMA language model.This is more than just a guide. It is a call-to-action to build an open protocol for foundation model plugins allowing us to share plugins across LLMs, and govern their interactions.LLaMA answering a question about the LLaMA paper with the chatgpt-retrieval-plugin. So Meta!BackgroundOpenAI\u2019s documentation on plugins explains that plugins are able to enhance ChatGPT\u2019s capabilities by specifying a manifest & an openapi specification.There are few details available about how the plugins are wired to ChatGPT, but OpenAI open-sourced the chatgpt-retrieval-plugin for semantic search and retrieving custom data for additional context.In this guide we will take that retrieval plugin, and add a script that integrates it with LLaMA 7B running on your local machine.The code that glues the plugin to LLaMA is available in this repo (we welcome contributions):lastmile-ai/llama-retrieval-pluginLimitationsThis approach successfully adds external context to LLaMA, albeit with gaps compared to OpenAI\u2019s plugin approach:Limitations in the underlying model. LLaMA is far from ChatGPT in many ways. It requires significant additional fine-tuning (such as Alpaca).Not generalizable to other plugins. The OpenAI documentation suggests ChatGPT can read a plugin\u2019s API schema, and dynamically construct the right API calls that satisfy the user\u2019s request. By contrast, things didn\u2019t go well when we tried to ask LLaMA to construct a cURL request given an OpenAPI schema. One solution to this would be fine-tuning a model specifically for OpenAPI schemas.DemoWe first set up our data store and upload two PDFs to it \u2014 the LLaMA paper and the Conda cheatsheet.Then we can query this data, with the relevant embeddings pulled in to the prompt as additional context.Step-by-step guideStep 0: Clone the llama-retrieval-plugin repoGitHub - lastmile-ai/llama-retrieval-plugin: LLaMA retrieval plugin script using OpenAI's retrieval\u2026The LLaMA Retreival Plugin repository shows how to use a similar structure to the chatgpt-retrieval-plugin for\u2026github.comStep 1: Set up the data storeThis step is almost identical to setting up the OpenAI retrieval plugin, but simplified through the use of conda and using pinecone as the vector DB. Following the quickstart in the repo:Set up the environment:conda env create -f environment.ymlconda activate llama-retrieval-pluginpoetry installDefine the environment variables:# In production use-cases, make sure to set up the bearer token properlyexport BEARER_TOKEN=test1234export OPENAI_API_KEY=my_openai_api_key# We used pinecone for our vector database, but you can use a different oneexport DATASTORE=pineconeexport PINECONE_API_KEY=my_pinecone_api_keyexport PINECONE_ENVIRONMENT=us-east1-gcpexport PINECONE_INDEX=my_pinecone_index_nameStart the server:poetry run startStep 2: Upload files to the data storeFor this step, we used the Swagger UI available locally at http://localhost:8000/docsAuthorize:Authorize using the value of the BEARER_TOKEN you specified in Step 1Upsert File:Specify any PDF file that you would like to get chunked into embeddingsQuery the data store to test:Take the id returned by the upsert, and construct a query in the Swagger UI to see what embeddings will be returned given a prompt:{  \"queries\": [    {      \"query\": \"What is the title of the LLaMA paper?\",      \"filter\": {        \"document_id\": \"f443884b-d137-421e-aac2-9809113ad53d\"      },      \"top_k\": 3    }  ]}The query API lets you test out the vector store, and configure the filtersStep 3: Set up LLaMAOur repo links to llama.cpp as a submodule, which is what we used for getting LLaMA 7B running locally.Follow the llama.cpp readme to get set upllama.cpp/README.md \u00b7 ggerganov/llama.cppInference of LLaMA model in pure C/C++ Hot topics: The main goal is to run the model using 4-bit quantization on a\u2026github.comStep 4: Use LLaMA to query your custom dataOpen a new Terminal, and navigate to the llama-retrieval-plugin repo.Activate the Conda environment (from Step 1):conda activate llama-retrieval-pluginDefine the environment variables:# Make sure the BEARER_TOKEN is set to the same value as in Step 1export BEARER_TOKEN=test1234# Set the URL to the query endpoint that you tested in Step 2export DATASTORE_QUERY_URL=http://0.0.0.0:8000/query# Set to the directory where you have LLaMA set up -- such as the root of the llama.cpp repoexport LLAMA_WORKING_DIRECTORY=./llama.cppRun the llama_with_retrieval script with the desired prompt:python3 llama_with_retrieval.py \"What is the title of the LLaMA paper?\" This script takes the prompt, calls the query endpoint to extract the most relevant embeddings from the data store, and then constructs a prompt to pass to LLaMA that contains these embeddings.You can read the code here: llama-retrieval-plugin/llama_with_retrieval.pyStep 5: Tweak and experimentYou can modify the llama_with_retrieval script to experiment with different settings that may yield better performance:Change the token limit (e.g. reduce it to give more room for the model response).Change the prompt template and observe model behavior.Change the LLaMA model parameters by modifying the command line. Note: You can also specify a custom LLaMA command line by setting the LLAMA_CMD environment variable.You can also use lastmileai.dev to track your various experiments as you tweak and tune models. For example, here\u2019s a notebook saving some trials using Stable Diffusion.Protocols over PlatformsWe hope this exercise shows the need for standardizing interactions between foundation models and plugins/extensions. We should be able to use a plugin designed for OpenAI models with another large language model, and vice versa. This is only possible with a Foundation Model Plugin Protocol standard.We are in the early stages of a revolution in computing, powered by the advent of state-of-the-art foundation models. We have an opportunity to define the behaviors that govern our interactions with these models, and return to the rich legacy of open protocols of the early internet instead of closed platforms of the modern era.Foundation Model Plugin ProtocolThe lastmile ai team is exploring what it takes to define a plugin protocol, and spur its adoption. We believe the protocol should be:model-agnostic \u2014 support GPTx, LLaMA, Bard, and any other foundation model.modal-agnostic \u2014 support different types of inputs and outputs, instead of just text.Our early thinking on this is inspired by SMTP for email, and LSP (Language Server Protocol) for IDEs. We will be sharing what we have in this space in the coming days, and would love to collaborate with you.Call to actionWe are just getting started at lastmile ai, and would love to hear from you, especially if you share our vision for an open and interoperable future. You can reach us here:TwitterDiscordEmailWe would also appreciate your feedback on our initial product offering, available at lastmileai.dev.Generative AiOpenAIChatgptDeveloperProtocol----3More from lastmile aiFollowUse lastmile ai to experiment with generative AI, personalize it for your use cases, and integrate it in your application. For enterprises and developersRead more from lastmile aiAboutHelpTermsPrivacyGet the Medium appSarmad Qadri9 Followerslastmileai.devFollowHelpStatusWritersBlogCareersPrivacyTermsAboutText to speech\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- OpenAI has released support for plugins to ChatGPT, allowing the language model to interact with the outside world using APIs.\n- This guide demonstrates a proof of concept using OpenAI's chatgpt-retrieval-plugin with Meta's LLaMA language model.\n- The limitations of this approach include differences in the models and difficulties in generalizing to other plugins.\n- The step-by-step guide includes setting up the data store, uploading files, setting up LLaMA, using LLaMA to query custom data, and experimenting with different settings.\n- The lastmile ai team is exploring the need for a Foundation Model Plugin Protocol standard to standardize interactions between foundation models and plugins/extensions."
  },
  {
    "id": 35313171,
    "timestamp": 1679829094,
    "title": "GPT-4 Passes Reverse Turing Test: But Intelligence is More Than Mimicking Humans",
    "url": "https://gist.github.com/rain-1/3bf56122b0ebeac929dff0f881ee8e4c",
    "hn_url": "http://news.ycombinator.com/item?id=35313171",
    "content": "The article describes a reverse Turing test where the author asked GPT-4 to come up with ten questions to determine if the answerer was an AI or human. The author then provided their own answers and asked ChatGPT to respond as well. GPT-4 was able to correctly identify if the responder was an AI or human based on their answers, but the author notes that intelligence is not just the ability to pretend to be human. The author suggests setting up a proper Turing test and putting restrictions on the human tester to make it more interesting. Additionally, the article includes the exact prompt used to get ChatGPT to answer the reverse Turing test questions. The results show the complexity of AI-generated responses that mimic human emotions and experiences.The text contains three different drafts of ten statements, each pertaining to a different topic, such as personal memories or emotions. The statements are brief, and the goal is to capture the key points in a short summary. The topics vary from discussing empathy for strangers, experiencing a dream of flying, and artificial intelligence becoming indistinguishable from human intelligence. Each draft is distinct and offers different perspectives and analogies. However, the common theme seems to be valuing the present moment and striving to make a positive impact on the world, whether through personal fulfillment or empathy towards others. The language is descriptive and emotional, but there are elements of sarcasm present in some statements.The text discusses personal opinions on various topics, including a dream of flying, the potential of artificial intelligence, and the meaning of life. There is also a discussion about different language models, including GPT-4 and Bard, and the possibility of comparing their performance through a reverse Turing test. One comment provides an analysis of Bard's answers, suggesting that they were likely generated by an AI rather than a human due to their generic nature and lack of personal perspective. The discussion highlights the potential of language models and their capabilities, as well as the importance of understanding their limitations and potential biases.",
    "summary": "- GPT-4 passes reverse Turing test, but intelligence is more than mimicking humans. \n- Author suggests a proper Turing test with more restrictions on human testers. \n- Article includes exact prompt used for ChatGPT to answer reverse Turing test questions. \n- Three draft statements capture key points on valuing present moment and making positive impact. \n- Different perspectives on topics such as dream of flying, AI potential, and meaning of life. \n- Language models like GPT-4 and Bard have potential but also limitations and biases."
  },
  {
    "id": 35317419,
    "timestamp": 1679853626,
    "title": "Using SQLite for Partial File Deduplication with BLAKE3",
    "url": "https://sqlite.org/forum/forumpost/7fecf11e42c71a91?raw",
    "hn_url": "http://news.ycombinator.com/item?id=35317419",
    "content": "A Hacker News user shared \"the craziest\" way they had used SQLite: for partial file deduplication. The post prompted discussion about other deduplication methods, with some users suggesting ZFS deduplication as an alternative. Others commented on the challenges of handling file updates in games, and suggested using technologies like cluster-replicated SQLite and content-defined chunking as possible solutions. The post also included a link to an analysis of deduplication compared to whole-file based storage. The users expressed interest in possible use cases for this method, particularly for developers updating content. Some commenters went into more technical detail, discussing block-level versus whole-file deduplication, and touching on topics like the cluster block terms and alignment considerations for Steamworks developers.The writer shares the \"craziest thing\" they used SQLite for: partial file deduplication. They created a database with tables representing files and their corresponding hash values. The challenge was to also track partial file matches, which required storing hashes of each allocation block of each file. The author's approach involved using the BLAKE3 hash function to compute hashes and a complex query to match similar files. They compared their complex approach to a simpler alternative approach and found that the complex approach saved more space in the long run. Other commenters on the post shared their own unconventional use cases for SQLite, including using it for file deduplication when datasets don't fit in memory and using it to store all system administration data.",
    "summary": "- A user shared their unconventional use of SQLite for partial file deduplication, which sparked discussion on alternative deduplication methods and challenges in handling file updates for games.\n- Possible solutions included cluster-replicated SQLite and content-defined chunking, and an analysis of deduplication was shared for comparison to whole-file based storage.\n- Interest was expressed in possible use cases for developers updating content, and technical details were discussed such as block-level versus whole-file deduplication and alignment considerations for Steamworks developers.\n- The author's approach involved using BLAKE3 hash function and a complex query to match similar files, proving more space-saving than a simpler alternative. \n- Other commenters shared their own unconventional use cases for SQLite, including file deduplication when datasets exceed memory and storing system administration data."
  },
  {
    "id": 35316808,
    "timestamp": 1679850543,
    "title": "The Importance & Challenges of Software Development Estimation",
    "url": "https://pm.stackexchange.com/questions/34768/why-are-developers-expected-to-estimate-tasks-at-all",
    "hn_url": "http://news.ycombinator.com/item?id=35316808",
    "content": "Developers are expected to estimate tasks to help the buyer in various ways, such as making commitments to customers, planning for external resources, knowing when resources are free for the next project, getting an idea of completion costs, and making priority calls. However, many developers argue that there are too many unknowns to provide accurate estimates, leading to pressure from managers to still provide some sort of estimate. Ranged estimates are often recommended, with wider margins for more unknown tasks, to convey uncertainty and allow for more flexible planning. Some argue that constantly providing estimates can be detrimental, leading to confrontational atmospheres and incentivizing developers to avoid changes that may put the deadline at risk.Developers discuss the challenges of providing accurate estimates for projects. They note that providing a range for estimates can be helpful, but pressure to narrow that range can result in inaccurate predictions and unrealistic expectations. There can also be unknown factors or risks that affect the timeline for completion. Some developers emphasize the importance of communication about these uncertainties and the need for stakeholders to understand the limitations of estimates. They argue that providing educated guesses based on available information and being transparent about potential risks can be more helpful than simply providing a deadline without proper consideration of unknowns. Ultimately, balancing the need for planning and budgeting with the reality of software development can be a tricky task.Software estimates can be difficult to make due to unknowns in organization and system context, making accurate narrow estimates rare. Developers are subject experts and should aim to provide an optimistic and pessimistic take on unknowns, what could be done, and how long it may take. A small feature can take anywhere from several months to a day depending on system constraints, and external consultants may have to estimate without much data. However, it's better to aim for a conservative estimate than a quicker but riskier one. It's also important for PMs and developers to work together to identify unknowns and create a path to make estimation possible, rather than insisting that it's impossible.The difficulty of estimating development time is a common topic among developers, with some arguing that it is impossible, while others emphasize the importance of providing estimates for planning purposes. However, the argument that estimating is always impossible is often inaccurate, and may arise as a result of poor factoring of codebases or lack of knowledge regarding potential steps of a project. It is important for developers to acknowledge the limitations of their estimates and communicate them effectively to stakeholders, while managers should also be aware of the uncertainties and risks involved in software development. Furthermore, businesses should prioritize creating a healthy culture of communication and collaboration between developers and stakeholders to ensure that project goals are realistic and achievable.The debate over whether or not software developers should provide estimates continues. Some argue that estimates are necessary for planning and prioritisation, while others argue that providing estimates is burdensome and often leads to unrealistic expectations. Comparisons have been made with other disciplines, such as construction contractors, who operate under legal regulations that require them to provide estimates and deliver projects at a fixed price. However, these comparisons are not always accurate, given the unique challenges of software development. Developers agree that estimating is important, but emphasise the difficulty of estimating accurately, particularly when there are so many \"unknown unknowns\". To address this problem, there needs to be a better approach to estimating and communication between developers and management.The idea that estimates are always unreliable is throwing out the baby with the bathwater. Although unknown things are not known precisely, they can still have bounds that provide a useful estimate. Developers can fail to communicate their confidence levels when giving estimates, but this does not mean estimates are useless. Managers use estimates to set deadlines and scope quality, and developers can use them to plan and communicate with stakeholders. Non-engineering people in tech companies may not be held to the same high standards of productivity, leading them to be seen as 'worthless'. Though the complexity of software development work varies greatly, it can be unpredictable due to unknown unknowns.Developers are frustrated with being asked for estimates for software development projects, arguing that almost everything they write is unique and cannot be compared to the repetition of carpentry work. They warn that estimates are usually inaccurate and can be pressured to be reduced, resulting in wild variances in project timelines. Instead, they advise giving four-to-eight weeks of development time before estimating, which can inform a rough estimate of whether the project will take a year or five years. However, others argue that for many software projects, there are comparable analogues, including security and rest CRUD. They also caution against seeking the blank cheque approach with open-ended projects.The discussion centers around the challenge of providing accurate estimates for software development projects. Some commenters suggest that asking for estimates can be helpful for scoping and communication purposes, but that they are rarely accurate. Others argue that it is difficult to provide accurate estimates due to the complexities and unknowns involved in software development. One commenter shares that most engineers tend to underestimate and that patterns can be used to adjust for this. Despite the challenges and limitations, many businesses still rely on estimates for planning and decision-making. The conversation also touches on issues of trust between business leaders and technical teams, as well as the potential for scapegoating when projects run into problems.The discussion revolves around whether the estimate provided by engineers is accurate and whether it is ethical for them to intentionally delay work until the end stages of the project. Some suggest that this is a common practice, and it is necessary to manage risks and ensure that hard requirements are fulfilled. They also suggest that this is how Scrum is intended to work. However, others are concerned that this creates problems with trust and leads to unfair compensation. Managers' attitudes towards this may depend on their preference for estimated vs. actual time spent on work. Some feel that accurate estimates are impossible due to uncontrollable external factors such as changing requirements and priorities, and that engineers may not be responsible for delays in such cases.Software development estimation is challenging due to changing requirements and iterative development. Engineers often face imprecise requirements and are blamed for late delivery when sales should never have sold the project in the first place. Estimation is often domain-specific, with precise estimators having more success when working on projects that align with their particular skillset. Management can provide precise requirements but should be aware of the impact of changes on timelines. It is also essential to recognize that software engineering is not equivalent to applied mathematics, and the challenges involved in estimation should be acknowledged. Ultimately, effective software development relies on communication and clear expectations between all parties involved.Software engineers often push away complex math-based solutions for \"satisfactory\" CS101 student-level solutions. While estimating resources for tasks can be challenging, even technically sophisticated software contains ordinary programming tasks. In software development, the people in higher positions with a bird's eye view of the project should be knowledgeable and accountable for estimates. Developers cannot entirely control the ecosystem they are working in, making it difficult to be authoritative about delivery times. Agile software development frameworks remove developers from the time estimation effort and rely on past performance, with developers focusing on breaking work up evenly. Ultimately, time estimation is an integral part of an engineer's job, and the goal is to provide the best solution for the client, whether it is fast or high quality.A software developer argues against the idea that software development is unmatched in its uniqueness and cannot be estimated. The developer contends that software development is like any other profession in that it involves building upon existing solutions and that there is a vast market for reusable software. The resulting snowflakes are not perfectly unique, but different variations on a common template. Suggesting that software development is so unique and complex that it defies estimation is therefore delusional according to the developer. They argue that much of the difficulty stems from poor planning and a lack of knowledge\u2014problems that could be addressed more effectively with a standardized vocabulary and improved training. Meanwhile, the developer also raises concerns about management pressure and unpaid overtime.The question of why developers are expected to estimate tasks in project management is raised in an online forum. Some commenters argue that estimating tasks is crucial to understanding and managing project constraints, and that experienced engineers should be able to provide high-level estimates based on past work. Others note that estimation is often inaccurate and can lead to unrealistic expectations and pressure to work overtime. Some suggest that effective communication between developers and management is necessary to ensure realistic expectations, and that improvements in decomposing work into smaller units and using agile frameworks could improve estimation accuracy. Ultimately, the need for managing project constraints within acceptable tolerances will not go away, but the process should be continually evaluated for improvement.In software development, estimates are used to manage risk and costs, and there are several techniques available to make estimation simpler and less contentious, such as continuous, iterative, and incremental delivery. In a Scrum environment, stories must be estimated for sprint planning, and developers are best positioned to estimate them, having the necessary experience and institutional memory of implementing similar stories in the past. Story points are used instead of time estimates to avoid the culture of predicting or forecasting and to enable estimates to include points for complexity and risk, rather than being based solely on time. Project managers need to understand that estimates are only estimates and not promises, and developers should be clear that their commitment is to the Sprint Goal, not to individual stories. Successful product development involves trading scope for timescale and requires regular engagement with stakeholders and prioritization of work in terms of business value and risk.The importance of estimating tasks in software development is discussed. There are many reasons for this, such as helping developers think through their work, meeting business deadlines, and providing useful information for marketing and sales teams. However, there are good and bad ways to do estimation, with a collaborative approach using ranges being effective. Management is expected to provide estimates as they must make informed risk decisions about business choices based on how long things take. While software development is not carpentry, both have similar uncertainty levels. The problem lies in the fact that there are more novice developers than master developers in the software world. For developers, estimating is a skill that can be developed with experience, producing more accurate estimates.The text highlights the importance of estimating project schedules for software development. Companies need schedules and deadlines to ensure that the project's delivery schedule meets the expectations of the salesman and accountants, and for account purposes. Software development is fundamentally different from other disciplines in that it is infinitely malleable, can have near-zero manufacturing costs, has zero lead time for raw materials and the requirements are always changing at the last minute. However, it is important to hold the \"Software is different!\" card close to your chest and play it at the end when people are asking for last-minute requirement changes. The author advises against playing that card upfront as it makes the estimator look like a whiner. The frustration of the estimator cannot be resolved by lowering estimates, and the importance of a realistic estimate is paramount to ensure progress is measurable.The text is a page on Stack Overflow, a popular Q&A website for programmers. It lists various questions related to project management and software development, such as estimating using story points instead of hours, project workflow, testing during sprints, and improving the process of estimation. The page also includes links to related questions and discussions on the website. Users can sign up or log in using Google, Facebook, or email and password. The website is licensed under CC BY-SA and collects user contributions. The page also includes information on Stack Exchange's privacy policy, terms of service, and cookie policy.",
    "summary": "- Developers are expected to estimate tasks but argue that there are too many unknowns to provide accurate estimates, leading to pressure from managers to still provide some sort of estimate.\n- Ranged estimates with wider margins for more unknown tasks are recommended to convey uncertainty and allow for more flexible planning.\n- Communication about uncertainties and the need for stakeholders to understand the limitations of estimates is important, and educated guesses based on available information can be more helpful than simply providing a deadline without proper consideration of unknowns.\n- Software estimates can be difficult to make due to unknowns, making accurate narrow estimates rare, but aiming for a conservative estimate is better than a quicker but riskier one.\n- Developers and PMs should work together to identify unknowns and create a path to make estimation possible, rather than insisting that it's impossible.\n- The debate over whether or not software developers should provide estimates continues, with some arguing that estimates are necessary for planning and prioritization, while others argue that providing estimates is burdensome and often leads to unrealistic expectations.\n- Effective software development relies on communication and clear expectations between all parties involved.\n- Stories should be estimated using story points instead of time estimates to enable estimates to include points for complexity and risk, rather than being based solely on time.\n- Software development estimates are important, and while it is challenging due to changing requirements and iterative development, it is not impossible to estimate tasks.\n- There are good and bad ways to do estimation, with a collaborative approach using ranges being effective."
  },
  {
    "id": 35312468,
    "timestamp": 1679821004,
    "title": "Differences between Language Models & Human Intelligence",
    "url": "https://www.atmosera.com/ai/understanding-chatgpt/",
    "hn_url": "http://news.ycombinator.com/item?id=35312468",
    "content": "A discussion on Hacker News explores the differences between human intelligence and the language processing abilities of large language models (LLMs) such as ChatGPT. Some argue that the Poverty of the Stimulus argument (which suggests that some aspects of language learning are innate) supports the idea that humans use different mechanisms than LLMs for reasoning and learning. Others highlight that while babies may only be exposed to a small amount of language, they additionally learn from a range of multimodal inputs such as touch and vision. Some also argue that software will never be able to replicate the direct experience and consciousness of humans. However, others point out the impressive capabilities of LLMs, such as being able to generate code faster than human interns.The claim that Language Model AI (LLM) systems are nothing more than glorified word predictors is incorrect, even if humans share some abilities with primates and animals. LLMs can handle inputs other than language and are becoming more complex as they gain the ability to process visual input. The real question is whether the relationship between language and perception is important in understanding the meaning of language. While LLMs are capable of mimicking reasoning in certain areas, they often lack a proper model of the subject they are talking about and are unable to ask the right questions to fill in the gaps. As AI researchers add more modalities to LLMs, these models will become more sophisticated and closer to human capabilities.The article discusses the moral implications of creating artificial beings with intelligence similar to humans. The author argues that just because biological life forms are merely glorified chemical information systems, it should not justify using an artificial being to diminish anyone's humanity. The focus should be on the principles that guide the use of technology. The comments section includes a debate about the similarity between humans and LLMs (language model machines), with some arguing that humans are inherently different and others pushing for exploration of the question. The conversation also touches on fears that LLMs could be used to displace human workers, and the role of capitalism in limiting technological progress.ChatGPT, an AI language model, can generate creative and hypothetical responses to nonsensical or incoherent prompts. It can also model the emotional connection, positive energy, and collective harmony that participants experience while engaging in a group activity, such as a gorroborin. However, its ability to reason and construct new knowledge from prior information is limited. It requires a large corpus of data and a massive amount of processing power to achieve such fluency in language and reasoning. While it can produce interesting concepts and ideas, they are likely based on existing knowledge and ideas. Thus, the debate on whether AI can truly create something entirely new and original remains. Criticism and concerns about AI should still be encouraged and discussed, rather than dismissed as anti-AI sentiments.The discussion centers around the limitations of large language models (LLMs) like GPT and their ability to truly understand complex systems, problem-solving, and reasoning. While some argue that LLMs are impressive pattern recognizers, their inability to self-validate and reasoning confines them to limited outputs based on their training data. The debate also touches on the defining factors of intelligence and the potential of AI to achieve self-preservation, self-actualization, and consciousness. Overall, the sentiment is not dismissive of LLMs, but cautious of their current and future limitations, requiring human oversight and expert knowledge to address their blind spots and potential misuses.The conversation discusses the differences between human and artificial intelligence. The argument is made that humans are able to experience time, have agency, and can use both to improve their responses, leading to more intelligent decision-making. Language is also discussed as an interface rather than the full essence of human thinking. However, the counterargument is made that humans are bound by physical laws and that agency is simply the brain coordinating its circuits. Additionally, it is suggested that language is a reductive representation of experience. The conversation concludes by pointing out that while artificial intelligence can give the illusion of intelligence or \u201cknowing,\u201d it has yet to be trained to admit when it does not know something, something humans are trained to do.The article discusses how ChatGPT, a computer program that generates human-like text based on input, is not sentient and only operates on statistical models. The debate concerns whether the program has emergent structures or algorithms within the neural network that go beyond statistics and predictions. The article suggests that there may be a higher-level abstraction at work but ultimately concludes that ChatGPT is just a glorified word predictor. The discussion parallels the debate about whether humans are just reasoning machines or if there is an emergent property, such as consciousness, that arises from the physical structures and processes in the brain. The article acknowledges that the higher-level structures in both ChatGPT and humans may be too complex to fully understand.The debate about whether or not language models like ChatGPT have sentience continues. Some argue that the model is simply a glorified word predictor, while others suggest that it offers insight into higher-level phenomena. One user notes that abstraction doesn't necessarily represent how things actually work, but can be a way of making something easier to think about. Meanwhile, another user questions whether there truly is a distinction between the ChatGPT and the human mind. While humans may be able to reason and perform arithmetic, he suggests, they are still reliant on the same statistical inferences that underpin machine learning algorithms. Regardless, the role of abstractions and the evolving capabilities of language models continue to be a subject of debate.Language models such as ChatGPT excel at predicting the next word statistically based on prior words, but this isn't reasoning or thinking as humans do. The model doesn't consider implications, possible outcomes, or options. However, it appears that it can reason in a sense, and create art, poetry, and new ideas. Humans need examples and training data to create something new, while ChatGPT doesn't. Math is still a hurdle for the system. Some conversations on HN address the possibility of GPT thinking and reasoning, with most agreeing that it's not yet possible. Several links are provided for more technical and less technical explanations of how GPT functions.OpenAI's ChatGPT's astonishing performance is due to the massive amount of data and computational power it processes, according to posters on Hacker News. They claim that the architecture of the model is well-understood, but what makes it unique is the sheer quantity of data it uses to learn and the complexity of the problems that it can solve. The training process involves three stages: pre-training on a range of input-output pairs to build general knowledge, then task-solving on up to 2,000 supervised data sets that develop how it executes prompts, and finishing with a\u00a0process of refining responses until they conform to human preferences. The result is a model that possesses reasoning and problem-solving abilities.ChatGPT is a deep-learning model created by OpenAI for natural language processing (NLP). It can generate human-like prose and produce code in multiple programming languages. ChatGPT uses a transformer encoder-decoder architecture to operate iteratively, generating text or code by predicting the next word or line based on the context in which it is used. It is trained with large amounts of data, making it capable of translating text or codes it has never seen before. ChatGPT falls under the branch of NLP, which encompasses a variety of activities that include text classification, keyword extraction, named-entity recognition, document summarization, and question answering. It has limitations though, and the advancement of AI could dislocate skilled workers and enable a concentration of wealth.Google's natural language processing tool BERT was trained with over 2.5 billion words from Wikipedia articles and 800 million words from Google Books to understand human language. It can be fine-tuned for specific tasks such as sentiment analysis or question answering. BERT's key to understanding human language is Masked Language Modeling, which removes random words from a text and predicts the missing words using text on the left and right. On the other hand, OpenAI's ChatGPT is a Transformer encoder-decoder model that can generate text based on natural language prompts. It was trained with half a trillion words and can perform certain NLP tasks without fine-tuning. ChatGPT responds to prompts by predicting words based on probabilities derived from the vast corpus of text it was trained on. It was also trained on billions of lines of code from GitHub. ChatGPT became available through a REST API in March 2023.",
    "summary": "- Discussion on the differences between human intelligence and language processing abilities of language models.\n- Language models are not just glorified word predictors and can handle inputs other than language.\n- Language models have limitations in understanding complex systems, problem-solving, and reasoning.\n- ChatGPT is a deep-learning model that can produce human-like text and code and is trained on large amounts of data.\n- Both BERT and ChatGPT are NLP tools but differ in their training methods and capabilities.\n- The debate over whether language models have sentience is ongoing.\n- Morality and ethics in creating artificial beings with intelligence similar to humans are discussed.\n- Criticism and concerns about AI should be encouraged and discussed."
  },
  {
    "id": 35312960,
    "timestamp": 1679826767,
    "title": "China's Open-Source RISC-V Processor: 1.5 GHz Speed Reached",
    "url": "https://github.com/OpenXiangShan/XiangShan",
    "hn_url": "http://news.ycombinator.com/item?id=35312960",
    "content": "A discussion on Hacker News on an open-source high-performance RISC-V processor turned into a debate on China's success recipe. While one user praised the country for its long-term plans, education, research investment, knowledge sharing, and corporate cooperation, others raised concerns, saying China's education focuses on test-taking rather than innovation, and that innovation is discouraged in polite company. One user said that there is no meritocracy in the Chinese Communist Party and that some corporations are corrupt. The discussion then moved on to China's writing system, with one user stating it as an obstacle to learning the Chinese language. Overall, the discussion highlighted differing opinions on China's success and limitations.The OpenXiangShan team in China has developed an open-source RISC-V processor, based on the Berkeley Out-of-Order RISC-V Processor (BOOM) microarchitecture. The team is aiming to build a high-performance processor at a lower energy consumption, with a target frequency of 2.5 GHz, and the initial results show that it has achieved 1.5 GHz. The processor is based on a hybrid custom RISC-V core with 9-10 pipeline stages, and it has a full 64-bit floating-point pipeline with a 3-cycle latency. The team claims it speeds up some workloads more than an Intel Xeon Gold 6130 CPU. Bounty on this project, from China's government-supported Zhongguancun Development Group, is worth $1m in total.\nChina's chip developers have built a 64-bit computer circuit using the free and open RISC-V architecture. The device can reach speeds of 2GHz and was created using the open source programming language Chisel, which is based on Scala. Chisel is quickly becoming a popular option for hardware design, with semiconductor firm SiFive using it, while the burgeoning open-source RISC-V architecture is being backed by the likes of Nvidia and Google parent Alphabet. Ultimately, an international standard should result for open RISC, which means little or no royalty charges on its use. The regulatory framework to regulate China-based issuers poses risks to US investors, according to financial commentators.XiangShan is an open-source RISC-V processor project that has been developed since June 2020. The current version of XiangShan, known as Kunminghu, is still under development, while the first stable micro-architecture of XiangShan is Yanqihu which can be found on the yanqihu branch. The project employs a sub-module from the open-source community such as L2 Cache/LLC by SiFive and Diplomacy/TileLink by Rocket-chip. XiangShan uses a DSL called \"Chisel\" that is a mixture of the Scala programming language and HDL, which generates synthesizable Verilog for hardware implementation. It is notable that as per the comments, the use of the Scala programming language in hardware design is not entirely odd and is quite efficient.",
    "summary": "- China's OpenXiangShan team has developed an open-source RISC-V processor based on Berkeley Out-of-Order RISC-V Processor microarchitecture that has reached a speed of 1.5 GHz, aiming for a target frequency of 2.5 GHz with a lower energy consumption than current processors.\n- The processor is built with a custom RISC-V core with 9-10 pipeline stages and a 64-bit floating-point pipeline with a 3-cycle latency, and it is claimed to speed up some workloads more than an Intel Xeon Gold 6130 CPU. It has received a $1m bounty from China's government-supported Zhongguancun Development Group.\n- Chisel, an open-source programming language based on Scala, is becoming a popular option for hardware design, including by the XiangShan project, while the RISC-V architecture is being backed by companies such as Nvidia and Alphabet, and an international standard for open RISC is expected to emerge.\n- Discussions on Hacker News highlighted differing opinions on China's success and limitations, with some praising the country for its long-term plans, education, research investment, knowledge sharing, and corporate cooperation, while others raised concerns about test-taking education, innovation discouragement, and corruption in the Chinese Communist Party."
  },
  {
    "id": 35310336,
    "timestamp": 1679799593,
    "title": "Flash Emulator Ruffle Progresses AS3 Support for Alternatives",
    "url": "https://ruffle.rs/blog/2023/03/12/progress-report.html",
    "hn_url": "http://news.ycombinator.com/item?id=35310336",
    "content": "Ruffle, a Flash emulator written in Rust, has made progress on supporting ActionScript 3.0 (AS3), with the team admitting the runtime environment is a lot stricter than AS1 or AS2. Ruffle supports ExternalInterface, enabling AS3 and HTML5 code to be mixed. However, socket support is not on the cards, as the web does not allow arbitrary TCP/IP sockets. Moreover, the emulator cannot emulate PeerConnection, which will need all-Ruffle swarms or some kind of peer forwarding protocol for mixed Ruffle/Flash Player swarms. Several coders commented on the ease and value of using Flash for gaming and animation. Adobe could not have released the player as open source, as it was still selling Adobe Animate.Flash was an innovative indie game engine before Unity, with a creative ecosystem for web games facilitated by Flash. However, Flash suffered from resource-hogging and various vulnerabilities that could trigger malware. The switch from a web where everyone publishes to a web where Facebook and YouTube dominate helped kill it. Adobe's reluctance to license the JVM led it to develop Adobe Flash Player, which was ubiquitous but built on flawed scripting, causing crashes and security problems. Ruffle, an open-source emulator for Flash content, has been engineered as an alternative for Flash after its time. It's easy to put on a website and ensures that Flash content is part of the open web, even on iPhones. Despite Adobe's SWF crate, there is as yet no good FOSS replacement for Flash's animation UI.Ruffle has made huge improvements to its engine accuracy and AVM1 capabilities, with many ActionScript 2 games now fixed. A page on its website now shows which ActionScript 3 APIs have been implemented, with frequent updates promised. XML support is also improving, fixing unresponsive buttons and menus. Support for mobile devices is also progressing, with text input boxes and context menus now working on iOS. Dynamic audio buffering has been introduced, making audio playback smoother, and some AVM2 games' intro sounds will soon be fixed. Drawing accuracy is also being worked on. Many fan-favorite Flash games are now playable, and new games are being added regularly.",
    "summary": "- Ruffle, an open-source Flash emulator written in Rust, progresses on supporting ActionScript 3.0 (AS3), with ExternalInterface support for mixing AS3 and HTML5.\n- Socket and PeerConnection support is not possible due to web limitations, but Ruffle shows promise as a replacement for Flash after its time.\n- Flash was an innovative indie game engine with a creative ecosystem for web games, but suffered from resource-hogging and security problems, leading to its decline.\n- Ruffle makes huge improvements to its engine accuracy, AVM1 capabilities, and ActionScript 2 game fixes, with improving XML support and mobile device compatibility.\n- Many favorite Flash games are now playable on Ruffle, and new games are being added regularly."
  },
  {
    "id": 35315310,
    "timestamp": 1679843773,
    "title": "English Spelling Absurdities: Complex Orthography Exemplified",
    "url": "https://english.stackexchange.com/questions/396553/what-is-this-famous-example-of-the-absurdity-of-english-spelling",
    "hn_url": "http://news.ycombinator.com/item?id=35315310",
    "content": "The article discusses an example of the absurdity of English spelling. The example is a word that was spelled in the most difficult way possible, but still followed orthographic rules in English. This simple word was spelled in a very complex way, such as \"fish\" being spelled like \"phystch.\" This is not a definitive example, and other examples include \"ghoti,\" which is pronounced like \"fish,\" and \"ghoughphtheightteeau,\" which is pronounced like \"potato.\" However, it is important to note that these examples arise from an incorrect application of the rules linking orthography to phonology, and the constructed word's three parts are inconsistent with how they would be pronounced in those placements. Nonetheless, such examples highlight the absurdity of English spelling.The text is a question on the website Stack Exchange, asking about a burning city referenced in the song \"I'll Try\" from the Tinkerbelle and the Lost Treasure soundtrack. The text also includes information about subscribing to the website's RSS feed and the company's policies. The website is focused on English language and usage, and provides a platform for users to ask and answer questions on various topics. The website is owned by Stack Exchange Inc, and user contributions are licensed under CC BY-SA. The website uses cookies, and users can customize their cookie settings.",
    "summary": "- English spelling can be absurd, as exemplified by words spelled in the most difficult way possible but still following orthographic rules.\n- Examples include \"fish\" spelled as \"phystch\" and \"ghoti\" pronounced as \"fish\" and \"ghoughphtheightteeau\" pronounced as \"potato.\"\n- These examples arise from an incorrect application of rules linking orthography to phonology.\n- Such examples highlight the absurdity of English spelling.\n- The text is a question on Stack Exchange about a burning city referenced in a song from the Tinkerbelle and the Lost Treasure soundtrack.\n- Stack Exchange is a platform for asking and answering questions on various topics related to English language and usage.\n- User contributions on Stack Exchange are licensed under CC BY-SA and the website uses cookies that users can customize."
  },
  {
    "id": 35309988,
    "timestamp": 1679796825,
    "title": "US Home Prices Reach 100-Year High Ratio to Income",
    "url": "https://www.longtermtrends.net/home-price-median-annual-income-ratio/",
    "hn_url": "http://news.ycombinator.com/item?id=35309988",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome Price to Income Ratio (US & UK) - 75 Year Chart | LongtermtrendsSubscribe to newsletterEvery month we send out an email about the latest developement in the chartsSubscribeLongtermtrends Home Price to Income Ratio (US & UK)Home Price to Median Household Income Ratio (US)Loading DataPlease wait, we are loading chart dataInterpretationHistorically, an average house in the U.S. cost around 5 times the yearly household income. During the housing bubble of 2006 the ratio exceeded 7 - in other words, an average single family house in the United States cost more than 7 times the U.S. median annual household income. The Case-Shiller Home Price Index seeks to measure the price level of existing single family homes in the United States. Based on the pioneering research of Robert J. Shiller and Karl E. Case the index is generally considered the leading measure of U.S. residential real estate prices. The index has a base of Jan 2000=100 and is multiplied by 1800 in order approximate the Average Sales Price of Houses Sold for the United States.  According to Mike Maloney this ratio is heavily influenced by interest rates. When interest rates go down the affordability of a house goes up, so people spend more money on a house. Interest rates have now been falling since 1981 when they peaked at 15.32% (for a 10-year US treasury bond).Data SourcesRecent dataFederal Reserve Bank of St. Louis: S&P/Case-Shiller U.S. National Home Price IndexFederal Reserve Bank of St. Louis: Median Income since 1983Historical datacensus.gov Median Income from 1947 until 1965DaveManuel.com: Median Income from 1967 until 1983Online Data Robert Shiller: Historical US Home prices until 1983Further InformationTradingView Chart: Average Sales Price of Houses Sold / Median Household Income in the United StatesLongtermtrends: The Real Home Price (US & UK)Longtermtrends: Stocks vs. Real EstateLongtermtrends: Real Estate to Gold RatioLongtermtrends: Yields for Mortgages, Corporate Bonds, and Treasury BondsHome Price vs. Median Household Income (US)Loading DataPlease wait, we are loading chart dataInterpretationThis chart gives a different view of the data from the chart above, comparing the percentage change between Case-Shiller Home Price Index (multiplied by 1800, as explained above) and Median Household Income in the United States over time.Average House Price to Average Income Ratio (UK)Loading DataPlease wait, we are loading chart dataInterpretationThis chart shows the ratio of the average UK house price to average annual income. The ratio declined steadily throughout the late 19th and early 20th centuries until the first world war. This was at a time when the vast majority of British people still rented from private landlords. The ratio fluctuated mostly between 4 and 7.5 through the rest of the 20th century and increased in economic booms and financial bubbles.Data SourcesRecent dataHM Land Registry: UK House Price Index since 2000Office for National Statistics: Consumer price inflation since 2000Historical dataBank of England: Research datasets (A millennium of macroeconomic data - House Price Index: A32)Bank of England: Research datasets (A millennium of macroeconomic data - Composite Average Weekly Earnings series: A47)Further InformationThe Guardian: A brief history of British housingHouse Prices vs. Average Income (UK)Loading DataPlease wait, we are loading chart dataInterpretationThis chart gives a different view of the data from the chart above, comparing the percentage change between UK house prices and average incomes over time. Page extended with data for the UK, by Will BeaufoyDownload Data for 19.95 USDView More Charts Longtermtrends DonateBitcoin Donations: bc1qvu8a9uy5p6lptdm3n3hyljer4s9ud2kfm4gv95In the news Terms of use NewsletterLongtermtrendsDonateBitcoin Donations: bc1qvu8a9uy5p6lptdm3n3hyljer4s9ud2kfm4gv95In the news Terms of use Newsletter Charts powered by Highcharts. All rights reserved.Your browser is out of date!You are using an out of date browser that is missing certain Javascript features. For this reason, the charts cannot be displayed.Please update to a modern browser: a list is available here.CloseAn error appeared while loading the data. Maybe there is a technical problem with the data source. Please let me know if this happens regularly @silvan_frank.",
    "summary": "- US home prices have reached a 100-year high ratio to income.\n- Historically, an average house in the US has cost around 5 times the yearly household income, but during the 2006 housing bubble, the ratio exceeded 7.\n- The Case-Shiller Home Price Index is considered the leading measure of US residential real estate prices.\n- The UK's average house price to average annual income ratio declined steadily throughout the late 19th and early 20th centuries until the first world war.\n- The UK's house price to income ratio mostly fluctuated between 4 and 7.5 through the rest of the 20th century and increased in economic booms and financial bubbles."
  },
  {
    "id": 35312563,
    "timestamp": 1679822128,
    "title": "The Anti-Productivity Manifesto: Choose What Matters to You",
    "url": "https://invertedpassion.com/the-anti-productivity-manifesto/",
    "hn_url": "http://news.ycombinator.com/item?id=35312563",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Anti-Productivity Manifesto - Inverted Passion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInverted Passion\nBe passionate about the territory, not the map\n \n\n\n\ud83d\udcee Subscribe to New Posts\n\ud83e\uddd9 About Me\n\ud83d\udcda Mental Models Book\n\ud83c\udf31 Knowledge Garden\n\ud83e\uddf5 Twitter Threads\n Menu\n\n\n\n\n\n\n\nThe Anti-Productivity Manifesto \nPosted on March 25, 2023March 25, 2023Author Paras ChopraPosted in Notes and Summaries \n\n\nAfter a barrage of recommendations on my twitter, I finally ended up reading Oliver Burkeman\u2019s Four Thousand Weeks. The central premise of the book is simple: everyone has got about four thousand weeks to live, and spending that limited time chasing efficiency is wrongheaded.\n\n\nThe message seems old. The entire self-help industry revolves around saying variations of it. Stay in the present. Enjoy the moment. Seize the day. But where the book differs from the rest is that it\u2019s both poetic and philosophical. It\u2019s the kind of the book that, once you finish, you end up mumbling: gosh, I should have written it.\nProductivity Treadmill\nLet\u2019s say you\u2019re very efficient at work. You like inbox zero. You don\u2019t like any unread messages on Slack. Because you\u2019re so efficient, you can do the same work in a few hours that others would do in a day or more. What should your days look like?\nIn an ideal world, such efficient folks like yourself would invest a few hours per day working hard, but then spend the rest of the day in a lazy glory. You\u2019re efficient, so you should be tending to gardens, playing cards with friends, daydreaming, cooking new recipes, calling old friends and going for long walks in nature. \nBut do you?\nWhat actually happens \u2013 you get more work. The world notices how fast you turnaround work and starts pushing more work your way. Your rapid replies on email only gets you more emails because your co-workers start expecting rapid replies for every little thing.\nThe key insight worth internalizing is that the amount of work offered by the world is effectively infinite. \nAnd if the work available is infinite, this constant productivity won\u2019t help you \u201cfinish\u201d your work faster, as there\u2019s no finishing in the first place. If there were, all the years of productivity and efficiency should have led you to a life full of bliss. But what you got instead is probably a burnout.\nThe Fisherman and The Businessman\nYou may have heard of this Brazilian parable before: \n\nA businessman meets a fisherman and offers him to teach efficient methods of fishing. \nThe fisherman asks what would we get from more efficiency, and the businessman replies that efficiency can help him make a lot of money and be rich.\nThen the fisherman asks what he would do if he had a lot of money, the businessman says he\u2019ll have all the time in the world. He could dance with friends, host dinners and maybe catch a few fish.\nThe fisherman looks puzzled and asks the businessman: \u201cIsn\u2019t that what I\u2019m doing now?\u201d\nThe point of the parable isn\u2019t that money is bad, or even that efficiency doesn\u2019t have its place in the world. The lesson is that a life chasing efficiency is actually internally inconsistent. You ought to be efficient, so you can enjoy life, and the parts of life that bring us joy are often things we do for their own sake without caring about efficiency. (There\u2019s no \u201cefficient\u201d way of going about long walks in nature, or sharing tiny bits of harmless gossip with close friends.)\nThe feeling of being left behind\nAll theory aside, the feeling that you\u2019d be left behind your peers is very real. A millionaire lawyer in front of her boss still feels that she has a lot to catch up on. The ten-million dollar worth boss still feels he has a lot to prove because he yet again missed winning the award. And the award-winning lawyer feels all the pressure to keep up with all the up-and-coming lawyers vying for what is truly hers.\nThe fear of the irrelevancy and losing out in the race impacts universally. It does not matter whether you\u2019re on top or in the middle, whether you have enough money to retire for the rest of your life, or whether you have won awards. The treadmill never stops.\nNo wonder, the second most common regret of the dying people is that they worked too hard.\n\nThis came from every male patient that I nursed. They missed their children\u2019s youth and their partner\u2019s companionship. Women also spoke of this regret, but as most were from an older generation, many of the female patients had not been breadwinners. All of the men I nursed deeply regretted spending so much of their lives on the treadmill of a work existence.\n\nAntidote to productivity: choose what matters to you\nThe only way to escape the productivity treadmill is to actively choose what matters to you. If friendships are important to you, choose to spend an evening with friends instead of delivering that project report ahead of time. If belonging is essential to you, cultivate weekends around \u201cpointless\u201d hobbies. Health is significant to everyone, so take out time for meditation and going to the gym.\nMost work (but not all) is a means to an end. Often we\u2019re not addicting to a particular kind of work, but the mere behavior of working. Answering emails feels good, irrespective of what kind of emails we\u2019re answering. Realize that this is a trap. If you must work hard and be efficient, consciously pick that work. Constantly ask yourself why are you working so hard on this damn thing. If the answer is: \u201cso I can get ahead\u201c, remind yourself that it\u2019s a treadmill and you\u2019ll always stay at the same place, no matter how fast you run.\nEmbracing finitude\nThere are infinite things to do in life. Driven by FOMO, the more things you want to cram in your finite days, the more it will feel that you\u2019re losing out. You cannot visit all the cities in the world, so if you feel like you must travel around the world, expect disappointment.\nSame with career and relationships. You cannot sample everything that the world has to offer, as the world offers effectively infinite choices. Finitude requires making peace with making few choices and living with the consequences. If you\u2019re constantly craving more, you\u2019d never appreciate what you already have.\nLife is nothing but a set of choices. And that is what makes it beautiful.\nYou don\u2019t have time, you are time\nTime is a series of nows. In that sense, the future never arrives. And if the future never arrives, why live a life continuously oriented towards it? I think most of us intuitively know that the present moment is all that exists, but we remain fixated on the future because we\u2019re often suffering in the present moment. The future gives us a false hope of moments devoid of suffering, but we don\u2019t realize suffering is self-created. The very fact that we believe the future will be better devalues the present moment.\nPerhaps this is with Buddha was hinting. The ultimate liberation from suffering \u2013 the enlightenment \u2013 happens when you\u2019re at peace with and bask at merely existing.\n\n\nJoin 130k+ followers\nFollow @paraschopra\n\n\n\n\nGet my new essays in your email\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost navigation\n\u2190 Wealth is not money, it\u2019s the things we use money for\n \n\n\n\n\n\n\n\n\n\nEssays with most visits\nHow money works\nHow to avoid cognitive bias\nThe real use of money is to buy freedom\nWhat does the Bhagavad Gita teach\nWhy are scientists paid so little\nTime is not running out\nOn becoming a leader in 10 hard steps\nBiases in product design\nWhy value based pricing is not a good way to set prices\nTypes of network effects\nProfessional and personal life success\n \n\nI tweet something new dailyFollow @paraschopra \n\n\nRecent essays\n\n\nThe Anti-Productivity Manifesto\n\n\nWealth is not money, it\u2019s the things we use money for\n\n\nYou can only succeed if you know how you can fail\n\n\nNotes from \u201cOgilvy on Advertising\u201d\n\n\nStartups live and die in a multidimensional landscape\n\n\nSocial media of the future will be human-to-AI, not human-to-human\n\n\nThink from first principles before you Google (or ask ChatGPT)\n\n\nBye 2022. Hello 2023.\n\n\nAll essays All essays\n\nSelect Month\n March 2023 \u00a0(2)\n February 2023 \u00a0(4)\n January 2023 \u00a0(1)\n December 2022 \u00a0(1)\n November 2022 \u00a0(1)\n October 2022 \u00a0(2)\n September 2022 \u00a0(1)\n August 2022 \u00a0(2)\n July 2022 \u00a0(5)\n June 2022 \u00a0(2)\n May 2022 \u00a0(4)\n April 2022 \u00a0(4)\n March 2022 \u00a0(5)\n February 2022 \u00a0(3)\n January 2022 \u00a0(5)\n December 2021 \u00a0(2)\n November 2021 \u00a0(3)\n October 2021 \u00a0(3)\n September 2021 \u00a0(3)\n August 2021 \u00a0(3)\n July 2021 \u00a0(3)\n June 2021 \u00a0(1)\n May 2021 \u00a0(4)\n April 2021 \u00a0(4)\n March 2021 \u00a0(5)\n February 2021 \u00a0(5)\n January 2021 \u00a0(5)\n December 2020 \u00a0(2)\n November 2020 \u00a0(3)\n October 2020 \u00a0(2)\n September 2020 \u00a0(2)\n August 2020 \u00a0(4)\n July 2020 \u00a0(2)\n March 2020 \u00a0(1)\n January 2020 \u00a0(1)\n November 2019 \u00a0(1)\n September 2019 \u00a0(1)\n July 2019 \u00a0(1)\n May 2019 \u00a0(2)\n April 2019 \u00a0(2)\n March 2019 \u00a0(2)\n February 2019 \u00a0(1)\n January 2019 \u00a0(2)\n December 2018 \u00a0(1)\n November 2018 \u00a0(1)\n October 2018 \u00a0(3)\n September 2018 \u00a0(4)\n August 2018 \u00a0(1)\n July 2018 \u00a0(2)\n June 2018 \u00a0(3)\n May 2018 \u00a0(3)\n April 2018 \u00a0(6)\n March 2018 \u00a0(8)\n February 2018 \u00a0(9)\n January 2018 \u00a0(13)\n December 2017 \u00a0(11)\n June 2017 \u00a0(1)\n March 2017 \u00a0(1)\n January 2017 \u00a0(1)\n September 2016 \u00a0(1)\n August 2016 \u00a0(1)\n June 2016 \u00a0(2)\n February 2016 \u00a0(1)\n July 2015 \u00a0(1)\n February 2015 \u00a0(1)\n December 2013 \u00a0(1)\n October 2013 \u00a0(1)\n July 2013 \u00a0(1)\n June 2013 \u00a0(1)\n May 2013 \u00a0(1)\n March 2013 \u00a0(1)\n February 2013 \u00a0(1)\n November 2012 \u00a0(1)\n October 2012 \u00a0(1)\n August 2012 \u00a0(1)\n July 2012 \u00a0(1)\n June 2012 \u00a0(1)\n May 2012 \u00a0(3)\n April 2012 \u00a0(1)\n March 2012 \u00a0(3)\n February 2012 \u00a0(1)\n January 2012 \u00a0(2)\n December 2011 \u00a0(1)\n November 2011 \u00a0(1)\n October 2011 \u00a0(2)\n September 2011 \u00a0(1)\n August 2011 \u00a0(2)\n July 2011 \u00a0(1)\n June 2011 \u00a0(2)\n May 2011 \u00a0(1)\n April 2011 \u00a0(1)\n March 2011 \u00a0(1)\n January 2011 \u00a0(2)\n December 2010 \u00a0(2)\n November 2010 \u00a0(2)\n October 2010 \u00a0(1)\n August 2010 \u00a0(2)\n June 2010 \u00a0(1)\n April 2010 \u00a0(1)\n January 2010 \u00a0(1)\n December 2009 \u00a0(1)\n November 2009 \u00a0(1)\n October 2009 \u00a0(3)\n September 2009 \u00a0(1)\n August 2009 \u00a0(1)\n July 2009 \u00a0(1)\n June 2009 \u00a0(2)\n April 2009 \u00a0(2)\n March 2009 \u00a0(1)\n February 2009 \u00a0(1)\n January 2009 \u00a0(1)\n December 2008 \u00a0(1)\n November 2008 \u00a0(1)\n October 2008 \u00a0(3)\n September 2008 \u00a0(3)\n August 2008 \u00a0(6)\n July 2008 \u00a0(7)\n June 2008 \u00a0(10)\n May 2008 \u00a0(10)\n April 2008 \u00a0(24)\n March 2008 \u00a0(2)\n February 2008 \u00a0(3)\n January 2008 \u00a0(1)\n September 2007 \u00a0(11)\n August 2007 \u00a0(4)\n July 2007 \u00a0(7)\n June 2007 \u00a0(8)\n May 2007 \u00a0(5)\n April 2007 \u00a0(6)\n March 2007 \u00a0(8)\n February 2007 \u00a0(11)\n January 2007 \u00a0(5)\n December 2006 \u00a0(4)\n November 2006 \u00a0(14)\n October 2006 \u00a0(9)\n September 2006 \u00a0(11)\n August 2006 \u00a0(5)\n July 2006 \u00a0(4)\n June 2006 \u00a0(11)\n May 2006 \u00a0(11)\n April 2006 \u00a0(13)\n March 2006 \u00a0(20)\n February 2006 \u00a0(10)\n January 2006 \u00a0(16)\n December 2005 \u00a0(41)\n November 2005 \u00a0(10)\n October 2005 \u00a0(5)\n September 2005 \u00a0(3)\n August 2005 \u00a0(7)\n July 2005 \u00a0(7)\n June 2005 \u00a0(4)\n May 2005 \u00a0(4)\n April 2005 \u00a0(8)\n March 2005 \u00a0(10)\n\n\n \n\nPages\n\nAbout Me\nAll blog posts and essays\nBold Conjectures Podcast\nFree Resources\nGaur & Chopra Escape Velocity Grant\nJoin Our Community\nMental Models for Startup Founders\nProjects\nStart here\nSubscribe to updates\nTwitter Threads\nWelcome, my friend\n\n\n\nSearch for:\n\n\n\n \n\n \n\r\n\t\t\t\t\t\t\t\t\t\t\u00a92021 Paras Chopra\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- The book Four Thousand Weeks by Oliver Burkeman argues that chasing efficiency is not the best use of our limited time on Earth. \n- Being efficient at work can lead to more work and a never-ending productivity treadmill. \n- The parable of the fisherman and the businessman highlights the importance of not solely chasing money and efficiency. \n- The fear of falling behind our peers and the pressure to constantly work hard can lead to regret. \n- To escape the productivity treadmill, it's crucial to actively choose what matters to us and prioritize things like friendships, hobbies, and health. \n- Embracing the limits of our time and choices can lead to a greater appreciation of the present moment. \n- Time is a series of nows and living solely for the future devalues the present moment."
  },
  {
    "id": 35317590,
    "timestamp": 1679854590,
    "title": "Hacker News & TechCrunch under maintenance",
    "url": "https://techcrunch.com/2023/03/26/tech-company-layoffs-2023-morale/",
    "hn_url": "http://news.ycombinator.com/item?id=35317590",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechCrunch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechCrunch\nWe'll be right back...\nOur engineers are working quickly to resolve the issue.Thank you for your patience.\n\n\n\n\n\n",
    "summary": "- Hacker News is currently experiencing delays and is unable to serve requests quickly.\n- TechCrunch is currently under maintenance and engineers are working quickly to resolve the issue."
  },
  {
    "id": 35316822,
    "timestamp": 1679850609,
    "title": "SVB Collapse Threatens $500B VC \"Haircut\" for Industry",
    "url": "https://www.bloomberg.com/news/articles/2023-03-24/svb-debacle-could-mean-a-500-billion-venture-capital-haircut",
    "hn_url": "http://news.ycombinator.com/item?id=35316822",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilicon Valley Bank Collapse Threatens VC Industry With $500B Markdown - Bloomberg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\nSkip to content\n\nBloomberg the Company & Its ProductsThe Company & its ProductsBloomberg Terminal Demo RequestBloomberg Anywhere Remote LoginBloomberg Anywhere LoginBloomberg Customer SupportCustomer Support \n\n\n\n\n \n\n\n\n             Switch Editions        UK      Europe      US      Asia      Middle East      Africa      \u65e5\u672c       Sign In Subscribe                Live Now   Bloomberg TV+            Bloomberg Markets European Open Bloomberg Markets European Open kick starts the trading day, breaking down what's moving markets and why. Francine Lacqua and Tom Mackenzie live from London bring you an action-packed hour of news no investor in Europe can afford to miss.      Bloomberg Radio            Bloomberg Daybreak Europe Overnight on Wall Street is morning in Europe. Bloomberg Daybreak Europe, anchored live from London, tracks breaking news in Europe and around the world. Markets never sleep, and neither does Bloomberg News. Monitor your investments 24 hours a day, around the clock from around the globe.  Listen      Bloomberg Originals            FourFourTwo: The Art of Goal Scoring Fast. Clever. Deadly. Deceptive. Are goalscorers born or made? Do you have to be selfish to be a striker? Is finding the back of the net the hardest job in football? The modern day striker has to be many things to make it to the top. FourFourTwo gets inside the mind of a striker, interviewing the masters of the art and the men who have to mark them, including Jermain Defoe, Romelu Lukaku, Michael Owen, Martin Keown and Ledley King.      Also streaming on your TV:                               Markets   Markets     Deals   Odd Lots   The FIX | Fixed Income   ETFs   FX   Factor Investing   Alternative Investing   Economic Calendar   Markets Magazine                 City of London Events Attendance Hit by Banking,\u00a0Tech Turmoil: The London Rush                 Markets Presight AI Soars 176% in Abu Dhabi Debut After $496 Million IPO       Market Data   Stocks   Commodities   Rates & Bonds   Currencies   Futures   Sectors      View More Markets      Economics   Economics     Indicators   Central Banks   Jobs   Trade   Tax & Spend   Inflation & Prices                 Economics China\u2019s Economic Recovery Faces Risks From Global Trade Slump                 Economics China Industrial Profits Drop on Weak Demand, Falling Prices                  Inflation & Prices Singapore Price Pressures Top Hong Kong With Quicker Reopening       View More Economics      Industries   Industries     Consumer   Energy   Entertainment   Finance   Health   Legal   Real Estate   Telecom   Transportation                 Technology South Korea Officials Seek Arrest of Do Kwon\u2019s Former Terraform Labs Colleague Daniel Shin                 Cybersecurity Pinduoduo App Malware Detailed by Cybersecurity Researchers       Featured   Business of Sports      View More Industries      Technology   Technology     Code Wars   Checkout   Prognosis                 Cybersecurity Pinduoduo App Malware Detailed by Cybersecurity Researchers                 Technology Twitter Source Code Leak Turns Into Hunt for Perpetrator                  Technology South Korea to Surpass China in Chip Machine Spending Next Year       View More Technology      Politics   Politics     US   UK   Americas   Europe   Asia   Middle East                 Politics Netanyahu Mulls Delay to Courts Overhaul As Protests Rock Israel                 Politics Ukraine Latest: Hungary to Vote on Finland\u2019s Bid to Join NATO       Featured   Next China      View More Politics      Wealth   Wealth     Investing   Living   Opinion & Advice   Savings & Retirement   Taxes   Reinvention                 Wealth When\u00a0Selling an \u2018\u00a38 Million\u2019 Flat for 25% Less Is the Right Call                 Wealth Bank of America Trims Banking, Lending Group Amid Industry Slump       Featured   How to Invest      View More Wealth      Pursuits   Pursuits     Travel   Autos   Homes   Living   Culture   Style                 Critic Review: Sweeney Todd, Sondheim\u2019s Bloody Barber, Is Back                 Screentime \u2018John Wick: Chapter 4\u2019 Comes Out Blazing With $73.5M       Featured   Screentime   New York Property Prices   Where to Go in 2022      View More Pursuits      Opinion   Opinion     Business   Finance   Economics   Markets   Politics & Policy   Technology & Ideas   Editorials   Letters                 John Authers A Tale of Two Crises \u2014\u00a0and One Is Even in France                 Javier Blas The Mystery of the Missing Oil Barrels Is Solved                  Parmy Olson Tech\u2019s AI Armies Are Huge, Yet\u00a0Struggling to Innovate       View More Opinion      Businessweek   Businessweek     The Bloomberg 50   Best B-Schools   Small Business Survival Guide   50 Companies to Watch   Good Business   Subscribe to the Magazine                 Finance How to Keep Corporate Accounts Safe Amid Bank Collapse Jitters                 Technology What Happens When Sexting Chatbots Dump Their Human Lovers                  Feature Iranian Activists Want Tech Companies to Ban the Ayatollah       View More Businessweek      Equality   Equality     Corporate Leadership   Capital   Society   Solutions                 Equality Black Children Six Times More Likely for UK Police\u00a0Strip Search                 City of London 50 Years Since Women Trailblazers Joined London Stock Exchange       Featured   In Trust Podcast      View More Equality      Green   Green     New Energy   ESG Investing   Weather & Science   Electric Vehicles   Climate Politics   Greener Living   Cleaner Tech                 Green BHP to Trial Carbon Capture With Major Chinese Steelmaker                 Green Plan to Curb Coal And Gas to Seal Key Australia Climate Pact       Featured   Data Dash   Hyperdrive      View More Green      CityLab   CityLab     Design   Culture   Transportation   Economy   Environment   Housing   Justice   Government   Technology                 CityLab Howard University Tackles Persistent Housing Woes With Bond Deal                 Economy Venezuela's Electrical Blackouts Widen Gap Between Rural and Urban Areas                  Environment Air Pollution Casts a Pall Over Booming Bangladesh Megacity       View More CityLab      Crypto   Crypto     Decentralized Finance   NFTs   Regulation   Technology                 Crypto Bitcoin Liquidity Hits 10-Month Low Even With the Price Surging                 Crypto Venezuela\u2019s Oil Graft Probe Widens With 11 More Arrest Warrants                  Crypto Bitcoin Retreats; Justin Sun-Linked Coins Drop After SEC Charges       View More Crypto       More                               \n\n\n\n\nTechnologySVB Collapse Could Mean a $500 Billion Venture Capital \u2018Haircut\u2019More scrutiny, disclosure is expected after SVB\u2019s collapse: BI\u201cExtend and pretend\u201d approach won\u2019t solve valuation problemByDiana Li+FollowMarch 24, 2023, 6:02 PM UTCListen to this article1:22Share this articleCopiedGiftGift this articleExitSubscriber BenefitBloomberg subscribers can gift up to  5 articles a month for anyone to read, even non-subscribers! Learn moreSubscribeSign InFollow the authors@diana_k16+ Get alerts forDiana LiThe $2 trillion venture capital industry could see portfolio markdowns of 25% to 30% \u2014 a \u201chaircut\u201d of possibly $500 billion \u2014 following the Silicon Valley Bank debacle, according to Bloomberg Intelligence.\u00a0\u201cAfter the failure of SVB, we expect greater valuation scrutiny and disclosure, especially as a large chunk of \u2018fiduciary\u2019 capital from pension funds has flowed into these markets \u2014 and unlike endowments and family offices, there are no avenues to extend and pretend,\u201d Bloomberg Intelligence analyst Gaurav Patankar writes in a note Friday.LIVE ON BLOOMBERGWatch Live TVListen to Live RadioMost ReadBusinessFirst Citizens\u00a0Nears Deal to Buy\u00a0Silicon Valley Bank, Sources SayTechnologyJack Ma\u2019s Retreat Undercuts China\u2019s Pitch to Private BusinessMarketsBond Traders Go All-In on US Recession Bets That Defy Fed ViewMarketsFirst Citizens Buys Silicon Valley Bank After Run on LenderMarketsInvestors Brace for Another Week of Volatility as Mad March Ends\n\n\n\n\n\n\n\nTerms of Service\n\nTrademarks\nPrivacy Policy\n\u00a92023 Bloomberg L.P. All Rights Reserved\n\n\nCareers\nMade in NYC\nAdvertise\nAd Choices\nHelp\n\n\n\n\n\n\n\n\n\n\n     \n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- Silicon Valley Bank's collapse could result in a \"haircut\" of up to $500 billion for the venture capital industry, with portfolio markdowns of 25% to 30%.\n- Greater valuation scrutiny and disclosure is expected following the failure of SVB, particularly as pension funds have invested a large chunk of fiduciary capital in these markets.\n- Unlike endowments and family offices, pension funds have no avenues for \"extend and pretend\" to manage valuations, so increased scrutiny may be necessary."
  },
  {
    "id": 35313232,
    "timestamp": 1679829628,
    "title": "Top Picks for Text-Only News Websites Reduce Distractions & Increase Speed",
    "url": "https://blog.wturrell.co.uk/text-only-news-websites/",
    "hn_url": "http://news.ycombinator.com/item?id=35313232",
    "content": "Web developer William Turrell recommends text-only news websites for faster loading times, lower data usage and reduced distraction from ads and unnecessary content. Turrell points to CNN, 68k News and CBC as top picks for their quality of coverage and relatively straightforward designs. While some outlets mix opinion with reporting, Turrell also suggests using an e-reader device for truly text-only experiences such as news from the Reuters Foundation or BBC's On This Day archive site. He also suggests using an ad blocker and, for desktop users, browser extensions like uBlock Origin and Firefox Multi-Account Containers to keep tracking cookies separate. The post also includes suggestions on phone or app choices to optimise reading experiences.The blog post discusses alternatives to websites that are loaded with ads and cookies, causing stress to readers. The author recommends turning off JavaScript in Safari settings to access text-only versions of sites like NPR and BizToc Light, which have fewer disturbances. They also suggest using the Reuters app for iOS, which has an offline mode and fast news photos, and is available for older devices. The post also includes links to the author's website and other posts on topics such as Mac shortcuts and debugging complex MySQL queries.",
    "summary": "- Web developer William Turrell recommends text-only news websites for faster loading times, lower data usage, and reduced distractions.\n- Top picks for text-only news websites include CNN, 68k News, and CBC for their quality of coverage and straightforward designs.\n- Using an e-reader device can provide a truly text-only experience with news from Reuters Foundation or BBC's On This Day archive site.\n- Utilize browser extensions like uBlock Origin and Firefox Multi-Account Containers to keep tracking cookies separate and use ad blockers.\n- To optimize reading experiences, there are suggestions for phone or app choices such as the Reuters app for iOS with an offline mode and fast news photos.\n- Safari settings allow for turning off JavaScript to access text-only versions of sites like NPR and BizToc Light, which have fewer disturbances."
  },
  {
    "id": 35311667,
    "timestamp": 1679812216,
    "title": "AI Successfully Diagnoses Dog's Ailments via ChatGPT 4",
    "url": "https://twitter.com/peakcooper/status/1639716822680236032",
    "hn_url": "http://news.ycombinator.com/item?id=35311667",
    "content": "A dog owner shared their experience of using ChatGPT 4 as a health consultant which helped to diagnose their dog's ailments successfully. The pet owner had visited a veterinarian to cure their dog's symptoms but failed to obtain an accurate diagnosis. After exhausting traditional methods of obtaining advice, the pet owner turned to ChatGPT 4 for guidance and was able to identify the correct diagnosis. They found GPT-4 to be more calculated and informative when providing diagnoses as compared to Google searches. This case illustrates that AI-enabled healthcare is an effective and efficient means to diagnose ailments and provides an alternate approach when traditional methods fail. Nonetheless, it is vital for patients to consult with a medical professional rather than placing excessive dependence on AI.The discussion on HN revolves around the competence of human professionals, particularly in the medical field, compared to current AI technology, such as ChatGPT. Many comments suggest that AI may not suffer from incompetence in the same way humans do, and despite their mistakes and occasional hallucinations, AI may be better than human professionals in many regards. However, some commenters caution against blindly following AI advice and suggest integrating AI into the medical diagnosis workflow instead of replacing humans. Anecdotes are shared regarding poor medical advice in developing countries, and the conversation touches on the potential risk of AI causing harm if users rely solely on its advice. Overall, the discussion centers on the potential benefits and risks of AI technology in the medical field.A Twitter user shared how OpenAI's language model GPT-4 correctly diagnosed a life-threatening case of anemia in their dog through ChatGPT. The diagnosis was based on blood test results that the user uploaded, which GPT-4 scanned to identify multiple possible causes of anemia. The user consulted another veterinarian, who confirmed the diagnosis and prescribed the appropriate treatment, saving their pet's life. While some raised concerns about the accuracy of AI-generated medical advice, others pointed out that the tool is a promising development that could help improve accessibility to healthcare, especially in areas with limited medical resources.The author expresses their optimism towards conversational AI, particularly Chat GPT 4, as a tool that can enable them to be more productive and delegate tasks. They acknowledge that it may disrupt certain aspects of their work, particularly in figuring out how to use various tools, but they see it as a massive enabler that can cross-check ideas, provide inspiration, and explore new concepts with. The author also finds the panic and conservatism surrounding GPT and AI to be a bit repulsive and prefers a more positive outlook on the technology. They believe that AI will change lots of things and cannot wait for the advancements it will bring.",
    "summary": "- A dog owner successfully used ChatGPT 4 to diagnose their pet's ailment when traditional methods failed, highlighting the potential of AI in healthcare. \n- The HN discussion revolves around the benefits and risks of AI technology in medicine, and the competence of human professionals. \n- Anecdotes were shared about poor medical advice in developing countries, and the potential risks of relying solely on AI advice. \n- ChatGPT 4 correctly diagnosed a life-threatening case of anemia in a dog, saving its life, but concerns were raised about the accuracy of AI-generated medical advice. \n- The author expresses optimism towards conversational AI, particularly Chat GPT 4, as a tool enabling productivity and exploration of new concepts."
  },
  {
    "id": 35317882,
    "timestamp": 1679856036,
    "title": "GUI Gallery: Windows 11, Apple II, Quark Catalyst 3",
    "url": "http://toastytech.com/guis/index.html",
    "hn_url": "http://news.ycombinator.com/item?id=35317882",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphical User Interface Gallery\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n GUIs\n Site News\n\n Xerox\n Visi On\n GEM\n Deskmate\n GEOS\n Desqview/X\n AmigaOS\n RISC OS\n BeOS\n QNX\n OS/2\n Apple\n Linux/Unix\n Windows\n Win Shells\n Misc GUIs\n\n GUI Timeline\n GUI Sites\n\n\n\n\n\u00a0\n\n\nWelcome to my GUI Gallery\n\n\nOn these pages you will find many screen shots of various desktop computer\nGraphical User Interfaces and operating systems. Many different people\nhave had different ideas of how a GUI should work and these screen shots\nshow many of the more popular ones.\nYes, an actual update:\nNew: Microsoft\nWindows 11 - Some quick screen grabs of Windows 11. Yuck.\nNew: Apple\nII Desktop 1.2 Prealpha - Some enthusiasts have made some enhancements\nto the Apple II Desktop.\nNew: Quark Catalyst\n3 - Finally some real screen shots thanks to an unprotected version.\nIf you find anything on this site that doesn't work right, or if you\nhave any suggestions please e-mail\nme! (If you do, please be absolutely sure to put something meaningful\nin the subject line, and use plain text, otherwise it will get deleted\nas spam)\nAnd be sure to check out my favorite GUI VisiCorpVisi\nOn now with a downloadable hard drive image that you can run under\nMESS 0.101 or later. Back in in 1983 there was a GUI platform and\noffice package for IBM PCs called Visi On from VisiCorp. Legend has it\nBill Gates saw a demo of this running at the 1982 comdex running on an\nIBM PC. He freaked out because Microsoft didn't have anything like this\nyet, ran back to Microsoft Headquarters, and had them start work on what,\nseveral years later, became Windows.\nAnd if you haven't already, don't forget to laugh really hard at Microsoft\nBOB!\n\n\n\n\n\n\n\n\n\n",
    "summary": "- A GUI Gallery featuring various Graphical User Interfaces and operating systems. \n- New additions include Microsoft Windows 11, Apple II Desktop 1.2 Prealpha, and Quark Catalyst 3. \n- The site welcomes feedback and suggestions from users. \n- Also includes information on VisiCrop's Visi On, a GUI platform and office package for IBM PCs, rumored to have inspired Bill Gates to start development on Windows."
  },
  {
    "id": 35318797,
    "timestamp": 1679860262,
    "title": "Run Wild: Rust CLI Automation with GPT-4 & Headless Chromium",
    "url": "https://github.com/refcell/run-wild/commit/7b71a4cd928b4382dd3086e7843170880075c098",
    "hn_url": "http://news.ycombinator.com/item?id=35318797",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrun wild gpt, run free... \u00b7 refcell/run-wild@7b71a4c \u00b7 GitHub\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\n\n\n\n            Sign\u00a0up\n          \n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n        Product\n        \n\n\n\n\n\n\n\n\n\n\n\nActions\n        Automate any workflow\n      \n\n\n\n\n\n\n\nPackages\n        Host and manage packages\n      \n\n\n\n\n\n\n\nSecurity\n        Find and fix vulnerabilities\n      \n\n\n\n\n\n\n\nCodespaces\n        Instant dev environments\n      \n\n\n\n\n\n\n\nCopilot\n        Write better code with AI\n      \n\n\n\n\n\n\n\nCode review\n        Manage code changes\n      \n\n\n\n\n\n\n\nIssues\n        Plan and track work\n      \n\n\n\n\n\n\n\nDiscussions\n        Collaborate outside of code\n      \n\n\n\nExplore\n\n\n      All features\n\n    \n\n\n\n      Documentation\n\n    \n\n\n\n\n\n      GitHub Skills\n\n    \n\n\n\n\n\n      Blog\n\n    \n\n\n\n\n\n\n\n\n        Solutions\n        \n\n\n\n\n\nFor\n\n\n      Enterprise\n\n    \n\n\n\n      Teams\n\n    \n\n\n\n      Startups\n\n    \n\n\n\n      Education\n\n    \n\n\n\n\n\nBy Solution\n\n\n      CI/CD & Automation\n\n    \n\n\n\n      DevOps\n\n    \n\n\n\n\n\n      DevSecOps\n\n    \n\n\n\n\n\nCase Studies\n\n\n      Customer Stories\n\n    \n\n\n\n      Resources\n\n    \n\n\n\n\n\n\n\n\n        Open Source\n        \n\n\n\n\n\n\n\n\nGitHub Sponsors\n        Fund open source developers\n      \n\n\n\n\n\n\nThe ReadME Project\n        GitHub community articles\n      \n\n\n\nRepositories\n\n\n      Topics\n\n    \n\n\n\n      Trending\n\n    \n\n\n\n      Collections\n\n    \n\n\n\n\n\nPricing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this user\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n \n\n\n\n\n              Sign in\n            \n\n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        refcell\n \n/\n\nrun-wild\n\nPublic\n\n\n      forked from m1guelpf/browser-agent\n\n\n\n\n \n\nNotifications\n \n\n \n\nFork\n    18\n\n\n\n\n \n\n\n          Star\n 184\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\n\nPull requests\n0\n\n\n\n\n\n\nActions\n\n\n\n\n\n\n\nProjects\n0\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\n\nInsights\n\n\n\n \n \n\n\n\nMore\n\n\n \n\n\n                  Code\n \n\n\n                  Pull requests\n \n\n\n                  Actions\n \n\n\n                  Projects\n \n\n\n                  Security\n \n\n\n                  Insights\n \n\n\n\n\n\n\n\n\nPermalink\n\n\n\n\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\n\nBrowse files\n\n\n\n\n\n\n\n\n\n\n      run wild gpt, run free...\n    \n\n\n\n\n\n\nLoading branch information\n\n\n\n\n\n\n\n\n \n\n\nrefcell\n    \n  committed\n  Mar 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n        1 parent\n          \n          e2d067c\n\ncommit 7b71a4c\n\n\n\n\n\n\n\n\n \n\n\n Show file tree\n\n\n \n\n\n Hide file tree\n\n\n\n      Showing\n      6 changed files\n      with\n      34 additions\n      and\n      26 deletions.\n    \n\n\n\n\n    Split\n\n    Unified\n\n \n\n \n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.env.example\n\n\n\n\n\n\n\n        .env.example\n      \n\n\n\n\n\n\n\n\n.gitignore\n\n\n\n\n\n\n\n        .gitignore\n      \n\n\n\n\n\n\n\n\nREADME.md\n\n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        src\n      \n\n\n\nsrc/agent.rs\n\n\n\n\n\n\n\n        agent.rs\n      \n\n\n\n\n\n\n\n\nsrc/main.rs\n\n\n\n\n\n\n\n        main.rs\n      \n\n\n\n\n\n\n\n\nsrc/openai.rs\n\n\n\n\n\n\n\n        openai.rs\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n        There are no files selected for viewing\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n1 \n\n.env.example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n@@ -0,0 +1 @@\n\n\n\n\n\nOPENAI_API_KEY=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 \n\n.gitignore\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n@@ -1,3 +1,4 @@\n\n\n\n\n\n/target\n\n\n\n\n\n/browser\n\n\n\n\n\n/user_data\n\n\n\n\n\n.env\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n19 \n\nREADME.md\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n\n\n\n\n\n@@ -1,26 +1,27 @@\n\n\n\n\n\n# A browser AI agent, using GPT-4\n\n\n\n\n\n# Run Wild\n\n\n\n\n\n\n\n\n\n\n\nThis project provides a bridge between GPT-4 and a headless Chromium browser, allowing you to automate actions simply by describing them to the program. It takes the form of a Rust CLI, but also exports most of the internals as a library for others to use.\n\n\n\n\n\n`run-wild` extends [m1guelpf](https://github.com/m1guelpf)'s [browser-agent](https://github.com/m1guelpf/browser-agent) project by allowing gpt4 to alter it's goal. This is very dumb and probably ought not exist, but c'est la vie.\n\n\n\n\n\n\n\n\n\n\n\nAt it's core, `run-wild` bridges GPT-4 and a headless Chromium browser, automating actions as self-directed by it's goal. It takes the form of a Rust CLI, but also exports most of the internals as a library for others to use.\n\n\n\n\n\n\n\n\n\n\n\n## Installation\n\n\n\n\n\n\n\n\n\n\n\n`browser-agent` is built using Rust, so you'll need to install the Rust toolchain. You can do this by following the instructions at [rustup.rs](https://rustup.rs/).\n\n\n\n\n\n`run-wild` is built using Rust, so you'll need to install the Rust toolchain. You can do this by following the instructions at [rustup.rs](https://rustup.rs/).\n\n\n\n\n\n\n\n\n\n\n\nOnce you have Rust installed, you can install `browser-agent` by running:\n\n\n\n\n\nOnce you have Rust installed, you can install `run-wild` by running:\n\n\n\n\n\n\n\n\n\n\n\n```bash\n\n\n\n\n\ncargo install browser-agent\n\n\n\n\n\ncargo install run-wild\n\n\n\n\n\n```\n\n\n\n\n\n\n\n\n\n\n\nYou should also place your OpenAI API key in the `OPENAI_API_KEY` environment variable. This key should have access to the `gpt-4` model.\n\n\n\n\n\n\n\n\n\n\n\nYou can copy the contents of the `example.env` file to a `.env` file in the root of the project, and fill in the `OPENAI_API_KEY` variable. The `.env` file is ignored by git, so you don't have to worry about accidentally committing your API key. Note though, `.env.example` is not ignored, so you should not change that file.\n\n\n\n\n\n\n\n\n\n\n\n## Usage\n\n\n\n\n\n\n\n\n\n\n\n```\n\n\n\n\n\nUsage: browser-agent [OPTIONS] <GOAL>\n\n\n\n\n\n\n\n\n\n\n\nArguments:\n\n\n\n\n\n  <GOAL>  The goal for the agent to achieve\n\n\n\n\n\nUsage: run-wild [OPTIONS] <GOAL>\n\n\n\n\n\n\n\n\n\n\n\nOptions:\n\n\n\n\n\n      --visual                Whether to show the browser window. Warning: this makes the agent more unreliable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 \n\nsrc/agent.rs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n\n\n\n\n\n@@ -6,9 +6,9 @@ pub enum Action {\n\n\n\n\n\n /// Click on an element.\n\n\n\n\n\n /// The usize is the id of the element.\n\n\n\n\n\n Click(usize),\n\n\n\n\n\n /// Respond to the user with the given text.\n\n\n\n\n\n /// The String is the text to respond with.\n\n\n\n\n\n Answer(String),\n\n\n\n\n\n\n\n\n\n\n\n /// Outputs the update goal.\n\n\n\n\n\n Goal(String),\n\n\n\n\n\n\n\n\n\n\n\n /// Type the given text into the given element and press ENTER.\n\n\n\n\n\n /// The usize is the id of the element, and the String is the text to type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@@ -39,14 +39,14 @@ impl TryFrom<String> for Action {\n\n\n\n\n\n\n\n\n\n\n\n Ok(Self::Type(id, text))\n\n\n\n\n\n }\n\n\n\n\n\n \"ANSWER\" => {\n\n\n\n\n\n \"GOAL\" => {\n\n\n\n\n\n let text = parts\n\n\n\n\n\n .collect::<Vec<_>>()\n\n\n\n\n\n .join(\" \")\n\n\n\n\n\n .trim_matches('\"')\n\n\n\n\n\n .to_string();\n\n\n\n\n\n\n\n\n\n\n\n Ok(Self::Answer(text))\n\n\n\n\n\n Ok(Self::Goal(text))\n\n\n\n\n\n }\n\n\n\n\n\n            _ => bail!(\"Unknown command, got {command}\"),\n\n\n\n\n\n }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 \n\nsrc/main.rs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n\n\n\n\n\n@@ -13,9 +13,6 @@ use browser_agent::{browser, translate, Action, Conversation};\n\n\n\n\n\n#[derive(Debug, Parser)]\n\n\n\n\n\n#[command(author, version, about, long_about = None)]\n\n\n\n\n\nstruct Cli {\n\n\n\n\n\n /// The goal for the agent to achieve\n\n\n\n\n\n goal: String,\n\n\n\n\n\n\n\n\n\n\n\n /// Whether to show the browser window. Warning: this makes the agent more unreliable.\n\n\n\n\n\n #[arg(long)]\n\n\n\n\n\n visual: bool,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@@ -52,7 +49,7 @@ async fn main() -> Result<()> {\n\n\n\n\n\n .with(tracing_subscriber::fmt::layer())\n\n\n\n\n\n .init();\n\n\n\n\n\n\n\n\n\n\n\n let mut conversation = Conversation::new(args.goal);\n\n\n\n\n\n let mut conversation = Conversation::new();\n\n\n\n\n\n let mut browser = browser::init(\n\n\n\n\n\n Path::new(\"./browser\"),\n\n\n\n\n\n Path::new(\"./user_data\"),\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@@ -100,7 +97,7 @@ async fn main() -> Result<()> {\n\n\n\n\n\n                element.type_str(text).await?;\n\n\n\n\n\n                element.press_key(\"Enter\").await?;\n\n\n\n\n\n }\n\n\n\n\n\n Action::Answer(text) => {\n\n\n\n\n\n Action::Goal(text) => {\n\n\n\n\n\n println!(\"{text}\");\n\n\n\n\n\n break;\n\n\n\n\n\n }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n22 \n\nsrc/openai.rs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Show comments\n          \n\n\n   View file\n\n\n      Edit file\n    \n\n    Delete file\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOriginal file line number\nDiff line number\nDiff line change\n\n\n\n\n\n\n\n\n\n\n\n@@ -22,32 +22,40 @@ pub struct Conversation {\n\n\n\n\n\n messages: Vec<ChatCompletionRequestMessage>,\n\n\n\n\n\n}\n\n\n\n\n\n\n\n\n\n\n\nimpl Conversation {\n\n\n\n\n\n /// Create a new conversation with GPT-4.\n\n\n\n\n\n #[must_use]\n\n\n\n\n\n pub fn new(goal: String) -> Self {\n\n\n\n\n\nimpl Default for Conversation {\n\n\n\n\n\n fn default() -> Self {\n\n\n\n\n\n Self {\n\n\n\n\n\n            goal,\n\n\n\n\n\n goal: String::from(\"Visit 10 webpages.\"),\n\n\n\n\n\n url: None,\n\n\n\n\n\n client: Client::new(),\n\n\n\n\n\n messages: vec![ChatCompletionRequestMessage {\n\n\n\n\n\n                name: None,\n\n\n\n\n\n                role: Role::System,\n\n\n\n\n\n                content: formatdoc!(\"\n\n\n\n\n\n                    You are an agent controlling a browser. You are given an objective that you are trying to achieve, the URL of the current website, and a simplified markup description of the page contents, which looks like this:\n\n\n\n\n\n                    You are an agent controlling a browser. You are given the URL of the current website, and a simplified markup description of the page contents, which looks like this:\n\n\n\n\n\n                    <p id=0>text</p>\n\n\n\n\n\n                    <link id=1 href=\\\"link url\\\">text</link>\n\n\n\n\n\n                    <button id=2>text</button>\n\n\n\n\n\n                    <input id=3>placeholder</input>\n\n\n\n\n\n                    <img id=4 alt=\\\"image description\\\"/>\n\n\n\n\n\n\n\n\n\n\n\n                    You are not given a goal but should create and alter a goal based on the previous actions you have taken. Your initial goal should be to visit at least 10 webpages and update your goal based on the content of those page.\n\n\n\n\n\n\n\n\n\n\n\n                    You must respond with ONLY one of the following commands AND NOTHING ELSE:\n\n\n\n\n\n                        - CLICK X - click on a given element. You can only click on links, buttons, and inputs!\n\n\n\n\n\n                        - TYPE X \\\"TEXT\\\" - type the specified text into the input with id X and press ENTER\n\n\n\n\n\n                        - ANSWER \\\"TEXT\\\" - Respond to the user with the specified text once you have completed the objective\n\n\n\n\n\n                        - GOAL \\\"TEXT\\\" - Outputs your updated goal.\n\n\n\n\n\n                \"),\n\n\n\n\n\n }]}\n\n\n\n\n\n }\n\n\n\n\n\n}\n\n\n\n\n\n\n\n\n\n\n\nimpl Conversation {\n\n\n\n\n\n /// Create a new conversation with GPT-4.\n\n\n\n\n\n #[must_use]\n\n\n\n\n\n pub fn new() -> Self {\n\n\n\n\n\n Self::default()\n\n\n\n\n\n }\n\n\n\n\n\n\n\n\n\n\n\n /// Request and execute an action from GPT-4.\n\n\n\n\n\n #[tracing::instrument]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToggle all file notes\nToggle all file annotations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0 comments\n    on commit 7b71a4c\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    Please\n  sign in to comment.\n\n\n\n \n\n\n\n\n\n\n\nFooter\n\n\n\n\n\n\n\n \n        \u00a9 2023 GitHub, Inc.\n        \n\n\n\nFooter navigation\n\nTerms\nPrivacy\nSecurity\nStatus\nDocs\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    You can\u2019t perform that action at this time.\n  \n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- Run-Wild is a Rust CLI automation tool that extends [m1guelpf]'s [browser-agent] to automate actions by self-direction.\n- It provides a bridge between GPT-4 and a headless Chromium browser, and exports most of the internals as a library for others to use.\n- Install using Rust Toolchain and place OpenAI API key in the `OPENAI_API_KEY` environment variable.\n- The agent is given a goal to achieve with a simplified markup of the current webpage to update it.\n- Commands are entered with specified text to automatically find elements and interact with them, the unique ID of an element should be input and typing instructions should be added for elements that accept text input.\n- Actions are limited to clicking links, inputs, and buttons, typing text, displaying updated goals, and outputting responses."
  },
  {
    "id": 35320656,
    "timestamp": 1679871775,
    "title": "Steve Jobs Defies RIAA's Request to Disable Audio Recording Software",
    "url": "https://weblog.rogueamoeba.com/2023/03/24/the-riaa-v-steve-jobs/",
    "hn_url": "http://news.ycombinator.com/item?id=35320656",
    "content": "The RIAA tried to get Apple to disable Audio Hijack Pro, which allowed users to record audio off their Macs. Steve Jobs stood up to the RIAA's \"influence/intimidation\" and refused to disable the software. Commenters on Hacker News condemned the RIAA for their copyright monopolist tactics and expressed their support for open source software and non-walled garden systems, which would allow greater freedom in computing. Some users also discussed the possibility of developing AI on demand technology, like Wikipedia for AI, for free to the public, though others expressed skepticism about the economic viability of such a project. One commenter also pointed out the similarity between the RIAA's behavior and Microsoft's efforts to keep Windows from running on top of DR-DOS.Rogue Amoeba's blog post titled \"The RIAA v. Steve Jobs\" recounts a chilling story told by Adam Curry in which Steve Jobs allegedly turned down a request from members of the Recording Industry Association of America (RIAA) to disable Rogue Amoeba's Audio Hijack Pro. The RIAA reportedly asked Apple to disable Audio Hijack Pro because it could be used to record audio from Apple devices. Rougue Amoeba's blog post notes that only an error on the user's part, such as running Windows with someone else's version of DOS, would cause any issues when using Audio Hijack Pro. Audio Hijack Pro is a recording tool that lets users record audio from applications running on their Mac.Rogue Amoeba Software offers a suite of audio tools for Mac users, including audio recording software Audio Hijack, soundboard manager Farrago, audio editor Fission, cable-free audio routing tool Loopback, audio recording app Piezo, and sound control tool SoundSource. These tools are designed to provide superior audio quality and control for users. Rogue Amoeba Software holds the copyright for these products.",
    "summary": "- RIAA tried to get Apple to disable Rogue Amoeba's audio recording software, Audio Hijack Pro, which allowed users to record audio off their Macs\n- Steve Jobs refused RIAA's request, standing up to their \"influence/intimidation\"\n- Commenters on Hacker News expressed support for open source software and non-walled garden systems, condemning RIAA's copyright monopolist tactics\n- Some users discussed the possibility of developing AI on-demand technology, but others expressed skepticism about its economic viability\n- Rogue Amoeba Software offers a suite of audio tools for Mac users, including Audio Hijack Pro, designed to provide superior audio quality and control for users."
  },
  {
    "id": 35311293,
    "timestamp": 1679808302,
    "title": "GNUstep Achieves Catalina Compatibility with Apple APIs",
    "url": "https://heronsperch.blogspot.com/2023/03/compatibility-project-almost-complete.html",
    "hn_url": "http://news.ycombinator.com/item?id=35311293",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeron's Perch: Compatibility project almost complete\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeron's Perch\n\n\n\n\nMostly Apple, GNUstep and stuff about me personally.  I'm the Chief Maintainer for the GNUstep project.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaturday, March 25, 2023\n\n\n\n\n\n\n\nCompatibility project almost complete\n\n\n\n\n\nAs the much villified theme for star trek enterprise says \"its been a long road getting from there to here\" i am almost done with all of the work that needed to be done to get us to Catalina compatibility in GNUstep.  The reason this is still significant is because Apple hasn't made many changes to either the Foundation or AppKit APIs since then.  I have been workinf hard over the last three years.  All of the new classes are fully tested.  Once this effort is completed I am going to focus on printing, which has always been a problem in GS.  And possibly a \"reference\" distribution. \n\n\n\n\n\n\n\nat\n\nMarch 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmail ThisBlogThis!Share to TwitterShare to FacebookShare to Pinterest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo comments:\n\n\n\n\n\nPost a Comment\n\n\n\n\n\n\n\nNewer Post\n\n\nOlder Post\n\nHome\n\n\n\n\nSubscribe to:\nPost Comments (Atom)\n\n\n\n\nSwift->ObjC interop\n\nSome interesting notes.  I will update this posting as i find more:  * https://dart.dev/guides/libraries/objective-c-interop\n\n\n\n\n\n\n\n\n\nCompatibility project almost complete\nAs the much villified theme for star trek enterprise says \"its been a long road getting from there to here\" i am almost done with ...\n\n\n\n\n\n(no title)\nAre we really going to fall for it again?\n\n\n\n\n\nSwift 2.0 Going Open Source.... great news!\nAs announced on their blog and on WWDC, Swift 2.0 will be going open source:   https://developer.apple.com/swift/blog/?id=29   GNUstep will ...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatreon\n\nBecome a Patron!\n\n\n\n\nBlog Archive\n\n\n\n\n\n\n\n\n        \u25bc\u00a0\n      \n\n\n\n2023\n\n(2)\n\n\n\n\n\n        \u25bc\u00a0\n      \n\n\n\nMarch\n\n(2)\n\nSwift->ObjC interop\nCompatibility project almost complete\n\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2020\n\n(1)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2015\n\n(3)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nOctober\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2014\n\n(5)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nOctober\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nSeptember\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(2)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2013\n\n(13)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nAugust\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(4)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMarch\n\n(4)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nFebruary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2012\n\n(3)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nSeptember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nFebruary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2011\n\n(4)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJanuary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2010\n\n(18)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nAugust\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMay\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMarch\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJanuary\n\n(3)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2009\n\n(6)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nFebruary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2008\n\n(10)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nOctober\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMay\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nFebruary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2007\n\n(3)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nAugust\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(2)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2006\n\n(12)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nSeptember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nAugust\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nApril\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMarch\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nFebruary\n\n(1)\n\n\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\n2005\n\n(23)\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nDecember\n\n(1)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nNovember\n\n(4)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nOctober\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nSeptember\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nAugust\n\n(3)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJuly\n\n(2)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nJune\n\n(7)\n\n\n\n\n\n\n\n        \u25ba\u00a0\n      \n\n\n\nMay\n\n(2)\n\n\n\n\n\n\n\n\n\nLabels\n\n\n\nApple\n\n\nGNUstep\n\n\nIBM\n\n\nLinux\n\n\nMethodology\n\n\nPersonal\n\n\nSlashbutt\n\n\n\n\n\n\n\nReport Abuse\n\n\n\nTwitter\n\nTweets about \"gnustep\"\n\n\n\n\nSite List\n\n\nGNUstep Project\nGNUstep Wiki\nGNUstep site analytics\n#GNUstep Channel on FreeNode webchat\nRandom Thoughts of a Camaelon\nThe Art is long\n\n\n\n\nGNUstep Metrics (by Ohloh)\n\n\n\n\n\nMy Stats\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome\n\n\n\n\n\n\n\n\nSearch This Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple theme. Powered by Blogger.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- GNUstep achieves Catalina compatibility with Apple APIs\n- Chief maintainer for the GNUstep project mentions work being done for the past three years\n- New classes are fully tested\n- Focus will shift to fixing printing issues and possibly creating a \"reference\" distribution"
  },
  {
    "id": 35315424,
    "timestamp": 1679844224,
    "title": "Arduino UNO R4: 32-bit Cortex-M4 Processor for Advanced Makers",
    "url": "https://blog.arduino.cc/2023/03/25/arduino-uno-r4/",
    "hn_url": "http://news.ycombinator.com/item?id=35315424",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArduino UNO R4 is a giant leap forward for an open source community of millions | Arduino Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Home\n>\n\n\n\n>\n\n\n\n\n\n\n\n Vineyard pest monitoring with Arduino Pro\n\nBlog Home\n\n\nArduino UNO R4 is a giant leap forward for an open source community of millions\n\nArduino Team \u2014 March 25th, 2023\n\n\nThe history of making is now ready for the future:\u00a0a 32-bit UNO will soon be available thanks to a powerful Renesas processor\n\nHere at Arduino we are thrilled to announce a new, revolutionary revision of the iconic UNO board, which will expand the concept of the open-source brand\u2019s most iconic and popular product while providing the maker community with a long-awaited update on performance and possibilities. The Arduino UNO R4 indeed preserves the well-known features of the UNO family \u2013 standard form factor, shield compatibility, 5V operating voltage, outstanding robustness \u2013 while offering no less than a 32-bit Cortex\u00ae-M4 and a 3-to-16x increase in clock speed, memory and flash storage.\nThis huge leap forward starts with a new processor by Renesas, a global leader in microcontrollers, analog, power and SoC products. While over 10 million users have enjoyed playing and working with Arduino UNO R3\u2019s 8-bit microcontroller for more than a decade, the new RA4-series MCU will open up endless new project opportunities for more advanced makers, and bring the board up to speed with current standards.\nThe UNO R4 will come in two versions \u2013 UNO R4 WiFi and UNO R4 Minima \u2013 offering unprecedented performance and possibilities for the maker community.\nThe WiFi version comes with an Espressif S3 WiFi module, expanding creative opportunities for makers, educators, and hobbyists alike; while the UNO R4 Minima provides a cost-effective option for those seeking the new microcontroller without additional features.\nIn details, the new Arduino UNO R4 features the Renesas RA4M1 (Arm Cortex\u00ae-M4) running at 48MHz, which provides a 3x increase over the UNO R3. In addition to that, SRAM went from 2kB to 32kB, and flash memory went from 32kB to 256kB to accommodate more complex projects. In addition, following the requests from the community, the USB port was upgraded to the USB-C and maximum power supply voltage was increased to 24V with an improved thermal design. The board provides a CAN bus, which allows users to minimize wiring and execute different tasks in parallel by connecting multiple shields. Finally, the new board includes a 12-bit analog DAC.\u00a0\nAll in all, Arduino UNO R4 is the answer to the requests for improvement and updates the developer and maker community has been advancing, making it easier than ever to get started with Arduino.\nWhen it comes to hardware compatibility, pinout, voltage and form factor are unchanged from UNO R3, ensuring maximum hardware and electrical compatibility with existing shields and projects.On the software side, a big effort is being made to maximize retrocompatibility of the most popular Arduino libraries so that users will be able to rely on existing code examples and tutorials. In most cases libraries and examples will work out-of-the-box, but a few of them which were optimized for the AVR architecture used in R3 will need to be ported. To help in the transition, Arduino will provide a public list of such libraries, along with links to existing alternatives. In addition, an early adopter program has been launched \u2013 with a dedicated website at www.arduino.cc/UNOR4 \u2013 for library developers excited to find out more about UNO R4 and willing to port their low-level code to the Renesas architecture.\u00a0\nThe Arduino UNO R3 will still be available and supported, at the side of all makers who want to work with its 8-bit AVR microcontroller.\nArduino UNO R4 is scheduled for release in late May, when more details about its features will be disclosed, but you can already subscribe the waiting list and get notified when in stock!\n\nJoin the waiting list\nJoin the early adopter program\n\n\n\nBoards:Uno R4Categories:AnnouncementsFeatured \n\n\n \n Tweet\n\n\n\n\n\n\nYou can follow any responses to this entry through the RSS 2.0 feed.\nYou can leave a response, or trackback from your own site.\n\n\n\n\n\n\nLeave a Reply\nYou must be logged in with your Arduino account to post a comment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- Arduino announces new UNO R4 board with a 32-bit Cortex-M4 processor by Renesas, offering increased performance and possibilities for advanced makers with 3-to-16x increase in clock speed, memory and flash storage.\n- The UNO R4 will come in two versions, UNO R4 WiFi and UNO R4 Minima, with an Espressif S3 WiFi module in the former and a cost-effective option for the latter.\n- The new board maintains compatibility with existing shields and projects with unchanged form factor, voltage, and pinout, and an effort is made to ensure retrocompatibility of popular Arduino libraries.\n- The UNO R4 is scheduled for release in late May, with an early adopter program available for library developers to port their low-level code to the Renesas architecture."
  },
  {
    "id": 35313903,
    "timestamp": 1679835157,
    "title": "openSUSE Linux Doubles User Base with Community Model",
    "url": "https://linuxiac.com/opensuse-grows-in-popularity/",
    "hn_url": "http://news.ycombinator.com/item?id=35313903",
    "content": "openSUSE, a popular Linux distro known for its stability, versatility, and ease of use, has doubled its user base in a year. Developed and maintained by the openSUSE community, the distribution offers a powerful package management system, an intuitive installer, and robust security features. Despite not being as widely recognized as its company-backed counterparts, such as Canonical's Ubuntu or Red Hat's Fedora, openSUSE has gained a loyal following among Linux enthusiasts, developers, and businesses. Its recent surge in popularity can be attributed to users recognizing its reliability and community-driven development model. The growing interest in open-source solutions further highlights the increasing demand for open-source technology in today's landscape.The article criticizes Ubuntu for its design choices that disregard user needs and corrupt the distro integration level. The author highlights the lack of communication and failure to address critical bugs, such as the inability to log in to report bugs without a UbuntuOne account. The article suggests that Ubuntu's focus on monetizing market share rather than providing a solid product leaves room for OpenSUSE to capture market share. The article ends by inviting comments, but sarcastically adds that comments should be aware of the subtext.",
    "summary": "- openSUSE Linux doubles user base in a year with its community-driven development model.\n- It offers package management system, intuitive installer, and robust security features.\n- openSUSE gaining popularity due to its reliability and community involvement.\n- Growing interest in open-source solutions highlights increasing demand for open-source technology.\n- Article criticizes Ubuntu for its design choices that disregard user needs and corrupt the distro integration level.\n- Ubuntu's focus on monetizing market share leaves room for openSUSE to capture market share."
  },
  {
    "id": 35313326,
    "timestamp": 1679830317,
    "title": "Astrophotographers Create 140MP Image of Dynamic Sun",
    "url": "https://old.reddit.com/r/space/comments/122475u/i_teamed_up_with_a_fellow_redditor_to_try_and/",
    "hn_url": "http://news.ycombinator.com/item?id=35313326",
    "content": "Astrophotographers have shared a 140-megapixel picture of the sun which was jointly processed from over 90,000 individual images captured with a modified telescope. Great care was taken to align the two atmospheric layers in a scientifically plausible way using NASA's SOHO data as a reference. It was created as a fusion of science and art, as the ever-changing sun will never look quite this way again. The sun intrinsically is a 3D system, which has complications of electromagnetic issues such as a weak magnetic field that affects how gases move, a Coriolis force that influences the direction in which gas flows, and vibrational modes that we are only beginning to understand. Modeling the sun is thus more complex than the weather on Earth.A team of astrophotographers, AJ James McCarthy and thevastreaches, have created the most detailed image of the sun. Measuring a whopping 140 megapixels, the image features a solar prominence that is over 14 times the size of Earth. The image was created by blending data from over 90,000 individual images captured with a modified telescope. The two atmospheric layers of the sun were aligned, with NASA's Solar and Heliospheric Observatory data used as a reference. The image showcases the intricate and dynamic details of the sun's chromosphere with a blend of art and science. The sun's color is white, but the team chose to depict it in a yellow hue for artistic purposes.The image shows a plasma tornado on the sun that is 14 times the height of Earth. Some commenters discuss the size of the tornado in various ways, including using the comparison of 14 Earths or the distance from Earth to the moon. There are also jokesAstrophotographers have captured the most detailed and dynamic full image of the Sun ever created, by combining data from over 90,000 individual images taken last Friday with a modified telescope to reveal the intricate details within the solar chromosphere. An image of the 2017 eclipse was used as an artistic element to display a structure that is otherwise invisible. The final image is a blend of science and art, and is an astrophoto that\u00a0is a one-of-a-kind, as capturing the ever-changing Sun in this manner is unlikely to be repeated. The majestic result was due to the collaboration between telescopic expert TheVastReaches and astrophotographer and writer A James McCarthy.A high-resolution photograph of the sun has been shared on social media. The image shows \"plasma made of hydrogen following magnetic field lines on the sun, which makes them look all wavy and thin.\" The tall column of plasma in the image is described as a \"tornado\" and is seen swirling as it rises. The sun is responsible for all life on earth, and the picture captures a perfect blend of technique and creativity. The photo has been lauded for its quality, with some suggesting that NASA would be envious. However, some people have taken the opportunity to make humorous or sarcastic comments, with one remarking that it looked like an \"orange cat fur\" close-up.",
    "summary": "- Astrophotographers have created a 140-megapixel image of the sun using over 90,000 individual images captured with a modified telescope.\n- NASA's Solar and Heliospheric Observatory data was used to align the two atmospheric layers of the sun in a scientifically plausible way.\n- The image is a blend of art and science and showcases the intricate and dynamic details of the sun's chromosphere.\n- The image depicts a plasma tornado on the sun that is 14 times the height of Earth and is a one-of-a-kind astrophoto unlikely to be repeated."
  },
  {
    "id": 35311300,
    "timestamp": 1679808330,
    "title": "Reverse-Engineering Soviet Space Navigation Computer: Globus INK",
    "url": "https://www.righto.com/2023/03/reverse-engineering-globus-ink-soviet.html",
    "hn_url": "http://news.ycombinator.com/item?id=35311300",
    "content": "Reverse-engineering the Soviet-era Globus INK, a mechanical analog computer used for spaceflight navigation, was the subject of an article shared on Hacker News. The INK calculated orbits through gears, cams and differentials to furnish astronauts with high-resolution, full-colour displays of their spacecraft's position; all of this was done outside the capacities of the electronic space computer of the 1960s. Many commenters admired the elegant machine's reliability and the creativity and dedication of the engineers who designed it. The Teletype, Z1 and Antikythera Mechanism, similarly mechanical technologies, were also discussed. Several comments touched on how the collapse of the Soviet Union was caused not by the nation's inability to produce impressive machines, but rather by political factors including stagnation and the government's failure to provide basic needs to the population.The Globus INK was an electromechanical analog computer used for navigation on Soyuz spacecraft. It used a rotating globe to indicate the spacecraft's position above Earth, with a complex system of gears and differentials to compute the position. The Globe's latitude and longitude dials showed the position numerically, while a light/shadow dial indicated when the spacecraft would enter or leave the Earth's shadow. The technology used by the Globus was remarkable, with complicated functions implemented using specially-shaped cams and ten differential gear assemblies. The unit projected the current position of the spacecraft forward, essentially dead reckoning, and only had a fixed orbit at a specific angle. The Globus was inflexible in this regard, and the time period of each orbit could be adjusted by only a few minutes to account for changes in altitude.The Globus INK was an analog computer that calculated orbits through a complex system of gears, cams, and differentials, providing astronauts with a remarkably high-resolution, full-color display of space craft's position in the 1960s. Its displays included the light/shadow dial, displaying the time left until the spacecraft enters Earth's shadow; the latitude wheel, showing the up-and-down motion of the spacecraft; and the longitude dial, displaying the side-to-side motion of the spacecraft. However, the device was limited in its functionality since all parameters had to be manually configured, it didn't take any external guidance inputs or provided accurate calculation. Also, it only supports a circular orbit at a fixed angle with no other features like modern digital displays.  Nonetheless, the device was of great value in the Soviet crewed spaceflight program in the 1960s.The Globus is an analog navigational computer used in Soviet space flights. Its mechanism includes a solenoid that provides force to the entire system while various gears and shafts scale the rotations as needed. The orbital time of the spacecraft is adjustable between 86.85 and 96.85 minutes according to the detailed page describing the Globus in Russian. The outputs from the orbit cam drive the overall orbit rotation, which drives the orbit cam, creating a feedback loop. The light and shadow indicator on the Globus is controlled by two knobs and the ground track on the map is roughly, but not exactly, sinusoidal. The latitude and longitude generated by the Globus are complicated trigonometric functions. The gear ratios further scale the rotations as needed, such as the Earth rotation gearing, which reduces the rotation rate by dividing it into half a rotation per orbit.",
    "summary": "- The Globus INK was a Soviet-era mechanical analog computer used for spaceflight navigation that calculated orbits through gears, cams, and differentials to display spacecraft's position in high-resolution and full-color in the 1960s, outside the electronic capacities of that era.\n- The device had limitations such as lack of external guidance inputs, requiring manual configuration of parameters and no modern digital displays, and only supported a circular orbit at a fixed angle.\n- Nonetheless, the Globus was reliable and valuable in the Soviet crewed spaceflight program, where it projected the current position of the spacecraft forward through dead reckoning. \n- The device used a solenoid, various gears and shafts to scale rotations as needed, and generated complicated trigonometric functions for latitude and longitude."
  },
  {
    "id": 35319807,
    "timestamp": 1679866016,
    "title": "Robot Learns to See in Just 30 Minutes Using CMS Technique",
    "url": "https://antonilo.github.io/vision_locomotion/",
    "hn_url": "http://news.ycombinator.com/item?id=35319807",
    "content": "Researchers have created a robot that can learn to see in just 30 minutes using a technique called Cross-Modal Supervision (CMS). The robot was previously trained to walk over arbitrary terrain solely using proprioception. The research team added the visual component by training the robot with real-world data. The robot learned to perform significantly better as a result. According to the researchers, the robot's vision can also be distorted, and the robot learns to adapt. The system was trained on a large set of terrains on the Berkeley campus, and the visual policy was checked for generalization on the Stanford campus. The last author on the paper, J. Malik, is a well-known contributor to computer vision.UC Berkeley researchers have developed a four-legged robot, dubbed \"Solo,\" that learned how to climb stairs using a combination of vision and proprioception. The approach involved training the robot to traverse some terrains in the real world with a blind walking policy before utilizing monocular RGB cameras and proprioception as a form of supervision to train it. They achieved this performance with less than 30 minutes of real-world data. The researchers also studied how quickly the policy could adapt to shifts in the visual field and demonstrated that the visual policy could adapt to new environments, including climbing stairs up to 19 cm high and slippery slopes of 35 degrees inclination. The technology was supported by the DARPA Machine Common Sense program and the ONR MURI award N00014-21-1-2801.",
    "summary": "- Researchers have used Cross-Modal Supervision (CMS) to train a four-legged robot to see and traverse terrain in just 30 minutes.\n- The robot was previously trained to walk using only proprioception and was taught to adapt to distorted vision.\n- The robot was trained on a large set of terrains on the Berkeley campus and was checked for generalization on the Stanford campus.\n- The last author on the paper, J. Malik, is known for his contributions to computer vision."
  },
  {
    "id": 35311332,
    "timestamp": 1679808679,
    "title": "FlexGen: High-Throughput LLM Inference on Single GPU",
    "url": "https://github.com/FMInference/FlexGen",
    "hn_url": "http://news.ycombinator.com/item?id=35311332",
    "content": "\n\n\n\nHacker News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Hacker News\n\n\n\n\n\n\n\n\n\n          Sorry, we're not able to serve your requests this quickly.\n        \n\n\n\n\nreload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - FMInference/FlexGen: Running large language models on a single GPU for throughput-oriented scenarios.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\n\n\n\n            Sign\u00a0up\n          \n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n        Product\n        \n\n\n\n\n\n\n\n\n\n\n\nActions\n        Automate any workflow\n      \n\n\n\n\n\n\n\nPackages\n        Host and manage packages\n      \n\n\n\n\n\n\n\nSecurity\n        Find and fix vulnerabilities\n      \n\n\n\n\n\n\n\nCodespaces\n        Instant dev environments\n      \n\n\n\n\n\n\n\nCopilot\n        Write better code with AI\n      \n\n\n\n\n\n\n\nCode review\n        Manage code changes\n      \n\n\n\n\n\n\n\nIssues\n        Plan and track work\n      \n\n\n\n\n\n\n\nDiscussions\n        Collaborate outside of code\n      \n\n\n\nExplore\n\n\n      All features\n\n    \n\n\n\n      Documentation\n\n    \n\n\n\n\n\n      GitHub Skills\n\n    \n\n\n\n\n\n      Blog\n\n    \n\n\n\n\n\n\n\n\n        Solutions\n        \n\n\n\n\n\nFor\n\n\n      Enterprise\n\n    \n\n\n\n      Teams\n\n    \n\n\n\n      Startups\n\n    \n\n\n\n      Education\n\n    \n\n\n\n\n\nBy Solution\n\n\n      CI/CD & Automation\n\n    \n\n\n\n      DevOps\n\n    \n\n\n\n\n\n      DevSecOps\n\n    \n\n\n\n\n\nCase Studies\n\n\n      Customer Stories\n\n    \n\n\n\n      Resources\n\n    \n\n\n\n\n\n\n\n\n        Open Source\n        \n\n\n\n\n\n\n\n\nGitHub Sponsors\n        Fund open source developers\n      \n\n\n\n\n\n\nThe ReadME Project\n        GitHub community articles\n      \n\n\n\nRepositories\n\n\n      Topics\n\n    \n\n\n\n      Trending\n\n    \n\n\n\n      Collections\n\n    \n\n\n\n\n\nPricing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this organization\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n\u21b5\n\n\n      Jump to\n      \u21b5\n\n\n\n\n\n\n \n\n\n\n\n              Sign in\n            \n\n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        FMInference\n \n/\n\nFlexGen\n\nPublic\n\n\n\n\n \n\nNotifications\n \n\n \n\nFork\n    394\n\n\n\n\n \n\n\n          Star\n 7.4k\n  \n\n\n\n\n\n\n\n\n\n        Running large language models on a single GPU for throughput-oriented scenarios.\n      \nLicense\n\n\n\n\n\n     Apache-2.0 license\n    \n\n\n\n\n\n\n7.4k\n          stars\n \n\n\n\n394\n          forks\n \n\n\n\n \n\n\n          Star\n\n  \n\n\n\n\n\n \n\nNotifications\n \n\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\n\nIssues\n26\n\n\n\n\n\n\nPull requests\n2\n\n\n\n\n\n\nActions\n\n\n\n\n\n\n\nProjects\n0\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\n\nInsights\n\n\n\n \n \n\n\n\nMore\n\n\n \n\n\n                  Code\n \n\n\n                  Issues\n \n\n\n                  Pull requests\n \n\n\n                  Actions\n \n\n\n                  Projects\n \n\n\n                  Security\n \n\n\n                  Insights\n \n\n\n\n\n\n\n\nFMInference/FlexGen\n\n\n\n\n\n\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\n\n\n\n\n\n\n\n\n\n\nmain\n\n\n\n\n\nSwitch branches/tags\n\n\n\n\n\n\n\n\n\n\nBranches\nTags\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView all branches\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView all tags\n\n\n\n\n\n\n\n\n\n\n\n\n\nName already in use\n\n\n\n\n\n\n\n\n\n      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?\n\n\n\n    Cancel\n\n    Create\n\n\n\n\n\n\n\n\n2\nbranches\n\n\n\n\n\n0\ntags\n\n\n\n\n\n\n\n \nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocal\n\n\n\n Codespaces\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n        Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n\n    Open with GitHub Desktop\n\n\n\n\n\n\n    Download ZIP\n\n\n\n \nSign In Required\n\n                Please\n                sign in\n                to use Codespaces.\n              \n\n\n\nLaunching GitHub Desktop\n\n    If nothing happens, download GitHub Desktop and try again.\n  \n\n\n\n\nLaunching GitHub Desktop\n\n    If nothing happens, download GitHub Desktop and try again.\n  \n\n\n\n\nLaunching Xcode\n\n    If nothing happens, download Xcode and try again.\n  \n\n\n\n\n\nLaunching Visual Studio Code\nYour codespace will open once ready.\nThere was a problem preparing your codespace, please try again.\n\n\n\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nYing1123\n\nUpdate README.md\n\n\n\n\n        \u2026\n      \n\n\n\n\n        3502de5\n      \n\nMar 26, 2023\n\n\n\n\n\nUpdate README.md\n\n\n3502de5\n\n\n\nGit stats\n\n\n\n\n\n\n\n96\n\n                      commits\n                    \n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n\n\n    Failed to load latest commit information.\n\n\n  \n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n\n\nbenchmark\n\n\n\nUpdate Petals setup details\n\n\n\nMarch 7, 2023 12:47\n\n\n\n\n\n\n\n\n\ndocs\n\n\n\nUpdate paper.md (#102)\n\n\n\nMarch 21, 2023 10:13\n\n\n\n\n\n\n\n\n\nflexgen\n\n\n\nData wrangle benchmark (#95)\n\n\n\nMarch 8, 2023 20:17\n\n\n\n\n\n\n\n\n\nscripts\n\n\n\nSimplify API (#68)\n\n\n\nFebruary 25, 2023 22:55\n\n\n\n\n\n\n\n\n\n.gitignore\n\n\n\nFlexGen for Data wrangle Tasks. (#91)\n\n\n\nMarch 6, 2023 14:33\n\n\n\n\n\n\n\n\n\nLICENSE\n\n\n\nRelease and merge commits\n\n\n\nFebruary 21, 2023 02:38\n\n\n\n\n\n\n\n\n\nREADME.md\n\n\n\nUpdate README.md\n\n\n\nMarch 26, 2023 10:42\n\n\n\n\n\n\n\n\n\npyproject.toml\n\n\n\nAdd more HELM examples (#82)\n\n\n\nMarch 1, 2023 11:21\n\n\n\n\n    View code\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlexGen\nThroughput-Oriented Inference for Large Language Models\nInstall\nMethod 1: With pip\nMethod 2: From source\nExamples\nHELM Benchmark\nData Wrangling\nPerformance Benchmark\nGeneration Throughput (token/s)\nRoadmap\n\n\n\n\n\nREADME.md\n\n\n\n\nFlexGen\nFlexGen is a high-throughput generation engine for running large language models with limited GPU memory. FlexGen allows high-throughput generation by IO-efficient offloading, compression, and large effective batch sizes.\nThroughput-Oriented Inference for Large Language Models\nIn recent years, large language models (LLMs) have shown great performance across a\nwide range of tasks. Increasingly, LLMs have been applied not only to interactive\napplications (such as chat), but also to many \"back-of-house\" tasks.\nThese tasks include benchmarking, information extraction, data wrangling, and form processing.\nOne key characteristic of these applications is that they are throughput-oriented: they require\nrunning LLM inferences over millions of tokens in batches, e.g., all the private documents in a company's\ncorpus, or all the tasks in the HELM benchmark.\nThese workloads are less sensitive to latency - the user starts up a job and lets it run overnight -\nbut increasing throughput is critical for reducing costs.\nThroughput is a measure of tokens processed per second over the job's entire runtime (which can be hours).\nThroughput-oriented workloads provide opportunities to trade off latency for higher throughput, which\nmakes it easier to take advantage of low-cost commodity GPUs.\nThe goal of FlexGen is to create a high-throughput system to enable new and exciting applications of\nfoundation models to throughput-oriented tasks on low-cost hardware, such as a single commodity GPU\ninstead of expensive systems.\nCheck out the examples of what you can run on a single commodity GPU with FlexGen, including benchmarking and data wrangling.\n\u274c Limitation. As an offloading-based system running on weak GPUs, FlexGen also has its limitations.\nFlexGen can be significantly slower than the case when you have enough powerful GPUs to hold the whole model, especially for small-batch cases.\nFlexGen is mostly optimized for throughput-oriented batch processing settings (e.g., classifying or extracting information from many documents in batches), on single GPUs.\n\nThis project was made possible thanks to a collaboration with\n \u00a0\u00a0\u00a0\n \u00a0\u00a0\u00a0\n \u00a0\u00a0\u00a0\n \u00a0\u00a0\u00a0\n \u00a0\u00a0\u00a0\n\n\nInstall\nRequirements:\n\nPyTorch >= 1.12 (Help)\n\nMethod 1: With pip\npip install flexgen\n\nMethod 2: From source\ngit clone https://github.com/FMInference/FlexGen.git\ncd FlexGen\npip install -e .\n\nExamples\nHELM Benchmark\nFlexGen can be integrated into HELM, a language model benchmark framework, as its execution backend.\nYou can use the commands below to run a Massive Multitask Language Understanding (MMLU) scenario with a single T4 (16GB) GPU and 200GB of DRAM.\npython3 -m flexgen.apps.helm_run --description mmlu:model=text,subject=abstract_algebra,data_augmentation=canonical --pad-to-seq-len 512 --model facebook/opt-30b --percent 20 80 0 100 0 100 --gpu-batch-size 48 --num-gpu-batches 3 --max-eval-instance 100\n\nNote that only a subset of HELM scenarios is tested. See more tested scenarios here.\nData Wrangling\nYou can run the examples in this paper, 'Can Foundation Models Wrangle Your Data?', by following the instructions here.\nPerformance Benchmark\nGeneration Throughput (token/s)\nThe corresponding effective batch sizes and lowest offloading devices are in parentheses. Please see here for more details.\n\n\n\nSystem\nOPT-6.7B\nOPT-30B\nOPT-175B\n\n\n\n\nHugging Face Accelerate\n25.12 (2 on GPU)\n0.62 (8 on CPU)\n0.01 (2 on disk)\n\n\nDeepSpeed ZeRO-Inference\n9.28 (16 on CPU)\n0.60 (4 on CPU)\n0.01 (1 on disk)\n\n\nPetals\n8.25 (2 on GPU)\n2.84 (2 on GPU)\n0.08 (2 on GPU)\n\n\nFlexGen\n25.26 (2 on GPU)\n7.32 (144 on CPU)\n0.69 (256 on disk)\n\n\nFlexGen with Compression\n29.12 (72 on GPU)\n8.38 (512 on CPU)\n1.12 (144 on CPU)\n\n\n\n\nHardware: an NVIDIA T4 (16GB) instance on GCP with 208GB of DRAM and 1.5TB of SSD.\nWorkload: input sequence length = 512, output sequence length = 32. The batch size is tuned to a large value that maximizes the generation throughput for each system.\nMetric: generation throughput (token/s) = number of the generated tokens / (time for processing prompts + time for generation).\n\nHow to reproduce.\nRoadmap\nWe plan to work on the following features.\n\n Optimize the performance for multiple GPUs on the same machine\n Support more models (BLOOM, CodeGen, GLM)\n Release the cost model and policy optimizer\n Macbook Support (M1 and M2)\n AMD Support\n\n\n\n\n\n\n\n\n\n\nAbout\n\n      Running large language models on a single GPU for throughput-oriented scenarios.\n    \nTopics\n\n\n\n  machine-learning\n\n\n  deep-learning\n\n\n  offloading\n\n\n  high-throughput\n\n\n  opt\n\n\n  gpt-3\n\n\n  large-language-models\n\n\n\nResources\n\n\n\n\n\n      Readme\n \nLicense\n\n\n\n\n\n     Apache-2.0 license\n    \n\n\n\nStars\n\n\n\n\n\n7.4k\n    stars\n\nWatchers\n\n\n\n\n\n88\n    watching\n\nForks\n\n\n\n\n\n394\n    forks\n\n\n\n\n\n\n\n    Releases\n\nNo releases published\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n        Used by 5\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 19\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      + 8 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\nPython\n96.5%\n\n\n\n\n\n\n\nShell\n3.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFooter\n\n\n\n\n\n\n\n \n        \u00a9 2023 GitHub, Inc.\n        \n\n\n\nFooter navigation\n\nTerms\nPrivacy\nSecurity\nStatus\nDocs\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    You can\u2019t perform that action at this time.\n  \n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n\n\n\n\n",
    "summary": "- FlexGen is a high-throughput generation engine for running large language models with limited GPU memory.\n- It allows high-throughput generation by IO-efficient offloading, compression, and large effective batch sizes.\n- FlexGen is designed for throughput-oriented batch processing settings, on single GPUs, mostly for classifying or extracting information from many documents in batches.\n- It has limitations as an offloading-based system running on weak GPUs and can be significantly slower than holding the whole model in more powerful GPUs, especially for small-batch cases.\n- FlexGen can be integrated into HELM, a language model benchmark framework, as its execution backend."
  },
  {
    "id": 35313982,
    "timestamp": 1679835699,
    "title": "Debating ChatGPT's Understanding & Impact on Humanity",
    "url": "https://www.reddit.com/r/linux/comments/122gmm9/richard_stallmans_thoughts_on_chatgpt_artificial/",
    "hn_url": "http://news.ycombinator.com/item?id=35313982",
    "content": "A discussion on Hacker News centered around comments made by Richard Stallman regarding ChatGPT, AI, and their impact on humanity. Some users debated the definition of \"understanding\" in the context of whether a calculator can understand math or if ChatGPT has a model of its context. The Chinese Room argument was also brought up, which claims that a digital computer executing a program cannot have a \"mind\", \"understanding\", or \"consciousness\". Some users expressed hope that future integrations of ChatGPT could farm out tasks to specialized systems, while others worried about relying on special case plug-ins that would impede GPT's independence. The potential for multimodal learning and the question of how much AI needs to understand before it is considered capable of abstractions were also discussed.Pig eggs (oocytes) are the female reproductive cells for pig reproduction and cannot be consumed as food, unlike chicken eggs. The discussion shifts to the question of whether AI should be granted human rights, with some arguing that it matters insofar as determining whether something is truly intelligent or sentient. However, others argue that the focus should remain on improving the AI models rather than conferring human rights. The analogy is drawn to a calculator, which can provide correct answers to math problems but does not truly \"understand\" math. The concern is that when hype is used to market AI technology, people may anthropomorphize it and assign it abilities beyond what it actually possesses, leading to potential harm in their decision-making processes.The debate over whether language models like GPT-3 and GPT-4 are truly intelligent continues, with opinions ranging from equating them to advanced calculators to questioning whether humans are essentially the same as language models. Some argue that the term \"artificial intelligence\" is too broad and marketing-driven, and we should instead use more specific terms like \"language model\". Others suggest that intelligence is the ability to accurately predict and match complex patterns in a changing environment, and thus language models could be considered intelligent in this context. However, there are still concerns over the reliability and potential biases of language models, as well as the ethical implications of granting them rights or treating them as sentient beings.The debate around the intelligence of artificial intelligence (AI) continues, with some experts arguing that it is not intelligent and others claiming that it has reached a certain level of understanding. Richard Stallman, for example, has dismissed AI as having no intelligence and not understanding anything, while others suggest that AI, such as ChatGPT, can reason along the lines of what it has previously said and even demonstrate knowledge and understanding of complex areas such as classical physics. The discussion highlights the need for specific quantitative comparisons to human intelligence, rather than relying on discrete judgements about what AI is or isn't, including ground-breaking research papers that may add clarity to the debate.Discussions on Reddit regarding artificial intelligence language model ChatGPT have sparked various opinions on its capabilities and limitations. Some commenters have highlighted the limitations of ChatGPT in terms of its understanding and reasoning abilities, whilst others have emphasized its language model capabilities through vast amounts of trained data in generating plausible-sounding responses based on the input it receives. Some users suggest that ChatGPT lacks a physical component critical to human intelligence, while others debate its potential impact on humans in the future. However, the general consensus is that ChatGPT's value lies in its utility, as it provides valuable insights and assistance when used responsibly and with an understanding of its limitations.Richard Stallman has questioned ChatGPT's capacity for human-like intelligence beyond the realms of data it is trained on. Responding to a question about whether Google had created AI general enough to make humans redundant, the Free Software Foundation founder replied: \"It doesn't need intelligence to nullify human's labour.\" Stallman went on to note that even if ChatGPT had reached a level of intelligence, it would not \"understand\" what humans find valuable about their own work. In his opinion, the AI is simply a tool, trained to read text and produce outputs reliably, unable to take on tasks requiring original thought.Richard Stallman commented on the development of artificial intelligence and its impact on humanity, specifically mentioning the language model ChatGPT. He argued that ChatGPT is not actually artificially intelligent and does not \"know\" or \"understand\" anything. Instead, it simply plays games with words to generate plausible English text based on statistical patterns. Stallman also posed philosophical questions about the meaning of intelligence and the potential dangers of democratizing AI. Some commenters disagreed with Stallman's views, arguing that behavior is what matters, and as AI approaches human-like behavior, we should not assume that it lacks intelligence. Others discussed the potential socioeconomic implications of AI on job displacement and the risks of monopolies and corporations controlling AI.The text generation tool, GPT, can create writing that sounds plausible and human-like, but it does not truly understand the meaning behind the words. It relies solely on patterns and statistical probabilities to generate responses. Therefore, one should approach any information provided by it with a critical eye and not take it as absolute truth without proper verification. While some may refer to GPT as \"AI,\" it is important to note that it does not truly understand language and is not sentient. Additionally, even as the technology advances and becomes more nuanced, it will never have a true understanding of language, as it will always rely on statistical patterns rather than true comprehension.",
    "summary": "- A discussion on Hacker News centered around comments made by Richard Stallman regarding ChatGPT, AI, and their impact on humanity.\n- Users debated the definition of \"understanding\" in the context of whether a calculator can understand math or if ChatGPT has a model of its context.\n- Users expressed hope for future integrations of ChatGPT and worried about impeding GPT's independence with specialized plug-ins.\n- The potential for multimodal learning and the question of how much AI needs to understand before it is considered capable of abstraction were also discussed.\n- There is debate over whether language models like GPT-3 and GPT-4 are truly intelligent, with concerns over their reliability and biases.\n- Richard Stallman has dismissed AI as having no intelligence and not understanding anything, while others suggest that ChatGPT can reason along the lines of what it has previously said.\n- Stallman argues that the AI is simply a tool, trained to read text and produce outputs reliably, unable to take on tasks requiring original thought.\n- GPT does not truly understand language and relies solely on patterns and statistical probabilities.\n- It is important to approach information from GPT with a critical eye and not take it as absolute truth without proper verification."
  },
  {
    "id": 35317589,
    "timestamp": 1679854590,
    "title": "UNIX Co-Creator & Linux Users Disappointed with macOS Restrictions",
    "url": "https://jasoneckert.github.io/myblog/linux-is-making-apple-great-again/",
    "hn_url": "http://news.ycombinator.com/item?id=35317589",
    "content": "Co-creator of UNIX Ken Thompson has recently transitioned to Linux, specifically Raspbian, due to his disappointment with Apple's macOS. Thompson's frustration with macOS is echoed by other Linux users, such as Linus Torvalds, who consider it to be restrictive. According to an article on Hacker News, every version of MacOS had its bugs upon release. Thompson's hardware of choice isn't mentioned, though he's involved with the Asahi Linux project, which enables running an ARM 64 Linux distribution on Apple Silicon hardware. A lack of alternative hardware options make it difficult for some to switch in search of the ideal Linux-friendly operating system.The article discusses how the Mac OS has improved over the years and how it compares to other operating systems. Some commenters share their experiences with Mac OS and suggest that it has become better in recent years, while others prefer Linux. Some criticize Mac OS for lacking focus stealing prevention and its file system, while others praise its hardware and software stability. The conversation also includes some side discussion about the use of the phrase \"Make America Great Again\" in the title which some find unnecessary and off-putting. Overall, the article and comments offer a mixed perspective on the use and benefits of the Mac OS.The article discusses the use of Linux on various devices, including a Raspberry Pi by Ken Thompson, a Dell XPS 15 Developer Edition by Linus Torvalds, and Apple's ARM computers running Ashashi Linux by the author. The author argues that Linux can be remarkably stable with the right hardware choices and setup, and that it can be an attractive alternative to Mac OS. The comment section includes a debate about whether referencing the slogan \"Make America Great Again\" (MAGA) is appropriate or represents an immediate red flag for racism. There are also discussions about Linux's advantages over Mac OS and Windows, as well as issues with hardware compatibility and tinkering required.The Linux creator and others in the comments express a preference for Linux over macOS and Windows for their computing needs due to ease of use, lower cost, and privacy concerns. Despite finding the hardware of the new Apple Air laptop appealing, they express reluctance to use it due to the lack of adequate Linux support. One commenter notes improvements since the time of Linus' original comments, but others still find macOS to be lacking in comparison to Linux. The conversation veers off into a discussion of internet and corporate propaganda on Hacker News.Many longtime Apple users have become disenchanted with the company's move toward closed standards and tighter control. The introduction of the high performance and low power ARM-based Apple Silicon architecture in 2020 made hardware the company's main selling point to tech professionals, but for many, having to use macOS was a deal breaker. However, Apple's allowance of the booting of non-macOS operating systems on its Apple Silicon has allowed for the Asahi Linux project to thrive. The reverse-engineered platform to run an ARM64 Linux distribution natively has made Apple Silicon a popular choice for tech enthusiasts and professionals. Asahi Linux's fast, collaborative development is a stellar example of open-source benefits and how to run an open-source project well by focusing on community, tooling, and users.",
    "summary": "- Co-creator of UNIX Ken Thompson switches to Linux due to disappointment with macOS, which is also echoed by Linux creator Linus Torvalds\n- Lack of alternative hardware options make it difficult for some to switch to a Linux-friendly operating system\n- Mac OS has improved over the years and has mixed perspectives in the comments section, with some criticizing its lack of focus stealing prevention and file system, while others praise its hardware and software stability\n- Linux can be an attractive alternative to Mac OS according to the article, with debates on hardware compatibility and a preference for Linux due to ease of use, lower cost, and privacy concerns in the comments section\n- Many longtime Apple users have become disenchanted with the company's move toward closed standards and tighter control, but the Asahi Linux project has allowed for non-macOS operating systems to run on Apple Silicon, making it a popular choice for tech enthusiasts and professionals."
  }
]
