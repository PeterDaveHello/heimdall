[
  {
    "id": 39479001,
    "title": "Scammers Leverage FedEx's Reputation in Phishing Attacks",
    "originLink": "https://www.troyhunt.com/thanks-fedex-this-is-why-we-keep-getting-phished/",
    "originBody": "Thanks FedEx, This is Why we Keep Getting Phished 23 February 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39479001",
    "commentBody": "Thanks FedEx, this is why we keep getting phished (troyhunt.com)1581 points by ahonhn 23 hours agohidepastfavorite516 comments habosa 19 hours agoFedEx may have the worst and least secure digital platform for a major company. Some examples I’ve noticed: 1. I moved into a 10-unit apartment building and wanted to set up FedEx Delivery Manager. I just put in my new address, no verification whatsoever, and I was immediately given access to the previous tenant’s delivery instructions which included the buildings private garage code. Any thief could have done the same. 2. When I moved out of that building I wanted to add my new address to delivery manager … but I couldn’t. The site errored every time. The reason? Some forums revealed the correct hypothesis that if you have special characters in your password then some parts of the site are permanently broken for you. Including the change password flow. So I had to have my wife make a new account with a worse password. Truly amateur stuff for an otherwise very impressive company. reply n0us 19 hours agoparentIs it impressive though? They have about a 50% success rate delivering things to me across multiple addresses and I know other people who have had similar long term issues. reply throwway120385 18 hours agorootparentAt one of my addresses FedEx will happily sell anyone overnight shipping and then just keep the parcel at the depot for a week until they have a driver who can actually make the trip. I have had like 6 very urgent packages delayed like this. Once my wife ordered something perishable and they pulled this then told her she had to drive into town and pick it up at the airport. I've also been nearly run off the road by FedEx drivers on the highway before. One guy was so angry that I was only going 10 over that he tailgated me within a foot and then punish passed me. They're also the only service that still corrects my other address to the wrong address. I tried for a whole month to get ahold of anyone there who even knows what address correction is and then just stopped using them for anything important. They doubled down on \"digital\" during the pandemic and fired a bunch of CSRs and stuff. It doesn't look like it's working out very well for them. reply Arrath 13 hours agorootparent> just keep the parcel at the depot for a week until they have a driver who can actually make the trip. Depot workers can get up to the weirdest stuff. One time I was returning unused product (oil well perforating guns, a UN 1.4D explosive device) via Yellow Freight. I handed over the cases and signed all the appropriate paperwork to handover custody at the depot and went on about my day. The supplier called me ~10 days later saying they never received the shipment! Perturbed, I called down to the depot who basically shrugged it off with \"no idea lol not our problem\". Their attitude changed when I told them that in accordance with my license and federal law I would be notifying the ATF at the end of the day that there were missing or lost explosives and it would very much be their problem. A couple hours later they called back and told me the boxes had missed their truck and were just sitting in the corner of the secure cage in the loading dock, forlorn and forgotten. What the fuck, guys. reply noisy_boy 8 hours agorootparentLesson for US customers: If you really want your shipment to be delivered, add a bullet or a pinch of gunpowder to the shipment. reply Fogest 11 hours agorootparentprevOne of the big problems I find in the shipping industry is the reliance on insurance. The idea that most packages are insured or easily replaceable. When I was a bit younger and doing some seasonal postal work in a processing plant this was the mentality. The mentality being that sometimes things will go wrong and ruin a package, but hey, whatever. Machines would sometimes destroy a package, packages would get thrown around, heavy boxes would be stacked on very small/fragile ones, etc... Myself and many of the people I worked with all tried their best. But at the end of the day there is only so much you can do as a temp seasonal worker to prevent such things. They'd rather have a higher amount of damaged/lost items and a higher throughput. It'd be interesting to see a competitor that made it their goal to handle packages with more care and not have this attitude. However I can't see them getting too far. They would likely have to charge more money, and any of the big companies are not going to care to pay more. They'd rather take the risk and just ship it again if it gets broken on the way. It'll end up being cheaper for them that way. The ones who lose out are the smaller businesses and individuals shipping personal items. It pissed me off when I'd see a damaged package of an item that was clearly a personal homemade thing. Something that isn't easy to just quick send another copy of. reply Nathanba 8 hours agorootparentI think there is something about the monkey brain in people that if you give them an item, they think they own it. It doesn't matter that it's just a loan or they are supposed to give it to someone else.. they think they can do whatever they want with it and anyone is lucky that they didn't mess with it. This seems to happen in the food service industry as well with the whole attitude of \"be nice to us so we don't mess with your food!\" The monkey brain can't help but think that it owns an item that it managed to grab. That's why I think that we need a psychological trick to make humans in package management think differently about the packages. Maybe writing something like \"Fedex FAMILY Owned\" on each package could do the trick. Although when I worked in a shipping facility I think people were so busy that there wasn't much \"thinking\" either way possible. Still we will probably just go with robots though. reply Fogest 8 hours agorootparentI think your last couple sentences is the reality. You are expected to be quick at your job and you don't have much time to think about each package. Was that a pretty heavy package you just put on top of a fragile one? That's unfortunate, but the company just doesn't give you the time to do it properly. And the company is okay with accepting that risk at the customers expense. reply zdragnar 16 hours agorootparentprevStrangely, I've had perishable medicine delivered to me (a biologic injection) for two years without a single hiccup by FedEx. They have been the most consistently reliable delivery service where I live (though the post office is pretty good too). My house is at the bottom of a hill that is difficult for rear wheel drive vehicles in winter. UPS, on the other hand, can go pound sand. They often refuse to deliver due to weather, then force me to either drive two hours round trip to their distribution center, or charge me to pick it up at the local UPS store. When when FedEx couldn't get their truck to my house due to road conditions, they were totally fine with my picking it up at their store. reply gopher_space 15 hours agorootparent> They have been the most consistently reliable delivery service where I live (though the post office is pretty good too). Every service relies on the USPS to some extent, which makes the Republican attempt to gut the organization so baffling. There's no replacement and nobody is looking to replace it. From my perspective as an ex letter carrier, your personal experience with package delivery is determined almost entirely by whoever runs the local hub and handles last-mile. Unfortunately it's a McDonald's Assistant Manager kind of role; anyone truly competent will be able to find better work sooner or later. reply ciabattabread 12 hours agorootparentIt took the 2020 pandemic for Republicans to finally get on board and pass the Postal Service Reform Act of 2022. reply carom 10 hours agorootparentprevI live in an apartment. I get mail for 4 or 5 previous tenants. I get corporate spam. I have unsubscribed from as much as I can, I have a return to sender stamp and have used it, yet I am inundated with trash on a daily basis. Technically, it is illegal for me to throw out this trash. In my opinion there is a massive amount of waste moving through USPS and the organization could use some serious cuts in order to take stock of what actually needs to be delivered. reply gopher_space 9 hours agorootparentYou've done everything except talk to the one human being involved who appears at your residence every single day. If I was your letter carrier and knew you felt this way I'd honestly be hurt that you didn't bother to ask me about any of it. > the organization could use some serious cuts Miss the part about them being the backbone of package delivery in this country? Or the part where there's nobody to replace them? Well it doesn't matter since the USPS is financially self-sustaining. reply gffrd 13 hours agorootparentprevIt's almost as if they're giant companies employing thousands of people, and quality varies across geography … reply Moru 9 hours agorootparentThis is what is so baffling with people. \"The $company/government isn't doing their job, we need to fire/change government/privatise this function, it would solve everything!\" Well, where do you think the former employees will work after their previous employer shuts down? It's not the form of government/company culture that is the biggest problem I'm affraid. reply wormius 14 hours agorootparentprevThat's really unacceptable. If they're going to be that late, they should at least ship it using Jiffy Express: https://www.youtube.com/watch?v=e134NoLyTug reply late2part 15 hours agorootparentprevtoday I learned a new thing: https://www.bikelaw.com/2017/07/punishment-pass-defined/ reply saintfire 15 hours agorootparentprevI'm in the same camp. The single time they actually delivered it to me without saying I wasn't home they had actually delivered it one street over. I spent 72 hours waiting (3x24 periods they told me to wait and call back tomorrow while they \"investigated\") for a $1300 package. Initially they said it must have been stolen and its my loss, to which I said \"no I was home and near the front door all day, you didn't deliver it\". Pretty absurd they can't just look where he was when it was \"delivered\" and deal with it. Or maybe they can and they just don't bother. Eventually the person actually called me using my number on the box and said it was delivered there. Still no recourse from FedEx, whom I have not informed I got the package in the end. reply eastbound 15 hours agorootparentI’d quote this as the best federated peer-to-peer package delivery. Distribute in a nearby city and it will get to its destination eventually. Fortunately, your personal info is written in the clear for everyone to see, and anyone can open the box. reply sidewndr46 14 hours agorootparentthat is called crowd sourcing your last mile of delivery reply yashap 17 hours agorootparentprevYeah, in my experience FedEx drivers absolutely LOVE saying they “attempted delivery of my package, but nobody was home,” so I have to go get it from the depot. But I 100% was home, working from home all day, and they 100% never came. reply Libcat99 16 hours agorootparentI had video of them pulling into the driveway and leaving without getting out of the vehicle and saying \"no one was home.\" I'm also in the video. reply lcnPylGDnU4H9OF 16 hours agorootparentThat sounds like internal verification uses GPS. So in most cases it's going to be the customer's word against the astonishingly lazy driver's evidence. reply cromulent 15 hours agorootparentI called them and questioned them about this - they didn't even come down my street, and yet claimed that they \"attempted delivery\". The customer service person was honest enough to say there was no code for the driver to say \"too busy, can't meet my unrealistic targets\". reply lcnPylGDnU4H9OF 12 hours agorootparent> too busy, can't meet my unrealistic targets At least that could explain why the driver showed up to the address without dropping off the package. If finding the package takes a non-trivial amount of time, it would add up over the course of the day. It's otherwise just wild to me that the driver did 99% of the delivery and just noped out of the last 1%. reply cozzyd 11 hours agorootparentthis happens to me all the time, but I live in a place where a delivery van/truck is basically always going to be double parking. reply eastbound 15 hours agorootparentprevCan you file a small-claims? You have nothing to lose, it’s not like they could threaten to stop delivering your packages. reply windthrown 10 hours agorootparentWhy couldn't they threaten to stop delivering? I was under the impression that only the Postal Service (USPS) had a regulatory mandate to serve all US addresses. reply Libcat99 10 hours agorootparentI think they'd be unlikely to since you are not the one purchasing shipping, the shipper is. reply duderific 14 hours agorootparentprevIt's probably not worth the time and effort. You can get a judgment, but good luck getting them to pay out on it. reply ballenf 13 hours agorootparentIf you got a judgment, you would get a prompt response. Problem you'd probably have is getting the judgment, if they show up at the hearing. Their clickwrap agreements are one barrier. Also, you have no relationship with them -- you weren't the customer (and if you were see point 1). Would be interesting to see what type of claim would work. Maybe conversion (ie theft) if they delivered it to the wrong address. But if they just hold it at the depot, I don't know what claim you could make. Would probably have to take it up with the seller. reply lagniappe 14 hours agorootparentprevA lien is a claim upon a part of another's property that arises because of an unpaid debt related to that property and that operates as an encumbrance on the property until the debt is satisfied. reply eastbound 14 hours agorootparentYes, and I wonder what a hundred thousand small-claims would do upon UPS or Fedex. reply JumpCrisscross 13 hours agorootparentprev> can get a judgment, but good luck getting them to pay out on it Honestly, finding a sheriff to enforce a judgement against FedEx property sounds like the fun part. reply bongodongobob 17 hours agorootparentprevCan I ask where you live? I'm 40 and have never had anything get lost in the mail, ever. Is it a big city thing or something? reply biftek 14 hours agorootparentIt really just depends on your local distribution hubs. My semi rural address regularly gets serviced by two different FedEx hubs, if I see it go to X hub I'll get it that day, but if it goes to Y hub it'll most likely be late. reply QuercusMax 13 hours agorootparentprevWhen we lived in San Jose, CA, we had stuff which never arrived quite often. Birthday cards and such especially. reply bigstrat2003 10 hours agorootparentprevThey definitely are not impressive. I always avoid them if I am given a choice, because for the last 20 years they have always been sub-par. UPS isn't perfect, but they consistently do better than FedEx. Sadly these days it's pretty uncommon for vendors to give you the choice of who they use to ship the package, so I can't always avoid them. reply jonathanlydall 16 hours agorootparentprevThey certainly can be quite impressive, I recently had something delivered from China I bought through Alibaba to South Africa, shipping cost less than 5USD and it arrived in about 13 days, 1 day less than the maximum estimate. In my case I got an email about customs and tax payment which was needed, but the link was clearly to fedex.com. reply Szpadel 13 hours agorootparentprevin my country fedex isn't popular, but I had one international package delivered by them and I was very positively surprised because they paid duties for me to speed up process and invoiced me that costs. reply madaxe_again 18 hours agorootparentprevNo. They’re 100% useless in my experience, and literally never manage to deliver to me - everything ends up returned to sender. No other courier has this problem. As for the SMSs - in Portugal, and I’d guess Australia too, they contract all of their local operations out to some random group of muppets who can’t organise their way out of a paper bag - the SMSs they send me come from a mobile number, are handwritten (they seem to literally have someone whose job it is to write messages, on a phone, and send them), as are the emails. When it comes to delivery, i’m inevitably the last delivery of the day as I live way out in the boonies, and they just go “it’s 5pm I’m going home”, and it goes back to the depot. They drive it back and forth for a week before declaring the parcel undeliverable. These days, if I see someone has shipped something with FedEx, despite my instructions not to, I immediately request a refund, as I know it won’t arrive. The whole thing beggars belief. reply timbaboon 13 hours agorootparentprevThat’s a bit better than my experience with DHL :) they’ve delivered packages to random people multiple times across the UK, France, Switzerland and South Africa. Important documents they’ve handed over to strangers, like my passport, for example… reply zardo 14 hours agorootparentprevI get a kick out of the mismatch between delivery estimates and tracking information. They're telling both that my package will be delivered this afternoon, and that it's in a distribution center 3000 miles away. reply kragen 18 hours agorootparentprev\"50% success rate delivering packages\" is a totally different level of risk from \"automated system gives your garage access code to anyone who claims to live there\" i mean in the first case what's at risk is the five-dollar trinket you bought off amazon reply jd3 13 hours agoparentprevI bought an OP-1 from teenage engineering years ago and fedex delivered it inside of the mailbox. USPS removed the fedex package from the mailbox and impounded it at our local USPS post office without ever notifying me. After 1-2 months of waiting/assuming the package had been stolen, I call the USPS office and asked if they somehow had the package in their custody/possession and, lo-and-behold, they did (in the \"undeliverable mail room\") and started lecturing me about how it was illegal for fedex to deliver a package into the mailbox, which is usps/government property etc. etc. I called Fedex to try to rectify this and, as far as I remember, they either never answered the phone or told me they had no way of contacting the delivery driver (??). I've always avoided fedex (and UPS, for that matter, since they destroyed two antique lamps that I ordered through ebay) since then. reply denkmoon 12 hours agorootparentThe mailbox? On your property? that you paid for an installed (or bought off the previous owner), is government/usps property and they'll steal a parcel that someone else has delivered to it? That's insane lmao reply quatrefoil 11 hours agorootparentUSPS owns and maintains some cluster mailboxes at apartment complexes and HOAs. reply zten 9 hours agorootparentNo, it goes further than that, all the way back to 1934. USPS is the only authorized service to use a mailbox. Here is an altogether far too detailed study of the law: https://www.gao.gov/assets/ggd-97-85.pdf You need separate bins/boxes/whatever for other services to use. reply bastardoperator 17 hours agoparentprevI ordered a computer from Southern California, they shipped it to Texas, Florida, Maine, and then back to Northern California. My last two orders were just stolen from someone at FedEx. They got the shipment, but it never left the facility after that. Customer service is an offshore apology machine that can't help with anything. I used to prefer fedex, but the standard of service is so subpar I go out of my way to avoid them. reply zamalek 17 hours agorootparentI assume you know that you can open a claim? They'll either find your package really fast, or will have to pay its full value. Often the vendor has to initiate the claim. If the vendor doesn't want to open a claim, refund. If the vendor doesn't want to refund, chargeback. reply deedub 16 hours agorootparentBe careful about those chargebacks. I bought two new pixel phones directly from Google and only one arrived. Google support was of course awful and Fedex did absolutely nothing outside of asking me what color the phone was. lol I ended up reversing charges for the missing phone and Google immediately wrecked me - I was using Fi at the time so they killed my cell service and killed my ability to use Google Pay for anything - including the Play Store. Probably some other stuff I don't even remember. Between my personal account and my business accounts I realized at that moment that Google could completely wreck my life. Be careful about retaliation for a chargeback, if you live within one company's ecosystem it can be a brutal retaliation you're not ready for. reply doubloon 16 hours agorootparentDid you contact the card company about this? Or your bank? Or a lawyer? Just curious. Card company should have someone who works on goog account reply thechao 13 hours agorootparentprevRetaliation for charge back probably elevates this from a civil matter to a criminal one; you should totally contact your local DA. They might think it's fun. reply joemi 12 hours agorootparentI wouldn't be surprised if it's just covered by the EULA. There's almost certainly a clause in there about Google being able to terminate service for any reason. reply zamalek 16 minutes agorootparentNot all contracts are legal. reply Aeolun 9 hours agorootparentprevI think it’s fair to say you should do chargebacks only to companies you won’t do business with any more. reply bastardoperator 13 hours agorootparentprevMy last two stolen packages required the vendor to open a claim, I did in both cases and both vendors refunded me. Fedex wouldn't even entertain trying to help me. reply jcotton42 10 hours agorootparentI had this with an Apple Watch return. The package was either lost or stolen in transit, and neither FedEx nor Apple were interested in helping me. Only got it resolved after emailing Tim Cook's address, which goes to executive customer relations. reply CamperBob2 16 hours agorootparentprevOnly if the package is insured. That's around 1% of the declared value of the package, so many/most vendors don't opt for it. reply eropple 19 hours agoparentprevUPS is up there, too. I still get text messages about an old address on an account I can't log into for...reasons. (Special characters sound plausible! And of course the password reset flow doesn't work.) Wonder if they share a vendor. reply judge2020 18 hours agorootparentUPS is better in my experience with them always requiring a code sent to me via USPS to verify access to UPS My Choice, except for when I signed up with a new construction address - It also seems to only show me packages with my last name on it, packages with just a company name did not show up. reply ryandrake 18 hours agorootparentprevI can’t believe it’s 2024 and we are still seeing bugs with handling “special” characters. Unicode has been here for how long? Robust string handling is supported in every language. There is no such thing as a special character. My name should be able to contain Chinese characters. My password should be able to contain emojis. What is this Stone Age shit still running on companies’ backends? reply crazygringo 18 hours agorootparent> My password should be able to contain emojis. It's probably better if it shouldn't. It's generally better to prevent passwords from containing characters that can't be entered on a decent proportion of devices you may encounter. Emojis are particularly problematic because new ones keep being added which require OS upgrades, and you might find yourself needing to log in from another device that just doesn't support those emojis yet. Also it's not like Unicode makes everything easy. For example, you have to remember to normalize the password before hashing. Otherwise something as simple as \"ñ\" may be a totally different byte sequence depending on which device you're using. reply grodriguez100 17 hours agorootparentIf a system cannot handle ñ in a password then it is completely broken. We are not talking about the latest emoji here but about a character which is part of one of the most common languages in the world, included in 8859-1 / Latin-1, etc. It is no longer realistic to pretend that only ASCII exists and try to get away with that. reply jerf 17 hours agorootparentThat's not what crazygringo means. ñ can be represented both as a single unicode U+00F1 https://www.compart.com/en/unicode/U+00F1, or as an n with a combining tilde https://www.compart.com/en/unicode/U+0303, which looks like this: ñ. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0] on linux >>> \"ñ\".encode(\"utf-8\") b'\\xc3\\xb1' >>> \"ñ\".encode(\"utf-8\") b'n\\xcc\\x83' A naive hashing algorithm will hash them to different things. For way too much information on this, see: https://www.unicode.org/reports/tr15/ Even a lot of Unicode-aware code written by a developer aware of at least some Unicode issues often fails to normalize properly, most likely because they're not even aware it's an issue. Passwords are a case where you need to run a Unicode normalization pass on the password before hashing it, but, unfortunately, if you're already stored the wrong password hash fixing it is rather difficult. (You have to wait for the correctly-incorrect password to be input, then you can normalize and fix the password entry. This requires the users to input the correctly-incorrect password; if they only input an incorrectly-incorrect password you can't do anything.) I'd suspect storing a lot of unnormalized passwords before learning the hard way this is an issue is the majority case for homegrown password systems. You hear \"don't roll your own crypto\" and think reaching for a bcrypt or scrypt library solves it, but don't realize that there's some stuff that needs to be done before the call to those things still. reply grodriguez100 17 hours agorootparentRight. I misunderstood the comment. Thanks for clarifying! reply WorldMaker 16 hours agorootparentprevWith built in emoji entry keywords in every modern OS how many devices are left that can't type emoji? Even if you plan to restrict to Unicode Version N - 1 or N - 2 where N is the current version to avoid \"user can't type password on older hardware\", the proportion of emoji you can reliably type today on just about any device is huge. reply crazygringo 16 hours agorootparentPeople are still using Windows 7 -- it's the third most popular Windows version after 10 and 11 -- and it only supports Unicode 5.1. Emoji weren't officially supported until Unicode 6.0, though there are a subset of current emoji (less than a quarter) that work on Windows 7 in practice. Meanwhile the current standard is 15.1. There's no security or convenience necessity whatsoever for supporting emoji in passwords, but inconsistent OS support is an excellent reason against it. reply WorldMaker 15 hours agorootparentWindows 7 market share is barely at 3% on the internet per statcounter.com. Third place doesn't mean \"popular\", especially not right now. There's quite a bit of convenience, and some concomitant security, to using emoji in passwords. Emoji are high entropy code points that are easily visually distinguishable across most language boundaries. A \"short\" password of just emoji is going to have way higher entropy and be way harder to brute-force/rainbow table than any equivalent \"length\" (by visual character count) ASCII-only password. That should go without saying. The fact that huge boost in entropy also comes with a massive benefit in how quickly a user can glance at their password and know that they typed in right/wrong often faster than they could if forced to build a line-noise password is a huge bonus. (Related to why Windows 10 experimented with Picture Passwords and a lot of Android users use some form or another of Gesture PINs.) That said, I think the real solution is of course to eliminate passwords altogether (and yes Passkeys are our best hope right now). But saying that we have to stick to ASCII for passwords because that's a lowest common denominator for keyboards is very much like saying that we should stick only to passwords that you can T-9 on flip phones or send in an SMS or that passwords shouldn't really be longer than 8 characters just in case some Unix system needs to use the old DES-based crypt() function or that passwords shouldn't contain quote marks, semicolons, or percentage signs because those might be SQL injection attacks and you might have some PHP apps that are vulnerable to those. You are letting silly technical lowest common denominator bugs stop you from increasing security for the median/mean user. reply bitfilped 12 hours agorootparent3% of the internet is still an incredibly large amount of people. reply WorldMaker 7 hours agorootparentSure? But what definition of \"popular\" does \"large amount of people\" meet? \"Of or relating to the general public\"? The general public is using Windows 10 and 11. \"Suitable to the majority\"? Again, the vast majority is 10 and 11. Same for \"frequently encountered or accepted\" and \"commonly liked or approved\": the most frequently encountered is Windows 10. So too is the most \"commonly liked\". 3% is still 3% and far and away a minority and definitely not in any way \"popular\", by any definition I can find. reply sib 11 hours agorootparentprevI'm pretty sure that most of the on-screen keyboards for TV / streaming device platforms don't support emoji. (I've spent about 6 years of my career running video streaming services... People watch a lot of video on TVs, it turns out, so you probably don't want to let them put these sorts of characters into their passwords when they sign up on mobile or computer devices.) reply WorldMaker 7 hours agorootparentFor better and a (lot) worse most of the TV / streaming device platforms are Android-derived and have access to emoji keyboards if not intentionally disabled, even on TV form factors. I realize it is a wide spectrum of users and a long tail of devices, but at some point again it isn't a technical reason that we are banning emoji from passwords but a political and lowest common denominator reason. I'm not trying to invalidate your personal experience. You've seen a lot of good social reasons users probably \"can't\" be trusted with emoji passwords. but at a purely technical level the number of OSes in 2023 that can't pop up an emoji keyboard if asked is incredibly slim and the number that can't have an emoji keyboard in user space as a software addon is even slimmer. If a device doesn't support at least UTF-8 encodings in 2024 that's an entirely different can of worms (and probably a bad sign for the security of the device itself). Both the Xbox and PS4+ have emoji keyboards. Apple TV has an emoji keyboard. Almost every version of Android TV and Samsung Tizen and Roku and Fire OS and …. Go ahead, tell me you have a lot of customer support problems that you don't want to support emoji in passwords. That I can believe. I can't believe it's a technical problem in 2023. Emoji are universal enough now in 2024 that OSes are broken if they can't send/receive emoji and don't have some sort of keyboard to input them. Even if we are still turning off the emoji buttons on password fields because we don't trust users to do it for social reasons rather than technical ones. reply kansface 15 hours agorootparentprevCompanies aren’t rewriting their entire stack or even upgrading across major versions basically ever. reply jabroni_salad 13 hours agorootparentAlright cool but maybe they can put the exact phrase \"IF you put an ampersand in your password, your account will be bricked and we wont help you with it\" on the password form. reply xenophonf 17 hours agorootparentprevI'm in complete agreement about usernames, but if you're at the point where you want to use Unicode in a password, you might as well make the jump to WebAuthn. Going from a UTF-8 input to a normalized bitstream that gets fed into a KDF could be tricky. reply gjsman-1000 18 hours agorootparentprevMost companies don't like rewriting their code. If it ain't broke, don't fix. (Weird password issues don't count as broke.) There's no guarantee, after all, that the rewrite won't have major edge cases and mistakes of it's own. The upper layer might change now and then, to give a veneer of modernity. But just like Windows being built on 90s technology, the stuff underneath could be even more ancient. reply ryandrake 18 hours agorootparentA software that can't accept a % as part of your password is absolutely, positively broken--in any industry or application. In many companies, this would be a P0 \"don't go home until it's fixed\" production emergency if a bug like this crept in to the software. We need to stop excusing long-standing bugs in horrible legacy software just because they are long-standing. reply WorldMaker 16 hours agorootparentUnfortunately the InfoSec Red Team determined that % in a password could be an attempt at an SQL Injection Attack and the Security Priority is to not fix the current behavior and instead other password checks in the company should also start erroring for % and other such \"power characters\" used in attacks. reply gjsman-1000 18 hours agorootparentprev> In many companies, this would be a P0 \"don't go home until it's fixed\" production emergency if a bug like this crept in to the software. Would it, really? P0 would probably be \"10% of our customers can't submit an order.\" Or \"20% of our vendors are experiencing 404s.\" reply ryandrake 18 hours agorootparentIf 10% of customers have passwords that now can't log in and submit orders, that would be an emergency. We're taking OP's word for it that FedEx doesn't allow certain characters as passwords (actually, from the description, it seems more like FedEx only allows specific characters which is even worse). If either of those are true, it is most certainly a defect. Whether FedEx treats that defect as an emergency is up to them I guess. I'm saying many modern companies would. You originally said \"Weird password issues don't count as broke.\" I think this might just be a case where we have to \"agree to disagree\". reply krisoft 16 hours agorootparent> it seems more like FedEx only allows specific characters which is even worse) If I read it right it sounds even worse. Fedex allows the characters and then random stuff just breaks. It is much preferred to get a simple \"only english alphabet and numbers please\" warning message when you are trying to set the password than not getting any warning and then things breaking. reply Fogest 11 hours agorootparentI've had this before at a University I used to attend. I had a password with either a % or a & and I found I couldn't log into one specific system. I changed my password to a different one, but still had one of those special characters. I was curious and tried a more \"basic\" password and I was able to get in. The system just wouldn't accept certain characters in your password. The main University password manager did disallow certain special characters, but clearly not enough of them. It never makes you feel very confident in an institutions security when they can't even figure out how to get a username/password to work properly on their systems. reply gjsman-1000 18 hours agorootparentprev> You originally said \"Weird password issues don't count as broke.\" I think this might just be a case where we have to \"agree to disagree\". I meant broke in the sense of \"if it ain't broke, don't fix.\" If there are over 300 microservices running code, connected to mainframes running code that was originally from the 80s, but they occasionally have password issues - the risks caused by trying to fix it might be greater than it's worth. That doesn't mean FedEx can't do a better job telling people not to use special characters - or detecting if their current password contains them and forces a password change. reply krisoft 16 hours agorootparent> If there are over 300 microservices running code, connected to mainframes running code that was originally from the 80s, but they occasionally have password issues And we ended up where the thread originally begin \"FedEx may have the worst and least secure digital platform for a major company.\" Besides that is horrible! There should be 1 microservice which deals with passwords, the authentication one. Everything else should just get a token attesting that the user is authenticated (or not). reply bsimpson 14 hours agoparentprevYou're reminding me of the time I realized that Schwab (a massive American bank/broker) truncated all passwords to 8 characters. reply Enginerrrd 13 hours agorootparentBonus points are given when they handle truncating your password differently in the initial validation vs authentication and it fails silently! reply int_19h 4 hours agorootparentOr, even more hilariously, that said truncation happens on the client, and varies between different clients that they have. I personally ran into this with Wells Fargo, where their mobile app would leave one more (or one less, I don't remember exactly now) character than their website. reply bigstrat2003 10 hours agorootparentprevPayPal used to do the same thing, but even worse they weren't consistent about it. The page to create your password truncated it, but the login page did not. I found out the hard way when I couldn't log in because of that stupid behavior. Thankfully they fixed it at some point, but it's absolutely mind blowing to me that anyone thought it was acceptable in the first place. reply ipqk 6 hours agorootparentprevYears ago I found a glaring security hole in schwab where when imputing a security question answer, if you got it wrong you could just hit the back button and try again. to their credit, they took me seriously and I believe they fixed it reasonably promptly. reply zerocrates 8 hours agorootparentprevHey they don't anymore so, progress! I remember comparing notes with fellow employees at a previous job, and depending on when you'd started working, the system had different password rules for you (users who'd been created earlier had a smaller set of allowed characters, etc.). Pretty sure it worked out to some Oracle nonsense. reply S201 14 hours agorootparentprevHeh, that's the same company that sends physical mail to me every time I make a trade because they believe that email sent to my personal domain is \"undeliverable\" and automatically opt me out of e-statements no matter how many times I opt-back in. They have to be losing money on me by paying for so much postage at this point. (And no, nothing is wrong with my email, it's hosted by a professional email host with the proper MX records and literally only Schwab claims to have this problem with me). reply bsimpson 14 hours agorootparentMy college had a credit union with an ATM in the cafeteria. It was in your interest to keep enough money in the credit union to pay for lunch etc. while you were a student there. When I graduated, I pulled the money back out. Apparently they issued the final interest payment after I'd emptied the account. For at least a year after that, I got monthly statements informing me that I had an account with less money in it than the postage on the statement. reply vincent-manis 2 hours agorootparentBack in the 1970s, I lived for a while in Boston. I needed both Canadian and American accounts, for reasons. So I opened an account with the Boston branch of the Bank of Nova Scotia. Things worked ok for a while, and then I moved back to Canada. I withdrew the pittance I had in the account, and asked the bank staff to close the account. For the next two years or so, I got account statements, showing the glorious zero balance. I think it only stopped when I moved and didn't notify them of a forwarding address. reply tbrownaw 3 hours agorootparentprevA different bank that I use will occasionally tell me that I'm about to be opted out of email because I haven't opened any of their mails and they don't think they're getting through. Which I assume is just because I have thunderbird set to not show remote images and that breaks their tracking. reply thfuran 13 hours agorootparentprevEarlier this winter, I got a bunch of those letters completely out of the blue. I was also receiving emails from Schwab throughout the several weeks they were sending me a pile of letters saying they couldn't deliver emails to my address. Then the letters stopped. reply TuringNYC 18 hours agoparentprevMy favorite was when they put my well-marked mail-order medicine right at the exit of the roof gutter pipe, instead of the front door. Sometimes it feels like the workers want to purposely cause chaos. reply callalex 15 hours agorootparentOne part workers, 3 parts horrible management setting impossible metrics and bad incentives. reply hypercube33 9 hours agoparentprevUp until a few years (well, it feels like it) ago wells Fargo had a case insensitive password for accounts. I didn't believe it since my password was upper and lower case and special characters but I tried one day and sure enough got right in. reply orangevelcro 19 hours agoparentprevI wonder if that's why I can't change my password with petco - every time I shop there they tell me I have rewards but I can't load them because the site errors out when I try to reset my password. I used to be able to load the rewards to my account without logging in at all, just clicked the link in my email, but I guess they fixed that and then I realized I didn't know my password. reply sidewndr46 14 hours agoparentprevI've had FedEx hand packages to other couriers who promptly lost them never to be seen again. When I contact them they said this counts as delivering the package. I no longer use FedEx for any shipment that I need to have arrive. reply DANmode 3 hours agoparentprevIf you give instructions to a delivery guy, they are not secure anymore. reply the__alchemist 12 hours agoparentprevOf the carriers, FedEx is the worst for me (North Carolina, USA). DHL is the fastest and most reliable. UPS and USPS tie for second place, slightly below. (People I talk to in person hate USPS, but I've had consistently good experiences with them for both sending, and receiving). Then FedEx several rungs below; Out for delivery, then rescheduled every time. reply nonameiguess 19 hours agoparentprevI'd put Spectrum up against them. A few years back, an incoming neighbor typoed their address in a new account setup request to my address and Spectrum very helpfully inferred that the previous resident would want their account terminated and they turned off my service. Apparently, you can DOS any person on the planet you want from the entire Internet by simply knowing their address. reply sidewndr46 13 hours agorootparentI once moved into a duplex and Spectrum's precursor told me I already had service. After 8 hours on the phone I talked to someone in customer service who told me \"I know the problem you have, I know how to fix it. I can 100% fix it. You are welcome to stay on the phone, but it will take more than 6 hours for me to create an account for you\". So in the end it took days to open a new account. When I moved they someone opened a second account in my name and kept billing me for the original account. reply pishpash 13 hours agoparentprevMuch worse than that. I wanted to get some free shipping supplies from FedEx, so I had to sign up for a shipping account. Account could not be created due to password issues on the website, forgot how I got around it but maybe had to use the mobile app which used a different flow. After getting the account, immediately I get shipping bills for international shipping in the thousands of dollars, both sender and recipient have nothing to do with me. Credit card on file was auto-charged. Removed credit card, started getting thick FedEx bills in physical mail. It turns out FedEx allows billing to be charged to any account as long as you have their nine-digit account number, so of course scammers do this all the time just generating random numbers. FedEx didn't give a shit, denied my reporting of fraud, allowed more scam shipping even after I reported. Finally I had to initiate chargeback via the credit card issuer and only then did they close the account. But I still get marketing emails that I can no longer turn off. Absolutely not a company anyone should use. reply sidewndr46 13 hours agorootparentThey ask for an ID whenever you use an account number. I have to FedEx stuff to my home address for work. The guy at the counter is always perplexed when I tell him the destination address is the same one as the one on my ID. reply pishpash 13 hours agorootparentMaybe if you do it in person, but they must have direct shipping flows where nobody checks. reply sidewndr46 13 hours agorootparentoh wow, that is incredibly dumb. reply delfinom 17 hours agoparentprevIt's fine. At least they don't automatically lowercase and truncate your password behind the scenes like AMEX. Lol. reply toss1 18 hours agoparentprevRe password reset workflow issues: I had an account at a bank where password reset always failed. I had to go through a VERY convoluted process with customer website support to get it fixed. It turned out that the problem was that my registered email address was just two characters (my initials) to the left of the \"@\", e.g., ab@mydomain.com. They allowed me to enter and use it throughout the system without any error flagging whatsoever, but it completely broke the password system. They claim to have raised it as a bug, but never fixed in 3 years+ (moving away from them now). reply filoleg 12 hours agorootparentThis comment just unlocked a new fear of mine. I specifically got a custom domain and email address for any non-personal/\"professional\" comms, which is essentially just me@.com. At least with non-ASCII characters in passwords, while I think it is stupid to not handle those properly, I can at least see some sort of an excuse there, no matter how weak it is. All it takes to mess this up is not thinking about handling those scenarios, so I can definitely see \"this issue was created due to us not thinking about this possibility or not willing to deal with handling it.\" But what's even the reason to not allow sub-3-character local portions of emails? How does one even mess those up, aside from intentionally setting some triggers for less than 3 characters in local portions of email addresses? reply JoshTriplett 12 hours agorootparent> But what's even the reason to not allow sub-3-character local portions of emails? How does one even mess those up, aside from intentionally setting some triggers for less than 3 characters in local portions of email addresses? Wild guess: someone copy-pasted an incorrect email address validation regex, and different parts of the system are using different criteria for email address validation. reply int_19h 4 hours agorootparentprevFWIW I have an email that is me@...org, and I've been using it for over a decade now without a single issue despite having lots of accounts created using it. reply robocat 14 hours agorootparentprevAfter 50 years of software crud, eventually a civilisation ending bug occurs and it can't be fixed (like how Telstra couldn't fix their phone system because the phone system was down). That's why we are all alone in the universe. Enjoy life while civilisation still works! reply bitfilped 12 hours agoparentprevI wasn't very impressed when they tossed my new 100G network switch under the water runoff spout on my porch during a snow melt day. reply genman 19 hours agoparentprevMaybe, but UPS is close to it. They for example are sending out emails that request users to log into their account to \"avoid losing their profile\". If this is not ripe for phishing then I don't know what will be. reply Rudism 18 hours agoprevA while ago my wife applied for a home equity loan. At some point I got a call from someone claiming to be from the bank she had applied through (I forget which one), calling to make sure I approved the loan since the home is in both our names. He asked for my name, which I gave him, and then the last four digits of my social security number, which I also gave him. He then proceeded to ask for my full social security number, at which point alarms started going off in my head and I started sweating about even giving the last four digits to a stranger who had called me out of the blue. I told him I wouldn't do that, and was there a number on the bank's website I could call in order to get back to him, in order to verify that he actually worked for the bank. The guy started acting really annoyed, and said he didn't think there was any number on the bank's website that could reach him, and that if I didn't give him my full social security number he would be forced to reject the loan application. I told him I didn't feel comfortable giving that information to someone who had phoned me, and if there was no way for me to call him back through an official bank phone number then the call was over. He hung up angrily. Turns out he actually was from the bank and he did cancel the loan application. reply userabchn 15 hours agoparentA bank called me to ask me security questions. I said that I would call back using the number on the bank's website. They said (and the bank confirmed when I did call the number) that there is no way to be transferred to the security question people when I call the bank - the only way is for them to call me. I explained that that was poor security practice. They said that I should just look at the caller ID to see that it was the bank calling. It was useless trying to tell them about caller ID spoofing. reply bertil 12 hours agorootparentIt’s a real mystery why, as soon as I heard about a bank founded by people who sounded like they had heard about the internet (Monzo, in the UK), I switched away from my venerable bank (NatWest) that, at the time still had security practices unsuited for the 18th century. Appropriately enough, the last thing they did was to insist —demand, really— that, in 2018, I fax them my demand. It just so happens that this could have been relatively safe because, after asking everyone I knew for a week (including some venerable hackers), the only way that I found to send a fax was to ask the local branch of the same bank. Asking them to authorize the transfer wasn’t possible (by showing them all relevant documentation). Asking them to let me send a fax, using their machine, to a sister branch to tell them to authorize a transfer without anyone verifying my ID, was fine. reply ajmurmann 10 hours agorootparentprevAnd then if your identifiers somehow get in the hands of bad actors and the bank gets fooled by them to open a bank account in your name, you are the one on the hook. It's utter insanity! reply calfuris 16 hours agoparentprevPSA: If you are of a certain age, the last four digits might be roughly all of the useful entropy in your SSN. Be careful with them. Before 2011, the first three digits indicated the office that issued the number and the middle two (the \"group number\") were used in a publicly-known sequence. The Social Security Administration helpfully published periodic lists of the highest group number reached by each office. This makes it extremely easy to predict the first five numbers for people who were registered at birth, which became quite common in 1986 when tax laws changed to require children's SSNs to claim the associated tax credit. reply filoleg 12 hours agorootparentTangentially related - wouldn't that mean that if you are an immigrant, then you are at least theoretically somewhat safe from that enumeration type of an attack? Because if I got my SSN in my late teens, then my date of birth shouldn't mean much at all to anyone trying to use that method you describe, right? reply calfuris 12 hours agorootparentYour date and place of birth would not be helpful, but an analogous attack may be possible. The key factors are when and where you applied and that the SSN was issued before June 25, 2011. reply kccqzy 16 hours agoparentprevThis is just an extremely incompetent and rude loan officer. Generally the loan officers are motivated to close the deal and write you a check because they get commission from that. They are nice to their customers because pissing off customers won't get them that sweet commission. The loan officer I last talked to managed to close more than $1B of mortgages in a year and he's the nicest guy on the phone. In your case, they could for example let you email them using their official bank email address, or use the bank's own web app or messaging system. reply lifeisstillgood 14 hours agorootparentWait what? 1B in mortgages per year, even at a nice fat 500k per is what 2,000 closures or something like 10 per day every day. It’s not impossible but, wow, that’s grinding it out day after day. reply trog 12 hours agorootparentI think it highlights why this jerk was rude and short about it. They want to avoid high maintenance customers because it impacts their short term metrics of how many they can churn out and directly affects their compensation. There are presumably zero repercussions for them personally - the worst case maybe is some long term reputational damage for the bank. reply kccqzy 13 hours agorootparentprevThis is in the Bay Area so more like 1M each. But still I was also very impressed. reply Kirby64 15 hours agoparentprevSimilar story, I transferred a decent amount of money from one bank account to another (different bank). I thought nothing of it, but I got a call randomly from what appeared to be the receiving bank's 'fraud' phone number (based on Google). I picked up, and the person on the end had an extremely thick accent similar to scam callers. He started asking me if I had made a transaction recently (I said yes), then asked me to confirm this transaction if I would provide additional information about myself, including home address and social... I refused, and was told if I didn't my bank account would get locked! Sure enough... I had to go down to the local branch to get my account unlocked, as well as prove the amount of money I was transferring was... available in the other account? Absolutely ridiculous. I don't even know what sort of fraud they were trying to prevent, as this wasn't a new bank account and I'd made transfers between them before. reply lucb1e 16 hours agoparentprevTerms of service from my bank say you're not allowed to give your PIN or secrets like one-time passwords (called \"TAN\" here) to third parties, not even the bank employees themselves. But when I contacted them about a phishing practice, it was A-OK because it was a \"legitimate\" website that phished your credentials to view the last 180 days of transaction histories, compute a credit score, and then withdraw the money. They would \"look into the situation and see if a better solution could be found\" with this german company... I don't understand how anyone is okay with this but klara or klarna or something is a pretty popular payment provider in germany as far as I know, but so my experience is now that banks like to change their security-relevant terms one-sided. But it's your fault if you give out secrets to the wrong person of course, not like the bank was going to care if your social security number had gone to a scammer for example reply d_k_f 16 hours agorootparentI've implemented the bank account checking flow for a German client in a purely B2B setting, and this is essentially based on the PSD2 directive, which requires all/some/most (not entirely sure) banks to provide exactly this functionality (google keywords \"PSD2\" and \"XS2A\"). The bank's T&C should reflect this ... somewhere. The main protection to you not getting scammed out of money this way is in the kind of TAN used for this process. It should/must only allow read access to your account, and at least one of my banks very clearly shows this in the 2fa approval app. Technically, checking your account history and then deducting money will (hopefully) have been two different processes. The moral/ethical implications of requesting (up to) 365 days of full bank transaction details and being allowed to store this information is a whole different animal, tough, and I'm glad I haven't had to do this myself yet. reply lucb1e 10 hours agorootparent> It should/must only allow read access to your account Besides that it also needs to perform the payment, why do they need to pull 180 days of transaction history just so that I can give the merchant their money? (I'd be happy to just be given an IBAN number and transaction description to use and do it myself.) At least that's what the consent screen said it was going to do: assess my creditworthiness before withdrawing the money. There was no way to pay without sharing who my employer is and how much I earn, which shops I visit in which cities, where I've been on holiday, what online purchases I do and on which platform and how frequently and for how much, etc. Obviously I declined this but since it's one of the logos you see every time, I guess a lot of people \"consent\" to this (knowingly or otherwise) reply JoshTriplett 12 hours agorootparentprevAirBnB has adopted Plaid for credit card verification recently, which wants bank login credentials. Nope, never going to happen. reply sf_rob 15 hours agoparentprevThis method of data exfiltration is in Kevin Mitnick's book! He needed a daily pin that banks used to validate intra-bank communications. He called a bank, said that he needed to fax over loan forms from another branch for signing later that day (or something like that). He then asked the bank that he called for the daily PIN. They refused because he called them. He pointed out that he was sending sensitive data to them so they needed to provide the pin... and they did. reply belthesar 16 hours agoparentprevAny bank where this is the standard operating procedure for interacting with loan applications is not a bank that I'd want to do business with. Perhaps this was just one loan officer's way of doing things, and not the way of the business, but that's just not okay to me. Any time anyone asks me for any part of my social over the phone, I ask for some other method of verification. Most folks have other ways of doing stuff. It's ridiculous that what should purely be an ID number is so powerful, but I can't change that fact, just how I interact with folks with regards to it. reply Tommah 9 hours agoparentprevOne of my startup jobs paid us through ADP. While our ADP account was being set up, my boss told us to be on the lookout for an email from them. So one day, I'm in the middle of programming something, and I check my email. Lo and behold, there is an email from ADP... or is it? It is about fifty words long and contains five grammatical errors. It's asking me to fill out the attached PDF and email it back. The PDF is asking for my full name, address, phone number, SSN, and so on. I figure this may be some kind of phishing attempt, so I ignore it and get back to my work. If it's real, I'll hear about it again, right? Well, two weeks later, my boss tells me amazedly, \"Hey, Bill from ADP is still waiting for your information! Why didn't you reply to him?!?!\" I laughed and told him why. As a bonus, when I was finally put into the system, they managed to get my zip code, phone number, and SSN wrong. At ADP, quality is job zero. reply WorldMaker 16 hours agoparentprev> He asked for my name, which I gave him, and then the last four digits of my social security number, which I also gave him. He then proceeded to ask for my full social security number, at which point alarms started going off in my head and I started sweating about even giving the last four digits to a stranger who had called me out of the blue. I'm super paranoid about even the last four. The first five digits of an SSN were algorithmic for most of US history, and still mostly are but a tiny bit more random entropy, and can be narrowed down with mostly only the city in which you were born and what year. You can often use basic k-means clustering to find it even without that information. More often than not entire families share the first five (or close to it) and you only need to phish one family member to k-means cluster the five digits for the rest. The last four are more often than not the most significant digits in terms of identification and entropy. Masking the rest is almost silly for most Americans. Our masking schemes have actually made phishing easier because people feel safer sharing just the last four, when for most those are the only four that matter. SSN was never intended to be a secret so its design is horrifyingly bad for something that has come to be a huge secret in banking and healthcare and so many other industries. Recent SSN changes have made it a little better for anyone born after roughly 2010, increasing somewhat the entropy in the first five, but the rest of us have problems that we can't solve easily and banks should be ashamed they helped lead us to these problems. reply bastawhiz 16 hours agoparentprevI'd have read him the riot act on the phone. My bank has big warning banners on virtually every page of the site warning me to be careful of scammers. Someone calling me on the phone and asking for my TIN? Yeah, I don't think so. reply krisoft 16 hours agorootparent> I'd have read him the riot act on the phone. No point. If he is a scammer he has a thick skin. If he is working for the bank this is either a training or a policy issue. Just refuse politely and report to the bank. (preferably to some security channel if there is one.) reply donalhunt 8 hours agoparentprevHad a very similar experience with a bank few years ago. I filed an official complaint because it was not possible to verify the caller was authentic. Can you guess what happened next? Yep... The complaints team cold called me and requested PII to confirm they were talking to the right person. I refused and the call ended. Later got a letter saying it wasn't possible to followup on my issue and they didn't see any issues with what I had raised. I tried... :/ reply cogman10 13 hours agoparentprevShout out to my car insurance, Amica. They called me because they needed some account information updated/clarified. Before we started doing anything I told them \"Hey, not to be rude but could I call you with the number on your website? I'm paranoid about scamming and that's safer\" They said \"Absolutely, that actually makes a lot of sense\". So, I called back and we got everything done. The issue, I think, is the larger the company is the more incentivized it is to hide away access to it's internal employees. If you can call a department directly you can start phishing between multiple employees pretty quickly. Locking that down and putting a horrible automated system in place makes that harder to do. reply mooreds 14 hours agoparentprev> Turns out he actually was from the bank and he did cancel the loan application. Plot twist! Didn't see that coming. Seems bizarre to me that this would happen, but reading sibling comments just keeps having me shake my head in dismay. reply sebtron 22 hours agoprevA few months ago I got an email from the IT center of the company I work for that was dodgier than any phishing email I have ever received: - Coming from a domain that looks nothing like the official domain of the company, rather some generic @itservice.com or something. - Subject: \"URGENT: your account is expiring soon\". - Multiple links provided in the email body, all illegible and multiple lines long, none of them from a domain that I can immediately link to the company. - No alternative way of resolving the issue is provided other than clicking on one of those links (no \"go to your account settings\", \"contact your line manager\" or so). And still, it turns out it was real. ~100k employees company btw reply lobochrome 22 hours agoparentOur IT did the exact same thing with expiring m365 passwords. They weren’t using the corp domain, typos all over and the URL was obscured using a bizarre link shortener. The same guys also force us to change our passwords every 6 months and block the last twenty. Passwords we have to enter in systems that can’t pull directly from password managers and thus have to type 10-20 per day. Guess the average strength of an employee password! I think IT incompetence should lead to audit fails or even better delisting from exchanges. reply WorldMaker 15 hours agorootparentI've noticed that Microsoft themselves aren't helping this right now. M365 seems to default to using random-tenant-guid.onmicrosoft.com for a lot of these transactional emails like password changes even though the official account.microsoft.com is fully multi-tenant aware and most Microsoft guidance tells you to always go directly to account.microsoft.com. These transactional email mistakes seem like another case of Microsoft accidentally exposing problems in their org chart to external customers. I imagine it has something to do with the wild rewrites from old Azure AD to new \"exciting brand\" Entra ID and other such shenanigans combined with Microsoft's willingness to bend over backwards to bad IT administrators and letting them set bad defaults (such as \"just us the .onmicrosoft.com GUID instead of a real domain\"), because companies love to pay them good money for the \"control\" to do stupid things in Group Policies and corporate configuration. Combined with the fact that the largest single source of spam I'm seeing right now is also coming from random tenant GUIDs .onmicrosoft.com (is Azure really missing that much SMTP security for random M365 tenants?) and this sort of corporate anti-training users to follow bad transactional email links, it certainly feels like we are in a perfect storm of M365 phishing. reply Fogest 11 hours agorootparentThe whole Microsoft Office suite online just feels like hacky code on top of more hacky code. And combine with how your account can also be signed into your PC, and then also signed into applications. I have a work email, and two personal emails that all make use of Microsoft products. What a mess it is managing the accounts and the different systems. The business emails and accounts just seem sloppy and seem to work different than personal accounts. Overall when compared to Google's suite of products, M365 just seems so sloppy. reply dimask 11 hours agorootparentAdd to this the different varieties of their apps. The whole MS thing is a mess imo also because it cannot decide if it is for enterprise or for personal use. Some colleagues had to reinstall outlook, and after that things did not work properly. What actually happened was that they had googled and downloaded \"outlook\" from microsoft's website, instead of installing the m365 suite version. Which is basically a different application or version or whatever, but sharing the same name and app icon. reply lobochrome 10 hours agorootparentprevAgreed! This should be out of the hands of the local IT clowns entirely. reply gnfargbl 20 hours agorootparentprevThe lack of use of a non-corp domain, the typos and the use of shortened links does sound like a form of incompetence, probably at the management layer. However, the password rotation requirement was until relatively recently something that many IT auditors would actually recommend, even though it leads directly to bad user password choices. In fact I wouldn't be at surprised to learn that was still the case in a lot of places. reply bluGill 20 hours agorootparentFortunately NIST has specific advice that recommends against that which is admissible in court (in the US). I'm not sure how to work through the bureaucracy to do this, but your company should sue them in court for incompetence to get their money back. reply Kye 20 hours agorootparentI've seen multiple accounts from IT/security people who discovered something like \"this could get the company in legal trouble\" with links to details was exactly what got an otherwise intractable issue resolved. reply flatline 20 hours agorootparentprevTwo then-current NIST standards (62 and 71?) side by side gave contradictory advice. It is a step forward though for sure. reply homeyKrogerSage 19 hours agorootparentprevIt is. I work as an IT tech at a military defense contractor and they require regular recycling passwords, with a decent number of passwords remembered. They at least have complexity requirements applied so not 100% bad, but still archaic reply resfirestar 17 hours agorootparentThe same NIST document (800-63) that recommends against password expiration also recommends against complexity requirements, instead organizations are supposed to develop a list of bad passwords that would likely be used in an external dictionary attack. People understandably get really fired up by the idea of not having to change their password every 90 days, but forget that the guidelines are a package that contains a lot of \"shall\"s (no password expiration is a mere \"should\") that would be more painful for organizations stuck with a lot of legacy software, like the requirement to use two authentication factors and the use of secure authentication protocols. reply withinboredom 19 hours agorootparentprevHeh. I just increased a number in my password for my passwords. Then just repeat. So “CompanyName[00]” meets almost all complexity requirements and all I have to do is increment the numbers. Note: I only do this when I have these requirements and I can’t use a password manager. reply mondobe 18 hours agorootparentSounds like a certain BOFH story... have you ever thought about just adding another \"s\" to the end of your password instead? reply DarkGauss 16 hours agorootparentprevYep. That leads directly to passwords like: ReallyLongP@assword$01, ReallyLongP@assword$02, ReallyLongP@assword$03, and so on. reply k8svet 20 hours agorootparentprevYeah, define recently. reply aaronharnly 18 hours agorootparentprevMy work password now has an \"18\" embedded somewhere in the middle of it thanks to my autoincrement approach to handling that kind of obnoxious policy. Then I became CTO and retired the policy to align to modern NIST recommendations, so that \"18\" is in there forever :) reply swozey 20 hours agorootparentprevI forget who puts that stuff out NIST/STIG(?) but IIRC in the recent few years they determined that rotating passwords like that was basically security theater and wasn't worth the damage to the staffs productivity reply marcosdumay 19 hours agorootparentThey decided it was useless security theater decades ago. What happened recently is that they discovered that they rule they used to actively push causes severe harm to security. Now there's a positive rule about not doing it. reply throwway120385 18 hours agorootparentYeah when I was a shipping clerk, we had a pile of usernames and passwords for the Census Bureau's Automated Export System on sticky notes next to the shared computer because the password rotation and complexity requirements made it impossible to remember our passwords. reply marcosdumay 17 hours agorootparentOh, there are many fun games from the 90's where you must infiltrate some place and every computer has some version of \"due to the password rotation requirements, this week's password for the South-East door is 1-2-3-4, effective from Monday\" pasted into it. When the NIST added the bad rule into their ruleset (it was mostly a collection of bad rules at the time), it was already widely mocked in popular culture (well, within the target population). I now wonder if that ruleset (the original one, that basically mandated you copy every flaw on Windows NT) was honest. reply Terr_ 15 hours agorootparent> there are many fun games from the 90's where you must infiltrate some place and every computer has some [sticky note] \"Come to think of it, it's about time to replay Deus Ex again...\" reply tmtvl 10 hours agorootparentDon't forget to invest heavily in Swimming! reply user3939382 20 hours agorootparentprevNIST, whose guidelines, somehow, even other federal departments and agencies usually don’t follow. NIST has very good password complexity and management guidelines. Just USE THEM! It’s not that hard! How do you have billion dollar companies that can’t RTFM. reply bluGill 20 hours agorootparentNIST whose guidelines are admissible in court and a competent judge will take over expert testimony. (an expert witness who says something that contradicts these guidelines is guilty of perjury, though good luck persecuting that) reply singleshot_ 18 hours agorootparentThe rules of evidence govern what is admissible in court and I don’t recall any rule pertaining to NIST guidelines. I think what you might mean is that the guidelines are a learned treatise which, while it would be hearsay for me or you to quote as a fact witness, is nevertheless something an expert witness can refer to. reply Zak 20 hours agorootparentprevPerjury is lying under oath, not disagreeing with government guidelines. reply bee_rider 19 hours agorootparentOn one hand, I agree that just disagreeing with a guideline isn’t perjury. Especially in a case like this where lots of the industry still uses the old (bad, imo) plan. On the other, an expert witness has specifically represented themselves to be an expert. Is there any level of incompetence that raises to the level of perjury in that case? IMO there ought to be. reply dmorgan81 18 hours agorootparentThat would be argued in cross-examination. A witness can be shown to be not a good witness. Perjury is very specific to knowingly lying while testifying under oath. We really don't want to expand it to areas of ignorance or disagreement; that way would stop people from testifying entirely. reply bluGill 16 hours agorootparentAn expert is someone who claims to know though, and thus if they say something that contradicts established facts they are lying under oath. reply singleshot_ 14 hours agorootparentThis is not even near the truth. An expert (under Daubert) is someone who convinces the court they can say something relevant and reliable based on a technique that passes a test concerning: Whether the technique or theory in question can be, and has been tested; Whether it has been subjected to publication and peer review; Its known or potential error rate; The existence and maintenance of standards controlling its operation; and Whether it has attracted widespread acceptance within a relevant scientific community. The expert does not “know.” The expert is the only witness who can give an opinion, more or less. Because the opinion is backed up by something, the court considers it useful. The technique they use is what’s important, not whether their opinion contradicts a fact. I think you will find in many expert trials, two experts get the same facts and come to two completely contradictory opinions, neither of which is perjury. reply bee_rider 19 hours agorootparentprevAre there any examples of the former that you know of? Or is this just optimism? reply spott 20 hours agorootparentprevNIST, but they required password rotation up until very recently, against their own advice. reply jraph 21 hours agorootparentprev> The same guys also force us to change our passwords every 6 months and block the last twenty It's good we have 26 letters, that comfortably leaves you a margin of 6 combinations :-) reply M95D 20 hours agorootparentprev> have to type 10-20 per day Same problem here. My solution: Get a mouse with internal memory for macros, such as Natec Genesis GX78 (old, no longer available, but this is an example). Program your new password on one of the unused mouse buttons or in a different profile. Use the mouse to type the password. reply reaperman 19 hours agorootparentMight be a good product to app-ify. Maybe a USB dongle that acts like a keyboard and controlled by your phone. Give it some sort of 1Password / Bitwarden integration. Could make it double as a YubiKey. Surely this exists already? reply Terr_ 15 hours agorootparentSeparately from the password aspect, consider how convenient it may be to use your smartphone as a kind of re-reified \"clipboard\": Use the camera and on-device OCR to copy text, then \"paste\" it as a virtual keyboard connected over USB. It's very niche, but in those rare situations it'll be a big time-saver compared to human transcription or the rigamarole of setting up some other kind of data channel. reply reaperman 7 hours agorootparentNow I’m curious if BT can be secure enough for all this (responsibly) reply f3d46600-b66e 19 hours agorootparentprevYubikey supports this already, but without the phone part. reply mikepurvis 19 hours agorootparentI should do this for ssh password entry. Running ssh-agent is still 90% of the story, but it comes up often enough that I'm on a terminal in a remote machine or inside a screen session or something that it would still be awfully useful to be able to just autotype it. reply reaperman 18 hours agorootparentprevDoes it require installing 3rd party software on the host machine? This might not work great for this kind of \"shadow IT\" application in all environments, whereas one that acts as a USB keyboard might be more versatile. reply aidenn0 17 hours agorootparentDoes it require installing 3rd party software on the host machine? No, it identifies as a keyboard. It also defaults to generating a password that will use the same scancodes on (most?) western keyboard layouts so that computers configured to default to e.g. QWERTZ or AZERTY will still result in the same password. reply reaperman 13 hours agorootparentHow do you tell it which password to type? reply aidenn0 12 hours agorootparentIIRC there is a maximum of two; one on short-press and one on long-press. reply organsnyder 17 hours agorootparentprevOnly to configure it. It presents as a USB keyboard (among other device types). reply reaperman 13 hours agorootparentHow do you tell it which password to type? I haven't seen yubikeys with physical interfaces to select a particular password. reply RunningDroid 10 hours agorootparentprevThe InputStick¹ can provide the hardware side, the software side is open-source² as well. It only has a keepass2android plugin at the moment though. 1: http://inputstick.com 2: https://github.com/inputstick reply Grazester 19 hours agorootparentprevYubikeys can do this. reply eropple 19 hours agorootparentIt can, and I tried this, but in practice we have to change our passwords at my current employer so frequently that I got more irked changing it on the Yubikey (not the least hassle-free of processes, as I couldn't install the Yubikey software on the work machine) than just typing the thing. reply pjc50 21 hours agorootparentprev> I think IT incompetence should lead to audit fails or even better delisting from exchanges. Fear of policy is why you get things like \"force us to change our passwords every 6 months and block the last twenty\". Getting a central arbiter of IT competence is a hard problem. reply abustamam 19 hours agorootparentprevI had a similar experience at an old company that used M365. YMMV but with Bitwarden I generate passphrases like Pregnant-Guppy-Skateboard9 and it made it tons easier for me to type 20x a day than &7UoTod#$7OOD reply dimask 11 hours agorootparentprev> Guess the average strength of an employee password! It is interesting how sometimes creating \"more secure\" measures results on less security. Our IT department decided that using 2fa for vpn is not enough, we should also extra 2fa for connecting to the webmail even through intranet or vpn. Guess who stopped using the vpn. Meanwhile, one can set up and use our email through any email client app on desktop or mobile without any 2fa at any step. Go figure. reply Thorrez 20 hours agorootparentprevIs blocking the last 20 passwords a bad thing? I agree the other stuff is bad, but to me, that part doesn't seem bad. reply meindnoch 20 hours agorootparentForced password updates are a bad thing. If your company does forced password updates, they are not following the NIST recommendation: https://pages.nist.gov/800-63-FAQ/#q-b05 If your company is not following the NIST recommendation, they are incompetent, and will be held liable in case of a breach. reply ixwt 20 hours agorootparentThe company I work for had a ransomware issue, so they got more zealous about security. They require us to change our passwords every 45 days now. When I pointed out the NIST recommendations of not rotating passwords, they say they are following the guidance of the response team that helped them recover from the ransomware. And that the NIST doesn't actually deal with the real world. reply internet101010 18 hours agorootparentprevInternal password resets are a bad thing. It has its place in document sharing/collaboration platforms not connected to AD as an additional layer of revoking access when people leave a company. reply bbarnett 20 hours agorootparentprevIf your company is not following the NIST recommendation, they are incompetent, and will be held liable in case of a breach This is a stretch. Liable? Please show the case law, or the legislation. (My statement has no relevance to the validity of NIST's recommendations) reply bluGill 20 hours agorootparentNot directly. However NIST is admissible in court and so if someone sues there is now evidence that they should have known better. reply bbarnett 16 hours agorootparentAnything is admissible in court, the judge merely has to allow it. There are 1000s of such organizations, and many conflict with each other. My point is, it's inaccurate to say you are liable for not following NIST. I could easily say you could be liable, for not following me. Does that make it so? No. reply SAI_Peregrinus 13 hours agorootparentNIST SP 800-63B is informative, not normative. It codifies existing industry-standard best-practice, but is not in itself law. However, not following best-practices may be argued as negligence if it leads to a breach or decrease in shareholder value. reply pflenker 20 hours agorootparentprevIt leads to less security as it is more likely that the new password will just be an old one with an incremented number at the end. reply cobbaut 20 hours agorootparentAnd unless there is a minimum password age some people will just change it 20 times and then back to the same password. reply thesuitonym 18 hours agorootparentprevThe worst part is it actually leads users to boasting about how they `beat the system', essentially telling their coworkers what their pattern is, making the password easier to guess. reply macintux 11 hours agorootparentI have long felt that organizations that require password rotation for employees should, when the users are changing their passwords, record and post the old password to an internal site (without any identification of the user) for educational (and mockery) purposes. reply Workaccount2 19 hours agorootparentprevMyself and most people keep our login passwords written on paper in our desk because of this stupid practice. Can't use previous passwords and new password every 90 days. This is on top of 2FA. reply pama 20 hours agorootparentprevEven if this rule technically seems benign, together with the forced change it encourages users to game the system leading to predictable patterns, eg adding a rotating letter or digit combo at the end of a same password. reply alistairSH 20 hours agorootparentprevIn combination with forced changes, it leads to… Password1 Password2 Password3 Etc reply pierat 20 hours agorootparentThe one I see that stays updatable is: PasswordFebruary2024! Where month and year update on the date of forced password change. reply alistairSH 19 hours agorootparentOh, that's a good one.reply Karellen 19 hours agorootparentprevITYM hunter3 hunter4 hunter5 reply bluGill 20 hours agorootparentprevI'm closing in on password100... It is the only sane thing to do, a good password is hard to memorize. (passphrases are must better, but hard to type correctly first thing in the morning and take too long when I need to type my password a dozen times a day) reply swozey 20 hours agorootparentprevI mean it's great for 99% of your passwords and pretty much forces people into using randomized generated passwords.. but I still have to remember at least ONE password by heart. Whether it's 32 characters or 16 or what not, I still need SOME way to get into my password manager to even get to my passwords. So what, I'm going to make my password tacokissies69 and.. what, add a 0 every 6 months so I pass the 20 password minimum? So a hacker can infer that my password is tacokissies69000 of some sort.. reply danaris 20 hours agorootparentprev> The same guys also force us to change our passwords every 6 months While I know this may be fruitless, it might be worthwhile to point out to them that the official guidance from NIST and similar organizations is now not to do this. The IT department where I work required yearly password changes up until I brought this change to their attention, at which point they changed to simply recommending a password change if you have reason to believe it might have been compromised. reply iamthirsty 15 hours agorootparentprevThe Walt Disney Company did exactly this when I was there, and everyone dreaded it. Did nothing but waste time. reply bnralt 19 hours agoparentprevBanks do this as well. I made a purchase, and within minutes got a very scammy looking e-mail from them - low quality gifs, asking me to click on links to a random non-bank website(something like purchase-verification-users.net/235532/confirm.html, and the site wasn’t coming up on any searches). At the same time I get a call from a random number asking me to go over some purchases - I looked up the number, and it’s none of the ones listed for my bank. So I hang up and call my bank directly. I spend 10 minutes going through the phone maze to talk to someone. Finally I get to them, and they confirm that is a number that they use to contact people. How come when you list numbers on your website you don’t list this one? Well, they said they often call from numbers they haven’t listed online. How about that e-mail, do you send those? Well, we sometimes contact people by e-mail, if it says it’s from us in the from: line you can click on it. Did you guys send that one? I don’t have that information; don’t click on it if the from: line isn’t us, but if it is, go ahead. reply xur17 15 hours agorootparent> Well, they said they often call from numbers they haven’t listed online. Worth noting - do not trust the incoming callerid number. This is trivial to fake. reply anonymous_sorry 20 hours agoparentprevMy company's security training tells me to carefully verify any URLs in received emails, but then they have some security software that rewrites all the URLs in incoming emails - presumably as a way of screening them themselves. This might be a reasonable trade-off for centralising monitoring, but it significantly hampers the ability to judge the legitimacy of emails myself. At least update your training! reply Corrado 51 minutes agorootparentM365 has an option to rewrite URLs in incoming emails. It's horrible, at least for people that can actually read URLs. Every link turns into a 300 character mess that I have no idea if its valid or not. The only way to tell is to click it. Maddening! reply lhamil64 20 hours agorootparentprevMy company does that too, it's really annoying. They also sometimes send out mass emails for things like surveys but link to some third party service. I've even seen them put, in the email, things like \"the link goes to a trusted third party and is perfectly safe\". Why should I trust that if I'm already suspicious of the emails legitimately? reply ToucanLoucan 19 hours agorootparentprevOur last round of security training was roundly mocked by our software division, especially around the subject of one of the rules emphasized over and over being to \"never click URLs in emails\" and the sign-in process for the website alongside the distribution of lessons was done exclusively through magic links... in emails. Our CEO is actually a developer himself on our core product (and a bit of a paranoid fella on the cybersecurity front to boot) and he was absolutely furious about this vendor being chosen... reply Rygian 22 hours agoparentprevDid you click on the \"Report Phishing attempt\" button installed by your IT center in your mail client? Sorry for the probable sarcasm. In a company that size, if the IT center does not provide a means to report phishing attempts then there are more serious problems than a dodgy email campaign. reply TeMPOraL 21 hours agorootparentFWIW, I did exactly that a few times where I was 90% certain the e-mail is legit, but it still looked like a phishing attempt. The IT department needs to learn to do better, this is inexcusable, especially in a corporation with otherwise restrictive policies that waste ridiculous amounts of money and effort (think: Windows Defender real-time \"protection\" on developer machines, with no way to exclude your repos). reply sebtron 22 hours agorootparentprevI wanted to, but I could not find it. It turn out I could not see the \"report phishing\" button because of an Outlook glitch. Thanks Microsoft. reply lrem 21 hours agorootparentForward the email to your security org? reply alistairSH 20 hours agorootparentThis. We have a dedicated phish/scam/it-sec channel in Slack for this (in addition to an embedded “report this email” plug-in in Outlook). reply sebtron 17 hours agorootparentprevI did end up forwarding the email to another IT service address (one that I knew was legit). They thanked me for the feedback and said they would improve the message. reply natebc 21 hours agorootparentprevThis is even worse in companies that have security offices actively sending out phishing emails worded as internal emails from your company that shame you if you click any of the links in them. email is well and truly dead. reply dunham 16 hours agorootparentThat reminds me that we had a \"chief architect\" who sent out his fairwell email with a link to his linked-in page in the footer, but the link actually went to a certain music video on youtube. I suppose, if you want to train people to not click on links, that's a fun way to do it. reply ano-ther 20 hours agorootparentprevIt’s a good idea. I am usually a bit pessimistic about it though. If their SOP doesn’t account for “looks like phishing but is from internal sender” then chances are that nobody connects the dots and informs that sender. The intelligence of a small and motivated IT team seems difficult to scale. reply dormento 20 hours agoparentprevOn our company (hosting & PaaS), I was contacted on our internal messenger by a person I've never seen before, asking me to \"please\" run some commands as root and send back the results. After the initial shock (and due infosec diligence) I found out it was just \"the new guy\", needing to collect info about our systems for equipment inventory purposes. Since they didn't have access to our networked management tool yet, and didn't know the finer points about how running `curl ...sh` randomly is not a good idea, they thought it would be ok to get that information piecemeal directly from people. It happens. reply chuckadams 17 hours agorootparentWhen I worked at Sun Microsystems, they had a clever launcher shell script dealie for things like StarOffice documents that did usage tracking, portability fixes (usually setting obscure environment vars), and of course downloading and opening the actual document. Then they started sending those shell scripts as email attachments. One day they sent out an email telling people to not open executable email attachments: the full memo was a SO document wrapped in one of these scripts. To their credit, after the inevitable replies to that email they never used that wrapper again (they moved the launchers to the centralized NFS install where they always should have been) reply from-nibly 19 hours agorootparentprevI flip tables when people make offhand requests like this. Infra teams are not keyboard monkeys with admin creds. reply bombcar 21 hours agoparentprevHealthcare companies in the US send the most scammy looking links for payment processing you’ve ever seen - things like my-healthcare-billing.net It’s insane. reply sgerenser 20 hours agorootparentYeah I got a text from one of these a couple years ago. Something like. “You have an overdue doctor bill of $183.56, please kindly pay immediately at this link: http://my-doctorpay.net/defintelylegit123. Thx!” Didn’t even include the name of the doctor or office, but after calling the only doctors office I had used recently it was apparently legit. I let them know whatever company handles their billing is completely incompetent. reply jameshart 19 hours agorootparentThe US healthcare billing model’s total lack of authentication and disconnection from point of service means that it’s broadly plausible you do owe some random provider money at any time up to several years after your last doctor visit. Send someone an official looking piece of paper telling them they received $394 worth of in office medical laboratory service from Tristate Medical Partners Inc in August last year, that insurance paid $374 and that they just owe you a $20 copay, and I think a lot of people will just go to the online bill pay site and hand over the money. reply sneak 20 hours agorootparentprevWhat incentive do they have to change it? People will still click and still pay, and if they don’t, they’ll refer it to collections and ruin their credit. As long as the billing office gets the money, in their view, the bar for “competence” is passed. This is something that only people like us can see. The rest of the world doesn’t care about the problem, and even if they did, they have zero incentive to fix it. reply avarun 17 hours agorootparent> People will still click and still pay, and if they don’t, they’ll refer it to collections and ruin their credit. Healthcare has one of the lowest payment collection rates of any consumer industry. And as of a couple years ago, medical debt under $500 can no longer go on your credit report even after going to collections. States have passed even more consumer-friendly versions of this law, like NY where no amount of medical debt can affect your credit score. So actually medical billers are directly hurting themselves with their incompetence in this and many other departments. reply bonton89 20 hours agorootparentprevLets not forget all the typosquatting looking domains Microsoft uses. It almost seems like they bought them up to protect users, forgot why they did that and said \"hey we have all these domains, lets use those?\" reply __float 19 hours agorootparentDo you have any examples? I'm largely out of the Microsoft ecosystem these days, aside from the occasional Xbox usage. reply bombcar 18 hours agorootparentOffice.com redirects you to login.microsoftonline.com which isn't horribly bad, but is starting to get there. Now you have microsoft365.com and friends, too. At least when things were login.microsoft.com you could apply the \"last part is definitive\" now that heuristic is pretty useless. And if you watch the actual DNS requests during a login, whew. CDNs make it even worse, here's a few VALID requests from my DNS cache: store-images.s-microsoft.com-c.edgekey.net www.msftconnecttest.com 123499-ipv4v6.farm.dprodmgd103.aa-rt.sharepoint.com download.windowsupdate.com.edgesuite.net At least some end in apparently legitimate domains, but sheesh, that last one looks like something straight out of 2000s era scams. reply WorldMaker 15 hours agorootparentAlso Azure AD and Entra ID and other parts of Microsoft 365 all use onmicrosoft.com, too. A fun bonus to that particular domain is the random meaningless to people GUID-derived tenant IDs in the second level. Knowing what is legitimate, and what is tied so a specific corporate tenant, seems impossible. Certainly helps Microsoft themselves avoid XSS problems, I'm sure, but greatly adds to the confusion of what is a legitimate M365 URL. reply Corrado 46 minutes agorootparentprevYea, it's really fun to log into some some Microsoft site and get redirected 10 times. The domains it goes through are staggering, some of them don't even look like MS names at all. More than once I've been convinced that there is something fishy going on. Only to realize that, nope, that's the way MS wanted it. reply philsnow 21 hours agorootparentprevI’m supposed to pay my semi-annual property taxes (on the order of ~thousands of USD) on a site that ends in .org instead of .gov, and nobody apparently sees anything weird or wrong with it. reply kube-system 17 hours agorootparentSome places in the US outsource not only payment processing, but the entire tax collection process to the private sector. I've heard stories of people living in Pennsylvania who have gone years without filing their local tax return because they thought the tax form was spam. Nope, that sketchy looking mail from some random business, with the .com address is the legally designated tax collector. reply bombcar 18 hours agorootparentprevNow that I think of it, I'm not sure I've ever seen a government payment site hosted on .gov; usually .com. reply 01HNNWZ0MV43FF 18 hours agorootparentYou can tell it's legit if they charge you $2 extra for a credit card instead of a bank transfer lol reply bombcar 16 hours agorootparentMost have gone that way, but a few were still letting you put your entire property tax on credit card with no fee whatsoever as recently as last year. Woohoo free miles! Sometimes the fee is so low that even when they do charge it, it's worth using the credit card. reply JoshTriplett 12 hours agorootparentYeah, I've encountered sites that charge a 1% fee for using a credit card, but I get 1.5% cash back. reply 15457345234 15 hours agorootparentprevid.me Still can't believe it Best hope the government of Macedonia remains friendly I guess reply pakyr 13 hours agorootparent*Montenegro reply mnau 21 hours agorootparentprevOur government uses equivalent of www.mydatabox.cz (real one is mojedatovaschranka.cz). Literally a domain that looks like from teaching material for phishing, no databox.gov.cz or something like that. The domain is for an official legal documentation communication with government and has same legal weight as letter that was person delivered and recipient was checked against ID. reply bluGill 20 hours agorootparentprevWorse every doctor/lab sends their own separate bill with their own separate account numbers and URLs. You could probably make a ton of money just a bill to every address in your city, so long as the amount is around $50 many will not question it anymore as they get so many of those things. reply chuckadams 17 hours agorootparentprevTo be fair, US healthcare billing companies aren't very far removed from scammers in the first place. Except most scammers are more ethical. reply silverquiet 21 hours agoparentprevRegarding the external domain thing, I can say that dealing with domains in a big company gets about as bureaucratic and terrible as just about everything else; I experienced this myself - at a youngish company when I needed a new sub-domain off the big official domain, it was just talk to $dude on the DNS team and he’ll help you out. And he did. A few years later once things had “grown up” a bit, I needed to update a record and I asked the same guy. He told me I needed to fill out a 25 question form and they’d review it. I about half copy and pasted it from another team member’s project and th",
    "originSummary": [
      "Scammers exploit FedEx's reputation to deceive people into phishing scams, resulting in a rise in fraudulent activities.",
      "The article highlights the growing trend of using well-known companies' names to orchestrate phishing schemes.",
      "Increased vigilance and awareness are crucial to avoid falling victim to such fraudulent tactics."
    ],
    "commentSummary": [
      "The discussion delves into security vulnerabilities in delivery services such as FedEx and challenges with password policies following NIST guidelines.",
      "Participants recount personal experiences with companies, revealing inefficiencies, security risks, and frustrations with technical issues in the digital era.",
      "Emphasis is placed on enhancing security practices, communication methods, and password management across diverse industries."
    ],
    "points": 1581,
    "commentCount": 516,
    "retryCount": 0,
    "time": 1708683961
  },
  {
    "id": 39488668,
    "title": "Creating a GPT Model in SQL: A Deep Dive",
    "originLink": "https://explainextended.com/2023/12/31/happy-new-year-15/",
    "originBody": "EXPLAIN EXTENDED How to create fast database queries Happy New Year: GPT in 500 lines of SQL with 9 comments Translations: Russian This year, the talk of the town was AI and how it can do everything for you. I like it when someone or something does everything for me. To this end, I decided to ask ChatGPT to write my New Year's post: \"Hey ChatGPT. Can you implement a large language model in SQL?\" \"No, SQL is not suitable for implementing large language models. SQL is a language for managing and querying data in relational databases. Implementing a language model requires complex algorithms, large datasets, and often deep learning frameworks, which are beyond the capabilities of SQL.\" It just proves that if you want something done right, you have to do it yourself. Encouraged by this optimistic forecast, today we will implement a large language model in SQL. Theory While writing this post, I used the wonderful article GPT in 60 Lines of NumPy by Jay Mody. This article explains the inner workings of a GPT model much better than I can hope to do. Still, a little recap is in order. What is a generative large language model from a technical perspective? A generative LLM is a function. It takes a text string as input (called \"prompt\" in AI parlance), and returns an array of strings and numbers. Here's what the signature of this function looks like: llm(prompt: str) -> list[tuple[str, float]] This function is deterministic. It does a lot of math under the hood, but all this math is hardwired. If you call it repeatedly with the same input, it will always return the same output. It may come as a surprise to anyone who's been using ChatGPT and similar products because they can give different answers to the same question. Yet, it's true. We will shortly see how it works. What are the values this function returns? Something like this: llm(\"I wish you a happy New\") 0 (' Year', 0.967553) 1 (' Years', 0.018199688) 2 (' year', 0.003573329) 3 (' York', 0.003114716) 4 (' New', 0.0009022804) … 50252 (' carbohyd', 2.3950911e-15) 50253 (' volunte', 2.2590102e-15) 50254 ('pmwiki', 1.369229e-15) 50255 (' proport', 1.1198108e-15) 50256 (' cumbers', 7.568147e-17) It returns an array of tuples. Each tuple consists of a word (or, rather, a string) and a number. The number is the probability that this word will continue the prompt. The model \"thinks\" that the phrase \"I wish you a happy New\" will be followed by the character sequence \" Year\" with a probability of 96.7%, \" Years\" of 1.8% and so on. The word \"think\" above is quoted because, of course, the model doesn't really think. It mechanically returns arrays of words and numbers according to some hardwired internal logic. If it's that dumb and deterministic, how can it generate different texts? Large language models are used in text applications (chatbots, content generators, code assistants etc). These applications repeatedly call the model and select the word suggested by it (with some degree of randomness). The next suggested word is added to the prompt and the model is called again. This continues in a loop until enough words are generated. The accrued sequence of words will look like a text in a human language, complete with grammar, syntax and even what appears to be intelligence and reasoning. In this aspect, it is not unlike a Markov chain which works on the same principle. The internals of a large language model are wired up so that the next suggested word will be a natural continuation of the prompt, complete with its grammar, semantics and sentiment. Equipping a function with such a logic became possible through a series of scientific breakthroughs (and programming drudgery) that have resulted in the development of the family of algorithms known as GPT, or Generative Pre-trained Transformer. What does \"Generative Pre-trained Transformer\" mean? \"Generative\" means that it generates text (by adding continuations to the prompt recursively, as we saw earlier). \"Transformer\" means that it uses a particular type of neural network, first developed by Google and described in this paper. \"Pre-trained\" is a little bit historical. Initially, the ability for the model to continue text was thought of as just a prerequisite for a more specialized task: inference (finding logical connections between phrases), classification (for instance, guessing the number of stars in a hotel rating from the text of the review), machine translation and so on. It was thought that these two parts should have been trained separately, the language part being just a pre-training for a \"real\" task that would follow. As the original GPT paper puts it: We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. It was not until later that people realized that, with a model large enough, the second step was often not necessary. A Transformer model, trained to do nothing else than generate texts, turned out to be able to follow human language instructions that were contained in these texts, with no additional training (\"fine-tuning\" in AI parlance) required. With that out of the way, let's focus on the implementation. Generation Here is what happens when we try to generate text from the prompt using GPT2: def generate(prompt: str) -> str: # Transforms a string into a list of tokens. tokens = tokenize(prompt) # tokenize(prompt: str) -> list[int] while True: # Runs the algorithm. # Returns tokens' probabilities: a list of 50257 floats, adding up to 1. candidates = gpt2(tokens) # gpt2(tokens: list[int]) -> list[float] # Selects the next token from the list of candidates next_token = select_next_token(candidates) # select_next_token(candidates: list[float]) -> int # Append it to the list of tokens tokens.append(next_token) # Decide if we want to stop generating. # It can be token counter, timeout, stopword or something else. if should_stop_generating(): break # Transform the list of tokens into a string completion = detokenize(tokens) # detokenize(tokens: list[int]) -> str return completion Let's implement all these pieces one by one in SQL. Tokenizer Before a text can be fed to a neural network, it needs to be converted into a list of numbers. Of course, that's barely news: that's what text encodings like Unicode do. Plain Unicode, however, doesn't really work well with neural networks. Neural networks, at their core, do a lot of matrix multiplications and capture whatever predictive powers they have in the coefficients of these matrixes. Some of these matrixes have one row per every possible value in the \"alphabet\"; others have one row per \"character\". Here, the words \"alphabet\" and \"character\" don't have the usual meaning. In Unicode, the \"alphabet\" is 149186 characters long (this is how many different Unicode points there are at the time of this writing), and a \"character\" can be something like this: ﷽ (yes, that's a single Unicode point number 65021, encoding a whole phrase in Arabic that is particularly important for the Muslims). Note that the very same phrase could have been written in usual Arabic letters. It means that the same text can have many encodings. As an illustration, let's take the word \"PostgreSQL\". If we were to encode it (convert to an array of numbers) using Unicode, we would get 10 numbers that could potentially be from 1 to 149186. It means that our neural network would need to store a matrix with 149186 rows in it and perform a number of calculations on 10 rows from this matrix. Some of these rows (corresponding to the letters of the English alphabet) would be used a lot and pack a lot of information; others, like poop emoji and obscure symbols from dead languages, would hardly be used at all, but still take up space. Naturally, we want to keep both these numbers, the \"alphabet\" length and the \"character\" count, as low as possible. Ideally, all the \"characters\" in our alphabet should be distributed uniformly, and we still want our encoding to be as powerful as Unicode. The way we can do that, intuitively, is to assign unique numbers to sequences of words that occur often in the texts we work with. In Unicode, the same religious phrase in Arabic can be encoded using either a single code point, or letter by letter. Since we are rolling our own encoding, we can do the same for the words and phrases that are important for the model (i.e. show up often in texts). For instance, we could have separate numbers for \"Post\", \"greSQL\" and \"ing\". This way, the words \"PostgreSQL\" and \"Posting\" would both have a length of 2 in our representation. And of course, we would still maintain separate code points for shorter sequences and individual bytes. Even if we come across gibberish or a text in a foreign language, it would still be encodable, albeit longer. GPT2 uses a variation of the algorithm called Byte pair encoding to do precisely that. Its tokenizer uses a dictionary of 50257 code points (in AI parlance, \"tokens\") that correspond to different byte sequences in UTF-8 (plus the \"end of text\" as a separate token). This dictionary was built by statistical analysis performed like this: Start with a simple encoding of 256 tokens: one token per byte. Take a large corpus of texts (preferably the one the model will be trained on). Encode it. Calculate which pair of tokens is the most frequent. Let's assume it's 0x20 0x74 (space followed by the lowercase \"t\"). Assign the next available value (257) to this pair of bytes. Repeat the steps 3-5, now paying attention to the byte sequences. If a sequence of bytes can be encoded with a complex token, use the complex token. If there are ambiguities (say, \"abc\" can, at some point, be encoded as \"a\" + \"bc\" or \"ab\" + \"c\"), use the one with the lowest number (because it was added earlier and hence is more frequent). Do this recursively until all sequences that can collapse into a single token will collapse into a single token. Perform the collapse 50000 times over. The number 50000 was chosen more or less arbitrarily by the developers. Other models keep the number of tokens in a similar range (from 30k to 100k). At every iteration of this algorithm, a new token that is a concatenation of two previous ones will be added to the dictionary. Ultimately, we will end up with 50256 tokens. Add a fixed-number token for \"end-of-text\", and we're done. The GPT2 version of BTE has another layer of encoding: the token dictionary maps tokens to strings and not arrays of bytes. Mapping from bytes to string characters is defined in this function. We will save the dictionary it produces in the table encoder. Let's see how we can implement the tokenizer in SQL. The tokenizer is an integral part of GPT2, and the token dictionary can be downloaded from OpenAI's website along with the rest of the model. We will need to import it into the table tokenizer. At the bottom of this post, you will find a link to the code repository. Its code will automate populating database tables needed for the model. In a recursive CTE, we will split this word into tokens (starting with single bytes) and merge the best adjacent pairs, until there is nothing left to merge. The merging itself happens in a nested recursive CTE. For the demo, I will use the word \"Mississippilessly\". Each record in the resultset shows the best pair to collapse found so far, and also the progress through the query. WITH RECURSIVE bpe AS ( SELECT (n + 1)::BIGINT AS position, character, TRUE AS continue, 1 AS step, NULL::INT AS token, NULL::TEXT AS combined FROM CONVERT_TO('Mississippilessly', 'UTF-8') AS bytes CROSS JOIN LATERAL GENERATE_SERIES(0, LENGTH(bytes) - 1) AS n JOIN encoder ON byte = GET_BYTE(bytes, n) UNION ALL ( WITH RECURSIVE base AS ( SELECT * FROM bpe WHERE continue ), bn AS ( SELECT ROW_NUMBER() OVER (ORDER BY position) AS position, continue, character, character || LEAD(character) OVER (ORDER BY position) AS cluster FROM base ), top_rank AS ( SELECT tokenizer.* FROM bn CROSS JOIN LATERAL ( SELECT * FROM tokenizer WHERE tokenizer.cluster = bn.cluster LIMIT 1 ) tokenizer ORDER BY token LIMIT 1 ), breaks AS ( SELECT 0::BIGINT AS position, 1 AS length UNION ALL SELECT bn.position, CASE WHEN token IS NULL THEN 1 ELSE 2 END FROM breaks JOIN bn ON bn.position = breaks.position + length LEFT JOIN top_rank USING (cluster) ) SELECT position, character, token IS NOT NULL, (SELECT step + 1 FROM base LIMIT 1), token, top_rank.cluster FROM breaks LEFT JOIN top_rank ON 1 = 1 CROSS JOIN LATERAL ( SELECT STRING_AGG(character, '' ORDER BY position) AS character FROM bn WHERE bn.position >= breaks.position AND bn.position0 ) ) SELECT step, MAX(token) AS token, MAX(combined) AS combined, ARRAY_AGG(character ORDER BY position) FROM bpe WHERE continue GROUP BY step ORDER BY step step token combined array_agg 1 None None ['M', 'i', 's', 's', 'i', 's', 's', 'i', 'p', 'p', 'i', 'l', 'e', 's', 's', 'l', 'y'] 2 271 is ['M', 'is', 's', 'is', 's', 'i', 'p', 'p', 'i', 'l', 'e', 's', 's', 'l', 'y'] 3 274 es ['M', 'is', 's', 'is', 's', 'i', 'p', 'p', 'i', 'l', 'es', 's', 'l', 'y'] 4 306 ly ['M', 'is', 's', 'is', 's', 'i', 'p', 'p', 'i', 'l', 'es', 's', 'ly'] 5 346 il ['M', 'is', 's', 'is', 's', 'i', 'p', 'p', 'il', 'es', 's', 'ly'] 6 381 pp ['M', 'is', 's', 'is', 's', 'i', 'pp', 'il', 'es', 's', 'ly'] 7 408 ess ['M', 'is', 's', 'is', 's', 'i', 'pp', 'il', 'ess', 'ly'] 8 747 iss ['M', 'iss', 'iss', 'i', 'pp', 'il', 'ess', 'ly'] 9 3974 ipp ['M', 'iss', 'iss', 'ipp', 'il', 'ess', 'ly'] 10 17140 Miss ['Miss', 'iss', 'ipp', 'il', 'ess', 'ly'] 11 30608 iless ['Miss', 'iss', 'ipp', 'iless', 'ly'] On each step, the BPE algorithm finds the best pair of tokens to merge and merges them (you can see the merged pair and its rank in the output). This procedure brings down the token space size from Unicode's 150k to 50k, and the number of tokens (in this particular word) from 17 to 5. Both are great improvements. When working with multiple words, the tokenizer first splits the text into separate words using this regexp and merges the tokens inside each word separately. Unfortunately, PostgreSQL doesn't support Unicode character properties in regexps, so I had to tweak it a little bit (probably killing proper Unicode support in the process). Here's how it looks in SQL: WITH input AS ( SELECT 'PostgreSQL is great' AS prompt ), clusters AS ( SELECT part_position, bpe.* FROM input CROSS JOIN LATERAL REGEXP_MATCHES(prompt, '''s|''t|''re|''ve|''m|''ll|''d| ?\\w+| ?\\d+| ?[^\\s\\w\\d]+|\\s+(?!\\S)|\\s+', 'g') WITH ORDINALITY AS rm (part, part_position) CROSS JOIN LATERAL ( WITH RECURSIVE bpe AS ( SELECT (n + 1)::BIGINT AS position, character, TRUE AS continue FROM CONVERT_TO(part[1], 'UTF-8') AS bytes CROSS JOIN LATERALGENERATE_SERIES(0, LENGTH(bytes) - 1) AS n JOIN encoder ON byte = GET_BYTE(bytes, n) UNION ALL ( WITH RECURSIVEbase AS(SELECT *FROM bpeWHERE continue),bn AS(SELECT ROW_NUMBER() OVER (ORDER BY position) AS position,continue,character,character || LEAD(character) OVER (ORDER BY position) AS clusterFROM base),top_rank AS(SELECT tokenizer.*FROM bnCROSS JOIN LATERAL(SELECT *FROM tokenizerWHERE tokenizer.cluster = bn.clusterLIMIT 1) tokenizerORDER BYtokenLIMIT 1),breaks AS(SELECT 0::BIGINT AS position, 1 AS lengthUNION ALLSELECT bn.position,CASE WHEN token IS NULL THEN 1 ELSE 2 ENDFROM breaksJOIN bnON bn.position = breaks.position + lengthLEFT JOINtop_rankUSING (cluster)) SELECT position, character, token IS NOT NULL FROM breaks LEFT JOINtop_rank ON 1 = 1 CROSS JOIN LATERAL(SELECT STRING_AGG(character, '' ORDER BY position) AS characterFROM bnWHERE bn.position >= breaks.positionAND bn.position0 ) ) SELECT position, character AS cluster FROM bpe WHERE NOT continue ) bpe ), tokens AS ( SELECT token, cluster FROM clusters JOIN tokenizer USING (cluster) ) SELECT * FROM tokens token cluster 6307 Post 47701 greSQL 318 Ġis 1049 Ġgreat The weird character Ġ is the whitespace. This query tokenizes the prompt and converts it into an array of numbers. This way, the prompt is ready for its journey through the layers of the model. Embeddings The tokens represent parts of the human languages (about 0.75 words per token, in general), so any model that is trying to succeed at text completion should somehow encode the relationships between these parts. Even in isolation, the parts of the speech have sets of orthogonal properties. Let's take the word \"subpoena\" (which happens to have a whole token in itself in the GPT2 tokenizer). Is it a noun? Yes, very much so. Is it a verb? Well, sort of. Is it an adjective? Not that much, but it can be if you squint hard enough. Is it legalese? Hell yes. And so on. All these properties are orthogonal, i.e. independent of each other. A word can be a legalese noun but not an adjective or a verb. In English, any combination thereof can happen. Things with orthogonal properties are best encoded using vectors. Instead of having a single property (like a token number), we can have many. And it helps if we can wiggle them as we want. For instance, for a word to continue the phrase \"A court decision cited by the lawyer mentions the …\" we would probably want something that's heavy on the legalese dimension and at the same time heavy on being a noun. We don't really care if it has a side hustle being an adjective, a verb, or a flower. In math, mapping narrower values into wider spaces (such as token IDs to vectors) is called an embedding. This is exactly what we are doing here. How do we decide which properties these vectors represent? We don't. We just provide enough vector space for every token and hope that the model during its training phase will populate these dimensions with something meaningful. GPT2 uses 768 dimensions for its vectors. There is no telling in advance (and, actually, even in the retrospective) what property of the word will, say, the dimension 247 encode. Surely it would encode something, but it's not easy to tell what it is. What properties of each token do we want to embed in the vector space? Anything that has any bearing on what the next token would be. Token id? Of course. Different tokens mean different things. Position of the token in the text? Yes, please. \"Blue violet\" and \"violet blue\" are not the same thing. Relationships of tokens to each other? Sure! That's, probably, the most important part of the job, and the Attention block of the Transformer architecture was the first one to get it right. Tokens and positions are easy to embed. Let's say we have the phrase \"PostgreSQL is great\", which, as we already know, maps to four tokens: [6307, 47701, 318, 1049]. Among other parameters of GPT2, there are two matrixes called WTE (word token embedding) and WPE (word position embedding). As the names suggest, the former stores embeddings of the tokens, and the latter stores embeddings of the positions. The actual values of these embeddings have been populated (\"learned\") during the training of GPT2. As far as we are concerned, they are constants that live in the database tables wte and wpe. WTE is 50257×768 and WPE is 1024×768. The latter means that the maximum number of tokens that we can use in a prompt to GPT2 is 1024. If we provide more tokens in the prompt, we just won't be able to pull positional embeddings for them. It's an architectural aspect (\"hyperparameter\" in AI parlance) of the model that is set at design time and cannot be changed by training. When people talk about the \"context window\" of an LLM, they mean this number. We have the token 6307 at place 0, 47701 at 1, 318 at 2, and 1049 at 3. For each of these tokens and positions, we have two vectors: one from WTE and another one from WPE. We need to add them together. The four resulting vectors will be the inputs for the next part of the algorithm: the feed-forward neural network with the attention mechanism. For the SQL part, we will use pgvector, a PostgreSQL extension. A little disclaimer: normally, I write code for my New Year posts in vanilla SQL, sometimes with pure SQL functions as helpers. It would be perfectly possible to do it for this post as well by defining vector operations on arrays, at the cost of some performance decrease (it was done in version 1 and worked, albeit slowly). With the advent of the AI and growing importance of vector databases, pgvector or its equivalent will definitely make it into the core of PostgreSQL within two or three releases. I just decided to ride the wave of the future. Here's how we do that in SQL: WITH embeddings AS ( SELECT place, values FROM UNNEST(ARRAY[6307, 47701, 318, 1049]) WITH ORDINALITY AS tokens (token, ordinality) CROSS JOIN LATERAL ( SELECT ordinality - 1 AS place ) o CROSS JOIN LATERAL ( SELECT wte.values + wpe.values AS values FROM wte CROSS JOIN wpe WHERE wte.token = tokens.token AND wpe.place = o.place ) embedding ) SELECT place, (values::REAL[])[0:5] FROM embeddings place values 0 [0.1035146, -0.22879261, 0.18413992, -0.29924694, 0.18642524] 1 [0.10757777, -0.0011023134, -0.0077463835, 0.03656415, -0.14654925] 2 [-0.005507436, -0.07471258, 0.11009377, -0.11708109, -0.14026159] 3 [-0.04785268, -0.0792546, 0.1628486, -0.3598496, 0.11462127] (To keep the output short, this query only shows the first 5 dimensions for each vector) Attention The part that really makes the Transformer architecture tick is the self-attention mechanism. It was first described in the 2017 paper \"Attention is all you need\" by Vasmani et al., probably the most famous AI paper, whose name has since become a snowclone (a cliché for naming other papers). So far, we have several vectors that, hopefully, encode some syntactic and semantic properties of the words in our prompt. We need these properties to somehow transfer to the last vector. A little spoiler alert: at the end of the day, it will be the last vector that will store the embedding for the continuation word. In a phrase like \"I looked at the violet and saw that it was not the usual …\", the ellipsis has to be something you see (and this notion has to jump from \"saw\"), something that's a property of a violet (jumping from \"violet\" to \"it\" and then to the ellipsis), and something that is \"unusual\" (jumping from \"not\" and \"usual\" and flipping the sign in the dimensions responsible for the usualness). The analogy in the real world would be a person reading a book in a foreign language that they kind of have a basic command of, but don't quite know very well. They would need to consciously trace their way from one word to another, and if they don't pay attention to the crucial part of the phrase, their understanding would be wrong. To enable this transfer of meaning from one token to another, we need to allow the vectors of all the tokens to influence each other. If we want to populate the word \"it\" with some concrete semantics, how much of the semantics should come from the previous vectors in the prompt, and how much should remain from the word \"it\" itself? To solve this problem, the model uses 12 sets of matrixes called Q (query), K (key) and V (value). Each of them has 64 columns. They are obtained from the vector embeddings through a 768×2304 linear transformation c_attn, whose weights and biases are stored in the tables c_attn_w and c_attn_b. The result of c_attn is a matrix with n_token rows and 2304 columns (3×12×64). It consists of 12 Q matrixes, 12 K matrixes and 12 V matrixes stacked horizontally, in this order. Each set of Q, K and V is called a \"head\". They are used to perform the step known as \"multi-headed causal self-attention\", by calculating the attention function. Here's the formula for the attention function: , where softmax is the weight normalization function. It's defined like this: is a constant matrix called a \"causal mask\". It is defined like this: Softmax turns negative infinities into zeros. Why do we need masking? The prompt in our previous examples had 4 tokens, and the first thing the model did was calculate the 4 embeddings for these 4 tokens. As the model progresses, these vectors will undergo a lot of calculations, but for the most part, they will be independent and parallel. Changes in one vector will not affect the other vectors, as if they had not existed. The self-attention block is the only place in the whole model where the vectors affect each other. Once the model is done with the math, the candidates for the next token will be decided solely from the last embedding. All the information flow should be directed towards this last vector and not from it. The transient values of the last embedding should not affect the transient values of the previous embeddings during the forward pass of the model. That's why we \"mask\" the latter embeddings so that they don't influence the earlier embeddings through this particular channel. Hence the word \"causal\" in \"multi-headed causal self-attention\". Why are the matrixes called \"query\", \"key\" and \"value\"? To be honest, I'm not sure it's even a good analogy. But I'll still do my take on the intuition behind it. In machine learning, generally, calculations should not involve variable-length loops or statement branching. Everything should be done through the composition of simple analytic functions (additions, multiplications, powers, logarithms and trig). It allows backpropagation, which relies on technologies like automatic differentiation, to work efficiently. The mathematical model of the key-value store is the expression , but it's not a smooth, differentiable function and it will not work well with backpropagation. To make it work, we would need to turn it into a smooth function that would be close to when is close to , and close to otherwise. The Gaussian distribution (\"bell curve\"), scaled to , with the expectation of and a small enough standard deviation would do perfectly for this purpose: , where is an arbitrary parameter, defining how sharp the bell curve is. In a vector space with many enough dimensions, if we take a fixed vector and several vectors that randomly and uniformly deviate from on every dimension, their dot products will naturally form the bell curve. So, in the vector space, the concept of a \"differentiable key-value store\" can be modeled by the expression , which is what we are using in our attention function. Again, this analogy is far-fetched. It's best not to pay too much attention (no pun intended) to these concepts of attention, meaning flow, hash tables and so on. Just think of them as an inspiration for a math trick that has been put to the test and proved to work really well. Let's illustrate this step: WITH embeddings AS ( SELECT place, values FROM UNNEST(ARRAY[6307, 47701, 318, 1049]) WITH ORDINALITY AS tokens (token, ordinality) CROSS JOIN LATERAL ( SELECT ordinality - 1 AS place ) o CROSS JOIN LATERAL ( SELECT wte.values + wpe.values AS values FROM wte CROSS JOIN wpe WHERE wte.token = tokens.token AND wpe.place = o.place ) embedding ), c_attn_w AS ( SELECT * FROM c_attn_w WHERE block = 0 ), c_attn_b AS ( SELECT * FROM c_attn_b WHERE block = 0 ), ln_1_g AS ( SELECT * FROM ln_1_g WHERE block = 0 ), ln_1_b AS ( SELECT * FROM ln_1_b WHERE block = 0 ), mha_norm AS ( SELECT place, mm.values + c_attn_b.values AS values FROM ( SELECT place, ARRAY_AGG(INNER_PRODUCT(c_attn_w.values, layer_norm.values) ORDER BY y)::VECTOR(2304) AS values FROM ( SELECT place, agg.values * ln_1_g.values + ln_1_b.values AS values FROM (SELECT place, norm.valuesFROM embeddingsCROSS JOIN LATERAL(SELECT AVG(value) AS mean,VAR_POP(value) AS varianceFROM UNNEST(values::REAL[]) value) aggCROSS JOIN LATERAL(SELECT ARRAY_AGG((value - mean) / SQRT(variance + 1E-5) ORDER BY ordinality)::VECTOR(768) AS valuesFROM UNNEST(values::REAL[]) WITH ORDINALITY AS n(value, ordinality)) norm) agg CROSS JOINln_1_b CROSS JOINln_1_g ) layer_norm CROSS JOIN c_attn_w GROUP BY place ) mm CROSS JOIN c_attn_b ), head AS ( SELECT place, (values::REAL[])[1:64]::VECTOR(64) AS q, (values::REAL[])[1 + 768:64 + 768]::VECTOR(64) AS k, (values::REAL[])[1 + 1536:64 + 1536]::VECTOR(64) AS v FROM mha_norm ), sm_input AS ( SELECT h1.place AS x, h2.place AS y, INNER_PRODUCT(h1.q, h2.k) / 8 + CASE WHEN h2.place > h1.place THEN -1E10 ELSE 0 END AS value FROM head h1 CROSS JOIN head h2 ), sm_diff AS ( SELECT x, y, value - MAX(value) OVER (PARTITION BY x) AS diff FROM sm_input ), sm_exp AS ( SELECT x, y, CASE WHEN diff0 THEN TO_CHAR(value, '0.00') ELSE ' 0' END, ' ' ORDER BY place) AS matrix FROM softmax GROUP BY x ) softmax_grouped USING (place) place q k v matrix attention 0 +0.381 -0.579 +0.073 … -1.395 +2.367 +0.332 … -0.006 +0.192 +0.047 … 1.00 0 0 0 -0.006 +0.192 +0.047 … 1 +1.518 +0.827 -0.388 … -2.380 +3.714 +0.659 … -0.315 -0.062 +0.018 … 0.73 0.27 0 0 -0.089 +0.124 +0.039 … 2 +0.238 -0.226 +0.344 … -1.952 +2.404 +1.953 … +0.256 -0.268 +0.301 … 0.67 0.26 0.07 0 -0.069 +0.095 +0.057 … 3 +1.130 -0.011 -0.103 … -2.855 +2.053 +2.813 … +0.176 +0.019 -0.099 … 0.59 0.19 0.12 0.10 -0.016 +0.071 +0.058 … Here is what we did: Before calculating the attention function, we normalized the vectors by applying the linear transformation . The matrix and the vector are called \"scale\" and \"shift\", accordingly. They are learned parameters of the model, which are stored in the tables ln_1_g and ln_1_b We are only showing the first head of the first layer of the algorithm. After we multiplied the vectors by the learned coefficients from c_attn_w and c_attn_b (\"weight\" and \"bias\"), we sliced the resulting 2304-vectors, taking 64-vectors starting at the positions 0, 768 and 1536. They correspond to the vectors Q, K and V for the first head. EXP in PostgreSQL fails on really small numbers, that's why we shortcut to zero if the argument to EXP is less than -745.13. We are only showing the first three elements for each vector. The attention matrix we show in full. As we can see, the first value vector got copied to the output as is (as it will do in every other layer of the algorithm). It means that once the model has been trained, the output embedding for the first token will be only defined by the value of the first token. In general, during the recursive inference phase, where tokens only get added to the prompt, only the last embedding in the output will ever change compared to the previous iteration. This is what the causal mask does. Looking a bit forward: the attention block is the only place in the entire algorithm where tokens can influence each other during the forward pass. Since we have disabled the ability of later tokens to influence the previous ones in this step, all the calculations done on the previous tokens can be reused between the forward passes of the model. Remember, the model operates by appending tokens to the prompt. If our original (tokenized) prompt is \"Post greSQL Ġis Ġgreat\" and the next one will be (for instance) \"Post greSQL Ġis Ġgreat Ġfor\", all the results of the calculations made on the first four tokens can be reused for the new prompt; they will never change, regardless of what is appended to them. Jay Mody's illustrative article doesn't make use of this fact (and neither do we, for the sake of simplicity), but the original GPT2 implementation does. Once all the heads are done, we will end up with 12 matrixes, each 64 columns wide and n_tokens rows tall. To map it back to the dimension of embedding vectors (768), we just need to stack these matrixes horizontally. The final step of multi-headed attention involves projecting the values through a learned linear transformation of the same dimension. Its weights and biases are stored in the tables c_proj_w and c_proj_b. Here's what the code for a complete multi-headed attention step in the first layer looks like: WITH embeddings AS ( SELECT place, values FROM UNNEST(ARRAY[6307, 47701, 318, 1049]) WITH ORDINALITY AS tokens (token, ordinality) CROSS JOIN LATERAL ( SELECT ordinality - 1 AS place ) o CROSS JOIN LATERAL ( SELECT wte.values + wpe.values AS values FROM wte CROSS JOIN wpe WHERE wte.token = tokens.token AND wpe.place = o.place ) embedding ), c_proj_w AS ( SELECT * FROM c_proj_w WHERE block = 0 ), c_proj_b AS ( SELECT * FROM c_proj_b WHERE block = 0 ), mlp_c_fc_w AS ( SELECT * FROM mlp_c_fc_w WHERE block = 0 ), mlp_c_fc_b AS ( SELECT * FROM mlp_c_fc_b WHERE block = 0 ), mlp_c_proj_w AS ( SELECT * FROM mlp_c_proj_w WHERE block = 0 ), mlp_c_proj_b AS ( SELECT * FROM mlp_c_proj_b WHERE block = 0 ), c_attn_w AS ( SELECT * FROM c_attn_w WHERE block = 0 ), c_attn_b AS ( SELECT * FROM c_attn_b WHERE block = 0 ), ln_1_g AS ( SELECT * FROM ln_1_g WHERE block = 0 ), ln_1_b AS ( SELECT * FROM ln_1_b WHERE block = 0 ), mha_norm AS ( SELECT place, mm.values + c_attn_b.values AS values FROM ( SELECT place, ARRAY_AGG(INNER_PRODUCT(c_attn_w.values, layer_norm.values) ORDER BY y)::VECTOR(2304) AS values FROM ( SELECT place, agg.values * ln_1_g.values + ln_1_b.values AS values FROM (SELECT place, norm.valuesFROM embeddingsCROSS JOIN LATERAL(SELECT AVG(value) AS mean,VAR_POP(value) AS varianceFROM UNNEST(values::REAL[]) value) aggCROSS JOIN LATERAL(SELECT ARRAY_AGG((value - mean) / SQRT(variance + 1E-5) ORDER BY ordinality)::VECTOR(768) AS valuesFROM UNNEST(values::REAL[]) WITH ORDINALITY AS n(value, ordinality)) norm) agg CROSS JOINln_1_b CROSS JOINln_1_g ) layer_norm CROSS JOIN c_attn_w GROUP BY place ) mm CROSS JOIN c_attn_b ), heads AS ( SELECT place, head, (values::REAL[])[(head * 64 + 1):(head * 64 + 64)]::VECTOR(64) AS q, (values::REAL[])[(head * 64 + 1 + 768):(head * 64 + 64 + 768)]::VECTOR(64) AS k, (values::REAL[])[(head * 64 + 1 + 1536):(head * 64 + 64 + 1536)]::VECTOR(64) AS v FROM mha_norm CROSS JOIN GENERATE_SERIES(0, 11) head ), sm_input AS ( SELECT head, h1.place AS x, h2.place AS y, INNER_PRODUCT(h1.q, h2.k) / 8 + CASE WHEN h2.place > h1.place THEN -1E10 ELSE 0 END AS value FROM heads h1 JOIN heads h2 USING (head) ), sm_diff AS ( SELECT head, x, y, value - MAX(value) OVER (PARTITION BY head, x) AS diff FROM sm_input ), sm_exp AS ( SELECT head, x, y, CASE WHEN diffh1.place THEN -1E10 ELSE 0 END AS value FROM heads h1 JOIN heads h2 USING (head) ), sm_diff AS ( SELECT head, x, y, value - MAX(value) OVER (PARTITION BY head, x) AS diff FROM sm_input ), sm_exp AS ( SELECT head, x, y, CASE WHEN diffh1.place THEN -1E10 ELSE 0 END AS value FROM heads h1 JOIN heads h2 USING (head) ), sm_diff AS ( SELECT head, x, y, value - MAX(value) OVER (PARTITION BY head, x) AS diff FROM sm_input ), sm_exp AS ( SELECT head, x, y, CASE WHEN diffh1.place THEN -1E10 ELSE 0 END AS value FROM heads h1 JOIN heads h2 USING (head) ), sm_diff AS ( SELECT head, x, y, value - MAX(value) OVER (PARTITION BY head, x) AS diff FROM sm_input ), sm_exp AS ( SELECT head, x, y, CASE WHEN diff = breaks.positionAND bn.position0 ) ) SELECT position, character AS cluster FROM bpe WHERE NOT continue ) bpe ), tokens AS ( SELECT ARRAY_AGG(token ORDER BY part_position, position) AS input FROM clusters JOIN tokenizer USING (cluster) ), gpt AS ( SELECT input, ARRAY_LENGTH(input, 1) AS original_length FROM tokens UNION ALL SELECT input || next_token.token, original_length FROM gpt CROSS JOIN input CROSS JOIN LATERAL ( WITH RECURSIVE hparams AS ( SELECT ARRAY_LENGTH(input, 1) AS n_seq,12 AS n_block ), embeddings AS ( SELECT place, values FROM hparams CROSS JOIN LATERALUNNEST(input) WITH ORDINALITY AS tokens (token, ordinality) CROSS JOIN LATERAL(SELECT ordinality - 1 AS place) o CROSS JOIN LATERAL(SELECT wte.values + wpe.values AS valuesFROM wteCROSS JOINwpeWHERE wte.token = tokens.tokenAND wpe.place = o.place) embedding ), transform AS ( SELECT 0 AS block, place, values FROM embeddings UNION ALL ( WITH previous AS(SELECT *FROM transform) SELECT block + 1 AS block, transformed_layer.* FROM hparams CROSS JOIN LATERAL(SELECT blockFROM previousWHERE blockh1.place THEN -1E10 ELSE 0 END AS valueFROM heads h1JOIN heads h2USING (head)),sm_diff AS(SELECT head, x, y, value - MAX(value) OVER (PARTITION BY head, x) AS diffFROM sm_input),sm_exp AS(SELECT head, x, y, CASE WHEN diff = lowAND rnd50256 ), output AS ( SELECT CONVERT_FROM(STRING_AGG(SET_BYTE('\\x00', 0, byte), '' ORDER BY position), 'UTF8') AS response FROM ( SELECT STRING_AGG(cluster, '' ORDER BY ordinality) AS response FROM input JOIN gpt ON ARRAY_LENGTH(input, 1) = original_length + threshold CROSS JOIN LATERAL UNNEST(input) WITH ORDINALITY n (token, ordinality) JOIN tokenizer USING (token) ) q CROSS JOIN LATERAL STRING_TO_TABLE(response, NULL) WITH ORDINALITY n (character, position) JOIN encoder USING (character) ) SELECT * FROM output response Happy New Year! I wish you all the best in your new year! This part the AI got right. I do wish you all the best in your new year! You can find the queries and the installation code in the GitHub repository: quassnoi/explain-extended-2024 Happy New Year! Previous New Year posts: 2010: SQL graphics in Oracle, MySQL, SQL Server and PostgreSQL 2011: Drawing a clock in SQL 2012: Drawing snowflakes in SQL 2013: View of Earth from space in SQL 2014: Drawing fractals in SQL 2015: Composing music in SQL 2016: Conway’s Game of Life in SQL 2017: The Sultan’s Riddle in SQL 2018: Settlers of Catan in SQL 2019: GIF decoder in SQL 2020: A stereogram in SQL 2021: 3D picture of the coronavirus in SQL 2022: Quantum computer emulator in SQL 2023: Solving the Rubik’s Cube in SQL Share this: Facebook Twitter Written by Quassnoi December 31st, 2023 at 11:00 pm Posted in PostgreSQL Tagged with AI, Generative Model, GPT, LLM, PostgreSQL « Happy New Year: solving the Rubik’s Cube in SQL 9 Responses to 'Happy New Year: GPT in 500 lines of SQL' Subscribe to comments with RSS This is simply amazing. I learned so much from reading this, and now I want to go try and implement this on the database platforms I am more experienced with. Thank you so much for this! Ember Crooks 5 Jan 24 at 16:51 Even though I’ve worked with the OpenAI API, GPT, langchain, and vector databases, I still took a lot away from this post. Very well-crafted description of how all the constituent pieces of an LLM come together. Jim 6 Jan 24 at 08:38 This is an excellent and simplistic explanation. GPT mystery solved :) Thank you very much. Rajesh Kumar 7 Jan 24 at 01:33 This has got to be the best read for anyone working with LLMs. James Melvin 14 Jan 24 at 16:10 Hello, Alex Bolenok! Sorry to bother you! I’ve just witnessed your blog from a Chinese Twitter @yihong0618. Your yearly challenge is amazing, great and fantastic, you know, that’s very funny! And I want to subscribe to your blog via email. Also, unfortunately, that doesn’t work! That shows “404. That’s an error. The requested URL was not found on this server. That’s all we know.” while I clicked the “Subscribe by email” button. I’ve just wanted to send you this feedback. Hope you fix that bug! Thanks a lot! Happy New Year! Bye! Madhur Coline 20 Jan 24 at 17:14 Thank you for letting me know. This functionality was provided by a third-party service which apparently had been discontinued. I’ll try to find an alternative for it, please stay tuned. Quassnoi 20 Jan 24 at 17:24 Should be all set now. You should get a notification about a new post in a year or so. Please let me know if it doesn’t work. Quassnoi 23 Jan 24 at 02:37 Thank you for this nice showcase! Very nice explanation! Detlef Detlef Steuer 6 Feb 24 at 14:44 Excellent, thanks Dario 24 Feb 24 at 10:37 Leave a Reply Name (required) Mail (will not be published) (required) Website Subscribe Subscribe in a reader Subscribe by email Email Contacts Ask me a question Drop me a line Should I? Yes. Feel free to ask questions and write me. An interesting question is a pleasure to answer, and I really enjoy receiving feedback Recent articles Happy New Year: GPT in 500 lines of SQL Happy New Year: solving the Rubik’s Cube in SQL A good first word for Wordle Happy New Year: quantum computer emulator in SQL Happy New Year: 3D picture of the coronavirus in SQL Calendar December 2023 M T W T F S S1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 « Dec Archives December 2023 December 2022 January 2022 December 2021 December 2020 December 2019 December 2018 December 2017 December 2016 December 2015 December 2014 July 2014 December 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 March 2013 January 2013 December 2012 December 2011 June 2011 April 2011 March 2011 February 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 December 2009 November 2009 October 2009 September 2009 August 2009 July 2009 June 2009 May 2009 April 2009 March 2009 February 2009 Categories Meta Miscellaneous MySQL Oracle PostgreSQL SQL Server Uncategorized Stack Overflow The Journalist template by Lucian E. Marin — Built for WordPress",
    "commentLink": "https://news.ycombinator.com/item?id=39488668",
    "commentBody": "GPT in 500 Lines of SQL (explainextended.com)466 points by thunderbong 7 hours agohidepastfavorite26 comments sigmoid10 1 hour agoIt's a nice demo. Unfortunately the article mixes up things in the explanation for causal masking, because it seems the author conflates aspects from training and inference. First, causal masking exists to prevent the model from \"peeking\" at future tokens during training, and second (at least for GPT-like architectures) for enforcing the autoregressive aspect during inference. During inference we only use the last token anyways, so it will attend the entire input sequence. So this token is definitely not decided only from the last token's embedding. reply chrsig 6 hours agoprevThis is beautiful. I'd actually been going down this same rabbit hole with sqlite, I hadn't gotten far enough to bring a neural net into it. I'd been inspired by the makemore lecture series[0]. At the 1hr mark or so, he switches from counting to using a nn, which is about as far as I've gotten. Breaking it down into a relational model is actually a really great exercise. [0] https://www.youtube.com/watch?v=PaCmpygFfXo reply jakjak123 2 minutes agoprevThis is a very good article and introduction. reply jer0me 6 hours agoprevRelated: A GPT in 60 Lines of NumPy - https://news.ycombinator.com/item?id=34726115 - February 2023 (146 comments) reply ianand 4 hours agoprevThis is great. In a similar vein, I implemented GPT entirely in spreadsheet functions with accompanying video tutorials https://spreadsheets-are-all-you-need.ai/ reply danielmarkbruce 4 hours agoparentNice job. Spreadsheets are a natural way to explain an LLM. I suspect that you can show training well too by calculating the derivatives for each parameter under each training example and showing it all explicitly mapped to the relevant parameter etc etc reply ianand 2 hours agorootparentThank you. Validating to hear others feel spreadsheets are a natural and accessible way to explain LLMs. Someone asks “what’s do they mean by a parameter in a model” or “what is the attention matrix” and you can just pull it up graphically laid out. Then they can fiddle with it and get a visceral feel for things. It also becomes easier for non coders do things like logit lens which is just a few extra simple spreadsheet functions. I actually plan to do what you describe after I do the embeddings video (but only for a “toy” neural net as a proof-of-concept introduction to gradient descent). reply airstrike 4 hours agoparentprevNot only is that amazing, your video was so well done. Superb crowd work! Color me double impressed. reply ianand 2 hours agorootparentThanks! Each one takes a surprisingly long time to make. Even figuring out how make the explanation accessible and compelling yet still accurate takes awhile and then there’s still the actual video to do. reply hsbauauvhabzb 5 hours agoprevI’ve completely avoided GPT and LLMs. This looks like it would generate some level of fluidity in text output, but not be able to parse and answer a question. Is there any simplistic blog posts / training courses which go through how they work, or expose a toy engine in python or similar that? All the training I’ve seen so far seems oriented at how to use the platforms rather than how they actually work. reply ford 4 hours agoparentJay Alammar has my favorite sequence of tutorials from basic neural network math to GPT2. Particularly [0], [1], and [2] [0] http://jalammar.github.io/illustrated-transformer/ [1] http://jalammar.github.io/illustrated-gpt2/ [2] https://jalammar.github.io/visualizing-neural-machine-transl... reply zaptrem 4 hours agoparentprevStrap in, this is by far the best resource: https://www.youtube.com/watch?v=kCc8FmEb1nY reply ksarw 1 hour agoprevGreat write up, I enjoyed the reading the explanations for each piece and found them to be clear and quite thorough. I did make the mistake though of clicking \"+ expand source\", and after seeing the (remarkable) abomination I can sympathize with ChatGPT's \"SQL is not suitable for implementing large language model...\" :) reply wanderingmind 3 hours agoprevThese marvels need to be preserved. Just posting the archive link here in case the blog is not maintained in future. https://archive.is/VAGzF reply neonate 55 minutes agoparentand https://web.archive.org/web/20240224015308/https://explainex... reply zarkenfrood 3 hours agoparentprevThanks, this is a fantastic article and it would be a shame to be lost. reply rawgabbit 3 hours agoparentprevThis is very cool reply lagniappe 3 hours agoprevThis is a great read, I didn't expect to scroll right back to the top as soon as I finished it the first time. reply seasonalnull 6 hours agoprevThis should be illegal reply behnamoh 6 hours agoprevWhat is this sorcery? reply brainless 5 hours agoprevI think, I think, GPT creating GPT... creating GPT will be a thing soon. GPTception. reply codetiger 5 hours agoparentGPT creating a better algo than itself is what’s even more interesting reply incahoots 5 hours agoparentprevPersonally I like the AI dogman angle. AI trained to beat other AI (resumes tailored to beat ATS algorithms) reply slt2021 5 hours agoprevI can feel the SQL-Force in this young jedi, Midichlorian level is on another level reply swasheck 5 hours agoparentalex is a genius. he’s worth a follow. reply namnhocq8 2 hours agoprev [–] Tại xỉu reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores building a significant language model in SQL, addressing skeptics like ChatGPT and delving into tokenization, vector embeddings, attention mechanisms, and backpropagation for a Generative Pre-trained Transformer (GPT) model.",
      "Using PostgreSQL for tokenization is emphasized for efficient text encoding to enhance neural network performance, including code snippets and examples.",
      "Positive reader feedback is noted, with an invitation to discover more SQL projects on GitHub for further exploration."
    ],
    "commentSummary": [
      "The post explores implementing GPT using 500 lines of SQL code, with users applauding the demonstration and engaging in discussions about training, inference, and integrating neural networks in spreadsheets.",
      "Users admire the article's content and presentation, with additional resources linked for learning about GPT and LLMs, fostering a deeper understanding of the topics discussed."
    ],
    "points": 466,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1708742731
  },
  {
    "id": 39483482,
    "title": "Modular Home Robot Framework: OK-Robot Invites Community Collaboration",
    "originLink": "https://ok-robot.github.io/",
    "originBody": "Hi all, excited to share our latest work, OK-Robot, which is an open and modular framework to perform navigation and manipulation with a robot assistant in practically any homes without having to teach the robot anything new! You can simply unbox the target robot, install OK-Robot, give it a \"scan\" (think a 60 second iPhone video), and start asking the robot to move arbitrary things from A to B. We already tested it out in 10 home environments in New York city, and one environment each in Pittsburgh and Fremont.We based everything off of the current best machine learning models, and so things don&#x27;t quite work perfectly all the time, so we are hoping to build it together with the community! Our code is open: https:&#x2F;&#x2F;github.com&#x2F;ok-robot&#x2F;ok-robot and we have a Discord server for discussion and support: https:&#x2F;&#x2F;discord.gg&#x2F;wzzZJxqKYC If you are curious what works and what doesn&#x27;t work, take a quick look at https:&#x2F;&#x2F;ok-robot.github.io&#x2F;#analysis or read our paper for a detailed analysis: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2401.12202P.S.: while the code is open the project unfortunately isn&#x27;t fully open source since one of our dependencies, AnyGrasp, has a closed-source, educational license. Apologize in advance, but we used it since that was the best grasping model we could have access to!Would love to hear more thoughts and feedback on this project!",
    "commentLink": "https://news.ycombinator.com/item?id=39483482",
    "commentBody": "OK-Robot: open, modular home robot framework for pick-and-drop anywhere (ok-robot.github.io)457 points by MahiShafiullah 16 hours agohidepastfavorite96 comments Hi all, excited to share our latest work, OK-Robot, which is an open and modular framework to perform navigation and manipulation with a robot assistant in practically any homes without having to teach the robot anything new! You can simply unbox the target robot, install OK-Robot, give it a \"scan\" (think a 60 second iPhone video), and start asking the robot to move arbitrary things from A to B. We already tested it out in 10 home environments in New York city, and one environment each in Pittsburgh and Fremont. We based everything off of the current best machine learning models, and so things don't quite work perfectly all the time, so we are hoping to build it together with the community! Our code is open: https://github.com/ok-robot/ok-robot and we have a Discord server for discussion and support: https://discord.gg/wzzZJxqKYC If you are curious what works and what doesn't work, take a quick look at https://ok-robot.github.io/#analysis or read our paper for a detailed analysis: https://arxiv.org/abs/2401.12202 P.S.: while the code is open the project unfortunately isn't fully open source since one of our dependencies, AnyGrasp, has a closed-source, educational license. Apologize in advance, but we used it since that was the best grasping model we could have access to! Would love to hear more thoughts and feedback on this project! rapjr9 7 hours agoRobots like this will have a small market until they can handle obstacles. The cat toy that the cat left in the middle of the floor, the papers that an open window blew off the table, the toys the kids left scattered about, the pencil that rolled off the desk while you were away, the dirty laundry you left laying on the floor, the ridge between carpet and hardwood floors, doors left open or closed, and more. That means there may be several tasks that intervene before a primary task can accomplished (move the toys, pick up the papers, pick up the laundry, open the door). Some obstacles will semi-permanently block a wheeled robot, such as cables, things stacked that you don't want moved, furniture, a sleeping pet, stacked unopened packages from the mail, etc. I believe this means general purpose home robots can not have wheels, they must have legs, perhaps more than two legs for stability. It may sound weird but I think the ideal design might be somewhere between a large friendly spider and a dog. It's odd how robotics has mostly fallen into this idea that the world is two dimensional and flat. They've idealized away the really difficult problems of dealing with mobility in a 3D world. Note that everything this robot does involves only planar horizontal surfaces. Basically it looks like a person had to go through the rooms and clean them up for the robot to function. Roomba's have the same problem. reply fragmede 3 hours agoparentthat's an indictment of the exact platform used not the general concept though. \"all\" that has to happen is for the arm(s) to be able to pick up things on the floor in front of the robot. it doesn't seem insurmountable, the demo connecting all those models together to be able to say \"move the Takis to the nightstand\" and have it be able to execute on that is amazing. it's just a \"small\" matter of robotics to make it so the arm is articulated enough to reach the floor. reply iancmceachern 4 hours agoparentprevThis same problem exists in the hospital setting on anything with wheels. They solve it there with \"cord pushers\". Basically cattle guards for stuff on the floor. Not every problem needs a complex solution. I think the brilliance of this project is in its simplicity, particularly in the robot design. reply rapjr9 4 hours agorootparentTake a look at these pictures: https://duckduckgo.com/?q=cluttered+old+persons+home&atb=v31... I was thinking that people who live in an environment like this are most in need of a robot to help them. reply iancmceachern 4 hours agorootparentAgreed, they could use the help. The issue I see is that is by far the most challenging corner case. It's not the largest market, but it's the most difficult to capture. Good business sense would dictate that you should try to capture the largest market, that is simpler to capture first, then go after these more difficult corner cases. reply floydnoel 4 hours agorootparentprevthese \"invented problems\" that software engineers (such as myself) find in every project are basically why we can't have nice things. why did software in the 90s run faster than the same functionality in the 2020's? it's this right here. reply ehnto 3 hours agorootparentI have had good discussions with a colleague about this, where developers lean toward getting roadblocked by all possible engineering problems, they advocate checking to see if there are solutions to the problem that don't require engineering. In this example, I think they'd suggest communication first then solve the engineering problem later. Eg: just tell people they need to clear the floor or it can get stuck. People will still want it. Perhaps the next step is lower touch engineering, ie: beep when it's stuck. I tend toward engineering stuff, but I have come to realize you can't always afford the engineered solution, and that doesn't have to stop you from delivering stuff. reply fnordpiglet 14 hours agoprevThis is remarkable and could be life changing for the disabled, elderly, gamers, or profoundly lazy and their caretakers. reply marci 13 hours agoparentI forgot where I saw that, but generally, improving things for people with disabilities improves things for everyone, like making sidewalks wheelchair friendly helps parents with a stroller, or people carrying heavy stuff, walking with a cane, young children on bicycles, people who can't see well... reply sandworm101 13 hours agorootparent>> improving things for people with disabilities improves things for everyone Everything has its limits. Many years ago I was involved in building a series of staircases in a rock climbing area inside a park. There were about a hundred steps in a handful of orientations to get from the parking lot over a rocky hill to the small valleys behind. The project was primarily to prevent trail erosion and falls. These steps weren't going to even have handrails. (Think 2x6 framed boxes filled with dirt and bolted to the rock.) Then someone in government said if we wanted to use donated money inside a park we would have to somehow make the project wheelchair accessible. All stop. Project over. No stairs were built. Access trail remained a mess. We were going to replicate these stairs from another climbing area in BC. There is no way to make such a thing wheelchair accessible. https://sonnybou.ca/ssbou2001/skaha01.jpg reply fnordpiglet 12 hours agorootparentIn the US? I assume ADA was the kicker. A lot of folks even in government don’t realize the ADA isn’t unthinking. If the activity or environment doesn’t lend itself to accessibility it’s not required. Cutting a wheel chair ramp into a mountain face is a good example where the ADA wouldn’t apply because it’s impractical given the environment to do so. Even national parks only offer a subset set of activities ADA complaint. reply sandworm101 11 hours agorootparentNo, it wasn't an ADA thing. It was a purely local thing. The local authority had adopted some resolution that no further \"development\" would happen before they added some sort of accessibility. So we couldn't move forwards even using donated money. We could repair things but not make substantive improvements. Rock climbing areas tend to be inaccessible or at least very rough terrain. Ironically, a vertical rock surface can be made accessible. There are actually many disabled climbers out there. But with a mixed dirt/rock/scree slope you basically need to install a mile-long ramp. reply fnordpiglet 11 hours agorootparentI guess pointing at the cliff and saying that’s the accessible route doesn’t fly eh? It’s an inclined slope - just very inclined. And yes there are tons of disabled climbers. reply sandworm101 11 hours agorootparentWe generally understand that disabled people have a right to access the spaces that everyone else does. But climbing/caving is different, different than most any other activity: Access to space is controlled by ability. I have stood on ledges that are impossible to get to without a certain set of skills. If there was a ladder or a staircase, standing on that ledge would mean nothing. We can make a pool or athletic field accessible, but making such a remote ledge half way up a sheer cliff accessible by people without those abilities isn't possible without destroying the nature of that space. So there is always going to be conflict. reply 8A51C 22 minutes agorootparentI like to think that each individual has a limit to their ability to access the physical world around them, which will likely go up and down through their lifetime. Factors which might affect this limit are physical or medical differences between individuals. These factors can be mitigated, such as a prosphetic, or medication to help with altitude sickness. Humans also have ways to change the physical world to mitigate these limits. I'm guessing that there is a road which brings you closer to this climbing area? And that most people use vehicles to get closer and leave those somewhere? That infrastructure is in place, but there was a time when it wasn't. Vehicles, great invention aren't they? You see where I'm going with this? Take away that infrastructure or take away the vehicles and the trail errosion problem is solved, because suddenly there is a massive drop in people accessing the area. I'm not suggesting either way that those steps should be built or not, that is indeed a conflict and no one can say where the line should be drawn, but please don't loose sight of the limits of your own ability, that your limit WILL change and the mitigating factors that are already in place that enable you to exceed your limit. reply exe34 1 hour agorootparentprevI've never understood this argument. Why would somebody else getting to a point through a different easy way cause another to feel like the hard way lost its value? reply samatman 9 hours agorootparentprevMaking an on-the-record decision to not provide accessibility is grounds for a lawsuit on that basis. It doesn't matter if they think they'd win that lawsuit, it's a chilling effect, and a big one. reply developerDan 12 hours agorootparentprevIt’s so frustrating that city leaders can’t even try to use common sense. Where I live a parking requirement blocked a restaurant from being built and our city council publicly acknowledged that there isn’t enough space for parking and a building, but “that’s the law” so they blocked it. Lazy idiots. reply alexthehurst 10 hours agorootparentIsn’t that the point of the parking requirement? If you don’t have room for enough parking to support the Thing, then you don’t have room to add the Thing to the neighborhood. Seems like the intended outcome. reply sandworm101 9 hours agorootparentprevOr maybe the city doesn't want businesses that are going to bring people into an area without giving them space to park the cars they inevitably bring with them. reply jetrink 12 hours agorootparentprevI've heard this called the curb cut effect. (It's a subject right in 99% Invisible's wheelhouse and there is a good episode about it that mostly focuses on the history of literal curb cuts.) 1. https://en.wikipedia.org/wiki/Curb_cut_effect 2. https://99percentinvisible.org/episode/curb-cuts/ reply xanderlewis 10 hours agorootparentprev‘Designing things like door handles for people with only one arm is a good idea not just because it helps those with only one arm, but also because all of us sometimes have only one arm. If we’re carrying a hot cup of tea, for instance…’ …to (very liberally) paraphrase Rory Sutherland. reply salviati 13 hours agorootparentprevI heard this from Anna Martelli Ravenscroft in her presentation \"Diversity as a Dependency\" [0] [0] https://www.youtube.com/watch?v=wOpdDxJzNkw reply hoc 10 hours agorootparentprevWhile I would agree in general, I once slipped on one of those overly steep carved-out kerbs in SF and broke my elbow... I guess if you hit a bad spot you might need a wheelchair afterwards (ok, but it really did hurt!) So you have to do it right to keep the potential harm as low as possible and not forget about security in the face of rewarding improvements. And watch your step, of course. Might also be applicable in the context of self-learning household robots and their potential to burn down that house :) reply Iv 11 hours agorootparentprev... daleks reply MahiShafiullah 11 hours agoparentprevThank you! A large motivation behind this line of home-robot work for me is thinking about the elderly, people with disabilities, or busy parents who simply don't have enough time to do it all. I am personally hopeful that we can teach AI to take the jobs that no one wants rather than the jobs that everyone wants :) reply dlivingston 16 hours agoprevThat's very cool. I have almost no experience with robotics, so excuse the silly questions: - How does it know what objects are? Does it use some sort of realtime object classifier neural net? What limitations are there here? - Does the robot know when it can't perform a request? I.e. if you ask it to move a large box or very heavy kettlebell? - How well does it do if the object is hidden or obscured? Does it go looking for it? What if it must move another object to get access to the requested one? reply fishbotics 15 hours agoparentDisclaimer: I'm not one of the authors, but I work in this area. You basically hit the nail on the head with these questions. This work is super cool, but you named a lot of the limitations with contemporary robot learning systems. 1. It's using an object classifier. It's described here (https://github.com/ok-robot/ok-robot/tree/main/ok-robot-navi...), but if I understanding it correctly basically they are using a ViT model (basically an image classification model) to do some labeling of images and projecting them onto a voxel grid. Then they are using language embeddings from CLIP to pair the language with the voxel grid. The limitations of this are that if they want this to run on the robot, they can't use the super huge versions of these models. While they could use a huge model on the cloud, that would introduce a lot of latency. 2. It almost certainly cannot identify invalid requests. There may be requests that are not covered by their language embeddings, in which case the robot would maybe do nothing. But it doesn't appear that this system has any knowledge of physics, other than the hardware limitations of the physical controller. 3. Hidden? Almost certainly wouldn't work. The voxel labeling relies on a module that labels the voxels and without visual info, it can't label them. Also, as far as I can tell, it doesn't appear to have very complex higher-order reasoning about, say, that a fork is in a drawer, which is in a kitchen, which is often in the back of a house. Partially obscured? That would be subject to the limitations of the visual classifier, so it might work. ViT is very good, but it probably depends on how obscured the object is. reply futhey 13 hours agorootparentThe cool thing is that there are solutions to all of these problems, if the more basic problems can be solved more reliably to prove the underlying technology works. reply ativzzz 14 hours agorootparentprev> While they could use a huge model on the cloud, that would introduce a lot of latency. Will all the recent work to make gen. AI faster (see groq for LLM & fal.ai for stable diffusion), I wonder if the latency will become low enough to make this a non-issue or at least good enough reply devmor 14 hours agorootparentIf AI/ML home systems become significantly common for consumers before the onboard technology is capable, I could see home cacheing appliances for LLMs. Like something that sits next to your router (or more likely, routers that come stock with it). reply ativzzz 14 hours agorootparentDoes a robot that moves things in a home need this? The challenging decisions are (off the top of my head): 1. what am i picking up? - this can be AI in the cloud as it does not need to be real time 2. how do i pick it up? - this can be AI in the cloud as it does not need to be real time - the robot can take its time picking the object up 3. after pickup, where do i put the object? localization while moving probably needs to be done locally but identifying where to put down can be done via cloud, again, no rush 4. how do put the object down? again, the robot can take its time You can see in the video the robot pauses before performing the actions after finding the object in its POV, so real time isn't a hard req for a lot of these reply MahiShafiullah 11 hours agoparentprevUser fishbotics already answers a lot of these questions downstream, but just confirming it here as an author of the project/paper: > - How does it know what objects are? Does it use some sort of realtime object classifier neural net? What limitations are there here? We use Lang-SAM (https://github.com/luca-medeiros/lang-segment-anything) to do most of this, with CLIP embeddings (https://openai.com/research/clip) doing most of the heavy lifting of connecting image and text. One of the nice properties of using CLIP-like models is that you don't have to specify the classes you may want to query later, you can just come up with them during runtime. > - Does the robot know when it can't perform a request? I.e. if you ask it to move a large box or very heavy kettlebell? Nope! As it is right now, the models are very simple and they don't try to do anything fancy. However, that's why we open up our code! So the community can build smarter robots on top of this project that can use even more visual cues about the environment. > - How well does it do if the object is hidden or obscured? Does it go looking for it? What if it must move another object to get access to the requested one? It fails when the object is hidden or obscured in the initial scan, but once again we think it could be a great starting point for further research :) One of the nice things, however, is that we take full 3D information in consideration, and so even if some object is visible from only some of the angles, the robot has a chance to find it. reply alx__ 14 hours agoprevThis is rad. I would totally buy a 25k robot if I could train it to fold and put away my laundry (serious) reply riedel 13 hours agoparentYou might have to buy a second one to this one for folding [1] [1] https://pantor.github.io/speedfolding/ reply MahiShafiullah 11 hours agorootparentIn fact, Hello Robot already shared a teleoperated demo of folding shirts! https://www.youtube.com/watch?v=QtG8nJ78x2M&t=180s But yes, a second arm is needed. reply modeless 11 hours agoparentprevI would buy a $100k robot if it could do the laundry and the dishes and the cooking and clean up after the kids. In a heartbeat. reply ctoth 11 hours agoprevFor solving long term tasks like finding things that aren't there, you can turn the annotated scene into a templated description and feed it to a large-enough model trained on interactive fiction. You are standing in a kitchen. Ahead of you to your right there is a large refrigerator with the handle on the right side. There is a set of cabinets to your left with a plate sitting on the counter above them. > get beer You don't see any beer here.open fridge Opening the refrigerator reveals 4 cans of beer. > get beer taken Obviously we're still several years from this working, but it's very exciting to consider. Interactive Fiction narrative fed by real sensors plus chain-of-thought blocks as internal monologue. reply garblegarble 10 hours agoparentGreat, now we can teach robots to wander around rooms looking for things, saying \"keys, keys, keys... where would I put keys?\" reply sillysaurusx 10 hours agorootparentGet a Tile. I have one attached to my keys, and saying \"hey Alexa, find my keys\" has been really nice. We also have one taped to our remote, which turned out to be excellent since our couch constantly eats it. I just wish it lit up, but sound-only is fine. It would be really cool if the robot could just know where your keys are by attaching some kind of tile-type thing to it. If it already has a scan of your home, theoretically it could show a photo. But I have no idea if it’s possible to pinpoint an object via rfid. reply fnordpiglet 8 hours agoparentprevMulti modal LLM already excel at theses sorts of tasks. Try taking a picture of your kitchen and ask chatgpt where to find the beer. I use this quite a lot actually. Being lazy I take photographs of components and boards and ask it how to wire them to my esp32. It’s able to distinguish the board, chip, etc, as well as the pinouts from a set of photos and tell me what wires to where and anything of note. It’ll often even suggest helpful libraries for the parts. It’s essentially magic. reply bshah_ 15 hours agoprevThe failures analysis is super well done, nice work! Curious what qualifies as hardware failure, e.g. there's 5 trials where the \"Realsense gave bad depth\", and how that's determined. reply MahiShafiullah 15 hours agoparentThanks! We collect all the data and analyze it post-facto to see what may have caused the failure. For example, on the 5 trials you mentioned, the Realsense gave wrong depth on transparent or semi-transparent objects, and so the pointcloud generated from the robot's head camera was simply wrong. reply khnov 16 hours agoprevIt is opensource but still costs nearly 25k dollar. why is it that expensive ? reply TaylorAlexander 15 hours agoparentIt’s a low volume product that has to support the salaries of the engineers who create and maintain the product. reply syedkarim 14 hours agorootparentI’m always surprised by how difficult it is for people to understand this. reply TaylorAlexander 14 hours agorootparentYep. I was recently looking at building an art project that required a gas valve that can freely rotate while under pressure. If you need one gas line, you can get a swivel for a normal shop hose reel for $15. If you need two gas lines on the same axis, the part is similar but way lower volume, so you have to go to a specialty supplier and the price is $350. The business that makes hose reel swivels makes lots of high volume parts, has lots of competition, and needs to charge close to cost to sell them. The business that makes specialty gas swivels for industry that offers multiple gas lines in one swivel, lots of different options, and makes them higher quality needs to charge a lot more to keep their business operational. reply claytonwramsey 14 hours agoparentprevBy robot standards, $25k is not a bad. Most mobile-manipulator robots cost 5 digits or more, mostly due to the small market, high materials and engineering cost, and general headaches of robot building. reply kscottz 15 hours agoparentprevSince when does open source mean cheap? Labor isn't free. Building custom PCBs and hardware in low quantity isn't cheap. Building, calibrating, and testing robots isn't cheap. reply yjftsjthsd-h 13 hours agorootparentNow in all fairness, open source tends to mean cheaper because it does reduce how much has to be invented in-house, and also (sometimes) because it lets you crowd source free labor. In software, that can lead to stuff getting completely built for free (or close) because the base costs are low and mostly consist of labor that some people might be willing to do for free. In hardware, it's likely that open source still reduces the costs, but... you can make a thousand copies of a library for free; making a thousand copies of a part is never going to be free. reply nico 14 hours agoparentprevWhere’s the price? Do you have a link to the product page? Thank you reply MahiShafiullah 13 hours agorootparentHere is the page for Hello Robots: https://hello-robot.com/ reply RIMR 15 hours agoparentprevThe software is open source. The hardware is proprietary and protected by patents. reply dheera 15 hours agorootparentI don't think patents are what is making this specific hardware expensive. Rather it's just a lack of market and supply chain scaling. reply owenpalmer 12 hours agoprevIsn't this the same as dobb-e? https://dobb-e.com/ reply MahiShafiullah 11 hours agoparentNo, although it has some of the same people on the team (aka I'm the first author there, and my advisor is advising both projects :) ) The primary difference is that this is zero-shot (meaning the robot needs 0 (zero!) new data in a new home) but has only two skills (pick and drop); where Dobb-E can have many skills but will need you to give some demonstrations in a new home. reply ohnit 11 hours agoparentprevThe projects look related and have an author in common. Both are mentioned on the website for robot that they used: https://hello-robot.com/stretch-embodied-ai reply btbuildem 12 hours agoprevI've been watching this project for a while now, great progress! I envision an integration with a mobility aid (eg, a wheelchair) for someone with limited control over their limbs. Imagine a \"smart\" exoskeleton that can help with otherwise impossible tasks -- it could be a game-changer for so many people. reply rsync 12 hours agoprevI very much want a stabilized platform vehicle that I can send point-to-point with a payload on it. So, a gyro-stabilized platform like a segway that I can send back and forth from point A to point B on a not-terrible-but-rough (walking path) route. I have tried to stay abreast of the options in the past and have never seen anything that matches this ... does anyone know if there is anything new that matches this use-case ? (the use-case is a tray of drinks and hors d'oeuvres that needs to go from one part of a property to another without spilling ... needs to be minimally all-terrain) reply thebruce87m 12 hours agoparentYou’ve maybe seen these already in restaurants? https://www.pudurobotics.com/product/detail/bellabot Not sure I’ve seen them take drinks though, but definitely food. reply KomoD 10 hours agorootparentSome of these robots are kind of \"jittery\" from what I've seen, I've seen soup delivered without spilling but it might not work well with drinks (not on \"rough\" terrain obviously) reply chubs 13 hours agoprevA friend is working on a slightly related project, I’m curious how they map out the room in voxels, anyone care to suggest how this is done? reply MahiShafiullah 12 hours agoparentThe mapping process can be done with any RGB-D cameras, we use an iPhone pro but any apple devide with AR-Kit should work. Once we have a sequence of RGB-D images with associated camera poses, we can just backproject the pixels (and any associated information, like CLIP embeddings) using the depth into voxels. reply taco_emoji 13 hours agoprevI know nothing about robotics, but can someone ELI5 why the robot makes so many extraneous movements? E.g. the video that shows it moving Takis from the desk to the nightstand, it approaches the desk, and then the arm mechanism moves all the way down (an unnecessary maneuver), then rises again before reaching the level needed to pick up the Takis. reply throwup238 13 hours agoparentA lot of those movements are there to zero out the axes so that each movement starts from a known good position and orients itself against the camera. Usually there's a switch that, for example, senses when the body goes all the way to the bottom, which is the origin for the whole positioning system. Several other movements are for safety since it doesn't have a bunch of cameras and really complex logic for collision avoidance so it resets to a smaller profile between moving around. Since motors are capable of very precise movements and errors accumulate, this is a best practice when starting new movements. Humans instead have a complex hand-eye coordination system that trained all of our lives (and some people are better at it than others). reply leptons 11 hours agorootparent>A lot of those movements are there to zero out the axes so that each movement starts from a known good position and orients itself against the camera. Usually there's a switch that, for example, senses when the body goes all the way to the bottom, which is the origin for the whole positioning system. Ideally the \"zeroing\" should be done once when the robot \"wakes up\" or only once in a while, and there should be digital encoders on all motors, the position should always be known within a tiny margin of error, and not enough to cause a problem for positioning. At least that's how I'd do it, I'm not sure how they built this thing. reply MahiShafiullah 11 hours agorootparentIt's always a trade-off! You could have more accurate sensors and motors that are more expensive, or you can have cheaper motors with no sensors and higher accumulated errors. Since this is more of a research project than a product, we went for a cheap robot with the slower-but-more-accurate approach. reply leptons 6 hours agorootparentEncoders are not that expensive and they don't have to be integrated into the motor. I've done this stuff before, it's not so costly and it really improves the entire system. reply ingend88 8 hours agoprevFor a long time, I wanted to use a robot with a gripper to make tea. Is there any 6DOF robot available within a reasonable price ofOld-school science fiction often proposed that we’d be entering a new age of art and leisure, as robots and AI take over menial tasks. In fact today I think we’re seeing AI and robots — in part — taking jobs from humans, and in order to provide entertainment and economic leverage to richer humans. It was also predicted in the mid 20th century that rising productivity would create a shorter work-week; instead we have figured out how to prevent workers from being compensated for higher productivity. https://www.epi.org/productivity-pay-gap/ reply KerrAvon 13 hours agorootparentprevI don't think you should reevaluate it in that context. Golden age science fiction assumed what we seem to be now calling AGI and still don't know how to create. What we're now calling artificial intelligence (thanks to OpenAI) is effectively an advanced version of autocomplete with infinite computing power behind it. It's incredibly inefficient, and if we ever build AGI we'll look back at AI like people looking back at the earliest manual typewriters without shift keys or lowercase. For golden age sci fi theories of human work vs leisure to actually take hold, we need universal basic income, or some other monetary theory that allows us to value other people for being alive rather than solely for being feudal slaves of deranged billionaires. \"Hotel maid\" as a job really shouldn't exist when robots can do it better and more consistently (which isn't true yet). At that point, not before, should be considered beneath human dignity. But we definitely need an answer for what happens to the newly undignified human. reply dreamworld 13 hours agorootparentDignity should be intrinsic, not a result of labor. Of course, labor is today necessary, (and in a way will always be necessary by someone), so working is indeed dignified to the extent it helps other people. I think chores aren't necessarily the terrible boredom. But having a robot as an option, you can do them as a sort of hobby if and when you want. That seems nice. I think we also will need to develop maturity to deal with our free time, but it's probably not the disaster I've seem many claim (that we lose meaning) -- maybe their way to cope with an unfair world? or my way to cope with laziness. The main thing is how to protect ourselves from rulers when we aren't necessary for labor. It seems like a difficult but solvable problem. Being able to choose how much to work (and play) is the dream! reply yjftsjthsd-h 13 hours agorootparentprevI agree that generalist robots would be better, but building them is really hard (which we know, because we've been trying to build them for decades now). So I think piecemeal robots are the happy-enough medium that we can build to start automating away work today (while we hopefully keep working on the general case). reply bozhark 15 hours agoparentprevMake it micro. I want mini robots cleaning dust and debris, silently and out of my way. I don’t want macro bots getting in my way reply observationist 15 hours agorootparentI agree, micro bots would be best to handle the dirty jobs. reply jamesdwilson 15 hours agorootparentokay, so we all agree a Matryoshka doll like system similar to SD card and microSD card is appropriate then. reply mikeegg1 14 hours agorootparentprevThat's what Zorg though in _Fifth Element_. reply jacobsenscott 9 hours agoprevIt appears slow, but tests show it completes most tasks more quickly, accurately, and with less complaining, than most members of the gen z cohort. reply idiotsecant 9 hours agoparentWeird energy. reply DoktorDelta 9 hours agoparentprevIt must not have anything better to do with its time reply crawsome 10 hours agoprevThis looks really cool, but I immediately think of the possibility of it starting a fire, and thinking everything's fine reply mdfriefeld 16 hours agoprevcongrats on the awesome work! reply MahiShafiullah 11 hours agoparentThank you! reply nxobject 9 hours agoprevTake that, SHRDLU! reply k4rli 12 hours agoprev [–] It's cool but what's the point for a normal person? Useful for warehouses and manufacturing but I don't see myself ever needing such things reply MahiShafiullah 11 hours agoparentA large motivation behind this line of home-robot work for me is thinking about the elderly, people with disabilities, or busy parents who simply don't have enough time to do it all. I am personally hopeful that we can teach AI to take the jobs that no one wants rather than the jobs that everyone wants :) reply polygamous_bat 12 hours agoparentprev [–] Are elderly or disabled people \"normal\" in your book? Do you see yourself or your loved ones growing old someday? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OK-Robot is an open and modular framework designed for robot navigation and manipulation within home settings, allowing users to deploy it on a robot, scan the area, and control object movement effortlessly.",
      "Although not flawless, it leverages contemporary machine learning models and encourages community engagement for enhancements, showcasing its commitment to continuous improvement.",
      "The framework's code is open source, supported by a Discord server for community assistance and dialogue, having undergone testing in various home environments, thus welcoming feedback and contributions."
    ],
    "commentSummary": [
      "OK-Robot is an open, modular home robot framework leveraging machine learning models for navigation and manipulation in homes, with a focus on aiding disabled individuals, the elderly, and others in need.",
      "Discussions center around challenges in robot design for cluttered environments and accessibility for people with disabilities, as well as the potential of robotics in household tasks and the impact of automation on the economy and labor workforce.",
      "Attendees are exploring the cost aspects of building robots, emphasizing precise movements in robotics, and deliberating on the role of robots in different industries and the necessity of universal basic income due to automation."
    ],
    "points": 457,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1708709003
  },
  {
    "id": 39480407,
    "title": "Satoshi and Sirius: Bitcoin Development Discussions 2009-2011",
    "originLink": "https://mmalmi.github.io/satoshi/",
    "originBody": "Satoshi - Sirius emails 2009-2011 This is the correspondence between myself (Martti Malmi, AKA Sirius) and Satoshi Nakamoto, the creator of Bitcoin. I did not feel comfortable sharing private correspondence earlier, but decided to do so for an important trial in the UK in 2024 where I was a witness. Also, a long time has passed now since the emails were sent. The archive is incomplete and contains only emails from my address @cc.hut.fi. My university email addresses changed to @aalto.fi in early 2011, and I don't have backups of those emails. There are some passwords and a street address mentioned in the emails, but those are no longer valid or relevant. Follow me on Nostr or Twitter Font size: + - Email #1 Date: Sat, 02 May 2009 18:06:58 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: Martti MalmiThanks for starting that topic on ASC, your understanding of bitcoin is spot on. Some of their responses were rather Neanderthal, although I guess they're so used to being anti-fiat-money that anything short of gold isn't good enough. They concede that something is flammable, but argue that it'll never burn because there'll never be a spark. Once it's backed with cash, that might change, but I'd probably better refrain from mentioning that in public anymore until we're closer to ready to start. I think we'll get flooded with newbies and we need to get ready first. What we need most right now is website writing. My writing is not that great, I'm a much better coder. Maybe you could create the website on sourceforge, which is currently blank. If you can write a FAQ, I can give you a compilation of my replies to questions in e-mail and forums for facts and details and ideas. Codewise, there's not much that's easy right now. One thing that's needed is an interface for server side scripting languages such as Java, Python, PHP, ASP, etc. Bitcoin would be running on the web server, and server side script could call it to do transactions. It's Windows, so I guess OLE/COM is the interface. One easy thing that really helps is to run a node that can accept incoming connections (forward port 8333 on your firewall) to make sure that new users who try it out have someone to connect to. If they run it and get no connections, they'll probably just give up. Satoshi Martti Malmi wrote: > Message body follows: > > Hello, > > I'm Trickstern from the anti-state.com forum, and I would > like to help with Bitcoin, if there's something I can do. > > I have a good touch on Java and C languages from school > courses (I'm studying CS), but not so very much development > experience yet. I think I could learn the C++ tricks quite > easily on that basis. I could also do testing or > documentation. > > Best regards, > Martti Malmi > > -- > This message has been sent to you, a registered SourceForge.net user, > by another site user, through the SourceForge.net site. This message > has been delivered to your SourceForge.net mail alias. You may reply > to this message using the \"Reply\" feature of your email client, or > using the messaging facility of SourceForge.net at: > https://sourceforge.net/sendmessage.php?touser=2495503 > Email #2 Date: Sun, 03 May 2009 08:08:36 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin All right, I can do the website and the FAQ. I'll start writing the FAQ now with the questions that I can think of. I have a feature suggestion for the program: a UI tool for creating password protected private keys and saving them into a custom location. Backups of the key will be needed to be safe from losing the control of your coins, and for using the coins on more than one computers. Password protection would be needed to make using your money more difficult for someone who happens to find your key file. Maybe a bug/feature tracker could be set up at the Sourceforge project page? I'm running a bitcoin node always when my PC is powered on, which means about 24/7. Bitcoin is a great project, and it's really cool to participate! -Martti Malmi Quoting Satoshi Nakamoto : > Thanks for starting that topic on ASC, your understanding of bitcoin is > spot on. Some of their responses were rather Neanderthal, although I > guess they're so used to being anti-fiat-money that anything short of > gold isn't good enough. They concede that something is flammable, but > argue that it'll never burn because there'll never be a spark. Once > it's backed with cash, that might change, but I'd probably better > refrain from mentioning that in public anymore until we're closer to > ready to start. I think we'll get flooded with newbies and we need to > get ready first. > > What we need most right now is website writing. My writing is not that > great, I'm a much better coder. Maybe you could create the website on > sourceforge, which is currently blank. If you can write a FAQ, I can > give you a compilation of my replies to questions in e-mail and forums > for facts and details and ideas. > > Codewise, there's not much that's easy right now. One thing that's > needed is an interface for server side scripting languages such as > Java, Python, PHP, ASP, etc. Bitcoin would be running on the web > server, and server side script could call it to do transactions. It's > Windows, so I guess OLE/COM is the interface. > > One easy thing that really helps is to run a node that can accept > incoming connections (forward port 8333 on your firewall) to make sure > that new users who try it out have someone to connect to. If they run > it and get no connections, they'll probably just give up. > > Satoshi > > > Martti Malmi wrote: >> Message body follows: >> >> Hello, >> >> I'm Trickstern from the anti-state.com forum, and I would like to >> help with Bitcoin, if there's something I can do. >> >> I have a good touch on Java and C languages from school courses >> (I'm studying CS), but not so very much development experience yet. >> I think I could learn the C++ tricks quite easily on that basis. I >> could also do testing or documentation. >> >> Best regards, >> Martti Malmi >> >> -- >> This message has been sent to you, a registered SourceForge.net user, >> by another site user, through the SourceForge.net site. This message >> has been delivered to your SourceForge.net mail alias. You may reply >> to this message using the \"Reply\" feature of your email client, or >> using the messaging facility of SourceForge.net at: >> https://sourceforge.net/sendmessage.php?touser=2495503 >> Email #3 Date: Sun, 03 May 2009 23:32:26 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi mmalmi@cc.hut.fi wrote: > All right, I can do the website and the FAQ. I'll start writing the FAQ > now with the questions that I can think of. That would be great! I added you (dmp1ce) as a dev to the sourceforge project and gave you access to edit the web space and everything. > I have a feature suggestion for the program: a UI tool for creating > password protected private keys and saving them into a custom location. > Backups of the key will be needed to be safe from losing the control of > your coins, and for using the coins on more than one computers. Password > protection would be needed to make using your money more difficult for > someone who happens to find your key file. Definitely. This will be an absolutely essential feature once things get going, making it so you can lock your wealth up with strong encryption and back it up more securely than any physical safe. So far I've been putting it off in favour of other features because it's not crucial yet until bitcoins start to have value. I plan to work on the escrow feature next, which is needed to make actual trades for physical stuff safer and before backing the currency with fiat money can begin. > I'm running a bitcoin node always when my PC is powered on, which means > about 24/7. Bitcoin is a great project, and it's really cool to > participate! Thanks! Right now there are a lot of people on the network who can't receive incoming connections, so every node that can really helps. Having more helps keep down the \"(not accepted)\" issue for now until I reduce the chances of that happening in v0.1.6. I guess one answer for the FAQ should be how to set up your firewall to forward port 8333 so you can receive incoming connections. The question could be something like \"what if I have 0 connections\" and that could be the answer that it might be because the nodes you can connect with is limited if you don't set that up. Here's a compilation of questions I've answered in forums and e-mail that should help you see what questions are frequently asked and some answers I've used. It's not intended to use all or most of the material here, just pick and choose. This is just a dump of everything I've answered. Some issues that we don't have easy answers for are best not to bring up. Casual users seems content to assume that the system works as stated (which it does), and getting into the design details just opens a can of worms that can't be answered without a deep understanding of the system. The advanced questions I've received have mostly been unique per person and best answered individually. **** QUESTION AND ANSWER DUMP **** Any questions used for the FAQ should probably be rephrased. questions: > The bottom of the UI shows: > > Generating 4 connections 4024 blocks 164 transactions > > I understand \"generating\"; I assume I am connected to 4 other nodes; and > I know I have recorded 164 transactions (including failed generation > attempts). I'm not clear what the \"blocks\" figure describes. It's much > smaller than the total of all the blocks shown against all my transactions. > It's the total number of blocks in the block chain, meaning the network's block chain, which everyone has a copy of. Every Bitcoin node displays the same number and it goes up about every 10 minutes whenever someone generates a block. When you haven't had it running for a while, once you're connected it spins up rapidly as it downloads what was generated while you were gone to catch up. I'm not sure exactly how to describe it (that would fit on the status bar in 1 word, maybe 2 words max), any ideas? The blocks number in the status column next to your transactions is the number of blocks that have come after that transaction. Your transaction is essentially \"in\" that many blocks. Satoshi > My best guess - it > is the length of the global chain, and the rapid advance at the start > is as the software downloads and verifies the preceding blocks in the > chain as being valid. Right. I'm trying to think of more clear wording for that, maybe \"%d network blocks\" or \"%d block chain\". > I'm having an unusual run of (block not-accepted) failures, and thought I'd let you know in > case this was of any significance. What rate of not-accepted did you see? I didn't see anything unusual on my end. If you had more than, say, 4 in a row, that would be abnormal and probably a loss of network communication. If it's scattered and less than 25%, just random bad luck. It's normal and harmless to randomly get some per cent of not-accepted, and of course randomness can sometimes bunch up and look like a pattern. The idea of an option to View/Hide unaccepted blocks is a good one, as well as View/Hide all generated blocks so you can more easily see incoming transactions. Seeing the unaccepted blocks is just annoying and frustrating. Everyone faces the same rate of unaccepted, it's just a part of the process. It would probably be best to default to hide unaccepted blocks, so as not to show giving and taking away something that never was, and not show new generated blocks at all until they have at least one confirmation. It would only mean finding out you have a generated block 15 minutes later than normal, and then you still have 119 blocks to go before it matures anyway. This is on the to-do list for v0.1.6. Satoshi [note: I have some improvements in 0.1.6 to reduce this problem somewhat, and it'll also improve when the network is larger] > For some reason your transfer to me shows up as \"From: unknown\" even > though I added you to my address book. > > I have a \"Generated (not accepted)\" line in my transaction list, it > seems like an attempt to generate a coin went wrong somehow. Not sure > what happened here - presumably my node successfully solved a block > but then I went offline before it was sent to the network? Transactions sent to a bitcoin address will always say \"from: unknown\". The transaction only tells who it's to. Sending by bitcoin address has a number of problems, but it's so nice having the fallback option to be able to send to anyone whether they're online or not. There are a number of ideas to try to improve things later. For now, if things work out like the real world where the vast majority of transactions are with merchants, they'll pretty much always make sure to set up to receive by IP. The P2P file sharing networks seem fairly successful at getting a large percentage of their users to set up their firewalls to forward a port. I badly wanted to find some way to include a comment with indirect transfers, but there just wasn't a way to do it. Bitcoin uses EC-DSA, which was essential for making the block chain compact enough to be practical with today's technology because its signatures are an order of magnitude smaller than RSA. But EC-DSA can't encrypt messages like RSA, it can only be used to verify signatures. The \"Generated (not accepted)\" normally happens if two nodes find a block at close to the same time, one of them will not be accepted. It's normal and unavoidable. I plan in v0.1.6 to hide those, since they're just confusing and annoying and there's no reason for users to have to see them. While the network is still small like it is now, if you can't receive incoming connections you're at more of a disadvantage because you can't receive block announcements as directly. > ...So far it has two \"Generated\" messages, however the > \"Credit\" field for those is 0.00 and the balance hasn't changed. Is > this due to the age/maturity requirement for a coin to be valid? Right, the credit field stays 0.00 until it matures, then it'll be 50.00. BTW, you can doubleclick on a line for details. > ...understand correctly, there is only one (or maybe a few) global > chain[s] into which all transactions are hashed. If there is only one > chain recording \"the story of the economy\" so to speak, how does this > scale? In an imaginary planet-wide deployment there would be millions > of even billions of transactions per hour being hashed into the chain... > ...I found the section on incentives hard to follow. In particular, I'm > not clear on what triggers the transition from minting new coins as a > reason to run a node, to charging transaction fees (isn't the point of > BitCoin largely to zero transaction costs anyway?). Presumably there's > some human in charge of the system... > ...How did you decide on the inflation schedule for v1? Where did 21 > million coins come from? What denominations are these coins? You > mention a way to combine and split value but I'm not clear on how this > works. For instance are bitcoins always denominated by an integer or > can you have fractional bitcoins?... > ...it's rare that I encounter truly > revolutionary ideas. The last time I was this excited about a new > monetary scheme was when I discovered Ripple. If you have any thoughts > on Ripple, I'd also love to hear them. There is only one global chain. The existing Visa credit card network processes about 15 million Internet purchases per day worldwide. Bitcoin can already scale much larger than that with existing hardware for a fraction of the cost. It never really hits a scale ceiling. If you're interested, I can go over the ways it would cope with extreme size. By Moore's Law, we can expect hardware speed to be 10 times faster in 5 years and 100 times faster in 10. Even if Bitcoin grows at crazy adoption rates, I think computer speeds will stay ahead of the number of transactions. I don't anticipate that fees will be needed anytime soon, but if it becomes too burdensome to run a node, it is possible to run a node that only processes transactions that include a transaction fee. The owner of the node would decide the minimum fee they'll accept. Right now, such a node would get nothing, because nobody includes a fee, but if enough nodes did that, then users would get faster acceptance if they include a fee, or slower if they don't. The fee the market would settle on should be minimal. If a node requires a higher fee, that node would be passing up all transactions with lower fees. It could do more volume and probably make more money by processing as many paying transactions as it can. The transition is not controlled by some human in charge of the system though, just individuals reacting on their own to market forces. A key aspect of Bitcoin is that the security of the network grows as the size of the network and the amount of value that needs to be protected grows. The down side is that it's vulnerable at the beginning when it's small, although the value that could be stolen should always be smaller than the amount of effort required to steal it. If someone has other motives to prove a point, they'll just be proving a point I already concede. My choice for the number of coins and distribution schedule was an educated guess. It was a difficult choice, because once the network is going it's locked in and we're stuck with it. I wanted to pick something that would make prices similar to existing currencies, but without knowing the future, that's very hard. I ended up picking something in the middle. If Bitcoin remains a small niche, it'll be worth less per unit than existing currencies. If you imagine it being used for some fraction of world commerce, then there's only going to be 21 million coins for the whole world, so it would be worth much more per unit. Values are 64-bit integers with 8 decimal places, so 1 coin is represented internally as 100000000. There's plenty of granularity if typical prices become small. For example, if 0.001 is worth 1 Euro, then it might be easier to change where the decimal point is displayed, so if you had 1 Bitcoin it's now displayed as 1000, and 0.001 is displayed as 1. Ripple is interesting in that it's the only other system that does something with trust besides concentrate it into a central server. Satoshi > If we assume that 0.1% is a good risk rate, then z=5 thus > any transaction must wait a bit less than an hour before being > solidified in the chain. As micropayments for things like web content > or virtual goods are by definition something that requires low > overhead, waiting an hour seems like quite a significant hurdle. For the actual risk, multiply the 0.1% by the probability that the buyer is an attacker with a huge network of computers. For micropayments, you can safely accept the payment immediately. The size of the payment is too small for the effort to steal it. Micropayments are almost always for intellectual property, where there's no physical loss to the merchant. Anyone trying to steal a micropayment would probably not be a paying customer anyway, and if they want to steal intellectual property they can use the file sharing networks. Currently, businesses accept a certain chargeoff rate. I believe the risk with 1 or even 0 confirming blocks will be much less than the rate of chargebacks on verified credit card transactions. The usual scam against a merchant that doesn't wait for confirming blocks would be to send a payment to a merchant, then quickly try to propagate a double-spend to the network before the merchant's copy. What the merchant can do is broadcast his transaction and then monitor the network for any double-spend copies. The thief would not be able to broadcast during the monitoring period or else the merchant's node would receive a copy. The merchant would only have to monitor for a minute or two until most of the network nodes have his version and it's too late for the thief's version to catch up and reach many nodes. With just a minute or two delay, the chance of getting away without paying could be made much too low to scam. A thief usually needs a high probability of getting an item for free to make it worthwhile. Using a lot of CPU power to do the brute force attack discussed in the paper in addition to the above scam would not increase the thief's chances very much. Anything that grants access to something, like something that takes a while to download, access to a website, web hosting, a subscription or service, can be cancelled a few minutes later if the transaction is rejected. > How is the required difficulty of each block communicated through the > network and agreed upon? It's not communicated. The formula is hardcoded in the program and every node does the same calculation to know what difficulty is required for the next block. If someone diverged from the formula, their block would not be accepted by the majority. > Is the code free/open source or just open source? It's free open source. It's the MIT license, which just requires some disclaimer text be kept with the source code, other than that you can do just about anything you want with it. The source is included in the main download. Satoshi > Is there a way to be told of new versions? Does the app auto update > itself? Some kind of mailing list would be excellent. The list is: bitcoin-list@lists.sourceforge.net Subscribe/unsubscribe page: http://lists.sourceforge.net/mailman/listinfo/bitcoin-list Archives: http://sourceforge.net/mailarchive/forum.php?forum_name=bitcoin-list I'll always announce new versions there. Automatic update, or at least notification of new versions, is definitely on the list. [this inflation discussion was before the transaction fee mechanism and fixed plan of 21 million coins was posted, so it may not be as applicable anymore] > Since they can be created for free (or at the cost > of computer power people have anyway for other reasons), > monetizing them means simply giving away money. You're still thinking as if the difficulty level will be so easy that people will be able to generate all the bitcoins they want. Imagine you have to run your computer 24/7 for a month to generate 1 cent. After a year, you could generate 12 cents. That's not going to make it so people can just generate all the bitcoin they want for spending. The value of bitcoins would be relative to the electricity consumed to produce them. All modern CPUs save power when they're idle. If you run a computational task 24/7, not letting it idle, it uses significantly more power, and you'll notice it generates more heat. The extra wattage consumed goes straight to your power bill, and the value of the bitcoins you produce would be something less than that. > Why would they, when they make money by generating > new ones No, they can't make money that way. It would cost them more in electricity than they'd be selling the bitcoins for. Historically, people have taken up scarce commodities as money, if necessary taking up whatever is at hand, such as shells or stones. Each has a kernel of usefulness that helped bootstrap the process, but the monetary value ends up being much more than the functional value alone. Most of the value comes from the value that others place in it. Gold, for instance, is pretty, non-corrosive and easily malleable, but most of its value is clearly not from that. Brass is shiny and similar in colour. The vast majority of gold sits unused in vaults, owned by governments that could care less about its prettiness. Until now, no scarce commodity that can be traded over a communications channel without a trusted third party has been available. If there is a desire to take up a form of money that can be traded over the Internet without a TTP, then now that is possible. Satoshi > As more capable > computer hardware comes out, the natural supply per user > doubles at every cycle of Moore's law. Actually, that is handled. There's a moving average that compensates for the total effort being expended so that the total production is a constant. As computers get more powerful, the difficulty increases to compensate. > I do not recall any economic history of a commodity subject > to natural inflation ever being used as money There's gold for one. The supply of gold increases by about 2%-3% per year. Any fiat currency typically averages more inflation than that. > Won't there be massive inflation as computers get faster and are able to solve the proof-of-work problem faster? The difficulty is controlled by a moving average that compensates for the total effort being expended to keep the total production constant. As computers get more powerful, the difficulty increases to compensate. > If someone double spends, then the transaction record > can be unblinded revealing the identity of the cheater? Identities are not used, and there's no reliance on recourse. It's all prevention. > ...You're saying > there's no effort to identify and exclude nodes that don't > cooperate? I suspect this will lead to trouble and possible DOS > attacks. There is no reliance on identifying anyone. As you've said, it's futile and can be trivially defeated with sock puppets. The credential that establishes someone as real is the ability to supply CPU power. > But in the absence of identity, there's no downside to them > if spends become invalid, if they've already received the > goods they double-spent for (access to website, download, > whatever). The merchants are left holding the bag with > \"invalid\" coins, unless they wait that magical \"few blocks\" > (and how can they know how many?) before treating the spender > as having paid. > > The consumers won't do this if they spend their coin and it takes > an hour to clear before they can do what they spent their coin on. > The merchants won't do it if there's no way to charge back a > customer when they find the that their coin is invalid because > the customer has doublespent. This is a version 2 problem that I believe can be solved fairly satisfactorily for most applications. The race is to spread your transaction on the network first. Think 6 degrees of freedom -- it spreads exponentially. It would only take something like 2 minutes for a transaction to spread widely enough that a competitor starting late would have little chance of grabbing very many nodes before the first one is overtaking the whole network. During those 2 minutes, the merchant's nodes can be watching for a double-spent transaction. The double-spender would not be able to blast his alternate transaction out to the world without the merchant getting it, so he has to wait before starting. If the real transaction reaches 90% and the double-spent tx reaches 10%, the double-spender only gets a 10% chance of not paying, and 90% chance his money gets spent. For almost any type of goods, that's not going to be worth it for the scammer. Information based goods like access to website or downloads are non-fencible. Nobody is going to be able to make a living off stealing access to websites or downloads. They can go to the file sharing networks to steal that. Most instant-access products aren't going to have a huge incentive to steal. If a merchant actually has a problem with theft, they can make the customer wait 2 minutes, or wait for something in e-mail, which many already do. If they really want to optimize, and it's a large download, they could cancel the download in the middle if the transaction comes back double-spent. If it's website access, typically it wouldn't be a big deal to let the customer have access for 5 minutes and then cut off access if it's rejected. Many such sites have a free trial anyway. Satoshi [in response to a question about scale] 100,000 block generating nodes is a good ballpark large-scale size to think about. Propagating a transaction across the whole network twice would consume a total of US$ 0.02 of bandwidth at today's prices. In practice, many would be burning off excess allocated bandwidth or unlimited plans with one of the cheaper backbones. There could be millions of SPV clients. They only matter in how many transactions they generate. If they pay 1 or 2 cents transaction fees, they pay for themselves. I've coded it so you can pay any optional amount of transaction fees you want. When the incentive subsidy eventually tapers off, it may be necessary to put a market-determined transaction fee on your transactions to make sure nodes process them promptly. To think about what a really huge transaction load would look like, I look at the existing credit card network. I found some more estimates about how many transactions are online purchases. It's about 15 million tx per day for the entire e-commerce load of the Internet worldwide. At 1KB per transaction, that would be 15GB of bandwidth for each block generating node per day, or about two DVD movies worth. Seems do-able even with today's technology. Important to remember, even if Bitcoin caught on at dot-com rates of growth, it would still take years to become any substantial fraction of all transactions. I believe hardware has already recently become strong enough to handle large scale, but if there's any doubt about that, bandwidth speeds, prices, disk space and computing power will be much greater by the time it's needed. Satoshi > One other question I had... What prevents the single node with the most > CPU power from generating and retaining the majority of the BitCoins? > If every node is working independently of all others, if one is > significantly more powerful than the others, isn't it probable that this > node will reach the proper conclusion before other nodes? An > underpowered node may get lucky once in a while, but if they are at a > significant horsepower advantage I would expect the majority of BitCoins > to be generated by the most powerful node. It's not like a race where if one car is twice as fast, it'll always win. It's an SHA-256 that takes less than a microsecond, and each guess has an independent chance of success. Each computer's chance of finding a hash collision is linearly proportional to it's CPU power. A computer that's half as fast would get half as many coins. [question about what to backup] The files are in \"%appdata%\\Bitcoin\", that's the directory to backup. %appdata% is per-user access privilege. Most new programs like Firefox store their settings files there, despite the headwind of Microsoft changing the directory name with every Windows release and being full of spaces and so long it runs off the screen. [question about what to backup] The directory is \"%appdata%\\Bitcoin\" It has spaces in it so you need the quotes cd \"%appdata%\\bitcoin\" On XP it would typically be: C:\\Documents and Settings\\[username]\\Application Data\\Bitcoin Backup that whole directory. All data files are in that directory. There are no temporary files. [question about what to backup] The crucial file to backup is wallet.dat. If bitcoin is running then you have to backup the whole %appdata%\\bitcoin directory including the database subdirectory, but even if it's not running it certainly feels safer to always backup the whole directory. The database unfortunately names its files \"log.0000000001\". To the rest of the world, \"log\" means delete-at-will, but to database people it means delete-and-lose-everything-in-your-other-files. I tried to put them out of harm's way by putting them in the database subdirectory. Later I'll write code to flush the logs after every wallet change so wallet.dat will be standalone safe almost all the time. > > You know, I think there were a lot more people interested in the 90's, > > but after more than a decade of failed Trusted Third Party based systems > > (Digicash, etc), they see it as a lost cause. I hope they can make the > > distinction that this is the first time I know of that we're trying a > > non-trust-based system. > > Yea, that was the primary feature that caught my eye. The real trick > will be to get people to actually value the Bitcoins so that they become > currency. Hal sort of alluded to the possibility that it could be seen as a long-odds investment. I would be surprised if 10 years from now we're not using electronic currency in some way, now that we know a way to do it that won't inevitably get dumbed down when the trusted third party gets cold feet. Once it gets bootstrapped, there are so many applications if you could effortlessly pay a few cents to a website as easily as dropping coins in a vending machine. [this next bit turned out to be very controversial. there is extreme prejudice against spam solutions, especially proof-of-work.] It can already be used for pay-to-send e-mail. The send dialog is resizeable and you can enter as long of a message as you like. It's sent directly when it connects. The recipient doubleclicks on the transaction to see the full message. If someone famous is getting more e-mail than they can read, but would still like to have a way for fans to contact them, they could set up Bitcoin and give out the IP address on their website. \"Send X bitcoins to my priority hotline at this IP and I'll read the message personally.\" Subscription sites that need some extra proof-of-work for their free trial so it doesn't cannibalize subscriptions could charge bitcoins for the trial. [again, I don't know why I'm including this, as it's best to stay away from claims about spam. people automatically react violently against any suggestion of a spam solution.] > Spammer botnets could burn through pay-per-send email filters > trivially (as usual, the costs would fall on people other than the > botnet herders & spammers). Then you could earn a nice profit by setting up pay-per-send e-mail addresses and collecting all the spam money. You could sell it back to spammers who don't have big enough botnets to generate their own, helping bootstrap the currency's value. As more people catch on, they'll set up more and more phony addresses to harvest it. By the time the book \"How I got rich exploiting spammers and you can too\" is coming out, there'll be too many fake addresses and the spammers will have to give up. > > * Spammer botnets could burn through pay-per-send email filters > > trivially > If POW tokens do become useful, and especially if they become money, > machines will no longer sit idle. Users will expect their computers to > be earning them money (assuming the reward is greater than the cost to > operate). A computer whose earnings are being stolen by a botnet will > be more noticeable to its owner than is the case today, hence we might > expect that in that world, users will work harder to maintain their > computers and clean them of botnet infestations. One more factor that would mitigate spam if POW tokens have value: there would be a profit motive for people to set up massive quantities of fake e-mail accounts to harvest POW tokens from spam. They'd essentially be reverse-spamming the spammers with automated mailboxes that collect their POW and don't read the message. The ratio of fake mailboxes to real people could become too high for spam to be cost effective. The process has the potential to establish the POW token's value in the first place, since spammers that don't have a botnet could buy tokens from harvesters. While the buying back would temporarily let more spam through, it would only hasten the self-defeating cycle leading to too many harvesters exploiting the spammers. Interestingly, one of the e-gold systems already has a form of spam called \"dusting\". Spammers send a tiny amount of gold dust in order to put a spam message in the transaction's comment field. If the system let users configure the minimum payment they're willing to receive, or at least the minimum that can have a message with it, users could set how much they're willing to get paid to receive spam. > The last thing we need is to deploy a system designed to burn all > available cycles, consuming electricity and generating carbon dioxide, > all over the Internet, in order to produce small amounts of bitbux to > get emails or spams through. > > Can't we just convert actual money in a bank account into bitbux -- > cheaply and without a carbon tax? Please? Ironic if we end up having to choose between economic liberty and conservation. Unfortunately, proof of work is the only solution I've found to make p2p e-cash work without a trusted third party. Even if I wasn't using it secondarily as a way to allocate the initial distribution of currency, PoW is fundamental to coordinating the network and preventing double-spending. If it did grow to consume significant energy, I think it would still be less wasteful than the labour and resource intensive conventional banking activity it would replace. The cost would be an order of magnitude less than the billions in banking fees that pay for all those brick and mortar buildings, skyscrapers and junk mail credit card offers. Satoshi > BTW I don't remember if we talked about this, but the other day some > people were mentioning secure timestamping. You want to be able to > prove that a certain document existed at a certain time in the past. > Seems to me that bitcoin's stack of blocks would be perfect for this. Indeed, Bitcoin is a distributed secure timestamp server for transactions. A few lines of code could create a transaction with an extra hash in it of anything that needs to be timestamped. I should add a command to timestamp a file that way. From a thread on p2presearch which starts with my rant about trust being the root weakness of all conventional financial systems. http://listcultures.org/pipermail/p2presearch_listcultures.org/2009-February/thread.html I've developed a new open source P2P e-cash system called Bitcoin. It's completely decentralized, with no central server or trusted parties, because everything is based on crypto proof instead of trust. Give it a try, or take a look at the screenshots and design paper: Download Bitcoin v0.1 at http://www.bitcoin.org The root problem with conventional currency is all the trust that's required to make it work. The central bank must be trusted not to debase the currency, but the history of fiat currencies is full of breaches of that trust. Banks must be trusted to hold our money and transfer it electronically, but they lend it out in waves of credit bubbles with barely a fraction in reserve. We have to trust them with our privacy, trust them not to let identity thieves drain our accounts. Their massive overhead costs make micropayments impossible. A generation ago, multi-user time-sharing computer systems had a similar problem. Before strong encryption, users had to rely on password protection to secure their files, placing trust in the system administrator to keep their information private. Privacy could always be overridden by the admin based on his judgment call weighing the principle of privacy against other concerns, or at the behest of his superiors. Then strong encryption became available to the masses, and trust was no longer required. Data could be secured in a way that was physically impossible for others to access, no matter for what reason, no matter how good the excuse, no matter what. It's time we had the same thing for money. With e-currency based on cryptographic proof, without the need to trust a third party middleman, money can be secure and transactions effortless. One of the fundamental building blocks for such a system is digital signatures. A digital coin contains the public key of its owner. To transfer it, the owner signs the coin together with the public key of the next owner. Anyone can check the signatures to verify the chain of ownership. It works well to secure ownership, but leaves one big problem unsolved: double-spending. Any owner could try to re-spend an already spent coin by signing it again to another owner. The usual solution is for a trusted company with a central database to check for double-spending, but that just gets back to the trust model. In its central position, the company can override the users, and the fees needed to support the company make micropayments impractical. Bitcoin's solution is to use a peer-to-peer network to check for double-spending. In a nutshell, the network works like a distributed timestamp server, stamping the first transaction to spend a coin. It takes advantage of the nature of information being easy to spread but hard to stifle. For details on how it works, see the design paper at http://www.bitcoin.org/bitcoin.pdf The result is a distributed system with no single point of failure. Users hold the crypto keys to their own money and transact directly with each other, with the help of the P2P network to check for double-spending. Satoshi Nakamoto http://www.bitcoin.org Martien van Steenbergen Martien at AardRock.COM Thu Feb 12 08:40:53 CET 2009 Very interesting. Is this akin to David Chaum's anonymous digital money? His concept makes sure money is anonymous unless it is compromised, i.e. the same money spent more than once. As soon as it's compromised, the ‘counterfeiter’ is immediately publicly exposed. Also, in bitcoin, is there a limited supply of money (that must be managed)? Or is money created exaclty at the moment of transaction? Succes en plezier, Martien. Martien van Steenbergen wrote: > Very interesting. Is this akin to David Chaum's anonymous digital money? > His concept makes sure money is anonymous unless it is compromised, i.e. > the same money spent more than once. As soon as it's compromised, the > ‘counterfeiter’ is immediately publicly exposed. It's similar in that it uses digital signatures for coins, but different in the approach to privacy and preventing double-spending. The recipient of a Bitcoin payment is able to check whether it is the first spend or not, and second-spends are not accepted. There isn't an off-line mode where double-spenders are caught and shamed after the fact, because that would require participants to have identities. To protect privacy, key pairs are used only once, with a new one for every transaction. The owner of a coin is just whoever has its private key. Of course, the biggest difference is the lack of a central server. That was the Achilles heel of Chaumian systems; when the central company shut down, so did the currency. > Also, in bitcoin, is there a limited supply of money (that must be > managed)? Or is money created exaclty at the moment of transaction? There is a limited supply of money. Circulation will be 21,000,000 coins. Transactions only transfer ownership. Thank you for your questions, Satoshi Martien van Steenbergen wrote: > Reminds me of: > > * AardRock » Wizard Rabbit Treasurer > ; and > * AardRock » PekunioIndeed, it is much like Pekunio in the concept of spraying redundant copies of every transaction to a number of peers on the network, but the implementation is not a reputation network like Wizard Rabbit Treasurer. In fact, Bitcoin does not use reputation at all. It sees the network as just a big crowd and doesn't much care who it talks to or who tells it something, as long as at least one of them relays the information being broadcast around the network. It doesn't care because there's no way to lie to it. Either you tell it crypto proof of something, or it ignores you. > Are you familiar with Ripple? As trust systems go, Ripple is unique in spreading trust around rather than concentrating it. [I've been asked at least 4 other times \"have you heard of Ripple?\"] Michel Bauwens wrote: > how operational is your project? how soon do you think people will be > able to use it in real life? It's fully operational and the network is growing. If you try the software, e-mail me your Bitcoin address and I'll send you a few coins. We just need to spread the word and keep getting more people interested. Here's a link to the original introduction of the paper on the Cryptography mailing list. (Inflation issues were superseded by changes I made later to support transaction fees and the limited circulation plan. This link is a moving target, this archive page is just a certain number of days back and the discussion will keep scrolling off to the next page.) http://www.mail-archive.com/cryptography@metzdowd.com/mail3.html A little follow up when the software was released. http://www.mail-archive.com/cryptography@metzdowd.com/mail2.html My description of how Bitcoin solves the Byzantine Generals' problem: http://www.bitcoin.org/byzantine.html Email #4 Date: Mon, 04 May 2009 03:17:22 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting Satoshi Nakamoto : > That would be great! I added you (dmp1ce) as a dev to the sourceforge > project and gave you access to edit the web space and everything. Oh, that's not me but another guy who wanted to help. I've seen him on the Freedomain Radio forum. My name is Martti Malmi and my Sourceforge account is sirius-m. No problem! Thanks for your answered questions, I'll add them to the faq. Here's what I've done so far: **** Bitcoin FAQ **** General Questions 1 What is bitcoin? Bitcoin is a peer-to-peer network based anonymous digital currency. Peer-to-peer (P2P) means that there is no central authority to issue new money or to keep track of the transactions. Instead, those tasks are managed collectively by the nodes of the network. Anonymity means that the real world identity of the parties of a transaction can be kept hidden from the public or even from the parties themselves. 2 How does bitcoin work? Bitcoin utilizes public/private key cryptography. When a coin is transfered from user A to user B, A adds B's public key to the coin and signs it with his own private key. Now B owns the coin and can transfer it further. To prevent A from transfering the already used coin to another user C, a public list of all the previous transactions is collectively maintained by the network of bitcoin nodes, and before each transaction the coin's unusedness will be checked. For details, see chapter Advanced Questions. 3 What is bitcoin's value backed by? Bitcoin is valued for the things it can be exchanged to, just like all the traditional paper currencies are. When the first user publicly announces that he will make a pizza for anyone who gives him a hundred bitcoins, then he can use bitcoins as payment to some extent - as much as people want pizza and trust his announcement. A pizza-eating hairdresser who trusts him as a friend might then announce that she starts accepting bitcoins as payment for fancy haircuts, and the value of the bitcoin would be higher - now you could buy pizzas and haircuts with them. When bitcoins have become accepted widely enough, he could retire from his pizza business and still be able to use his bitcoin-savings. 4 How are new bitcoins created? New coins are generated by a network node each time it finds the solution to a certain calculational problem. In the first 4 years of the bitcoin network, amount X of coins will be created. The amount is halved each 4 years, so it will be X/2 after 4 years, X/4 after 8 years and so on. Thus the total number of coins will approach 2X. 5 Is bitcoin safe? Yes, as long as you make backups of your coin keys, protect them with strong passwords and keep keyloggers away from your computer. If you lose your key or if some unknown attacker manages to unlock it, there's no way to get your coins back. If you have a large amount of coins, it is recommended to distribute them under several keys. You propably wouldn't either keep all your dollars or euros as paper in a single wallet and leave it unguarded. 6 Why should I use bitcoin? • Transfer money easily through the internet, without having to trust third parties. • Third parties can't prevent or control your transactions. • Be safe from the unfair monetary policies of the monopolistic central banks and the other risks of centralized power over a money supply. The limited inflation of the bitcoin system's money supply is distributed evenly (by CPU power) throughout the network, not monopolized to a banking elite. • Bitcoin's value is likely to increase as the growth of the bitcoin economy exceeds the inflation rate - consider bitcoin an investment and start running a node today! 7 Where can I get bitcoins? Find a bitcoin owner and sell her something - MMORPG equipement, IT support, lawn mowing, dollars or whatever you can trade with her. You can also generate new bitcoins for yourself by running a bitcoin network node. Email #5 Date: Mon, 04 May 2009 16:51:00 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi Oh crap, I got your sourceforge usernames mixed up, sorry about that. I clicked on the wrong e-mail when I was looking for your username. You now have access. Your FAQ looks good so far! You can create whatever you want on bitcoin.sourceforge.net. Something to get new users up to speed on what Bitcoin is and how to use it and why, and clean and professional looking would help make it look well established. The site at bitcoin.org was designed in a more professorial style when I was presenting the design paper on the Cryptography list, but we're moving on from that phase. You should probably change the part about \"distribute them under several keys\". When the paper says that it means for the software to do it, and it does. For privacy reasons, the software already uses a different key for every transaction, so every piece of money in your wallet is already on a different key. The exception is when using a bitcoin address, everything sent to the same bitcoin address is on the same key, which is a privacy risk if you're trying to be anonymous. The EC-DSA key size is very strong (sized for the future), we don't practically have to worry about a key getting broken, but if we did there's the advantage that someone expending the massive computing resources would only break one single transaction's worth of money, not someone's whole account. The details about how to backup your wallet files is in the Q&A dump and also it's explained in readme.txt and definitely belongs in the FAQ. Oh I see, you're trying to address byronm's concern on freedomainradio. I see what you mean about the password feature being useful to address that argument. Banks let anyone who has your name and account number drain your account, and you're not going to get it back from Nigeria. If someone installs a keylogger on your computer, they could just as easily get your bank password and transfer money out of your account. Once we password encrypt the wallet, we'll be able to make a clearer case that we're much more secure than banks. We use strong encryption, while banks still let anyone who has your account info draw money from your account. mmalmi@cc.hut.fi wrote: > Quoting Satoshi Nakamoto : > >> That would be great! I added you (dmp1ce) as a dev to the sourceforge >> project and gave you access to edit the web space and everything. > > Oh, that's not me but another guy who wanted to help. I've seen him on > the Freedomain Radio forum. My name is Martti Malmi and my Sourceforge > account is sirius-m. No problem! > > Thanks for your answered questions, I'll add them to the faq. Here's > what I've done so far: > > **** Bitcoin FAQ **** > > General Questions > > 1 What is bitcoin? > > Bitcoin is a peer-to-peer network based anonymous digital > currency. Peer-to-peer (P2P) means that there is no central > authority to issue new money or to keep track of the > transactions. Instead, those tasks are managed collectively by > the nodes of the network. Anonymity means that the real world > identity of the parties of a transaction can be kept hidden from > the public or even from the parties themselves. > > 2 How does bitcoin work? > > Bitcoin utilizes public/private key cryptography. When a coin is > transfered from user A to user B, A adds B's public key to the > coin and signs it with his own private key. Now B owns the coin > and can transfer it further. To prevent A from transfering the > already used coin to another user C, a public list of all the > previous transactions is collectively maintained by the network > of bitcoin nodes, and before each transaction the coin's > unusedness will be checked. > > For details, see chapter Advanced Questions. > > 3 What is bitcoin's value backed by? > > Bitcoin is valued for the things it can be exchanged to, just > like all the traditional paper currencies are. > > When the first user publicly announces that he will make a pizza > for anyone who gives him a hundred bitcoins, then he can use > bitcoins as payment to some extent - as much as people want pizza > and trust his announcement. A pizza-eating hairdresser who trusts > him as a friend might then announce that she starts accepting > bitcoins as payment for fancy haircuts, and the value of the > bitcoin would be higher - now you could buy pizzas and haircuts > with them. When bitcoins have become accepted widely enough, he > could retire from his pizza business and still be able to use his > bitcoin-savings. > > 4 How are new bitcoins created? > > New coins are generated by a network node each time it finds the > solution to a certain calculational problem. In the first 4 years > of the bitcoin network, amount X of coins will be created. The > amount is halved each 4 years, so it will be X/2 after 4 years, > X/4 after 8 years and so on. Thus the total number of coins will > approach 2X. > > 5 Is bitcoin safe? > > Yes, as long as you make backups of your coin keys, protect them > with strong passwords and keep keyloggers away from your > computer. If you lose your key or if some unknown attacker > manages to unlock it, there's no way to get your coins back. If > you have a large amount of coins, it is recommended to distribute > them under several keys. You propably wouldn't either keep all > your dollars or euros as paper in a single wallet and leave it > unguarded. > > 6 Why should I use bitcoin? > > • Transfer money easily through the internet, without having to > trust third parties. > > • Third parties can't prevent or control your transactions. > > • Be safe from the unfair monetary policies of the monopolistic > central banks and the other risks of centralized power over a > money supply. The limited inflation of the bitcoin system's > money supply is distributed evenly (by CPU power) throughout > the network, not monopolized to a banking elite. > > • Bitcoin's value is likely to increase as the growth of the > bitcoin economy exceeds the inflation rate - consider bitcoin > an investment and start running a node today! > > 7 Where can I get bitcoins? > > Find a bitcoin owner and sell her something - MMORPG equipement, > IT support, lawn mowing, dollars or whatever you can trade with > her. You can also generate new bitcoins for yourself by running a > bitcoin network node. > Email #6 Date: Tue, 05 May 2009 04:00:00 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting Satoshi Nakamoto : > You can create whatever you want on bitcoin.sourceforge.net. Something > to get new users up to speed on what Bitcoin is and how to use it and > why, and clean and professional looking would help make it look well > established. The site at bitcoin.org was designed in a more > professorial style when I was presenting the design paper on the > Cryptography list, but we're moving on from that phase. Ok. Could you set the project MySQL database passwords so that I can set up a CMS on the site? I was thinking about WordPress, as it seems simple and well maintained. I need a password for the read/write account and one database (or the database admin pass to create it myself). This can be done somewhere in the project admin pages, I think. > You should probably change the part about \"distribute them under > several keys\". When the paper says that it means for the software to > do it, and it does. For privacy reasons, the software already uses a > different key for every transaction, so every piece of money in your > wallet is already on a different key. The exception is when using a > bitcoin address, everything sent to the same bitcoin address is on the > same key, which is a privacy risk if you're trying to be anonymous. > The EC-DSA key size is very strong (sized for the future), we don't > practically have to worry about a key getting broken, but if we did > there's the advantage that someone expending the massive computing > resources would only break one single transaction's worth of money, not > someone's whole account. The details about how to backup your wallet > files is in the Q&A dump and also it's explained in readme.txt and > definitely belongs in the FAQ. Ok, that's good to know. > Oh I see, you're trying to address byronm's concern on freedomainradio. > I see what you mean about the password feature being useful to address > that argument. Banks let anyone who has your name and account number > drain your account, and you're not going to get it back from Nigeria. > If someone installs a keylogger on your computer, they could just as > easily get your bank password and transfer money out of your account. > Once we password encrypt the wallet, we'll be able to make a clearer > case that we're much more secure than banks. We use strong encryption, > while banks still let anyone who has your account info draw money from > your account. Well, I guess that's true after all. Email #7 Date: Tue, 05 May 2009 04:07:41 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting mmalmi@cc.hut.fi: >> Oh I see, you're trying to address byronm's concern on freedomainradio. >> I see what you mean about the password feature being useful to address >> that argument. Banks let anyone who has your name and account number >> drain your account, and you're not going to get it back from Nigeria. >> If someone installs a keylogger on your computer, they could just as >> easily get your bank password and transfer money out of your account. >> Once we password encrypt the wallet, we'll be able to make a clearer >> case that we're much more secure than banks. We use strong encryption, >> while banks still let anyone who has your account info draw money from >> your account. > > Well, I guess that's true after all. ...the difference being, though, that not everyone can easily transfer their regular bank money into an uncontrollable location. In bitcoin anyone can do it. Email #8 Date: Tue, 05 May 2009 18:39:44 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi mmalmi@cc.hut.fi wrote: >> You can create whatever you want on bitcoin.sourceforge.net. Something >> to get new users up to speed on what Bitcoin is and how to use it and >> why, and clean and professional looking would help make it look well >> established. The site at bitcoin.org was designed in a more >> professorial style when I was presenting the design paper on the >> Cryptography list, but we're moving on from that phase. > > Ok. Could you set the project MySQL database passwords so that I can set > up a CMS on the site? I was thinking about WordPress, as it seems simple > and well maintained. I need a password for the read/write account and > one database (or the database admin pass to create it myself). This can > be done somewhere in the project admin pages, I think. They have Wordpress built in, you might not need to set up any database stuff manually. I enabled the Wordpress feature and added you as an admin, account sirius-m, e-mail sirius-m@users.sourceforge.net. I'm not sure how it works out the password for access, maybe it's just based on being logged in to sourceforge. https://apps.sourceforge.net/wordpress/bitcoin/wp-admin/ They also have support for MediaWiki if you want it. In case you still need it, here's the accounts and passwords for mysql. # Access this project's databases over the Internet https://apps.sourceforge.net/admin/Bitcoin # Documentation: Guide to MySQL Database Services http://p.sf.net/sourceforge/mysql # Hostname: mysql-b (exactly as shown, with no domain suffix) # Database name prefix: b244765_ -- i.e. \"CREATE DATABASE b244765_myapp\" as your ADMIN user. # RO user: b244765ro (SELECT) # RW user: b244765rw (SELECT, INSERT, DELETE, UPDATE) # ADMIN user: b244765admin (has RW account privileges, and CREATE, DROP, ALTER, INDEX, LOCK TABLES) # web-access URL: https://mysql-b.sourceforge.net/ passwords: b244765ro EaG3nHLL b244765rw sNKgyt4W b244765admin Mz589ZKf > ...the difference being, though, that not everyone can easily > transfer their regular bank money into an uncontrollable location. In > bitcoin anyone can do it. That's true. We shouldn't try to use security against identity theft as a selling point, since it leads into these counter arguments. The current banking model is already tested and the actual loss percentage is known. Even if ours is probably better, it's an unknown, so people can imagine anything. The uncertainty about what the average loss percentage will be is greater than the likely loss percentage itself. Email #9 Date: Wed, 06 May 2009 08:31:41 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting Satoshi Nakamoto : > They have Wordpress built in, you might not need to set up any database > stuff manually. > > They also have support for MediaWiki if you want it. The built-in Wordpress comes with ads, and new plugins and themes need to be installed by the Sourceforge staff, so I installed Wordpress at http://bitcoin.sourceforge.net/. The admin page is at .../wp-admin/, with admin/Wubreches3eS as login. If there's something to add or change, feel free to. The current layout is just a quickly applied free theme, but I'll see if I can do something more visual myself. The MediaWiki might be quite useful for maintaining the FAQ, which could be retrieved from there to the main site somehow. The wiki says I need to be an editor or admin to create a new page, which is funny, because https://apps.sourceforge.net/mediawiki/bitcoin/index.php?title=Special:ListGroupRights says that users can create pages. Email #10 Date: Wed, 06 May 2009 08:41:43 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Lainaus mmalmi@cc.hut.fi: > The current layout is just a quickly applied free theme, but I'll see > if I can do something more visual myself. And of course I'll continue improving the contents also. Email #11 Date: Thu, 07 May 2009 03:35:50 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi It's already an improvement, and like you say, there must be better themes to choose from. It would be good to make the download link go directly to the download area: https://sourceforge.net/project/showfiles.php?group_id=244765 I haven't found any way to gain admin control over the mediawiki feature. It thinks I'm a different S_nakamoto from the one that has admin access: User list * S nakamotoQuoting Satoshi Nakamoto : > >> They have Wordpress built in, you might not need to set up any database >> stuff manually. >> >> They also have support for MediaWiki if you want it. > > The built-in Wordpress comes with ads, and new plugins and themes need > to be installed by the Sourceforge staff, so I installed Wordpress at > http://bitcoin.sourceforge.net/. The admin page is at .../wp-admin/, > with admin/Wubreches3eS as login. If there's something to add or change, > feel free to. > > The current layout is just a quickly applied free theme, but I'll see if > I can do something more visual myself. > > The MediaWiki might be quite useful for maintaining the FAQ, which could > be retrieved from there to the main site somehow. The wiki says I need > to be an editor or admin to create a new page, which is funny, because > https://apps.sourceforge.net/mediawiki/bitcoin/index.php?title=Special:ListGroupRights > says that users can create pages. Email #12 Date: Fri, 22 May 2009 11:05:56 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting Satoshi Nakamoto : > I haven't found any way to gain admin control over the mediawiki > feature. It thinks I'm a different S_nakamoto from the one that has > admin access: > User list > * S nakamoto* S nakamoto (admin, editor) > * Sirius-m > > I tried deleting and re-enabling the feature, no help. Oh well. I think this has something to do with the underscore character in your username; MediaWiki handles them as spaces. I could ask SF Support about this. Email #13 Date: Fri, 22 May 2009 11:08:43 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting mmalmi@cc.hut.fi: > Quoting Satoshi Nakamoto : > >> I haven't found any way to gain admin control over the mediawiki >> feature. It thinks I'm a different S_nakamoto from the one that has >> admin access: >> User list >> * S nakamoto > * S nakamoto (admin, editor) >> * Sirius-m >> >> I tried deleting and re-enabling the feature, no help. Oh well. > > I think this has something to do with the underscore character in your > username; MediaWiki handles them as spaces. I could ask SF Support > about this. Or could you control the MediaWiki with your account nakamoto2? Email #14 Date: Fri, 22 May 2009 11:12:41 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Quoting mmalmi@cc.hut.fi: > Quoting mmalmi@cc.hut.fi: > >> Quoting Satoshi Nakamoto : >> >>> I haven't found any way to gain admin control over the mediawiki >>> feature. It thinks I'm a different S_nakamoto from the one that has >>> admin access: >>> User list >>> * S nakamoto >> * S nakamoto (admin, editor) >>> * Sirius-m >>> >>> I tried deleting and re-enabling the feature, no help. Oh well. >> >> I think this has something to do with the underscore character in your >> username; MediaWiki handles them as spaces. I could ask SF Support >> about this. > > Or could you control the MediaWiki with your account nakamoto2? Oh, sorry for spamming with emails, but the problem is indeed with the underscore character: http://apps.sourceforge.net/trac/sourceforge/ticket/300 Email #15 Date: Sun, 24 May 2009 23:03:38 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi You're right, that was it. I went in and granted us access using the alternate account. I like your idea of at least moving the FAQ into the wiki. I've seen other projects that use the wiki for the FAQ or even the whole site. If you can figure out how to make it so regular users can edit things, then anyone who wants to can help. mmalmi@cc.hut.fi wrote: > Quoting mmalmi@cc.hut.fi: > >> Quoting mmalmi@cc.hut.fi: >> >>> Quoting Satoshi Nakamoto : >>> >>>> I haven't found any way to gain admin control over the mediawiki >>>> feature. It thinks I'm a different S_nakamoto from the one that has >>>> admin access: >>>> User list >>>> * S nakamoto >>> * S nakamoto (admin, editor) >>>> * Sirius-m >>>> >>>> I tried deleting and re-enabling the feature, no help. Oh well. >>> >>> I think this has something to do with the underscore character in your >>> username; MediaWiki handles them as spaces. I could ask SF Support >>> about this. >> >> Or could you control the MediaWiki with your account nakamoto2? > > Oh, sorry for spamming with emails, but the problem is indeed with the > underscore character: > http://apps.sourceforge.net/trac/sourceforge/ticket/300 > Email #16 Date: Sun, 07 Jun 2009 08:34:29 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin > I like your idea of at least moving the FAQ into the wiki. I've seen > other projects that use the wiki for the FAQ or even the whole site. > If you can figure out how to make it so regular users can edit things, > then anyone who wants to can help. The user group privileges seemingly can't be changed without changing the wiki source files, which can only be done by the SF admins as a hosted app is concerned. The hosted apps are also otherwise quite inflexible: you can only login with a SF account, you can't change themes by yourself and of course there's the ad-bar above the pages. I think that replacing the current Wordpress installation at bitcoin.sourceforge.net with TikiWiki could be a great solution. TikiWiki supports CMS features, forums, wikis, bug trackers, and many other features also if needed. Perhaps the best looking example of a TikiWiki installation is at http://support.mozilla.com/. I'll take backup of the current site and see if TikiWiki can be installed at SF. If it doesn't work, I'll see how wiki/forum features can be integrated with Wordpress or think of something else. Email #17 Date: Tue, 09 Jun 2009 09:55:26 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin I couldn't get TikiWiki to work, so I installed Bitweaver, which is a lightweight TikiWiki derivative. Its functionality looks good for the purpose and it's easy to customize. The admin account password is Wubreches3eS again. New users can register to the site and write to the wiki and the forums. Next I'm going to look into how custom menus and custom layouts are made. Email #18 Date: Thu, 11 Jun 2009 07:34:20 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Now that the project web is up and running, do you think that setting up a custom VHOST for the bitcoin.org domain would be a good idea? Instructions: http://apps.sourceforge.net/trac/sourceforge/wiki/Custom%20VHOSTs Also, could you please send me a link to a SF Logo for statistics, as instructed at: http://apps.sourceforge.net/trac/sourceforge/wiki/Use%20of%20sflogo%20for%20statistics%20tracking Email #19 Date: Thu, 11 Jun 2009 22:24:25 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi The site layout is looking nicer. More impressive looking. There are a lot of things you can say on the sourceforge site that I can't say on my own site. Even so, I'm uncomfortable with explicitly saying \"consider it an investment\". That's a dangerous thing to say and you should delete that bullet point. It's OK if they come to that conclusion on their own, but we can't pitch it as that. A few details: the FAQ says \"see section 2.3\", but the sections aren't numbered. Also, could you delete the last sentence on the FAQ \"They are planned to be hidden in v0.1.6, since they're just confusing and annoying and there's no reason for users to have to see them.\" -- that's not really something I meant to say publicly. The links to sites to help set up 8333 port forwarding is great. favicon is a nice touch. Someone came up with the word \"cryptocurrency\"... maybe it's a word we should use when describing Bitcoin, do you like it? Sourceforge is so slow right now I can't even get the login page to load. Maybe due to the site reorg they just did. I'll keep trying and try to get you that logo stats thing. mmalmi@cc.hut.fi wrote: > Now that the project web is up and running, do you think that setting up > a custom VHOST for the bitcoin.org domain would be a good idea? > Instructions: > http://apps.sourceforge.net/trac/sourceforge/wiki/Custom%20VHOSTs > > Also, could you please send me a link to a SF Logo for statistics, as > instructed at: > http://apps.sourceforge.net/trac/sourceforge/wiki/Use%20of%20sflogo%20for%20statistics%20tracking > > Email #20 Date: Fri, 12 Jun 2009 12:22:34 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin > There are a lot of things you can say on the sourceforge site that I > can't say on my own site. Even so, I'm uncomfortable with explicitly > saying \"consider it an investment\". That's a dangerous thing to say > and you should delete that bullet point. It's OK if they come to that > conclusion on their own, but we can't pitch it as that. > > A few details: the FAQ says \"see section 2.3\", but the sections aren't > numbered. Also, could you delete the last sentence on the FAQ \"They > are planned to be hidden in v0.1.6, since they're just confusing and > annoying and there's no reason for users to have to see them.\" -- > that's not really something I meant to say publicly. I made the changes. You could also register to the site or use the admin account to make necessary changes yourself, since the pages are located in the wiki. > Someone came up with the word \"cryptocurrency\"... maybe it's a word we > should use when describing Bitcoin, do you like it? It sounds good. \"The P2P Cryptocurrency\" could be considered as the slogan, even if it's a bit more difficult to say than \"The Digital P2P Cash\". It still describes the system better and sounds more interesting, I think. I could notify the mailing list about the new site and invite them to write on the forums and to the wiki. Email #21 Date: Sun, 14 Jun 2009 21:30:58 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi mmalmi@cc.hut.fi wrote: > I made the changes. You could also register to the site or use the admin > account to make necessary changes yourself, since the pages are located > in the wiki. Thanks, I've been really busy lately. I registered username \"satoshi\". Since there's no SSL login, I want to mainly use that account with sub-admin powers and use the admin account as little as possible. I created a \"Moderators\" group to give my satoshi account as much editing control as possible without the ability to overthrow everything. There's something weird with the download bar on the right covering things up, like on the new account registration it covers up the entry fields unless you make the browser really wide, and the homepage it covers up the screenshots. (with Firefox) Email #22 Date: Mon, 22 Jun 2009 19:27:11 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin > There's something weird with the download bar on the right covering > things up, like on the new account registration it covers up the entry > fields unless you make the browser really wide, and the homepage it > covers up the screenshots. (with Firefox) Problem fixed. I switched to a fixed width layout, which is also easier to read as the lines are shorter. Email #23 Date: Tue, 21 Jul 2009 03:43:34 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Hi, I made a post on the Bitcoin developer's forum at SF about a month ago and sent you, David and Hal a notification about it to your users.sourceforge.net emails. A few days ago I wondered why no one had replied, and tried if the SF mail aliases even work - and they didn't, at least in the case of my account. So could you please forward this message to the others? Best regards, sirius-m Email #24 Date: Tue, 21 Jul 2009 04:14:43 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi I know this sounds really retarded, but I still haven't been able to get the sourceforge login page to load, so I haven't been able to read it either. https://sourceforge.net/account/login.php Hal isn't currently actively involved. He helped me a lot defending the design on the Cryptography list, and with initial testing when it was first released. He carried this torch years ago with his Reusable Proof Of Work (RPOW). I'm not going to be much help right now either, pretty busy with work, and need a break from it after 18 months development. It would help if there was something for people to use it for. We need an application to bootstrap it. Any ideas? There are donors I can tap if we come up with something that needs funding, but they want to be anonymous, which makes it hard to actually do anything with it. mmalmi@cc.hut.fi wrote: > Hi, > > I made a post on the Bitcoin developer's forum at SF about a month ago > and sent you, David and Hal a notification about it to your > users.sourceforge.net emails. A few days ago I wondered why no one had > replied, and tried if the SF mail aliases even work - and they didn't, > at least in the case of my account. So could you please forward this > message to the others? > > Best regards, > sirius-m > Email #25 Date: Wed, 22 Jul 2009 13:10:02 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin > I know this sounds really retarded, but I still haven't been able to > get the sourceforge login page to load, so I haven't been able to read > it either. https://sourceforge.net/account/login.php That's strange, I haven't had any problems with that. Clearly the banking establishment got scared and banned your account (and founded www.bitcoin.com in attempt to fetch the trademark), eh. You could ask if the SF staff at sfnet_ops@corp.sourceforge.com can help you. > I'm not going to be much help right now either, pretty busy with work, > and need a break from it after 18 months development. Oh, that sounds tough. Take your time. > It would help if there was something for people to use it for. We need > an application to bootstrap it. Any ideas? I've been thinking about a currency exchange service that sells and buys bitcoins for euros and other currencies. Direct exchangeability to an existing currency would give bitcoin the best possible initial liquidity and thus the best adoptability for new users. Everyone accepts payment in coins that are easily exchangeable for common money, but not everyone accepts payment in coins that are only guaranteed to buy a specific kind of a product. The instructional formula for stable pricing in euros would be something like: (The amount of euros that you're ready to trade for bc + the euro-value of goods that other people are selling for bc) / (Total number of bc in circulation - own bc assets). So if there's a total of 1M bitcoins of which you own 100K, you have 1000 eur and no one else trades with bitcoin yet, you can safely offer the exchange rate of 1 eur / 900 bc, without having to devaluate even if everyone sold their coins to you. This could be guaranteed as the minimal exchange rate, but the rate could be also higher when demand is high. Initially, when others aren't yet offering anything for bitcoins, you can increase your bitcoin assets cheaply - for the minimum price that people bother to do the transaction for. If you had all the existing coins for yourself, you could set the price to whatever you want, because you wouldn't face the risk of having to buy even a single coin with that price (not counting the new money created by others). So it's best to get as much coins as possible before backing bitcoin with all your available euros. Profit can be gained, as usually in trading, by having a margin between the buying and selling prices. Making Bitcoin as usable as possible will make the business run better, as people do not only want to sell all their coins to you, but also want to buy them and use them as a medium of exchange. At its simplest this exchange service could be a website where traders, who can be individual persons, can post their rates, and random users can leave trade requests. Some kind of an average rate estimate could be shown on the site. Small-scale trading by individuals would be outside legal hassle in most countries, and putting all the eggs in the same basket would be avoided. Another idea, which could be additional to the previous one, would be an automated exchange service. The service would automatically calculate the exchange rate and perform the transactions. This would be nicer to the user: completion of the transaction request would be certain and instantaneous. Making this service might actually be quite easy if there was a command line interface to Bitcoin: just take any web application framework and use PayPal back-end integration to automatically send euros when Bitcoins are received, and vice versa. This kind of business would also work great on larger scale if you set up a company and take care of all the bureaucracy needed to practice currency exchange. (I actually have a registered company that I've used for billing of some IT work, I could use that as a base.) This exchange business thing is something that I'd be interested in doing, and I also have the sufficient technical skills to do it. Although, before this can be done, there should be a non-alpha version of Bitcoin (and the command line interface / API). > There are donors I can tap if we come up with something that needs > funding, but they want to be anonymous, which makes it hard to actually > do anything with it. If this gets started, donors / high-risk investors would be very welcome to bring capital for the currency's backup. So, what do you think about the idea? Note that this is not something that I'm asking you to do (unless you want to) if you're busy with other things. I can do it myself, if I get positive reviews about the plan. Email #26 Date: Wed, 29 Jul 2009 18:14:51 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin I've had quite a few errors coming up when trying to build the third-party libraries and adding them to the Bitcoin build. Do you happen to have a ready-to-build package that you could upload to the CVS or somewhere else? I use mingw + msys, but I guess I could try Visual C++ also, if it's easier that way. Email #27 Date: Mon, 24 Aug 2009 06:38:13 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin I got it compile with MinGW + MSYS when I used wxPack instead of just wxWidgets. Maybe wxAdditions was required. The bitcoin.exe filesize was 52MB though, I should see how that can be fixed. Next I'm going to implement the \"minimize to tray\" feature and the option to autostart Bitcoin with Windows, so the number of nodes online would stay higher. After that I could see if I can do a Linux port or the command line interface needed for web app frameworks. Drop by at #bitcoin-dev on FreeNode some time if you use IRC. And again, thanks for the great work you've done with Bitcoin. Quote mmalmi@cc.hut.fi: > I've had quite a few errors coming up when trying to build the > third-party libraries and adding them to the Bitcoin build. Do you > happen to have a ready-to-build package that you could upload to the > CVS or somewhere else? I use mingw + msys, but I guess I could try > Visual C++ also, if it's easier that way. Email #28 Date: Mon, 24 Aug 2009 23:00:35 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi That's a good point that since you know how many coins exist and how fast new ones are created, you could set a support price based on the amount of legacy currency you have and be sure you'll have enough to meet all demands. I had imagined an auction, but it would be far simpler and more confidence inspiring to back it at a specific exchange rate. Offering currency to back bitcoins would attract freebie seekers, with the benefit of attracting a lot of publicity. At first it would mostly be seen as a way to get free money for your computer's idle time. Maybe pitched like help support the future of e-commerce and get a little money for your computer's spare cycles. As people cash in and actually get paid, word would spread exponentially. It might help to keep the minimum transaction size above an amount which a typical user would be able to accumulate with one computer, so that users have to trade with each other for someone to collect enough to cash in. Aggregators would set up shop to buy bitcoins in smaller increments, which would add confidence in users ability to sell bitcoins if there are more available buyers than just you. People would obviously be sceptical at first that the backing will hold up against an onslaught of people trying to get the free money, but as the competition raises the proof-of-work difficulty, it should become clear that bitcoins stay scarce. People will see that they can't just get all the bitcoins they want. It would establish a minimum value under bitcoins enabling them to be used for other purposes if, hopefully, other purposes are waiting for something to use. >> It would help if there was something for people to use it for. We need >> an application to bootstrap it. Any ideas? > > I've been thinking about a currency exchange service that sells and > buys bitcoins for euros and other currencies. Direct exchangeability > to an existing currency would give bitcoin the best possible initial > liquidity and thus the best adoptability for new users. Everyone > accepts payment in coins that are easily exchangeable for common > money, but not everyone accepts payment in coins that are only > guaranteed to buy a specific kind of a product. That would be more powerful if there was also some narrow product market to use it for. Some virtual currencies like Tencent's Q coin have made headway with virtual goods. It would be sweet if there was some way to horn in on a market like that as the official virtual currency gets clamped down on with limitations. Not saying it can't work without something, but a ready specific transaction need that it fills would increase the certainty of success. > At its simplest this exchange service could be a website where > traders, who can be individual persons, can post their rates, and > random users can leave trade requests. Some kind of an average rate > estimate could be shown on the site. Small-scale trading by > individuals would be outside legal hassle in most countries, and > putting all the eggs in the same basket would be avoided. Basically like an eBay site with user reviews to try to establish which sellers can be trusted. The escrow feature will help but not solve everything. It would be far more work to set up such a site than just to set up a single exchange site of your own, and there won't be enough users to make it go until later. I'm thinking it wouldn't make sense to make an eBay type site until later. > Another idea, which could be additional to the previous one, would be > an automated exchange service. The service would automatically > calculate the exchange rate and perform the transactions. This would > be nicer to the user: completion of the transaction request would be > certain and instantaneous. Making this service might actually be quite > easy if there was a command line interface to Bitcoin: just take any > web application framework and use PayPal back-end integration to > automatically send euros when Bitcoins are received, and vice versa. > This kind of business would also work great on larger scale if you set > up a company and take care of all the bureaucracy needed to practice > currency exchange. (I actually have a registered company that I've > used for billing of some IT work, I could use that as a base.) Even if you had automation, you'd probably want to review orders manually before processing them anyway. It wouldn't be hard to process orders by hand, especially at first. You could always set a minimum order size to keep orders more infrequent. > This exchange business thing is something that I'd be interested in > doing, and I also have the sufficient technical skills to do it. > Although, before this can be done, there should be a non-alpha version > of Bitcoin (and the command line interface / API). > > If this gets started, donors / high-risk investors would be very > welcome to bring capital for the currency's backup. > > So, what do you think about the idea? Note that this is not something > that I'm asking you to do (unless you want to) if you're busy with > other things. I can do it myself, if I get positive reviews about the > plan. That's great, I could probably get a donor to send currency to you which you convert to euros and pay out through methods that are convenient for users. I don't want to do an exchange business myself, but it can be done independently of me. Like you say, there is more software development to be done first, and also I'd like to keep trying for a while to think of a bootstrap application to use bitcoins for. I've had some ideas that could only be done before an exchange exists. BTW, I tried to buy bitcoin.com before I started but there was no chance, it's owned by a professional domain speculator. It's normal for open source projects to have .org so it's not so bad. Email #29 Date: Mon, 24 Aug 2009 23:04:25 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi Glad that worked, it's a pain that the dependencies are so big and hard to build. Some of them give little attention to the Windows build. Next time I update to the latest versions, maybe I'll lay everything out in one directory tree and bundle the whole thing up into a giant archive. I'm not sure they had wxPack before. I'm glad they got that so everyone doesn't have to build wxWidgets themselves. OpenSSL is the harder one to build. I reduced the EXE size by running strip.exe on it to take out the debug symbols. That's with mingw. That's the better compiler, I only used VC for debugging. mmalmi@cc.hut.fi wrote: > I got it compile with MinGW + MSYS when I used wxPack instead of just > wxWidgets. Maybe wxAdditions was required. The bitcoin.exe filesize was > 52MB though, I should see how that can be fixed. > > Next I'm going to implement the \"minimize to tray\" feature and the > option to autostart Bitcoin with Windows, so the number of nodes online > would stay higher. After that I could see if I can do a Linux port or > the command line interface needed for web app frameworks. > > Drop by at #bitcoin-dev on FreeNode some time if you use IRC. > > And again, thanks for the great work you've done with Bitcoin. > > Quote mmalmi@cc.hut.fi: > >> I've had quite a few errors coming up when trying to build the >> third-party libraries and adding them to the Bitcoin build. Do you >> happen to have a ready-to-build package that you could upload to the >> CVS or somewhere else? I use mingw + msys, but I guess I could try >> Visual C++ also, if it's easier that way. > > > Email #30 Date: Fri, 28 Aug 2009 07:10:06 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin > It might help to keep the minimum transaction size above an amount > which a typical user would be able to accumulate with one computer, so > that users have to trade with each other for someone to collect enough > to cash in. Aggregators would set up shop to buy bitcoins in smaller > increments, which would add confidence in users ability to sell > bitcoins if there are more available buyers than just you. That might be a good idea. > That would be more powerful if there was also some narrow product > market to use it for. Some virtual currencies like Tencent's Q coin > have made headway with virtual goods. It would be sweet if there was > some way to horn in on a market like that as the official virtual > currency gets clamped down on with limitations. Not saying it can't > work without something, but a ready specific transaction need that it > fills would increase the certainty of success. Bitcoin could be promoted to the users of virtual communities like World of Warcraft and Second Life, which both have millions of users. It would be great if not only peer-to-peer item traders, but also providers of some existing virtual services that already have a lot of customers, were to adopt the currency early on. A programming question: What do you think about using the Boost's program_options to write settings like the transaction fee into a file bitcoin.config? Or is it better to save them in the database as it is now? Having a config file would make it easier to change the settings when running the program on a remote server with a console access only. Email #31 Date: Sat, 29 Aug 2009 18:31:05 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi > Next I'm going to implement the \"minimize to tray\" feature and the > option to autostart Bitcoin with Windows, so the number of nodes online > would stay higher. Now that I think about it, you've put your finger on the most important missing feature right now that would make an order of magnitude difference in the number of nodes. Without auto-run, we'll almost never retain nodes after an initial tryout interest. Auto-running as a minimized tray icon by default was the key to success for the early file sharing networks. It wouldn't have been appropriate for v0.1.0 when stability wasn't a given yet, but now it's good and stable. This is a must-have feature for the next release so any users that come back to try the new version we hopefully retain this time. I think the most user friendly way of doing auto-run is putting an icon in the Startup folder. I see OpenOffice.org and a number of other things on my computer do it that way. The other way, creating a runas registry entry, is not easily visible or editable by users, I've never liked that much. I guess what we want is an auto-run option that's on by default, if the option is changed then it creates or deletes the startup icon. While it's tempting to do a Linux port, once we do it we have that extra work with every release from then on. I'd rather put it off a while longer. Auto-run might give us 300% more nodes while Linux might give us 3% more. Linux would help server farms, but actually we'd like to favour individual users. Someone reported that it works fine in WinE. Email #32 Date: Wed, 16 Sep 2009 15:54:42 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin Just for information: I committed my working copy to the svn/branches. There's the minimize to tray feature and some other changes. It's nicer to run in the background now, but it's still incomplete and I'm working on it. The bugs are listed in bugs.txt. Did you get your Sourceforge account work yet? Email #33 Date: Wed, 30 Sep 2009 19:12:29 +0100 From: Satoshi NakamotoSubject: Re: Bitcoin To: mmalmi@cc.hut.fi That's great, that's a good step forward. Yes, I worked out the sourceforge login problem, it was some tricky thing on the login page that exposed a quirky bug in a browser add-in. mmalmi@cc.hut.fi wrote: > Just for information: I committed my working copy to the svn/branches. > There's the minimize to tray feature and some other changes. It's nicer > to run in the background now, but it's still incomplete and I'm working > on it. The bugs are listed in bugs.txt. > > Did you get your Sourceforge account work yet? > Email #34 Date: Thu, 08 Oct 2009 20:44:49 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Bitcoin I made a Windows installer for the latest version of Bitcoin, which includes the autostart and minimize to tray features. The installer makes a start menu shortcut and a startup registry entry. I first implemented the autostart with a shortcut to the startup folder, but I found out that it doesn't always work by default and ended up doing it with a registry entry. The registry entry is removed by the uninstaller and can be also disabled from the options menu, so I don't think it's such a big menace to the user after all. I made the installer with NSIS, and the nsi script can be found in the SVN. Could you add the installer to the SF download page? Here's the file: http://bitcoin.sourceforge.net/uploads/Bitcoin_setup.exe There are some new users registered to the bitcoin.sf.net site. One of them just announced that he's trading Bitcoins for dollars. Here's his site: http://newlibertystandard.wetpaint.com/. Making an exchange service first seemed a bit premature for the time being, but on the other hand it's good that people show interest towards the project, and this might attract even more interested people (and hopefully more developers). I just sent the guy an email. Email #35 Date: Fri, 16 Oct 2009 19:41:40 +0100 From: Satoshi NakamotoSubject: Re: Setup, Autorun, v0.1.6 To: mmalmi@cc.hut.fi Thanks for that. I'm still merging in some changes I had that need to go in before any next release. Some things based on questions and feedback I've received that'll reduce confusion. I'll probably enable multi-proc generating support, and hopefully make it safe to just backup wallet.dat to backup your money. It's good to be coding again! I'm going to hide the transaction fee setting, which is completely not needed and only serves to confuse people. It was only there for testing and demonstration of a technical detail that can only be needed in the far away future, if ever, but was necessary to implement at the beginning to make it possible later. What was the problem with the shortcut in the startup folder? If you could send me the code, I'd like to take another look and see if I can see what the problem was. The first strcat in the registry code should be strcpy, otherwise it would fail intermittently. If the same code was in the shortcut one, maybe that was the problem. It's encouraging to see more people taking an interest such as that NewLibertyStandard site. I like his approach to estimating the value based on electricity. It's educational to see what explanations people adopt. They may help discover a simplified way of understanding it that makes it more accessible to the masses. Many complex concepts in the world have a simplistic explanation that satisfies 80% of people, and a complete explanation that satisfies the other 20% who see the flaws in the simplistic explanation. mmalmi@cc.hut.fi wrote: > I made a Windows installer for the latest version of Bitcoin, which > includes the autostart and minimize to tray features. The installer > makes a start menu shortcut and a startup registry entry. I first > implemented the autostart with a shortcut to the startup folder, but I > found out that it doesn't always work by default and ended up doing it > with a registry entry. The registry entry is removed by the uninstaller > and can be also disabled from the options menu, so I don't think it's > such a big menace to the user after all. > > I made the installer with NSIS, and the nsi script can be found in the SVN. > > Could you add the installer to the SF download page? Here's the file: > http://bitcoin.sourceforge.net/uploads/Bitcoin_setup.exe > > There are some new users registered to the bitcoin.sf.net site. One of > them just announced that he's trading Bitcoins for dollars. Here's his > site: http://newlibertystandard.wetpaint.com/. Making an exchange > service first seemed a bit premature for the time being, but on the > other hand it's good that people show interest towards the project, and > this might attract even more interested people (and hopefully more > developers). I just sent the guy an email. > Email #36 Date: Sun, 18 Oct 2009 18:59:42 +0100 From: Satoshi NakamotoSubject: Re: Setup, Autorun, v0.1.6 To: Martti MalmiI got it, I see you checked in the startup folder code before changing it to registry. I don't see any visible problems in the code. I guess it depends what exactly the problem was with it not always working by default. Was there a Vista/UAC security problem? Satoshi Nakamoto wrote: > What was the problem with the shortcut in the startup folder? If you > could send me the code, I'd like to take another look and see if I can > see what the problem was. The first strcat in the registry code should > be strcpy, otherwise it would fail intermittently. If the same code was > in the shortcut one, maybe that was the problem. > > mmalmi@cc.hut.fi wrote: >> I made a Windows installer for the latest version of Bitcoin, which >> includes the autostart and minimize to tray features. The installer >> makes a start menu shortcut and a startup registry entry. I first >> implemented the autostart with a shortcut to the startup folder, but I >> found out that it doesn't always work by default and ended up doing it >> with a registry entry. The registry entry is removed by the >> uninstaller and can be also disabled from the options menu, so I don't >> think it's such a big menace to the user after all. Email #37 Date: Mon, 19 Oct 2009 00:02:28 +0300 From: mmalmi@cc.hut.fi To: Satoshi NakamotoSubject: Re: Setup, Autorun, v0.1.6 Well, the code worked and made a shortcut in the startup folder. For some reason it didn't automatically start when booting, but worked fine when you clicked on it in the menu. Now I tried making a shortcut manually, and this time it works on autostart,",
    "commentLink": "https://news.ycombinator.com/item?id=39480407",
    "commentBody": "Satoshi – Sirius emails 2009-2011 (mmalmi.github.io)379 points by lawrenceyan 20 hours agohidepastfavorite376 comments ak_111 16 hours agoSatoshi having the foresight and discipline to take careful measures that would enable him to keep his identity secret, and succeeding to do so up to this point is almost more impressive achievement of his technical skills than bitcoin. Even back in 2009, it was difficult (impossible?) to operate online without leaving tons of digital footprint, and we can guess that for sure state-backed actors tried to identify him and probably failed. Unless of course he was a state-backed actor(s). reply nostrademons 11 hours agoparentHe's probably dead. My two top picks for who Satoshi might be are Len Sassaman (died 2011) and Hal Finney (died 2014) There's little point in unmasking somebody who's already dead - their ability to influence future events is gone. So even if state intelligence surveys knew who it was, there'd be no benefit to unmasking it. reply andirk 10 hours agorootparentHal's final words to his family lead me to believe that he was not the creator of bitcoin. reply boppo1 9 hours agorootparentSpare us a search please. The top results are final forum posts, not words with his family. reply api 10 hours agorootparentprevThis would also neatly explain why the Satoshi coins have not moved. reply chx 7 hours agorootparentPaul Le Roux also fits. He had the crypto knowledge and the coins haven't moved because he is in federal custody. He was also quite good at opsec. reply TFortunato 7 hours agorootparentI don't know his story, but I had a little chuckle at the juxtaposition of \"quite good at opsec\" with \"in federal custody\" reply sangnoir 5 hours agorootparentOne probably has to be perfect - not just good with opsec - to maintain anonymity from the government. The FBI has multiple side-channels, such as agents physically tracking if you're home at your \"super-secure\" 7-VPN computer when your Internet persona is active online reply chx 6 hours agorootparentprevYou can be good and yet the heavy hand of the law still gets you. They got Escobar and \"El Chapo\" Guzmán too. And his operation was smaller than either of those fine gentlemen's. reply Hamuko 2 hours agorootparentprevYou can be perfect 999 times and still get fucked by that 1 mistake. reply lukan 1 hour agorootparentprevHe created truecrypt for his, well buisness. But are there any other indications, he also did anything towards cryptocoins? This is the first time I heard of this theory and so far I really doubt it. Satoshi seems to have been one tinkering alone and in peace with his concepts. Le Roux seems to have been more involved in action, too busy to create bitcoin. reply nostrademons 10 hours agorootparentprevOr why Hal Finney was cryopreserved. :-) reply api 10 hours agorootparentIn the future someone steals his frozen head to scan it and try to recover the Satoshi wallet keys... reply joering2 6 hours agorootparentin the real real far future you don't need his head, but maybe a single hair or a bone? Assuming every DNA cell keeps all memories or perhaps like a chicken running with a cutoff head maybe if his hands to be reconstructed, given enough time over a keyboard he would finally \"twich\" a password? Just thinking out loud... reply themoonisachees 3 hours agorootparentYou have played too much assassin's creed. DNA determinism has not been realistic ever. reply 123yawaworht456 2 hours agorootparentAssassin's Creed thing is more like ancestral memory. DNA determinism is more of a Dune thing. https://en.wikipedia.org/wiki/List_of_technology_in_the_Dune... reply TimeBearingDown 5 hours agorootparentprevWhat. I don’t see any reason to believe this is remotely feasible, ever? reply spoonjim 2 hours agorootparentprevYou need to read a middle school biology textbook reply speed_spread 9 hours agorootparentprevAre you sure he's not cryptopreserved? reply wmf 4 hours agorootparentHe couldn't upload himself to the blockchain because Ordinals hadn't been invented yet. reply acjohnson55 15 hours agoparentprevWhy do you assume state-backed actors failed to identify him? I would guess he is probably known with a high degree of certainty to at least one nation's intelligence but that publicizing that knowledge and the documentation of it is not in anyone's interest. reply bugglebeetle 11 hours agorootparentI would assume that his entire identity is a little more than a cutout for a U.S. state intelligence agency. reply voidfunc 11 hours agorootparentThis. I assume Satoshi is nation state actor. Most likely the US. reply neoncontrails 11 hours agorootparentWhat makes you think the US would be motivated to hamstring its own Federal Reserve, or threaten the dollar's status as the world's reserve currency? reply bee_rider 10 hours agorootparentI don’t think bitcoin is some sort of intelligence thing, Occam’s razor, it is probably just a dude. I mean, what was his big feat of secrecy? Writing a paper needn’t necessarily leave a big footprint. But! Bitcoins are too clunky to threaten the federal reserve really. And, a system that is widely understood by laymen to be anonymous, but is actually pseudonymous and inherently traceable, seems like Christmas for intelligence and police organizations. reply lolinder 11 hours agorootparentprevWhat makes you think that Bitcoin poses any threat to the dollar or the Federal Reserve? reply TimeBearingDown 5 hours agorootparentIt’s no threat at all for the foreseeable future. Make no mistake though, over the next decades, the core idea is an existential threat. If a currency like Monero with further developed scaling and privacy features is able to gain a foothold in developing nations, and enough off-ramps are set up via decentralized exchanges like Bisq and through direct acceptance for goods and services, then it is difficult to see the spread stopping between nations with reasonably free Internet, especially as factions within each government will likely have some direct interest. The US dollar will be least threatened, the longest. reply lottin 2 hours agorootparentPrivacy features in a currency are a double-edged sword. It means that the money is very difficult or impossible to recover in the event of theft, fraud, or even user errors. It isn't a risk most people want to be exposed to. reply pjerem 2 hours agorootparentThat’s not an issue to replace cash, which shares the same flaws. But yeah, you don’t want to have your savings in monero (or in crypto, tbf). However for decentralized people to people transactions, monero may have its chance. reply lottin 1 hour agorootparentPhysical cash is typically used in face-to-face transactions, which somewhat reduces the risks. The scenarios in which a digital version of physical cash might make sense are few and far between. To suggest that such a currency could one day threaten the US dollar dominance is absurd, in my opinion. reply sangnoir 5 hours agorootparentprevHypothetically, getting those who hate \"the feds\" to record their transactions on a public ledger would be criminal intelligence coup even bigger than when FBI's \"Encrypted Phone\" platform became popular with criminals[1]. In this hypothetical, the FBI would hack/subvert/operate their own mixer service and eliminate uncooperative services, so that all money-flows are transparent to investigators. https://www.justice.gov/usao-sdca/pr/fbi-s-encrypted-phone-p... reply TimeBearingDown 5 hours agorootparentNot all cryptocurrencies use public ledgers. Bitcoin was the first, but it was always intended to add privacy tech - see MimbleWimble. Zero knowledge proofs and other strong privacy protections are available on more modern projects. Some ledgers are entirely dark, granting a decent anonymity set. reply sangnoir 1 hour agorootparentHow many of those cryptocurrency were created by Satoshi Nakamoto, the subject of the thread's speculation? I was speculating on the why a 3LA would have created Bitcoin, specifically. reply mtnGoat 8 hours agorootparentprevSpitballing here… it could have been a test to see how easy they could get a digital currency into common use. The idea of a digital currency offers the Fed a lot of advantages… no money laundering, traceability, etc. it could actually advance them if well executed, not threaten them. reply DinaCoder99 1 hour agorootparentSeems like a very poor fit for the Fed's needs outside of a honeypot for people actually trying to launder money. reply coffeebeqn 6 hours agorootparentprevDoes the fed employ a lot of cryptographers? I feel like people expect the U.S. gov to be omnipotent when the last 20 years have been just fumble after another reply wsanf 4 hours agorootparentWhile not omnipotent, the NSA does hire a huge amount of mathematicians and has a budget in the tens of billions. Most of what they do is also behind (extremely) closed doors. reply ikiris 8 hours agorootparentprevHas bitcoin done either of these laughable things within any plausibility? reply neoncontrails 5 hours agorootparentBitcoin? No. But if you're asking whether digital currencies (which share a lot of the same underlying characteristics) might transform the global monetary landscape, well, they already have: 11 countries have issued CBDCs, and another 130 are actively exploring them as a more convenient alternative to USD for international transaction settlements. Several of those are in advanced pilot stages. No one with serious ties to the US financial system finds this to be a laughing matter, I assure you. The dollar is by far the currency of choice in trade invoicing (more than 50% of total trade) and foreign exchange transaction volume (almost 90% of the total) globally (Moronoti, 2022). This also means that US settlement authorities and financial institutions are involved in finalising most global transactions. If two countries have CBDCs, then they in principle would have the ability to settle transactions between themselves with near-instant finality, potentially bypassing the current dollar-based system. I think we can safely expect at least one major CBDC-based cross-border payment system to launch by the end of the year. Soramitsu is the most promising candidate IMHO. A prevailing theory is that foreign corporations that operate domestically within a country will need to create accounts with a domestic central bank for CBDC payments to work efficiently. If this becomes a reality, the status of the dollar's \"exorbitant privilege\" will be up for immediate dispute. Its geopolitical hegemony over global finance won't be swept away overnight, but it will suffer a major blow. Only time will tell how serious. reply lottin 2 hours agorootparentYou don't say why a CBDC would be a more convenient alternative to USD for international transaction settlements. A CBDC is simply a digital version of an existing currency. It isn't nothing new, since bank deposits already allow digital transactions with any currency. reply neoncontrails 1 hour agorootparentYou're missing the point. The reason the dollar is the global currency of choice is because it offers the infrastructure for any two parties to settle a transaction. The existence of CDBCs for wholesale purposes has the potential to fundamentally change that. Central banks could directly settle transactions between themselves in local currencies via dedicated corridors that bypass the dollar settlement system. That would mean more diversification of currency pairs, with increased liquidity for currency pairs that do not include USD. > It isn't nothing new, It is though. The infrastructure to support cross-border payments with CBDCs is bleeding edge stuff. The term floated around in obscurity for a while, but it's only been in use since 2019 or so. See: https://en.wikipedia.org/wiki/History_of_CBDCs_by_country reply timschmidt 6 hours agorootparentprevI've always figured some intelligence agency figured out how to reverse SHA-256 by calculating hash collisions on a global scale while wresting some capital and power from the international banks in one move. reply layer8 9 hours agorootparentprevOr a GPU manufacturer. ;) reply whiterknight 8 hours agorootparentEven though you are joking he didn’t anticipate Gpus or ASICS at all. The paper says “one cpu one vote”. reply ChainOfFools 5 hours agorootparentStill a dumb idea even if it managed to hold. One CPU one vote is it's not even as \"fair\" as $1 one vote, because it isn't a bare CPU that does the hashing, but the necessary power, space, cooling and network connectivity as well. The result would have been no different than if GPUs never came into the equation: people in a position to buy an extravagant share of mining resources, no matter what form factor they came in or how they approach the problem of calculating hashes, would always have had a massive and self-amplifying advantage getting started in the network, being awarded more coin bases and controlling more of the leverage over liquidity than anyone else. in the process creating the basis for a shadow banking system even more inscrutable and free from accountability than any central government or bank could hope to be. The meme of crypto people claiming to be fighting against the central banking or currency is cynical to put it mildly. reply TimeBearingDown 4 hours agorootparentI think you massively understate this advantage. Those with existing resources have advantages in nearly every endeavor possible. This can only be mitigated, not prevented, and not likely in the first example of a currency outside nation state control, which was unthinkable previously. It’s a possible option for evading asset seizure or hyperinflation from a despotic government to not insignificant numbers of people already. One step at a time. Ethereum 2.0’s proof of stake eliminates the ability of the biggest actors to stockpile and control supply of hardware, while also providing stronger security and massively reducing energy use from mining. On its face, directly staking coins over accurate security validations makes the problem even more obvious, but the result is that the rich accelerate their ownership slower. You may be well served by speaking with some of the very well intentioned people working on Bitcoin, Ethereum, and Monero. From my experiences the majority of them do believe they are bettering the world, as do most who work in open source anywhere, and they continue to strive much more for that reason than any indirect personal enrichment. reply TimeBearingDown 4 hours agorootparentprevThe inevitable rise of GPUs and more specialized hardware was being discussed by Satoshi and others on bitcointalk around early 2010. Just my memory as a source, or you can see some discussion of emails between Laszlo Hanecz who bought the 19K BTC pizza and was GPU mining and Satoshi. reply majikandy 7 minutes agorootparentWasn’t it 10k btc for 2 Papa John’s Pizzas? layer8 7 hours agorootparentprevA GPU vendor would of course try to avoid being too obvious. reply Fnoord 8 hours agorootparentprevOr a nation state where energy is very cheap and people can live anonymously over the internet ie. Russia or China. reply eru 7 hours agorootparentWhat makes you think Russia or China make living 'anonymously over the internet' easier than other places? About energy: https://www.statista.com/statistics/263492/electricity-price... says that China and Russia both have lower absolute household electricity prices than eg the US. But they are higher when compared to average incomes. reply realusername 1 hour agorootparentprevThose countries want way too much control for a decentralized currency. reply hibikir 6 hours agorootparentprevIMO you have way too much faith in state agencies' ability to keep secrets. It's information the world would like to know, so it's a hard secret to keep. On top of that anyone with access to the keys of big wallets would be very tempted to just use them. This doesn't seem like a situation that can be kept secret by a mid-sized conspiracy. If this was a state project, how many people would have to know about it and still keep quiet, despite all the advantages of not keeping it quiet, or the risk of leaks? It'd be tough to get three people to keep this quiet. The dozens that would have to be involved at an intelligence agency, if this is really a project that was started in one of them? The specifics would have leaked by now. reply ryanSrich 5 hours agorootparent> It'd be tough to get three people to keep this quiet Incompetence fallacy and impossibility complex. Just because something seems difficult or impossible doesn't mean it is. Especially when it's the most logical explanation. People often like to think the government is just a bunch of incompetent bureaucrats. Yet the U.S. government is the most powerful entity on earth. There's not a single reason to believe that any large number of government employees could keep a secret on the level of Satoshi's true identity. reply nodesocket 7 hours agorootparentprevHonestly somebody should put a bounty to be paid of course in BTC for definitively identifying Satoshi. With enough incentive I’m sure can be figured out. Recent AI improvements should be able to be used to scan all his/their writings and code. reply martindevans 7 hours agorootparentIsn't there effectively a multi-billion dollar bounty on finding out who Satoshi is and deploying a bit of \"Rubber-hose cryptanalysis\"? reply chx 7 hours agorootparentAll three good candidates for Satoshi are beyond said cryptanalysis: Sassaman and Finney are dead, Paul Le Roux is in a federal prison and it is not known to the public where, even without Bitcoins, quite a few people want him dead so the feds are not going to make it easy to get access to him. reply krick 14 hours agoparentprev> probably failed That's silly. The fact that you don't know who somebody is says nothing about what some \"state-backed actor\" knows. If anything, I'm fairly confident that some people in NSA/CIA know who he is for a decade at least, and \"probably\" have it written in some documents that will long outlive you. Of course, this is as proofless statement as you saying that they \"probably failed\" to figure it out, but what you are saying basically amounts to \"it is so unlikely for this to happen, so it's such a miracle it probably happened!\" A more reasonable thing to say would be \"it is so unlikely for this to happen, so it probably didn't happen\". reply wwtdtgotiatl 8 hours agorootparentIt took ten years to find Osama Bin Laden, which we can fairly assume had a lot more resources directed at it. You seem to falling into this common trap of intel agency omnipotence when we have plenty of examples to the contrary. reply krick 8 hours agorootparentYou seem to be falling into this common trap of confusing \"finding a human's body hiding offline in mountains of Pakistan\" and \"figuring out the name of a guy thinking he is shitposting anonymously on the internet\" (and that if we assume that the \"shitposting guy\" was just that, and not some remarkable researcher with some very specific skill-set, and also not affiliated with any 3-letter agency in the first place — which is hell of an assumption as well). (Also, doesn't matter, but just for the record, I don't recognize your assumption as \"fair\". It's not like a I deny it, it's just way too many assumptions for a discussion involving more unknowns than any real factual information at all.) reply whiterknight 8 hours agorootparentprevyep, they absolutely use propaganda’s to achieve a scarecrow effect. Remember all the info they fed journalists about bin Laden hiding in networks of underground caves? Then it turns out he is hiding at a family members house with all his relatives? reply deepsun 11 hours agorootparentprevThere are limits on secrets lifetime that's highly dependent on number of people in it. Someone even tried to calculate a formula In democratic societies it's very hard to keep a thing secret that involved 10+ people for 20+ years. reply tsimionescu 11 hours agorootparentWell, the Manhattan project is a good example of something that remained secret from the public for far longer than any formula would predict, given the gigantic amount of people involved (though of course other state actors knew about it long before). reply rappatic 10 hours agorootparentprevThis is Grimes' \"On the Viability of Conspiratorial Beliefs\" (https://doi.org/10.1371/journal.pone.0147905). reply boppo1 8 hours agorootparentBummer I was excited for a scholarly paper by Claire Boucher. reply roenxi 11 hours agorootparentprevIf that calculation was completely wrong, how would anyone know? We never get a perfect snapshot of the world to compare with. What that stat really says is any conspiracy involving 10+ people, if the details manages to stay secret for 20 years, will likely never come to light. reply eganist 11 hours agorootparentWith the US at least, it can probably be loosely tested by comparing declassified records (50 years on) with program size at the time. reply biorach 14 hours agorootparentprev> That's silly. That's unnecessary and a bit childish and devalues the rest of your reply reply xdavidliu 12 hours agorootparentI would argue that saying \"childish\" is just as unnecessary as saying \"silly\" reply DetroitThrow 11 hours agorootparentprev>That's...childish That's unnecessary and a bit silly and devalues the rest of your reply reply verve_rat 12 hours agorootparentprevI think you are over reacting. reply hwbunny 35 minutes agoparentprevWell, Craig Wright tries very hard to unmask the creator(s), by pretending to be Satoshi. reply asmr 13 hours agoparentprevIf you dig a lot you will find a footprint. There is evidence that there was a small core team and that satoshi may not be a single person, if it is, he is most likely to be Wei Dai. The other likely alternative is of course the hypothetical state-backed actor. reply Alupis 9 hours agorootparent> There is evidence that there was a small core team and that satoshi may not be a single person \"Three can keep a secret, if two of them are dead.\" - Benjamin Franklin It seems highly improbable that a team of any size would have been successful at keeping this a secret for this long, let alone not wrestle for control of vast BTC wealth. reply tremarley 11 hours agorootparentprevOn 21/08/2008 Satoshi claims he was not aware of Wei Dei’s “B-Money” paper. reply diggan 11 hours agorootparentOn the other hand, if they were Wei Dei, they wouldn't exactly say \"Ah yes of course, I wrote this paper but don't use that name, use Satoshi\" but they would of course say \"Oh I didn't know, I'll put a reference to it in my paper\". reply idontwantthis 12 hours agorootparentprevWhat is the rationale behind a state creating BTC? reply boppo1 8 hours agorootparentI have a pet theory that the smart people at the NSA are aware that politicians with 4 year terms aren't effective at long term financial planning. The current debt situation coupled with the last ~30 years of mostly loose monetary policy has set the US up for serious problems if it doesn't come up with another world-changer like the ICE, electric light, or internet. Hence, Bitcoin is a hedge industry could embrace against a failing dollar. I know the US isn't solely or originally responsible for those, but boy it sure ran the ball a long distance. reply kadoban 6 hours agorootparentAs far as the US government is concerned, this primary effect of Bitcoin and other crypto is a weakening of their ability to enforce sanctions and prevent money laundering. If Bitcoin was a government program, it probably wasn't the US government. I'd guess North Korea, Iran, Russia, etc. One of the countries heavily bothered by US-led sanctions, or at least one that doesn't already have an important ~global currency to disrupt. It seems to have grown mostly in the English-speaking world to start with, but that doesn't seem like a fatal flaw of my theory. reply ErikBjare 2 hours agorootparentThe same could be said for Tor and onion routing, which was a US government program. reply dmitrygr 7 hours agorootparentprevTrust me, If USA's economy collapses, no amount of bitcoin will save you. Nothing will reply wil421 11 hours agorootparentprevFund or obfuscate funding for programs they want but the public or political appetite doesn’t want to know about it. reply krapp 11 hours agorootparentThat's already what black budgets are for. And funding drug cartels. reply reaperman 10 hours agorootparentMoving money in/out of places which are hostile to USA. Paying assets in hostile locales. reply krapp 7 hours agorootparentI'm pretty sure the US can already do both, and that neither of those would be easier with a US backed cryptocoin. Literal American cash dollars (which tend to work everywhere, even anti-American regimes) under the table would be more secure. But then assets in other countries are probably just paid through shell companies in those countries with local currency or something. reply lazide 11 hours agorootparentprevAnd Tor? Similar possibilities. reply dist-epoch 12 hours agorootparentprevWei Dei is one of my suspects too, mostly because of Crypto++, but not only. Why do you suspect is Wei Dei, was there any reveals regarding this in the lasts few years? reply nodesocket 8 hours agoparentprevI can’t believe we haven't figured it out yet. - What about the email at gmx.com? Can an insider get into it? - Access logs with browser agents and ips? - White paper writing style and code analysis and heuristics. reply qingcharles 7 hours agorootparentDidn't he also register bitcoin.org? reply nodesocket 7 hours agorootparentNot sure, whois showing: Registered On: 2008-08-18 Expires On: 2029-08-18 Updated On: 2023-10-31 reply dist-epoch 12 hours agoparentprevState backed actors in the West don't go on a hunt without orders. Who would be so interested to order his identity discovered? And for what purpose? They found Bin Laden who didn't allow anyone of his associates to come within 50 km of him with an electronic device. We will only find out what FBI/CIA is capable of when the Justice Department orders the identity of Satoshi to be discovered. reply wordpad25 10 hours agorootparentUghh, it's somewhat important to national security who's behind a multi-trillion dollar shadow market larger than most national economies reply mrinfinite 6 hours agorootparentYou all know Satoshi Nakamoto translates exactly to Central Intelligence... Sell all your things and invest in bitcoin. its annonymous, tho (social security number required to buy a piece of bitcoin)... reply timeon 9 hours agorootparentprevIs he? He cannot move those amounts. reply k12sosse 12 hours agorootparentprevWe got him, look at the map! See the 50' no-radio circle in the middle of that city? He's there. Sometimes a lack of signal is a signal itself. reply dist-epoch 12 hours agorootparentRead again, of his associates. He lived in a village, among other houses and people with phones. reply paulpauper 12 hours agorootparenthe's a human. only 7 billion of them reply medo-bear 15 hours agoparentprev> Unless of course he was a state-backed actor(s) I'd be even more impressed if some state had the foresight to come up with Satoshi reply ak_111 14 hours agorootparentWell, one of the theories I fancy is that we know that Dorian Satoshi Nakamoto worked on a classified defence project, now it is almost impossible that he was the creator of btc, however there is a chance that a group of security service hackers who interacted with him while he worked there were inspired by this eccentric persona and thus decided to adopt his name as a joke when they were thinking of made-up moniker. reply lettergram 9 hours agoparentprevUnless of course, the NSA or other government agency created bitcoin. reply dgfitz 6 hours agorootparentBitcoin didn’t succeed, define “succeed” however you want, but because of how it was marketed. Bitcoin is the OG shitcoin. If there is one thing we can all agree on: NSA isn’t good at marketing. This whole thread is evidence of that. reply mvdtnz 1 hour agoparentprevI'd be determined to stay anonymous if my life's work was a currency for pedophiles too. reply fenalphthalein 17 hours agoprevHonest inquiry here - What I don't understand is how people think the identification of Satoshi is \"bound to happen\". What did the person do wrong, exactly? Based on how I understand it, if the person did nothing wrong by inventing Bitcoin, no investigation will occur and no judge will sign off on a search warrant to get the ID data. No private investigator will be able to obtain the data either, as ISPs wouldn't just dish out private info like that without a warrant. Did the inventor of Bitcoin do something wrong to allow for a judge to violate their privacy in a court case? That's the only way I see the info getting out, but is there a crime to allow that situation to arise? What other (legal or illegal) path is there to identify a person who posted something online? reply dogman144 16 hours agoparentThe space has moved past this risk for a lot of reasons, to start. And it’s hard to understand I think in light of modern (relative to pre-2018/19) widespread mainstream adoption. But, a long term protection for BTC when it was smaller and tbh anyone’s guess how it would turn out (still is IMO), was: who are you going to haul into senate hearings, court, cryptography export control violations, whatever over BTC? This happened ample times in the recent past before BTC with digital money attempts and cryptography projects. It’s happening now with mixers on btc and ethereum. It was a real risk to BTC in its own way. With BTC then and now, there was no real leader though. There were important core devs and industry leads, but no one held true sway like, say, Vitalik did with eth early days. So it wasn’t so much a firm “did something wrong” risk for BTC’s founder, but more of a concern that the US govt had taken very heavyhanded measures against many similar projects to BTC. As there was no one to target in BTC’s case, this protection played a large role in its early push into staying power. Also going to color this with CIA had the lead dev at the time visit them to discuss it in 2011. So there was certainly some real sustained attention to it from the start. reply fenalphthalein 16 hours agorootparentSounds like this person was really smart to begin with. High-level societal awareness caused them to choose the private route, and focus on releasing something for the greater good. I wouldn't be surprised if this person never even took a single bitcoin for themselves, other than the ones used for code testing purposes. That would create another avenue for people to come after them if it became public that they hoarded some of the Bitcoin for themselves. reply reactordev 16 hours agorootparentThis. Maybe, Satoshi saw where it was going, knew it had wings, didn’t want to be the elephant’s plaything in some senate hearing, and bowed out. Sometimes people make things because it’s the right thing to do. Other times people make things because they are experimenting and seeing what sticks. This was a case of both. The right idea, at the right time, without hubris, and without someone to blame or throw in court if the experiment fails. reply johnmaguire 16 hours agorootparentprev> I wouldn't be surprised if this person never even took a single bitcoin for themselves, other than the ones used for code testing purposes. Unlikely - https://coincodex.com/article/28459/satoshi-nakamoto-wallet-... reply jjmarr 15 hours agorootparentThe value of his publicly-known wallets are well into the tens of billions. Yet Nakamoto has not cashed out. reply arein3 13 hours agorootparentMaybe he will cash out in the future if his cryosleep awakening will be successful Allegedly this guy is nakamoto https://en.m.wikipedia.org/wiki/Hal_Finney_(computer_scienti... reply tromp 15 hours agorootparentprevSatoshi could have chosen a 0 BTC subsidy in the blocks he mined. Or he could have burned all the BTC he mined. But he chose to do neither, leaving himself as the biggest BTC owner ever. Other coins have been designed in a way where the founders can only obtain coins by mining them in very small quantities or buying them on the open market (mostly by fixing the block subsidy forever). reply bitcoin_anon 12 hours agorootparentOr he deleted the keys. Also can you choose a smaller subsidy? Wouldn’t that be an invalid block? reply tromp 11 hours agorootparentYes, the coinbase can be any value from 0 to the maximum, which is subsidy + fees. It has been below the maximum several times in fact. reply dogman144 14 hours agorootparentprevI mean that “other coins design” part is looking at this aspect from the 2024 perspective of many blockchains many designs existing. In 2009, calling Bitcoin the only blockchain in town doesn’t even do service to its extreme novelty at the time. There were no other ideas on how to design, let alone any ideas on what would work long term, and there were no “open markets” for crypto haha. reply BlueTemplar 15 hours agorootparentprevWhen in 2011 ? You seem to mean that it was unknown by then, but it wasn't : 2011 was pretty much the year when it blew up into the public consciousness, spreading from the likes of Slashdot and Ars Technica into more generalist publications (also causing its first - or was that 2nd? - bubble popping) : \"The Crypto-Currency\" - The New Yorker (2011) https://archive.is/wsbcQ (I love how I picked it randomly, and the first two subtitles are \"Bitcoin and its mysterious inventor.\" and \"It’s not clear if bitcoin is legal, but there is no company in control and no one to arrest.\") reply dogman144 15 hours agorootparentI know what you’re getting at but I disagree with the analysis and I’ll try to frame what I mean, which is somewhat the opposite. I mean the ‘11 visit is indicative of serious attention paid to by serious people very early on relative to the rest of crypto’s history. As in, the founder was right to be cautious. “Early on” in this case means that outside of tech pubs and curiosity pieces due to the compelling founder mystery, the space was treated as a joke by and large. Like watch Banking on Bitcoin, and imagine trying to convince critics of it at that time that ETFs, crypto aide to Ukraine, 3x nation state adoptions, custody teams at big banks, and so on were all coming. I would just completely disagree if you argued this wasn’t the theme then. So yes, 2011 and intel agency interest is quite early on. For example, it’s taken 15 years to get tangible regulatory clarity which arguably just starting finally with the ETF. reply paulpauper 11 hours agorootparentprevthis is like winning lotto ticket but not cashing it . anyone in theory could have read the article or related ones and bought some, but you would needed to hold reply aillia 15 hours agoparentprevI hear your point and it's a valid one. Consider the recent case of Tornado Cash and the Open Source Is Not A Crime movement. Two individuals were arrested for developing open-source code on GitHub. Just last week, GoFundMe shut down the Tornado Cash legal defense crowdfunding. This suggests that the state is more interested in protecting itself from individuals rather than defending their rights. This could potentially set a precedent where inventors or developers of decentralized technologies could be targeted, even if they've done nothing inherently wrong. If interested you can learn more here: https://wewantjusticedao.org/ reply cududa 14 hours agorootparentOh this is bullshit and you know it. Another example of \"we didn't call it a security so it's not a security\" They weren't arrested for the code. They were arrested for actively participating and profiting off money laundering with North Korea being a customer. Zero-knowledge proofs are different from public ledgers. That's where the issue comes in to play. The Treasury Department has already given guidance that cryptocurrency mixers fall under Know Your Customer laws and the Bank Secrecy Act, and are required to know who exactly is using their services and how. It's not \"Criminalizing Open Source\". You live in a society with laws. Obfuscating classic financial products with tech jargon worked for the first half of the decade. Y'all are just mad it doesn't work anymore and claim \"You just don't understand the technology. You haven't issued guidance on specifics of crypto currency. You can't use hundred year old laws\" Yes, you can use 100 year old laws. At the end of the day, the financial shenanigans of most crypto, exchanges, and tokens are fundamentally the same things that have already been regulated. You just have new words. reply ipaddr 14 hours agorootparentYou live in a society of variable laws that change at runtime get applied unevenly. reply cududa 4 hours agorootparentClass templates get applied at runtime based on the heap size/ legacy properties of the initializing task. If we’re using software metaphors for things that aren’t software, I can pull that card too. reply pushedx 8 hours agorootparentprevThe first half of which decade? reply cududa 4 hours agorootparentYour pedantism perfectly illustrates my point reply hef19898 14 hours agorootparentprevTornado Cash was what, money laundering and circumvention of sanctions? Pretty illegal. reply avgDev 12 hours agorootparentprevTornado cash was doing something illegal. GoFundMe is a business, which may do whatever it wants. Tornado Cash has no rights to obtain funds though GoFundMe. reply soojimit 11 hours agorootparentTornado Cash is a protocol which can be used by both good and bad actors. Saying TC was responsible for bad actors laundering their crypto through the protocol is like saying auto makers are responsible for car crashes or Bob Kahn is responsible for all the illegal activities on the internet. reply lesuorac 10 hours agorootparentOr like gun manufacturers are liable for crimes! Oh they've been sued and lost [1]? Maybe not that one. [1]: https://apnews.com/article/sandy-hook-school-shooting-reming... reply lordfrito 8 hours agorootparentprevEven if used by \"good actors\", you're still facilitating money laundering. Which is always illegal. There is no \"legal\" way to launder money. reply pcthrowaway 2 hours agorootparentThe technology behind Tornado Cash could also be used for instituting something like truly fully anonymous group surveys (such as those employee surveys big companies always ask you to take that they claim are \"anonymous\") It doesn't have to be used for money laundering, and even if using it to move funds anonymously, that doesn't mean you're money laundering. There are good reasons to not want individuals and state actors whose jurisdiction you're not under to track your financial movements, even if you are reporting your income accurately with your own government. reply mikrl 8 hours agorootparentprev“ In August 2022, the U.S. Department of the Treasury blacklisted the service, making it illegal for US citizens, residents and companies to use.” [0] Regardless of how you feel about it, you can’t deny that they were doing something illegal under US law, and a consequence of that is that the Feds can come down on you, even if the law seems ad hoc and unfair. [0] : https://en.wikipedia.org/wiki/Tornado_Cash reply thisgoesnowhere 14 hours agorootparentprevWell either that or what they were doing is just obviously illegal and they should be at fault for it. reply tsimionescu 11 hours agoparentprev> ISPs wouldn't just dish out private info like that without a warrant. ISPs routinely sell such information for money en masse. Police departments are a major buyer, but also ad agencies and others. Plus, bribing a low level employee for access to such records, or directly infiltrating the ISP to get access yourself, is child's play to any determined group. It is extraordinarily naive, especially in a post-Snowden world, to think that any and all information available to a private company is not also available to, at least, spy agencies of the parent state. reply falserum 11 hours agoparentprev> Did the inventor of Bitcoin do something wrong to allow for a judge to violate their privacy in a court case? That's the only way I see the info getting out, but is there a crime to allow that situation to arise? This feels like wrong framework/approach. Fundamentaly question here: “is it worth it for somebody?” Economists path to an answer: If for somebody[3], profit[1] of identifying satoshi outweighs the cost[2], it will be done. [1] profit in very abstract sense. E.g. elimination of (perceived?) threat, aquisition of credible threat to other enemies, political points, money, making an example for others, showing off skills. [2] “cost” is also used in very abstract sense. E.g. Favor from a known(or compromised) judge, man hours dedicated by FBI/MI6, money, negative press budget after “bending” some rules, risk of getting caught by supriors/underlinglins/press/constituents. [3] “somebody” - to no surprise - can be anybody/anything. E.g. A corporation, a government, maybe single branch or department, maybe sole individual able to use his government position for personal gain, an employee of ISP, a blockchain historian, most likely Satoshi’s ex. Important to note: both individuals and governments do break the law when they think it is necessary. I find at least two credible incentives to find satoshi: - bitcoin can be used to lounder money, circumvent financial sanctions, so governments want to stop that and make example of it. - Satoshi, has 1 000 000 bitcoins. That’s a lot of money. a) banal roberies are done for far less. b) CIA or similar might want to know who wields this much resource, friend or foe (especially if its value would grow even more) How Satoshi can be uncovered I have no idea, but the story of Silkroad owner shows, that minor slipups can be revealed after number of years. reply IncreasePosts 16 hours agoparentprevIt only takes one person at an ISP to steal and leak the data. I mean, an IRS employee leaked the president's tax returns and is currently in federal prison for it. I imagine the stakes are much lower for just stealing some IP address assignment data from an ISP archive(if such an archive exists). reply reactordev 16 hours agorootparentIt only takes one VPN to hide it. reply ziddoap 16 hours agorootparentVPN's shift the trust, they don't eliminate the need for it. Feel free to read the above as: >It only takes one person at a VPN provider to steal and leak the data. reply mksybr 15 hours agorootparentPerhaps he only communicated as satoshi over Tor. reply Affric 5 hours agorootparentPerhaps they practiced near perfect opsec. VPN, their own IP, stealing access, TOR, hacking the routers and APs and cleaning up… reply reactordev 12 hours agorootparentprevYou’ve never played Uplink I see. One doesn’t just hop to one VPN and call it a day… reply thrwwycbr 10 hours agorootparentprevIt only takes one Kape Technologies to unhide all of it. reply paulpauper 11 hours agorootparentprevprobably used TOR reply hansvm 16 hours agoparentprev> as ISPs wouldn't just dish out private info like that without a warrant ISPs regularly sell private data to the highest bidder. Similarly with payroll providers and whatnot (a non-trivial fraction of my paystubs -- not just salary, but withholding, exempt tax status, ... -- are available to anyone with a few dollars; historically, it _seems_ like the only buyers have been employers trying to see if their salary offers aligned with my expectations). reply fckgw 16 hours agorootparentThey'll sell anonymized data in aggregate but no, you can't just go to an ISP and buy the user behind an IP without a court order. reply hansvm 15 hours agorootparentThey sell \"anonymized\" data, not just \"aggregated\". The only missing link is tying that back to a real person (i.e., they haven't solved differential privacy; they've just given the illusion that they're not selling personal data). Tying it back to a real person is easy though because the non-anonymized fields (age, gender, salary, zip-code, ...) are uniquely identifying for most individuals and are available for sale tied back to a real human from other sources which you can fuzzily join the ISP data into. It's similar to how bitcoin transactions (before mixers and whatnot) were de-anonymized. You have the secret information (an identity), the public information (transaction history), and you're able to fuzzily join that public information to other public sources containing the secret information to also have secret information tied with the original \"anonymous\" source. reply ziddoap 14 hours agorootparentJust to re-emphasize, because I think it's really poorly understood: most \"anonymized\" data is a few additional data points away from being re-identified. Data re-identification was already happening in 2006 (just one example below). And now there's exponentially more data available to use for this purpose. >We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world’s largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber’s record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information. [1] https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf reply acdha 14 hours agorootparentprevAmerican ISPs injected tracking codes into their user’s HTTP traffic so they could get paid by advertisers. I would not speak in absolutes about that, especially because anonymizing data is a hard problem which even we’ll-intended people have made mistakes with. reply welder 14 hours agorootparentprevYes you can, companies have deals with ISPs for individual real-time mobile and home browsing data. If you pay enough it has real names, otherwise it has person id and household id along with other data that makes it easy to associate with the real person or household. reply ekabod 16 hours agoparentprevMaybe one country jurisdiction thinks he may owe taxes, so they may investigate. reply falserum 10 hours agorootparents/thinks/decides/ reply sparkie 6 hours agoparentprevSee: Liberty Dollar. https://en.wikipedia.org/wiki/Liberty_dollar_(private_curren... reply tim333 11 hours agoparentprevI think people who follow / read up on the thing have a pretty good idea who it is but as you say he didn't really do anything wrong. Reasons for anonymity include not having criminals try to extort you and maybe some government having a go over money laundering or people suing for this of that so I think people with a good idea stay quiet to respect Satoshi's desires. I've got a theory he may come out and donate to a charitable foundation when he's old and near the end. reply usrusr 15 hours agoparentprevDark sarcasm take: there's a large volume of early bitcoin that may or may not be lost forever. The risk of addresses that have gone dark a long time ago lighting up again must have a big influence of any bitcoin evaluation that is at least in part based on reason. Fossilized coins could hugely change the supply/demand dynamic. The documented death of a person believed to be Satoshi would significantly shift that risk assessment. Nobody would know wether the person took meaningful keys to their grave or not, but the risk equation would contain one scenario less than before in the category of old coin flood. reply gopher_space 3 hours agorootparentYou think it’s a killswitch? reply keiferski 16 hours agoparentprevThe USG seems pretty intent on implementing KYC across the entirety of the financial system, so it wouldn't really surprise me if they aimed to identify wallets holding large (say, $100 million USD or more) amounts of Bitcoin. reply dannyw 16 hours agorootparentRealistically the threshold will be something like $100. reply le-mark 16 hours agorootparentprevWould this not be self reported by wallet owners? Because if each transaction uses a unique wallet address, funds are very difficult to connect to an owner. Until they’re connected to a sale to fiat at least? reply keiferski 15 hours agorootparentYes but my point is more that if the resources of a nation state are at play, they will probably be able to figure out who Satoshi is/was. reply mortallywounded 16 hours agoparentprevI don't think it's a legal issue. People want to know who it was and credit where it's due. Satoshi didn't do anything wrong but distributed consensus was finally solved (or so it seems) and that's a big deal. reply reactordev 16 hours agorootparentIdolization of Satoshi is strong. For that reason alone, if I were him/her, I would disappear. The work is self-evident and the idea a dime a dozen. The execution of it and the fact that it was accepted is what we should be idolizing. Which is exactly what happened. BTC became a thing and was no longer an idea. I reject anyone claiming to be Satoshi because Satoshi would never claim to be Satoshi. ;) reply mortallywounded 16 hours agorootparentThat's why I hope the truth comes out. If say, Satoshi is Len, then Satoshi is no longer a god. He's a regular dude, that suffered like many people and tragically took his own life. There's a lot to unwrap there. reply reactordev 12 hours agorootparentMaybe, we are better off NOT knowing. Having closure could mean the end of BTC. It could mean the end of a lot of things. It could also be beginnings, no doubt. However, like Schrödinger’s cat, it’s best if it’s kept in a state of quantum entanglement. reply falserum 10 hours agorootparentQuantum superposition reply treffer 14 hours agoparentprevThese court orders might also happen if someone _claims_ that crimes have happened. The legal system has to come to that conclusion, which requires an investigation. Yeah it must be an important claim. That's of course completely unacceptable and illegal. But it is one way such warrants could happen. reply thefatboy 15 hours agoparentprevWhy do you think they want his identity because he did something WRONG? reply phone8675309 16 hours agoparentprevGovernments are going to argue that the creation of BitCoin and lack of KYC to use it is a major contributor to money laundering. reply abriosi 9 hours agoprevSatoshi regularly took two spaces after a period. He uses vocabulary tied to British There is a famous British cryptographer called Adam Back, who is also the inventor of the proof of work method laid out on the paper “hashcash”. He also leaves two spaces after a period (or used too) I don’t think it really matters who created it. If you read the political story of bitcoin things look a lot clearer. “The Blocksize War: The Battle Over Who Controls Bitcoin's Protocol Rules” is a good entry point reply adrianmonk 9 hours agoparent> Satoshi regularly took two spaces after a period. So did I, for a long time, because I was taught that way in typing class. And so were millions of other people. It's how it was usually done on typewriters. It supposedly made the text easier to read. It has fallen out of fashion now. I eventually switched to one space once I realized things were going that direction. I'm not sure if I had switched by 2009. So I think this just tells you that Satoshi is probably old enough to have been taught the old rule. reply hn_throwaway_99 7 hours agorootparentI will say, I did enjoy reading abriosi's assumption, though. As I get older I get more aware of the things I just \"took for granted\" that everyone knows (because nearly everyone in my generation does know it) are really just generation-specific. Like when I learned most kids can't read cursive anymore. Or that, for a long time, my use of \"emoji noses\", :-), really dated me (and I still think it looks better with a nose than without!) So I admit I had a similar chuckle with the idea that putting two spaces after a period was a unique characteristic! Even well into the PC era, 2 spaces was the norm before proportional fonts became widespread. And I still had a heck of a time moving to a single space because it just looked so weird to me. reply freeAgent 9 hours agoparentprevAdam Back is far too jealous of Satoshi inventing Bitcoin. He put, “Bitcoin is HashCash extended with inflation control” in his Twitter profile for years after he got into Bitcoin after initially dismissing it when contacted by Satoshi. Back definitely isn’t Satoshi. reply whiterknight 8 hours agorootparentAnd too greedy. Why would he be doing this weird startups and marketing schemes if he already had all the money? reply freeAgent 8 hours agorootparentYeah, there are many, many reasons why Back is not and cannot be Satoshi. These emails also provide more evidence that Satoshi was what would later be called a “Big Blocker” in favor of on-chain scaling and minimal tx fees set by nodes independently (though likely converging). Back is famously a Small Blocker who employed all the major Small Blocker devs with Blockstream, which ended up effectively controlling Bitcoin Core. Thankfully, we still have Bitcoin Cash following Satoshi’s intended path for scaling. reply voldacar 5 hours agorootparentEven if this is correct (which it probably is) it doesn't matter because bch is worthless because it doesn't have the name bitcoin. Whoever controls bitcoin core controls the meaning of the word \"bitcoin\" so if the bch people never find a way to wrest back control from the blockstream people then this whole thing is just irrelevant. History is written by the victors, etc reply freeAgent 5 hours agorootparentThat perspective is valid, but it’s not mine. BCH is bigger than Bitcoin circa Satoshi’s days already. I’m honestly not too concerned about it. The Bitcoin that I became interested in still exists. It just isn’t called BTC/“Bitcoin” anymore. reply shp0ngle 3 hours agorootparentprevAlso Bitcoin SV (SV for Satoshi's Vision). And Bitcoin ABC. There are so many to chose from. reply freeAgent 2 hours agorootparentThere are, but SV and ABC (now called eCash/XEC) also made departures from Bitcoin that I feel are pretty significant: BSV: completely removed any concept of a tx spam cap and encouraged use of its blockchain for random data storage. Neither of these are things Satoshi supported. Its spiritual leader is also a charlatan. XEC: changed both the mining algorithm and added in a \"dev tax\" on block rewards. The dev tax in particular is something I don't imagine Satoshi would have supported, or he would have added it himself from the start. But to each their own. reply pcthrowaway 2 hours agorootparentprevBitcoin SV is the Craig Wright-backed crypto that is pretty different from Bitcoin, and is only \"following Satoshi's intended path\" if you actually believe that hack is Satoshi reply rl3 8 hours agorootparentprevThe perfect ruse. /s reply swamp40 9 hours agoparentprevTwo spaces after a period just means you learned on a typewriter. I still do it. reply silisili 8 hours agorootparentI learned on a PC, and we were taught that way initially also. I still think it makes sentences easier to read, so still do it. Though usually on mobile it's .nn because that's where my thumb always wants to land. reply swamp40 9 hours agorootparentprevHah, HN shrunk it down to one space. reply Dove 5 hours agorootparentActually, the browser did. Your double space is still there in the page source. :) (I still do it, too, and mine is also there.) reply asciii 9 hours agoparentprevI think you're spot on. Plus, the use of \"colour\" (with u) and reference to something as \"rather Neanderthal\" reply lawn 2 hours agoparentprevAdam Back, who when asked how to scale Bitcoin while waiting for LN answered that we should let a \"local technology expert\" setup a tab. Just, no. reply greyface- 11 hours agoprevSatoshi Nakamotowrote: > There are donors I can tap if we come up with something that needs > funding, but they want to be anonymous, which makes it hard to actually > do anything with it. I wonder who these donors were. reply neom 17 hours agoprevFor those curious about the court case it's referencing, here is the context: https://www.forbes.com/sites/digital-assets/2024/02/07/craig... (https://archive.is/7YyMl) reply semiquaver 16 hours agoparentIf you prefer an (outdated but entertaining) podcast: https://www.alabseries.com/episodes/episode-3-faketoshi-the-... reply barcode_feeder 10 hours agoprevThe usage of British English as an identifying factor seems ridiculous to me. Faking such a thing is extraordinarily low-hanging fruit even for a bumbler. Letting slip some regional red herring is quite literally the easiest misdirection I can think of) reply bogota 7 hours agoprevI love reading this stuff. 2010 is when i found out about bitcoin and wanting to learn about it was what took me from someone who played around on linux to someone who could write software and then ended up finishing a CS degree after. Reading this reminds me of what I originally loved so much about the tech scene at the time. I haven’t been able to find that spark for a long time now unfortunately. Maybe im just looking in the wrong place but i feel it is hard to find another community like the early bitcoin one. reply udev4096 4 hours agoparentTotally agree on this. It was the true hacker spirit back then reply metachris 2 hours agorootparentThe Ethereum community still is. reply encoderer 14 hours agoprevI love this mystery and I’m so grateful for it. Growing up we had DB Cooper and Deepthroat - interesting and compelling stories but those guys are famous only for being anonymous. They didn’t really do anything special. But satoshi… reply bsparker 14 hours agoparentand banksy! reply superjan 12 hours agorootparentThat’s no secret anymore, is it? reply codethief 10 hours agorootparentThat's news to me! What did I miss? reply jasonwatkinspdx 9 hours agorootparentHis identity has been known for quite some time. His first name is Robin, and he used the alias Robin Banks for a while, which eventually became Banksy. But also Banksy is something of a collective effort, with people like 3D from Massive Attack apparently occasionally collaborating. reply mike_d 9 hours agorootparentprev\"Banksy\" is now a group of artists, but the original is believed to be Robin Gunningham. He is named as a co-defendant in a lawsuit against Pest Control (the company that sells and validates Banksy art). reply joering2 5 hours agoparentprevSorry but what is \"Deepthroat\" - I only found p0rn underneath, what is the \"Deepthroat\" story you been growing up with? Obviously aware of DB C. reply pingswept 5 hours agorootparenthttps://en.wikipedia.org/wiki/Mark_Felt reply encoderer 4 hours agorootparentprevhttps://www.history.com/news/watergate-deep-throat-fbi-infor... reply sema4hacker 17 hours agoprevAre all of the digital fingerprints created by Satoshi (emails and posted code) completely untraceable, with no archives of domains, IP addresses, access logs, etc., still in existence that might identify where he was logging in from? reply greyface- 12 hours agoparentThere is some evidence pointing to a Covad IP address in Los Angeles: https://news.ycombinator.com/item?id=29728339 reply dogman144 17 hours agoparentprevLast I read the domain registration for Bitcoin.org (I think) is the main exposure point. But, what you raised is why I don’t buy they haven’t been ID’d. Digital fingerprints across multiple forums, and platforms, the logs to find a way in are there somewhere. I figure it is Len Sassaman. reply bottlepalm 16 hours agorootparentLen was a Linux guy, Satoshi was not. There's even an email here that says just that, \"technically much more linux capable than me.\" https://mmalmi.github.io/satoshi/#email-241 reply dogman144 16 hours agorootparentI think you’d have to factor in Satoshi’s opsec measures though vs taking them at their word at being bad at Linux, consider SN displayed very capable opsec in other forums. Len had significant time and topic correlations to many/basically all iirc of the feeder research and projects that clearly fed into BTC. SN also went offline around the time Len passed. Those two factors plus the related details sealed it for me. Edit - like if I was known to research under Szabo and Finney (iirc) right around the same time BTC launched, was known to advocate to peers to launch controversial open source under pseudonyms, and so on, I’d probably wrap my public persona under “BTC sucks” and my SN persona under “idk linux well,” and so on. Seems an obvious step to take. reply optimalsolver 16 hours agorootparentBut that just makes your theory unfalsifiable and uninteresting. For every contradiction you can just say \"That's what he wanted you to think!\" reply dogman144 15 hours agorootparentRight, it obviously spirals into this issue and others like it. reply asveikau 16 hours agorootparentprevI don't think you can fake being blind to unix style when writing c++. The c++ style that grew out of the windows world is kind of unique. (Although I personally am both a longtime enthusiast of unix-like OSes and a former MS employee, so I am familiar with both ... But I find that to be kind of rare.) reply ziddoap 15 hours agorootparentprev>I think you’d have to factor in Satoshi’s opsec measures though Lying about trivial and mundane stuff is a wildly hard thing to maintain over any period of time and, for long-term opsec, more likely to cause issues than not. Being \"linux capable\" or not is mundane and vague enough (as well as applicable to enough people) that there isn't really any gain in lying about it but it adds risk in the case that you slip up in your maintaining of that lie 10 years down the road. There are much more effective ways to resist being identified, which are also easier to maintain long-term. reply dogman144 15 hours agorootparentWell, a lot of other effective things were done as well as you say. For me, comes down to that I disagree that the creator of one of the most consequential tech break through that hits at the core of national sovereignty and control didn’t think of a lot of angles to this. Early Cypherpunks, of which SN was certainly one, were a pretty insane/intense crew in these areas. And to your point about the difficulty of maintaining trivial deceptions long term, well Len passed pretty soon after the initial years. reply ziddoap 15 hours agorootparent>didn’t think of a lot of angles to this. I'm not saying it wasn't thought about. If anything, I'm saying the opposite. When you think about it long enough, you realize that many of the 'little lies' carry more risk than they are worth. Lying about being \"linux capable\" falls into that category. >And to your point about the difficulty of maintaining trivial deceptions long term, well Len passed pretty soon after the initial years. I was speaking more generally about opsec and lies which aren't worth the trouble and increased risk. Specific to your comment: If Len knew they would die soon after, there is less incentive to lie about little things like linux capability. If they didn't know they would die soon after, they would care about the long-term opsec. reply dogman144 14 hours agorootparentAll interesting points. I think I disagree with the last part due to my original post - nobody knew how this would turn out, but those involved knew projects like this consistently attracted serious State attention. B/t protect the protocol by trying every possible angle against this sort of “adversary” (which, here in 2024, seems to have worked), versus cutting corners, the comprehensive nature of SN’s opsec seems to imply it’d show up in a lot of small ways like lying about Linux. Analysis of the codebase also had similar findings about attention to detail (“thought of everything” sort of difficulty regarding appsec). Overall, there’s a good write up on Len as SN worth digging into if the topic is interesting. I also think the ‘11 New Yorker piece got close to the truth. reply ziddoap 13 hours agorootparent>versus cutting corners, the comprehensive nature of SN’s opsec seems to imply it’d show up in a lot of small ways like lying about Linux. I'm not sure if I'm explaining myself poorly, or if we're maybe just speaking past each other, or I'm not understanding you. You're saying that not lying about linux capability would be \"cutting corners\". I'm saying that not lying (in this specific situation) would be the better opsec, and that anyone serious about opsec against government-level adversaries would not bother lying about such a mundane detail because it is all risk with no benefit to opsec. This concept was taught to me at a previous job where the adversaries were of the same magnitude as governments, and I'm confident that anyone seriously into the opsec/prviacy \"scene\" would concur. Satoshi was, obviously, careful about opsec. Therefor I do not think they would lie about such a trivial and vague detail such as saying someone else is more linux capable than they are, because it would be a risk to lie about it compared to not lying. reply AlexAndScripts 10 hours agorootparentI presume you won't say, but now I'm wondering about who has similar intelligence capabilities to governments... reply bottlepalm 16 hours agorootparentprevHave you considered Le Roux? Someone who had a real motive to create Bitcoin, and who had actually written Windows based crypto software before. reply ClickedUp 13 hours agorootparentInterestingly, Le Roux added \"Solotshi\" to his name on his 2008 passport: https://i.imgur.com/44I9wlL.jpeg Solotshi/Satoshi. reply IncreasePosts 16 hours agorootparentprevGiven his past it's hard to imagine Le Roux sitting on hundreds of billions of dollars worth of bitcoins, even from inside a federal prison. reply astoor 15 hours agorootparentGiven his past it is easy to imagine his keys got misplaced while on the run or met with some kind of \"unfortunate accident\". reply bottlepalm 16 hours agorootparentprevPretty good incentive to say nothing isn't it? reply dogman144 15 hours agorootparentprevI’ve read the various write ups, and iirc the New Yorker piece and who/the group they pointed and a write up on Len seemed to make the most sense. Fun area, been a while since I dug into it. reply bottlepalm 14 hours agorootparentVery few projects are created truly anonymously. I believe the Bitcoin creator had a real motive to stay anonymous, and a practical use case that was driving him to make Bitcoin eg transferring large amounts of illegitimate wealth internationally and outside of the banking system. reply dogman144 12 hours agorootparentthere’s pretty clear documentation on the motivations for why it was made, but I suppose it could be duplicitous and hard to ever verify one way or the other unless SN wallets became active again. reply ak_111 12 hours agorootparentprevI know it sounds utterly morbid, but has anyone proposed the conspiracy that Len was \"suicided\" after his identity was identified by a very shady -- possibly state-backed -- actors . This guy was a walking bag of cash at that point and people have been killed for far less. reply subsubzero 16 hours agorootparentprevyup, agree, also looking how Len writes, he is definitely not Satoshi. You can see on his twitter(Len) - https://twitter.com/lensassaman that he is quite punctual, ie. sentences end with periods, quotation is accurate. What gives it away is every sentence he writes on twitter is one space after the period, Satoshi is 2 spaces every single time. Also seeing the same thing for Hal Finney(https://twitter.com/halfin), so my deduction is neither of them is Satoshi. reply alisonatwork 15 hours agorootparentPINE (the mail client) had a ^J keyboard shortcut to justify the lines. It's been a long time since I used it, but I seem to recall that it would insert double space after period when you hit that key. It might even have been possible to set it up to auto justify on save/send. I suspect that's why a lot of old (plain text) email had the double space after period and perhaps still does in OSS circles. I think the default vim justification worked that way too. Around this time I went through a phase of bloody-mindedly using Mail/mailx and vi on OpenBSD while still sending mail through my ISP's SMTP and using fetchmail to grab it through POP3. I would not at all be surprised if cypherpunk types were doing the same thing, even if their main desktop or laptop was Windows and they used single space after period for non-email communication. Edit to add: I just looked up fmt(1) manpage[0] and it specifically mentions using it to format mails, and that the default is two space after period. [0] https://man.openbsd.org/fmt.1 reply someplaceguy 15 hours agorootparentThe bitcoin whitepaper was written in OpenOffice and it also has double spaces after periods, which doesn't fit your theory. reply alisonatwork 14 hours agorootparentI don't really have a theory, just sharing my experience growing up being taught to use two spaces, then in the early 2000s consciously adjusting my writing style back to one space, then having my plaintext emails still end up with two spaces anyway. It's interesting that a document written in a WYSIWYG word processor would have two spaces because I think what originally got me to switch to one was word processor auto corrects removing the extra space, or at least putting blue squigglies in during the grammar check. I guess my feeling is that although this might be an indicator of authorship, it's not necessarily a smoking gun one way or the other. reply dogman144 15 hours agorootparentprevThere’s a great write up on Len that digs into this style of analysis and others, and that’s what sold me. Worth reading if it the topic interests you, it’s linked elsewhere here I think! Lots of fun spacing, timezone to forum posts analysis, who worked and researched with who… reply stavros 15 hours agorootparentprevHal's personal site has two spaces after a period. reply subsubzero 15 hours agorootparentI see one space - https://web.archive.org/web/20140403012916/http://www.finney... EDIT - really interesting, could very well be Hal, every sentence after a period ends with 2 spaces - view-source:https://web.archive.org/web/20140403012916/http://www.finney... reply stavros 15 hours agorootparentView source. reply BlueTemplar 15 hours agorootparentWait, what causes this kind of replacement ?? reply stavros 15 hours agorootparentHTML considers whitespace insignificant. reply mortallywounded 16 hours agorootparentprevLen was a Macbook user, but he would not have done Bitcoin on his personal laptop. It's much more likely he used available PCs in a computer lab on the campus he studied/worked at, which were likely Windows machines. It's also been shown Satoshi (and Len's) activities aligned and they overlapped with a school/academic year. reply mortallywounded 16 hours agorootparentHere's Len's macbook as proof: https://www.flickr.com/photos/enochsmiles/449655745/ Fun fact, he was experimenting with email based image uploads on flickr. That was around the time Satoshi suggested they build an image hosting site that accepts Bitcoin. It's not a leap to assume Len's brain made the following cypherpunk leaps: remailer (anonymous email) -> image upload by email -> pay via semi-anonymous crypto currency Len's own bio says, \"I have a very strong interest in the real-world applicability of my work.\" reply Geee 16 hours agorootparentprevAlso, see https://twitter.com/lensassaman/status/77358901774917632 where Len doesn't seem to be a fan of Bitcoin. Not sure what he means by that though. reply mortallywounded 16 hours agorootparentSatoshi stepped away from Bitcoin in 2010 and handed over the project to the maintainers. Len started posting about Bitcoin in 2010 (post Satoshi handing the project over). It seems to me, if Len was Satoshi, he grew distant from the project. Maybe it wasn't the cypherpunk utopia he envisioned. Maybe the wikileaks and silkroad issues weren't what he wanted to enable. Perhaps he wanted to distance himself further from the project. reply tdudhhu 15 hours agorootparentHe was also depressed at that time. reply dogman144 15 hours agorootparentMy understanding is around the time SN left correlated to around the time Len’s mental health escalated. That noted, RIP/don’t mean to crassly speculate about what sounded like a talented and difficult life. reply layer8 16 hours agorootparentprevMeredith Patterson might know, then. reply Hamuko 1 hour agoparentprevTimezone-wise it'd make the most sense if he was somewhere in the US, since he almost never posted between 05:00 and 11:00 GMT. That'd be between 00:00 and 06:00 New York time. reply WhereIsTheTruth 16 hours agoparentprevJust trace its usecases, it leads to both EU/FED exploring a digital fiat and a digital passport, must be someone who has worked with the government My theory: the CIA/NSA reply 1970-01-01 11 hours agoprevIs there a website listing people that Satoshi definitely could not be? That it seems would be more useful to our evergreen \"Who is Satoshi\" discussions. reply bcrosby95 8 hours agoparentAdd me to the list of \"definitely not Satoshi\". Just a few billion more to go. reply qingcharles 7 hours agorootparentNice try, Satoshi. reply aqfamnzc 11 hours agoparentprevHow would we really rule anyone out? reply esquivalience 10 hours agorootparentin the case of Craig Wright - Bring a multimillion dollar court case to prove it. reply noman-land 17 hours agoprevSatoshi double spaces after periods. reply stavros 15 hours agoparentI heard that Satoshi was Hal Finney (from a good friend of Hal's). Looking at his personal site, guess how many spaces there are after a period: https://web.archive.org/web/20140403012916/http://www.finney... reply dontupvoteme 14 hours agorootparentI think it's a fair bet that Satoshi is either dead, insane, or the government. Finney checks the most likely one. reply neom 13 hours agorootparentThe government is a new (but fun) one for me! What's the theory there? reply mrinfinite 6 hours agorootparentSatoshi Nakamoto translates directly unquestionably into: Central Intelligence... Freedom Baby.. Bitcoin!!! Digital money!! iphones! reply dontupvoteme 12 hours agorootparentprevIt's a mechanism by which the CIA(or others!) could pay operatives covertly. I'm pretty sure i read this like a decade ago, but to me it makes sense. Especially given that numbers stations apparently blared out orders into the late 1900s. reply maipen 12 hours agorootparentNever made sense to me. Bitcoin is open. Cash is private and anonymous. If monero was the first currency to come out I would’ve considered that. reply geraldwhen 9 hours agorootparentprevThe writing style matches the emails as well. reply jablongo 15 hours agorootparentprevOn this website there are single spaces following periods. reply elaus 15 hours agorootparentWhen HTML is rendered, multiple normal white space characters collapse into one, e.g. if you write \"Hello it's me\" it will be displayed in a browser as \"Hello it's me\". The source code tells the whole truth. reply bcrosby95 8 hours agorootparentThis is why back in the '00s my boss forced us to put a space and an \" \" after every period. Ugh. reply aqfamnzc 11 hours agorootparentprevHaha, HN seems to have removed your demo whitespace. (Even in the source) reply stavros 15 hours agorootparentprevView source. reply joshumax 10 hours agoparentprevYeah, I've always been surprised[1] when people come out claiming to be Satoshi but ignore this very blatant writing style in their own texts. I haven't really interacted that much with them online and both the double spaces and the British spellings struck out to me and a few others years ago. 1: https://news.ycombinator.com/item?id=15917598#15919288 reply chrisoconnell 17 hours agoparentprevThe real analysis is here. reply dboreham 17 hours agoparentprevMust be American then. reply raid2000 17 hours agorootparentOr just above the age of 35 or so? reply hansvm 16 hours agorootparentOr if their typing instructor grew up around that time. reply dboreham 10 hours agorootparentprevYou mean 135? The double space thing doesn't exist in the UK. reply BlackjackCF 16 hours agorootparentprevI thought the double spacing was a typewriter thing. Is it uniquely American? reply seanhunter 16 hours agorootparentIt is not. I learned to do it because old-school unix vi would identify your sentences better for sentence-based moves if you had 2 spaces after the period. I'm actually trying to unlearn it now because you don't need it for any kind of vim/neovim and I read on some ultrapedantic typesetting website that it's wrong for some reason I don't quite remember now. In any case it's definitely not specifically American (neither am I) and all the other \"forensics\" that people are trying based on vocab etc are somewhat of a stretch also. eg non-Americans use \"gotten\" non British people use \"British\" English (eg people from Ireland or from former British colonies for the most part) non-Americans use \"ize\" sometimes for spellings (I could never be bothered to learn the few exceptions needed to spell \"ize/ise\" words correctly in the British style and worked enough for American companies who wanted US spelling as a house style for my personal spelling to be even remotely consistent and certainly not indicative of where I am from. reply seabass-labrax 16 hours agorootparentAs a British person, despite having been taught that the '-ise' suffix is 'proper' English, I have made some effort to unlearn this habit, as it was never really based on any etymological roots anyway. Here's what Wiktionary has to say about it[1]: Many English verbs end in the suffix /aɪz/. Historically, this has been spelled -ize on words originating from Greek (for example baptize, Hellenize), while -ise has been used, especially in -vise, -tise, -cise and -prise, on words that came from French or Latin roots (for example surprise, supervise). In the 19th century, it became common in the United Kingdom (due to French influence)... to use -ise also on words that had historically been spelled -ize (hence baptise, Hellenise). However, the... Oxford English Dictionary continue to use the spelling -ize on Greek words, and -ize has always been the spelling used in the United States and Canada on such words. The whole debate becomes rather moot when it is considered that Ancient Greek didn't use the Latin script, so both '-ize' or '-ise' would have looked distinctly foreign to a Greek author two thousand years ago. Horace so succinctly noted that \"Captive Greece took captive her savage conqueror and brought civilisation to barbarous Latium\", but he might have been a little less glowing if the orthography of Greek loanwords was as heated a debate in Rome as it is in contemporary Britain! [1]: https://en.wiktionary.org/wiki/-ize reply seanhunter 16 hours agorootparentprevI must also be American in that case. (Hint: I'm not). reply jinwoo68 16 hours agorootparentprevIt might be just that he uses Emacs for writing emails. Emacs uses double space after periods by default. reply sokoloff 16 hours agorootparentEmacs uses the presence of double spaces after periods as a marker that that particular sequence of text is the end of a sentence. It doesn't insert them by default, but rather interprets their insertion in a particular way. See: sentence-end-double-space, a variable, and sentence-end, a function, both defined in ‘paragraphs.el’. Other editors made this same interpretation of existing, common practice. reply Mistletoe 16 hours agorootparentprevExactly how we learned to do in keyboarding class. It’s still with me after all these years. reply RajT88 16 hours agorootparentprevnext [10 more] My wife double spaces after periods, and although she is a US citizen, she is not a product of the American education system. My wife is Satoshi Nakamoto. reply bombcar 16 hours agorootparentNow I'm sensing a whole \"I am Spartacus\" thing happening. reply DrBazza 16 hours agorootparentI’m Satoshi and so is my wife. I didn’t think double spaces after a full stop is an American thing. We were taught that in the 70s back when typewriters were still a thing. And I can’t break the habit today. reply bombcar 16 hours agorootparentI've seen it from various people from various backgrounds. The biggest commonality is age (typewriters) but I've seen it from youngsters, too. I split the difference as my typing grew up with LaTeX so I want a slightly larger space after a period, but I don't care to type it ;) reply RajT88 15 hours agorootparentI was taught typing on electric typewriters in junior high, and yes 2 spaces after a period. Which is strange, because my first typing experience was on Apple IIe's in grade school. I don't recall any typing instruction back then, so probably my double space habit comes from the electric typewriter instruction. reply bombcar 15 hours agorootparentThe \"double space\" for typewriters comes from style guides based on typesetting which was based on limitations of the type used in the ancient days. There's much argument over whether it is proper or not, and if so, how much. See The Elements of Typographic Style or A Few Notes on Book Design - https://mirror.math.princeton.edu/pub/CTAN/info/memdesign/me... reply ramses0 14 hours agorootparentDr.[space]Pepper is a soft drink.[space][space]This is a new sentence. Actually, \"Dr Pepper\" doesn't use a period so the point is void, but there's definitely some potential semantic (and display) differences between the periods in (eg) N.A.S.A. and the periods at end of a sentence. Not quite as straightforward as you might think. reply bombcar 14 hours agorootparentThe books go into it, and LaTeX has \\. for periods that are not sentence-stops (there's even more, as word-breaking and line-breaking come into play, as you don't want to end a line with Dr. when it's part of a name, etc. reply RajT88 14 hours agorootparentprevThere is an inside joke here as well. I regularly accuse my wife of being Satoshi Nakamoto. reply BlueTemplar 15 hours agorootparentprevMy wife is Satoshi too ! insert two spaced salute reply 95 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Email exchanges between Martti Malmi (Sirius) and Satoshi Nakamoto from 2009-2011 highlight Bitcoin development, addressing topics like website development, server-side scripting, and node operation.",
      "Martti proposes creating a website and FAQ with secured private keys, while Satoshi seeks assistance with website content and server scripting.",
      "The correspondence delves into issues like blocks, transactions, scalability, proof of work, spam, feature enhancements, website improvements, Bitcoin exchange service setup, and software upgrades."
    ],
    "commentSummary": [
      "The discussion covers the mysterious identity of Satoshi Nakamoto, the mind behind Bitcoin, touching on speculation about motives, government connections, and the consequences of revealing Satoshi's identity.",
      "Various topics include anonymity, privacy features in cryptocurrencies like Monero, Central Bank Digital Currencies, cryptocurrency mining, opsec in critical situations, and linguistic analysis for authorship verification.",
      "It emphasizes the significance of honesty, operational security (opsec), and the risks associated with creating and managing a groundbreaking project like Bitcoin."
    ],
    "points": 379,
    "commentCount": 376,
    "retryCount": 0,
    "time": 1708695476
  },
  {
    "id": 39481554,
    "title": "Gemma.cpp: Lightweight Inference Engine for Gemma Models",
    "originLink": "https://github.com/google/gemma.cpp",
    "originBody": "gemma.cpp gemma.cpp is a lightweight, standalone C++ inference engine for the Gemma foundation models from Google. For additional information about Gemma, see ai.google.dev/gemma. Model weights, including gemma.cpp specific artifacts, are available on kaggle. Who is this project for? Modern LLM inference engines are sophisticated systems, often with bespoke capabilities extending beyond traditional neural network runtimes. With this comes opportunities for research and innovation through co-design of high level algorithms and low-level computation. However, there is a gap between deployment-oriented C++ inference runtimes, which are not designed for experimentation, and Python-centric ML research frameworks, which abstract away low-level computation through compilation. gemma.cpp provides a minimalist implementation of Gemma 2B and 7B models, focusing on simplicity and directness rather than full generality. This is inspired by vertically-integrated model implementations such as ggml, llama.c, and llama.rs. gemma.cpp targets experimentation and research use cases. It is intended to be straightforward to embed in other projects with minimal dependencies and also easily modifiable with a small ~2K LoC core implementation (along with ~4K LoC of supporting utilities). We use the Google Highway Library to take advantage of portable SIMD for CPU inference. For production-oriented edge deployments we recommend standard deployment pathways using Python frameworks like JAX, Keras, PyTorch, and Transformers (all model variations here). Community contributions large and small are welcome. This project follows Google's Open Source Community Guidelines. Active development is currently done on the dev branch. Please open pull requests targeting dev branch instead of main, which is intended to be more stable. Quick Start System requirements Before starting, you should have installed: CMake Clang C++ compiler, supporting at least C++17. tar for extracting archives from Kaggle. Step 1: Obtain model weights and tokenizer from Kaggle Visit the Gemma model page on Kaggle and select Model Variations |> Gemma C++. On this tab, the Variation dropdown includes the options below. Note bfloat16 weights are higher fidelity, while 8-bit switched floating point weights enable faster inference. In general, we recommend starting with the -sfp checkpoints. 2B instruction-tuned (it) and pre-trained (pt) models: Model name Description 2b-it 2 billion parameter instruction-tuned model, bfloat16 2b-it-sfp 2 billion parameter instruction-tuned model, 8-bit switched floating point 2b-pt 2 billion parameter pre-trained model, bfloat16 2b-pt-sfp 2 billion parameter pre-trained model, 8-bit switched floating point 7B instruction-tuned (it) and pre-trained (pt) models: Model name Description 7b-it 7 billion parameter instruction-tuned model, bfloat16 7b-it-sfp 7 billion parameter instruction-tuned model, 8-bit switched floating point 7b-pt 7 billion parameter pre-trained model, bfloat16 7b-pt-sfp 7 billion parameter pre-trained model, 8-bit switched floating point Note Important: We strongly recommend starting off with the 2b-it-sfp model to get up and running. Step 2: Extract Files After filling out the consent form, the download should proceed to retrieve a tar archive file archive.tar.gz. Extract files from archive.tar.gz (this can take a few minutes): tar -xf archive.tar.gz This should produce a file containing model weights such as 2b-it-sfp.sbs and a tokenizer file (tokenizer.spm). You may want to move these files to a convenient directory location (e.g. the build/ directory in this repo). Step 3: Build The build system uses CMake. To build the gemma inference runtime, create a build directory and generate the build files using cmake from the top-level project directory. For the 8-bit switched floating point weights (sfp), run cmake with no options: cmake -B build or if you downloaded bfloat16 weights (any model without -sfp in the name), instead of running cmake with no options as above, run cmake with WEIGHT_TYPE set to highway's hwy::bfloat16_t type (this will be simplified in the future, we recommend using -sfp weights instead of bfloat16 for faster inference): cmake -B build -DWEIGHT_TYPE=hwy::bfloat16_t After running whichever of the above cmake invocations that is appropriate for your weights, you can enter the build/ directory and run make to build the ./gemma executable: cd build make -j [number of parallel threads to use] gemma Replace [number of parallel threads to use] with a number - the number of cores available on your system is a reasonable heuristic. For example, make -j4 gemma will build using 4 threads. If this is successful, you should now have a gemma executable in the build/ directory. If the nproc command is available, you can use make -j$(nproc) gemma as a reasonable default for the number of threads. If you aren't sure of the right value for the -j flag, you can simply run make gemma instead and it should still build the ./gemma executable. Note On Windows Subsystem for Linux (WSL) users should set the number of parallel threads to 1. Using a larger number may result in errors. Step 4: Run You can now run gemma from inside the build/ directory. gemma has the following required arguments: Argument Description Example value --model The model type. 2b-it, 2b-pt, 7b-it, 7b-pt, ... (see above) --compressed_weights The compressed weights file. 2b-it-sfp.sbs, ... (see above) --tokenizer The tokenizer file. tokenizer.spm gemma is invoked as: ./gemma \\ --tokenizer [tokenizer file] \\ --compressed_weights [compressed weights file] \\ --model [2b-it or 2b-pt or 7b-it or 7b-pt or ...] Example invocation for the following configuration: Compressed weights file 2b-it-sfp.sbs (2B instruction-tuned model, 8-bit switched floating point). Tokenizer file tokenizer.spm. ./gemma \\ --tokenizer tokenizer.spm \\ --compressed_weights 2b-it-sfp.sbs \\ --model 2b-it Troubleshooting and FAQs Running ./gemma fails with \"Failed to read cache gating_ein_0 (error 294) ...\" The most common problem is that cmake was built with the wrong weight type and gemma is attempting to load bfloat16 weights (2b-it, 2b-pt, 7b-it, 7b-pt) using the default switched floating point (sfp) or vice versa. Revisit step #3 and check that the cmake command used to build gemma was correct for the weights that you downloaded. In the future we will handle model format handling from compile time to runtime to simplify this. Problems building in Windows / Visual Studio Currently if you're using Windows, we recommend building in WSL (Windows Subsystem for Linux). We are exploring options to enable other build configurations, see issues for active discussion. Model does not respond to instructions and produces strange output A common issue is that you are using a pre-trained model, which is not instruction-tuned and thus does not respond to instructions. Make sure you are using an instruction-tuned model (2b-it-sfp, 2b-it, 7b-it-sfp, 7b-it) and not a pre-trained model (any model with a -pt suffix). How do I convert my fine-tune to a .sbs compressed model file? We're working on a python script to convert a standard model format to .sbs, and hope have it available in the next week or so. Follow this issue for updates. Usage gemma has different usage modes, controlled by the verbosity flag. All usage modes are currently interactive, triggering text generation upon newline input. Verbosity Usage mode Details --verbosity 0 Minimal Only prints generation output. Suitable as a CLI tool. --verbosity 1 Default Standard user-facing terminal UI. --verbosity 2 Detailed Shows additional developer and debug info. Interactive Terminal App By default, verbosity is set to 1, bringing up a terminal-based interactive interface when gemma is invoked: $ ./gemma [...] __ _ ___ _ __ ___ _ __ ___ __ _ ___ _ __ _ __ / _` |/ _ \\ '_ ` _ \\| '_ ` _ \\ / _`/ __| '_ \\| '_ \\(_|__/||||| (_| || (__| |_)|_)\\__, |\\___|_| |_| |_|_| |_| |_|\\__,_(_)___| .__/| .__/ __/ ||||___/|_| |_| tokenizer : tokenizer.spm compressed_weights : 2b-it-sfp.sbs model : 2b-it weights : [no path specified] max_tokens : 3072 max_generated_tokens : 2048 *Usage* Enter an instruction and press enter (%Q quits). *Examples* - Write an email to grandma thanking her for the cookies. - What are some historical attractions to visit around Massachusetts? - Compute the nth fibonacci number in javascript. - Write a standup comedy bit about WebGPU programming. > What are some outdoorsy places to visit around Boston? [ Reading prompt ] ..................... **Boston Harbor and Islands:** * **Boston Harbor Islands National and State Park:** Explore pristine beaches, wildlife, and maritime history. * **Charles River Esplanade:** Enjoy scenic views of the harbor and city skyline. * **Boston Harbor Cruise Company:** Take a relaxing harbor cruise and admire the city from a different perspective. * **Seaport Village:** Visit a charming waterfront area with shops, restaurants, and a seaport museum. **Forest and Nature:** * **Forest Park:** Hike through a scenic forest with diverse wildlife. * **Quabbin Reservoir:** Enjoy boating, fishing, and hiking in a scenic setting. * **Mount Forest:** Explore a mountain with breathtaking views of the city and surrounding landscape. ... Usage as a Command Line Tool For using the gemma executable as a command line tool, it may be useful to create an alias for gemma.cpp with arguments fully specified: alias gemma2b=\"~/gemma.cpp/build/gemma -- --tokenizer ~/gemma.cpp/build/tokenizer.spm --compressed_weights ~/gemma.cpp/build/2b-it-sfp.sbs --model 2b-it --verbosity 0\" Replace the above paths with your own paths to the model and tokenizer paths from the download. Here is an example of prompting gemma with a truncated input file (using a gemma2b alias like defined above): cat configs.htail -35tr '' ' 'xargs -0 echo \"What does this C++ code do: \"gemma2b Note CLI usage of gemma.cpp is experimental and should take context length limitations into account. The output of the above command should look like: $ cat configs.htail -35tr '' ' 'xargs -0 echo \"What does this C++ code do: \"gemma2b [ Reading prompt ] ...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... The code defines two C++ structs, `ConfigGemma7B` and `ConfigGemma2B`, which are used for configuring a deep learning model. **ConfigGemma7B**: * `seq_len`: Stores the length of the sequence to be processed. It's set to 7168. * `vocab_size`: Stores the size of the vocabulary, which is 256128. * `n_layers`: Number of layers in the deep learning model. It's set to 28. * `dim_model`: Dimension of the model's internal representation. It's set to 3072. * `dim_ffw_hidden`: Dimension of the feedforward and recurrent layers' hidden representations. It's set to 16 * 3072 / 2. **ConfigGemma2B**: * `seq_len`: Stores the length of the sequence to be processed. It's also set to 7168. * `vocab_size`: Size of the vocabulary, which is 256128. * `n_layers`: Number of layers in the deep learning model. It's set to 18. * `dim_model`: Dimension of the model's internal representation. It's set to 2048. * `dim_ffw_hidden`: Dimension of the feedforward and recurrent layers' hidden representations. It's set to 16 * 2048 / 2. These structs are used to configure a deep learning model with specific parameters for either Gemma7B or Gemma2B architecture. Incorporating gemma.cpp as a Library in your Project The easiest way to incorporate gemma.cpp in your own project is to pull in gemma.cpp and dependencies using FetchContent. You can add the following to your CMakeLists.txt: include(FetchContent) FetchContent_Declare(sentencepiece GIT_REPOSITORY https://github.com/google/sentencepiece GIT_TAG 53de76561cfc149d3c01037f0595669ad32a5e7c) FetchContent_MakeAvailable(sentencepiece) FetchContent_Declare(gemma GIT_REPOSITORY https://github.com/google/gemma.cpp GIT_TAG origin/main) FetchContent_MakeAvailable(gemma) FetchContent_Declare(highway GIT_REPOSITORY https://github.com/google/highway.git GIT_TAG da250571a45826b21eebbddc1e50d0c1137dee5f) FetchContent_MakeAvailable(highway) Note for the gemma.cpp GIT_TAG, you may replace origin/main for a specific commit hash if you would like to pin the library version. After your executable is defined (substitute your executable name for [Executable Name] below): target_link_libraries([Executable Name] libgemma hwy hwy_contrib sentencepiece) FetchContent_GetProperties(gemma) FetchContent_GetProperties(sentencepiece) target_include_directories([Executable Name] PRIVATE ${gemma_SOURCE_DIR}) target_include_directories([Executable Name] PRIVATE ${sentencepiece_SOURCE_DIR}) Building gemma.cpp as a Library gemma.cpp can also be used as a library dependency in your own project. The shared library artifact can be built by modifying the make invocation to build the libgemma target instead of gemma. Note If you are using gemma.cpp in your own project with the FetchContent steps in the previous section, building the library is done automatically by cmake and this section can be skipped. First, run cmake: cmake -B build Then, run make with the libgemma target: cd build make -j [number of parallel threads to use] libgemma If this is successful, you should now have a libgemma library file in the build/ directory. On Unix platforms, the filename is libgemma.a. Acknowledgements and Contacts gemma.cpp was started in fall 2023 by Austin Huang and Jan Wassenberg, and subsequently released February 2024 thanks to contributions from Phil Culliton, Paul Chang, and Dan Zheng. This is not an officially supported Google product.",
    "commentLink": "https://news.ycombinator.com/item?id=39481554",
    "commentBody": "Gemma.cpp: lightweight, standalone C++ inference engine for Gemma models (github.com/google)378 points by mfiguiere 18 hours agohidepastfavorite127 comments austinvhuang 18 hours agoHi, one of the authors austin here. Happy to answer any questions the best I can. To get a few common questions out of the way: - This is separate / independent of llama.cpp / ggml. I'm a big fan of that project and it was an inspiration (we say as much in the README). I've been a big advocate of gguf + llama.cpp support for gemma and am happy for people to use that. - how is it different than inference runtime X? gemma.cpp is a direct implementation of gemma, in its current form it's aimed at experimentation + research and portability + easy modifiable rather than a general purpose deployment framework. - this initial implementation is cpu simd centric. we're exploring options for portable gpu support but the cool thing is it will build and run on a lot of environments you might not expect an llm to run, so long as you have the memory to load the model. - I'll let other colleagues answer questions about the Gemma model itself, this is a C++ implementation of the model, but relatively independent of the model training process. - Although this is from Google, we're a very small team that wanted such a codebase to exist. We have lots of plans to use it ourselves and we hope other people like it and find it useful. - I wrote a twitter thread on this project here: https://twitter.com/austinvhuang/status/1760375890448429459 reply leminimal 16 hours agoparentKudos on your release! I know this was just made available but - Somewhere the README, consider adding the need for a `-DWEIGHT_TYPE=hwy::bfloat16_t` flag for non-sfp. Maybe around step 3. - The README should explicitly say somehere that there's no GPU support (at the moment) - \"Failed to read cache gating_ein_0 (error 294)\" is pretty obscure. I think even \"(error at line number 294)\" would be a big improvement when it fails to FindKey. - There's something odd about the 2b vs 7b model. The 2b will claim its trained by Google but the 7b won't. Were these trained on the same data? - Are the .sbs weights the same weights as the GGUF? I'm getting different answers compared to llama.cpp. Do you know of a good way to compare the two? Any way to make both deterministic? Or even dump probability distributions on the first (or any) token to compare? reply austinvhuang 16 hours agorootparentYes - thanks for pointing that out. The README is being updated, you can see an updated WIP in the dev branch: https://github.com/google/gemma.cpp/tree/dev?tab=readme-ov-f... and improving error messages is a high priority. The weights should be the same across formats, but it's easy for differences to arise due to quantization and/or subtle implementation differences. Minor implementation differences has been a pain point in the ML ecosystem for a while (w/ IRs, onnx, python vs. runtime, etc.), but hopefully the differences aren't too significant (if they are, it's a bug in one of the implementations). There were quantization fixes like https://twitter.com/ggerganov/status/1760418864418934922 and other patches happening, but it may take a few days for patches to work their way through the ecosystem. reply beoberha 17 hours agoparentprev> Although this is from Google, we're a very small team that wanted such a codebase to exist. We have lots of plans to use it ourselves and we hope other people like it and find it useful. This is really cool, Austin. Kudos to your team! reply austinvhuang 17 hours agorootparentThanks so much! Everyone working on this self-selected into contributing, so I think of it less as my team than ... a team? Specifically want to call out: Jan Wassenberg (author of https://github.com/google/highway) and I started gemma.cpp as a small project just a few months ago + Phil Culliton, Dan Zheng, and Paul Chang + of course the GDM Gemma team. reply trisfromgoogle 14 hours agorootparentHuge +1, this has definitely been a self-forming collective of people who love great AI, great research, and the open community. Austin and Jan are truly amazing. The optimization work is genuinely outstanding; I get incredible CPU performance on Gemma.cpp for inference. Thanks for all of the awesomeness, Austin =) reply rgbrgb 17 hours agoparentprevThanks for releasing this! What is your use case for this rather than llama.cpp? For the on-device AI stuff I mostly do, llama.cpp is better because of GPU/metal offloading. reply austinvhuang 17 hours agorootparentllama.cpp is great, if it fit your needs you can use it. I think at this point llama.cpp is effectively a platform that's hardened for production. In its current form, I think of gemma.cpp is more of a direct model implementation (somewhere between the minimalism of llama2.c and the generality of ggml). I tend to think of 3 modes of usage: - hacking on inference internals - there's very little indirection, no IRs, the model is just code, so if you want to add support for your own runtime support for sparsity/quantization/model compression/etc. and demo it working with gemma, there's minimal barriers to do so - implementing experimental frontends - i'll add some examples of this in the very near future. but you're free to get pretty creative with terminal UIs, code that interact with model internals like the KV cache, accepting/rejecting tokens etc. - interacting with the model locally with a small program - of course there's other options for this but hopefully this is one way to play with gemma w/ minimal fuss. reply dartharva 17 hours agoparentprevSo... llamafile release? https://github.com/Mozilla-Ocho/llamafile reply austinvhuang 17 hours agorootparentgguf files are out there, so anyone should be able to do this! are people looking for an \"official\" version? ps i'm a fan of cosmopolitan as well. reply jart 7 hours agorootparentCosmopolitan is a fan of you :-) great work on gemma.cpp. I'm really impressed with it so far. reply dankle 16 hours agoparentprevWhat's the reason to not integrate with llama.cpp instead of a separate app? In what ways this better than llama.cpp? reply austinvhuang 15 hours agorootparentOn uses, see https://news.ycombinator.com/item?id=39481554#39482302 and on llama.cpp support - https://news.ycombinator.com/item?id=39481554 Gemma support has been added to llama.cpp, and we're more than happy to see people use it there. reply freedomben 15 hours agorootparentI think on uses you meant to link to https://news.ycombinator.com/item?id=39482581 child of https://news.ycombinator.com/item?id=39481554#39482302 ? side note: imagine how gnarly those urls would be if HN used UUIDs instead of integers for IDs :-D reply verticalscaler 16 hours agoparentprevHi Austin, what say you about how the Gemma rollout was handled, issues raised, and atmosphere around the office? :) reply trisfromgoogle 14 hours agorootparentI'm not Austin, but I am Tris, the friendly neighborhood product person on Gemma. Overall, I think that the main feeling is: incredibly relieved to have had the launch go as smoothly as it has! The complexity of the launch is truly astounding: 1) Reference implementations in JAX, PyTorch, TF with Keras 3, MaxText/JAX, more... 2) Full integration at launch with HF including Transformers + optimization therein 3) TensorRT-LLM and full NVIDIA opt across the stack in partnership with that team (mentioned on the NVIDIA earnings call by Jensen, even) 4) More developer surfaces than you can shake a stick at: Kaggle, Colab, Gemma.cpp, GGUF 5) Comms landing with full coordination from Sundar + Demis + Jeff Dean, not to mention positive articles in NYT, Verge, Fortune, etc. 6) Full Google Cloud launches across several major products, including Vertex and GKE 7) Launched globally and with a permissive set of terms that enable developers to do awesome stuff Pulling that off without any major SNAFUs is a huge relief for the team. We're excited by the potential of using all of those surfaces and the launch momentum to build a lot more great things for you all =) reply kergonath 14 hours agorootparentI am not a fan of a lot of what Google does, but congratulations! That’s a massive undertaking and it is bringing the field forward. I am glad you could do this, and hope you’ll have many other successful releases. Now, I’m off playing with a new toy :) reply verticalscaler 13 hours agorootparentprevHas there been any negative articles or valid criticism at all in your opinion? =) reply trisfromgoogle 13 hours agorootparentAlways -- anything that comes with the Google name attached always attracts some negativity. There's plenty of valid criticism, most of which we hope to address in the coming weeks and months =). reply verticalscaler 13 hours agorootparentCan you without addressing just acknowledge some of it here? Specific examples? =) > not to mention positive articles in NYT, Verge, Fortune, etc. You in fact are mentioning them and only them. I was wondering if you can simply mention the negative ones. Otherwise it sort of sounded at first like its all roses. ;) reply trisfromgoogle 13 hours agorootparentI mean, many articles will have a negative cast because of the need for clicks -- e.g., the Verge's launch article is entitled \"Google Gemma: because Google doesn’t want to give away Gemini yet\" -- which I think is both an unfair characterization (given the free tier of Gemini Pro) and unnecessarily inflammatory. Legitimate criticisms include not working correctly out of the box for llama.cpp due to repetition penalty and vocab size, some snafus on chat templates with huggingface, the fact that they're not larger-sized models, etc. Lots of the issues are already fixed, and we're committed to making sure these models are great. Honestly, not sure what you're trying to get at here -- are you trying to \"gotcha\" the fact that not everything is perfect? That's true for any launch. reply Permik 9 hours agorootparentI thought that reflecting what went poorly is really informative and inspiring! It really shows how you are taking this seriously, and iterating on a great project that you're building better and better, thanks for the insight and for a peek behind the curtain reply jart 6 hours agorootparentprev> Legitimate criticisms include not working correctly out of the box for llama.cpp I don't think that's a legitimate criticism. Especially not for something that just launched. You should be helping your own project first, before you help others. For example, it'd be nice to see AVX2 work as well as AVX512 with gemma.cpp. reply cornel_io 7 hours agorootparentprevI think he's trying to bring up the racial image gen bias stuff that's going on with Gemini, but for some reason won't say it. He also doesn't appear to realize there is a difference between the two products/teams/launches... reply verticalscaler 13 hours agorootparentprevnext [8 more] [flagged] jph00 12 hours agorootparentThese comments appear to be about Gemini's image generation, IIUC. Gemma, however, is a language model -- whilst I believe that a larger unreleased version of it is used as part of the Gemini product, it doesn't seem relevant to these criticisms. Also, the Gemma base model is released, which doesn't AFAIK contain any RLHF. The impression I have is that you're using the release of Gemma to complain about tangentially related issues about Google and politics more generally. The HN guidelines warn against this: \"Eschew flamebait. Avoid generic tangents... Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something. Please don't use Hacker News for political or ideological battle.\" reply summerlight 13 hours agorootparentprevIt looks like you're trying to get some sort of \"confession\" from relevant people based on recent memes against the company? The reality is likely that the developers sincerely believe in the value of this product and are proud of its launch. You're just adding uninteresting, irrelevant noise to the discussion and you probably won't get what you want. reply trisfromgoogle 13 hours agorootparentprevNeither of those applies at all to Gemma, though? I'm still confused -- what are you trying to accomplish with this line of questioning? reply verticalscaler 12 hours agorootparentnext [5 more] [flagged] trisfromgoogle 12 hours agorootparentI've been completely honest, human-like, and non-evasive with you. I answered your questions directly and frankly. Every time, you ignored the honest and human-like answers to try and score some imaginary points. We're honestly trying our best to build open models *with* the community that you can tune and use to build neat AI research + products. Ignoring that in favor of some political narrative is really petty. reply SquareWheel 10 hours agorootparentThat user is clearly not working with the principle of charity in mind. I've flagged their comments, and would suggest disengaging with them. reply verticalscaler 11 hours agorootparentprev> not to mention positive articles in NYT, Verge, Fortune, etc. > There's plenty of valid criticism, most of which we hope to address in the coming weeks and months =). > many articles will have a negative cast because of the need for clicks This simply comes across as, at best, spin. Given what just happened with Gemini I urge you not to communicate in this style. > doesn't apply at all to Gemma That would be the crux of the matter. As a sibling comment states: > a larger unreleased version of it (Gemma) is (likely) used as part of the Gemini product There is no reason for anybody outside Google to think otherwise, these are blackboxes. > Ignoring that in favor of some political narrative is really petty. You can have assume any politics you wish, the issues with Gemini have already been acknowledged by Google along with an apology. https://blog.google/products/gemini/gemini-image-generation-... over time, the model became way more cautious than we intended and refused to answer certain prompts entirely — wrongly interpreting some very anodyne prompts as sensitive. There is no information for me or anybody else to go on that your Gemma models are not nerfed - whether maliciously or accidentally nerfed - is immaterial. Instead of addressing that you and you alone eventually brought it back to politics. > We're honestly trying our best to build open models with the community Amongst other things this requires much more trust and transparency and an altogether different communication style. reply wokwokwok 6 hours agorootparentLet it go. You’re being flagged and downvoted on your threads because you’re being unreasonable, not because of some moderator level conspiracy. The argument you’re making is not falsifiable. If you want to pursue this line of argument, you need to pause, think about how you can confidently and unambiguously make substantive claims; for example, substantive examples from actually using these models. The way you’re currently arguing is not meaningful or compelling. reply moffkalast 17 hours agoparentprevCool, any plans on adding K quants, an API server and/or a python wrapper? I really doubt most people want to use it as a cpp dependency and run models at FP16. reply austinvhuang 17 hours agorootparentThere's a custom 8-bit quantization (SFP), it's what we recommend. At 16 bit, we do bfloat16 instead of fp16 thanks to https://github.com/google/highway, even on CPU. Other quants - stay tuned. python wrapper - if you want to run the model in python I feel like there's already a lot of more mature options available (see the model variations at https://www.kaggle.com/models/google/gemma) , but if people really want this and have something they want to do with a python wrapper that can't be done with existing options let me know. (similar thoughts wrt to API servers). reply moffkalast 16 hours agorootparentIn my experience there's really no reason to run any model above Q6_K, the performance is identical and you shave off almost 2 GB of VRAM of a 7B model compared to Q8. To those of us with single digit amounts, that's highly significant. But most people seem to go for 4 bits anyway and it's the AWQ standard too. If you think it'll make the model look bad, then don't worry, it's only the relative performance that matters. I would think that having an OpenAI standard compatible API would be a higher priority over a python wrapper, since then it can act as a drop in replacement for most any backend. reply austinvhuang 16 hours agorootparentA nice side effect of implementing cpu simd is you just need enough regular RAM, which tends to be far less scarce than VRAM. Nonetheless, I get your point that more aggressive quantization is valuable + will share with the modeling team. reply moffkalast 16 hours agorootparentTrue, it's the only way I can for example run Mixtral on a 8GB GPU, but main memory will always have more latency so some tradeoff tends to be worth it. And parts like the prompt batch buffer and most of the context generally have to be in VRAM if you want to use cuBLAS, with OpenBLAS it's maybe less of a problem, but it is slower. reply zoogeny 15 hours agoprevI know a lot of people chide Google for being behind OpenAI in their commercial offerings. We also dunk on them for the over-protective nature of their fine-tuning. But Google is scarily capable on the LLM front and we shouldn't count them out. OpenAI might have the advantage of being quick to move, but when the juggernaut gets passed its resting inertia and starts to gain momentum it is going to leave an impression. That became clear to me after watching the recent Jeff Dean video [1] which was posted a few days ago. The depth of institutional knowledge that is going to be unlocked inside Google is actually frightening for me to consider. I hope the continued competition on the open source front, which we can really thank Facebook and Llama for, keeps these behemoths sharing. As OpenAI moves further from its original mission into capitalizing on its technological lead, we have to remember why the original vision they had is important. So thank you, Google, for this. 1. https://www.youtube.com/watch?v=oSCRZkSQ1CE&ab_channel=RiceK... reply llm_nerd 12 hours agoparentWhile I generally agree with you, who has ever counted Google out? We've made fun of Google for lagging while they instead spend their engineering time renaming projects and performing algorithmic white-erasure, but we all knew they're a potent force. Google has as much or more computing power than anyone. They're massively capitalized and have a market cap of almost $2T and colossal cashflow, and have the ability to throw enormous resources at the problem until they have a competitor. They have an enormous, benchmark-setting amount of data across their various projects to train on. That we're talking like they're some scrappy upstart is super weird. >As OpenAI moves further from its original mission into capitalizing on its technological lead, we have to remember why the original vision they had is important. I'm way more cynical about the open source models released by the megas, and OpenAI is probably the most honest about their intentions. Meta and Google are releasing these models arguably to kneecap any possible next OpenAI. They want to basically set the market value of anything below state of the art at $0.00, ensuring that there is no breathing room below the $2T cos. These models (Llama, Gemma, etc) are fun toys, but in the end they're completely uncompetitive and will yield zero \"wins\", so to speak. reply loudmax 11 hours agorootparentI certainly would not count out Google's engineering talent. But all the technical expertise in the world won't matter when the leadership is incompetent and dysfunctional. Rolling out a new product takes vision, and it means taking some risks. This is diametrically opposed to how Google operates today. Gemini could be years ahead of ChatGPT (and maybe it is now, if it weren't neutered), but Google's current leadership would have no idea what to do with it. Google has the technical resources to become a major player here, maybe even the dominant player. But it won't happen under current management. I won't count out Google entirely, and there's still time for the company to be saved. It starts with new leadership. reply okdood64 5 hours agorootparent> Google has the technical resources to become a major player here Wait, it's not a major player in ML/AI? reply jerpint 12 hours agorootparentprev> Meta and Google are releasing these models arguably to kneecap any possible next OpenAI. They want to basically set the market value of anything below state of the art at $0.00, ensuring that there is no breathing room below the $2T cos Never thought about it that way, but it makes a lot of sense. It’s also true these models are not up to par with SOTA no matter what the benchmarks say reply brigadier132 14 hours agoparentprevThere was a podcast yesterday that explained well why Google is in a tough position. https://youtu.be/-i9AGk3DJ90?t=616 In essence, Google already rules information retrieval. Their margins are insane. Switching to LLM based search cuts into their margins and increases their costs dramatically. Also, the advantage they've built over decades has been cut down. All of this means there is potential for less profit and a shrinking valuation. A shrinking valuation means issues with employee retention and it could lead to long term stagnation. reply corysama 12 hours agorootparentThe Innovator's Dilemma over and over again. reply brikym 11 hours agorootparentprevI’m sure Kodak had the same problem with the digital camera. reply Eisenstein 3 hours agorootparentThey did. They invented and patented the digital camera back in the 70s, refused to improve on it for fear of eating their own market base, and then went bankrupt. * https://spectrum.ieee.org/first-digital-camera-history reply whimsicalism 15 hours agoparentprevRealistically, if Google has all this talent, they should have gotten the juggernaut moving in 2020. Google has had years to get to this stage, and they've lost a lot of the talent that made their initial big splashes to OAI and competitors. Try finding someone on a sparse MoE paper from Google prior to 2022 who is still working there and not at OAI. With respect, they can hardly even beat Mistral, resorting to rounding down a 7.8b model (w/o embeddings) to 7b. reply freedomben 15 hours agorootparentOrganizational dysfunction can squash/squander even the most talented engineers. Especially in a big org in big tech. My bet is that their inability to deliver before is probably a result of non-comittal funders/decision makers, product whiplash, corporate politics, and other non-technical challenges. Google has been the home of the talent for many years. They came on my radar in the late 00s when I used Peter Norvig's textbook in college, and they hired Ray Kurzweil in like 2012 or 2013 IIRC. They were hiring ML PhDs with talent for many years, and they pioneered most of the major innovations. They just got behind on productizing and shipping. reply whimsicalism 14 hours agorootparentRight, which was fine for them before there was major competition. But starting in 2020, they have basically attrited most of their talented labor force to OAI and competitors who were not similarly dysfunctional. reply dguest 15 hours agoparentprevMaybe someone who knows google better can answer my question here: are they behind simply because LLMs are not really their core business? In other words, it wasn't (and still isn't) obvious that LLMs will help them sell add space. And of course writing that gives me a terrible realization: product placement in LLMs is going to be a very big thing in the near future. reply elwell 14 hours agorootparentLLM bad because cannibalizes search ads. Wait as long as possible. OpenAI opens pandora's box. Now full speed ahead; catch up and overtake. reply freedomben 15 hours agorootparentprevI'm an outsider and am speculating based on what I've heard, so maybe I shouldn't even comment, but to me it seems like it's been entirely corporate/organizational reasons. Non-serious funding, shifting priorities, personnel transfers/fluctuations, internal fragmentation, and more. Lack of talent has never been their problem. reply refulgentis 12 hours agoparentprevThere's nothing provided here other than Jeff Dean gave a stock entry-level presentation to students at Rice, therefore \"The depth of institutional knowledge that is going to be unlocked inside Google is actually frightening for me to consider.\" You should see Google's turnover numbers from 4 years ago, much less now. It's been years, it's broken internally, we see the results. Here, we're in awe of 1KLOC of C++ code that runs inference on the CPU. Nobody serious is running inference on CPU unless you're on the extreme cutting edge. (ex. I need to on Android and on the Chrome OS Linux VM, but I still use llama.cpp because it does support GPU everywhere else) I'm not sure what else to say. (n.b. i am a xoogler) reply janwas 5 hours agorootparentWe understand that some teams prefer to use CPU even when mobile GPU would be available. This code is also intended to facilitate research & experimentation, which may not fall under your definition of 'serious' :) reply iaseiadit 3 hours agorootparentprev> You should see Google's turnover numbers from 4 years ago, much less now. High turnover was industry-wide a few years back because pay went through the roof and job hopping was the best way to capture that. I suspect it’s lower now, following mass layoffs and substantially fewer openings. reply whitten 6 hours agorootparentprevAre there any online transcripts or recordings of the Rice presentation from Jeff Dean ? reply refulgentis 6 hours agorootparentYes, footer of parent: https://youtu.be/oSCRZkSQ1CE?si=Na1d1cK3TApDhkSO reply ofermend 17 hours agoprevAwesome work on getting this done so quickly. We just added Gemma to the HHEM leaderboard - https://huggingface.co/spaces/vectara/leaderboard, and as you can see there its doing pretty good in terms of low hallucination rate, relative to other small models. reply swozey 17 hours agoparent> LLM hallucinations I wasn't familiar with the term, good article - https://masterofcode.com/blog/hallucinations-in-llms-what-yo... reply ed 16 hours agorootparentKarpathy offers a more concise (and whimsical) explanation https://x.com/karpathy/status/1733299213503787018 reply swozey 17 hours agoprevThe velocity of the LLM open source ecosystem is absolutely insane. I just got into hobby projects with diffusion a week ago and I'm seeing non-stop releases. It's hard to keep up. It's a firehose of information, acronyms, code etc. It's been a great python refresher. reply austinvhuang 17 hours agoparentDon't be discouraged, you don't have to follow everything. In fact it's probably better to dive deep into one hobby project like you're doing than constantly context switch with every little news item that comes up. While working on gemma.cpp there were definitely a lot of \"gee i wish i could clone myself and work on that other thing too\". reply xrd 12 hours agoprevI was discussing LLMs with a non technical person on the plane yesterday. I was explaining why LLMs aren't good at math. And, he responded, no, chatgpt is great a multivariate regression, etc. I'm using LLMs locally almost always and eschewing API backed LLMs like chatgpt. So I'm not very familiar with plugins, and I'm assuming chatgpt plugs into a backend when it detects a math problem. So it isn't the LLM doing the math but to the user it appears to be. Does anyone here know what LLM projects like llama.cpp or gemma.cpp support a plugin model? I'm interested in adding to the dungeons and dragons system I built using llama.cpp. Because it doesn't do math well, the combat mode is terrible. But I was writing my own layer to break out when combat mode occurs, and I'm wondering if there is a better way with some kind of plugin approach. reply staticman2 10 hours agoparentSillytavern is a front end for local and cloud models. They have a simple scripting language and there's been some experiments with adding game functionality with it: https://chub.ai/characters/creamsan/team-neko-e4f1b2f8 This one says it uses javascript as well: https://chub.ai/characters/creamsan/tessa-c4b917f9 Thise are the only two listed as SFW. There's some others if you hit the nsfw toggle and search for the scripted tag.I don't know if this is the right approach but you could also write a module for Sillytavern Extras. reply throwaway19423 17 hours agoprevCan any kind soul explain the difference between GGUF, GGML and all the other model packaging I am seeing these days? Was used to pth and the thing tf uses. Is this all to support inference or quantization? Who manages these formats or are they brewing organically? reply austinvhuang 16 hours agoparentI think it's mostly an organic process arising from the ecosystem. My personal way of understanding it is this - the original sin of model weight format complexity is that NNs are both data and computation. Representing the computation as data is the hard part and that's where the simplicity falls apart. Do you embed the compute graph? If so, what do you do about different frameworks supporting overlapping but distinct operations. Do you need the artifact to make training reproducible? Well that's an even more complex computation that you have to serialize as data. And so on.. reply moffkalast 16 hours agoparentprevIt's all mostly just inference, though some train LoRAs directly on quantized models too. GGML and GGUF are the same thing, GGUF is the new version that adds more data about the model so it's easy to support multiple architectures, and also includes prompt templates. These can run CPU only, be partially or fully offloaded to a GPU. With K quants, you can get anywhere from a 2 bit to an 8 bit GGUF. GPTQ was the GPU-only optimized quantization method that was superseded by AWQ, which is roughly 2x faster and now by EXL2 which is even better. These are usually only 4 bit. Safetensors and pytorch bin files are raw float16 model files, these are only really used for continued fine tuning. reply Gracana 13 hours agorootparent> and also includes prompt templates That sounds very convenient. What software makes use of the built-in prompt template? reply moffkalast 12 hours agorootparentOf the ones I commonly use, I've only seen it read by text-generation-webui, in the GGML days it had a long hardcoded list of known models and which templates they use so they could be auto-selected (which was often wrong), but now it just grabs it from any model directly and sets it when it's loaded. reply liuliu 16 hours agoparentprevpth can include Python code (PyTorch code) for inference. TF includes the complete static graph. GGUF is just weights, safetensors the same thing. GGUF doesn't need a JSON decoder for the format while safetensors needs that. I personally think having a JSON decoder is not a big deal and make the format more amendable, given GGUF evolves too. reply next_xibalba 17 hours agoprevIs this neutered in the way Gemini is (i.e. is the \"censorship\" built in) or is that a \"feature\" of the Gemini application? reply ComputerGuru 16 hours agoparentIt depends on the model you load/use, the team released both censored and \"PT\" versions. reply jonpo 11 hours agoparentprevThese models (Gemma) are very difficult to jailbreak. reply olegbask 3 hours agoprevIt would be amazing to add support for M1 aka Metal: I was able to run Q8 version with llama.cpp and it's blazingly fast. The problem: I don't know how much accuracy it loses and https://huggingface.co/google/gemma-2b-it/tree/main takes too much memory which results in OOMs. Do you have any estimates on getting Metal support similar to how llama.cpp works? Why `.gguf` files are so giant compared to `.sbs`? Is it just because they use fp32? reply namtranase 14 hours agoprevThank the team for the awesome repo. I have navigated gemma.cpp and run it from the first day, it is smooth in my view. So I hope gemma.cpp will continue to add cool features (something like k-quants, server,...) so it can serve more widely. Actually, I have developed a Python wrapper for it: https://github.com/namtranase/gemma-cpp-python The purpose is to use easily and update every new technique from gemma.cpp team. reply austinvhuang 4 hours agoparentNice, this is really cool to see! There were other threads that expressed interest in something like this. reply a1o 18 hours agoprevIf I want to put a Gemma model in a minimalist command line interface, build it to a standalone exe file that runs offline, what is the size of my final executable? I am interested in how small can the size of something like this be and it still be functional. reply coder543 18 hours agoparenthttps://ollama.com/library/gemma/tags You can see the various quantizations here, both for the 2B model and the 7B model. The smallest you can go is the q2_K quantization of the 2B model, which is 1.3GB, but I wouldn't really call that \"functional\". The q4_0 quantization is 1.7GB, and that would probably be functional. The size of anything but the model is going to be rounding error compared to how large the models are, in this context. reply sorenjan 17 hours agorootparentWhat's the use case of models this small? Can you use the \"knowledge\" encoded in them and ask them questions and get relevant answers, or are they used as text processors to summarize documents etc? reply trisfromgoogle 14 hours agorootparentGemma 2B generation quality is excellent in my own very-biased opinion. I asked it to write a response to your comment: -- Large language models (LLMs) have achieved significant progress in recent years, with models like GPT-3 and LaMDA demonstrating remarkable abilities in various tasks such as language generation, translation, and question answering. However, 2b parameter models are a much smaller and simpler type of LLM compared to GPT-3. While they are still capable of impressive performance, they have a limited capacity for knowledge representation and reasoning. Despite their size, 2b parameter models can be useful in certain scenarios where the specific knowledge encoded in the model is relevant to the task at hand. For example: - Question answering: 2b parameter models can be used to answer questions by leveraging their ability to generate text that is similar to the question. - Text summarization: 2b parameter models can be used to generate concise summaries of documents by extracting the most important information. - Code generation: While not as common, 2b parameter models can be used to generate code snippets based on the knowledge they have learned. Overall, 2b parameter models are a valuable tool for tasks that require specific knowledge or reasoning capabilities. However, for tasks that involve general language understanding and information retrieval, larger LLMs like GPT-3 may be more suitable. -- Generated in under 1s from query to full response on together.ai https://api.together.xyz/playground/chat/google/gemma-2b-it reply brucethemoose2 18 hours agoparentprevThe code is a basically irrelevant fraction of the model weights. The raw FP16 is like 17GB. In practice your priority would be fancy quantization, and just any library that compiles down to an executable (like this, MLC-LLM or llama.cpp) reply a1o 18 hours agorootparent17GB looks like a lot. Thanks, I will wait until people figure how to make these smaller before trying to use to make something standalone. reply swatcoder 17 hours agorootparentIt's always going to be a huge quantity of data. Even as efficiency improves, storage and bandwidth are so cheap now that the incentive will be to convert that efficiency towards performance (models with more parameters, ensembles of models, etc) rather than chasing some micro-model that doesn't do as well. It might not always be 17GB, but don't expect some lesser order of magnitude for anything competitive. As maturity arrives, we'll likely see a handful of competing local models shipped as part of the OS or as redistributable third-party bundles (a la the .NET or Java runtimes) so that individual applications don't all need to be massive. You'll either need to wait for that or bite the bullet and make something chonky. It's never going to get that small. reply wg0 17 hours agorootparentprevThese won't be smaller I guess. Given we keep the number of parameters same. Pre LLM era (let's say 2020), the hardware used to look decently powerful for most use cases (disks in hundreds of GBs, dozen or two of RAM and quad or hex core processors) but with the advent of LLMs, even disk drives start to look pretty small let alone compute and memory. reply brucethemoose2 17 hours agorootparentAnd cache! The talk of AI hardware is now \"how do we fit these darn things inside SRAM?\" reply sillysaurusx 17 hours agorootparentprevThe average PS5 game seems to be around 45GB. Cyberpunk was 250GB. Distributing 17GB isn’t a big deal if you shove it into Cloudflare R2. reply brucethemoose2 17 hours agorootparentprevIn theory quantized weights of smaller models are under a gigabyte. If you are looking for megabytes, yeah, those \"chat\" llms are pretty unusable at that size. reply samus 18 hours agoparentprevDepends how much you quantize the model. For most general-purpose LLMs, the model completely dwarfs the size of the binary code. reply replete 18 hours agoparentprevI used gemm:2b with ollama last night and the model was around 1.3gb IIRC reply superkuh 17 hours agoparentprev*EDIT*: Nevermind, llamafile hasn't been updated in a full month and gemma support was only added to llama.cpp on the 21st of this month. Disregard this post for now and come back when mozilla updates llamafile. --- llama.cpp has integrated gemma support. So you can use llamafile for this. It is a standalone executable that is portable across most popular OSes. https://github.com/Mozilla-Ocho/llamafile/releases So, download the executable from the releases page under assets. You want either just main and server and llava. Don't get the huge ones with the model inlined in the file. The executable is about 30MB in size, https://github.com/Mozilla-Ocho/llamafile/releases/download/... reply brucethemoose2 18 hours agoprev...Also, we have eval'd Gemma 7B internally in a deterministic, zero temperature test, and its error rate is like double Mistral Instruct 0.2. Well below most other 7Bs. Was not very impressed with the chat either. So maybe this is neat for embedded projects, but if it's Gemma only, that would be quite a sticking point for me. reply Vetch 17 hours agoparentWas it via gemma.cpp or some other library? I've seen a few people note that gemma performance via gemma.cpp is much better than llama.cpp, possible that the non-google implementations are still not quite right? reply brucethemoose2 17 hours agorootparentI eval'd it with vllm. One thing I do suspect people are running into is sampling issues. Gemma probably doesn't like llama defaults with its 256K vocab. Many Chinese llms have a similar \"default sampling\" issue. But our testing was done with zero temperature and constrained single token responses, so that shouldnt be an issue. reply Havoc 18 hours agoparentprevThat does seem to be the consensus unfortunately. Would have been better for everyone if google’s foray into open model a la FB made a splash reply brucethemoose2 18 hours agorootparentYeah, especially with how much Google is hyping it. It could have been long context? Or a little bigger, to fill the relative gap in the 13B-30B area? Even if the model itself was mediocre (which you can't know until after training), it would have been more interesting. reply trisfromgoogle 14 hours agoparentprevAny chance you can share more details on your measurement setup and eval protocols? You're likely seeing some config snafus, which we're trying to track down. reply brucethemoose2 5 hours agorootparentI just loaded it in vllm with default settings. I can't share the eval, but it's pretty simple: it asks a question about some data, and is restricted to only answer yes/no (based on the output logits and suggested in the prompt). It's called with 0 temperature and only 1 output token, so sampling shouldn't be an issue. reply dontupvoteme 14 hours agoprevAt the risk of being snarky, it's interesting that Llama.cpp was a 'grassroots' effort originating from a Bulgarian hacker google now launches a corporatized effort inspired by it. I wonder if there's some analogies to the 80s or 90s in here. reply alekandreev 59 minutes agoparentAs a fellow Bulgarian from the 80s and 90s myself, and now a part of the Gemma team, I’d say Austin, Jan, and team very much live up to the ethos of hackers I'd meet on BBSes back then. :) They are driven entirely by their own curiosity and a desire to push computers to the limit. Combined with their admirable low-level programming skills, you get a very solid, fun codebase, that they are sharing with the world. reply trisfromgoogle 14 hours agoparentprevTo be clear, this is not comparable directly to llama.cpp -- Gemma models work on llama.cpp and we encourage people who love llama.cpp to use them there. We're also launched with Ollama. Gemma.cpp is a highly optimized and lightweight system. The performance is pretty incredible on CPU, give it a try =) reply manlobster 5 hours agoprevI wonder why they didn't use bazel as their build system. reply brokensegue 18 hours agoprevdoes anyone have stats on cpu only inference speed with this? reply austinvhuang 16 hours agoparentany particular hardware folks are most interested in? reply brokensegue 16 hours agorootparentI'm just looking for ballpark figures. Maybe a common aws instance type reply notum 12 hours agorootparentNot sure if this is of any value to you, but Ryzen 7 generates 2 tokens per second for the 7B-Instruct model. The model itself is very unimpressive and I see no reason to play with it over the worst alternative from Hugging Face. I can only imagine this was released for some bizarre compliance reasons. reply brokensegue 11 hours agorootparentthe metrics suggest it's much better than that reply janwas 5 hours agorootparentprevFor the 7B IT and a short factual query I see 5.3 tps on a 5 year old Skylake Gold 6154 CPU @ 3.00GHz, 16 threads. Expect a slight increase as we improve scalability. FYI using the NUQ (4.5-bit) quantization improves throughput by about 1.4x. reply natch 14 hours agoprevApart from the fact that they are different things, since they came out of the same organization I think it’s fair to ask: Do these models have the same kind of odd behavior as Gemini? reply tarruda 16 hours agoprevIs it not possible to add Gemma support on Llama.cpp? reply austinvhuang 16 hours agoparentGemma support has been added to llama.cpp, in fact it was added almost immediately after the release: https://twitter.com/ggerganov/status/1760293079313973408 However, be aware that there were some quality issues with quantization initially (hopefully they're resolved but i haven't followed too closely): https://twitter.com/ggerganov/status/1760418864418934922 reply brucethemoose2 18 hours agoprevNot to be confused with llama.cpp and the GGML library, which is a seperate project (and almost immediately worked with Gemma). reply throwaway19423 17 hours agoparentI am confused how all these things are able to interoperate. Are the creators of these models following the same IO for their models? Won't the tokenizer or token embedder be different? I am genuinely confused by how the same code works for so many different models. reply brucethemoose2 16 hours agorootparentIt's complicated, but basically because most are llama architecture. Meta all but set the standard for open source llms when they released llama1, and anyone trying to deviate from it has run into trouble because the models don't work with the hyper optimized llama runtumes. Also, there's a lot of magic going on behind the scenes with configs stored in gguf/huggingface format models, and the libraries that use them. There are different tokenizers, but they mostly follow the same standards. reply null_point 13 hours agorootparentI found the magic! https://github.com/search?q=repo%3Aggerganov%2Fggml%20magic&... reply jebarker 16 hours agoparentprevI doubt there'd be confusion as the names are totally different reply kwantaz 15 hours agoprevnice reply einpoklum 18 hours agoprevCome on Dejiko, we don't have time for this gema! https://www.youtube.com/watch?v=9FSAqDVZHhU reply sillysaurusx 17 hours agoparentEvery time I see Gemma all I hear is Jubei screaming Genmaaaa since the n is almost silent. https://youtu.be/TFR9-cZecWo?si=rMED2LEh-fssHeeG reply austinvhuang 16 hours agorootparentlol reply a-french-anon 17 hours agoparentprevGlad I wasn't alone. reply einpoklum 17 hours agorootparentWell, it was just so nostalgic for me nyo :-\\ reply colesantiago 18 hours agoprevIsn't there a huge risk that Google could most likely deprecate Gemini, Gemma and Gemma.cpp? Not really smart to build on anything with Google e.g. Google Cloud for AI. Has this perception changed or pretty much the same? reply beoberha 18 hours agoparentGemini - maybe, though I find it pretty unlikely it’ll happen anytime soon. Not sure what you mean about Gemma considering it’s not a service. You can download the model weights and the inference code is on GitHub. Everything is local! reply ertgbnm 18 hours agoparentprevThe weights are downloadable so there isn't much of a risk if Google stops hosting Gemma apart from the fact that it won't get new versions that you swap out in the future. reply cyanydeez 15 hours agorootparenteven if there's a new model, I'm not seeing how these models provide any reliability metric. if you figure out a money making software/service, you're gonna be tied to that model to some significant degree. reply brucethemoose2 18 hours agoparentprevThis is not necessarily a production backend, as it mentions in the readme. There are some very interesting efforts in JAX/TPU land like https://github.com/erfanzar/EasyDeL reply Wissan 17 hours agoprev [–] Hello reply sintax 15 hours agoparent [–] Demo when model quantized to q0_K? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gemma.cpp is a lightweight inference engine for Gemma foundation models by Google, accessible on Kaggle, ideal for research and experimentation.",
      "Users can access model weights and tokenizer for different Gemma models on Kaggle.",
      "It is recommended to utilize Python frameworks such as JAX, Keras, PyTorch, and Transformers for deploying models on edge devices, and community contributions are encouraged with continuous development on the dev branch."
    ],
    "commentSummary": [
      "Gemma.cpp is a C++ inference engine developed by Google for Gemma models, emphasizing portability and easy modification, with a focus on CPU SIMD performance and future GPU support.",
      "Criticisms involve repetition penalty, bias, and model size, sparking concerns about transparency, trust, and competition with OpenAI, while highlighting Google's organizational challenges and talent retention.",
      "Debates within the AI community encompass performance, compatibility, and development aspects like model packaging formats, capabilities, and size limits of Gemma models."
    ],
    "points": 378,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1708701323
  },
  {
    "id": 39479478,
    "title": "Searchformer: Revolutionizing Planning with Transformers",
    "originLink": "https://arxiv.org/abs/2402.14083",
    "originBody": "Computer Science > Artificial Intelligence arXiv:2402.14083 (cs) [Submitted on 21 Feb 2024] Title:Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping Authors:Lucas Lehnert, Sainbayar Sukhbaatar, Paul Mcvay, Michael Rabbat, Yuandong Tian Download PDF HTML (experimental) Abstract:While Transformers have enabled tremendous progress in various application settings, such architectures still lag behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks and present Searchformer, a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard $A^*$ search. Searchformer is an encoder-decoder Transformer model trained to predict the search dynamics of $A^*$. This model is then fine-tuned via expert iterations to perform fewer search steps than $A^*$ search while still generating an optimal plan. In our training method, $A^*$'s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. In our ablation studies on maze navigation, we find that Searchformer significantly outperforms baselines that predict the optimal plan directly with a 5-10$\\times$ smaller model size and a 10$\\times$ smaller training dataset. We also demonstrate how Searchformer scales to larger and more complex decision making tasks like Sokoban with improved percentage of solved tasks and shortened search dynamics. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2402.14083 [cs.AI](or arXiv:2402.14083v1 [cs.AI] for this version) Submission history From: Lucas Lehnert [view email] [v1] Wed, 21 Feb 2024 19:17:28 UTC (758 KB) Full-text links: Access Paper: Download PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.AInewrecent2402 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=39479478",
    "commentBody": "Beyond A*: Better Planning with Transformers (arxiv.org)297 points by jonbaer 22 hours agohidepastfavorite118 comments gene-h 14 hours agoThere has been more interesting work on using transformers for robot motion planning[0]. Getting a robot arm from point a to b without hitting stuff is a very difficult problem, the problem is both high dimensional and continuous. Previous planning methods are both computationally intensive and not very good. This is one reason why robot motion appears 'unnatural' and robots generally being bad at many tasks we'd like them to do. This approach appears pretty competitive with other planning methods, planning near optimal paths faster. [0]https://sites.google.com/ucsd.edu/vq-mpt/home reply gromneer 6 hours agoparentInformative comments like this is the reason I go to the comment section before reading the article. reply softfalcon 16 hours agoprevI wonder if they tried the modified J* algorithm (an optimization of A* for games graph/path-finding) before going down this research route. It's in Game AI Pro 2 [0] if anyone is curious. [0] https://www.amazon.ca/Game-AI-Pro-Collected-Professionals/dp... reply leeoniya 15 hours agoparentalso https://github.com/anvaka/ngraph.path reply mysterydip 16 hours agoparentprevI love these books (and nice to see Steve Rabin still doing them), but $120 for an ebook? That's unexpected. reply setr 15 hours agorootparentWorse yet… the game ai pro books are entirely free for digital copies. You’d basically be paying $120 for it to be stitched together into a single pdf, instead of one per chapter http://www.gameaipro.com/ reply cjaybo 14 hours agorootparentThat’s one expensive imagemagick command! reply hlfshell 15 hours agorootparentprevIf you consider it like a textbook (very small niche audience for very specialized knowledge) it does kind of match up due to the small expected volume to sell. Authors still gotta eat. reply ogogmad 11 hours agoparentprevTo be fair, they said at the end that their path-finder is not yet competitive with the SOTA. The paper tests how well a transformer does at predicting an execution trace (like in a JIT compiler) and whether this can help improve heuristics in things like path-finding. I'm weary because transformers are slow. reply tannhaeuser 12 hours agoprevPlanning is already well taken care of by established techniques ranging from graph search, SAT-solvers, OR, Prolog, etc. The point usually is optimization over multiple feasible alternatives, which I have a hard time seeing transformers being up to. I see the role of LLM techniques more in translating natural language descriptions to executable programs - but then Prolog is already very close, it being designed for classic NLP after all. reply 3abiton 3 hours agoparentIt would be interesting to see the comparison between Prolog and a similar purposes LLM reply tannhaeuser 36 minutes agorootparent> Searchformer [...] solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search ... [and] significantly outperforms baselines that predict the optimal plan directly with a 5-10× smaller model size and a 10× smaller training dataset. So this can be interpreted as a generic statement to say there might be progress during learning iterations (compared to its own arbitrary first iteration baseline). I think it's important to not getting carried away and assume the recent immense progress in generative AI is just easily repeated for any other AI task. There's also quantum computing having been advertised for over a decade now for a break through in planning and optimization efficiency. > We also demonstrate how Searchformer scales to larger and more complex decision making tasks like Sokoban with improved percentage of solved tasks and shortened search dynamics. Worth mentioning that Sokoban is nowhere near a complex decision making tasks let alone state of the art in an academic or commercial planning/optimization context. > A∗'s search dynamics are expressed as a token sequence outlining when task states are added and removed [...] during symbolic planning. Go ahead and compare against eg. Quantum Prolog's readily available container planning problem and solutions [1] then to generate exactly that in the browser - a plan with symbolic actions to perform - or alternatively, a classic Graphplan or CLIPS planning competition problem. [1]: https://quantumprolog.sgml.io/* reply bravura 19 hours agoprevMachine Translation used to involve complicated grammatical decoding, using search. Now we just use transformers for MT, with much simpler decoding that doesn't really need search. Perhaps we can reach full inception. Let's use our current best-of-breed predictive models to learn heuristics for neural architecture search (NAS) and search for new neural blocks (better than transformer and mamba). reply FeepingCreature 16 hours agoparent\"Every time I fire a linguist, the performance of the speech recognizer goes up.\" --Frederick Jelinek reply xg15 18 hours agoparentprev...and finally enter a world where literally no one understands anymore how the technology works, not even the people developing them. Singularity, here we come... reply zwirbl 18 hours agorootparentWe could then go on to create something akin to the mechanicum, create the position of tech priests and have them pray to the machine god on on our behalf reply moi2388 17 hours agorootparentIf you think that still needs to be created you haven’t worked at tech support reply TeMPOraL 17 hours agorootparentThe priest class is there, what we need is to level up the machine god itself. reply smcameron 16 hours agorootparentprevThe tech priests will build electric monks to do that job. reply throwuwu 17 hours agorootparentprevBarring the singularity, just because you find something with search doesn’t mean you can’t understand why it’s better. reply tintor 15 hours agoprev\"26.8% fewer search steps than standard A∗ search\" So, slightly better than A* which is far from SOTA on Sokoban (https://festival-solver.site/). What is impressive in this paper? Why is this on Hacker News? reply Negitivefrags 14 hours agoparentSo A* is the most optimal search algorithm under the specific constraints it specifies. You can't do better. However, sometimes the specific domain you are searching has other constraints that can be exploited to do better than A*. An example of this being Jump Point Search that exploits certain properties of grid searches if you can only move in certain ways. If you were able to write a general searching algorithm that can effectively exploit the whatever the specific properties of the underlying domain \"automatically\" without you having to actually work out what they are, that would be useful right? reply tintor 12 hours agorootparentPaper authors choose to compare against A* and Sokoban. A* can't solve even the first level of original Sokoban 90 levels. reply mromanuk 15 hours agoparentprevBecause they used a transformer to reach a nice solution, better than a typical A* search, which is a \"naive\" or go to solution. And they didn't think about designing an algorithm. I find it quite impressive that a simple encoder-decoder transformer can achieve so much. reply RogerL 11 hours agoparentprevIt is in the abstract, very first line. \"While Transformers have enabled tremendous progress in various application settings, such architectures still lag behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks ...\" This paper is interesting (to me) as an example of how to use transformers for decision making. I don't particularly care if it is up to A* standards at the moment. reply tintor 10 hours agorootparentAbstract doesn't answer my question. What is the scientific contribution of the paper? They trained transformer on pairs of . reply gopher_space 8 hours agorootparent> What is the scientific contribution of the paper? That's not a question you ask other people, that's a bullet point at the top of the outline you created while reading the paper for yourself. You should see the creation of said outline as a measure of your actual interest in the subject. reply airstrike 15 hours agoparentprev> Why is this on Hacker News? Anything that is on HN is on HN because the community likes it reply MooseBurger 13 hours agoparentprevIn certain computer science problems, a suboptimal action at time t may give rise to an optimal outcome at time >t. Why wouldn't this be the case for research generally? Has our community really devolved to the point where things should only be noteworthy insofar as they optimize for SOTA for a given problem? What a sad thought. reply esafak 15 hours agoparentprevHas anyone compared planning algorithms by complexity against optimality (error)? reply DalasNoin 13 hours agoparentprevIt's on hn because it sounds similar to the so called Q* algorithm, the supposed secret openai algo that has seen a huge amount of speculation. reply Analemma_ 13 hours agoparentprevBecause it's further evidence for the \"unreasonable effectiveness of transformers\", i.e. that transformers are a fully-general approach for all kinds of learning tasks, not just next-token prediction. Obviously there is a strong and a weak version of that hypothesis and the strong version is probably not true, but to the extent that we appear to be honing in Nature's \"one true way\" to learn how to accomplish a task, that seems like important news. reply hlfshell 15 hours agoparentprevWhat? Someone somewhere tried to do something and wasn't the most optimal possible solution? We should just ban their account honestly. Comments like these are antithetical to a strong technical sharing community. reply pqdbr 15 hours agorootparentI agree. OP's comment could be quickly rewritten into something useful and just by changing the tone, for example: \"26.8% fewer search steps than standard A∗ search\" For reference of prior art, it's slightly better than A*, which is far from SOTA on Sokoban (https://festival-solver.site/). reply agumonkey 15 hours agorootparentprevEspecially considering the amount of trivial mainstream tech articles nowadays. It's cool to see more algorithmic topics. reply mindwok 15 hours agoparentprevSome people find things interesting regardless of if they break records. reply ultra_nick 18 hours agoprevIf transformers can plan, then AGI only requires better education... reply nyrikki 15 hours agoparentApproximating exhaustive search is not logic or causality. reply throwuwu 17 hours agoparentprevThere’s a lot more pieces, agency being a big one but online learning is required too and many other layers beyond that. reply th0ma5 16 hours agoparentprevThat's probably the foreseeable future, ingesting ever larger amounts of data hoping it prevents hallucinations. reply adi4213 16 hours agoprevFor the auditory learners, here is this paper in a summarized audiobook format : https://player.oration.app/09fefe41-f2a7-4257-a25e-30e479b30... reply syassami 16 hours agoparentThanks for sharing, I've been looking for an app like this for ages. reply adi4213 16 hours agorootparentThank you so much for your comment! Apologies if my comment came off like an ad - I have mild dyslexia and struggle to keep up with ML papers; I hope others also find this useful! If you have any feedback or issues, feel free to email us at support [at] trurecord.com reply goggy_googy 13 hours agoprevThis paper reminds me of the Neural Network Diffusion paper which was on the front page of HN yesterday in the sense that we are training another model to bypass a number of iterative steps (in the previous paper, those were SGD steps, in this one, it is A* exploration steps). On a different note, they choose such a bad heuristic for the A* for Sokoban. The heuristic they choose is \"A∗ first matches every box to the closest dock and then computes the sum of all Manhattan distances between each box and dock pair\". I played Sokoban for 20 minutes while reading the paper and I feel like this is a very poor exploration heuristic (you often need to move boxes away from goal state to make progress). reply nyrikki 12 hours agoparentI have a hunch they made their decision to train off that particular type of A* traces to avoid an exponential number of embeddings. reply thesz 12 hours agoprevCan transformers prove absence of the solution? E.g., did they tried to train them on the unsolvable problems? I once tried my hands on the PCB routing and here's a simple problem of simultaneous multipath search that is unsolvable: A.....b B.....a A and B are starting points and a and b are goal points, respectively for A and for B. It is a 2xN maze, the orders of stating and goal points are reversed. The search algorithm sometimes required to prove absence of the solution. A* can do that, transformers? I do not think so. reply nyrikki 11 hours agoparentIn this case, A* is in a finite, bounded 3030 grid. As A is just a type of branch and bound algorithm, which the degenerate form is exhaustive search. Which should be able to 'prove' the absence of a path by simply failing to find one before exhausting all paths. PCB routing is not as simple as this problem for real world problems. Digging into why TSP with a positive integer Euclidean metric is NP-C but with a real valued Euclidean metric is NP-hard may be one way to think about it. But if you choose the right metric and huristic, in what approximates a finite space, A* can run an exhaustive search in practical time. It is probably a good idea to separate search space exhaustion from no-instance proving which in the case of decision problems can cause confusion. If you think of NP as relating to yes-instances, co-NP is the no-instances. reply thesz 11 hours agorootparentYou are mathematician, am I right? Your answer is correct (sorta, as far as I am concerned) and does not add to the discussion I tried to open. Your answer does not show anything related to the ability of transformers to prove absence of solution, to be precise. reply nyrikki 9 hours agorootparentNo, just a programmer that has to apply math. Transformers can only do what is called weak negation. if (not (goal X)), then (assert not x) One example I have seen is: \"you can cross if you have no information on a train coming” VS: \"you can cross if you have evidence that no train is coming\" See the difference? As to what 'transformers' can encode is ambiguous and depends on many factors but here is some light reading. https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00493... https://arxiv.org/abs/2204.06618 reply amelius 19 hours agoprevIs someone keeping a list of classical algorithms or NP complete problems that are now better performed using deep learning? reply scscsc 17 hours agoparentFor your convenience, here is the list of NP-complete problems where \"AI\" works better than the state of the art in the worst case:. reply jvanderbot 17 hours agorootparentAI + classical algorithms is my sweet daydream. Trained heuristics (even better domain specific ones), deployed for classical A*, ILP families, focal search, etc etc. That is going to be really amazing. reply blt 16 hours agorootparentIt is happening. There are papers on deep learning to improve the variable choice in branch-and-bound, etc reply jvanderbot 16 hours agorootparentYeah my first exposure was from Marco Pavone's lab, on ML heuristics for MICP in the context of a cubical tumbling robot, IIRC. Really cool stuff. reply amelius 17 hours agorootparentprevEven solving large linear systems would already be amazing. But a SAT solver would be nice too :) reply jvanderbot 17 hours agorootparentI misunderstand your comment. We have those solvers. I'm suggesting AI would plug into existing solvers. This is a ripe area for research. reply cs702 17 hours agorootparentprevThank you for that. I needed the laugh :-) reply nyrikki 15 hours agorootparentprevFor those of you who didn't get the joke here. (S)ETH is a bit of a bummer if you only consider the dominate term in big-O, for the general case. https://web.stanford.edu/class/cs354/scribe/lecture17.pdf reply Davidzheng 17 hours agorootparentprevProbably soon AI will be able to find improvements to most of them? Like using AI to do search in algorithm space reply thomasahle 16 hours agorootparentFor all we know, some of the current best (still exponential) algorthms were guided by AI. If a mathematician solves a problem using mathematica, they don't usually write in the paper what tools they used. reply j2kun 17 hours agoparentprevFrom my understanding this is very much still active research, without any clear wins deployed in production settings. reply jvanderbot 20 hours agoprevI am extremely optimistic about using learned heuristics in discrete algorithms like A* or Focal search or the various families of ILP. In most modern discrete optimization libraries, e.g. CPLEX it's the heuristics and tuning that explain the performance. I'm less understanding of using a end to end learning approach to replace a well understood optimal search routine, but that might be pearl clutching. It just seems to me the authors missed that opportunity. reply boesboes 19 hours agoparentI think it is just the bubble/hype effect around transformers and AI. I might try to use transformers to solve tic-tac-toe and apply for some VC moneys. In a few years we'll all be writing about how much more efficient actual code is compared to AI perhaps ;) reply losvedir 19 hours agorootparentEveryone on Transformer News will be talking about the latest web framework for GPT-7 and how to horizontally scale their system to handle dozens of requests a second, and how when you need to scale beyond that it will \"be a good problem to have\". Meanwhile, you and I will be talking about how our low-level, handwritten Ruby on Rails code is so much faster and more efficient, and closer to the metal so you can understand what's _really_ going on. reply nvrmnd 16 hours agoparentprevI agree, learning admissible heuristics will retain worst case performance, which has always been the measuring stick for these algorithms. It's not at all uncommon to find faster solutions for the average or even p99 cases that cannot provide guarantees on the worst case. reply SnowflakeOnIce 14 hours agorootparentHow would one go about proving that a learned heuristic (something from an AI model) is in fact admissible? reply jvanderbot 12 hours agorootparentFor something like focal search, it doesn't even need admissibility, you just apply it as a second selection heuristic among the choices your admissable heuristic returns as 'top k' choices. reply SnowflakeOnIce 12 hours agorootparentSo a tiebreaker then? reply cptroot 12 hours agoprevI find it hard to believe that all the heavy-weight data processing and GPU computation really make a constant factor reduction in search steps worth it. reply SnowflakeOnIce 12 hours agoparentIt's also not clear to me how one would determine that an ML model-generated plan is indeed optimal, or how far from optimal it is. A*-based approaches give you these things. reply teleforce 21 hours agoprevTo the authors, please rename this new algorithm from the boring Searchformer to more interesting name for example Optimus Prime. reply anentropic 21 hours agoparentalso because googling for \"Searchformer\" brings up a different paper and model: https://www.sciencedirect.com/science/article/abs/pii/S01722... \"Planformer\" seems unused and would reduce confusion (also since \"Search\" implies RAG etc which is not what this model is about) reply krallistic 20 hours agorootparent\"Search\" has been the name for the A* space. So it makes absolute sense. \"Planning\" means in the symbolic AI space often something quite in the direction of PDDL/STRIPS/ICAPS planning. reply nick12r55t1 18 hours agorootparentT*former or T-star reply evanmoran 18 hours agorootparentT* (T-star) is a great name. reply shrubble 17 hours agorootparentIt is the copyrighted name of a lens coating by Zeiss Optical, however. reply TeMPOraL 17 hours agorootparentT1* and T2* are common terms in magnetic nuclear resonance imaging, suggesting Tn* for any integer n should be free of bullshit IP protection. May I thus suggest T10*, following the pattern of a11y and i18n? reply teleforce 20 hours agorootparentprevFunny that you mention RAG since the RAG authors had expressed their regret of not using a much better name and the name stucked once it becomes very popular. On second thought, in the spirit of A* perhaps they can rename it to O' short for Optimus Prime but this probably will break most of the databases in the world [1],[2]. [1] Exploits of a Mom: https://xkcd.com/327/ [2] Prime (symbol): https://en.m.wikipedia.org/wiki/Prime_(symbol) reply basil-rash 18 hours agorootparentI can’t think of any database that doesn’t support the ' character in their varchar. reply remexre 18 hours agorootparentI think the concern was all the buggy apps that connect to databases will accidentally be getting SQL injected. reply basil-rash 12 hours agorootparentIf they’re susceptible to injections this is the absolute least of their problems. In fact their DB is already dropped. reply rdedev 17 hours agorootparentprevAt this point we need a website cataloging all transformer related names. reply leosanchez 20 hours agoparentprevMegatron would be better IMO. reply moffkalast 20 hours agorootparentNvidia: \"We'll pretend you didn't say that.\" reply johndough 19 hours agorootparenthttps://github.com/NVIDIA/Megatron-LM > Megatron is a large, powerful transformer [...] reply verticalscaler 20 hours agorootparentprevClearly Megatron because LLMs are decepticons. reply leosanchez 20 hours agorootparentYes that was my reasoning :) reply wiz21c 19 hours agorootparentjust deceptive reply nkozyra 19 hours agoparentprevI think Searchformer is kind of catchy. :shrug: reply willcipriano 19 hours agoparentprevSacagawea is my proposed name. reply FooBarWidget 20 hours agoparentprevWouldn't that be a trademark violation? reply wongarsu 20 hours agorootparentTrademarks are specific to classes of goods. A trademark for toys named Optimus Prime doesn't prevent you from making software called Optimus Prime. reply mminer237 18 hours agorootparentWhile true, for something as famous as Optimus Prime, there could conceivably by liability for dilution by blurring. reply jan_Sate 20 hours agoprevWouldn't that be an overkill to train a model specifically for that? I wish someone could come up with an algorithm that would outperform a trained model. This way we would actually understand how it works. reply wongarsu 20 hours agoparentShortest path search is a very well understood problem, and for \"simple\" cases A* is the gold standard. You could probably tweak the heuristic used by A* to the problem to get similarly good results (at much lower compute cost than running what amounts to an LLM with huge context length). But this is a toy problem. The interesting thing about the paper is that you might be able to get good-performing search algorithms for any problem with a cookie-cutter process, instead of spending many man-hours tweaking a hand-written search algorithm. It might also be possible to easily adapt it to much more complex search problems, like cooperatively evading other agents navigating in the same space. reply jvanderbot 20 hours agoparentprevWell in this case, A* outperforms in terms of funding a solution when it exists. It's just the transformer produces a solution faster, but misses some. reply SnowflakeOnIce 19 hours agorootparentNote that the paper doesn't measure execution time of the A* or Transformer-based solutions; it compares length of A* algorithm traces with length of traces generated by a model trained on A* execution traces. I suspect that the actual execution time would be far faster with the A* implementation than any of the transformers. reply bamboozled 18 hours agorootparentprevWas the pun intended ? reply feverzsj 20 hours agoparentprevPath planning is highly dynamic and requires real time adjustment. In mature software, the heuristics are already highly optimized for local road/traffic data and users. So, I don't think AI can actually outperform them yet. reply Moldoteck 20 hours agoparentprevdo you want the solution faster or more precise? Depending on the answer you would pick either A* or this model reply SnowflakeOnIce 19 hours agorootparentThey don't report execution time in the paper. It's likely that the A* implementation would run faster in terms of CPU or wall clock. reply Moldoteck 18 hours agorootparentTransformer model that optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search. Doesn't fewer search steps imply faster? reply senand 18 hours agorootparentNo, each step could take significantly more time (and resources). reply eterevsky 20 hours agoprevWhile A* could be used to solve Sokoban, wouldn't some sort of Monte-Carlo Tree Search be better at it? I wonder how would it compare to this model. reply espadrine 19 hours agoparentThe part of MCTS that matters for solving it is the Bellman equation, which is a component of the Bellman-Ford shortest-path algorithm, so all of those methods are part of a continuum. Which one works best is pretty sensitive to the exploratory decisionmaking algorithm: do I search this cell first, or that one? That heuristic is the differentiator, whether it is put on top of a Dijkstra-style algorithm (A*) or a Bellman-Ford-style algorithm (MCTS). reply k2xl 19 hours agoprevShameless plug, but if you are interested in Sokoban type games check out https://thinky.gg . Features a fun Sokoban variant (called Sokopath) as well as another NP hard variant called Pathology (goal is to get from point A to point B in the shortest amount of steps). Many in the community have tried to create various solvers and things get very hard once the grid gets to be over 5x5. However, some interesting levels with very high maximum step counts have been discovered by the thinky communnity (via simulated annealing) reply nikolay 15 hours agoparentThank you! Great games! Super nice execution! I love it! reply tulio_ribeiro 14 hours agoprevAmazing. Now do that to sorting algorithms. reply light_hue_1 18 hours agoprev> 26.8% fewer search steps than standard A∗ search So you're saying I shouldn't read this paper? A* is not particularly good. If all the algorithm can do is mirror it by training on its output what's the point? reply casebash 18 hours agoparentYeah, at first I read that as it using 26.8% of the original steps, but reducing the number of steps by 26.8% is not that impressive. I wonder whether it actually reduces total search time as there is added overhead of running the neural network. reply light_hue_1 16 hours agorootparentThere's absolutely no way it reduces search time. A* is trivial to run per timestep. The time must be thousands to maybe hundreds of thousands of times slower. I publish in this area and this is a common thing for reviewers to bring up when authors don't report wall clock time. And then for papers to be rejected. What's the value in making an algorithm that's drastically slower? Not much. reply ta8645 16 hours agorootparent> What's the value in making an algorithm that's drastically slower? Perhaps as an important stepping stone? Deferred optimization and all that. reply paidcompute 18 hours agoprevPretty impressive reply adamnemecek 18 hours agoprevBoth ml and A* are integral transforms. reply Salgat 18 hours agoparentWhat do you mean by that? reply abdellah123 19 hours agoprev [–] what's with Cornell University??! They produce constant amazing papers and projects on AI reply losvedir 19 hours agoparent [–] What makes you say Cornell? Isn't this from Meta? reply tekknolagi 18 hours agorootparent [–] I think it's either a joke or misunderstanding about arxiv reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Searchformer is a Transformer model designed to tackle intricate planning tasks with fewer search steps than conventional methods.",
      "It surpasses baseline performance in maze navigation and Sokoban puzzles, indicating potential for handling more extensive decision-making tasks.",
      "Training Transformers to anticipate search dynamics proves beneficial, enhancing performance with reduced model sizes and training data."
    ],
    "commentSummary": [
      "Transformers are being explored for robot motion planning, showing potential for generating optimal paths quicker than prior techniques in tackling high-dimensional and continuous problems.",
      "Debates encompass alternative algorithms, technologies, and drawbacks of transformers, emphasizing AI's role in enhancing classical algorithms and the efficiency contrast between transformers and conventional methods like A*.",
      "Discussions involve model nomenclature in AI, efficiency comparisons between transformer models and traditional strategies such as A*, and the examination of exploratory decision-making algorithms like Bellman-Ford and MCTS in path planning challenges."
    ],
    "points": 297,
    "commentCount": 118,
    "retryCount": 0,
    "time": 1708689205
  },
  {
    "id": 39486717,
    "title": "Meta's TestGen-LLM: Boosting Developer Productivity",
    "originLink": "https://read.engineerscodex.com/p/metas-new-llm-based-test-generator",
    "originBody": "Share this post Meta's new LLM-based test generator is a sneak peek to the future of development read.engineerscodex.com Copy link Facebook Email Note Other Discover more from Engineer’s Codex Explaining tools and technologies used and created by big tech companies. Become a smarter software engineer in just 7 minutes a week. Over 22,000 subscribers Subscribe Continue reading Sign in Meta's new LLM-based test generator is a sneak peek to the future of development Meta's TestGen-LLM is a sneak peek to the future of developer productivity: specialized, orchestrated, and rigorously filtered Feb 23, 2024 25 Share this post Meta's new LLM-based test generator is a sneak peek to the future of development read.engineerscodex.com Copy link Facebook Email Note Other 2 Share Engineer’s Codex is a publication about real-world software engineering. Subscribe Error Meta recently released a paper called “Automated Unit Test Improvement using Large Language Models at Meta”. It’s a good look at how Big Tech is using AI internally to make development faster and software less buggy. For example, Google is using AI to speed up code reviews. A major win of this paper is that while it integrates LLMs into a developer’s workflow, it also recommends fully-formed software improvements that are verified to be both correct and an improvement to current code coverage. Compare this to GitHub Copilot, where suggestions still have to be manually verified to work by the human - and we all know that debugging code is twice as hard as writing it. Meta claims that this “this is the first paper to report on LLM-generated code that has been developed independent of human intervention (other than final review sign off), and landed into large scale industrial production systems with guaranteed assurances for improvement over the existing code base.” Furthermore, there are solid principles that developers can take away in order to use AI effectively themselves. Table of Contents (total read time: 7 minutes): Key Points (1 minute read) Stats (1 minute read) Actionable Takeaways ← if you’re short on time, just read this! (3 minute read) How TestGen-LLM Works (2 minute read) SWE Quiz is for ambitious developers who want to make sure their software fundamentals are rock solid. Reveal gaps in your knowledge and make sure you really know what you’re doing both at work and while interviewing. Take the tests for authentication, caching, databases, API Design, and more. Check out SWE Quiz Key Points TestGen-LLM uses an approach called ‘Assured LLM-based Software Engineering’ (Assured LLMSE), using private, internal LLMs that are probably fine-tuned with Meta’s codebase. This means that it uses LLMs to generate code improvements that are backed by verifiable guarantees of improvement and non-regression. TestGen-LLM uses an ensemble approach to generate code improvements. This means that it uses multiple LLMs, prompts, and hyper-parameters to generate a set of candidate improvements, and then selects the best one. This approach can help to improve the quality of the generated improvements. TestGen-LLM is specifically designed to improve existing human-written tests rather than generate code from scratch. TestGen-LLM has been integrated into Meta's software engineering workflows. This means that it can be used to automatically improve tests as part of the development process. It would be cool to see some screenshots of how exactly it’s integrated, but the paper doesn’t provide any. Source: Page 5 Stats These stats are either direct quotes or paraphrased quotes from the paper. The image above shows that: in an evaluation on Reels and Stories products for Instagram, 75% of TestGen-LLM test cases that were generated built correctly, 57% passed reliably, and 25% increased coverage. TestGen-LLM was able to improve 10% of all classes to which it was applied and 73% of its test improvements were accepted by developers, and landed into production. In a “test-a-thon” between engineers, where various Meta engineers created tests in order to increase Instagram’s test coverage, “the median number of lines of code added by a TestGen-LLM test was 2.5.” However, one test case “hit the jackpot” and covered 1,326 lines. This is a really important stat, which I iterate upon below. All improved cases generated during the “test-a-thon” did “cover at least one additional valid corner case, such as an early return and/or special processing for special values such as null and empty list.” Source: Page 7 Actionable Takeaways TestGen-LLM is a good example of how LLMs can be used to improve dev productivity and software reliability in a time-efficient manner. There are a few takeaways I got from reading this paper that give us a look both to how Big Tech is implementing LLMs internally and to how any developer or engineering manager reading this can use LLMs in a more productive manner. (Note: many of these are my own personal opinions that I’ve taken away from the paper.) Incremental, integrated improvements for specialized use cases Small context windows and scattered dependencies make LLMs nearly unusable for non-boilerplate solutions in large codebases. Aside from any privacy concerns, it’s not feasible to paste in multiple files of code into an LLM when there could be 20+ dependencies from across a codebase in a C++ header file (as an example). Even if you do paste in multiple files, there is a time and cognitive cost to actually using and trying the code outputted by an LLM in a chat window or even in the code editor by GitHub Copilot. The price of extra cognitive load cannot be understated. Hacker News commenters find the inaccuracies of GPT-based tooling exhausting and unreliable. This is where the verification of outputs being both valid and non-regressive is extremely important. This means that for a long-term productivity boost in large codebases, improvements will probably come in incremental, specialized use cases, like test generation and automatic suggestions during code reviews. These are also low risk ways to save cumulative developer time. Basically, “GPT wrappers” will continue to be useful 🙂. Finding and catching edge cases The real value of LLMs here are displayed through the edge cases. The paradox of writing good code is that nobody ever gets credit for fixing problems that never happened. Will Wilson writes: “The fundamental problem of software testing… is that software has to handle many situations that the developer has never thought of or will never anticipate. This limits the value of testing, because if you had the foresight to write a test for a particular case, then you probably had the foresight to make the code handle that case too. This makes conventional testing great for catching regressions, but really terrible at catching all the “unknown unknowns” that life, the universe, and your endlessly creative users will throw at you.” Most of the test cases created by Meta’s TestGen-LLM only covered an extra 2.5 lines. However, one test case covered 1326 lines! The value of that one test case is exponentially more valuable than most of the previous test cases and exponentially improves the value of TestGen-LLM. LLMs can vigorously “think outside the box” and the value of catching unexpected edge cases is very high here. In fact, it’s so high that the creator of FoundationDB’s startup, Antithesis, is entirely based on the fact that software testing edge cases are best found by AI. For reference, FoundationDB was acquired by Apple and is the basis for Apple iCloud’s billions of databases. Orchestration, pipelines, and processing are required Base model LLMs aren’t “plug-n-play\" and shouldn’t reasonably ever be expected to. Sure, they might output pristine React and Tailwind CSS code, but that’s a narrow use case in most production codebases. They need a fair amount of processing and filtering for code generation tasks that require correctness. Part of this processing means grounding LLMs with examples. Google and Meta both make suggestions based on existing code, where the results are much, much better than raw generation. LLMs used in production should take ideas from how Meta processes and filters LLM outputs, and most outputs should be expected to be discarded. Integrations win LLMs do work best integrated into workflows. This is a reason why GitHub Copilot is so popular and another reason why Google’s Workspace integrations are a great idea. Asking a chatbot works great for certain use cases, like debugging and boilerplate code generation, but chatbots can often fail at more complex use cases. How TestGen-LLM Works TestGen-LLM applies a series of semantic filters to candidate solutions generated by Meta’s internal LLMs, making sure that only the most valuable tests are preserved. Here’s how it works: Filter 1: Buildability: Initially, TestGen-LLM checks if the generated code can be built within the app's existing infrastructure. Any code that fails to build is immediately discarded. Filter 2: Execution (does the test pass?): Next, the system runs the tests that passed the buildability filter. Any test that doesn't pass is discarded. This step is crucial because, without a way to automatically determine the validity of a failing test (whether it's due to a bug or an incorrect assertion), TestGen-LLM opts to keep only those tests that can be used for regression testing (aka making sure they can protect current code against future regressions). Filter 3: Flakiness: To address the issue of flakiness (tests that pass or fail inconsistently under the same conditions), TestGen-LLM employs repeated execution. A test must pass consistently across multiple (five) executions to be considered non-flaky. Filter 3: Coverage Improvement: Finally, to ensure that new tests actually add value, TestGen-LLM evaluates them for their contribution to test coverage. Tests that do not enhance coverage by exploring new code paths or conditions are discarded. Only tests that provide new insights or protect against regressions are kept. These processing filters are pretty important as they guarantee improvements to a test suite. It also shows that LLMs are very far from being “plug-and-play.” The tests that successfully pass through all these filters are guaranteed to enhance the existing test suite, offering reliable regression testing capabilities without duplicating effort or wasting resources. Pre- and post-processing steps in TestGen-LLM facilitate the extraction and reconstruction of test classes, streamlining the integration of new tests into the software development workflow. Conclusion This paper is a good formalization of an use case that many devs probably already use LLMs like ChatGPT, Gemini, and Mistral/LLaMA for. Keeping it in writing is a good way of tracking the progress of future improvements on LLMs in the software reliability space. Unit tests are probably the lowest, most basic level of code generation where LLMs have the most immediate value, but as time goes on, we’ll definitely see LLMs be able to catch and test for bugs in increasingly complex software systems. The question is - will that make software easier to develop in the long run or will it lead to a proliferation of software complexity in the future? If you want to read more about complex real-world software engineering explained simply, consider subscribing to Engineer’s Codex. It’s free :) Subscribe Error 25 Share this post Meta's new LLM-based test generator is a sneak peek to the future of development read.engineerscodex.com Copy link Facebook Email Note Other 2 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=39486717",
    "commentBody": "Meta's new LLM-based test generator (engineerscodex.com)292 points by ben_s 11 hours agohidepastfavorite141 comments ajmurmann 8 hours agoI find it interesting that generally the first instinct seems to be to use LLMs for writing test code rather than the implementation. Maybe I've done too much TDD, but to me the tests describe how the system is supposed to behave. This is very much what I want the human to define and the code should fit within the guardrails set by the tests. I could see it as very helpful though for an LLM to point out underspecified areas. Maybe having it propose unit tests for underspecified areas is a way to do look at that and what's happening here? Edit: Even before LLMs were a thing, I sometimes wondered if monkeys on type writers could write my application once I've written all the tests. reply skissane 8 hours agoparent> Maybe I've done too much TDD, but to me the tests describe how the system is supposed to behave. This is very much what I want the human to define and the code should fit within the guardrails set by the tests. People who work on legacy code bases often build what are called “characterisation tests” - tests which define how the current code base actually behaves, as opposed to how some human believes it ought to behave. They enable you to rewrite/refactor/rearchitect code while minimising the risk of introducing regressions. The problem with many legacy code bases is nobody understands how they are supposed to work, sometimes even the users believe it is supposed to work a certain way which is different from how it actually does - but the most important thing is to avoid changing behaviour except when changes are explicitly desired. reply makeitdouble 3 minutes agorootparentYes. There's also other (better) ways to solve this issue: for instance sampling input/outputs in production and srtting them in stone in the tests. An issue with going with llms will be to validate if the behavior described are merely tolerated or if they're correct. Another will be wether something is actually tested (e.g. a code change still wouldn't break the test). Too granular output check would be an issue as well. All in all this feels like a bad idea, but I hope to be wrong. reply ajmurmann 7 hours agorootparentprevAgreed, that's a great use case for autogenerated tests. reply dmarchand90 2 minutes agorootparentFrom my experience I use llms for writing tests because llms are much better at writing tests than the application code. I suspect this might be due to the fact that the code ends up being a very detailed and clear prompt to the llm. reply totetsu 8 hours agorootparentprevCouldn’t an llm provided with the right level of logs write really good characterization tests? reply skissane 7 hours agorootparentA significant part of writing characterisation tests can be simply staring at a code coverage report and asking “can I write a test (possibly by modifying an existing one) which hits this line/branch”. Sometimes that’s easy, sometimes that’s hard, sometimes that’s impossible (code bases, especially crapulent legacy ones, sometimes contain large sections of dead code which are impossible to reach given any input). An LLM doesn’t have to always get it right to be useful-have it generate a whole bunch of tests, run them all, keep the ones which hit new lines/conditions, maybe even feed those results back in to see if it can iteratively improve, stop when it is no longer generating useful tests. Hopefully, that addresses most of the low-hanging fruit, and leaves the harder cases to a human. There already exist automated test generation systems which can do some of this–for example, concolic testing-but an LLM can be viewed as just another tool in the toolbox, which may sometimes be able to generate tests which concolic testing can’t, or possibly produce the same tests quicker than concolic testing would. There is also the potential for them to interact synergistically - the LLM might produce a test which concolic testing couldn’t, but then concolic testing might then use that to discover further tests which the LLM couldn’t. reply crowcroft 8 hours agorootparentprevThe seems like a perfect use case. Quickly find all the foot guns you didn’t know to look for. reply wahnfrieden 7 hours agorootparentas long as you have process to dismantle the tests and move fully over to a new system, if you are indeed migrating/upgrading. leaving a legacy thing dangling and tightly coupled tests lingering for years happens easily when going from 95% to 100% can cost too much for management and stakeholders in various ways relative to other pressing needs reply skissane 6 hours agorootparent> as long as you have process to dismantle the tests and move fully over to a new system, if you are indeed migrating/upgrading. leaving a legacy thing dangling and tightly coupled tests lingering for years happens easily when going from 95% to 100% can cost too much for management and stakeholders in various ways relative to other pressing needs Characterisation tests are not supposed to be tightly coupled – they are supposed to be integration/end-to-end tests not unit tests – the point is to ensure that some business process continues to produce the same outputs given the same inputs, not that the internals of how it produces that output are unchanged. Code coverage is used as an (imperfect) measure of how complete your set of test inputs is, and as a tool to help discover new test inputs, and minimise test inputs (if two test inputs all hit the same lines/branches, maybe it is wasteful to keep both of them–although it isn't just about code coverage, e.g. extreme values such as maximums and minimums can be valuable in the test suite even if they don't actually increase coverage.) They can take the form of unit tests if you are focusing on refactoring a specific component, and want to ensure its interactions with the rest of the application are not changed. But at some point, a larger redesign may get rid of that component entirely, at which point you can throw those unit tests away, but you'll likely keep the system-level tests reply benreesman 5 hours agoparentprevAt the risk of telling you something you already know, I’d bring to your attention for example property-based testing, probably most popularized by Hypothesis, which is great wud I recommend, but by no means the only approach or high-quality implementation. I think QuickCheck for Haskell was around when it got big enough to show up on HN. Just in case any reader hasn’t tried this, the basic idea is to make statements about code’s behavior that are weaker than a totally closed-form proof system (which also have their place) stated as “properties” than are checked up to some inherently probabilistic bound, which can be quite useful statements. The “canonical” example is reversing a string: two applications of string reverse is generally intended to produce the input. But with 1 line of code, you can check as many weird Unicode edge cases or whatever as you have time and electricity. I know this example seems trite, but I met this because some hard CUDA hackers doing the autodiff and kernels and shit that became PyTorch used it to tremendous effect and probably got 5x the confidence in the code for half the effort/price. It doesn’t always work out, but when it does it’s great, and LLMs seems to be able to get a Hypothesis case sort of, closer than starting from scratch. reply TeMPOraL 2 hours agoparentprevFWIW, writing implementation is much more pleasant/interesting experience, because you're writing the actual thing the application is supposed to do. In contrast, when writing tests, you're describing what the application is supposed to do, using an extremely bloated, constrained language, requiring you to write dozens or hundreds of lines of setup code, just to be able to then add few glorified if/else statements. In my experience, at least in languages like C++ or Java, unit tests are made of tedium, so I'm absolutely not surprised that the first instinct is to use LLMs to write that for you. reply robryk 58 minutes agorootparentThis is my experience, unless I try to make the contract of the thing simple to test via property testing. Then, writing tests often becomes basically an exercise in writing down the contract in a succinct way. Sadly, this is a rare approach, so if you cooperate with others it's hard to use it. reply janosdebugs 1 hour agoparentprevThis kind of thinking is sadly lost on many. I have seen copious amounts of nonsensical tests slapped full of hard-wired mocks and any change in the functionality would break hundreds of tests. In such a scenario an LLM might be the bandaid many are looking for. Then again, the value of such tests is questionable. reply robryk 10 minutes agorootparentMy best example of that was a test that was asserting that a monitoring metric changes in some way with a comment expressing doubt whether the asserted values are correct (but whoever wrote it still wrote the test that enshrined the behaviour that they themselves doubted). reply xboxnolifes 8 hours agoparentprev> I find it interesting that generally the first instinct seems to be to use LLMs for writing test code rather than the implementation. Maybe I've done too much TDD, but to me the tests describe how the system is supposed to behave. This is very much what I want the human to define and the code should fit within the guardrails set by the tests. I feel the same way about how test code is viewed even outside of AI. A lot of the time the test code is treated as a lower priority code given to more junior engineers, which seems like the opposite of what you would want. reply pydry 1 hour agorootparentThis is how I feel too. For me, tests usually end up being a concrete specification which I can execute. Getting LLMs to write tests is like getting LLMs to write my spec. reply zeroonetwothree 8 hours agorootparentprevWhen I do code review I always review the tests first. If they look through and reasonable then I can be a lot less careful reviewing the rest. reply postalrat 4 hours agorootparentTests never cover everything so exactly what are you looking for? reply anu7df 5 hours agoparentprevI really believe this \"application\" is the result of thinking about tests as a chore and requirement without great benefits. Your thought of LLM writing application give the tests is interesting also from test pass/fail as optimization that ca be run online by the LLM to improve the result without human feedback. reply grogenaut 6 hours agoparentprevOne reason I can think of is that many engineers really don't do testing. They write tests after the fact because they have to. I've worked with a bunch of engineers who will code for days then write a few tests \"proving\" the system works. They have low covergage and are usually brittle. This system would be a godsend in the minds of engineers who think / operate that way. I've also had managers who told me I wasn't allowed to write tests firsts as it was slower. Luckily I was able to override / ignore them as I was on loan \"take it up with my boss\". They're probbably thinking the same as the above engineers. Another way to think of this is most devs hate documentation... if they had an AI that would write great docs from the code they'd love it. And these to these devs docs they don't have to write are great docs :) reply tjpnz 4 hours agorootparent>I've also had managers who told me I wasn't allowed to write tests firsts as it was slower. Sounds like a great place to work. reply MASNeo 1 hour agoparentprevIf you had as many monkeys as parameters in LLM they might run your business ;-) I dread the morning after a night of getting something to work…somehow. reply pokstad 7 hours agoparentprevI agree, humans should write tests. Humans are the oracles of the program output who know whether the code did the right or wrong thing. I’m guessing they want to automate tests because most engineers skimp on them. Compensating for lack of discipline. reply mrbonner 8 hours agoparentprevI wrote a simple LLM backed chat application. My primary usage right now is to copy paste the code I have written (Java and Python) into the chat and ask it to generate unit test cases. I think it has reduced my development time a huge amount. It also generates tests for edge cases. The generated code usually are usable 90% of the time. It also is very good at making mocks for service calls. I'm using Claude 2.1 model with Bedrock. It's nowhere as fancy as FB tool but I know it is blessed by company. reply makk 5 hours agoparentprev> I find it interesting that generally the first instinct seems to be to use LLMs for writing test code rather than the implementation. When you try to get the LLM to write the code, you find that it’s easier to get it to write the tests. So you do that and publish about that first. reply closeparen 5 hours agoparentprevCovering all the \"if err != nil { return err }\" branches in Go is pretty mindless work. reply madeofpalk 8 hours agoparentprev> This is very much what I want the human to define and the code should fit within the guardrails set by the tests. Most systems are pretty predictable. it(\"displays the user's name\") isn't very novel, and is probably pretty easy for a LLM to generate. reply ajmurmann 4 hours agorootparentWell, someone needs to define that the username should be shown in the first place reply ralusek 8 hours agoparentprevI basically agree with this but some caveats. I often find there are maybe 5% of the tests I should write that only I could write, because they deal with the specifics of the application that actually give it its primary purpose/defining features. As in, it's not that there is any test I believe AI eventually wouldn't be able to write, it's more that there are certain tests that define the \"keyframes\" of the application, that without defining explicitly, you'd be failing to describe your application properly. For the remaining 95% of uninteresting surfaces I'd be perfectly happy to let an AI interpolate between my key cases and write the tests that I was mostly not going to bother writing anyway. reply ajmurmann 8 hours agorootparentYou are probably right and the percentages change with the language and framework being used. When I write Ruby I write enormous amounts of tests and many of these could probably be derived from the higher-level integration tests I stared with. In Rust on the other hand, I write very few tests. I wonder if this also shows which code could be entirely generated based on the high-level tests. reply nicklecompte 10 hours agoprevI don't want to review this whole thing but one part in particular seems way off. [Caveat: I sorta-read the original paper shortly after it was posted, my memory is fuzzy and I am only skimming it now.] From the blog: > Most of the test cases created by Meta’s TestGen-LLM only covered an extra 2.5 lines. However, one test case covered 1326 lines! The value of that one test case is exponentially more valuable than most of the previous test cases and exponentially improves the value of TestGen-LLM. LLMs can vigorously “think outside the box” and the value of catching unexpected edge cases is very high here. Of course \"exponentially more valuable\" should set off your BS detector. But to verify, from the paper: > However, this result arose due to a single test case, which achieved 1,326 lines covered. This test case managed to ‘hit the jackpot’ in terms of unit test coverage for a single test case. Because TestGen-LLM is typically adding to the existing coverage, and seeking to cover corner cases, the typical expected number of lines of code covered per test case is much lower....The median number of lines of code added by a TestGen-LLM test in the test-a-thon was 2.5. This is a more realistic assessment of the expected additional line coverage from a single test generated by TestGen-LLM. Nowhere do the authors mention \"unexpected edge cases\" or \"thinking outside the box.\" They clearly present this 1,326 lines of coverage test as a fluke, e.g. maybe the test case checked one branch of a horrible switch statement, or perhaps it was even a fluke in how code coverage is counted. It is noteworthy that the authors do not seem to have looked into it any further, even in the \"qualitative results\" section. Inaccurate editorializing really doesn't help anyone. The internet is too damn full of people pretending to understand things they pretended to read. reply engineercodex 10 hours agoparentHey! Thanks for your comment - I'm the one who wrote this article. I wasn't trying to say that the paper authors talked about \"unexpected edge cases\" or \"thinking outside the box.\" I edited the post to be more clear that some of these takeaways are my own opinions. This article is less of a summary of a paper and rather commentary on what the results of the paper entails. After all, Hacker News is meant for discussion :) I will say though that I do believe that I still stand by the \"exponentially more valuable\" portion. I think the fact that LLMs can fluke their way into \"hitting a jackpot\" in terms of test coverage is exactly why they're so valuable. When you have something constantly trying out different combinations, if it hits even one jackpot, like in the paper, it's extremely valuable to the team. It's a case that could have been either non-obvious or simply too tedious to write a test for manually. I think there's tremendous value in that, especially speaking as someone who has spend way too much time simply figuring out how to test something within a Big Tech codebase (F/G) when I already knew what to test. reply camkego 8 hours agorootparentPedantic warning here. In fast and loose day-to-day common English language \"exponentially more\" means \"fast growth\" or \"a whole lot\". But that usage is meaningless! Why?, technically, you can't have exponential growth without a dependent variable. You can have exponential growth as a function of time, height, spend, distance, any freaking metric or variable. But it has to be as a function of a value. You CAN'T have exponential growth that is not a function of some value or variable or input. I suppose in this case you could argue you have exponential growth as a function of the discrete using-an-LLM or not-using-an-LLM, but I've never heard of exponential growth as a function of a discrete. Often people using the term \"exponential growth\" in common English don't understand what it means. Sorry. reply nicklecompte 8 hours agorootparentprevSeconding digdugdirk's comment :) Thanks for the thoughtful response and I apologize if I came across as mean. My problem is we have no clue what those lines actually were. If it was effectively dead code, then it's not surprising that it was untested, and the LLM-generated test wouldn't be valuable to the team. We have no clue what the value of the test actually was, and using a single stat like \"lines of code covered\" doesn't actually tell us anything. Saying the test was \"exponentially more valuable\" is pure speculation, and IMO not an especially well-founded one. (Sort of like saying people who write more lines of code are more productive.) This speculation seems downright irresponsible when the paper specifically emphasizes that this result was a fluke. When the authors said \"hit the jackpot\" they did not mean \"hit the jackpot with a valuable test\", they meant \"hit the jackpot with an outlier that somewhat artificially juked the stats.\" I truly believe if the LLM managed to write a unusually valuable test with such broad coverage they would have mentioned it in the qualitative discussion. Instead they went out of their way to dismiss the importance of the 1,326 figure. reply digdugdirk 9 hours agorootparentprevThanks for engaging with the above constructive criticism, it's a refreshing change from what is sadly the norm. One additional question - do you forsee any issues with this application where LLMs enter a non-value add \"doom loop\"? I can imagine a scenario where a test generation LLM gets hooked on the lower value simplistic tests, and yet management sees such a huge increase on the test metric (\"100x increase in unit tests in an afternoon? Let's do it again!\") that they continue to bloat the test suite to near-infinity. Now we're in a situation where all future training data is now training on complete cesspool of meaningless tests that technically add coverage, but mostly just to cover an edge case that only an LLM would create. Not sure if that makes sense, but tl;dr - having LLMs in the loop for both code creation and code testing seems like it's a feedback loop waiting to happen, with what seems like solely negative repercussions for future LLM training data. reply samstave 8 hours agorootparentPerhaps there should be domains of focus for the test LLMs - even if they are clones, but assigned to only a particular domain, then their results have to be PR's etc... Why not treat every LLM as a dev contributing to git such that Humans, or other LLms need to gatekeep in case something like that happens? (start by treating them as Interns, rather than Professors with office hours) reply fermentation 9 hours agoparentprevThe incentives at meta around code production are all wrong. The team behind this is absolutely gearing this around lines of code and number of diffs produced. This'll just be another codegen tool creating another mountain of code that is difficult to debug. reply siliconc0w 9 hours agoprevGood testing is hard to do - coverage is not a categorical good. You can easily write too many tests that calcify programs and basically just creates a change-detector program. Oh it looks like you changed something, oh no - all the tests are broken, but it's okay we can now ask the LLM to regenerate them! 100% Coverage! Amazing! What progress! reply suzzer99 9 hours agoparentAgreed. Good tests are an order of magnitude harder than good code. reply brabel 1 hour agorootparentI don't know where you're getting that from but it's simply wrong. Testing is quite easy IMO. I've been working at the same place for almost 10 years and I introduced our testing framework. We have hundreds of thousands of tests. New guys have some trouble to get started, but after a couple of months they're writing tests for our systems like a pro. Most tests are use-case based or written for checking error-handling. Use-case tests are easy to write: you don't even need to be a programmer (in fact, it's good if use-cases are defined by a Product Owner or Tester), though of course some cases are only known to the programmer as they're the only ones who dive into the details. The programmer should come up with all use-cases the PO missed, of course, and judge whether or not they need to test those too... sometimes it's ok to not test as the cost-benefit is low. Anyway, once you have this use-case based test mentality, it's very easy to write the tests (using a proper language to do it is important! Don't use just JUnit if you're doing Java as it will be really tedious to write and you will stop midway - I know, I've been there... I highly recommend using Spock, though other frameworks to make writing test pleasurable exist). This applies mostly for \"integration tests\". For unit tests, hopefully you don't find them difficult to write?! I find them quite easy to write since I know how to write testable code, which takes a while to learn but once you do, it's really easy. If you have examples of difficult to write tests, I would be curious to see it! Perhaps we can discuss how to make them easy. reply viraptor 42 minutes agorootparentThe positive ones (use cases) are usually pretty straightforward. It's once you get to failures like \"how does the whole system recover if one packet, 3 steps into a transaction is corrupted\". If the system is complex enough, that warrants a whole internal fault injection framework and can take a really long time to make it reliable and usable. To be fair most projects don't care beyond \"rollback the database and maybe display a 5xx error or something\". But some do. Anyway, use cases are fine. It's the failures / edge cases that cause pain. reply postalrat 4 hours agorootparentprevWhich is why they should be treated as a waste of time unless specific tests can be justified. reply hinkley 4 hours agoparentprevI know for sure that code with no coverage has terrible tests. For everything else I have to read through five other people’s idea of good test. We are all terrible at writing tests. We just find our own ways to do it. reply pshc 7 hours agoparentprevOne gig I worked had web component tests where they committed a snapshot of the expected DOM and asserted that the component spat it out... so for every subsequent change the dev would naturally hit the re-generate button and commit it all. Plentiful deltas, questionable signal. reply 3abiton 4 hours agoparentprevIt's all about the long tail cases. reply webdood90 9 hours agoparentprev> ... basically just creates a change-detector program interesting perspective - why do you think this is a bad thing? to me, it's an opportunity to verify that the change is intended. without it, how do you know that the program does what it is supposed to do? reply siliconc0w 9 hours agorootparentWithout deliberate tests it can be very difficult and time consuming to parse out intended change from unwanted or incidental change. reply nyrikki 8 hours agorootparentprevIt tightly couples domain needs with implementation details. Thinking of it as a leaky abstraction helps me. I try hard to separate domain logic tests from implementation specific tests. Your code could be loosely coupled with high cohesion, but with lots of random tests like you get when code coverage is a performance metric, you have to add a lot of complexity that only relates to an implementation. reply whoisjuan 9 hours agorootparentprevNo op, but I don’t think test-driven development resounds with everyone who writes code. I don’t want to write tests for everything. I just want to write the ones that matter. reply nyrikki 8 hours agorootparentThat is a common misconception about TDD. TDD is _about_ writing tests that matter, but most people think it is about writing all unit tests first. If you are following TDD anywhere close to the way it is described, you will only be writing tests that relate to domain functionality first. Note how it is described here, although it is turse. https://martinfowler.com/bliki/TestDrivenDevelopment.html The coverage metric as a goal writing style doesn't work for TDD, sorry you were exposed to that. You are correct that model doesn't work. reply elicksaur 8 hours agorootparentprevHow do you know that the tests accurately define what the code is supposed to do? Another way, if you know what the code is supposed to do, why write it down in two places? reply bbojan 2 hours agorootparent> Another way, if you know what the code is supposed to do, why write it down in two places? This would be like criticizing double-entry accounting by asking \"if you know what the amount is, why write it down in two places?\" We write the code down in two places because that gives us advantages that far outweigh the added effort: - Once written, your test will catch regressions forever - A test is often excellent documentation on what the code does - It's now much easier to refactor the code, making it more likely that it will be refactored when needed. reply elzbardico 9 hours agoprevI feel for the future maintainers of all this crappy LLM legacy code in the future. It’s gonna be ugly. reply idle_zealot 9 hours agoparentSurely we will get LLMs to maintain it. reply duderific 9 hours agoparentprevSo, I guess LLMs are actually creating jobs rather than destroying them. Not exactly fun jobs though. reply steve_adams_86 4 hours agorootparentNot exactly well paid either, I suspect. reply bigfudge 9 hours agoparentprevI suspect it will be no worse than enterprisey code. It might even look quite similar, although the comments and docs will be more thorough and less likely to be actively wrong. reply jachee 9 hours agorootparent…unless the LLM hallucinates the comments and docs. reply Nathanba 8 hours agorootparentprevIt will be worse because there will be a lot more of it reply armchairhacker 7 hours agoparentprevJust delete the tests, problem solved. Your CI dashboard even gives you the green checkmark. reply steve_adams_86 4 hours agorootparentThis made me think of that midwit meme with “delete the tests, green check mark in CI” on either side of the graph and “100% coverage” in the centre. Not totally valid, but… A bit of truth, haha. Maybe the right side should be something about fuzzing and using static types. Use systemic and automated checks. I’m a little ashamed that I thought in memes so readily. reply block_dagger 6 hours agoparentprevI too feel compassion for the AI agents that will be dealing with this code. 99% of human developers will be out of the loop by then. reply travoc 6 hours agorootparentI’m old enough to remember the first time they said this about offshoring. reply bongodongobob 9 hours agoparentprevAgreed. LLMs will never get any better than they are right now and haven't improved at all in 2 years. Just fancy Markov chains. The only way they can be used to write code is by people who don't know how to code blindly commiting code to prod without any review whatsoever. People who do know how to code couldn't possibly have a use case and it won't make them any more productive. I'm just going to ignore all this LLM nonsense that isn't changing the world at all and you definitely should too. reply SnowTile 5 hours agorootparentDisagree, I find them very useful to quickly explain new libraries or do tedious things like regex reply Jtsummers 7 hours agoprevQuoting myself (lightly edited) from when the paper itself came up. They misrepresent the stats in their writeup. https://news.ycombinator.com/item?id=39406726 Their abstract doesn't match their actual paper contents. That's unfortunate. Their summary indicates rates in terms of test cases: > 75% of test cases built correctly, 57% passed reliably [implying test cases by context], and 25% increased coverage [same implication] The actual report talks about test classes, where each class has one or more test cases. > (1) 75% of test classes had at least one new test case that builds correctly. > (2) 57% of test classes had at least one test case that builds cor- rectly and passes reliably. > (3) 25% of test classes had at least one test case that builds cor- rectly, passes and increases line coverage compared to all other test classes that share the same build target. Those are two very different statements. They even have a footnote acknowledging this: > For a given attempt to extend a test class, there can be many attempts to generate a test case, so the success rate per test case is typically considerably lower than that per test class. But then in their conclusion they misrepresent their findings again, like the abstract: > When we use TestGen-LLM in its experimental mode (free from the confounding factors inherent in deployment), we found that the success rate per test case was 25% (See Section 3.3). However, line coverage is a stringent requirement for success. Were we to relax the requirement to require only that test cases build and pass, then the success rate rises to 57%. reply acituan 8 hours agoprevUnless well separated, this will easily turn developer-hostile by some clueless management demanding high coverage and enthusiastic juniors smuggling in massive amounts of AI tests so that at the end of the day you will need get a rubberstamp from an hard-to-maintain llm-gen test code each time you want to submit your work. Yes authoring some tests might be sped up but not necessarily maintaining them - or maintaining the code under test because you are not necessarily generating good ones. Not to mention sweating over tests usually help developers with checking the design of the code early on too; if not very testable, usually not a good design either, e.g not sufficiently abstracted component contracts which suck in a context where you need to coauthor code with others. What some people miss is that tests are supposed to be sacrifical code, that most of which will not catch anything during their lifetime - and that is OK because it gives an automated peace of mind and saves from potential false clues when things fail. But that also means max investment into a probabilistic safeguard is not gonna pan out at all times; you will always have diminishing marginal utility as the coverage tops. Unless you're writing some high traffic part of the execution path - e.g. a standard library - touting high coverage is not gonna pay off. Not to mention almost always an ecology of tests need be there - not just unittests but integration, system etc - to make the thing keep chugging at the end of the day. Will llm's sit at the design meetings and understand the architecture to write tests for them too? Or what they can do will be oversold at the expense of what should be done. A sense of \"what is relevant\" is needed while investing effort in tests - not just at write-time but also at design-time and maintain-time - which is what humans are pretty OK at, and AI tools are not. What llms can save time with is keystrokes of an experienced developer who already has a sense of what is a good thing to test and what is not. It can also be - and has been - a hinderance with making the developers smuggle not-so-relevant things into the code. I don't want an economy of producing keystrokes, I want an appropriately thought set of highly relevant out keystrokes, and I want the latter well separated from the former so that their objective utility - or lack thereof - can be demonstrated in time. reply paradoxyl 7 minutes agoprevJust another way to censor the free speech of those who opppose the technocracy, or \"private-public partnership\" or whatever weasel words they use to take away freedom from the masses. reply sandGorgon 1 hour agoprev>using private, internal LLMs that are probably fine-tuned with Meta’s codebase. what does this mean ? i would have thought they would simply use codellama. is there any research around privately finetuned code llms ? why would they be better ? reply aussieguy1234 9 hours agoprevAlready done it with GPT-4. I showed it a TypeScript module, asked it to generate a unit test and it made a working test not only covering the happy paths but a few edge cases as well. reply ramoz 8 hours agoparentYea… agree. I’m not resonating with the downvotes here on similar comments. ChatGPT goes above and beyond for me in many ways. Tests seem… easy in terms of gpt capabilities. Last week I had it write python that traversed an AST and construct a react flow graph as well as the component. I made no edits, went through a few iterations of prompt feedback, and it worked great. Many similar interesting abilities I’ve observed from gpt. reply galaxyLogic 3 hours agoprevHow does the AI know what tests it should write? I think this is an interesting experiment but somewhat dubious. The way I see AI would best help software development is that I the programmer have a question about my or somebody else's code, which the AI then answers, sometimes with a code-proposal but not always. It should be able to answer questions like \"Is there a way to simplify this code? What are some inputs that would cause an error?\" etc. AI should help us understand the code, and understand how to improve it. Not write all of it on its own because if we don't tell it what to do, it cannot know what we want it to do. Tests is a good example. What do we want it to test? reply TeeWEE 2 hours agoprevThe proof is in the pudding, show me the code! In my experience LLM are smart but sometimes inconsistent and over a long chat it might say things that are logically self contradictions… when you tell it that it confirms it. It just seems like it lacks a consistent world view. I don’t trust them yet. Maybe with even more scale they become better. They act a little bit like young children, with a lot of domain knowledge. reply MASNeo 1 hour agoprevOk, so test case generation has been around a while and now that it is working, where is the GitHub Action? reply samsk 11 hours agoprevFinally some AI Codegen, that makes sense to me. reply ShamelessC 11 hours agoparentFinally? reply refulgentis 10 hours agorootparentThere's a persistent rather large minority that has a nuanced take: it can't write code they like (don't want to edit), but it's great for weekend projects (where they're trying new things without established personal preferences). Forest for the trees if you ask me, but, to each their own. reply skissane 10 hours agorootparentSometimes, I find writing pseudocode easier than code. And then I ask an AI to turn it into code. Sometimes the results aren’t too bad, and just need a few tweaks for me to use it-overall I’ve saved mental effort compared to translating the pseudocode into code by hand. And if the results aren’t useful, I’ve only wasted a few seconds, and then I just have to do it manually. reply huytersd 10 hours agorootparentprevnext [2 more] [flagged] plufz 10 hours agorootparentI don’t know if I’m slow but I try to use ML for dev work but I have a hard time using it to be productive. Maybe it is because I don’t want to use GPT and copilot but I rather use local codellama, mistral, dolphin, etc. But I have found very limited use for it. I use ML for other things like transcriptions with whisper, translations with m2m100 and summerizing articles with custom python scripts and different models. Not even the simplest things like convert this Apache conf to nginx works in a satisfactory way. It can’t solve bugs. It can’t help me with like edge cases for weird libraries etc. It’s like it only can help me with very obvious things that is quicker to just write myself. How do you use it? reply Fricken 2 hours agoprevMeta likes to release positive news about itself in the wake of it's competitors misfortunes. reply avereveard 2 hours agoprevDevelopers will do anything not to write tests reply anoopelias 6 hours agoprevI thought that unit tests are a balance. A balance of not too much, not too little. \"Too little\" means you are not covered on the edges. \"Too much\" means the tests are too rigid its scary to change the code. Ideally, \"one change\" (Whatever that might be) in production code should cause exactly 1 test to fail. How does TestGen-LLM address this problem? reply gxt 10 hours agoprevElementary tests, like unit tests, should be mecanically generated by walking the AST, differences ack`d and snapshoted when commiting. Every language should come with this built-in. reply bluefishinit 10 hours agoparentThis is called compiling with a type system. reply superb_dev 10 hours agoparentprevWhat exactly are we testing at that point? reply Groxx 9 hours agorootparentEnsuring that `if x == 1` works when x == 1. Very important. Very valuable. Imagine if `if err != nil { return err }` just stopped working tomorrow. Your tests would detect it! Outage prevented! reply Cthulhu_ 9 hours agorootparentYou're being sarcastic but honestly, I've never found a regression because of a unit test. Only past few days though, I did find two bugs that would've been prevented if the original code was covered by a decent unit test. reply sangnoir 6 hours agorootparent> You're being sarcastic but honestly, I've never found a regression because of a unit test So you've never made a change caused a unit test to fail? If not, how large is your codebase, and is ownership shared across multiple teams? I caught dozens of latent or unreported bugs by writing unit tests for a 6kloc JS app which had 0% coverage before. reply cgdub 9 hours agorootparentprevI don't write Perl or Ruby anymore, but this would have been immensely helpful back then. reply yes_man 8 hours agoprevI think the future of development is the other way around. Devs and PMs define the goalposts with tests, AI will handle the implementation reply romwell 10 hours agoprevYeah, after working in semiconductor industry (computational lithography) where test-driven design is the norm... I'm not convinced. I'm not saying that writing tests before the production code is something that should always be done. But tests are just as much a part of the codebase as anything else, and absolutely must be written alongside the code being tested. The most important part of the test is that it showcases intent of the developer. A test suite demonstrates the following: * How the code should be used * What the code does * What the code doesn't do * What it was written for Then when that code is used or modified by another developer, they don't have to hunt for clues in the codebase like they're Sherlock Holmes. If the tests aren't telling a story, you're writing tests wrong. And until the computers gain the ability to read your mind and do a better job at understanding what you want to do, AI/LLM-based generators can't do this job for you. Of course, if the only goal of your test suite is getting a green checkmark on a pre-commit check (and being able to show great coverage numbers), then yeah, you can double your productivity with AI. Automatic code generators will surely help you write more bad code at lightning speed. And if others complain that tons of boilerplate make the code bloated and hard to understand — just tell them to use AI to deal with it. Worked for you! That really does seem to be the future of development. But not the future I'm looking forward to. reply azeirah 10 hours agoparentI agree with almost everything you said, although I do think this type of testing has a place. There are different types of testing, what you're describing sounds to me like testing the \"core\" of your code, part documentation, part validation, part stability, etc. Other types of testing like fuzzing provide an entirely kind of value. I believe this AI- driven testing can inherit a space to target tests at the tail end of the distribution, many tests with little value. Providing extra coverage where human energy and time is lacking. That is how I see the current state of AI tooling regardless, as a cognitive assistant. I'd be surprised if this line of research doesn't end up being very fruitful in the coming years. reply romwell 9 hours agorootparentThat I can fully agree with (particularly, comparison with fuzzing). Your comment presents a way more grounded perspective on the future of LLMs in programming than the article does. reply yes_man 8 hours agoprevI think the future of development is the other way around. Devs and PMs define the goalposts with tests, AI will do the implementation reply cavisne 7 hours agoprevDoesn’t meta famously not do much testing at all? Ie they use experiments to “test in prod”. reply Temporary_31337 1 hour agoprevAll this to write another CRUD app ;) reply jimbob45 7 hours agoprevFor greenfield projects, these LLM coders would be invaluable. For my old codebase with observed requirements and magic numbers? Lol it’s going to be just as confused as I am. reply peter_l_downs 11 hours agoprevnext [4 more] [flagged] engineercodex 10 hours agoparentOuch - half of the article (the \"Actionable Takeaways\" section) was my own commentary. The summary was for those who didn't want to necessarily parse through the entire paper's PDF. Happy to listen to any constructive feedback if you have any, though! reply dvaun 11 hours agoparentprevnext [3 more] [flagged] engineercodex 10 hours agorootparentI inserted these because I personally like reading related discussions and articles of topics at hand. Not sure how this is a negative :/ reply dvaun 4 hours agorootparentYou’re right. That was undeserved, my apologies. Edit: I’d like to note that your writing was fun to read—my comment was instead leaking a bad mood I had at the time. reply holoduke 11 hours agoprevI am using copilots now since a few months and it really makes me a 2x more productive developer. Its like you become an orchestrator of a dev team. You still need to look into details, but things just flow much much faster. I can only imagine how it will be like if I also have access to a AI debugger / end to end tester. Completing the loop and making it super efficient. Also think that this is not only the case for developers. Even for lawyer it could be the same thing. Expected production output of a worker is going to rise. The ones who do not embrace AI assistants in the near future will have a hard time in the future. reply zdragnar 11 hours agoparent> Even for lawyer it could be the same thing Funny you mention that, since lawyers have already gotten in trouble for citing fictional cases when submitting work performed by chatgpt. It's useful for rote things, but for anything that you depend on, you still need to give it just as much attention as if you'd done it yourself. reply skissane 10 hours agorootparent> Funny you mention that, since lawyers have already gotten in trouble for citing fictional cases when submitting work performed by chatgpt. For something like legal work, you don’t want a raw LLM. You want an agent integrated with a legal database, in such a way that it can’t cite cases which don’t exist in the database. And it can’t generate a direct quote from a case unless that text actually occurs in the case. You still need a human lawyer familiar with the law to pick up on subtler errors, but better technology can prevent the grosser ones. And the subtler errors (e.g. misrepresenting what a case says through partial or out of context quoting) is the kind of error human lawyers sometimes make too - like every other profession, lawyers vary greatly in their competence, and often only the grosser cases of incompetence incur sanctions reply zmgsabst 9 hours agorootparentTried Lexis+ AI, and… it’s just not very good yet. Much like ChatGPT, it can only handle recall and summation — and even then, I don’t fully trust it because it often misses key ideas. And much like ChatGPT, it can’t do anything coherent at length without a lot of help and working around its faults. And seems entirely unaware of similar sounding words having distinct legal meanings. Which is not good. reply skissane 8 hours agorootparent> Tried Lexis+ AI, and… it’s just not very good yet. I wonder to what extent that’s due to current inherent limitations of the technology, and to what extent it is due to quality of implementation issues. It is hard to say because (I presume) there is only limited public information on how it is actually implemented. e.g. which LLM is it using? How much fine-tuning has been done? Are they using other potentially helpful techniques such as guided sampling? Or breaking down the task into parts and having multiple agents each specialised to handle one particular part? > Much like ChatGPT When you compare it to ChatGPT, do you mean GPT3.5 or GPT4? I also would guess that certain areas of law (especially criminal law) may be prone to triggering “safeguards” which result in poorer performance than if those safeguards were absent. Arguing that what your client did was legal (even be it ethically unsavoury) is an essential part of a lawyer’s job reply cloverich 10 hours agorootparentprev> you still need to give it just as much attention as if you'd done it yourself. It's different than a Lawyers case, where the facts require manually cross referencing. In our case, that verification can come via directly and immediately running the code. How good the actual code is varies, but the fundamental difference remains. reply qup 11 hours agorootparentprevI agree, but it does change the shape of the work you would be doing. Validating work isn't the same as generating new work. Whether that's better, or useful, probably differs by situation. reply blibble 10 hours agorootparent> Validating work isn't the same as generating new work. in many cases it's way harder reply unshavedyak 11 hours agoparentprevI still haven't figured out how people use this that much. I use LLMs almost daily via ChatGPT, Phind, Kagi Ultimate (my current one), etc. However i spend too much time pushing the LLM towards my goal that i can't imagine it speeding my coding up. I clearly find value in LLMs to some degree, but speeding up my coding is not yet one.. i'd love to, but i just don't understand. I can only imagine typing more in explanation for the LLM than it would take me to write it to begin with. reply azeirah 10 hours agorootparentFor myself I have several distinct cognitive weaknesses that I can often just unload onto an AI in a conversational style. For instance I know I'm good at breaking up large tasks into smaller ones, but because planning and executive functioning is by far my worst energy consuming skill (adhd) I can save a lot of energy (but not time) by approaching it conversationally. I'd often use colleagues for the same thing, but then my productivity costs 2 salaries Similarly, I have some trouble with memory and cognitive speed when I'm tired which is unfortunately often the case due to my health, I know well enough what I kinda \"want\" to do and I let the AI generate something that comes near what I need and I can work from there once I have the right starting point. Just my personal experience I'd wanted to share. reply freedomben 10 hours agorootparentprevIt all seems to depend on what you are doing. The more niche and technical the task, the less the AI can help. If you are just generating crud and points for a common web language and framework, it can be an 80% boost. I think the real problem with this is that people aren't differentiating these different types of work when they give these numbers. reply ickyforce 9 hours agorootparentIt's not just the type of work but also experience. Here are two cases: 1. After working for many years in Java I needed to build a service. I spent few days designing it and then a month on implementation. I used DBs and libraries I knew very well. I didn't need to access google/stackoverflow, I didn't need to look up names of (std)lib methods and their parameters and if something wasn't working it was fairly obvious what I needed to change. 2. Recently I wanted to create a simple page which fetched a bunch of stuff from some URLs and showed the results, simple stuff. But with React since that was what frontend team was using. I never used React and rarely touched web in the recent years. Most of my time was spent googling about React and how exactly CORS/SOP work in the browsers, and with polishing it took a couple of days. I'm pretty sure that in case 1) AI wouldn't help me much. Maybe just as a more fancy code completion. In case 2) AI would probably be a significant time save. I could just ask it to write some draft for me and then I could make few tweaks, without having to figure out React. But somehow nobody quantifies their experience with the languages/tools when they are using AI - I'm sure there's a staggering difference between 1 month and 10 yoe. reply samatman 6 hours agorootparentprevSo I wanted to take a heatmap and bin it into fifteen values on a logarithmic basis. So I asked ChatGPT to do it for me, and it just worked. Would this have been difficult for me to just write? No. I wouldn't call it difficult. But it would have involved effort, which is a resource I'm happy to conserve. It's like the difference between a sandwich you make and a sandwich you ask someone to make. Then I asked it to generate the integer ranges which correspond to each bucket. It screwed that one up, which I found out by copying the function to a scratch file and trying some representative values in the REPL. So I told it to iterate all the values between in and max and generate the ranges that way. That one worked. Net of less effort, plus I had a test for it which I could copy-paste from the REPL to the test suite. Faster? Maybe, maybe not. But I'm rate-limited by gumption, not minutes. When it's easier to describe the function than write it, and it's simple enough that the robot won't screw the pooch, I hand it off to the LLM. It's a great addition to the toolkit. reply swatcoder 10 hours agorootparentprevSome revered novelists spend all day to write a single page and others are able to get in a flow and produce a chapter in that same time. Without getting into touchy questions of quality and talent and the whole 10x trope, there are a lot of working engineers out there that produce code a lot more slowly than others and that work on more common problems than others. My sense is copilot-like products provide the biggest boon to those people and are a lot harder for people who are more naturally prolific or who work on more esoteric things. reply holoduke 7 hours agorootparentHave you ever tried it?. It sounds like you are a bit against the idea of an AI supporting your work. reply block_dagger 6 hours agorootparentprevTry this: in a situation where you need a small change to an existing class that you haven't looked at in a long time, dump the code and spec to ChatGPT with a request to add the feature or make the change along with a supporting spec. This can really speed up getting to the final result. reply oblio 10 hours agorootparentprevIMO a chunk of it is like Peel developers: people that prioritize their own speed above all else: readability, team reviews, etc. I'd love to be proven wrong. reply 010101010101 10 hours agorootparentprevI rarely find interfacing with an external chat interface useful, but integration with the coding environment (e.g. Copilot) is an immediate productivity boost. reply okdood64 5 hours agorootparentprevThe co-pilot equivalent tool I use makes me about 10-15% more productive. Noticeable but not life changing. reply holoduke 8 hours agorootparentprevIts usually with simple things like code completion on logging, boiler plate, repetitive tasks etc. I am surprised sometimes how copilot knows what my next step is. I am typing in the start of an algorithm and copilot gives me the rest. And it predicts a lot of things correctly. It saves me tons of time. Another thing what i like is that I no longer need to no all the programming language related syntax. In the past I looked up stuff on stackoverflow. Now i simply type a short comment like \"reverse the array...\". Copilot automatically suggests the right syntaxes. Sometimes need some adjustments, but thats fine. reply rglover 10 hours agoparentprev> The ones who do not embrace AI assistants in the near future will have a hard time in the future. The exact opposite will be true and the funny (sad?) part is that they will lack the skills necessary (because they got lazy and over-trusted the AI) to fix mistakes/incompatible solutions. reply fhd2 10 hours agorootparentMy thinking as well. If coding assistants become so good that I'm at a competitive disadvantage, I'll just start using them. It's not rocket science. So far, everything I've tried largely slowed me down. As a Google/SO replacement for some types of questions, they sure save me maybe an hour per week, but that's really all I could extract so far. Maybe my work is not too typical though, I spend only a fraction of my time actually typing in code. And I do eliminate the need for boilerplate through other means (picking frameworks/libraries that are a good fit for the problem, refactoring, meta programming, scripts, suitable tool chain etc). reply zmgsabst 9 hours agorootparent1 hour per week of increased coding is a 5-7% boost in productivity, using the Amazon guidelines for how SDEs use their time — 50%/20hrs for SDE1 and 33%/13hrs for SDE3. Is that enough to be competitive? I’m not sure — but at scale that would be a 5% reduction in headcount for the same work, or ~$12M/yr for every 1,000 engineers. If you can figure out how to get 2-3 hours more coding done a week, we’re talking real gains. reply fhd2 8 hours agorootparentDepends on where the time is saved. If it's in figuring out how to do something in Django where StackOverflow is flooded with outdated answers, sure. I see those kinds of savings. But the tragic beauty of programming is that a little time saved today can very well mean lots of time lost later. The former you can measure, the latter is a tougher nut. reply skwirl 9 hours agorootparentprevPeople said the same thing about garbage collectors. reply swatcoder 8 hours agorootparentAnd sure enough, people practiced only in garbage collected environments are the ones who struggle most to work with Rust's borrow checker or write sound embedded/IOT code, or to attend to refence leaks in things like event listeners. Did they help people write lots of effective code faster? Yes. Did they breed a generation of people with little intuition around how memory works? Also yes. reply samatman 6 hours agorootparentThis statement boils down to \"people who know C or C++ have an easier time learning Rust\" which is not especially informative, or even interesting. reply rco8786 8 hours agoparentprevI’ve had it enabled for months across both Javascript and Kotlin codebases and it’s…fine? Good enough that I leave it enabled. But only barely. I’m certainly not orchestrating a dev team. It has probably the same productivity boost that intellisense gave back when it came out. Which is good, but still marginal. Certainly not replacing anyone’s job. reply taude 10 hours agoparentprevin the future, it seems like we might just become PR reviewers reply kissgyorgy 10 hours agoprevWhat future? LLMs got into our tech stack faster than a JavaScript framework was created! If you are not using some kind of Copilot TODAY, you are missing out a lot. reply josefresco 10 hours agoparentMy success rate for writing code with ChatGTP or Copilot is about 5%. Started much better but now I can’t get either to fix any mistakes or generate useful code. Anecdotal but it hasn’t changed my life as a coder. reply qwertox 10 hours agoparentprevYes, but for me ChatGPT today was more useless than a rubber duck. Only when I said \"thanks for nothing\" it tried to turn all the blabla into code, which was unusable. GitHub copilot instead, as an intelligent Intellisense, is absolutely great; a real blessing and gift to coders. reply nozzlegear 9 hours agoparentprevYMMV but trying to use any code that ChatGPT or Copilot generates for F# (my main language) just leads to a lot of compilation errors or worse, subtly incorrect code. reply LASR 11 hours agoprev [–] Everyone by now should be writing unit tests using ChatGPT4. I paste in functions / classes I want to write unit tests for. Paste in a sample unit test, and it does a solid job of writing tests for it in the same manner as in the sample. For unit tests, you don't even need the multi-step coverage optimization in this article. You just manually inspect, adjust it etc. reply swatcoder 11 hours agoparentIf I have a choice between a clever, practiced antagonist to plan and write my tests and an automated system that can fit common testing patterns to my code... I'm always going to get more robust results from the former. But yeah, if you're just working solo on basic stuff and need to protect against off-by-one errors and accidental mutations in later refactoring, it's a great tool. You'd never write duly antagonistic tests for your own code anyway. reply interroboink 11 hours agoparentprevWhat about people who don't trust sending their code to a 3rd party for processing? (edit: I didn't downvote you, but I do think your claim is over-broad) reply biot 8 hours agorootparentI suspect a lot of people overestimate how special their code is. Also, if your code exists in a private repo on GitHub, then you're already trusting the same third party when using GitHub Copilot. reply petesergeant 10 hours agoparentprev [–] Doesn’t that just bake in any bugs in the original implementation? reply samatman 6 hours agorootparentOddly enough it doesn't. The secret sauce is: the robot doesn't run the tests. It digests the code and writes tests for it. So it doesn't know if they'll pass or not. And sure enough, some of them don't, because the code was buggy. I've seen some awful code come out of ChatGPT, but never a bad test. Good tests are short, which makes them hard to screw up. It has a reasonable grasp on what an edge case is as well. reply romwell 9 hours agorootparentprev [–] Of course not! The Power of AI™ can figure out the true intent of the code by looking at the initial (and, potentially, buggy) implementation, and help the programmer by generating edge test cases where the code doesn't produce correct results. The programmer will easily tell those test cases from the ones where the AI did a mistake and generated a flawed test case because the AI doesn't make such silly mistakes; clearly, it's the programmer's code that needs to be corrected. In fact, the AI would do a better job at that, too, which clearly speeds up the development cycle. The correct way to use the tool is to let the AI both generate the test cases and modify the code so that it would pass the tests it generates. After all, if the AI can't figure out what you wanted to do in the first place — how can you? Of course, there's more to it. Whichever problems you run into can be surely attributed to writing the code in an AI-unfriendly way. In the past, we had the adage that the code is read more times than it's written. This is still true, but we need to abandon the old habit habit of having a human reader in mind. Just like you rearrange your furniture to make your house more accessible to the robot vacuum cleaner, you need to write the code with the AI in mind. When you write a Google query or a prompt for ChatGPT (effectively the same thing anyway), you don't write it like you'd talk to a person. You're going to have to write code the same way to be truly effective, and think a little bit like AI to get the most use out of it. That might sound like a lot of work to get code that does what you want. But of course, that's not the case. Just use the AI for this. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta has launched TestGen-LLM, a new test generator leveraging LLM technology to enhance developer productivity by generating code improvements with verified guarantees, emphasizing enhancing existing tests.",
      "TestGen-LLM ensures generated tests are viable, executable, stable, and boost test coverage, showcasing high acceptance rates among developers and seamless integration into Meta's workflows.",
      "The tool underscores the significance of niche LLM applications in software development, emphasizing the importance of addressing unforeseen scenarios, stressing the pivotal role of LLM integration and processing in optimizing software testing and development efficiency."
    ],
    "commentSummary": [
      "Engineers are debating the use of Large Language Models (LLMs) to create test code or implementation, with mixed opinions on its advantages and disadvantages.",
      "Some view AI-generated tests as beneficial and efficient, while others stress the importance of human involvement in testing processes.",
      "Concerns include the quality and quantity of tests produced by LLMs and the potential impact of AI on future software development practices."
    ],
    "points": 292,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1708725898
  },
  {
    "id": 39487341,
    "title": "Gizmodo Writer Evades Detection by Renaming to \"Slackbot\"",
    "originLink": "https://www.theverge.com/2024/2/23/24081249/slack-slackbot-gizmodo-tom-mckay",
    "originBody": "Apps/ Tech/ Labor A former Gizmodo writer changed his name to ‘Slackbot’ and stayed undetected for months A former Gizmodo writer changed his name to ‘Slackbot’ and stayed undetected for months / Management didn’t pick up on the duplicate Slackbot — or its grouchy new eyebrows. By Emma Roth, a news writer who covers the streaming wars, consumer tech, crypto, social media, and much more. Previously, she was a writer and editor at MUO. Feb 23, 2024, 11:01 PM UTC Share this story There’s something a bit different about this Slackbot icon... Image: Tom McKay Hiding on Slack isn’t all that hard, apparently; you just have to pretend you’re a bot. That’s what IT Brew’s Tom McKay did when he left Gizmodo in 2022, and he went undetected by the site’s management for months. In a post on X, McKay shared some screenshots of the new “Slackbot” persona he took on after he officially left Gizmodo. He also confirmed to The Verge that this silly prank really happened. If you’re not glued to Slack for most of the day like I am, then you might not know that Slackbot is the friendly robot that lives in the messaging service. It helps you do things like set reminders, find out your office’s Wi-Fi password, or let you know when you’ve been mentioned in a channel that you’re not a part of. When it was his time to leave, McKay swapped out his existing profile picture for one that resembled an angrier version of Slackbot’s actual icon. He also changed his name to “Slackbot.” You can’t just change your name on Slack to “Slackbot,” by the way, as the service will tell you that name’s already been taken. It does work if you use a special character that resembles one of the letters inside Slackbot, though, such as replacing “o” with the Unicode character “о.” The move camouflaged McKay’s active Slack account for months, letting his account evade deletion. It also allowed him to send bot-like messages to his colleagues such as, “Slackbot fact of the day: Hi, I’m Slackbot! That’s a fact. Have a Slack-ly day!” My colleague Victoria Song, who previously worked at Gizmodo, isn’t all that surprised that this situation unfolded, and says, “As Tom’s former coworker and a G/O Media survivor, this tracks.” Of course, not every company will fall for this trick, as some have security measures in place to prevent this kind of thing. But perhaps Gizmodo’s management thought that McKay’s account had already been deleted. Or maybe they just weren’t eagle-eyed enough to spot a duplicate Slackbot with a suspicious pair of brows. Most Popular Most Popular The AIs are officially out of control Google apologizes for ‘missing the mark’ after Gemini generated racially diverse Nazis Google Pay replaced Google Wallet — now it’s going away to make room for Google Wallet A former Gizmodo writer changed his name to ‘Slackbot’ and stayed undetected for months Vision Pro owners are reporting a mysterious crack in the front glass Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=39487341",
    "commentBody": "A former Gizmodo writer changed name to 'Slackbot', stayed undetected for months (theverge.com)264 points by mfiguiere 10 hours agohidepastfavorite88 comments justanother 9 hours agoI knew an ex-employee back in the day (not me I swear) who created a dialup/ISDN provisioning profile called 'Ringing' in the modem rack controller module (not the Radius server, that would be too obvious), such that a glance at the modem rack status page showed everyone who was connected, and one that was 'Ringing', just like any other incoming call that hadn't been picked up yet. It went completely undetected, yielding 128Kbit ISDN service for well over a year. Obviously I do not advise this, especially now that the CFAA has been interpreted to include things like changing URL parameters and flicking boogers on the carpet. reply nadermx 8 hours agoparentYou got a reference on the CFAA? On the contrary, I found that it was probably not a problem to change a URL parameter \"We also note that in order to be guilty of accessing “without authorization, or in excess of authorization” under New Jersey law, the Government needed to prove that Auernheimer or Spitler circumvented a code-or password-based barrier to access. See State v. Riley, 988 A.2d 1252, 1267 (N.J. Super. Ct.Law Div.2009). Although we need not resolve whether Auernheimer’s conduct involved such a breach, no evidence was advanced at trial that the account slurper ever breached any password gate or other code-based barrier. The account slurper simply accessed the publicly facing portion of the login screen and scraped information that AT&T unintentionally published.\" https://law.justia.com/cases/federal/appellate-courts/ca3/13... reply justanother 8 hours agorootparentExactly correct. Nonetheless, a prosecution was indeed brought, and the opinion you're citing is an appeal. Without the EFF's financial support, weev would not be a free man. reply 3abiton 3 hours agorootparentThat's one way to go. Yolo on a prank. reply KennyBlanken 3 hours agorootparentprevThere is a massive difference between scraping unintentionally published information on a public website and cloaking your account to subvert your employer revoking access to its systems and continuing to access them when you know you're not allowed to be. reply falserum 1 hour agorootparent> cloaking your account This seems like a bit of strech for “cloaking”. (Like wearing vaguely similar colored t-shirt as employees do) > continuing to access them when you know you're not allowed to This part is rock solid. reply foobiekr 5 hours agoparentprevI spent months passively waiting for a former employer to evict me from Slack. It was genuinely bizarre, almost a year later I still had full access to a ton of internal channels. They are friends, but this was not them being friendly, it was just because slack account management integration with Google Office is a dumpster fire. reply paradox460 5 hours agorootparentI've got one up on this. I kept my insurance from a past company for nearly 2 years after I got laid off. Would have rather they cancelled it, as it caused a massive headache around the time my son was born reply mooreds 1 hour agorootparentDid you notify them and ask to have it cancelled? reply solatic 1 hour agoprevA lot of people advise ways of locking down name changes, but this doesn't really solve the problem. I'm sure there's someone out there whose first name is actually Jira. I worked for $company where customer dashboards were set up on a wildcard - https://*.$company.com, e.g. https://foo.$company.com. Guess what happens when someone picks a dashboard slug that conflicts with an actual record, like `www` or `blog`? Their dashboard becomes completely inaccessible. Of course, the setting to change the prefix is also on https://$dashboard.$company.com, so the customer is unable to fix it themselves and requires support. Of course, support's tools don't expose the ability to change the $dashboard prefix directly... Figuring out how to build the denylist isn't really trivial. Of course, there's pre-existing DNS entries. Then there's pre-existing $dashboard prefixes that already exist. Then there's dirty language, Unicode symbols, Punycode (i.e. xn-- prefixes)... then there's setting up redirects from the old prefix and reserving it so that nobody can claim it in the future... I'm not surprised Slack has holes here, it's a fundamentally hard problem. reply hennell 56 minutes agoparentLimit usable characters, and just literally check the page doesn't resolve already before allowing the change. Customers will never be locked out and characters can't impersonate others. If you want to allow some symbols you can either whitelist or check if usernames are an appropriate levenshtein distance away from core names (like say slackbot) and either ban such things or flag to a human \"hey this could be an issue\". It's fundamentally hard to stop everything, but it's not hard to stop the biggest issues. reply Prcmaker 42 minutes agoparentprevMy partners work has an employee named 'Admin'. IT struggles with what to do thee. reply rokkitmensch 9 hours agoprevThis reminds me of a glorious day at my consulting company ca. 2016 when we discovered that we could change each other's names on Slack. At one point everyone was just named dad. reply kej 7 hours agoparentThis sounds a lot like when my kids realized anyone can edit Netflix/Disney+ profile names and pictures. reply Aeolun 3 hours agorootparentAll the accounts are filled with the maximum number of ‘djehebdxineEbsuan’ profiles. And my son is asking why there’s a limit ;) reply gerdesj 8 hours agoparentprevLove it but I will insist on grandad or I will set the girls (grand-daughters) on you ... and they are merciless 8) reply zzixp 6 hours agoparentprev... is this still possible? (my college frisbee team is on slack) reply brunosutic 1 hour agoprevReplacing ascii with similar-looking unicode characters is an old trick. There's a bunch of these characters out there. You can use it in the code to prank your colleague developers - April 1st is nearing! I even made a vim plugin that highlights these \"dangerous\" characters: https://github.com/vim-utils/vim-troll-stopper I've never been pranked with unicode characters, but I've had a situation at work where a consultant from Japan unintentionally used some \"japanese space\" characters in a translation file, and that broke our app. Since I have my vim plugin running all the time it didn't take me a lot to see what's going on. reply lostlogin 41 minutes agoparentThe accidental crap can go a long way. I recall someone using a superscript ‘O’ as a degrees symbol in a medical report. This then got converted to a non—superscript character and rather changed the meaning. Extra unhelpful was that they wrote the word ‘degrees’ after the attempt at the symbol too. reply toomuchtodo 10 hours agoprevBest place to hide is something that looks like a service account everyone is afraid to touch for fear of what will break if disabled. Well played! reply InitialLastName 8 hours agoparentOn the other hand, an over-zealous IT guy at my job just deleted our Jira automation account (because he didn't know what it was there for and got sketched out by the name $CompanySecretary). Cue (a few days later) a large pile of pain as we tried to find and fix every workflow and ticket that formerly referred to that user before something really important broke. reply user_7832 7 hours agorootparentAah, he took down Chesterton's fence and found the reason of its existance! (https://en.wiktionary.org/wiki/Chesterton%27s_fence) reply ChainOfFools 4 hours agorootparentMore than once I have taken down a Chesterton's fence that I myself had originally put up reply mooreds 1 hour agorootparentSounds like a few good stories.... reply willcipriano 4 hours agorootparentprevChesterton's key more like. reply themoonisachees 3 hours agorootparentprevAt my previous job, we had an entire system aptly named Pandora whose entire role was keeping track of which ssh keys were permitted to be found on servers. It had a bot that would crawl through every server, and if it found a key not in it's database, it nuked it. Every new person or automation key had to first be registered fomarlly, with an end date. A bit of a hassle but definitely necessary for the space the company was in. reply smelendez 2 hours agorootparentThat’s a good idea although I’d probably be paranoid enough to have a human do the deletions, out of fear of the failure mode where it deletes all the keys everywhere and nobody can log into anything. reply konha 2 hours agorootparentprevWhy not use ssh certificates at that point? reply falserum 1 hour agorootparentI assume op’s system was to allow A to ssh to B, but not to C. (With lot of different As and Cs) Where “but not to C” is the reason for existence. How certificates simplify that part? (Never used them, but my understanding they are usefull when you want x1,x2,… ssh’ing into y1,y2,…; two uniform sets; if set sizes approach 1, then cert usefullness aproach zero) reply toomuchtodo 8 hours agorootparentprevInstitutional knowledge and documentation is not free, but it has a cost! reply InitialLastName 8 hours agorootparentApparently the cost of reading the documentation, asking anybody, or just looking at the account's activity was too high. reply at_a_remove 5 hours agorootparentprevDang. Our scream test was just \"disable if nobody could tell what it was for.\" reply thih9 9 hours agoparentprevReminds me of popular malware and their process names. reply neilv 10 hours agoprev> Of course, not every company will fall for this trick The company can have the last laugh: https://en.wikipedia.org/wiki/Computer_Fraud_and_Abuse_Act reply selectodude 6 hours agoparentThat’s why he waited two years to say he did it which just so happens to be the CFAA statute of limitations. reply sio8ohPi 4 hours agorootparentIANAL, but as far as I can tell that's only for civil actions (and it runs from the date that the damages are discovered, not necessarily the time of the offense). For criminal charges, I believe you'd use the default 5 year statute of limitations for noncapitcal federal crimes (18 U.S.C. § 3282) reply themoonisachees 3 hours agorootparentBut the company can't force the state to pursue criminal action whereas it can sue in a civil court any time it wants. reply argiopetech 10 hours agoparentprevThis was my first thought on the \"silly prank\" line. reply dancemethis 9 hours agoparentprevwell, Slack is the one having the last laugh, since they get their hands on a lot of \"sensitive business data\". reply dazbradbury 9 hours agoprevThe fact slack doesn't allow you to lock down name changes must be such a gaping security hole for big companies. Change your name to the CEO, and profile image to match. Odds of people noticing the difference are extremely small until it's too late. Changing to slackbot seems like small fry! reply jackson1442 8 hours agoparentName changes can be locked; I'm in an Enterprise Grid org and our display names/usernames are synced against our employee profile. We're also required to SSO every single time we launch the desktop app so once you're terminated you're definitely not getting back in (they deactivate accounts very quickly too, so mobile is likely not a major concern). Basically the only thing you can change without filing a ticket is your picture and some mostly-irrelevant freetext fields. reply KennyBlanken 3 hours agorootparentHow does an enterprise chat tool not have the ability to invalidate all session tokens and all connected clients to disconnect? reply sli 3 hours agorootparentPerverse incentives. People are paying them already without that feature, so why bother? They are incentivized to do and provide as little as possible. reply ryanjshaw 10 minutes agoparentprevIn MS Teams, your name is from AD and you almost certainly don't have permission to change that. Also, bots have hexagonal avatar frames while humans have circular ones. I'm not sure how many people notice, though. reply bongodongobob 8 hours agoparentprevUh, it does allow that in the organization settings. Also the SAML/SSO comment below as well. If you can change names, IT admins are either non-existent or just being lazy. reply bigyikes 7 hours agorootparentMy company allows name changes. It’s fun. reply bongodongobob 7 hours agorootparentThat means they're not using SAML/SSO which sounds absolutely crazy to me, unless you only have like a dozen users. The implication is that your IT team doesn't take security seriously. Not because you can change names, but because they aren't implementing identity policies. reply grogenaut 5 hours agorootparentyou can very much allow people to change display names while using saml/sso. My work setup allows this. We can change photo and description as well but nothing else. reply reaperman 5 hours agorootparentSame here. reply mynameisvlad 2 hours agorootparentprevOr it’s just a more relaxed atmosphere? Not everything needs to be corporate no-fun serious business 24/7. We’re on an enterprise Slack instance with >1000 members and SSO/SAML. Changing names and photos allows us to be fun and everyone trusts everyone else to not spoil the party. reply nightpool 6 hours agorootparentprevEh, a lot of startups even in the 100-200 employee range are still manually inviting Slack members. It's not really the end of the world as long as you're on top of things and have good communication between HR, IT, etc. Spreadsheets solve a lot of problems (in this case, having a good template offboarding/onboarding spreadsheet in Google drive that everyone can collaborate on to make sure stuff gets done quickly). reply reactordev 9 hours agoparentprevBigger companies use SAML or other federation that makes it impossible to login without a corporate authentication. reply dazbradbury 9 hours agorootparentPresumably with SAML/SSO you can still change your slack display name and profile picture? reply grinich 9 hours agorootparentThe data only comes during the sign-in flow. If you want to change it dynamically outside of that, it's typically done via SCIM. For anyone curious, we wrote a blog post all about this. https://workos.com/blog/the-developers-guide-to-directory-sy... (I work at WorkOS.) reply reactordev 8 hours agorootparentprevNegative, that comes from Azure AD, or Cognito, or Keycloak, or whatever. The users name, email, phone, location, avatar pic, department, etc all comes over in the SAML payload. reply bigyikes 7 hours agorootparentThis is not correct in general. My job uses SSO and I can change my Slack name. reply foobarian 6 hours agorootparentIn our case we can not change the Slack display name, but we can change the @ handle. Pretty good compromise IMO. reply reactordev 6 hours agorootparentprevIt is correct, your company just messed up somewhere... reply neom 9 hours agorootparentprevNot slack, we use teams at work and I have very limited ability to do anything, can't change my name and we have profile pics disabled. reply freeAgent 9 hours agoparentprevI’m pretty sure this is one reason why my firm recently removed people’s ability to change their name on our videoconferencing system. reply makeitdouble 7 hours agoparentprevAt the same time the ability to change name is sich a godsend. We're currently abusing it to have presence info straight in the display name (e.g. mike-2/12~16vac.) to let anyone contacting us what to expect for response times, or wether to ask for a task if it's a few days before a planned vacation. Nobody seemed to look at the actual status property and it beats going to the calendars to check. reply p1mrx 6 hours agorootparent> mike-2/12~16vac Looks like mike-2 is a robot powered by a doorbell transformer. reply makeitdouble 4 hours agorootparentHe'd probably be fine with that perception. reply notatoad 8 hours agoprevthe screenshots of people replying to him who clearly know he's not slackbot, including calling him Tom, kind of contradict the headline here. he was clearly not \"undetected\". we've got some former staff in our slack still. they check in and say hi every now and then, it's nice. if one of them started pretending to be a snarky slackbot one day, we'd probably have a laugh about it too. reply ksenzee 7 hours agoparent“Undetected by management” is the meaning here, as the article makes clear. His friends knew he was there and were having a laugh. reply INTPenis 3 hours agoparentprevSame here, slack is not our main communications channel but it was used for some external consultants. And sure enough people who had quit were never kicked out so they just continued planning lunches together. reply twodave 6 hours agoprevOne place I worked was slow to deactivate slack accounts, so when I left I made a private channel #daves_cave and invited friends my friends to it. I would leave a short story or pithy saying now and then; it was fun until management got wise and deactivated me. reply petesergeant 4 hours agoparentI’ve got a private, paid Slack team ($10 a month?) and you can invite people from other paid Slack teams to chat in rooms on it. Nice thing about this is it’s “by design”, so less likely to get shut down, and also unlikely to fall foul of computer misuse laws. reply jimnotgym 1 hour agoprevI would have thought the answer to this at a corporation was Single Sign On? I don't run IT these days, but when I did...we used to mark them as inactive in Azure Active Directory. They could no longer log in to any Office 365 service, Outlook Teams or whatever, and none of the third party services we had using MS SSO. Wouldn't you join Slack to it too? reply thecupisblue 58 minutes agoprevAdmins not killing old accounts is a security hole that I'd say 50% of companies I worked with had/have. I can still log into the google workspace, slack, check out confidential documents on drive (not because of transparency, but because they dont know how to share properly). I can check out what is happening in nearly any of their projects by peeking at the channel and if I want to know more, I just take a look at the documents, including their pitches. If I poked for a bit, I could probably also find API keys and DB credentials. These people work for banks, insurances, national televisions, hotels, airlines and more. If I was a bad actor, it would be incredibly easy to cause damage to both them and the clients or do insider trading based on the upcoming project data. But it seems like half of these places just don't care about security - even when contacted, admins/responsible people just flat out ignored it. And then we wonder how breaches happen. reply vlovich123 10 hours agoprevNormally an organization would have this protected via SSO & thus the deactivation of the employee's account on Gizmodo's systems would have kicked them off of the company's slack. Just another reason why it's valuable to avoid non-SSO 3p cloud apps so that \"who's an active user\" has a single source of truth. reply throwanem 9 hours agoparentSlack has supported SSO via a variety of providers for quite a long time now. If G/O Media didn't bother setting up the integration, that's on them. reply timetopay 9 hours agoparentprevOne thing that SSO isn't great at is deactivating live sessions. Often, you either solve this with short session times (annoying to users), making a note in the de-provisioning steps document (not foolproof), or using a third party vendor (costly). reply tw04 9 hours agorootparentSure it is, this problem has been solved for a long time: SCIM. Any modern idp should support SCIM and if the app doesn’t I’d question using it at all. reply leeter 5 hours agorootparentMe: \"We should use SCIM, our IDP and our App both support it\" PM: \"No that's too complicated, we'll roll our own provisioning and never worry about de-provisioning because they won't be able to log in due to SAML anyway!\" I can't tell you how many times I've had that conversation... but I'd need at least both hands and a foot. reply grinich 5 hours agorootparentThis is why most SSO forces you to sign in again every day. So frustrating! reply timetopay 9 hours agorootparentprevSCIM adoption isn't near where it needs to be. I guess yeah, this is the correct answer. We live in a world where SSO is considered an enterprise feature, I hope one day that it's considered default. reply mooreds 1 hour agorootparentAgreed. And most apps have it locked to the most expensive level. Slack, to their credit, offers this at the business+ tier: https://api.slack.com/admins/scim reply grinich 9 hours agorootparentprevShameless plug for my startup (hope that's ok!) If you're building an app and need to add SCIM, check out WorkOS. My email is in my profile to chat. More info -> https://workos.com/directory-sync reply amenghra 5 hours agorootparent$125 per connection / month and then you wonder why companies don't offer SSO/SCIM by default in their free/cheap plans. reply mooreds 1 hour agorootparent(I work for a competitor in the same space as grinich.) Charging for scim is a convenient way to segment customers, the same way SLAs are. For companies that care deeply about controlling user access (or are forced to by law or regulator), that isn't much money. Features like this subsidize the free/cheap version, which you can then offer to let folks learn about and love your software, and use. After all, you can replace scim with careful manual processes until you get to a certain size. It's similar to the sso tax: https://sso.tax/ I'm not aware of a scim.tax site, but maybe there should be one? :) reply cco 9 hours agorootparentprev>...using a third party vendor (costly). I promise we're not _that_ costly. But yes, having built a slackbot/Slack OAuth myself and dealing with it at my $CURRENT_CO (stytch.com), Slack is a service you have to be very careful with. They offer a very powerful API and permissioning model, but it can be nerve wracking. reply Marciplan 10 hours agoprevit was a joke Verge reply rokkitmensch 9 hours agoparentPerhaps sadly, it's the kind of joke you can get in mega-trouble for these days (see other comments about CFAA and flicking boogers on the carpet). reply adamrezich 7 hours agoprevthis is a reporter \"reporting\" on another reporter's self-reporting (on twitter) of what he did from when he quit/was fired/laid off (the \"article\" doesn't even say) from his job as a reporter. \"reporting\" is in quotes here because it's the thinnest possible veneer atop the original tweet. what possible value does this article have over the original tweet, aside from adding an additional, unnecessary needed layer of \"reporting\" for this non-story? it's difficult to see this as anything but a \"journalism\" circlejerk (redundant). reply berkes 31 minutes agoparentThe author gave some context for readers not familiar with slack. And interviewed another former employee (albeit with minimal effort) to add another validation point. reply jstarfish 9 hours agoprev [–] 'Nothing signed \"THE MGT.\" would ever be challenged; the Midget could always pass himself off as the Management.' reply srhtftw 6 hours agoparent [–] NO SMOKING. NO SPITTING. THE MGT. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Former Gizmodo writer Tom McKay rebranded himself as \"Slackbot\" on Slack post-departure, blending in for months unnoticed.",
      "By altering his profile picture and name to resemble the Slackbot icon, he fooled colleagues with bot-like messages.",
      "Some firms have safeguards against such actions, but Gizmodo's management failed to identify the duplicate account."
    ],
    "commentSummary": [
      "The discussion covers issues with account management integration between Slack and Google Office, emphasizing challenges in username and profile management across platforms.",
      "Tips shared include using Unicode characters and service accounts to enhance security and combat impersonation on these platforms.",
      "Recommendations are made for implementing Single Sign-On (SSO) and System for Cross-domain Identity Management (SCIM) to boost security and prevent unauthorized access, addressing the limitations of enterprise chat tools."
    ],
    "points": 264,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1708729811
  },
  {
    "id": 39487124,
    "title": "Unveiling Generative Models with INTRINSIC LoRA",
    "originLink": "https://intrinsic-lora.github.io/",
    "originBody": "Generative Models: What do they know? Do they know things? Let's find out! Xiaodan Du1, Nicholas Kolkin2, Greg Shakhnarovich1, Anand Bhattad1 1Toyota Technological Institute at Chicago, 2Adobe Paper arXiv Code New! Video (coming soon) INTRINSIC LoRA (I-LoRA) uncovers the hidden capabilities of generative models like VQGAN, StyleGAN-XL, StyleGAN-v2, and Stable Diffusion. I-LoRA modulates key feature maps to extract intrinsic scene properties such as normals, depth, albedo, and shading, using the models' existing decoders without additional layers, revealing their deep understanding of scene intrinsics. Abstract Generative models have been shown to be capable of synthesizing highly detailed and realistic images. It is natural to suspect that they implicitly learn to model some image intrinsics such as surface normals, depth, or shadows. In this paper, we present compelling evidence that generative models indeed internally produce high-quality scene intrinsic maps. We introduce INTRINSIC LoRA (I-LoRA), a universal, plug-and-play approach that transforms any generative model into a scene intrinsic predictor, capable of extracting intrinsic scene maps directly from the original generator network without needing additional decoders or fully fine-tuning the original network. Our method employs a Low-Rank Adaptation (LoRA) of key feature maps, with newly learned parameters that make up less than 0.6% of the total parameters in the generative model. Optimized with a small set of labeled images, our model-agnostic approach adapts to various generative architectures, including Diffusion models, GANs, and Autoregressive models. We show that the scene intrinsic maps produced by our method compare well with, and in some cases surpass those generated by leading supervised techniques. Summary of scene intrinsic extraction capabilities across different generative models without changing generator head. ✓: Intrinsics can be extracted with high quality. ～: Intrinsics can be extracted with medium quality. ✗: Intrinsics cannot be extracted. Model Pretrain Type Domain Normal Depth Albedo Shading VQGAN Autoregressive FFHQ ～ ～ ✓ ✓ StyleGAN-v2 GAN FFHQ ✓ ～ ✓ ✓ StyleGAN-v2 GAN LSUN Bed ✓ ✓ ✓ ✓ StyleGAN-XL GAN FFHQ ✓ ～ ✓ ✓ StyleGAN-XL GAN ImageNet ✗ ✗ ✗ ✗ Stable Diffusion-UNet Diffusion Open ✓ ✓ ✓ ✓ Stable Diffusion Diffusion Open ✓ ✓ ✓ ✓ Image Surface Normals Depth Albedo ShadingOmnidata-v2 I-LoRA ZoeDepth I-LoRA Paradigms I-LoRA Paradigms I-LoRA Figure: Comparison of intrinsic maps generated by our method using augmented Stable Diffusion 2.1 and the pseduo ground truth BibTeX @article{du2023generative, author = {Du, Xiaodan and Kolkin, Nicholas and Shakhnarovich, Greg and Bhattad, Anand}, title = {Generative Models: What do they know? Do they know things? Let's find out!}, journal = {arXiv}, year = {2023}, } This website is cloned from NeRFies website repo.",
    "commentLink": "https://news.ycombinator.com/item?id=39487124",
    "commentBody": "Generative Models: What do they know? Do they know things? Let's find out (intrinsic-lora.github.io)258 points by corysama 11 hours agohidepastfavorite72 comments dougmwne 10 hours agoThis is awesome! So one of the big reasons there was hype about Sora is that it felt very likely from watching a few videos that there was an internal physical simulation of the world happening and the video was more like a camera recording that physical and 3D scene simulation. It was just a sort of naïve sense that there HAD to be more going on behind the scenes than gluing bits of other videos together. This is evidence, and it’s appearing even in still image generators. The models essentially learn how to render a 3D scene and take a picture of it. That’s incredible considering that we weren’t trying to create a 3D engine, we just threw a bunch of images at some linear algebra and optimized. Out popped a world simulator. reply ozgung 28 minutes agoparentWe humans live in a 3D world and our training set is a continuous stereo stream of a constant scene from different angles. Sora, on the other hand, learned the world by watching TV. It needs to play more video games, in order to learn 3D scenes (implicit representation of a world) and taking their pictures (rendering). Maybe that was the case I don’t know. reply whimsicalism 3 hours agoparentprev> just a sort of naïve sense that there HAD to be more going on behind the scenes than gluing bits of other videos together People really still think that's all thats happening? reply sigmoid10 30 minutes agorootparentThere's a lot of nonsensical babble out there from people who have minimal technical insight - both on the sceptic and on the enthusiast side of AI. It really wasn't clear for the longest time how these models generate things so well. Articles like this one are still rare and comparatively new. And they certainly haven't been around when less informed enthusiasts where already heralding AGI. On the other hand, we have accrued quite a bit of evidence by now that these models do far more than glue together training data. But there are still sceptics out there who spread this sort misinformation. reply 0_____0 2 hours agorootparentprevWho is people? Most folks only vaguely know about generative AI if they know about it at all. I'm technical but not in software specifically and usually ignore most AI news, so GP's comment is in fact news to me! reply labrador 20 minutes agoparentprevI would expect \"gluing bits of other videos together\" to be more accurate than a physics simulation because the former is based on learning from watching actual videos where the later is based on math, or am I completely misunderstanding this? reply patcon 3 hours agoparentprev> we weren’t trying to create a 3D engine, we just threw a bunch of images at some linear algebra and optimized. Out popped a world simulator. Heh. Sounds like what a personified evolution might say about a mind ;) reply ClumsyPilot 8 hours agoparentprevWell we do have game engines for a while now. Maybe a game engine with a chat interface would do a better job reply TheDudeMan 5 hours agorootparentDepends on whether your goal is to render a scene or push the envelope in generative AI. reply 3abiton 3 hours agorootparentprevI think is the key, most likely it was a big part of their training dataset. reply asadotzler 1 hour agoparentprevLike the cat springing a 5th leg and then losing it just as quick, in a cherry-picked video from the software makers? How does that fit your wishful narrative? reply ukuina 10 hours agoprevThe name is a reference to a fictional gameshow in Bojack Horseman called \"Hollywoo Stars and Celebrities: What Do They Know? Do They Know Things?? Let's Find Out!\" https://bojackhorseman.fandom.com/wiki/Hollywoo_Stars_and_Ce...! reply _____-___ 6 hours agoparentI reference this specific game show title quite a bit, but I don't think that many people get it sadly, so I just seem weird haha reply reso 9 hours agoparentprevNot gonna lie I upvoted this post based only on the title. reply echelon 9 hours agoparentprevI adore that show so much. I have this sticker on my laptop. If you haven't seen Bojack Horseman, it's funny and heartfelt. Palpably existential. If that kind of thing speaks to you, you owe yourself a watch. In terms of a complete animation package, I think it easy outdoes Futurama. There's so much relatable depth to it. It hits hard, but it stays lighthearted enough to make you feel good about it. As it turns out, I'm now working on filmtech, so that \"Hollywoo\" sticker fits me even better now. reply saberience 25 minutes agorootparentJust a warning to anyone who read this comment, the show (in later seasons) gets incredibly dark, existential, and depressing, to the point where I couldn't watch it anymore as it made me both anxious and depressed. Anyone prone to anxiety or depression or sad thoughts in general should probably avoid, it's really that depressing, and I can imagine it making suicidal people even more suicidal. reply the_af 8 hours agorootparentprevI want to like Bojack and I know it has drama and heartfelt moments (watched all of season 1 I think), but in my opinion it's undone by its moments of \"wacky\" humor. I don't even mean that there are humanoid animals and humans living together, no explanation -- I can embrace that. I mean the Simpsons/Family Guy kind of humor... I could do without it and I think it would make the show better. Or maybe it does get better after season 1? Since everyone seems to love it. reply yosame 7 hours agorootparentSeason 1 is definitely the weakest season, especially at the start. There's definitely still wacky humour in the rest of the show, but it loses the family guy cutaway gags. I'd personally recommend giving season 2 a shot, if you still don't like it then the shows probably not for you. reply karmakurtisaani 1 hour agorootparentprevI remember reading they had to make season 1 \"wacky\" to sell the show. What the show becomes later would have been ... hard to describe to studio executives. reply KerrAvon 5 hours agorootparentprevIt’s very Los Angeles nihilist in tone. If that doesn’t make you happy, maybe skip it. reply reducesuffering 6 hours agorootparentprevSeason 1 is definitely weakest; very common in great TV series. Just start from season 2 right now and I'm pretty sure you'll love it. It will always have \"wacky\" moments with a character like Todd in it though. reply khedoros1 3 hours agorootparentprev> but it stays lighthearted enough to make you feel good about it. There were plenty of parts that were dark enough to make it difficult to watch. There were lighthearted parts, but that's not a description I would've applied to the show as a whole. reply jeffparsons 6 hours agorootparentprev> It hits hard, but it stays lighthearted enough to make you feel good about it. That wasn't my experience of it. It's a brilliant show, to be sure, but at some point I felt the bleakness, particularly around Bojack's inability to help himself, became too much for me. Maybe different parts of the show resonate in different people. reply rocketbop 1 hour agorootparentI agree it wasn’t light at all in the later parts. Very bleak. If it was ever supposed to be a comedy it didn’t end as one but I can’t think of other animated series you could class as a drama. I think it is one of only about three animated shows that are genuinely outstanding as TV and not just animation or comedy. The other two being Simpsons and Futurama. reply saberience 24 minutes agorootparentI couldn't finish watching the show, it was just too depressing and dark for me to the extent that it made me personally more anxious and depressed. reply modeless 3 hours agoprevOoh, so this can take real images and predict albedo and lighting! Please, someone use this to make relightable gaussian splatting scenes. Dynamic lighting would really expand the usefulness of 3D scans made from photos, and I haven't seen anyone get anything close to what I would call \"good\" results in that area yet. reply IshKebab 20 minutes agoparentCan it definitely use real images? I imagine extracting the depth map from real images would be the most useful application if it can. reply dkarras 10 hours agoprevThis is pretty remarkable. So these really do learn humanly interpretable representations and not only doing some magic in the billion dimensional hyperplane that we can't hope of deciphering. reply corysama 10 hours agoparentAs an old 3D graphics engineer, the fact that albedo is in there is as just striking as it should be expected. The core components of physically based rendering are position (derivable from image XY and depth), surface normal, incoming light, and at least albedo + one of a few variations on surface material properties such as specularity and roughness. That the AI is modeling depth is pretty expected. Modeling surface normal is a nice local convolution of depth. But, modeling albedo separated from incoming light is great. I wonder if specularity is hiding in there too. reply hackerlight 10 hours agorootparentIt's a good depth map, too. Better than other tools I've seen which require fiddling with lots of knobs to get a good result. Might be useful for textures for parallax mapping. reply int_19h 8 hours agoparentprevI find it amazing that, for all the evidence we have of generative models having some fairly complex internal model of the world, people still insist that they are mere \"stochastic parrots\" who \"don't really understand anything\". reply mewpmewp2 7 hours agorootparentFrom the other side however if you really think about it, our understanding of everything must be stochastic as well. So perhaps this sort of thing yields in many complexities that we are not aware of. How would I know I am not a stochaistic parrot of some sort. I am just neural nets traine on current envrionment while the base model that is dependent on DNA, through evolution and natural selection of the fittest. Same as currently competing LLMs where the best one will win out. reply int_19h 5 hours agorootparentYou're not wrong, but the \"stochastic parrot\" claim always comes with another, implicit one that we are not like that; that there's some fundamental difference, somehow, even if it is not externally observable. Chinese room etc. In short, it's the good old religious debate about souls, just wrapped in techno-philosophical trappings. reply cthalupa 3 hours agorootparentYou could leverage the exact same accusation against the other side - we know fundamentally how the math works on these things, yet somehow throw enough parameters at them and eventually there's some undefined emergent behavior that results in something more. What that something more is is even less defined with even fewer theories as to what it is than there are around the woo and mysticism of human intelligence. And as LarsDu88 points out in a separate thread, there are alternative explanations for what we're seeing here besides \"We've created some sort of weird internal 3D engine that the diffusion models use for generating stuff,\" which also meshes closely with the fact that generations routinely have multiple perspectives and other errors that wouldn't exist if they modeled the world some people are suggesting. If there's something more going on here, we're going to need some real explanations instead of things that can be explained multiple other ways before I'm going to take it seriously, at least. reply asadotzler 1 hour agorootparentprevWell, when the cherry picked videos from OpenAI have a cat springing a fifth leg for no reason, people are right to be skeptical. reply wredue 6 hours agorootparentprevWe have zero evidence that these models have any “understanding” of anything. “Understanding” would mean that they be able to train themselves, which they are as yet unable to do. We are tuning weights and biases to statistically regurgitate training data. That is all they are. reply chaxor 47 minutes agorootparentWhile I agree with the hidden statement of the utility in online reinforcement learning here, it should be pointed out that for some snapshot of a system, which may have already been trained with a large amount of data - the structure of the learned space and the inferences within it seem like a reasonable definition for 'understanding'. I don't know many people that would suggest that knowing about ones family structure, such as their mom/dad/uncle, and how their history relates to them, is required to be _completely reconstructed_ every time they interact with their environment somehow from first principles. Online reinforcement learning can have large merits without resorting to stating it's required for learning. Just as self awareness can occur independently of consciousness can occur independently of intelligence is independent of empathy and so on. They are all different, and having one component doesn't mean anything about the rest. reply esafak 5 hours agorootparentprevI don't buy that definition of understanding. Yours is closer to learning. If you had an accident and lost the ability to learn new things, you would still be able to understand based on what you have learnt so far. And that's what these models are like. They don't retrain themselves because we haven't told them to. reply visarga 5 hours agorootparentprevSo, in order for a kid to understand multiplication means they must be able to train themselves and not regurgitate the multiplication table? reply ipaddr 5 hours agorootparentYes I think so. Understanding would involve understanding that it's a short form for adding. Remembering multiplication tables allows you to use math but it doesn't infer understanding. Training themselves is necessary. All learning is self learning. Teachers can present material in different ways but learning is personal. No one can force you to learn either. reply visarga 5 hours agorootparentYou can check if a model (or a kid) understands multiplication by simply probing them with questions, to explain the concept in their own words, or on concrete examples. If their answers are robust they understand, if their answers are fragile and very input dependent, they don't. \"To understand\" is one of those poorly defined concepts, like \"consciousness\", it is thrown a lot in the face when talking about AI. But what does it mean actually? It means to have a working model of the thing you are understanding, a causal model that adapts to any new configuration of the inputs reliably. Or in other words it means to generalize well around that topic. The opposite would be to \"learn to the test\" or \"overfit the problem\" and only be able to solve very limited cases that follow the training pattern closely. That would make for brittle learning, at surface level, based on shortcuts. reply int_19h 4 hours agorootparent> It means to have a working model of the thing you are understanding, a causal model that adapts to any new configuration of the inputs reliably The weasel word here is \"reliably\". What does this actually mean? It obviously cannot be reliable in a sense of always giving the correct result, because this would make understanding something a strict binary, and we definitely don't treat it like that for humans - we say things like \"they understand it better than me\" all the time, which when you boil it down has to mean \"their model of it is more predictive than mine\". But then if that is a quantifiable measure, then we're really talking about \"reliable enough\". And then the questions are: 1) where do you draw that line, exactly, and 2) even more importantly, why do you draw the line there and not somewhere else. For me, the only sensible answer to this is to refuse to draw the line at all, and just embrace the fact that understanding is a spectrum. But then it doesn't even make sense to ask questions like \"does the model really understands?\" - they are meaningless. (The same goes for concepts like \"consciousness\" or \"intelligence\", by the way.) The reason why I think this isn't universally accepted is because it makes us not special, and humans really, really like to think of themselves as special (just look at our religions). reply mardef 5 hours agorootparentprevI wouldn't call someone reciting a French-English dictionary a French speaker that understands the language. Other way around. If a kid understood the concepts of multiplation, they could train themselves on the next logical steps like exponents. The consequences of this in the terms of AI would mean they build on a series of concepts and would quickly dwarf us in intelligence. reply huytersd 5 hours agorootparentprevNo, you can have abstract representations of a concept which would fit understanding in a certain sense of the word. You can have “understanding” of a concept without an overarching self aware hypervisor. It’s like isolating a set of neurons in your brain that represent an idea. reply LarsDu88 8 hours agoprevReminds me of when I tried to extract G-buffers from my Unity High Definition Rendering Pipeline test project: https://www.youtube.com/watch?v=Fwtc694qNUM I'm not sure if this paper is really proving anything though. There's a giant-ass UNET Lora model that's being trained here, so is it really \"extracting\" something from an existing model, or simply creating a new model that can create channels that look like something you'd get out of a deferred rendering pipeline. After all, taking normals, albedo, and depth and combining them (deferred rendering) is just one of several techniques to create a 3d scene. Wasn't even used in videogames until the early 2000s (in a Shrek videogame for the Xbox! (https://sites.google.com/site/richgel99/the-early-history-of...) What would really be awesome is to get a LORA model that can extract the \"camera\" rotation and translation matrix for these image generation models. That would really demonstrate something (and be quite useful at the same time). reply joefourier 7 hours agoparentIf you look at the supplementary material, they do a test where they train the Lora with a randomly initialised Unet and it is largely incapable of extracting any surface normals as opposed to using the pretrained Stable Diffusion Unet - clearly showing the features of the model are relevant to its performance. reply sfink 7 hours agoparentprevI don't really know what I'm talking about, but doesn't this address that? > with newly learned parameters that make up less than 0.6% of the total parameters in the generative model 0.6% sounds like a small number. Is it measuring the right thing? Certainly, I wouldn't expect the model to necessarily be encoding exactly the set of things that they're extracting, but it still seems very significant to me even if it is \"just\" encoding some set of things that can be cheaply (in terms of model size) and reliably mapped to normals, albedo, and depth. (I don't care what basis vectors it's using, as long as I know how to map them to mine.) reply LarsDu88 6 hours agorootparent0.6 percent of a model with 890 million parameters is still 5.34 million parameters. That's still pretty big. Maybe big enough to fake normals, learn some albedo smoothing functions, and learn a depth estimator perhaps?? reply hn_throwaway_99 8 hours agoprevI skimmed the paper, but a lot of it was over my head. As someone not very versed in image generation AI, can anyone help me understand? This sentence (which another commenter highlighted) appears to be the key part: > I-LoRA modulates key feature maps to extract intrinsic scene properties such as normals, depth, albedo, and shading, using the models' existing decoders without additional layers, revealing their deep understanding of scene intrinsics. What exactly does \"modulates key feature maps to extract intrinsic scene properties\" mean? How were these scene property images generated if no additional decoding layers were added? reply visarga 5 hours agoparentSay you have a neural network with 1B parameters, you add 5M more parameters spread around (LoRA), and continue training for a while but only the newly added parameters, not the base network. The result is a \"modulated\" network that would predict scene properties. The interesting thing is that it only takes a few more parameters so it must be that the original network was pretty close already. reply educaysean 7 hours agoprevThis is good news for VR (or spatial computing). If the models understand the physical world as well as the paper shows, generating two projections of a scene does not sound like a difficult ask. Really excited for what's to come. reply vslira 9 hours agoprevNot to be a skeptic or anything, but how do we know normal maps etc weren’t enriched into the datasets by the image gen companies? I understand this paper links to open source model where that can be verified, but maybe this is one secret sauce of these more advanced models? reply dougmwne 9 hours agoparentYou would need to train on pairings of normal map images to source images. To my knowledge, that’s not a common training technique and this ability seems to bridge across several open models. reply coffeebeqn 8 hours agorootparentIt’s also kind of cool if it “understands” a normal map and that it maps to specific 3D geometry. People generally use 3D tools like Zbrush to sculpt the details to normals. Probably some people can draw them too reply dvh 2 hours agoprevI asked ai that was posted here yesterday to draw common european chub and virtually every single one had adipose fin. reply auggierose 9 hours agoprevSo how do they get the normals, for example? Are they generated by the AI before the image is generated in order to generate the image, and they are just reading them off some internal state? reply dougmwne 8 hours agoparentYes, there’s rudimentary evidence that there’s essentially a 3D engine within the model that participates in generating the image. If we could inspect and interpret the whole process it would likely be bizarre and byzantine, like a sort of convergent evolution that independently recreates a tangled spaghetti mess of unreal engine, adobe lightroom, and a physical simulation of a Canon D5. reply qingcharles 7 hours agorootparentEssentially similar perhaps to the 3D engine that a human brain runs that generates a single \"3D\" image from two 2D cameras (eyes) and fills in missing objects in blind spots, etc. reply tsimionescu 4 hours agorootparentNote that while having two eyes helps build a more accurate 3D image, people with one eye still see in 3D. Eye movement is at least as important a part of 3D vision as stereoscopy. reply corysama 9 hours agoparentprevThe training data is just billions of {RGB image, text description} pairs. So, it appears the model figured out how to make the normals as part of the process of making the images. Or, are you asking how the researchers extracted it? > I-LoRA modulates key feature maps to extract intrinsic scene properties such as normals, depth, albedo, and shading, using the models' existing decoders without additional layers, revealing their deep understanding of scene intrinsics. reply auggierose 3 hours agorootparentYes, that sentence \"modulates key feature maps\" doesn't tell me anything. What do they mean when saying they extract the normals? reply bbor 10 hours agoprevI have no idea what Toyota or adobe are up to and why they’re funding research with a name like this, but I fucking love it. It’s science, let’s get some whimsy back in here!! More materially: Optimized with a small set of labeled images, our model-agnostic approach adapts to various generative architectures, including Diffusion models, GANs, and Autoregressive models. Am I correct in understanding that this is purely a visuospatial tool, and the examples aren’t just visual by coincidence? Like, there’s no way to stretch this to text models? Very new to this interpretability approach, very impressive. reply sp332 10 hours agoparentThere's research into editing facts in language models. https://rome.baulab.info/ reply blovescoffee 4 hours agoparentprevYou have no idea why Toyota or Adobe are funding computer vision research? reply bbor 59 minutes agorootparentlol yeah a little. A) it said something very odd sounding like “Toyota university of Chicago”, which wtf why does Toyota have a university, and B) most labs would be hesitant to publish a paper with an extraneous clause in the title just to reference an absurd cartoon reply raincole 10 hours agoparentprevBojack Horseman reference that we didn't know we need. reply seattle_spring 5 hours agorootparentWhat is this, a crossover episode? reply frri 7 hours agoparentprevSi hzux reply mindcrime 9 hours agoprevDamn, now I'm suddenly finding myself wanting to go back and re-watch Bojack Horseman. Not that that would be a bad thing. reply goryramsy 11 hours agoprev [–] SSL error? Just me? reply corysama 10 hours agoparentWorks on my machine. Alternative link: https://github.com/duxiaodan/intrinsic-lora reply 01HNNWZ0MV43FF 10 hours agoparentprev [–] Works here. \"Verified by DigiCert\". SHA-256 fingerprint of 38:2C:D4:2D:33:C0:2B:C6:67:8E:65:7C:E1:7B:84:6D:04:73:A7:E7:91:CD:B3:5B:8E:AD:90:1A:F1:E1:1A:08 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper presents INTRINSIC LoRA (I-LoRA), a technique revealing hidden potentials of generative models such as VQGAN, StyleGAN-XL, StyleGAN-v2, and Stable Diffusion by extracting intrinsic scene features like normals, depth, albedo, and shading without extra layers.",
      "This model-agnostic method generates top-notch scene intrinsic maps, outperforming certain established supervised methodologies.",
      "I-LoRA showcases the capability to extract intrinsic scene properties, elevating the quality of generated content from various generative models."
    ],
    "commentSummary": [
      "The discussion covers generative models like Sora, the transformation of \"Bojack Horseman\" from light to dark themes, and the complexity of AI models, including rendering 3D scenes and AI's understanding and generalization abilities.",
      "Reference to I-LoRA, extracting scene properties, the significance of model features, and neural networks producing images directly without decoding layers is included.",
      "Mention of a computer vision research project funded by Toyota and Adobe, alongside speculation on AI potentially exceeding human intelligence."
    ],
    "points": 258,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1708728406
  },
  {
    "id": 39481188,
    "title": "German Bundestag Votes to Legalize Cannabis for Private Use",
    "originLink": "https://www.bundestag.de/dokumente/textarchiv/2024/kw08-de-cannabis-990684",
    "originBody": "Gesundheit Abgesetzt: Entwurf zur Legalisierung von Cannabis in erster Lesung Erwachsenen soll der private Eigenanbau von bis zu drei Cannabis-Pflanzen zum Eigenkonsum gestattet werden. (picture alliance / Panama PicturesChristoph Hardt) Die Bundesregierung plant die Legalisierung von Cannabis. Der dazu vorgelegte Gesetzentwurf „zum kontrollierten Umgang mit Cannabis und zur Änderung weiterer Vorschriften“ (Cannabisgesetz, 20/8704) sollte ursprünglich am Freitag, 13. Oktober 2023, auf der Tagesordnung des Bundestages stehen. Die Beratung der Initiative wurde jedoch von der Tagesordnung abgesetzt. Gegen die Legalisierungspläne spricht sich die CDU/CSU-Fraktion aus. Ihr dazu angekündigter Antrag mit dem Titel „Cannabislegalisierung stoppen, Gesundheitsschutz verbessern – Aufklärung, Prävention und Forschung stärken“ sollte in der 40-minütigen Debatte ebenfalls beraten werden. Im Anschluss sollten die beiden Vorlagen zur weiteren Beratung an den federführenden Gesundheitsausschuss überwiesen werden. Gesetzentwurf der Bundesregierung Die bisher illegale Droge Cannabis soll unter bestimmten Bedingungen für den privaten Konsum legalisiert werden. Vorgesehen sind der legale Besitz und Konsum von Cannabis für Erwachsene. Ermöglicht werden der private Eigenanbau, der gemeinschaftliche nichtgewerbliche Eigenanbau und die kontrollierte Weitergabe von Cannabis durch Anbauvereinigungen. Mit dem Gesetzentwurf werde ein verantwortungsvoller Umgang mit Cannabis erleichtert, heißt es in der Vorlage der Bundesregierung. Das Gesetz zielt den Angaben zufolge darauf ab, zu einem verbesserten Gesundheitsschutz beizutragen, Aufklärung und Prävention zu stärken, den illegalen Markt für Cannabis einzudämmen sowie den Kinder- und Jugendschutz zu verbessern. Die aktuelle Entwicklung zeige, dass der Konsum von Cannabis trotz der bestehenden Verbotsregelungen weiter ansteige. Das vom Schwarzmarkt bezogene Cannabis sei oft mit einem erhöhten Gesundheitsrisiko verbunden, da der Gehalt des Wirkstoffs Tetrahydrocannabinol (THC) unbekannt sei und giftige Beimengungen, Verunreinigungen sowie synthetische Cannabinoide enthalten sein könnten. Erwachsenen ist künftig der Besitz von bis zu 25 Gramm Cannabis für den Eigenkonsum erlaubt. Möglich werden soll zudem der private Eigenanbau von bis zu drei Cannabispflanzen zum Eigenkonsum. Privat angebautes Cannabis muss jedoch vor dem Zugriff durch Kinder und Jugendliche geschützt werden. Außerdem dürfen nichtgewerbliche Anbauvereinigungen Cannabis künftig anbauen und an ihre Mitglieder zum Eigenkonsum weitergeben. Dafür gelten strenge Vorschriften. So werden für die Anbauvereinigungen maximal 500 Mitglieder zugelassen, die ihren Wohnsitz oder gewöhnlichen Aufenthalt in Deutschland haben müssen. Zulässig ist nur die Mitgliedschaft in einer Anbauvereinigung. In den Anbauvereinigungen darf Cannabis nur in begrenztem Umfang an Mitglieder weitergegeben werden, wobei die Mitgliedschaft und das Alter zu überprüfen sind. An Mitglieder weitergegeben werden dürfen maximal 25 Gramm pro Tag oder 50 Gramm pro Monat. Die Ausgabe von Cannabis an Heranwachsende zwischen 18 und 21 Jahren ist auf 30 Gramm pro Monat mit einer Begrenzung des THC-Gehalts auf zehn Prozent zulässig. Konsumcannabis darf als Haschisch oder Marihuana nur in kontrollierter Qualität und in Reinform weitergegeben werden. In einer Schutzzone von 200 Metern um Anbauvereinigungen sowie Schulen, Kinder- und Jugendeinrichtungen, Kinderspielplätzen und öffentlich zugängliche Sportstätten wird der Konsum von Cannabis verboten. Um insbesondere Kinder und Jugendliche vor der Droge zu schützen, gilt ein allgemeines Werbe- und Sponsoringverbot für Konsumcannabis und Anbauvereinigungen. Geplant ist außerdem eine Stärkung der Prävention durch eine Aufklärungskampagne der Bundeszentrale für gesundheitliche Aufklärung (BZgA) über die Wirkung und Risiken von Cannabis. Die Novelle soll nach vier Jahren auf ihre gesellschaftlichen Auswirkungen hin evaluiert werden. Es bleibt bei der Verschreibungspflicht für Medizinalcannabis. (pk/10.10.2023) zur Startseite Marginalspalte Dokumente 20/8704 - Gesetzentwurf: Entwurf eines Gesetzes zum kontrollierten Umgang mit Cannabis und zur Änderung weiterer Vorschriften (Cannabisgesetz - CanG) PDF1 MB — Status: 09.10.2023 Tagesordnung Sitzungsverlauf Herausgeber Deutscher Bundestag, Online-Dienste zur Startseite",
    "commentLink": "https://news.ycombinator.com/item?id=39481188",
    "commentBody": "German Bundestag Passes Cannabis Legalization (bundestag.de)255 points by 2-718-281-828 19 hours agohidepastfavorite213 comments WirelessGigabit 16 hours agoAnd still to this day if you get caught with weed in Belgium they put you in front of a judge who is going to berate you for smoking a joint once per week. There are still random police checks checks between Maastricht and Belgian cities on the other side. Same with public transportation. Many times, when entering Belgium, cops get on the bus with a dog to see if you have weed on you. And this is the same country that allows people to drink a beer while driving home from work. reply dmoy 16 hours agoparent> allows people to drink a beer while driving home from work. hold up, what? I knew various European countries had much less draconian liquor laws than the US, but... while driving? reply nopcode 16 hours agorootparentThere's only a limit of how much alcohol you can have in your bloodstream. Doesn't matter how or when that alcohol got there. Drinking a beer in the car is just as legal here as drinking a pepsi. Personally I don't see the problem. reply godelski 14 hours agorootparentOh that's much more reasonable. I always thought the US laws were weird because open container is a really weird thing to do anything more than be some suspicion (I think you should need more. Like someone is acting drunk, but hard to prove). Why can't my friends drink in the car? Why can't I have a trashbag full of empty cans that I'm bringing back from a camping trip? I gotta put those in my trunk? Not all vehicles have trunks. I can bring a bottle of wine or whisky to a friends, we don't drink all of it, and I gotta hide it or wrap it in duct tape to drive it home? The point of the law is about the danger posed to you, others, and property. Just focus on that. reply singleshot_ 16 hours agorootparentprevThis is how it was in certain western US states prior to Dole v. S. Dakota. In fact in my neck of the woods a few drive through liquor stores remain. reply skrause 15 hours agorootparentprevYou wouldn't want to do that anyway because you'll give the police probable cause to take you to the police station for a blood test. reply oezi 16 hours agorootparentprevNo European country restricts where you can drink (to my knowledge). Only what things you can do when drunk. reply SargeDebian 13 hours agorootparentYou are not allowed to have access to an open container while in the driver's seat in the Netherlands. reply vytautask 16 hours agorootparentprevThat's not true. E.g. Lithuania has laws restricting it (can not even have opened alcohol bottles inside of a car). reply codethief 14 hours agorootparentprevTo my knowledge, in Spain you're not allowed to drink in public(?) Whether or not people/the police care seems to be an entirely different matter, though, and also depend on the city/region. reply swarnie 16 hours agorootparentprevI had to look this up but apparently the UK doesn't either. Still, if a police officer exists within 10 miles of you and sees you and pulls you over its going to cause you a massive delay. I think its a 20 minute minimum wait before breath tests, then blood at a station. reply leadingthenet 16 hours agorootparent> I had to look this up but apparently the UK doesn't either. There are a few city-wide regulations in Scotland that prohibit it, possibly in other parts of the UK as well, but there's indeed no such national law. reply unwind 16 hours agorootparentprevHuh? Please see [1] for examples (aka \"Sweden has entered the chat\"). [1]: https://en.m.wikipedia.org/wiki/Drinking_in_public reply nippoo 15 hours agorootparentprevYup. This is the case in the UK too. You're not allowed to be drunk and drive, but you're absolutely allowed to have a can of beer while driving. This surprised me when going to the States - there's nothing stopping you from downing a can then getting in the car, but it's illegal to even have an open container of alcohol in the car (even if held by a passenger and you're teetotal) reply ManBeardPc 15 hours agorootparentprevIn Bavaria I've seen beer vending machines inside of factories with heavy machinery and forklifts everywhere. reply metanonsense 14 hours agorootparentBeer is to Bavarians, what guns are to Texans. Don‘t dare to even think of taking it from them. reply luckystarr 3 hours agorootparentThe amount of beer consumed in Bavaria is on a decreasing trend. Breweries are worried and some are looking into exports. Times are changing. reply tetris11 13 hours agoparentprevThe groups of armed military personnel stomping through train stations in Brussels was definitely a culture shock for me. Not even the US is like that. reply tempodox 17 hours agoprevSo it becomes technically legal, but they put so many obstacles in your way that buying illegally will hardly lose attraction. Cannabis dealers won't go out of work any time soon. reply r0ckarong 17 hours agoparentBiggest thing is that you can now at least legally possess it. They never cared where it came from before either. Smoking it isn't illegal, just somehow buying it and having it. Truly an insane situation. Now at least you can own a reasonable amount of weed without being in this absurd limbo. reply godelski 14 hours agorootparent> Biggest thing is that you can now at least legally possess it. I really want this to be true for a lot of drugs and even other criminal activities. Not because I necessarily support these things, but because we've seen that when we don't do this, prosecutors put far more of their time and energy into going after the users because they are much easier to go after. But if we do consider these things problems, we need to go after those distributing and manufacturing. It's like trying to put out a fire by removing all things that are flammable. Sure, it can work, but you're going to have a hard time doing this if you're in the woods. Main focus should be on the fire. reply fragmede 12 hours agorootparentbut manufacturer and distribution is just filling a need the market. without the demand for the product, it won't sell, so what's really needed are better social services so addicts can get off their addictions. jobs, housing, counseling, hope. saying it should be legal to have it and then go after the manufacturer instead is also treating the symptom, sucking out the smoke without addressing the fire. reply godelski 10 hours agorootparentSure, I took Econ 101 too. But the problem is that that's 101. Once you get to a more advanced level you find more complexity. It is completely possible to generate demand. In some sense this should be obvious as there was no demand for smartphones 50 years ago. You might say some of the ideas were there and thus that's demand, so that could be fair. But certainly not if we go back 500 where even many of these concepts did not exist and the demand would be for easier communication, a much more abstract idea. I mean in Econ 101 you learn about the Efficient Market Hypothesis too, but no economist actually believes it to be true. With drugs I think this is a bit more apparent because there is addiction. It is well known that a common strategy is getting users hooked. Either by offering some initially for free or at a reduced price, or by increasing the addictive qualities of the product. In fact, we even see similar phenomena in the white market. Starbucks coffee has about twice as much caffeine as a standard cup[0] and this certainly creates a higher demand for their coffee. But I don't think many are aware of this. Also consider there are different ways of \"legal.\" Some places have \"decriminalized\" drugs, which would be in line with this idea. For example, the state of Oregon in the US did this. Many people portray this as legality, but it isn't. If you are found with drugs there they will still be confiscated AND you pay a $100 fine and the court will give you information about addiction treatment centers. So not really legal, but not a major criminal offense. That seems like a fair way to put pressure towards manufacturing and distribution if you don't want to just legalize possession (which would always be limited in quantities). I also just don't buy your analogy in any way. We reduce things that have demand all the time through market regulations. Anything that is illegal to sell or produce is something that there is demand for somewhere. There's a HUGE demand for slave labor, but we've regulated that away (demand is for cheap labor, and slave labor is towards the cheapest one can get if not THE cheapest). The reason to go after manufacturers and distributors is because network effects. When you cut off a dealer you cut off all the people who got their drugs through them. Of course another dealer can take their place, but the effect is still real and far more disruptive than going after tree nodes. You are cutting off branches and the new dealer is like trying to reorganize those orphaned nodes. It's harder. The manufacturers are nodes much closer to the root and so have much greater disruption downstream. You're right that there are orphaned nodes, but it isn't uncommon for people to get off drugs after their supply runs dry. You've essentially forced them. TLDR: focus on the choke points in a network. [0] https://www.washingtonpost.com/opinions/five-myths-about-caf... reply f6v 17 hours agorootparentprevPossession has been tolerated for a long time now. You can’t walk through a city and not smell weed. AFAIK the tolerable limit was 5g, a person should seek help if they need more than that on them. reply throwbadubadu 16 hours agorootparentWhy, you also only ever buy one liter of milk, and otherwise should seek counsel? Orn lets make it less abstract and say one sixpack of beer? reply throw_0815 16 hours agorootparentprevThat very much depends on the Bundesland where that city is located. Good luck doing that in Munich. Personally I got prosecuted for (ordering!) 3g of weed, although later that got folded. Still trouble, though. Also I can still get problems with my driving license for that same amount (even though that alleged possession was in no way connected with driving any vehicle). reply bitfilped 13 hours agorootparentprevThat's a few joints as best, are we really declaring people as hopeless addicts for having more than a handful of joints on them? This seems similar to saying someone should never be allowed to have more than an 1/8th of alcohol on them at any time. Seems silly when put in perspective of what drugs are quantities are already legal. reply Gud 10 hours agorootparent5g is way more than a few joints. I smoke weed frequently (daily user). I go through 5g in maybe two weeks. reply bitfilped 10 hours agorootparentI use frequently as well, you must roll shorties. (Non-infused) pre rolls are typically sold with 1g each for reference. reply pantalaimon 16 hours agorootparentprevThe amount used to depend on the state, in Berlin up to 16g was considered a small amount for personal consumption. reply echoangle 16 hours agorootparentprevDepends on the location, don’t try that in Bavaria reply weaksauce 16 hours agorootparentprevan ounce is about 14 grams. 5 is slightly more than an eighth. if you don’t live near the dispensary and want some for a month or a few months an eighth is not really that much. i don’t think seeking help is an appropriate response here. reply jamiek88 16 hours agorootparentAn ounce is 28 grams. But your point stands. reply weaksauce 12 hours agorootparentyeah i see ads for 14g all the time and for some reason that stuck in my head as an ounce but 3.5 grams is an eighth of an ounce so 5 is slightly more than that. either way more than 5g is a reasonable amount to have on you if you are going to buy it for a longer timeframe. reply jpsouth 16 hours agorootparentprevAn ounce is 28 grams, 5g isn’t that much flower at all in the grand scheme of things. I presume it’s an attempt at stopping dealing, maybe to minors? But it feels asinine to have such a limit. Like another poster says, should this extend to a single crate of beer? One bottle of spirits? One pouch of tobacco? Having a 5g limit just means I’m going to make more frequent trips to the shop to purchase more cannabis, just let me buy a pound and leave me to it. reply shagmin 16 hours agorootparent> Having a 5g limit just means I’m going to make more frequent trips to the shop to purchase more cannabis That and possibly seeking out cannabis with a higher THC concentration. reply jpsouth 8 hours agorootparentTrue, as much as that’s not quite what I’d do because I like to just maintain a high, I’m sure a lot of folks would. Hell, on the weekend I’d switch it up to the higher %s to be fair. NL has this same rule of no more than around 5g, I’m not 100% how much the exact limit is but it’s nearby 5g. reply fabian2k 17 hours agoparentprevIn the end this is more of a compromise that was still politically feasible. Depending on who governs in the future this will likely be either expanded or rolled back. Parts of this also depend on some EU regulations that might have to be changed for full legalization to be possible. reply tfourb 17 hours agorootparentThe EU regulation was the central obstacle. It does not allow for commercial legalization of Cannabis beyond small trial projects. Originally, commercial legalization was the core of the German proposal, but it had to be revamped to only private and non-profit legalization because of legal concerns connected with EU law. reply wickedwiesel 16 hours agorootparentI am not a legal expert but I read that the case of the Netherlands proves this to be at least partially wrong. Retail sale is legal. Some municipalities have legalized supply chains. https://www.bloomberg.com/news/articles/2019-09-11/the-nethe... reply m0llusk 17 hours agoparentprevLikely true, and reminds me of an amusing and revealing story. There was a craft brewery that started to become popular and had to hire a relatively large number of employees to run the operation. Word got out that nearly everyone who worked there used cannabis, so police got an investigator to spy by getting hired to work in the brewery. They repeatedly asked other employees if they could buy cannabis from them, but every time the employees responded by freely sharing cannabis. Much cannabis culture is not strongly commercial. People grow and share. Maybe there is something in that which software developers could learn from. reply ilc 17 hours agorootparentMaybe a bit more GPL use would help here. :) reply pixl97 15 hours agorootparentprevI mean even a small operation can grow more than one person can ever smoke in their lifetime in short order. Any other commercial crop that we grow at scale is sold in the dollars per ton range. Outside of a few special cultivars there is no practical reason said drug is expensive and easily shareable for nearly free. reply personomas 17 hours agoparentprevAnd they'll probably tax the shit out of it #germany reply alleskleber 17 hours agorootparentThe tax revenue from commerical sales was one of the big pro arguments before they had to cancel/deley those plans due to EU/international laws. reply personomas 16 hours agorootparentAh great addition thank you for your comment. I love your name by the way. I wonder what EU/international laws prevent that reply hoffs 15 hours agorootparentIt's basically one of the UN treaties and Schengen ones that potentially clash, but that's debated as seen here https://eucrim.eu/articles/legalize-it-opportunities-and-cha... reply personomas 14 hours agorootparentThanks reply eqvinox 17 hours agorootparentprevThere is actually no tax on it (… in the current law) (You obviously still need to manage VAT if your business exceeds 22'000€/50'000€ per year.) reply mytailorisrich 17 hours agorootparentSo no tax except 19% VAT and about 30% corporate income tax... reply pantalaimon 16 hours agorootparentno, it's not allowed to sell it commercially, so no VAT. You can only obtain it through clubs for a fee to cover the production cost. reply mytailorisrich 16 hours agorootparentOh OK. So it's not fully legalised then... reply brodo 19 hours agoprevIt's a big step and still a compromise. Let's see how this whole non-commercial approach works out. I know some people who don't want to get into growing and don't want to join a club. reply lqet 18 hours agoparentExactly, this is what I don't buy in the \"black market will get extremely unattractive\" argument. The status quo is to buy illegally (but with very low risk for the buyer, and usually excellent anonymity) from established dealers, often people with a lot of knowledge in growing/processing. The new legal approach would be to either grow yourself, or join a club [0]. I don't consume cannabis, but if I would have to choose between joining a state-registered alcohol club, brewing my own beer, growing my own grapes, or just buying a bottle of wine illegally now and then from someone who has expertise in making it (and with nearly all risk on the seller side), I would definitely opt for the latter. [0] https://en.wikipedia.org/wiki/Cannabis_Social_Club reply murermader 17 hours agorootparentThe big advantage is that you can be sure that the cannabis you are buying is actually of a good quality. Especially in Baden-Württemberg (cannot find the source anymore), more cannabis that has been confiscated by the police was impure than pure. And you never know whether you get indica, sativa, 10% THC, 25% THC, CBD that is spiked with HHC, just CBD, or cannabis that is spiked with something else. If you find a good dealer that you can trust has good quality weed, than that is fine. But I have been buying from a lot of different dealers over the past few years (not random people on the street, people I know through other people), and the quality is always all over the place. I never want to buy from any black-market dealer ever again, once these cannabis clubs are up and running. reply nicbou 17 hours agorootparentThis. Buying weed in Berlin is nothing like buying in pre-legalization North America. If you buy without a solid connection, you will more often than not get a laced product. It took me a few years to get a reliable supplier and people frequently reach out to me on Reddit because I brought it up years ago. This might help. reply Abroszka 18 hours agorootparentprevThe main benefit comes from knowing what you have if you grow it vs. buying something that looks like weed from the guy on the street. Also growing it is super easy. If you can grow tomatoes then you are already overqualified. reply monocasa 18 hours agorootparent> Also growing it is super easy. If you can grow tomatoes then you are already overqualified. That's a little overstated. It's easy to grow very low quality weed. Growing something capable of being on a shelf to be sold is very much a skill that takes time, even for someone with a green thumb; the girls get too stressed very easily, and attract pests like you wouldn't believe. reply Abroszka 18 hours agorootparentPretty sure tomatoes attract more pests. Also people grow these in the forest on small sunny patches and they do just fine. It's literally a \"weed\", it grows like crazy. But yes, it won't be premium quality, just some average weed. reply monocasa 17 hours agorootparentI mean, you can grow \"ditch weed\" that way. It's not 1974 anymore. reply nick__m 15 hours agorootparentprevStress is good for canabis plant, however, I agree with you that growing quality pest free weed requires daily attention. I have grown extremely strong weed before the Canadian legalization and the method I used to maximize thc production consists of constantly stressing the plant. It was a combination of topping¹, super-cropping² and stem splitting³. 1- During the vegetative phase cut the top of the plant, wait a few weeks and repeat. 2- https://www.royalqueenseeds.com/blog-bigger-cannabis-yields-... 3- https://herbiesheadshop.com/blog/cannabis-stem-splitting-all... reply monocasa 15 hours agorootparent> Stress is good for canabis plant That's why I said \"too stressed\". It's a fine line you want to straddle. reply loeg 17 hours agorootparentprevNo, it's extremely easy to grow high quality weed too. It cannot be overstated how easy of a crop it is. The (mildly) difficult and labor-intensive part is the post-processing: https://news.ycombinator.com/item?id=39482755 reply monocasa 16 hours agorootparentA) that link is to a deleted post B) I was a small grower who worked contributed a small bit to the regulatory infrastructure for Colorado's legalization and communicated with many growers of many crop sizes. It's not extremely easy. Additionally trimming isn't difficult in that it takes skill, it's difficult in that it's a lot of mind numbing work. Consistently growing is difficult as a skill. The whole discussion kind of reminds me of the beer brewing industry, where techies think because they had a couple garage brews that went well (and don't consider the ones that didn't), they think they are a replacement for a brewery. And weed is even worse; you're looking at an hour a day for a small batch, and you can't miss a day. And the girls are way worse at telling you what went wrong, whereas you can generally tell exactly what went wrong with beer from the off flavors. reply bongodongobob 17 hours agorootparentprevIt really just depends on your seeds. Yes there is fancy shit you can do, but good seeds + light + water is literally all you need to grow perfectly fine weed. The trickier stuff is in curing it, but even that is pretty straightforward. reply monocasa 17 hours agorootparentEven with good genetics, you can easily run into the problems I've said. reply waffleiron 17 hours agorootparentSame with the orchids my grandma keeps. Weed isn’t more difficult than (quite a few) other plants people have been growing at home. reply monocasa 16 hours agorootparentYeah, I'd consider good quality weed to be like orchids. I'm not saying it's not doable; I'm saying it's not \"just like tomatoes\" or \"just grows itself, that's why the call it 'weed'\". reply loeg 17 hours agorootparentprevWell, nutrients. But MasterBlend tomato goes a long way. reply lqet 18 hours agorootparentprevThat may be true, but it is still much more convenient and anonymous to just give someone you trust some money, especially if you live in an apartment, or have small children. I would be extremely hesitant to grow cannabis on our balcony. I am 100% sure neither my landlord, nor my neighbors would approve. reply Abroszka 18 hours agorootparent> I would be extremely hesitant to grow cannabis on our balcony. Why is that? Just buy a small body, auto flowering seed, some fresh soil and water it every couple days and wait. You won't have a gigantic harvest but that's basically all you have to do and you will have more weed than you know what to do with. When grown, cut it, hang it upside down and wait until it's dry. reply lqet 18 hours agorootparent> Why is that? Anonymity. My neighbors, my parents, my wife's parents, the parents of children that visit my child, everybody passing our balcony on the street, and essentially every visitor to our apartment would assume that we consume drugs regularly. This is something I could not have cared less about when I was in my early twenties and living in a building full of students. But it is not something you want to be associated with if you have children in kindergarten or school and if you have to face other parents or teachers from your neighborhood on a daily basis. If I would start to consume cannabis, I would prefer to do it in private. reply Abroszka 18 hours agorootparentThat's understandable. There is still a social stigma attached to it. Hopefully it will change over time. reply ivirshup 18 hours agorootparentprevMost Germans live in apartments, and rent. The growing and processing does produce strong odors, which a landlord/ neighbors may not approve of. reply throwaway234591 18 hours agorootparentCommon misconception. You generally want to grow cannabis in a \"grow box\" of some kind, because you need decent control over the light the plant receives (there's distinct vegetative/flowering phases for cannabis plants). In that case your enclosed box can ventilate through a carbon filter, which by most reports (see the countless threads on r/microgrowery for example) cuts the odors down to nothing, even late in the flowering phase. Visual guide: https://www.supergreenlab.com/guide/how-to-build-a-ikea-eket... reply jpsouth 16 hours agorootparentYou can do it outside as well, but typically a box is the best with regulated lighting, temperature and humidity. I’m not sure I believe the carbon filter reduces the smell to nothing, in my experience it still stinks while running through an internal AND external carbon filter. reply rob74 18 hours agorootparentprevThe smoking also produces strong odors, which (as a neighbor) I do not approve of, so I'm not sure if adding the odors from growing and processing to that will make the situation much worse? reply GordonS 18 hours agorootparentMany are switching to vaping these days, which produces far less odour, and what little there is dissipates quickly. Vapour also doesn't stick to fabrics, walls etc like smoke does - it's just superior to smoking in every way. reply feoren 17 hours agorootparent> [Vaping is] just superior to smoking in every way. Is there higher risk of infection transmission? I'm sure those reports a few years ago of serious lung infections from tainted vape oils are biasing my thinking here, but it also makes some sense that a high-temperature flame on a dry medium wouldn't transmit nearly as many microorganisms as a lower temperature vaporization of a wet medium. reply pantalaimon 16 hours agorootparentWith cannabis you usually have dry herb vaporizers, not liquid based devices. reply LargoLasskhyfv 16 hours agorootparentprevThat usually came from some additive for the desired viscosity of the vaping liquid, leading to popcorn lungs. Only black market things, didn't happen to legally aqquired stuff where it was legal at the times. reply monocasa 18 hours agorootparentprevThe growing smells are much more pungent. reply ivirshup 18 hours agorootparentprevI was thinking more about timescale. If someone smokes a joint near your window, that smell will probably be gone in half an hour. If there is a plant that's just sitting there, it'll be more subtle, but it's not going anywhere. That said – many people like the smell of Hopfentee (Hop tea), which is pretty similar. reply Abroszka 18 hours agorootparentprevRight, it does have a strong odor. But if you have a balcony then it's easy even in an apartment. Without a balcony it is a kinda difficult as you need some carbon filtering set up. reply WinstonSmith84 18 hours agorootparentprevSuppose you could have the same argument with all the rest: growing your vegetables is super easy (and then add the chickens and fishes etc.). Well, some people just prefer to go to the supermarket.. reply aqme28 18 hours agorootparentprevThat’s true, but I think that of all the drug markets, weed is the least likely to be adulterated in any way reply Blahah 18 hours agorootparentWeed can easily be adulterated (e.g. by spraying with synthetic cannabinoids), but generally it's trivial to find a supplier who doesn't do that. But also true of MDMA and ketamine. reply black_puppydog 18 hours agorootparentprev> from established dealers, often people with a lot of knowledge in growing/processing I don't know where you live but where I grew up in Germany this was, and still is, decidedly not the status quo. Folks I know literally \"import\" from hundreds of kilometers away because that's the next place where they could find someone who fits your description. The rest of the market is exactly as sketchy as I'd expect. reply mc32 18 hours agorootparentprevIn some countries legal alcohol is expensive so they buy cheap stuff from “moonshiners” or whatever they’re called in those places, every once in a while you hear about poisonings affecting hundreds of people. So, I don’t know. I probably would pay the state premium over the guy who doesn’t have great quality control. reply diggan 18 hours agoparentprev> don't want to join a club. What would be the reason for not wanting to join a club? Seems like a pretty OK solution between \"it's totally illegal\" and \"the state store sells it\", with some safe guards but still let non-profits organize the work and community. FWIW, we have \"social clubs\" here in Spain, where it's neither illegal/legal on a national level, and it seems to be working out OK as far as I know. reply weinzierl 18 hours agorootparentAnonymity! Do you want to be a state registered drug user? The clubs have to be registered and need a license. They need to keep a register of members. It is not in the law that they need to give this register to the authorities, but it is still a risk. EDIT: I looked up the details. The clubs need to keep track of every sale, including data about the buyer. They have to report this to the authorities twice a year in anonymized form. reply tetha 17 hours agorootparent> The clubs have to be registered and need a license. They need to keep a register of members. It is not in the law that they need to give this register to the authorities, but it is still a risk. I very much recall how long the promise of \"Covid Guest Lists are not used by the police\" lasted. reply eqvinox 17 hours agorootparentprevThe anonymized form is only for the \"automatic\" reports without anyone asking. The authority can request — §26(2) — the data (= non-anonymized) at any point based on without any requirement for a specific reason. That said, \"the authority\" is not necessarily the police or public prosecutor; the determination who does this is left to the federal state (who might make it the police/prosecutor, or not…) — presumably if they're not \"the authority\" themselves, they would have to ask \"the authority\" to forward it. reply brodo 18 hours agorootparentprevThe law contains extensive book-keeping requirements for the clubs. Users don't want to be on a list. Especially with the CDU/CSU saying that they plan to re-criminalize if they win the next election. With the rise of the AfD and personal negative interactions with the state that these people had, I can understand that they are cautious. Also, these are not social clubs but growing clubs. You are not allowed to consume Cannabis in the club and 100 meters around it. reply nicbou 16 hours agorootparentprevI just want to walk into a store, buy weed and walk out. Same as alcohol or cigarettes. This being Germany, I expect to have to spend weeks joining the waiting lists of overbooked clubs, hoping that one of them has a free slot. Then more forms, sent by post because email is evil, then finally I can buy weed 3 months down the road. If you live in Germany for a while, you learn that you never get anything without a fight here. It's always tedious. reply dorvak 18 hours agoparentprevThis is actually a smaller step, as it needs to be approved by the Bundesrat before being effective. This could take month and it’s not guaranteed to pass. reply TillE 18 hours agorootparent> it needs to be approved by the Bundesrat Apparently it doesn't. \"Nach der Zustimmung des Bundestags kommt das Gesetz am 22. März abschließend in den Bundesrat. Zustimmungsbedürftig ist es dort nicht, die Länderkammer kann aber den Vermittlungsausschuss anrufen und die Legalisierung so verzögern.\" https://www.sueddeutsche.de/politik/bundestag-livestream-can... They can't veto it, but they could delay it. reply brodo 18 hours agorootparentprevThe 180,000 people per year who will not face legal issues because of this law will disagree on how big a step this is. reply weinzierl 17 hours agorootparentDo you think these 180 000 people will be able or willing to join a club? With a mandatory membership fee and legally mandated minimum membership period of three months? As these clubs are not allowed to hire people and are also forbidden to allow non-members to act on club duties, a membership will mean some work too. How many of the 180 000 are willing to put in that effort. reply muldvarp 10 hours agorootparentIt doesn't matter whether or not they will join a club. It matters that simply owning (a non-negligible amount of) cannabis is no longer illegal. reply eqvinox 18 hours agoparentprev> \"die kontrollierte Weitergabe von Cannabis durch Anbauvereinigungen\" This does not sound like you have to \"join a club\", you just have to buy directly from a club. (… reading actual text now to check …) Nope, nevermind… §1 Abs. 13: \"Anbauvereinigungen: […] deren Zweck der gemeinschaftliche nichtgewerbliche Eigenanbau und die Weitergabe von Cannabis zum Eigenkonsum durch und an Mitglieder sowie die Weitergabe von Vermehrungsmaterial ist.\" ⇒ you either have to grow it yourself or be a member of an association that grows it; can't buy directly from a club if you're not a member. reply wuiheerfoj 17 hours agorootparentIn Spain this amounts to paying 10EUR to join a club then you can buy at your leisure. Seems like a fairly low barrier. The data maintenance stuff is a bit more concerning, but I imagine once cannabis is embedded in the country the reporting will disappear in a round of cuts to gov spending reply eqvinox 17 hours agorootparentThe German law tries to prevent this several ways: - charging individually for sales is prohibited by §25(2) and §24; the only allowed thing is to have consumption-dependent but standardized (\"Pauschale\") membership costs. (This is, honestly, worded a bit weird and might need a lawyer to interpret \"properly\".) [Edit: this got changed in the final version — and is now more restrictive, only membership fees are allowed.] - you are only permitted to be a member of one association, §16(2) - associations are only permitted to have 500 members, §16(2) - there is a minimum membership duration of 3 months, §16(5) reply weinzierl 17 hours agorootparentThe biggest hurdle for clubs will be that they need dedicated property that fulfills the necessary security requirements. Running a club partly or wholly from a private residence is explicitly forbidden. reply weinzierl 17 hours agorootparentprevThe German clubs are not allowed to sell or gift. Members pay a membership fee and are in return allowed to share the crop of their three allowed plants with other members. reply diggan 17 hours agorootparentThis is basically how it works in Spain as well, you don't use the words \"buy\" or \"sell\", but you contribute financially to the club treasury and you may withdraw that deposit in suitable amount of weed. You don't hand over cash to the person behind the counter, as an example. You're not there to \"purchase\", but the effect is the same. reply lqet 18 hours agorootparentprev> \"... dürfen nichtgewerbliche Anbauvereinigungen Cannabis künftig anbauen und an ihre Mitglieder zum Eigenkonsum weitergeben.\" Free translation: non-commercial clubs can grow cannabis and hand it out in small amounts to registered members reply sva_ 19 hours agoprevYou should post an English source such as https://www.dw.com/en/germanys-bundestag-votes-for-cannabis-... reply nielsole 18 hours agoparent> Please submit the original source. The guidelines don't say anything about language reply sva_ 18 hours agorootparentThey don't state it explicitly, but https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply makeitdouble 17 hours agorootparentI feel that's where the rubber meets the road on automatic translation. Even on HN we're seeing it as non practical or reliable enough to let users deal with their own needs directly. That's one of the reason I'm so tired of seeing translation as one of the bullet point repeated over and over for AI use. At the end of the day it will never be more than a niche if people don't trust the result (for the record, I agree they're not great) reply caeruleus 15 hours agoprevThere's a nuance to this that I haven't seen mentioned so far: With this law, Cannabis will be removed from the list of scheduled drugs and turned into a simple prescription drug. It will be a lot less complicated to prescribe medical Cannabis. reply pantalaimon 18 hours agoprevrelevant for HN: The Joint Routing Protocol: http://darklab.org/jrp.txt reply verticalscaler 18 hours agoparentI subscribe to the Kat Williams Gambit myself: Everybody has their own joint so you don't share spittle with dudes like some clueless teenager. :) reply newsclues 17 hours agorootparentYeah cutting out sharing joints led to much less transmission of illness like colds. reply TillE 18 hours agoprevI've read so much hand-wringing German coverage of this issue, and while sometimes comparisons are made to other countries, it's almost never mentioned that cannabis has been legal for half of the US population for years now, and the sky hasn't fallen. The system set up by this law is extremely dumb, but at least small home grows are legal, and the government is still exploring a path to commercial sales that would be compliant with EU law. reply aqme28 18 hours agoparentIt’s been (effectively) legal in neighboring Netherlands for even longer reply dubbel 18 hours agorootparentAs far as I know the Netherlands only legalized consumption and sale, but not production? Which just lead to higher demand for products what were still largely supplied by criminal groups. reply aden1ne 17 hours agorootparentPossession is still technically illegal, tho it hasn't been enforced since the 1970s. That said, since December 2023 there has been fully legally-produced cannabis on the Dutch market. While media tends to call it \"state weed\" (\"staatswiet\"), it's not nationalized, it's just licensed production. Currently it's only available in a number of cities, chiefly in the South of the country, but more cities should be onboarded onto the system this year. reply bregma 18 hours agoparentprevCannabis is still illegal for 100% of the US population under federal law. reply rob74 18 hours agorootparentWhat does that mean in practice? It's legal in California, but the FBI might arrest you if you go to Yosemite National Park with cannabis? reply alistairSH 17 hours agorootparentAnd airports and other places that are nominally under federal control. That said, airports generally care more about bombs and hard drugs, but the risk is higher than a bottle of bourbon. It's also still a disqualifier for federal employment. reply bregma 18 hours agorootparentprevFor a start it means no bank can legally lend you money for your cannabis business or they would be subject to prosecution. reply kjkjadksj 17 hours agorootparentA cursory google search shows that as a result of that stipulation there are in fact financing packages or lenders that acknowledge the risk and seek to meet that demand. reply lucb1e 16 hours agoparentprevComment made little sense to me so I looked it up: \"hand-wringing: an overwrought expression of concern or guilt\" (Merriam Webster) TIL this is the polar opposite from the Dutch expression to rub your hands together which means \"being happy about a success; being content; expressing happiness\" (Ensie, translated by me) Asking my german partner, they say it's a thing you'd do when plotting something evil, so more negative than positive I guess, but there is no expression to go with it like \"hand wringing\" or \"in de handen wrijven\" are common expressions. I would subscribe to it being a plotting thing in Dutch as well, but that also doesn't work with the US English definition and the way that you used it Do people from the USA also use it this way in a physical sense, rubbing hands together when they are concerned or feeling guilty or is it just an artifact of history similar to \"hanging up\" a phone? In the Netherlands I've definitely seen rubbing hands for excitement reply DaedPsyker 15 hours agorootparentThere is the expression in English, rubbing your/their hands with glee. All context dependent as for the physicality. Someone holding their hands tightly and rubbing them might be nervous for example. Someone fast moving them but not cold could be more joyous. reply d_k_f 16 hours agorootparentprevA slight addendum from another German: we have the adjective \"händeringend\", which is the verbatim translation of \"hand wringing-ly\". It's usually not used in a negative, scheming connotation, though - if you look/search for something \"händeringend\", your are desperately looking for that something. The actual act of wringing your hands is associated with generic Bond villains, though. Language is weird. reply faeriechangling 15 hours agoprevAs legalization goes underway we’re now aware of how smoking and vaporizing seem to be linked to endothelial cell damage and heartattacks, probably not great for potency either. Marijuana is not a safe drug nor the panacea it’s marketed as. We also seem to be seeing higher rates of addiction to marijauna, despite it being nominally non-addictive. Only thing which appears relatively safe is oral consumption over inhaling. All the same, it’s really not THAT dangerous a drug and criminalization is senseless and a total farce. All the problems legalization causes combined pale in comparison to how dumb criminalization is. reply jenadine 13 hours agoparentRight. Also alcohol is not good. Tobacco is not good. Sugar is not good. But there are safe amounts. reply eqvinox 16 hours agoprev\"fun fact\": if someone is for whatever reason opposed to an association growing cannabis somewhere near where they have any kind of \"influence\" — they'd just have to get something resembling a public playground or public sports installation there. I'm willing to bet that this is gonna be how conservative local authorities force out cannabis growing. reply haswell 17 hours agoprevI think that on balance, legalization is a good thing. Certainly it should not be illegal when alcohol is legal. At the same time, I'm about 30 days into quitting entirely after realizing that I couldn't have a healthy relationship with it. I'm experiencing intense anxiety, dark thoughts, and have struggled with the intensity of REM rebound. My resting heart rate immediately went up about 15BPM on average as my body starts the process of finding its new equilibrium. I first started using it \"medicinally\" to cope with poor sleep and depression. It actually helped lower my anxiety (with the right strain). It suppresses REM sleep and dreams, which was beneficial since my dreams tended to be part of the reason I had such poor sleep. For a time, it was incredibly helpful, and it helped me establish some better habits and process some difficult things. But over time, it crept into more and more parts of my life. I never went full \"wake & bake\", but found myself wanting to use it earlier and earlier each day. When I did use it recreationally, I started to feel the pull even stronger. It started to majorly impact my short term memory, and I started noticing myself forgetting important things while exploring a new relationship. I started to feel like it was no longer beneficial, and decided to quit. And that's when I realized how hard it was to quit. I tried and failed multiple times before finally building enough willpower to actually do it. And there's this part of me that still worries that I'll fall back into it when things get hard. For better or worse, I'm dealing with some really difficult situations in my life and I'm staying away from it anyway. This gives me optimism, but damn, I didn't think it would be this difficult. In many ways, it feels like the pendulum has swung too far with legalization. This is not to imply I think it shouldn't be legal, but that the culture around it and the public messaging hasn't really caught up with the reality of the potential for harmful use. The public is well aware of the downsides of alcohol use, and there are well-established methods and institutions to help people deal with alcohol addiction and recovery. If someone is an alcoholic, the public understands the severity of this addiction, and recognizes the challenge that such a person faces in staying sober. But people who are addicted to cannabis often have a hard time convincing people that this is a real issue. The fact that it's not physically addictive in the same ways as alcohol and other drugs has led to the misconception that the addiction potential is not real and that the difficulty of managing it is not real. The warnings that \"using this can be habit forming\" don't seem to convey the reality of what it feels like to form that habit, and how hard it can be to break it. Growing communities like /r/leaves and /r/Petioles tell this story over and over. I think that the extremely high THC strains, and even higher THC concentrations in concentrates and cartridges has a lot to do with this. The stuff people are getting these days isn't your hippy uncle's weed, and while the public consciousness is calibrated on the relatively harmless stuff, the stuff that people are using all day looks nothing like that. All of this to say: be careful. I have had some incredibly good experiences with it, and I think it helped me open my mind. It helped me through a tough time. It's also really enjoyable. But it has a much darker side than many people realize, and it took me far to long to accept that I might be one of the people who can't have a healthy relationship with it. And the fact that I'd had a \"take it or leave it\" feeling about it for years lulled me into a false sense of security. The slide towards maladaptive use happened gradually and took awhile to notice. I hope that with the continued movements towards legalization, there is also an increase in public awareness and support for people who get themselves into trouble. More focus on the safety concerns of high THC strains and harmful use. More growers who focus on medicinally useful products vs. just chasing the highest THC. reply bbsz 16 hours agoparentHey, good luck with dropping it, 30 days is already a milestone! First 3 to 6 months is always terrible. I also had issues with sleep because of dreams, and also used cannabis for that purpose. Getting back to sleeping without THC in the bloodstream is, well... an experience on it's own. It's funny how all of the adults I've heard/read basically share the same experience of dropping it (REM rebound, heart rate and anxiety/strange thoughts). And, yeah, today's weed is far more potent than weed I initially started to smoke almost 2 decades ago. reply haswell 15 hours agorootparentThank you! 30 days has indeed felt like an accomplishment, and I'm looking forward to getting through the rest of this. I've done a significant amount of processing and have a good therapist now, which has helped me deal with the sleep somewhat. New tools and new habits make a big difference. reply cubefox 16 hours agoparentprev> Certainly it should not be illegal when alcohol is legal. I don't think this argument makes sense. Alcohol could well be a net harm on society, while a ban is not realistic due to its established role in society. This doesn't imply cannabis should have been legalized. reply haswell 16 hours agorootparentThere's a lot implied in that quoted sentence that I didn't expand on. The point more broadly is that if our society is willing to accept alcohol as a recreational substance with downsides, and more generally the idea that consuming recreational substances shouldn't be a criminal act, it makes no sense to send people to prison for consuming a substance that seems far less harmful in general. > ...while a ban is not realistic due to its established role in society. This doesn't imply cannabis should have been legalized. I disagree. Prior to legalization, cannabis already had an established role in society and saw widespread use. The primary difference between it and alcohol is that we sent people to prison for one, and didn't for the other, while also accepting the statistical reality that alcohol seems generally far more harmful. More harmful in terms of individual health outcomes and the downsides of becoming an addicted user, and more harmful to others around those who use it, e.g. deaths caused by drunk drivers, domestic abuse fueled by alcoholism, etc. At least in the US (not sure about the climate in Germany), the reality was that cannabis use was already widespread, and that people's lives were routinely ruined for using it despite their use causing no harm to others. All while problematic use of alcohol routinely resulted in what are effectively slaps on the wrist, even when people routinely put other people at risk while driving under the influence. It's against this backdrop that I'm comparing the two. Both were already pervasive. The difference in policy between the two made no sense. And this is all before considering the clear upsides to cannabis. The medicinal applications are real, and have enabled people to live better lives without the downsides of the other widely prescribed pharmaceutical options. Altering our mental states by consuming substances seems like a deeply human thing (in addition to be observed in other species), and is deeply embedded in us. I think there are very good reasons to ban some substances for the sake of public health. But I don't think a default stance against mind alteration is a good one either. reply cubefox 13 hours agorootparentIn Germany (and not just Germany probably) the use of cannabis, and other drugs apart from alcohol and nicotine, is significantly less widespread and normalized than in the US. It's definitely far from being as normalized as alcohol. (Although cannabis obviously became more pervasive in the past few decades. Perhaps not least due to exported US American TV shows normalizing it.) Legalizing cannabis in such an environment seems to me like legalizing alcohol in a country where alcohol use isn't already normalized -- like in Iran. A very questionable idea. One would need strong arguments on why the expected benefits are larger than the expected harms. > And this is all before considering the clear upsides to cannabis. The medicinal applications are real, and have enabled people to live better lives without the downsides of the other widely prescribed pharmaceutical options. Yes, but using cannabis (THC, presumably) as a specialized medication is very different from legalizing it altogether. It would be no different from other drugs that need approval from a government agency with regards to efficacy and safety, before being available only with a prescription. (Being available with prescription only makes sense if there is a significant chance of abuse. Which is the case if the substance is addictive. Which suggests non-addictive substances like, perhaps, LSD and psilocybin, could be freely available. Though I'm not an expert on these drugs.) > Altering our mental states by consuming substances seems like a deeply human thing (in addition to be observed in other species), and is deeply embedded in us. I think there are very good reasons to ban some substances for the sake of public health. But I don't think a default stance against mind alteration is a good one either. I would argue that a lot of the harm comes from a substance a) being addictive, and b) being significantly unhealthy. To the point where the net harm probably outweighs the net benefit. Caffeine is pretty much the only substance I know that is addictive while being quite harmless. But actually banning things has to consider the real chance of being successful with such a ban. The more people are already addicted or otherwise accustomed to a drug (e.g. to cigarettes or alcohol) the less realistic is a ban being successful and enforceable. reply haswell 13 hours agorootparentCan I ask where you're from? I'm just curious about worldview based on geographic factors and how that might influence perspective. > I would argue that a lot of the harm comes from a substance a) being addictive, and b) being significantly unhealthy. To the point where the net harm probably outweighs the net benefit. I think it's important to point out that cannabis is a plant, and has a drastically different risk profile than alcohol. You keep grouping the two as if they're similar, but they're not. I say this as someone who has clearly experienced the downsides, but who still doesn't think banning it makes any sense, especially if there are criminal penalties involved. Historically, the bans have been predicated on lies, and associating it with harder drugs that are a clear and obvious danger to public health. The issue I have with your argument is that it presupposes that these are plants to be legalized (vs. legal by default). The burden of proof should lie on why we think they are harmful, and why they shouldn't be legal by default, IMO. And when looked at through that lens, existing policies have clearly not been aligned with reality. I'd support common sense regulations and requirements around public education, maybe even limits on strength. But there's a wide spectrum of possibility between banning something and making sure that people use it safely. If we want to focus on banning substances that are addictive and a net harm to society, there is a lot more low hanging fruit across the food industry. Let's start with sugar. reply aChattuio 16 hours agoprevFYI: the German discrimination was/is so strong that you will lose your driver license when they catch you with weed nearly independent of the amount and location (Saturday park big city)/no car in sight reply jenadine 13 hours agoprevAnd can you drive a car a couple of days after taking weed without losing your driver licence? In Germany, the limit of THC in the blood while driving is almost zero, AFAIK reply rvnx 18 hours agoprevCurious to know what impact it will have on criminality. If dealers are making lot of money from cannabis, and the state removes that opportunity from them, then they may switch to more disturbing businesses. reply ffsm8 18 hours agoparent> and the state removes that opportunity from them does it though? canabis still cant be sold, legally. from a realistic perspective, this only made the black market more valueable, as the dealers no longer have to worry about prosecution as long as they're carrying but the actual acts are the same in real world. You mean the stealing for money for high priced black market drugs? You mean the shootouts/high speed chases where people run from the cops because they have a bag on them? Or do you mean lighting up a joint? The thing is, it's very easy to look at the statistics of violent crimes before and after. Also the vast majority of law enforcement agencies classify their crimes so you get detailed statistics of what kinds of crimes occur on a monthly/yearly basis. reply pantalaimon 18 hours agoparentprevThey still can make money from it since it's not available for sale commercially (EU laws prohibit this). So you can only get it by joining a club or grow it yourself, both are a hassle for most people so the black market will remain, but I expect there to be a lot more competition since not only organized crime is now able to partake but anyone who (legally) grows. reply robcohen 18 hours agoparentprevI could see that being an effect in the short term, but I don't think there's a fixed amount of criminality in a given society. I'd bet there's a significant linear correlation with the size of the black market in society (in terms of annual revenue) and the amount of criminality. Reduce the amount of revenue, reduce the amount of criminality. Source: Nothing. reply coffeebeqn 18 hours agoparentprevMost people don’t want to grow at home and the black (grey?) market will always be more profitable. Or maybe they’ll start a dispensary reply faeriechangling 15 hours agoparentprevI’ve seen it legalized around these parts and pot dealers didn’t turn to murder for hire or extortion rackets, they just shrugged their shoulders and found another regular job. We did however waste a lot less time prosecuting imaginary crimes. reply bregma 18 hours agoparentprevCannabis sales and possession has been legal in Canada for, what, 6 years or so. You only need to be of a certain minimum age and pay the excise duty (and find a way to dispose of the extreme packaging). The black market now accounts for only about 60% of the cannabis sales. Hard drug use like crack and fentanyl has become rampant as dealers lace their product to compete on a kick level (the legal stuff is relatively mild). There's currently a shakeout and consolidation in the legal cannabis industry going on due to overinvestment. The mom-and-pop storefronts that cropped up on seemingly every street corner during the pandemic are starting to disappear. Regulatory charges and overhead eat much of the profit. There is still trouble getting financing for the legal industry because of US legislation preventing banks that do business in that country from lending money to such businessess outside of the USA, legal or not. Black market dealers do not have any of these issues. reply adamgordonbell 18 hours agorootparentEvidence that the fentanyl problem is driven by pot legalization? Is there less opioid problems where they didn't legalize? Yeah, there are a million pot stores, and many closing but that's just a bubble for you. reply kjkjadksj 17 hours agoparentprevThere is still a black market in legal states in the US. The tax burden is high. reply kmlx 18 hours agoparentprev> If dealers are making lot of money from cannabis from i've read cannabis is not a money making product for \"dealers\". cannabis is used to introduce customers to other much more profitable drugs. reply diggan 18 hours agorootparentThe ever-popular \"gateway\" theory (https://en.wikipedia.org/wiki/Gateway_drug_effect) but applied to the dealers. As someone who used to deal some every now and then, I think I could count on one hand the amount of people I sold weed to, who would be OK with whatever drug, the rest were only purchasing cannabis and cannabis only. They didn't reach out to me to \"get high no matter what cost\" but specifically to \"get high by smoking cannabis\". If I didn't have cannabis, there was no interest in getting anything. reply bondarchuk 18 hours agoparentprevOr maybe they'll get an office job. reply rqtwteye 17 hours agoparentprevI think they will just learn to code. reply ulrischa 17 hours agoprevThis map shows where you actually can consume cannabis in Berlin, taking into account the distance rules to schools etc. https://bubatzkarte.de/#10/52.5242/13.3553 reply fabian2k 17 hours agoparentThere were some changes to that part, it is now defined as within 100 meters and in view of the specific protected location. reply eqvinox 17 hours agorootparent20/8704 says 200 meters. Did that get modified? I don't see anything more recent than that. Edit: ah, it's in 20/10426. \"in range of sight\", \"sight is ≤ 100m\". reply fabian2k 17 hours agorootparentI got that from https://dserver.bundestag.de/btd/20/104/2010427.pdf I'm not sure where to find the actual text of the law in the final version. reply slashdev 18 hours agoprevI don't use cannabis, but I wonder how much cannabis, alcohol, television, social media, etc sap energy and drive from people in general. At a societal level, is that partially responsible for the decrease in entrepreneurship? How could we tell? Less entrepreneurship means less innovation and less jobs and less tax revenue, it's bad for society overall. reply pixl97 18 hours agoparentLol, wtf. Humans do not exist as entities to serve businesses for the grand goal of entrepreneurship. I tend to believe people that think this way have their own work addictions that are just as harmful as addictions to substances. Furthermore your 'decrease in entrepreneurship' should be suffixed with 'where I am'. And when you put 'where I am' suddenly you'll run into a bunch of much more likely culprits such as 'administrative burden and bureaucracy', 'IP and copyright laws/legal complications', 'successful large businesses paying knowledge workers and keeping them out of the self market', 'tax burdens for self employed workers' Drugs is going to be so far down that list in most places that it's not a serious consideration. reply slashdev 18 hours agorootparentMaybe, maybe not. I don't know, neither do you. I'd like to see some studies. reply pixl97 17 hours agorootparentThen Google it, there is plenty of research, otherwise you're JAQing off users that are pre-biased against drugs. Not a single serious study I see in the list (and these are across multiple countries) has hedonism anywhere on list of the most pertinent problems. The Congressional Budget Office writes plenty about this and throws out statements like the following >Some economists are becoming concerned about diminished competition among firms—especially those firms involved in Internet-based commerce—and its harm to entrepreneurship, and about the impact of noncompete clauses Information technology has drastically changed the business landscape in such a way that it no longer looks or acts like the pre-internet world. Furthermore global marketplaces like Amazon allow entrepreneurs to exist outside of the countries doing the counting. reply slashdev 15 hours agorootparentMaybe, that's true. But this isn't an article about those problems, it's an article about legalizing drugs. I don't think it's true that it is harmless to society, and I don't think we fully understand what the ramifications will be. reply pixl97 14 hours agorootparentHarmless doesn't exist and you can never reach it. If you want harmless have AI lock you in a bubble and feed you pulp and happy thoughts in your own bubble universe. What you're looking for is the principle of least harm. Time and time again we've proven that banning drugs is not the least harmful option. It turns out that humans really love vice which causes even more harmful black markets. We have lots of articles and information about drugs and their effects on society, you were attempting to link it to entrepreneurship of which from what can be seen is a very tenuous link at best. reply stetrain 18 hours agoparentprevI don't partake in cannabis, or much alcohol (ie one social drink once a week). The reasons I haven't tried entrepreneurship are much more about financial risks. Rent is expensive. Homeownership is barely attainable anywhere near an economically active metro area even with a decent tech income. Healthcare is expensive and unpredictable. Insurance is expensive without an employer subsidy and insurance pool. I think a great argument for better social safety nets and decreased housing costs is a lower barrier to entrepreneurship. If the policy answer for every question on paying for living is \"Just get a good job with a good salary and benefits from MegaCorp\" that isn't really conducive to striking out on your own. reply pixl97 17 hours agorootparentAlso, in the West (most likely the US you're talking about), businesses can and do quickly respond if your business plan starts working and either swallow your customer base whole, or regulate you out of existence. A larger business with access to financial capital markets doesn't need to out compete you on merit. They can bundle your service for free until you collapse then raise prices later. Just look at how many 'killed by Google' projects seem to work like this. reply stetrain 17 hours agorootparentYes, the tendency of successful businesses in a market to acquire upstarts has an effect as well. The positive outcome for many startups that take investment money is to be acquired in such a move to pay back those investors. The negative outcome is that you get crushed without being acquired. reply rlili 18 hours agoparentprevWealth inequality, caused by worker exploitation (which drives cannabis/alcohol/television/etc up) is a lot worse for society. reply vincnetas 18 hours agoparentprevIs there a limit when there's enough taxes/revenue/jobs? I would like one, i would like to live life for life not for job. Job is a mean to live not a reason for it. Because if there is no limit jobs will always expand to fill the all the time a person has. reply shepherdjerred 17 hours agoparentprevYou're getting a lot of flak. You never said that everyone should always work, or that everyone should be an entrepreneur. My question is: what's the \"ideal\" amount of entrepreneurship? Why is it the amount you chose? It's very philosophical and there really isn't a right answer. More to the point: if it weren't cannabis, alcohol, television, social media then it would be something else. Most people don't _want_ their lives to be driven by work. They want a paycheck and to live their life. Some people develop proper addictions, but that's (in my uninformed opinion) due to the stress of their lives. It's a _lot_ of work to find a higher meaning in life, and many (most?) people instead choose to seek momentary pleasure/sedate themselves. Those who have an addiction or rely on substances aren't any \"better\" than those who abstain. Everyone is doing their best while trying to get by. reply bzzzt 18 hours agoparentprevI don't partake either, but you'd have to offset the loss in tax revenue to the gains for people with PTSD or chronic pain who get better quality of life and may be able to work more and need less healthcare services. Working at maximum stress levels all the time is also suboptimal. Moderation is the key. reply slashdev 18 hours agorootparentThere's nothing wrong with that. Just within limits. As you say, moderation is key. reply this15testing 18 hours agoparentprevnot everyone wants to work every waking moment of their life, and that's ok. reply slashdev 18 hours agorootparentI'm not saying everybody should be an entrepreneur, far from it, but a decrease in entrepreneurship at a societal level hurts everyone. You can see that too, right? reply dr_dshiv 17 hours agorootparentCalifornia has historically had some of the largest consumption of cannabis and the highest density of entrepreneurship. reply sigspec 18 hours agoparentprev\"I'm just asking questions here guys\" No new ideas. womp womp reply elevaet 16 hours agoparentprevAnecdata: I've noticed a huge range in the way people are affected by chronic weed smoking. It seems like most people tend to become more content with their current situation and happy to enjoy the moment. This seems make most people less motivated, maybe because they have less problem with how things are. But there are outliers: I've met a few folks over the years who are voracious weed smokers, and have an outrageously productive output. I'm not sure if it's because people are simply wired different, or if these latter camp just figured out how to use weed really well. reply dr_dshiv 17 hours agoparentprevHypothesis: Cannabis is a major part of the entrepreneurial drive/mood for many people. It isn’t just a drain. It’s a spark, too. reply timeon 17 hours agoparentprevYou forgot games and scrolling HN. reply foobarian 18 hours agoparentprevYou know what, let's ban it all! What could possibly go wrong. /s reply slashdev 18 hours agorootparentI'm not advocating for that, it was clearly a disaster. But I wonder if it's beneficial to discourage those things more through education, taxes, etc. reply lp4vn 18 hours agorootparentWhat about discouraging wealth inequality and the lack of social support for the population in general? This would be a horrifying interference of the state in the dynamic of society, right? But somehow for some people the state legislating about the behaviour of the average Joe to make sure he continues to be a well behaved cog is absolutely appropriate. reply r2_pilot 18 hours agorootparentprevMaybe instead of taxing it to reduce its use, we can try making life better all around so people aren't incentivized to use it? Making other things more fun/accessible would decrease the time/availability for that behavior. reply slashdev 18 hours agorootparentI don't think that's an either/or type of choice, do both reply rwmj 18 hours agorootparentprevWhy do you care what other people do with their private time? reply rvnx 18 hours agorootparentprevIn South Park, the real danger of cannabis is well explained: it may turn you into a couch potato, causing you to miss out on life instead of engaging in productive activities. And South Park is the most realistic depiction of the clown world we are living in. reply qwertyuiop_ 17 hours agoprevNow the Alexanderplatz is going to stink to high heavens. reply m3kw9 18 hours agoprevThe issue with cannabis as a social thing is that it tastes and smell bad, worse than cigs. reply vincnetas 18 hours agoparentYeah, but smoking indoors is forbidden in most of the Europe, so this is not an issue. reply decafninja 17 hours agorootparentIt's forbidden in the US too. However I've noticed the intensity of weed smell makes it noticeable even where tobacco smell would not be. I don't care what weed smokers do as long as it doesn't negatively affect me. However quite often their stench does. Yet another reason why I want to move to a supposedly eco-unfriendly single family home in the suburbs ASAP. Since weed became legalized, the stench in urban apartment buildings has been nauseating. reply m0llusk 17 hours agorootparentHad we as a society been pursuing coexistence instead of crushing people with laws then we might have made progress with this by now. Controlling odors is an engineering problem with several solutions that are not widely applied. It is also important to note that the spread and lingering of smoke smells in apartment buildings is just one symptom of a general problem of poor indoor air circulation and air quality. Addressing those issues effectively will help with quality of life and health and should be done regardless. reply wiseowise 17 hours agoparentprev> worse than cigs. No, by a mile no. reply kjkjadksj 17 hours agoparentprevSome people don’t mind the smell and not all ways of taking it even produce a smell or taste reply rileycantread 18 hours agoprevbluntsmökenzeit reply reneberlin 16 hours agoprevI personally prefer \"woman on weed\" much more than those on alcohol. But i think that wasn't the topic at all :) reply nicbou 16 hours agoparentIt indeed wasn't the topic at all reply weinzierl 18 hours agoprev [–] EDIT: After checking what has passed, everything I wrote seems to hold up. Source: https://www.bundesgesundheitsministerium.de/service/gesetze-... I've not looked into what exactly passed, but the proposal was joke. Even more so, it was joke regardless where you stand on this topic - and that's quite an achievement. The proposal was constructed in a way that it technically legalized, but in a way that I'm sure will be of no practical relevance. According to the proposal, to buy legally you had to be a member of a registered club, so no anonymity. The club could only sell what it produces (three plants per member) and could only have a restricted number of members. The club can sell at most 50 g per month, it needs an addiction prevention officer, it cannot be near a kindergarden, and so on. Very bureaucratic, so these clubs will be exactly as popular as intended. reply diggan 18 hours agoparent> According to the proposal, to use legally you had to be a member of s club, so no anonymity. The club could only sell what it produces and could only have a couple of members. This is basically how it works in Barcelona, Spain as well. I don't think it's legal/illegal nationwide, but we have invite-only social clubs where you can only become a member if you know existing members. I think (but I'm not sure) there is a maximum number of members per club too. And you don't \"buy\" weed there, but you contribute money to the organization, and you may withdraw this contribution in the future as weed. Seems to work out just fine here. reply brodo 18 hours agoparentprevThat’s wrong. You don’t have to be a member of a club to consume legally. Consumption has always been legal. Ownership was banned and is now legal for up to 50 grams. reply weinzierl 18 hours agorootparentTo consume you have to own, so consumption was not legal. Ownership is now legal for 25 grams if they are from your own plants or from the plants of another member of the club you are registered with. reply hef19898 18 hours agoparentprevIt is a first step so, isn't it? reply weinzierl 18 hours agorootparentMy opinion: The law is constructed such that the parties that promised it (and are now in the government) can keep face (especially in the light of the upcoming elections), but that it will not have any practical relevance. reply lm28469 18 hours agoparentprev [9 more] [flagged] verticalscaler 18 hours agorootparent [–] You're about to be downvoted and flagged by people who have never been to Berlin. Edit: Great googly moogly I must be clairvoyant. reply hef19898 18 hours agorootparent [–] No, the reason is the racism. reply lm28469 18 hours agorootparent [–] What's racist about it ? Feel free to check the official stats of any western countries, or are numbers racist too ? reply hef19898 18 hours agorootparent [–] The fable of linking illegal migrants to rape and drug trafficking when number show no such thing at scale. Also, how do you tell a illegal from a legal migrant? Did you go to your rapist drug den park and ask for papers? reply lm28469 18 hours agorootparent [–] > Also, how do you tell a illegal from a legal migrant? Believe it or not but when you gang rape people in the middle of a public park you usually get arrested and prosecuted, then your identity and status are given to the public. > The fable of linking illegal migrants to rape and drug trafficking when number show no such thing at scale. Again, every country releasing data about it proves the contrary, take france, every single crime category has an over representation of foreigners: https://www.insee.fr/fr/statistiques/5763585?sommaire=576363... https://www.insee.fr/fr/statistiques/5763559?sommaire=576363... And it's not even descendant of legal migrants &c. it's just people who don't have the nationality. In big cities it's even worse, in Paris public transports 65% of sexual assaults are committed by foreigners, 93% of thefts too. I'm all for discussing the various causes but if your ideology is so strong you can't accept official stats I think it's pointless, continue to live in your imagined world and we'll continue to avoid our local park at night because we're racist. Also for Berlin, 22% of foreigners, 50%+ of rapes committed by foreigners, https://rmx.news/crime/germany-nearly-300-gang-rapes-recorde... reply hef19898 17 hours agorootparent [–] Since when is Berlin in France? Also, not all foreigners are equal, if you get the drift. Also, you, like a lot of people, ignore the connection between crime, poverty, economic stability and ethnicity. And your conclusion is, well, racist. reply lm28469 17 hours agorootparent [–] > Since when is Berlin in France? it's just an example because I know where to get these sources. Feel free to discuss the content though ;) > Also, you, like a lot of people, ignore the connection between crime, poverty, economic stability and ethnicity. And your conclusion is, well, racist. The poorest regions in France and Germany are the lowest in crime, rural areas are by far poorer and aren't plagued by neither rapes nor drug dealing. Even with all the causes listed I can't get past the fact that people get gang raped and stabbed 500 meters from my flat, and it doesn't change the fact that people avoid the place and that it's the biggest local drug dealing spot. Keep moving the goal post, hopefully one day you'll face the facts, and once the facts are accepted we can discuss the causes all day long and attempt to find solutions, of course if the facts can't be discussed neutrally finding a solution is impossible reply hef19898 17 hours agorootparent [–] Since this this whole shit shownof a thread started with a claim about drugs and rapes in a Berlin park, this statement of yours, re: statics for France, is interesting: >> it's just an example because I know where to get these sources. Feel free to discuss the content though ;) I take it you are not based in Germany, and certainly not Berlin, then. The French problem with banlieues is an intersting one. One that can be discussed under a relevant submission. Nice so, of moving the goal post, litterally, from Berlin to France. Not that I expected anything else. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The German government proposed a law to legalize cannabis for private adult consumption, permitting possession of up to 25 grams and cultivation of up to three plants for personal use.",
      "The legislation aims to encourage responsible use, improve health protection, reduce illegal cannabis markets, and enhance youth protection through strict regulations on private cultivation and distribution.",
      "Cannabis consumption near schools and youth facilities will be banned within a 200-meter radius, with no advertising or sponsorships allowed, while medical cannabis will remain available only by prescription."
    ],
    "commentSummary": [
      "The discussion explores drug legalization, consumption, and criminal activities across European countries, focusing on cannabis legalization in Germany and comparing it to Belgium's strict laws.",
      "It delves into challenges like drug addiction, market regulations' impact, availability of drugs through illegal channels, and personal experiences with cannabis addiction.",
      "The debate also highlights how cannabis legalization might affect criminal activity, entrepreneurship, societal impact, wealth inequality, and variations in drug laws among nations."
    ],
    "points": 255,
    "commentCount": 213,
    "retryCount": 0,
    "time": 1708699717
  },
  {
    "id": 39481670,
    "title": "Gemini Pro 1.5: AI Game-Changer in Technology",
    "originLink": "https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic",
    "originBody": "Subscribe ≡ About Collections Contact Us Sponsor Us Login Chain of Thought I Spent a Week With Gemini Pro 1.5—It’s Fantastic When it comes to context windows, size matters by Dan Shipper February 23, 2024 53 2 Listen DALL-E/Every illustration. Sponsored By: Destiny Own game-changing companies Venture capital investing has long been limited to a select few—until now. With the Destiny Tech100 (DXYZ) , you'll be able to invest in top private companies like OpenAI and SpaceX from the convenience of your brokerage account. Claim your free share before it lists on the NYSE. Sponsored by Destiny. Claim your free share Want to sponsor Every? Click here. I got access to Gemini Pro 1.5 this week, a new private beta LLM from Google that is significantly better than previous models the company has released. (This is not the same as the publicly available version of Gemini that made headlines for refusing to create pictures of white people. That will be forgotten in a week; this will be relevant for months and years to come.) Gemini 1.5 Pro read an entire novel and told me in detail about a scene hidden in the middle of it. It read a whole codebase and suggested a place to insert a new feature—with sample code. It even read through all of my highlights on reading app Readwise and selected one for an essay I’m writing. Somehow, Google figured out how to build an AI model that can comfortably accept up to 1 million tokens with each prompt. For context, you could fit all of Eliezer Yudkowsky’s 1,967-page opus Harry Potter and the Methods of Rationality into every message you send to Gemini. (Why would you want to do this, you ask? For science, of course.) Gemini Pro 1.5 is a serious achievement for two reasons: 1) Gemini Pro 1.5’s context window is far bigger than the next closest models. While Gemini Pro 1.5 is comfortably consuming entire works of rationalist doomer fanfiction, GPT-4 Turbo can only accept 128,000 tokens. This is about enough to accept Peter Singer’s comparatively slim 354-page volume Animal Liberation, one of the founding texts of the effective altruism movement. Last week GPT-4’s context window seemed big; this week—after using Gemini Pro 1.5—it seems like an amount that would curl Derek Zoolander’s hair: 2) Gemini Pro 1.5 can use the whole context window. In my testing, Gemini Pro 1.5 handled huge prompts wonderfully. It’s a big leap forward from current models, whose performance degrades significantly as prompts get bigger. Even though their context windows are smaller, they don’t perform well as prompts approach their size limits. They tend to forget what you said at the beginning of the prompt or miss key information located in the middle. This doesn’t happen with Gemini. These context window improvements are so important because they make the model smarter and easier to work with out of the box. It might be possible to get the same performance from GPT-4, but you’d have to write a lot of extra code in order to do so. I’ll explain why in a moment, but for now you should know: Gemini means you don’t need any of that infrastructure. It just works. Let’s walk through an example, and then talk about the new use cases that Gemini Pro 1.5 enables. VC investing has traditionally been reserved to a privileged few. But now Destiny Tech100 (DXYZ) is changing that. You can own a piece of groundbreaking private companies such as OpenAI and SpaceX, all from the convenience of your brokerage account. Claim your free share before it hits the NYSE. Sponsored by Destiny. Claim your share Want to sponsor Every? Click here. Why size matters (when it comes to a context window) I’ve been reading Chaim Potok’s 1967 novel, The Chosen. It features a classic enemies-to-lovers storyline about two Brooklyn Jews who find friendship and personal growth in the midst of a horrible softball accident. (As a Jew, let me say that yes, “horrible softball accident” is the most Jewish inciting incident in a book since Moses parted the Red Sea.) In the book, Reuven Malter and his Orthodox yeshiva softball team are playing against a Hasidic team led by Danny Saunders, the son of the rebbe. In a pivotal early scene, Danny is at bat and full of rage. He hits a line drive toward Reuven, who catches the ball with his face. It smashes his glasses, spraying shards of glass into his eye and nearly blinding him. Despite his injury, Reuven catches the ball. The first thing his teammates care about is not his eye or the traumatic head injury he just suffered—it’s that he made the catch. If you’re a writer like me and you’re typing an anecdote like the one I just wrote, you might want to put into your article the quote from one of Reuven’s teammates right after he caught the ball to make it come alive. If you go to ChatGPT for help, it’s not going to do a good job initially: This is wrong. Because, as I said, Sydney Goldberg did not care about Reuven’s injury—he cared about the game! But all is not lost. If you give ChatGPT a plain text version of The Chosen and ask the same question, it’ll return a great answer: This is correct! (It also confirms for us that Sydney Goldberg has his priorities straight.) So what happened? ChatGPT behaved as if I’d given it an open-book test. We can improve ChatGPT’s responses by, when asking it a question, giving it a little notecard with some extra information that it might use to answer it. In this case we gave it an entire book to read through. But you’ll notice a problem: The entire book can’t fit into ChatGPT’s context window. So how does it work? In order to answer my question, there’s a lot of code in ChatGPT that performs retrieval: It divides The Chosen up into small chunks through which it searches to find ones that seem relevant to the query. The retrieval code passes the original question, “What’s the first thing that Sydney Goldberg says to Reuven after he gets hit in the eye by the baseball?” and the most relevant sections of text it can find in the book to GPT-4, which produces an answer. (For a more detailed explanation, read this piece.) Again, we have to pass GPT-4 chunks of text—not the whole book—because GPT-4 can only fit so much text into its context window. If you’re paying attention, you’ll see the problem: Because the context window is so small, the performance of our model for answering certain kinds of queries is bottle-necked by how good we are at searching for relevant pieces of information to give to the model. (I wrote about this phenomenon about a year ago in this piece.) If our search functionality doesn’t turn up relevant text chunks, well, GPT-4’s answer won’t be good. It doesn’t matter how smart GPT-4 is—it’s only as good as the chunks we turn up. Let’s say we’re picking up The Chosen after a few weeks. We’ve read the first two sections, and before we begin the third we want to get a summary of what’s already happened in the book. We upload it to ChatGPT and ask it to summarize: ChatGPT gives us a vague answer that’s correct, but it’s not very detailed because it can’t fit enough of the book into its context window to output a great one. Let’s see what happens when we don’t have to divide the book up into chunks. Instead, we use Gemini, which can read through the entire book at once: You’ll notice that Gemini’s answer is significantly more detailed and provides key plot points from the book that ChatGPT can’t give. (Technically, we could probably get a similar summary out of GPT-4 if we devised a clever system for chunking and summarizing it, but it would take a lot of work, and Gemini makes that work unnecessary.) Gemini’s use cases aren’t limited to reading novels of self-discovery through softball accidents. There are hundreds of others that it unlocks that were previously difficult to do with ChatGPT, or with a custom solution. For example, at Every, we’re incubating a software product that can help you organize your files with AI. I wrote the original code for the file organizer, and our lead engineer, Avishek, wrote a GPT-4 integration. He wanted to know where to hook the GPT-4 integration into the existing codebase. So we uploaded it to Gemini and asked: It found the right place in the code and wrote the code Avishek needed in order to complete the integration. This is something just short of magic, dramatically accelerating developer productivity, especially on larger projects. It doesn’t stop there, either. I’ve been writing for a long time about how transformer models might become copilots for the mind—and end our need to organize our notes forever. Gemini Pro 1.5 is a step in that direction. For example, recently I was writing a piece about an effect I’ve noticed that I’m calling “I can do it myself” syndrome, where people tend to not use ChatGPT and similar tools because they feel like they can get the same task done more quickly, at better quality, if they do it themselves. It’s like inexperienced managers who micromanage their reports to the point of doing most of the work themselves, guaranteeing it’s done the way they want it to, but sacrificing a lot of leverage in the process. I wanted an anecdote to open the essay with, so I asked Gemini to find one in my reading highlights. It came up with something perfect: I could not have found a better anecdote, and it’s not a generic one—it’s from my own reading history and taste. Except, I later learned that the anecdote is made up. The general thrust of the idea is true—Luce did run both the editorial and business sides of Time—so it is pointing me in the right direction. But after I reviewed my Readwise highlights I couldn't find the exact quote Gemini came up with. (I only figured this out after Gwen and other savvy Hacker News commenters pointed it out in a previous version of this article.) So, Gemini is not perfect. You do need to check its work. But if you're careful it's a powerful tool. Again, all of this comes back to the context window. This kind of performance is only possible because with Gemini we don’t need to search for or sort relevant pieces of information before we hand it to the model. We just feed it everything we have and let the model do the rest. It’s much easier to work with large context windows, and they can deliver far more consistent and powerful results without extra retrieval code. The question is: What’s next? The future of large context models About a year ago I wrote: “People have been saying that data is the new oil for a long time. But I do think, in this case, if you’ve spent a lot of time collecting and curating your own personal set of notes, articles, books, and highlights it’ll be the equivalent of having a topped-off oil drum in your bedroom during an OPEC crisis.” Gemini is the perfect example of why this is true. With its large context window, all of the personal data you’ve been collecting is at the tip of your fingers ready to be deployed at the right place and the right time, in whatever task you need it for. The more personal data you have—even if it’s disorganized—the better. There are a few important caveats to note, though: First, this is a private beta that I can use for free. These models often perform differently (read: worse) when they are released publicly, and we don’t know how Gemini will perform when it’s tasked with operating at Google scale. There’s also no telling how much pumping 1 million tokens is going to cost into Gemini when it’s live. Over time the cost of using it will likely significantly decrease, but it will take a while. Second, Gemini is pretty slow. Many requests took a minute or more to return, so it’s not a drop-in replacement for every LLM use case. It’s for the heavy lifting that you can’t get done with ChatGPT, which you probably don’t need to do on a regular basis. I would expect speed to increase significantly over time as well, but it’s still not there yet. OpenAI has some catching up to do, and I’ll be watching to see how they respond. But the other players on my mind—companies like Langchain, LlamaIndex (where I’m an investor), Pinecone, and Weaviate—are to some degree betting on retrieval being an important component of LLM usage. They either provide the library that does the chunking and searching for information to pass to the LLM, or the datastore that keeps the information searchable and safe. As I mentioned earlier, retrieval is less relevant when you have a large context window, because you can input all of your information into each request. You might think those companies are in trouble. Gemini’s huge context window does make some of what they’re building less important for basic queries. But I think retrieval will still be important long-term. If there’s one thing we know about humanity, it’s that our ambition scales with the tools we have available to satisfy it. If 1 million token context models become the norm, we’ll learn to fill them. Every chat prompt will include all of our emails, and all of our journal entries, and maybe a book or two for good measure. Retrieval will still be used to figure out which 1 million tokens are the most relevant, rather than what it’s used for now: to find which 1,000 tokens are the most relevant. It’s an exciting time. Expect more experiments from me in the weeks to come! Dan Shipper is the co-founder and CEO of Every, where he writes the Chain of Thought column and hosts the podcast How Do You Use ChatGPT? You can follow him on X at @danshipper and on LinkedIn, and Every on X at @every and on LinkedIn. Correction: An earlier version of this article did not note that the Henry Luce quote was hallucinated. It has been updated with that information. What did you think of this post? Amazing Good Meh Bad Like this? Become a subscriber. Subscribe → Or, learn more. Thanks to our sponsor: Destiny If you’re fond of unicorns, AI, and space—get a Destiny Tech100 share. You'll be able to own a piece of OpenAI, SpaceX, Discord, Stripe, and others. Claim your free share before the NYSE listing. Sponsored by Destiny. Claim your share Want to sponsor Every? Click here. Read this next: Chain of Thought How Sora Works (and What It Means) OpenAI's new text-to-video model heralds a new form of filmmaking 171 1 Feb 16, 2024 by Dan Shipper Chain of Thought AI-assisted Decision-making How to use ChatGPT to master the best of what other people have figured out 179 6 Oct 6, 2023 by Dan Shipper Chain of Thought How Hard Should I Push Myself? What the science of stress tells us about peak performance 158 2 Oct 17, 2023 by Dan Shipper Thanks for rating this post—join the conversation by commenting below. Comments Post Colleen Cole about 2 hours ago I just signed up for Gemini 1.5 yesterday and my first run at it was initially disappointing. I fed it a transcript of a podcast episode and asked it to sum up the frameworks discussed during the episode. Strangely it kept telling me it didn’t know the people on the podcast and couldn’t respond as them. I rejigged my prompt and basically got the same answer. The third time, I got a high school level answer. Finally, I fed it an AI answer from another tool, and at that point, it apologized and then listed the steps it would take to do a better job in the future. Methinks I need to sort out my prompts with it a bit. That said, I moved on asking it to use some of the frameworks I outlined to brainstorm about a launch, and at that point, it started to shine. I’m looking forward to see how it develops as a tool. ♡ 0 · Reply @doogiesjunkdrawer about 2 hours ago Great article... stimulating. The phrase “context is everything” comes to mind. While that’s an oversimplification, the more complete the context, usually the better the answer, decision or outcome. But that depends heavily on the quality and precision of the question. E.g. the hologram in “I Robot”. AI can’t fix a poor prompt. That relies on us. We need to know why and what value we are pursuing (and even its use) when we ask a question and seek its answer. To use AI/GPT effectively, we need to level up our ability to ask good questions. BTW- that’s applies to today, right now. In general, we need a renewed effort on improving critical thinking and reasoning skills focused around the why of our what's if we expect to get effective how's for the given Job-To-Be-Done (JTBD). Don't get me started about \"Prompt Engineering\"... so far that sounds like the job we should be doing right now. Crappy inputs, crappy outputs. Thanks again for the thought provoking article. ♡ 0 · Reply ✕ Every smart person you know is reading this newsletter Get one actionable essay a day on AI, tech, and personal development Subscribe Already a subscriber? Login Contact Us · Sponsor Us · Search · Terms ©2024 Every Media, Inc",
    "commentLink": "https://news.ycombinator.com/item?id=39481670",
    "commentBody": "I Spent a Week with Gemini Pro 1.5–It's Fantastic (every.to/chain-of-thought)248 points by dshipper 18 hours agohidepastfavorite217 comments Eliezer 5 hours agoThis is a slightly strange article to read if you happen to be Eliezer Yudkowsky. Just saying. reply aChattuio 51 minutes agoparentYou are Eliezer? You wrote the HP fan fiction? Cool, your ff was the first.one I ever read and loved the take on it :) reply p1esk 5 hours agoparentprevWhy? I see your book was mentioned in the article, but I don't see what's strange about it. reply HaZeust 2 hours agorootparentIt's kind of weird seeing your work pop up in a writing out of nowhere. It's happened for my research articles before and I've had to do a double-take before saying to myself, \"huh... That was nice of them.\" reply AdrianEGraphene 5 hours agoparentprevcool personal site. nice & to the point. Yea, I thought you would have gotten used to seeing elements of yourself on the web, but I guess there's levels to notoriety. reply xmonkee 5 hours agoparentprevwoah, haha reply criddell 18 hours agoprevI kind of love the idea of feeding the text of entire books to an AI. More often than I’d like to admit, I’ll be reading a novel and find myself not remembering who some character is. I’d love to be able to highlight a name in my ereader and it would see that I’m 85 pages into Neuromancer and give me an answer based on that (ie no spoilers). Or have a textbook that I can get some help and hints while working through problems and get stuck like you might get with a good study partner. reply mbil 18 hours agoparentKindle X-Ray kind of does this https://goodereader.com/blog/kindle/what-is-x-ray-for-the-am... reply ornornor 4 hours agorootparentYeah but then you have to contribute making Bezos even richer. reply bamboozled 3 hours agorootparentBezos getting richer? Get used to it. reply ornornor 2 hours agorootparentI don’t have to contribute to it, as much as I can help it. reply pyinstallwoes 1 hour agorootparentWhat do you use instead of Amazon? reply ornornor 1 hour agorootparentAnything else. I live in Switzerland and prefer to use galaxus, Migros, inter discount, mueller, foletti, or buy second hand. Absolutely anything I can to not buy from Amazon even if the alternative is 10–15% more expensive. reply TrueGeek 18 hours agoparentprevI'm the opposite. In movies (and real life to an extent) I have trouble telling people apart. I'd love a closed caption like service that just put name tags over everyone. reply ryandrake 18 hours agorootparentThat's one of the perpetually-SciFi use cases of Augmented Reality: You're walking around with AR glasses and whenever someone comes into your field of view, your display hovers over them their name, their job, when you last talked to them, what their hobbies are, and so on. A huge privacy nightmare, but useful for people who can't recall names and details about people they've met. reply egeozcan 17 hours agorootparentI don't think it'd be a privacy nightmare if it used private databases created by the user. Like a personal CRM, something like Monica, but with a real-time touch. reply avarun 17 hours agorootparentWouldn't be from a legal sense, but the societal implications of technology like that becoming commonplace are still immense. The limitations of human memory provide safety in a way today that would quickly erode if everybody could remember exactly everything that's ever been said or seen around them. reply Cyph0n 9 hours agorootparentFor an interesting exploration of this, I suggest watching the Black Mirror episode “The Entire History of You” (S1E3). reply nindalf 54 minutes agorootparentHonestly one of the best episodes of TV I’ve seen, simply because it challenged one of my core beliefs. I’ve always struggled with a poor memory and I’ve tried all kinds of systems to improve retention and recall. This episode challenged the benefits of remembering everything pretty well and made me reconsider. reply chambored 17 hours agorootparentprevSafety from what exactly? reply avarun 14 hours agorootparent\"You said X 3 years ago, but now you said, which is the opposite of X. How dare you?\" is one class of problems. Another is that you can learn quite a bit more about a person than they wished to actually divulge to you if you're able to capture and study their exact behaviors over a long enough stretch of time. reply twerkmonsta 11 hours agorootparentWait, why are people not allowed to change their mind on something? If anything this would make it more explicit and understandable when people did change their mind on something. reply ziddoap 10 hours agorootparent>Wait, why are people not allowed to change their mind on something I don't think parent comment is suggesting that people aren't allowed to change their mind. They are pointing out that many people yell \"hypocrite!\" when someone does change their mind. It's already a phenomenon on social media where people will dig through someone's post history and drag them through the coals, using previous stances on a topic in an attempt to discredit the current stance. Parent is suggesting that this problem would be exacerbated. reply int_19h 8 hours agorootparentI think that people will stop yelling \"hypocrite!\" once they themselves get repeatedly get called out on the same by others. Our reactions to stuff like that are defined largely by our cultural expectations, but those are in turn constantly shaped by what is made possible or impossible by technology. Back in the pre-voicemail phone era, for example, people would routinely call someone and expect them to be available for a half-hour chat - you could turn it down, sure, but in many cases it would be considered impolite to do so as a matter of social convention. Then voicemail appeared, and SMS was the final nail in that coffin. So I think that this problem will exist for a while, but if the tech that enables it persists long enough, it will eventually go on as conventions change to adapt to it. reply true_religion 7 hours agorootparentI disagree. People would instead become like modern politicians and never give an opinion. reply justahuman74 5 hours agorootparentPoliticians are trying really hard to show a particular public image, their job depends on it. In my job you could call me a hypocrite all day and it wouldn't matter (though I'd find the uncreative repetition annoying) reply int_19h 5 hours agorootparentprevThey won't have that option, because AI will happily infer their actual opinions from things they do say (and how they say them). reply groggo 17 hours agorootparentprevStill privacy nightmare and creepy. There's plenty of public info on people, that once collected and assembled into one place is basically stalking. Not saying it's not a cool idea though :) reply Aeolun 9 hours agorootparentThis is no different from my photo’s app automatically labelling faces right? I’m fairly certain the vision pro could do it right now. reply rasz 9 hours agorootparentprevInstall our virtual keyboard/virtual screen saver/dancing baby/flashlight app /small print: requires read all, send all permissions reply HKH2 17 hours agorootparentprevAnd instead of just shrugging it off, you could tag strangers that annoy you and end up with a giant list of grudges against a whole host of people. The false positives (e.g. twins and doppelgangers) should make it interesting. reply dylan604 17 hours agorootparentTake it to the next step towards Black Mirror where the AR shadows out people you've blocked and then mutes their voice so you can't hear them reply earthnail 17 hours agorootparentThat would make for fantastic comedic situations when you then physically bump into them after you erased them from your AR vision xD. reply EwanG 17 hours agorootparentprevWhich feeds into Saint Motel's song \"You're Nobody Til Somebody Wants You Dead\" which has a bit about how the list just grows and grows until it's everyone you've ever known... reply visarga 5 hours agorootparentprevBasically the Slack experience. You don't need to remember people, you can see your past interactions right there. reply pmarreck 17 hours agorootparentprevI had a product idea for an AR app that would do this for everyone who's opted into it. So for real-world networking events, you might choose to disclose some things about yourself but only for that venue and only for some window of time for example. I never built it, but it's perfectly possible to do. The genius idea IMHO was the business model- If you were into certain things you wanted to keep private from most but only wanted to disclose to other people who were into those same things, you could pay a fee, and it would then show you others who were in that \"market\" (of ideas, drugs, sex, whatever). (It might only ask you to pay it if it found someone nearby who matched. And then it would automatically notify the other person unless you paid an ADDITIONAL fee... Not sure about the latter idea, but it was an idea.) The only issue is everyone holding their phone up in front of their faces. reply HKH2 17 hours agorootparentHow would you stop spies or undercover cops trying to infiltrate the \"market\"? reply pmarreck 17 hours agorootparentOr people who want to \"out\" gay people. I know. That would be a good argument over not permitting a unilateral notification of a match (which, at the very least, I wanted to make very expensive and thus profitable, if it's allowed at all). If it notified both people 100% of the time, and one of you was a possible impostor, you could report them. And from a legal standpoint, showing interest in a market doesn't make you guilty. And, you could possibly also build \"cred\" in one of these tagged \"markets\" by getting cred from others who say you're legit, and that information would be revealed at the same time (possibly at your discretion). reply HKH2 8 hours agorootparentMakes sense. You still might get honeypots though; could you make cred work more generally with trust between friends, friends of friends etc. without compromising the markets? reply chowells 10 hours agorootparentprevSo your genius idea is to get people to pay to put themselves on a future blackmail list when your data is leaked/stolen/sold? I have to say, it is a kind of evil genius. reply piva00 16 hours agorootparentprev> The genius idea IMHO was the business model- If you were into certain things you wanted to keep private from most but only wanted to disclose to other people who were into those same things, you could pay a fee > The only issue is everyone holding their phone up in front of their faces. No, the genius idea is its major issue, just by paying you gain access to private data (people's preferences) without any kind of chain of trust to make sure that someone is actually part of the group (\"market\" in your terms) for which they want access to. By paying you could know that someone around you is looking for cocaine, or is willing to sell sexual services, or is looking to match other people from the same gender, or holds a certain political view against an authoritarian government, etc. reply pmarreck 12 hours agorootparentI answered this in a sibling comment. You could acquire credibility in a particular preference from the network over time. https://news.ycombinator.com/item?id=39482786 reply bluefirebrand 9 hours agorootparentSounds great, I'm going to make a \"credibility as a service\" startup and we'll find ways to farm whatever score in whatever fields you want. And you can be sure government agencies will do the same. reply BurningFrog 17 hours agorootparentprevI've seen scenes in movies where assistants of heads of state will discreetly whisper to them who the people in the room are. With a service like this we could all live like Kings! reply avarun 17 hours agorootparentThis features distinctively in the show Veep, where one of the main characters provides exactly this for the Vice President. reply dboreham 10 hours agorootparentprevThe sad truth is that technology isn't much used to help people. Instead it's used to make money. E.g. there's all this amazing AI, buy my phone keyboard autocorrect has the intelligence of a slug. reply crooked-v 9 hours agorootparent> my phone keyboard autocorrect has the intelligence of a slug iOS 17 already uses a local LLM under the hood for autocorrect and text suggestions. Responses to the change (at least for people who actually noticed it) have been pretty universally positive. reply eesmith 16 hours agorootparentprevhttps://en.wikipedia.org/wiki/Farley_file > A Farley file is a set of records kept by politicians on people whom they have met. > The term is named for James Farley, Franklin Roosevelt's campaign manager. Farley, who went on to become Postmaster General and chairman of the Democratic National Committee, kept a file on everyone he or Roosevelt met. > Whenever people were scheduled to meet again with Roosevelt, Farley would review their files. That allowed Roosevelt to meet them again while knowing their spouse, their children's names and ages, and anything else that had come out of earlier meetings or any other intelligence that Farley had added to the file. The effect was powerful and intimate. > Farley files are now commonly kept by other politicians and businesspeople. reply gniv 17 hours agorootparentprevAmazon already does some of this (they identify actors in a scene iirc), so they could \"easily\" extend it to what you're suggesting. reply esafak 11 hours agorootparentXray, they call it. It's a great feature! https://www.amazon.com/salp/xray reply mncharity 15 hours agorootparentprevMany years ago there was an MIT startup based on the idea, IIRC, that subliminally flashed names increased recall among cognitively impaired elderly when the flashed names were correct, but didn't negatively impact recall when the flashed names were incorrect. So even quite poor face recognition could be worthwhile. reply golergka 9 hours agorootparentprevWhen I first watched Departed, I didn't realise that Matt Damon and Leonardo DiCaprio's characters are different people until the third act. It was very confusing. reply neltnerb 1 hour agorootparentHah, I thought I was the only one. I'm not particularly face blind either... something about the era I guess. reply aidenn0 9 hours agoparentprevJapanese novels are particularly hard for me to keep characters straight due to sometimes very different forms of address depending on who (including the narrator) is mentioning the character. reply keiferski 17 hours agoparentprevFYI someone did do this for Neuromancer. Not sure if they used AI or not. https://docs.google.com/document/u/0/d/1ovTscY-bEuMNAEgNXTCX... reply ChildOfChaos 11 hours agoparentprevI'd love to feed it all the advice books on certain topics that I am struggling with and then chat with it like a group of advisors. reply world2vec 18 hours agoparentprevGreat idea, especially with huge books with hundreds of characters (looking at you \"Gravity's Rainbow\" and your ~400 characters with wacky names). reply jamie_ca 15 hours agoparentprevI can't recall which reader app I used, but I've seen this done before in ages past. No AI, so no big concept of inferred identities, but if someone's referenced by name you could long-tap the name, and get a list of all previous references in the text. Super useful for referencing secondary characters in super-long epics like The Wheel of Time. reply pests 14 hours agorootparentI'm really bad with names. I almost wish for unique color highlighting for every name. I would remember previous scenes or conversations way better than keeping track of tons of character names. reply skydhash 5 hours agorootparentprevSome printed books has that. It’s called the dramatis personae. Everyone not listed in it is not important. So not even tech is needed for that. reply Slow_Hand 9 hours agorootparentprevIt would be amusing if the AI inferred the identity of a mystery character before they were revealed. reply mschulkind 10 hours agorootparentprevSome kindle books have the X-ray feature that does exactly this. reply cryptonector 17 hours agoparentprevSoon we'll have AI writing books, then reading them for us so we don't have to. There is value to that, if we mostly only use this capability to digest books we otherwise wouldn't read but also if we don't stop reading books. Most likely we'll just stop reading books, and that strikes me as scary. reply crazygringo 18 hours agoparentprevThat's a truly fantastic idea actually. I'd love to see that built into e-readers. As well as when I pick back up reading after two weeks -- remind me everything that's happened so far? Where it gives a five-paragraph summary where the first paragraph is top-level covering the entire story so far, and the last paragraph is just about the previous few pages. Not to mention with non-fiction -- highlight an acronym that was defined somewhere 28 pages ago and tell me what the heck it is again?! reply glhaynes 18 hours agorootparentI love these ideas. One more: \"He said xyz but we know he's lying. What would motivate him to do that?\" reply wouldbecouldbe 17 hours agoparentprevFor most classic novels I expect GPT to already have in it's memory. reply 2OEH8eoCRo0 9 hours agoparentprev> I’d love to be able to highlight a name in my ereader I do this on my Kindle. Highlight the name, search, and the first occurrence is usually their introduction. No AI needed. reply rkangel 17 hours agoprevThis is exactly the sort of article that I want to read about this sort of topic.: * Written with concrete examples of their points * Provides balance and caveats * Declares their own interest (e.g. \"LlamaIndex (where I’m an investor)\") reply legel 7 hours agoparentAnd stylish and culturally engaging. Loved the Zoolander “context window for ants?!” reply kromem 11 hours agoprevI'm most excited at what this is going to look like not by abandoning RAG but by pairing it with these massive context windows. If you can parse an entire book to identify relevant chunks using RAG and can fit an entire book into a context window, that means you can fit relevant chunks from an entire reference library into the context window too. And that is very promising. reply zmmmmm 11 hours agoparentThe question I would like to know is whether that just leads you back to hallucinations. ie: is the avoidance of hallucinations intrinsically due to forcing the LLM to consider limited context, rather than directing it to specific / on topic context. Not sure how well this has been established for large context windows? reply kromem 5 hours agorootparentHaving details in context seems to reduce hallucinations, which makes sense if we'd switch to using the more accurate term of confabulations. LLM confabulations generally occur when they don't have the information to answer, so they make it up, similar to it you've seen split brain studies where one hemisphere is shown something that gets a reaction and the other hemisphere is explaining it with BS. So yes, RAG is always going to potentially have confabulations if it cuts off the relevant data. But large contexts themselves shouldn't cause it. reply visarga 5 hours agoparentprev> you can fit relevant chunks from an entire reference library into the context window too I'm curious if a large language model utilizes an extensive context that includes multiple works, whether copyrighted or not, to produce text that significantly differs from the source material, would this constitute infringement? Considering that the model is engaging in a novel process by relating numerous pieces of text, comparing and contrasting their information, and then generating the output of this analysis, could the output be considered usable as training data? I would set such a model to make a list of concepts, and then generate a wikipedia-like article on each one of them based on source materials obtained with a search engine. The model can tell if the topic is controversial or settled, what is the distribution of human responses, if they are consistent or contradictory, in general report on the controversy, and also report on the common elements that everyone agrees upon. It would be like writing a report or an analysis. Could help reduce hallucinations and bias, while side stepping copyright infringement because it adds a new purpose and layer of analysis on top of the source materials, and carefully avoids replicating original expression. reply crucialfelix 3 hours agoparentprevI would think for the common case of answering a question given a reference library, that RAG is going to remain cheaper and better. No way do we want to post the entire reference library for every conversation. Only if it's one off: read this book, answer questions. reply streetcat1 6 hours agoparentprevI am not sure, it depends on the cost. If they charge per token, a large context will mostly be irrelevant. For some reason, the article did not mention it. reply kromem 5 hours agorootparentThe article did mention costs, specifically it was provided to them for free and they don't know how much it will actually cost. As for your larger point, it really depends on the ROI. To summarize your Twitter feed, probably not. To identify correlating factors and trends across your industry's recent research papers, the $5 bill will probably be fine. reply josteink 2 hours agoparentprev> And that is very promising. Agreed. But I don’t think a lot of people will be willing to use an openly racist AI for business purposes. I want my AI to fact-based, not ideologically driven and presenting things which doesn’t exist as facts. reply cpill 7 hours agoparentprevyeah, imagine what this will do for lawyers reply wkat4242 17 hours agoprevWouldn't that cost a fortune? If I feed the maximum into gpt-4 it will already cost $1.28 per interaction! Or is Gemini that much cheaper too? reply alphabetting 17 hours agoparentI think Google has some big advantages in cost with TPUs and their crazy datacenter infra (stuff like optical circuit switches) but I'd guess long context is still going to be expensive initially. reply okdood64 4 hours agorootparentThey used ML to get a ~40% cooling efficiency on their datacenters. It's mentioned in a talk by Cassie Kozyrkov. reply wkat4242 15 hours agorootparentprevYeah I'm specifically interested in this because I'm in a lot of local telegram groups which I have no patience to catch up on every day. I'd love to have ChatGPT summarise it for me based on a list of topics I care about. Sadly the cost of GPT-4 (even turbo) tends to balloon for this usecase. And GPT-3.5-turbo while much cheaper and more than accurate enough, has a context window that's too shallow. I wonder if Telegram will add this kind of feature also for premium users (which I also subscribe to) but I imagine it won't work at the current pricing levels. But it would be nice not having to build it myself. reply esperent 7 hours agorootparentGPT3.5 and GPT4 are not the only options though, right? I don't follow that closely but there must be other models with longer context length that are roughly GPT3.5 quality by now, and they even probably use the same API. reply ajcp 6 hours agorootparentMistral 8x7b has can handle context of ~32,000 pretty comfortably and it benchmarks at or above GPT3.5 reply asadalt 5 hours agoparentprevI imagine it will cost peanuts within a year reply og_kalu 17 hours agoprevYeah. A few people on X have had access for a couple days now. The conclusion is that it's a genuine context window advance, not just length, but utilization. It genuinely utilizes long context much better than other models. Shame they didn't share what led to that. reply glandium 3 hours agoparentI've noticed that ChatGPT (4) tends to ignore large content in its context window until I tell it to look into it context window (literally). reply simpaticoder 6 hours agoprev>It read a whole codebase and suggested a place to insert a new feature—with sample code. I'm hopeful that this is going to be more like the invention of the drum machine (which did not eliminate drummers) and less like the invention of the car (which did eliminate carriages). reply sologoub 5 hours agoparentAn interesting comparison - there are far more cars today than carriages/horses at peak, and also far more drivers of various sorts than there were carriage drivers at peak. Another comparison could be excel with the various formulas vs hand tabulation or custom mainframe calculations. We didn’t get less employment, we got a lot more complex spreadsheets. At least this is my hope, fingers crossed. reply tgv 2 hours agoparentprevThere were and still are a lot of bands that have no drummer, though. You can think of that what you will, but \"did not eliminate drummers\" is just not a useful statement in this context. reply exodust 2 hours agoparentprevDrum machines are rarely used by drummers. A more fitting analogy would be technology drummers use to improve or broaden their drumming, without giving up their sticks, pedals and timing. The reasoning here is human coders still need to be present, thoroughly checking what AI generates. Regarding AI image generation. If an artist decides to stop making their own art, replacing their craft with AI prompts, they have effectively retired as an artist. No different to pre-AI times if they swapped their image making for a stock art library. AI image generation is just \"advanced stock art\" to any self-respecting artist or viewer of art. Things get blurry when the end result uses mixed sources, but even then, \"congrats, your artwork contains stock art imagery\". Not a great look for an artist. reply 4bpp 17 hours agoprevI imagine the folks over at NSA must be rubbing their hands over the possibilities this will open up for querying the data they have been diligently storing over the years. reply croes 17 hours agoparentThat's the point where hallucinations are pretty dangerous. reply pmarreck 17 hours agorootparentNot too hard to verify. reply dylan604 17 hours agorootparentVerify? There are plenty of examples where things have been \"verified\" to prove a point. WMDs ring a bell? reply pmarreck 12 hours agorootparentWhat is your point? That obtaining absolute knowledge of truth is impossible, and therefore anything claiming to be true is worthless? In general, be careful not to kill \"good\" on the way to attempting to obtain \"perfect\" in vain. And GPT4's hallucination rate is quite low at this point (may of course depend on the topic). reply dylan604 12 hours agorootparentNot at all. I'm coming from the opposite side saying that anything can be \"verified\" true if you just continue to repeat it as truth so that people accept it. Say often, say it loud. Facts be damned reply pmarreck 12 hours agorootparentYes but that's the argument by repetition (ad nauseam) fallacy reply dylan604 8 hours agorootparentfallacy or not, it works. reply phatfish 10 hours agorootparentprevThis has always happened and will continue always happening. Best not get caught up on it, just put people right when you feel you have the facts to back it up. reply dylan604 8 hours agorootparent10 years ago, I would have agreed with you. Today, facts are useless. Once someone has picked a side, there is no changing it for the majority of people. reply avarun 17 hours agoparentprevPalantir already provides this product to them. reply barnabees 8 hours agorootparentPalantir provides this by re-packaging and re-selling GPT-4, Claude, and Gemini reply hehhehaha 5 hours agorootparentprevPalantir sells a glorified Airflow instance reply speedgoose 3 hours agorootparentI heard it’s a big Cassandra too. But that’s only the backends and the frontend and their data engineers are important too. reply seanmcdirmid 17 hours agoparentprevThey could always try using tech to reduce their false positive rate rather than increase it. reply jeffbee 11 hours agoparentprevNSA does not have large-scale storage. If they did, it would be in a building somewhere, it would have electric power and they would have bought storage devices for it from some company. The largest-known actual NSA datacenter is the size of a runty leftover from having built a real cloud datacenter, and there's only one of those while FAMG have hundreds of far larger datacenters. reply CobrastanJorji 11 hours agorootparentPhew, glad the NSA doesn't have any large scale storage. Big relief. By the way, what do they use their $10 billion AWS contract for? reply jeffbee 11 hours agorootparentI know it's not storing every email, phone call, photo, and video ever transmitted on the internet, like certain people want you to believe. A $10b AWS contract would not even amount to enough storage to keep one copy of the public web. reply pavs 10 hours agorootparenthttps://en.wikipedia.org/wiki/Utah_Data_Center#%3A%7E%3Atext... Very confidently incorrect. reply jeffbee 5 hours agorootparentIf you think 100,000 square feet is a large data center, you obviously do not work in the industry. reply resolutebat 10 hours agorootparentprevI'm fairly sure the budget of archive.is is less than $10B. (Admittedly they don't store videos though.) reply taylorfinley 10 hours agorootparentprevhttps://en.wikipedia.org/wiki/Utah_Data_Center Genuine question, is Exabyte-scale small in the context of cloud? Is Amazon stacking yottabytes? Edit: 'Exabyte scale' was from a Forbes article in 2013 reply jeffbee 5 hours agorootparentIf you think this is a large datacenter, you are mistaken. You could fit this inside any cloud datacenter, and there are hundreds of those. The NSA thing draws 65MW. Google alone has over 7000MW of first-party energy generation resources, that doesn't begin to account for what they draw from the grid, and they're not even the biggest datacenter owner. reply elorant 10 hours agorootparentprevA building somewhere. Like inside a military base for example. Good luck finding out what’s inside it and having anyone who worked on a restricted contract telling you about it. reply unethical_ban 10 hours agorootparentprevGiven the history of NSA, warrantless surveillance and the overt existence of the Utah data center + collaboration with telcos and big tech, and the promise of AI analysis and quantum computing... I find it difficult to accept your underlying premise that NSA doesn't have access to a massive amount of data which AI may be able to analyze for them. reply tr3ntg 17 hours agoprev> These models often perform differently (read: worse) when they are released publicly, and we don’t know how Gemini will perform when it’s tasked with operating at Google scale. I seriously hope Google learns from ChatGPT's ever-degrading reputation and finds a way to prioritize keeping the model operating at peak performance. Whether it's limiting access, raising the price, or both, I really want to have this high quality of an experience with the model when it's released publicly. reply glandium 3 hours agoparentI wonder how true the degradation is, actually. One thing that I've noticed is that randomly, ChatGPT might behave differently than usual, but get back to its usual behavior on a \"regenerate\". If this is bound to happen, and happens to enough people, and combining with our cognitive biases regarding negative experiences, the degradation could just as well be a perception problem combined to social networks spreading the word and piling up on the biases. reply emporas 16 hours agoprev>\" While Gemini Pro 1.5 is comfortably consuming entire works of rationalist doomer fanfiction, GPT-4 Turbo can only accept 128,000 tokens.\" A.I. Doomers will soon witness their arguments fed into the machine, generating counter-arguments automatically for 1000 books at a time. They will need to incorporate a more and more powerful A.I. into their workflow to catch up. reply ganzuul 2 hours agoparentA Wikipedia edited solely by AI replacing time war with edit war. reply dynamite-ready 3 hours agoprevBeing able to feasibly feed it a whole project codebase in one 'prompt' could now make these new generation of code completion tools worthwhile. I've found them to be of limited value so far, because they're never aware of the context of proposed changes. With Gemini though, the idea of feeding in the current file, class, package, project, and perhaps even dependencies into a query, can potentially lead to some enlightening outputs. reply platelminto 18 hours agoprevGPT-4 Turbo has a context window of 128k tokens, not 32k as the article says. reply Workaccount2 17 hours agoparentI believe with the API you can get 128k, but using the app or web client it is 32k. This might have changed though. reply dshipper 18 hours agoparentprevFixed!! Thanks for finding that reply inciampati 5 hours agorootparentThe sibling comment explained. The web client is 16k or 32k, but you can pay their API $1.28 per interaction and use a full context on GPT-4-turbo. reply aantix 17 hours agoprevDoes the model feel performant because it’s not under any serious production load? reply EwanG 17 hours agoparentArticle seems to suggest just that as the author states that he's doubtful the model will perform as well when it's scaled to general Google usage reply gnarlouse 5 hours agoprevIs anybody else getting seriously depressed at the rate of advancement of AI? Why do we believe for a second that we’re actually going to be on the receiving end of any of this innovation? reply viraptor 1 hour agoparentThere's enough advancement in the low end area that I'm not worried about that particular side. I mean, you can deploy mixtral on a single, common laptop (yes, an expensive one, but still). On the other side - who's actually going to be using that AI? It's not like some rich person can say \"make me an app that does ...\" - that will still involve lots of manual work for a very long time. reply coffeecat 3 hours agoparentprevI think the impact of AI will be too pervasive and complex to be understood in terms of a simple winners/losers dichotomy. My prediction is this: Software developers and lawyers will probably have significantly lower incomes, and so to some extent, we'll lose status relative to everyone else. But software and legal work will become cheap as hell. This ought to reduce prices generally on just about everything. Even housing prices should go down, as the median worker will be making less money. Governments will probably try to counteract the ensuing deflation with massive stimulus programs. Optimistically, this could culminate in new UBI programs. A happy outcome is not by any means guaranteed, but seems likely in the long term. reply p1esk 4 hours agoparentprevI spoke to someone recently who believes poor people will be gradually killed off as the elites who control the robots won't have any use for them (the people). I don't share such an extreme view (yet), but I can't quite rule it out either. reply SV_BubbleTime 4 hours agorootparentI’ve found many of the same people that talk/think like that are anti-gun and I have trouble rationalizing it. So, IDK, maybe there will be killer robot dogs, but I’m not going down without a fight. reply ornornor 4 hours agorootparentYou don’t need guns to kill a class of people. Just low/no opportunities, drastically reduced income, etc will make the problem take care of itself: the class you’re targeting this way will slowly stop having/keeping children, live shorter lives, and fade away. Not saying this is what’s happening though, I don’t think it was ever great to be poor or have low opportunities, or that it’s more lethal now than it ever was. reply riku_iki 3 hours agorootparent> or that it’s more lethal now than it ever was. it can get much more lethal now compared to the past 50 years in US. reply SV_BubbleTime 4 hours agoparentprevIf you mean skynet, not worried. If you mean beyond anyone’s imagination a way to push narrative propaganda ideology advertising sales BS… yea. I’m far less worried about my kids being bullied than I am being manipulated to a degree we just can’t imagine - and it’s bad now without AI. reply bamboozled 3 hours agoparentprevWhy has any pleb been on the end of any innovation ? Isn’t the entire point of Gemini bringing AI to the plebs ? reply croes 17 hours agoprevI'm a bit worried about the resource consumption of all these AIs. Could it be that the mass of AIs that are now being created are driving climate change and in return we are mainly getting more text summaries and cat pictures? reply shmageggy 17 hours agoparentIt's a valid concern, and there is research into this. https://news.climate.columbia.edu/2023/06/09/ais-growing-car... is one article, but lots more to be found via Google. Currently AI training is very small relative to agriculture and industry, but of course it's trending upwards. reply danpalmer 17 hours agoparentprevData center infrastructure is a relatively small component of global emissions. I believe \"compute\" is something likeI wanted an anecdote to open the essay with, so I asked Gemini to find one in my reading highlights. It came up with something perfect: Can someone verify that anecdote is true? Here is what the image contains: > From The Publisher: In the early days of Time magazine, co-founder Henry Luce was responsible for both the editorial and business sides of the operation. He was a brilliant editor, but he had little experience or interest in business. As a result, he often found himself overwhelmed with work. One day, his colleague Briton Hadden said to him, \"Harry, you're trying to do everything yourself. You need to delegate more.\" Luce replied, \"But I can do it all myself, and I can do it better than anyone else.\" Hadden shook his head and said, \"That's not the point. The point is to build an organization that can do things without you. You're not going to be able to run this magazine forever.\" That citation appears to be \"The Publisher : Henry Luce and his American century\". The book is available at archive.org as searchable text returning snippets, at https://archive.org/details/publisherhenrylu0000brin_o9p4/ Search is unable to find the word \"delegate\" in the book. The six matches for \"forever\" are not relevant. The matches for \"overwhelmed\" are not relevant. A search for Hadden finds no anecdote like the above. The closest are on page 104, https://archive.org/details/publisherhenrylu0000brin_o9p4/pa... : \"\"\"For Harry the last weeks of 1922 were doubly stressful. Not only was he working with Hadden to shape the content of the magazine, he was also working more or less alone to ensure that Time would be able to function as a business. This was an area of the enterprise in which Hadden took almost no interest and for which he had little talent. Luce, however, proved to be a very good businessman, somewhat to his dismay—since, like Brit, his original interest in “the paper” had been primarily editorial. (“Now the Bratch is really the editor of TIME,” he wrote, “and I, alas, alas, alas, am business manager. . .. Of course no one but Brit and I know this!”) He negotiated contracts with paper suppliers and printers. He contracted out the advertising. He supervised the budget. He set salaries and terms for employees. He supervised the setting up of the office. And whenever he could, he sat with Brit and marked up copy or discussed plans for the next issue.\"\"\" That sounds like delegation to me and decent at business and not doing much work as an editor. There's also the anecdote on page 141 at https://archive.org/details/publisherhenrylu0000brin_o9p4/pa... : \"\"\"In the meantime Luce threw himself into the editing of Time. He was a more efficient and organized editor than Hadden. He created a schedule for writers and editors, held regular meetings, had an organized staff critique of each issue every week. (“Don’t hesitate to flay a fellow-worker’s work. Occasionally submit an idea,” he wrote.) He was also calmer and less erratic. Despite the intense loyalty Hadden inspired among members of his staff, some editors and writers apparently preferred Luce to his explosive partner; others missed the energy and inspiration that Hadden had brought to the newsroom. In any case the magazine itself—whose staff was so firmly molded by Hadden’s style and tastes—was not noticeably different under Luce’s editorship than it had been under Hadden’s. And just as Hadden, the publisher, moonlighted as an editor, so Luce, now the editor, found himself moonlighting as publisher, both because he was so invested in the business operations of the company that he could not easily give them up, and also because he felt it necessary to compensate for Hadden’s inattention.”\"\"\" Again, it doesn't seem to match the summary from Gemini. Does someone here have better luck than I on verifying the accuracy of the anecdote? Because so far it does not seem valid. reply gwern 10 hours agoparentI wasn't able to find that quote myself, and I was suspicious because I've skimmed _The Publisher_ in the past (trying to verify a quote about why _Time_ magazine picked red) and the Gemini anecdote doesn't sound like the author or Luce/Hadden. So I pinged the author on Twitter with your comment. He confirms that the anecdote was confabulated by Gemini, was based on the pg141 story, and he's edited OP to note the error: https://twitter.com/danshipper/status/1761135157036097608 reply int_19h 7 hours agorootparentAmazingly, without changing either the title or the overall positive tone of the article. reply eesmith 4 hours agorootparentprevThe updated \"Except\" says: > The general thrust of the idea is true—Luce did run both the editorial and business sides of Time—so it is pointing me in the right direction. My skim of the book suggests that's being too generous. Where is the \"I can do this myself syndrome\"? The p 141 anecdote suggests it equally applies to both Hadden and Luce (\"Hadden, the publisher, moonlighted as an editor, so Luce, now the editor, found himself moonlighting as publisher\"), and that Luce had business experience by this time (he had been doing it for years, and was good at it; p104), and that contra Gemini, Hadden did not provide that advice, nor would Luce have thought it valid (\"because he felt it necessary to compensate for Hadden’s inattention\"). The author continues: > So, Gemini is not perfect. You do need to check its work. But if you're careful it's a powerful tool. I feel like that's a deliberate misdirection. Of course it's not perfect. That's never been the question. The questions are, how much do you need to check it is work, and how careful do you need to be? I noticed https://every.to/about does not list a fact checker. reply eesmith 16 hours agoparentprevTo follow up to myself - the author asked: > What's the first thing that Sydney Goldberg says to Reuven after he gets hit in the eye by the baseball? and ChatGPT responds: > The first thing Sydney Goldberg says to Reuven after he gets hit in the eye by the baseball is, \"That was a great catch, Reuven! That was sensational!\". Curious thing is, the name is spelled Sidney Goldberg. https://archive.org/details/chosen0000chai_y4e8/page/32/mode... reply jeffbee 11 hours agorootparentThese chatbots just adopt your typos. If I ask Gemini about the architecture of blaze instead of bazel it will write paragraphs using blaze consistently even though it doesn't exist. reply eesmith 2 hours agorootparentWhich makes them error amplifiers. reply stavros 11 hours agorootparentprevBlaze is the name of the Google tool that Bazel was based on. reply jeffbee 11 hours agorootparentI realize that, I was trying to trick it into sending me internal documentation. Instead what it does is describe all the places I can find information about blaze, such as at https://blaze.build ... it just runs with whatever you told it. reply stavros 11 hours agorootparentYou're definitely right that they adopt your typos, and that it adopted your typo in that case, I'm just pointing out that a tool called Blaze does exist. reply Aeolun 9 hours agoprevI think it’s a bit disturbing that the author gets an answer that is entirely made up from the model, even goes so far as to publish it in an article, but still says it’s all so great. reply cageface 3 hours agoparentIt's telling that even an obviously sophisticated and careful user of these tools published the output of the model as fact without checking it and even used it as one of the central pillars of his argument. I find this happening all the time now. People that should know better use LLM output without validating it. I fear for the whole concept of factuality in this brave new world. reply renewiltord 9 hours agoparentprevThat's \"disturbing\"? I've used imperfect tools before and still thought they were great. It's mildly interesting someone's mental state would be so affected by that. reply Aeolun 4 hours agorootparentIt’s a compounding thing. Ever since the rise of these LLM’s I’ve seen people argue against human experts by saying “the LLM says this”. It’s like they’ve completely outsourced their thinking to the LLM. reply jeffbee 11 hours agoprevHow do people get comfortable assuming that these chat bots have not hallucinated? I do not have access to the most advanced Gemini model but using the one I do have access to I fed it a 110-page PDF of a campaign finance report and asked it to identify the 5 largest donors to the candidate committee ... basically a task I probably could have done with a normal machine vision/OCR approach but I wanted to have a little fun. Gemini produced a nice little table with names on the left and aggregate sums on the right, where it had simply invented all of the cells. None of the names were anywhere in the PDF, all the numbers were made up. So what signals do people look for indicating that any level of success has been achieved? How does anyone take a large result at face value if they can't individually verify every aspect of it? reply xyzzy_plugh 7 hours agoparentI'm not sure why you are being down voted but this is the same problem I immediately encounter as soon as I try to do anything serious. In the time it takes to devise, usually through trial and error, a prompt that elicits the response I need, I could've just done the work myself in nearly every scenario I've come across. Sometimes there are quick wins, sure, but it's mostly quick wrongs. reply bamboozled 3 hours agoparentprevBecause it’s easy and people love easy. The other night I was coding with ChatGPT, and it was hallucinating methods etc, and I was so happy that it had actually written the code , even though I knew it was wrong and potentially even dangerous, it looked good. I actually told myself I'd never be someone to do this. Now it wasn't ultra critical stuff I was working on, but it would've caused a mess if it didn't work out. I ran it against a production system because I was lazy and tired and wanted to just get the job done. In the end I ended up spending way more time fixing its ultra wrong yet convincing looking code I didn’t get to bed till 1am. This will become more commonplace. reply karmasimida 11 hours agoprevI think the retrieval is still going to be important. What is not important is RAG. You can retrieval a lot of documents in full length, not need to do all these chunking/splitting, etc. reply kromem 11 hours agoparentDepth isn't always the right approach though. Personally, I'm much more excited at the idea of pairing RAG with a 1M token context window to have enormous effective breadth in a prompt. For example, you could have RAG grab the relevant parts of every single academic paper related to a given line of inquiry and provide it into the context to effectively perform a live meta-analyses with accurate citation capabilities. reply whakim 8 hours agorootparentI really don’t think the issue with RAG is the size of the context window. In your example, the issue is selecting which papers to use, because most RAG implementations rely on naive semantic search. If the answer isn’t to be found in text that is similar to the user’s query (or the paper containing that text) then you’re out of luck. There’s also the complete lack of contextual information - you can pass 100 papers to an LLM, but the LLM has no concept of the relationship between those papers, how they interact with each other and the literature more broadly (beyond what’s stated in the text), etc. etc. reply jiggawatts 3 hours agoprevThese huge context sizes will need new API designs. What I’d like to see is a “dockerfile” style setup where I can layer things on top of a large base context without having to resubmit (and recompute!) anything. E.g.: have a cached state with a bunch of requirements documents, then a layer with the stable files in the codebase, then a layer with the current file, and then finally a layer asking specific questions. I can imagine something like this being the future, otherwise we’ll have to build a Dyson sphere to power the AIs… reply next_xibalba 17 hours agoprevIt is hard to imagine Gemini Pro being useful given the truly bizarre biases and neutering introduced by the Google team in the free version of Gemini. reply feoren 17 hours agoparentIt's hard to imagine that the pro version removes the line \"oh, and make sure any humans are ethnically diverse\" from its system prompt? reply losvedir 17 hours agorootparentConfusingly, Pro is the free version. Ultra is the paid one. What some people have access to here is the next-ish generation of Pro, 1.5, which sports a huge context window. I haven't heard anything about an Ultra 1.5 yet. (As a paying user of Ultra, I'm kind of bummed about not having access to this improved Pro...) reply feoren 16 hours agorootparentThanks for the clarification -- that is quite confusing. reply next_xibalba 17 hours agorootparentprevI don't understand your question (if it is made in good faith). Are you implying that a pro version would allow the user to modify the system prompt? Also, your assumption is that the data used to train the model is not similarly biased, i.e. it is merely a system prompt that is introducing biases so crazy that Google took the feature offline. It seems likely that the corpus has had wrongthink expunged prior to training. reply feoren 16 hours agorootparentYes, I'm assuming the forced diversity in its generated images is due to a system prompt; no, I don't believe they threw out all the pictures of white people before training. If they threw away all the pictures of German WWII soldiers that were white, then Gemini wouldn't know what German WWII soldiers looked like at all. No, it's clearly a poorly thought out system prompt. \"Generate a picture of some German soldiers in 1943 (but make sure they're ethnically diverse!)\" They took it offline not because it takes a long time to change the prompt, but because it takes a long time to verify that their new prompt isn't similarly problematic. > It seems likely that the corpus has had wrongthink expunged prior to training. It seems likely to you because you erroneously believe that \"wokeism\" is some sort of intentional strategy and not just people trying to be decent. And because you haven't thought about how much effort it would take to do that and how little training data there would be left (in some areas, anyway). > Are you implying that a pro version would allow the user to modify the system prompt? I am saying it is not hard to imagine, as you claimed, that the pro version would have a different prompt than the free version*. Because I know that wokeism is not some corrupt mind virus where we're all conspiring to de-white your life; it's just people trying to be decent and sometimes over-correcting one way or the other. * Apparently these are the same version, but it's still not a death knell for the entire model that one version of it included a poorly thought-out system prompt. reply next_xibalba 16 hours agorootparent> you erroneously believe that \"wokeism This is an ironic statement. On the one hand, you are able to read my mind and determine the worldview and intent behind my words. One the other, you suggest I'm doing the same to people who subscribe to \"wokeism\". Meanwhile, Jack Krawczyk, a Sr. Director of Product on Gemini, has been publicly declaring on X (over years) things like \"...This is America, where the #1 value our populace seeks to uphold is racism\" and \"...We obviously have egregious racism in this country..\" and \"I’ve been crying in intermittent bursts for the past 24 hours since casting my ballot. Filling in that Biden/Harris line felt cathartic.\" Do you think he is an exemplar of \"wokeism\" (however you want to define that term)? Do you think he is influential within the Gemini org? Do you think he is emblematic of the worldview of Google employees? Do you think his words are those of the type of person who is \"just trying to be decent\" but has made honest mistakes in his work? > I am saying it is not hard to imagine, This is really pretty pedantic, don't you think? I'd bet most people who read those words understood what I meant. Which is that it is unlikely (though, yes, not hard to imagine) that Gemini will allow users to alter the system prompt. The bottom line is, Google appears to have either 1) introduced extreme bias into Gemini in some way or 2) to be pretty incompetent. Neither inspires confidence. reply huytersd 8 hours agoparentprevI like the neutering. Its bias is forcefully inclusive which I appreciate. reply hackerlight 5 hours agoprev> Second, Gemini is pretty slow. Many requests took a minute or more to return, so it’s not a drop-in replacement for every LLM use case. reply lukasb 10 hours agoprevIs anyone else disappointed with Gemini Ultra for coding? It just makes basic mistakes too often. reply neolefty 18 hours agoprevHow does it scale to such a large context window — is it publicly known, or is there some high-quality speculation out there that you recommend? reply alphabetting 18 hours agoparentNot publicly known. I think speculation is use of mamba technique but I haven't been following closely reply inciampati 5 hours agorootparentUnlikely as this would likely require user instruction to write prompts differently. Without attention, guidance should proceed data to be processed. People will notice this change. Besides, mamba's context is \"infinite\", which they would definitely talk about in marketing ;) reply mbil 18 hours agoparentprevI don't know, but there was a paper posted here yesterday: LongRoPE: Extending LLM Context Window Beyond 2M Tokens[0] [0]: https://news.ycombinator.com/item?id=39465357 reply rfoo 13 hours agoparentprevMy bet is it's just brute force. I don't understand how they did 10M though, this isn't in the brute-force-with-nice-optimizations-on-systems-side-may-do-it ballpark, but they aren't going to release this to the public anyways so who knows, maybe they don't and it actually takes a day to finish a 10M prompt. reply QuadmasterXLII 10 hours agorootparent10 million means a forward pass is 100 trillion vector vector products. A single A6000 can do 38 trillion float-float products a second. I think their vectors are ~4000 elements long? So the question is, would the google you know devote 12,000 gpus for one second to help a blogger find a line about jewish softball, in the hopes that it would boost PR? My guess is yes tbh reply rfoo 4 hours agorootparentidk For longer context to brute force it the problem is more on the memory side instead of the compute. Both bandwidth and capacity. We have more than enough compute for N^2 actually. The initial processing is dense, but is still largely bound by memory bw. Output is entirely bound by memory bw since you can't make your cores go brrr with only GEMV. And then you need capacity to keep KV \"cache\" [0] for the session. A single TPU v5e pod has only 4TB HBM, assuming pipeline parallel across multiple TPU pods isn't going to fly, I haven't run the numbers but I suspect you get batch=1/batch=2 inference at best. Which is prohibitively expensive. But again who knows, groq demonstrated a token-wise more expensive inference tech and got people wowed by pure speed. Maybe Google's similar move is long context. They have an additional advantage as they can have exclusive access to TPU so that before H200 ships they may be the only one who can serve a 1M token LLM to the public without breaking a bank. [0] \"Cache\" is a really poor name. It you don't do this you get O(n^3) which is not going to work at all. IMO it's wrong to name your intermediate state \"cache\" if removing it changes asymptotic complexity. reply cal85 17 hours agoparentprevNot sure about high quality, but they discussed this question a bit on the recent All-In Podcast. reply coldtea 18 hours agoprev>That will be forgotten in a week; this will be relevant for months and years to come. Or, you know, until next month or so, when OpenAI bumps their offer reply pickledish 17 hours agoprev> This is about enough to accept Peter Singer’s comparatively slim 354-page volume Animal Liberation, one of the founding texts of the effective altruism movement. What? I might be confused, is this a joke I don't get, or is there some connection between this book and EA that I haven't heard of? reply avarun 17 hours agoparentPeter Singer is well known as a \"founder\" of EA, and vegetarianism is a tenet that many EAs hold, whether or not you directly consider it part of EA. Animal welfare is, at the very least, one of the core causes. That specific book may have been written before effective altruism really existed, but it makes sense for one of Singer's books to be considered a founding text. reply pickledish 17 hours agorootparentAhhh ok, had no idea, I'm pretty new to this stuff. Thank you for the explanation! reply Solvency 17 hours agoprevHow can Google so thoroughly embarrass themselves on the image front and then do well on text? reply wredue 16 hours agoparentnext [4 more] [flagged] artninja1988 4 hours agorootparentWeird strawman about what actually happened. If you prompted \"ginger women\" or even the names of two Google confounders you got a completely different race for no reason. Embarrassing reply Solvency 14 hours agorootparentprev...what? reply wredue 6 hours agorootparentShhh shhh shh. It’s okay. People with skin colours other than white exist, and that’s okay. I humbly await your countless posts being a baby about how Jesus is always portrayed as a chiseled white dude now that you’re aware that if he existed at all, he had brown skin. reply hersko 17 hours agoparentprevThey are not doing well on text.... https://deepnewz.com/politics/google-s-woke-gemini-ai-slamme... reply hersko 17 hours agoprev> This is not the same as the publicly available version of Gemini that made headlines for refusing to create pictures of white people. That will be forgotten in a week; this will be relevant for months and years to come. I cannot disagree with this more strongly. The image issue is just indicative of the much larger issue where Google's far left DEI policies are infusing their products. This is blatantly obvious with the ridiculous image issues, but the problem is that their search is probably similarly compromised and is much less obvious with far more dire consequences. reply tr3ntg 17 hours agoparentDo you remember Tay? You don't have to have \"far left DEI policies\" to want to defend against worst case scenario as strongly as possible. Even if, in the case of this image weirdness, it works against you. Google has so much to lose in terms of public perception if they allow their models to do anything offensive. Now, if your point was that \"the same decisions that caused the image fiasco will find its way into Gemini 1.5 upon public release, softening its potential impact,\" then I would agree. reply egillie 11 hours agoparentprevWait do people not remember this? https://twitter.com/rzhang88/status/1549472829304741888?t=R4... reply mrcartmeneses 17 hours agoparentprevMountains != molehills reply dylan604 17 hours agorootparentno, but we're making transformers, right? it's easy to transform a molehill into a mountain reply doug_durham 17 hours agoparentprevThis has nothing to do with the rightwing scary boogieman \"DEI\". This is more about preventing Google's stock from getting hammered when White Supremacists use the tool to create excellent propaganda. No company can withstand that. The current world of context-free social media posting based journalism is causing this. Google's approach was heavy handed and poorly thought out. I don't know what their solution will be. reply zarathustreal 11 hours agorootparent“White Supremacists” creating “excellent propaganda”? “rightwing scary boogieman “DEI””? My friend, I strongly suggest you take a moment to do some self-reflection reply Fischgericht 9 hours agoparentprevCould we please stop using the derogatory term \"far left\" instead of saying \"facts\"? Look, the US right wing is just full of lunatic conspiracy theories. A third of Republicans believe that Tailor Swift is a psyop. They believe in stolen elections, drinking bleach against Covid, etc etc. What in the US is described as \"right-wing\" or \"center right\" is simply: Believing in made up batshit crazy bullshit. The reason your LLM is not outputting \"right-wing\" \"opinions\" is because those all are factually wrong. They are not \"opinions\", they are factually wrong. And I am very happy that LLMs are not trained on made up bullshit, but on actual facts. So: Please stop calling facts \"left-wing\". Facts are facts. But please go ahead training your own LLM on content like Fox \"News\", so you have a LLM spewing out all the conspiracy theories you desire. And yes, adding a hidden and forced diversity prompt to Gemini clearly was a mistake. But there is valid background story here: For decades, pretty much everything in advertising, beauty and toys did not reflect at all the factually existing diversity. It's just a couple of years now that make-up companies for example have noticed that people of color exist and that their products are not adapted for this. And available image content to train on does not reflect the real diversity there is on this planet. Check one of the large image databases for available skin colors - it absolutely does not reflect the different skin colors present on this planet. Trying to reflect that diversity is not \"far left\". Stop implying that \"caucasian white\" is the middle ground, it's not. Don't treat this as a no-brainer subject. Quite a lot of South Africans not surprisingly look very dutch. There are not easy answers to this problem, so don't assume malice. reply josteink 2 hours agorootparent> They believe in stolen elections The election was clearly rigged though. There’s increasing amounts of evidence for that. And it’s obvious they are trying to rig the next election too. They are, as we speak, fully out in the open, using law-fare to try to get opposing candidates jailed or taken off the ballots. This is just “facts” as you like to put it. This is what dictators and communists do. I think it’s perfectly reasonable to categorise people who support this as “far left”. What else would you call someone who supports communism over democracy? > drinking bleach against Covid Funny how you claim to represent “facts” while presenting hoaxes which has long been debunked as if they are real. Not very consistent IMO. It seems like you should perhaps expand your news-sources to be more diverse? It would probably further your fact-based agenda. reply emptysongglass 4 hours agorootparentprevWhat you've done, conversely, is to other the opposition until they are, from your perspective, \"batshit crazy\". The far left also believes in as equally divergent ideas from a global middle that you could apply any of your extremist epithets to them. You are not the arbiter of what counts as reasonable beliefs. Neither is the far left (or the far right). reply Sakos 18 hours agoprevI love the potential of having such a big context window, but I'm concerned about who will get access to it (or rather who won't get access to it) and what it will cost or who will pay for it. reply criddell 18 hours agoparentYou could have asked the same question in 1964 when IBM released the System/360. Nice computer, but who will pay for it and who will have access to it? I think it’s inevitable that these AI’s will end up costing almost nothing to use and will be available to everybody. GPT-4 is already less than $1 / day and that’s only going to go down. reply thatfatboy 8 hours agorootparent> GPT-4 is already less than $1 / day and that’s only going to go down. but only the Government has access to it uncensored. reply eesmith 15 hours agorootparentprevI do not think that's a good example. A lot of people jumped on the chance to buy a 360. Here are some quotes from https://archive.org/details/datamation0064unse_no5/page/68/m... : > The internal IBM reaction could be characterized as quiet, smug elation. One office is supposed to have sold its yearly quota on A (Announcement) -Day. In Texas, a man allegedly interrupted the 360 presentation to demand he be allowed to order one right then . . . which sounds like a combination plant and a new version of the rich Texan jokes. ... > the 360 announcement has to worry the competition considerably . . . partly because anything new from IBM creates an automatic bandwagon effect, partly because the completeness of the new line offers less reason for people to look outside. ... > another feels that the economic incentive (rental cuts of 50 per cent for 7080, 7090) will force him down the 360 route. And he thinks 360 interrupt features will open the door to real-time applications which can be approached on an incremental basis impossible before. ... > One maverick doesn’t share the enthusiasm of his company, which ordered “plenty” of 360’s within an hour of the announcement, without price agreements. And from https://archive.org/details/bitsavers_Electronic9640504_9809... : > Other computer manufacturers profess to be unworried, but International Business Machines Corp. has received millions of dollars in orders for its system/360 computer [Electronics, April 20, p. 101]. Here are some of the people who paid for it in 1964: https://archive.org/details/sim_computers-and-people_1964_13... > \"Men's Fashion Firm Orders IBM System/360 Computer,\" 13/7 (July) > \"Score of IBM System/360's to be Leased by Paper Company,” 13/8 (Aug.) The Albert Government Telephone Commission bought two: https://archive.org/details/annualreportofa1964albe_0/page/1... reply criddell 10 hours agorootparentAll I’m really saying is that new technology is often only available to the wealthy (companies, governments and rich Texans) but eventually things get cheaper and more widely available. It was hard to get access to IBM System/360 levels of computation in 1964 and in 2024 most of us have far more capabilities in the inexpensive machines in our pockets. I think these new AIs will follow similar curves. Hard to get access to and expensive to use at first. Over time they will get more powerful and less expensive. GPT4 is already less than $1 / day. reply eesmith 2 hours agorootparentThen you should structure your point about computing in general, and not be specific to the IBM 360. In 1964 it made no sense to say \"I'm concerned about who will get access to it (or rather who won't get access to it) and what it will cost or who will pay for it\" about the IBM 360 because that system was available to the same customers as the previous generation of machines, plus it made computing more widely affordable to other customers. While Gemini appears to be more expensive than thus less generally available than other LLMs. reply Sakos 17 hours agorootparentprevI didn't ask it then. I wasn't even alive. I'm asking now. It is a legitimate concern and continues to be a concern with these AI models and you whining that \"oh but 50 years ago bla bla\" (as if these two things are in any way comparable) doesn't change anything about the risks of selective access. reply p1dda 4 hours agoprev [–] \"I got access to Gemini Pro 1.5 this week, a new private beta LLM from Google that is significantly better than previous models the company has released. (This is not the same as the publicly available version of Gemini that made headlines for refusing to create pictures of white people. That will be forgotten in a week; this will be relevant for months and years to come.)\" Wow, I already hate Gemini after reading this first paragraph. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gemini Pro 1.5, an AI model by Google, stands out from other models like GPT-4 with a larger context window capable of handling entire novels and codebases, showcasing improved performance and ease of use.",
      "This AI model is considered a game-changer due to its code integration capabilities, boosting developer productivity, and moving towards transformer models as mental copilots.",
      "The article underlines the importance of verifying the model's outputs, leveraging personal data for performance enhancement, and the challenges and benefits of utilizing large language models effectively through asking good questions and critical thinking skills."
    ],
    "commentSummary": [
      "The discussion explores the use of advanced AI models like Gemini Pro 1.5, touching on privacy, societal implications, and potential misuse.",
      "Debates include the impact on social interactions, AI applications across industries, reliability, and limitations of AI chatbots, and the consequences of depending on language modeling algorithms.",
      "Concerns about Google's AI systems, such as bias and performance constraints, raise issues regarding the integrity, effectiveness, and societal effects of AI technologies on decision-making processes."
    ],
    "points": 248,
    "commentCount": 217,
    "retryCount": 0,
    "time": 1708701820
  },
  {
    "id": 39482428,
    "title": "Mamba: Revolutionizing Language Model Efficiency",
    "originLink": "https://jackcook.com/2024/02/23/mamba.html",
    "originBody": "Mamba: The Easy Way Oxford, UK — February 23, 2024 Shared on Hacker News and X Today, basically any language model you can name is a Transformer model. OpenAI’s ChatGPT, Google’s Gemini, and GitHub’s Copilot are all powered by Transformers, to name a few. However, Transformers suffer from a fundamental flaw: they are powered by Attention, which scales quadratically with sequence length. Simply put, for quick exchanges (asking ChatGPT to tell a joke), this is fine. But for queries that require lots of words (asking ChatGPT to summarize a 100-page document), Transformers can become prohibitively slow.1 Many models have attempted to solve this problem, but few have done as well as Mamba. Published two months ago by Albert Gu and Tri Dao, Mamba appears to outperform similarly-sized Transformers while scaling linearly with sequence length. If you’re looking for an in-depth technical explanation of Mamba, paired with a full Triton implementation, you’re in the wrong place. Mamba: The Hard Way has already been written by the legend himself, Sasha Rush. If you haven’t heard of Mamba (or Triton), or you’re looking for a higher-level overview of Mamba’s big ideas, I have just the post for you. The prospect of an accurate linear-time language model has gotten many excited about the future of language model architectures (especially Sasha, who has money on the line). In this blogpost, I’ll try to explain how Mamba works in a way that should be fairly straightforward, especially if you’ve studied a little computer science before. Let’s get started! Quadratic attention has been indispensable for information-dense modalities such as language... until now. Announcing Mamba: a new SSM arch. that has linear-time scaling, ultra long context, and most importantly--outperforms Transformers everywhere we've tried. With @tri_dao 1/ pic.twitter.com/vXumZqJsdb — Albert Gu (@_albertgu) December 4, 2023 Background: S4 Mamba’s architecture is based primarily on S4, a recent state space model (SSM) architecture. I’ll summarize the important parts here, but if you want to understand S4 in more detail, I would highly recommend reading another one of Sasha’s blogposts, The Annotated S4. At a high level, S4 learns how to map an input \\(x(t)\\) to an output \\(y(t)\\) through an intermediate state \\(h(t)\\). Here, \\(x\\), \\(y\\), and \\(h\\) are functions of \\(t\\) because SSMs are designed to work well with continuous data such as audio, sensor data, and images. S4 relates these to each other with three continuous parameter matrices \\(\\mathbf{A}\\), \\(\\mathbf{B}\\), and \\(\\mathbf{C}\\). These are all tied together through the following two equations (1a and 1b in Mamba’s paper): \\[\\begin{align}h'(t)&=\\mathbf{A}h(t)+\\mathbf{B}x(t)\\\\y(t)&=\\mathbf{C}h(t)\\end{align}\\] In practice, we always deal with discrete data, such as text. This requires us to discretize the SSM, transforming our continuous parameters \\(\\mathbf{A}\\), \\(\\mathbf{B}\\), \\(\\mathbf{C}\\) into discrete parameters \\(\\mathbf{\\bar{A}}\\), \\(\\mathbf{\\bar{B}}\\), \\(\\mathbf{C}\\) by using a special fourth parameter \\(\\Delta\\). I’m not going to get into the details of how discretization works here, but the authors of S4 have written a nice blogpost about it if you’re curious. Once discretized, we can instead represent the SSM through these two equations (2a and 2b): \\[\\begin{align}h_t&=\\mathbf{\\bar{A}}h_{t-1}+\\mathbf{\\bar{B}}x_t\\\\y_t&=\\mathbf{C}h_t\\end{align}\\] These equations form a recurrence, similar to what you would see in a recurrent neural network (RNN). At each step \\(t\\), we combine the hidden state from the previous timestep \\(h_{t-1}\\) with the current input \\(x_t\\) to create the new hidden state \\(h_t\\). Below, you can see how this would work when predicting the next word in a sentence (in this case, we predict that “and” follows “My name is Jack”). In this way, we can essentially use S4 as an RNN to generate one token at a time. However, what makes S4 really cool is that you can actually also use it as a convolutional neural network (CNN). In the above example, let’s see what happens when we expand the discrete equations from earlier to try to calculate \\(h_3\\). For simplicity, let’s assume \\(x_{-1}=0\\). \\[\\begin{align}h_0&=\\mathbf{\\bar{B}}x_0\\\\h_1&=\\mathbf{\\bar{A}}(\\mathbf{\\bar{B}}x_0)+\\mathbf{\\bar{B}}x_1\\\\h_2&=\\mathbf{\\bar{A}}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{B}}x_0)+\\mathbf{\\bar{B}}x_1)+\\mathbf{\\bar{B}}x_2\\\\h_3&=\\mathbf{\\bar{A}}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{B}}x_0)+\\mathbf{\\bar{B}}x_1)+\\mathbf{\\bar{B}}x_2)+\\mathbf{\\bar{B}}x_3\\end{align}\\] With \\(h_3\\) calculated, we can substitute this into the equation for \\(y_3\\) to predict the next word. \\[\\begin{align}y_3&=\\mathbf{C}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{A}}(\\mathbf{\\bar{B}}x_0)+\\mathbf{\\bar{B}}x_1)+\\mathbf{\\bar{B}}x_2)+\\mathbf{\\bar{B}}x_3)\\\\y_3&=\\mathbf{C\\bar{A}\\bar{A}\\bar{A}\\bar{B}}x_0+\\mathbf{C\\bar{A}\\bar{A}\\bar{B}}x_1+\\mathbf{C\\bar{A}\\bar{B}}x_2+\\mathbf{C\\bar{B}}x_3\\end{align}\\] Now, notice that \\(y_3\\) can actually be computed as a dot product, where the right-hand vector is just our input \\(x\\): \\[y_3=\\begin{pmatrix} \\mathbf{C\\bar{A}\\bar{A}\\bar{A}\\bar{B}} & \\mathbf{C\\bar{A}\\bar{A}\\bar{B}} & \\mathbf{C\\bar{A}\\bar{B}} & \\mathbf{C\\bar{B}} \\end{pmatrix}\\begin{pmatrix} x_0\\\\ x_1\\\\ x_2\\\\ x_3 \\end{pmatrix}\\] Since \\(\\mathbf{\\bar{A}}\\), \\(\\mathbf{\\bar{B}}\\), and \\(\\mathbf{C}\\) are all constant, we can precompute the left-hand vector and save it as our convolutional kernel \\(\\mathbf{\\bar{K}}\\). This leaves us with an easy way to compute \\(y\\) with convolution, as shown by the following two equations2 (3a and 3b in Mamba’s paper): \\[\\begin{align}\\mathbf{\\bar{K}}&=\\begin{pmatrix}\\mathbf{C\\bar{B}} & \\mathbf{C\\bar{A}\\bar{B}} & \\cdots & \\mathbf{C\\bar{A}^k\\bar{B}}\\end{pmatrix}\\\\y&=\\mathbf{\\bar{K}} * x\\end{align}\\] Importantly, these recurrent and convolutional forms, which I like to call “RNN mode” and “CNN mode,” are mathematically equivalent. This allows S4 to shape-shift depending on what you need it to do, with no difference in its outputs. We can compare the differences between these “modes” in Table 1 from the S4 paper, which shows the runtime complexity of training and inference for each form (bold denotes the best result for each metric).3Convolution Recurrence S4 Training \\(\\boldsymbol{\\tilde{L}H(B+H)}\\) \\(BLH^2\\) \\(\\boldsymbol{BH(\\tilde{H}+\\tilde{L})+B\\tilde{L}H}\\) Parallel Yes No Yes Inference \\(LH^2\\) \\(\\boldsymbol{H^2}\\) \\(\\boldsymbol{H^2}\\) Notice that CNN mode is better for training, while RNN mode is better for inference. In CNN mode, we can take advantage of parallelism to train across many examples, all at once. In RNN mode, although we can only calculate one step at a time, each step requires exactly the same amount of work. Because S4 can use both modes, it essentially gets the best of both worlds: fast training, and even faster inference. Idea #1: Selectivity Now we can move on to the first major idea introduced by Mamba: selectivity. Let’s recall the two equations that define the discrete form of S4: \\[\\begin{align}h_t&=\\mathbf{\\bar{A}}h_{t-1}+\\mathbf{\\bar{B}}x_t\\\\y_t&=\\mathbf{C}h_t\\end{align}\\] Note that in S4, our discrete parameters \\(\\mathbf{\\bar{A}}\\), \\(\\mathbf{\\bar{B}}\\), and \\(\\mathbf{C}\\) are constant. However, Mamba makes these parameters vary based on the input. We’ll instead end up with something like this:4 \\[\\begin{align}h_t&=s_\\mathbf{\\bar{A}}(x_t)h_{t-1}+s_\\mathbf{\\bar{B}}(x_t)x_t\\\\y_t&=s_\\mathbf{C}(x_t)h_t\\end{align}\\] The authors argue that selectivity, or input-dependence, is important for a number of tasks. Here’s how I like to think about it: because S4 does not have selectivity, it is forced to treat all parts of the input exactly the same. However, when you’re reading a sentence, some words inevitably matter more than others. Imagine we have a model that classifies sentences based on intent, and we give it the sentence: “I want to order a hamburger.” Without selectivity, S4 spends the same amount of “effort” processing each word. Click on the buttons below to see what happens as the sentence is processed, one word at a time. Click on the arrows to update the hidden state I want to order a hamburger ← → Hidden State I (This is an oversimplification, but it should give you a sense of what’s going on.) But if you were a model trying to classify the intent of this sentence, you would probably want to “focus” more on some words than others. How much value do the words “want” and “to” really contribute to the underlying meaning of this sentence? In reality, it would be great if we could spend more of our limited mental energy on words like “order,” to know what the user wants to do, and “hamburger,” to know what the user is ordering. By making model parameters a function of the input, Mamba makes it possible to “focus” on the parts of the input that are more important for the task at hand. Click on the arrows to update the hidden state I want to order a hamburger ← → Hidden State I (Also an oversimplification.) However, selectivity presents us with a problem. Let’s think back to the convolutional kernel \\(\\mathbf{\\bar{K}}\\) that we calculated earlier. \\[\\mathbf{\\bar{K}}=\\begin{pmatrix}\\mathbf{C\\bar{B}} & \\mathbf{C\\bar{A}\\bar{B}} & \\cdots & \\mathbf{C\\bar{A}^k\\bar{B}}\\end{pmatrix}\\] In S4, we could precompute this kernel, save it, and multiply it with the input \\(x\\). And this was fine, because \\(\\mathbf{\\bar{A}}\\), \\(\\mathbf{\\bar{B}}\\), and \\(\\mathbf{C}\\) were constant. But again, in Mamba, these matrices change depending on the input! As a result, we can’t precompute \\(\\mathbf{\\bar{K}}\\), and we can’t use CNN mode to train our model. If we want selectivity, we’ll need to train with RNN mode. We can cross out equation 3b for dramatic effect. \\[\\xcancel{y=\\mathbf{\\bar{K}} * x}\\] This posed a problem for Mamba’s authors: training in RNN mode is really slow. Imagine we’re training our model on a sequence with 1,000 tokens. A CNN would essentially compute a dot product between its kernel and the input vector, and it can do these computations in parallel. By comparison, an RNN would need to update its hidden state 1,000 times in sequence. This slow training time of RNNs is more or less what has prevented them from ever really taking off, and it led Mamba’s authors to their second big idea. Idea #2: Fast training without convolutions The second major idea of Mamba involves training in RNN mode very, very quickly. At some point, Gu and Dao realized that their recurrence was very similar to a scan algorithm, also known as a prefix sum. To compute a prefix sum, we need to take an input array \\([x_1, x_2, x_3, \\cdots, x_n]\\) and return an output array where each element is the sum of that item and the items that came before it. In other words, the first element of the output will be \\(x_1\\), the second element will be \\(x_1+x_2\\), the third \\(x_1+x_2+x_3\\), and so on. An example is shown below. Now let’s draw out the process for updating Mamba’s hidden state in RNN mode. Wait a minute… Let’s think about this. If we had to formalize a prefix sum, we could write it out as the following equation: \\[h_t=h_{t-1}+x_t\\] This equation forms a recurrence: at each step, we compute the new value by adding the previous stored value to the current input. Now, let’s look again at the recurrence for updating Mamba’s hidden state. \\[h_t=\\mathbf{\\bar{A}}h_{t-1}+\\mathbf{\\bar{B}}x_t\\] These are really, really similar!5 And here’s the cool part: while computing a prefix sum may seem inherently sequential in nature, we actually have efficient parallel algorithms for this task! In the diagram below, we can see a parallel prefix sum algorithm in action, where each vertical line represents one item in our array. Credit: David Eppstein Take a second to convince yourself that this algorithm works: choose any vertical line, start at the top, and work your way down, tracing each addition back to the array’s first few items. By the time you reach the bottom, you should have the sum of all items to the left of your line. For example, you can see that the array’s third element receives the added value of the second element at the end, after the first element is added to the second element at the beginning. As a result, the third element contains the sum of the first, second, and third elements by the time the parallel scan is finished. If we were running this algorithm in a single thread, with no parallelism, it would take longer than if we were just adding the values together in sequence. But GPUs have lots of processors, allowing for highly parallel computation. As a result, we can compute this prefix sum (or scan) operation in roughly \\(O(\\log n)\\) time! So Mamba’s authors realized that if they wanted to train efficiently in RNN mode, they could probably use a parallel scan. Since PyTorch does not currently have a scan implementation, Mamba’s authors wrote one themselves, and the results weren’t great. Credit: Gu and Dao, 2023 In the figure above, you can see that their PyTorch-based scan implementation (green) is always slower than FlashAttention-2 (blue), the fastest available “exact Attention” implementation.6 At a sequence length of 128,000 tokens, where the scan almost seems to catch up in runtime, it runs out of memory. In order for Mamba to be practical, it needed to be faster. This brought Mamba’s authors to Dao’s prior work on FlashAttention. Review: FlashAttention FlashAttention is a very fast implementation of Attention. When published, FlashAttention trained BERT-large 15% faster than the previous fastest training time, and it was 3 times faster than the widely-used HuggingFace implementation of GPT-2. In a nutshell, FlashAttention’s key insight has to do with the speeds at which different operations run on your GPU. They realized that some GPU operations are compute-bound, meaning they are limited by the speed at which your GPU performs computations. However, other operations are memory-bound, meaning they are limited by the speed at which your GPU is able to transfer data. Imagine you and a friend are playing a game: your friend has to run 50 meters to deliver two numbers to you, which you then need to multiply by hand. A timer starts when your friend begins running, and ends when you get the answer. Let’s say the numbers you need to multiply are 439,145,208 and 142,426,265. It would take you awhile to multiply these by hand. Your friend might take 5 seconds to deliver the numbers, but you might take 60 seconds to perform the multiplication. As a result, you are both compute-bound, since most of your time is spent on computation. Now, imagine the numbers you need to multiply are 4 and 3. While your friend still takes 5 seconds to run 50 meters, you can compute this result instantly. Now, you are both memory-bound, since most of your time is spent transferring data. In this analogy, your GPU is essentially racing to move data into the right places to perform its computations. For example, let’s consider a masking operation. To compute a masked vector, your GPU simply needs to erase data values whenever the mask is equal to zero (and keep them the same whenever it is equal to one). If we used \\(\\boldsymbol{\\oslash}\\) to denote a masking operation, an example of this would be as follows, where the mask forces us to set the last three data elements to zero: \\[ \\begin{pmatrix} 4 & 9 & 4 & 1 & 2 & 7 \\end{pmatrix} \\hspace{0.1cm}\\boldsymbol{\\oslash}\\hspace{0.1cm} \\begin{pmatrix} 1 & 1 & 1 & 0 & 0 & 0 \\end{pmatrix}=\\boxed{\\begin{pmatrix} 4 & 9 & 4 & 0 & 0 & 0 \\end{pmatrix}} \\] Since this is extremely easy to compute, your GPU ends up spending most of its time transferring memory, to move the data and mask matrices into the right places for computation. This means that masking is memory-bound. On the other hand, matrix multiplication involves lots and lots of additions and multiplications. Because so much more time is spent on computation than memory transfers, matrix multiplication is compute-bound. With this in mind, let’s look at a breakdown of the computations performed during Attention (matmul = matrix multiplication). Credit: Dao et al., 2022 It turns out that dropout, softmax, and masking, which make up the bulk of Attention’s runtime, are all memory-bound. This means that most of the time we spend computing Attention is simply spent waiting for your GPU to move around data. With this in mind, I assume FlashAttention’s authors wondered, how can we speed up operations that are bounded by the speed of memory transfers? This led FlashAttention’s authors to another key realization: GPU memory has two major regions. One of these, high-bandwidth memory (HBM), is really big, but really slow. The other one, static random-access memory (SRAM), is really small, but really fast. Let’s break down the differences between these regions on an A100 GPU: Credit: Dao et al., 2022 FlashAttention’s authors realized that you can compute memory-bound operations more efficiently if you’re extra careful about how you use these regions of GPU memory. They use an approach called tiling, in which small portions of your data are moved from HBM (slower) to SRAM (faster), computed in SRAM, and then moved back from SRAM to HBM. This makes FlashAttention really, really fast, while still being numerically equivalent to Attention. Credit: Dao et al., 2022 The details of how this works are fascinating, and I encourage you to check out the FlashAttention paper to learn more. However, for the purpose of understanding Mamba, this is basically all you need to know. Back to Mamba Remember that before we started this tangent on FlashAttention, we were trying to speed up our parallel scan implementation. Here is the same graph from earlier, where we can see that the scan implementation in PyTorch (green) is always slower than FlashAttention, the fastest “exact” Transformer (blue).7 Credit: Gu and Dao, 2023 It turns out that if you take this same memory-aware tiling approach when computing a scan, you can speed things up a lot. With this optimization in place, Mamba (red) is now faster than FlashAttention-2 (blue) at all sequence lengths. Credit: Gu and Dao, 2023 These results show that as far as speed goes, Mamba is practical, operating at a faster speed than the fastest exact Transformers. But is it any good at language modeling? Results Gu and Dao evaluate Mamba on a number of sequence modeling tasks involving language, genomics, and audio. I’m not as familiar with the latter two domains, but the results look cool: Mamba establishes state-of-the-art performance when modeling DNA from the Human Genome project, and audio from a piano music dataset. However, it’s the language results that have gotten many people excited. A lot of the online discourse about Mamba has focused on Figure 4, which I’ve included below. Credit: Gu and Dao, 2023 In this graph, model size increases to the right, and language modeling performance improves as you go further down.8 This means that the best models should be down and to the left: small (and therefore fast), and also very good at modeling language. Since Gu and Dao are academics, they don’t have thousands of GPUs available to train a GPT-4-sized model, so they made this comparison by training a bunch of smaller models, around 125M to 1.3B parameters. As the graph above shows, the results look really promising. When compared to other models of similar sizes, Mamba appears to be the best at modeling language. What next? I really enjoyed writing this blogpost, as I think Mamba innovates on language modeling in a pretty unique and interesting way! Unfortunately, a few reviewers didn’t agree: Gu and Dao planned to present Mamba at ICLR in May, but their paper was rejected a couple weeks ago, causing some bewildered reactions online. Mamba apparently was rejected !? (https://t.co/bjtmZimFsS) Honestly I don't even understand. If this gets rejected, what chance do us 🤡 s have. — Sasha Rush (@srush_nlp) January 25, 2024 I would guess Gu and Dao are working now on the next version of the paper, and I would also imagine some companies with more GPUs than they know what to do with are currently trying to figure out whether Mamba’s performance holds up at larger model sizes. As we continue to want models that can process more and more tokens at once, linear-time models such as Mamba might someday provide an answer if they can demonstrate good performance. Until then, we can keep hacking away on our lame, old-school Transformers. 1. Faster Transformers such as Gemini 1.5 are almost certainly using Attention modifications, e.g. RingAttention, StreamingLLM, Linear Attention. ↩ 2. CNNs flip the kernel to perform convolution, which is why \\(\\mathbf{\\bar{K}}\\) looks backwards compared to the left-hand vector from our derivation of \\(y_3\\). ↩ 3. In this table, \\(\\boldsymbol{L}\\) denotes sequence length, \\(\\boldsymbol{B}\\) denotes batch size, \\(\\boldsymbol{H}\\) denotes the model’s hidden size, and tildes denote log factors. Don’t worry about the math too much for the purpose of this blogpost. ↩ 4. In reality it’s a little more complicated than this: the continuous \\(\\mathbf{A}\\) is constant, while our discretization parameter \\(\\Delta\\) is input-dependent. \\(\\mathbf{\\bar{A}}\\) is therefore input-dependent as a result of discretization. ↩ 5. Mamba’s recurrence and the prefix sum are “similar” because importantly, Mamba’s recurrence is a linear transformation of its inputs. This is not true of RNNs, which is why we can’t use a parallel scan to train RNNs. ↩ 6. If you read footnote 1, note that FlashAttention/FlashAttention-2 is a different type of Attention modification because unlike those examples, FlashAttention is numerically equivalent to standard Attention. It’s faster, but it yields the exact same outputs. FlashAttention’s authors refer to this as computing “exact Attention.” ↩ 7. See footnote 6. ↩ 8. Perplexity, shown on the y axis, is a common measure of language modeling performance. If you’re given the first part of a sentence and asked to predict the next word, you can think of perplexity as a value indicating how “perplexed” you are when you are shown the right answer. For example, if you are given the sequence “I went for a walk outside”, you shouldn’t be too surprised when the next word is “today.” Lower values indicate you are less perplexed, and therefore have a better understanding of how language works. ↩",
    "commentLink": "https://news.ycombinator.com/item?id=39482428",
    "commentBody": "Mamba: The Easy Way (jackcook.com)245 points by jackcook 17 hours agohidepastfavorite58 comments jxmorris12 15 hours agoIn case people are wondering why Mamba is exciting: There's this idea in AI right now that \"scaling\" models to be bigger and train on more data always makes them better. This has led to a science of \"scaling laws\" which study just how much bigger models need to be and how much data we need to train them on to make them a certain amount better. The relationship between model size, training data size, and performance turns out to be quite predictable. Transformers are great because they can continue scaling and giving us better performance – unlike, we think, RNNs. Probably the most exciting thing about Mamba is the claim that it can be a bit smaller, and train on a bit less data, and still provide better performance than the equivalent Transformer, especially at longer sequence lengths. For more info, see the scaling laws plot in Figure 4 of the Mamba paper: https://arxiv.org/abs/2312.00752 reply KuriousCat 12 hours agoparentPeople have shown even CNNs can match up the peformance of the transformers. https://openreview.net/forum?id=TKIFuQHHECj# I believe there is a lot of herding going on due to the influence of people who had compute to play around with than deeply insightful or principled exploration of networks. reply jdeaton 7 hours agorootparentyou linked a paper about vision transformers... reply hervature 6 hours agorootparentBeing used as a comparison... From the abstract: > Bringing these components together, we are able to build pure CNN architectures without any attention-like operations that are as robust as, or even more robust than, Transformers. reply hansonw 13 hours agoparentprev“RNN-mode inference” is also extremely exciting because you can precompute the hidden state of any prompt prefix (i.e. a long system prompt, or statically retrieved context) and continued generations pay the same cost irrespective of the prefix length. reply shikon7 6 hours agorootparentBut this also means that possible information retained is constant irrespective of the prefix length. This might be a problem if the prefix is composed of essentially uncompressable data. reply hansonw 1 hour agorootparentIndeed: https://arxiv.org/pdf/2402.01032.pdf Perhaps future iterations of SSMs will accommodate dynamically sized (but still non-linearly-growing) hidden states / memories! reply 5kg 13 hours agoparentprevI'd love to see someone who has the resources train a model bigger than 2.8b and show the scaling law still holds. reply nickpsecurity 13 hours agorootparentSome prior comments said those architectures lack the memory or something of a transformer. That there’s a weakness that’s keeping people using transformers. If true, I’d like to also see tests of various domains with equivalent transformer and Mamba designs to see if that difference impacted anything. From there, we’d have a better idea about whether Mamba-176B is worth the money. reply intalentive 11 hours agoprevNice post. A couple things to add: 1. The Mamba co-author was also the FlashAttention lead author. 2. The secret ingredient that makes SSMs viable for deep learning is HiPPO theory. If you start with random initialization you're not going to get results. What you need is \"optimal online function approximation\" using Legendre polynomials, a Fourier basis, etc., in matrix form. The Mamba story starts with Legendre Memory Units. Invariably someone comments, \"How do we know that it scales?\" We don't. But the lead author has backing and a new startup at cartesia.ai. Could be the next Mistral. reply sigmoid10 11 hours agoparentThe architecture is completely public. I would be surprised if certain other players (including but not limited to Mistral AI) are not training models yet. We'll hear soon enough if this is viable. Maybe not for official release candidates, but at least for internal testing. reply 3abiton 3 hours agorootparentNonetheless, this is extremely exciting, unlike RWKV and Retention Network reply magnio 16 hours agoprevFantastic blog post, thank you for this. I am not even familiar with transformers, yet the explanation is stellar clear to me, and the included references and context are a trasure trove. The explanation of FlashAttention is the best I have seen, and that is not even the focus of the article. One question I have on selectivity: footnote 4 says \"the continuous A is constant, while our discretization parameter ∆ is input-dependent.\" What is the effect of varying the discretization instead of the (main, as I understand it) state A? My gut says it simplifies training and provides stability, but I feel A carries most of the behavior of the model, so it should have more wiggle room throughout training. reply jackcook 15 hours agoparentThank you for the kind words! I think it’s mostly to reduce complexity during training. Here’s an excerpt from page 9 of the Mamba paper: “We remark that while the A parameter could also be selective, it ultimately affects the model only through its interaction with ∆ via A = exp(∆A) (the discretization (4)). Thus selectivity in ∆ is enough to ensure selectivity in (A, B), and is the main source of improvement. We hypothesize that making A selective in addition to (or instead of) ∆ would have similar performance, and leave it out for simplicity.” reply nlrk 3 hours agorootparentwhen I read the paper I thought the idea was changing \\Delta permits getting the model to learn different things over different time scales. As you quoted “the main source of improvement\". I don’t have an llm backround, just controls, so I might wrong. reply whimsicalism 15 hours agoparentprevHow are you not familiar with transformers yet have seen multiple explanations of FlashAttention? reply samus 12 hours agorootparentThe issue with Attention essentially is that it is used to relate all token of the input sequence with each other. The need to do that somehow makes sense no matter how much one understands about the internals of a transformer. The naive way to do that boils down to matrix multiplications, and a lot more people understand the performance issues implied by them. reply whimsicalism 11 hours agorootparentyour comment makes no sense to me, sorry. if you understand attention you understand transformers, period. reply defrost 9 hours agorootparentLikewise your comment(s) makes no sense to me. If you can understand attention and transformers, how can you not understand that population numbers can rise, reach a peak, fall, and then level out (all w/out any genocidial actions)? How can you claim that it is \"absurdism\" to imagine something that can be seen in data across the plant and animal kingdom? reply samus 11 hours agorootparentprevThat's good to know :) reply avarun 14 hours agorootparentprevLiterally the exact question I had reading that comment haha reply jsenn 14 hours agoprevThis was really helpful, but only discusses linear operations, which obviously can’t be the whole story. From the paper it seems like the discretization is the only nonlinear step—in particular the selection mechanism is just a linear transformation. Is that right? How important is the particular form of the nonlinearity? EDIT: from looking at the paper, it seems like even though the core state space model/selection mechanism is linear (except for discretization?), they incorporate a nonlinearity in the full “mamba block”, which is stacked up with residual connections and layer norm just like in a transformer. They describe this as combining a linear attention and an MLP into a single step, rather than alternating attention and MLP as in a transformer. reply jackcook 12 hours agoparentYes you're spot on, the nonlinearities come from the full Mamba blocks, which I left out of this post for simplicity/to focus on the bigger ideas the paper introduced. You can see it marked by the \"X\" on the right-most part of Figure 3 in the Mamba paper: https://arxiv.org/abs/2312.00752 reply paxys 16 hours agoprevFrom what I can tell all the large players in the space are continuing developing on transformers right? Is it just that Mamba is too new, or is the architecture fundamentally not usable for some reason? reply thatguysaguy 16 hours agoparentToo new is definitely one thing. Someone is going to have to make a gamble to actually paying for a serious pretraining run with this architecture before we know how it really stacks up against transformers. There are some papers suggesting that transformers are better than SSMs in fundamental ways (e.g. They cannot do arbitrary key-based recall from their context: https://arxiv.org/abs/2402.01032). This means it's not just a no-brainer to switch over. reply espadrine 15 hours agorootparentAnother element is that Mamba required a very custom implementation down to custom fused kernels which I expect would need to be implemented in deepspeed or the equivalent library for a larger training run spanning thousands of GPUs. reply cs702 13 hours agorootparentNot necessarily: https://www.reddit.com/r/MachineLearning/comments/1amb3xu/d_... reply gaogao 15 hours agorootparentprevIt's a reasonably easy bet that Together is doing or will do a serious pretraining run with Mamba, where if that's a success other players might start considering it more. reply whimsicalism 15 hours agorootparentprev> There are some papers suggesting that transformers are better than SSMs in fundamental ways I mean the vanilla transformers are also shown failing at the tasks they present. reply whimsicalism 15 hours agoparentprevwe have no idea what the large players in the space are doing reply danielmarkbruce 13 hours agorootparentExactly this. Except, there is zero chance they just looked at mamba and went \"meh, too new for us\". People are definitely trying stuff. It takes a lot of fiddling around with a brand new model architecture to get something working well. OpenAI aren't going to give a running commentary on the state of all the things they are looking into. reply denial 13 hours agoprevSomething minor I always wonder about when I read Mamba is the discretization. All of the sources I see referred to as derivations of it have a discretization of the form h_t =Ah_{t-1} + Bx_{t-1} for the first line instead of the given one of the form h_t =Ah_{t-1} + Bx_t. Does anyone know why this is? reply pama 12 hours agoparentNot sure how much detail you need but generally there exist implicit and explicit integrators for numerically solving (integrating) ODE. The implicit ones, like the one used here, tend to be more stable. The ideas behind SSM come from control theory ideas that used integrators with stability guarantees so that the rest of the neural network can focus on other aspects of the problem. reply denial 12 hours agorootparentThat's a helpful pointer. Thank you. reply israrkhan 11 hours agoprevMoE (Mixture of Experts) is an effective way to scale transformers. Gemini 1.5 is already doing upto 1 million tokens. I have not seen any large scale mamba model, so not aware of its shortcomings, but I am sure there are tradeoffs. It should be possible to combine Mamba with MoE, I wonder how that would look like... a billion token context? reply nestorD 9 hours agoparentMoE let's you use scale model size up with compute. That leads to hopefully more intelligent models. It, however, is independent with context size: the ability to process a lot of tokens / text. reply intalentive 11 hours agoparentprevhttps://arxiv.org/abs/2401.04081 https://github.com/jzhang38/LongMamba reply israrkhan 11 hours agorootparentinteresting. This is exactly what I was thinking about. Thanks for sharing reply whimsicalism 11 hours agoparentprevnope :) MoE does not scale transformers along sequence length reply lxe 15 hours agoprevI'm very positive I can actually understand the terminology used in discussing machine learning models if it was presented in a way that describes the first principles a little bit better, instead of diving directly into high level abstract equations and symbols. I'd like a way to learn this stuff as a computer engineer, in the same spirit as \"big scary math symbols are just for-loops\" reply paulluuk 15 hours agoparentIronically, you can probably just ask a Transformer model to explain it to you. I'm the same as you: I have no problem grasping complex concepts, I just always struggled with the mathematical notation. I did pass linear algebra in university, but was glad I could go back to programming after that. Even then, I mostly passed linear algebra because I wrote functions that solve linear algebra equations until I fully grasped the concept. I've found that GPT-4 is very good at taking a math-notation-rich document and just describing it in terms a math-notation-averse engineer would understand. I was a data engineer for about 6-7 years at various companies, always working together with data scientists who insist that `x_` or `_phi` are proper variable names. Man am I glad to be working with engineers now. reply danielmarkbruce 13 hours agorootparentThis is very effective. Also, just try really hard. Repeat. It's new language to explain concepts you likely already know. You don't remember spanish by looking at the translations once. reply QuadmasterXLII 10 hours agoparentprevThat's a heuristic that's usually true. You can definitely understand convolution or attention better with a \"big scary math symbols are just for-loops\" explanation, but there are also things like dopri45 or elliptic curve crypto where we just have to accept that Weird Math Shit is happening and the symbols are inevitable. It looks to me like mamba has dragged a part of llm research into the latter camp. reply yorwba 15 hours agoparentprevIt is unclear to me whether you're praising the article as particularly easy to understand or complaining that it contains equations like h_t = A h_{t-1} + B x_t y_t = C h_t (which the author attempts to illustrate in the \"My name is Jack\" figure below) reply whimsicalism 15 hours agoparentprevIf you want to learn this stuff as a computer engineer, you can read the code here [0]. I find the math quite helpful. [0]: https://github.com/state-spaces/mamba reply esafak 15 hours agoparentprevAsk an LLM to translate it into terms you understand. This is something they excel at. reply moffkalast 15 hours agoprevIf I'm not mistaken the largest mamba model right now is 2.8B and undertrained with low quality data (the Pile only). The main problem is that it's new and unproven. Should become very interesting once someone with both data and significant financial backing takes the plunge and trains something of notable size. Perhaps Llama-3 might already end up being that attempt, as we seem to be heavily into diminishing returns for transformers. reply SekstiNi 13 hours agoparentThere is one trained on 600B tokens from SlimPajama [1], but that's fairly tiny compared to other recent releases (ex. stablelm-3b [2] trained on 4T tokens). > low quality data (the Pile only) The Pile is pretty good quality wise. It's mostly the size (300B tokens) that's limiting. [1]: https://huggingface.co/state-spaces/mamba-2.8b-slimpj [2]: https://huggingface.co/stabilityai/stablelm-3b-4e1t reply moffkalast 12 hours agorootparentEh quality is subjective. There are good parts, like Books3 and arxiv, but a large part of it is common crawl which has just about anything people put up on the internet, random IRC chat logs, HN and Reddit shitposts, Youtube subtitles which are in broken English half the time, and of course the Enron corporate email dump to make every model sound like an HR middle manager. reply mistrial9 14 hours agoprevnamespace collision detected https://anaconda.org/conda-forge/mamba reply Der_Einzige 16 hours agoprev [–] Very annoying namespace conflict since a package called \"mamba\" (faster reimplementation of the python conda package manager) already existed for awhile before this architecture was even dreamed up. https://github.com/mamba-org/mamba Beyond that, I'll care about an alternative to transformers when it shows superior performance with an open source 7b-34b model compared to transformer model competitors. So far this has not happened yet reply jasonjmcghee 16 hours agoparent> Please don't complain about tangential annoyances—e.g. article or website formats, name collisions, or back-button breakage. They're too common to be interesting. reply lpasselin 16 hours agoparentprevThe mamba paper shows significant improvements in all model sizes, up to 1b, the largest one tested. Are there any reason why it wouldn't scale to 7b or more? Have they tried it? reply samus 12 hours agorootparentThat's the issue - I keep hearing that it is beyond small research group's budget to meaningfully train such a large model. You don't just need GPU time, you also need data. And just using the dregs of the internet doesn't cut it. reply woadwarrior01 16 hours agoparentprev [–] I use the former and have been experimenting with the latter. Fortunately, the contexts are separate enough that they never come up in the same sentence. reply amelius 16 hours agorootparent [–] I was using mamba to install mamba the other day, when suddenly I had to run for a live mamba. reply croes 16 hours agorootparentWhile chewing a Mamba? https://www.mamba.us/ reply scarmig 15 hours agorootparentprev [–] I had the exact same experience, and I was also using it for a web application powered by the Mamba web framework. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mamba, a novel language model created by Albert Gu and Tri Dao, surpasses Transformers in scalability and efficiency by tackling the quadratic attention issue with a Sequential State Model design.",
      "By discretizing continuous parameters, Mamba enables speedier handling of lengthy queries, merging features from recurrent and convolutional neural networks to boost training and inference speed.",
      "Despite not being accepted for ICLR presentation, the authors introduced parallel algorithms like FlashAttention to improve GPU processing efficiency, showcasing Mamba's potential for advancing language modeling performance."
    ],
    "commentSummary": [
      "The focus is on scaling models in AI, particularly discussing the Mamba model as a possible enhancement to Transformers, with potential benefits and effectiveness under scrutiny.",
      "Challenges include training large models, ensuring data quality, and grappling with the intricate nature of various model architectures in deep learning.",
      "There are discussions on combining Mamba with other models like MoE, along with the necessity of custom fused kernels for more extensive training sessions."
    ],
    "points": 245,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1708704718
  },
  {
    "id": 39481805,
    "title": "Genius Dogs: Learning 100+ Toy Names without Training",
    "originLink": "https://www.scientificamerican.com/article/dog-language-geniuses-are-rare-but-apparently-real/",
    "originBody": "December 14, 2023 4 min read Dog ‘Language Geniuses’ Are Rare but Apparently Real A subset of exceptional pooches can identify by name more than 100 different objects, mostly toys By Rachel Nuwer A small number of border collies and other dogs demonstrate an adeptness at learning new words. Credit: Malcolm McHugh/Alamy Stock Photo Animals Dogs regularly make top-10 lists of the world’s smartest animals. As any pet owner has likely noticed, though, some dogs—like some people—are sharper than others. And a few might even be, in canine terms, geniuses. As researchers describe today in Scientific Reports, certain dogs are capable of learning the names for more than 100 different toys. Remarkably, most of the dogs in the study seemed to do this spontaneously, without any special training from humans. “Owners just notice one day that their dog knows the name of toys,” says the paper’s lead author Shany Dror, a doctoral candidate in ethology at Eötvös Loránd University in Hungary. “Someone says, ‘Pizza,’ and their dog suddenly comes with the pizza toy.” Language is integral to how human beings think, communicate and collectively function, yet questions abound about the evolutionary origins of this behavior. Comparing and contrasting other species’ abilities to comprehend words and phrases can be a useful method for learning more about how human language came to be. Most of these studies to date have focused on apes or dolphins, but results can be complicated by the fact that such investigations have often involved animals in captivity instead of in the wild. On supporting science journalism If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. Dogs, on the other hand, have been living in tandem with humans for some 15,000 to 20,000 years and are constantly exposed to language. “The way we interact with our dogs is very similar to how we do with our infants,” Dror says. “The connection dogs form with human caretakers is also very similar to infants.” Yet at some point, she continues, babies learn to talk, while puppies do not. Only a few researchers have tried to explore the origin of that difference. In 2004 scientists at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, reported that a border collie named Rico knew the words for more than 200 different items. In the nearly 20 years since the paper on Rico was published, however, researchers outside of Dror’s group have only found six dogs that demonstrated similar abilities, which has limited the scope of studies that have been performed. Dror, who is also a professional dog trainer, wanted to expand the field by finding more dogs with an aptitude for language. First, she tried to train 34 dogs from typical households to learn a set of vocabulary words. “That was a miserable failure,” she says. “We all worked really hard, but after three months, they didn’t even know the names of two toys.” So rather than trying to teach dogs, she decided to put out a call for owners of particularly astute canines to come forward. She and her colleagues also launched the “Genius Dog Challenge,” a live YouTube-broadcasted game that pits smart dogs against one another to see which possesses the greatest linguistic prowess. After five years, the researchers identified 41 “gifted word learner dogs,” or ones that knew the names of at least five toys. The dogs came from nine different countries on three continents and included a range of breeds. More than half were border collies, but the team also documented language abilities in a few mixed-breed and purebred dogs, including three Labradors, two Pomeranians, and a Pekingese, Shih Tzu, corgi, toy poodle, German shepherd, and cross between an Australian cattle dog and a miniature Australian shepherd. When Dror first gathered the data, which were validated on video calls online, the 41 dogs knew an average of 29 words for toys, and the top performer among them knew 86. From that baseline, the dogs demonstrated an “amazing” learning speed, Dror says, with owners reporting that dogs needed only five minutes or so to learn a new toy. Proving that old dogs—or at least older dogs—can learn new tricks, the canines continued to expand their vocabulary over the years. By the time the researchers were finalizing their new paper, 16 owners reported that their dogs now knew the names of more than 100 toys. The new research represents “a very exciting step forward” for the field, says Heidi Lyn, a comparative psychologist at the University of South Alabama, who was not involved in the work. “Overall, I think this study is a great example of the next wave of potential for citizen science and for understanding our canine companions and their ability to understand us.” Dror and her colleagues do not know what differentiates canine wordsmiths from average dogs. The animals in the study were very motivated to play with toys and also paid close attention when their owners spoke. But as Dror points out, these are hardly unique traits among dogs. She suspects that dogs’ early rearing environment, combined with some form of natural talent, plays a role in whether they become gifted word learners, but “we still do not know the elements that compose each of these factors and how the two interact,” she says. Irene Pepperberg, a comparative psychologist at Boston University, who was not involved in the research, says that it’s interesting to see in the study that not all working dogs—or those bred to be herders, hunters or trackers—can become gifted word learners. Yet almost all gifted word learners are working breeds. Those include the obvious breeds such as shepherds and labs but also less obvious ones such as poodles, which were used in militaries in the 17th century through World War II, and Pomeranians, which were originally bred as watchdogs. “At least until recently, when beauty standards have evolved and probably affected the gene pool, breeds were carefully selected to learn and respond to aspects of human speech over thousands of years,” Pepperberg says. Dror and her colleagues hope to pursue follow-up studies that delve into the factors that contribute to certain dogs’ talent for language and examine how the animals’ approach to learning is similar or different to that of human children. The team wants to expand its sample size, too, so Dror encourages owners who think their dog may be a genius to reach out. “We’re always interested in meeting new dog owners and meeting their dogs,” she says. Rights & Permissions Rachel Nuwer is a freelance science journalist and author who regularly contributes to Scientific American, the New York Times and National Geographic, among other publications. Follow Nuwer on Twitter @RachelNuwer More by Rachel Nuwer",
    "commentLink": "https://news.ycombinator.com/item?id=39481805",
    "commentBody": "Certain dogs are capable of learning the names for more than 100 different toys (scientificamerican.com)219 points by Capstanlqc 17 hours agohidepastfavorite193 comments bongodongobob 15 hours agoI adopted an Australian Shepherd from a friend a year ago and I'm absolutely blown away by how smart he is. He even knows the neighbor dogs' names. I can say \"go get spot!\" and he'll run after the right dog. He knows all my family members names. He knows that \"you've arrived\" on Google maps means we are there. He knows that \"power on\" coming from my Bluetooth headphones means we are going for a walk. He gets the concept for new tricks in about a half hour. I do have to practice them daily, but he gets the gist almost immediately. I knew Aussies were smart and I'm not sure where he is on the bell curve, but yeah, some dogs really have a knack for language. reply cush 12 hours agoparentI did this with my Aussie as well. I'd hide all of her toys throughout the house then instruct her \"go get your hamburger!\" and in a few minutes, she'd come back with her hamburger. It was wild that she'd remember what toy she was looking for during that time. More impressive still, was she would be able to learn new toy names through inference. I'd come home with a new toy turtle, hide all her toys, say \"go get your Turtle!\", and she'd come back with the new toy. And from then on she'd know which one was Turtle. She had an insatiable appetite for training and learning! reply q7xvh97o2pDhNrh 8 hours agorootparent> More impressive still, was she would be able to learn new toy names through inference. I'd come home with a new toy turtle, hide all her toys, say \"go get your Turtle!\", and she'd come back with the new toy. Is it possible that she already knew about turtles before, though? In that case, she might just be running a rehearsed routine. You know, a shell script. reply lelanthran 2 hours agorootparentIn this context, I'd argue it's more likely a logo program. reply rubyn00bie 1 hour agorootparentprevI can tell my dog to get your “new toy” and she’ll come back with the new toy. She’s a terrier and chihuahua mix. Before her, I hadn’t ever really considered that dogs are so capable. She’s learned words and phrases that are relevant to her consistently. If I’m on a walk with her and want to bribe her to go home I’ll say “Turkey?” and she’ll start pulling on her leash. The funny part is she normally gets a treat after taking a dump, but if I say “turkey” she will drop her treat and wait for me to give her Turkey. If I say “chicken” she will wait, with an unholy focus, until I give her chicken. She makes me keep my promise and knows what it is. Her being small has sort of caused me to be more nurturing and closer than I had been with dogs growing up. As a result, I think it’s enabled her to express herself because I’m able to perceive it. It's a positive feedback loop. It’s also led me to believe there’s a lot of division between “us” (humans) and other animals is only because we can’t directly talk to them or lack the patience. We’ve tried to make our existence special, and we just aren’t (even if the amalgamation of our traits makes us unique). That’s not to say she’s gonna be doing calculus (1) or philosophizing with me, but she’s much more capable than I had ever assumed the other “animals” are. And it’s made me acutely aware that we get what we give when it comes to our understanding of other species (or our lack thereof). 1) she’s able to “count” to three (or understand quantities at some level), and while, it is unlikely to impress a mathematician unless they have a love of dogs dogs. It certainly impresses me. reply OnlyMortal 3 hours agorootparentprevGood grief. Well played. reply debo_ 7 hours agorootparentprevclap reply WalterBright 2 hours agorootparentprevI trained a cat to ignore all my commands. reply krisoft 1 hour agorootparentIncluding the one instructing the cat to ignore all of your commands? :) sounds paradoxical, but I guess if anyone a cat will be able to pull it off. reply Extropy_ 11 hours agorootparentprevI have a 3 year old pug. He'll run through the house searching for the right family member if you count down from 10 and say \"Go find X! Where is he?!\" reply cush 6 hours agorootparentThat's too cute! I like to imagine that you have hardwood floors in this house, and he skitters around in a frantic panic Tokyo-drifting his way to that family member reply legohead 12 hours agoparentprevI had a dumb labrador that was hard to train. Now I have a kokoni who knows 20 commands & words, and she is super easy to train. We haven't tried to test the limit of her abilities, we just ran out of things to teach her (that we cared about, at least). She never cared for toys though. I noticed while teaching her to \"speak\" that she would sneeze a lot, I guess it's kind of a reflex for her when she tries to speak. So I wondered, can I teach a dog to sneeze? And sure enough, after a bit of training, she will now sneeze on command. reply draculero 9 hours agorootparentI had a dog that yawned to say \"no\". I don't know if she trained us or I trained her, but she associated stopping doing something with a yawn. Don't like petting? yawn and the human will stop. Don't like that food? yawn and we will change it. Don't like going to the veterinary? yawn - but that never worked. I loved that dog. reply bicx 5 hours agorootparentI think that yawning is also something dogs do when they are frustrated. My dog does it a good bit, and that’s when I know to give her a break. Or maybe I’m just being trained too… reply DANmode 3 hours agorootparentIt's a known anxiety response for dogs. The hard part is most humans can't connect their own angst with their environmental conditions! reply qup 12 hours agorootparentprevShe sounds like my dog, who has sneezing fits a lot. The shelter said she was a shepherd/boxer mix when I adopted her, but I believe she's a mountain cur. Either way, she's wonderful, and learned every trick I taught her in the first couple of months. She still knows them all 9 years later. She's learned a lot about me without my instruction, we just fit like a glove. I don't have an exact count, but she knows at least 30 commands (some are for the same thing, like \"wait for me\" and \"slow down\"). I use natural language. I'm not sure how many other things she's picked up. I always tell her \"be right back\" if it's true, but I'm not sure if she understands it or not, because she's not an anxious dog. She's never been that interested in food or toys. She's a farm dog. The best. I wish they'd speed up that research on dog longevity. She's 9. reply cogman10 11 hours agorootparent> who has sneezing fits a lot Sneezing is a way dogs say they want to play. That's adorable that she loves sneezing for you. [1] [1] https://www.thekennelclub.org.uk/health-and-dog-care/health/... reply qup 8 hours agorootparentThat makes sense, because it is indeed when she's excited. We play a little game where I pretend I don't know what she wants, and she gets very excited when I figure out she wants to go outside, and has a few sneezes to celebrate. reply cjtrowbridge 9 hours agorootparentprevI also have a Kokoni. He has a doll that looks just like him since he was born. Sometimes he will pose it to be doing things you tell him to do that he doesn't want to do. So wild to see. reply teruakohatu 9 hours agorootparentDo you have photos of your dog doing that? reply user_7832 12 hours agorootparentprev> she would sneeze a lot Btw dogs often do this to indicate they're playing/mean no harm :) reply raffraffraff 2 hours agorootparentI have had greyhounds and lurchers, and every one of them does it. It's not a full sneeze, I call it a \"snit\" because that's what it sounds like. They're large dogs, so when they're being playful, jumping around and play fighting, we sometimes tell them \"no!\" is they're about to knock something over. This always gets us a \"snit\". The yawn thing that someone else mentioned is also common. If they are displeased with you, you get a yawn. Like if you ask them to do something (sit, paw etc) too many times and they're bored of you, you'll get an exaggerated vocal yawn. And the last one I'll mention, because it's so common in all dogs I've seen, is the shake. Directly after a tense situation, they shake, like they do when they're drying themselves. For example, if you're walking your dog and they encounter another dog that is larger, or a breed that they don't know or don't trust, they'll sometimes do a quick shake a few seconds after the encounter. I always reward the shake with a treat, to tell them \"good dog, you kept your shit together in a stressful situation\". A trainer told me to do that when I had a grey who had very bad social anxiety, and it really worked. reply spike021 13 hours agoparentprevI have a Shiba Inu and he's very much the same. If I say \"look there's your friend Bella!\" He goes nuts because that's his favorite friend to play with. He can even recognize the sound of their owner from multiple apartment buildings away. Not kidding at all. He'll go frantic begging to go outside and as soon as we're out he'll perk his ears, figure out the direction to go, and take off. And then after five or so mins heading that way he finds his best bud. reply cj 12 hours agorootparentMy Shiba has learned the days of the week. I have a family member that visits every Thursday, and he sits by the door waiting for them (only on Thursdays). And god forbid I work a weekend or do something off schedule, he gets stressed out thinking something is wrong. I often joke he would be a more normal dog if he had a lobotomy. Sometimes I wish he were a bit dumber :) reply xahrepap 4 hours agorootparentI had a Samoyed when I was a child that knew Sunday. We had a specific routine for him while we went to church. He’d stay in the backyard in his large kennel while we were gone. After not too long we’d wake up Sunday morning and he’d go straight to his kennel. :) In our case it was probably him sensing other things that only happened on Sundays. reply pilaf 9 hours agorootparentprevThat's amazing. Have you looked up whether this ability has been observed in other dogs? Do you think your Shiba is counting the days, or maybe there is something different about Thursdays (besides your family member visiting) that's giving him a hint? reply spike021 8 hours agorootparentMy Shiba knows his \"spots\" where he meets friends of his and what times we usually run into them. And when they miss those times he will lead us to their apartment because he knows which door they live behind. It's crazy. reply maxerickson 9 hours agorootparentprevCan maybe be something like a garbage truck. reply cj 9 hours agorootparentLucky guess! I take the garbage out on Thursdays :) I doubt the dog is actually keeping track of the days. Definitely picks up cues from my own behavior based on the day/schedule, like taking the garbage out. reply VHRanger 8 hours agorootparentprevIt's almost certainly something he does subtly different. The timing of making breakfast is different, or he cleans up more conscienciously, etc. Not that dogs can't figure out weekly rythms, but they're much better at spotting subtle precursor behaviors reply bongodongobob 13 hours agorootparentprevCool! Mine can hear my neighbors garage door open when they get home from work and goes nuts because his bestie is about to be let outside. Took me a while to figure that one out, haha. \"How the hell are you predicting when the neighbors dog gets let out??\" reply scott_w 2 hours agoparentprevSheepdogs are insanely bright. I have a border collie and she learns names by observation and deduction. My partner asked her where I was and she came running to me, despite never having put effort into teaching her my name. A couple of months later, a friend was at my door. I asked her “where’s Lucas?” to which she responded by looking at me and my partner before running to him. This behaviour has been observed, where a collie identified a new toy name by reasoning it was the only “new” thing so must be the thing being asked for! reply deergomoo 12 hours agoparentprevMy dog occasionally forgets our house has an upstairs. He's still a good boy though. reply RussianCow 12 hours agorootparentNice to meet you, fellow labrador owner! reply jjtheblunt 11 hours agoparentprevOur shetland sheepdog as kids was super smart (and funny as a consequence) in this huge vocabulary way too. Our current feral ancestry central american dog (dna tests call them village dogs, meaning not of a breeder created subset of the gene pool) is scary smart too. She’s probably got a HN account come to think of it. reply actionfromafar 10 hours agoparentprevI know a cocker spaniel who knows lots of such things - except tricks. Doesn't care much for tricks. But the little rascal observes and listenes keenly on everyone and everything around ... reply sophacles 15 hours agoparentprevA good friend of mine had an Aussie who was really smart. My friend was a dog trainer, and she once told me \"the secret is Grace (the dog) does most of it - the puppies learn better by watching her demonstrate, and she keeps them in line\". One day a mutual friend of ours died in a car wreck. I went to see my friend and we were sitting there telling stories and grieving... Grace read the room and brought my friend her favorite movie on dvd - something she watched when she was feeling blue. Grace wasn't quite sure what to do for me, but she brought me the cup I usually drank from when I was visiting. I don't know how much of that to attribute to smarts, training, and/or natural empathy, but that was an impressive dog, and its an impressive breed for sure! reply bongodongobob 15 hours agorootparentI believe it. Apparently that's how herding dogs train on farms. You just buy a puppy and it literally shadows the adult. They train themselves. reply RoyalHenOil 13 hours agorootparentI have two koolies (an Australian herding breed that is very closely related to Australian shepherds, border collies, and kelpies). I got my older dog during the lockdowns when I had a lot of free time to train him, and I got my younger dog a couple years later, when I had much less time to train her. The younger one has taught herself almost everything the older one knows, mostly by observing him, but sometimes by him actively trying to teach her. When she doesn't know something, he shows obvious signs of frustration and urging: I give a command, he does the thing I'm asking for, she doesn't react because she doesn't know the command, and then he starts growling and harumphing (and sometimes even air snaps near her face to get her attention) until she follows his lead. reply VHRanger 8 hours agorootparentprevHerding is a self rewarding behavior for herding breeds. You can train herding by simply stopping the herding when he messes up (negative punishment). As long as he does it correctly he keeps doing it (positive reinforcement). For my border collie it's similar in agility. He doesn't care about treats and barely needs toys - doing the agility is the reward for learning it for him reply adishy 7 hours agorootparentprevTransfer learning on (cute) biological neural nets! reply sokoloff 11 hours agoparentprevWe got our 3/4 poodle mix during Covid and remote work. To this day, he strongly associates me putting on jeans with \"we're about to go for a walk\" (which isn't entirely wrong, for sure). reply AuryGlenz 9 hours agorootparentI had a toy poodle growing up that would often know what I was going to do before I did. He also growled at my girlfriend for the only time around when she started cheating on me. Maybe coincidental, but it was the only time I ever recall him growling at anyone and he had known her for 2 years. reply lebean 7 hours agorootparentDogs have a keen sense of smell. reply strangattractor 4 hours agoparentprevI can't even learn the names of 10 people I met at a party:) reply bparsons 3 hours agoparentprevGood dog reply br3d 13 hours agoprevI think what's way more interesting is that dogs can master class inclusion: they can understand that this toy is \"Mr Shakey\" and this toy is \"Elephant\" but they can also understand that there is a superordinate category of \"toys\" that includes both Mr Shakey and Elephant, and when asked \"Go and get me a toy\" can choose either. This is mind-blowing, as children normally have to reach 7 or 8 before they have a solid grasp of class inclusion [0] 0 https://www.jstor.org/stable/1129264#:~:text=showing%20relat.... reply wosk 12 hours agoparentI did not read the paper, so I cannot comment on the \"solid grasp of class inclusion\", but regarding the capacity that you described in your comment, I have a 2-year-old and it's been a long while since she has mastered this (book vs this book, toy vs toy, fruit vs an apple and so on). As far as I know, most two year old have already acquired this concept. (EDIT I see the other comment says something similar and you have replied) reply AeroNotix 11 hours agorootparentI didn't even know \"class inclusion\" was a thing really. Though obviously the concept makes sense. My daughter had a solid grasp of it definitely around 16-18 months. She could easily talk about books or toys, cars, food, drinks etc. Not sure if this is unusual but 7-8 as the other poster mentioned sounds crazy late for that kind of conceptual understanding to appear. reply dotnet00 11 hours agorootparentYeah, it's not really convincing that it can typically take up to 7-8. By that age kids are already able to read, write and do basic math, which of course requires them to understand \"classes\" like numbers and letters, such that they could handle both \"write a number\" and \"write 23\". reply grimgrin 12 hours agoparentprevI did not know what class inclusion was, but now I'm thinking it's more complex than that? After a little bit of reading. \"all daisies are flowers\" and not \"all flowers are daisies\", this example seems more like the \"solid grasp\" you're referring to. And not basic categorization that a 3 year old might have: \"foods\", \"toys\" reply br3d 12 hours agorootparentHmm, I'm now struggling to remember basic developmental psych, but there's definitely a phase at which linguistic children struggle with things having two names (it can't be both \"dog\" and \"Rex\") but I think you're right - this phenomenon is subtly different to class inclusion. But either way, dogs can do something with language comprehension that speaking children can't, which is the bit I find really interesting reply AeroNotix 11 hours agorootparentI need to read up more on this because in my extremely small sample size this kind of dual naming understanding came in really early with my daughter. I feel like it's a linguistic subtlety that us adults are struggling with conveying the exact concept. reply djtango 9 hours agorootparentMy niece and nephew are being raised semi bilingually and they were happy to accept things could have multiple names before age 2 IIRC. The youngest only just turned 2.5 and can happily flick between Chinese and English (though has a bias towards English because that's what she hears more by a big margin) Will be interesting how my future kids will be as they will be pretty much exactly 50:50. reply eyelidlessness 9 hours agoparentprevThey can also be taught certain distinctions within a class after having recognized the class itself. For instance my pup picked up pretty early on that it’s big fun to chase birds. Where we lived at the time there were few crows (I honestly don’t recall seeing any), and when we moved to Seattle where crows are many she of course wanted to chase them too. But since I know that it’s better not to make crow enemies, I taught her not to chase them specifically. She now recognizes (usually) that crows are off limits, but still understands that other birds are generally fair game. (I don’t know if she’s also picked up on the fact that the crows recognize her too, but they definitely do.) reply buescher 9 hours agoparentprevI don't know if it's a solid grasp of abstract class inclusion so much as the concrete difference between \"let's play (with a toy)\" and \"go get this specific toy (which will prompt play)\" but yes, it's still impressive. reply AlbertCory 12 hours agoprevWhile Ernie is certainly smart, I've found one gap in his IQ: He has some favorite houses because the person who lives there gives him treats. Several times, we'll see that person on the street and then pass their house, and Ernie still gets excited. I tell him, \"Ernie, we just saw Jan. She can't possibly be in the house.\" He never listens. reply technothrasher 9 hours agoparentYeah, my pup gets very excited when my wife comes home and can even tell the sound of her car before she sees it. But... I can tell her, \"mom's home!\" and she'll get very excited and start running between the front and the back door, when \"mom\" is actually sitting right next to me in full view. On the other end of the intelligence scale, I've got a buddy with a pup who I once told to get a stick, which he dutifully did and when I said, \"no, not that stick, the one by the ball\" he quickly dropped it and went and got the one by the ball. You can also tell him which color ball to get and he will. reply Intralexical 5 hours agoparentprevAw. Associative memory. Well, the causality's misattributed, but humans do that all the time. reply bradley13 2 hours agoprevAnyone with a working breed dog - especially a herding dog like a border collie, kelpie, etc - will not be surprised. They can be scary smart. I've seen my wife teach our kelpie a new \"trick\" in just a minute or two. A few repetitions to attach a command to the action, and done. We can't even keep track of it all, but the dog will remember, even months later. N.B. Please realize that these dogs are not just pets. They need a job, or to be kept busy. Otherwise, they will invent a job, like dismantling your house. reply nyjah 8 hours agoprevMy German shepherd is 9 and tho I don’t think she could learn 100 different toys, it’s fun to be like “blue ball” and “go get a toy… no not that one” etc. Beyond learning that stuff, this dogs emotional radar is incredible. When she was younger if I was watching sports and something stupid would happen she would immediately comfort me and climb in my lap. And as she’s gotten older I don’t even have to say anything. If I am quiet deep in thought about something that is upsetting me, she knows it. Just beyond a sweet heart dog. Definitely seen articles about yawning in unison with dogs and that’s exactly me and her. She’s basically my shadow. I’m convinced she can hear my heart beat and listens to my breathing. It’s always funny to reach for the tv remote and she’s getting up because that’s become a cue. Dogs have a lot of those. reply _whiteCaps_ 15 hours agoprevI surprised that poodles were called out as a less obvious smart dog. My dog learned on her own that me holding keys + wearing glasses = car ride, while keys + no glasses = walk. It took me a while to learn how she knew what we were going to do. reply knodi123 15 hours agoparentMy dog recognizes different cars by their noise profile. So he'll wake up from a nap and get excited whenever my wife pulls onto our street, but stay down for any other car. It probably helps that we're the only prius on the block, but still impressive! reply ta8645 12 hours agorootparentI heard about a test someone did, after wondering how their dog was always standing in the window at the end of each workday, anticipating their owners arrival home. After casting about, a theory was developed that the dog \"smelled time\". That is, as the day wore on, the scent of their owner, decreased in the air; at a low-enough concentration, the dog knew it was about time for the front door to open and their owner to arrive home. To prove the theory, someone went to the owner's work at noon-time, and gave him a new shirt, collecting the one he'd been wearing for half a day. They took that worn shirt, and swirled it through the air back at the house; recharging the owner's scent in the air. The dog was asleep and away from the front door, and surprised when its owner arrived home at the normal time. reply bbarnett 11 hours agorootparentCertainly interesting enough to do another test, but instead without another human entering the house. Maybe a sealed box that opens to vent the scent. You'd need to have the same box do the same, with no scent too. reply LandR 14 hours agorootparentprevMy parents dog knows where she is going in the car. On the way to the beach where she goes for her runs there are 3 rumble strips on the road, she always starts getting excited as soon as the car goes over them. Even though she's probably still 6-8 miles from beach! They also take her to a local pub that is dog friendly and she has friends there. She knows when she is going there as she starts getting excited when the car turns right at a certain roundabout. Go left or straight on, nothing, but turn right and she's right up all excited! reply RussianCow 11 hours agorootparentMy dog is like this. She knows (without looking out the window) when we are close to home or some other exciting places, and I can only imagine that she has memorized the turns we take to get to those destinations. It blows my mind because there are no obvious indications, and I highly doubt I would pick up on them if blindfolded in the car. reply lostlogin 14 hours agorootparentprevEVs have a high pitched whine and our dog can hear the car from a long way out. reply alamortsubite 15 hours agorootparentprevOur last cat did this, too (though in our case the car was a Mazda 3). It took me a while to realize what was going on. reply _whiteCaps_ 15 hours agorootparentprevOh yeah, had some dogs like that when I was a teenager. They could recognize my Firebird from a few blocks away. :-) reply 1letterunixname 13 hours agorootparentprevYep, mine does too. Their hearing is amazing. reply tlavoie 15 hours agoparentprevOur dogs are also also very good at picking up other cues. Not only can we not say \"walk,\" but the \"well...\" as in, \"well, time to take the dogs\" gets the same reaction now. Our SPCA-special (shepherd / husky / other?) learned after _one_ event that the tub running with the bathroom door open means that it's bath-time, and time to head out through the pet flap to the safety of the outdoors. reply bentcorner 11 hours agorootparentThis is not a difficult task but my dog absolutely recognizes the various ways I end meetings during work or discord chats while gaming and always starts bothering me for pets when I'm done. reply eyelidlessness 7 hours agorootparentMy pup knows that when I say “thank you” in a certain tone of voice that it’s nearing the end of a meeting. She’ll wait patiently the whole time until I say it, then perk up. And she gets annoyed when anything prolongs the meeting after that signal, and start getting restless because she knows the meeting should be over. reply telman17 4 hours agorootparentMy dog does this too! reply alamortsubite 15 hours agoparentprevIt's a bit weird, but I think our animals spend far more time observing us than we realize. reply galenlynch 11 hours agoparentprevI interpreted that sentence to mean poodles were a less obvious working dog: \"Yet almost all gifted word learners are working breeds. Those include the obvious breeds such as … but also less obvious ones such as poodles\" reply fumeux_fume 1 hour agoparentprevYeah, that’s not that impressive. reply drcongo 15 hours agoparentprevI love this kind of cause and effect linking that dogs do - mine has noticed that I often go in the downstairs restroom before walkies and now I regularly find her sitting expectantly on the bottom of the stairs when I come out. She only seems to be able to remember about 4 words though. reply TaylorAlexander 15 hours agoparentprevCurious how you determined what she had determined. reply bongodongobob 15 hours agorootparentFor mine, when I have my keys he runs right to the car. Without them, he'll run past to the sidewalk. If I grab my keys and laptop (to go to work) he'll walk away and lay down. reply _whiteCaps_ 15 hours agorootparentprevShe hates car rides, so she'd run and hide when she saw me with glasses on. I finally clued in the day I forgot to put my glasses on before going to the car, and she was happy to go outside. reply 1letterunixname 13 hours agoparentprevMy first dog was a ¾ poodle ¼ cocker spaniel. She knew where the car was going; anticipated events from objects including leashes, combs, toys, and food; and deduced ever changing codewords for activities before moving a muscle. reply 11235813213455 13 hours agoprevI spend lot of time watching birds, and they are really having complex conversations, definitely more than 100 \"words\" too. And we can say the same about ants, (it's more chemical/touch communication). Basically all animals are smart reply whatindaheck 8 hours agoparent> Basically all animals are smart I think it would do us all good to remind ourselves of this more. It’s not humans vs. animals. We’ve all survived billions of years of evolution / natural selection. Even in “dumb” animals there is a bar present that got them this far. reply hannasm 6 hours agoprevHumanity has a choice about whether to help these intelligent animals reproduce more than the dumb ones. We've already taken over a great deal of the free will of every animal on the planet but especially domesticated animals. Developing the genetics of additional intelligent beings on this planet is entirely within our capability if we want to invest lives. The advent of dogs from wolves in, iirc, about 50 years is a testament to Darwinian ideas. Reducing our planet to a desert wasteland is also an option. I'm a huge dog lover but it would be fantastic if we could find ways to coexist with more species in the long term as well. Given our own, still somewhat precarious existence, bringing up other species is of limited priority. Take care of your pets and buy your zoo memberships at least reply whatsakandr 15 hours agoprevIf you haven't seen \"What About Bunny\" on YouTube, I highly recommend it. The dog has learned to use buttons to communicate her thoughts quite effectively. My favorite is \"Why bunny dog?\" reply kelvie 15 hours agoparentThere's a massive sampling and confirmation bias with Bunny, though admittedly as a sheepdog owner the videos are very cute. Whenever I talk to e.g. coworkers about an impressive ML demo that was sped up and pre-recorded, I point to Bunny the dog to show how impressive a talking dog is. reply araes 13 hours agoparentprevThe huskies Mishka and K'eyush have also been pretty popular over the last years. Videos of 10M+ upvotes, so obviously somebody's been watching. A lot are kind of painfully viewing owners poke their canines for likes, yet there are a few that are rather clear human language use such as Miska singing \"Jingle Bells\". Very obvious human word use and response to human communication for a task. Youtube, Mishka, https://www.youtube.com/watch?v=HtDFxm4Wupo&t=84s reply madeofpalk 8 hours agoparentprevHaving seen Bunny for a few years on social media, I'm not convinced. reply cal85 15 hours agoparentprevI just watched a few videos and it’s seems obvious it’s all down to cherry picking and confirmation bias on the part of the owner. I’ve no doubt the owner believes the dog is deliberately constructing sentences, but that isn’t what’s happening. reply ksenzee 12 hours agorootparentThere are some where I think you’re right, and some where there is pretty clearly some genuine communication going on. You might want to watch a few more. reply observationist 9 hours agorootparentprevIt's very clear that language use is occurring. A recent video shows the owner on the phone with the vet, and when she says \"come in to express the anal glands\" Bunny immediately gets up and uses the \"no\" button. Another dog, while its owner is blowdrying her hair, presses the \"wet\" and then \"dry\" buttons. Otter, Bunny's brother dog, learns the context of words from her, and they use words to each other, with clear, contextual meaning. They express humor, sadness, anger, frustration, empathy, caring, happiness, apathy, excitement, and more. Their grammar is limited, the processing they can do is slower and on a smaller scope than humans. They definitely lack the breadth and depth of human cognition, but I can't understand how, given the overwhelming evidence of deliberate use of language in complex, nuanced, abstract, emotional, contextually relevant ways, people insist that \"well that's not what they're doing!\" I think it's very likely that any and every mammal with a brain above a certain size will be able to use language, given the appropriate tools for it. People are quick to point out the story of Clever Hans, but I think that story is worth revisiting. There's a very powerful bias for people to hold humans above other animals as somehow intrinsically special, fundamentally different from all other creatures, and language use being somehow unique to humanity seems to be one of the most stubbornly held beliefs. I think we have language because we have vocal cords, complex mouths, opposable thumbs, fingers, and very large primate brains with a proportionally massive neocortex. Take away the hands and we lose tool use, and probably can't develop culture, and so never develop language or complex vocalization, and never garner the benefits of those things. Take away culture and you have humans living in feral conditions. Modern studies of language deprivation, children raised in feral conditions, and other situations show us that it looks like some humans lose the ability to learn language past a certain age under those conditions. Take away the effective mouth and vocal cords of human biology, and we may never have developed spoken language, but would likely have developed signing and nonvocal audible communication methods, and then developed culture around that. So knowing that, when you take another look at the talking dogs with buttons, it's worth considering that up until a few years ago, people had essentially raised their pets in the absence of culture. No efforts were made to teach them language in the context they'd be able to handle. They didn't have tools that served as vocalization, limiting their effective vocabulary to bark, howl, sneeze, and whimper. Some dogs, through care and exposure, were seen as exceptional if they picked up words through context and repetition, like toy names and so forth. If a standardized vocabulary was made available, with a repeatable training framework for dogs and cats, we give them what amounts to a culture prosthetic, and buttons give them a replacement for mouths and vocal cords. It shouldn't be unreasonable or even particularly shocking to consider animals with brains similar to our own being capable of language use. Imagine the conversations you could have with an orca trained to use buttons, or a pig, cow, bear, lion, or whatever your favorite mammal is. I think we need to be much more open minded, not overly skeptical, and stop trying to find ways of insisting on human exceptionalism. It might help us learn more about how language and cognition work, and what it is about human brains that gives us such an apparent edge. Or maybe that edge isn't as significant as we think? reply tigerlily 15 hours agoparentprevYes! And the one about the stranger in the paw (my memory is sketchy on the exact words). Mindblowing. reply treflop 16 hours agoprevI know I've seen videos of animals where I thought \"damn, this one must be above the bell curve.\" And you know, there are individual humans vastly smarter than us so I figure there gotta be the same in the animal kingdom too. reply ahazred8ta 12 hours agoparentCanadian author Spider Robinson had a cat that spontaneously used a tool. The cat selected a narrow wedge shaped piece from a woodpile, carried it to the other side of the house, jammed the small end into a door crack, and levered open a locked bathroom door. reply seunosewa 12 hours agoparentprevAnd you can legally breed them. reply h2odragon 8 hours agorootparentIntelligence doesn't pass reliably. You may be slightly more likely to get one smart pup in a litter from smart parents. Any given litter is likely to show the standard range of variation for the breeds. It's my observation that lots of people have dogs who are smarter than the person appreciates. People don't listen to their dogs, they just talk at them. reply msrenee 6 hours agorootparentI'd say it passes reliably enough that some breeds are smarter than others. Over generations, I see no reason you wouldn't be able to consistently breed intelligent dogs. reply throwaway98797 10 hours agorootparentprevlegally really changes the vibe of your comment reply leot 15 hours agoprevIt's unclear why the researchers believe that when a dog doesn't learn the names of a bunch of toys it means that they can't. There are lots of things people are able to learn today that they \"couldn't\" a few years ago (programming, math, reading). How are the researchers able to tell that the limitation lies with the dog and not with the trainer/household? reply swatcoder 15 hours agoparentIndeed! The article talks about some kind of rare \"genius\" trait, but the findings just seem to demonstrate that there exists some dogs that were able to demonstrate a big vocabulary in their tests. Many people with dogs already knew that, but it's a sound finding to have citable anyway (especially since some people still hold weirdly dismissive beliefs about everyday animal intelligence). But it doesn't say anything scientific about whether this is an inherent trait rather than a contextual outcome, what the frequency of any such trait might be, whether the dogs that failed the tests were incapable rather than indifferent, etc. Of course, the exact same pattern of ovverstatement shows up in human behavioral and psychological research, so we shouldn't be surprised to see it here :) reply detourdog 15 hours agorootparentI agree just like any learning it involves engagement of some type> reply UniverseHacker 16 hours agoprevI adopted an older obese dog many years ago that seemed to understand hundreds of words, including the brand names of junk food. He would listen closely to human conversations. For example if someone mentioned socks, shoes, leash, walk or synonyms of those he would immediately go wait by the door for a walk. reply silverquiet 15 hours agoparentDogs can pick up on a lot of human things that aren't spoken; they're actually very good at body language. That and their ability to eat starch/more omnivorous diets are probably the biggest differences between them and wolves. reply InitialLastName 13 hours agorootparentI once visited a wolf rescue where a wolf pup was being raised in a pen with two Great Pyrenees puppies (to socialize it with them). The biggest behavioral difference I noticed between the two was that while the wolf was willing to be (and perhaps even enjoyed being) pet and handled, it absolutely did not care that we were in the pen. It wandered off after a few moments checking out the new visitors, whereas the puppies (being puppies) wouldn't leave us alone. reply Loughla 12 hours agorootparentThere is nothing in this world like a Great Pyrenees puppy at about 8 months. They're SO big, but SO dumb and cuddly. They're the perfect thing, and the embodiment of joy. reply thebeardisred 12 hours agoprevI'm a little disappointed that there is not a single mention of Psychologist John W. Pilley (https://en.wikipedia.org/wiki/John_W._Pilley) nor Chaser the Border Collie (https://en.wikipedia.org/wiki/Chaser_(dog)). Pilley did an extensive amount of work including teaching Chaser over 1000 nouns. This was repeatedly verified in trials. https://www.youtube.com/watch?v=tGlUZWNjxPA https://www.nytimes.com/2019/07/27/science/chaser-border-col... https://www.akc.org/expert-advice/news/remembering-chaser-th... edit: Added another link to the AKC article on Chaser. reply AlbertCory 12 hours agoparent> a little disappointed that's putting it mildly. It's hard to believe SciAm could even publish this. Neil deGrasse Tyson went on TV with Chaser and his owner. He tested Chaser by putting an unnamed toy in the pile, and then said \"go get Darwin.\" (\"Darwin\" being an unused name) Chaser successfully figured out it must be the toy whose name he didn't know. reply soperj 16 hours agoprevThey should breed them... I'm sure we could select for language geniuses. reply whatsakandr 15 hours agoparentThat's a new breed I could support. Just throw together a bunch of different breeds of smart dogs. They'll be much mror healthy than most breeds of dog. reply spike021 13 hours agorootparentOn the other hand, smart dogs can be much more difficult to train. They can easily pick up what you're training them to do, but when you want them to actually do it the results can be far more mixed. This is because they're so smart that they seem to know whether doing the thing they were trained to do is worth it to them. Source: I have a Shiba Inu, which is simultaneously one of the smartest and most primitive of dog breeds. From the beginning he picked up tricks and other training extremely quickly, usually within a handful of repetitions. But he can be very independent and stubborn. He seems to know whether something is worth doing or not. Almost.....too smart. reply cj 12 hours agorootparent> whether doing the thing they were trained to do is worth it to them. Also have a Shiba and 100% observe the same. I recently thought that he forgot certain commands, until I went on a trip and boarded him (which he hates), and the day I get back he's super excited and suddenly \"remembers\" how to do everything I thought he forgot how to do. Quirks like this is why I definitely don't recommend them as a first dog. They are great dogs but aren't the easiest breed to train. reply ozim 12 hours agorootparentprevSame with my dog, it is a mixed breed and intelligent enough to learn quickly, but also intelligent enough to have \"you want me to sit, out of the blue? nah I don't care\". So we had to build loads of trust with it. Now it trusts me and my partner that if we ask it to do stuff we mean it and there is some reason for the behavior like watch out for a stranger or other dog or it something interesting will follow. reply eyelidlessness 7 hours agorootparentprevMy pup is similarly discerning and stubborn in deciding whether or when to obey certain commands, but I appreciate it most of the time. In many cases it’s part of how she communicates her emotional state, and it helps me understand her better. reply sandworm101 15 hours agorootparentprevBut creating any new breed, as in an actual breed rather than crossing mutts that will produce a variety of offspring, usually involved significant inbreeding. You need to weed out the genes that you don't want and concentrate on the few that define the breed in order to create a homogenous stock. Otherwise, in a couple generations the new offspring may pick start expressing the recessive genes and be nothing like the originals. reply VHRanger 8 hours agorootparentprevThat's basically border collies reply bongodongobob 15 hours agorootparentprevAfaik working breeds are the smartest and are already the most genetically diverse. Not sure if correlation or causation though. reply VHRanger 8 hours agorootparentCorrect - border collies are what he described. When kennel clubs formed in the late 19th century to standardize breeds, the border collie stood apart by only testing for herding ability and not selecting on anything else. Other breeds were selected mainly for looking like what that breed looks like. Turns out border collies are consistently classed the smartest dogs. They also have less of the typical genetic issues other breeds have reply w0de0 15 hours agoparentprevThe article suggests that we already have, as all of the found clever dogs are (at least part) a (formerly) working breed. One suspects nurture has a significant role, though, as it also does with human language development. Were we actually to pursue a program like this we’d need also and perhaps more importantly research dog pedagogy (skylogogy? dogagogy?). reply GeoAtreides 11 hours agoparentprevhm, is it ethical to breed for sapience? It's interesting how literally building a new sapient being (i.e. AGI) _might_ be widely accepted and uncontroversial, yet the idea of selectively breeding dogs until they reach sapience feels wrong and yucky reply WalterBright 2 hours agoprevPeople have bred dogs for all kinds of attributes. Why not breed dogs for language skill? reply airbreather 16 hours agoprevI have owned six dogs in my life, most recently getting a 7 week old pup staffy x ridgeback, now 16 weeks old. He goes with our 9 year old girl staffy, who can follow conversations, eg planning to go to the park or beach without directly mentioning it in any way. All my dogs have understood a lot of words, some more than others, but all way more than 20. The aspects that promote this, I believe, are this: 1. They are treated as companion animals. They live in the house with the humans and generally have full access thru the house. 2. No crating. Maybe if it is some kind of working dog, but a companion animal is a companion, and would you put a companion in a crate 22 hours a day? I don't care if you think that a dog comes to like the crate, I would say don't confuse familiarity with liking it. In what evolutionary precept is crating a thing that ever had any parallel in the wild? 3. You talk to the dog, like it is a human that can't speak. You tell it what you are doing using consistent language. Example, when leaving the house, we tell the dogs what we are doing and how long we will be. eg I am taking J to school, I'll be back soon. Or, I am going to work. Very quickly they learn and know what to expect and anxiety is reduced. I can tell because if I say I'm going to work, they immediately head to their favourite long term day resting spots.if I say I am going to the shops, they know I will be 30-90 minutes and there is a chance I will be returning with treats and hang around the door. Also just a few times now and then, especially early on, the dog will come with me to, say, drop the child at school, or visit work, so they can see where we go and understand a little better what goes on. Having the dogs live with as part of the family means sometimes there are problems, eg our pup is currently teething and just can't help himself with items of certain texture. We keep important things out of reach, close bedroom doors when not home and use mistakes a chance to teach. The older dog has never once got into the bin or any other such misdemeanours when unsupervised at home. I see a lot of people ignore their dogs most of the time, I wouldn't expect such dogs to have strong language skills, but try might. If they are around and a wake, ours are constantly talked to, just telling them what we are doing or what is going on. They learn to associate, often quite quickly. Also many owners seem to make little effort for language consistency, outside of obedience commands like sit etc. Living in the house, it's important the dogs are consistently treated in accordance with their position in the pack. What many people think is being kind, is people kind and dog mean. A dog is happiest when it knows its place. The happiness is not related to the level of that place, more the consistency of treatment. A dog confused about its place might instinctively feel the need to challenge for leadership of the pack, that's when people get eaten. If your dog is looking stressed and uncertain of its place, by challenging you in little ways, you need to do the little things to reinforce its position eg it does not go thru the door before you, it does not eat before you. Maybe you eat and leave a very small amount if food on your plate, which you then give the dog.you admonish any challenge for control, not meanly, but firmly.grasping the muzzle with your hand, not hard, can be enough. When just weeks old, that is what the mother does with her mouth, it is a powerful gesture ingrained almost instinctively. Pampering a dog is being mean to a dog, treats should be earned not given randomly, that is just confusing. Just like people, dogs behave the way you treat them. I learned from an ex military dog trainer who went way further in his work training, but those were special animals trained to cope with crowds etc and in that environment might be called upon to save someone's life one day. But many of the techniques used would shock most people, but make perfect sense when considered in the context of training a pack animal to be a working animal. reply kemayo 13 hours agoparentThe argument I've seen made for crating from an evolutionary-history perspective is that dogs are den animals -- they actively like having a small nook that they can feel safe in, where they're comfortable and nothing can sneak up on them. I have a crate for my dog. The door stays open all the time, it has a comfy mat on its floor, and sometimes he goes there to take a nap. He's only ever shut in it when there's a reason -- a contractor in the house, or I need to keep the front door propped open for a while, or similar. (When he was a puppy it was incredibly useful, though, because it was a way to teach him to settle down.) reply dboreham 10 hours agorootparentCats like boxes. reply rufus_foreman 10 hours agorootparentDoesn't even need to be an actual box. You can just draw a slightly larger than cat sized square on the floor with masking tape. reply detourdog 15 hours agoparentprevInteresting my dogs have had the same lifestyle. My current dog I'm sure is a genius but we let him be a dog. He has an amazing vocabulary and after watching a Nova show regarding dog language we performed similar tests on him and he was able to complete the tasks. He is a good boy. reply everly 14 hours agoparentprevWhile I fully agree with you that crating is to be avoided and I'd never do it - I can see some evolutionary parallel. My husky loves to settle in corners/L-shapes, and a crate is not so different than a small cave/den which offers certainty that no predator can sneak up behind you. reply dj_mc_merlin 15 hours agoparentprevWow, amazing rundown. I have a friend who is a dog trainer and she's explained a lot of these things to me before but you've made them click. reply at_a_remove 14 hours agoparentprevI've always tied \"orders\" to a specific gesture, performed simultaneously, and I use a specific intonation, a \"command voice.\" It comes from a different place in the chest, is lower, and is easier to precisely reproduce than my usual wittering on. reply iskander 12 hours agoprevMy dog seems to know least the names of 6 family members, 4 friends, and names of ~6-7 other dogs (in that she can go to those individuals on command). She also knows: cat, dog, cow, horse, friend, hello, \"dai lapu\" (Russian for give me your paw), \"sidi\" (Russian for sit), sneak, \"bang\" (for playing dead), dinner, breakfast, bath, outside, \"go potties\", and probably quite a few other snippets of English. She also knows how to open windows in a car and looks for the buttons before pressing them with her paw. reply Scubabear68 13 hours agoprevThe amazing thing to me about dogs is the tremendous range of variability we have bred into them. Size, shape, color, intelligence, basic body makeup, senses, hunting instincts, even average life span vary by an astonishing amount. And sadly, of course, the selective breeding has also caused systematic weaknesses in some breeds (prone to bad hips, knee injuries, relatively short life span, etc). The genie is out of the bottle but I wish we could breed healthier animals. reply llamaLord 12 hours agoparentJust a quick note on this, it's not entirely appropriate to blame selective breeding \"in general\" for those issues. Quite often those issues come from specific selective breeding practises designed to make the dogs more \"fashionable\" by breeding specific aesthetic attributes over healthy dogs. That being said, there is an enormous community of extremely passionate breeders around the world who are absolutely dedicated to breeding HEALTHIER dogs, especially in breeds that are known to have issues due to poor breeding. We have a Boston Terrier we got from one such breeder after spending over two years looking for someone we trusted to do the process right, and we are so happy we did. Not only do we have an amazing pet, but we know we are activity contributing to the process of improving the overall health of the breed, even though it did cost us more to do. A few things to look for in order to pick a \"good\" breeder. 1. How many litters do each of their female dogs have over their lives. If a breeder is expecting them to produce more than two (three at the most) litters, that's a red flag. 2. Do the mums deliver naturally, or via C-section. We only learned through extensive research that some breeds (often including Boston's) almost all have to give birth via C-section because they've been so extremely bread. We specifically looked for a breeder who's dogs a born naturally. If the pups are so extreme in your they've been bread that the mum can't get them out naturally... Something has gone too far. 3. Is the breeder a \"purist\" when it comes to the breed. Now this is going to be the opposite of what most people expect, but you WANT a breeder who is 1930's levels eugenicist when it comes to their breed. Fundamentally, most of the issues from breeding come about through mongrelisation of the breed. Low quality breeders cross-breed dogs to introduce \"cool\" or \"fashionable\" new traits, without caring about the million other genetic inconsistencies they're bringing into the mix at the same time. A great example is with Boston Terriers we learned. The breed spec for them is VERY clear, they have a white base coat with a black or extremely dark brown \"tuxedo\" style coat covering their lower body and a portion of their front-legs. ANYTHING that has colours other than those three, is a cross-breed for fashion purposes. There is no such thing as an \"albino Boston\", or a \"patterned Boston\" etc etc, these are marketing names people came up with for mongrelised versions of the breed which will almost always have major health issues. reply gecko6 6 hours agorootparentI am a dog breeder, and I endorse this message :-) reply fumeux_fume 5 hours agoprevJust adopted a very sweet Irish Wolfhound mix. She's as dumb as bricks or just has no desire to impress us with any display of intelligence. I would be floored if she was able to produce any toy on command let alone a specific one, lol. reply tedpetershn 5 hours agoprevMy daughter taught her Australian Shepherd to make Sushi... https://www.instagram.com/p/C3jX6nzu5Ce/ reply shireboy 7 hours agoprevWe had a Westie that we trained to do this. We’d make him “wait” then we’d his toy, and say “ok go find it” . He’d go all over looking for it and enjoyed the game. I highly recommend a community training camp if there is one in your area. reply hackeraccount 15 hours agoprevI've always thought my Grandmother's dog was a genius. It wasn't that the dog knew a lot of things - it was house trained of course, it would sit, fetch, heel and the biggest trouble I ever remember it getting into was scratching the bottom of door. That said I swear it figured out all of that stuff on its own because I'm pretty no one in the house invested 5 minutes trying to train that dog to do anything. I honestly think it just wanted to be a good dog. I would almost say the dog was mistreated because benign neglect is almost cruel to a dog but it wasn't that bad, the dog wasn't ignored, it just didn't get a chance to really shine. Poor muffin. reply iancmceachern 6 hours agoprevWe have poodles, always have, they know amazing things, words, behaviors, when somethings \"up\", how to manipulate us. Love reading everyone else's anecdotes. reply tguvot 2 hours agoparenthave two standards. both smart but in a different ways. one totally understands your intentions. the other one is \"street smart\" and tries to manipulate us reply tmnvix 7 hours agoprevI do wonder if dogs recognise when other dogs are particularly intelligent/unintelligent. Given that there seems to be such wide variation amongst breeds, I'd assume so. reply motohagiography 11 hours agoprevIf dogs are smarter than we knew, what are some additional tasks we could give them? I have manuals for disability support dog training (opening doors, getting medications, helping to dress, etc) but maybe we could teach them to: - clean or arrange rooms or outdoor spaces - find and pile firewood - collect litter - convey messages to named people What else? reply doubled112 11 hours agoparentThere's something very human about \"hey, this thing is smart, better put it to work for us\" reply dotnet00 10 hours agorootparentTo be fair, we wouldn't have domesticated dogs if they weren't smart enough to work for us as hunting/herding assistants. reply carapace 10 hours agorootparentprevPeople who live near orangutans say that they can talk but don't do it in front of humans because they don't want to be made to work. reply a_gnostic 14 hours agoprevMy buddy swears his one year old kitten understands how to turn on the A/C, but lacks the opposable thumbs to do it effectively. reply sandworm101 15 hours agoprevMemorizing 100 names for things might seem like a big deal, but I guarantee that all dogs have memory for 100+ smells associated with things. They would call us stupid for not being able to remember the smell of more than a few dozen objects. My point: don't judge intelligence based on how well an animal can replicate human behavior. Each of them can do things that make us look like the idiots. reply dj_mc_merlin 15 hours agoparent> They would call us stupid for not being able to remember the smell of more than a few dozen objects. Dogs obviously have incredibly more advanced olfactory systems but I feel like you're downplaying humans here. I'm pretty sure there's hundreds of very specific smells I could identify pretty well. Smell of home, pencil rubbers, chalk clouds, rotten bananas, denim.. things do have quite specific smells and there's a lot of things. reply BytesAndGears 15 hours agorootparentPlus the whole feeling of “I just smelled this thing and it reminds me of my aunt’s house, who died 35 years ago”. I think it’s pretty established that humans are very good with smell. We just aren’t very sensitive compared to dogs reply aqfamnzc 12 hours agorootparentI recently started swimming for fitness after not doing so since 10 years ago in high school. I get a rush of nostalgia and a good feeling whenever I catch a whiff of chlorine on my hands or hair throughout the day. reply sandworm101 13 hours agorootparentprev>> I could identify pretty well. Smell of home, pencil rubbers, chalk clouds, rotten bananas, denim.. things do have quite specific smells Those are classes of things, not specific objects. We all know the smell of erasers, but can we identify the smell of a specific eraser? Part of it is sensitivity but it is also largely that our brains are not designed to associate smells with individual objects. Think of how we handle faces, which we can spot even if at a different orientation than we have seen before. Or how we can hear a specific voice amongst a crowd. Dogs do that with scent profiles. reply dj_mc_merlin 13 hours agorootparentThis is a really good way to frame it that would indeed mean we only remember dozens of individual things, if that. The smell of home remains, as well as the smells of close relatives.. but I can't think of much else. reply ProfessorLayton 12 hours agorootparentprevNot sure how to word this without getting too weird, but It's certainly possible to identify well over a dozen people by smell alone — not just friends/family that one spends a lot of time with, but also attractive people. reply thfuran 14 hours agorootparentprevThe ability to remember specific sensory impressions just is not the same thing as sensory acuity. People can remember a bunch of things, but our noses aren't nearly as sensitive as dogs'. reply tapland 14 hours agorootparentprevJust yesterday i experienced the smell that was just like the apples from a tree in our yard 25 years ago. There are easily many hundreds of unique smells we can identify. reply araes 13 hours agoparentprevA quick search to WP Dog Intelligence [1] will quickly note that there have been cases of 1,000 words and this is actually fairly well known. It's perhaps interesting that researches are confirming anecdotal reports online, although as noted in another comment below, there are 10M+ videos from multiple channels all on the same subject. I donno, it's like humans are just realizing animals might not be that less intelligent. Parrots ask existential questions. Prior research on dog language: \"2008, Betsy, a Border Collie, knew over 345 words by the retrieval test, and she was also able to connect an object with a photographic image of the object, despite having seen neither before.\" (mentioned in article) \"Rico initially knew the labels of over 200 items [and] inferred the names of novel items by exclusion\" \"2013, a Border Collie, \"Chaser\", who had learned the names and could associate by verbal command over 1,000 words[...], and [was] capable of linking nouns to verbs\" [1] https://en.wikipedia.org/wiki/Dog_intelligence#Learning_and_... reply ghshephard 15 hours agoparentprevThis was an interesting article: https://www.smithsonianmag.com/science-nature/you-actually-s... \"According to McGann, our olfactory inferiority is nothing but a 150-year-old myth born of erroneous assumptions and faulty science.\" reply fnordpiglet 14 hours agorootparentWhy do we have K9 search and rescue dogs and drug sniffers instead of just having police officers sniffing everyone’s luggage? The answer from the article is, essentially, because dogs are much better at odor detection than us. It weirdly seems to say because we have the ability to sense odors we are better than we think we are, which implies we think we can’t smell at all or something. But dogs are much much better than us. reply ghshephard 11 hours agorootparentThe article made a quite different argument than \"dogs are much better at odor detection than us\" - that is contrary to what the research shows. Humans have much better ability to smell some things than dogs do, but, dogs are (as you noted) capable of smelling some things better than humans. reply fnordpiglet 11 hours agorootparentThey make some squinty suppositions from some limited studies that suggest dogs (which can smell cannabis flowers) can’t smell flowers better humans etc. But then they conclude with this statement that sort of refutes the entire premise: “”” Besides having more olfactory receptor cells than humans, dogs also boast a specialized snout adapted to methods of breathing that deliver a steadier stream of information-rich scent. Dogs and some other animals even experience scent differently. Their olfactory system allows them to smell liquid phase chemicals that aren't airborne—think of layers of urine and other liquids on your neighborhood fire hydrant—by working like a pump to deliver them to a specialized nasal organ. “”” Which is pretty indicative that as everyone knows from daily experience with dogs, dogs are better at smelling things than humans. There may be a range over which that superiority falters at some chemicals but I saw nothing other than headlines and pop science supposition that indicates humans are superior at smelling than dogs. reply ghshephard 5 hours agorootparentThis seemed pretty conclusive science: ```For example, Laska notes, the total number of odorants for which dogs have an established, lowest detectable threshold level is 15. Humans actually have a lower threshold for five of those. “Those five odorants are components of fruit or flower odors,” he says. “For a carnivore like a dog those odorants are behaviorally not as relevant, so there was no evolutionary pressure to make a dog's nose extremely sensitive to fruit and flower odors.”``` reply nicklecompte 15 hours agoparentprevIt wasn't clear to me from this that these dogs had any special cognitive abilities, as opposed to neurosensory abilities, e.g. maybe most dogs can't audibly distinguish human vowels and consonants well enough for this to work. reply RoyalHenOil 13 hours agorootparentI wonder this as well. In my experience, dogs have a MUCH easier time learning hand signals than learning verbal cues. I wonder if dogs would generally be capable of learning many more words if they were taught in sign language. reply newman8r 15 hours agoparentprevBirds are able to do it as well, this popular bird on youtube seems to know at least that many words https://www.youtube.com/@ApolloandFrens reply pazimzadeh 15 hours agoparentprevWho can't remember the smell of more than a few dozen objects? reply sandworm101 13 hours agorootparentWe remember scents. We remember how chocolate smells. We do not smell well enough to associate smell with a particular object. Then, in turn, our brains are not hardwired to associate specific smells to specific objects. Look at our memory for faces. It isn't all about eyesight. Our brains have specific circuitry for faces. Dogs have the same for smell. Sensitivity is one thing, how the brain is wired is another. reply PaulDavisThe1st 10 hours agorootparent> We remember how chocolate smells. I rememeber: * how English Cadbury's smells * how El Rey Cordoba milk chocolate (from Venezuela) smells * how Hershey's smells * how hot chocolate made with Swiss Miss mix smells * how Toblerone smells I could go on. reply newman8r 10 hours agorootparentAlthough in a blind smell test, I wonder how well would you do? I've seen people fail hard at identifying what food their eating when blindfolded, and they have the additional power of taste rather than just smell. We're wired to be able to pull up those memories and imagine a smell, but not to be able to identify what we're smelling when it's right in front of us. reply pazimzadeh 5 hours agorootparentI would do really well. Especially for Hershey's which I can detect from across the room thanks to that distinctive baby vomit smell from butyric acid they use as a preservative. reply robocat 12 hours agorootparentprev> Then, in turn, our brains are not hardwired to associate specific smells to specific objects. I think you are speculating cause. Culturally we tend not to communicate much about smells - it could just as easily be that most of us have the ability but it is never trained because it isn't much use to us. Anecdotally I know people with a wide range of different olfactory abilities. It is interesting to try and think of how we could test for the ability. Perhaps not testing for my pencil, but something else - a child - a dog - shoes - urine. reply pazimzadeh 5 hours agorootparentprevNo offense but by 'we' I think you mean you reply kevinmchugh 15 hours agorootparentprevYeah, and humans can identify different hops or chocolate or coffee beans by smell. We can't track very well but still have pretty sophisticated noses reply samatman 14 hours agoparentprevWhile it is of course true that humans can smell less acutely than dogs, I'm fairly confident that the number of odors I can remember is somewhere in the low thousands. reply xeonmc 15 hours agoparentprevWhat do you mean fish are not stupid for being unable to climb trees? reply rashkov 15 hours agoparentprevI wonder if something like synesthesia could help them map language to smells reply oooyay 14 hours agoprevMy greyhound/pit mix knows my names of many of her toys. She also has a range of expressions she uses to disagree with me or tell me I'm wrong. Her favorite toy is this kevlar llama unicorn that my mother has resewn for her twice. If I tell her to bring me her lobster (also kevlar) sometimes she'll shake her head, bow, and then stare intently at me. She understands the prompt for, \"What is it?\" and will lead me to the thing she wants or fetch it. On multiple occasions she's brought me her llama instead. I thought this was a fluke for a while but if I argue with her enough she'll go get her lobster. She has a really big toy bin and she plays with a lot of toys, so selecting these two by name has always been curious. She also has toys for different purposes. The remnants of a Lamb Chop long lost are her snuggle toy, she doesn't play tug of war with it anymore. If you try to she'll display the same expression for dissatisfaction. reply gottorf 12 hours agoparentShe must get it from the greyhound. My pit shows occasional flashes of intelligence, but I think she's too anxious to behave smartly almost all the time... reply goles 13 hours agoprevhttps://archive.is/E8PKp reply binarymax 15 hours agoprevIf a dog can learn 100 toys, then they can learn 52 cards, and maybe play some poker. reply fionaellie 11 hours agoprevHow can I teach my dog the names of her toys? reply throwawaaarrgh 11 hours agoparentClicker training reply ggm 12 hours agoprevOlaf Stapleton \"Sirius\" reply genman 15 hours agoprevOur dog is not particularly smart but once we counted that she knows at least about 20 words, one of those being \"cat\", so we use \"that furry animal\" instead when we talk to not agitate her for no reason. reply antisthenes 15 hours agoprevKnowing what we know about the variability within species, why would anyone NOT think that there is immense variations in intelligence in other mammalian species? Especially a species that we've been selectively breeding for specific traits, some of which include independence and the ability to problem-solve? reply at_a_remove 15 hours agoprevI've seen a few videos on YouTube of cats trained on these push-down language buttons, mounted in a hexagonal pattern, on a mat laying on the floor. The cats press a button and the button plays back a word which the owner has recorded. I'd like to see more testing out of it but the cats seem to be rather expressive. They pick the same button, so at least they are consistent in their wants. They have a few verbs in the mix, it seems, not just nouns. I wonder how dogs would do on these buttons. reply gs17 14 hours agoparentI've watched a few in the past and I'm not convinced the more complex interactions are \"real\" language use instead of operant conditioning combined with confirmation bias. Too many of the videos will have button sequences that seem random get assigned a meaning, and even non-request button presses will get attention. Buttons for \"food\", \"water\", \"pet me\", \"play with me\", \"outside\" almost definitely work. Before I lived with a cat again, I was skeptical of those as \"well, duh, any of those buttons get a reward, they don't care what it is\", but our cats ask for those specific things without buttons. reply deathanatos 11 hours agorootparentI know a dog that, if you've not paid attention to her water bowl and it's empty, and she wants water, will simply paw the rim of the bowl to cause it to overturn, which makes a loud clatter on the hard floor. Once she then has your attention, she'll give you a look, as if it say \"water, let's go.\" I dare say she trained us — after all, we didn't teach her to do that. And sure, it's simple … but she's still purposefully communicating a desire/intent. (She's a good girl, too.) reply at_a_remove 14 hours agorootparentprevI've been on the lookout for that, but I was struck by some particular \"conversations\" that involved re-direction. \"Sorry\" \"How about something else\" \"Mommy - Sick\" and so on. There was some back and forth there that I could not quite discount. reply _whiteCaps_ 15 hours agoparentprevYou should check out Bunny the dog on Youtube / Tiktok. reply m3kw9 9 hours agoprevNot sure why dogs and other smartish animals couldn’t make the jump like humans reply throwawaaarrgh 11 hours agoprevEverybody thinks their dog and/or child is a genius. But I've had a lot of dogs. Even within the same litter, some are bright, and some are dumber than a box of hammers. If your dog is smart, that's great, but your next one of the same breed might not be. Some individual dogs also don't take well to training, while others do. It's way more about the individual than the breed. reply paulpauper 14 hours agoprev [–] is it actual learning or a Clever Hans effect or other operant conditioning. reply gs17 11 hours agoparent [–] They attempted to reject a Clever Hans effect. >To minimize potential inadvertent cues from the owner, the instructions required the owners to place the dog's toys in a different room. Owners were instructed to ask for each of the toys while ensuring that at least three toys were available for the dog to choose from. For the test they had a camera in the room with the owner and another in the room with the toys (so the owner couldn't cheat by removing the other toys). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Certain highly intelligent dogs, especially border collies, can memorize the names of more than 100 toys without targeted training, as revealed by a study from Eötvös Loránd University in Hungary.",
      "The \"Genius Dog Challenge\" study highlights dogs from different breeds and countries with exceptional word-learning skills, prompting researchers to investigate the factors behind this ability and compare it to children's learning processes.",
      "Researchers aim to delve deeper into understanding the linguistic capabilities of these dogs and how they differ from those of human children."
    ],
    "commentSummary": [
      "Dogs, especially breeds like Australian Shepherds and Border Collies, showcase remarkable intelligence and communication skills, such as learning toy names and understanding human language.",
      "The potential for dogs to communicate using buttons is explored, raising questions about animal intelligence and communication capabilities.",
      "Emphasis is placed on the significance of training, care, and breeding practices in nurturing and improving dogs' cognitive abilities."
    ],
    "points": 219,
    "commentCount": 193,
    "retryCount": 0,
    "time": 1708702313
  },
  {
    "id": 39480513,
    "title": "Top High Interest Savings Accounts: APY Ranges from 5.32% to 5.15%",
    "originLink": "https://www.highinterest.io/",
    "originBody": "The High interest savings leaderboardBank Name Current APY Slug Customers Bank5.32%customers-bankOpen menuOpen websiteWestern Alliance Bank5.28%western-alliance-bankOpen menuOpen websiteTAB Bank5.27%tab-bankOpen menuOpen websiteJenius Bank5.25%jenius-bankOpen menuOpen websiteUFB Direct5.25%ufb-directOpen menuOpen websiteEvergreen Bank Group5.25%evergreen-bank-groupOpen menuOpen websitePopular Direct5.2%popular-directOpen menuOpen websiteEverBank (FL)5.15%everbank-flOpen menuOpen websiteBread Financial5.15%bread-financialOpen menuOpen websiteRBMAX5.15%rbmaxOpen menuOpen website Showing 1-10 of 205 banks PreviousNext",
    "commentLink": "https://news.ycombinator.com/item?id=39480513",
    "commentBody": "High Interest Savings Leaderboard (highinterest.io)209 points by cainxinth 20 hours agohidepastfavorite211 comments sahila 19 hours agoHYSA are great but even better are buying money market funds or tbills. Money market funds restrictions are they can be bought/sold during market hours and tbills have a specified lock up period, like a month or more. Both can be bought from your broker, it’s intimidating but actually quite simple. For example buying money market vusxx fund today is giving an equivalent 6.25% apy for high tax earners in California - this is because much of it is tax exempt whereas hysa is not. This google sheet has all of the current rates and is useful: https://docs.google.com/spreadsheets/d/1v3fn3sZRvkSgqb-RnN2g... reply thesuitonym 19 hours agoparentIt's my understanding that high yield savings accounts are still the best place for an emergency fund. A tbill might net you more money, but if you're still 8 months from maturity, how does that help you at all? reply nonethewiser 19 hours agorootparentHYSA are also FDIC insured which is no joke. Money market funds are vulnerable to \"bank runs\" the same way a bank is. There have been times, like in 2008, where you were not able to actually pull all your money out. https://www.investopedia.com/articles/economics/09/money-mar... I guess technically there is always a risk of 100% loss but in the case of the HYSA that would happen if the United States dissolves. With a money market all you need is a bank run. reply yojo 19 hours agorootparentYep. I was unfortunate enough to get stuck in a money market fund that “broke the buck” during the financial crisis. It took over a year to liquidate, and I think I still lost around 2% of the principal. Definitely not a place to stick money you absolutely need to be able to pull out soon. reply toomuchtodo 17 hours agorootparentprevI use SPAXX at Fidelity. It is mostly government paper, and while not explicitly FDIC insured, I am confident of it's solvency in almost all situations due to new money market regs (that should prevent the most common MMF products from \"breaking the buck\"). If you are incredibly conservative, you could keep enough cash for 30-90 days in an FDIC deposit account, with the rest in money market funds that will take time to resolve solvency issues. https://www.sec.gov/news/statement/crenshaw-statement-adopti... https://institutional.fidelity.com/app/proxy/content?literat... https://fundresearch.fidelity.com/mutual-funds/summary/31617... reply __derek__ 14 hours agorootparentprevPost-GFC, that's not a real risk for retail MMFs. They're de facto narrow banks now. reply matthewdgreen 19 hours agorootparentprevVanguard money-market funds can be exited at the close of business any day: bonds may comprise the underlying assets, but you don't actually have to wait for maturity. The main risk with these funds is that you don't get FDIC insurance. Historically this has not been a problem (for Vanguard), but past results etc. ETA: in 2008 there was an instance where one fund \"broke the buck\", but the Fed stepped in and backstopped it. reply divbzero 16 hours agorootparentprevIf you buy T-bills through a brokerage, you can easily resell them on the secondary market using the same brokerage. The market price climbs as maturity approaches, so you typically capture yield in proportion to how long you held the T-bill. reply bombcar 18 hours agorootparentprevIt depends on what your emergency fund is for. Most people posting here have enough unused credit card \"headroom\" to get them through a month; so the main thing for an emergency fund is that you can get the cash out of it with low or no cost within that month. Some use bond funds to do it, some use bond or CD \"ladders\" - buy a bond expiring in 12 months that is 1/12 your emergency fund each month, and in a year you'll have a rolling \"self built fund\" that you can get 1/12 of every month with no penalties. Bogleheads forum has tons of discussion around these kinds of things. reply NordSteve 19 hours agorootparentprevSell the bill? Market is very liquid. reply nonethewiser 19 hours agorootparentIf you have to wait 2-3 days to get money your money its not an emergency fund. reply ixwt 19 hours agorootparentSo putting my money into a HYSA isn't a good place for an emergency fund? It will take 2-3 days to transfer (without fees). I've never understood this mentality. I've got a credit card with nearly 6 months of expenses as a limit, most of it not used because I pay it off month to month. I'd be more worried about the tax implications of selling ETFs and such than the 2-3 days of wait to transfer. Maybe I lack imagination, but I can't think of anything that I'd need my entire emergency fund immediately. Throw the emergency cost onto a credit card, and transfer the money from the emergency fund to pay off the bill. I guess that doesn't work in some other countries where credit cards aren't as prolific as the US. reply Renevith 16 hours agorootparentFor what it's worth, Wealthfront's HYSA offers free same-day transfers, at least to major banks (they just need to support RTP transfers, which many do). But I agree with your point that an emergency fund is fine as long as you can access it within a few days. reply haswell 18 hours agorootparentprev> It will take 2-3 days to transfer (without fees). This depends on the bank. If you have a checking account with the same bank, the funds can be available right away. The standard withdrawal frequency limits still apply. reply abofh 1 hour agorootparentWithdrawal limits on savings accounts were suspended for COVID, and at least in my experience, hasn't come back - but ymmv reply naniwaduni 17 hours agorootparentprevI think this is one of those places where mass-market financial advice is aimed at people who are bad with money and might not be able to float a month of expenses on credit. I'm not sure I've ever had a nontrivial expense in the US that simultaneously couldn't be paid on credit and wasn't known for weeks in advance either. I would expect any no-credit charge in excess of about a dinner bill to be announced at least a week in advance, implicitly through an invoicing process at the very least, and I would frankly have reservations about whether any vendor who didn't have a way to handle this was really a legitimate business. Even if that's not an option, your broker is probably fine with floating you a sum of cash matching your recent MMF sale amount as overdraft or margin at a price of somewhere between \"we've already factored it into our fees as a cost of doing business\" andwith no federal tax I thought it was only federal tax, not no federal tax? reply roland35 18 hours agoparentprevThere comes a point where you are optimizing finances beyond what is necessary, in my opinion. Have a decent plan for your cash so it's earning good interest, then go out and focus your time on the rest of life. Automate as much as possible. Don't worry about a few $10s of extra interest! reply alemanek 17 hours agorootparentIf your bank account is also at your broker (ex. Schwab, Fidelity) then money market funds are actually more convenient than a HYSA. My money market fund money is available the day after I sell and there is no waiting period to transfer between my accounts at Schwab. Also I can use the money market fund to underwrite cash secured puts or for other investment activities. Transferring between institutions I have had take 3-5 days before funds clear. Wires can be faster but come with fees and a whole bunch of questions to make sure you aren’t a scammer trying to empty an account. So, it is good to know about all your options. I keep my 6month emergency fund in SNOXX money market fund. With Fidelity you can set a sweep to go into their short term treasury fund and not even have to sell anything to transfer the money out. reply rrrrrrrrrrrryan 18 hours agorootparentprevThere are times when you need to have a ton of money in cash or near-cash (e.g. saving for a down payment for a first home), and then it makes a lot of sense to optimize. For a normal emergency savings fund, it does not make sense (unless you legitimately enjoy doing it!) reply soupfordummies 17 hours agoparentprevI did some cursory reading on money market funds (MMFs) and I don't quite get the advantage if rates are roughly the same? For instance, if there is a high-yield savings account (HYSA) option that gives 5.3% interest and a MMF that gives 5.4% (with a 0.1% expense ratio), would I not receive the same amount of interest in practice? Not trying to disagree with you or anything, just making sure I understand the vehicle. reply naniwaduni 17 hours agorootparentUsually, taxation differences. Also, MMF yields are generally quoted net of expense ratios already, you don't subtract them out a second time. reply balderdash 9 hours agorootparentprevFrom a practical standpoint they’re the same - it’s the at the margin (MMF is likely to “reset” more quickly than a high yield savings account, you’re also risking it “breaking the buck” in times of extreme stress, + a lot of the income in a MMF you won’t pay state tax on, on the other hand an HYSA is FDIC insured) reply latchkey 16 hours agorootparentprev5.3% https://www.viobank.com/cornerstone-money-market-savings reply greyface- 12 hours agoparentprev> tbills have a specified lock up period, like a month or more What is this referring to? I've bought and sold T-Bills in the same week, and have never encountered anything about a lockup. reply sahila 6 hours agorootparentYou’re right you can but/sell on the secondary markets easily. If you buy it directly on treasurydirect.gov, then you might have a lockup depending on the time interval you pick. reply balderdash 9 hours agorootparentprevI think they may be confusing it with savings bonds reply 7moritz7 19 hours agoparentprevI don't see any reasons not to put everything into diversified ETFs. Low risk, reliably comparatively high returns unless the world economy or the entire US economy crash (which would ruin the value of almost every asset anyways). reply dannyw 19 hours agorootparentYour emergency fund shouldn’t be in stocks. reply lr4444lr 19 hours agorootparentprevIf you have a high likelihood of needing the cash in the next 0-24 months, that risk isn't so low. reply yodsanklai 19 hours agorootparentprevWhat low-volatility ETFs strategy would you recommend? let say my goal is to survive inflations and market crash such as 2008 for instance. Personally, I have a very hard time putting all my hard-earned savings on ETFs which can lose a lot of their value overnight. reply dmoy 16 hours agorootparentI wouldn't recommend using stock ETFs for an emergency fund. SGOV is a reasonable option, it's basically just doing a 1-3 month Treasury ladder for a charge of 0.2%, and slightly less frustrating liquidity. (So right now you'd get like 5.2% with SGOV, vs 5.4% with treasuries) reply dannyw 8 hours agorootparentBOXX is more tax advantaged. reply coryfklein 16 hours agorootparentprevFrankly I do this as well. I think it depends on your personal financial situation and how often you expect to be withdrawing from your emergency fund. By increasing levels of \"emergency\", do you use your emergency fund to pay for: * Gas because you forget to plan properly for road trips? Keep your funds in cash. * Your vehicle's regular oil change which happens every couple years and you should be able to plan for? Maybe a HYSA * Your transmission goes out and you need a new car? Diversified ETFs probably fine Many \"emergencies\" can in fact be saved for, which leaves only the truly rare and uncommon ones, which usually don't require that you have all of the emergency fund available as cash at a moment's notice. Also because they inherently only happen on a time scale of YEARS, then in the long run you're just self-insuring yourself and it's a bummer if the transmission goes out in a down year and you have to exit a position, but statistically speaking you'll come out ahead. reply dageshi 19 hours agorootparentprevWhat you suggest is comparatively high risk vs tbills and MM funds. T-bills are literally the safest possible investment bar none. reply giantg2 19 hours agorootparent\"T-bills are literally the safest possible investment bar none.\" Wouldn't I bonds be safest? They protect against inflation. reply trogdor 18 hours agorootparent“Safe” in this context generally refers only to downside risk. T-bills are safer than I-bonds because T-bills are short-term investments. I-bonds have an early-withdrawal penalty. (I-bonds also have a $10,000 annual purchase limit, but that’s less-relevant.) reply giantg2 18 hours agorootparentYou're missing that Tbills have inflationary risk. reply trogdor 16 hours agorootparentNo, I am not. Inflation risk is not downside risk. Inflationary risk is the risk that inflation will undermine an investment's returns through a decline in purchasing power. Downside risk is the risk of loss in value of an investment due to a decline in the price of the security. Decline in value of an investment because of a decline in the price of the security is not the same as decline in value of the investment because of inflation. Even if the practical consequence is the same. Inflationary risk matters, and it should not be ignored. But it doesn’t factor into whether an investment is considered “safe,” as that term is typically used in this context. reply giantg2 16 hours agorootparent\"Inflation risk is not downside risk.\" \"But it doesn’t factor into whether an investment is considered “safe,” as that term is typically used in this context.\" If you ignore real terms and don't care about actual value (the entire goal of investing), sure. I guess is cash is \"safe\" too if your ok with losing double digit percentages of your valve over the past 3 years. reply trogdor 15 hours agorootparentThis conversation is about the meaning of specific terms, not about whether I care about real investment returns. Of course I care about real returns. reply giantg2 15 hours agorootparentAren't semantics considered off-topic or not contributing to the conversation at HN? reply bombcar 18 hours agorootparentprevYou also have TIPS available, but I-bonds are better than TIPS (you can tell because I-bonds are limited per person, TIPS are not). If you bought (or even buy) I-bonds at the right time, it can be a spectacularly good deal. reply purpleblue 17 hours agorootparentprevT-bills have short duration so their inflationary risk is minimal. reply giantg2 17 hours agorootparentAt the lower end, sure. 52 weeks can still be an issue. reply tallanvor 19 hours agorootparentprevYou can only buy $10k worth of I-bonds per year. But you're correct that I-bonds are designed to prevent you from losing money. reply naniwaduni 17 hours agorootparentYou're still taxed on nominal gains on I bonds, so in principle you're still exposed to potential downside up to your tax rate. The way rates are set on I bonds is also unusually subject to tracking error. reply giantg2 19 hours agorootparentprevMost people don't have $10k a year to invest anyways. reply padolsey 19 hours agorootparentprevPart of that diversification is the money markets, no? reply HumblyTossed 19 hours agoparentprev> but even better This is highly dependent on what the intended purpose of the money is. reply giarc 19 hours agoparentprevI'm just seeing a bunch of #NAME errors. reply mdrzn 19 hours agorootparentClick on the \"Instructions\" tab at the bottom of the page, you have to create a copy for your personal use. The #NAME errors is caused by the table trying to get data from a tab called \"My RateSet\" which doesn't exists yet. reply santoshalper 19 hours agorootparentprevSame reply 2OEH8eoCRo0 19 hours agoparentprevAren't money market funds only good today because of the high fed interest rate? If/when that comes back down so will the money market rates. reply anxrn 19 hours agorootparentAnd so will HYSA rates. reply Bluecobra 19 hours agorootparentprevYes. When they start cutting rates that would be good time to buy Treasury Notes/Bonds or longer term CDs so you can lock in the interest rate for a period of time. reply naniwaduni 17 hours agorootparentExpected rate cuts are generally already priced into longer-term bond prices, so trying to get in just before rates go down is basically exactly as hard as market timing. reply matthewaveryusa 19 hours agorootparentprevHigher than 0% yes. Historically rates are still on the low side. And yes they move with the fed rate. reply lotsofpulp 19 hours agoparentprevTTTXX at BoA/Merrill is another one. Although, in a shit hits the fan scenario, I would expect to be able to access my FDIC insured account money more reliably than a money market fund. reply throw0101c 19 hours agoprevFor the Canadians in the audience: * https://www.highinterestsavings.ca/chart/ * https://www.ratehub.ca/savings-accounts/accounts/high-intere... There are also 'HISA ETFs' like CASH.TO: * https://moneyguynow.com/best-canadian-high-interest-savings-... However note: > The biggest difference between HISA mutual funds and HISA ETFs is that ETFs are not CDIC-insured. This occurs because HISA mutual funds allow investors to be registered with the deposit institution as individual depositors, whereas a HISA ETF bundles the sums provided by all investors and invests the proceeds in the ETF’s name. However, HISA ETFs mostly invest with systemically important financial institutions (SIFIs), which are subject to greater regulatory requirements than non-systemically important ones. In Canada, we have three types of SIFIs. * https://www.pwlcapital.com/high-interest-savings-account-etf... reply voisin 18 hours agoparent> There are also 'HISA ETFs' like CASH.TO FYI, I tried to buy this in my TD Direct Investing Account and it wouldn’t let me. I called in and found out TD had blocked trading for any clients in CASH and there was another similar ETF, the #1 and #2 most liquid high interest savings ETFs around. I was told that to trade in these I had to open up a managed account (and pay fees to TD, negating part of the benefit of these ETFs). I thought this seemed highly unethical and inappropriate and so I contacted a variety of regulators (even trying to find which regulator had oversight of this was a major pain!) only to be told that there is no requirement for investing platforms to be neutral conduits to the markets and that they have full authority to block trading to help their other competing businesses. Canada: where corrupt self dealing by the oligopolies is the name of the game. /endrant reply dghughes 19 hours agoparentprevA Canadian Tire TFSA ??? WTF? lol reply throw0101c 18 hours agorootparentYou can get a bank account at the grocer, PC Financial at Loblaws, so why not. * https://en.wikipedia.org/wiki/President%27s_Choice_Financial reply iav 19 hours agoprevNot to overcomplicate things, but anyone planning to save money for >12 months should be using the BOXX ETF (https://etfsite.alphaarchitect.com/boxx/) to convert the interest income into a long-term capital gain. Even if you end up cashing out before the 12 months, you are still going to pay the same taxes as with a savings account, so there is truly no downside. reply ca_tech 19 hours agoparentFor a detailed report on the mechanics behind the BOXX ETF, Bloomberg just published this article: https://archive.is/8kq0G It is not a perfect solution for everyone. You do need to take into account your income tax rate and your capital gains tax rate. reply infecto 19 hours agorootparentThe universe has come full circle. For those of us who cannot resolve archive link. Article https://www.bloomberg.com/news/articles/2024-02-22/this-exch... Matt Levine's https://www.bloomberg.com/opinion/articles/2024-02-22/put-th... reply ct0 19 hours agorootparentDoes your DNS block archive.is? reply johnmaguire 19 hours agorootparentCloudflare has issues with archive.is: https://news.ycombinator.com/item?id=28495204 reply Hello71 18 hours agorootparentthe opposite is the case. from your link: \"Archive.is’s owner is intentionally blocking 1.1.1.1 users\" reply bombcar 18 hours agorootparentThe archive owner wants takedown requests to be forced to be cross-border, so he wants to know where the request is coming from so he can serve from a server in a different country. Cloudflare blocks the extension to DNS that allows that. If you don't care, you can set your DNS to bypass Cloudflare for those domains only. reply lxgr 16 hours agorootparentI’ve known this for a while now but it never ceases to amaze me. This must be up there with “no copyright intended” in terms of misguided compliance strategies. reply johnmaguire 16 hours agorootparentprevIt's always appeared to be a matter of perspective, to me. That being said, by \"Cloudflare has issues with archive.is\" I very literally meant that they have issues with the DNS records served to them by Archive.is. (i.e. They do not support EDNS.) reply infecto 18 hours agorootparentprevI have had issues in the past. The problem with posting only the archive link is it provides no stable reference link to the actual article. reply woleium 19 hours agorootparentprevi was going to ask this. you can fix it with a static hosts file entry, or dnsmasq config update on your router. See https://www.reddit.com/r/DataHoarder/s/gfH9MFAxcp for more info reply hippich 18 hours agorootparentprevCan someone explain it a bit better? I am not quite sure why in addition to spx this fund buys options on Bookings? Also, where is the risk in this strategy, besides counter parties risk. reply derf_ 12 hours agorootparentThe Bookings options are explained in the Bloomberg article. They use offsetting bets so that one generates a large gain and the other generates a large loss (either way the stock moves). Then the gain is offloaded through an in-kind redemption (not a taxable event for an ETF) and the loss is kept on the books to offset any other taxable gains in the fund. I guess you could worry what happens if the stock doesn't move, but since they get to pick the timing, that seems unlikely to be an issue in practice. I can think of at least a few risks that one would not have with T-bills besides counterparty risk. You have management risk: they have said what their strategy is and what they will do, but what if they don't? I would also ask who is on the other side of these trades and how big that market is or can be. Alpha Architect's own explainer implies that box spreads can also be used to borrow money and that this might be cheaper for the borrowers than margin loans, which makes some sense, but it seems like a pretty esoteric instrument to use for that. Most of their argument is an appeal to the efficiency of markets, which might be true until it isn't. Finally, there's regulatory risk. They think this works under the current rules, but a regulator might disagree with that. If someone does not like it a sufficient amount the rules could be changed, just like there's already an exception for \"original issue discount\" that makes zero-coupon bond income like Treasuries count as interest income, not capital gains, even though no interest payments are ever made. I'm not in finance, though, I'm just some guy, so take all of the above with a grain of salt. reply nonethewiser 19 hours agoparentprevThis is hilarious. It's not as risk-free as an FDIC insured HYSA account though. I don't care what the ETF tracks - being an ETF that tracks something comes with some additional risk. reply padolsey 19 hours agorootparentYes to that. And this may be my own risk-averseness, but I don't have complete confidence in all these derivative instruments anyway. I don't have time or sufficient interest to look into the construction of ETFs and how their holdings are managed, so I will opt for a mixture of stock-picking, index funds, bonds, ETFs, and just plain old savings accounts at banks I can see on the cold hard cement of the city. I try to be diversified in which financial instruments I choose. It seems most people have blind faith that X or Y instrument are constructed, managed and regulated in a reliable and trustworthy way. They entrust their money into weird mechanisms where they believe they own AAPL stock but actually it's just a derivative slice on precarious terms (fractional shares or other slimey broker-made nonsense). reply bombcar 18 hours agorootparentYou can certainly over-engineer your solution, but just watch the world and see how \"you would have fared\" in situations that affect others. For example, everything goes to shit if Rogers goes down so hard that no electronic payments of anything works; so maybe some percentage of an emergency fund should be literal cash on hand. reply MetaWhirledPeas 19 hours agoparentprevWhat's the rate of return that way? The 5% coming from the bank is pretty nice and is easily understood. I scrolled to the end of that BOXX page and even watched the video, and I still don't understand it. reply KMag 17 hours agorootparentThe short answer is that if you could answer that question in advance to a high accuracy, you could make billions as bond trader. In theory, you get paid similarly to regularly going out into the bond market and buying US government bonds that expire in the next few months, but with a potential tax savings twist. (I am a random Internet dude, not a tax lawyer.) The returns supposedly track the short end of the yield curve on US Treasuries. That would make sense, as theoretically, the net premium of a box spread is equal to the net present value of the payout (under the no arbitrage assumption). That net present value should be very close to the yield on a zero-risk asset over the same time period. They're using 1 to 3 month options, so in theory, they get yield close to short-term US Treasuries (the market prices a near-zero probability of the US defaulting on its bonds in the next few months). I haven't looked into the tracking error between SPY box spreads and the short end of the US yield curve. https://en.wikipedia.org/wiki/Box_spread#cite_note-2 says the yield averages about 0.35% above holding equivalent maturity US Treasuries. Though, it sounds like they're using box spreads composed of American options, so I wonder how they deal with early exercise risk. You only get bond-like performance from a box spread if you don't have early-exercise risk. The further out of the money they place their strikes in the box spread to avoid early exercise risk, the lower the liquidity they get, and higher trading costs. The tax trick is that they also enter into a delta-neutral trade on a high-value single stock. (They don't use and index for this part because they want the difference between the winning and losing parts of this trade to be as large as possible, so they want volatility in the underlying asset.) At certain points, they realize the losses on the losing half of that trade (reducing tax liability), and perform a tax-free in-kind exchange of units (shares) in their ETF for the winning half of that trade. Of course, they don't know in advance which half will win and which will lose, but it doesn't matter. The brokerage buying their ETF in order to make the tax-free exchange bumps up the price of the ETF, very close to the value of the winning leg of the tax-saving trade. Note the several caveats above (and probably some I missed) in comparing with US Treasuries yield. This is not investment or tax advice. reply _ink_ 19 hours agorootparentprevThe Bloomberg article states 5.07% after fees. reply nonethewiser 19 hours agorootparentWhich is before taxes. Just like the 5% HYSA is before taxes. In the case of BOXX this is going to be 0-20% (depending on your income) whereas the HYSA tax will be 10-37% (depending on your income). reply lotsofpulp 19 hours agorootparentIf you are subject to state or other local income taxes, then the HYSA is subject to those also, whereas BOXX would not be. reply nonethewiser 19 hours agorootparentGreat point, I missed that. reply andrewla 19 hours agoparentprevI only just learned about this in Matt Levine's newsletter [1], and assuming they don't get regulated out of existence, it seems almost too good to be true. The effective tax-discounted rate of return on a 5.6% interest-bearing account is really only 3.5% because it's ordinary income (paying taxes of .37 * 5.6). But as long-term gains it becomes 4.3% (paying taxes of .238 * 5.6). And while it is compounding you pay no taxes at all. [1] https://www.bloomberg.com/opinion/articles/2024-02-22/put-th... reply teeray 19 hours agoparentprev> there is truly no downside What about FDIC? reply hatch7 19 hours agorootparentnext [3 more] [flagged] aaomidi 19 hours agorootparentMy dude the feds have consistently bailed out more than the minimums. If FDIC ever fails, then these ETFs are likely to crash with them due to the sheer “wtf” moment that would be. reply TMWNN 18 hours agorootparent>My dude the feds have consistently bailed out more than the minimums. You mean \"maximums\". And, no, that's not true. IndyMac customers got back about 50 cents on the dollar for non-insured deposits. The typical non-insured depositor in post-2008 bank failures (all tiny, until SVB and Signature) got about 75 cents on the dollar. reply empathy_m 19 hours agoparentprevI keep thinking about parking cash in box spreads on SPX directly -- pay net $98,000 in option premium now and earn $100,000 in a few months, effectively lending to the market at the rate implied by highly liquid option prices. The section 1256 tax treatment is especially cool not so much because of the 60/40 taxation but because if you have several consecutive years of 60/40 gains you can edit your past year's income by incurring a current year loss and having a carryback loss. reply vamega 18 hours agorootparentI've borrowed money using SPX box spreads. You can get data on the recent trades and build a box spread at https://www.boxtrades.com/ There's a long thread on the Bogleheads forums about Box Spreads here: https://www.bogleheads.org/forum/viewtopic.php?t=344667 reply 4star3star 19 hours agoparentprevFor someone like myself who is only sophisticated enough to fund an IRA, CD, or savings account, how does one start out with BOXX ETF? reply bombcar 18 hours agorootparentGo to https://www.bogleheads.org and read until you start to feel the ability to answer questions. reply andrewla 19 hours agorootparentprevOpen a brokerage account, and buy it just like a stock. If you have an IRA you likely already have an account at a brokerage. reply paxys 19 hours agoprevWhile it may be tempting to pick whatever is on top of the list, you should make your decision after factoring in bank locations, reputation, customer service, online tools, ATMs, fees etc. rather than just go for the extra 0.04% in interest. reply LVB 19 hours agoparentMarcus recently locked my account for unspecified reasons and it took a couple weeks to unlock simply because they weren’t allowed to send a verification code to my phone since it was on a prepaid plan (?!?). Quite nerve-wracking to have all of your “safety” funds inaccessible and stuck behind fairly helpless front line agents that offer no escalation path. reply hn8305823 19 hours agorootparent> for unspecified reasons > my phone since it was on a prepaid plan That is likely your reason (burner phone). Did they ask you for hard evidence of your identity before unlocking your account? reply ezfe 19 hours agorootparentMy family has three phone lines and 2 are on \"prepaid\" Verizon phone lines, and one is on a regular AT&T line. The fact the prepaid lines are considered inferior is ridiculous and causes stupid problems. It's a regular Verizon line but because it's prepaid some websites don't like it. reply LVB 18 hours agorootparentprevI'm using a standard T-Mobile prepaid plan with my name on it, auto-paid monthly using a CC with my name on it. The silly part is that this same phone is what they: a) registered my account with a few years ago, b) send their 2FA codes to for normal account login. But it is unacceptable to their support system, I guess. The \"unspecified reason\" turned out to be me trying to transfer some money to a business checking acct that I have. That's against their ToS and could have probably been a quick reversal (when I finally got through to the right person it took about 5 minutes), but the phone verification thing gummed stuff up for a few weeks. reply jrockway 16 hours agorootparentprevLooking up your cell phone number in a several-months-out-of-date database is not the KYC process for bank accounts in the US. reply bonton89 18 hours agorootparentprevMy prepaid phone isn't a burner phone. Not everyone uses their phone enough to like getting screwed on post paid plans. reply Kon-Peki 19 hours agoprevIf you can handle not being FDIC insured, check out Ford Interest Advantage. This is the money that Ford uses to fund auto loans. In practice, it works like a checking account with ACH deposits/withdrawals. 5.5% https://www.ford.com/finance/investor-center/ford-interest-a... reply hn8305823 19 hours agoprevTop of market interest rates are a signal that the bank needs capital (yours). Be careful with more than $250k in any one regional bank right now. reply bombcar 18 hours agoparentThat's a good rule of thumb for anyone (but if you have a quarter million in cash equivalents you're probably a business or super-wealthy). I wonder if anyone has done a correlation study with bank failures vs CD/HYSA rates. The ones I know of that \"everyone\" flowed into have survived. reply userabchn 15 hours agoparentprevKaupthing [1] was offering very attractive interest rates in 2007. [1] https://en.wikipedia.org/wiki/Kaupthing_Bank reply keeganjw 19 hours agoparentprevThis seems like a fair assessment. Especially for all these tiny banks that are absolutely not too big to fail. reply PieUser 18 hours agoprevTheres a much more comprehensive list here: https://www.doctorofcredit.com/high-interest-savings-to-get/ reply grumpwagon 17 hours agoparentAlso, I believe doctor of credit is not funded by affiliate links like most sites that list this stuff are (including the GP link, I believe) reply velcrovan 17 hours agoprevIf you're a US citizen, don't sleep on I-bonds for your emergency fund. The current rate for I-bonds is 5.27%. It adjusts up or down automatically with inflation. The only catch is you can't put in more than $10k per calendar year, and if you withdraw before 5 years you give up 3 months of interest. Much, much better than a CD. https://treasurydirect.gov/savings-bonds/i-bonds/i-bonds-int... reply jccalhoun 19 hours agoprevI've been using depositaccounts for years to check rates for savings and CDs https://www.depositaccounts.com/ reply ryandrake 16 hours agoprevOptimizing one's savings rates always seemed to me to be high effort, low reward. Like coupon clipping or credit card churning. You either live with convenience and low returns or you get a slightly better return by making \"opening new accounts\" your entire life. I already have a credit union account for checking, multiple brokerages, an HSA account, a 401(k) account (different from my brokerages), a Roth IRA account, a 529 account, an account at TreasuryDirect, and probably others I'm not thinking of. Now if I want the best yield savings, I need to open yet another bank account? If I want the best CD rates, I'll need further another account? Yuck! And when I want to move funds from one asset class to another, it's a ACH transfer or some other needlessly multi-day transfer from one institution to another. It's exhausting. reply bhelkey 14 hours agoparentThe value of optimizing here is really easy to estimate. You know how big your emergency fund is, your current interest rate, and the interest rate you could get. If you have $5000 in BOA (0.01% APY), switching to one of the listed HYSA (~5% APY) nets you ~$250 a year. Is the convenience worth the opportunity cost? That's up to you to decide. reply ourmandave 19 hours agoprevThere is some missing nuance if you just look at the list. Orion FCU is listed at 0.01%, but you can get 6% (on the first $10K) if you open a premium checking acct. Although you have to deposit at least $500/month and use the atm card as much. Not exactly what people with large amounts outside their network are looking for, but still. reply BitwiseFool 19 hours agoparentThese sorts of accounts are just not worth the hassle. The interest rate seems spectacular but it's contingent on satisfying conditions that are easy to miss each month. Plus, the fallback rate is punishingly low. When looking at the effort required compared to a \"normal\" savings account, it's a terrible deal. reply decafninja 19 hours agoprevHYSA may not be the absolute best thing, but they're simple enough for dumb laymen like me. At some point I might transfer some, or all, funds out of my HYSA but for now it's good enough to park things in while I do some more research on what options I have. reply ssgodderidge 19 hours agoprevThis is cool! I'd love to also see the leaders' rates over time, rather than a point-in-time snapshot. Switching banks is relatively time consuming. I'd prefer to choose a bank with the highest rate over the last 1yr, 2yr, 3yr+ periods. reply scruple 18 hours agoprevThe list is missing American Express HYSA. It's at 4.35% APY. reply anonu 7 hours agoprev6 month treasuries through XHLF... 3bps management fee, yielding above 5% can be traded in any brokerage account: https://bondbloxxetf.com/bondbloxx-bloomberg-six-month-targe... reply eli 19 hours agoprevUsing a convenient bank is more important than squeezing a few more basis points in yield. reply latchkey 16 hours agoprevVIO Bank is classified wrong and should be at the top of the list. https://www.viobank.com/cornerstone-money-market-savings reply Gooblebrai 19 hours agoprevGreat idea. Would love to have the same for the UK! reply padolsey 19 hours agoparentRaisin: really easy mobile app: https://www.raisin.co.uk/ Flagstone: 10k minimum, old-school but well-trusted, great rates for higher deposits: https://www.flagstoneim.com/ E.g. on flagstone you can get over 5% instant access if you're prepared to put £10k or more away. reply fotcorn 19 hours agoparentprevHere you go: https://www.moneysavingexpert.com/savings/savings-accounts-b... reply frereubu 19 hours agoparentprevMy accountant directed me to https://moneyfactscompare.co.uk/savings-accounts/ which I've used quite a bit over the years. Haven't compared it to other comparison sites, but it seems to be pretty good for most basic financial stuff like mortgages too. reply supsep2 10 hours agoparentprevTrading212 is giving 5% interest for uninvested cash. I started using trading212 and it’s been solid so far. reply asystole 18 hours agoparentprevMonzo gives me 4.6% instant-access and I manage it from the same app I manage my current account in. My savings are fairly modest so it really doesn't seem worth the bother to shop around for an extra ~0.4%. reply beejiu 19 hours agoparentprevhttps://bankaccountsavings.co.uk/ reply dom96 19 hours agorootparentWhere is the pretty chart and table showing me the interest rates offered? reply gfiorav 19 hours agoprevFor folks who don't know: In these HYSA, every time the interest pays (monthly), it triggers a taxable event. This might be important for you to consider. If you invest longer term in bonds and good securities instead, you could time your tax better (i.e.: sell when your income tax is lower; retirement). In the US, you can get \"lifetime/permanent insurance,\" which has a cash component that can be invested in bonds and enjoyed on much better tax terms (eating less into your bond's return). This is not financial advice. reply bombcar 17 hours agoparentThere are many tax-advantaged accounts and methods that would likely come in before \"perm life insurance\" unless you're an insurance salesman ;) reply aketchum 20 hours agoprevI opened a Sofi account when interest rates started rising after having only a Truist account paying 10 bps. Sofi paid $300 bonus and that was what actually got me to actually make the switch (their average cac must be over $400!). Its so interesting how the switching costs are very low but still feel high enough that it is tough to actually open new accounts even when you can easily earn $500 extra per year per $10k in balance. I wonder if fedNow adoption will make it more common to bank hop without the delays of the ach network reply smallmancontrov 19 hours agoparentFiguring out how to shit up outgoing transfers is a core competency of any financial institution, so I wouldn't count on fedNow to save us without additional standards forcing good behavior. reply Onward5818 17 hours agoprevFor the Dominicans in the audience: I made a tool like this one one for our market. http://crecepesos.com reply givinguflac 19 hours agoprevThis is really cool! Any reason Apple savings isn’t included? reply shortrounddev2 19 hours agoparentApple savings is a frontend for Marcus by Goldman Sachs, which is listed there reply ezfe 19 hours agorootparentMarcus and Apple Savings aren't always in sync, they've reached 4.5% at much different paces reply dia80 19 hours agoprevThis warrant's a little caution, there may well be some negative selection bias here. The banks most likely to go bust are the ones most desperate for cash so they offer the highest interest rates... If it's FDIC insured you are good up to $250k but I don't know exactly how much inconvenience is associated with your bank going bust and potentially collecting FDIC insurance. reply chrisq21 18 hours agoparentThis might not be the norm, but when SVB went bust FDIC insured money was paid out in a matter of days. reply ApolloFortyNine 18 hours agoprevThere's a an etf USFR that tracks the treasury notes all these companies buy anyways. Buying it you can use your favorite brokerage and sell whenever you want, without having to deal with another bank or the interest rate at your bank becoming less competitive. reply lr4444lr 19 hours agoprevCan someone clarify for me what the other pros and cons would be for these different banks aside from interest rate? Should I perhaps not go for an extra 0.05 - 0.15% if there are unusual rules around withdrawals, or are some known to have shady data privacy practices? reply no_wizard 19 hours agoprevThere are some Credit Unions that are offering even higher rates, I saw for a time 6 or 7%, but they sometimes had limitations for either joining the CU or upper limits on how much each account could have (though you could spread money across multiple CDs) reply babyshake 16 hours agoprevI'm pretty surprised to see notable differences between Wealthfront, Betterment and SoFi. I'd assume these types of services would be in a dead heat in terms of the interest offered. reply gerad 20 hours agoprevVUSXX - 5.29% reply jcdavis 19 hours agoparentAnd, crucially, last year 80% of VUSXX's interest was state tax exempt. Unless you specifically need the features of a savings account (eg ACH), money market funds are the way to go. reply lotsofpulp 19 hours agorootparentTTTXX is 100% exempt from state and local income taxes, as far as I know. reply bryceneal 19 hours agoparentprevI only recently discovered this. Are there any practical advantages to high yield savings account, then? Or do they only exist for people who don't understand how to buy money market funds? reply bradfa 19 hours agorootparentMoney market funds are not protected by FDIC. Savings accounts or CDs from banks are protected by FDIC. Your choice is likely to be made around risk. Granted, I don't think money market funds actually losing value or going to 0 is very common, but with FDIC insurance you have true 0 risk forreply Hasz 19 hours agoprevEh, please include banks that don’t offer an affiliate link. I use VIO, which offers 5.3% on all balances. reply giarc 19 hours agoparentI hovered over a few links and they didn't seem to be affiliate links. reply rmbyrro 19 hours agoprevDon't keep cash or cash-based assets. Only what you need for personal liquidity and emergencies. The govt will steal your money through inflation. If you don't wanna mess with or don't have enough money saved to buy real estate, buy an index ETF or a real estate fund. reply hn8305823 19 hours agoparentIt's good to keep at least 1 year of salary in savings. Investing it in other assets can be problematic when the global macro environment falters because you won't be the only one trying to liquidate! It's not hard to imagine a scenario where the stock market and risk assets in general crash, and then you get laid off. reply rrrrrrrrrrrryan 18 hours agoparentprevA 90/10 stocks/bonds portfolio will outperform a 100/0 portfolio over the long term. During a market downturn money flees to safety, bonds appreciate, stocks fall, and when you rebalance back to 90/10 you'll effectively be buying stocks at a discount. The 100/0 guy has no such option and misses out entirely. reply velcrovan 17 hours agorootparent> The 100/0 guy has no such option and misses out entirely. Not true. The 100/0 guy can buy stocks during a downturn just as well as the 90/10 guy. If we're really talking long term, that is, if neither person is selling, and if both are investing the same amounts regularly, then on average the 100/0 portfolio will outperform the 90/10 portfolio. Looking at history, the reason to go with anything besides 100/0 over the long term has to do with risk tolerance, not performance. https://investor.vanguard.com/investor-resources-education/e... reply naniwaduni 16 hours agorootparentMost people can't do 100/0 because they're structurally overweighted on a single weird illiquid asset that pays out more distributions than the rest of their assets combined. reply hatch7 19 hours agoprevAnd not one intelligent person is asking, how is the bank giving me a return for seemingly nothing? HYSA investments are wildly irresponsible and risky. They degrade the financial system and support horrible practices and institutions. I challenge anyone to find ONE financial instution which discloses what HYSA is invested in. These aren't even good investments. VTI is up 25% y/y. With these \"high interest\" investments below the prime rate, you're literally guaranteed to lose money, all while taking a massive and unncessary risk. reply mmiyer 18 hours agoparentThe bank gets 5.4% from the federal government.[1] HYSA rates closely track the federal funds rate, because the banks are essentially passing on the fed funds rate to consumers (minus a cut for themselves). The bank can also get 5.3% from short term treasuries right now. So the answer is basically that the federal reserve is giving the return. 1. https://www.federalreserve.gov/monetarypolicy/reserve-balanc... reply hatch7 15 hours agorootparentThis is hilarious. You actually think the Fed is paying everyone's HYSA yields? So, let me get this straight, you actually believe \"Customers Bank\", for example, which is currently offering 5.32%, is going through all the trouble of investing your money to get a 0.08% return from the same? Or is it possible these HYSA institutions are investing your money into other, more risky investments, like foreign banks, for example? Again, I have to wonder and ask, why has no intelligent person done the due dilligence to find out what their money is invested in for such a generous return, as they should for any other financial vehicle? Literally not one person in this entire post can provide evidence of what their bank invests HYSA funds in. This is how financially illiterate we are. reply somehnguy 19 hours agoparentprevSince when are High Yield Savings Accounts investments? They're FDIC insured bank accounts and inherently (essentially!) zero risk. reply hatch7 19 hours agorootparentThe point is they're not zero risk. You are safer investing your money into an index fund ETF. And if you consider them safe, then accept my challenge to find a bank which discloses what HYSA is invested in. Or better yet, do the research yourself and prepare to be amazed and disgusted to see how the proverbial sausage is made. And to the person clamoring on about FDIC insurance, I also invite to look up how many deposits it actually covers, while reiterating that they still have not yet found a single bank which discloses what HYSA investments are in. The Wealthfront reply is on to something, by finding an article which alludes to mysterious \"banks\" your money is lent to. Do more research about those \"banks\" are, though. It's not at all what you think. reply cj 19 hours agorootparentChallenge accepted. Wealthfront: https://www.wealthfront.com/blog/cash-account-apy/ https://www.wealthfront.com/blog/wealthfront-isnt-a-bank/ (See section #2) > Because we broker our deposits, we’re able to offer you access to wholesale interest rates — the interest rates that banks offer to broker-dealers like Wealthfront for deposits, which can be higher than the rates banks offer individual customers. When our partner banks pay a high rate on your deposits, we pass along a high rate to you. TLDR: Wealthfront gives your money to other banks who pay Wealthfront interest which is passed on to you. All FDIC insured. reply torstenvl 18 hours agorootparentprevHow many times has the stock market seen major losses over the past 90 years? How many times have FDIC-insured accounts seen major losses over the past 90 years? reply ezfe 19 hours agorootparentprevLol what? A HYSA is lower risk than an index fund because it's FDIC insured. reply erehweb 19 hours agoparentprevWhere's the risk. It's FDIC insured, no? reply cj 19 hours agoparentprev> These aren't even good investments. VTI is up 25% y/y. It's easy to say this today, but a year ago today the majority of \"experts\" were saying we were heading for a recession (which never materialized). It was anyone's guess whether VTI would have been higher or lower y/y. reply mattgreenrocks 19 hours agoparentprevHYSA has always been the place for emergency funds for me. Very different from an investment. Do people use HYSAs for investing? reply HumblyTossed 19 hours agoparentprevHaha, you do you, man. And good luck to you. reply carlosjobim 19 hours agoparentprevThey lend your money out to other people paying a higher interest. In fact, they lend your money out several times. Even if your bank pays 0% interest, they are lending your money out many times over to people who pay the bank interest. reply carlosjobim 12 hours agorootparentReply to the poster below me, who was censored for some reason: AFAIK the money that people have in their bank accounts are used as reserves for all loans the banks give. I don't know of any separation of funds. reply ta1243 19 hours agoprev [–] There are many banks which give you far better rates. [0] has 47% for example Clearly it's not talking about Lira then, but it doesn't mention currency or country reply frereubu 19 hours agoparent [–] Error: trying to access array offset on value of type null reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary features top high-interest savings accounts with APY ranging from 5.32% to 5.15%, including banks like Customers Bank, Western Alliance Bank, and TAB Bank."
    ],
    "commentSummary": [
      "The debate on highinterest.io compares the safety of FDIC-insured high-yield savings accounts (HYSA) with the risks associated with money market funds, treasury bills, and specific investments like VUSXX fund or SPAXX at Fidelity.",
      "Various investment options such as T-Bills, savings bonds, and ETFs are explored for optimizing finances, building emergency funds, and maximizing returns while minimizing risks, emphasizing tax benefits and solvency considerations.",
      "Recommendations include maintaining a diversified investment portfolio, assessing factors like FDIC insurance and liquidity, to make informed decisions for financial growth and stability."
    ],
    "points": 209,
    "commentCount": 211,
    "retryCount": 0,
    "time": 1708696142
  },
  {
    "id": 39485259,
    "title": "Equifax Imposes New Requirements for Free Credit Reports",
    "originLink": "https://news.ycombinator.com/item?id=39485259",
    "originBody": "For years, I have been obtaining free annual credit reports (annualcreditreport.com) which must be provided by law. Recently, for the first time, when I tried to obtain my Equifax report, I was prompted for an email address and a mobile phone number, a new requirement that apparently cannot be bypassed. The other two bureaus, and Equifax previously, confirmed identity by asking knowledge based questions. They do not need my phone or email for anything.Next, trying to obtain the report by phone instead of web site per instructions, I got to the point where I entered my ZIP code on the phone keypad, the voice menu system correctly repeated the number back to me, but every time I press 1 to indicate it is correct, the system acts like it got an invalid response and only gives me the option to enter further information by voice, not by the phone keypad. Just as with my phone number and email, they do not need to record my voice to provide my report.I wrote a complaint to the annualcreditreport firm earlier this week, no response yet.",
    "commentLink": "https://news.ycombinator.com/item?id=39485259",
    "commentBody": "Equifax free credit report dark patterns201 points by PopAlongKid 14 hours agohidepastfavorite89 comments For years, I have been obtaining free annual credit reports (annualcreditreport.com) which must be provided by law. Recently, for the first time, when I tried to obtain my Equifax report, I was prompted for an email address and a mobile phone number, a new requirement that apparently cannot be bypassed. The other two bureaus, and Equifax previously, confirmed identity by asking knowledge based questions. They do not need my phone or email for anything. Next, trying to obtain the report by phone instead of web site per instructions, I got to the point where I entered my ZIP code on the phone keypad, the voice menu system correctly repeated the number back to me, but every time I press 1 to indicate it is correct, the system acts like it got an invalid response and only gives me the option to enter further information by voice, not by the phone keypad. Just as with my phone number and email, they do not need to record my voice to provide my report. I wrote a complaint to the annualcreditreport firm earlier this week, no response yet. vegetablepotpie 11 hours agoThe problem is, as you articulated, they are required by law to provide credit reporting information about you to you. They have no incentive to do this because they make their money by collecting and selling data about us. They have every reason to use this reporting requirement to collect more information about you. They have every reason to conflate credit freeze with credit hold, and confuse consumers in order to extract regular payments from them. They have zero reason to keep sensitive data about you secure. In fact, they have every reason to promote fear and uncertainty in the public that their sensitive personal information is in the hands of criminals as a growth opportunity for their industry to sell credit monitoring services. They have successfully convinced the public that identity theft is a separate and distinct crime done exclusively by one person to another rather than simply fraud that they are aiding and abetting. Consumers and credit reporting bureaus have a fundamentally adversarial relationship that no legislation can harmonize. They exist because they do serve a purpose for finance, which is to give an indication of how much money they can make lending money to someone. Regardless, this reporting does not have to be done by for-profit corporations. This can just as easily be done by non-profits or government agencies. Although these are not perfect, they are free of the perverse incentives driven by for profit corporate structures. reply ugh123 1 hour agoparent>They have successfully convinced the public that identity theft is a separate and distinct crime done exclusively by one person to another rather than simply fraud that they are aiding and abetting. I interpret that as: Companies like Equifax allow (or disregard good security practices to enable) data breaches to land your data into identity theft rings. They (Equifax) then try to sell you \"protection services\" while they continue to dangle your data to tantalized thieves. What a fucking racket. reply no_wizard 10 hours agoparentprevHere's an idea: lets burn down FICO and the credit reporting bureaus. After all things seemed to work fine before credit scores. Perhaps we put too much \"stock\" in them in the first place. There has to be better ways to manage this. One way I could forsee is a government agency that acted as a reporting depot. Then you could forbid the sale of information, and create legislative firewalls for it to keep it out of the hands of other agencies[1]. Though I will continue to argue that credit scores are deeply flawed[0]. [0]: FWIW, I have excellent credit too, so I hardly run into any real issues with it, but I have see the other side of this table. They are often used in such a way I would classify it as prejudiced discrimination with extra steps. For bigger / riskier loans. You could instead opt for point in time financial audits, for example. [1]: Two things of note. One, last I looked into this, the government very much pulls credit reports on pull without any oversight as it sits today. Two, there is a history of legislative firewalls that do work, they need clear and strong oversight provisions, and today we have almost zero oversight of the credit bureaus. I'd roll the dice on creating something akin to the GAO or Federal Reserve type agencies (that is to say, very independent from lawmakers and presidents but still have competent oversight), but for something that functions for the intentions behind what these scores are suppose to be for. reply ziddoap 10 hours agorootparent>lets burn down FICO and the credit reporting bureaus. This seems to be the harder problem. I read potentially better solutions all the time, but I never read about how to get to that point first. reply judge2020 2 hours agorootparentWhat are these better solutions? The bureaus exist because companies can only quote you loan products if they have a good [enough] understanding of how responsible you are with debt and paying existing creditors. You could make arguments about some pitfalls with the score, but any other creditworthiness system will need a lot of data if lenders want to be able to trust it to provide insight to your monthly debts and payment history. reply 317070 54 minutes agorootparentMany European countries do not have a credit score system. Companies and banks are a lot less inclined to give you credit, but I don't see how that is a bad thing for society? reply tagyro 30 minutes agorootparentGermany enters the scene. There was a recent article about Schufa - https://news.ycombinator.com/item?id=39395329. reply no_wizard 10 hours agorootparentprevIts lack of motivation really. I think people have become ingrained / numb to them that they don't really think about it until they have a problem, or some sector of society gets repeatedly screwed by the bureaus etc. There's been no systematic callout of the bureaus in wider society, that I can tell. reply alexb_ 9 hours agorootparentprev> After all things seemed to work fine before credit scores. Perhaps we put too much \"stock\" in them in the first place. There has to be better ways to manage this. The old way to do it, pre-credit score, is that they would take a look at your zip code, take a look at the color of your skin, and decide if you were a \"trustworthy individual\" reply winrid 3 hours agorootparentThat's just ridiculous. Modern countries like France do not use credit scores. They just look at your last few bank statements. reply judge2020 2 hours agorootparentFrom what I can find online, is it true that “Fichiers Banque de France”, owned by the French Government, has a de facto credit system to log credit defaults (so that lenders can deny you if you’ve missed payments for too long in the past)? reply Aloha 6 hours agorootparentprevOr you'd have tot take out a literal letter of credit from your bank - who would use all of that, plus some other stuff to assess your worthiness. reply lazide 9 hours agorootparentprevNow now, don’t be nasty. They’d also look at the quality of your suit, or lack thereof, your accent, and try to guess your religion. reply cheriot 10 hours agoparentprev100% agree on the incentives Similar to why cookie accept/deny interfaces are atrocious. They're intended to be! I think a solution will require more creativity than \"have the government do it\", but the current system is clearly broken. reply para_parolu 10 hours agorootparentI don’t think government should do it at all. That would be same broken thing. I just don’t want a selected (not by me) set of companies collect information about me without my consent. I would rather have an opt-in system where I can select a vendor to make a report on me to provide to lender. Only when I want it. reply WarOnPrivacy 8 hours agorootparent> I don’t think government should do it at all. I'd want a non-profit to handle it. I'd want full public disclosure of internal processes, data sources and data buyers. I'd want strong, unhindered oversight provided by a fully independent public board along with separate oversight provided by the FTC - with oversight entities able to exhort meaningful influence over methods, sources and customers. reply NoblePublius 6 hours agorootparentprevEvery financial institution has its own credit file on you. They don’t need the third party services at all. Credit profiles can be created easily from any number of public data sources. These companies exist because we wrote laws requiring them to exist, and for no other reason. reply cheriot 5 hours agorootparentIf you don't like the terms with your current bank, how would you apply for a loan with a different one [that doesn't know you]? People need the ability to shop around. reply hellotomyrars 4 hours agorootparentprevThe reach of a per financial institution credit file is different. I’m also not sure how much that is true or practical without a Pre-existing relationship with that particular institution but when your credit is polled for things that aren’t about even obtaining credit (renting/employment) what matters is the FICO Scorsese from the big 3. They have an outsized importance in functioning in society and deserve extra scrutiny. I don’t have an inherent problem with having a broadly accepted and comprehensive credit-risk profile, but the way we do it and the institutions who profit off of it are disgusting. reply godelski 7 hours agoparentprevI don't think OP is reporting because they need to be educated on the motivations of these institutions.[0] I think instead OP is reporting to bring to light an abuse to the system. I'm happy OP is doing this and making noise because we can only address issues we're aware of and that get enough traction. But I find comments like these often become popular and highly upvoted because of their formulation but end up serving very little utility and ultimately dismissive. I think they're upvoted because they are in factual and accurate, and we like the confirmation because it shows how intelligent we are. But I think they end up being dismissive because it is missing the point. It is dismissive because there are no actual points being addressed or solutions being offered. There is an implicit solution of the government generating said report, but I think this would need to be (more) explicit. It also seems that anytime these comments raise to the top that the conversations become very unorganized and off topic, because frankly there is little to go off of. If writing a purely educational response I think it is quite hard to do (and even this comment might have the same repercussions but I'm trying to add more and my intent here is to align the thread. No one need reply to my comment). Personally I think a good solution would be for the law regarding these free reports should be updated to specify that they should not be a data collecting process. That they are only allowed to ask for information that they already have and that this is solely used to verify the authenticity of the user. Using this process to generate novel data is an abuse of the system. I also personally feel that the public should be able to have more recourse for mistakes that are made by these companies (within reason). I still feel like there has not been enough recourse for the Equifax breach and that not enough has been done to protect citizens. I don't think this is an unpopular opinion, but ensuring our politicians are aligned with public beliefs is a whole other conversation. [0] Personally I feel it is pretty obvious and apparent that credit agencies operate to collect and process data about people. It is then also apparent, to me, that of course the incentives align to them getting even more data about you as possible. It seems to me that anyone that is doing yearly report generating is highly likely to be aware of the business model. But not everyone is me so maybe that's not the intent. And what's obvious to one person isn't always obvious to others. reply g051051 8 hours agoparentprev> They have successfully convinced the public that identity theft is a separate and distinct crime done exclusively by one person to another rather than simply fraud that they are aiding and abetting. This demonstrates a fundamental misunderstanding of how credit reporting works. When \"identity theft\" occurs, it's important to realize that the credit reporting firms are not involved. That is solely due to failures, at the institutions that actually grant credit, to verify the identity of the person they are interacting with. The flow goes: a fraudster uses harvested data to impersonate someone to a credit grantor, such as a credit card company. The credit grantor, accepting this identity at face value, asks the credit reporting agency (CRA) about the credit rating of the impersonated entity. The CRA says \"Joe Victim has a relatively low risk of fraud\". So the identity theft has already occurred before the CRA is even consulted. Later on, when the fraudster fails to pay as agreed, the credit grantor incorrectly reports to the CRA that the fraud was caused by Joe Victim. Again, the CRA is just relying on the data provided to them by their clients. reply sidewndr46 8 hours agorootparentYou might want to rethink that. Credit reporting firms actively aid identity fraudsters because it is profitable https://privacyrights.org/data-breaches/court-ventures reply lolinder 8 hours agorootparentprevI understood the comment about aiding and abetting to be a reference to the fact that Equifax leaked about half of all Social Security Numbers back in 2017. For 145 million Americans the \"harvested data\" you refer to was data that the credit bureaus hoovered up and then failed to protect. reply g051051 8 hours agorootparent> Equifax leaked about half of all Social Security Numbers back in 2017. They weren't leaked, they were stolen. Does a bank \"leak money\" when it's robbed? reply lolinder 8 hours agorootparentIf the bank failed to apply industry-standard security techniques then yeah, I'd say the bank leaked money. The criminals are obviously the most culpable, but when you're storing more than 100 million SSNs it's not unreasonable to expect your IT department to: * Update their dependencies within two months of a critical security vulnerability being patched (Mar 7 to May 12). * In the event of a breach, detect it within a reasonable timeframe (76 days is not reasonable when you're the Fort Knox of financial information). * Have a reasonably well-segmented network such that a compromise in a single user-facing web app doesn't lead to your entire network being compromised. reply g051051 8 hours agorootparent> Update their dependencies within two months of a critical security vulnerability being patched (Mar 10 to May 12). They thought they did, but failed. > In the event of a breach, detect it within a reasonable timeframe (76 days is not reasonable when you're the Fort Knox of financial information). Impossible to guarantee. A sophisticated enough attack might never be detected, regardless of the competence of the security department. > Have a reasonably well-segmented network such that a compromise in a single user-facing web app doesn't lead to your entire network being compromised. It is impossible to so completely segment a network. If I can get the data via an authorized program, that means there's a path between networks and a hacker can potentially exploit that path. reply lolinder 7 hours agorootparent> They thought they did, but failed. Oh, never mind then. Clearly since they thought they updated the dependency it's all good. > Impossible to guarantee. A sophisticated enough attack ... It is impossible to so completely segment a network ... While I will acknowledge that this seems to have been Equifax's approach to security (it's impossible to do completely so why bother doing it at all?), this is not widely accepted as a philosophy of security in any industry. That a bank could still be robbed by a military incursion from a neighboring nation state is not sufficient reason to leave the vault door open overnight. The record abundantly shows [0] that Equifax had security protocols that were weak enough that no sophisticated actor was needed to bypass their protections. As far as their failure to detect the breach, this is what the House investigation concluded: > Equifax allowed over 300 security certificates to expire, including 79 certificates for monitoring business critical domains. Failure to renew an expired digital certificate for 19 months left Equifax without visibility on the exfiltration of data during the time of the cyberattack. [0] https://oversight.house.gov/report/committee-releases-report... reply smaudet 5 hours agorootparentAnd they should have been held accountable, were they? If such an entity demonstrates gross negligence yet there are no repercussions, perhaps it is worse than negligence, it is outright larceny - Equifax could be characterizes as a govt supported cartel. It is not unreasonable then we should actually physically destroy their premises and all related collected information as an active threat to the nation, as well as re-issuing all sensitive information to all affected individuals. As for what to do instead, credit reporting need not be the important solution, rather one part of an accepted solution, such as multiple scores issued to multiple numbers that are not tied together by a single bureau. Then when credit checks are pulled it is not sufficient to use a single service and the incentive to illegally utilize said information decreases, as the relevance is reduced for any one credit check. reply drewmol 8 hours agorootparentprevIMO, Leaked is probably the better word here. Equifax did not steal the data in the first place either, they recorded/copied it from other sources which leaked or sold it to them. reply g051051 8 hours agorootparent> other sources which leaked or sold it to them. Every data source (such as a bank or credit card) provides that data to CRAs because consumers granted permission to do so when entering into a business relationship. Either that, or it's publicly available data purchased from aggregators. reply Arrath 7 hours agorootparent> because consumers granted permission to do so when entering into a business relationship Do we have an actual choice? reply lazide 6 hours agorootparentYou could not get a loan or credit, I guess. There are costs to that approach, of course. reply smaudet 5 hours agorootparentWildly unfeasible. The consumer does not have a choice, they do not have an ability to live within their means without incurring credit checks. Take housing - perhaps it is possible to purchase outright a home with cash, however you will not find generally anyone willing to take payment in cash. If you cannot afford that and are not taking a loan, then you must rent. However you cannot rent without a credit score. So no the consumer did not consent to anything. This is a ridiculous and dishonest viewpoint. reply eek2121 13 hours agoprevBanks and data companies are moving to biometrics for proof of identity and you may have hit this. At least 3 credit card companies I use are signed up/using a biometrics/information provider. (they wouldn’t tell me who, despite federal disclosure requirements — I only knew they were using someone because my current accurate info was replaced by info from 7 years ago) There are companies trying very hard to find out everything from your hair color, facial features, and skin type to your email address and connect them all for everything from identity management to advertising. They are working on getting your payroll data directly from your employer as well, so you will not be able to self declare income in the future. You will know when you run across the companies that use these providers because their data is often wrong or out of date and they usually ask you for a video of yourself holding your id to update it and may even give you a problem then. The amount of information these companies are collecting and piecing together is scary — one company is tracking major website comment activity and tying it back to their core data sets which has your IRL info. This means that in the future, you could be denied employment, a mortgage, or an auto loan because of something you said last year in Twitter. reply theturtletalks 11 hours agoparentYou’re forgetting about the KYC/AML laws that lets these companies do that. They can deny bank loans, auto loans, etc based on comment history and then hide behind KYC/AML laws. Under those laws, they don’t have to provide any reason whatsoever for the rejection and can operate without impunity. They are the judge, jury, executioner and the government gave them that power. reply PeeMcGee 11 hours agorootparentFor those of us not up to speed on finance TLA's: KYC (Know Your Customer) AML (Anti-Money Laundering) reply lesuorac 10 hours agorootparentprevI mean if you're not willing to sue somebody then they're always the judge/jury/executioner. It's a bit akin to all those people who complain it's impossible to know why Google closed your account despite evidence [1] to the contrary. [1]: https://www.huffpost.com/entry/why-google-bothered-to-ap_b_2... reply theturtletalks 10 hours agorootparentYou do realize most of these payment processors or even financial institutions have arbitration clauses right? And as a business, they have the legal right to refuse for any reason not disability related. Hell, they could deny a disabled person a loan based on the unlikelihood they would pay it back and then hide behind KYC/AML laws. Oh we're not denying you based on disability, it's just some flags have popped up in our system and we can't tell you why. Google doesn't have KYC/AML laws to hide behind. The funniest part is that HSBC already revealed to criminal organizations on how to evade KYC/AML tripwires. When you outlaw freedom, only the outlaws have freedom. reply rolobio 11 hours agoparentprevTheir data is pretty much always wrong for me. I share my father's name, so whenever I do a credit check they ask me about the homes I owned before I was even born... Unfortunately, my family has moved a lot and I can't remember all the addresses. reply delfinom 9 hours agoparentprevThank god NYS made it illegal for employers to query your existing payroll data from the databrokers awhile back. But unfortunately every single major payroll provider (like ADP) in the US now shares your payroll data with Equifax and more. And those services openly advertise for employers to use them to be able to beat down new employees on salaries among other things. reply xattt 8 hours agoparentprevI made a comment in another post a few weeks about strategies to poison your apparent profile. Any strategies? reply godelski 7 hours agoparentprevI've always found this process and surveillance capitalism completely insane. It is a huge national security issue. I know governments like to have data on people to let them more effectively exert control (for good or bad) but the truth of the matter is that any data that is collected can similarly be used by your adversaries. It is always and will always be a double edged sword. I don't think the problems will be adequately resolved until this becomes deeply ingrained in both the public mind as well as the minds of politicians. Data is certainly extremely useful, but we need to take a moment to weigh the utility against how vulnerable it makes us. reply MyFirstSass 11 hours agoparentprevAre they tracking anonymous comments or how does it work? This should be illegal in all countries. reply ziddoap 10 hours agorootparent>Are they tracking anonymous comments or how does it work? Many people happily put their real names in their social media. Many people put information and/or pictures which easily identifies them when combined with other data, which credit agencies have an enormous amount of (workplace, purchase of a new vehicle, house photos, school, etc.). Those two things alone probably cover a large percent of the population. Add in things like: using a username on social media that is the same/similar enough to the email address you signed up to credit monitoring, purchasing browser fingerprint data from whatever websites and comparing it to logged-in site visitors, etc. and the outlook is bleak. reply nicholasjarnold 12 hours agoparentprevIt's literally out of control. We cannot have a healthy democracy in a systematically surveilled society. When people understand they're being actively and constantly surveilled they tend to self-censor their expression. When we do not have a healthy and honest exchange of expression (something that has arguably been being eroded for a long while now) it will fundamentally erode one of the pillars of our society. Kudos to CA and IL for attempting to do something about this legislatively. As a citizen with some modicum of hope for the future I will vote for strong privacy protections. As an engineer I will not work on products that progress our state of surveillance capitalism (yep, realize the constraints here). I hope others agree and act accordingly. reply nickff 12 hours agorootparentI’m not sure that these requirements are actually due to Surveillance Capitalism; Government KYC requirements may be the culprits, as they’re steadily on the rise (especially with all the recent sanctions). reply chatmasta 6 hours agoparentprevBasically: a bunch of laws intersected to screw you over, even if it wasn't the intent of any one of them individually. But nobody cares, because anyone like you who looks out for their privacy is a weirdo. :( reply thedanbob 12 hours agoprevIt is mind-blowing to me how incompetent the credit agencies are. I just tried to check my credit was frozen everywhere and I couldn't log into Experian. Tried \"forgot my password\"... oops, \"can't find your username\". Tried entering my email, \"please verify with your phone number\"... oops, \"doesn't match our records\". Tried \"verify another way\" and it asked for my phone number and last 4 of my SSN. Hey, that worked! That should not be an option... And guess what, my account lists my username, email, and phone number exactly as I entered them. But I still can't change my password since that requires verifying my current password, which they've apparently forgotten. What an absolute joke. reply jimt1234 11 hours agoparentI think it's the opposite of Hanlon's razor: Never attribute to stupidity/incompetence that which is adequately explained by malice/evil-intent. reply dawnerd 11 hours agoparentprevI'm completely blocked out of equifax ever since their hack. I've even sent them a certified letter and no response. Impossible to call them too. Just says sorry contact us... ok Been annoying when trying to have a credit check run and the place uses equifax and they deny based on frozen credit. Like ya, I know. Could be worse I suppose, could be open and unable to freeze. reply toast0 11 hours agorootparentTry opening a new account with a different email. Worked for me when I tried after going through the process. reply SeanLuke 11 hours agoparentprevYou are not their customer. reply JohnMakin 10 hours agoparentprevJust wait until you have to deal with someone else's credit information showing up in your report because of vaguely-similar names. It's very difficult to deal with without paying for a proxy to deal with it for you. reply toomuchtodo 13 hours agoprevPlease raise a complaint with the FTC and CFPB. Regulators are the only path to success. https://reportfraud.ftc.gov/ https://www.consumerfinance.gov/complaint/ reply 1vuio0pswjnm7 1 hour agoprevYou tried methods #1 and #2. Stamps are expensive but the effectiveness of method #3 might surprise you. The mail-in form is not going to ask for a voice sample. From consumerfinance.gov: \"You can request and review your free report through one of the following ways: 1. Online: Visit AnnualCreditReport.com 2. Phone: Call (877) 322-8228 3. Mail: Download and complete the Annual Credit Report Request form. Mail the completed form to: Annual Credit Report Request Service P.O. Box 105281 Atlanta, GA 30348-5281 You can request all three reports at once or you can order one report at a time. By requesting the reports separately (for example, one every four months) you can monitor your credit report throughout the year.\" reply paws 8 hours agoprevIt's possible to opt out of the TheWorkNumber [0] by postal mail. You might consider it. [1] [0] https://employees.theworknumber.com/employee-data-freeze [1] https://krebsonsecurity.com/2017/11/how-to-opt-out-of-equifa... reply jackson1442 8 hours agoparentHighly recommend doing this - also if you think your employer is reporting data to The Work Number (highly probably if they use ADP), ask them for information on your employee profile. Equifax has lied to me about the existence of my profile even though they did, in fact, have data on me. Only when my employer told me the identifiers for my profile did I find out that they had previous data on me and I was able to opt-out. reply breadwinner 12 hours agoprevRemember, this is the company that could not keep the data they already have safe [1]. And now they want more info from you, so that they can store even more info about you (carelessly) and sell it? This is what happens when you have less regulation. [1] https://www.csoonline.com/article/567833/equifax-data-breach... reply gfs 13 hours agoprevCredit reports are a racket. I've barely had any luck obtaining one of my reports from the site in the past few years. I'm at the point where I think I will freeze my credit. reply davidjade 13 hours agoparentWe’ve been living with credit freezes for over 10 years now, ever since a bunch of fraud incidents (thanks leaky IRS). Only ever have to deal with it when we need credit (rarely), putting in for a temporary lift. Bonus is we get zero refinance or CC offers in the mail. reply biftek 12 hours agoparentprevEveryone should freeze their credit by default, it's very easy to unfreeze when you actually need to apply for something. reply alistairSH 12 hours agorootparentIdeally, that would be the default state, and you'd request un unlock when you need to borrow money. reply sidewndr46 8 hours agorootparentprevI did that years ago and I've passed multiple hard credit checks. It doesn't do anything. reply sidewndr46 8 hours agoparentprevI'm in my mid 30s at this point. Starting on my 18th birthday I've never been allowed to see my credit record from at least one bureau. Any attempt to do so is met with a requirement to prove my identity, and any attempt to prove my identity is responded to with a request for further documentation. reply JamesSwift 13 hours agoparentprevI recently had someone submit a fraudulent loan application using my information. I went through the process of freezing immediately after, and I would highly recommend you do it. It was the easiest thing possible. I just went to the links on here https://www.nerdwallet.com/article/finance/how-to-freeze-cre... and was done in like 10 minutes for all 3. reply rufus_foreman 10 hours agoparentprevI applied for a credit card recently and got denied, which was weird since I have a good credit score. Applied for a different one, they eventually emailed and asked if I still wanted the card. When I said I did, they told me they needed me to unfreeze one of my credit reports. I had forgotten I did it years ago. Oops. I eventually got a snail mail from the first credit card company telling me that was why it was denied and to unfreeze it if I still wanted the card. reply arkadiyt 12 hours agoprevI continue to request my reports via certified mail to the annualcreditreport address, and this time for the first year Equifax just ... didn't reply. Completely ignored my request. reply gzer0 11 hours agoparentSubmit a complaint via the CFPB. They most certainly will then respond. I had a frustrating experience trying to obtain my consumer report from Early Warning Services, a less-known alternative to Chex Systems. Their process for requesting a report was unnecessarily complex and seemed designed to discourage users. Initially, I had to navigate to a hidden webpage, which then directed me to a PDF form. This step alone was convoluted. After filling out the form, I discovered a line within the PDF that provided a link to a consumer portal, which looked like it hadn't been updated since the early 2000s. The next step required me to create an account on this outdated portal, upload the completed PDF, and wait for a response. However, my troubles didn't end there. For reasons unknown to me, my account was suddenly deleted. When I reached out to their IT support for help, they were clueless about the reason behind this issue. Fed up with the lack of support and transparency, I decided to file a complaint with the Consumer Financial Protection Bureau (CFPB). To my surprise, this action prompted a swift response from Early Warning Services. Within just two days of filing the complaint, they sent me my consumer report. reply gottorf 12 hours agoparentprevDo you have your credit frozen with just Equifax, or something? Just trying to think of vanilla (i.e. incompetence rather than malice) reasons to explain this. Of course, it goes without saying that they all suck... reply dylan604 12 hours agoprev> confirmed identity by asking knowledge based questions I'm not sure I feel good about this either. Isn't your mother's maiden name, the street you grew up on, your first concert, or your pet's name all information that is pretty much well known by now. Primarily by you (royal) for taking those stupid social media quizzes. reply jerhewet 11 hours agoparentI actually prefer this over the other currently available options (Install our app on your phone so you can click \"Accept\" ... and give us access to scrape everything off of your smartphone!). I just select random questions from their list, and use the same answer for each of the questions. If they don't accept the same answer for each question, then I conclude I don't need whatever it is they're offering as badly as they think I need it, and move on to another entity or form of communication (if you won't make this convenient for me, then fine -- you can send me snail mail correspondence). reply MyFedora 10 hours agorootparent> ... and give us access to scrape everything off of your smartphone! Deny them the access? Phones are way more restricted than home computers here. App stores also reject apps that insist on permissions that are out of their scope. reply staplers 9 hours agorootparentApp stores also reject apps that insist on permissions that are out of their scope. Only for smaller apps. There are major apps that have unique integrations with app stores and consumer devices. Phone security/privacy is largely PR in this regard. reply dylan604 11 hours agorootparentprevI used my password manager to fill in those questions with passwords, but that proved difficult when I had to provide the answer to the question over the phone to some rep. reply themagician 9 hours agoparentprevThe funniest part about these is that if someone has stolen your identity and successfully gotten things added to your credit report then you may actually FAIL to answer correctly questions about yourself. reply motohagiography 11 hours agoprevTheir continued existence is pernicious and a policy failure. We should be able to replace them with a competitive privacy preserving scheme that wipes those businesses out. reply Sohcahtoa82 11 hours agoprevI just stick with Credit Karma for keeping up with my credit report. Yeah, they want to sell me loans and shit, but it's easy to ignore/block those ads and just get the data I'm looking for. reply soared 9 hours agoprevThis is most likely why https://unifiedid.com/ reply cheesemayo 12 hours agoprevGiving them the benefit of a doubt, it could be a first (or half) step in adding a level of security around credit information. It wasn't long ago that they were breached (not though user identity checking! by a software vuln!) and they're probably still smarting from it. Maybe this is part of a half-baked auth scheme or notification system. reply captn3m0 6 hours agoprevI found a security issue in the credit reports Equifax India sends out. Been trying to report it for almost a year now I think. Equifax doesn’t care. reply 29athrowaway 1 hour agoprevEquifax is the only company ridiculed in political satire shows with full length episodes due to their inept information security practices. reply hellotomyrars 8 hours agoprevI haven’t had issues with the annual credit report process personally. The system is shitty though. Equifax will give you a copy off your real credit report once per month if you sign up with them which is better than the other two will do. The rub though is they try as hard as possible to make you think you have to pay for it and every time you sign in you have to decline to pay. It’s so fucked up. If we’re going to have our lives controlled by credit agencies, then individuals should be able to access their real score at any time for no cost and no bullshit. What a fucking racket. reply olliej 12 hours agoprevI still love the whole \"we know our data is wrong, but we sell it as fact, and know that that information is used to impact cost to you, but you're required to constantly check with us, or pay us to tell you when we're lying\". Yet somehow this isn't extortion, and somehow it's not illegal defamation. The moment credit agencies started running their own monitoring services, it seemed like they were openly admitting that they were defaming people. I still do not understand why this is legal. reply g051051 8 hours agoparent> The moment credit agencies started running their own monitoring services, it seemed like they were openly admitting that they were defaming people. I still do not understand why this is legal. If you're signed up for credit monitoring, you get notified when your credit info gets changed, so you have a chance to react if it's an error (or fraud). How is that defamation? Why would it be illegal? reply handoflixue 1 hour agorootparentg051051? The guy who keeps trying to post porn all over this site? I can't believe you've got the guts to go posting here. I've told everyone about your disgusting behavior. What's that? You never did that? Well, for just $5/month you can sign up for my monitoring service and we can investigate your claims. In the mean time, I'm going to keep warning everyone about your behavior. I feel like most people would consider the above behavior unacceptable, but it's okay because I'm a big company dedicated to stopping perverts like you. (hopefully it is clear that I'm not actually serious. Unlike the credit agencies) reply olliej 5 hours agorootparentprevNo. It's defamation because they know their information is frequently incorrect, that it is trivial for people to get outright fraudulent transactions attached to people's \"credit report\". Knowing that, they then present that information as fact to others, despite knowing that the information they provided is used specifically for purposes where false information will add significant costs to the people they're reporting on. Now you're right, I can get credit monitoring, in which I pay money so that I can spend my time verifying they're not publishing fraudulent information. So now it goes from defamation to extortion: we'll defame you unless you pay us and do the work of ensuring we don't defame you. reply mindslight 8 hours agoparentprevThe answer is that they literally bought their own law exempting themselves from defamation laws. It's called the \"Fair\" Credit Reporting Act. Legislative sanity would see a repeal of the FCRA and the addition of a US equivalent of the GDPR, giving us a right to privacy that's applicable to every single company. I don't consent to being a data subject of any part of the surveillance industry, including this oldest part calling themselves \"credit bureaus\". reply dheera 11 hours agoprevThey already have your mobile phone number because banks and credit lines you take will report that information to them. They ask you for your phone number to verify you, not because they want your phone number when they already have it. If you want to avoid them knowing your \"real\" phone number and leaking that to marketing agencies, the best thing you can do is get 2 mobile phone numbers, one you actually use with your friends and family, and one you provide to businesses and stick that SIM in a beater phone and keep it silent. I HATE this system and wish we had some GDPR-like law for preventing sharing of such information outside the corporation you provide it to, but such is the current state of the system in the US. reply jimt1234 11 hours agoprev [–] Quit complaining. If your personal data is leaked, and your credit and financial life is ruined, at least you get a year of free credit monitoring. Sheesh. /s reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The person is facing new requirements from Equifax for obtaining their free annual credit report, such as providing an email address and a mobile phone number.",
      "Difficulties arose when trying to obtain the report via phone due to the system not recognizing their input.",
      "A complaint was submitted to annualcreditreport.com, but they are still waiting for a response."
    ],
    "commentSummary": [
      "The discussion centers on Equifax and credit bureaus' unethical practices, such as collecting excessive personal data, security flaws, and a lack of accountability.",
      "Recommendations include exploring new credit scoring systems, enhancing government supervision, and fortifying privacy safeguards amidst rising worries about data breaches and identity theft.",
      "To mitigate risks, users are urged to freeze their credit, report issues to regulators, and safeguard personal data to deter fraud and privacy infringements."
    ],
    "points": 201,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1708717743
  }
]
