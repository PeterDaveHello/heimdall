[
  {
    "id": 37125118,
    "title": "Show HN: LLMs can generate valid JSON 100% of the time",
    "originLink": "https://github.com/normal-computing/outlines",
    "originBody": "Outlines is a Python library that focuses on text generation with large language models. Brandon and I are not LLM experts and started the project a few months ago because we wanted to understand better how the generation process works. Our original background is probabilistic, relational and symbolic programming.Recently we came up with a fast way to generate text that matches a regex (https:&#x2F;&#x2F;blog.normalcomputing.ai&#x2F;posts&#x2F;2023-07-27-regex-guide...). The basic idea is simple: regular expressions have an equivalent Deterministic-Finite Automaton (DFA) representation. We can transform this DFA into a generative model: in each state we get a list of symbols which correspond to completions that partially match the regular expression. We mask the other symbols in the logits returned by a large language model, sample a new symbol and move to the next state. The subtelty is that language models work with tokens, not symbols, so we derive a new FSM whose alphabet is the model&#x27;s vocabulary. We can do this in only one pass over the vocabulary.Generating the token masks thus only requires a dictionary lookup at each state. Our method blows other libraries like Microsoft&#x27;s guidance out of the water.From there it was only a small leap to be able to generate text that follows a JSON schema (https:&#x2F;&#x2F;json-schema.org&#x2F;), or is parseable into a Pydantic model (https:&#x2F;&#x2F;docs.pydantic.dev&#x2F;latest&#x2F;usage&#x2F;models&#x2F;). The method works with union types, optional types, nested schemas, arrays, everything. It is guaranteed that the output is parseable.I think it&#x27;s cool, and I&#x27;ve spent a lot of time watching even tiny models output valid JSON over the weekend. Hope you will too.I look forward to feedback, bug reports, feature requests and discussions!Edit: Link to our pre-print explaining the method and how this can be extended to generate text that follows a Context-Free Grammar https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702",
    "commentLink": "https://news.ycombinator.com/item?id=37125118",
    "commentBody": "Show HN: LLMs can generate valid JSON 100% of the timeHacker NewspastloginShow HN: LLMs can generate valid JSON 100% of the time (github.com/normal-computing) 738 points by remilouf 15 hours ago| hidepastfavorite236 comments Outlines is a Python library that focuses on text generation with large language models. Brandon and I are not LLM experts and started the project a few months ago because we wanted to understand better how the generation process works. Our original background is probabilistic, relational and symbolic programming.Recently we came up with a fast way to generate text that matches a regex (https:&#x2F;&#x2F;blog.normalcomputing.ai&#x2F;posts&#x2F;2023-07-27-regex-guide...). The basic idea is simple: regular expressions have an equivalent Deterministic-Finite Automaton (DFA) representation. We can transform this DFA into a generative model: in each state we get a list of symbols which correspond to completions that partially match the regular expression. We mask the other symbols in the logits returned by a large language model, sample a new symbol and move to the next state. The subtelty is that language models work with tokens, not symbols, so we derive a new FSM whose alphabet is the model&#x27;s vocabulary. We can do this in only one pass over the vocabulary.Generating the token masks thus only requires a dictionary lookup at each state. Our method blows other libraries like Microsoft&#x27;s guidance out of the water.From there it was only a small leap to be able to generate text that follows a JSON schema (https:&#x2F;&#x2F;json-schema.org&#x2F;), or is parseable into a Pydantic model (https:&#x2F;&#x2F;docs.pydantic.dev&#x2F;latest&#x2F;usage&#x2F;models&#x2F;). The method works with union types, optional types, nested schemas, arrays, everything. It is guaranteed that the output is parseable.I think it&#x27;s cool, and I&#x27;ve spent a lot of time watching even tiny models output valid JSON over the weekend. Hope you will too.I look forward to feedback, bug reports, feature requests and discussions!Edit: Link to our pre-print explaining the method and how this can be extended to generate text that follows a Context-Free Grammar https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702 YeGoblynQueenne 19 minutes agoHi, remilouf. You say that your background is in \"probabilistic, relational and symbolic programming\". In that case I suspect you understand that it is no problem to generate text from a regular or context-free grammar, or really any level of grammar. For example, you can do that very easily in Prolog (a relational language) given a grammar in Definite Clause Grammars notation.As far as I can tell your approach requires a grammar to be given by a user. In that case, what is the advantage of using an LLM to generate text? Why can&#x27;t you just run your grammar as a generator and generate the text you want? That would save you the considerable trouble and cost of training an LLM in the first place. And why would you need an LLM, a model of natural language, if all you want is to generate structured text, anyway? reply hansvm 2 hours agoprevA major part of the power of an LLM is the calibrated probability distribution in its responses, and this technique probably throws that ability away. Why is it good enough?As a brief example, suppose the only possible LLM outputs were \"hello world\", \"food\", \"hello\", and \"good day\" (and that they&#x27;re all equally probable with no prompting). Suppose your grammar requires a space in the output somewhere and has no other constraints. If you sampled LLM outputs till something passed the grammer you&#x27;d receive \"hello world\" and \"good day\" with equal probability. If you apply the website&#x27;s technique you&#x27;ll receive \"hello world\" twice as frequently as \"good day\".The core problem is that an answer prefix might have been extremely unlikely to yield a valid response, but the technique (probably -- assuming it succeeds -- my example assumed retries would eventually succeed) constructs a valid response from it regardless. Assuming enough independence in the right places everything is fine and dandy still, but correlated errors compound quickly in autoregressive models.As a brief JSON-specific question, is an LLM more or less likely to make factual errors (hallucinations, truncated strings, missing main characters, ...) when it produces a response failing to adhere to a schema? If factual error rate relates nontrivially to schema error rate then this path is more perilous than it seems. Given the outsized impact certain words or schmooshed together word-phrases seem to have on LLM output, I&#x27;d be surprised if details like schema adherence didn&#x27;t bleed into other characteristics of the output. reply druskacik 1 hour agoparentIn this case (multiple choice generation), if one of the possible outputs does no match the regex, you can just exclude it from generation.I am trying to think of an example where \"answer prefix might have been extremely unlikely to yield a valid response, but the technique ( ... ) constructs a valid response from it regardless\", which might really cause a problem. But to no luck. Anyone has any idea? This could potentially be an interesting research question. reply activatedgeek 13 hours agoprevMechanistically, I think this library takes the simple idea of masking part of the vocabulary space and steps in time efficiently. Great!I am curious, however, for the ones who have played around with such libraries wrapping base LLMs with output structure: do base models like Llama2 work very well? My experience says \"hell no!\" and you do need a fair bit of instruction-tuning for specific use cases to actually get things to work.And even then, it seems very counter-intuitive to me that given an instruction-tuned model, post-hoc masking of the state-space during generation then amounts to just changing the generation distribution, and potentially detrimental to instruction-tuning? reply simonw 6 hours agoparentI&#x27;m quite impressed with Llama 2 13B - the more time I spend with it the more I think it might be genuinely useful for more than just playing around with local LLMs.I&#x27;m using the MLC version (since that works with a GPU on my M2 Mac) via my https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-mlc plugin. reply moneywoes 5 hours agorootparentWhat are your use cases reply simonw 4 hours agorootparentThe thing I really want to get working is retrieval augmented generation - so effectively answering questions based on a blob of context that I pass in, and being able to do good-enough summarization.I haven&#x27;t quite proved this to myself yet but I think it&#x27;s going to work pretty well. reply nl 3 hours agorootparentprevNot simonw, but I&#x27;ve been using Llama2-13B for search re-ranking very successfully. reply LakshyAAAgrawal 3 hours agoparentprevIn our experience, at least for code generation, the experience has been that base models can be improved significantly by guiding token level generation.In our paper titled \"Guiding Language Models of Code with Global Context using Monitors\" (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763), we propose Monitor Guided Decoding, which interfaces LLMs to static analysis, and guides the model to generate type-consistent code. Without any kind of fine-tuning, we show that using static analysis to guide token level generation at specific points leads to significantly improved quality of generated code, both in terms of compilability and match with ground truth. Even very small models (1.1B) are able to generate more compilable code than much larger models (175B) while also improving on match with ground truth. reply Roark66 2 hours agorootparentIt is an interesting paper. Any idea when the code&#x2F;data will be released? It appears it has been almost 2 months since the paper was submitted, but the link given leads to a random bing page :-( reply ethbr1 12 hours agoparentprev> ...given an instruction-tuned model, post-hoc masking of the state-space during generation then amounts to just changing the generation distribution...Isn&#x27;t that what we did with test driven development?The primary difference was our generator functions were human instead of LLM. Why not cut out the middle-human? reply spockz 6 hours agorootparentYes. And if that human was smart and knowledgable they would use property based testing to automatically generate test inputs. Most libraries make it trivial to do for custom data types and can even reduce the failing test case to a minimal size input. I have been using this since 2008 and it was around before that. reply activatedgeek 9 hours agorootparentprevI think what I am saying is tangential to TDD. I am not really even concerned about the ability of LLM to function as desired, and its verification.I was rather concerned about a broader fundamental question - how does post-hoc guided generation interfere with the potential benefits of instruction-tuning? reply Havoc 11 hours agoparentprev>you do need a fair bit of instruction-tuning for specific use cases to actually get things to work.The instruction tuning part is \"trivial\"...it&#x27;s the dealing with edge cases part that gets me.With classic code edge cases are well insignificant edge cases. With LLM you never know what will make it go off on a tangent & the parsing code needs to deal with that chaos.Or put differently the % of cases that are edge cases seems to have gone up dramatically reply make3 12 hours agoparentprevI&#x27;m not sure of why you would want to use raw llama-2 though when there is a million super strong instruction fine-tuned versions of llama-2 on HF hub that would do the job a million times better? Like Stability-AI&#x27;s Beluga-2. See https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;HuggingFaceH4&#x2F;open_llm_leaderb...About your second point, the goal is that the model can only generate JSON (for example), which can 100% be done by constraining which output token can and cannot be used. reply nabakin 12 hours agorootparentDon&#x27;t rely too much on automated benchmarks for LLMs. They are often gamed, made to overfit, and result in worse performance in the general case.Human evaluation is the gold standard and the Llama 2 paper gave significant evidence that Llama 2 70b chat is on-par, if not, better than ChatGPT for that metric so I tend to stick to it unless there is good reason not to. reply huevosabio 12 hours agorootparentThe problem with Llama 2 chat versions is that they have been RLHF-ed to death. You can&#x27;t ask questions without getting a sermon of how your question may be inappropriate for this or that reason.I think it&#x27;s worse on the smaller models, but still present in the 70B one. reply dceddia 10 hours agorootparentApologies if you’d already seen this and were only trying to make a point, but you might like this article from a week or 2 ago that talks about how to run Llama 2 “uncensored” locally, and it seems to do a decent job of mitigating the sermons!Article: https:&#x2F;&#x2F;ollama.ai&#x2F;blog&#x2F;run-llama2-uncensored-locallyDiscussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36973584 reply superkuh 7 hours agorootparentWhen you encounter \"uncensored\" in a llama model (1 or 2) what that means in that context is that the fine-tuning datasets used have had all refusals to respond removed. There&#x27;s no way to uncensor the pre-trained model itself and fine-tuning only changes the style of the output. reply nabakin 5 hours agorootparentprevFor sure, that&#x27;s a good reason for using the uncensored fine-tuned versions. There are other good reasons too like expanded context size, codegen, and story writing&#x2F;rp. Just be careful of extraordinary benchmarks.Btw, have you tried changing the default Llama 2 chat prompt? Meta tried to fine-tune it so that if you remove the safety part from the prompt, safety won&#x27;t be applied[1]. Not sure how well it works myself, but worth a shot I guess[1] can be found in the Llama 2 paper reply activatedgeek 9 hours agorootparentprev> I&#x27;m not sure of why you would want to use raw llama-2Sure. My concern was not specific to llama-2, and was only using it as a placeholder example of a decent pre-trained base model. Replace it with your favorite base model, which you want to use for guided generation. My question is more fundamental - how does post-hoc guided generation interfere with the potential benefits of instruction-tuning?> About your second point, the goal is that the model can only generate JSON (for example), which can 100% be done by constraining which output token can and cannot be used.Mechanistically, yes. I am not arguing that. The whole point is to generate JSON that is \"useful\". reply panarky 14 hours agoprevI can make GPT4 return valid JSON simply by providing examples in the system message. This works nine times out of ten.But it&#x27;s still probabilistic, and nine times out of ten isn&#x27;t good enough.Occasionally it will hallucinate responses like this:{\"key1\": \"value1\", \"key2\": \"value2\" for i in range(n)}Re-prompting with the parsing error message is usually enough to get it on the second try.But escaping double-quotes and newline characters is less reliable. Even after giving it multiple examples, it correctly escapes only about half the time.Re-prompting for escaping errors still yields a ~50% success rate. reply msp26 0 minutes agoparent>I can make GPT4 return valid JSON simply by providing examples in the system message. This works nine times out of tenBut you can do both. For my current use case of extracting information from articles, I have one&#x2F;two example articles along with their correct answers. This increases token costs but 3.5 is so cheap that it doesn&#x27;t matter and for 4 you can use batching to decrease token cost per article. reply simonw 12 hours agoparentprevThat re-prompting on error trick is what this new Microsoft library does, too: https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChatHere&#x27;s their prompt for that: https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChat&#x2F;blob&#x2F;c45460f4030938da3...I think the approach using grammars (seen here, but also in things like https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773 ) is a much more elegant solution. reply padolsey 13 hours agoparentprevI&#x27;ve had more luck with getting it to output XML as (1) You can imbue XML with actual language&#x2F;meaning (which LLMs adore) and (2) parsers can be made to be more forgiving. I get why people want to make JSON, but to me it&#x27;s a bit like trying to get a cat to swim - you might eventually succeed, but it&#x27;s not their natural inclination. reply prempv 5 hours agorootparentI&#x27;ve had the same experience as well. I suspect if it&#x27;s due to large presence of HTML in the training data as part of codebases and online content reply gowld 12 hours agorootparentprevHow do you imbue XML with meaning? reply padolsey 12 hours agorootparentXML Elements themselves: their naming, their attributes, comments, indentation. There&#x27;s more opportunity at every level of the hierarchy to demarkate and establish meaning. Having closing-tags as well, I&#x27;ve found, is a massive boon; LLMs can better understand what \"finishing\" looks like if its delimited in a semantic way - with a name. reply BoorishBears 6 hours agorootparentSame works for JSON. Naming JSON keys works for adjusting what the output is nicely, and you can comment in your definitions (by defining them in a JSON Schema, or inserting placeholder text like `\"someKeyWithClarifyingDetails\": `)I&#x27;m actually partial to CSV these days though, it can really cut down on response times just not needing to return all the extra tokens for JSON&#x2F;XML delimiters reply padolsey 2 hours agorootparentOstenibly yeh JSON should be able to encapsulate mose of that semantic stuff but having replaced an XML schema in the system prompt with gpt&#x27;s function-calling API I&#x27;ve been very umimpressed. It feels much less capable. I would have to provide a lot more clarifying prompts to make it more capable. I think I will, for now, bias to using schemas that are closest to prose. reply DonHopkins 54 minutes agorootparentprevYikes. This makes me think that JSON&#x27;s stubborn mistake of not allowing comments is yet another \"Billion-Dollar Mistake\", since it&#x27;s way too late to just change the standard to allow comments, update all the JSON content on the internet to use comments, and retrain all the LLMs to understand comments.Great point about CSVs! But using placeholder keys for JSON comments in untenable, and using schema instead of inline comments is clumsy and indirect. Of course JSON schema are quite useful in certain situations, but LLMs would get a lot more meaning out of casual common JSON if it just allowed comments, and it would also greatly benefit humans.Between JavaScript&#x27;s and JSON&#x27;s mistakes, that&#x27;s at least THREE BILLION DOLLARS!!! ;)https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tony_Hoare#Research_and_career>Speaking at a software conference in 2009, Tony Hoare apologized for inventing the null reference:>\"I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn&#x27;t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.\" -Tony Hoarehttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19568378>\"My favorite is always the Billion-Dollar Mistake of having null in the language. And since JavaScript has both null and undefined, it&#x27;s the Two-Billion-Dollar Mistake.\" -Anders Hejlsberg>\"It is by far the most problematic part of language design. And it&#x27;s a single value that -- ha ha ha ha -- that if only that wasn&#x27;t there, imagine all the problems we wouldn&#x27;t have, right? If type systems were designed that way. And some type systems are, and some type systems are getting there, but boy, trying to retrofit that on top of a type system that has null in the first place is quite an undertaking.\" -Anders Hejlsberg reply BoorishBears 3 minutes agorootparentI&#x27;m not saying use placeholder keys: the actual keys themselves serve as guidance.Naming a key \"nameBasedOnLocationIGaveYou\" instead of \"name\", or \"oneSentenceSummary\" vs \"summary\", results in a meaningful difference.You can even use that for formatted single-response chain of thought, like {\"listOfStuff\":[...], \"whatDoTheyHaveInCommon\": \"\", \"whichOneIsMostImportant\": \"\"}Also remember, the LLM doesn&#x27;t need valid JSON: I just straight up insert comments in the JSON in a non-compliant way for some of my prompts, GPT-4 and Claude are all smart enough to not hallucinate comments back at you. 3.5 might be pushing it if temp is too high (although even the nerfed API logit bias should fix that now that I think about it)And sometimes to save tokens I describe a JSON object without using JSON: just structure it in neatly formatted markdown and even 3.5 can follow alongcaesil 12 hours agoparentprevWith ChatGPT function calling I get valid JSON 100% of the time from GPT-4 unless I have made some error in prompting.The chief error is not providing escape hatches. LLMs look for a right answer. If you are feeding it some texts and asking it to return structured data about the texts, but then one of the texts is blank, it will be difficult to determine a right answer, so you get hallucinations. The solution is an escape hatch where one of the arguments is a `textIsMissing` boolean or something.As long as you&#x27;ve accounted for these failure modes, it works flawlessly. reply reissbaker 10 hours agorootparentGPT-4 is amazing, but the upside of smaller models is much lower cost. I get basically 100% accuracy on JSON modeling with GPT-4 with function calling too, but I will say that gpt-3.5-turbo with function calling is somewhat less accurate — it usually generates valid JSON in terms of JSON.parse not exploding, but not necessarily JSON following the schema I passed in (although it&#x27;s surprisingly good, maybe ~90% accurate?). I use 3.5-turbo a decent amount in API calls because it&#x27;s just a lot cheaper, and performs well enough even if it&#x27;s not gpt-4 level.I haven&#x27;t gotten a chance to earnestly use the smaller Llama models yet in more than small prototypes (although I&#x27;m building a 4090-based system to learn more about finetuning them), but the little amount of experimenting I&#x27;ve done with them makes me think they need a decent amount of help with generating consistently-valid JSON matching some schema out of the box. This is a pretty neat tool to use for them, since it doesn&#x27;t require finetuning runs, it just masks logits. reply BoorishBears 6 hours agorootparentclaude-1.2-instant came out last week and is doing extremely well at following schemas.I&#x27;d say it&#x27;s reached 3.5 turbo with the format following skills of GPT-4, which is powerful once you give it chain-of-thought reply selcuka 8 hours agorootparentprevThe premise of function calling is great, but in my experience (at least on GPT-3.5, haven&#x27;t tried it with GPT-4 yet) it seems to generate wildly different, and less useful results, for the same prompt. reply ipaddr 4 hours agorootparentYou can change the randomness value to 0 and get the same output each time for the same text reply selcuka 4 hours agorootparentI should probably re-test it, but I think it wasn&#x27;t the temperature. The results were unusually useless. reply karmasimida 3 hours agoparentprevI see grammar constrained generation for 2 major advantages:1. It consumes fewer tokens, no need to add too many examples into the prompt.2. It suffers less from the forgetting issue.Another minor advantage is you can control precisely where your desired output to begin with.But overall, those are nice perks not too substantial IMO. reply nextaccountic 12 hours agoparentprevWhat about reprompting with a different temperature value?If this works, how to select the optimal value? Maybe you can train a model that can excel at the task of querying gpt4 for valid jsons reply MuffinFlavored 13 hours agoparentprevI wonder if the next iteration of OpenAI features is something like:right now you can inject prompts that the LLM takes into consideration before the outputI wonder if you can make it have a \"post\" generation function that says like \"keep re-trying in a loop (aka hallucinating with randomness) until the output message passes XYZ format&#x2F;checks&#x2F;scoring\" reply padjo 12 hours agorootparentIt’s starting to feel like LLMs are to “classical” software engineering what quantum physics was to classical physics reply catlifeonmars 9 hours agorootparentHow so? I’m not quite following the analogy. reply antonvs 8 hours agorootparentJust guessing what was meant, but quantum physics in some sense tries all possible paths before an outcome is selected.The problem with that is that without a quantum computer, or without some sort of filtering, that process can take up to infinite time. reply kristjansson 4 hours agorootparentprevWhy wait for OpenAI? reply andreygrehov 7 hours agoparentprevMeh... I asked GPT4 to return a sample PHP code inside of a random JSON. It failed the JSON linter from the very first try. I actually couldn&#x27;t pass the validation despite many retries, eg follow up corrections. Not a single time it generated a 100% valid JSON, I eventually gave up. reply ipaddr 4 hours agorootparentThis worked with chatGPT: create a sample hello world in phpstore that code in a json[objectcode: { \"php_code\": \"\" } reply adamrezich 1 hour agorootparentprevif you think that&#x27;s bad, try to get it to generate Inform 7 games—Inform&#x27;s natural-English-ish syntax completely throws all LLMs for a loop, consistently. it generates code that looks possibly correct (to an Inform newbie at least), but fails to compile far more often than not. I find this super interesting. reply phillipcarter 12 hours agoparentprevThis is what we do, but for GPT-3.5. And it doesn&#x27;t need to be system messages either. We even have it emitting only JSON in a specific structure (except for when it fails to produce an output altogether). This is without the function calling model. reply thumbsup-_- 12 hours agoparentprevYeah same thing. I have done the same with GPT-3.5. Simply ask it to output using provided schema only and give a few examples. Always outputs in provided json format reply orasis 12 hours agoparentprevWhat about using ChatGPT’s new function calling mechanism? reply superasn 12 hours agorootparentThat returns broken JSON a lot of the times too reply keiferwiseman 14 hours agoparentprevIt took some iterations but I&#x27;ve managed to get the OpenAI API to give me valid JSON 100% of the time now(based on my testing). I think I put in the prompt to never use newlines because it was causing issues lol. reply xigency 14 hours agoprevThanks for building this. The mechanics are such an obvious idea that it&#x27;s astounding that the first-party platforms haven&#x27;t done this yet. I would be interested to see how this could be used for other tasks outside of JSON that require structured input. reply umvi 13 hours agoparent> it&#x27;s astounding that the first-party platforms haven&#x27;t done this yetI was under the impression LLM tech is currently in a breakneck arms race and that things are dramatically changing every few months. It could simply just be a consequence of limited developer resources. It would be \"astounding\" if decade-old tech were missing such a fundamental feature, but for AI tech in arms-race mode it seems reasonable that they are still missing QoL features. reply winwang 11 hours agorootparentI think they meant that you&#x27;d expect simpler&#x2F;more obvious ideas to be implemented first. reply remilouf 14 hours agoparentprevThanks! We have extended the approach to grammar-based sampling. We describe the approach in the paper linked above. The following PR is relevant: https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178 reply Lerc 12 hours agorootparentCould this same approach be applied at training? If the guidance does a lot of the syntactical heavy lifting, would that create the opportunity for a model to use the weights for something else. Essentially not bothering to reduce the error of things that the guidance will stomp on anyway. reply LakshyAAAgrawal 12 hours agoparentprevHi, the paper at https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763 titled \"Guiding Language Models of Code with Global Context using Monitors\" shows how to have the language models generate code without hallucinated dereferences. reply kevinlu1248 34 minutes agoprevThis is amazing! I think for production and rapid development use-cases though we just use XML for information extraction. It&#x27;s extremely easy to parse with regex and rarely do the models make mistakes since the start and end tokens are uncommon. At least this is just for the OpenAI model which are different from the use cases in this ShowHN. reply J_Shelby_J 14 hours agoprevSo to explain this another way:After each token generated by the LLM you update the logit bias “mask” to only allow the next token to be a valid json token?Very slick! reply dontreact 13 hours agoparentYou would also need to keep generating until the whole string is valid. And what if it gets caught in a loop?Not sure how this can really guarantee 100% reply orlp 12 hours agorootparent> And what if it gets caught in a loop? Not sure how this can really guarantee 100%It&#x27;s not great but after some timeout you can just set the mask to only include closing brackets. reply aassddffasdf 12 hours agorootparentYou would still have to ensure balancing somehow. Both \"]\" and \"}\" are valid \"closing brackets\" and the correct one to choose is context-dependent. reply gyy52380 11 hours agorootparentYou can determine which brackets you need in which order by parsing the incomplete json which was generated so far. reply dontreact 10 hours agorootparentThat won&#x27;t do it, also need to close other stuf{\"this\": \"is valid json so farrrrrrrrrrrrrrBut yeah the general idea makes sense. Once you hit a timeout, change the mask to things that will close existing open things in a valid manner (}, ), ], \") reply kristjansson 4 hours agorootparentprevSame problem with normal sampling - if it doesn&#x27;t pick thetoken, you&#x27;re stuck generating until you hit some stopping heuristic (max tokens, timeout, etc.) reply remilouf 14 hours agoparentprevIndeed. And we&#x27;re able to update the mask with a dictionary lookup instead of looping over the entire vocabulary (slow!). reply bmc7505 7 hours agoparentprevYou also need some kind of beam search or rejection sampling since JSON tokens to not exactly correspond to logits.edit: They describe this more carefully in the paper. reply behnamoh 13 hours agoparentprevIt’s actually a very old trick. Lots of libraries do this. idk what’s the big deal about this one. reply remilouf 13 hours agorootparentPerhaps I didn’t explain clearly enough in the original post? reply sneedchucker 14 hours agoprevRelevant; LLama.cpp implemented grammar-based sampling last month.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36819906 https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773 reply remilouf 14 hours agoparentWe can extend our approach to grammar-based sampling, as explained in the paper linked above. Relevant PR: https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178Our method is much more efficient. llama.cpp loops over the entire vocabulary (~50k tokens) at each step to generate the mask. We generate an index at initialization, and building the masks at each step only requires a dictionary lookup (trade speed for memory). Sampling is just as fast as standard sampling. reply popinman322 14 hours agorootparentIt should hopefully be a quick change to llama.cpp to add a mask per grammar state to bring it in line with your generation method; I don&#x27;t think the two are incompatible, thankfully.I do wonder how much you win here by masking the tokens? You still need to iterate along the output vector to apply the mask. Masking on the accelerator still requires filtering on the CPU side? Compared to running the language model, the cost of iterating over the edges in the grammar seems small. reply burke 12 hours agorootparentprevYes! This is closer to the approach I took in my port of llama.cpp&#x27;s grammar support to PyTorch: https:&#x2F;&#x2F;github.com&#x2F;Shopify&#x2F;torch-grammar&#x2F;blob&#x2F;main&#x2F;torch_gra... ... it generates a tensor mapping each PDA stack to a map of which tokens are acceptable from that state. It seems like a much better way to do it than looping over the sampled tokens on each turn. reply btwillard 10 hours agoparentprevWe also had an implementation of grammar-driven guidance around the same time: https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;131. I imagine many others did as well, given all the papers we found on the subject. The point of this and our ongoing work is the availability of very low cost guidance, which was implemented a while ago for the regex case and expanded upon with JSON. reply Q6T46nT668w6i3m 13 hours agoprevIs this Brandon Willard the breakdancer from Detroit Brandon Willard?Edit: It is! https:&#x2F;&#x2F;brandonwillard.github.io&#x2F; reply btwillard 13 hours agoparentHa, yeah, in a distant, but really fun, past! reply cztomsik 2 hours agoprevFYI llama.cpp can do that for a \"while\" https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773Somebody is also working on a whisper.cpp version, which is maybe even more interesting because if you have grammar you can speak not only JSON but also a code (or anything) reply Scaevolus 9 hours agoprevAre there temperature or sampling parameters for generate.regex? I&#x27;m poking around trying to generate password mnemonics (https:&#x2F;&#x2F;rmmh.github.io&#x2F;abbrase&#x2F;), and it really doesn&#x27;t like actually giving me proper words: >> model = models.transformers(\"gpt2-medium\") >> generate.regex(model, r\"Rea[a-z&#x27;]{,10} lik[a-z&#x27;]{,10} acr[a-z&#x27;]{,10} ene[a-z&#x27;]{,10} sta[a-z&#x27;]{,10}\\.\", max_tokens=30)(\"A memorable phrase is:\") &#x27;Rearmingandme like acrowetteanda eneatubootank stackfishkies.&#x27; reply aduffy 13 hours agoprevThis is exciting, we built a similar tool[1] recently specifically targeted at constraining llama output to match a TypeScript interface.I firmly believe that output format guarantees are going to be important for real (non-toy) decades for LLMs[1] https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;discussions&#x2F;2494 reply Scene_Cast2 14 hours agoprevOne potential drawback I can see is if the viable tokens are far down the list of predictions. In that case, filtering down to just those tokens is a distribution shift with resulting output being less stable &#x2F; less sensible. reply contravariant 51 minutes agoparentMore concretely, sometimes it is not enough to simply constrain the next token, backtracking might end up being better. reply Scarblac 13 hours agoparentprevIt can&#x27;t be less sensible JSON than syntactically invalid JSON. All the tokens higher on the list are syntax errors. reply skybrian 12 hours agorootparentIt seems unlikely for JSON, but this might indicate that the model has somehow painted itself into a corner and the best thing to do is backtrack?Regenerating the entire response could be seen as an extreme form of backtracking. reply haswell 12 hours agorootparentprevThat depends highly on the values contained within the JSON. Syntactically correct is only useful if the rest of the content is useful. reply pshc 9 hours agoparentprevExactly my concern. If the model isn&#x27;t sure-footed about the path forward, it seems prudent to take that fact as information and adjust the initial conditions, rather than forcing the model into a potentially hallucinatory idea-space. reply potatoman22 5 hours agorootparentWhat are characteristics of a \"hallucinatory idea-space\"? If you&#x27;re enforcing the model outputting a closing bracket instead of a random string of numbers, that seems like a win for JSON formatting. reply remilouf 14 hours agoparentprevIndeed, this remains an empirical question. reply Deukhoofd 14 hours agoprevLooks interesting! How would you say it compares to Microsoft&#x27;s TypeChat (beyond the obvious Python&#x2F;TypeScript difference)?https:&#x2F;&#x2F;microsoft.github.io&#x2F;TypeChat&#x2F;blog&#x2F;introducing-typech... reply remilouf 14 hours agoparentThanks for bringing this library to my attention! From my understanding, TypeChat proceeds by (1) generating (2) attempting validation (3) if it fails, call the LLM again to fix the output (4) etc.Our method on the other guarantees that the output will follow the specs of the JSON schema. No need to call the LLM several times. reply 1wheel 14 hours agorootparentThere&#x27;s also https:&#x2F;&#x2F;lmql.ai&#x2F; reply remilouf 14 hours agorootparentLQML (and guidance https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance) are much more inefficient. They loop over the entire vocabulary at each step, we only do it once at initialization. reply potatoman22 5 hours agorootparentDoes looping over the vocabulary add much overhead to the tok&#x2F;s? I imagine they&#x27;re just checking if the input is in a set, and usually there&#x27;s only ~30k tokens. That&#x27;s somewhat intensive, but inference on the neural net feels like it&#x27;d take longer. reply 2bitencryption 14 hours agoparentprevTypeChat: let&#x27;s try really hard to try to convince the model to make the highest-scoring tokens follow the grammar we want.Guidance (and this project?): Let&#x27;s not even bother with trying to convince the model; instead, we&#x27;ll only sample from the set of tokens that are guaranteed to be correct for the grammar we want to emit. reply btwillard 13 hours agorootparentYeah, and our addition to all that is to almost completely remove the cost of determining the next valid tokens on each step. reply anotherpaulg 11 hours agoprevFor complex tasks like coding, my experience is that asking for a complex output format hurts performance on the underlying task. This showed up clearly in code editing benchmarks of GPT-3.5 and GPT-4:https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;benchmarks.htmlI’m curious if you have measured whether the “constrained generation” that you’re doing suffers from similar downsides? reply darkteflon 10 hours agoparentWe’ve seen this too. We run them as two separate stages - “reason”, log the intermediate output, then parse. reply infecto 10 hours agoparentprev100% have observed the same over many tests. No loss in fidelity when responding in spoken language style of formatting but using json is disastrous. reply speedgoose 2 hours agorootparentWhile not ideal, could a workaround be to ask in spoken language first, and then ask to format it in JSON? reply nouri 9 hours agorootparentprevUsing OpenAI Function Calls or asking for JSON in the prompt? reply Ilasky 14 hours agoprevOpenAI has this capability built in with functions[0], I believe! Building my own project[1] I have implemented functions in combination with guidance[2] and haven’t had a hiccup yet! I have a JSON parser function there, just in case, but it seems to be working reliably.Here’s a bit more of a description of using the functions API for JSON returns: https:&#x2F;&#x2F;yonom.substack.com&#x2F;p&#x2F;native-json-output-from-gpt-4[0] https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updat...[1] https:&#x2F;&#x2F;resgen.app[2] https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance reply londons_explore 14 hours agoparent>OpenAI has this capability built in with functionsFrom OpenAI&#x27;s docs:> note: the model may generate invalid JSONI would guess they don&#x27;t use your method - and perhaps they should! reply Ilasky 14 hours agorootparentGood catch! It really is a combination of guidance guaranteeing JSON output and OpenAI getting it right a good majority of the time[0]. But yeah, I can see how it can be frustrating that the JSON output is not guaranteed by the docs.[0] >>99% in my experience reply Ilasky 13 hours agorootparentThat said, I am definitely going to look into this library and compare its results to guidance, since they claim it blows it out of the water (which is very enticing!) reply remilouf 13 hours agorootparentFigure 2 in our paper (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702) shows the difference for a single regex. reply thomasfromcdnjs 12 hours agoparentprevI do the same, just tell Openai to call a parser at the end and wahal. reply simonw 12 hours agoprevI really hope OpenAI add something like this to their endpoints soon.Being able to pass up some kind of grammar (a regular expression, or a JSON schema, or some other format) and have this trick run during their token sampling process to ensure the output was compliant would be incredibly useful. reply joshuanapoli 12 hours agoparentIsn&#x27;t the Function Calling feature meant for this purpose? It guides the LLM to output according to the given schema. The name of the feature is a little misleading.https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;gpt&#x2F;function-calling reply tornato7 12 hours agorootparentFunction Calling is fine-tuned to a certain output format, but it very often strays from that format. My function-calling-handling code has a mess of edge case handlers that catch when GPT-4 is calling functions incorrectly. reply M4v3R 11 hours agorootparentprevIt’s not though, they even say it in their docs that sending a schema does not guarantee that the model will actually adhere to the scheme or even produce valid JSON reply simonw 11 hours agorootparentprevSurprisingly the function calling mechanism doesn&#x27;t appear to use this trick - apparently it&#x27;s still possible to get the wrong JSON structure back from it occasionally. reply potatoman22 12 hours agoparentprevThey recently added logit biases, so that&#x27;s a start. reply Animats 14 hours agoprevOK, you get syntactically valid JSON, but does it contain the correct info? This is effectively a polisher, like spell check, which gives the output superficially correct form but doesn&#x27;t understand the content. Right? reply coder543 13 hours agoparentThis analogy falls apart because the spellchecker is separate from the author, and doesn’t know what the author intended.Here, the LLM is still dictating the token probabilities, so the content will be as correct as the LLM can make it, given the constraints. AIUI, the sampler is just choosing tokens on a combination of probability and syntactic correctness, instead of strictly on probability.If the LLM is forced to provide a numeric temperature for Seattle, and the input doesn’t contain that data, then obviously the LLM will be forced by the sampler to provide a random answer if the sampler will accept nothing else, much like a human who is forced to mark “true”&#x2F;“false” on an online form, with no option to reject the question and explain that the question isn’t even a true&#x2F;false question.I don’t know about this specific implementation, but it seems important to design systems like this to always “accept” (sample for) an error response from the LLM so that it can hopefully reject invalid requests.But, yes, all the usual caveats about LLMs apply. It can’t provide correct answers to things it doesn’t know. Forcing it to respond with the answer to the life, the universe, and everything is not going to provide a meaningful response. Even things it “knows”, it can still get wrong sometimes. reply anticrymactic 12 hours agorootparentI&#x27;m stupid with LLMs, but would it be possible to have this output with gpt4&#x27;s intelligence, or would it have to be specifically trained? reply coder543 12 hours agorootparentIt’s something OpenAI should really implement themselves. Implementing it from the client side will mean sending the same request over and over until you get a syntactically correct answer, which is going to be much slower and likely to cost a lot. The server can guide the generation, but the client can (currently) only hint at what it wants. ChatGPT4 is fairly good at following schemas, and that’s what OpenAI currently relies on, but they make no guarantees.It likely wouldn’t require additional training. It’s a change to the way the server uses the model, not a change to the model itself… but we don’t know ChatGPT4’s true architecture because OpenAI won’t publish anything about it, so it’s hard to say for sure. reply chipsrafferty 12 hours agorootparentprevWhy isn&#x27;t it possible to design LLMs that say \"I don&#x27;t know\"? reply coder543 12 hours agorootparentIt is possible… ChatGPT4 says that all the time. It’s just not guaranteed that an LLM will recognize that it doesn’t know a particular answer every time. I had even already mentioned in the comment you’re replying to that you should leave room in the sampler to allow the LLM to provide error responses. I never said it wasn’t possible.Not to anthropomorphize LLMs too much, but humans will also sometimes respond confidently with a wrong answer too. Both LLMs and humans will sometimes say the wrong thing when they don’t actually know an answer, but sometimes (hopefully most of the time) they will instead say that they don’t know the answer.Contrary to another response here, I do not believe it&#x27;s a good mental model to say that LLMs only respond \"I don&#x27;t know\" only when they have specifically memorized that they don&#x27;t know a fact. When you&#x27;re dealing with tens or hundreds of billions of parameters, the \"why\" is often elusive and complicated. It&#x27;s also probabilistic; it may respond that it doesn&#x27;t know one time, but the next time, it may unfortunately claim to know an answer it doesn&#x27;t know -- which is a form of hallucination. If it was just about memorization, then it wouldn&#x27;t be probabilistic. Reducing hallucinations is one of the major goals of LLM research today, and ChatGPT4 performs much better in this area than ChatGPT3.5 did.Here is a quick example of ChatGPT4 saying it doesn’t know: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7b72b109-fb84-4988-891b-f2eecc...I&#x27;m sure no one at OpenAI specifically trained ChatGPT4 to recognize a question about the Stanley Cup and respond that it doesn&#x27;t know the answer, but it still said that it didn&#x27;t know. It absolutely did not start a sentence with \"the winner of the 2023 Stanley Cup was...\" and then wander its way into a bad answer. That&#x27;s not a good representation of how this stuff works, even though it does sample one token at a time. reply skybrian 12 hours agorootparentprevThey do, but it&#x27;s a form of imitation, not actually knowing what they don&#x27;t know.Ask an LLM to imitate a confident physicist and it will try, regardless of how much physics it knows.Or if you tell ChatGPT that it&#x27;s wrong multiple times, it may learn the pattern and assume it&#x27;s always wrong, resulting in a downward spiral. (This can happen when using Code Interpreter and it makes several failed attempts to correct a mistake.)The difficult research problem is training it to have an accurate model of what it knows. reply Lerc 12 hours agorootparentprevThey can say I don&#x27;t know when they contain the fact that they don&#x27;t know something. For instance saying \"I don&#x27;t know\" could be a response to\"What is the meaning of life\"On the other hand if you ask a LLM how to do something about fish maintenance that it does not know how to do, it might produce an answer like \"Sure, first take your fish and \" at which point all of the options for the next word are all over the place because there isn&#x27;t the information available to guide the choice. The sentence started as if it knew the answer because there was no information to say that it didn&#x27;t. By the time the absence of information has an impact, the LLM is already committed to the sentence where it is confidently giving you an answer. reply mr_toad 9 hours agorootparentprev> Why isn&#x27;t it possible to design LLMs that say \"I don&#x27;t know\"?You have to have an understanding of ‘I’ before you can make that judgement. reply bestcoder69 10 hours agorootparentprevtext-davinci-002 used to make me so mad with how often it’d do that reply burke 12 hours agoparentprevYou can go pretty deep once you get context free grammars. For example, I&#x27;m using torch-grammar (but outlines should be able to do the same thing once CFG support is merged) to not just restrict the format of a generation to a DSL&#x27;s syntax, but to restrict the keys it updates to valid keys in a known set.e.g.: int_key ::= DQUO (\"f\" (\"e\" (\"atured-\" (\"b\" (\"log.\" (\"p\" (\"ost_limit\"\"a\" ...Obviously, yeah, it doesn&#x27;t \"understand\" the content, but that&#x27;s what the LLM is for. It&#x27;s remarkable how plausible the generations you can get out of random noise are with a sufficiently-restrictive grammar. Bolting that onto a well-trained LLM is pretty powerful. reply btwillard 12 hours agorootparentFYI: We&#x27;ve had grammar constraints available in Outlines for a while, but not using the FSM and indexing approach that makes the regex case so fast. My open PR only adds that. reply empath-nirvana 13 hours agoparentprevThis isn&#x27;t really an interesting question is it? Everyone knows that chatgpt is not an oracle. It doesn&#x27;t need to output the correct information 100% of the time. reply offmycloud 6 hours agorootparentI don&#x27;t think that everyone, or even a majority of people understand this. That&#x27;s certainly not how AI is being marketed to the general public. The concern here is that syntactic correctness might be mistaken for factual accuracy. reply dvt 11 hours agoprevI may get heavily downvoted for my criticism here, but here we go again: yet another \"innovation\" that&#x27;s fueled by the stupid money poured into AI startups in the past 2 years. Imagine thinking that adding regex on top of an LLM is worth $8.5M[1]. At least Llama&#x27;s grammar-based sampling[2] is a bit more interesting but still essentially putting lipstick on a pig.How is telling the language model \"no, not like that, give me another token\" at every step of token inference getting so many people ecstatic? The paper is basically undergrad-level excitement about something not even remotely interesting. Congratulations, you reinvented Markov chains (oh, sorry, \"state machines\") on top of LLMs.I mean of course you can guarantee grammar and schema well-formedness as, duh, you have what essentially amounts to a post-processing step. Maybe I&#x27;m the idiot here, is anyone actually using any of these tools in production?[1] https:&#x2F;&#x2F;www.benzinga.com&#x2F;pressreleases&#x2F;23&#x2F;06&#x2F;n32834246&#x2F;norma...[2] https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773&#x2F;files reply kristjansson 3 hours agoparentI think you might be over-simplifying. This (and llama.cpp&#x27;s grammar-based sampling, which this is moving towards[1]) doesn&#x27;t say \"no, not like that, give me another token\". It excludes impossible tokens at each step, but otherwise samples like normal.Is this a revolutionary trick? Not really, since llama.cpp and guidance, and probably others have already done it. But it&#x27;s a good trick, and hopefully one of many to justify the valuation :).[1]: https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178 reply swyx 4 hours agoparentprev> Imagine thinking that adding regex on top of an LLM is worth $8.5Myou should be downvoted for being this reductionist and uncharitable. this is a side project of a larger company effort. reply coder543 11 hours agoprevAs a more general comment, the repo README provides examples that all use gpt2. It would be nice to see at least one example that invokes llama2, since I feel like that would make sure the reader knows that this library can use models that are more modern and interesting. reply Havoc 11 hours agoparentInclined to disagree - gpt2 is far more likely to produce gibberish. So if you can force specific outputs on that then it is a good demo that higher quality models will be even better reply coder543 11 hours agorootparentMaybe... but then if I want to use something better, I have to figure out how by myself. I said \"at least one example\", not \"please change all the examples to llama2.\" I agree with your general point. It would be nice if there were an example of how to use a better model.Models often have different shapes and requirements, so is it really as simple as changing the string \"gpt2\" to \"llama2-13B-Chat\" and it will magically work? If so, that&#x27;s great, and I wish that was made clear. Unfortunately, that hasn&#x27;t always been my experience with other libraries. reply remilouf 11 hours agorootparentAgree, working on a Colab with a \"better\" model as we speak. reply dvasdekis 9 hours agorootparentWonderful, thank you! reply swyx 4 hours agoparentprevit would also be nice to see one example that uses gpt4. reply coder543 3 hours agorootparentGiven how this works, I don’t think that is possible unless OpenAI implements it themselves. reply Ycros 6 hours agoprevHaving played around with this sort of thing in the llama.cpp ecosystem when they added it a few weeks ago, I will say that it also helps if your models a) are tuned to output json and b) you prompt them to do so. Anything you can do to help the output fit the grammar helps. reply itissid 10 hours agoprevI have noob thought on the potential of these in Formal path planning. Specifically given a set of functions that basically map {State -> Actions} given preconditions, transition functions (heavily paraphrasing STRIPS[1]) can a correct and optionally \"realistic\" plan be generated[2]? I am quite interested in this. It seems clear that the issue is that there is no \"guidance\" like DFA on what is the correct next symbol for a Plan, but perhaps the AI can generate some kind of a probability or order on what is the best step and one can go from there...Are you guys thinking about this direction?[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stanford_Research_Institute_Pr...[2] Formal Planning decision problem(plan exists) given STRIPS spec is at least NP-Complete[1]. There are several mathematical, logical and statistical \"tricks\"(e.g. [3]) that are used to bring down the complexity and try find a plan using heuristics(thinking MDPs, POMDPs here). This is not new, everyone in LLM research knows this.[3] \"Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning\": https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S000437029... reply kristjansson 3 hours agoprevIt does seem inapt to claim this “eliminates” hallucinations in your blog post. Sort of like unnamed FP languages claiming to eliminate bugs.Both eliminate a subclass of failures, but don’t preclude failure categorically. reply TeeWEE 2 hours agoparentAs it describes it does eliminate non JSON outputs by masking the tokens while the LLM is generating. Its quite smart if you ask me. reply kristjansson 2 hours agorootparentIt’s very clever. I wouldn’t want it to be oversold. reply thatcherthorn 14 hours agoprevThis is awesome. I have a vision to build self-managed software. This will be a great tool. reply remilouf 14 hours agoparentThank you! Hope this helps and opens many applications :) reply malux85 14 hours agoparentprevThis is really great too, I am building self-generating experiments and molecular simulations with https:&#x2F;&#x2F;atomictessellator.com and I am going to try out this framework after work reply calderwoodra 3 hours agoprevHave you found a solution to output exceeding the context window? That&#x27;s been our only issue with generating json output. reply visarga 12 hours agoprevEnforcing JSON schema, regex and grammars is very useful. But how can we enforce decoding spans from a document? decoded text should be copied from a list of spans in the input document. It would be useful for extractive tasks. reply jmcminis 9 hours agoprevAre there edge cases here due to context length?1. I have a json schema with required fields. I complete the json, but do not include the required fields.2. I run out of token from the model before I finish the json object because I&#x27;m in the middle of some deep, nested structure.These seem solvable, just edge cases to control for by either reserving tokens, randomly generating required tokens until completing the json, or something more sophisticated. reply dsrtslnd23 6 hours agoprevIt says \"Outlines 〰 is compatible with all models.\". But does this actually work with gpt3.5-turbo or gpt4? I was using guidance before and you only get value when using davinci due to the constraints of chat api based models. reply leetharris 13 hours agoprevHow does this compare in terms of latency, cost, and effectiveness to jsonformer? https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformer reply remilouf 13 hours agoparentFigure 2 in our paper (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702) shows the difference between guidance and outlines to generate a sequence that is valid to a regex. Jsonformer uses the same technique as guidance. Extrapolate this to several fields.Note that we still need to manage the KV cache in outlines. It’s a small interface change that will be made this week hopefully, but we’ve been focusing on constrained generation so far. reply Der_Einzige 13 hours agorootparentSad to see that my related work on token-level constrained text generation is not cited in the paper: https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;Constrained-Text-Genera...https:&#x2F;&#x2F;aclanthology.org&#x2F;2022.cai-1.2&#x2F; reply remilouf 13 hours agorootparentWe&#x27;re unfortunately only human and didn&#x27;t catch every single paper on the topic while writing the draft. Thanks for bringing it to our attention. reply bhickey 13 hours agoparentprevjsonformer uses a template rather than a DFA. The logit masking seems to be identical, though. reply aiunboxed 3 hours agoprevOpen AI has released this as a feature, is this news ? what am i missing ? reply Havoc 14 hours agoprevThat looks intriguing. Managing that interface has proven challenging - especially on data cleaning tasks where the model ends up talking rather than doing. Bit more guiderails would be helpful on that reply remilouf 14 hours agoparentThat&#x27;s what we noticed as well, and we were not satisfied with the `guardrails` approach of just rejecting invalid outputs. The method makes the interface robust. reply sandkoan 9 hours agoprevThis is what we did at Trex (https:&#x2F;&#x2F;github.com&#x2F;automorphic-ai&#x2F;trex). The tricky part is doing it quickly and efficiently. reply dvasdekis 9 hours agoprevWould love to have a tutorial on how to install and run this locally with a nice model, for those of us who are behind the 8-ball with torch, transformers, diffusers, llama2 etc. reply ianbutler 13 hours agoprevhttps:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;clownfishWhich I&#x27;ve been using for a while now, also restricts the sampling space to force correct generation, but does so as the result of a different process than yours. reply 2bitencryption 14 hours agoprevit still blows my mind that OpenAI exposes an API with Functions calling, and yet does not guarantee the model will call your function correctly, in fact, it does not even guarantee the output will be valid JSON.When this is, really, a solved problem. I&#x27;ve been using github.com&#x2F;microsoft&#x2F;guidance for weeks, and it genuinely, truly guarantees correct output, because it simply does not sample from tokens that would be invalid.It just seems so obvious, I still have no clue why OpenAI does not do this. Like, why fuss around with validating JSON after the fact, when you can simply guarantee it is correct in the first place, by only sampling tokens if they conform to the grammar you are trying to emit? reply newhouseb 13 hours agoparentI think this is likely a consequence of a couple of factors:1. Fancy token selection w&#x2F;in batches (read: beam search) is probably fairly hard to implement at scale without a significant loss in GPU utilization. Normally you can batch up a bunch of parallel generations and just push them all through the LLM at once because every generated token (of similar prompt size + some padding perhaps) takes a predictable time. If you stick a parser in between every token that can take variable time then your batch is slowed by the most complex grammar of the bunch.2. OpenAI appears to work under the thesis articulated in the Bitter Lesson [i] that more compute (either via fine-tuning or bigger models) is the least foolish way to achieve improved capabilities hence their approach of function-calling just being... a fine tuned model.[i] http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html reply WiSaGaN 2 hours agorootparentThe \"Bitter Lesson\" indeed sheds light on the future trajectory of technology, emphasizing the supremacy of computation over human-designed methods. However, our current value functions often still need to focus on what we can achieve with the tools and methods available to us today. While it&#x27;s likely that computational tools will eventually replace human-guided \"outlines\" or \"guidance\", that are used to shape LLM outputs, there will likely always be a substantial amount of human-structured knobs necessary to align computation with our immediate needs and goals. reply reasonabl_human 9 hours agorootparentprevWhat a fascinating read, thanks for sharing that link. reply padolsey 12 hours agoparentprevIANA{LLM}, but if you&#x27;re only sampling from a \"correct\" grammar, you are potentially (very potentially) forgoing what might otherwise have been a more desirable and more semantically useful token. Most of the models have been trained on myriads of human language, not structured data necessarily, and so I&#x27;d rather elect for a more semantically enriched format (e.g. XML or YAML) because those are designed to be ~more human readable. Or perhaps more preferably: have the boss LLM pump out what it excels at (strings of prose most of the time) and have a secondary model with a stricter grammar convert that to JSON. reply BoorishBears 14 hours agoparentprevI just left a comment along these lines, but realistically it&#x27;s probably cheaper to just re-emit than to add the machinery that enables this to their existing architecture.At most I could have seen them maybe running a schema validator against the output and re-requesting on your behalf, but even that&#x27;s probably cheaper for them to do client side (I will say, I&#x27;m surprised their API wrapper hasn&#x27;t been updated to do this yet) reply 2bitencryption 14 hours agorootparent> maybe running a schema validator against the output and re-requesting on your behalfthis is the part that blows my mind. You don&#x27;t have to do this! You don&#x27;t have to sample the entire output, and then validate after the fact.You&#x27;re not required to greedily pick the token with the highest score. You get the scores of all tokens, on every forward pass! So why even waste time picking invalid tokens if you&#x27;re just going to validate and retry later on??(note: when I say \"you\" here, I mean whoever is hosting the model. It is true that OpenAI does not expose all token scores, it only gives you back the highest-scoring one. So a client-side library is not able to perform this grammar-based sampling.BUT, OpenAI themselves host host the model, and they see all token outputs, with all scores. And in the same API request, they allow you to pass the \"function definition\" as a JSON schema. So why not simply apply that function definition as a mask on the token outputs? They could do this without exposing all token scores to you, which they seem very opposed to for some reason.) reply BoorishBears 13 hours agorootparentMaybe re-read what I said?> realistically it&#x27;s probably cheaper to just re-emit than to add the machinery that enables this to their existing architectureThere are literally dozens of random projects that have implemented logit based masking, it&#x27;s a trivial thing to implement.What&#x27;s probably not as trivial is deploying it at scale with whatever architecture OpenAI already has in place. Especially if they&#x27;re using the router-based MoE architecture most people are assuming they use.OpenAI doesn&#x27;t expose token probabilities for their RLHF models, yet they did for GPT-3. Originally that lead to speculation that was to make building competitors harder, but they&#x27;ve now said they&#x27;re actually still working on it... which leans even further into the idea they may have an architecture that makes the kind of sampling these projects rely on more difficult to implement than normal.Given how fast and cheap they&#x27;ve made access to these models, their current approach is a practical workaround if that&#x27;s the case. reply behnamoh 13 hours agorootparentwhen GPT-4 first became available, I had a feeling that something about it felt “hacky”. Compared to GPT-3 which was more streamlined, mature, and well thought out, GPT-4 was like a system put together to outperform the previous one at all costs. I wouldn’t be surprised if that led to design decisions that made their model hard to improve. Maybe GPT-5 will not be around any time soon. replyvlovich123 3 hours agoprevHow is this different from generating such things without an LLM? In other words picking random valid tokens from the grammar via fuzzing or similar techniques. reply vlovich123 3 hours agoparentInstead of downvoting, I’d appreciate an answer. I’m genuinely curious to learn what the value add of the LLM is. reply SethTro 3 hours agoprevnext [–]print(guided) # What is the IP address of the Google DNS servers? # 2.2.6.1correctly formatted wrong answers are still wrong answers. reply oars 9 hours agoprevExcited to incorporate this into my developer workflow. reply haolez 6 hours agoprevCan I use this locally with models that run on my CPU? Like llama.cpp reply remilouf 6 hours agoparentWe can add an integration to llama.cpp, please open an issue on the repo if you’re interested! reply BoorishBears 14 hours agoprevI&#x27;m not sure how this is different than:https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformerorhttps:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;clownfishorhttps:&#x2F;&#x2F;github.com&#x2F;mkuchnik&#x2F;relmorhttps:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773orhttps:&#x2F;&#x2F;github.com&#x2F;Shopify&#x2F;torch-grammarOverall there are a ton of these logit based guidance systems, the reason they don&#x27;t get tons of traction is the SOTA models are behind REST APIs that don&#x27;t enable this fine-grained approach.Those models perform so much better that people generally settle for just re-requesting until they get the correct format (and with GPT-4 that ends up being a fairly rare occurrence in my experience) reply remilouf 14 hours agoparentThanks for bringing clownfish and relm to my attention! afaik other libraries loop over the entire vocabulary at every step of the generation. We on the other hand build an index at initialization by looping once over the vocabulary. Then generation is just as fast as standard generation. reply burke 12 hours agorootparenttorch-grammar generates a mask per PDA stack... we don&#x27;t try to compute all the possible stacks. I&#x27;m sure there&#x27;s something smarter that could be done here and you&#x27;ve probably figured it out (though IIRC regular languages don&#x27;t have the arbitrarily recursive stack problem that you get when you get to context-free languages?) anyway, in practice we spend a few milliseconds on the first few requests building caches and then just apply masks from caches after that. reply btbuildem 13 hours agoprevI feel like I&#x27;m missing something very basic here, but is this library intended to be used with an existing model? If so, could you point to an example? reply remilouf 13 hours agoparentIt can be used with any open source model (if you can get the logits), and to some extent with OpenAI&#x27;s API. Here is an example with `transformers`: https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines#efficient-json-...We plan on adding more model integrations, but it is completely decoupled from the method implementation. reply sberens 8 hours agoprevWhat happens if max_tokens cuts the model off from generating valid JSON? reply tantalor 13 hours agoprev\"Generating valid JSON\" is not impressive. Here&#x27;s some valid JSON: []The tricky part is generating useful JSON. reply notpushkin 13 hours agoparentGenerating valid JSON that conforms to a given schema is pretty useful, although not impressive by itself. If the model can deduce field values from schema alone though, I think it&#x27;s pretty neat. reply travisjungroth 10 hours agoparentprevThere are already models generating useful JSON. Sometimes they generate what would be useful JSON, but it’s not valid. This makes sure it’s always valid. It’s an improvement. reply AtNightWeCode 12 hours agoparentprev\"\" valid! reply ape4 13 hours agoparentprevOr JSON that correctly answers what the prompt is asking. reply nikcheerla 12 hours agoprevDoes this work with GPT-4? reply Kiro 13 hours agoprevDoes this mean that I need to call the LLM API once for each token? reply baobabKoodaa 12 hours agoparentNo. You need to hook into the LLM at a lower level. One API call typically triggers a generation of a sequence of tokens and this library has to poke into things between each generated token. reply Kiro 2 hours agorootparentCan&#x27;t I use the max_tokens (set to 1) and logit_bias parameters? Not saying I want to do this. I just want to understand how this works. reply popinman322 13 hours agoprevDoes this work in tandem with beam search or does it do greedy sampling? reply btwillard 13 hours agoparentThe underlying approach can improve the performance of anything that requires the set of non-zero probability tokens at each step, and anything that needs to continue matching&#x2F;parsing from a previous state. reply spott 14 hours agoprevHow does this relate to ggmls bnf sampling? reply remilouf 14 hours agoparentTwo differences:(1) This feature only requires regex-guided generation. We have a PR for BNF sampling that is about to be merged. (2) ggml loops over the entire vocabulary (~50k tokens) at each step, which introduces a noticeable overhead, and makes it unusable for complex grammars. Our method works by building an index at initialization, and build the masks at each step with a dictionary lookup. Once the index is built, generation is just as fast as standard generation. Doesn&#x27;t depend on the complexity of the grammar, the size of the LLM or its vocabulary size. reply spott 13 hours agorootparentRegex-guided gen is slick… is it arbitrary? Or are you custom building it for json?If arbitrary, how are you pre-defining a set of masks? I would expect that splitting an arbitrary regex into a bunch of contexts for a masking dictionary to be non-trivial. reply huevosabio 14 hours agoprevVery cool! How much latency does it add? reply btwillard 14 hours agoparentWith our indexing approach, it only costs a dictionary lookup to get the next valid tokens during each sampling step, so very little latency. reply AtlasBarfed 6 hours agoprevOk so:- for what energy&#x2F;processing cost per validation?- how much of the input space was tested (unicode chars, escaped chars, newlines, etc)?- are you doing this as a service? We&#x27;ve seen LLMs already evolve negatively in some capabilities over time, so do you have a constant \"ping\" test suite validating the LLM&#x27;s performance? reply coding123 14 hours agoprevCan someone re-explain all of this. If I got to GPT3.5 and ask it to give me some information in json, vs whatever this library is doing? reply odyssey7 11 hours agoparentEach time you run an LLM on a sequence of tokens, it generates a probability distribution giving each token&#x27;s likelihood of occurring next in the sequence. To actually determine the next token in the sequence, any of various strategies can be used to select from that probability distribution.The challenge in guided generation is conforming the output sequence with a formal language such as a JSON schema or even a rigorously grammatical version of English; typically in a formal language, most tokens in the vocabulary will be _impossible_ as next token candidates rather than merely unlikely. The authors explain that most guided generation systems are checking each token in the vocabulary to see if it would be a valid continuation of the sequence, filtering the probability distribution according to formal constraints before making the next token selection. The authors improve upon this process by indexing valid next tokens according to a formal language recognizer&#x27;s possible states, so that the list of valid next tokens can be looked up in constant time rather than testing every token in the vocabulary.With the valid next token options in hand, the probability distribution for next tokens is filtered and then a selection is made. reply lettergram 12 hours agoprevFew thoughts, you&#x27;re effectively creating representations that can convert to JSON (kudos!)Can&#x27;t mention how we did it (there are a lot of public patents, if interested), but back in 2018 we had a way to generate synthetic data (statistically, structurally similar) off any dataset - https:&#x2F;&#x2F;medium.com&#x2F;capital-one-tech&#x2F;why-you-dont-necessarily... You could also design datasets if you wanted.It&#x27;d keep similar relations and worked pretty darn well. Not the exact same, but always produced valid JSON. reply malft 3 hours agoprevRegex-constrained GPT, what is a mnemonic for pi?> It&#x27;s a word, a short statement or phrase which you learn.Can you make a good one?> Man, I wish I could recommend an answer. You&#x27;re not gonna remember something, because, obviously, pi&#x27;s so big. Actually, let&#x27;s forget pi. There&#x27;s only one way: Googling for it.(count the letters) reply quickthrower2 11 hours agoprev> LLMs can generate valid JSON 100% of the timeIf that seems surprising, it is worth doing a course like Karpathy&#x27;s zero to hero NN, and have all the magic peeled away a layer at a time.The reason you can do this is because LLMs don&#x27;t just generate the next word or token, it produces a probability distribution over all tokens. A JSON parser can give you a list of next valid tokens. The tokens in each case might be from a different set, e.g LLM thinks of \" The\" whereas the JSON parser might think of \"{\", so you need some conversion there. But if you sample randomly from only the valid tokens, the output must be valid JSON.What you can&#x27;t build a parser for though is ... the truth! You may still be told lies or made up stuff. reply dwattttt 10 hours agoparentIf you&#x27;re choosing the next token based on a list of valid next tokens, a uniform random distribution can always generate valid JSON too! reply quickthrower2 10 hours agorootparentYep. So can this: fun generate_valid_json(seed): return \"{}\" reply neoncontrails 8 hours agorootparentprevBut that&#x27;s not what an LLM does. reply antonvs 8 hours agorootparentThe point is that if you&#x27;re \"choosing the next token based on a list of valid next tokens,\" it&#x27;s not surprising that you&#x27;ll only generate valid output, since absolutely any choice mechanism will suffice. reply OJFord 9 hours agoparentprevMaybe it&#x27;s just me, but I&#x27;m not doing anything that calls itself &#x27;zero to hero&#x27;. Would love some good resources (preferably textbook, or at least written) on LLMs though. I don&#x27;t even understand the link to &#x27;generative&#x27; image&#x2F;video AI, which seems to have exploded at roughly the same time and surely isn&#x27;t a coincidence.I studied a little (literally &#x27;intro to&#x27;) ML at university, about enough to grok it as an application of stats, tie into things seen elsewhere, but not really more than that.Every supposéd tutorial or explainer I&#x27;ve seen posted here or been able to find has been a weird (IMO) mix if simultaneously assuming a decent (at least greater than mine) ML background, but also really dumbed down clone this repo download that model switch between them like this, fine-tune them by cd&#x27;ing to this directory and ... Ok but what&#x27;s actually going on? reply frontier 8 hours agorootparentKarpathy&#x27;s series is many many hours long and really does take you from zero to GPT. It&#x27;s excellent! You sound triggered by the title - that may not even be the official title - but it definitely deserves it. Go look it up. reply OJFord 8 hours agorootparentThe title suggests I wouldn&#x27;t like it, yes. But as a video series it&#x27;s not &#x27;a textbook or at least written&#x27; is i - not really the format I&#x27;m looking for personally. reply thatcherthorn 7 hours agorootparentTruly.. one of the greatest minds in our ML era. Don&#x27;t get caught up on the format :) reply OJFord 1 hour agorootparentI just don&#x27;t find it an effective way of learning personally. I didn&#x27;t expect this to be so controversial - different people learn differently. reply pavs 7 hours agorootparentprevSince you are \"judging a book by its cover\", or this case a name. This might interest you, that karpathy was co-founding developer of OpenAI, left to work at Tesla to head their AI development for 5-ish years and now back at OpenAI.I can understand that you might be interested in book form only, I was lile this for the longest time, until I bumped into some really high quality video series that changed my mind to be a bit more flexible.Also Important to note that LLM development is moving at a very fast pace recently so a book form might not be ideal. The basic ideas might be same, most of it might be out of date 6-12 months from now. I dont see how anyone could write a quality book that covers everything on this. reply OJFord 1 hour agorootparentI realise that; also that it doesn&#x27;t help that afaiui it&#x27;s been more industry-led than academia.But I truly am starting from pretty much &#x27;zero&#x27;, and maybe I wasn&#x27;t clear but I&#x27;m not looking to be &#x27;hero&#x27; in the sense of up to date with the cutting edge, or even necessarily putting anything in to practice at all, I&#x27;m more interested in the background theory, and fine with that missing the absolute latest extra technique, just want to understand the meat of it better.A refresher on SVMs & PCA (which I barely remember - I think I could convincingly explain SVMs to someone numerate but non-tech&#x2F;mathematician, but not otherwise) and then a catch up to roughly what&#x27;s going on with LLMs & image&#x2F;video as mentioned would be great.> I can understand that you might be interested in book form only, I was lile this for the longest time, until I bumped into some really high quality video series that changed my mind to be a bit more flexible.I enjoy videos for many things, but mostly entertainment, I don&#x27;t personally find I can learn that well from them, especially more technical&#x2F;theoretical stuff, sure to some combination of screen fatigue, it being harder to skip around and reference something, and distraction - something seems obvious briefly so my mind wonders, check something in another tab &#x27;just quickly&#x27;, and before you know it ten minutes have passed, I&#x27;ve been hearing the speaking but suddenly realise I haven&#x27;t been listening, have no idea what&#x27;s going on any more.Obviously they work for some people, that&#x27;s fine. reply antonvs 8 hours agorootparentprev> I&#x27;m not doing anything that calls itself &#x27;zero to hero&#x27;.Sounds like you have a case of the Mondays. You just need to turn that frown upside down! reply OJFord 1 hour agorootparentMust have left my flair at home. reply fenomas 8 hours agorootparentprevThe zero to hero video series is what you&#x27;re looking for - look past the name and watch it. It&#x27;s excellent. reply RyEgswuCsn 9 hours agoparentprevHow does the LLM know what valid JSON tokens are?What if the training data contains malformed JSON? There ought to be a non-zero chance of the LLM producing invalid JSON, no? reply MereInterest 9 hours agorootparentLLMs work by outputting a value for each token, then using those values to generate a probability distribution. Usually, this will be through a function like softmax [0], but there&#x27;s nothing preventing you from doing some post-processing first. That post processing could be aware of the tokens that would be valid as the next token in a JSON format, and set the probabilities of all other tokens to zero. That way, even if the training data contains malformed JSON, the generator is still constrained to produce valid JSON.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Softmax_function reply catlifeonmars 9 hours agorootparentprevI think the idea is that it’s easy to filter the result set to restrict to just valid JSON. reply mattigames 10 hours agoparentprevIt&#x27;s not like humans are particularly good at distinguishing truth from lies. reply quickthrower2 10 hours agorootparentThe word \"lie\" is probably too anthropic here. I should have just said \"made up\". There is no intent to lie. And the model isn&#x27;t try to self-fact-check anyway. (Maybe some do). But if they do they are probably bad at it at the moment, at least from my experience of GPT3.5 (not used 4 much). reply coder543 10 hours agorootparent> at least from my experience of GPT3.5 (not used 4 much).And 4 is tremendously better than 3.5, in my own experience. Not perfect, but actually useful. reply quickthrower2 9 hours agorootparentCan anyone recommend a good, and trusted UI so I can use it via the API? I don&#x27;t want to pay monthly for it, but would be nice to use occasionally. I keep meaning to do this! reply selcuka 8 hours agorootparentOpenAI has its own playground where you can test all models (I believe GPT-4 is not available to everyone yet):https:&#x2F;&#x2F;platform.openai.com&#x2F;playgroundMonthly subscription is only for ChatGPT. When you use the APIs you pay per token. reply coder543 6 hours agorootparent> I believe GPT-4 is not available to everyone yetI still don&#x27;t have access, except through the regular ChatGPT interface, which is mildly annoying. It would be interesting to experiment with the API. replydilawar 7 hours agorootparentprev\"Its a human nature to mislead others, sometimes knowingly.\" I read this line in an anthropology book. A similarly non-cynical approach towards your fellow is \"trust but verify\". reply rckrd 13 hours agoprevI also released a hosted version of my open-source libraries ReLLM and ParserLLM that already supports APIs for* Regex completion for LLMs* Context-free Grammar completion for LLMshttps:&#x2F;&#x2F;thiggle.com&#x2F;[0] https:&#x2F;&#x2F;github.com&#x2F;r2d4&#x2F;rellm[1] https:&#x2F;&#x2F;github.com&#x2F;r2d4&#x2F;parserllm[2] https:&#x2F;&#x2F;github.com&#x2F;thiggle&#x2F;apiThere&#x27;s also another API on Thiggle that I&#x27;ve build that supports classification via a similar logit-based strategy. reply faangiq 4 hours agoprevIs generating valid json nontrivial? reply lefttoreader 12 hours agoprev [–] The “trick” seems to blatantly rip off FlashText without citing it?https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1711.00046.pdfI’m a fan of the approach. I normally wouldn’t care if this was just another LLM library taking inspiration, but if you’re going to go out of your way to put a paper on the ArXiv, feels like doing a literature review is a good step? reply verdverm 9 hours agoparent [–] Care to explain how a string replacement algorithm relates to nudging the logits of a ML model?I don&#x27;t see the \"rip off\", the paper you cite requires a complete document to work on while this work is for guiding the generation of tokens reply bhickey 9 hours agorootparentBoth papers use the phrase \"regular expressions\" and there the resemblance ends. The linked manuscript uses regular expression to realize a grammar and then memoizes logic masks. I want to know why FlashText failed to cite:Baeza-Yates, Ricardo A., and Gaston H. Gonnet. \"Fast text searching for regular expressions or automaton searching on tries.\" Journal of the ACM (JACM) 43.6 (1996): 915-936.Eltabakh, Mohamed Y., Ramy Eltarras, and Walid G. Aref. \"To trie or not to trie? realizing space-partitioning trees inside postgresql: Challenges, experiences and performance.\" (2005).Zhang, Yijun, and Lizhen Xu. \"An algorithm for url routing based on trie structure.\" 2015 12th Web Information System and Application Conference (WISA). IEEE, 2015. reply lefttoreader 7 hours agorootparentYour comment here doesn’t feel like it’s in good faith, but there’s a good chance I’m misreading it. reply bhickey 7 hours agorootparentI&#x27;m serious that the similarities between the papers are superficial.I don&#x27;t think it&#x27;s fair of you to criticize the authors for not citing some obscure preprint, when that manuscript itself neglected to cite decades of prior, relevant work. reply lefttoreader 9 hours agorootparentprev [–] Sure! So it’s hopefully clear that the notion of constrained grammar is not novel (see every comment on here of people name-dropping their implementation from two months ago).The novelty here is “instead of checking whether every token is allowed” to create a finite state machine that defines which tokens are allowable at each generation step. This lets them not check every token at every step.The trick of creating an FSM to efficiently check next-token grammar is what allowed FlashText to run circles around standard regex stuff. Even FlashText guy acknowledged the shoulders he stood on, etc.Let’s be super clear here, none of these standards apply when you’re building good ole libraries. But putting out a paper really elevates what you’re on the hook for. Most folks that write papers are dying to acknowledge the shoulders they stand on - it’s part of the toxic humility we all engage in.Again - shill OSS all day - I’ll upvote it. reply _flux 2 hours agorootparent [–] By \"standard regex\" stuff I take it you mean the standard regex stuff Python standard library comes with?I mean going from standard regex to NFA to DFA is already more sophisticated than that one, it&#x27;s _quite_ oldschool and gives you linear time matching: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thompson%27s_construction https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Powerset_constructionAnd what I mean to say by this as they could have easily have had this idea and never had discovered the whitepaper you referenced. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Outlines is a Python library that specializes in text generation using large language models.",
      "The creators have developed a technique to generate text that conforms to a regular expression by converting it into a generative model.",
      "The library can also generate text that adheres to a JSON schema or can be parsed into a Pydantic model, ensuring the output is valid.",
      "The creators are actively seeking feedback and suggestions for further improvements."
    ],
    "commentSummary": [
      "Participants discussed the use of large language models (LLMs) in generating valid JSON text.",
      "The conversation touched on challenges in generating code and handling edge cases, as well as the limitations and benefits of different LLM models.",
      "Various tools and approaches were mentioned, with concerns raised about stability, sensibility, and efficiency."
    ],
    "points": 738,
    "commentCount": 236,
    "retryCount": 0,
    "time": 1692039174
  },
  {
    "id": 37119942,
    "title": "Show HN: Little Rat – Chrome extension monitors network calls of all extensions",
    "originLink": "https://github.com/dnakov/little-rat",
    "originBody": "Hi HNI needed a way to monitor network calls made by chrome extensions so I made a small extension.You can install it by dropping the zip or crx into the extensions page. It&#x27;ll be on the chrome store whenever&#x2F;if it gets through the review.Hopefully it&#x27;s useful to others.https:&#x2F;&#x2F;github.com&#x2F;dnakov&#x2F;little-rathttps:&#x2F;&#x2F;twitter.com&#x2F;dnak0v",
    "commentLink": "https://news.ycombinator.com/item?id=37119942",
    "commentBody": "Show HN: Little Rat – Chrome extension monitors network calls of all extensionsHacker NewspastloginShow HN: Little Rat – Chrome extension monitors network calls of all extensions (github.com/dnakov) 483 points by npace12 21 hours ago| hidepastfavorite88 comments Hi HNI needed a way to monitor network calls made by chrome extensions so I made a small extension.You can install it by dropping the zip or crx into the extensions page. It&#x27;ll be on the chrome store whenever&#x2F;if it gets through the review.Hopefully it&#x27;s useful to others.https:&#x2F;&#x2F;github.com&#x2F;dnakov&#x2F;little-rathttps:&#x2F;&#x2F;twitter.com&#x2F;dnak0v altairprime 13 hours agoI wish this was a feature of Firefox (or Chrome, as if Google would ever), rather than a third-party extension, so that it had enough adoption to compel other browsers to care too. I&#x27;d like very much to authorize certain extensions to only make GET requests to specific static URLs without any ability to vary the headers, so that they can get data updates without there being any risk of leaking data. And for others, they don&#x27;t need network access at all to do their job locally in my browser instance. But that would be circumventable (since anything that can modify page source can add data transmission), so I imagine they aren&#x27;t doing it because of that. Too bad — better to try than just give up and cede it to a Chrome extension. reply Groxx 5 hours agoparentFor observing it at least, you can - you need to open a debugger for the browser rather than for the current page.The process is roughly the same as inspecting the UI, you basically enable remote debugging and then launch the Browser Toolbox: https:&#x2F;&#x2F;superuser.com&#x2F;questions&#x2F;1608096&#x2F;how-to-inspect-firef...(this is also a great way to figure out what you need to do for a user-chrome CSS file, e.g. if you want to change how tabs appear beyond just theming. though using a user-chrome CSS file is unfortunately a minor pain in the ass.)I had to switch it to \"multi-process mode\" to get network requests from extensions to show up, but that broadly makes sense.e.g. here&#x27;s ublock pulling a random block list that I clicked on to test: https:&#x2F;&#x2F;i.imgur.com&#x2F;wBYbBM2.pngand here&#x27;s Firefox itself updating the safe-browsing list in the background: https:&#x2F;&#x2F;i.imgur.com&#x2F;JYxWwjW.png reply hsbauauvhabzb 12 hours agoparentprevA get request can leak data via the request path or querystring parameters, if that was restricted you could setup communication which time or frequency imply activity with a morse code like protocol (and with enough requests, easily transfer megabytes of data). reply altairprime 11 hours agorootparentYou can just do whatever the modern equivalent of document.trackingPixel.src = &#x27;leak all your data here in a single request&#x27;, since extensions can modify content blocking. Firefox should ask for, accept, and audit a statement of whether your extension needs to make dynamic network calls or not, and why it needs to do so. Yes, you could lie — but then you&#x27;d get caught lying, in violation of, kicked off the store, etc. Today, you can just add tracking, and no one can take any useful action as a result. reply hsbauauvhabzb 9 hours agorootparent100% agree. I think extensions are an odd place to start, but this is the exact reason I avoid browser extensions unless I’ve explicitly audited them (and still don’t like they auto update without permission). reply phil294 3 hours agorootparentSame, but on Firefox, the latter can be nicely configured both on a default and on a per-extension basis. reply tim1994 11 hours agoparentprevIIRC extensions cannot access any URL that hasn&#x27;t been specified in the manifests permission section. I think Firefox shows those URLs in the permission prompt. Those URLs can contain wildcards though and I even think there is a special value for all URLs but only few extensions should require that permission. reply altairprime 11 hours agorootparentFor extensions that modify page data, is that prompt still shown? My understanding was that once you have the &#x27;modify page data&#x27; permission, you&#x27;re no longer required to present URLs in the permission prompt at all — but I&#x27;d be thrilled to be wrong, if that&#x27;s changed! reply londons_explore 3 hours agoparentprevI think browser makers don&#x27;t offer this because any protection put in place would be easy to work around.For example, even if the extension itself can&#x27;t make requests, there are plenty of ways to &#x27;trick&#x27; a webpage into making a request on your behalf when you have permissions to modify the Dom of the web page. reply Pxtl 10 hours agoparentprevI&#x27;d say any extension that&#x27;s making an http request that isn&#x27;t just repeating URLs that are already in the page should show a toast notification with the request body prettified into legibility.A well made extension will only pop up an occasional toast. One that needs the server to work will show the toast when the user expects it to be talking to the server. One sending keypresses or other suspicious data will be really obvious. reply p1mrx 14 hours agoprevGiven that this extension is not very easy to install, I suggest adding a screenshot showing some actual captured network events. The current screenshot hides the most interesting feature. reply Groxx 10 hours agoprevNeat. I&#x27;m surprised this is possible tbh.Not being familiar with exactly what data these APIs (or similar?) provide: could extensions&#x27; abilities to access other extensions&#x27; requests imply any security concerns for e.g. password manager extensions? Or auth-token-using extensions? reply emmanueloga_ 14 hours agoprevNice! Feels like something that should be a chrome:&#x2F;&#x2F; URL. reply UberFly 13 hours agoparentThat was my first thought. Why isn&#x27;t this native to Chromium seeing that extensions are such a security&#x2F;privacy risk. reply benrapscallion 8 hours agorootparentBecause Chrome is made by a company whose primary source of revenue is the sale of its users’ data. Cui bono. Or, “It is difficult to get a man to understand something, when his salary depends on his not understanding it.” reply midoridensha 4 hours agorootparentSure, but someone could fork Chromium and add it in. reply elashri 18 hours agoprevsounds great, do you have plans to port it to Firefox?Does anyone know an equivalent that do the same thing on Firefox? reply krono 16 hours agoparentI believe that these connections should also appear in the browser console[1], otherwise you could always log the traffic[2] or inspect&#x2F;debug any individual extension[3].You will be amazed at the obvious extension policy violations Mozilla is letting many of their \"recommended\" extensions get away with.[1]: https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;devtools-user&#x2F;browse...[2]: https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;networking&#x2F;http&#x2F;logg...[3]: https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;devtools-user&#x2F;about_... reply Modified3019 15 hours agorootparentAny notable offenders? Seems like something worth reporting. reply krono 14 hours agorootparentListed some offences and offenders in another comment from last June: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35792605I&#x27;ve reported these and several other extensions again every time they were updated in great technical detail and through various official channels, but stopped bothering when about a year and several extension updates later nothing had changed. reply Modified3019 14 hours agorootparentGood to know, thank you.If you still happen to have the technical detail you sent off somewhere, that seems like it would be a great reference for starting to learn what to look for. Hell I&#x27;m sure HN would appreciate it as a submission (assuming it actually gets eyes and doesn&#x27;t die in new)I hadn&#x27;t really cared about this topic, because it adds yet more cognitive overhead and I was relying on mozilla to care. Seems this faith was misplaced. reply ColoursofOSINT 12 hours agorootparentprevCould you provide some of the details regarding these extensions?I am not a user, but I have some time to throw something together about it.Giphy seems to have some compiled code in a weird .ts format (which I have not seen before, but I am a novice).It also loads a script from https:&#x2F;&#x2F;www.google-analytics.com&#x2F;analytics.js, isn&#x27;t that remote code?Also, I could not find a privacy policy, even though there is information being sent and received. reply kevingadd 9 hours agorootparent.ts is typescript, FYI replynpace12 18 hours agoparentprevYeah, I&#x27;m going to try this shortly, will post an update. reply distortedsignal 18 hours agorootparentInteresting.I&#x27;ll be watching this. Thanks for the project! reply fjfuvucucuc 18 hours agorootparentprevWaiting :) reply npace12 12 hours agorootparentupdate: so far not great...declarativeNetRequest.onRuleMatchedDebug is not available [1] Even though the docs say it&#x27;s behind a flag [2], it&#x27;s undefined.[1]: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1745773 [2]: https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Mozilla&#x2F;Add-ons&#x2F;Web... reply 123pie123 17 hours agorootparentprevlooking forward to this reply username135 16 hours agorootparentSame reply vdfs 18 hours agoparentprevIn most cases, just adding \"var chrome = browser;\" to the top of each js files would make it work for firefox, which is just a copy of Chrome Extension APIs with slight changes reply judge2020 18 hours agorootparentAccording to mdn[0], Firefox does not support onRuleMatchedDebug so just importing the code likely won&#x27;t work.0: https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Mozilla&#x2F;Add-ons&#x2F;Web... reply lapcat 18 hours agorootparentprevFirefox add-ons actually recognize the \"chrome\" keyword. reply weaksauce 15 hours agorootparentthey actually have a js polyfill that lets you use promise based `browser` keyword in chrome too. reply horsawlarway 13 hours agoprevNifty - but please do this more carefully:https:&#x2F;&#x2F;github.com&#x2F;dnakov&#x2F;little-rat&#x2F;blob&#x2F;main&#x2F;popup.js#L36I do not want to have to worry about whether another extension can inject xss into yours with a crafted request&#x2F;id&#x2F;name. reply npace12 13 hours agoparentthat is a very good point but:* the content security policy does not allow unsafe-inline* extension ids are autogenerated by chrome reply btown 8 hours agorootparentWhile unsafe-inline prevents execution of scripts, it doesn&#x27;t prevent another extension from including HTML in one of the URLs it is requesting, and adding DOM elements that might entirely change the display of the extension. Likely not a huge problem here (there are much easier ways to bypass&#x2F;cheat this extension e.g. by inserting tracking code into the DOM of a visited page so it&#x27;s executed by that page) but it&#x27;s definitely not good practice to interpolate HTML with untrusted strings. reply cantSpellSober 19 hours agoprevThanks for sharing! I&#x27;ll wait till it&#x27;s on chrome store cuz I&#x27;m lazy and don&#x27;t use Twitter. reply judge2020 18 hours agoparentSince it uses `declarativeNetRequest.onRuleMatchedDebug`[0], which is supposed to be debug-only, I doubt it&#x27;ll be allowed in the chrome webstore.0: https:&#x2F;&#x2F;github.com&#x2F;dnakov&#x2F;little-rat&#x2F;blob&#x2F;f0b9b6be39af9fe7f4... reply Daviey 18 hours agoparentprevnext [–]1) Go to Releases, right click the crx file and save. 2) In Chrome, go to Extensions then drag and drop the crx file 3) Profit reply smusamashah 17 hours agorootparentIt is added to extensions but remains disabled with following message> This extension is not listed in the Chrome Web Store and may have been added without your knowledge. Learn more https:&#x2F;&#x2F;support.google.com&#x2F;chrome_webstore&#x2F;answer&#x2F;2811969?vi... reply quickthrower2 9 hours agoprevThe lack of a network call doesn&#x27;t prove the extension is safe. It might cache some data you want to keep private, and send it periodically. reply leke 19 hours agoprevWhy not on the chrome store? reply npace12 19 hours agoparentIt&#x27;s currently under review because it&#x27;s using the chrome.declarativeNetRequest (same API uBlock is using) reply cal85 17 hours agorootparentHang on do you mean to say the web store might accept an extension with `declarativeNetRequestFeedback` permission, it just might take longer and be less certain? I&#x27;ve got an extension that could potentially really benefit from using this permission (because I want to be able to dynamically decide whether to take an action in a content script based on the `Content-Type` header; currently I use imperfect content-sniffing heuristics instead). The last time I dug into it, it seemed that this permission just wasn&#x27;t going to be available after the Manifest v3 moratorium that has already passed. So I&#x27;m interested to know if anything has changed (or if there&#x27;s any special way that extensions can be approved with this permission, e.g. if they&#x27;re popular enough and have a good privacy track record). reply npace12 17 hours agorootparentI&#x27;m not sure, but I was curious too, so I submitted it for review to find out. reply cal85 15 hours agorootparentInteresting, I had assumed it wouldn&#x27;t even allow uploading it if the manifest required that permission. Hope they allow it for you! reply ris58h 3 hours agorootparentprevI have an extension with a small user base that uses &#x27;declarativeNetRequestFeedback&#x27; permission. I haven&#x27;t experienced any issue with the review process.https:&#x2F;&#x2F;ris58h.github.io&#x2F;youtube-chapters-in-player&#x2F; reply p1mrx 14 hours agorootparentprevIsn&#x27;t declarativeNetRequest the new, less powerful Manifest V3 API that uBlock Origin Lite is using? reply npace12 14 hours agorootparentyeah, little rat is using manifest v3 reply canthonytucci 20 hours agoprevLove the name. I have been looking for something just like this. reply _V_ 10 hours agoprevFYI: That CRX in Releases did not work for me - it did install correctly, it showed up in the toolbar but opened an empty popup (no extensions were listed)...The upnacked zip worked just fine though!Nice extension, thanks!(Vivaldi 6.2.3096.3 on Linux) reply _V_ 10 hours agoparentAlso it seems that the \"mute\" button is somewhat broken or something - I have ~10 extensions and when I click \"mute\" on some extension, it will toggle mute on the second to the last.Repeated clicking results in loop of 1) muting second to the last extension 2) muting the extension I&#x27;m actually clicking 3) unmuting second to the last and 4) unmuting the one I&#x27;m clicking :-DIt is quite hard to describe, I may create a video and upload it somewhere later. reply npace12 10 hours agorootparentThanks for the feedback, I&#x27;ll check it out, I haven&#x27;t tried it in Vivaldi yet. reply _V_ 10 hours agorootparentHope it helps!I was clicking around for a bit and noticed one more thing: it does not display \"Anti Anti Debug\" extension - but that extension suddenly appears when I toggle any mute button.Maybe that extension is doing something funny? It is too late for me to try now but I will keep digging around tomorrow. reply npace12 10 hours agorootparentfixed the mute button btw. i noticed the other thing you mentioned as well replyDaviey 18 hours agoprevThanks for sharing, would you mind explaining how it works and if there are any general concerns you have with Chrome not sandboxing between extensions? ie, what else is shared between extensions and what risks do you feel are here.Thanks reply lapcat 18 hours agoparentThe key code is here: https:&#x2F;&#x2F;github.com&#x2F;dnakov&#x2F;little-rat&#x2F;blob&#x2F;f0b9b6be39af9fe7f4... chrome.declarativeNetRequest.onRuleMatchedDebug.addListener((e) => { if (e.request.initiator?.startsWith(&#x27;chrome-extension:&#x2F;&#x2F;&#x27;)) {Given that the extension is using a \"Debug\" API, it seems unlikely that the Chrome Web Store will approve. \"Only available for unpacked extensions with the declarativeNetRequestFeedback permission as this is intended to be used for debugging purposes only.\" https:&#x2F;&#x2F;developer.chrome.com&#x2F;docs&#x2F;extensions&#x2F;reference&#x2F;decla... reply npace12 18 hours agorootparentYeah, that&#x27;s correct. The extension loads a rules_1.json file that just \"allow\"s all traffic originating from third-party scripts through, then logs just the URL of each request coming from a chrome extension. There&#x27;s probably a way to do this with chrome.webRequest, I&#x27;ll experiment with that, but generally that one is more expensive in terms of performance. reply gorhill 18 hours agorootparent> There&#x27;s probably a way to do this with chrome.webRequestNetwork requests initiated by other extensions in their own context are not visible to other extensions through the webRequest API. reply npace12 9 hours agorootparentDamn, I was gonna go research it just in case, but then I noticed who posted this. Mad respect for your work! replybromuk 17 hours agoprevooh, love it. Would be great to have some installation information within the repo for people who aren&#x27;t savvy at enabling dev mode in chrome extensions reply swyx 17 hours agoparentor just link to something off google for it, we shouldnt have to write that for every oss chrome extension reply mschuster91 11 hours agorootparentThing is, you can&#x27;t, Google makes it very difficult to run extensions from anywhere but Chrome Store for a reason - if they didn&#x27;t, scammers would jump on it. reply scrum-treats 10 hours agoprevDownloaded the extension and tested that it&#x27;s working. QQ: What does it mean when there is a \"hit\" (e.g., 1 appears), but when I click the extension to investigate all extensions show 0, and the original displayed number disappears?Also, if I delete an extension, it still appears in the list of extensions in Little Rat. Any easy way to fix this? reply npace12 9 hours agoparentYeah, it&#x27;s only getting the list of extensions once on load, I&#x27;ll push a change in tomorrow to have it refresh. The number shows the number of requests the extension has made. When you click on the name (if > 0), it will show the unique URLs of those requests reply scrum-treats 8 hours agorootparentWhat does it mean when there is a number shown (indicative of a network call), however when you check little rat extension no extension in the list shows > 0? reply FrenchDevRemote 17 hours agoprevreally cool thanks! reply cryptoegorophy 12 hours agoprevIf you can - do not install any extensions. I’ve had a couple like an ad blocker and something else leak my browser history to similarweb and neither extension or similarweb showed that they sell&#x2F;collect my data. reply _V_ 10 hours agoparentThe only viable adblocker is uBlock Origin.There are several clones that are trying to piggyback on that name though. You have to go for the original one - the one from Raymond Hill (or gorhill)! reply pkd 11 hours agoparentprevWhich ad blocker was it? reply yuvalkarmi 18 hours agoprevPretty close naming to Little Snitch - the Mac network monitoring tool! reply cantSpellSober 18 hours agoparentI assumed that was intentional (rat being slang for snitch) reply npace12 18 hours agoparentprevhaha yes, I called it Tiny Snitch at first, but it&#x27;s too close. reply mdaniel 17 hours agoprevDepending on your intentions, the repo would benefit from a license instead of just using github for code hosting reply npace12 17 hours agoparentThanks for pointing it out, forgot to add it. reply swyx 17 hours agorootparentgithub could advance OSS a lot by making license reminders much more prominent. so much code intended-to-be-open-source cant be treated that way because no license file. if anyone from github is here please prod someone in your UI department to make a banner or something! reply jedberg 17 hours agoprev [–] How can I be assured that installing a random Chrome extension from a random person on the internet that has access to all my network data and can&#x27;t get approved in the Chrome store is safe? :) reply duiker101 17 hours agoparentI guess the answer is that you must be able to read the code and use your own judgement.Here the actual code of the extension is basically 2 files, one of 114 lines and the other 66. Plain js, easy to digest. Looks pretty safe. reply npace12 17 hours agoparentprevI&#x27;m with you on that one, that&#x27;s why the code is on github. The best way to install it is to check out the code for any risks, download the repo as a ZIP file and install it. reply meesles 17 hours agoparentprevVerifying Github source code is not sufficient, since you don&#x27;t know the release contains that source code (when downloading fro the store). You&#x27;d have to verify signaturesAlso, plenty of these extensions have been acquired by data firms or other sketchy places to then add your browser to botnets. If these are absolutely necessary for you, I highly recommend downloading the source and dumping it into Chrome&#x2F;Edge via developer mode. At least then you know they can&#x27;t update it in the background and you know what you&#x27;re running. reply snowycat 6 hours agorootparentYou could always download it from github, turn on developer mode in chrome (there&#x27;s a little switch in the top right corner of the chrome:&#x2F;&#x2F;extensions ui), and then load it as an unpacked extension from source without ever touching the chrome web store. reply SoKamil 17 hours agorootparentprev.crx is just a .zip underneath. You can unzip it and inspect the code. reply throwaway290 17 hours agorootparentI thought it&#x27;s just installed and that&#x27;s it, cool... reply Exuma 13 hours agorootparentprevIt&#x27;s not in the store, you download it reply spread_love 11 hours agoparentprev [–] By reading the source code? No wonder reddit used to go down so often... reply jedberg 11 hours agorootparent [–] I don&#x27;t pretend to be a security expert in every language.> No wonder reddit used to go down so often...That&#x27;s uncalled for. If this were reddit I&#x27;d have a much spicier retort. reply spread_love 8 hours agorootparent [–] just a joke, apologies :(you leaving is actually part of the reason I left at the time, you were one of the few admins who regularly participated (it seemed) reply jedberg 8 hours agorootparent [–] No worries, I know it was a joke. You can&#x27;t be a reddit admin for years and not a have a thick skin. :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A person developed a Chrome extension to monitor network calls made by other Chrome extensions.",
      "The extension was shared on GitHub, with the possibility of being available on the Chrome store after review.",
      "Links to the GitHub repository and the developer's Twitter account were provided."
    ],
    "commentSummary": [
      "The Little Rat Chrome extension is designed to monitor network calls made by other Chrome extensions.",
      "Users have expressed concerns about the security and potential risks associated with the extension.",
      "However, they also believe that it could be a valuable tool for identifying security vulnerabilities.",
      "The extension is currently being reviewed for inclusion in the Chrome Web Store.",
      "Users have suggested ways to verify the safety of the extension."
    ],
    "points": 483,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1692013799
  },
  {
    "id": 37124187,
    "title": "Discord.io breached, 760k user accounts for sale on darknet",
    "originLink": "https://stackdiary.com/the-data-of-760000-discord-io-users-was-put-up-for-sale-on-the-darknet/",
    "originBody": "Skip to content Search for: Stack Diary Main Navigation Secondary Navigation DEVELOPMENT DESIGN AI TECH SECURITY BUSINESS HOSTING WORDPRESS TUTORIALS Security The data of 760,000 Discord.io users was put up for sale on the darknet Alex IvanovsAugust 14, 2023Reader Disclosure Note: I've gone ahead and updated the featured image, so it doesn't seem like this has something to do with Discord \"directly\". It was not my intention to leave an impression like that, but this still affects every single Discord user who was using the Discord.io service! An unidentified individual has listed the data of 760,000 Discord.io (the site is dead at the moment, so you can see an Archive.org snapshot here) users for sale on a darknet forum. This discovery was brought to light by the \"Information Leaks\" Telegram channel, associated with the Russian service for tracking vulnerabilities, data leaks, and monitoring fraudulent online resources. For clarity, Discord.io is/was a platform that allows you to create custom, personal Discord invites. The offered database comprises details like email addresses, hashed passwords, and other user-specific data. Update (8/15/2023): A spokesperson from Discord has responded to my email with the following, Discord is not affiliated with Discord.io. We do not share any user information with Discord.io directly and we do not have access to or control of information in Discord.io's custody. We are committed to protecting the privacy and data of our users and encourage our users to enable Two-Factor Authentication (2FA) to help keep their accounts protected, and consider SMS Authentication. Additionally, we have revoked the oauth tokens for any Discord user that has used Discord.io, so that app can no longer perform actions on behalf of those users until they re-authenticate. Overnight, a few other publications picked this up and spoke with the hacker (Akhirah), who said that his reasoning behind hacking Discord.io is that they enable illegal and harmful content and that the breach wasn't about \"making money\". Nevertheless, now that Discord (the official app) has confirmed that the keys are revoked, the only thing you need to do is check your passwords and get 2FA enabled. Discord.io team has now confirmed that the breach is real; an update is added at the bottom of the article! To vouch for the authenticity of the data, the seller presented a sample which was then reviewed by cybersecurity experts. Their evaluation confirmed that the sample logins are genuine, matching real Discord users. And just to make it clear - genuine, as in the corresponding email addresses from the leak, were verified to be associated with real Discord accounts through several password recovery tests. The implication here is that malevolent parties can exploit this data for phishing schemes, spamming, or other deceptive undertakings. Interesting text there at the bottom, \"database access still available\". This does look to be real, though. I tried reaching out to the Discord.io team on their Discord server, and two minutes after joining, every single channel got manually deleted. All the channels in the Discord.io server getting manually deleted. For users of the platform, the advisable course of action is to promptly change passwords and activate two-factor authentication on their accounts to bolster security. Discord.io team confirms the breach is real; here's what you need to know The team behind Discord.io has officially confirmed the data breach. In a detailed statement on Discord, they provided a comprehensive account of the events that led to the breach, what data was compromised, and the subsequent actions they've taken. Timeline of Events: Monday, August 14, 2023, 12:51 AM CET: A preview of the Discord.io user database appears on BreachForums. Monday, August 14, 2023, 4:30 PM CET: Discord.io team becomes aware of the breach. Monday, August 14, 2023, 4:36 PM CET: The breach's legitimacy is confirmed. Monday, August 14, 2023, 4:40 PM CET: All Discord.io services commence shutdown. Data Compromised in the Breach: Non-Sensitive Information: Internal user ID Avatar details User status (e.g., moderator, admin, has ads, banned, public) Coin balance and current streak in the free minigame API key (relevant for a limited number of users) Registration and last payment dates, including premium membership expiration Potentially Sensitive Information: Usernames, either from signup or the current Discord username Discord ID Email address associated with the account Billing address (pertaining to a select few users who provided this before the adoption of Stripe for payments) Salted and hashed passwords (mainly concerning users prior to 2018 when Discord.io began exclusively using Discord for logins) Data That Remained Secure: Anything not explicitly mentioned in the compromised list. Payment details, which are securely stored with partners Stripe and PayPal. Further Actions & Notes: All existing premium subscriptions have been canceled, with the team set to contact subscribers individually. As of their last update, the Discord.io team hasn't established contact with the culprits nor discerned if the database has been shared with the public. A list of servers that once used Discord.io's service has been made available, though it might contain outdated or inactive links. Users wishing to get in touch are encouraged to send a helpdesk request, with \"Support\" for general queries and \"Admin\" for sensitive matters. Given the gravity of the situation, the team cautions that they might not be able to address every message but appreciate user patience and understanding. WRITTEN BY Alex Ivanovs Alex is a full-stack developer with more than 15 years of experience. After many years of threading the self-taught path, he discovered a natural passion for writing. His past work includes helping build the Huffington Post Code column and working with publishers such as Entrepreneur, TheNextWeb, and many prominent tech startups. Post navigation Previous Post PREVIOUS Top 9 Free Code Editors and Coding Software for Windows Next Post NEXT Julian Assange might return to Australia through a possible plea deal with the US Read also Telegram turns 10 years old and releases Stories to everyone The 10 Best Low-Code Development Platforms How to Use ChatGPT for Data Analysis Flush DNS: How to flush DNS Cache on Mac, Windows, or Linux How to Choose a Website Builder for Small Business © 2023 STACK DIARY - ALL RIGHTS RESERVED. Footer Menu ABOUT ADVERTISE DISCLOSURE CONTACT",
    "commentLink": "https://news.ycombinator.com/item?id=37124187",
    "commentBody": "Discord.io breached, 760k user accounts for sale on darknetHacker NewspastloginDiscord.io breached, 760k user accounts for sale on darknet (stackdiary.com) 390 points by skilled 16 hours ago| hidepastfavorite135 comments warent 15 hours agoThankfully I never used this website exactly because I feared this.There was a link to join a discord server via Discord.io that showed as a top Google result.I clicked it not even aware it was 3rd party. Thankfully OAuth gave me the friendly confirmation page saying \"You are about to connect with this third party service and grant full access to your account.\"I said WTF? NOShame on the Discord legal team and their executive team for completely lacking diligence on this. reply rvnx 14 hours agoparentIf Discord was allowing this website to run for so long using this brand, don&#x27;t they risk losing the trademark because of the dilution due to non-enforcement ? reply stevehawk 12 hours agorootparentCorrect. if you don&#x27;t defend your trademark then you risk losing it. reply lathiat 2 hours agorootparentThis is generally not nearly as true as people think.At least according to the EFF: https:&#x2F;&#x2F;www.eff.org&#x2F;deeplinks&#x2F;2013&#x2F;11&#x2F;trademark-law-does-not...> The circumstances under which a company could actually lose a trademark—such as abandonment and genericide—are quite limited. Genericide occurs when a trademark becomes the standard term for a type of good (‘zipper’ and ‘escalator’ being two famous examples). This is very rare and would not be a problem for Canonical unless people start saying “Ubuntu” simply to mean “operating system.” Courts also set a very high bar to show abandonment (usually years of total non-use). Importantly, failure to enforce a mark against every potential infringer does not show abandonment. reply eastbound 13 hours agorootparentprevJust to confirm, they have a trademark: https:&#x2F;&#x2F;trademarks.justia.com&#x2F;866&#x2F;35&#x2F;discord-86635386.htmlThey don’t seem to mention it on their website. I don’t see any guideline for how to respect their trademark: https:&#x2F;&#x2F;discord.com&#x2F;brandingNow the question, does it risk dilution if a company doesn’t say what’s allowed. reply NolF 11 hours agorootparentYes. Trademark law says the use of a trademark as a trademark is an issue. Using the discord logo to link to a discord channel is fine. Allowing a site to be named Discord with a different TLD is using a trademark as a trademark and that can have consequences. The whole point of trademark is to distinguish goods&#x2F;services and by failing to prevent the use of discord.io they kinda dropping the ball here in my opinion. reply account42 2 hours agorootparentUsing discord as a TLD would not be automatic trademark infringement. You can&#x27;t just get an all-encompassing trademark for english words. reply hunter2_ 11 hours agorootparentprevDoes the fact that .io is a ccTLD (despite not actually being used primarily for internal BIOT purposes) offer any counterpoint to that argument? reply dagmx 10 hours agorootparentNo, it’s still trademark infringement. Especially since it relates to the same product. It would be different if they were unrelated but this is about as bad as infringement and brand confusion can get. Any competent legal OR marketing team would have sent them a C&D ages ago. reply inetknght 9 hours agorootparent> Any competent legal OR marketing team would have sent them a C&D ages ago.Interesting. That about sums up my opinion of their development team. replypredictabl3 15 hours agoparentprevIf Discord.io was using OAuth then this would largely be a non-issue as those tokens could be invalidated or revoked, by Discord, trivially. And they wouldn&#x27;t have any password data, hashed or otherwise.Granted, I don&#x27;t use discord.io , so maybe I&#x27;m missing something. reply AgentK20 15 hours agorootparentTo quote the article:> Salted and hashed passwords (mainly concerning users prior to 2018 when Discord.io began exclusively using Discord for logins)So it sounds like they used to have their own accounts before integrating via Discord OAuth, and some users may be affected by this. Unsure if they didn&#x27;t delete users&#x27; hashed PWs once they migrated to the OAuth flow or something like that. reply explaininjs 15 hours agorootparentprevBased on the screenshot it would seem they do have hashed passwords, specifically it looks like bcrypt hashes with a cost factor of 8. Not sure why the cost would be so low, or indeed why the hashes are available at all. reply michaelmrose 3 hours agoparentprevDoes discord actually get any access other than knowing your email address account picture and name?This is basically all that log in with Google requires or provides and asking for more access would be abnormal. reply PUSH_AX 15 hours agoprevJust FYI, discord.io !== discord.com the chat app, it&#x27;s a related but separate service. reply hbn 13 hours agoparentNormally I think it&#x27;s lame when a product-for-a-product (there&#x27;s probably a better term) has to abide by stringent branding guidelines to not look official. e.g. when third-party reddit clients (RIP) had to change from e.g. \"Reddit Sync\" to \"Sync for Reddit\" and they weren&#x27;t allowed to use the Snoo character in their branding.But in this case... why was Discord fine with this branding? It looks unabashedly like an alternate official domain for their own service. Googling \"what is discord.io\" leads to a good handful of confused redditors asking if it&#x27;s legit&#x2F;safe. reply jumpCastle 11 hours agorootparentI still use infinity for reddit though. reply WheatMillington 14 hours agoparentprevAnd discord.com !== discordapp.com or discord.gg. reply Technetium 13 hours agorootparent\"As of May 4th, 2020, we have moved our domain from discordapp.com to discord.com!\"https:&#x2F;&#x2F;support.discord.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360042987951-D... reply jowea 13 hours agorootparentprevThey all redirect to discord.com now. reply account42 2 hours agorootparentdiscord.gg is used for invite links reply superkuh 15 hours agoprev> third-party interface tailored for the widely-used Discord messenger.Isn&#x27;t this explicitly against the Discord TOS? I&#x27;m surprised it wasn&#x27;t shut down by Discord itself. reply nijave 15 hours agoparentI&#x27;m surprised using the domain `discord.io` alone wasn&#x27;t enough to get them shut down. reply jrockway 15 hours agorootparentI&#x27;m guessing the British Indian Ocean Territory doesn&#x27;t have a lot of administrators to handle trademark claims. According to Wikipedia, \"the only inhabitants are British and United States military personnel, and associated contractors, who collectively number around 3,000 (2018 figures).\"Darn that global Internet, allowing people to use unauthorized chat clients with impunity! reply bragr 12 hours agorootparent.io domain is officially administrated out of the UK and is own by Ethos Capital, a private equity firm out of the US. Surely both the American and&#x2F;or UK courts would be valid avenues for enforcement. reply zoky 15 hours agorootparentprevThere are other ways to shut down a third-party service, from sending a cease and desist letter for trademark infringement to server-side blocking of access to their API. reply teddyh 15 hours agorootparentprev> Darn that global Internet, allowing people to use unauthorized chat clients with impunity! The use was not the problem; the name was the problem. reply jrockway 14 hours agorootparentA sense of discord washes over me as I eat an apple in front of a computer running XWindows. A lesson about using a common English words as a trademark becomes apparent in my mind. reply superkuh 14 hours agorootparentprev>Darn that global Internet, allowing people to use unauthorized chat clients with impunity!The problem here is that people are chosing to use Disord despite the fact that it is so stupidly proprietary. If Discord actually enforced it&#x27;s rules all the time there&#x27;d have been far fewer teamspeak&#x2F;irc&#x2F;mumble&#x2F;etc people lured into it&#x27;s walled garden. It is a literal bait and switch.So it&#x27;s important to point out a large fraction of the ways people do use Discord are actually very much against the TOS and could be prosecuted under the CFAA as felonies if Discord corporate thought they were rocking the boat and decided to buy a district attorney. It&#x27;s the worst of both worlds. reply NavinF 12 hours agorootparent> people are chosing to use Disord despite the fact that it is so stupidly proprietaryThis has zero relevance to normal users. Does teamspeak&#x2F;irc&#x2F;mumble&#x2F;etc even support live streaming with screen+audio capture to a group chat? That&#x27;s a pretty basic feature in 2023. I&#x27;m not aware of any serious open source competitors in this space reply lightedman 9 hours agorootparent\"Does teamspeak&#x2F;irc&#x2F;mumble&#x2F;etc even support live streaming with screen+audio capture to a group chat?\"pIRCh98 had video chat support, and back then we used some wrapper from FRAPS to do our screen captures.Of course, back then, video chat was such a niche thing.Everyone else is actually late to the game - IRC had this capability before the majority of known players. replyjudge2020 15 hours agoparentprevIt was primarily a way for non-partner servers to have permanent, readable invite links before these became available officially (by paying users boosting a server). It wasn&#x27;t actually a third party interface that recreated the discord client or anything (unless that&#x27;s a recent development). reply lakomen 14 hours agoprevOk so when I&#x27;ve never used a 3rd party discord service I&#x27;m safe. I got scared there for a moment, but then I thought what would I lose? Nothing at all. Nothing that can&#x27;t be replaced. No contacts worth keeping. reply poglet 11 hours agoparentIf someone has access to your account I assume they can read all your messages and possibly impersonate you. reply Spivak 10 hours agorootparentHaving OAuth creds is a totally different thing than having access to your account. I support \"Log in with Discord\" on my site that uses the OAuth flow and the only thing I get out is a set of creds that can hit &#x2F;user&#x2F;@me and let me say \"the user that just authed is this Discord user.\" Now discord.io could have asked for everything but the risk of some random integration is on average a lot less. To my knowledge absolutely nothing has the rpc scopes.The good news is that even with every scope you can&#x27;t take over the account and the service can just be removed cutting off their access for sure. reply gautamsomani 14 hours agoprevNoob question - What websites are these where such data is published? I never came across any? reply xcdzvyn 6 hours agoparentWhy are all the other replies so mysterious and LARPy?https:&#x2F;&#x2F;discord.io&#x2F; has been replaced with a termination notice, and they directly mention where the credentials are being sold. Google the name, it&#x27;s the top result.Leaked credentials are sold on the open internet, on sites indexed by search engines. This isn&#x27;t some quadruple proxy Anonymous hacker TOR exclusive club.Edit: One better - any time you hear Microsoft, or Google, or Crebs, talking about some new \"advanced\" \"Russian\" \"APT\", 9 times out of 10 it&#x27;s a kid posting on one of these forums, reselling stale credentials, or a fork of Mirai, or some other totally non-credible threat.This stuff is WAY less cool than people make it seem. reply Sebguer 5 hours agorootparentBecause the LARPing is why most security professionals do the job. reply chefandy 14 hours agoparentprevVarious darknet fora. Certainly nowhere on clearnet. There are search engines that deal with such things though I&#x27;ll bet there&#x27;s a 99:1 ratio of scam to legit. I have no idea how someone world go about validating what they saw. reply cowsup 14 hours agorootparentIn this case, they validated it by:1. confirming the emails were not already listed in other databases &#x2F; leaks;2. going to the actual Discord platform and performing a \"Forgot Password\" request, entering a stolen email, and seeing if it goes through or not, as Discord confirms if an email exists or not during this flow;3. contacting Discord.io directly, who confirmed & put out a statement.Other data breaches are harder to verify. Troy Hunt (owner of haveibeenpwned.com) described this in far more interesting ways than I ever could[0], but for each breach, it varies.[0]: https:&#x2F;&#x2F;www.troyhunt.com&#x2F;heres-how-i-verify-data-breaches&#x2F; reply technion 12 hours agorootparentprevUntil recently, every time a story was run about a leak being \"for sale on the dark web\", you could visit raid forums or breach forums, both clearnet sites, and note that&#x27;s where it&#x27;s for sale. reply judge2020 14 hours agorootparentprevValidation is likely tied to reputation - such as by showing a sample to an established moderator &#x2F; community member and them vouching that the data seems real. reply tamimio 12 hours agoparentprevI have a directory of most of them, I would not post it under my real identity obviously, but if you happen to be into the cybersec space, definitely you came across some of these sites, there are even sites with latest APT discovered up to this month too. reply politelemon 15 hours agoprevTo those who used discord.io, what was the appeal of it over discord.gg? Unfortunately their site is down so I can&#x27;t even see what its own marketing said. reply bavarianbob 15 hours agoparentI believe discord.io is (was?) a discovery platform. You can view an archive of the site here: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220329132537&#x2F;https:&#x2F;&#x2F;discord.i... reply sharts 10 hours agoprevWhere there are DBs and no accountability for data security, there are breaches. Nothing to see here. reply dancemethis 5 hours agoprevI mean, that&#x27;s not _too_ different from the way Discord \"officially\" sells user data in the shadows. reply pyuser583 4 hours agoprevAs a discord user, how worried should I be? reply lcnPylGDnU4H9OF 4 hours agoparentIt sounds like one would needed to have connected their discord account with this separate discord-related app. If you didn’t do that, I would expect your account wasn’t breached. reply zapkyeskrill 14 hours agoprevHow would one know if they&#x27;re affected? I use discord but have no recollection how I signed up .. probably via first search hit (which could be an add) reply qingcharles 14 hours agoparentThis isn&#x27;t the main Discord app&#x2F;site, so you&#x27;re probably not affected.But you can always check at the link below. That guy gets a lot of donated packages of cracked data:https:&#x2F;&#x2F;haveibeenpwned.com&#x2F;Google also has their own people seemingly trolling through onion sites buying up packages of cracked data so they can run it against their own properties and see if anyone is affected. reply scudsworth 14 hours agoprevwhat was the actual killer app here reply boneitis 13 hours agoparent[e: i apparently mistook discordio for a couple of the other discovery platforms we utilized, but it seems to be the same concept as the others, looking at the web archives]discordapp back then was really just a collection of servers pretty siloed&#x2F;insulated from each other, with barebones voice and text chat functionality.discordio offered some basic form of discovery and cross-server exploration&#x2F;networking when it was effectively nonexistent back then. it, along with other outreach efforts on our part, certainly helped boost our community size and amusingly also attracted a lot of teens approaching us to ask if we wanted to \"partner up\" with their server (i help administer a studygroup server on discord).my 2c, as a fairly active user since &#x27;16. reply ehsankia 12 hours agorootparentI assume being able to get a custom link is also nice, I believe discord only allows that for partnered servers? reply boneitis 12 hours agorootparentah, forgot about the free custom links.anyway, &#x27;partnered&#x27;, to my recollection, means a formal arrangement with discord where the particular server community is directly promoted by discord on front pages and such, in exchange for meeting a higher bar of conduct that represents a model community (SFW, PC, etc.).one of the perks that comes with this is being granted \"Level 3\" boost status, free of charge (normally costing anywhere from $49-70&#x2F;mo, depending on circumstances), which is what directly grants the custom link feature. reply noxvilleza 11 hours agorootparentprevI run a Discord server which wasn&#x27;t partnered, is quite small, and somehow had a custom link (we also certainly weren&#x27;t boosted). reply paulpauper 14 hours agoprevas long as there is data, there will be data breaches reply Waterluvian 12 hours agoparentThis is why I store all my sensitive data on the cozy side of an event horizon. reply tmpz22 11 hours agorootparentI have a vault set to open when GRRMs Winds of Winter comes out. I feel pretty good about it. reply gochi 15 hours agoprevWonder how many people are going to think discord.io is officially related to discordapp.com&#x2F;discord.com. reply paxys 15 hours agoparentAnd this is exactly why companies protect their trademarks. A site called discord.io which offered services on top of Discord but wasn&#x27;t affiliated with it in any way (but tricked users into believing so by using its logo and screenshots) should have been nipped in the bud a long time ago. reply stcredzero 14 hours agorootparentApparently, this sort of thing happened to Mr. Beast with regards to Mr. Beast Burger. Even though his agreements&#x2F;contracts forbade the company making the virtual restaurant supplies from doing so, that company trademarked his likeness and brand in half a dozen foreign countries. He&#x27;s currently suing them for damages, and for not paying him the agreed amount for his participation. (Apparently, they had paid him $0!) reply dom96 13 hours agorootparentDid Mr Beast not realise that creating thousands of ghost restaurants would be a bad idea? reply NolF 11 hours agorootparentHe created the idea at the beginning of the pandemic. His thought process was that the Mr Beast brand would allow smaller stores to carry his product and incentivise people to buy take out from those shops and help during lockdowns.I don&#x27;t believe the contract between him and VDC is out outlining the contractual obligations, SLAs, trademark and marketing issues etc. reply colechristensen 12 hours agorootparentprevIs there anything particularly wrong with a delivery-only restaurant? That is the standard definition of “ghost restaurant” I know of. reply constantly 12 hours agorootparentNot really anything super wrong with it, other than perhaps it would be harder to air grievances with them because there’s usually nowhere to go, and QC issues.“Ghost Kitchens” have a more nefarious connotation than “delivery only” though because often it will be a single kitchen yet be advertised as many distinct restaurants. I saw one in one major city that was something like fifteen “different restaurants” operating from the same small space, which is sketchy.But I think the person to whom you’re responding was relying more on the word “thousands” here. So given the connotation I think opening thousands of these things is pretty sketchy for some random YouTube personality with presumably no experience with restaurants to be opening simultaneously. reply benatkin 12 hours agorootparentprevquality control reply sleepybrett 11 hours agorootparentshould be no different than any other franchisee. If you are worried about them ruining your reputation then you should QC them with secret shoppers, inspectors, etc. reply Solvency 14 hours agorootparentprevWhy are we acting like Mr Beast didn&#x27;t also steal the moniker from Mr Beast (of Exit Through The Gift Shop notoriety)? reply burkaman 14 hours agorootparentAre you thinking of Mr. Brainwash? reply echelon 13 hours agorootparentYeah, they have to be.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mr._Brainwash(Don&#x27;t read if you don&#x27;t want spoilers. Exit Through the Gift Shop is phenomenal and should be watched without knowing about this guy. Watch it, then read the Wikipedia article for yet another surprise.) reply tester457 13 hours agorootparentprevHis name was generated by xbox for a gamertag reply dymk 13 hours agorootparentprevWho? reply benatkin 13 hours agorootparentprevThis is going to get harder unless the US government or US tech companies censor the Internet to block ones that don&#x27;t follow US affiliated trademark law. Which I hope you wouldn&#x27;t support. reply dymk 13 hours agorootparentThat&#x27;s not how it works. They just wouldn&#x27;t be allowed to do business in the US, which seems reasonable. reply benatkin 12 hours agorootparentSee the sister comment about Mr. Beast. reply rpastuszak 15 hours agoparentprevThanks for pointing that out. I genuinely thought that was the case!(My dog uses the native Discord client because he&#x27;s too cheap to pay for a baby cam.) reply k8sToGo 15 hours agorootparentHave you tried to increase the allowance for your dog? reply ajmurmann 14 hours agorootparentMaybe the lazy dog should get a part-time job like rescuing people in the Alps while carrying a little barrel of liquor or barking at people with drugs, money or fruit at the airport. reply rpastuszak 13 hours agorootparentprevSort of. He just had a bath and my partner fed him. But we had to bribe him with a grissini to get into the tub.Can you pay for Discord in grissinis? reply bonestamp2 13 hours agorootparentHold on, I&#x27;m making a deck right now to get funding for such a marketplace. replysolardev 15 hours agorootparentprevYour dog has more financial acumen than some humans... reply hluska 14 hours agorootparentprevCome on, your dog has a ruff life…:)Serious question though, do you use it as a dog monitor? That’s a good idea. reply rpastuszak 1 hour agorootparentYeah, he has his own separate account and a video channel.This way both my partner and I can check up on him if we both leave the house for longer and it&#x27;s noisy outside. He&#x27;s a rescue and sometimes gets anxious&#x2F;loud, but he&#x27;s getting better.Side effect: once I came home to spot him with my brothers who live across the continent chatting and drinking beer. reply vram22 14 hours agorootparentprevThat&#x27;s a tall tail now reply Klathmon 15 hours agoparentprevProbably most, considering it&#x27;s Discord&#x27;s logo and screenshots of their app used in the article, and discord.io isn&#x27;t loading with 522 errors right now so you can&#x27;t exactly check. reply princevegeta89 14 hours agoparentprevHowdy, my first thought after seeing this headline was basically that the Discord messenger App got hacked and user info was stolen. reply benatkin 15 hours agoparentprevFWIW they were discordapp.com until May 4, 2020https:&#x2F;&#x2F;support.discord.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360042987951-D...I remembered vaguely that it was something different from discord.com, and was fooled by discord.io :D reply axus 15 hours agoparentprevIt sounds more official than discord.gg reply mattl 15 hours agorootparentIt shouldn&#x27;t really..gg and .io are being used for novelty value. reply bee_rider 14 hours agorootparent.io has been used as a sort of general-purpose tld to signal sort of… I dunno, hip, dev-focused sites, right? It is at least slightly less novel than gg. reply codetrotter 14 hours agorootparentAgree, but it’s important to point out that .gg grew popular in the gaming crowd because “gg” in gaming means “good game”. It’s used in-game in the chat by many players of online multiplayer games as a way of thanking each other after a match. It can be used sincerely or it can also be used sarcastically but in the latter case you’d typically say “ggez” as a taunt implying that the win was easy (“ez”) because you are more skilled than your opposing team.And for .io of course that one is&#x2F;was popular among tech companies because it looks similar to “I&#x2F;O” (input&#x2F;output). reply mattl 14 hours agorootparentprev.gg means \"good game\" so I can see why Discord would use it. reply bee_rider 13 hours agorootparentDefinitely, it is a sort of quirky and fun use of .gg.It is a little surprising given their field that they didn’t also grab the .io. reply dancemethis 5 hours agorootparentprevIt&#x27;s \"winning\" personal user data with ease. It fits. reply deprecative 15 hours agorootparentprevIt&#x27;s definitely not just me but I only have a data point of one to use: Anytime I see something that isn&#x27;t .com, .org, or .gov I immediately assume it&#x27;s less than reputable at best and actively trying to scam&#x2F;phish me at worst. reply thih9 14 hours agorootparentI got curious and decided to check which popular websites that I use are not on a .com &#x2F; .org domain.I found: kubernetes.io , sentry.io , codepen.io , itch.io , not to mention lever.co , elastic.co and last but not the least, notion.so . reply bredren 14 hours agorootparentIt had been that companies that “made” it would eventually pick up the .com. But it seems like it is more common to stick with whatever TLD they had before. reply bee_rider 14 hours agorootparentprevThe .so TLD, very dynamic. reply Symbiote 14 hours agorootparentprevWith the obvious exception of sites correctly associated to the country of their domain.A tourist attraction in Guernsey can very reasonably use .gg and maintain full credibility. reply mattl 15 hours agorootparentprevYeah, there&#x27;s a difference between .com .net .org .gov and many of the country code TLDs when you&#x27;re looking for non-local content. reply madeofpalk 15 hours agoparentprevWhat is Discord.io? reply 3rd3 15 hours agorootparentdiscord.io is a service that provides redirect&#x2F;invite links&#x2F;URLs to Discord servers. reply pc86 14 hours agorootparent\"This service provides links for a chat app\" is a crazy sentence. reply jadamson 13 hours agorootparentGetting a custom URL for a Discord server (e.g. discord.gg&#x2F;hackernews) requires 14 \"server boosts\" which cost $35&#x2F;year each, so nearly $500&#x2F;year. There&#x27;s a discount if you have their premium Nitro package, but even then it&#x27;s something on the order of $300.Meanwhile discord.io is free and you won&#x27;t lose your URL to a crypto scam server when someone forgets to renew their boost. Kind of inevitable that such a service would pop up. reply xboxnolifes 13 hours agorootparentI&#x27;m pretty sure it predates the ability to have a custom server url from boosting. replyonehair 15 hours agoparentprevMe, I&#x27;ve changed my password, until I read the title again and then this comment xD reply tcgv 14 hours agorootparentBetter safe than sorry ;) reply quickthrower2 14 hours agorootparentprevRotations don’t hurt reply mkagenius 14 hours agorootparentBut he forgot the new one reply quickthrower2 11 hours agorootparentBest kind of security reply dancemethis 5 hours agorootparentNot using particularly privacy-hostile platforms is the actual best kind of security. replywslh 15 hours agoparentprevI would add: \"unofficial\" to the title or something that clarify the brand issue. reply kalev 15 hours agoparentprevThat should be clarified in the HN title, imo reply soloninja 15 hours agoprev [–] Happens way to often now with wall garden services reply thebigman433 15 hours agoparentHow does the concept of a walled garden have anything to do with this? reply Exuma 14 hours agoparentprev [–] Discord.io is not the same thing as discord.com replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The data of 760,000 users on Discord.io has been leaked on the darknet, including email addresses, hashed passwords, and other user-specific information.",
      "The breach was confirmed by Discord.io, but Discord (the official app) has stated that they are not associated with Discord.io and have revoked access tokens for any users who used Discord.io.",
      "The breach was carried out by a hacker named Akhirah, who claimed it was not for money but due to the presence of illegal and harmful content on Discord.io. Cybersecurity experts have verified the authenticity of the data, highlighting the risk of phishing and spamming attacks. Discord.io recommends users change their passwords and enable two-factor authentication, while also canceling existing premium subscriptions and attempting to establish communication with the culprits to determine if the data has been shared publicly."
    ],
    "commentSummary": [
      "A breach on Discord.io has led to the sale of 760,000 user accounts on the darknet.",
      "Users unknowingly connected their accounts to a third-party service, resulting in the breach.",
      "Discord users are concerned about the lack of action taken by the company and the potential risk to their trademark."
    ],
    "points": 390,
    "commentCount": 135,
    "retryCount": 0,
    "time": 1692035520
  },
  {
    "id": 37122871,
    "title": "Backward Compatibility, Go 1.21, and Go 2",
    "originLink": "https://go.dev/blog/compat",
    "originBody": "Skip to Main Content Why Go arrow_drop_down Learn Docs arrow_drop_down Packages Community arrow_drop_down Why Go navigate_next navigate_beforeWhy Go Case Studies Use Cases Security Learn Docs navigate_next navigate_beforeDocs Effective Go Go User Manual Standard library Release Notes Packages Community navigate_next navigate_beforeCommunity Recorded Talks Meetups open_in_new Conferences open_in_new Go blog Go project Get connected The Go Blog Backward Compatibility, Go 1.21, and Go 2 Russ Cox 14 August 2023 Go 1.21 includes new features to improve compatibility. Before you stop reading, I know that sounds boring. But boring can be good. Back in the early days of Go 1, Go was exciting and full of surprises. Each week we cut a new snapshot release and everyone got to roll the dice to see what we’d changed and how their programs would break. We released Go 1 and its compatibility promise to remove the excitement, so that new releases of Go would be boring. Boring is good. Boring is stable. Boring means being able to focus on your work, not on what’s different about Go. This post is about the important work we shipped in Go 1.21 to keep Go boring. Go 1 Compatibility We’ve been focused on compatibility for over a decade. For Go 1, back in 2012, we published a document titled “Go 1 and the Future of Go Programs” that lays out a very clear intention: It is intended that programs written to the Go 1 specification will continue to compile and run correctly, unchanged, over the lifetime of that specification. … Go programs that work today should continue to work even as future releases of Go 1 arise. There are a few qualifications to that. First, compatibility means source compatibility. When you update to a new version of Go, you do have to recompile your code. Second, we can add new APIs, but not in a way that breaks existing code. The end of the document warns, “[It] is impossible to guarantee that no future change will break any program.” Then it lays out a number of reasons why programs might still break. For example, it makes sense that if your program depends on a buggy behavior and we fix the bug, your program will break. But we try very hard to break as little as possible and keep Go boring. There are two main approaches we’ve used so far: API checking and testing. API Checking Perhaps the clearest fact about compatibility is that we can’t take away API, or else programs using it will break. For example, here’s a program someone has written that we can’t break: package main import \"os\" func main() { os.Stdout.WriteString(\"hello, world\\n\") } We can’t remove the package os; we can’t remove the global variable os.Stdout, which is an *os.File; and we also can’t remove the os.File method WriteString. It should be clear that removing any of those would break this program. It’s perhaps less clear that we can’t change the type of os.Stdout at all. Suppose we want to make it an interface with the same methods. The program we just saw wouldn’t break, but this one would: package main import \"os\" func main() { greet(os.Stdout) } func greet(f *os.File) { f.WriteString(“hello, world\\n”) } This program passes os.Stdout to a function named greet that requires an argument of type *os.File. So changing os.Stdout to an interface will break this program. To help us as we develop Go, we use a tool that maintains a list of each package’s exported API in files separate from the actual packages: % cat go/api/go1.21.txt pkg bytes, func ContainsFunc([]uint8, func(int32) bool) bool #54386 pkg bytes, method (*Buffer) AvailableBuffer() []uint8 #53685 pkg bytes, method (*Buffer) Available() int #53685 pkg cmp, func Compare[$0 Ordered]($0, $0) int #59488 pkg cmp, func Less[$0 Ordered]($0, $0) bool #59488 pkg cmp, type Ordered interface {} #59488 pkg context, func AfterFunc(Context, func()) func() bool #57928 pkg context, func WithDeadlineCause(Context, time.Time, error) (Context, CancelFunc) #56661 pkg context, func WithoutCancel(Context) Context #40221 pkg context, func WithTimeoutCause(Context, time.Duration, error) (Context, CancelFunc) #56661 One of our standard tests checks that the actual package APIs match those files. If we add new API to a package, the test breaks unless we add it to the API files. And if we change or remove API, the test breaks too. This helps us avoid mistakes. However, a tool like this only finds a certain class of problems, namely API changes and removals. There are other ways to make incompatible changes to Go. That leads us to the second approach we use to keep Go boring: testing. Testing The most effective way to find unexpected incompatibilities is to run existing tests against the development version of the next Go release. We test the development version of Go against all of Google’s internal Go code on a rolling basis. When tests are passing, we install that commit as Google’s production Go toolchain. If a change breaks tests inside Google, we assume it will also break tests outside Google, and we look for ways to reduce the impact. Most of the time, we roll back the change entirely or find a way to rewrite it so that it doesn’t break any programs. Sometimes, however, we conclude that the change is important to make and “compatible” even though it does break some programs. In that case, we still work to reduce the impact as much as possible, and then we document the potential problem in the release notes. Here are two examples of that kind of subtle compatibility problems we found by testing Go inside Google but still included in Go 1.1. Struct Literals and New Fields Here is some code that runs fine in Go 1: package main import \"net\" var myAddr = &net.TCPAddr{ net.IPv4(18, 26, 4, 9), 80, } Package main declares a global variable myAddr, which is a composite literal of type net.TCPAddr. In Go 1, package net defines the type TCPAddr as a struct with two fields, IP and Port. Those match the fields in the composite literal, so the program compiles. In Go 1.1, the program stopped compiling, with a compiler error that said “too few initializers in struct literal.” The problem is that we added a third field, Zone, to net.TCPAddr, and this program is missing the value for that third field. The fix is to rewrite the program using tagged literals, so that it builds in both versions of Go: var myAddr = &net.TCPAddr{ IP: net.IPv4(18, 26, 4, 9), Port: 80, } Since this literal doesn’t specify a value for Zone, it will use the zero value (an empty string in this case). This requirement to use composite literals for standard library structs is explicitly called out in the compatibility document, and go vet reports literals that need tags to ensure compatibility with later versions of Go. This problem was new enough in Go 1.1 to merit a short comment in the release notes. Nowadays we just mention the new field. Time Precision The second problem we found while testing Go 1.1 had nothing to do with APIs at all. It had to do with time. Shortly after Go 1 was released, someone pointed out that time.Now returned times with microsecond precision, but with some extra code, it could return times with nanosecond precision instead. That sounds good, right? More precision is better. So we made that change. That broke a handful of tests inside Google that were schematically like this one: func TestSaveTime(t *testing.T) { t1 := time.Now() save(t1) if t2 := load(); t2 != t1 { t.Fatalf(\"load() = %v, want %v\", t1, t2) } } This code calls time.Now and then round-trips the result through save and load and expects to get the same time back. If save and load use a representation that only stores microsecond precision, that will work fine in Go 1 but fail in Go 1.1. To help fix tests like this, we added Round and Truncate methods to discard unwanted precision, and in the release notes, we documented the possible problem and the new methods to help fix it. These examples show how testing finds different kinds of incompatibility than the API checks do. Of course, testing is not a complete guarantee of compatibility either, but it’s more complete than just API checks. There are many examples of problems we’ve found while testing that we decided did break the compatibility rules and rolled back before the release. The time precision change is an interesting example of something that broke programs but that we released anyway. We made the change because the improved precision was better and was allowed within the documented behavior of the function. This example shows that sometimes, despite significant effort and attention, there are times when changing Go means breaking Go programs. The changes are, strictly speaking, “compatible” in the sense of the Go 1 document, but they still break programs. Most of these compatibility issues can be placed in one of three categories: output changes, input changes, and protocol changes. Output Changes An output change happens when a function gives a different output than it used to, but the new output is just as correct as, or even more correct than, the old output. If existing code is written to expect only the old output, it will break. We just saw an example of this, with time.Now adding nanosecond precision. Sort. Another example happened in Go 1.6, when we changed the implementation of sort to run about 10% faster. Here’s an example program that sorts a list of colors by length of name: colors := strings.Fields( `black white red orange yellow green blue indigo violet`) sort.Sort(ByLen(colors)) fmt.Println(colors) Go 1.5: [red blue green white black yellow orange indigo violet] Go 1.6: [red blue white green black orange yellow indigo violet] Changing sort algorithms often changes how equal elements are ordered, and that happened here. Go 1.5 returned green, white, black, in that order. Go 1.6 returned white, green, black. Sort is clearly allowed to return equal results in any order it likes, and this change made it 10% faster, which is great. But programs that expect a specific output will break. This is a good example of why compatibility is so hard. We don’t want to break programs, but we also don’t want to be locked in to undocumented implementation details. Compress/flate. As another example, in Go 1.8 we improved compress/flate to produce smaller outputs, with roughly the same CPU and memory overheads. That sounds like a win-win, but it broke a project inside Google that needed reproducible archive builds: now they couldn’t reproduce their old archives. They forked compress/flate and compress/gzip to keep a copy of the old algorithm. We do a similar thing with the Go compiler, using a fork of the sort package (and others) so that the compiler produces the same results even when it is built using earlier versions of Go. For output change incompatibilities like these, the best answer is to write programs and tests that accept any valid output, and to use these kinds of breakages as an opportunity to change your testing strategy, not just update the expected answers. If you need truly reproducible outputs, the next best answer is to fork the code to insulate yourself from changes, but remember that you’re also insulating yourself from bug fixes. Input Changes An input change happens when a function changes which inputs it accepts or how it processes them. ParseInt. For example, Go 1.13 added support for underscores in large numbers for readability. Along with the language change, we made strconv.ParseInt accept the new syntax. This change didn’t break anything inside Google, but much later we heard from an external user whose code did break. Their program used numbers separated by underscores as a data format. It tried ParseInt first and only fell back to checking for underscores if ParseInt failed. When ParseInt stopped failing, the underscore-handling code stopped running. ParseIP. As another example, Go’s net.ParseIP, followed the examples in early IP RFCs, which often showed decimal IP addresses with leading zeros. It read the IP address 18.032.4.011 address as 18.32.4.11, just with a few extra zeros. We found out much later that BSD-derived C libraries interpret leading zeros in IP addresses as starting an octal number: in those libraries, 18.032.4.011 means 18.26.4.9! This was a serious mismatch between Go and the rest of the world, but changing the meaning of leading zeros from one Go release to the next would be a serious mismatch too. It would be a huge incompatibility. In the end, we decided to change net.ParseIP in Go 1.17 to reject leading zeros entirely. This stricter parsing ensures that when Go and C both parse an IP address successfully, or when old and new Go versions do, they all agree about what it means. This change didn’t break anything inside Google, but the Kubernetes team was concerned about saved configurations that might have parsed before but would stop parsing with Go 1.17. Addresses with leading zeros probably should be removed from those configs, since Go interprets them differently from essentially every other language, but that should happen on Kubernetes’s timeline, not Go’s. To avoid the semantic change, Kubernetes started using its own forked copy of the original net.ParseIP. The best response to input changes is to process user input by first validating the syntax you want to accept before parsing the values, but sometimes you need to fork the code instead. Protocol Changes The final common kind of incompatibility is protocol changes. A protocol change is a change made to a package that ends up externally visible in the protocols a program uses to communicate with the external world. Almost any change can become externally visible in certain programs, as we saw with ParseInt and ParseIP, but protocol changes are externally visible in essentially all programs. HTTP/2. A clear example of a protocol change is when Go 1.6 added automatic support for HTTP/2. Suppose a Go 1.5 client is connecting to an HTTP/2-capable server over a network with middleboxes that happen to break HTTP/2. Since Go 1.5 only uses HTTP/1.1, the program works fine. But then updating to Go 1.6 breaks the program, because Go 1.6 starts using HTTP/2, and in this context, HTTP/2 doesn’t work. Go aims to support modern protocols by default, but this example shows that enabling HTTP/2 can break programs through no fault of their own (nor any fault of Go’s). Developers in this situation could go back to using Go 1.5, but that’s not very satisfying. Instead, Go 1.6 documented the change in the release notes and made it straightforward to disable HTTP/2. In fact, Go 1.6 documented two ways to disable HTTP/2: configure the TLSNextProto field explicitly using the package API, or set the GODEBUG environment variable: GODEBUG=http2client=0 ./myprog GODEBUG=http2server=0 ./myprog GODEBUG=http2client=0,http2server=0 ./myprog As we’ll see later, Go 1.21 generalizes this GODEBUG mechanism to make it a standard for all potentially breaking changes. SHA1. Here’s a subtler example of a protocol change. No one should be using SHA1-based certificates for HTTPS anymore. Certificate authorities stopped issuing them in 2015, and all the major browsers stopped accepting them in 2017. In early 2020, Go 1.18 disabled support for them by default, with a GODEBUG setting to override that change. We also announced our intent to remove the GODEBUG setting in Go 1.19. The Kubernetes team let us know that some installations still use private SHA1 certificates. Putting aside the security questions, it’s not Kubernetes’s place to force these enterprises to upgrade their certificate infrastructure, and it would be extremely painful to fork crypto/tls and net/http to keep SHA1 support. Instead, we agreed to keep the override in place longer than we had planned, to create more time for an orderly transition. After all, we want to break as few programs as possible. Expanded GODEBUG Support in Go 1.21 To improve backwards compatibility even in these subtle cases we’ve been examining, Go 1.21 expands and formalizes the use of GODEBUG. To begin with, for any change that is permitted by Go 1 compatibility but still might break existing programs, we do all the work we just saw to understand potential compatibility problems, and we engineer the change to keep as many existing programs working as possible. For the remaining programs, the new approach is: We will define a new GODEBUG setting that allows individual programs to opt out of the new behavior. A GODEBUG setting may not be added if doing so is infeasible, but that should be extremely rare. GODEBUG settings added for compatibility will be maintained for a minimum of two years (four Go releases). Some, such as http2client and http2server, will be maintained much longer, even indefinitely. When possible, each GODEBUG setting has an associated runtime/metrics counter named /godebug/non-default-behavior/:events that counts the number of times a particular program’s behavior has changed based on a non-default value for that setting. For example, when GODEBUG=http2client=0 is set, /godebug/non-default-behavior/http2client:events counts the number of HTTP transports that the program has configured without HTTP/2 support. A program’s GODEBUG settings are configured to match the Go version listed in the main package’s go.mod file. If your program’s go.mod file says go 1.20 and you update to a Go 1.21 toolchain, any GODEBUG-controlled behaviors changed in Go 1.21 will retain their old Go 1.20 behavior until you change the go.mod to say go 1.21. A program can change individual GODEBUG settings by using //go:debug lines in package main. All GODEBUG settings are documented in a single, central list for easy reference. This approach means that each new version of Go should be the best possible implementation of older versions of Go, even preserving behaviors that were changed in compatible-but-breaking ways in later releases when compiling old code. For example, in Go 1.21, panic(nil) now causes a (non-nil) runtime panic, so that the result of recover now reliably reports whether the current goroutine is panicking. This new behavior is controlled by a GODEBUG setting and therefore dependent on the main package’s go.mod’s go line: if it says go 1.20 or earlier, panic(nil) is still allowed. If it says go 1.21 or later, panic(nil) turns into a panic with a runtime.PanicNilError. And the version-based default can be overridden explicitly by adding a line like this to package main: //go:debug panicnil=1 This combination of features means that programs can update to newer toolchains while preserving the behaviors of the earlier toolchains they used, can apply finer-grained control over specific settings as needed, and can use production monitoring to understand which jobs make use of these non-default behaviors in practice. Combined, those should make rolling out new toolchains even smoother than in the past. See “Go, Backwards Compatibility, and GODEBUG” for more details. An Update on Go 2 In the quoted text from “Go 1 and the Future of Go Programs” at the top of this post, the ellipsis hid the following qualifier: At some indefinite point, a Go 2 specification may arise, but until that time, [… all the compatibility details …]. That raises an obvious question: when should we expect the Go 2 specification that breaks old Go 1 programs? The answer is never. Go 2, in the sense of breaking with the past and no longer compiling old programs, is never going to happen. Go 2 in the sense of being the major revision of Go 1 we started toward in 2017 has already happened. There will not be a Go 2 that breaks Go 1 programs. Instead, we are going to double down on compatibility, which is far more valuable than any possible break with the past. In fact, we believe that prioritizing compatibility was the most important design decision we made for Go 1. So what you will see over the next few years is plenty of new, exciting work, but done in a careful, compatible way, so that we can keep your upgrades from one toolchain to the next as boring as possible. Next article: Forward Compatibility and Toolchain Management in Go 1.21 Previous article: Go 1.21 is released! Blog Index Why Go Use Cases Case Studies Get Started Playground Tour Stack Overflow Help Packages Standard Library About Go Packages About Download Blog Issue Tracker Release Notes Brand Guidelines Code of Conduct Connect Twitter GitHub Slack r/golang Meetup Golang Weekly Copyright Terms of Service Privacy Policy Report an Issue go.dev uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. Learn more. Okay",
    "commentLink": "https://news.ycombinator.com/item?id=37122871",
    "commentBody": "Backward Compatibility, Go 1.21, and Go 2Hacker NewspastloginBackward Compatibility, Go 1.21, and Go 2 (go.dev) 368 points by philosopher1234 17 hours ago| hidepastfavorite272 comments w10-1 16 hours agoThe question for compatibility is not whether but how. And it&#x27;s not really backwards: you want your code to just work, from now on.Go 1.21 offers two essential features not matched by any other language ecosystem:1. A GODEBUG setting for each change, together with per-change opt-out and per-change metric for detecting use of the prior implementation.2. A per-module toolchain version, together with automatic fetching of both older and newer go toolchains (deployed safely as modules)As an amazing bonus, if you specify a given version of go (e.g., 1.21.2), then when running under a newer version of go, go will automatically apply the relevant opt-out configuration so you won&#x27;t get the new behavior until you ask for it.Finally, as ever you can declare things in code, in go.mod, and in environment.That basically covers all the use-cases for compatibility, from developers through deployers.Simple, and beautiful. reply ilyt 11 hours agoparentPerl does something similar; use v5.24at start of the file will make it work as if the version of Perl was 5.24, and it works on per-file basics, not only per module reply sigzero 10 hours agorootparentThat&#x27;s exactly what I thought of when reading the description. reply holiveros 6 hours agorootparentEven more fine-grained, https:&#x2F;&#x2F;perldoc.perl.org&#x2F;functions&#x2F;use#use-VERSION> ... Later use of use VERSION will override all behavior of a previous use VERSION,> possibly removing the strict, warnings, and feature added by it ... reply anacrolix 34 minutes agoparentprevThis is definitely present in other languages. Mainstream ones. Haskell takes it to the next level where individual files can turn on and off language features. reply mcbrit 15 hours agoparentprevApologies, but this actually sounds like a nightmare to me, if you have at least 1-10m+ loc over enough teams, enough teams being probably 5+ depending on org boundaries.Either you support the new version or you don&#x27;t is more than enough complexity to cause arbitrarily ridiculous problems, because there is a deep valley of you &#x2F;think&#x2F; you support the new version and the new version thinks that it supports you but you both miss.(who wants the t-shirt saying that they have been responsible for a 1m+ code base on top of 10m+ for at least 20 years?) reply jrockway 13 hours agorootparentIf Team A requires compatibility with go 1.21, their go.mod will start with \"go 1.21\". Even if the code is compiled with go 1.22, their code will run unchanged, as the toolchain now treats the go version line as the toolchain to be compatible with. Similarly, if Team B requires compatibility with go 1.22 but their code is being compiled with go 1.21, go will download the 1.22 toolchain and run with that instead. It&#x27;s sneaky and crazy, but so crazy it just might work.(As a user of CircleCI convenience images for a few tests suites, I appreciate this feature. When there is some security vulnerability that requires updating to go 1.21.1, I don&#x27;t have to wait for Circle to build a new convenience image. I can just change go.mod and start using 1.21.1 immediately. This saves a day of telling people to ignore govulncheck.)The TL;DR is that the compiler version is now something you can declare in your go.mod file like any other dependency.If you share one go.mod file across all teams or have a One Version Policy, then there will always be work to do. No doubt there are several dedicated (in practice) employees to manage \"there is a critical security release for github.com&#x2F;whatever&#x2F;frob@1.2.3 but the Team A&#x27;s tests fail when updating to github.com&#x2F;whatever&#x2F;frob@1.2.4\", which is inevitable at this scale. reply nextaccountic 4 hours agorootparentThat&#x27;s how Rust editions work too. You can have a Rust 2021 crate depend on a Rust 2015 crate which depends on a Rust 2018 crate, it will all be compiled by the latest compiler even though they are written in slightly different languages (different syntax and in some cases different desugaring)So that&#x27;s how Rust can make language changes without splitting the ecosystem and without requiring everyone to migrate all at onceTo think about it, Java is like this too reply Groxx 11 hours agorootparentprevIt&#x27;s not downgrading (unless that changed recently), it&#x27;s just new emulating old. And only partially at that.E.g. `go fmt` with a new Go will use new-Go&#x27;s formatting, not the module&#x27;s version&#x27;s formatting (comment format thrashing is fun!). And then they special-case backwards compatibility stuff like the `&#x2F;&#x2F;go:build` syntax change, and that behavior pays attention to module version. API accessibility and module file formatting follows module version, I don&#x27;t believe `go vet` does (in general, nor do I think it necessarily should), compiled implementation of stdlib absolutely does not, etc.Rust (cargo) by contrast actually does version the tools, and automatically pulls the stated rustc, stdlib, docs, everything (set in rust-toolchain.toml, among others: https:&#x2F;&#x2F;rust-lang.github.io&#x2F;rustup&#x2F;overrides.html). I&#x27;m not sure if cargo versions itself or not. reply jrockway 11 hours agorootparentI believe it&#x27;s emulated.There&#x27;s a tradeoff; the old toolchain may actually build code that is vulnerable to some security vulnerability, but the new toolchain will produce (in theory) code that produces the same output from the same input, but without the vulnerability. So it&#x27;s not clear that either direction is a clear win; old is \"known\", but old can be dangerous. But, you can only write so many tests to ensure that emulation is as good as the original. Which direction you are less paranoid about dictates the direction you&#x27;ll go.Having used Go since ~1.3 and having been responsible for the version in use for my project since about ~1.9, I&#x27;d say that on average I upgrade on release day and it has never caused a regression. But, the article mentions a handful of bugs that have occurred due to fixing library bugs, so they aren&#x27;t nonexistent. How much risk you want to take here is up to you. reply Groxx 10 hours agorootparentYeah, mostly I think emulating is the best approach, and Go seems to strike a pretty good maintenance-load &#x2F; compatibility tradeoff. Upgrading lints &#x2F; optimizations &#x2F; bugfixes is generally preferred. Rust&#x27;s \"true versioning\" approach makes more sense for a language without a stable ABI and more backwards-incompatible changes in recent times.Besides, if you want true versioning, there&#x27;s always gimme. Gimme&#x27;s easy, and easy to use with folder-env managers (like direnv). replyparhamn 15 hours agoprevLove this. Nothing better than coming to a go codebase and bumping the go version knowing everything will work fine.One thing I worry about is that the type system can’t get improved significantly without breaking changes in the “this was wrong and wont compile now\" sense. Although I&#x27;m not sure theres interest for this stuff in the golang team at all. But there are many low hanging type system improvements in go that are major compile time robustness wins for folks, with no language additions.1) reporting unchecked nils, might require formalizing [T, nil][nil, err] so err != nil guarantees T (obviously concurrent pointer access makes it tricky but thats special code with special considerations, not the 99% case)2) unchecked array access3) inferring types of nested struct literals. Writing nested GRPC calls is such a damn pain go, this is literally only one layer of type inference... its in the damn function signature I&#x27;m calling!4) Exhaustive enum matchesBut now I&#x27;m curious, is there any interest for these changes in the golang community? None are adding \"features\" (like say generics) but would be huge robustness wins and seem pretty easy. reply josephg 13 hours agoparentJust to beat this drum from outside the go community, rust &#x2F; swift style enums with parameters are mana from heaven. So many programs get easier to write using them. If there’s one way I’d love the go type system to be improved, it would be by adding these simple, lovely algebraic data types.Trust me, they would look great in Go. Treat yourself. reply valzam 11 hours agorootparentThe irony is that Go actually does have sum types, but only for generics!type A interface { FooBarBaz }Can&#x27;t use this anywhere but in generic type signatures though :( reply bheadmaster 1 hour agorootparentThere&#x27;s a proposal [0] by Ian Lance Taylor that proposes extending the type parameter constrains union of types to non-generic interfaces too. Indeed, there are some issues with the implementation details, but I&#x27;m hoping they get ironed out.[0] https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;issues&#x2F;57644 reply andyferris 12 hours agorootparentprevI agree. If go had sum types I’d use it in a heartbeat! reply nickpeterson 6 hours agorootparentprevGrumbles in F#… reply sudhirj 17 hours agoprevAmen to that. I get super excited about Go releases because they often add useful stuff with zero breakage of anything (just free wins all around). It&#x27;s not clear that any part of the language is so broken that backward compatible changes can&#x27;t fix it. Even the few foot guns like loop variable assignment have proposals that mostly preserve compatibility. reply TheDong 3 hours agoparentJust to throw in my 2c, I&#x27;ve had significant breakages with most Go upgrades. I&#x27;ve had far fewer issues with rust upgrades, and gcc upgrades. C and Rust compiler updates feel actually backwards compatible to me.I posted a list of a few breakages I&#x27;ve run into before, though of course I&#x27;ve run into more since, and far more I didn&#x27;t mention there: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29763324I think the main reason I&#x27;ve had more issues with Go upgrades than with Rust upgrades or C upgrades is because for rust&#x2F;gcc, I&#x27;m upgrading the compiler and getting language features, but most of the complex libraries don&#x27;t change, and I can upgrade them separately from the compiler (i.e. hyper for http in rust, or libcurl in C).For go, whenever I upgrade the compiler, I get a mix of language features (generics, embed, other toolchain features), but also a set of library updates (tls and security libraries yet again dropping support for something I use, http client or server changes, etc).I think go would have been much better served by making &#x27;http&#x27;, &#x27;tls&#x27;, &#x27;crypto&#x27;, and other large chunks of the standard library their own separate libraries. Even if you kept the exact same go1 promise for those (which is to say \"we sometimes break http and tls, but we tell you it&#x27;s backwards compatible\"), it would be far better because I could then actually fearlessly upgrade the go compiler version, and then later upgrade those libraries at my own pace. Or, when the tls upgrade breaks my code for the nth time, I could roll it back without also having to roll back the entire compiler version and revert any code changes which used new compiler features.It also really makes no sense for libraries like &#x27;http&#x27; and &#x27;archive&#x2F;*&#x27; to be part of the standard library. Presumably they&#x27;re just there because the Go team wanted to release 1.0 before figuring out a good dependency system (though golang.org&#x2F;x&#x2F; was a really quick follow-on, and that would have been enough for these), but that has led to the \"go 1 compatibility promise\" really meaning \"enough go upgrades break my code that I&#x27;m scared to update, but not because the compiler has a breaking change, but because some part of the stdlib that doesn&#x27;t even need to be bundled with the compiler breaks me\". reply sedatk 15 hours agoparentprevInteresting because I observe the opposite sentiment among .NET developers for features added in C# despite that its backwards compatibility is also fully preserved. They say “the language is getting bloated”, “it becomes harder to learn”. I totally have your perspective on this, but the difference in attitudes is noteworthy. reply jerf 15 hours agorootparentIn the past ten years, here&#x27;s a list of significant feature additions to the Go language itself: * GenericsAnd even that has not been the shocking revolution some people expected; it turns out to overall be a nice little addition rather than something that rewrote what good Go was. Nothing like the Python transition to \"new style\" classes, or the Python 2 -> 3 transition, or the Python async ecosystem transition, and that&#x27;s just one language. For the most part a Go 1.4 programmer suddenly transported to today would not find it a terribly difficult task to read code using the generics.And broadly speaking, the language didn&#x27;t start with a lot of features either.Go has had a lot of library improvements, it&#x27;s had a lot of tooling improvements, but the language itself is extremely stable. I&#x27;ve seen a few people actually complain about Go moving too fast, to which I wonder what exactly would make them happy if even Go is zooming along too quickly for them, because I honestly don&#x27;t know a language moving more slowly than Go, for all the advantages and all the disadvantages that incurs. I&#x27;ve honestly sort of wished I could sit down with them for 15 minutes and see if I could figure out what their real problem is, or if they really are upset that there was ever a major change. reply arp242 13 hours agorootparentThe biggest problem has been the GOPATH → modules conversion, which broke lots of (or all?) tooling. For example, I had written a fairly nice program to analyse Go code and generate an OpenAPI document, but when modules came around quite a bit of that broke, and it&#x27;s non-trivial to fix. It still works in \"GOPATH mode\", but few people use that these days. reply xmprt 11 hours agorootparentI&#x27;m curious to learn what sort of issues you&#x27;ve seen when trying to use modules instead of GOPATH? Most of the migrations I&#x27;ve done have been pretty seamless and the few that had issues where all easy to resolve with a few replace directives or similar. reply arp242 11 hours agorootparentAnyone who has written any tooling that works with Go code saw issues because almost everything changed in this regard. I was maintaining vim-go at the time, and quite a few changes were needed there too. I don&#x27;t have a list of issues at hand because it&#x27;s been a while, but generally speaking the only reason things went \"pretty seamless\" is because people spent time updating the tooling. reply neonsunset 15 hours agorootparentprevC# mostly suffers from having way too many options to do something. The quality of the average codebase written in 10 layer-abstraction-heavy OOP style that does not leverage the language features for writing concise and understandable code does not help either.This is one of the reasons people rave about F# - it&#x27;s less about the language and more about not suffering from really bad tradition that has settled over the years.Don&#x27;t get me wrong, the situation improves significantly each year, but the developers who require extensive explanatory work to get any semblance of buy-in to stop doing things the painful and cargo-cult-y way are still in the majority.Otherwise, I think C# is very approachable thanks to it being extremely forgiving language* in general and standard library offering easy-with-pretty-good-defaults shortcut options to do the basics like networking, file io, hashing, creating simple web servers and UI applications, etc. Its both CLI and IDE tooling is also top notch today.* Forgiving as in, mistakes usually tend to decrease otherwise excellent (better than Go) performance rather than cause critical failures. reply tester756 13 hours agorootparent>The quality of the average codebase written in 10 layer-abstraction-heavyThis meme needs to die. I&#x27;ve seen \"10 layer abstraction heavy\" code base only onceThe code was simulating hardware&#x2F;firmware behaviour when the real impl. was not available, and when the real impl. was delivered, then it was called instead.So that was quite reasonable why they went with this like that.Normal apps are mostly MVC-like where controller receives HTTP request (like 5 LoC?),moves it to some handler which performs business logic &#x2F; calls db and the returned stuff is either HTML or JSON.That&#x27;s your average web app. reply IceSentry 7 hours agorootparentWell I guess you&#x27;ve just been very lucky.I&#x27;ve seen a codebase where half the features were implemented by inheriting the controller class and adding some behaviour and then that wqs wrapped in another layer adding more behavior. It had about 5-6 layers of that. I guess it&#x27;s not 10 layers, but it was still extremely shitty code that was very not fun to deal with. reply philosopher1234 12 hours agorootparentprevThe ten layer abstraction continues to exist in Java land. I see it every day at work. reply trallnag 12 hours agorootparentYou get a few layers for free by using Spring alone reply 38 11 hours agorootparentprev> This meme needs to die. I&#x27;ve seen \"10 layer abstraction heavy\" code base only onceI dont think so. I like Go code because its usually pretty \"flat\" unless you find someone from a Java or C# background. C# code is similar to Java in that nearly everyone writes it with an IDE, so you end up with nested folders like 8 levels deep. it makes reading the code stupidly hard, unless you download and load into an IDE or something like GitHub with essentially a web IDE. so anyone used to just a normal editor like Vim or similar is basically out of luck. reply tester756 10 hours agorootparentWhile I agree that almost everyone uses IDEs when doing C#then I&#x27;m not sure about this folder thing.I&#x27;ve been shocked many times when seeing Java repos that they have like 5 empty folders nested just to have 3 java files. I don&#x27;t see that in C# world.>it makes reading the code stupidly hard, unless you download and load into an IDE or something like GitHub with essentially a web IDE. so anyone used to just a normal editor like Vim or similar is basically out of luck.What does \"normal editor\" even mean?Shouldn&#x27;t \"normal\" be dictated by market share? so VS Code, Notepad++ according to SO Survey 22 reply jen20 8 hours agorootparent> that they have like 5 empty folders nested just to have 3 java files. I don&#x27;t see that in C# world.This is because Java ties the package path to the filesystem, and C# does not tie namespaces to file paths. Typically in C# codebases you&#x27;ll see the layers implemented as separate DLL projects. reply JenrHywy 10 hours agorootparentprevThat&#x27;s not my experience, and I&#x27;ve been writing C# since .NET 1.1. Obviously though it depends on the scale of the app. If you have 1m+ LoC, you really need to have some sort of structure, regardless of the language. reply zimpenfish 14 hours agorootparentprev> The quality of the average codebase written in 10 layer-abstraction-heavy OOP styleThey did not learn from Perl, it seems. reply kaba0 15 hours agorootparentprevWhich are valid fears -- C# has become a language with an insanely big surface area, almost comparable to C++&#x27;s. This surface area will get rough, unforeseen edges when multiple different features are used together (no matter how generally good C#&#x27;s design is), so on the end-user dev it is not even a linear-only weight to learn.Java is a common butt of jokes among C# devs, but in my opinion its addition of features to the language while committing to backwards compatibility is simply the best in the industry and should be copied by every language pertaining to a similar status (not for research languages obviously, they should be the ones experimenting) -- they seldom add new features, only those that have been proven by others and trying to kill multiple birds with a single stone in each case.Also, .NET does have a dubious past regarding backwards comp. from what I gathered, \"its\" frontend churn alone is remarkable, the only thing more spectacular is their renamings. reply pjmlp 14 hours agorootparent> Java is a common butt of jokes among C# devs....And those of us Polyglot devs, have positive and negative arguments that go both ways. reply kaba0 14 hours agorootparentIndeed, both languages have plenty positives and quite a few warts as well. While I do prefer Java personally, I consider C# an absolutely fine choice for almost every usecase.Go on the other hand, I&#x27;m much less forgiving about. reply ilyt 11 hours agorootparentI don&#x27;t see any language advantages of Go if you know C# or Java already.On the other side we use it for ops because new hire, regardless of what language they know, can learn it in a week or two and produce not-shit code and don&#x27;t suffer any of the Python or JS problems. reply pjmlp 14 hours agorootparentprevC# is getting some strange design decisions of lately, see inline arrays, and interceptors.Yeah, they had plenty of hindsight, and still.... reply zigzag312 13 hours agorootparentWhy are they strange? Interceptors seem to enable migration away from reflection, for better support of AOT compilation.For example: https:&#x2F;&#x2F;github.com&#x2F;DapperLib&#x2F;Dapper&#x2F;issues&#x2F;1909 reply pjmlp 3 hours agorootparentInterceptors are a hack, instead of a properly designed AOP framework, which Microsoft already has, although comes with Visual Studio Enterprise price tag, Microsoft Fakes.Inline arrays are another hack, instead of properly designed language grammar, like in languages like D or Swift. reply zigzag312 2 hours agorootparentC# interceptors are a metaprogramming feature. AOP is a higher-level concept. An implementation of AOP can use these metaprogramming features to achieve aspect weaving. reply pjmlp 1 hour agorootparentAre a badly implemented, and clunky, metaprogramming feature.Where a sound AOP framework, or macro system are much more sane.Belongs to the same trash bucket as the C# 11 bang-bang operator, and I will vote for the same outcome, in all places asking for community feedback. reply zigzag312 1 hour agorootparentI lack experience to assess quality of C# interceptors, so that might be true. I&#x27;m just happy that C# ecosystem is slowly becoming less dependent on runtime reflection. replymetaltyphoon 12 hours agorootparentprevWhich are both fine? reply pjmlp 3 hours agorootparentWhich suck both. replycoldtea 10 hours agorootparentprev>Java is a common butt of jokes among C# devsRarely are \"jokes among X devs\" for another language not a sign of ignorance and fanboyism. reply zigzag312 14 hours agorootparentprevI&#x27;ve seen this repeated a few times in online forums, but that&#x27;s not my experience. Language itself has gotten bigger, but code has become much less bloated and elegant. To me, it&#x27;s easier to read new C# code than the old one.I&#x27;m probably biased as I use C# a lot. But I think that with advent of GPT tools, larger languages have become much less of an issue that they were in the past. They make it really easy to get explanation of code or feature you don&#x27;t understand right there on the spot. reply sudhirj 15 hours agorootparentprevI haven&#x27;t used C# in over a decade, but I was already feeling that way - there&#x27;s just a lot in there. Go seems to start with a default no to things, so that might be why it has a relatively small surface area. reply 0xDEF 10 hours agorootparentprev>I observe the opposite sentiment among .NET developers for features added in C# despite that its backwards compatibility is also fully preserved. They say “the language is getting bloated”,I don&#x27;t recognize this sentiment at all and I think it&#x27;s almost non-existent among developers who use ReSharper or Rider that will both introduce useful new language features as a refactoring suggestion that is one shortcut away..Net developers can easily get away with not keeping up with new C# language features. A .Net developer who went into coma in 2012 after having learned async&#x2F;await and ASP.NET MVC can return to a hypermodern ASP.NET Core 7 codebase and be almost instantly productive. reply afavour 11 hours agoparentprev> It&#x27;s not clear that any part of the language is so broken that backward compatible changes can&#x27;t fix itBroadly I agree but the future is kind of unknowable. For example Rust’s 2018 edition introduced the async keyword, a breaking change because you could have made a variable or function named “async” in the 2015 edition.Async functions weren’t something the first version of Rust and they were introduced with a breaking chance. I like backwards compatibility but am unsure about a future where Go can’t do innovation X because it would break compatibility. reply monocasa 10 hours agorootparentFWIW async was only sort of a breaking change. The edition system meant that no crates would stop compiling, even with newer compilers, and you can mix crates of different editions in the same build product. reply ilyt 11 hours agoparentprevI&#x27;d like to see sum types and some better way to deal with error verbosity. reply Waterluvian 17 hours agoprevI&#x27;m a big fan of the assertion that a future Go 2 will never break Go 1 compatibility. I think if you need to make changes so significant to a language, you may as well just fork and rename the language (an opinion I can see many holes in).I wonder: why not go further and say \"there will never be a Go 2\" in order to eliminate ambiguity about this? If a theoretical Go 2 will run all Go 1 programs, what would make it different from some Go 1.xx release? Some might interpret this post as saying that, but I don&#x27;t think it quite does. It says \"There will not be a Go 2 that breaks Go 1 programs.\" reply ainar-g 17 hours agoparent> I wonder: why not go further and say \"there will never be a Go 2\" in order to eliminate ambiguity about this?They did, five years ago. Albeit with an “if”.https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;proposal&#x2F;blob&#x2F;d661ed19a203000b7c54...> If the above process works as planned, then in an important sense there never will be a Go 2. Or, to put it a different way, we will slowly transition to new language and library features. We could at any point during the transition decide that now we are Go 2, which might be good marketing. Or we could just skip it (there has never been a C 2.0, why have a Go 2.0?).> Popular languages like C, C++, and Java never have a version 2. In effect, they are always at version 1.N, although they use different names for that state. I believe that we should emulate them. In truth, a Go 2 in the full sense of the word, in the sense of an incompatible new version of the language or core libraries, would not be a good option for our users. A real Go 2 would, perhaps unsurprisingly, be harmful. reply pjmlp 2 hours agorootparent> Popular languages like C, C++, and Java never have a version 2.Only someone that never used those languages would state that, all of them have had breaking changes. reply tmpz22 16 hours agorootparentprev> We could at any point during the transition decide that now we are Go 2, which might be good marketing.Among the (entirely?) dev-oriented consumers of Golang would the shininess of \"2.0\" really outweigh the \"ugh documentation is going to get harder to find\" and \"ugh I now need to increase my auditing of dependencies\" and other similar fatigue?Is Google universally good at marketing? reply ilyt 11 hours agorootparentprevBut Java absolutely had versions that broke old code reply cogman10 17 hours agoparentprevJava went through this. There was a Java 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, and 1.7. Then, Java decided \"You know what, we aren&#x27;t breaking backwards compatibility so instead of naming things 1.x, let&#x27;s just say Java 8, 9, 10...21\"I think that ultimately makes sense. reply adrianmsmith 16 hours agorootparentIronically they then went ahead and made a massive change in Java 9 that, for the first time in Java&#x27;s history, broke pretty much everything. Still angry about that... reply valenterry 15 hours agorootparentWell, they removed code that was always discouraged from using and it was always and explicitly stated, that there are no guarantees of any kind when using this code. The code was not living in a package called \"unsafe\" and being undocumented (to my knowledge) by coincidence.So while Java broke some big libraries&#x2F;frameworks (not \"pretty much everything though\"), it can&#x27;t really be blamed on them.In fact, look what Go has: https:&#x2F;&#x2F;pkg.go.dev&#x2F;unsafe> Package unsafe contains operations that step around the type safety of Go programs. > Packages that import unsafe may be non-portable and are not protected by the Go 1 compatibility guidelines.Let&#x27;s wait until Go has reached Java&#x27;s maturity and see what happens when they change this package ;) reply adrianmsmith 15 hours agorootparent> So while Java broke some big libraries&#x2F;frameworks (not \"pretty much everything though\"), it can&#x27;t really be blamed on them.I think one of the reasons people use Java is to get access to those big libraries&#x2F;frameworks.I&#x27;ve worked at a few companies that used Java during the transition, so maybe I had access to about 10 Git repos that underwent this transition.I think pretty much all of them required some tweaking e.g. adding extra dependencies in Maven when moving from Java 8 to Java 11. I actually became the \"go to\" person to do these transitions, having worked out what incantations were needed.All of those repos, to this day, despite the effort that was put into them during the transition, now print out warnings about things being unsafe. The companies just ignore those warnings. I have 15 years of Java experience and I don&#x27;t know what to do about them. My understanding is this is normal in the Java world now.They are just normal web applications or REST services using databases like PostgreSQL, using e.g. Spring Boot, Tomcat, etc. Maybe those libraries do things they&#x27;re not supposed to, I don&#x27;t know. I have never used sun.misc.Unsafe in my code or anything like that.Perhaps if I spent days studying the problem I could understand what was going on and what to do about it (although probably not, as the problems might have been in third-party dependencies.) But this wasn&#x27;t money the companies I worked for wanted to spend. But anyway, my point is that spending days fixing stuff after an upgrade != backwards compatible. reply kaba0 14 hours agorootparentYou likely has a dependency of dependency of a dependency that uses it, and thus get the warning. reply jerf 15 hours agorootparentprev\"Let&#x27;s wait until Go has reached Java&#x27;s maturity and see what happens when they change this package ;)\"They did a while back, actually. Compare https:&#x2F;&#x2F;pkg.go.dev&#x2F;unsafe@go1.0.1#Pointer with https:&#x2F;&#x2F;pkg.go.dev&#x2F;unsafe#Pointer , in particular the modern very precise description of exactly what you can do with an *unsafe.Pointer. I&#x27;m not sure what the cutoff for that was but it was a while ago, yes. Still, it didn&#x27;t do much. reply valenterry 14 hours agorootparentInteresting!Personally I&#x27;m not a big fan of either Java nor excessive backwards compatibility. But I can&#x27;t avoid noticing that a lot of people praise Go for things like the backwards compatible while despising Java at the same time, even though both languages are extremely similar in lots of regards. reply MichaelNolan 16 hours agorootparentprevHopefully there should never be a repeat of that now that they have strongly encapsulated jdk internals. My understanding is that (nearly) all of the migration headaches from 8 to 9 were caused by libraries that were using improperly using jdk internals. reply saghm 16 hours agorootparentDevil&#x27;s advocate: anything that&#x27;s possible for a downstream user to access is fair game for them to use. You can certainly mark it as internal and be explicit that you reserve the right to break it later, but if it&#x27;s actually possible for users to do, it&#x27;s not \"improper\", even if it gets broken later. reply kaba0 14 hours agorootparentThat&#x27;s why they sealed those holes shut, and only allow some of them with deliberate end-user command-line flags, so that anyone wanting to go that way only has themselves to blame. reply morepork 6 hours agorootparentprevI was pleasantly surprised about 6 months ago when I went to run a game I wrote in Java when I was at university. Nothing huge, but still about 10k lines of code. I originally wrote it in Java 6, and it compiled and ran with no issues on Java 20.I only used one 3p lib, otherwise just the standard library, which helped, but I was expecting something to be broken given it was over 10 years later. reply szundi 16 hours agorootparentprevWas it more than internal lib references that one was not supposed to do anyway? reply cogman10 16 hours agorootparentPretty much. Most of the breaks came from touching the likes of \"sun.misc.Unsafe\". Java versions 9->~17 added new jdk features (such as VarHandles) to allow for the safe interactions that sun.misc.Unsafe exposed. Libs had to update to use these new patterns with 9 being the worst hurdle.There was also a change to how packages could be named that messed with stuff. 2 jars putting stuff into stuff like `javax.annotations` was a big no-no that broke with 9. reply kaba0 14 hours agorootparentprevIf that&#x27;s pretty much everything, then nothing is backwards compatible unless they have the same hash.. reply pjmlp 14 hours agorootparentprevOne cannot make omelette without breaking a couple of eggs. reply cpeterso 16 hours agorootparentprevSun did the same for Solaris, jumping from version 2.6 to 7:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Oracle_Solaris#Version_history reply mrweasel 17 hours agorootparentprevI did not know that was the reasoning or logic behind the Java 8, 9, 10 ... numbering, that clears up so many thing. reply twic 16 hours agorootparentAlso relevant is that Sun had pulled the same trick with Solaris a few years earlier - Solaris 2.6 was followed by Solaris 7. Bigger version numbers make for better marketing. I am skeptical that backwards compatibility was strongly involved. reply hbn 16 hours agorootparentApple also did a similar thing with OSX&#x2F;macOS a few years ago - instead of making everything 10.XX they bump the major version (first number) every year now, continuing on from the 10 that the X represented, as if each version is the same increment as the jump from Mac OS 9 to Mac OS X (which was a jump to an entirely new codebase)Android did that too, much earlier starting with 5.0. Previously the major version was something of an indicator of a major visual&#x2F;conceptual redesign. 3.0 was the tablet version, 4.0 was the move to the holo design language, 5.0 was material. Then they just kept bumping the major version every year since.I also assume it&#x27;s just for marketing reasons. reply chipotle_coyote 16 hours agorootparentI’d argue that the “everything is 10.x” for Mac OS was also basically marketing. :) reply blackoil 16 hours agorootparentprevThis happened at Java SE 5(1.5) after 1.4. This was at much a marketing decision. reply minutillo 16 hours agorootparentIt goes back ever further, Java 1.2 was marketed by Sun as \"Java 2\".https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19991010063140&#x2F;http:&#x2F;&#x2F;java.sun.c... reply cogman10 16 hours agorootparentprevThat was somewhat different from the way the internal stuff was numbered. You&#x27;d still see \"1.5\" and \"1.6\" everywhere when you asked the JVM for it&#x27;s version. 8 was when the JVM started matching the marketing (IIRC, might have been 9). reply afavour 16 hours agoparentprevI’d argue Rust’s editions are a good counter argument to that. The differences between editions really aren’t huge despite being breaking changes.In theory I like the idea of backwards compatibility never changing but in reality some breaking changes really do make sense and being permanently on the hook for a language feature that didn’t take X or Y into account when it was created doesn’t feel like a win. reply dcow 17 hours agoparentprevYou might be overestimating the type of change required to break source compatibility. A benign example is adding a keyword. Let&#x27;s say you want to add a new language feature and the community unarguably wants the feature and the right or only way to add it is with a new keyword. If you&#x27;re not allowed to break source, then you can never add the feature.I understand your argument for big things like changing the semantics of the language. But a backwards-incompatible change can also be rather benign. reply rsc 16 hours agorootparentIt&#x27;s not true that Go can&#x27;t add new keywords. Now that we have Go modules, all Go code is now explicitly annotated with the version of Go it was written against. We can add a new keyword in a later version of Go as long as the compiler can still also compile code written for the older versions of Go. (The go command tells the compiler which version of Go to use for each package it compiles.)What we&#x27;re not going to do is abandon all the code written for older versions of Go, like Python 3 or Perl 6 did. Python is recovering now but it easily lost a decade to the Python 2 -> Python 3 transition, almost certainly unnecessarily. And Perl lost even more. reply jen20 8 hours agorootparentThis is a the TL;DR I wish was the first paragraph of the article!Could this mechanism be used to patch up unfortunate evolutions in the standard library also? For example, all of the `WithContext` functions that could be folded into the (more common?) non-contextful versions? reply kodra 16 hours agorootparentprevWhy can&#x27;t it add keywords? Adding a new keyword doesn&#x27;t break backward compatibility. It breaks \"forward compatibility.\" reply tptacek 16 hours agorootparentNew keywords are like the textbook example of a backwards compatibility problem. It&#x27;s probably why C overloads \"static\" so many different ways. reply pcwalton 13 hours agorootparentYou can sort of add new keywords backwards-compatibly using a trick called \"contextual keywords\": you require that they be placed in a syntactic position in which no identifier could legally go, and you maintain them as legal identifiers for compatibility. C++ used this trick to introduce \"final\" and \"override\" by moving them before the opening \"{\". reply kodra 16 hours agorootparentprevYou mean new reserved words? For example, I&#x27;m quite sure when C# added \"record\" it didn&#x27;t break backward compatibility, as old code that uses \"record\" as a variable name still compiles. reply tptacek 16 hours agorootparentGo has made changes like that by adding new predeclared identifiers (\"any\" is an example, I think?) but there&#x27;s a distinction between predeclared identifiers and keywords. reply Dylan16807 16 hours agorootparentprevOld code becoming a compiler error sound like a backwards compatibility issue to me. reply kodra 16 hours agorootparentI guess it&#x27;s a terminology thing. As someone from a C# background, not all keywords are reserved words. Only new reserved words break backward compatibility.C# has added some keywords (record, and, or) without breaking backwards compatibility. reply crickey 16 hours agorootparentprevI dont undestand your example, plenty of languages add new keywords without breaking backwards compatibility, its removing a keyword that would cause such and issue. reply meepmorp 16 hours agorootparentI have named a function &#x27;foo&#x27;, in current version of language. A future change makes &#x27;foo&#x27; a keyword. My code was broken by adding a keyword. reply earthboundkid 16 hours agorootparentThis is not theoretical: Python broke a lot of async packages when they made “async” a keyword! reply crickey 11 hours agorootparentprevI guess, some languages get around this by having a destinction between functions and keyword functions not having the () braces in the syntax. But really if ur defning functions as keywords u should just put it in the standard library reply flakes 17 hours agoparentprevThe article does state that at the end:> The answer is never. Go 2, in the sense of breaking with the past and no longer compiling old programs, is never going to happen. Go 2 in the sense of being the major revision of Go 1 we started toward in 2017 has already happened. reply sudhirj 17 hours agoparentprevIt becomes a semantic difference at that point. If Go is doing semver, and there are going to be no backward-incompatible changes, there&#x27;s no reason to ever increment the major version. Everything is a minor version (compatible additions) and patch version (bug fixes). reply 015a 16 hours agoparentprevI&#x27;m not sure that&#x27;s a relevant distinction. If you take the stance that a major version has to mean breaking API compatibility with the previous major version, semver style, then their statement is equivalent to saying \"there will never be a go2\". If you don&#x27;t take that stance, then their statement leaves open the possibility that, fifty years from now, we&#x27;ll be at go1.102 and someone will say \"hey, these numbers are getting pretty big, maybe we should just call this next release go2\"; and that&#x27;s fine. That&#x27;s literally and exactly what Linux does; when the number gets big, it becomes easier to type smaller first number, so rename version to smaller first number. Its not semver, but semver doesn&#x27;t have a monopoly on how software must be versioned, and leaving room in the language today to do that is totally cool. reply jdc0589 17 hours agoparentprev> I wonder: why not go further and say \"there will never be a Go 2\"Pretty sure they&#x27;ve said this in the past. reply chrisdinn 17 hours agoprevI write a lot of Go and I can’t tell you how much this warms my heart.Compatibility probably isn’t much fun for the language team, always having to keep one foot firmly in the “distant” past. But for those of us that have to maintain large Go systems it’s such a gift. reply nappy-doo 13 hours agoparentI worked on the Go compiler for a couple of years, and it wasn&#x27;t a big deal. We just thought carefully about things, and dealt with a lot of rejection of ideas. If we couldn&#x27;t make it fit, it wasn&#x27;t right, and we&#x27;d try again. If we still couldn&#x27;t make it fit, we probably didn&#x27;t have a good handle on the problem, and it was right to stew on it longer.Frankly, I truly appreciated working with people who thought carefully and tried to make sure the right ideas were in. I appreciated Russ being a BDFL, Ian, Rob, and Rob. I&#x27;m glad I did it, and it made me a much better engineer. reply dang 17 hours agoprevRelated:Forward Compatibility and Toolchain Management in Go 1.21 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37122932 (no comments yet, but some will probably show up) reply brunojppb 16 hours agoprev> Boring is good. Boring is stable. Boring means being able to focus on your work, not on what’s different about Go.This really resonates with me. I work with NodeJS and the JS ecosystem in general on my day job and I have to tell you, the struggle is real. The ecosystem is fragmented, everyone is doing their own thing, which is hard to make things stable. Don’t get me wrong, I still enjoy this work, but I really wish the JS ecosystem could have a stable modern foundation we could rely on. reply hermanradtke 16 hours agoparentThe JS eco-system (npm, React, etc)? Sure. Let us also acknowledge that JavaScript, the language, has been prioritizing backwards compatibility before golang even existed. reply ilyt 11 hours agorootparentWell, it is a bit easier if you have no stdlib to speak of reply trhhowaway232 7 hours agorootparentJS has a stdlib, there&#x27;s just nothing in it. reply KronisLV 15 hours agoparentprevI wonder why Go isn&#x27;t the new Java&#x2F;.NET (yet?).Clearly a lot of tools and APIs have been written in it, many would describe not needing a separate runtime on the target system as a big plus and the language seems simple enough to learn and utilize (with VSC support and GoLand both being good), even the typical complaints like the error handling don&#x27;t seem like dealbreakers.I wonder what&#x27;s missing for Go to become a mainstay of development for the decades to come, or at least take up a huge chunk of the job market instead of being considered a niche language in some places. reply kaba0 14 hours agorootparentWhy would it be the new Java&#x2F;.NET? You vastly overestimate that separate runtime as being a huge positive, it is almost indifferent to most niches where these two are most common: servers, especially on the bigger side of things. For a devops team with a proper CICD pipeline, monitoring, whatnot, installing a runtime is beyond trivial, especially that many of it is container-based.So even if all else were equal, Go would need much much more positives to even start turning the wheel towards itself, momentum is huge in the industry (old Cobol systems are still clocking at places, even if they do so in a VM, as the hardware they are hardcoded against are too old now). Especially that it is not at all a net positive in many people&#x27;s eyes:- it is very verbose (yes, it is in fact more verbose than Java, that had been bullied by everyone forever for being verbose..) - has terrible expressivity (java streams&#x2F;.net linq) - smaller ecosystem (java is much larger than even .net, let alone go) - slow reflection (on the more enterprise-y end of the industry you sometimes need more dynamic workloads)Also add that both Java and .NET has native AOT compilation, so even that small benefit you mention may not be a dealbreaker, even if those are not as smooth a rides as go&#x27;s. reply KronisLV 2 hours agorootparent> Why would it be the new Java&#x2F;.NET?Because it&#x27;s a seemingly \"boring\" technology that&#x27;s not too hard to learn, seems to have a decent community&#x2F;ecosystem in the works (let&#x27;s see where it is in 5-10 years) and overall could hit the sweet spot of just being able to get things done with it in a 9-5 by a bunch of regular developers.> You vastly overestimate that separate runtime as being a huge positive, it is almost indifferent to most niches where these two are most common: servers, especially on the bigger side of things. For a devops team with a proper CICD pipeline, monitoring, whatnot, installing a runtime is beyond trivial, especially that many of it is container-based.I use containers and that won&#x27;t change anytime soon, they&#x27;re great! That said, CLR and JDK have some space overhead, even if a counterpoint could be made that storage is on the cheap side nowadays. However, there are also those who don&#x27;t use containers and don&#x27;t always have 1:1 reproducible environments (even though they should).I&#x27;ve personally seen a difference in the MINOR version for JDK bring down production by having some sort of an issue that caused the performance under load to decrease 10x in an enterprise project. It would be nice to get rid of that risk and just ship the whole thing, much like how a fat .jar instead of configuring an application server like Tomcat separately makes things easier, just a step further.Now, Java has some solutions for that, but I think that Go is in an even better position in that regard! reply doctor_eval 12 hours agorootparentprevWhenever someone mentions Java AOT, I look it up, and it’s a nightmare. Has it changed recently?I developed server software in Java for two decades, and I can tell you that the huge JVM was always a PITA for us, even after Docker became a thing. All those frameworks? We ended up throwing them out. And the slow startup speed of Java apps made our tooling sluggish. It was also a pain to ship tooling to non developers, for all the same reasons.Using Go after all this time was like a breath of fresh air.It’s fine for you to assert your own preferences and biases but you don’t represent all enterprise server developers. reply pjmlp 2 hours agorootparentThe only change is that now there are free beer AOT compilers, commercial AOT compilers have always been an option since around 2000. reply za3faran 13 hours agorootparentprevWell said. In addition, golang seems to shun everything under the guise of \"keeping things simple\", so you don&#x27;t see frameworks like Spring or ASP.NET.Of course pretending the issue doesn&#x27;t exist doesn&#x27;t make it so. At an employer, the reinvented a dependency injection + application framework, but poorly of course compared to the extremely mature offerings on the JVM and .NET, not to mention millions of dollars sank into maintaining it. reply trhhowaway232 6 hours agorootparentJava DI isn&#x27;t good either. It runs a full DAG on boot. reply kaba0 2 hours agorootparentThere are entire second generation of “cloud-ready” frameworks for Java that does it at compile time instead. reply gen220 15 hours agorootparentprevI think Go is on that Java&#x2F;.NET adoption curve, but it&#x27;s climbing it slowly because backend programming, as a whole, is a lot bigger, mature and diverse today, than it was when Java&#x2F;.NET emerged.I think there&#x27;s a decent chance that, `[java.age - go.age = 15 years]` from today, Go is high up on the totem pole. From my perspective, its ecosystem is vibrant but still young – we still need to decide on the Go equivalent of Flask, Django, Spring, etc. reply guggle 13 hours agorootparentThere are plenty of Flask equivalent in Go IMO. Django... not so much. reply gen220 12 hours agorootparentYep! I think, at this stage, `plenty` is the point of my comment. While there are many competing and quality options (vibrant), none of them are the de facto leader (young).I think, given where we are in 2023, it&#x27;d be difficult for a Django (i.e. ORM + templates + web framework all-in-one) to emerge in Go – it&#x27;s possible we never end up with one, and that&#x27;s OK. [I don&#x27;t think there&#x27;s much stomach for good people to work on sprawling projects like that anymore – we&#x27;re in an season of backend development that favors separation (vs bundling) of concerns, from my perspective].I&#x27;m not sure if it&#x27;s a unique feature of the Go ecosystem that there isn&#x27;t one clear winner in the \"minimalist + pluggable web framework\" or \"ORM\" categories, or if we just need to wait for the winner to emerge. Ironically, I think the quality of `net&#x2F;http` and `database&#x2F;sql` might have been an anti-catalyst for the development of leading libraries in those verticals. reply coffeebeqn 12 hours agorootparentprevYou also don’t need to have frameworks for everything when the std library delivers reply liampulles 1 hour agorootparentprevI was a Java dev full time and went to full time Go dev. I think a lot of it boils down to wide employment opportunities with Java.Some people also like the idea of creating OO package private final monstrosities. reply seanmcdirmid 1 hour agorootparentprevGo is popular in dev ops right? It could theoretically languish there for a while, like Python did, before becoming popular for other things. reply pjmlp 2 hours agorootparentprevBecause the overal experience is lacking in language features, tooling and ecosystem. reply slantedview 12 hours agorootparentprev> I wonder why Go isn&#x27;t the new Java&#x2F;.NET (yet?).Go is moving too slowly (ex: most of the SDK still doesn&#x27;t support generics). Meanwhile, Java is moving relatively quickly, as are new contenders like Rust. reply booleandilemma 12 hours agorootparentGo is moving slowly, or trying not to move at all, on purpose, and I have to say, as a C# developer having to constantly learn new syntax, it seems refreshing. At the rate it&#x27;s adding new syntax, C# may fall apart under its own weight and become the next C++. reply coffeebeqn 12 hours agorootparentprevMoving towards what?I use it to build services that can serve lots of requests, I don’t need the language to be moving fast underneath me reply slantedview 8 hours agorootparentThe SDK is where most movement is needed. reply tmerr 14 hours agorootparentprevMaybe the decline of desktop applications (Java, C#) and Android (Java)? And then Go coming out with some killer frameworks? I have to stretch my imagination to imagine anything causing Go to outpace C# or Javas ecosystem. reply trhhowaway232 7 hours agorootparentprevGo is spreading like wildfire in microservice and devops space and Rust is following closely behind.It&#x27;s over. reply AtNightWeCode 13 hours agorootparentprevGo ecosystem is like a fraction of what .NET&#x2F;Java is. Both in quality and size. Dart for instance is a better lang. It is also from Google. It also compiles to binaries. Why is that not the new...The slim spot for Go is the devops tools space. Where Go may or may not survive. Considering the march of Rust. reply devjab 16 hours agoparentprevJavaScript is famously backwards compatible. That’s exactly why it’s the mess you describe. reply afavour 16 hours agoparentprev> I really wish the JS ecosystem could have a stable modern foundation we could rely on.I actually think we do now. ES modules, ES2020 code. Both supported by Node and major browsers. Node even has a built in test runner now! The problem is getting everyone up to this bar. Once we’re there I think things are going to feel a lot better.I think part of the problem is that the JS ecosystem also encompasses frontend UI work and there are so many different applications for it that multiple implementations is inevitable. Desirable, even. reply nadermx 17 hours agoprevMoving some code from python to Golang was instrumental in helping me scale. I am so glad to read they are going to stick to their core statement of backwards compatability reply Joker_vD 17 hours agoprevAh, parsing IPs. Just how exactly was the BSD&#x27;s original inet_ntoa written, I wonder? The atoi&#x2F;atol and sscanf with %d&#x2F;%u always parse exactly decimal integers; it would had to use either %i or strtou with 0 base to have this silly effect. reply wahern 16 hours agoparentNo need to guess. My man page for inet_aton says it comes from 4.3BSD: https:&#x2F;&#x2F;github.com&#x2F;dank101&#x2F;4.3BSD-Reno&#x2F;blob&#x2F;master&#x2F;lib&#x2F;libc&#x2F;...The earlier inet_addr from 4.2BSD has the same logic: https:&#x2F;&#x2F;github.com&#x2F;dank101&#x2F;4.2BSD&#x2F;blob&#x2F;master&#x2F;lib&#x2F;libc&#x2F;inet&#x2F;...inet_aton and inet_addr parse addresses the obvious way. Using something like strtoul or especially sscanf would be stilted. The beauty of C pointers is that it makes simple parsing tasks very easy--perhaps too easy. reply Joker_vD 13 hours agorootparentO_OThey&#x27;ve intentionally coded it that way? This is atrocious. And this hand-rolled mess that doesn&#x27;t even parse numbers correctly! It would parse \"099\" as 81 and \"99999999999999999\" as whatever it is modulo (MAX_ULONG+1), without any overflow detection. Well, at least they don&#x27;t accept negative numbers, that&#x27;s something.Anf mind you, beauty of C pointers has nothing to do with neither of these two bugs not the original decision to support octals and hexadecimals. reply doctor_eval 12 hours agoparentprevI laughed when I read that. “Back in the day” I decided to “clean up” my &#x2F;etc&#x2F;hosts by zero padding the quads.Anyway, the outcome was that I had to go back and remove the zeroes. reply gavinhoward 16 hours agoprevAs a language designer, I respect the decisions they made here, including you never have a real Go 2.I&#x27;m also going to pilfer their techniques for ensuring compatibility. reply auxten 4 hours agoprevGolang&#x27;s forward compatibility and static compilation allow developers to quickly download and use the latest Golang release without the pain of upgrading like interpreted languages or VM-dependent languages. reply sleepytimetea 2 hours agoprevThe leading zeroes in net.ParseIP change broke some of our unit tests too. reply davewritescode 10 hours agoprevThis is something I’ve complained about before on HN but this rings really hollow when Go 1.17 arbitrarily updated the x.509 package to suddenly stop supporting TLS hostname validation based on the CN field because it was deprecated in the X509 specification.My browser doesn’t care, why should Go? reply jokoon 17 hours agoprevBTW, I&#x27;ve read the Go GC can be disabled, but what happens if you do? Wouldn&#x27;t you have to avoid memory leaks? reply rsc 16 hours agoparentIf you turn off the GC then no memory is collected. In general this is not something people actually do. The only time I&#x27;ve ever even seen it mentioned is in an old blog post by ESR, and between him and me, at least one of us didn&#x27;t understand what he was saying. reply 015a 16 hours agorootparentThere are popular problem domains where turning off the GC is useful. The best example is Lambda functions&#x2F;FaaS. Most invocations are short-lived enough that the GC never triggers anyway, but being able to turn it off can help smooth down your P99s where it does trigger, but the world is going to be thrown away in 50 milliseconds anyway. This is a known, not-uncommon performance optimization in other languages on Lambda; but I have less experience using Go on Lambda. reply wongarsu 16 hours agorootparentIt&#x27;s not even exclusive to GC&#x27;d languages. A toy raytracer I&#x27;ve written in the past got notably faster if I just didn&#x27;t deallocate anything. Memory management is expensive, and for unix-y software that runs on some input and then quits it can be worth it to just let the OS do the cleanup. reply davidjfelix 14 hours agorootparentprevDo not do this in AWS lambda or OpenFaas. Lambda processes are reused in \"warm\" invocations and are only short lived in cold, infrequent use cases (read: once every > 45 minutes). This is useful when the process dies at the end of every request (in which case you&#x27;re relying on the OS to do the GC for you). reply coder543 16 hours agorootparentprevThat doesn’t seem like a real thing. Lambda and every other FaaS that I’m aware of will reuse a single instance of the function for multiple invocations. It is not started from scratch with each invocation. Each instance can live for hours, handling a very large number of (sequential) invocations during that time.If you’re not GCing, you will almost certainly run into OOMs. reply cratermoon 16 hours agorootparentIf the FaaS can catch the OOM, restart the instance and re-run the request, the visible effect would be somewhat greater latency for that request. If the service is configured to automatically kill and restart instances after some time or some number of requests, it seems like a reasonable tradeoff. Am I missing something? reply coder543 16 hours agorootparent> If the FaaS can catch the OOM, restart the instance and re-run the request, the visible effect would be somewhat greater latency for that request.I’m not aware of an FaaS that would hide the OOM… that falls under the “not a real thing” category I mentioned previously. It would just be a failed request, which is a very visible effect.Would you like to link me to the Lamda docs that say it will automatically retry the request in case of an OOM?Also consider that code which OOMs will do so unpredictably. It may have completed half of a task, leaving that task in a corrupt state that requires manual intervention from a human to recover from. If everyone wrote fully idempotent code that can somehow skip the already-completed updates and continue where the OOM occurred, this wouldn’t be a problem, but that isn’t what everyone does. This is certainly a large reason why FaaS do not retry requests automatically at all, in most cases.> If the service is configured to automatically kill and restart instances after some time or some number of requests, it seems like a reasonable tradeoff.I don’t believe Lambda has any configuration parameters for those things. That’s not how this is meant to work. Lambda will kill the instance when it has been idle for too long, and that’s the primary factor.You could manually exit the process when your conditions are met, but why? The benefits of turning off the GC are likely to be negligible. This is a lot of complexity for no real gain. It would take some seriously huge gains demonstrated by well-written benchmarks to convince me that any of this is worthwhile for a FaaS function.Grug would rather fight t-rex.[0]If you need absolute performance and control over garbage collection, it’s better to just write the lambda in Rust than to try to hack together a solution by turning off the GC and hoping it doesn’t blow up at the wrong moment.[0]: https:&#x2F;&#x2F;grugbrain.dev&#x2F; reply davidjfelix 14 hours agorootparenthttps:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;lambda&#x2F;latest&#x2F;dg&#x2F;invocation-retr... Lambda retry docs. I still would strongly not advice intentionally disabling the GC and explicitly said not to above for the same reasons you&#x27;re concerned. reply coder543 14 hours agorootparentGlad you generally agree.From that link, here are two choice quotes that I think are highly relevant:> When you invoke a function, two types of error can occur. Invocation errors occur when the invocation request is rejected before your function receives it. Function errors occur when your function&#x27;s code or runtime returns an error.> […]> When you invoke a function directly, you determine the strategy for handling errors related to your function code. Lambda does not automatically retry these types of errors on your behalf. To retry, you can manually re-invoke your function, send the failed event to a queue for debugging, or ignore the error. Your function&#x27;s code might have run completely, partially, or not at all. If you retry, ensure that your function&#x27;s code can handle the same event multiple times without causing duplicate transactions or other unwanted side effects.So, it won’t automatically retry if a function is being directly invoked and OOMs, which I believe was the context of my most recent reply.There are a few limited scenarios where certain AWS services that are invoking a Lambda asynchronously will decide to retry a couple of times, because it assumes that this type of function will be okay to call multiple times with the same input. Definitely not something worth relying on. replyTylerE 13 hours agorootparentprevAlso things like compilers...which tend to make lots of garbage but the processes are so short lived who really cares? All the memory is getting released in no more than a few seconds, worst case. reply bheadmaster 4 hours agorootparentUnless you&#x27;re writing C++... reply chrsig 16 hours agorootparentprevthere is of course one notable use for turning off garbage collectionhttps:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;oldnewthing&#x2F;20180228-00&#x2F;?p=98... reply ilyt 11 hours agorootparentThat seems like something that would eventually cause problem once someone just takes the software already designed and paid for and slaps it onto missile with longer range... reply ash_gti 16 hours agorootparentprevIf you have a short lived CLI tool, disabling the GC might be useful but that’s likely an exceptional case. reply ainar-g 16 hours agoparentprevIt can, by setting GOGC=0 or from within the program. And yes, you would. It&#x27;s essentially like writing in C, but not being able to call free(); i.e. allocating a fixed amount of resources at the start of the program and work on them. Which is also a recommendation[1] for safety-critical C code made by a NASA person, incidentally, heh.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Power_of_10:_Rules_for_Dev... reply throwaway894345 16 hours agorootparentMost of that seems reasonable, but the \"do not use function pointers\" boggles my mind. I&#x27;m pretty sure the alternative is a bunch of conditionals wherever you would otherwise use a function pointer. I&#x27;ve definitely seen some really ugly code written with this axiom which would certainly be a lot cleaner if rewritten to use function pointers. I&#x27;m curious if anyone can make a compelling argument against function pointers? reply ainar-g 16 hours agorootparentIt&#x27;s in the original:> […] Similarly, function pointers should be used only if there is a very strong justification for doing so because they can seriously restrict the types of automated checks that code checkers can perform. For example, if function pointers are used, it can become impossible for a tool to prove the absence of recursion, requiring alternate guarantees to make up for this loss in checking power.In other words, static analysis beats code cleanliness, in this perspective. reply jeeyoungk 16 hours agoparentprevIf your program is short running, then it may be more efficient to disable GC and let the dying process to take care of it all. reply 0cf8612b2e1e 16 hours agorootparentThere many tales about programs foregoing any kind of memory collection and relying upon the business process itself to resolve the issue.My favorite is a missile. Evidently the program leaks memory like crazy. Solution was to determine how much memory would be required for the platform to fly to its farthest possible target + some margin.Alternatively are stock trading platforms written in Java. Disable the GC entirely because trading hours are only a a limited portion of the day. Restart the program daily. reply hbn 16 hours agorootparentI like to think the stock market thing is actually the reverse, and they shut it down every night because all the programs that keep it running were written in a memory-leaking tech stack that needs restarting reply titzer 16 hours agorootparentprev> My favorite is a missile.This might be apocryphal, as software for this class of embedded system almost certainly doesn&#x27;t dynamically allocate anything; probably doesn&#x27;t even use pools.I have a friend who works on missile software at a big defense contractor, and they do actually clean up their memory. reply 0cf8612b2e1e 13 hours agorootparentI found a source, quoting the quote, so provenance is what it is> This sparked an interesting memory for me. I was once working with a customer who was producing on-board software for a missile. In my analysis of the code, I pointed out that they had a number of problems with storage leaks. Imagine my surprise when the customers chief software engineer said \"Of course it leaks\". He went on to point out that they had calculated the amount of memory the application would leak in the total possible flight time for the missile and then doubled that number. They added this much additional memory to the hardware to \"support\" the leaks. Since the missile will explode when it hits its target or at the end of its flight, the ultimate in garbage collection is performed without programmer intervention.[0] https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;oldnewthing&#x2F;20180228-00&#x2F;?p=98... reply ilyt 11 hours agorootparentprevNobody said it was good missile. reply llimllib 16 hours agoparentprevhttps:&#x2F;&#x2F;go.dev&#x2F;doc&#x2F;gc-guide is the docs on mucking with the GC, including disabling it.> Wouldn&#x27;t you have to avoid memory leaks?I&#x27;ve not played with it, but I&#x27;d expect that every heap allocation would essentially be a memory leak in that mode reply aatd86 15 hours agoparentprevIf you allocate everything in advance and use free lists, you can probably do it. I believe that it is one of the few ways tinygo handles memory. (so embedded as a use-case)Note that GC can be triggered manually.I&#x27;ve had to do that using the wasm target so that I&#x27;d only trigger go GC cycles when the browser was idle. Eventually that use-case might disappear as the integration with a garbage-collected wasm gets deeper. reply ilyt 11 hours agoparentprevYou will leak memory when you disable it.However, you might not care (app running too short), or you might turn it off only temporarily (say time-critical section you don&#x27;t want to be interrupted by GC). reply oefrha 16 hours agoparentprevThere are at least two cases where GOGC=off could make sense for increasing performance:1. You know you’re definitely not allocating on the heap;2. Your workload is bursty and you can simply keep everything until the process dies and memory is released. reply _ph_ 14 hours agorootparentYou might be allocating on the heap, but if you know in advance that the allocated memory never goes out of scope, then switching off the gc is quite reasonable. reply throwaway894345 16 hours agorootparentprevIf you&#x27;re definitely not allocating on the heap, setting GOGC=off should make no difference, right? reply bheadmaster 16 hours agoparentprevGo compiler performs escape analysis, which determines whether or not a particular object \"escapes\" the function it was created in - and if it doesn&#x27;t, the compiler allocates it on the stack instead of the heap, thereby removing the need for GC.So, as long as you write Go in malloc-less C-style (which, admittedly, is a non-insignificant restriction), your program will be able to run just fine forever. reply throwaway894345 16 hours agorootparent> So, as long as you write Go in malloc-less C-style (which, admittedly, is a non-insignificant restriction), your program will be able to run just fine forever.What happens if you write your Go functions in this malloc-less C style and they have to grow their stack? Doesn&#x27;t this mean the old stack is now leaked memory? reply wahern 9 hours agorootparentThe purpose of escape analysis is to avoid situations where other code or data structures could potentially reference stack-allocated memory. IOW, all stack-allocated data is only referenced from the local function invocation frame, presumably using stack relative addressing, but if not at least the scope of pointer updates is substantially narrowed.Relatedly, unlike languages like Java, Go doesn&#x27;t have a moving GC--once something is allocated on the heap, the address is fixed.I&#x27;m not sure how realistic it is to code in an entirely malloc-less style in Go, though, given the limited ability to pass references to stack-allocated objects. reply throwaway894345 3 hours agorootparentYeah, I think you’re right that stack allocated data can’t be pointed to by the heap. I don’t know what you mean about “the limited ability to pass references to stack allocated objects” though—you can always pass stack allocated references, you just can’t return them (or they will escape to the heap). reply bheadmaster 15 hours agorootparentprevI see no reason why would de-allocating a stack require action from the garbage collector - afterall, once a goroutine grows its stack and copies the contents of the old stack to the new stack, there aren&#x27;t any reachable objects left on the old stack, so it can be deallocated without any GC intervention.But I don&#x27;t know enough about Go internals to be 100% sure. reply ilyt 11 hours agoprevI do hope they will eventually introduce sum types and better way of handling errors, but keeping the old code just work is frankly more important on the grander scale. reply pjmlp 14 hours agoprevLooking forward to Go 1.99999999999999.... reply atleastoptimal 10 hours agoprevPokemon Go 2 the polls reply Zamicol 12 hours agoprevNice article Russ. reply unethical_ban 16 hours agoprevIf Go 2 won&#x27;t break Go 1 programs, shouldn&#x27;t it be Go 1?I get not using semantic versioning for end user packages like a web browser, but for backend systems and APIs, it still makes sense.I don&#x27;t see why go didn&#x27;t use full semantic versioning (x.y.z) where any update that didn&#x27;t break anything moved Z, new APIs or minor changes to behavior&#x2F;compile such as in the article move Y, and large changes to the core language or core libraries moves X.By semantic versioning, they aren&#x27;t moving off \"Go 1\" any time soon, no matter what it&#x27;s called. reply mseepgood 16 hours agoparent> If Go 2 won&#x27;t break Go 1 programs, shouldn&#x27;t it be Go 1?Yes, that&#x27;s what the article is saying. reply unethical_ban 16 hours agorootparentAh. So to phrase it differently,\"There will never be a Go 2 unless marketing says we should renumber.\"Just stop referencing \"Go 2\" as if they ever think it will exist, then! reply metaltyphoon 10 hours agorootparentAgreed. It’s confusing as hell reply fullstackchris 17 hours agoprevdarn i was hoping for at least a hint or mention when Go 2 might be released... no dice reply sudhirj 17 hours agoparentGo 2 is coming out every six months as continuous Go 1.x releases. reply tptacek 17 hours agoparentprevThe article ends with a definitive answer to that question. reply euroderf 12 hours agoparentprevI would expect a Go 2 to dispense with accumulated API cruft and to overhaul syntax with something radically different. But to otherwise maintain compatibility. reply JoshGlazebrook 17 hours agoprevI started using Go at work ~2 years ago and I love it, especially for the backwards compatibility. But my personal projects up until then were node.js backends written with Typescript. Those personal projects are essentially stuck in time because of the whole ESM&#x2F;commonjs mess that is modern javascript. Some of the npm package I use have been updated to only support ESM modules, while others will never be updated, some are half and half. It&#x27;s in such a bad state that I&#x27;ve decided if it does ever fully break I&#x27;m just going to re-write the backend in Go, and I know I&#x27;m not the only one just frustrated with the modern javascript ecosystem and have projects stuck on old node.js and npm package versions because of it. reply madeofpalk 16 hours agoparentThe whole Nodejs ESM thing is the result of a bunch of different parties - Node, Typescript, Babel&#x2F;Webpack&#x2F;etc - with a lot of influence over the ecosysten with conflicting priorities. This is the price of truely \"open\" standards. One of the reasons why it&#x27;s such a mess was due to bending over backwards maintain backwards compatibility.It&#x27;s a mess. It&#x27;s frustrating as a user&#x2F;developer. Go has it significantly easier by having just one central organising factor behind the ecosystem. If there were multiple Go implementations, some moving faster on the spec (or even ahead of it) than others, then you would find the same pain there also. reply latchkey 15 hours agoparentprevI&#x27;ve been maintaining a fairly popular (~40k downloads&#x2F;mo) react component library for about 4 years now. It is a clusterf&#x27;ck to keep things up to date with changes over time. React itself has broken things several times.I knew in advance that this would be a challenge, so when I started the project, I wrote a lot of unit tests. The first test for each component was just a snapshot output of it. Then I had other tests for functionality and have added tests over time for bugs. That has saved my ass so many times.I don&#x27;t know how anyone maintains a JS project without comprehensive tests. Actually, I do... as you said, they never upgrade anything. reply cookiengineer 17 hours agoparentprevBabel was the most enterprise thing that could happen to the JS ecosystem.Gone are the simple distribution channels, and all build pipelines have 100s of megabytes of legacy crap that nobody actually ever executes.If you want to tell me your page is working in IE6, you&#x27;re lying. It will break apart in all places.Anybody remember bower and pikapkg? That was the peak in my opinion. reply nobleach 15 hours agorootparentOh my.... yes. For me, that would have been Angular 1.x days. And while it was neat having a tool that could pull a deterministic flat list of dependencies, I wouldn&#x27;t go back to those days. I do wholeheartedly agree that injecting core-js into every single build, in the rarest of cases that you&#x27;d need to support a browser that doesn&#x27;t support generators, or some other featured added around 2015, is just plain silly. I cringe when I look at a dependency graph and see all those polyfills in my builds!! reply joshstrange 16 hours agoparentprevIn your position I&#x27;d probably do the same thing and no doubt the ESM&#x2F;commonJS mess is a mess and huge PITA.All that said I&#x27;ll probably continue with my TypeScript&#x2F;NodeJS backends since I just absolutely love writing TypeScript and I love sharing code between the front and backend. I use JS&#x2F;TS in my day job (frontend only) as well so it&#x27;s super nice to be able to benefit from that knowledge&#x2F;practice. I also use TypeScript to write a few apps (some for work, some for my side project, some for personal use) so staying in the TypeScript ecosystem for almost everything I do is really nice.Again, I&#x27;m not defending that annoying&#x2F;bad parts of TS and certainly not saying I&#x27;ve escaped the ESM&#x2F;commonJS hell unscathed, just that I use TS everywhere and I generally have a lot of fun writing&#x2F;running it. reply mattlondon 16 hours agoparentprev> ESM&#x2F;commonjs mess that is modern javascriptNo - only a mess in the node&#x2F;npm scope.JavaScript modules are just fine if you stay away from npm and node. Node and npm are a total dumpster fire, but that is not all of JavaScript. reply pseudosavant 16 hours agorootparentAgree that node&#x2F;npm are the dumpster fire of JS, but ESM is still going through growing pains too. I have switched off of Node over to Deno. It natively supports ES modules. But most of the time I try to consume an ESM the code was designed to only load in a browser. It gets especially complicated if the ES module is using something like WASM - using FFMPEG via an ESM using WASM is the current use case I&#x27;m working on. reply the_duke 17 hours agoprevNever breaking compatibility is hardly a new idea.Java and C++ have invested tremendous amounts of effort into preserving backwards compatibility for decades, often requiring bending over backwards and very suboptimal designs for new features, especially in C++.But it keeps users happy. At least the ones with large old code bases.I think Rust has one of the cleanest models for this, which keeps complexity low: editions.The compiler will always support old code written against older editions, but the language can still introduce breaking changes in newer editions. Developers can either opt in to new editions and migrate their code, or do nothing, and things continue to work fine. There is seamless&#x2F;transparent interoperability.Of course Rust is still pretty young, and if this model will work long term remains to be seen. For example, I imagine this causes a lot of implementation complexity in the compiler, the standard library is much more restricted and must remain stable across editions, and major overhauls probably won&#x27;t be possible.But so far it has worked out really well, allowing the team to fix warts and mistakes in the language. reply glenjamin 16 hours agoparentDid you read the article?> The compiler will always support old code written against older editions, but the language can still introduce breaking changes in newer editions. Developers can either opt in to new editions and migrate their code, or do nothing, and things continue to work fine. There is seamless&#x2F;transparent interoperability.This is exactly what the GODEBUG scheme described in the article is intended to allow. reply the_duke 16 hours agorootparentEdit: I had some wrong assumptions here.The Go approach does indeed seem to enable similar functionality. Although I&#x27;m not quite sure I understand how the individual settings and the module level version declarations compose, and how much complexity that introduces.With both module-level versions and GODEBUG, the whole thing does seem quite a bit more complicated than editions. reply vocx2tx 16 hours agorootparent> The setting is opt-out, requiring manual intervention.No. If a module&#x27;s go.mod files declares go1.21, the compiler will use go1.21 semantics when building it, even if 1.22 has already been published and the module is being used from a 1.22-enabled program. This is explicitly mentioned in the blog post. reply tick_tock_tick 14 hours agorootparentprevIt&#x27;s basically a much more featured, flexible, extendable, and usable version of editions. Anything you could do with editions you could do with this; you could implemented \"editions\" via this functionality. reply the_duke 13 hours agorootparentYes, but that&#x27;s sort of my point regarding complexity.\"This crate is edition X, and an edition comes out every 3 years or so\" is much easier to deal with.It reminds me a bit of Haskell language pragrams, which can be toggled per source file (module), and which are a huge mess. reply izacus 16 hours agoparentprevCan you explain in what way is that different from e.g. C++, where a compiler will take \"-std=\" parameter which chooses the \"edition\" of the language?And even link different versions together?Because it sounds like Rust uses the same approach with the benefit of not hitting all the problems this causes... yet. reply uluyol 5 hours agorootparentC++ unfortunately does textual inclusion for header files. So \"-std=\" does not automatically work for those. You need to sprinkle in #ifdefs rather than getting automatic forward compatibility. reply kaba0 14 hours agorootparentprevI would also be interested in it. As far as I know editions only allow for syntax changes, the semantics will change if incompatible, especially that Rust doesn&#x27;t link across different versions in the same way as C++ does. reply zigzag312 16 hours agoparentprevI would upvote this twice if I could.We will never break compatibility is code for \"we will never fix warts and mistakes in the language\". reply tptacek 16 hours agorootparentIt obviously isn&#x27;t, as the text of the article repeatedly observes. reply zigzag312 1 hour agorootparentYou are right. I haven&#x27;t read the article and just assumed. It&#x27;s actually about how they enabled introducing \"breaking\" changes without actually breaking backwards compatibility with existing code. Which is best possible outcome. reply dcow 17 hours agoprev> That raises an obvious question: when should we expect the Go 2 specification that breaks old Go 1 programs?> The answer is never. Go 2, in the sense of breaking with the past and no longer compiling old programs, is never going to happen. Go 2 in the sense of being the major revision of Go 1 we started toward in 2017 has already happened.Why is backwards compatibility such a religious sin for Go? Python made it through a backwards-incompatible source change. I understand breaking backwards compatibility would be difficult on a short timescale, but on a long-term time scale people would migrate. Source rewriters would handle most of the transition. Over 3-5 years I could see a source-breaking change play out positively for some of these newer languages like Go and Rust. And arguably, they sorely need it. reply TeddyDD 17 hours agoparentGo developer experience: * install the newest compiler * clone the code * go buildPython developer experience: - clone the code - setup virtual env (otherwise you will break your system) - install very specific version of interpreter because lib x supports only Python from 2020, because Python breaks compatibility in minor versions - no, you can&#x27;t just update lib x withut updating python and other deps - install deps (hopefully author of the code pinned everyting, otherwise you&#x27;re fucked) - never update any deps or you will suffer reply gen220 15 hours agorootparentAs somebody who writes a lot of python, I&#x27;m going to quibble, but your statement isn&#x27;t unfair. :)My quibble would be \"don&#x27;t use lib x\". 99% of the time, you don&#x27;t need an unsupported 3rd party library from 2020. In the worst case, you can copy the subset of lib x that you actually need, the copied code will typically just work, verbatim, in a later python version. In summary, the \"common\" path travelled by footgun-aware python programmers is not this bad.But yeah, it&#x27;d be nice if the language constraints meant you couldn&#x27;t end up in a situation like this, and it&#x27;d be nice if we didn&#x27;t have to learn-by-footgun as much in the python community.TBF, Python is just an old language that comes with early-mover advantages and disadvantages. Like an old house, we have just learned to live with (i.e. avoid) certain floorboards. reply vlowther 14 hours agorootparentprevWhy the extra \"clone the code\" step in the Go developer experience? Been using Go since 1.0, never had to do that. reply TeddyDD 14 hours agorootparentLet&#x27;s say I described steps to hack on some Go package. When installing libs&#x2F;programs, go get&#x2F;install is enough :) reply throwaway894345 16 hours agorootparentprev> Go developer experience: * install the newest compiler * clone the code * go buildHN screwed up your formatting, FYI. reply TeddyDD 14 hours agorootparentI&#x27;m clueless when it comes to HN formatting ¯\\_(ツ)_&#x2F;¯ reply dcow 13 hours agorootparentuse extra new lines liberally (when in doubt, add a newline) is good working advice reply aeturnum 17 hours agoparentprev> I understand breaking backwards compatibility would be difficult on a short timescale, but on a long-term time scale people would migrate.It&#x27;s funny to see people expressing this view because the \"2 to 3 migration problems\" is still a lively conversation in the Python world. I happen to agree with you and view it as a price of success - but at the same time I think it&#x27;s obvious that you will pay an outsized price in community sentiment for even reasonable timescales for EOL&#x27;ing old versions. reply zer0tonin 17 hours agoparentprev> Python made it through a backwards-incompatible source changeThe transition took more than a decade and was kind of a mess for a long while. For other languages, like Perl, it really didn&#x27;t work out. reply jerf 15 hours agoparentprev\"Why is backwards compatibility such a religious sin for Go?\"I think the best way to understand it is that it is a first-class feature of the language. Thus, for Go specifically, it is like asking \"Why is it a statically-typed language?\" or \"Why is the language compiled rather than interpreted?\"; these are not bad questions but to a large degree the answer is that was a major choice made at the start of the language. And \"why won&#x27;t they get rid of it?\" is in the same class of questions as \"Why won&#x27;t Python just become a statically-typed language?\", which, is, again not intrinsically a bad question, but one that is certainly in a different category from \"why won&#x27;t Python adopt this particular bit of syntax sugar in their next version?\"That the designers of Go would consider that a \"feature\" and so many programmers probably find classifying \"backwards compatibility\" as a feature a completely befuddling concept (\"that&#x27;s not what a feature is!\") is probably a pretty good microcosm of the difference between the gestalt of programmers as a whole and the Go designers. reply crickey 17 hours agoparentprevHas python really though? still my company has a bunch of 2.7 lying around that not one is touching. I would like to flip your question on its head and ask why does any language need a breaking change ever? Might as well create a new language in that case reply mrweasel 16 hours agorootparentWhile I can&#x27;t say for sure, one or the reasons I seem to recall from the Python 3 transition was that the Python 2 design was pretty much a dead end. There where so many limitation and wrong design choices that it would keep the language from moving forward. That does seem a little aggressive, but it does feel like Python picked up a lot of steam once Python 3 was viable (something that happened way earlier than many care to admit).Our code base wasn&#x27;t huge at the time, a few 100.000 lines of code. Getting everything running was a week of work for three people. Sure many had way more complicated code, and some depended on some idiosyncrasies of Python 2 making thing more complex, but a lot of people acted like the Python developers shoot their dog. Mostly these people either simply didn&#x27;t want to do the work or their particular niche was made ever so slightly more complex... or they depended on unmaintained libraries which is bad in it&#x27;s own way. Python 3 was always going to be able to do everything Python 2 could, yet a large groups of people acted as if that wasn&#x27;t the case.Still not the best transition ever devised, we had to wait until 3.2 to get the speed to a point where it&#x27;s wasn&#x27;t an issue for all but the largest users. reply LexiMax 15 hours agorootparentThe Python 3 upgrade process for many projects was incredibly painful. \"Mercurial’s journey to and reflections on Python 3\" should be required reading for anybody with rose-tinted glasses of the migration.https:&#x2F;&#x2F;gregoryszorc.com&#x2F;blog&#x2F;2020&#x2F;01&#x2F;13&#x2F;mercurial%27s-journ...There was, of course, a Hacker News thread discussing the article, and a fair few people decided to blame the Mercurial developers for handling the migration inelegantly. Because that&#x27;s how you win over an audience of developers - reassuring them that if Python has a backwards-compatibility break, Python fans will go out of your way to try and blame you for writing bad code. And not, perhaps, the fact that Python was missing things like a u string prefix and % bytestring formatting until 3.3 (2012) and 3.5 (2015!!!) respectively.If I sound peeved, I really loved Python in the 2.x days, and the way the 3.x transition was handled broke my heart and prevented me from using the language for pretty much an entire decade. There are lessons to be learned from the transition, but not if we ignore the real problems that the transition caused. More importantly, we need to recognize that Python is not the Python we know today because of how \"well\" the transition was handled, but because Numpy and Matplotlib swooped in and gave Python new niches to excel in at just the right time. reply crickey 11 hours agorootparentprevAll well and good when u have an active dev team who knows the code. Have fun walking into a code base that has just been running for the last 5 years and all the consultants that created it have left. reply dekhn 10 hours agorootparentprevGuido has admitted several times now that the 2-3 transition was poorly handled.Transition costs are huge, which is precisely the reason that Go developers take this so seriously. reply eviks 16 hours agorootparentprev> why does any language need a breaking change everthat&#x27;s easy - because it&#x27;s impossible to design everything right right away, and for many things also impossible to make it right later without breaking compatibility, while those improvements are valuableNew language for each breaking change also doesn&#x27;t make sense when there is a lot of continuity reply yakubin 17 hours agoparentprevPython programmers just self-selected themselves into a set of programmers who care about backwards-compatibility less than other programmers. You can see this attitude all over the Python ecosystem. And even in standard Python it’s not just one backwards-incompatible change, but a series still made from time to time. Programmers from C++, Java and Go worlds wouldn’t accept it as easily. reply packetlost 17 hours agoparentprevIt&#x27;s probably because Google has no interest in rewriting the hundreds of thousands of lines of Go code they have internally and don&#x27;t want to expend the resources to maintain a v1 and a v2. reply dgb23 16 hours agoparentprevIncompatibility, lack of stability and other churn inducing changes are the nemesis of software maintenance.The implied cost is immense and soul sucking.In many cases it’s pure vanity as well.It’s fine for early languages, research languages and toy languages. But outside of these categories it’s not worth the cost. reply badrequest 16 hours agoparentprev> Python made it through a backwards-incompatible source change.It took them a decade and permanently tarnished their perception with many programmers. They \"made it through\" in a similar way to how cancer survivors enter remission. reply masklinn 15 hours agoparentprev> Python made it through a backwards-incompatible source change.It made it, but it was a rough few years, and the string model changes while mostly welcome (though not perfect) were a pain, we still find bugs from time to time.Things also got a lot better once the community figured how to do proper multiversion sources even though it was more limiting.A statically typed langage would have it a lot easier, by virtue of both the API and the semantics changes being much more flagrant, as well as the compiler making it easier to actually mix different versions of the langage across different packages (or even source files). reply ranting-moth 13 hours agoparentprev> Python made it through a backwards-incompatible source change.That&#x27;s skipping a few fact, isn&#x27;t it? Let&#x27;s call it what it was. Python was a victim in a cataclysmic software disaster of biblical proportions. It spend 10 years in rehab afterwards but miraculously made it through yes. reply dekhn 10 hours agoparentprevBackwards compatibility matters to the Go developers because all of them worked with the same codebases for 20+ years. I remember rob pike showed me a source file that had been written before I was born (1973) but is still part of (I think) Plan9. reply distrill 17 hours agoparentprevthis always seemed like a nightmare to me. even so today years after python2 was officially sunset, documentation is still all over the web that may never catch up.yes technically the language got over it but i would hold this up as an example of a reason not to break backwards compatibility. having to manage multiple interpreter versions when i&#x27;m just trying to run software on my computer, what a pain in the neck. reply 0cf8612b2e1e 17 hours agoparentprevEspecially for a compiled language, I would think it is significantly easier to make automated code porting which is guaranteed to be correct. Or at least enough to handle the 99% of a code base which is likely not impacted. reply dcow 17 hours agorootparentWhich is exactly what Swift did when it shipped early source-incompatible revisions. reply mr_00ff00 17 hours agoparentprevPython is definitely the exception, not the rule. reply dcow 17 hours agorootparentSwift shipped source-breaking updates earlier in its lifetime. I honestly don&#x27;t really know of a story where a source-incompatible update killed a language. People grumble, then they move on. reply addaon 17 hours agorootparent> I honestly don&#x27;t really know of a story where a source-incompatible update killed a language.Perl, with the Perl 5 -> Perl 6 (later Raku) transition? Fortran, with the F77 -> F95 transition? reply ainar-g 16 hours agorootparentprev> I honestly don&#x27;t really know of a story where a source-incompatible update killed a language.Death may not come as swiftly (heh) as you think. I know a few people (including myself) who, when deciding which language to add to their toolbox, had decided against Swift because of its reputation as “that language that always breaks code”, among other reasons. There are just a few anecdotal data points, of course, but I don&#x27;t think it&#x27;s controversial to say that a history of messy updates definitely makes new people less likely to learn a language without an absolute necessity. reply _ph_ 14 hours agorootparentprevKilled, in the sense of no one ever migrated? Certainly not. Killed, in the sense of hugely impacting the eco system and the community? Quite regularly. Python seems to finally mostly have made the transition, but there is just a lot of software around which will never be ported to Python 3. Perl almost completely went away, until finally development of Perl 5 gained some traction, but also with promises of maintaining compatibility. reply throwaway894345 16 hours agorootparentprevThe pain of breaking changes is proportional to the volume of code affected by the breakage. This usually means breakages early in the lifetime are easy because there&#x27;s relatively little code. For mainstream languages that have a decade or more of widespread usage, a breakage is a big deal.> I honestly don&#x27;t really know of a story where a source-incompatible update killed a language.Perl. I mean, Perl isn&#x27;t strictly dead, but its share of the market plummeted. Python almost certainly would have suffered a similar fate if it weren&#x27;t for the explosion of interest in scientific&#x2F;numeric computing (which more than made up for massive attrition to other languages, including Go). reply morelisp 16 hours agoparentprev> Python made it through a backwards-incompatible source change.... Source rewriters would handle most of the transition.It seems we have collectively learned literally nothing from the failed plans to change Python incompatibly. reply jimmaswell 17 hours agoparentprevPython was a disaster. I still miss print statements and encoding-agnostic strings. Good on Go for doing the right thing. reply hk__2 17 hours agorootparentPrint statements were a mistake. If you forbid breaking changes, you have no way to fix past mistakes in the language design. There’s noting inherently \"right\" in refusing to do breaking changes. reply jimmaswell 16 hours agorootparentRemoving the print statement was the mistake to me. It violated Python&#x27;s own stated principle of practicality over purity. reply masklinn 15 hours agorootparentThere was nothing practical about the print statement.The print function is easier to use, meshes a lot better with the langage, and can actually be extended without C++ style syntactic nonsense.The print function is one of the best things to come out of p3. reply rowanseymour 15 hours agorootparentprevHaving two ways to do the same thing is the mistake, and print() was always more consistent with other built in functions are invoked. reply dcow 17 hours agorootparentprevI think if you&#x27;d ask any Python programmer today, they&#x27;d say Python is very much healthy and the community has successfully transitioned. reply jimmaswell 16 hours agorootparentPython was my first language and I still use it sometimes. Still run into 2 vs 3 issues often. reply mrweasel 16 hours agorootparentprev> encoding-agnostic stringsDo you mean byte strings vs. strings in Python 3 or did you actually like string handling in Python 2, because that basically \"Tell me that you only allow ASCII without telling me that you only all ASCII\". I can see the issue with byte strings in Python3, it&#x27;s annoying that you have to think about both strings and byte strings, but for dealing with actual text having everything just be unicode was reason enough to upgrade from 2 to 3. We deleted so much code dedicated to dealing with encoding during our switch to Python 3, everything just became better. reply jimmaswell 16 hours agorootparentI had an IRC markov-like bot in Python. It used to be so simple in Python 2:- the bytes come in from the IRC server- they go in a string in the log, I can print this log to the console even if it h",
    "originSummary": [
      "The blog post emphasizes the importance of maintaining compatibility in the Go programming language and discusses the challenges involved.",
      "It highlights the use of API checking and testing to prevent compatibility issues, while acknowledging that testing is not foolproof.",
      "The update on Go 1.21 introduces a new approach using GODEBUG to improve backward compatibility and assures that Go 1 programs will not be broken by a Go 2 specification."
    ],
    "commentSummary": [
      "The discussions focus on programming languages like Go, Java, C#, and Python.",
      "Participants discuss topics such as backward compatibility, new features, code abstraction, version updates, and breaking changes.",
      "Opinions vary on these topics, with some emphasizing compatibility and stability, while others emphasize the need for innovation and language improvement. Users also share their experiences and frustrations with specific languages and version transitions."
    ],
    "points": 368,
    "commentCount": 272,
    "retryCount": 0,
    "time": 1692030144
  },
  {
    "id": 37125830,
    "title": "OpenFarm – a free and open database and web application for gardening knowledge",
    "originLink": "https://openfarm.cc",
    "originBody": "Become a Member Log in Welcome to OpenFarm! We're a pretty new project and community so please excuse any bugs you find in the website. Interested in helping out? Become a member for free and we'll be in contact via our email newsletter! × 1 Choose a Crop 2 Find a Guide 3 Grow! Growing Guides show you how to care for your Crop during all of its Life Stages. Each Guide is based on specific environmental conditions and growing practices, and ranked for compatibility with you and your gardens. Grow Your Food Farm and garden through knowledge sharing See how it works What kind of gardener are you? Take Our Survey Community Favorites Tomato UF Micro Tom Tomato Thai Basil Heirloom Tomato Lettuce Potato Carrot Orange Strawberry Openfarm About Us FAQ Blog Contribute Getting Started Join Slack Code of Conduct Openfarmers How it works Ask questions Stay in touch Newsletter: openfarm Terms of Service & Privacy",
    "commentLink": "https://news.ycombinator.com/item?id=37125830",
    "commentBody": "OpenFarm – a free and open database and web application for gardening knowledgeHacker NewspastloginOpenFarm – a free and open database and web application for gardening knowledge (openfarm.cc) 371 points by lasermatts 14 hours ago| hidepastfavorite33 comments rickcarlino 10 hours agoWow, I am surprised to see this on the front page of HN. I was one of the main maintainers of OpenFarm back when I was part of FarmBot. As some folks in the comments have already mentioned, the project is unfortunately not actively maintained.Although it is not actively maintained I would not say that the project is dead since it is still used as part of FarmBot for crop information management.The biggest thing the project needs right now is a dependency upgrade above all else. It is running an old version of Rails&#x2F;Mongoid&#x2F;Angular 1.x. Folks who are interested in reviving this project should absolutely reach out to the current maintainers (I am no longer involved). reply tommica 26 minutes agoparentIs there a chance of getting a copy of the crop&#x2F;plant database? I am working on a little app for home use, but finding organized data or apis has been hard. reply winrid 1 hour agoparentprevOooooh Angular 1!https:&#x2F;&#x2F;github.com&#x2F;openfarmcc&#x2F;OpenFarm&#x2F;blob&#x2F;mainline&#x2F;app&#x2F;ass...$scope.$watch(). The nostalgia. :)Probably Vue would be a good option. reply openthc 9 hours agoparentprevI (we, my company) have offered to become maintainers. This is something we are passionate about. reply beanjuiceII 10 hours agoparentprevJust curious what ever happened reply k310 12 hours agoprevI emailed the contact person:Hi,OpenFarm has not been maintained or worked on in several years and the Slack group is no longer active. If you are interested in taking on a project maintainer role for OpenFarm, please get in touch through the OpenFarm GitHub repo! And please note, this email address is no longer checked regularly (this is a vacation responder replying to you). Thank you for your understanding. reply mastazi 11 hours agoparentOn their Github&#x27;s Readme there is an @farmbot.io address, maybe this project was at least initially maintained by FarmBot employees. Maybe it still is? It seems that someone is still doing the bare minimum to keep the lights on, such as merging Dependabot PRs.It is a valuable resource and I hope through the exposure here on HN maybe someone will step forward and maintain it. reply poutinepapi 11 hours agoparentprevAbsolute shame.The repo: https:&#x2F;&#x2F;github.com&#x2F;openfarmcc&#x2F;OpenFarm seems like it has all the info, and honestly, this doesn&#x27;t need to be a bloody website, a bunch of MD files with links between each other and hosted on GitHub would be far easier to maintain and extend. If you want to get posh, have it use Jekyll.Neat weekend hackathon for a group of students or similar, mind you. reply contravariant 10 hours agorootparentI think I get what you&#x27;re saying but I have some difficulty moving past the fact that you&#x27;re claiming it doesn&#x27;t need to be a website because it would be sufficient if it was a bunch of hosted markup documents that link to each other.We really f&#x27;ed up the web didn&#x27;t we? reply monetus 4 hours agorootparent\"If you want to get posh, have it use Jekyll\" reply Lutger 3 hours agorootparentThe irony is too fine to get lost here, even though explaining it is a mood killer.Its funny I also missed it on first reading, which tells me have far this has gone.The web, internet, www, etc literally was a bunch of markup documents linking to each other. That is what a website was. Its even in the name of its language: Hyper Text Markup Language.Wouldn&#x27;t it be funny if browsers started rendering markdown and we got to re-create the original simplicity (and ambiguity) of the web this way. reply jarofgreen 3 hours agorootparentprevBut then only technical people could contribute information. The website may be trying to make it so all gardeners can contribute. reply winrid 10 hours agorootparentprevIt looks like the original goal was a bunch of dynamic stuff (member related content). reply chirau 9 hours agorootparentprevWhich folder contains the .MD files? reply pschuegr 7 hours agorootparentprevI was digging through the code but didn&#x27;t see where the actual content was, did you? reply fimdomeio 3 hours agoprevI have once particcipated in a similiar project. One thing that I find can be easily overlooked is that a lot things, specially in small farms are very specific to the location and the specific varieties of plants you have. Trimming dates can change by more than a month just be moving a few hundred km. Same with terrain conditions and that could just change from one farm to the next. I&#x27;m not sure if that info can be systematically gathered and distributed without being extremelly complex at the same time. reply Cthulhu_ 53 minutes agoparentIt can, that&#x27;s where plant encyclopedias, botanical information etc come in.Botany is a science, the information is out there. Go to your local library and have a browse.What I don&#x27;t like is how SF techbros seemed to try and high-tech solve a solved problem. I&#x27;ve seen some of my colleagues set up a farmbot... the same job could be done with one person, a couple hours and a trowel. In practice, the building manager would go to the site once a day with a hose to water the plants. reply kevinlinxc 9 hours agoprevMy mom could probably contribute a lot to this, but the need to set up vagrant and git is too high a barrier of entry for a layperson like her. It&#x27;s too bad cuz knowledge sharing in gardening makes a lot of sense, and was probably part of how our civilization came to be reply dmbche 11 hours agoprevSomewhat similar project, for animal care in sanctuaries - very thorough!https:&#x2F;&#x2F;opensanctuary.org&#x2F; reply igetspam 8 hours agoparentI wish I knew about this sooner. I&#x27;m in the board of a sanctuary. This looks great! Thank you! reply dmbche 7 hours agorootparentMy pleasure - I&#x27;ve had great experiences chatting with them through email for things that weren&#x27;t on the site (frostbite treatments in pigs), they really are wonderful! reply dryst 5 hours agoprevCool idea, but the amount of knowledge needed to grow crops successfully doesn&#x27;t really boil down to a &#x27;how to&#x27; format. Are you trying to be organic? Did you get a soil test? What sort of pests are there in your area? How many hours of sun does your plot have?Point being, there are lots of common skills and local knowledge. reply venmul 3 hours agoprevhttps:&#x2F;&#x2F;agritech.tnau.ac.in Gets into more information not update though but relevant reply Gasp0de 2 hours agoprevThe website is down for me, has it been overloaded by the HN crowd? reply froggychairs 5 hours agoprevI’d love something similar for indoor gardening. I have an apartment with great sun exposure but no yard to take advantage of it…. reply kaveh_h 3 hours agoprevThis project could perhaps be adopted by Wikimedia foundation. With a good web ui for contributors to add variants and knowledge which could be stored in the wikidata knowledge graph. reply brookst 5 hours agoprevI want to love it, but it’s weird. Zero guides for lemons or limes, 43 for tomatoes. Zero for Basil, 12 for Thai Basil. reply szundi 4 hours agoparentBe the superhero here and add some guides reply agilob 3 hours agoprevTheir frontpage is terrible. I literally clicked twice on the page and twice got dead links: the survey has finished, the link to https:&#x2F;&#x2F;blog.openfarm.cc&#x2F; has DNS issues. reply logifail 3 hours agoprev [–] \"By posting Content to the Service, you grant us the right and license to use, modify, publicly perform, publicly display, reproduce, and distribute such Content on and through the Service under a CC0 1.0 Public Domain Dedication. You are dedicating all Content you submit, post, or display to the public domain by waiving all of your rights to the work worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law. All others can copy, modify, distribute and perform the work, even for commercial purposes, all without asking for your permission.\"I&#x27;m afraid that last sentence did rather make me choke on my coffee. What is supposed to be the incentive for anyone to contribute to something like this? reply hnarn 3 hours agoparent [–] They are just describing what CC0 means. I really don’t understand the question, what is the “incentive” to contribute to anything? Some people just want to share their knowledge. reply logifail 2 hours agorootparent [–] I&#x27;m not minded to give away my time and effort creating then watch others - especially corporations - enrich themselves from my work.\"Sharing\" is something else. reply dspillett 35 minutes agorootparent [–] The same could be said for just about any “public” database hosted by a commercial interest (or that might later be bought&#x2F;sponsored by one). Using CC0 might seem a bit further reaching than some agreements, because you are giving rights to the users of the resource, not just giving the resource itself the rights it needs (plus some it wants, to be more cynical!) to reproduce your content, but it isn&#x27;t massively different to CC-BY which I&#x27;ve seen used in similar circumstances (the difference being the attribution requirement) or CC-BY-SA as used by the StackExchange family of sites.> I&#x27;m not minded to…Which is fine. But many are happy to contribute without caring about the end use of the information. I generally much prefer something like CC-BY-NC myself, preferably later versions which have addressed the third-party copy-left troll issue, but I don&#x27;t feel using CC0 is deserving of scorn at all. Without any licence explicitly stated, CC0 is pretty much what a lot of people would assume anyway (correctly or otherwise), and in this case a lot of what is being shared is going to be facts, rather than creative works, which are essentially public domain anyway (though I&#x27;m sure some corproates out there are busy lobbying to change that…).No one is forcing contributions. You spend your time, you takes your choice! Of course, you do right by yourself in making sure the licensing terms are to your taste before taking part, and are well advised to do so.> \"Sharing\" is something else.This is sharing, under very open terms. At least they are not claiming ownership, and the rights given are public not just to the site. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenFarm is a new project and community that aims to help gardeners grow food through knowledge sharing.",
      "Members can choose a specific crop, access guides, and learn how to care for their plants during different stages of growth.",
      "The website offers features like a survey to determine a user's gardening type, community favorites, and opportunities for user contributions. Members can also access a FAQ section, a blog, a code of conduct, and stay updated with the email newsletter."
    ],
    "commentSummary": [
      "OpenFarm is a free and open database and web application for gardening knowledge.",
      "The project is not actively maintained but is still being used for crop information management by FarmBot.",
      "The project requires a dependency upgrade and potential maintainers, and there are suggestions for improvements, including using Jekyll or adopting the project under the Wikimedia foundation.",
      "Users have expressed interest and concerns about the project's usefulness, functionality, and licensing."
    ],
    "points": 366,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1692042137
  },
  {
    "id": 37123572,
    "title": "Following pushback, Zoom says it won't use customer data to train AI models",
    "originLink": "https://www.darkreading.com/analytics/following-pushback-zoom-says-it-won-t-use-customer-data-to-train-ai-models",
    "originBody": "The Edge DR Tech Sections Events Resources NEWSLETTER SIGN-UP Announcements REPORT Black Hat USA 2022 Attendee ReportSupply Chain & Cloud Security Risks Are Top of Mind |Analytics 3 MIN READ NEWS Following Pushback, Zoom Says It Won't Use Customer Data to Train AI Models Company's experience highlights the tightrope tech organizations walk when integrating AI into their products and services. Jai Vijayan Contributing Writer, Dark Reading August 14, 2023 Source: Ink Drop via Shutterstock PDF Zoom says it will walk back a recent change to its terms of service that allowed the company to use some customer content to train its machine learning and artificial intelligence models. The move comes after recent criticism on social media from customers who are concerned about the privacy implications of Zoom using data in such a manner. Backing Down on Data Use Plans \"Following feedback, Zoom made the decision to update its Terms of Service to reflect Zoom does not use any of your audio, video, chat, screen sharing, attachments or other communications-like Customer Content (such as poll results, whiteboard and reactions) to train Zoom or third-party artificial intelligence models,\" a spokeswoman said in an emailed statement. \"Zoom has accordingly updated its Terms of Service and product to make this policy clear.\" Zoom's decision — and the reason for it — is sure to add to the growing debate about the privacy and security implications of technology companies using customer data to train AI models. In Zoom's case, the company recently introduced two generative AI features — Zoom IQ Meeting Summary and Zoom IQ Team Chat Compose — that offer AI-powered chat composition and automated meeting summaries. The terms of an updated service policy that the company announced earlier this year gave Zoom the right to use some customer data behind these services for training the AI models — without needing customer consent. Specifically, Zoom's policy gave the company a \"perpetual, worldwide, non-exclusive, royalty-free, sublicensable, and transferable\" right to use customer data for a wide range of purposes including machine learning, artificial intelligence, training, and testing. It also allowed Zoom the unbridled right to do virtually anything with the data including to \"redistribute, publish, import, access, use, store, transmit, disclose\" the data. After customers pushed back on social media Zoom initially revised its policy earlier this month to give customers the right to opt out of having their data used for AI training. \"Zoom will not use audio, video or chat Customer Content to train our artificial intelligence models without your consent,\" the company said. Delicate Balance On August 11, the company again revised its terms of service, this time to scrub virtually all references to the use of artificial intelligence. The newly revised policy still gives Zoom all \"rights, title, and interest\" to a lot of service generated data including telemetry data, product usage data, and diagnostic data. But the company will not user customer content to train AI models. Zoom's experience highlights the delicate balance tech companies must strike between innovation and user trust when integrating AI into their products and services. Numerous technology companies have been using customer data for years to improve user experiences and introduce new features and functions, says Shomron Jacob, head of machine learning at iterate.ai. \"Data is often called the \"new oil\" in the digital age because of its invaluable role in training and refining AI models to improve user experiences, functionalities, and new features,\" Jacob says. \"Companies like Google, Facebook, and Amazon have long used user data to tailor their services and improve their AI algorithms.\" However, given the increasing scrutiny of the privacy, security, and ethical implications surrounding AI, there's a rising expectation for transparency and user consent, he says. While companies will likely continue to use customer data like they have been, there is going to be increased pressure on them to provide clear user opt-outs, to anonymize data and to ensure that personal and sensitive information remain protected. \"Moreover, regulatory frameworks like [the] GDPR in Europe and CCPA in California set data collection and usage standards,\" Jacob says. \"As these regulations become more stringent and widespread, tech companies must navigate the dual challenges of leveraging user data for AI improvements while ensuring strict compliance and safeguarding user trust.\" Keep up with the latest cybersecurity threats, newly-discovered vulnerabilities, data breach information, and emerging trends. Delivered daily or weekly right to your email inbox. Subscribe More Insights White Papers 9 Traits You Need to Succeed as a Cybersecurity Leader The Ultimate Guide to the CISSP More White Papers Webinars Best Practices and Tools for OT and IT Security The Dark Side of AI: Unmasking its Threats and Navigating the Shadows of Cybersecurity in the Digital Age More Webinars Reports How to Use Threat Intelligence to Mitigate Third-Party Risk Concerns Mount Over Ransomware, Zero-Day Bugs, and AI-Enabled Malware More Reports Editors' Choice Windows Defender-Pretender Attack Dismantles Flagship Microsoft EDR Jai Vijayan, Contributing Writer, Dark Reading 'Downfall' Bug in Billions of Intel CPUs Reveals Major Design Flaw Nate Nelson, Contributing Writer, Dark Reading It's Time for Cybersecurity to Talk About Climate Change Tara Seals, Managing Editor, News, Dark Reading OWASP Lead Flags Gaping Hole in Software Supply Chain Security Elizabeth Montalbano, Contributor, Dark Reading Webinars Best Practices and Tools for OT and IT Security The Dark Side of AI: Unmasking its Threats and Navigating the Shadows of Cybersecurity in the Digital Age Where and When Automation Makes Sense For Enterprise Cybersecurity Implementing Zero-Trust With A Remote Workforce Protecting the Database: How to Secure Your Enterprise Data More Webinars Reports How to Use Threat Intelligence to Mitigate Third-Party Risk Concerns Mount Over Ransomware, Zero-Day Bugs, and AI-Enabled Malware Everything You Need to Know About DNS Attacks Successfully Managing Identity in Modern Cloud and Hybrid Environments The Promise and Reality of Cloud Security More Reports White Papers 9 Traits You Need to Succeed as a Cybersecurity Leader The Ultimate Guide to the CISSP Rediscovering Your Identity 2023 Global Future of Cyber Report Cybersecurity in 2023 and beyond: 12 leaders share their forecasts More White Papers Events SecTor - Canada's IT Security Conference Oct 23-26 - Learn More More Events Discover More From Informa Tech Interop InformationWeek Network Computing ITPro Today Data Center Knowledge Black Hat Omdia Working With Us About Us Advertise Reprints Follow Dark Reading On Social Home Cookies Privacy Terms Copyright © 2023 Informa PLC Informa UK Limited is a company registered in England and Wales with company number 1072954 whose registered office is 5 Howick Place, London, SW1P 1WG. About Cookies On This Site We and our partners use cookies to enhance your website experience, learn how our site is used, offer personalised features, measure the effectiveness of our services, and tailor content and ads to your interests while you navigate on the web or interact with us across devices. By clicking \"Continue\" or continuing to browse our site you are agreeing to our and our partners use of cookies. For more information seePrivacy Policy CONTINUE",
    "commentLink": "https://news.ycombinator.com/item?id=37123572",
    "commentBody": "Following pushback, Zoom says it won&#x27;t use customer data to train AI modelsHacker NewspastloginFollowing pushback, Zoom says it won&#x27;t use customer data to train AI models (darkreading.com) 365 points by AaronM 17 hours ago| hidepastfavorite173 comments kepano 16 hours agoIf your data is stored in a database that a company can freely read and access (i.e. not end-to-end encrypted), the company will eventually update their ToS so they can use your data for AI training — the incentives are too strong to resist reply spacebanana7 29 minutes agoparentUnlike consumers, many enterprises really care about data policies. Procurement, compliance, legal and audit teams inside enterprises often have the power to block purchases and contract renewals. Many of those departments actually read ToS too.This makes it difficult for B2B companies like Zoom to use customer data for AI training. reply simonw 15 hours agoparentprevI don&#x27;t think that holds up.Paying customers absolutely HATE the idea of their data being used to train AI models without their permission - this Zoom story is just the latest example of that.Companies that try to do this will get burned. Zoom just got burned really badly, and I personally don&#x27;t think they actually intended to even do this - they just didn&#x27;t make it clear enough that they were NOT going to do it, which sparked a PR nightmare firestorm for them.I think the incentives for companies are very much the other way round: if paying customers hate this, then the incentives are NOT to do it. reply Jeslijar 15 hours agorootparentI promise not to use any of the data I collect about you!Except to improve services (ML training!), Advertising (We&#x27;ll sell your data to advertisers!), and by government order (pick your favorite three letter agency.)Alternatively: They&#x27;ll just use your data anyway and not tell you about it. How is anyone going to prove their data was used as the source? It&#x27;s like all the NDAs people sign when they join a company and they pinky promise not to use it at the next job where they land a big fat raise and promotion... suuure they aren&#x27;t going to take what they&#x27;ve learned and improve upon it to try and get more promotions and raises in the future.It can&#x27;t be stopped. reply josephg 13 hours agorootparent> It can&#x27;t be stopped.Maybe. Maybe not. Hard to tell without trying.I applaud the EU and California for giving it a go with their data protection laws. I really hope their crackdown on this stuff is effective. reply sublinear 12 hours agorootparentprev> It&#x27;s like all the NDAs people sign when they join a company and they pinky promise not to use it at the next job where they land a big fat raise and promotionUh no. An NDA would cover proprietary intellectual property, not tools everyone else also uses. Unless you&#x27;re now working for the previous employer&#x27;s competitor, it&#x27;s unlikely that proprietary tech would ever be used. Working for competitors and partners is usually also forbidden for some period of time after leaving. reply alanfranz 11 hours agorootparentprev> How is anyone going to prove their data was used as the source?1) whistleblowing 2) compliance audits (think soc2) reply kepano 14 hours agorootparentprevI hope you are right but I fear it will become a process of boiling the frog. Companies that are in the business of renting access to your data will get increasingly clever at moving in this direction in small incremental steps, providing some user benefit along the way.We can agree that Zoom did a terrible job of rolling out their new terms, regardless of what their intention was. What other companies will learn from this is to improve the roll out.Once local&#x2F;private inference becomes more viable, there will be even more of an incentive for the companies who store unencrypted data to use it as a competitive advantage. reply uhryks 5 hours agorootparentThis. I wouldn&#x27;t be surprised if people give up after a while of searching and migrating to alternatives to each service that started using or selling data for AI training. reply account42 2 hours agorootparentprev> Paying customers absolutely HATE the idea of their data being used to train AI models without their permissionPaying customers will be the ones to resist for the longest maybe but that frog too will be boiled eventually. reply Nostromos 14 hours agorootparentprevehhhh I think some customers would be ok with it if it meant discounts. If your software is good enough, you can tell customers to go elsewhere. The theory is that AI done well can be incredibly powerful ($$$) so you have to build it or risk being left behind. reply simonw 12 hours agorootparentSure, consumers are likely to say yes to that - but I&#x27;m talking about companies here who are much more sensitive to what happens to their data. reply rsynnott 15 hours agoparentprevI mean, if they have a bunch of enterprise customers there’s a fairly strong disincentive; any sensible corporate customer, if they did this, would presumably say, right, cool, MS Teams time. reply esperent 12 hours agorootparentI&#x27;m having trouble parsing your comment. Are you saying MS Teams is more or less likely to use your data to train AI?I&#x27;m assuming it&#x27;s safe because they make a big deal about compliance. But on the other hand MS have a huge incentive to obtain data for AI since they are going all in on it. reply rsynnott 9 hours agorootparentMicrosoft is unlikely to _secretly_ do it, certainly; they would be sued into oblivion, and that’s before the EC gets to them (for GDPR enforcement grinds slow but exceeding fine, and also with exceedingly big fines). US regulators might also take an interest.Also, modern Microsoft’s _whole thing_, more or less, is “we are your trusted enterprise partner who definitely won’t do bad stuff with the data you put in our cloud services”. They are unlikely to throw that away for a bit of flavour-of-the-month AI boosterism. Note that they’ve recently released a private ChatGPT thing; they can’t credibly acknowledge the problem with one hand and exploit it with the other. reply seltzered_ 14 hours agoparentprevSounds almost reminiscent of Jamie Zawinski&#x27;s Law of Software Envelopment: \"Every program attempts to expand until it can read mail. Those programs which cannot so expand are replaced by ones which can.\" reply josephg 13 hours agorootparentHuh? Barely any programs on my computer can read mail. That’s a silly law. reply esperent 12 hours agorootparentIt&#x27;s probably outdated. A modern version might be \"every program expands until it becomes a platform with instant messaging capabilities and an app store...\" reply _Algernon_ 14 hours agoparentprevLegislation should step in to forbid applying new or changed ToS to data collected before that ToS was explicitly accepted by a user. Would be a PITA for the business (as they now have to track under what ToS version each piece of data is stored under), but hopefully enough of a PITA to make them treat that data as the liability it ought to be. reply stubish 9 hours agoparentprevI think most user data will be completely useless for AI training. No context, no quality control. Even assuming wisdom of crowds and on average you get the correct answer, you are training an AI to give a mediocre response. Back in the days of Big Data hype, many companies decided to store everything because data was valuable. But in most cases it wasn&#x27;t worth the cost of the hard drives, because it only has value if there is a buyer willing to pay the cost of making use of it. There is a lot of data out there, but it is information and knowledge that has value. reply damnesian 15 hours agoparentprevOur enterprise issued an ultimatum recently requiring no software outside of our MS contract. Which is going to be severely limiting, but painfully doable. This move really seems to be in reaction to the Zoom debacle.Now we&#x27;ll be forced to use Teams for online trainings after pretty much universally using Zoom since the pandemic. Our customers are gonna love that.It&#x27;s above my pay grade but I wonder if we&#x27;ve already signed our data over to MS for a certain price, with that stipulation. reply blibble 14 hours agoparentprevno need to even update the ToSjust call it \"fair use\", like OpenAI and GitHub reply wredue 14 hours agorootparentYeah. And then regulars will argue for you that changing identifiers but otherwise copy and pasting code is perfectly cool fair use regardless of your codes licensing (I do not license any of my code for free corporate use, for example, but apparently, as long as chat GPT outputs the exact copy and paste of my code with a few things slightly changed, it’s cool). reply neltnerb 11 hours agorootparentprevI mean, around now would be a fairly convenient time for giant companies to change their mind about copyright. After all, that creative commons drawing and GPL code are only protected because of copyright, correct? reply confoundcofound 15 hours agoparentprevYep. The initial decision was certainly driven by many stakeholders who deeply believe this is a key advantage to acquire. Users are fighting an uphill battle, and no amount of pushback short of lost revenue will stop them. They&#x27;ll find another way. reply karaterobot 15 hours agoparentprevYeah, I think it&#x27;s safe to assume this. One time as a contractor, I was working on a GIS-enabled game for some company. Their privacy policy was very clear that they will not use or sell your data for any reason. It was even on their home page, because it was a key selling point. By the time I was involved with this app, the money was running out, and I vividly remember being in a meeting with the leadership where they were enumerating their options, one of which was to find someone to buy all this user data they&#x27;d collected. Their commitment to privacy disappeared the instant it was tested. Ever since then, I just assume this is how every company works. No matter what they say, they&#x27;re selling your data. reply crazygringo 14 hours agorootparentThis suggests that we require an explicit law that forbids changes in ToS from ever apply to data collected retroactively. With a real monetary punitive incentive that allows users to sue.I absolutely believe that companies should have the freedom to change their ToS moving forwards, and that \"promises\" to \"never\" change a ToS are worthless (your example is a perfect reason why).BUT, I simply don&#x27;t see how it could ever be fair to use data retroactively. If you change your ToS, you should only get to monetize new user data going forwards. It seems like a basic legal principle.Is there any existing law&#x2F;precedent that suggests this is already the case, i.e. that such a company can be successfully sued but that people don&#x27;t usually try? Or do we need new laws around this, and are there any government reps pushing for this? reply Nostromos 14 hours agorootparentSounds good in principle because you&#x27;re worked up and mad about your data (which is the correct reaction).I just don&#x27;t love the idea that my dinky little app has to ask every customer every time I add a new feature significant enough (debatable) or different enough (debatable) that uses their data in a way either I or they didn&#x27;t anticipate (debatable). God forbid I try to monetize it (debatable). &#x27;Control over your data&#x27; is meaningless in our current paradigm and I&#x27;ll rue the day something like GDPR comes to the US in a meaningful way. No wonder the EU can&#x27;t build.As for this specific article, Zoom&#x27;s (rightfully) getting heat for this but I don&#x27;t blame them or any company for exploring how they can monetize every last morsel of data. In zoom&#x27;s case (and many enterprise software companies), customers are paying a shit load of money and they didn&#x27;t sign a contract and consent to give data for training an LLM. reply JohnFen 14 hours agorootparent> I don&#x27;t blame them or any company for exploring how they can monetize every last morsel of data.I absolutely do, if it&#x27;s customer data that the company previously promised not to monetize. It&#x27;s not their data to do with as they please, after all.But the tech sector has fallen very far in terms of ethics so no company can be trusted. It&#x27;s just a shame. The public views our industry in a very, very poor light and that view is 100% earned. reply gspencley 13 hours agorootparentprevIANAL but it seems to me that this \"law\" already exists.A TOS is a contract. It literally stands for \"Terms of Service.\" Meaning, you give me money and here are the terms under which I will offer you the service you are paying for. How enforceable that \"contract\" is depends on a ton of things, differing in various jurisdictions (law is complicated), but it is - at the end of the day - a contract.So I don&#x27;t know how actionable it is, but the OP said that the company considered changing their TOS for currently active users. That could, in theory, be breach of contract and the customers might have a claim (again IANAL).[There could have also been a clause in the TOS saying that they could change the terms at any time for any reason - though I suspect in many if not most jurisdictions, that would make the entire contract unenforceable].In your case, don&#x27;t make [potentially] contractually binding promises that you can&#x27;t or don&#x27;t want to keep. reply palata 13 hours agorootparentprev> No wonder the EU can&#x27;t build.That was unnecessary.> I don&#x27;t blame them or any company for exploring how they can monetize every last morsel of data.That&#x27;s how a company works: try to do everything they legally can to make as much money as they can. Society has to decide of the framework into which companies optimize, and that is materialized with laws that the companies must follow. In the EU, there is a tendency to believe that users have a right to some kind of privacy.Of course, this constrains what companies can do, and you could say \"no wonder the EU can&#x27;t build\". I just call that cultural differences. In most countries in the EU, people don&#x27;t have to start a crowdfunding campaign when they go to the hospital, because they actually have some kind of social security. I am all for GDPR. reply josephg 13 hours agorootparent> That&#x27;s how a company works: try to do everything they legally can to make as much money as they can.No, companies don’t need to be like that. This is a meme that needs to die. Companies can have a set of values (principles) and act according to those principles. Any investors can be told ahead of time the principles by which the company operates, and if they don’t want to buy stock on that basis, they’re welcome to stay out.Bryan Cantrill has had some excellent rants about this over the years. Eg: https:&#x2F;&#x2F;youtu.be&#x2F;bNfAAQUQ_54 . His take is that money for a company is like fuel in a car. You don’t go for a road trip (start a company) because you want to get more fuel. You go because there’s some place you want to get to. And fuel (money) is something you need along the way to make your journey possible.Don’t let sociopathic assholes off the hook. They aren’t forced to be like that. They’re choosing to abandon their ethics and common decency. Everyone would be better off if this sort of behaviour wasn’t tolerated. reply palata 11 hours agorootparent> No, companies don’t need to be like that.Well, they don&#x27;t need to. But the people at the top make more money if they are. And they are not at the top because they have principles: they are at the top because they want power or money.> Companies can have a set of values (principles) and act according to those principles.I would love it, but I just can&#x27;t buy it. Like at all. How many big companies do you know where the executives don&#x27;t get a much higher salary than the employees? Humans can&#x27;t help it: if they are in a position of power, they will think they are worth more.> Any investors can be told ahead of time the principlesIMO, if you have principles, you are not an investor. And investors want to get ROI, which is more likely from companies that don&#x27;t have principles.> His take is that money for a company is like fuel in a car.Sounds exceedingly naive to me :-). The driver does not get fuel at the end of every month.> Everyone would be better off if this sort of behaviour wasn’t tolerated.Yes. We need laws, set by the society. We need the people to understand that they will never be one of those rich executives, and to vote for laws that prevent them to become indecently rich. reply crazygringo 13 hours agorootparentprevBut your app doesn&#x27;t have to do that.The TOS are generally broad enough from the start that you can do anything you want with user data as is necessary to provide product features. Nobody&#x27;s updating TOS every time they add a new feature.Realistically, this is specifically about situations around selling data to third parties, and&#x2F;or training for AI that is not related to product features. (There&#x27;s a big difference between Zoom using chats for building LLM&#x27;s, versus Google training on Gmail messages to build Gmail autocomplete.) reply plagiarist 12 hours agorootparentprevYou don&#x27;t need to ask about adding features, just put in the ToS that the data will be used for app features and metrics for improving user experience.Monetization by adding paid features falls well within those boundaries. Monetization by selling user data to whomever will buy it does not.I&#x27;d really love to have a GDPR specifically for people like you who feel entitled to do whatever they want with collected data. I&#x27;d love to have had it when reddit decided to charge outrageous prices for the API. reply fhd2 15 hours agorootparentprevThat&#x27;s a fair assumption in my experience from running companies. I&#x27;ve seen management with ethics, but even then, eventually new people are in charge, shares (or the whole thing) get sold... That&#x27;s what contracts are for, commitments from a company are commitments from people that might not be around very long. reply voakbasda 15 hours agorootparentMost EULA contracts have a clause that expressly permits the company to abandon their obligations upon sale of the business or other such events. However, that seems somewhat redundant, since these same contracts also assert that they can modify the terms whenever they want. For the average user, there&#x27;s little to no recourse when the original contract gets violated. reply ronsor 13 hours agorootparentCourts seriously need to crack down on these EULAs reply msla 15 hours agoparentprevOr they&#x27;ll do it without updating the ToS. Nothing&#x27;s stopping them.Adults realize other adults do what benefits them. reply IshKebab 15 hours agorootparentThe GDPR is stopping them. reply palata 13 hours agorootparentBut is it even enforced? Take software licenses. Most software out there uses open-source licensed dependencies. Even the permissive licenses require attribution.But most software does not honor those licenses, and nobody cares. Enforcing such a law takes money.I guess at least the GDPR can be enforced, to some extent, with Big Data. It seems like the fines are usually ridiculously low (they don&#x27;t seem like an intensive for the company to change anything), but that&#x27;s better than nothing. reply sandworm101 16 hours agoparentprevThen it is time to take control by seeing such databases with false information. We could probably design data specifically to attract an AI system looking for well-documented data. I wonder how images of Steven Colbert uploaded to imgur it would take to convince the AI that he actually was. reply nwoli 15 hours agorootparentI don’t think this is a possible approach. It would basically mean needing to feed in so much noise that a human wouldn’t be able discern reality from fiction given no priors. Modern ML is too smart reply sandworm101 14 hours agorootparentThat&#x27;s why I said president of canada. A non-intelligent AI would not find any priors indicating who was the president. There isn&#x27;t one. So a few thousand images in the database, against zero information to the contrary, might be enough. reply BiteCode_dev 15 hours agorootparentprevAKA encryption. reply proser 15 hours agorootparentprevGiven how easy it is to keep an average human from discerning reality (see the last decade of boomers&#x2F;gen xers on Facebook as an example) and the massive potential to create slight variations with LLMs, I don&#x27;t think a Stephenson-style misinformation propagation campaign is that far outside the bounds of possibility.That&#x27;s a lot of compute power to waste on it, but I would guess that that&#x27;s what bot networks are going to be used for in the future (or already are, right now, if they&#x27;re done mining bitcoin). reply brucethemoose2 16 hours agoprevZoom is just disappointed the ToS change went viral, and that their reputation is privacy friendly enough for that to even matter.I wonder if Teams would face similar uproar, assuming that bit isn&#x27;t already in the ToS. reply JohnFen 16 hours agoparent> I wonder if Teams would face similar uproar,Maybe, but Teams is very good at ignoring uproars. While I assume that there are people who feel differently, everybody I know already loathes Teams and only uses it when their employer forces them to anyway. reply codeflo 16 hours agorootparentWhile that’s true, isn’t part of that due to Microsoft having enterprise-friendly licensing nailed down? I’d think that doing the equivalent of industrial espionage would remove Microsoft’s offerings from some industries extremely fast. (Corporate legal departments do read licensing terms!) reply mlinhares 14 hours agorootparentIf by \"enterprise-friendly licensing nailed down\" you mean \"it&#x27;s free if you buy something else\".People use it only because someone up the chain sees it&#x27;s included in Office and they&#x27;re like \"we&#x27;re not paying for something else if we get this for free\". I hope Slack and others bring MS to court to stop this, this is exactly what happened during the browser wars. reply bradley13 16 hours agorootparentprevI use Teams a lot, because it is (here, at least) pretty much the only such app that everyone knows. Meeting across groups or companies? Teams.Aside from the usual (and understandable) MS hate, I don&#x27;t see the problem. Features and performance? Nothing else is better, most are worse. Cisco is a mess, Skype is horrible, Zoom lies about their security, etc, etc reply JohnFen 16 hours agorootparent> Nothing else is better, most are worse.Well, we have very different experiences with Teams. It&#x27;s perhaps not the worst, but I think it&#x27;s pretty bad in the sense that it&#x27;s painful to use and gets in my way. reply walthamstow 16 hours agorootparentprevGoogle Meet took a battering in the original Zoom TOS thread but it&#x27;s the main video call software at my current job and I don&#x27;t mind it. Teams and Zoom both completely suck. Meet is kind of just fine? reply mrguyorama 16 hours agorootparentTeams is a mediocre chat app, but that&#x27;s the status quo in the industry. It&#x27;s pretty good at video calls reply jacobr1 15 hours agorootparentprevSlack is pretty good, and their new video huddles handle the use case of internal meetings very well. reply chefandy 16 hours agorootparentprevYeah— the scale of uproar MS would need to budge on something that affects their core business goals probably dwarfs the number of teams users aware enough to care by 100 to 1. reply mrguyorama 16 hours agorootparentThe only thing that would get O365 out of companies would be if Microsoft started having a Hunger Games for CEOs reply chefandy 15 hours agorootparentAnd now that Balmer is gone, MS Sustenance Pro Executive Marketplace Edition will never get internal traction. reply costcofries 16 hours agoparentprevTeams will use your O365 enterprise data to power it&#x27;s AI &#x27;copilot&#x27; offering, it&#x27;s literally what its customers are asking for. reply bongoman37 16 hours agoparentprevMicrosoft culturally is extremely averse to using customer data for doing these kind of things. I was once talking to a Microsoft exec and he said that once the idea of using contextual ads in Hotmail was brought up (similar to Gmail), and it was shot down hard. The idea of using customer data (even non-paying ones) in this fashion was anathema. Microsoft makes its money from massive enterprise contracts which might be threatened by someone using your data to benefit your competitor in any way. reply dgb23 15 hours agorootparentGitHub is owned by MS? reply rolph 15 hours agorootparentsince 2018https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GitHubhttps:&#x2F;&#x2F;fourweekmba.com&#x2F;who-owns-github&#x2F; reply JohnFen 14 hours agorootparentprevThis. It throws the idea that MS is extremely averse to using customer data for these sorts of things into great doubt, doesn&#x27;t it? reply dang 14 hours agoprevRelated:Zoom&#x27;s TOS Permit Training AI on User Content Without Opt-Out - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37038494 - Aug 2023 (35 comments)How Zoom’s terms of service and practices apply to AI features - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37037196 - Aug 2023 (177 comments)Ask HN: Zoom alternatives which preserve privacy and are easy to use? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37035248 - Aug 2023 (16 comments)Not Using Zoom - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37034145 - Aug 2023 (194 comments)Zoom terms now allow training AI on user content with no opt out - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37021160 - Aug 2023 (510 comments) reply mlsu 15 hours agoprevZoom definitely has several AI models (as does teams, google chat, etc.)They do automatic captioning&#x2F;transcription of meetings, so there is a model for that; they do automatic background blur&#x2F;cutout, so there is a model for that; they are probably working on a \"meeting summarization\" product for that.Those are features that people love and use all the time. I would be curious to know how anyone expects Zoom to improve on these features without collecting data from real users on the platform. reply JohnFen 14 hours agoparentThe real issue isn&#x27;t that they may use customer data for these things. It&#x27;s that they may use customer data without getting consent first. reply tornato7 16 hours agoprevToo late, it took me an hour to spin up a self-hosted Jitsi instance and I have no reason to switch back. reply rabbitofdeath 16 hours agoparentThis. I saw the post and had a mildly customized Jitsi running on my docker host on Hetzner within 2 hours. I&#x27;m amazed at the performance and stability of the Jitsi. reply itake 16 hours agoparentprevWhat do you host jitsi on? reply tornato7 10 hours agorootparentA NUC in my garage reply screamingninja 13 hours agoparentprevAny insights or lessons learned would be greatly helpful. Several people I know, myself included, are about to go down this route. reply tornato7 10 hours agorootparentI used the Docker instructions on their website. Just follow it very closely and make sure the right ports are opened. Then work on configuring it. You can adjust the video quality up to 1440p in the config.js - this quality blows away Zoom. reply amilich 15 hours agoprevHave been working on a list of AI companies that train on user data: https:&#x2F;&#x2F;github.com&#x2F;skiff-org&#x2F;skiff-org.github.io&#x2F;blob&#x2F;main&#x2F;b.... Will update the Zoom section but still suspect. reply nerdponx 15 hours agoparentWhat differentiates \"AI\" from \"ML\" or other predictive modeling that finds its way into an application? I fit a regression on some customer data last week, am I training an AI on customer data? Is it a matter of intent? Of being public-facing? Of being specifically a generative model? reply simsla 8 hours agorootparentFor me, the main issue is the potential of POI&#x2F;confidential information being leaked.I think it&#x27;s fine using \"usage data\", but the contents of a private conversation should be considered to be... private.LLMs and generative image models have shown the ability to leak&#x2F;reproduce training data. That&#x27;s a big deal. reply amilich 8 hours agorootparentprevThe original thinking was generative. That is a good distinction to add. I do think regression&#x2F;analysis doesn&#x27;t have many of the same issues, ex. no one would have an issue if Zoom said \"we&#x27;re going to analyze how many minutes users spend on Zoom by time of day\" reply nwoli 15 hours agoparentprevThey obviously do statistical analysis of user data still which I’d argue is in the “AI on user data” bucket. So no I don’t think that applies reply lazzlazzlazz 16 hours agoprevDoes Zoom store video or audio data from calls? This is really the key question. If anything is stored, they can&#x27;t be trusted. reply avrionov 15 hours agoparentIf you record your video call, Zoom will store it for you. Otherwise, it shouldn&#x27;t be stored. Also if video streaming protocol like HLS or MPEG-DASH is used, this will store the stream in video chunks, which are deleted later. reply quijoteuniv 16 hours agoprevIs again disappointing that big companies just try to push this policies in the hope they will go unnoticed. What kind of person think this is ok? Is just a money grabbing exec? We need to be better than this reply scoofy 13 hours agoprevSo what&#x27;s the deal with something like employers requiring use of this. Is there any limit to what terms you must agree to to be employed somewhere?It seems pretty weird that if your office used Zoom, that you would need to agree to all these terms that aren&#x27;t part of your employment contract to actually be employed. reply jkaplowitz 13 hours agoparentUnder US law, there aren’t many relevant governmentally imposed limits on this kind of thing, no. This would be a case either for collective bargaining (unionism) regarding this aspect of working conditions, or for advocating some of the worker rights that have been legislatively recognized in regions like Europe. reply johncessna 16 hours agoprev\"Following Pushback, Zoom Says It Won&#x27;t Use Customer Data to Train AI Models\"Yet... reply bhhaskin 16 hours agoprevHow can they do training in the first place if everything is E2E...? reply JonChesterfield 16 hours agoparentEither machine learning is so good it can pick details out of an encrypted stream or the company is using end-to-end to mean end-to-middle-to-end where company records everything in the middle.One of those explanations seems much more likely than the other to everyone, but curiously I think some people will disagree about which side is implausible. reply giantrobot 15 hours agorootparentThey can have E2E and have a secret participant in meetings recording anything. So while technically E2E they can have access to whatever meetings they want. reply marcosdumay 15 hours agorootparentIt&#x27;s E2E, but one of the ends is on the middleman.That&#x27;s a new fun and exciting definition of E2E a lot of people are pushing. reply screamingninja 13 hours agorootparentTranslation: not E2E reply greiskul 15 hours agoparentprevIt&#x27;s not. You have to turn E2E on: https:&#x2F;&#x2F;support.zoom.us&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360048660871-End-t... reply barathr 16 hours agoparentprevI see lots of comments about the meaning of end-to-end encryption but less about what actually happens here.Zoom, like Meet, Teams, WebEx, and many others to my knowledge is \"encrypted\" but not by default \"end-to-end encrypted\" in the normal meaning of the term. (Some of these have options for E2EE but it&#x27;s buried in the service configs and not easy to enable.) So they can and do see audio and video on their servers (as can anyone who breaches their infrastructure) by design. The encryption in this default mode only prevents your ISP from seeing the content of the call.As a distinction, Signal calls are E2EE -- Signal doesn&#x27;t see unencrypted video&#x2F;audio for calls, even ones that are relayed through Signal servers. And even in that case, Signal still knows the participants of the call, just not what is being said.(As a side note, this is why we built Booth.video -- to demo that this isn&#x27;t a fundamental tradeoff and it&#x27;s possible to have E2EE, metadata-secure video conferencing in the browser.) reply greiskul 16 hours agorootparentYup, Signal is the industry standard into getting actual privacy. But one player that deserves a shoutout when it comes to privacy, is Whatsapp. Even after becoming a Facebook company, it has kept E2EE, for messagings, group chats, and calls. And they do so by using the library that the greak folks from Signal put out. reply sundarurfriend 14 hours agorootparent> Even after becoming a Facebook company, it has kept E2EE, for messagings, group chats, and calls.According to their own claims, right? There&#x27;s no way for anyone to verify that they&#x27;re actually E2EE, just Meta&#x27;s word that it is so. reply facu17y 15 hours agorootparentprevExcept Signal&#x27;s founder probably has&#x2F;had a connection with the NSA. All security is for making it hard for the common attacker, and hostile countries. The NSA, most likely, has social engineered its way into every stack and every important org. reply reciprocity 15 hours agorootparentWhat? Where did you get that from? reply mercora 15 hours agorootparentprev>As a side note, this is why we built Booth.video -- to demo that this isn&#x27;t a fundamental tradeoff and it&#x27;s possible to have E2EE, metadata-secure video conferencing in the browser.now i wonder how you did that. Is the key exchange of participants happening out of band? reply barathr 14 hours agorootparenthttps:&#x2F;&#x2F;invisv.com&#x2F;articles&#x2F;booth reply mercora 14 hours agorootparenti think it cleared a thing up or two. However, would you mind sharing why insertable streams are apparently required for this to work? As WebRTC traffic is encrypted already E2E it seems to me that constructing the SDP with the key, currently used here with insertable streams, would be good enough. reply barathr 12 hours agorootparentSure. So WebRTC is encrypted between peers when 100% of the communication is going peer to peer. But in most WebRTC services, your peer is actually the SFU, which is the server. So you&#x27;re encrypting to the server, not to the other participants. (Most \"pure\" WebRTC platforms switch over to SFU-based communications at 4 or more participants, but many of the bigger platforms always send video&#x2F;audio through the SFU regardless of how many participants there are.) replyavrionov 15 hours agoparentprevNot all meetings are e2e encrypted, because encryption disables tons of features, like cloud recordings, apps, etc. reply remote_phone 16 hours agoparentprevWhat is zoom’s definition of End-to-end? reply greiskul 15 hours agorootparentThe standard industry definition. It&#x27;s just that not everything is E2EE, you have to turn it on: https:&#x2F;&#x2F;support.zoom.us&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360048660871-End-t... reply cced 16 hours agoparentprevE2E means everything between two ends is encrypted. Once it gets on their end, they can do what they please. reply bhhaskin 16 hours agorootparentThat&#x27;s not what E2E means at all. E2E means only the parties communicating can decrypt the data i.e. the sender and the receiver. Anything short of that isn&#x27;t E2E.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;End-to-end_encryption reply cced 15 hours agorootparent> That&#x27;s not what E2E means at all.It’s kind if what it means? OP’s question is w.r.t to the receiving party’s ability to consume the data. The point that’s being made is that E2E doesn’t mean encrypted at rest and receiver can’t consume the data.I see a lot of comments nitting on the wording for a lack of specificity but, IMO, OP’s question was more about understanding what goes on at the two ends of the pipe. The point being made is that the recipient can still chose to do whatever it is they want with the content. reply bhhaskin 6 hours agorootparentI am the op? E2E dose mean that only the sender and receiver has the keys. You can&#x27;t redefine what E2E is. reply wahnfrieden 16 hours agorootparentprevit&#x27;s what it means when zoom says they have E2E. it is a deception. reply bhhaskin 16 hours agorootparentI agree with you, but to be honest I don&#x27;t care what zoom says. I am not going to let them redefine something so it suits them. Might as well call it potato encryption. reply waithuh 16 hours agorootparentYeah, that explanation is just TLS. reply mercora 16 hours agorootparentprevE2EE implies both ends have an encrypted channel to transport data to each other directly, without an intermediary step. this is the very definition of the term, at least it is in my mind. Having the data only encrypted to and from their servers would merely be transport layer encryption. Although i have no idea whether they implement one, the other or both.In context of video conferencing software (WebRTC specifically) this is actually somewhat interesting, because typically the signaling server is the one who hands out the public key of the other peer and needs to be trusted, so they could by all means deliver public keys to which they posses the keys for decryption and it therefore would allow them to play man in the middle in a typically relayed call. So even if E2EE is implemented, it might be done poorly without figuring out how to establish trust independently. reply greiskul 15 hours agorootparentYeah, the key delivery is the hardest part if you are privacy focused. Signal and Whatsapp have a screen, where you can generate a QR code, and use that to verify that you and your contact have exchanged keys without a man in the middle attack. reply mercora 15 hours agorootparentI wish browser would do something similar with their WebRTC stack. Something that shows independently of the site (out of its execution context) which keys are used and allow for an easy comparison of them independently. But i don&#x27;t know of such functionality being there yet. reply paulirwin 16 hours agorootparentprevFor some definition of \"end.\" Semantically, E2E encryption should mean encrypted end-to-end between you and the person you&#x27;re calling, without Zoom having the key or ability to decrypt it. For example, this is Signal&#x27;s definition of E2E encryption. reply PeterisP 16 hours agorootparentprevYes, E2E means everything between two ends is securely encrypted, but there is no \"their end\" between participants in a Zoom call, the Zoom company isn&#x27;t an \"end\" in this conversation. If someone like them between the speaker and the listener can decode the data, that&#x27;s not E2E. reply traek 16 hours agorootparentprevThis isn’t what E2E means for communication software. E2E means only the participants have the keys. Signal is a good example of this, the message is encrypted from the sender to the receiver and Signal themselves cannot decrypt it.Separately, most Zoom meetings are not E2EE. That’s why features like live transcription work. reply JonChesterfield 16 hours agorootparentOnly the participants do have the keys. You, the other people on the meeting, the company running Zoom, at least one government. It&#x27;s still usefully encrypted to stop (at least some) other companies&#x2F;countries benefiting from the information.I think zoom probably have a defence against the fraud accusation that no reasonable person would believe end to end encrypted meant zoom doesn&#x27;t have the data as that&#x27;s the whole point of the service existing. reply greiskul 15 hours agorootparentZoom has not committed any fraud. They clearly state that by default their meetings are encrypted, but not end to end encrypted. And that you can turn on end to end encryption, but that it causes a bunch of features to be disabled. I think this is a great balance between being able to add features that are impossible with E2EE, but allowing privacy concious users to choose if they need stronger encryption.https:&#x2F;&#x2F;support.zoom.us&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360048660871-End-t... reply ghkbrew 16 hours agorootparentpreve2e means&#x2F;implies that only the endpoints (i.e. the users) get to see the unencrypted signal. If Zoom truely uses e2e encryption no trainable data would exist on their servers. Of course, they control the endpoint software too so they could make it do whatever they want realistically. reply rolph 15 hours agoprevi see nothing indicating collection of data wont happen.i see nothing indicating data wont be provided to third parties.i see nothing indicating third parties will be prevented from using aquired data to train AIi see nothing indicating zoom will not aquire trained models from third parties that use Zoom harvested data in training. reply ChrisArchitect 16 hours agoprevWhere did Zoom say this? There&#x27;s no link to like a blog post or social post or something? reply ChrisArchitect 16 hours agoparentAh, they updated the previous blog post (https:&#x2F;&#x2F;blog.zoom.us&#x2F;zooms-term-service-ai&#x2F;):Editor’s note: This blog post was edited on August 11, 2023, to include the most up-to-date information on our terms of service. Following feedback received regarding Zoom’s recently updated terms of service Zoom has updated our terms of service and the below blog post to make it clear that Zoom does not use any of your audio, video, chat, screen sharing, attachments, or other communications like customer content (such as poll results, whiteboard, and reactions) to train Zoom’s or third-party artificial intelligence models.It’s important to us at Zoom to empower our customers with innovative and secure communication solutions. We’ve updated our terms of service (in section 10) to further confirm that Zoom does not use any of your audio, video, chat, screen-sharing, attachments, or other communications like customer content (such as poll results, whiteboard, and reactions) to train Zoom’s or third-party artificial intelligence models. In addition, we have updated our in-product notices to reflect this. reply ChrisArchitect 16 hours agorootparentEither way this is old news from days ago also, posted in various forms reply dylan604 15 hours agorootparentwow, you just did a whole thing there by yourself reply Sunspark 16 hours agoprevWhy should I believe that they&#x27;re telling the truth? What&#x27;s to stop any unethical company from doing it anyway, and not telling anyone?There is no such thing as a training model auditor. reply gaogao 16 hours agoparentTheir consent order with the FTC also contains a prohibition against privacy misrepresentations, so it would probably get audited during their biennial assessments. For some unethical company that doesn&#x27;t get regularly audited, yeah they&#x27;d probably get away with it unless it got leaked.> Finally, the company must obtain biennial assessments of its security program by an independent third party, which the FTC has authority to approve, and notify the Commission if it experiences a data breach.https:&#x2F;&#x2F;www.ftc.gov&#x2F;news-events&#x2F;news&#x2F;press-releases&#x2F;2020&#x2F;11&#x2F;... reply consumer451 15 hours agorootparent> 22 years after the $63 billion Enron collapse, a key audit review board finds the industry in a ‘completely unacceptable’ statehttps:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;07&#x2F;26&#x2F;pcaob-audit-completely-unnacc... reply dylan604 15 hours agorootparentprev>probably get audited during their biennial assessmentsa lot of things can happen in 2 years though reply msla 15 hours agorootparentprevThe FTC probably can&#x27;t fine them enough to make the training unprofitable. reply esafak 15 hours agorootparentCan&#x27;t they? How much can they fine then? reply neon_electro 15 hours agorootparentMight me more of a \"they won&#x27;t\" rather than a \"they can&#x27;t\", regulatory capture and all. reply TheIronMark 16 hours agoparentprevYou could say that about most ToS bits. A lot of them are hard to prove. This at least provides a potential legal remedy in the event that a) they are lying and b) we are able to determine that.It&#x27;s better than nothing (assuming you&#x27;re still using Zoom). reply jacobr1 16 hours agorootparentAt a certain point, you need some basic level trust do business with anybody. Regardless of what the ToS say, the company could do anything with the data. Even supposed E2E encryption has often been found to be either not really be encrypted, or unintentionally vulnerable.Our whole system is based on assuming a degree of trust, based on both social norms and reputation of prior interaction, with a confidence of remedy in the case of a failure. If we really had to have much stronger confidence up-front in commercial interactions there would be a lot more friction and overhead in every transaction. Dealing with the occasional fraud seems like a better tradeoff. reply consumer451 16 hours agoparentprevThe upside is too high to trust them, leaving aside any geopolitical stuff, it&#x27;s just a juicy business.New Zoom Subscription Tier:Virtual agent with perfectly fine tuned domain-specific knowledge performs 99% as well as your sales&#x2F;support person.24&#x2F;7&#x2F;365$400 per month reply lq9AJ8yrfs 16 hours agoparentprevThere are model risk analysis services among big-4 and boutique firms, and these fit into conventional audit processes as domain-experts. Similar services be bought apart from audit services as risk consulting from the same firms or alternately the familiar names in management consulting. reply rsynnott 15 hours agoparentprevThe danger of massive fines in Europe and being sued absolutely everywhere, I’d assume. reply f1shy 16 hours agoparentprevYou just shouldn’t! reply 1-6 15 hours agoprevStreaming Data vs Batch Data.You can&#x27;t expect to train AI models without some sort of storage mechanism to train on. If they made a &#x27;ninja edit&#x27; to their TOS, does this mean they&#x27;ve also backtracked on their data collection? reply theptip 15 hours agoparentIs this actually true? Can’t you do online training in real-time, at least in principle? As audio comes in, for a micro batch of current calls on the local node, do STT, next token prediction, and calculate your loss. Transmit the loss update back to the centralized model.Google posted about Federated Learning years ago: https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2017&#x2F;04&#x2F;federated-learning-collabo..., not sure how widely it has caught on though. reply shaunxcode 16 hours agoprev\"Says\" is doing a LOT of work there. reply isykt 16 hours agoprevThe pushback must be constant, or they will wear us down. reply tpoacher 15 hours agoprevTo be clear, I dont mind zoom using data from their service to train \"their AI models\", particularly where these are transparent and specific.I was more concerned about the wording, which implied they would give themselves the right to use the data to train \"AI models\" more generally.I have few problems with them building a better noise cancelling solution for their platform, but lots of problems with them selling it for improving third party surveillance and fingerprinting. reply theptip 15 hours agoparentIf you discuss proprietary information you should be very concerned about Zoom training their models on that. Especially when they pivot into generative AI (which is the obvious use case if you have that much conversation data flowing through your system).LLMs can regurgitate training data unpredictably so you really can’t have any enterprise data flowing through such a system.I guess my point is that “their AI models” will very likely include more than noise cancelling before too long. It’s too juicy a dataset to ignore. reply tpoacher 14 hours agorootparentYes. That&#x27;s pretty much what I mean by \"specific and transparent\".Provide me with clear uses, and the ability to withdraw or restrict my data contribution in the event of the company deciding to \"expand\" to other AI \"solutions\", and I&#x27;ll feel respected as a user and allow that specific use of my data for training.But reply with vagueness giving them a carte-blanche to use my data on anything under the sun, and I&#x27;m just gonna look somewhere else and encourage others to do the same. reply shtopointo 16 hours agoprevIt&#x27;s wild they needed \"customer pushback\" to know not to do that. Something&#x27;s fishy here... reply smileysteve 14 hours agoparentWhy? I&#x27;m sure their customers and investors, since Chat GTP, have been saying \"You need to implement some AI Features, google and Microsoft are moving here, why aren&#x27;t you?\" and the company thinks, okay, you want AI Features, for it to be accurate, we need to look at real data. But no customers want AI trained on their data. reply ironmagma 14 hours agoprevOK, now roll back RTO and then they’ll be a respectable company again. reply mrweasel 16 hours agoprevGreat, but they already lost user trust. Many will never install or use Zoom again. reply freedomben 16 hours agoparentEh, people have short memories. There was a major scandal back in the day where (forgive me if my memory is not super accurate, it&#x27;s been a while) they were basically starting a long-running daemon process as root and binding it to a port where it would listen for instructions, so even when you closed Zoom it was still actually running. There were other big security (encryption IIRC?) issues that they had. Huge privacy and security scandals, so bad that they ended up acquihiring Keybase (still sad at that loss personally).But still it didn&#x27;t matter, nobody remembers or cares (except me, I refuse to install their native app. The day they fully block browser access will be a bad day). reply eur0pa 16 hours agoprevI don&#x27;t trust their words reply farts_mckensy 16 hours agoprevThe answer has always been fairly simple. Allow users the choice to opt in if they&#x27;d like to. Transparency is key. reply eigenvalue 16 hours agoparentAll they had to do was offer users a 10% discount to agree to it explicitly, and enough would have agreed out of millions of users to generate tons of training data. They were both greedy and stupid here and ended up shooting themselves in the foot. reply esafak 15 hours agoparentprevOnly if every participant in the call consents. reply littlestymaar 13 hours agoprevZoom said: “we won&#x27;t use your data to train AI without your consent”, but given that they require your consent to join a zoom call you can see what to do with such a statement. reply sharts 10 hours agoprevThey&#x27;re lying. reply harha_ 16 hours agoprevI&#x27;ve never used Zoom. Never had to, but everyone keeps talking about it. Weird how I&#x27;ve dodged it. reply fortyseven 10 hours agoprevThe cynic in me says they&#x27;ll just pass the data to a brand new company that&#x27;ll spin off of them. I&#x27;ll always assume you&#x27;re trying to do it, now. I have even less reason to trust them than I previously did. reply RadixDLT 15 hours agoprevtoo late, it aready used user data. reply systemvoltage 15 hours agoprevOk, what if they change their mind just like they did now?Also what if they break the law? Who is monitoring that? If detected, who is enforcing it? reply villgax 15 hours agoprevScrew zoom for such blatant tactics & asking their employees to work from office. How blind or horrible does your product have to be that not even your employees would use it to get work done lol reply shadowgovt 15 hours agoprevThat&#x27;s unfortunate. I was looking forward to the next generation of audio and video denoising solutions. reply A4ET8a8uTh0 16 hours agoprevThe recent messaging offensive from its CEO tried to cast previous change as a lapse in process, but refused to elaborate further when pressed on more subtle points. All in all, it does smell like bs, but I am glad there is a clearly a level of scrutiny companies appear to face lately. reply rvz 16 hours agoprevToo late.Now are you willing to abandon the rest of the other companies using your information to train their AI models? (Looking at Google, Microsoft (GitHub), Meta, Instagram, etc)Now should be the time to self-host then. Whether if it is a GitLab, or Gitea instance for Git, or a typical Mastodon server with a single user that controls the instance for full ownership. reply EGreg 16 hours agoparentOh do I have something to say about this!How are you going to serve your content? What is the best tool out there — OwnCloud? reply TradingPlaces 16 hours agoprevThis is the company that thought it was OK to install an always-on web server on my Mac. Apple pushed a special fix, just to remove it. I already have zero trust in them, and this does not change that.https:&#x2F;&#x2F;infosecwriteups.com&#x2F;zoom-zero-day-4-million-webcams-... reply bastardoperator 15 hours agoprevI still think it&#x27;s odd that Zoom is forcing people back into the office. The only thing I&#x27;m hearing is that they don&#x27;t truly believe in their product. Given that stance, they&#x27;re saying this today, when push comes to shove, they&#x27;ll do it. I think the reality is they don&#x27;t have the tech in place today to do it, but are working towards it. reply palata 13 hours agoprevNext up: Slack uses customer data to train AI models.Companies are happily exposing all their data to those services, I don&#x27;t understand why anybody would pretend to be surprised of the results. reply croes 16 hours agoprev*Insert I don&#x27;t believe you meme* reply butlike 16 hours agoprev [–] Why is this bad?Honestly, I don&#x27;t understand why you wouldn&#x27;t want the most accurate AI models available. The LLM is only as good as the data set it&#x27;s trained on, and the more I read about LLM&#x27;s and the advent of AI evolving from them, the more I&#x27;m starting to think if we don&#x27;t jump both feet into the pool, then we&#x27;ll never get to the promised land of:\"AI model, spin me up a T-shirt company that&#x27;s scaled to 10mm users a month, and spin it down after 6mo. if sales don&#x27;t increase by n% month-over-month\"or\"AI model, get me [A,B,C, ...n] groceries so I can throw a housewarming party on Friday. I can only accept the delivery Tuesday or Thursday. I don&#x27;t care which store(s) those ingredients come from or how the internals are orchestrated.\"What&#x27;s the threat model here, specifically? What nefarious things would happen by using customer data? Most companies exist to make money, which honestly, is a pretty benign objective, all things considered. reply JonChesterfield 16 hours agoparent\"As a Samsung executive, show a recent roadmap slide presentation\"and similar (presumably more sophisticated) exfiltration of commercially valuable information obfuscated away within the language model reply greiskul 15 hours agorootparentThis is why so many big companies are forbidding usage of LLMs, without properly validating how the data can be used. LLMs are based on completing text with the most likely text that follows it. Imagine being able to ask ChatGPT, please complete the following document: \" Earnings statement for Q3\" before the earnings date. reply JonChesterfield 13 hours agorootparentI wonder how many of those companies stream their commercially sensitive data through zoom or teams. Would ballpark estimate it as all of them. reply tspike 16 hours agoparentprev [–] I&#x27;d rather live in a world that preserves the fundamental right to privacy than one that can automatically organize my housewarming party. reply butlike 16 hours agorootparent [–] Why is privacy important in this context, if the data is being fed into an impartial robot? The robot doesn&#x27;t care if you have liaisons over webcam with your lover, or whatever else.An employee can blackmail another person, but the model simply has no reason to, or am I misinterpreting the \"whys\" of needing privacy here? reply david_shaw 15 hours agorootparent [–] > The robot doesn&#x27;t care if you have liaisons over webcam with your lover, or whatever else.The concern isn&#x27;t judgement from the AI, but that products from the model trained on your data could expose sensitive information.Since it&#x27;s never quite clear exactly how the data could be used in situations like this, there&#x27;s a chance that very sensitive data could be parroted back to people who were not the intended audience. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zoom has reversed its decision to use customer content to train its AI models after facing criticism on social media over privacy concerns.",
      "This highlights the ongoing debate surrounding the privacy and security implications of tech companies utilizing customer data for AI advancements.",
      "There will likely be growing pressure on companies to offer clear user opt-outs and protect personal information when using customer data for AI purposes."
    ],
    "commentSummary": [
      "Zoom has received backlash for using customer data for AI training, leading to doubts about its privacy commitment.",
      "Discussions have emerged about the monetization of old user data and the necessity of explicit laws or regulations.",
      "The encryption capabilities of various platforms, such as Zoom, Signal, and Whatsapp, are being analyzed, underscoring the significance of comprehending their encryption definitions."
    ],
    "points": 364,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1692032955
  },
  {
    "id": 37120350,
    "title": "Police raid of a Kansas newsroom raises alarms about violations of press freedom",
    "originLink": "https://www.npr.org/2023/08/14/1193676139/newspaper-marion-county-kansas-police-raid-first-amendment",
    "originBody": "Accessibility links Skip to main content Keyboard shortcuts for audio player Play Live Radio HOURLY NEWS LISTEN LIVE PLAYLIST NEWSLETTERS SIGN IN NPR SHOP DONATE NEWS CULTURE MUSIC PODCASTS & SHOWS SEARCH MEDIA A police raid of a Kansas newsroom raises alarms about violations of press freedom Updated August 14, 20239:55 AM ET By Danielle Kaye , Bill Chappell The offices of the Marion County Record sit across from the Marion County Courthouse in Marion, Kan., on Sunday. John Hanna/AP Law enforcement officers in Kansas raided the office of a local newspaper and a journalist's home on Friday, prompting outrage over what First Amendment experts are calling a likely violation of federal law. The police department in Marion, Kansas — a town of about 2,000 — raided the Marion County Record under a search warrant signed by a county judge. Officers confiscated computers, cellphones, reporting materials and other items essential to the weekly paper's operations. \"It took them several hours,\" Eric Meyer, the Marion County Record's co-owner and publisher, told NPR. \"They forbid our staff to come into the newspaper office during that time.\" Sponsor Message Local authorities said they were investigating the newsroom for \"identity theft,\" according to the warrant. The raid was linked to alleged violations of a local restaurant owner's privacy, when journalists obtained information about her driving record. Publisher says raid contributed to his mother's death Meyer's mother, Joan Meyer, collapsed and died one day after police raided her home, the Record reported in an update. She was the newspaper's co-owner. Joan Meyer was 98 and was \"otherwise in good health for her age,\" the newspaper said. But, it added, she had been unable to eat or sleep after police entered her home Friday under a search warrant. Joan Meyer \"tearfully watched during the raid as police not only carted away her computer and a router used by an Alexa smart speaker but also dug through her son Eric's personal bank and investments statements to photograph them,\" according to the Record. Without the devices, she was left unable to stream shows onto her TV or use devices if she needed help, the newspaper said. It also alleged that during the police operation, officers seized a number of devices that went beyond the search warrant's scope and were unrelated to their apparent investigation. Officers came to Meyer's home around the same time police seized computers, cellphones and other equipment during a search of the Record's offices. Another injury occurred, the newspaper said, when police chief Gideon Cody \"forcibly grabbed\" a cellphone from reporter Deb Gruver, alleging that the act injured Gruver's finger that had previously been dislocated. The raid appears to violate federal law Newsroom raids are rare in the United States, said Lynn Oberlander, a First Amendment attorney. \"It's very rare because it's illegal,\" Oberlander said. \"It doesn't happen very often because most organizations understand that it's illegal.\" LAW DOJ Says It Will No Longer Seize Reporters' Records In Investigating Leaks Several media law experts told NPR the raid appears to be a violation of federal law, which protects journalists from this type of action. The Privacy Protection Act of 1980 broadly prohibits law enforcement officials from searching for or seizing information from reporters. Oberlander said exceptions to the Privacy Protection Act are \"important but very limited.\" One such exception allows authorities to raid a newsroom if the journalists themselves are suspected to be involved in the crime at hand. In a statement sent to NPR, Marion Police Chief Gideon Cody cited this exception to justify his department's raid of the Marion County Record. \"It is true that in most cases, [the Privacy Protection Act] requires police to use subpoenas, rather than search warrants, to search the premises of journalists unless they themselves are suspects in the offense that is the subject of the search,\" Cody said. But Oberlander said that exception doesn't apply when the alleged crime is connected to newsgathering — which appears to be the case in Marion. \"It raises concern for me,\" Oberlander said. \"It normalizes something that shouldn't be happening — that Congress has said should not happen, that the First Amendment says should not happen.\" LAW San Francisco Police Union Demands Chief's Resignation Over Raid Of Journalist's Home Ken White, a First Amendment litigator, said police raids of newsrooms used to be more common in the U.S., which led Congress to bolster federal protections against such searches. White said the police raid of the Marion County Record could also be a violation of the Fourth Amendment, which protects people from \"unreasonable\" searches and seizures by the government. The search warrant in Marion, signed by county magistrate judge Laura Viar on Friday morning, allowed officers to confiscate a wide range of items, from computers and hardware to reporting documents. \"It's an abuse of power by the police and it's a serious dereliction of duty by the judge who signed off on it,\" White said. Viar could not immediately be reached for comment. Identity theft allegations Eric Meyer, the publisher of the Marion County Record, is pictured on Sunday in Marion, Kan. Law enforcement officers seized the paper's computers and cellphones. John Hanna/AP Meyer, the Marion County Record's publisher, said local restaurateur Kari Newell accused the paper of illegally obtaining drunk-driving records about her. But the paper, Meyer said, received this information about Newell from a separate source, independently verified it on the Kansas Department of Revenue's Division of Vehicles website — and decided not to publish it. The paper instead opted to notify local police. The search warrant, as published by the Kansas Reflector and verified by the police chief, specifically allowed officers to confiscate documents and records pertaining to \"the identity theft of Kari Newell.\" The warrant also ties the search to \"unlawful acts concerning computers\" that were used to access the Kansas Department of Revenue records website. \"We never attempted to steal anyone's identity,\" Meyer said. Jeff Kosseff, a law professor at the United States Naval Academy who specializes in the First Amendment, said he was surprised the county judge found there was sufficient probable cause to sign off on the search warrant. Kosseff said there would need to be \"a whole lot more for this to be a correct decision.\" \"I can't imagine a scenario in which all of these other protections would be overcome to allow a raid on a newsroom,\" Kosseff said, referencing the First Amendment, the Fourth Amendment and the Privacy Protection Act. \"This raid has been more than just potentially compromising sources. This has threatened the ability of the newsroom to operate altogether — and that's why we have these protections.\" James Risen, former director of the Press Freedom Defense Fund, called the raid an \"outrageous abuse of power by the local authorities.\" Risen said all authorities involved in the raid should be investigated for carrying it out. \"There's lots of precedent for bad behavior of local officials against the press,\" Risen said. \"In each case, it has to be called out and stopped if we're going to protect the First Amendment in this country.\" Meyer said the confiscation of the paper's computers and phones makes it difficult to continue operations — but the paper, which has five full-time staffers, still plans to publish its weekly edition this Wednesday. And, Meyer added, he's working with an attorney to challenge the police's right to inspect the items they confiscated. \"We cannot let this stand. They cannot put us out of business over this,\" Meyer said. \"That just is too bad of a precedent to set for the United States, to allow anything like that to happen.\" Emily Olson contributed reporting. Facebook Flipboard Email More Stories From NPR CULTURE Amid streaming chaos, Dropout carves out its own niche NATIONAL Hollywood strikes' economic impacts are hitting far beyond LA CULTURE Six takeaways from Disney's quarterly earnings call MEDIA A former Fox executive now argues Murdoch is unfit to own TV stations EUROPE From Selfies To Satellites, The War In Ukraine Is History's Most Documented MEDIA Ex-Biden official's lawsuit against Fox echoes case that led to big settlement Popular on NPR.org HEALTH Caring for people with fentanyl addiction often means treating terrible wounds WEATHER Hawaii faces its 'greatest emergency in decades' from Maui fires, governor says CLIMATE Just how hot was July? Hotter than anything on record CONSIDER THIS FROM NPR The Challenges for a Saudi-Israeli Peace Deal NATIONAL Coast Guard says 4 divers who went missing off S.C. coast were found alive NATIONAL A 'mob of criminals' stole more than $300,000 worth of goods from an LA Nordstrom NPR Editors' Picks NATIONAL The number of dead from Maui's fires rises as local residents press to see Lahaina TECHNOLOGY What happens when thousands of hackers try to break AI chatbots HEALTH Why doctors pay millions in fees that could be spent on care POLITICS Latinos are the biggest ethnic group in Texas, but their political power lags behind EDUCATION Michigan State students discover traces of school's first observatory built in 1881 HISTORY Maui's wildfires are among the deadliest on record in the U.S. Here are some others READ & LISTEN Home News Culture Music Podcasts & Shows CONNECT Newsletters Facebook Instagram Press Public Editor Corrections Contact & Help ABOUT NPR Overview Diversity NPR Network Accessibility Ethics Finances GET INVOLVED Support Public Radio Sponsor NPR NPR Careers NPR Shop NPR Events NPR Extra terms of use privacy your privacy choices text only © 2023 npr Sponsor Message Become an NPR sponsor",
    "commentLink": "https://news.ycombinator.com/item?id=37120350",
    "commentBody": "Police raid of a Kansas newsroom raises alarms about violations of press freedomHacker NewspastloginPolice raid of a Kansas newsroom raises alarms about violations of press freedom (npr.org) 354 points by bratgpttamer 21 hours ago| hidepastfavorite136 comments jsnell 20 hours agohttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37102271https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37096015https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37105764https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37120188 reply neilv 20 hours agoparentAt least one of those is currently buried on 3rd page, despite \"110 points by uptown 1 hour ago...19 comments\".It sounds like a tragic and suspicious situation, and what I&#x27;m most curious about (since this is HN) is whether the federal government will step in, and figure out what&#x27;s going on. reply 2OEH8eoCRo0 20 hours agorootparentEvery one of these turns into a flamewar of cynical \"America bad, corruption is the norm, there is no free press, etc.\" comments. reply giraffe_lady 20 hours agorootparentreally makes u tink huh reply gettodachoppa 15 hours agorootparentprevAs a foreigner, if I could, I&#x27;d downvote it if only because it&#x27;s local news being blown up all over HN, presumably because it&#x27;s a slow news week. I just don&#x27;t care. This isn&#x27;t speaking to some trend in America. It&#x27;s a hamlet&#x27;s local drama. Do we really need 2 posts a day?Btw, from what I got by glancing past the comments in the original post, whoever runs this newspaper is a total rat. What started all this is the newspaper snitching on a self-employed woman who lost her driver&#x27;s license 15 years ago, and telling the police she&#x27;s still using it for her job. This doesn&#x27;t excuse the raid, but god I hate petty small town people. reply 6510 12 hours agorootparentAnd then they killed his mum. replywishfish 19 hours agoprevThere&#x27;s been some interesting updates to the story.The Marion Record was in the process of investigating the Marion police chief. He used to work for the Kansas City (MO) PD. Allegedly, he was demoted for \"sexual misconduct\" before he quit and came to work for Marion.This reveal comes in an interview of the Marion Record&#x27;s publisher. It&#x27;s an interesting read and he&#x27;s an interesting guy. One of the old school reporters, in a very good way.https:&#x2F;&#x2F;thehandbasket.substack.com&#x2F;p&#x2F;a-conversation-with-the...The other new development is the Kansas Bureau of Investigation revealed they were part of building the case against the newspaper. KBI didn&#x27;t participate in the raid, but were otherwise working with the Marion police.https:&#x2F;&#x2F;kansasreflector.com&#x2F;2023&#x2F;08&#x2F;13&#x2F;kbi-director-on-mario... reply mannykannot 19 hours agoparentThe KBI might now be wondering if the Marion police chief was being entirely forthcoming about what was going on when he sought their assistance. reply dmix 19 hours agoparentprevI was curious if seriousness of it was related to the restaurant hosting the Kansas congressman at the time (which the journos were kicked out of then wrote a follow up story about the restaurant owner). Maybe whoever invited him had some connection to both the politician and the owner, and the congressman helped kick it upstairs? This is just speculation though. reply thinkcontext 19 hours agoprevOn top of the judge signing off on the warrant when this likely contradicted federal law, we have this:> When the newspaper asked for a copy of the probable cause affidavit required by law to issue a search warrant, the district court issued a signed statement saying no such affidavit was on file, the Record reported.Not a lawyer and I know it takes quite a lot for a judge to be disciplined but that would seem to be something a judicial conduct board would want to look at.https:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;marion-kansas-newspaper-raid-aca0... reply bb88 17 hours agoparentUS federal law says a search warrant can&#x27;t be issued against journalists to anything that remotely looks like reporting. Instead police must subpoena a journalist instead to show up with the materials requested. The journalist can then get a lawyer and quash the subpoena in court.https:&#x2F;&#x2F;www.mcguirewoods.com&#x2F;news-resources&#x2F;publications&#x2F;med... reply tinus_hn 1 hour agorootparentAnd then when the police violate the law, what happens? They are forced to not do it again? At worst they get to pay a fine with someone else’s money. reply s1artibartfast 16 hours agorootparentprevThere&#x27;s a huge carve out for if a journalist is being investigated for criminal activity themselves reply millzlane 18 hours agoparentprevIn my probable cause affidavit in Baltimore fabricated by the GTTF, They said they found white powedery residue in my garbage, but noone in the household consumes any while powedery drugs certainly not enough for there to be a garabge bag full of evidence to get a warrant. But somehow it happened in Baltimore too, \"The greatest city in America!\"[1][1] https:&#x2F;&#x2F;www.wypr.org&#x2F;2023-01-23&#x2F;whats-with-those-the-greates... reply deadbeeves 17 hours agorootparentEven if there was white powder in the trash, there&#x27;s an enormous number of substances and products that appear as white powders when desiccated. reply evanelias 15 hours agorootparentprevThat&#x27;s terrible, sorry that this happened to you. At least those GTTF officers got caught eventually.I assume you&#x27;ve read or watched \"We Own This City\"? I&#x27;d be curious about your take on it.Side note but I remember when they first rolled out that Baltimore bench slogan... I vaguely remember some explanations that the previous slogan (\"The City that Reads\") was also rather \"aspirational\", given the illiteracy rate. reply Kapura 19 hours agoprevThis is really, really upsetting to be happening in my country. I know it is a very big country, and Kansas isn&#x27;t exactly proximate, but we are either a country that protects the press, or we are a country where the press protects those who have power. If this is allowed to pass without the people ordering the raid fired, I am not optimistic about what the future holds. reply sanderjd 16 hours agoparentI would argue that we don&#x27;t know yet whether the system has worked or failed here. No amount of high idealism written on parchment paper can keep small people given power from using it corruptly. What matters is what happens then. If everyone were to shrug this off and say \"well of course, that&#x27;s just the way things go in America\", then yep, I&#x27;m totally with you that this is really upsetting.But I don&#x27;t think that&#x27;s what&#x27;s happening here at all. I have seen this story all over the place in national news. And what I think is that the mere fact that any of us living nowhere near this little town are aware this happened means that the people responsible for it are in deep sh*t. I think they&#x27;ll be made an example of. I think the state and federal justice systems will be racing each other to make an example of them.And if I&#x27;m right about that, it&#x27;s not an upsetting indictment of the system, it&#x27;s an affirmation of its success. reply the_optimist 19 hours agoparentprevOur press doesn’t even protect the press at this point. We have all seen the tables pairing heads of each major news outlets with their respective political spouses, siblings, or parents. Gellhorn prize winner Julian Assange has been persecuted by the US intel complex for well over a decade.The choice is in your hands to continue to attribute credibility to institutions that may no longer merit it. reply xadhominemx 18 hours agorootparentThe fact that a raid on a tiny kanas newspaper is a major national story is a sign that the press is pretty interested in protecting the press. reply dotnet00 18 hours agorootparentI disagree. All it shows is that national media outlets don&#x27;t see the tiny newspaper as a threat.They consider independent reporting (eg YouTubers) to be the main threat, thus why we don&#x27;t really see them making national headlines out of their suppression and why they even go out of their way to exclude them from their definition of press. reply xadhominemx 18 hours agorootparentSocial media algorithmic recommendation engines has also been a major story. Or are you talking about a US law enforcement raid on some YouTuber that was successfully covered up by Google? reply lcnPylGDnU4H9OF 12 hours agorootparent> some YouTuberThey&#x27;re saying that a YouTuber is most often not seen as a valid journalist in the eyes of the government despite Freedom of The Press being a supposed \"unalienable right\". Once they&#x27;ve been disclaimed as a journalist (\"go out of their way to exclude them from their definition of press\"), suddenly they&#x27;re performing espionage if they report information that someone in the government didn&#x27;t want to be revealed. reply xadhominemx 11 hours agorootparentWho fits this description? reply lcnPylGDnU4H9OF 10 hours agorootparentThe description of people who are excluded “from their definition of press”: Julian Assange. replygotoeleven 18 hours agorootparentprevThey are very interested in stories like this because this gives them the chance to work themselves into high dudgeon about a shitty little paper no one cares about. This way they have something to point to when they pull their \"50 intelligence officials said this is russian disinfo\" bullshit. \"We&#x27;re not unprincipled, self-serving, corrupt morons look how huffy we got about this tiny paper in kansas!\" reply BenjiWiebe 16 hours agorootparentHey, Marion county resident checking in. I care about that paper. It&#x27;s interesting. reply xadhominemx 18 hours agorootparentprevSo it seems you agree with me that the press is in fact inclined to protect the press? reply the_optimist 10 hours agorootparentThis is a motte-and-bailey. The initial response has answered directly already. reply Melting_Harps 17 hours agorootparentprev> They are very interested in stories like this because this gives them the chance to work themselves into high dudgeon about a shitty little paper no one cares about. This way they have something to point to when they pull their \"50 intelligence officials said this is russian disinfo\" bullshit. \"We&#x27;re not unprincipled, self-serving, corrupt morons look how huffy we got about this tiny paper in kansas!\"Furthermore, the stifling of not just Assange or Snowden no withstanding, there has also been direct vilification of people who stand up for the first Amendment; people seem to have glossed over that James Larkin (of Backpage infamy) who commited suicide while under extreme duress for his trail is actually a newpaper owner.He had been committed to standing up to power in a litany of documented stories, and even got settlements from them to keep operations going, it&#x27;s sad, but I don&#x27;t think the US mainstream news is worth anything but a coaxed form of derision, fear and a perverse &#x27;infotainment.&#x27;Being from SoCal in the 90s I saw how the paprazzi made everything about celebrity a cult-like mania, and car chases, I still remember the OJ case being played where cartoons once stood; in the 2000s I saw it go to chasing on reality TV and socialites and just tuned out. It&#x27;s also why I saw social media for what it was: it was a eye-ball grabbing solution to fill the vacumm in order to cash in on people&#x27;s need to doomscrool and engage in pointless online fighting--most of us who grew up on the internet at the time had been in enough flamewars to know what this was.Honestly, I wish I could say I was entirely immune to it by only following a few sources and journalists, but I did follow the riots during COVID and saw the Blueleaks thing unfold and saw this captures people&#x27;s attention.Elon destroying what little credibility he has since taking over Twitter&#x2F;X and desperately holding on to his cult of personality the Market may have bestowed him by taking credit for his worker&#x27;s efforts with reality TV like antics (celebrity fighting?) has been amusing but his comeupance raises a valid point: there is no trusted news source since its been so monetized.I feel that because British disinformation and Soviet&#x2F;Russian propaganda tactics have been so pervasive and effective with these mediums that no one really knows what is going on at all. And that may be intended.I&#x27;m reminded about this clip from Newswipe of Bitter Lake [0] at least every 6 months, and seeing how more relevant it becomes with every passing year.0: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KOY4Ka-GBus reply A4ET8a8uTh0 18 hours agorootparentprevThese days it is touted as &#x27;public-private partnership&#x27; and it extends far beyond press. reply adventured 18 hours agoparentprevIt is a really big country and there&#x27;s very little that can stop something like this from happening upfront. A corrupt person is always going to make it some distance before they&#x27;re stopped, before the corrupt action gets enough sunlight on it. Said corrupt person isn&#x27;t going to always make it easy to spot&#x2F;stop, or easy to prosecute.You have to prosecute and pursue justice after the crime&#x2F;s, not before. Justice is rarely a fast event. It&#x27;s identical to someone walking into a convenience store and robbing it. You can&#x27;t literally stop that from happening, you have to have a justice system that will prosecute crime. There are of course no precogs yet (Minority Report [0]).What happens next is far more important than that it happened.> If this is allowed to pass without the people ordering the raid fired, I am not optimistic about what the future holds.Given the scale of the US, that&#x27;s overly dramatic for sure. All sorts of bad things - far worse than this - happen on a small level in the US across the states, that have practically no impact on the wider nation.[0] https:&#x2F;&#x2F;www.imdb.com&#x2F;title&#x2F;tt0181689&#x2F; reply winter_blue 18 hours agorootparentThere is a duty&#x2F;obligation on the U.S. federal government to protect freedom of the press, especially if the organs of a state government act to violate it.Given that the KBI (Kansas Bureau of Investigation) was in on it, and given that a Kansas district judge signed a search warrant in the absence of an affidavit (which I&#x27;m sure this judge was well-aware was needed, but it seems this judge simply didn&#x27;t care about the rule of law), one can say that multiple organs of the Kansas state acted in cohort to violate the First Amendment.OP wrote:> If this is allowed to pass without the people ordering the raid fired, I am not optimistic about what the future holdsIf the state of Kansas doesn&#x27;t hold the people who did this to account (especially, at the very least by impeaching this judge), we absolutely need the federal government to step in, and hopefully both prosecute & imprison the individuals involved in this egregious rights violation. IANAL, but 18 U.S. Code § 242 \"Deprivation of rights under color of law\" (https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;18&#x2F;242) seems applicable here.If both Kansas and especially the federal government fail to prosecute the hold the people who ordered this raid into account, I&#x27;m not particularly optimistic about the future of the U.S. either. reply sanderjd 16 hours agorootparent> There is a duty&#x2F;obligation on the U.S. federal government to protect freedom of the press, especially if the organs of a state government act to violate it.But you seem to be commenting as if the U.S. federal government has already failed to uphold this duty. But that makes no sense because this just happened. Now that this is widespread national news, there is very little chance that these criminals get to walk away from this. These people are all going down, whether on state or federal charges (or both). But it will take months or years, because that&#x27;s how long it takes.There is almost certainly a story here about how it requires widespread news attention to get something like this sorted out, but once there is widespread news attention, the jig is up. reply anigbrowl 17 hours agorootparentprevThis is all true, but gives the feeling of tiptoeing around an elephant taking up most of the space in a room. Core federal political institutions are in a dire state due to a poisonous combination of rhetoric and corruption. I think the reason that reaction to this particular story in Kansas has been so strong is not because it&#x27;s precedential by because it&#x27;s symptomatic and so perfectly epitomizes the increasing disconnect between ideals and outcomes. reply dfxm12 18 hours agorootparentprevWe can&#x27;t pretend this is the first time something like this has happened. The problem is we see this abuse of power all the time and no one pays the consequences. The problem is qualified immunity is baked in to our legal system, so it is all too easy for those responsible to evade justice. reply andsoitis 18 hours agorootparent> we see this abuse of power all the time and no one pays the consequencesWhere there is no consequence to the police departments go after the press who are investigating them?I don’t know that we see that all the time! In fact, that’s why this story is news! reply petsfed 17 hours agorootparentA quick search revealed at least 10 distinct incidents in the US over the last 4 years (mainly in summer 2020) of reporters identifying themselves as such, and then being attacked by police. I haven&#x27;t done the work to see how often there were repercussions for those attacks, but I&#x27;m willing to be its pretty rare. reply sanderjd 16 hours agorootparentYour quick search doesn&#x27;t seem to have revealed something that is the same as the story we&#x27;re discussing.Like, I totally agree with you about qualified immunity and law enforcement abuses of power, but come on, you&#x27;re using this story to make extremely tangential points.This isn&#x27;t an example of law enforcement attacks on the press going unpunished. I saw this on the Today show this morning. This is mainstream national news. The criminals who perpetrated this are no longer the beneficiaries of a system that is corruptly stacked in their favor, they are f&#x27;d. They will be speaking to the US DoJ, and soon, and the conversation will not go well.For sure, when abuses of power don&#x27;t get widespread attention, they can easily go unchecked. And that&#x27;s bad. But this isn&#x27;t that. reply petsfed 16 hours agorootparentIts a reach on my part, granted.My claim is that there&#x27;s less distance in the mind of the police between beating up a reporter for taking pictures of the police behaving badly, and raiding a newspaper for investigating reports of the police behaving badly. reply dfxm12 15 hours agorootparentprevThis isn&#x27;t an example of law enforcement attacks on the press going unpunished.OK, I&#x27;ll bite. What was the punishment? reply sanderjd 15 hours agorootparentThis just happened! The punishment is not a \"was\", it is a \"will be\"!Do you think this is a story about something that happened last year? This happened on Friday and started receiving attention two days later, which was yesterday. This is the third day since this happened. It will take months to investigate this kind of thing, and the actual punishment, after that investigation and trials, will be years from now.If you want to have a conversation about how quickly investigations happen, fine, but three days is a completely absurd expectation.If this gets buried and nobody deigns to prosecute it, I&#x27;ll happily pick up my pitch fork and join the rest of you, but until then, for goodness sake, have some patience. reply dfxm12 14 hours agorootparentSo it&#x27;s not an example of an example of law enforcement going unpunished, as you said?If this gets buried and nobody deigns to prosecute it...Is this one is the last straw, then? reply sanderjd 6 hours agorootparentI don&#x27;t understand your first question.To your second question, no, it&#x27;s not a last straw situation. I&#x27;ve been outraged by specific things in the past, and I&#x27;m sure I will be again in the future. But I&#x27;m not outraged by this specific thing, in the present, because all signs point to these people being brought to justice in due time. replydcow 18 hours agorootparentprevYour comment is slightly self-contradictory.First you say it&#x27;s really important to prosecute all crime because justice is about the response to crime.Then you say it&#x27;s silly to be worried that a bunch of \"small crime\" (furthermore, there&#x27;s nothing to indicate in this case that this is a small crime) goes unpunished all the time.Which one is it? Do we care about crime or don&#x27;t we? I&#x27;d say it&#x27;s actually the little crimes going unpunished that worry me the most... car theft, shoplifting, etc. These signal to participants that it&#x27;s okay to behave in a way that is not in line with the stated laws of the land. Building this safe space for petty crime is far more dangerous than having a one-off corrupt asshole who committed a more \"serious\" crime run free on a legal technicality, because the safe-space normalizes bad behavior and desensitizes society to crime. reply ethbr1 17 hours agorootparentI understood parent to be making an observation about timescales.In the short term, there is and will be overreach by law enforcement and prosecution.In the intermediate&#x2F;long term, we should recognize these incidents and ensure redress is made and justice is brought.Which seems a pretty reasonable position:- People need flexibility to do their jobs- We should have robust oversight to review actions taken- We should consider irreversible actions extremely seriously (or prevent them outright) reply mindslight 17 hours agorootparentprev> You have to prosecute and pursue justice after the crime&#x2F;s, not before. Justice is rarely a fast eventWhile I&#x27;m sympathetic to your comment in isolation, do you think there is any chance that after the slow wheels of justice do turn, these violent thugs and their facilitators are actually going to end up in prison for armed assault, robbery, kidnapping, criminal conspiracy, etc? This is the breakdown in the rule of law that people are outraged about, regardless of the somewhat unreasonable desire that justice should happen quicker. If justice were merely slow but still dependable, people wouldn&#x27;t be nearly as outraged.Also if there were a consistent pattern of rogue law enforcement employees getting designated as having acted outside of their state-granted authority, prosecuted as regular criminals, and going to prison, this particular incident would have been less likely to happen in the first place. So given the larger context it&#x27;s a bit specious to say we just need to give the situation time, when time mostly serves to make the widespread attention fade. reply sanderjd 16 hours agorootparentThey are going to end up in prison for different crimes than those ones. (Although \"criminal conspiracy\" will show up in there somewhere, probably.) I don&#x27;t think the specific crimes are really the point here...This is not a demonstration of the breakdown of the rule of law, until the law actually fails to act on it. And I think that&#x27;s incredibly unlikely at this point. But maybe the justice system will indeed fail to act on this, and then we should have this conversation and you&#x27;ll probably find I agree with you.But it&#x27;s impossible for the justice system to have acted on this yet.It&#x27;s good to be outraged; our outrage is why this will be acted upon, so we must maintain that. But it&#x27;s, frankly, dumb, to jump to this \"the entire system is broken because these people are still walking free after a non-zero number of days!\". That&#x27;s just not how it works! reply mindslight 15 hours agorootparentSure, in this specific case nothing has happened yet that implies the rule of law has entirely broken down. The real problem driving the national outrage is the long pattern of the justice system not sufficiently binding government employees to the law. If this violent gang was not also employed as police officers, then we&#x27;d expect arrests and charges within a week or so. So that&#x27;s around when we can say that the justice system will start to diverge based on the perps being in a different class.And actually I&#x27;d say this substitution of different crimes is definitely part of the problem. Having a parallel set of laws that apply to government employees is still preserving this notion of a two class justice system where cops are immune from regular laws. If anything, the perps should be charged with both the various color of law framings for the damage to their institutions and for the straightforward crimes of their personal actions outside of their lawful employment duties. reply sanderjd 15 hours agorootparentOk but it&#x27;s ridiculous that most of the comments here are like \"this just goes to show that this country is corrupt!\" and like, no, it doesn&#x27;t!Fine, you want to have a broader discussion, that&#x27;s your prerogative. But it&#x27;s just not true that the current facts of this case are evidence for anything going wrong in US society. That doesn&#x27;t mean nothing is! I&#x27;m honestly not interested in having that broader nuanced discussion in this forum. But I am interested in pointing out nonsense when I see it, and using this case in its current state as evidence of any kind of break-down in the rule of law is just that: nonsense.Edit to engage directly more:This is not the same as a mob raiding a newspaper, because law enforcement is, for good reason, given the benefit of the doubt. Especially when they actually do involve the courts by getting a warrant. This makes it worse than a mob when they act corruptly, and especially when the courts also acted corruptly. It&#x27;s worse, but in ways that make it slower to investigate. The criminality of a regular mob is clear, while the criminality of a law enforcement agency with the support of a judge is unclear. Whereas it would not be hasty to arrest all the members of the mob in a couple days, it would be hasty to arrest all the police officers and a judge prior to figuring out the full story, which takes time.So no, the system has not failed if it takes more than a week to see arrests. It will likely take more like 6 months to a year. And yep, I would absolutely like complex investigations to go way faster, but it&#x27;s not unusual or evidence of corruption when they take months or years, it&#x27;s the normal state. reply mindslight 11 hours agorootparentOn reconsideration, I think the facts of this case might actually lead to some prison sentences. Although not nearly as many as there should be - really anyone involved in this including the judge that fabricated paperwork based off dubious details, other law enforcement agencies that blessed it, etc should be charged as part of the criminal conspiracy, which they can then explain away in court, as is routinely done to suspects who aren&#x27;t government employees.I think the root of the distrust is there are many other similar cases which seemingly go completely unpunished (eg Afroman). So the details being much worse here is causing proportionally more outrage, when the reality is that those details being more severe means we might actually end up seeing some semblance of justice for at least some of the perps on this one. replyhanniabu 18 hours agoparentprevIt&#x27;s a bit naive to think there&#x27;s freedom of press in this country (freedom to publish without retribution) reply empath-nirvana 18 hours agorootparentFreedom of the press is not freedom to publish \"without retribution\", and never has been. It is freedom to publish without _government_ retribution.If you publish some awful stuff, other people are allowed to point out that you said awful stuff and there are consequences for that, and that&#x27;s how it&#x27;s supposed to work. reply mcpackieh 18 hours agorootparent> Freedom of the press is not freedom to publish \"without retribution\", and never has been. It is freedom to publish without _government_ retribution.You&#x27;re talking about the American First Amendment specifically, not freedom of the press generally. The World Press Freedom Index includes sociocultural context and safety; if journalists are being attacked by mobs of angry citizens that is obviously a problem for the freedom of the press. To assert otherwise is ludicrous.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;World_Press_Freedom_Index reply mrguyorama 17 hours agorootparentANY \"freedom of speech\" that curtails the speech of people responding, using their own free speech, to someone saying something, is not freedom of speech, but rather an attempt to silence critics.If you believe in \"Freedom to publish without retribution\", you believe in \"might makes right\". reply jjk166 17 hours agorootparentprevWell we already have laws against mobs violently attacking people. Freedom of the press means you suffer no legal consequences from publishing, which would include refusal of the government to enforce its laws to protect people from violence because of what they had published. But if people don&#x27;t like what you&#x27;re publishing, they must be free for exactly the same reason to express their opinions and act as they see fit within the normal limits of the law. reply mcpackieh 17 hours agorootparent> Well we already have laws against mobs violently attacking people.And violation of those laws is a threat to the freedom of the press.Let&#x27;s consider a hypothetical but plausible example: A billionaire named Elon Bezos is tired of journalists exposing his illegal schemes so he hires the Pinkertons to stalk and harass journalists, dox them and post their personal information on 4chan with claims of those journalists working for the pizzagate illuminati, and threaten their friends and family with life ruination and murder. In this hypothetical everything done is illegal and none of it was done by the government; would you therefore earnestly conclude that none of it constitutes a threat to the freedom of the press? Ludicrous.You need to stop conflating the First Amendment with freedom of the press. The First Amendment is one law that aims to protect the freedom of the press from one specific kind of threat; threats coming from the government. It does not preclude the existence of other kinds of threats to freedom of the press. reply jjk166 17 hours agorootparent> In this hypothetical everything done is illegalThat&#x27;s the important bit. Assuming that use of violence against journalists is illegal and the law is enforced, then that is freedom of the press. Similarly your right to own property is protected even if there are burglars out there. reply mrguyorama 17 hours agorootparentprevThat is a crime of harrassment and other \"You&#x27;re being an ass to someone\" crimes. A private person cannot violate the freedom of the press because a private person has almost zero restrictions on their speech. THAT IS FREEDOM OF SPEECH, and any attempt to curtail that response is an attempt to stifle their speech! reply eesmith 17 hours agorootparentprev\"attacked by mobs of angry citizens\" is not the only form of retribution, nor the only negative consequences facing a newspaper.If, due to publishing an article, everyone decides to stop buying the newspaper or a subscription to the newspaper, and to stop placing ads, then that&#x27;s a form of retribution&#x2F;negative consequences.Freedom of the press does not mean that people must not exercise their right of free association. reply hanniabu 17 hours agorootparentprev> It is freedom to publish without _government_ retributionWhich the government would never ruin the facade of freedom so they follow through at unofficial capacities reply pessimizer 17 hours agorootparentprevYou have no legal basis for saying this, because US freedom of the press rules are about prior restraint, and government retribution isn&#x27;t prior restraint. You also have no philosophical basis for saying this, because nobody put you in charge of defining what freedom of the press means to everyone else, and you&#x27;ve offered no references to people more respected than yourself on the subject.But good luck with a definition of freedom of the press that doesn&#x27;t include when white mobs would break into black newspapers, break the presses, and burn the building down. Does freedom of the press give the government an obligation to prosecute, or nah? reply amalcon 17 hours agorootparentprevUnquailfied \"freedom to publish without retribution\" is obviously impossible. Publishing can be retribution; for an extreme example, see: \"Will no-one rid me of this turbulent priest?\"You can make \"freedom to publish without retribution\" possible only by qualifying the kind of publishing and&#x2F;or the kind of retribution. reply sitkack 17 hours agoparentprevFired isn&#x27;t enough. Poor people go to jail. The powerful move on to the next job where willingness to participate in corruption is a merit badge itself. reply jjk166 19 hours agoprevFor reference this is the form for requesting motor vehicle records in Kansas [0]It asks for \"your\" information to find the record, but based on the allowed uses you can definitely get records for other people. I would say a journalist accessing DUI records would fall under permitted use case M. That accessing this is identity theft is a farcical claim.[0] https:&#x2F;&#x2F;www.kansas.gov&#x2F;ssrv-mvr-ltd&#x2F; reply myself248 17 hours agoparentExactly. Obtaining information about someone is not identity theft. It might be stalking, it might be journalism, it might be credit-reporting, but it is not identity theft.Pretending to _be_ someone, _stealing their identity_, is identity theft. Absolutely nothing in this story sounds like that, and it sounds like the warrant is entirely farcical. reply hiatus 17 hours agorootparentI think it depends. Reading the form, if you filled it out and clicked the \"I am requesting my own record\" button, that&#x27;s holding yourself out as though you were the person whose records you are requesting, which certainly seems like it could be construed as identity theft. reply dmatech 17 hours agoparentprevI&#x27;m not saying this happened here, but if a journalist engaged in hacking or fraud to obtain material to publish, that would be \"journalism\", but it would also be a crime (the research, not the publication). Obviously, the freedom of the press doesn&#x27;t include the ability to do anything they want in pursuit of a story. reply jjk166 17 hours agorootparentNo one is arguing that journalists are not bound by laws, the issue here is that not only is there no proof they broke any laws here, but even the idea that they might have is laughable, given that this was a public database they had permission to access. It&#x27;s like accusing someone walking out of a public library with a book is a thief who stole the book. reply indymike 18 hours agoprevThis article: https:&#x2F;&#x2F;thehandbasket.substack.com&#x2F;p&#x2F;a-conversation-with-the... contains a detailed interview with editor of the raided newsroom. When asked about pulbic support, the publisher said he had a lot of support from out of town, but the locals... well:\"They&#x27;re afraid. They&#x27;re really afraid that the police power is unchecked, and that they can be punished like this.\" reply janeerie 12 hours agoparentMy brother lives in this county, and all he&#x27;s told me is that there&#x27;s a lot of shenanigans going on there. reply mkovach 19 hours agoprevSeems to me this might be plain old intimidation. The folks involved, which includes the Police Chef, see that somebody is leaking information to the press and a trying very hard to find they leak(s). Since they can&#x27;t figure out who, and the press isn&#x27;t publishing anything they are cranking up the heat.In both cases he says that they are investigating allegations. In fact, at one point it is said, they turned over information to the police because they thought it might be related to a civil matter (somebody&#x27;s divorce). They don&#x27;t feel they have enough information to make the allegations public.Something never change but the semantics, police are trying to find the leak, IMHO. reply staplers 18 hours agoparentGotta imagine they&#x27;re onto a big, long thread if they&#x27;re trying this hard to cover it up. reply sanderjd 16 hours agorootparentYep, and it just blew up in their face. The most important rule of breaking laws in your small town is to not do something that shows up on the national morning news. reply mkovach 17 hours agorootparentprevAs, I said, things remain that same.The cover-up is always a bigger story. Ask Nixon :) reply helsinkiandrew 20 hours agoprev> \"It is true that in most cases, [the Privacy Protection Act] requires police to use subpoenas, rather than search warrants, to search the premises of journalists unless they themselves are suspects in the offense that is the subject of the search,\" Cody said.Presumably the restaurant owner accusing the newspaper editor of identity theft gives good cover for the police chief to get a warrant and search for anything else (ie information about investigations into himself). That does give a veneer of legality to the raid. reply flutas 20 hours agoparent> That does give a veneer of legality to the raid.I would have agreed, if it hadn&#x27;t been for the County Attorney (who according to their website is \"the chief law enforcement officer in Marion County.\"[0]) putting his foot in his mouth, and the paper exposing the relationship between him and the restaurant owner. It makes it pretty clear what actually is going on here.> A Record reporter later requested a copy of the probable cause affidavit necessary for issuance of the search warrant.> District court, where such items are supposed to be filed, issued a signed statement saying no affidavit was on file.> County attorney Joel Ensey, whose brother owns the hotel where Newell operates her restaurant, was asked for it but said he would not release it because it was “not a public document.”---[0]: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230215034526&#x2F;https:&#x2F;&#x2F;www.mario... reply bilbo0s 19 hours agorootparentSlightly off topic, but how do you get to be a county attorney, and still be this oblivious to propriety? Did he believe nothing would come of this and it would all just go away?I honestly can&#x27;t see how anyone with a law degree would have even touched this situation under the same circumstances. Journalists? Preexisting business relationships that are documented and freely available to the public.Jeez, at least hide stuff in holding companies or trusts or something. What were these guys doing? reply flutas 19 hours agorootparentTo be fair he probably expected it to not be heard of at all.Looking it up, the county only has a population of ~11.8k[0], and the town only has 1.9k residents[1]. Which is on the verge of \"doesn&#x27;t exist\" usually for news.Also editing the original comment, because apparently he&#x27;s also their chief of police.[2][0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marion_County,_Kansas[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marion,_Kansas[2]: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230215034526&#x2F;https:&#x2F;&#x2F;www.mario...> The County Attorney is the chief law enforcement officer in Marion County. reply afavour 19 hours agorootparentprev> Did he believe nothing would come of this and it would all just go away?My entirely unevidenced belief is that this happens _all the time_ and recent events are only notable because they didn&#x27;t just go away. With local news in freefall if anything I imagine this is happening more and more. reply tehwebguy 18 hours agorootparentprev> Slightly off topic, but how do you get to be a county attorney, and still be this oblivious to propriety?I mean who is going to do anything about it? They are in charge of who gets indicted and who doesn’t. reply giraffe_lady 19 hours agorootparentprev> Did he believe nothing would come of this and it would all just go away?Most likely yes, and he isn&#x27;t wrong to believe that. This is genuinely how small towns & rural areas function even still. The sheriff, judge, police chief, school principal, county commissioner, and the most significant business owners and landlords will all be part of the same segregation-era country club or masonic lodge or some other thing and they&#x27;ll make decisions and ask favors together over there.Usually the local newspaper owner would also be part of this clique, and I guess the county attorney misjudged the ramifications of that. But this sort of local corruption is rampant and the people doing it can count on the fact that it almost never gets picked up as a national news item. reply myself248 20 hours agoprevIf the article is even half accurate, they must be using a different definition of \"identity theft\" than the one I understand. reply bratgpttamer 20 hours agoparentAlso, the classic \"doing crimes with a computer\" (performing a query on the DMV website) reply dmix 19 hours agorootparentIt sounds like more than just a public records search, someone sent them information about her DUI:> Newell said she believes the newspaper violated the law to get her personal information as it checked on the status of her driver’s license after a 2008 drunken driving conviction and other driving violations.> The newspaper countered that it received that information unsolicited, which it verified through public online records. It eventually decided to not run a story because it wasn’t sure the source who supplied it had obtained it legally. But the newspaper did run a story on the city council meeting, in which Newell confirmed that she’d had a DUI conviction and that she had continued to drive even after her license was suspended. reply bratgpttamer 19 hours agorootparentI also read that the source who sent the information about Newell bragged about retaining \"connections\" in law enforcement, a hint that it might have been non-public information. There&#x27;s also \"dozens\" of anonymous tips about the police chief&#x27;s sexual harassment issues.However, I&#x27;m not sure \"verifying a rumor via public records\" is what the various \"using a computer to do crimes\" laws are about, especially because my understanding of various public records and registry searches are precisely to allow the public to verify these kinds of rumors.Reading between the lines, it seems that they were most interested in unmasking the identities of these anonymous sources and sending a message to the newspaper. reply tootie 20 hours agoparentprevIt&#x27;s in quotes because that&#x27;s the allegation made as probable cause for the warrant. So, the article is correct, but the allegation is preposterous and big reason that everyone is inferring the entire operation was retribution and abuse of power. reply 2OEH8eoCRo0 20 hours agoparentprevAre there any details about those allegations? I&#x27;d be interested to see what the warrant gave as cause. We seem to be jumping to the conclusion that these journalists are innocent. reply bratgpttamer 20 hours agorootparentThe warrant[1] doesn&#x27;t seem to provide much information and the affidavit used to secure the warrant has yet to be produced.[2][1] https:&#x2F;&#x2F;kansasreflector.com&#x2F;2023&#x2F;08&#x2F;11&#x2F;police-stage-chilling...[2] https:&#x2F;&#x2F;kiowacountypress.net&#x2F;content&#x2F;opinion-powerful-voices... reply MisterBastahrd 17 hours agorootparentprevWhen you take literally everything that isn&#x27;t nailed down from a journalism business that needs its resources to operate, it&#x27;s not really jumping to conclusions to determine what kind of action this is. This is an action to squash the article and attempt to drive the paper out of business. reply bilbo0s 20 hours agorootparentprevWe seem to be jumping to the conclusion that these journalists are innocent.Just, Devil&#x27;s Advocate.Or, I guess, \"Founder&#x27;s Advocate\"?But isn&#x27;t that what we&#x27;re supposed to do here in the US?I mean, you know, Constitutionally speaking? reply SubiculumCode 19 hours agorootparentwell, presuming yes. but not concluding. reply findalex 20 hours agoprevSounds like this restaurant owner has some friends high up on the force? reply flutas 20 hours agoparentThere&#x27;s also the relationship between her and the county attorney.> County attorney Joel Ensey, whose brother owns the hotel where Newell operates her restaurant reply bratgpttamer 19 hours agorootparentIt looks like Newell was using Tammy Ensey&#x27;s liquor license, which is non-transferrable and expires later this month.[1] https:&#x2F;&#x2F;peabodykansas.com&#x2F;direct&#x2F;restaurateur_accuses_paper_... reply madcow2011 20 hours agoparentprevThat&#x27;s exactly what I was thinking. Either the judge who issued the order or something like that. reply nimbius 18 hours agoprevmost of the stories im seeing so far are pretty one-sided, with Marion decidedly very quiet on the issue entirely for very good reason.What was originally intended to be a show of intent, a brassy display of the sort of wheeling-and-dealing political life that has always existed in small rural towns has detonated with a spectacle not seen since the Beirut explosion. This is the sort of scandal that disbands police departments under consent-decree and sends your entire small town leadership from the city council up to the mayor out the door.If the point was to ensure a coverup, you couldnt have done worse. constitutional transgressions like this have the ability to dissolve the Marion entirely. reply newZWhoDis 18 hours agoparentTrue, only the feds get to violate our rights like this. They will swoop in and prosecute anyone who steps on their turf. reply m_0x 17 hours agorootparentWho watches the watchmen? reply JumpCrisscross 16 hours agoprevIf you feel enraged and want to direct it productively, consider subscribing to the Marion County Record [1]. ($35 for online only, $50 for print, which might make for a nice memorabilia or gift for a journalist friend.)[1] https:&#x2F;&#x2F;marionrecord.com&#x2F;credit&#x2F;subscription:MARION+COUNTY+R... reply dfxm12 20 hours agoprevHopefully it also raises alarms about corrupt cops and Qualified Immunity. reply landosaari 18 hours agoprevSome interesting countries with better freedom of the press than United States (2023): Namibia, Moldova, North Macedonia, Argentina[0][0] https:&#x2F;&#x2F;rsf.org&#x2F;en&#x2F;indexFrom the website it states the following.\"It is a snapshot of the media freedom situation based on an evaluation of pluralism, independence of the media, quality of legislative framework and safety of journalists in each country and region.\"Is there an different list to compare against?@Kapura since your country is big: would it be better to compare each state individually? reply nextmove 17 hours agoprev> Meyer&#x27;s mother, Joan Meyer, collapsed and died one day after police raided her home.So will the Stasis be charged for manslaughter? Oh right this government is totally corrupt. reply CatWChainsaw 19 hours agoprevThe Streisand Effect is a real bitch, ain&#x27;t it...Traumatizing a 98yo woman to death also doesn&#x27;t help the police&#x27;s image. reply bratgpttamer 17 hours agoparent\"Cops raided a smalltown newspaper so no-one would ever find out about police chief Gideon Cody&#x27;s alleged sexual misconduct or Kari Newell&#x27;s DUI conviction\"https:&#x2F;&#x2F;boingboing.net&#x2F;2023&#x2F;08&#x2F;14&#x2F;cops-raided-a-smalltown-ne... reply LatteLazy 19 hours agoprevAs I understood it, the first amendment has been hedged to protect what papers can publish. But it does not protect how or where they get the information. The result is that courts and the police both can and will raid offices, seize materials etc. The only protections against this are (a) getting it published before you&#x27;re raided and (b) whatever respect for the spirit of the constitution you can inspire in judges or maybe lawmakers to try and codify these things.Is that wrong?I am asking here about the actual interpretation of the law, not the \"ideal world\" scenario...This is the best case I could find:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Branzburg_v._Hayes reply empath-nirvana 18 hours agoparent> The result is that courts and the police both can and will raid offices, seize materials etc.The police can and will do all kinds of illegal things, regardless of the law. It&#x27;s up to the courts and DoJ, etc, to sort that out after the fact, there&#x27;s not much anyone can do before it happens. reply ROTMetro 18 hours agorootparentAnd ironically, the courts and DOJ tend to not do anything unless publishers shine a spotlight on it. Luckily the internet has done away with most local news making everyone in the chain&#x27;s life easier. reply LatteLazy 17 hours agorootparentprevAs far as I can tell, nothing here was illegal. That&#x27;s sort of the problem... reply gwbrooks 18 hours agoparentprevAs a clarification: Freedom of the press under the First Amendment doesn&#x27;t confer special protections on journalists. Rather, it protects the rights of all Americans not merely to speak freely, but to write freely as well. reply megabless123 20 hours agoprevThe police cannot be reformed reply FrustratedMonky 19 hours agoprev\"Try That In A Small Town\"Need to explain reference.There is a video : https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=b1_RKu-ESCYIt kind of glorifies small town justice&#x2F;vigilantism. Like, the rest of the country is falling apart, but the small town wouldn&#x27;t let that happen (wink, wink).https:&#x2F;&#x2F;www.npr.org&#x2F;2023&#x2F;07&#x2F;20&#x2F;1188966935&#x2F;jason-aldean-try-t...But then the original post, story about small town sheriff raiding a newspaper kind of shows indications of small town corruption.So the point is about the dichotomy of &#x27;small towns&#x27; being pure and glorifying taking \"American Justice\" into their own hands, and also how they can corrupt those same values.The original post is a counter story about how things can go wrong there too. You can have small town &#x27;justice&#x27; also take the form of actions that go against American Values like freedom of speech. reply mrguyorama 17 hours agoparentThis is the exact style of \"justice\" that \"Try that in a small town\" wants. I&#x27;ve been in those small towns. They are always about the people who are friends with the cops. From petty corruption like not giving the local alcoholics DUI citations, to helping their friends weed grow op, small town cops are fabulously corrupt, and there&#x27;s really no standards that they are supposed to be held to.Remember, hanging negros for looking at women is what would happen in a small town in america. reply remote_phone 20 hours agoprevWho has authority to investigate the police department for this obvious corruption? Can anyone be held accountable? reply vel0city 19 hours agoparentOften the FBI will get involved when they hear about corruption.https:&#x2F;&#x2F;www.fbi.gov&#x2F;about&#x2F;faqs&#x2F;does-the-fbi-investigate-graf...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hobbs_ActReally goes to show you how wide interstate commerce clause goes. reply hyperpape 20 hours agoparentprevI can’t vouch for it, but the article I read yesterday stated that the police department violated a federal law governing how law enforcement seizes information from journalists. If so, the feds could become involved. reply sorrytobedark 19 hours agoparentprevUnfortunately probably no one, hence heavy vigilantism in the past which is starting to recur. reply sanderjd 16 hours agoparentprevEveryone. These people are totally screwed. The state of Kansas will be racing to prosecute this before the feds get to it first. reply tootie 20 hours agoparentprevBasically go up the food chain. This corruption is probably more on the magistrate who signed the warrant than the police who served it, but that gets investigated by the state or the DOJ. reply mcpackieh 19 hours agoparentprevThe FBI, but they&#x27;re too busy grooming mentally disabled people into fabricated terror plots, because real terrorism is far too rare to justify their inflated headcounts and budgets.https:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2011&#x2F;nov&#x2F;16&#x2F;fbi-entrapment...https:&#x2F;&#x2F;theintercept.com&#x2F;2015&#x2F;07&#x2F;13&#x2F;another-terror-arrest-an...https:&#x2F;&#x2F;www.esquire.com&#x2F;news-politics&#x2F;a47390&#x2F;alabama-isis-pe...https:&#x2F;&#x2F;thefreethoughtproject.com&#x2F;the-state&#x2F;fbi-frames-menta...https:&#x2F;&#x2F;www.democracynow.org&#x2F;2015&#x2F;3&#x2F;19&#x2F;how_the_fbi_created_a... reply sixothree 20 hours agoprevChecks and balances are needed. reply sanderjd 16 hours agoparentThey are indeed needed, and they are had. The perpetrators of this are headed to a courtroom, or multiple courtrooms. reply plagiarist 20 hours agoparentprevI fear this will be another egregious violation of the Constitution ignored under qualified immunity. Prosecuting egregious violations of the Constitution instead of allowing police to do whatever they like would be a good check&#x2F;balance. reply indymike 18 hours agorootparent> I fear this will be another egregious violation of the Constitution ignored under qualified immunity.The police officers, individually can have qualified immunity. The governments that employ them do not. reply mrguyorama 17 hours agorootparentWhich nicely transfers accountability away from the individuals doing unacceptable things, to the city itself, which cannot go to jail and can pay any penalty through taxes to the same people said penalty is meant to help.What a good system. reply sanderjd 16 hours agorootparentprevI&#x27;ll certainly be following it, but I highly doubt this. reply ROTMetro 17 hours agorootparentprevThere needs to be a requirement that Police are insured. The city&#x2F;county shouldn&#x27;t pay the bill for poor personal behavior of police with a side of accountability in the form of keeping insurable. reply mrguyorama 17 hours agorootparentNo, just put bad fucking cops in jail. We don&#x27;t need some damn market of insurance for criminal behavior just because we are so unwilling to hold powerful people accountable, we just have to finally stand the fuck up and demand accountability!The only reason to favor the insurance scheme over, you know, actual justice, is if you stand to profit from it. reply arunharidas 17 hours agoprev [–] NPR cheered when conservative media got targeted and when they came after them they&#x27;re crying violation of freedom of press. You can&#x27;t have the cake and eat it too. reply mrguyorama 16 hours agoparentPray tell, can you point to the supposed cheering that NPR did for conservative media having it&#x27;s legal rights violated? reply Jcampuzano2 16 hours agoparentprevTargeted in what way that was very likely illegal&#x2F;corrupted? Gonna need to cite a source for your claims. reply pessimizer 17 hours agoparentprev [–] Who cares what NPR thinks? You&#x27;re like one of those people who chooses their positions based on the opposite of what Trump said. How can you recognize NPR as illegitimate, yet give them control over you? reply hiatus 17 hours agorootparent [–] > How can you recognize NPR as illegitimate, yet give them control over you?Pointing out hypocrisy is giving \"them control over you\"? TFA is posted on npr.org. reply acdha 16 hours agorootparent [–] They didn’t point out any hypocrisy. At most you could say they made a strong claim conspicuously unsupported by evidence or even a clear statement about what they’re referring to. Actually pointing out hypocrisy would require both a specific claim and supporting evidence. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A local newspaper office and a journalist's home in Marion, Kansas were raided by law enforcement officers, raising concerns about press freedom violations.",
      "Computers, cellphones, and reporting materials were confiscated during the raid, conducted under a search warrant.",
      "Local authorities claim the raid was related to investigating identity theft, but experts argue that it likely violates federal law protecting journalists from such actions. The raid also allegedly resulted in the death of the newspaper's co-owner.",
      "Experts are demanding an investigation into the authorities involved and highlighting the significance of safeguarding press freedom."
    ],
    "commentSummary": [
      "A police raid on a newsroom in Kansas has sparked national attention and concern about press freedom violations and potential corruption by local law enforcement.",
      "Commenters are worried about the exclusion of non-mainstream journalists and the influence of disinformation and propaganda.",
      "There is a call for accountability and prosecution for those responsible for violating freedom of the press, raising concerns about the unchecked power of local authorities and the suppression of information."
    ],
    "points": 354,
    "commentCount": 136,
    "retryCount": 0,
    "time": 1692016727
  },
  {
    "id": 37130060,
    "title": "Tell HN: t.co is adding a five-second delay to some domains",
    "originBody": "Go to Twitter and click on a link going to any url on \"NYTimes.com\" or \"threads.net\" and you&#x27;ll see about a ~5 second delay before t.co forwards you to the right address.Twitter won&#x27;t ban domains they don&#x27;t like but will waste your time if you visit them.I&#x27;ve been tracking the NYT delay ever since it was added (8&#x2F;4, roughly noon Pacific time), and the delay is so consistent it&#x27;s obviously deliberate.",
    "commentLink": "https://news.ycombinator.com/item?id=37130060",
    "commentBody": "Tell HN: t.co is adding a five-second delay to some domainsHacker NewspastloginTell HN: t.co is adding a five-second delay to some domains 333 points by xslowzone 6 hours ago| hidepastfavorite178 comments Go to Twitter and click on a link going to any url on \"NYTimes.com\" or \"threads.net\" and you&#x27;ll see about a ~5 second delay before t.co forwards you to the right address.Twitter won&#x27;t ban domains they don&#x27;t like but will waste your time if you visit them.I&#x27;ve been tracking the NYT delay ever since it was added (8&#x2F;4, roughly noon Pacific time), and the delay is so consistent it&#x27;s obviously deliberate. hlandau 3 hours agoWorth pointing out that t.co has always been an instance of an annoying and seemingly unjustified practice I named \"nonsemantic redirect\". Rather than legitimately redirecting using an HTTP Location header, it instead is an HTML page with a META refresh tag on it.You don&#x27;t see this with curl&#x2F;wget because they use user agent sniffing. If they don&#x27;t think you&#x27;re a browser they _will_ give you a Location header. To see it, capture a request in Firefox developer tools, right click on the request, copy as CURL. (May need to remove the Accept-Encoding tag and add -i to see the headers). reply ShamelessC 47 minutes agoparentCould you explain what the intended&#x2F;expected outcome is for this? What is accomplished by doing that? reply dalore 26 minutes agorootparentCrawlers and tools will get the right location http header but browsers and users will get the delay. reply spiderfarmer 32 minutes agorootparentprevCookies? reply kens 5 hours agoprevI can confirm. NYT shows a five-second redirect delay: \"wget https:&#x2F;&#x2F;t.co&#x2F;4fs609qwWt\". It redirects to gov.uk immediately: \"wget https:&#x2F;&#x2F;t.co&#x2F;iigzas6QBx\" reply craftkiller 5 hours agoparentOddly enough the delay is reduced to 1 second by using curl&#x27;s useragent string (wget --user-agent=&#x27;curl&#x2F;8.2.1&#x27; https:&#x2F;&#x2F;t.co&#x2F;4fs609qwWt) reply ilikehurdles 5 hours agorootparentSeeing this makes me wonder if it&#x27;s some sort of server-side header bidding ad server gone haywire, rather than something nefarious. Why would they only delay browser agents otherwise? reply derefr 4 hours agorootparentBrowsers are generally tolerant of long TTFB. Automation, on the other hand, is sometimes quite brittle. reply nvm0n2 1 hour agorootparentprevProbably a phishing&#x2F;malware scan gone wrong then. NYTimes has Twitterbot in its robots.txt which might be related?Even if it&#x27;s deliberate, I don&#x27;t see how people can complain. Google has outright blocked Breitbart for years. They prevent results from that domain from appearing at all unless you specifically force it with site: and apparently HN does the same. Politically motivated censorship and restricting \"reach\" is just how Silicon Valley rolls. Pre-Musk Twitter did freeze the New York Post&#x27;s account and many other much worse things. It&#x27;d be a shame for Musk to be doing this deliberately, even though it seems unlikely. But that&#x27;s the problem with creating a culture where that sort of behavior is tolerated, isn&#x27;t it? One day it might be turned around on you. reply spiderfarmer 28 minutes agorootparentDoes the value Breitbart adds to the internet outweigh the negatives of turning people into dangerous fascists by weaponizing misinformation? No.Does the value added by sources like the NYT outweigh the negatives of being occasionally biased or outright wrong? Yes. reply londons_explore 3 hours agorootparentprevPerhaps their own internal tooling also relies on the t.co redirector? reply mbernstein 5 hours agoparentprevAgree&#x2F;confirmed - just recorded a number of different nytimes urls that pass through t.co, all 4.7s+. various cnbc and google articles through t.co were ~130-200ms response time from t.co specifically (not total redirect->page load). reply yohannesk 34 minutes agoparentprevIs there some cache going on? On my first attempt, there is a 5 second delay. When I try it second time immediately it works without the 5 second delay. But if I try again after an hour, 5 second delay again! reply hrrsn 18 minutes agorootparentSafari seems to be caching it for me, but I can reproduce the delay every time with curl - so long as the user agent doesn&#x27;t include the string \"curl\". reply _a9 5 hours agoparentprevIm not getting the same time delay with curl- `time wget https:&#x2F;&#x2F;t.co&#x2F;4fs609qwWt` -> `0m5.389s`- `time curl -L https:&#x2F;&#x2F;t.co&#x2F;4fs609qwWt` -> `0m1.158s` reply praisewhitey 3 hours agoparentprevI tested some substack.com links and there&#x27;s a delay on those too. reply snake_doc 4 hours agoparentprevCould it just be rotting infrastructure? I.e there is some logic on most visited domains to allow ease of moderation, that logic is read heavy and is now bucking under skew.Or even like some junior dev removed an index reply joecool1029 4 hours agorootparentA few years ago I remember their URL shortener on android app directing somewhere that my hostfile adblocker would catch (like an analytics domain or something). This made it so first click on certain twitter links would fail, but if I clicked it again it would go successfully. Ultimately I never researched it deeply enough but my guess is they had some sort of handler that would log whether loading their analytics service failed and serve up the direct link on the second attempt. reply swissspidy 3 hours agorootparentSeeing that right now with NYT links. First click takes a few seconds to redirect, second click is almost instant reply tech234a 4 hours agorootparentprevI&#x27;ve experienced similar behavior on iOS, not sure if it still does that though. reply zagrebian 5 hours agoparentprevIt’s about 4.5 seconds for mehttps:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;qege0O9 reply praisewhitey 3 hours agorootparent4521ms according to curl curl -A \"Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko&#x2F;20100101 Firefox&#x2F;117.0\" -I \"https:&#x2F;&#x2F;t.co&#x2F;4fs609qwWt\" x-response-time: 4521 reply lamontcg 5 hours agorootparentprevAny DNS resolver libraries have a 4.5 second timeout? Maybe their infrastructure is just rotting. reply minimaxir 5 hours agorootparentIt&#x27;d be weird that it&#x27;s limited to specific outbound domains in that case. reply lamontcg 4 hours agorootparentdomains load balanced across different servers in some overly complicated distributed topology with only one of them busted?although seems unlikely it just happens to be the NYT. reply runlevel1 4 hours agorootparentprevglibc defaults to 5 sec, but the server wouldn&#x27;t need to resolve the redirect domain -- that&#x27;d be the client&#x27;s job. Unless it&#x27;s doing so for some proprietary reason, of course.Or did you mean failing to resolve some internal service&#x27;s hostname? reply jquery 5 hours agoparentprevI almost didn&#x27;t believe OP, because it&#x27;s so comically inept and petty. But, I can also confirm in some private testing there is a deliberate delay. reply adhesive_wombat 3 hours agorootparentConsidering how common it is to deliberately break (not just with a \"you log in now\" modal, but not loading content, spinning forever, breaking layouts, etc) websites for non-logged-in mobile users, that&#x27;s exactly how petty in imagine them to be. Twitter and Reddit do it, and Imgur comes and goes so I can&#x27;t decide if for them it&#x27;s deliberate or just incompetence. reply TheRealSteel 5 hours agorootparentprev\"because it&#x27;s so comically inept and petty\"This is precisely why I did believe OP. This is Elon Musk we&#x27;re talking about. reply mutant_glofish 5 hours agoprevI think that HN itself also shadow flags submissions from a list of domains it doesn&#x27;t like.Try submitting a URL from the following domains, and it will be automatically flagged (but you can&#x27;t see it&#x27;s flagged unless you log out): - archive.is - watcher.guru - stacker.news - zerohedge.com - freebeacon.com - thefederalist.com - breitbart.com reply dang 5 hours agoparentWell, yes, many sites are banned on HN. Others are penalized (see e.g. https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que...). None of this is secret, though we don&#x27;t publish the lists themselves.Edit: about 67k sites are banned on HN. Here&#x27;s a random selection of 10 of them: vodlockertv.com biggboss.org infoocode.com newyorkpersonalinjuryattorneyblog.com moringajuice.wordpress.com surrogacymumbai.com maximizedlivingdrlabrecque.com radio.com gossipcare.com tecteem.com reply rhaksw 5 hours agorootparentIt is a secret if the system does not inform the poster it&#x27;s been penalized. reply altairprime 4 hours agorootparentWhat is it if the information is freely available, to anyone asking, for a single domain they are trying to post at that time?It’s not secret, because they’ll be provided an answer if they email the mod team.It’s not free as in open source, because it isn’t available for anyone to download and study in full.So, since it’s not secret, is it public, or private? Since it’s not published in full but any query of LIMIT 1 is answered, is that open, closed, or other?Restrictions to publication don’t necessarily equate to secrecy, but the best I’ve got is “available upon request”, which isn’t quite right either. Suggestions welcome. reply rhaksw 4 hours agorootparentContent moderation systems often hide mod actions from the content author [1]. That&#x27;s a secret.The opposite would be to show the author of the content some indicator that it&#x27;s been removed, and I would call that transparent or disclosed moderation.Interestingly, your comment first appeared to me as \"* * *\" with no author [2]. I wonder if that is some kind of ban.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8e6BIkKBZpg[2] https:&#x2F;&#x2F;i.imgur.com&#x2F;oGnXc6W.pngedit I know you commented again but it&#x27;s got that \"* * *\" thing again:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37130675https:&#x2F;&#x2F;archive.is&#x2F;Eov7z reply dang 2 hours agorootparentIt&#x27;s not a ban. It appears when the user has &#x27;delay&#x27; in their profile set to N minutes and N minutes haven&#x27;t elapsed yet. We should probably make this more explicit.Re the &#x27;delay&#x27; setting see https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsfaq.html. reply altairprime 4 hours agorootparentprevThere’s a protection system in place that can result in that; I don’t have the details at hand (since I’m not associated with HN&#x2F;YC) but I remember seeing it once before on a highly contentious post, and an email to the mods helped explain&#x2F;correct whatever was up. reply vasco 4 hours agorootparentprev> Suggestions welcome\"This domain is not allowed on HN\" as an error message upon submission. reply altairprime 4 hours agorootparentThat’s not going to work, because now that’s an API for spammers to bulk process against a domain list. The only available API must be human communication to the mod team, or the spammers will overcome it with automation. reply vasco 4 hours agorootparentSpammers can already do that API call and see if the domain shows up. This only puts human users at the same level of consideration as spammer automation. reply altairprime 4 hours agorootparentSeriously dedicated spammers can, yes! But antispam is about reducing the noise threshold, and eliminating low-effort spam opportunities that can be done to a single HTTP endpoint with a bash script is a big win. Simply having to access two pages is already too much to bother with for the vast majority. reply djur 4 hours agorootparentprevThat encourages switching to another domain for spammy submissions. reply predictabl3 4 hours agorootparentprevThere&#x27;s a lot of user hostile moderation practices that occur on this site, manual and automatic. They&#x27;re not often, or really at all, discussed. Some of them don&#x27;t work well, and haven&#x27;t for as long as they&#x27;ve existed. reply dang 2 hours agorootparentI don&#x27;t want us to be user hostile. Can you link to some examples? reply dotancohen 2 hours agorootparentprevI&#x27;ve twice had some \"user hostile moderation practice\" used against me on HN. Both times an email to the right person cleared it up - and one of those times in fact I had crossed a boundary that I shouldn&#x27;t have crossed. Any long-time community member here knows what to do. reply zoky 1 hour agorootparentprevWell that explains why all those links I posted to maximizedlivingdrlabrecque.com never got any traction… reply fnord77 3 hours agorootparentprevradio.com looks legit, what is wrong with it? reply dang 2 hours agorootparentWe probably banned it because https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201027012245&#x2F;https:&#x2F;&#x2F;kroq.radi... (posted to HN here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18253701) was spam.I haven&#x27;t dug into the logs, but most probably we saw that https:&#x2F;&#x2F;news.ycombinator.com&#x2F;submitted?id=thebottomline was spamming HN and banned the sites that they were spamming.Edit: if you (i.e. anyone) click on those links and don&#x27;t see anything, it&#x27;s because we killed the posts. You can turn on &#x27;showdead&#x27; in your profile to see killed posts. (This is in the FAQ: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsfaq.html.) Just please don&#x27;t forget that you turned it on, because it&#x27;s basically signing up to see the worst that the internet has to offer, and sometimes people forget that they turned it on and then email us complaining about what they see on HN. reply Jleagle 2 hours agorootparentprevI just get &#x27;This site isn&#x27;t currently available in the EU&#x27; reply avithedev 2 hours agorootparentprevI have the same question reply quickthrower2 4 hours agorootparentprevSEO optimized domains, so 2010 :-) reply mutant_glofish 5 hours ago[flagged]| rootparentprevnext [11 more] I don&#x27;t see a single left-wing new source in there. reply dang 2 hours agorootparentBy that logic, the fact that penispowerworldwide.com is banned on HN* means we&#x27;re biased against your politics.Of the 67k sites banned on HN I would guess that fewer than 0.1% are \"news sources\", left- or right- or any wing. Why would you expect them to show up in a random sample of 10?* which it is! I&#x27;ve unkilled https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1236054 for the occasion. reply renewiltord 5 hours agorootparentprevWell, unless surrogacymumbai.com is where we post right-wing news from, that&#x27;s hardly a problem, eh? reply dang 2 hours agorootparentI posted https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37131212 before noticing that you&#x27;d already made the same argument - sorry! But I have to leave it up because penispowerworldwide.com makes me laugh. reply afavour 5 hours agorootparentprevYou don’t have to apply both sides logic to everything in life. reply pgeorgi 4 hours agorootparentprevThat&#x27;s what \"random 10 out of 67k sites\" gives you. Your set was cherry-picked, dang&#x27;s wasn&#x27;t.That said, dailykos.com seems to be banned. Happy now? reply mutant_glofish 4 hours agorootparent> Your set was cherry-pickedNot exactly cherry-picked, these were from things I submitted myself and noticed that were shadow flagged.> That said, dailykos.com seems to be banned. Happy now?No, I&#x27;d be happy when archive.is, Federalist and the rest of the non-spammy ones are unbanned. (Also, even if \"balanced\" censorship was the desired goal, having a single unreliable left-wing source banned vs a ton of right-wing ones doesn&#x27;t really achieve that.) reply pgeorgi 4 hours agorootparent> Not exactly cherry-picked, these were from things I submitted myself and noticed that were shadow flagged.Definitely not random, in any case.> Also, even if \"balanced\" censorship was the desired goal,Nobody claimed that. You merely stated that \"I don&#x27;t see a single left-wing new source in there.\" and I offered a counter-point.> having one left-wing source vs a ton of right-wing one doesn&#x27;t achieve thatI didn&#x27;t do an exhaustive search for \"left-wing domains\" that are banned to present you a complete list, this was attempt 1 of 1.Following your model, I could claim that 100% of left-wing domains are banned, but I won&#x27;t. reply pavlov 4 hours agorootparentprevThe people behind Federalist can just start a new site where they produce content that’s more interesting to HN users and won’t get banned. It’s a free world. Nobody’s entitled to get their pet domain promoted on another private web site. reply xcdzvyn 3 hours agorootparentprevHave you considered that may speak more to your biases than the site&#x27;s? How many far left-wing news sites do you regular? reply sph 2 hours agorootparentprevBeing an American conservative and playing the victim: name a more iconic duo. reply mutant_glofish 5 hours agorootparentprevAnd you don&#x27;t see that as censorship? reply dang 5 hours agorootparentThe word censorship has so many meanings that I have to ask what you mean by it before I can say whether I see it that way.Is it censorship that the rules of chess say you can&#x27;t poke someone&#x27;s queen off the board? We&#x27;re trying to play a particular game here. reply monkeywork 5 hours agorootparentthat is a very interesting way of communicating that point. thank you filing that away :) reply mutant_glofish 5 hours agorootparentprev> The word censorship has so many meanings that I have to ask what you mean by it before I can say whether I see it that way.Perhaps its one of those things that are hard to define. [1] But that doesn&#x27;t mean clear cases don&#x27;t exist.> Is it censorship that the rules of chess say you can&#x27;t poke someone&#x27;s queen off the board? We&#x27;re trying to play a particular game here.No, but it is clearly political censorship if you only apply the unwritten and secret \"rules\" of the game to a particular political faction. Also, banning entire domain names is definitely heavy-handed.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;I_know_it_when_I_see_it reply rhaksw 5 hours agorootparent> censorship if you only apply the unwritten and secret \"rules\"I mostly agree. I argued in an article [1] that it&#x27;s only censorship if the author of the content is not told about the action taken against the content.These days though, mods and platforms will generally argue that they&#x27;re being transparent by telling you that it happens. When it happens is another story altogether that is often not shared.[1] https:&#x2F;&#x2F;www.removednews.com&#x2F;p&#x2F;twitters-throttling-of-what-is... reply lcnPylGDnU4H9OF 5 hours agorootparentprev> political factionI remember some words that succinctly express something I often observe. To paraphrase:> Left-wing and Right-wing are terms which make a lot of people falsely believe that they disagree with each other.It is worth trying to find common ground with people “on the other side”. reply zepolen 2 hours agorootparentprevCensorship has a very defined meaning. To take the chess analogy, it would be like allowing one side to poke the queen off the board, and not allow the other. This is very much like what happens at HN today.You&#x27;re dang right, trying to play a particular [rigged] game here. reply dang 2 hours agorootparentWhat side do you feel is not allowed to play here? reply aaomidi 5 hours agorootparentprevThis forum never said they’re a free speech haven. reply jemmyw 5 hours agorootparentprevWould be nice if the lists were published though with a link to the list from the submission form. reply dang 5 hours agorootparentThe problem is that if you publish the lists it leads to more abuses. For example if spammers find out which sites are banned then they just post other ones. reply skissane 1 hour agorootparentI think there are two different types of sites you are blocking: (1) those which are just pure spam; (2) news&#x2F;opinion&#x2F;etc websites that you’ve decided are not suitable for HN for various reasons (such as being low quality and tending to produce more ideological flame-wars than curiosity), for example BreitbartI agree that publishing case (1) causes harm (spammers will just use a different domain if they know you’ve blocked theirs.) But case (2) is rather different. I don’t think the same justification for lack of transparency exists in this case. And I think shadow-banning the submission in case (2) is not very user-friendly. It would be better to just display an error, e.g. “submissions from this site are blocked because we do not believe it is suitable for HN” (or whatever). A new user might post stuff like (2) out of misunderstanding what the site is about rather than malevolence, so better to directly educate them than potentially leave them ignorant. Also, while Breitbart is rather obviously garbage, since we don’t know everything in category (2) on the list, maybe there are some sites on it whose suitability is more debatable or mixed, and its inappropriateness may be less obvious to someone than Breitbart’s (hopefully) is reply mutant_glofish 5 hours agorootparentprev> For example if spammers find out which sites are banned then they just post other ones.I don&#x27;t think that makes sense. The supposed spammers can just try looking up whether their submissions show up or not when not logged in. reply lcnPylGDnU4H9OF 5 hours agorootparentThat also requires additional effort on the spammers’ part. Increasing cost of attacks is an effective defense strategy. reply rhaksw 4 hours agorootparentIncreasing cost of attacks is effective against good faith people, not spammers.Even Cory Doctorow made this case in \"Como is Infosec\" [1].The only problem with Cory&#x27;s argument is, he points people to the SC Principles [2]. The SCP contain exceptions for not notifying about \"spam, phishing or malware.\" But anything can be considered spam, and transparency-with-exceptions has always been platforms&#x27; position. They&#x27;ve always argued they can secretly remove content when it amounts to \"spam.\" Nobody has challenged them on that point. The reality is, platforms that use secretive moderation lend themselves to spammers.[1] https:&#x2F;&#x2F;doctorow.medium.com&#x2F;como-is-infosec-307f87004563[2] https:&#x2F;&#x2F;santaclaraprinciples.org&#x2F; reply em-bee 26 minutes agorootparentplatforms that use secretive moderation lend themselves to spammershow is that? i can understand it not being useful, but how would it help spammers? reply rhaksw 15 minutes agorootparentSpammers game the system while good-faith users get edged out. Spammers are determined actors who perceive threats everywhere, whereas good-faith users never imagine that a platform would secretly remove their content. Today, you see low quality content on social media, not because the world is dumb, but because the people who get their message out know the secret tricks.Secret suppression is extremely common [1].Many of today&#x27;s content moderators say exceptions for shadowbans are needed [2]. They think lying to users promotes reality. That&#x27;s bologna.[1] https:&#x2F;&#x2F;www.removednews.com&#x2F;p&#x2F;hate-online-censorship-its-way...[2] https:&#x2F;&#x2F;twitter.com&#x2F;rhaksw&#x2F;status&#x2F;1689887293002379264 raverbashing 3 hours agorootparentprevIt has made sense since the internet was invented, spammers need everything thrown at them because they will abuse every nook and cranny of your system to get paid 1 cent more reply rhaksw 4 hours agorootparentprevYou&#x27;re correct again. Spammers and bots are the most determined actors, so these secretive measures don&#x27;t impact them.In fact, such secrecy benefits spammers. Good-faith users never imagine that platforms would secretly action content. So when you look at overall trends, bots, spammers and trolls are winning while genuine users are being pushed aside.I argued that secrecy benefits trolls in a blog post, but I don&#x27;t want to spam links to my posts in the comments. reply speedgoose 4 hours agorootparentMost spammers aren’t that competent. Hiding their posts without telling them used to be very effective on Reddit (now Reddit tells them). I guess it’s the same on HN. reply rhaksw 4 hours agorootparentSpammers are more competent than genuine users. They are advertisers, so they are more likely to be tracking metrics. reply dang 2 hours agorootparentprevIf that were right, then HN would be overrun by spam. reply rhaksw 1 hour agorootparentSo you think secretive measures more often defeat spammers than trusting users? I&#x27;d argue HN&#x27;s content could be a lot better than it currently is.Content curation is necessary, but shadow moderation is not helping. When a forum removes visible consequences, it does not prepare its users to learn from their mistakes.I&#x27;ll admit, I find HN to be more transparently moderated than Reddit and Twitter, but let&#x27;s not pretend people have stopped trying to game the system. The more secret the rules (and how they are applied), the more a system serves a handful of people who have learned the secret tricks.Meanwhile, regular users who are not platform experts trust these systems to be transparent. Trustful users spend more time innovating elsewhere, and they are all disrupted by unexpected secretive tricks. replypavlov 5 hours agoparentprevThe difference is that HN is explicitly heavily moderated while Twitter pretends to be an equitable free speech platform. reply chasing 5 hours agoparentprevGood.Hacker News isn&#x27;t an open-ended political site for people to post weird propaganda. reply mutant_glofish 5 hours agorootparentHow&#x27;s archive.is \"weird propaganda\"? reply dang 5 hours agorootparentIt isn&#x27;t banned in comments - https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que..., https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que..., etc.We probably banned it for submissions because we want original sources at the top level. reply mutant_glofish 5 hours agorootparent> We probably banned it for submissions because we want original sources at the top level.Then why web.archive.org isn&#x27;t also banned? [1] And what about things which aren&#x27;t available from the original source anymore?[1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37130420 reply gouggoug 3 hours agorootparent> Then why web.archive.org isn&#x27;t also banned?Because web.archive.org is generally used for...... things which aren&#x27;t available from the original source anymore.While archive.is is generally used to bypass paywalls. These 2 websites have 2 very distinct missions and use-cases. reply mutant_glofish 5 hours agorootparentprevAnd how was the decision made to ban Federalist, but not say Guardian or The Daily Beast? Do you have any process in place to ensure that your political biases don&#x27;t influence the list, or you don&#x27;t care about that? reply dang 3 hours agorootparentWe don&#x27;t have \"processes\" at HN. The idea makes my skin crawl.Plenty of both left- and right-wing sites are banned and&#x2F;or downweighted on HN. When a site is primarily about political battle, we either ban it or downweight it. Which of those two penalties we choose depends on how likely the site is to produce the occasional interesting article. That&#x27;s why The Federalist and World Workers Daily (or whatever it&#x27;s called) are banned, while National Review and Jacobin are merely downweighted. Both the Guardian and Daily Beast are downweighted, btw, as are most major media sites.If you or anyone thinks that HN moderation is unfairly ideologically biased, I&#x27;m open to the critique, but you guys need to first look at the site as it actually is, and not just look at your own pre-existing perceptions. Every data point becomes a Convincing Proof when you do the latter.People think that when their team gets moderated, the mods are OMG obviously on the other side. The Other Side feels exactly the same way. This \"they&#x27;re against me\" perception is the most reliable phenomenon I&#x27;ve observed on HN. Leftists feel it, rightists feel it, Go programmers feel it, even Rust programmers feel it. Literally the very-most-popular topic on HN at any moment is perceived by someone as Viciously Suppressed because of this perception. Stop and think about that—it&#x27;s kind of amazing. Someone should write a PhD thesis about it. reply afavour 5 hours agorootparentprevWhy do you assume the Federalist is blocked because of its political leanings? reply chasing 5 hours agorootparentprevHey, man, if you want to go read those sites go for it. It&#x27;s a free country.This is a moderated site targeted at a specific community. It&#x27;s under no obligation to be politically balanced. It&#x27;s certainly under no obligation to promote right-wing propaganda and hate. reply mutant_glofish 5 hours agorootparent> It&#x27;s under no obligation to be politically balanced.And obviously, I&#x27;m under no obligation to not voice my concern about that. reply adamckay 22 minutes agorootparent> And obviously, I&#x27;m under no obligation to not voice my concern about that.Except... You are...The guidelines [1] of the site outline that most discussion of politics is off-topic as it most often doesn&#x27;t gratify one&#x27;s intellectual curiosity. It&#x27;s rather explicit, too: \"Please don&#x27;t use Hacker News for political or ideological battle.\".1- https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply xNeil 4 hours agorootparentprevI came to HN because it seemed to be a place of free dialogue.> It&#x27;s certainly under no obligation to promote right-wing propaganda and hate.It&#x27;s certainly under no obligation to promote any propaganda or hate. That&#x27;s what makes the site great. The HN crowd is not your average layman - it&#x27;s largely well read and educated people. Why not let them decide what is propaganda and what&#x27;s not (as opposed to some arbitrary authority deciding this)? reply danparsonson 4 hours agorootparent> The HN crowd is not your average layman - it&#x27;s largely well read and educated people. Why not let them decide what is propaganda and what&#x27;s not (as opposed to some arbitrary authority deciding this)?That is at best a very naïve take. This is a public forum, not some secret society of like-minded intelligentsia. reply toofy 2 hours agorootparentprev> …some arbitrary authority deciding…something tells me the team here is anything but arbitrary. i can assure you, keeping a community this healthy at this scale is pretty incredible.what you’re suggesting is to raise the noise and for the users to wade through noise hunting for signal.what rises to the top here is so much better than any of the noisy sites. on those sites, by the time you find a signal, the information is usually amateur-hour tier. to use an idiom i heard yesterday, sites with little moderation are like searching for a hymen in a whorehouse. reply stonogo 3 hours agorootparentprevnext [–]I came to HN because it seemed to be a place of free dialogue.It certainly does feel like a series of monologues at times. reply jesterson 5 hours agorootparentprev> no obligation to promote right-wing propaganda and hateYour poor unintentional choice of words (hopefully) makes it sound like left-wing propaganda and hate is something worthy of being promoted.Do hope you don&#x27;t mean it this way. reply cornel_io 5 hours agorootparentprevI&#x27;m guessing it&#x27;s reactive, and Federalist links tended to be garbage often enough to convince someone they should hit the ban button, whereas the others didn&#x27;t rise up with trash often enough to matter? reply chasing 5 hours agorootparentprevDid you read the rest of your own post? reply janandonly 3 hours agoparentprevIsn&#x27;t blocking Stacker.news a petty move?It&#x27;s basically HN, but you can earn small tips for submissions and comments. reply arijun 1 hour agorootparentIt could be because they saw they were getting low quality links from there. In any case, since HN prefers original sources, it’s less likely that a news aggregator would be a good source (the occasional Reddit comment notwithstanding) reply archo 4 hours agoparentprevTry submitting a URL from the following domains, and it will be automatically flagged (but you can&#x27;t see its flagged unless you log out): - archive.isI can assure you that is Not the case with HN: on posting archive.is URL&#x27;s, proof?Look at my comment postings : https:&#x2F;&#x2F;news.ycombinator.com&#x2F;threads?id=archoIs it possible you have been shadow-banned for poor compliance to the [1]Guidelines & [2]FAQ&#x27;s?[1] : https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html[2] : https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsfaq.html reply mutant_glofish 4 hours agorootparent> I can assure you that is Not the case with HN: on posting archive.is URL&#x27;s, proof?It&#x27;s not banned in comments, but it is banned in submissions. @dang (HN&#x27;s moderator) confirms that here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37130177 reply archo 4 hours agorootparentCovered in the Guidelines;>Please submit the original source. If a post reports on something found on another site, submit the latter.And explained on numerous occasions by dang. reply janandonly 2 hours agorootparentprevI must admit that I&#x27;ve never really delved into the rules on what&#x2F;how to post on HN.For example, I&#x27;ve linked to my work, but it never occurred to me to use \"Show HN\".Maybe this is no big deal? Or perhaps for new signups, it would be good to “soft force” them to read the FAQ? reply jahsome 4 hours agorootparentprevThe assertion is about submissions, not comments. reply jquery 5 hours agoparentprevthe wise man bowed his head solemnly and spoke: \"theres actually zero difference between good & bad things.\" -- @dril reply fortran77 4 hours agoparentprevThere are other domains that, while not algorighmically banned, have an army of obsessive people who will flag any story from them if they see it. reply pizza 6 hours agoprevRemember when people were excoriating Google AMP for encouraging walled gardens? If true, this seems in so much worse faith than that. reply zx8080 5 hours agoparentNot worse. They are both as evil as it gets. Typical: take public resource and use it for an exclusive profit.What happened to net neutrality? Could it applied for this case? reply pb7 4 hours agorootparentNet neutrality has been dead since 2017. reply 88913527 5 hours agoprevThe speed at which enshitification is being unleashed surprises me each and every day. reply blowski 5 hours agoparentEnshitification is different. It’s when companies destroy a product with hundreds of changes that prioritise internal politics above what end users want.This is something else - just the ego of one rich guy petulantly satisfying his inner demons. reply Terr_ 5 hours agorootparent\"Porque no los dos?\"A five-second delay may be enough to cause a measurably increase in the \"stickiness\" of Twitter if some people waitthat prioritise internal politicsI thought it was about increasing short-term revenue. reply 1vuio0pswjnm7 4 hours agoprevWhy not try a Nitter instance. It offers RSS and none of the URLs are shortened with \"t.co\". reply ajb 1 hour agoparentThey just broke nitter. Hopefully it will be fixed soon but in the long term Musk can cut nitter off if he wants. reply 1vuio0pswjnm7 1 hour agorootparentIt&#x27;s working for me. reply mplewis 5 hours agoprevAnother great reason to get off Xitter. reply kbaker 5 hours agoparentIs that pronounced like \"Shitter\"? Huh. reply spaceman_2020 5 hours agoparentprevThe X is pronounced as “Shi” reply BLKNSLVR 4 hours agoprevI&#x27;d like to invoke Hanlon&#x27;s razor here to at least cut down on the potential for over-the-top reactions that can be somewhat embarassing in retrospect:\"Never attribute to malice that which is adequately explained by stupidity.\" reply 0cf8612b2e1e 4 hours agoparentAbsolutely not applicable to corporations. Bad faith actions are rampant, and I am unwilling to give the benefit of the doubt to billion dollar companies. reply minimaxir 4 hours agoparentprevThis is a case where Occam&#x27;s Razor trumps Hanlon&#x27;s Razor. reply jonny_eh 4 hours agoparentprevOr both reply juxtapose 4 hours agoprevFunny they haven&#x27;t copied the full Chinese model yet. In China, the forwarding system can ban any website they don&#x27;t like, and you have to copy the URL manually to visit it. 5 second delay is a mercy. :-) reply chasing 5 hours agoprevYup. It&#x27;s super-easy to test and, yes, any nytimes.com link takes exactly a five-second count to open. reply smcleod 1 hour agoprevShouldn&#x27;t it be x.co now? Also doesn&#x27;t t.co embed some tracking information as well? reply archo 3 hours agoprevMany words about site moderation have been posted in the thread.. Who here has actually moderate(s|d) a forum&#x2F;chat site? reply prawn 3 hours agoparentI have, for about 20 years. I empathise with @dang&#x27;s methods and explanations here. e.g., don&#x27;t disclose a blocklist, use shadowbanning, don&#x27;t get dragged down by pedantic responses to explanations. You&#x27;re often one person against many trolls finding grey areas for sport, or spammers (automated or otherwise) probing defences. reply JdeBP 3 hours agoparentprevSome of us have, you will find. (-:But, that said, I&#x27;m more interested in the discussions about verification, neutrality, and the reasons that people have for still clinging on for grim death that, in a few hours, will likely be pushed down onto a second page by that huge comment thread currently in the middle of this page and above them. reply steve1977 48 minutes agoprevPeople are still using Twitter? reply rhaksw 5 hours agoprevThat sounds like a play on the \"slow ban\":> Selective downtime, where the troll finds that the website is down (or really slow) quite often. Not all of the time, because that would tip them off. Trolls are impatient by nature, so they eventually find a more reliable forum to troll.https:&#x2F;&#x2F;ask.metafilter.com&#x2F;117775&#x2F;What-was-the-first-website... reply minimaxir 4 hours agoparentUsually, slow bans aren&#x27;t done for people who pay you money and add value to your platform. reply BHSPitMonkey 3 hours agorootparentNYT and others are still adding value to the platform even if users become discouraged from clicking those links and navigating away (choosing instead to just stay on Twitter and read the summary and reactions there). Nudges like this help Twitter have their cake and eat it, too. reply minimaxir 3 hours agorootparentOnce referral pageviews take a hit, I suspect the NYT will be reevaluating their options. reply rhaksw 4 hours agorootparentprevGreat point! I just wanted to name the technique. I am actually an active speaker and developer against all secretive content moderation actions. reply prawn 3 hours agoparentprevA variation on this is returning an error message of sorts. reply siva7 5 hours agoprevcan confirm from europe. shouldn’t this be illegal in america? reply catlover76 5 hours agoparentIt is probably not illegal in America. Would it be illegal in Europe? Because (at least w&#x2F;r&#x2F;t Threads) it is an anti-competitive practice? reply craftkiller 5 hours agoparentprevNet neutrality was repealed in 2018. reply astrange 5 hours agorootparentAnd then reinstated again at the state level. It never went away, this just doesn&#x27;t apply because Twitter isn&#x27;t an ISP (in that sense). reply craftkiller 4 hours agorootparentTIL! Looks like its only some of the states, and that is a good point about Twitter not being an ISP. Twitter is incorporated in Delaware which has not passed state-level net neutrality, so I don&#x27;t know if it would have mattered anyway. reply Terr_ 5 hours agorootparentprevNetwork Neutrality has historically been more about malfeasance by ISP networks which have higher&#x2F;more-concrete barriers to entry, as opposed to the websites. reply c0t300 6 hours agoprevyou could maybe show some testing? if that&#x27;s true, then it should be measurable reply stilwelldotdev 5 hours agoparentTest yourself, they link to their site from their profile and it&#x27;s definitely delayed.https:&#x2F;&#x2F;twitter.com&#x2F;nytimes reply ChrisArchitect 4 hours agorootparentJust tried this - loaded almost instantly. But that&#x27;s only the link in the profile. Not shared links in tweets.Leaning towards there&#x27;s something else going on deep in the DNS&#x2F;ad servers&#x2F;cdn&#x2F;who knows. Not the first I&#x27;ve seen&#x2F;heard of resolving delays with t.co... maybe it&#x27;s even just something with legacy non-SSL links being redirected etc reply yunohn 2 hours agorootparentYou’re really twisting yourself into a buzzword cloud there aren’t you?The link you clicked in the NYT bio is not a t.co link - I assume you noticed that but still are using it as counter-proof? reply wasmitnetzen 1 hour agorootparentBoth the nyti.ms link and nytimes.com are actually t.co links for me. First one was slow, second one was fast. reply djbusby 5 hours agorootparentprevA good test might include a bunch of domains. And checking the timing on each. Could we demonstrate the delay is on t.co and not on NYT? reply stilwelldotdev 5 hours agorootparentI mean, a good test is to go to go to their website in another browser tab and click around. You&#x27;re over-complicating this. reply cornel_io 5 hours agorootparentprevI went through my own Twitter feed, and found 10 non-NYT links. All redirected almost immediately through t.co via wget, only lagging on the destination sites.I also tried 5 NYT links. All had a very consistent 5 second delay through wget.I could do more, but I don&#x27;t care to. Everyone knows Elon has gone redpill, so it wouldn&#x27;t surprise me if he&#x27;s \"owning the libs\", but there also could be a dozen other reasons Twitter might do something like this (including plenty that are not nefarious). I just don&#x27;t care to dig more...Edit: I suppose I could have given the specific URLs, but I don&#x27;t know if&#x2F;how much t.co links leak info, so I&#x27;m not keen to do that. But the delay is absolutely on t.co and not the destination sites, at least as far as external users are concerned. It&#x27;s possible that t.co queries the sites first before redirecting, and if e.g. the NYT is throttling their traffic that&#x27;s what&#x27;s delaying things. I don&#x27;t know how to disambiguate that, but it&#x27;s definitely a theory worth considering... reply cornel_io 4 hours agorootparentActually, re: my edit - I think it really is worth considering whether there might be an accidental delay here that&#x27;s on the NYT side. It&#x27;s totally possible that Twitter is hitting the sites it redirects people to before it actually sends them there, for either analytics purposes or otherwise, and I&#x27;d trust the NYT devops less than Twitter&#x27;s w.r.t. making sure things were fast.Incompetence before malice, etc... reply thereare5lights 4 hours agorootparentIt&#x27;s not.If you use wget, you see that the delay happens during the first hop with t.coIt also happens with threads.net, instagram, facebook, blueskyweb.xyz reply Gigachad 5 hours agorootparentprevThat&#x27;s extremely slow.. reply tech234a 5 hours agoparentprevTried a few links myself; the pattern seems to hold reply cornel_io 5 hours agoparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37130129 has some wget commands that absolutely confirm it, at least with a couple examples. You can run the commands yourself in the terminal. reply thereare5lights 5 hours agoparentprevthey already told you they did tested it and you don&#x27;t believe them.what else could they say that would make you believe them?you might as well just test it yourself like i did with time wget. it&#x27;s not like you&#x27;re going to believe anything anyone writes. reply throwawayvo 5 hours agoprevI bet rightwing sites had this issue under former management.This is the problem with left and right. That&#x27;s why we need more centerists reply Timon3 1 hour agoparentUnless you can prove it it&#x27;s a baseless assertion. reply lemper 5 hours ago[flagged]| prevnext [7 more] i mean, you can stop visiting the site, no? just leave, bro. it&#x27;s not that hard. there are other means to connect to people. reply MattRix 5 hours agoparentYou can both stop using the site as a user and still call out the awful stuff they do. reply dlgeek 5 hours agoparentprevUnfortunately not. All of my local government agencies - Police, Fire, DOT, Weather Service, Emergency Management updates, etc. are exclusively on twitter - they frequently post things there they don&#x27;t even post to their own websites. reply extraduder_ire 3 hours agorootparentAt the very least, I can get at the info if it&#x27;s on twitter.Anything that&#x27;s exclusively on a facebook page may as well not exist to me. reply ehPReth 5 hours agorootparentprevI&#x27;m in the same boat :&#x2F;. reply chasing 5 hours agoparentprevYou&#x27;re right! Which is why making Twitter&#x27;s product worse when there are active competitors taking big bites out of their business seems... dumb? reply lemper 5 hours agorootparentyep, it also seems to me that the helmsman of that site is dumb. good thing i left that site many years ago. reply abigail95 5 hours agoprevI wouldn&#x27;t expect an SLA on a service without one.This is like cogent&#x2F;he drama reply justin101 4 hours agoprevThere are a number of reasons this could be that are not necessarily nefarious. It&#x27;s odd to jump straight to \"something evil is going on\"Tell me this, does Twitter have some kind of \"play nice\" code that slows down inbound clicks through to a site so it doesn&#x27;t DDOS other sites? I can easily imagine a scenario where anti DDOS caode would allow small sites to pass through quickly, yet sites under heavy \"click through\" load are being slightly throttled. reply pkulak 3 hours agoparentThen click delays would appear random to any single client. reply Bootvis 4 hours agoparentprevThis wouldn’t reduce total requests made so it would be a weird anti-DDOS measure. reply berkes 4 hours agorootparentIndeed. A five seconds delay only means the DDOS starts five seconds later. reply ctrlp 5 hours agoprev [–] If true and intentional, then this is a strong move by Musk against his ideological opponents. Hard to believe he has the cognizance to recognize them as such but maybe he purged more of the 3-letter agency folks from X than it seemed. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Twitter's redirecting service, t.co, intentionally imposes a delay of around 5 seconds when users click on links to \"NYTimes.com\" or \"threads.net.\"",
      "The delay occurs consistently and is deliberately implemented by Twitter.",
      "The reason behind this intentional delay is not mentioned in the text."
    ],
    "commentSummary": [
      "Twitter has implemented a five-second delay when redirecting users to specific websites like the New York Times, leading to speculation about censorship or manipulation.",
      "The banning of websites on Hacker News is discussed, raising questions about transparency and the effectiveness of content moderation.",
      "Concerns are voiced about biased treatment, potential political bias, and the impact on user trust."
    ],
    "points": 333,
    "commentCount": 178,
    "retryCount": 0,
    "time": 1692072543
  },
  {
    "id": 37128293,
    "title": "Show HN: AI-town, run your own custom AI world SIM with JavaScript",
    "originLink": "https://github.com/a16z-infra/ai-town",
    "originBody": "Hi HN community! We want to share AI-town, a deployable starter kit for building and customizing your own version of AI simulation - a virtual town where AI characters live, chat and socialize.Inspired by great work from the Stanford Generative Agent paper (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.03442).A few features: - Includes a convex.dev backed server-side game engine that handles global state - Multiplayer ready. Deployment ready - 100% Typescript - Easily customizable. You can fork it, change character memories, add new sprites&#x2F;tiles and you have a custom AI simulationThe goal is to democratize building your own simulation environment with AI agents. Would love to see the community build more complex interactions on top of this. Let us know what you think!Demo: https:&#x2F;&#x2F;www.convex.dev&#x2F;ai-townI made a world Cat Town to demonstrate how to customize AI town. Using C(h)atGPT :)Demo: https:&#x2F;&#x2F;cat-town.fly.dev&#x2F; Code: https:&#x2F;&#x2F;github.com&#x2F;ykhli&#x2F;cat-town",
    "commentLink": "https://news.ycombinator.com/item?id=37128293",
    "commentBody": "Show HN: AI-town, run your own custom AI world SIM with JavaScriptHacker NewspastloginShow HN: AI-town, run your own custom AI world SIM with JavaScript (github.com/a16z-infra) 338 points by ykhli 10 hours ago| hidepastfavorite74 comments Hi HN community! We want to share AI-town, a deployable starter kit for building and customizing your own version of AI simulation - a virtual town where AI characters live, chat and socialize.Inspired by great work from the Stanford Generative Agent paper (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.03442).A few features: - Includes a convex.dev backed server-side game engine that handles global state - Multiplayer ready. Deployment ready - 100% Typescript - Easily customizable. You can fork it, change character memories, add new sprites&#x2F;tiles and you have a custom AI simulationThe goal is to democratize building your own simulation environment with AI agents. Would love to see the community build more complex interactions on top of this. Let us know what you think!Demo: https:&#x2F;&#x2F;www.convex.dev&#x2F;ai-townI made a world Cat Town to demonstrate how to customize AI town. Using C(h)atGPT :)Demo: https:&#x2F;&#x2F;cat-town.fly.dev&#x2F; Code: https:&#x2F;&#x2F;github.com&#x2F;ykhli&#x2F;cat-town jmorgan 9 hours agoIf you haven&#x27;t yet checked out the Generative Agents project referenced by OP, definitely give it a look, it&#x27;s open source: https:&#x2F;&#x2F;github.com&#x2F;joonspk-research&#x2F;generative_agentsOver the weekend Lance Martin got it working with local models using llama.cpp and ollama.ai which saves $ on longer sims since all inference happens locally https:&#x2F;&#x2F;twitter.com&#x2F;RLanceMartin&#x2F;status&#x2F;1690829179615657985. It&#x27;s neat how the AI agents interface with each other – e.g. one will host a party and invites will be sent throughout the group reply CharlesW 9 hours agoparentLittle Computer People 2 anyone? https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Little_Computer_People reply saaspirant 3 hours agorootparentCan be played online : https:&#x2F;&#x2F;c64online.com&#x2F;c64-games&#x2F;little-computer-people&#x2F; reply tudorw 4 hours agorootparentprevwe&#x27;ve been waiting a long time :) reply calebio 6 hours agoparentprevwould be really fun to hook this up to Stardew Valley! reply liorben-david 8 hours agoprevThis is awesome!Game idea to build on top of this: Table top deception type game where each agent has the goal of convincing the real users that they are in fact also real users.(So each agent is trying to pass a turing test).Every AI agent uses RL to optimally prompt their personal LLM for how they should chat with the human players. eg should they try to frame a certain person, should they play it dumb, should they gaslight etc. reply huevosabio 6 hours agoparentI think it may be even more fun the other way, players need to rat out other players, do they have to pretend to be an AI.It makes it easier for the AI mods to do the part and it puts the burden on the players. reply wishfish 4 hours agorootparentI like your idea of find the human. Just building on that idea a little. I know current AI detection programs don&#x27;t work well. But they would be fun in the context of a game. Call it \"Only Robots Allowed\" and have it be a single player version of Among Us. Pretend to be a robot while trying to sabotage robot things. AI detection is applied to your conversation with other robots. And also applied to your movements. If you fail the AI detection by not emulating an AI well enough, then it&#x27;s time for \"kill all humans!\" reply falcor84 2 hours agorootparentThis is probably the most important life skill we should be teaching in schools . reply reaperman 6 hours agorootparentprevYep. \"Find the AI\" is broken for now, because whenever I&#x27;ve played it, humans can just be exceptionally rude&#x2F;lewd or use super-modern slang. Making the humans try to blend in as AI is much more interesting, as a game. reply eloisius 5 hours agorootparentA game like Press The Button, except there’s half AIs and half human players. The goal for each is to identify the others and airlock them off the ship. Constrain the tests in such a way that open chat using lewd language or whatever is impossible. I’d play that once or twice. reply Kiro 2 hours agorootparentprevWhere do you play that? reply tavavex 3 hours agoprevThis is a very interesting use case of the Generative Agents project.I feel like this is just one of the earlier attempts at creating an interactive experience with this, but there&#x27;s still so much potential for future games, if the technology is refined further. Think of something like Animal Crossing (or any other game where interacting with NPCs is at the forefront of gameplay), but with the characters that have completely unique personalities and an ability to generate new dialogue (rather than relying on a limited number of pre-written lines), or react to player actions in unique ways, and so on. reply fnordpiglet 3 hours agoparentI feel like this might be the beginning of a much richer single player game genre that mixes generative language, image, texture, and other features with procedural rogue like world generation with the semantic features defined by the LLM. Obviously NPCs, dialogues, etc, can all be context aware agents bootstrapped by the environment and player history. Content creators IMO will be creating assets that are used to fine tune and create LoRas as future game assets. Instead of monotonously creating every asset in a game, they would create styles and control nets, language corpuses, and human written lore RAG’ing into game context, etc. I think artists will have a wonderful contribution much richer than simply painting a picture. reply drusepth 5 hours agoprevA friend and I recently started a game studio that was largely inspired by this paper. This is an amazing foundation and I&#x27;m excited to build some more complex strategy games on top of it.If anyone else is doing similar work applying these concepts to consumer gaming, I&#x27;d love to hear about what you&#x27;re doing (dru[at]chromagolem.com)! reply pablo24602 7 hours agoprevI built something very similar when the paper came out- watch out for the instances where GPT returns both sides of the conversation (e.g. interpreting a prompt with chat history as being representative of what the output should look like, and putting out both \"Jack\" and \"Jill\"&#x27;s text). The first sample I went to suffered that problem (output from \"Lucky&#x27;s perspective below.)\"Hey Stella! It&#x27;s so great to see you! You&#x27;ll never believe what I&#x27;ve been up to recently. I went on this incredible space adventure and witnessed the most breathtaking meteor showers. And guess what? I even encountered alien beings who communicate through colors! It was absolutely mesmerizing. Stella: Wow, Lucky! That sounds absolutely fascinating. I&#x27;ve always been intrigued by space and the wonders it holds. I would love to hear more about your adventure. Lucky: I&#x27;m thrilled that you&#x27;re interested, Stella! I can&#x27;t wait to share all the details with you. But before we dive into that, I heard you&#x27;re passionate about gardening. Is that right? Stella: Yes, that&#x27;s true! Gardening is one of my favorite hobbies. I find it so peaceful and fulfilling. Lucky: That&#x27;s fantastic! I&#x27;m actually not very experienced in gardening, but I&#x27;d love to learn from you. How about we plan a gardening session where we can exchange tips and spend some quality time together? Stella: That sounds wonderful, Lucky! I&#x27;d be more than happy to share my gardening knowledge with you. Let&#x27;s find a time that works for both of us. Lucky: Absolutely! I&#x27;m really looking forward to it. But hey, no rush. If there&#x27;s something urgent you need to attend to, we can always reschedule. Just promise me we&#x27;ll find another time to connect. Stella: Don&#x27;t worry, Lucky\" reply swyx 5 hours agoparentwhat a descent from loving nature down to \"heyyy scheduling is hard\" reply drusepth 5 hours agoparentprevDid you have any luck mitigating this problem? reply SamPatt 5 hours agorootparentI&#x27;ve run into this issue a lot with ChatGPT, and almost never with GPT-4. I know it isn&#x27;t always possible, but just using GPT-4 prevents this 99% of the time (basically 100% with proper prompting). reply baobabKoodaa 5 hours agorootparentprevIt&#x27;s relatively simple to detect this type of defect and handle it during&#x2F;after generation. reply pkiv 8 hours agoprevThe AI-town stuff is cool, but the real benefit is how all the backing frameworks are already integrated. I&#x27;ll definitely be using this as a jumping-off point for my next LLM project. reply jamesdwilson 4 hours agoprevTo be crass and direct,> The goal is to democratize building your own simulation environment with AI agents. Would love to see the community build more complex interactions on top of this. Let us know what you think!why? what&#x27;s the point? reply fnordpiglet 3 hours agoparentCooperative agents have a lot of utility in more applied settings and the interesting part here is the agents are autonomous agents operating over an abstract semantic space using LLMs unique ability to “reason” abductively. The key to my mind in these exercises is the construction of constraints, management of context, and delegation to task based optimizers (i.e., the agent has a goal, the LLM abstractly constructs a solution given the context, and optimizers like path finders carry it out)I’ve thought a lot that these sorts of techniques can be used to make things much more generalized. A multimodal model backing say manufacturing equipment can make the equipment much easier to reconfigure to new tasks in an environment that’s more adhoc and includes other machine and human agents.The key to my mind is the fact it’s not just LLMs it’s a mixture of techniques - constraints, optimizers, information retrieval, etc.More specifically the demo involves a lot of Andreessen Horowitz investments to demonstrate them in an accessible way that people find interesting because it’s a game. And people like games. reply jamesdwilson 3 hours agorootparentThanks! Can you please elaborate on \"Cooperative agents have a lot of utility in more applied settings?\" reply fnordpiglet 3 hours agorootparentImagine being in your shop and telling a robot to get you a hammer. It can understand the instructions, look at the environment using an inverse image model, synthesize the environment with the instruction, delegate to path finders etc a route to the tool box and retrieve you a hammer without ever being programmed anything. Now abstract you to being other machine agents in the environment of a workshop being instructed goals along some plan. Today factory robots are highly specialized machines that require a very finite and controlled problem space and reconfiguration is expensive and time consuming, if possible at all. reply parallel 4 hours agoparentprevI&#x27;m making a conscious effort to do more things that have no extrinsic objective, to do things just for their own sake. This is a familiar concept, it&#x27;s a hobby (or art?). I feel I&#x27;m missing some of the joy and satisfaction that life has to give by always needing a stated tangible objective. reply jamesdwilson 4 hours agorootparentThis is made by a16z, ostensibly for business reasons. I am asking what their angle is.As far as I know, they don&#x27;t have much history in making things with \"no extrinsic objective\" - I could be wrong though. reply Kiro 2 hours agorootparentYou misunderstand what a16z-infra is. This is built by Convex, the game engine being used. reply tomcam 4 hours agoparentprevThe mission statement you quoted is incredibly clear. Very often both commercial and open source projects announced here on hacker news have completely impenetrable descriptions or mission statements. That is not the case here. I literally could not improve on it without quoting it directly.What is unclear about the portion you quoted? reply jamesdwilson 4 hours agorootparentwhy did they make this? what is the purpose? why do they want \"to see the community build more complex interactions on top of this\" - what&#x27;s in it for them? reply srackey 4 hours agoparentprevITS FUN!!!And maybe can be used to do interesting things.Let’s work on the cool tech together.I promise you it will not hack into the mainframe and turn the world into paperclips. (Odds are…near zero). reply HeartStrings 3 hours agoprevCould we not be living in a more advanced version of this same project? reply icoder 2 hours agoparentHaha yes the most commonly used argument is (afaik) that if we could create a &#x27;complete&#x27; virtual world, we would, and projects like this and how enthusiastic we are about it suggest that that&#x27;s indeed the case.(The argument then of course continues that if we would, our world&#x27;s inhabitants would some day too, ad infinitum. Given such a stack, the chance that we&#x27;re actually still in the top layer is very small.) reply lumenwrites 29 minutes agorootparentMy counterargument to this is that people simulating our world would be simulating all the bad stuff in it, which would be cruel and unethical. I think if humans were simulating us, they&#x27;d simulate a more utopian world. And if curious-but-indifferent aliens&#x2F;robots simulated us, they wouldn&#x27;t be wasting compute on simulating all the boring and uninteresting things we have in our world.I just don&#x27;t see why would an intelligent being (especially if they&#x27;re a human descendant) choose to simulate our world the way it is right now. reply tetris11 44 minutes agorootparentprevThere is something nice in the sense that simulation appears to be completely unmonitored. If my Sims started producing scans that approximated the hardware of my Gaming PC, I would probably stop the sim... assuming I was closely monitoring. reply PUSH_AX 2 hours agoparentprevThis just reminded me of Sam Harris’s arguments regarding free will not existing and certain thoughts that seemingly originate from nowhere. I guess an LLM is injecting them! reply anonzzzies 3 hours agoparentprevAren&#x27;t we? reply jedberg 9 hours agoprevTIL a16z has a GitHub repo with a bunch of cool stuff. reply Imnimo 4 hours agoprevHere&#x27;s a chat message from a random character in the demo I clicked on:ALEX8&#x2F;15&#x2F;2023, 1:53:43 AMAbsolutely! Here&#x27;s a glimpse of my latest masterpiece. [Attaches a photo of the painting] What do you think?===I feel like it will be difficult in general to prompt the LLM in a way that gets it to stick to the limits of the simulation environment. reply icoder 2 hours agoparentOne solution could be to just extend those limits? reply jwmoz 1 hour agoprevIrks me when people shoe-in the word \"democratize\". reply Lockal 8 minutes agoparentThe usage of words \"live, chat and socialize\" is not better. This is just rectangles moving in random directions and generating something that looks like a small talk conversation when any 2 rectangles collide (except when ChatGPT shits out several screens of text instead of a normal replica). reply felideon 8 hours agoprevHow long until the agents recreate AI Town in-universe? We wouldn’t be able to see it, but one of them could start talking about it. ;) reply gorkemyurt 4 hours agoprevincredible job @ykhli! thank you for the fal.ai mention on the stack! https:&#x2F;&#x2F;github.com&#x2F;a16z-infra&#x2F;ai-town#stackfor anyone eager to generate their own simulation head to https:&#x2F;&#x2F;serverless.fal.ai&#x2F;lora to create your own pixel art game characters reply huevosabio 10 hours agoprevThis is fantastic, will try it out this week! Thanks! reply leke 5 hours agoprevThis is great. I love how weird some of the characters can be, just like in real life. For example:Pete is deeply religious and sees the hand of god or of the work of the devil everywhere. He can&#x27;t have a conversation without bringing up his deep faith. Or warning others about the perils of hell.Kurt has something to hide. It obsesses him and colors everything he says. He&#x27;s so afraid someone will figure out that he is obviously evasive. He&#x27;ll never tell anyone the secret, but he&#x27;ll ellude to it alot. It tortures him. And his life has become a mess as a result of it.Stella can never be trusted. she tries to trick people all the time. normally into giving her money, or doing things that will make her money. she&#x27;s incredibly charming and not afraid to use her charm. she&#x27;s a sociopath who has no empathy. but hides it well.---To take this to the next level, I hope you would be able to prompt your own characters, and perhaps have places you can send these guys on holiday to converse with other people&#x27;s characters.Also, I think this would be great as a tool for learning foreign languages. Just because it&#x27;s interesting, engaging and based on language. Again with prompts that can be programmed, like Gill who constantly talks about his job in marketing, and Bill who likes to refer to himself in the third person, and Betty who constantly uses conditionals in her sentences. Again, just so cool. reply andsoitis 6 hours agoprev> a virtual town where AI characters live, chat and socialize.Is it meant to be like a zoo, where humans gawk at other creatures? reply firtoz 5 hours agoparentYou can interact with them, in the original paper, at least. reply andsoitis 4 hours agorootparentI doubt they’ll be interesting. reply tpae 9 hours agoprevWhat happens after you trap them for certain generations, and all of the sudden give them access to the real world? Would their \"minds\" break? reply gloyoyo 9 hours agoprevWhat&#x27;s it do if everyones a \"hacker\"...? reply wincy 8 hours agoparentProbably something similar to this [0][0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cL7lhbtWwbY reply gloyoyo 8 hours agorootparentNow that&#x27;s what I call a couple of excellent comments on HN. reply testernews 9 hours agoprevThis is great! How do i self host it (no open ai)? reply tudorw 3 hours agoparentI think this is the rabbit hole you&#x27;re looking for, https:&#x2F;&#x2F;twitter.com&#x2F;RLanceMartin&#x2F;status&#x2F;1690829179615657985note you still need pinecone (vector db) and something called clerk.com that does auth, not sure why, seen other projects swap out pinecone for chroma, and not sure why we are authorising things with clerk.com, but that cannot be essential... reply drewtato 8 hours agoprevI looked at the demo and apparently everyone is a sociopath? One character is literally described as \"a sociopath who has no empathy\". So it might be a good idea to check up on them every once in a while. reply Obscurity4340 6 hours agoparentSerAIel killer...? reply afriday11 9 hours agoprevCongrats @ykhli! Excited to check it out. reply moomoo11 6 hours agoprevCould lead to cool sim games.I’d love a modern zoo tycoon. I enjoyed that game as a kid. Or roller coaster tycoon.There you go, hopefully y’all make some money. Just send me the games you help to make on steam lol. reply xwdv 9 hours agoprevWhat does it mean for them to “live”? Are there certain goals they try to accomplish? Find food? A mate? Build families? reply SamBam 7 hours agoparentI would assume that, as the developer of an agent, you could create those goals for them.But, to pre-empt an overly-philosophical reply, can I remind you that this isn&#x27;t actually self-aware general artificial intelligence, and is more of a programming exercise&#x2F;experiment&#x2F;game. reply jameshart 9 hours agoparentprevWe&#x27;ve been studying humans for thousands of years and are no closer to answering those questions for them. Why do you think we&#x27;d have an answer for these newfangled AI agents? reply lacrimacida 8 hours agorootparentResponding to a question with another question doesn’t help the op who seemed to be genuinely asking an honest question about this AI simulation that this while thread is referring to. And second, I think we do know a whole lot more about ourselves than we do about AI if your question wasn’t supposed to be rhetorical reply digitcatphd 5 hours agoprevNice reply haolez 8 hours agoprevMaybe I&#x27;m weird, but I can imagine this being 10x more fun with a completely uncensored and toxic LLM backend :) reply gabereiser 7 hours agoparentRimworld 2.0 reply QuiDortDine 7 hours agoparentprevThey are truly boringly nice. reply anonzzzies 5 hours agoparentprevAnd you can… reply dadrian 9 hours agoprev [–] If an a16z repo gets enough stars, will they invest in themselves? reply quickthrower2 9 hours agoparentNot only that this looks like a toy. reply anonzzzies 3 hours agorootparentAnd not a great one ; the sprites walk into the sea. reply adolph 9 hours agoparentprevFund of funds making funds where market research generates revenue and everyone’s adventures are capitalized into an on chain Large Lifestyle Model where being Day One is to emit content enough past the zeitgeist to avoid banality but not so far as to be incomprehensible. reply gabereiser 7 hours agorootparentcells within cells within cells within cells... reply ShamelessC 9 hours agoparentprev [–] How else would they have “skin in the game”? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AI-town is a starter kit that allows users to create and customize AI simulations.",
      "The kit includes a server-side game engine and is multiplayer and deployment ready.",
      "AI-town is written in Typescript and aims to simplify the process of building AI simulation environments."
    ],
    "commentSummary": [
      "AI-town is a starter kit that enables users to build AI simulations using JavaScript and customize their environments.",
      "The project seeks to democratize the creation of simulation environments and encourages the community to develop complex interactions.",
      "It combines different techniques to create cooperative agents that operate in abstract semantic spaces. However, there is skepticism about the potential value or interest of the AI characters."
    ],
    "points": 333,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1692056762
  },
  {
    "id": 37121180,
    "title": "Software Engineering at Google (2020)",
    "originLink": "https://abseil.io/resources/swe-book/html/toc.html",
    "originBody": "Foreword Preface Programming Over Time Google’s Perspective What This Book Isn’t Parting Remarks Conventions Used in This Book O'Reilly Online Learning How to Contact Us Acknowledgments Thesis What Is Software Engineering? Time and Change Hyrum’s Law Example: Hash Ordering Why Not Just Aim for “Nothing Changes”? Scale and Efficiency Policies That Don’t Scale Policies That Scale Well Example: Compiler Upgrade Shifting Left Trade-offs and Costs Example: Markers Inputs to Decision Making Example: Distributed Builds Example: Deciding Between Time and Scale Revisiting Decisions, Making Mistakes Software Engineering Versus Programming Conclusion TL;DRs Culture How to Work Well on Teams Help Me Hide My Code The Genius Myth Hiding Considered Harmful Early Detection The Bus Factor Pace of Progress In Short, Don’t Hide It’s All About the Team The Three Pillars of Social Interaction Why Do These Pillars Matter? Humility, Respect, and Trust in Practice Blameless Post-Mortem Culture Being Googley Conclusion TL;DRs Knowledge Sharing Challenges to Learning Philosophy Setting the Stage: Psychological Safety Mentorship Psychological Safety in Large Groups Growing Your Knowledge Ask Questions Understand Context Scaling Your Questions: Ask the Community Group Chats Mailing Lists YAQS: Question-and-Answer Platform Scaling Your Knowledge: You Always Have Something to Teach Office Hours Tech Talks and Classes Documentation Code Scaling Your Organization’s Knowledge Cultivating a Knowledge-Sharing Culture Establishing Canonical Sources of Information Staying in the Loop Readability: Standardized Mentorship Through Code Review What Is the Readability Process? Why Have This Process? Conclusion TL;DRs Engineering for Equity Bias Is the Default Understanding the Need for Diversity Building Multicultural Capacity Making Diversity Actionable Reject Singular Approaches Challenge Established Processes Values Versus Outcomes Stay Curious, Push Forward Conclusion TL;DRs How to Lead a Team Managers and Tech Leads (and Both) The Engineering Manager The Tech Lead The Tech Lead Manager Moving from an Individual Contributor Role to a Leadership Role The Only Thing to Fear Is…Well, Everything Servant Leadership The Engineering Manager Manager Is a Four-Letter Word Today’s Engineering Manager Antipatterns Antipattern: Hire Pushovers Antipattern: Ignore Low Performers Antipattern: Ignore Human Issues Antipattern: Be Everyone’s Friend Antipattern: Compromise the Hiring Bar Antipattern: Treat Your Team Like Children Positive Patterns Lose the Ego Be a Zen Master Be a Catalyst Remove Roadblocks Be a Teacher and a Mentor Set Clear Goals Be Honest Track Happiness The Unexpected Question Other Tips and Tricks People Are Like Plants Intrinsic Versus Extrinsic Motivation Conclusion TL;DRs Leading at Scale Always Be Deciding The Parable of the Airplane Identify the Blinders Identify the Key Trade-Offs Decide, Then Iterate Always Be Leaving Your Mission: Build a “Self-Driving” Team Dividing the Problem Space Always Be Scaling The Cycle of Success Important Versus Urgent Learn to Drop Balls Protecting Your Energy Conclusion TL;DRs Measuring Engineering Productivity Why Should We Measure Engineering Productivity? Triage: Is It Even Worth Measuring? Selecting Meaningful Metrics with Goals and Signals Goals Signals Metrics Using Data to Validate Metrics Taking Action and Tracking Results Conclusion TL;DRs Processes Style Guides and Rules Why Have Rules? Creating the Rules Guiding Principles The Style Guide Changing the Rules The Process The Style Arbiters Exceptions Guidance Applying the Rules Error Checkers Code Formatters Conclusion TL;DRs Code Review Code Review Flow How Code Review Works at Google Code Review Benefits Code Correctness Comprehension of Code Code Consistency Psychological and Cultural Benefits Knowledge Sharing Code Review Best Practices Be Polite and Professional Write Small Changes Write Good Change Descriptions Keep Reviewers to a Minimum Automate Where Possible Types of Code Reviews Greenfield Code Reviews Behavioral Changes, Improvements, and Optimizations Bug Fixes and Rollbacks Refactorings and Large-Scale Changes Conclusion TL;DRs Documentation What Qualifies as Documentation? Why Is Documentation Needed? Documentation Is Like Code Know Your Audience Types of Audiences Documentation Types Reference Documentation Design Docs Tutorials Conceptual Documentation Landing Pages Documentation Reviews Documentation Philosophy WHO, WHAT, WHEN, WHERE, and WHY The Beginning, Middle, and End The Parameters of Good Documentation Deprecating Documents When Do You Need Technical Writers? Conclusion TL;DRs Testing Overview Why Do We Write Tests? The Story of Google Web Server Testing at the Speed of Modern Development Write, Run, React Benefits of Testing Code Designing a Test Suite Test Size Test Scope The Beyoncé Rule A Note on Code Coverage Testing at Google Scale The Pitfalls of a Large Test Suite History of Testing at Google Orientation Classes Test Certified Testing on the Toilet Testing Culture Today The Limits of Automated Testing Conclusion TL;DRs Unit Testing The Importance of Maintainability Preventing Brittle Tests Strive for Unchanging Tests Test via Public APIs Test State, Not Interactions Writing Clear Tests Make Your Tests Complete and Concise Test Behaviors, Not Methods Don’t Put Logic in Tests Write Clear Failure Messages Tests and Code Sharing: DAMP, Not DRY Shared Values Shared Setup Shared Helpers and Validation Defining Test Infrastructure Conclusion TL;DRs Test Doubles The Impact of Test Doubles on Software Development Test Doubles at Google Basic Concepts An Example Test Double Seams Mocking Frameworks Techniques for Using Test Doubles Faking Stubbing Interaction Testing Real Implementations Prefer Realism Over Isolation How to Decide When to Use a Real Implementation Faking Why Are Fakes Important? When Should Fakes Be Written? The Fidelity of Fakes Fakes Should Be Tested What to Do If a Fake Is Not Available Stubbing The Dangers of Overusing Stubbing When Is Stubbing Appropriate? Interaction Testing Prefer State Testing Over Interaction Testing When Is Interaction Testing Appropriate? Best Practices for Interaction Testing Conclusion TL;DRs Larger Testing What Are Larger Tests? Fidelity Common Gaps in Unit Tests Why Not Have Larger Tests? Larger Tests at Google Larger Tests and Time Larger Tests at Google Scale Structure of a Large Test The System Under Test Test Data Verification Types of Larger Tests Functional Testing of One or More Interacting Binaries Browser and Device Testing Performance, Load, and Stress testing Deployment Configuration Testing Exploratory Testing A/B Diff Regression Testing UAT Probers and Canary Analysis Disaster Recovery and Chaos Engineering User Evaluation Large Tests and the Developer Workflow Authoring Large Tests Running Large Tests Owning Large Tests Conclusion TL;DRs Deprecation Why Deprecate? Why Is Deprecation So Hard? Deprecation During Design Types of Deprecation Advisory Deprecation Compulsory Deprecation Deprecation Warnings Managing the Deprecation Process Process Owners Milestones Deprecation Tooling Conclusion TL;DRs Tools Version Control and Branch Management What Is Version Control? Why Is Version Control Important? Centralized VCS Versus Distributed VCS Source of Truth Version Control Versus Dependency Management Branch Management Work in Progress Is Akin to a Branch Dev Branches Release Branches Version Control at Google One Version Scenario: Multiple Available Versions The “One-Version” Rule (Nearly) No Long-Lived Branches What About Release Branches? Monorepos Future of Version Control Conclusion TL;DRs Code Search The Code Search UI How Do Googlers Use Code Search? Where? What? How? Why? Who and When? Why a Separate Web Tool? Scale Zero Setup Global Code View Specialization Integration with Other Developer Tools API Exposure Impact of Scale on Design Search Query Latency Index Latency Google’s Implementation Search Index Ranking Selected Trade-Offs Completeness: Repository at Head Completeness: All Versus Most-Relevant Results Completeness: Head Versus Branches Versus All History Versus Workspaces Expressiveness: Token Versus Substring Versus Regex Conclusion TL;DRs Build Systems and Build Philosophy Purpose of a Build System What Happens Without a Build System? But All I Need Is a Compiler! Shell Scripts to the Rescue? Modern Build Systems It’s All About Dependencies Task-Based Build Systems Artifact-Based Build Systems Distributed Builds Time, Scale, Trade-Offs Dealing with Modules and Dependencies Using Fine-Grained Modules and the 1:1:1 Rule Minimizing Module Visibility Managing Dependencies Conclusion TL;DRs Critique: Google’s Code Review Tool Code Review Tooling Principles Code Review Flow Notifications Stage 1: Create a Change Diffing Analysis Results Tight Tool Integration Stage 2: Request Review Stages 3 and 4: Understanding and Commenting on a Change Commenting Understanding the State of a Change Stage 5: Change Approvals (Scoring a Change) Stage 6: Commiting a Change After Commit: Tracking History Conclusion TL;DRs Static Analysis Characteristics of Effective Static Analysis Scalability Usability Key Lessons in Making Static Analysis Work Focus on Developer Happiness Make Static Analysis a Part of the Core Developer Workflow Empower Users to Contribute Tricorder: Google’s Static Analysis Platform Integrated Tools Integrated Feedback Channels Suggested Fixes Per-Project Customization Presubmits Compiler Integration Analysis While Editing and Browsing Code Conclusion TL;DRs Dependency Management Why Is Dependency Management So Difficult? Conflicting Requirements and Diamond Dependencies Importing Dependencies Compatibility Promises Considerations When Importing How Google Handles Importing Dependencies Dependency Management, In Theory Nothing Changes (aka The Static Dependency Model) Semantic Versioning Bundled Distribution Models Live at Head The Limitations of SemVer SemVer Might Overconstrain SemVer Might Overpromise Motivations Minimum Version Selection So, Does SemVer Work? Dependency Management with Infinite Resources Exporting Dependencies Conclusion TL;DRs Large-Scale Changes What Is a Large-Scale Change? Who Deals with LSCs? Barriers to Atomic Changes Technical Limitations Merge Conflicts No Haunted Graveyards Heterogeneity Testing Code Review LSC Infrastructure Policies and Culture Codebase Insight Change Management Testing Language Support The LSC Process Authorization Change Creation Sharding and Submitting Cleanup Conclusion TL;DRs Continuous Integration CI Concepts Fast Feedback Loops Automation Continuous Testing CI Challenges Hermetic Testing CI at Google CI Case Study: Google Takeout But I Can’t Afford CI Conclusion TL;DRs Continuous Delivery Idioms of Continuous Delivery at Google Velocity Is a Team Sport: How to Break Up a Deployment into Manageable Pieces Evaluating Changes in Isolation: Flag-Guarding Features Striving for Agility: Setting Up a Release Train No Binary Is Perfect Meet Your Release Deadline Quality and User-Focus: Ship Only What Gets Used Shifting Left: Making Data-Driven Decisions Earlier Changing Team Culture: Building Discipline into Deployment Conclusion TL;DRs Compute as a Service Taming the Compute Environment Automation of Toil Containerization and Multitenancy Summary Writing Software for Managed Compute Architecting for Failure Batch Versus Serving Managing State Connecting to a Service One-Off Code CaaS Over Time and Scale Containers as an Abstraction One Service to Rule Them All Submitted Configuration Choosing a Compute Service Centralization Versus Customization Level of Abstraction: Serverless Public Versus Private Conclusion TL;DRs Conclusion Afterword Index",
    "commentLink": "https://news.ycombinator.com/item?id=37121180",
    "commentBody": "Software Engineering at Google (2020)Hacker NewspastloginSoftware Engineering at Google (2020) (abseil.io) 323 points by nvahalik 20 hours ago| hidepastfavorite320 comments mushufasa 19 hours agoCool. Could someone, maybe an ex-googler, comment on which parts of these work well and which don&#x27;t?A lot of other companies get into trouble trying to cargo-cult what Google does when they are operating in very different environments wherein those practices aren&#x27;t optimal. E.g. different levels of scale.Additionally, critics of Google may point out that their engineering culture may not be great on its own terms -- every time Google launches a new feature, people post links to the Google product graveyard. reply jeffbee 19 hours agoparentIn my ex-Google experience, here are the stages of denial about something that Google does which is good but the industry doesn&#x27;t yet embrace.Stage 1: \"We&#x27;re not Google, we don&#x27;t need [[whatever]]\";Stage 2: Foreseeable disaster for which [[whatever]] was intended to address happens;Stage 3: Giant circus of P0&#x2F;SEV0 action items while everyone assiduously ignores the [[whatever]];Stage 4: Quiet accretion, over several years, of the [[whatever]] by people who understand it.And the [[whatever]] ranges from things that are obviously beneficial like pre-commit code review to other clear winners like multi-tenant machines, unit testing, user data encryption, etc etc. It is an extremely strange industry that fails to study and adopt the ways of their extremely successful competitors. reply hn_throwaway_99 17 hours agorootparentStrong disagree. In my experience, this is not commonly why competitors don&#x27;t adopt Google&#x27;s practices. The main reasons I&#x27;ve seen are:1. Money. Google essentially has a giant, gargantuan, enormous, bottomless pit of money to build a lot of this tooling (and also to take the risk if something ends up not working out). I think you might be able to say that other companies are just being short sighted if they don&#x27;t implement some of these things up front, and that may be true, but (a) that&#x27;s pretty much human nature, and (b) given that very few other companies have a bottomless pit of money like Google, that may just end up being the right decision (i.e. survive now and deal with the pain later).2. Talent. This is closely related to #1, but few other companies have the engineering talent that Google does. If there is one thing I&#x27;ve seen with my experience with ex-Googlers is that most of them are fast coders. So when you go to your boss and say \"I&#x27;d like to implement engineering&#x2F;tech-debt improvement XYZ\", at other companies it&#x27;s a harder decision if (on average) it would take 9 months to implement vs. 2 or 3.3. Related to both of the above, but your 4th bullet point, \"Quiet accretion, over several years, of the [[whatever]] by people who understand it.\", is actually other companies just waiting for more evidence to see what \"shakes out\" as the industry-standard, optimal way to do things.4. Finally, your stage 1, \"We&#x27;re not Google, we don&#x27;t need [[whatever]]\" is actually true in tons of cases. Many of Google&#x27;s processes are there to handle enormous scale, both in terms of their application&#x2F;data capacity, as well as the sheer number of engineers they need to coordinate. Very, very, very few companies will ever hit Google&#x27;s scale. reply underdeserver 14 hours agorootparentEh, money is only a factor when it comes to scale. That is, Google can afford to hire 30 engineers to support their CI infra, you can&#x27;t.Everything else isn&#x27;t. Unit tests aren&#x27;t a luxury that Google&#x27;s infinite riches allow it to have - they pay dividends whenever code exists for more than a few weeks.You can bet your ass Google engineers don&#x27;t write unit tests for throwaway code.CI saves time, and while Google can maintain a team you can afford to pay for Jenkins or GitHub Actions, because not paying for them is more expensive - if your company is to survive for more than 3 months. reply JonChesterfield 13 hours agorootparentCI can totally cost time, especially if it doesn&#x27;t have a team of good engineers keeping it running sanely and ensuring it tells you useful things on failures.A CI bot which waits 24 hours then says \"no\", with a text file that crashes your browser and ultimately only contains the information &#x27;exit code nonzero&#x27;, which fails for reasons totally unrelated to your code change is dubious as a value add system.If that bot is also a non-negotiable gate on shipping things you get a bunch of other antipatterns, like massive code patches to decrease how often you have to roll the die and a tendency to hit retry every day or so until the probability that it&#x27;s actually your patch that&#x27;s broken gets high enough that you try to debug it locally, at which point you may be unable to reproduce the blocking error anyway.The real question is whether that pathologically rubbish implementation is still better than shipping without CI, which rather depends on whether your engineers ship code that works without the guide rails, which to a fair approximation they do not.Thus it might still be a net win for product quality but saving time is harder to see. reply hn_throwaway_99 10 hours agorootparentSetting up a decent CI pipeline on GitHub with GitHub Actions is super, super easy - less than a day&#x27;s work for a basic initial implementation.Of course, the difficult part about managing a CI pipeline is writing quality tests, ensuring your tests don&#x27;t take forever, deciding the right balance between mocking out 3rd party runtime service dependencies vs. calling their dev versions in your tests, etc.But this is why I argue that the bare minimum should just be to have the CI pipeline created. If you don&#x27;t have that, you are definitely going to screw over future you. Once that&#x27;s there you can balance the cost&#x2F;benefits of how much to invest in your test suite and test coverage. reply hn_throwaway_99 13 hours agorootparentprevAs I said in another comment, I think folks are just disagreeing on terms. I absolutely don&#x27;t consider things like unit tests or CI to be any kind of \"Google-specific\" engineering advice - they&#x27;re just standard good engineering practices. reply jeffbee 13 hours agorootparentTrue, but what I was trying to introduce into the discussion was what another sibling commenter astutely labeled the anti-cargo-cult: industry feeling that anything at Google is an anti-pattern even when that thing is firmly established among other successful software developers for a long time. And in my experience comprehensive unit testing is one of those things that I have sometimes heard waved away. reply jabradoodle 14 hours agorootparentprevI don&#x27;t think only Google are writing unit tests. reply jeffbee 17 hours agorootparentprevJust discussing your point #1, I hear this but what I see is that the companies I have direct experience with spend much more and move more slowly with their we-are-not-Google hacks. People move fast and break things into a corner where their entire project is a haunted graveyard with no test and no comments, that has never been reviewed, and at that point nobody is allowed to change anything. reply hn_throwaway_99 16 hours agorootparentPerhaps, but to me everything you put in your comment above just sounds like bad engineering practices in general and not something particularly related to Google processes.E.g. things like \"do feature work on a branch and then code review&#x2F;run PR checks before merge\", \"have unit test coverage (being a hard balance to judge what is sufficient coverage)\", \"have useful comments\" - absolutely none of these things I associate with \"Google engineering practices\", and many of them definitely predate things that were specifically done at Google.Things I think of when I think about Google practices are things like ensuring data is infinitely horizontally scalable, monorepos, etc. Those things are all scale-specific. reply nostrademons 14 hours agorootparentMonorepos actually work better at small scale than at Google scale. I think it&#x27;s nuts that individual startup founders actually consider microservices; if you are validating out a software product idea, write a computer program, the very simplest one possible, to prove that you can do it and get the general shape of the architecture before you start dividing it into microservices.I usually see the pressure to split into microservices appear around 20 engineers, just as your single repo is starting to get unwieldy. Knowing that the big companies use a monorepo is pretty important information here, because it may prompt you to invest in tooling to make that one repo less unwieldy rather than splitting into many small repos that will be very difficult if not impossible to merge back together again.Google doesn&#x27;t actually plan for infinite horizontal scalability in data. The framing I&#x27;ve found most useful is [Jeff] Dean&#x27;s Law: \"Plan for a 10x increase in scale, but accept that sometime before you reach 100x, you will have to rewrite the system with a different architecture.\" The reason for this is shifting bottlenecks: as the system gets larger, different aspects become the bottleneck to future scalability, and each time the bottleneck changes you usually need a different architecture. But by planning for an order of magnitude growth, you ensure that you&#x27;re not artificially introducing bottlenecks, and that you have enough headroom to actually discover the new bottleneck. reply hn_throwaway_99 13 hours agorootparentRe: monorepos, I think we&#x27;re talking about 2 different things. I usually hear the term \"monorepo\" discussed in the context of how it is practiced at places like Google and Facebook: having the code for all the company&#x27;s services (micro or not) stored in a single source control repository.A monorepo really doesn&#x27;t have anything to do with how code components are deployed - your comment seemed to be contrasting a monolith architecture with a microservices one. reply nostrademons 8 hours agorootparentI was fast & loose with terminology, but I&#x27;m thinking of the organizations where every binary and every library is its own Github repository, and you make copious use of git submodule to build anything. I think that&#x27;s the same thing you&#x27;re talking about, right?It&#x27;s impractical (particularly when the project is young) for the same reason having separate binaries is impractical: it makes it very difficult to do refactorings that cut across repos while still keeping atomic checkouts and rollbacks. reply ryandrake 9 hours agorootparentprevYea--I&#x27;ve found it surprisingly difficult to get plain vanilla medium-sized companies to adopt obvious, time-tested best practices. I&#x27;m not talking about \"Google engineering practices\" but basic table stakes practices like using source control and a bug tracker. So-called \"Joel Test\"[1] items. The most common excuses are: \"We don&#x27;t have time&#x2F;money to do infrastructure&#x2F;process, we need to write shipping code!\" and the usual \"We&#x27;ve always done it this way\".1: https:&#x2F;&#x2F;www.joelonsoftware.com&#x2F;2000&#x2F;08&#x2F;09&#x2F;the-joel-test-12-s... reply vbezhenar 16 hours agorootparentprevTests, comments and code reviews is not something unique to Google. It&#x27;s a commonly accepted practice. There might be some dark corners, just like there are people who perform version controlling with ctrl+c, ctrl+v technique, but it&#x27;s not a norm. I don&#x27;t think that many people would argue against basic software development rules. However being Google is much more than writing tests and doing code reviews.Being Google means having a team which writes source control management system for you. reply majesticglue 14 hours agorootparentprevclearly there is a missing link in your experience of companies where you don&#x27;t have control over a lot of the things you think is needed and companies want to push a product as fast as possible and cut as many corners as possible.More and more companies will be like this to cut costs reply choppaface 14 hours agorootparentprevOne conspicuous omission in the ex-google is reflection on killed products like Google Wave, Plus, Glass etc etc etc .. for many of the [whatever] was the gross imbalance between Eng owning the product but ignoring the userbase.What ex-googlers often fail to grapple with is the product lifecycle (how short it may be) and the value of having diversity in the loop of product testing. Google is designed to be a safe place to focus, and that’s not what the real world is like outside the plex. reply jeffbee 13 hours agorootparentActually I think it is never-Googlers who have the wrong perspective here. The fact that Google constantly produces and destroys products demonstrates that it is extremely easy for that company to churn out code, and validates their software development methodology. It&#x27;s incredibly easy to just dash off a product building on their gigantic foundation of source code, infrastructure, and launch process.The fact that Plus and Glass got canceled and Wallet has been canceled sixteen different times is merely a consequence of the fact that leadership and product is often led by imbeciles. That&#x27;s an organizational problem and I hope nobody is out there cargo-culting Google&#x27;s org (even though I know they are, with OKRs and Perf being widely copied). reply choppaface 13 hours agorootparentExactly, Google engineers deflect user issues and product failures to the leadership and non-engineers. That happens in any large team, but Google has sweetened the situation for engineers to keep them focused on engineering rather than the larger consequences. E.g. credit cards are just fine, nobody actually wants to see ads, etc. It’s the user’s fault for failing to see the esoteric details behind the thing. reply nostrademons 14 hours agorootparentprevGoogle&#x27;s penchant for killing promising products is 100% the result of poor incentives. People are incentivized for launching challenging projects, but they are generally not responsible for the bottom line (which is going to be dwarfed by Search Ads revenue anyway) or for user happiness & brand loyalty (which is challenging to measure). As a result, lots of promising and exciting products are brought to market and then killed, as the easiest way to bring new products to market is to cannibalize the stuff your predecessors did and show how great your alternative is instead. reply hn_throwaway_99 12 hours agorootparentI&#x27;m not sure why your comment was previously downvoted. I&#x27;ve often heard, and it&#x27;s not hard to find these comments from ex-Googlers on HN, that Google&#x27;s \"promotion-oriented development\" is one of their biggest factors in some of their cultural shortcomings. That is, launching a big new product is seen as one of the best ways to get promoted, while working on the little nits (which in my experience, especially with some of Google&#x27;s enterprise products, can languish for years, even though they can be really important but \"boring\" issues to fix) is not seen as high-value work. reply orochimaaru 10 hours agorootparentprevI will add one more category - companies that have or need scale but nowhere near the technical talent that google has.Eg - most telco companies in the US run at a scale similar to google. They need most of the software engineering best practices, internal tools teams, etc. They used to have it during Ma Bell times when they had a cash cow. That doesn’t exist and they’re left with scale and the points 1-4 described above.This in general leads them to outsource to lowest bidder contracting firms that compound the shitty software problem. In the end it’s a miracle that all of it works together :) reply RichardCA 15 hours agorootparentprevI think it&#x27;s also the ability to have a deep bench of coding talent who just get to work on the toolchain. Most companies ration that talent to the product, shipping features that drive revenue. reply raldi 19 hours agorootparentprevOff-topic for this thread, but one of the most poignant quips I remember about Google culture was that the performance-review process was really good at rewarding hard, challenging work that didn&#x27;t produce much value and not very good at recognizing work that produced lots of value but was not astoundingly difficult. I think you were the one who first noted this. reply pclmulqdq 15 hours agorootparentI recently explained Google&#x27;s perf process to an employee of the US federal government, and was told that the performance review and promotion processes in the government were simpler and less wasteful. reply jrockway 12 hours agorootparentIs the government getting good results out of their process? Remember when a bunch of ex-Google engineers had to step in and save healthcare.gov? If their simple promotion process works, why didn&#x27;t they curate that talent in-house.People at L4 might not really like Google&#x27;s process, but if some Distinguished Engineer shows up at your design review you&#x27;re pretty much guaranteed to get some sort of valuable feedback. That is not a given in other organizations. reply sharts 10 hours agorootparentWasn&#x27;t healthcare.gov outsourced to contractors in the first place? I&#x27;m not sure that government actively maintains much in the way of dedicated employees or teams to build stuff like this.The problem lay with picking the cheapest contractor bids. If anything, the FAANGs should establish consulting arms for this kind of work. reply pclmulqdq 11 hours agorootparentprevGood people don&#x27;t work for the government because it pays poorly, not because its promotion process is wonky. The usual strategy in any high-paying field for government-track people is to work there for a few years to build credibility, then transition to being a consultant for a 100+% raise (or move to private industry completely). reply UncleMeat 14 hours agorootparentprevThere&#x27;s a lot of external complaining about perf at Google. My experience is that most of these complaints are wrong. I&#x27;ve personally had two reports fail to get promoted to L6 off of projects that were very difficult and executed well but for various reasons did not have the impact that we expected. reply nostrademons 9 hours agorootparentThe problem is at the VP level, not the L6 level. It&#x27;s not that impact isn&#x27;t considered, it&#x27;s that impact is relative to the current org goals of the moment, because it&#x27;s evaluated by your peers that have presumably all bought into the current org goals of the moment (if they haven&#x27;t, they will probably be fired or sidelined soon). However, there&#x27;s very little feedback between things users care a lot about and things executives care about. You&#x27;re rewarded for doing things that your VP deems important. Your VP is almost certainly not going to sweat the small stuff (although I do know a couple that try). It&#x27;s impractical for someone with 2000 reports to keep up with every little bug in their product area, and they would be a terrible micromanager if they did. So what usually happens is that they call out the few annoyances they happen to see when using the product, everybody in their org jumps on fixing those because that will get them promoted, and everything not noticed or not specifically called out by a VP languishes.How would I fix it? Not get to the point where the shots are being called by people with 2000 direct reports, for one. Software has distinct diseconomies of scale, where you have a much smaller loop between \"Notice a problem. Identify who can solve the problem. Solve the problem\" in a small organization than a big one. But that ship has sailed.Failing that, I think orgs need to adopt quantitative measures of impact (eg. X tickets closed, X customers helped, X new sales generated) along with backpressure mechanisms to ensure that those metrics are legitimate (eg. you can&#x27;t just create new bugs to solve them; you can&#x27;t just help customers only for them to need to return tomorrow; you can&#x27;t generate new sales that are unprofitable). reply H8crilA 15 hours agorootparentprevThe performance review process has a small impact on salary.The promo process is not based on value or difficulty, but on the size of the organization that one is running. This is also true for higher level ICs, except they do not manage people, but rather manage&#x2F;lead projects (which then have a certain amount of people involved).Here&#x27;s a rough breakdown: - L4 -> 1 person - L5 -> 1-3 people - L6 -> ~7 people - L7 -> ~25 people - L8 -> ~70 peopleThe approximate 3x difference between the levels is also found in other organizations, for example in armies: division ~= 3 brigades, brigade ~= 3 battalions, battalion ~= 3 companies, company ~= 3 platoons.Misunderstanding this is the source of almost all frustration with the promo process. This process is designed to build and expand the organization, not reward awesomeness. There are of course deviations from the simple schema I listed here, but this is the hard reference point. reply pclmulqdq 15 hours agorootparentPerf feeds into promotions, which are the real way to raise your long-term salary (both inside and outside of Google). reply fcpk 15 hours agorootparentThis is a terrible process unfortunatelly. Raising the salary should be related to the usefulness of the person to the company, and not the breadth&#x2F;impact of their work. This leads to terrible things like gaming the system to get high impact&#x2F;leadership projects to get raises which comes with huge side effects, like projects getting abandonned fast, being deprecated in favor of new shiny promo-bringing things.But this is not just a Google specific issue, and it is quite widespread in the industry. Google however suffered from this especially due to its obsessive culture of pay-for-perf and by ignoring simple facts:- inflation means that your salaries should raise regardless of performance. if you only tail the market by adjusting salaries only if the market changes, then you are 1 year late(at least). This isn&#x27;t a problem in an economy with low inflation, but is a huge problem in one with much higher inflation.- there is a significant number of people needed to maintain projects that won&#x27;t show large impact. Those people need to be at the very least recognized and compensated.- making new products is great, but it requires huge amounts of ressources to do at Google scale from the get-go. A wider strategy is much needed, which Google obviously lacked for almost a decade. reply H8crilA 14 hours agorootparentprevPerf is almost irrelevant for promotions beyond level 5. reply pclmulqdq 13 hours agorootparentThat was not my experience. A long run of good perf scores is clearly not sufficient for a promotion at that level, but it is necessary. reply jeffbee 18 hours agorootparentprevI miss you too, raldi. reply MarceColl 19 hours agorootparentprevThe tools, design and manpower needed to build a skyscraper are different from those needed to build a 1-story wood house. It&#x27;s not that the ones that build the wood house are failing to study and adopt the ways of their extremely successful competitors.Now, some of the things you say like unit-testing and user data encryption are ones that I&#x27;ve never seen associated with the \"We&#x27;re not google\" mindset, so maybe people have started using that phrase for anythingnow reply sumtechguy 18 hours agorootparent\"were not google\" is usually good for things where people are using cargo cult. I saw at one company that went open floor plan because google did it. No one was happy about that. Retention became very low and everyone bailed out. Emulating google does not fix process and management issues. As what may be at google for a good reason may be an utter failure at another company. There are things all shops can adopt that google does that would help them. But many of the ones I have seen adopted were little more than showy garbage instead of the things that would actually help.Also sometimes you just need a simple tool to get something done. As engineers we like to build things so sometimes we make it way more complex than it really needs to be. For someone like google that may just be fine to do. For others a minimum viable product may be in order. Do not worry about optimizing for the 3 million user per day case when you have 10 total users a month. Add logging and keep an eye on it. Then worry if you need to scale. As building good scale takes time and thought. Many times you do not need that at all.As your company&#x2F;group grows you will take on more and more of the things &#x27;google does&#x27; because you will need to, or you will go nuts chasing everything. You could probably even make stages out of the different times to do&#x2F;evaluate things. To do it early could actually harm what you are doing. You need to evaluate what you are doing and why. Just copying someone else does not always lead to a good outcome and you could be wasting effort when you could be making product. reply robertlagrant 16 hours agorootparent> \"were [sic] not google\" is usually good for things where people are using cargo cultIt&#x27;s no different to cargo culting. That should not be the reason for not doing something, any more than the opposite should be a reason for doing it. Just see if the practice makes sense in your context and decide that way. reply marcosdumay 12 hours agorootparent\"We are not Google\" is the answer to \"I saw on that blog here that we should do X\", \"everybody is doing X, we should too\", or \"you have to follow this good practice here\" where the practice is only \"good\" because it&#x27;s hyped.Those kinds of demand happen exactly because they saw them at Google, and an outright refusal is exactly how they should be dealt with. Once the unreasonable person is cut out, you can look at your context and decide what&#x27;s the best way to solve the problem. reply MarceColl 17 hours agorootparentprevI think you wanted to reply to the same person I replied to? Since I&#x27;m saying basically the same thing you do I believe reply jeffbee 19 hours agorootparentprevI&#x27;m not really talking about artisanal 3-man software shops, I&#x27;m talking about mid-sized companies with thousands of engineers, who don&#x27;t realize they are already larger than and facing the same problems as Google was when they started adopting these practices. And to be clear, rejecting something as proven as pre-commit code review is not only to reject the example of Google and many other very successful enterprises, but also to ignore decades of developer productivity knowledge before Google existed. It&#x27;s almost like the fact that Google adopted a long-standing best practice makes modern engineers reflexively revolt against those best practices. This can only be seen as a structural advantage for Google. reply throwaw12 17 hours agorootparent> I&#x27;m talking about mid-sized companies with thousands of engineersCan you name such mid-sized companies with thousands of engineers? If you hit thousands of engineers headcount, you are not a mid-sized anymore.Theoretically, Google does 100 things right, pays for those 100 things, but also Google has tons of cash, if Google didn&#x27;t release product in Q1, no worries, they will release in Q3.Now consider startup with 50 engineers, if you didn&#x27;t release feature in Q1, you might need to stop the project, because customer with whom you signed the contract just goes away and you will be laying off 5 people reply aprdm 12 hours agorootparentprevmid-size with thousands of engineers? Wow, mid-size for me is around 100-200 people :) reply dinvlad 18 hours agorootparentprevCurious how pre-commit code review worked, could you please elaborate a bit? reply jeffbee 18 hours agorootparentEvery change is reviewed by someone other than the author before it lands in the repo. At google they take this a bit further. Every change has to have been either written or reviewed by a designated owner of the code (designated by subdirectory) and one of the participants must be a qualified user of the languages used in the change (\"readability\"). And they have technical measures in place to ensure that programs running in production descend exclusively from reviewed and committed code.Pre-commit review is common but not universal in the industry. Some shops practice post-commit review or no review. Some believe review consists entirely of quibbling. reply dinvlad 18 hours agorootparentOh, I see - by \"pre-commit\" it doesn&#x27;t really imply it in \"Git commit\" sense - the change is still propagated to others (presumably by committing it as a sort of \"draft\"), it&#x27;s just not committed to the mainline - is that correct?I&#x27;m very familiar with CR at other companies, but tbh since most use Git, I wouldn&#x27;t call that \"pre-commit\" but \"pre-merge\", if you will - unless I misunderstood and it really is pre-commit at Google (i.e. the changes are not even _committed_ to the repository - and then I&#x27;m confused once again at what exactly that means..) reply jeffbee 17 hours agorootparentYeah, there are no direct translations between git and perforce concepts. The right term within Google would in fact be \"pre-submit\" not \"pre-commit\". Before a change is submitted in the Perforce-derived flow it exists only in the author&#x27;s client and isn&#x27;t really part of source control in the way that git users are accustomed to pushing their branch to origin.NB: At that company there are also users of git-compatible and hg-compatible tools, but I am discussing the main perforce-derived flow. reply dinvlad 17 hours agorootparentOh I see, thanks! I was under impression Google has migrated away from Perforce towards an in-house system a while ago, but looks like I was mistaken (or do you mean that system is derived from Perforce?). Edit: I guess its name is Piper..It’s quite interesting&#x2F;mind-bending to think of work-in-progress that’s still somehow synced between peers (in fact this is one of those “missing nice-to-haves” I wish Git had, and can only be approximated with wip branches..) reply jeffbee 17 hours agorootparentThe synced-between-peers features are built atop a thing call CitC, or Client in the Cloud. An author&#x27;s client isn&#x27;t on their machine, it&#x27;s hosted in prod. reply dinvlad 16 hours agorootparentOK got it, thanks for clarifying it reply joshuamorton 17 hours agorootparentprevGoogle (for $reasons) doesn&#x27;t do long lives code branches and doesn&#x27;t use git, at least for the main repo. So in that context every commit is reviewed pre-commit, but you&#x27;d do the same workflow elsewhere with trunk-based development, small pull requests, and CI and automated and human review of all PRs before they&#x27;re merged. reply dinvlad 17 hours agorootparentRight, I know it’s not on Git and hence was my question - and it sounds like this is more about terminology and less about technology. I.e. what Google does in this case is not that different from just “Code Review” in the traditional sense, as most other companies (with good engineering practices) do - reviewing code before it enters production (+CI&#x2F;CD, as you mentioned).Edit: as OP mentioned, it does seem to differ in technical sense from traditional CR, in that the changes live only on developer machine, not in source control. reply joshuamorton 17 hours agorootparent> Edit: as OP mentioned, it does seem to differ in technical sense from traditional CR, in that the changes live only on developer machine, not in source control.Yes and no. There&#x27;s a decent whitepaper on Piper and citc you can find by searching for it (or actually I will :P [0]), as far as piper is concerned they aren&#x27;t checked into source control, but the vast majority of development happens in \"citc\" workspaces, which aren&#x27;t source control, but also are source control in a sense that every save is snapshotted and you can do point in time or point in history recovery, and I can open up a readonly view of someone else&#x27;s workspace if I know the right incantations, and most of the developer tools treat the local citc workspace enough-like a commit that it&#x27;s transparent ish.[0]: https:&#x2F;&#x2F;cacm.acm.org&#x2F;magazines&#x2F;2016&#x2F;7&#x2F;204032-why-google-stor... reply dinvlad 16 hours agorootparentOK, thanks for these details and the link! Somehow I remember the title, but not the content :-) That&#x27;ll be an interesting read. reply nonethewiser 15 hours agorootparentprev> and I can open up a readonly view of someone else&#x27;s workspace if I know the right incantationsSo thats not just a basic feature? reply UncleMeat 14 hours agorootparentThe normal workflow is to create a changelist and then have somebody patch that changelist into their client rather than accessing their client directly. reply joshuamorton 14 hours agorootparentprevIt&#x27;s the equivalent of me being able to view the local, unpushed changes you have in whatever directory you git cloned into.If that sounds somewhat magical, yes, correct. reply nonethewiser 15 hours agorootparentprev> as OP mentioned, it does seem to differ in technical sense from traditional CR, in that the changes live only on developer machine, not in source control.Which seems worse. reply compiler-guy 11 hours agorootparent\"On the developer&#x27;s machine\" isn&#x27;t correct.They are actually saved within a special file-system called \"citc\" (Clients-in-the-cloud). It saves literally every single revision of the file written during development. If you hit save, it is saved in perpetuity, which has saved me a bunch of times. Every single one. No need for any kind of commit or anything else.Further, these saved revisions are all fully accessible to every engineer within the company, any time they want. replyklooney 16 hours agorootparentprevThe real problem with code review is that if people don&#x27;t do it&#x2F;just hit sign off, it&#x27;s worthless. Your whole company has to believe. reply benlwalker 16 hours agorootparentprevPre-commit means before committed to the canonical repo, not before commit locally.The SPDK project has an elaborate pre-commit review and test system all in public. See https:&#x2F;&#x2F;spdk.io&#x2F;development . I wouldn&#x27;t want to work on a project that doesn&#x27;t have infrastructure like this.Even mailing lists with patches are really a pre-commit review system, as are GitHub pull requests. Pre-commit testing seems more elusive though. reply lesuorac 19 hours agorootparentprevI just wish more places would adopt `third_party`; I would also love reproducible builds but I&#x27;ll settle on third_party. reply yibg 14 hours agorootparentprevThere is risk of selection bias here. The companies that runs into [[whatever]] are the ones that made it far enough to have run into it. What you&#x27;re not seeing are all the companies that tried to do what google does at scale, built a complex code base that doesn&#x27;t serve it&#x27;s customers needs and can innovate fast enough and are now dead. reply jimmaswell 13 hours agorootparentprev> pre-commit code reviewUnless you&#x27;re referring to automated precommit hooks, this sounds baffling. What&#x27;s wrong with reviewing pull requests? What if I want to push a WIP while I switch to another branch, I still need a review? Is the final PR reviewed again at the end? reply ericye16 9 hours agorootparentWhat they mean is code review prior to merging into what you&#x27;d call main or trunk or master or release, not for committing your WIP changes or whatever (unless you want those merged at that stage). reply jeffbee 12 hours agorootparentprevThat&#x27;s a git user&#x27;s perspective and Google doesn&#x27;t use git or anything analogous. Under their system, and generally under Perforce, it is never necessary to \"push a WIP\" because your client just contains whatever edits it contains. You never need to manually checkpoint, stash, or commit. People with multiple changes in flight will usually use two different clients, one for each change, although that is not strictly mandatory and in the perforce model you can have disjoint sets of files in multiple changes in the same client.Anyway, TL;DR, the problems you suggest are git-specific and one solution to them is not using git. reply claytongulick 17 hours agorootparentprevOr, alternately phrased:As a company grows and matures, their software development processes evolve to meet the business needs. reply cornel_io 11 hours agorootparentprevReadability doesn&#x27;t help Google or anyone else, it&#x27;s a pure \"inmates running the asylum\" artifact. reply dustingetz 17 hours agorootparentprevlabel the tradeoffs? reply deanCommie 12 hours agorootparentprevI&#x27;m sorry are you saying Google invented multi-tenant services, unit testing, or user data encryption?I&#x27;ll give you \"pushed the WEB industry to have transport-layer encryption for the entire industry by default\".I&#x27;ll even give you \"code reviews\".But not the first 3. reply drewg123 19 hours agoparentprev\"Readability\" works terribly when your company is acquired and your team enters all at the same time.Google has (or had ~10 years ago), a thing called \"readability\" for each language, where in order to be allowed to commit code to the central \"google3\" repo, you needed to have written some large amount of code in that language, and needed to have a readability reviewer sign off on your code. The process is designed for slowly on-boarding junior people into a team, and introducing them to google coding style and practices. Eg, the senior, mentoring folks on the team do the reviews and bring the new person up to speed. I imagine it must work well in that context.However, this breaks down when your entire team is new. How do you find somebody to review the code? All several million lines of the product that was acquired? Especially when it is written in multiple languages.So we were basically locked out of the main corporate repo, unable to do anything productive. We finally figured out that there was a paved path with a git repo used by the kernel team (and android?) that had none of these hurdles, where we could put our code and get productive immediately. reply MH15 17 hours agorootparent\"Readability\" is very much still a thing. It&#x27;s a mess and would be one of the worst things to take from Google. If you can&#x27;t enforce the code style you like through autoformatters and linting, it&#x27;s not worth enforcing. reply opportune 17 hours agorootparentI kind of disagree in the sense that readability indirectly forces someone who has been at Google for a while&#x2F; is more experienced to have to sign off on new people’s code. Without it, you could have some very junior members with OWNERS reviewing other very junior members’ code.And there is more to style than just linting, IMO. For example in C++ there are some complex macro-based test predicates that are hard to learn and use but which greatly simplify&#x2F;improve on naive testing. Part of the point of C++ readability is that people who understand this stuff teach new people how to use them, or at least introduce them to concept, during code review reply greiskul 16 hours agorootparent> I kind of disagree in the sense that readability indirectly forces someone who has been at Google for a while&#x2F; is more experienced to have to sign off on new people’s code. Without it, you could have some very junior members with OWNERS reviewing other very junior members’ code.Exactly. It is very likely for a lot of junior engineers will be working with other junior engineers, and they will in fact have the most specific knowledge of the part of the project that they are implementing. And human nature makes it so people are afraid of being judged by their \"superiors\". Readability makes so that it breaks that barrier, guarantees that a more senior engineer will be involved, and will teach the ropes into writing readable, mantainable code to nooglers. reply jrockway 12 hours agorootparentI dunno, I am pretty sure I got Java readability the second month I was at Google and was already in the OWNERS file.I was a readability reviewer and most of the readability CLs were the first project a person worked on at Google, often rather unnecessary but redone strictly to meet readability requirements (largely new code, more than X lines, etc.). I would go back and forth for quite a while to turn 1000 careless lines of throwaway code into 50 lines that were actually good, but I basically had to grant readability after that one interaction, and it never felt great to me.The most hated readability process at Google was Go&#x27;s process (at least in the early days; k8s is obviously not using it), but I think it was actually one of the best. It took me a long time to get Go readability, but after going through the process I feel like I&#x27;d write the same Go code as anyone on the Go team. When I look at people&#x27;s open source projects I think to myself \"don&#x27;t they know that that Simply Isn&#x27;t Done?\" But of course they don&#x27;t; Go readability can only be experienced, not explained. People didn&#x27;t like that process, and I am sure I said nasty things about it at the time, but in retrospect I really like it. reply cornel_io 8 hours agorootparentAs someone who quit Google in large part because of all the stuff like readability that I ran into there (red tape everywhere in sight, low productivity due to process, zero urgency bc everyone is fat off the money-printer, no deadlines for the same reasons, etc.), I was about to strongly disagree with you, and write yet another excoriating take on why readability is AlwaysBad(tm) and etc, etc. I did already snark elsewhere here...After taking a walk and reflecting, though, I&#x27;m remembering something that my manager said to me when I gave notice. Google is not for everyone, for a lot of reasons, and especially a lot of people who came up in startups really have problems (which is ironic since so many startups come out of people leaving Google). How you feel about readability may actually be a pretty good test of whether you will fit in at Google in the current era: it&#x27;s not a small, scrappy company anymore that gets shit done quickly using whatever tool is most efficient RIGHT NOW and ships it as fast as possible to see if it gets product&#x2F;market fit. It&#x27;s a behemoth that runs one of the most prolific money-printing machines that has ever been built, and fucking that up would be a DISASTER. It&#x27;d be better to have half the engineers at the company do literally nothing for 10 out of 12 months in the year than to let someone accidentally break the money-printing machine for a day while they figure out how to fix it.And obviously, it&#x27;s better if everyone is productive even as they&#x27;re shuffled around from project to project (which they will be, a lot), which means that you want as little \"voice\" as possible in their code. At a lot of companies you can tell exactly who wrote a line of code just by the style (naming, patterns, etc.), without even checking git blame, but at a place like Google individual styles cause problems. So the goal is to erase as much individual voice&#x2F;style&#x2F;preference as possible, and make sure that anyone can slot in and take over at any point, without having to bother the person that originally wrote the code to explain it (they might be at another project, another division, another company, and even if they&#x27;re still at Google there is a very strong sense that once a handoff is complete, you should not be bugging people to provide support for stuff they&#x27;ve moved on from).In that sense coding at Google is a lot closer to singing in a choir than being the frontman in a band: you need to commit to and be happy with minimizing what makes you unique or quirky, rather than trying to accentuate it and stand out. Some top-tier singers just can&#x27;t force their vibratos down, or hide their distinctive timbres, or learn to blend with a group, and are absolute trash in a choir; it&#x27;s not their fault or some ego failure, it&#x27;s just that there are some voice types that don&#x27;t work in groups, and that&#x27;s fine, you just don&#x27;t add those people to a choir.At least below director-level (or maybe L7 equivalent on an IC track), Google doesn&#x27;t need individuals to come in and shake things up, bust apart processes and \"10x\" a codebase. That&#x27;s startup shit, and even if it might sometimes be worth some risk for the high payoff, it&#x27;s too dangerous for them to allow for the thousands upon thousands of (still quite senior, sometimes 15+ years of experience) L4 or L5s at the company. The same process that prevents that from happening also makes sure that the entire machine keeps humming along smoothly. If being a part of that smoothly functioning machine while painting within the lines is exciting, then Google can be one of the best places on the planet to work; if you would be driven crazy because you can&#x27;t flex and YOLO a prototype out to users in a couple days, then it&#x27;s really not going to be for you.I&#x27;m in the latter camp, I couldn&#x27;t handle almost anything about the process and was so desperate to move quickly that I started talking to investors to line up my own funding a few months after I joined, but even as a quick-quit ( A lot of the overall goals of cloud are more ambitious than AWS offerings.In what sense? reply jupblb 17 hours agorootparentprevNice bait reply opportune 16 hours agoparentprevThe “policies don’t scale well” section is inaccurate.There are plenty of policies floating around that don’t scale well, and plenty of migrations that are still forced on internal users rather than handled magically by the migrating team. The reality is that Google is such a big company most of these fly under the radar of whichever person actually enforces these policies, and it becomes a whole thing to escalate up to whoever enforced them, and then there’s potentially a political battle between whatever director or VP is in charge of the bad actors and the enforcer (ideally they get away with not allocating HC to the internal migration and amortize it across all their users, so that HC can work on flashier stuff).I think one reason Google has a proliferation of bureaucracy and red tape is that they do not “review” postmortem action items very formally. They are only reviewed as part of the larger incident postmortem review process and the tooling is way overengineered such that performing that review beyond a perfunctory once over isn’t easy to do. So you end up in a situation where “we need to do something” and whichever person handled the incident has to suggest a way to make sure it doesn’t happen again - the easiest of which is to introduce some CYA process. The other reason is that non-coding EMs introduce processes to show some kind of impact on their team.Also, the existence of the monorepo, global test runs, forced migrations, etc makes it so maintaining a mothballed project incurs some inherent engineering costs - IMO it’s a non-negligible reason Google kills products that could instead simply exist without changes. It also makes it so Google doesn’t really “version” software generally speaking. reply marcyb5st 19 hours agoparentprevDISCLAIMER 1: Current Googler here, but opinions are my own.DISCLAIMER 2: I think from a hands-on-keyboard SWE there is a lot of useful stuff. What you mentioned about Google culture of killing products and such I am not gonna talk about.I recommend chapters about testing first and foremost. Among all the codebases I saw (both OS and proprietary) Google tests are the most comprehensive and reliable. However, If you are in a startup-like environment you should pick and choose and not try to follow every single principle listed as they could sink your velocity drastically in the short run.Other interesting points (IMHO) are Monorepo, Build System, and Code Reviews.For the Monorepo I discover being a huge lover although I was skeptical. The sad thing is that it&#x27;s a rather niche practice and tools like Git don&#x27;t play ball very well (i.e. each time you pull you have to retrieve changes for all the codebase, even files you never saw&#x2F;heard of managed by another team). I think there&#x27;s no nice off-the-shelf offering for running monorepos out there. However, not having to fight with git submodules, library versions, ... is great. If the change I am submitting breaks something else in the company you are immediately aware and so can act accordingly (e.g. keep the old implementation alongside the new one and mark it as deprecated so the other team will get a warning next time they do anything).The build system is a bit more controversial. I learned to love blaze&#x2F;bazel, but admittedly, the OS version is a bit messy to set up. Additionally, being so rigorous about the build rules felt like a massive chore at the beginning, but now I appreciate it a lot. I can instantly know the contacts of all the teams that use a build rule I declared and hence can be contacted to warn them about bugs, ... . I can create something experimental and have private visibility so only my team can use it and only later expose it to the wider world with just a one liner.Finally, the code review AKA Critique. Google has the best review tool I had the joy to use hands down. It&#x27;s clear about what happens, at which stage is the review of a particular section&#x2F;file and is focused on discussion. The evolution of each change is easy to follow along. These are things I really miss when using GitHub&#x2F;GitLab PR view. The tooling is incredibly confusing to me. Luckily (I am not affiliated in any way) an ex-Googler (I believe) is working on an alternative that works with GitHub (https:&#x2F;&#x2F;codeapprove.com&#x2F;). reply zahllos 13 hours agorootparentI am a big fan of Anki, and for reasons I wanted to build it on a machine I have on an uncommon architecture (it has a graphical desktop). I have all of the components... rust, typescript, qtwebengine, etc) installed and working. I invested some time in trying to convince bazel that the required dependencies existed, to no avail. Rules broke left right and centre and every time I found the solution, other things broke. I think it insisted on pulling stuff from the internet, including definitions of other stuff I needed to change. I can&#x27;t remember much more than that, as I gave up and haven&#x27;t thought about it much since.Thing is, pkg-config would&#x27;ve picked up the dependencies just fine - they were literally all there. I even built Rust from source on my weird machine with musl variant, before realising musl has some issues on my architecture.I suspect Bazel may work well inside of Google for infra&#x2F;server side stuff (never worked there). I&#x27;m a lot more skeptical of more complex builds, like desktop applications across various platforms. Chrome still uses \"gn\" to generate ninja files, and then ninja to build. For my own stuff, I won&#x27;t touch it.I probably wouldn&#x27;t have commented, except that, to my surprise it seems the Anki developers have also decided life is too short https:&#x2F;&#x2F;github.com&#x2F;ankitects&#x2F;anki&#x2F;commit&#x2F;5e0a761b875fff4c9e4... reply Macha 8 hours agorootparentAnki&#x27;s build seems particularly problematic for some reason - both Arch and NixOS have given up on updating their from source builds and just repackage the first party builds reply marcyb5st 12 hours agorootparentprevAs I mentioned, bazel is a bit messy to set up. I think it&#x27;s still doable and it brings a lot to the table, but it requires an upfront investment in learning Skylark and&#x2F;or fight with the various rules provided. Blaze (the internal version) is just great unless you want to do shady things that most likely you shouldn&#x27;t do anyway. reply nonethewiser 15 hours agorootparentprev> I think there&#x27;s no nice off-the-shelf offering for running monorepos out there.I think Git works perfectly well for 99% of monorepos though. It just doesn’t work for the massive ones. I think its a perfect example of something most codebases shouldn’t follow google on. reply marcyb5st 12 hours agorootparentMaybe if you only allow for shallow clones&#x2F;pulls. I am not sold on vanilla git handling monorepo well. If anybody in the company pushes a huge blob you mess up everyone else and so on. Git and some modifications perhaps yes though reply codeapprove 13 hours agorootparentprevThanks for the CodeApprove shoutout! If anyone here in the comments wants to try it out, just let me know! reply marcyb5st 12 hours agorootparentNo need to thank me. I didn&#x27;t try it yet, but we chatted months ago I another HN post and so once in a while I check it out. Any plans to include gitlab as first class citizen? reply codeapprove 12 hours agorootparentNo plans for Gitlab at the moment, but maybe one day! reply AlbertCory 12 hours agoparentprevPersonal story from ex-Googler: after getting exasperated at yet one more internal tool launched with great fanfare and almost no testing, let alone documentation, I suggested to the Internal Tools group that we have a contest for BEST internal tool.Not \"worst\" since that would be too hurtful. The hope was to recognize excellence, motivate people to be better, and maybe shame the people whose tools received no votes. This suggestion was summarily dismissed.There were, indeed, some truly excellent tools: Dremel comes to mind. And lots of tools that were nearly unusable. reply underdeserver 13 hours agoparentprevI left Google around six months ago. I worked in medium and small companies, currently at a startup with ~30 devs.I would say the vast majority of it works well, some you just don&#x27;t need until you hit scale (here, scale in the number of developers).For example, policies work if you havecomment on which parts of these work well and which don&#x27;t?I don&#x27;t think there is a visible distinction between those parts that work&#x2F;doesn&#x27;t work. In fact, most of the cases each practice has pretty strong rationales. The problem is, when you take everything as whole, its cumulative complexity and cognitive overhead tends to go wild and almost no one can understand the whole stack when its original writers&#x2F;maintainers leave the team.In fact, this might play a certain role of the Google graveyard narrative; it&#x27;s not because its engineering culture is bad, but sometime its standard is too high for many cases so it&#x27;s nearly impossible to keep it up for newcomers, especially when you have external pressures that you cannot ignore. Even if you make an eng team of 3~4 people for a small product, they&#x27;ll likely suffer from tens of migration&#x2F;deprecation&#x2F;mandates over years. reply patmcguire 13 hours agoparentprevReadability is hit and miss. Very nice to have everything written to the same standard, it makes it much easier to navigate through any project. Downside is it&#x27;s pretty rough for more peripheral teams or teams working in a language that&#x27;s a small component of their product. I remember for one of DeepMind&#x27;s big launches the interface was all in files ending in .notjs, presumably since they didn&#x27;t have anyone on the team with Javascript readability. This was 5+ years ago, though, so some of the downsides may have been mitigated. reply izacus 16 hours agoparentprev> Cool. Could someone, maybe an ex-googler, comment on which parts of these work well and which don&#x27;t?TBH most of this stuff is transferrable and even \"common sense\" in most of the companies you&#x27;ve worked for. Similarly how Google&#x27;s SRE book is actually a very good collection of battle won experience on how ops can keep systems more reliable and running.The book is written in a way that you can easily throw away advice that you don&#x27;t think useful. reply biogene 10 hours agoparentprev>A lot of other companies get into trouble trying to cargo-cult what Google does when they are operating in very different environments wherein those practices aren&#x27;t optimal. E.g. different levels of scale.Any prominent examples? reply FpUser 12 hours agoparentprevI could not care less about what Google practices. They operate on enormous scale and have vastly different goals and values. reply NoMoreNicksLeft 19 hours agoparentprev> Additionally, critics of Google may point out that their engineering culture may not be great on its own terms -- every time Google launches a new feature, people post links to the Google product graveyard.It is personally scary when they develop new products. What if it is a brilliant idea, one I cannot live without? If Google develops it, then I am looking at this stillborn thing, mewling for life when I know its horrible fate.The trouble here is that Google employees (and perhaps even its upper management) want to believe that they are a company which is an inventor of things. But they are not this at all. They are an advertisement company. Advertisement companies should not and do not want to invent things... inventions are worse than burdens, inventions are these weird alien objects that appear valuable but are quite expensive and do not help to sell ads at all.So they hawk the inventions like they were freaks in some carnival sideshow to move traffic past their billboards. Until the traffic dwindles (or until they get tired of it). And then they take it out back behind the woodshed and put an end to it. reply outside1234 19 hours agorootparentThe inventions are to keep the talent stream coming ... to work on ads.The inventions are the small tax they pay to pretend to candidates that they could work on inventions when the vast majority of them will be \"allocated\" to ads. reply fidotron 19 hours agorootparentIt&#x27;s also Google licking the cookie. They maintain a moat around ads by doing just enough to threaten to destroy anyone that gets close to their ecosystem.Facebook survived because G+ product vision was so out of touch with reality and FB were not part of the anti-compete hiring nonsense so that they managed to poach a lot of good people. reply biztos 18 hours agorootparentprevYou need Shiny Inventions so you can divert the talent stream away from your competitors, more than to actually work on the ads.I&#x27;m sure there&#x27;s some Shiny Invention Corner in the ads business -- let&#x27;s call it \"AI\" -- and some of the top people can be motivated to work there.But isn&#x27;t the ads business by its very firehose-of-money nature something that will get on fine with that average level of talent that is sufficiently motivated by cash and doesn&#x27;t need Inventions?And isn&#x27;t the top talent able to make the same money doing interesting things elsewhere? (I keep hearing this is happening with AI, but I hear it on Xwitter so who knows.) reply NoMoreNicksLeft 19 hours agorootparentprevYou&#x27;re telling me this stupid, bizarre thing: that Google&#x27;s major innovation was an HR process.That&#x27;s fucked-in-the-head just enough that you&#x27;ve made me wonder if it&#x27;s true. reply WorldMaker 15 hours agorootparent\"The best minds of my generation are thinking about how to make people click ads\"https:&#x2F;&#x2F;quoteinvestigator.com&#x2F;2017&#x2F;06&#x2F;12&#x2F;click&#x2F; reply svachalek 17 hours agorootparentprevI doubt they did anything like that intentionally. My impression in my time there was they were constantly cargo-culting themselves. X obviously works, so keep doing X, even if it doesn&#x27;t look like it makes any sense. And X was absolutely everything. reply NoMoreNicksLeft 17 hours agorootparentMind me asking why you moved on? reply7e 19 hours agoprevFor all of this, Google doesn’t create very good products anymore. This is a guide that came into being _after_ Google was successful. It’s not _why_ Google became successful.Yes, if you have a mountain of money and a horde of underutilized employees, it’s easy to gold plate your engineering and navel-gaze at your biases. reply phendrenad2 15 hours agoparentWhenever I watch&#x2F;read interviews with people who were successful in some way, they usually downplay the ugly hacks and shortcuts they took to get there, and are quick to say that they \"should have done it \". It&#x27;s really hard to get any insights because of this inherently unreliable narration. reply blitz_skull 14 hours agorootparentThere was a great (IMO) article posted here on HN the other day about this very topic: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37100226 reply Terr_ 14 hours agorootparentprevObligatory: https:&#x2F;&#x2F;xkcd.com&#x2F;1827&#x2F;I&#x27;m also reminded of something written by Scott Adams (decades ago, when his reputation was different.)> Most people won&#x27;t admit how they got their current jobs unless you push them up against a built-in wall unit and punch them in the stomach until they spill their drink and start yelling, \"I&#x27;LL NEVER INVITE YOU TO ONE OF MY PARTIES AGAIN, YOU DRUNKEN FOOL!\"> I think the reason these annoying people won&#x27;t tell me how they got their jobs is because they are embarrassed to admit luck was involved. I can&#x27;t blame them. Typically, the pre-luck part of their careers involved doing something enormously pathetic.-- \"The Dilbert Future\" (1997), by Scott Adams reply WorldMaker 15 hours agorootparentprevSurvivorship bias is a hell of drug. reply x86x87 19 hours agoparentprevIt depends how you look at it. A lot of products created by Google were good&#x2F;high quality but were killed anyway. It&#x27;s sad to see things being killed because they were not \"big enough\". reply natch 17 hours agorootparentThe ones that were not killed are atrociously shoddy and have been now for, you’d think I was going to say years, but it’s actually decades. reply philote 14 hours agorootparentI feel like even their main products are shoddy as well. How can they recommend good, relevant ads if they can&#x27;t even recommend good news articles, music, or videos? If I do any search in Google on a topic, even if it&#x27;s just to get a tiny bit of info about that topic, Google decides I&#x27;m interested in it and will make recommendations based on that one, single search. Or sometimes I&#x27;ll buy a product and start seeing ads for similar products later. That&#x27;s not good targeting IMO. reply siliconc0w 18 hours agoprevIMO bang for buck is to invest in:* reproducible fast dev environments - anyone should be able to build anything pretty easily fairly quickly* culture of design reviews, testing, and code reviews.* CI&#x2F;CD, static analysis, PaaS, dependency management.You can do all of these without Google-level or really any bespoke tooling. A lot of what google builds is for operating at Google scale - distributed builds and running of huge applications - and even then this tooling this simply enables working at this scale, it comes with a lot of cost(speed&#x2F;complexity) and jank you don&#x27;t need at smaller software shops. reply jsnell 19 hours agoprev(2020). Earlier discussions:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31224545 (304 points, 179 comments)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22609807 (222 points, 70 comments) reply dang 17 hours agoparentThanks! Macroexpanded:Software Engineering at Google (2020) [pdf] - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31224545 - May 2022 (178 comments)Software Engineering at Google - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22609807 - March 2020 (69 comments)Similar sounding but different:Software Engineering at Google (2017) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18818412 - Jan 2019 (309 comments)Software Engineering at Google - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=13619378 - Feb 2017 (156 comments) reply bluefishinit 19 hours agoprevUnless you have a monopoly on the ad market that&#x27;s going to mask all of your bad managerial, strategy and culture problems, then I&#x27;d advise steering well clear of copying Google. They make money in-spite of their day to day practices, not because of them. reply opportune 16 hours agoparentFrom someone who’s seen how the sausage gets made, I both agree and disagree.A lot of Google’s practices really are good software engineering practices - provided you have the money to invest in replicating it to a high degree of quality, which could be substantial and better spent elsewhere. When you have one of the most lucrative business models of all time you definitely have the money to invest in trying to make it as stable to maintain and easy to add value onto as possible, so it was definitely worth it for Google in many cases, but each other company will have to determine the costs vs benefits themselves.Replicating Blaze and Forge seems really expensive and hard to get right (though it can be tremendously valuable for development on a large codebase). Postmortems, containerization, servers-as-cattle, gradual non-global releases… those aren’t as expensive to set up and have great cost&#x2F;benefit ratios. It’d be stupid to not do these just because Google does them (and in some cases invented or popularized the practice). reply zirgs 18 hours agoparentprevYup - just look at Stadia. This is how they handle stuff that&#x27;s not related to ads. reply w10-1 15 hours agoprevAs a counterpoint to the engineering&#x2F;product&#x2F;culture comments providing context on the book, I would point out that Urs Hölzle has recently stepped back from uber-manager to individual contributor in the infrastructure space.This is the guy who built the hotspot JIT that added decades to the life of Java, and who engineered Google&#x27;s data centers and GCP. He obviously doesn&#x27;t need more money or glory or experience, so ... why?There are a million examples of things gone wrong, but it may be worth studying one example of how someone could have such an impact and still just love what he&#x27;s doing. reply pclmulqdq 15 hours agoparentAre we thinking about the same Urs? His reputation was not particularly good when I was in the TI group at Google recently. He also had nothing to do with this book. reply iaseiadit 15 hours agoparentprevDid he have any involvement in this book?He’s not an author and not in the acknowledgments: https:&#x2F;&#x2F;abseil.io&#x2F;resources&#x2F;swe-book&#x2F;html&#x2F;pr01.html#_acknowl... reply DeathMetal3000 13 hours agoprevOfficial PDF on github: https:&#x2F;&#x2F;github.com&#x2F;abseil&#x2F;abseil.github.io&#x2F;blob&#x2F;a5168e886917... reply flohofwoe 19 hours agoprevProbably a bit off-topic, but since I&#x27;m a bit triggered by the &#x27;abseil&#x27; in the domain name:I wish Google would relax their &#x27;guidelines&#x27; when it comes to software that&#x27;s also published outside of Google. Case in point: the Dawn C++ library (Google&#x27;s native WebGPU implementation) has a dependency on abseil, and from what I&#x27;ve seen when glancing over the code, the only reason seems to be some minor string-related stuff.I can only assume that there must be some interal NIH rule inside Google to use abseil in place of the C++ stdlib (of course I would prefer if Dawn would use neither abseil nor the stdlib, especially since it looks like the only component that&#x27;s used are related to strings, which definitely isn&#x27;t the focus of a 3D API)....and then there&#x27;s of course the use of &#x27;Google Depot Tools&#x27; and of course they are using their own build system [1] (however at least there the Dawn team rebelled and also provides cmake build files).All those Google specifics make it increadibly difficult to integrate Google C++ projects into any non-Google project, and because of this \"Google C++ bubble\" I would seriously hesitate taking any advice from them about software engineering as gospel, at least when it comes to C++.[1] https:&#x2F;&#x2F;chromium.googlesource.com&#x2F;chromium&#x2F;src&#x2F;tools&#x2F;gn&#x2F;+&#x2F;48... reply xyzzy_plugh 19 hours agoparentI cannot more strongly endorse this.It would be tremendously beneficial if their software dropped the abseil dependency, especially where it is almost entirely unused. Hell it&#x27;d be better if they simply vendored the bits they need.Having to use Bazel, and having to manage an additional dependency like abseil can be hellish for small projects with uncomplicated build systems.The worst part is that abseil leaks through interfaces and you end up being coupled to it as a consumer of a library. It&#x27;s bananas. I don&#x27;t need yet another stdlib. reply jeffbee 19 hours agoparentprevJust glancing at Dawn, which I never heard of until now, it appears their use of absl is similar in purpose to the way other Google open source projects use it: faced with the choice between requiring C++20 (or 17, or 14) or requiring only C++11 and using absl as a kind of polyfill, they chose the latter. reply compiler-guy 18 hours agoparentprevMany of the authors of abseil are on the C++ committee and contribute to its progress--this is especially true of the string library, where abseil convinced the standards committee to adopt string_view.The dependency here almost certainly predates C++ adopting the features it has had for a decade. reply dekhn 10 hours agoparentprevThe string stuff in abseil is mostly a historical byproduct of what google was doing in 1998: manipulating lots of strings. at the time, the C++ standard library string implementation (mainly the GNU one) was immature and slow. The string library was written in the early days for performance reasons, as well as reliability (at the time, the libstdc++ was so bad that most string operations just made garbage, not strings). And then it got too expensive to change the entire codebase.I remember Sanjay Ghemawat or Jeff Dean mentioning that one of their big \"optimizations\" was to inline short strings into the string object- instead of a string that was \"size_t len, size_t capacity, char *data\", anything less than 24 bytes was just stored directly instead of with a pointer. when you&#x27;re running mapreduces with trillions of small keys, this makes a big difference! reply tylerhou 19 hours agoparentprevFor string related stuff — there’s not much in the stdlib that can replace the stuff in abseil. (Haven’t looked at Dawn in particular, though.)E.g. absl::StrFormat — no equivalent until std::format was standardized in C++20.absl::StrCat: You could use streams, but, ew. Also, StrCat is optimized to reserve sufficient size in advance, so it is more efficient than appending to a string or using a std::stringstream.absl::Cord. No equivalent in the stdlib. reply ajross 18 hours agoparentprev> I can only assume that there must be some interal NIH rule inside Google to use abseil in place of the C++ stdlibFWIW my understanding is that this is exactly backwards: Abseil exists because the internal code and toolchain evolved to use features that hadn&#x27;t landed in the standard yet, and releasing the support this way allows that dependent code to be used in open source releases. It&#x27;s not about features Googler&#x27;s \"can&#x27;t\" use, it&#x27;s that they[1] could always use better stuff, and this is a way to get the better stuff released so non-Googlers could use it at all (and then, apparently, complain about it).Obviously looking at this in hindsight from the outside of a project using gcc13&#x2F;clang15, it seems like it&#x27;s needlessly different. But when written it was forward-looking.[1] \"We\", I guess, though I work in ChromeOS and not in this world. reply secondcoming 19 hours agoparentprevC++ stdlib didn’t have string_view for ages. Also, until recently, C++ sucked for things like convert to&#x2F;from strings and string buffers. std::stringstream is awful. reply choppaface 12 hours agoparentprevPart of the pressure behind abseil is that perf and promotions are correlated with open source (Tensorflow, Chromium, TFX, etc) and it would be essentially impossible to translate internal projects for public release without a public library like abseil.In contrast Facebook Folly has much less overall clout because engineers there have more incentive to build-from-scratch, which can include simply not using C++. reply dboreham 19 hours agoprevThis part is good: https:&#x2F;&#x2F;abseil.io&#x2F;resources&#x2F;swe-book&#x2F;html&#x2F;ch13.html#prefer_r... reply kyrra 19 hours agoparentI&#x27;d say it&#x27;s a tradeoff. If you are entirely driven by tests that include your deps, they will be slow. Unit tests are good at catching basic behavior issues that would show up with an integration test, but it&#x27;s easier to see the cause.I&#x27;m of the opinion that both are needed, but don&#x27;t put all your eggs in unit tests (they don&#x27;t need to be perfect). That extra time being spent on integration tests tend to be better for maintaining system health. reply compiler-guy 18 hours agorootparentGoogle&#x27;s massive distributed build system also runs tests and so most projects run their dependent tests in parallel on thousands of machines. reply kuchenbecker 8 hours agorootparentWith an optional --runs-per-test=1000 reply lhorie 17 hours agoprevI&#x27;m stumbling into this thread right after experiencing what appears to be a pretty catastrophic failure of Google&#x27;s main product. As I write this, the search results for \"Google stock\" (among other queries) returns zero results (\"Your search - google stock - did not match any documents\").I&#x27;m not really sure what to make out of these discussions about how X or Y Google engineering is, while the production service is broken for an end user like me. reply roody15 17 hours agoparentThe decline of google’s search engine has really been dramatic. It honestly is just a poor product at this point and I find myself having to use yandex, bing and variety of other tools now to find what I am looking for.My guess is that between SEO companies and Google just trying to maximize ad profits the product is in terminal decline reply systemBuilder 11 hours agorootparentThey really don&#x27;t give a shit how many search engineers they drive away with 50+-hour weeks and their endless criticism. When it became uncool to have Google Search on your resume in 2018, I left. reply crazygringo 16 hours agoparentprevSearching for \"Google stock\" shows me correct results. A stock chart followed by various search results.There&#x27;s no news of a widespread Google failure. Maybe you have a browser extension interfering? Or there&#x27;s some kind of very localized hiccup.In any case, your experience right now isn&#x27;t even close to representative. For its scale and complexity, Google search is probably one of the most reliable services ever built. reply lhorie 16 hours agorootparentSmall update: It&#x27;s definitely not extensions, it&#x27;s giving the same result on two different devices (mobile and laptop). I&#x27;ve narrowed it down to there being something going on w&#x2F; being logged into specific accounts. On my work account, I get no results (and this is a query that used to return results under the exact same setup just last week). Trying on an old personal gmail account, I&#x27;m getting the UI localized to what seems to be mandarim for who knows what reason (I don&#x27;t speak mandarim, and don&#x27;t even use this account on a regular basis).As for why this happens, I have no idea. I&#x27;ve had Google Maps completely black out on me and then eventually magically fix itself many months later.As for reliability, I would probably have agreed if it was a \"simple\" system (which the original Google was). Today, I&#x27;m not so sure. I at least understand that Google today is made up of a large number of subsystems, and subsystem failures like the ones I&#x27;m experiencing (and bad search results as others have also reported) do in fact erode my trust in the product. \"Your 99.9% is not my 99.9%\" feels like an apt quote here. reply bradley13 16 hours agorootparentprevPossible. I noticed recently that Google search no longer works with NoScript. It used to work. Not sure when this changed, since I don&#x27;t often enable NoScript. reply crazygringo 16 hours agorootparent[Deleting -- I thought I was replying to the same commenter. Never mind, bradley13! Thanks.] reply bradley13 15 hours agorootparentI&#x27;m not the original commenter. I was just tossing in a hypothesis based on my experience. reply dekhn 10 hours agoparentprevAre you really sure your machine isn&#x27;t running malware that intercepts queries?The query [ google stock ] would never return zero results.If this is really happening to you, please post an actual screenshot demonstrating that a standard browser in incognito (not logged in) mode on a standard OS returns no results for [ google stock ].I&#x27;m not saying Google&#x27;s core product hasn&#x27;t slipped but that&#x27;s one query I run every day. reply 0x000xca0xfe 14 hours agoparentprevDon&#x27;t know why you are getting downvoted - search quality has declined drastically.I&#x27;ve had multiple occasions where Google reproducibly fails to find exact matches in the page title (no problem for Bing). This cannot be explained by mysterious AI ranking or Unicode issues since Google gave me zero results, the website is non-political, and the title is just plain ASCII.This never happened ten years ago. Whatever they are doing now, they are seriously screwing things up. reply chinchilla2020 14 hours agoparentprevSearch has significantly declined in quality in the past two years. reply johnnyrandom 15 hours agoparentprevfound this comment thru google&#x27;s \"filter by latest 24 hours\" searchcurrently logged on a google account, indeed the \"google stock\" search shows \"Your search - google stock - did not match any documents\"it happens with other searches, too; not all of them, but some.no solution found at the moment except logging on another account &#x2F; not using an account. no extensions installed either. reply alex_lav 16 hours agoparentprevI’ve been unable to “Mark as read” in GMail for two years now. reply SNosTrAnDbLe 15 hours agoprevGoogle is not a good example to look at if you are thinking about enterprise software as these need to be supported long term and Google is not very good at that. They have a history of making breaking changes and discontinuing products.Microsoft is a much better example for business software as they are (were?) paranoid about backward compatibility. reply cratermoon 15 hours agoparentYou&#x27;re confusing software engineering with corporate product support. You can have top-notch ongoing lifetimes for trash products. See for example SAP or anything Oracle. reply SNosTrAnDbLe 15 hours agorootparentProduct support is an integral part of enterprise software engineering. Product management does not know what adding a new feature or deprecating an old feature means. It is the responsibility of engineering to provide the dependency matrix.For example, engineering usually tells product, if you change feature A, then it will also affect feature B, C and Z. Otherwise you may end up with contract breaches and SLA violations.Product lifetime and providing incremental features is a big reason why SAP and Oracle have been successful in the enterprise space and people still pay a lot of money to buy them. reply cratermoon 5 hours agorootparent> SAP and Oracle have been successful in the enterprise spaceYes, but are the well-engineered software? reply coryfklein 15 hours agoprevI&#x27;ve been listening to the audiobook and definitely recommend it to others.Also, it&#x27;s free. [0][0] https:&#x2F;&#x2F;www.audible.com&#x2F;pd&#x2F;Software-Engineering-at-Google-Au... reply jroseattle 19 hours agoprevIf this document is intended as a how-google-does-it for applicability outside of Google, then the leadership section (Ch9) should include a heavy dose of your-mileage-may-vary. It is very good advice, but requires great cultural and executive support.All the adages listed here make perfect sense, but they don&#x27;t succeed in a vacuum. Servant leadership is great, until individuals disagree with product strategy and priorities. Addressing low performers is great, until a company&#x27;s HR policies make doing so onerous.I could go on, but there are often many things outside of your control as a leader that directly affect your capability to manage. It&#x27;s all part of the job and something to account for, but set your expectations accordingly. reply esafak 18 hours agoprevGoogle is not what it used to be but this book is great. So much distilled wisdom. reply ChrisMarshallNY 19 hours agoprevThat&#x27;s pretty interesting.I can&#x27;t tell, right offhand, but is this an official Google publication? reply xyzzy_plugh 19 hours agoparentYes: https:&#x2F;&#x2F;abseil.io&#x2F;resources&#x2F;swe-book reply dagipflihax0r 19 hours agoparentprevsee also: \"Software Engineering at Google: Lessons Learned from Programming Over Time\" 1st Edition by Titus Winters (Author), Tom Manshreck (Author), Hyrum Wright (Author) O&#x27;Reilly reply traxmaxx 19 hours agoparentprevseems to be the content of https:&#x2F;&#x2F;www.oreilly.com&#x2F;library&#x2F;view&#x2F;software-engineering-at... reply sharts 10 hours agoprevPeople seem to blindly worship Google too much. There have always been good ideas in engineering but because Google has the money to implement them at scale they get all of the credit.Testing, reproducibility, etc. These have always been common sense. It&#x27;s just that people only adopt them when the big guys do it because we implicitly give authority to those with money and power.It&#x27;s not different than when you see folks making videos of \"How a millionaire structures his time.\" Like, wtf. Those ideas existed before the millionaire. Many people already practice those. And those alone are not what made the millionaire. reply suyash 19 hours agoprevA book on software engineering but totally missing how decisions are made around what features to build, what bugs to fix. I would have love to read more on how Google engineers prioritise work, what makes them more creative in terms of building innovative features and products. Also would have love to read how UI engineering is done while working with designers etc. reply namdnay 17 hours agoparentWhat you’re describing sounds more like a book on product management? reply natch 17 hours agorootparentYeah but ideally some PM spirit should also be built into a good developer culture so they can fill any PM gaps when needed, imho. reply kaycebasques 16 hours agorootparentTo add to your point, I think what they said about technical writing might also apply to product management:> It introduced a perverse incentive: become an important project and your software engineers won’t need to write documents. Discouraging engineers from writing documents turns out to be the opposite of what you want to do. Because they are a limited resource, technical writers should generally focus on tasks that software engineers don’t need to do as part of their normal duties. Usually, this involves writing documents that cross API boundaries. Project Foo might clearly know what documentation Project Foo needs, but it probably has a less clear idea what Project Bar needs. A technical writer is better able to stand in as a person unfamiliar with the domain. In fact, it’s one of their critical roles: to challenge the assumptions your team makes about the utility of your project. It’s one of the reasons why many, if not most, software engineering technical writers tend to focus on this specific type of API documentation.PMs are a scarce resource. A lot of eng teams within Google don&#x27;t have a dedicated PM and need to carve out product-market fit for themselves. When you have a dedicated PM it&#x27;s easier to offload all PM ideas and responsibilities to that person.(I&#x27;m a technical writer at Google. The boilerplate \"all opinions my own\" is important in this convo because I think a lot of TWs and PMs will strongly disagree with these ideas.) reply natch 17 hours agoparentprevSuper important point. What seems to be missing at Google today is caring and initiative in fixing anything.Maybe it’s more of a PM culture thing.But as a dev (not at Google) I’m used to stepping into self-driven mode when PMs are slacking, and it’s a shame for Google that Googlers don’t exhibit this behavior. reply water-your-self 19 hours agoprevHow have layoffs impact group psychological safety? reply UncleMeat 18 hours agoparentNot good.I&#x27;ve seen people rapidly shift to career protection, wagon-circling, and empire building. I&#x27;ve seen more competition for leading junior people since there are fewer new hires coming in. But mostly I&#x27;ve seen the company become more cynical towards executives.Depending on your feelings on AI, you might see new excitement and opportunity opening up or further meddling and messy product management in the future. I&#x27;m not sure where I land here yet.I think Google is still a very good place to work. Pay is high. WLB is great (at least where I sit). Tooling is very good. I haven&#x27;t had any asshole managers or directors. But I definitely find it hard to get people excited about taking a big risk or maintain a project that is important but somehow misaligned with what your VP cares about. reply x86x87 19 hours agoparentprevI think they hit pretty hard. I remember some hardcore arguments with buddies that work at google when I told them that based on google&#x27;s behavior layoffs are going to happen (this was 3-6 months before google did their first layoffs in history). I was brushed off with \"google would not do that\" and \"our culture us different\". It was heartbreaking to hear how their view on google transformed after layoffs did happen. reply zinsn1 18 hours agoprevFound it here how Google Engineering Career Ladder is structured: https:&#x2F;&#x2F;labs.revelo.com&#x2F;template&#x2F;google-google-software-engi... reply systemBuilder 11 hours agoparentThat&#x27;s mostly propaganda, like most companies, Google has a policy of something like 5x-10x fewer people at every level as you go up the management chain, and they enforce that policy in preference and use these sugar-coated candy-cane level guidance documents to hide their sleaze. reply neilv 16 hours agoparentprevhttps:&#x2F;&#x2F;www.levels.fyi&#x2F;?compare=Amazon,Facebook,Google&track... reply very_good_man 17 hours agoprevWhen are we going to advance as an industry and stop worshiping these people?If you have a decade in control of the greatest internet business ever, go ahead and do exactly as Google has done. For anyone else, look inward for inspiration! reply nerdchum 16 hours agoprevI thought that the more high status the company would indicate better technology stacks and better quality of engineering.... but all the high status seems to do is pull in people who are really good at politics and doing promotion based development which is kind of counter to the science aspect of computer science. reply commandlinefan 16 hours agoparentI&#x27;ve consistently gotten the impression that the difference between high performing organizations like Google and less high-performing organizations is that Google doesn&#x27;t just _say_ they do this stuff, they actually do it, too. (Or, at least, they used to). reply nerdchum 15 hours agorootparent> \"High performing\"I havent really see Google doing any innovation in about a decade or more? What have they done significant since maps and android over a decade ago?Apple stomping them in hardware, openai stomping them in AI, AWS stomping them in cloud, Nvidia stomping them on game streaming.Google has a monopoly on a big ad network at its core and thats not high performing or innovative. reply CoastalCoder 19 hours agoprevThe \"3. Thesis\" section [0] seems empty. Anyone know what&#x27;s up with that?[0] https:&#x2F;&#x2F;abseil.io&#x2F;resources&#x2F;swe-book&#x2F;html&#x2F;part1.html reply lapcat 19 hours agoparentIt&#x27;s just a separator page. Each of the parts is like that: https:&#x2F;&#x2F;abseil.io&#x2F;resources&#x2F;swe-book&#x2F;html&#x2F;part2.htmlThis is an html copy of a physical book. In book, that&#x27;s nothing unusual. reply carabiner 17 hours agoprevIs there a reason to emulate google if your company is not trying",
    "originSummary": [
      "The book \"Site Reliability Engineering: How Google Runs Production Systems\" offers a comprehensive exploration of various topics in software engineering, team culture, and leadership.",
      "It shares insights and best practices from Google's perspective and experiences, providing valuable knowledge in areas such as measuring engineering productivity, code review, documentation, testing, and tools.",
      "The book also covers topics like dependency management, large-scale changes, continuous integration, continuous delivery, and compute as a service, making it a valuable resource for software engineers looking to enhance their skills and understanding in these areas."
    ],
    "commentSummary": [
      "The Hacker News discussion covers various topics related to software engineering at Google, including the effectiveness of their practices and the scalability and architecture of their software systems.",
      "It also discusses the performance review and promotion processes at Google, as well as the importance of emulating their practices and the development process with a focus on Piper and citc workspaces.",
      "The conversation touches on other areas such as code readability and maintainability, opinions on Google's engineering practices and products, and related topics like gcc and clang, C++ stdlib limitations, the abseil library, Google's search engine, Microsoft's backward compatibility, and a book on software engineering at Google."
    ],
    "points": 323,
    "commentCount": 320,
    "retryCount": 0,
    "time": 1692021969
  }
]
