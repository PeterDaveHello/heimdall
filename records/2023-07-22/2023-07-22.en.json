[
  {
    "id": 36811554,
    "timestamp": 1689929328,
    "title": "I have written a JVM in Rust",
    "url": "https://andreabergia.com/blog/2023/07/i-have-written-a-jvm-in-rust/",
    "hn_url": "http://news.ycombinator.com/item?id=36811554",
    "content": "I have written a JVM in RustPublished Wednesday, Jul 12, 2023 - 2164 words, 11 minutesTagged: stack-based-virtual-machines , java , rustLately I\u2019ve been spending quite a bit of time learning Rust, and as any sane person would do, after writing a few 100 lines programs I\u2019ve decided to take on something a little bit more ambitious: I have written a Java Virtual Machine in Rust. \ud83c\udf89 With a lot of originality, I have called it rjvm. The code is available on GitHub.I want to stress that this is a toy JVM, built for learning purposes and not a serious implementation. In particular, it does not support:genericsthreadsreflectionannotationsI/Ojust in time compilerstring interningHowever, there are quite a few non-trivial things implemented:control flow statements (if, for, ...)primitive and object creationsvirtual and static method invocationexceptionsgarbage collectionclass resolution from a jar fileFor example, the following is part of the test suite:class StackTracePrinting {  public static void main(String[] args) {    Throwable ex = new Exception();    StackTraceElement[] stackTrace = ex.getStackTrace();    for (StackTraceElement element : stackTrace) {      tempPrint(          element.getClassName() + \"::\" + element.getMethodName() + \" - \" +              element.getFileName() + \":\" + element.getLineNumber());    }  }  // We use this in place of System.out.println because we don't have real I/O  private static native void tempPrint(String value);}It uses the real rt.jar containing the classes from the OpenJDK 7 - thus, in the example above, the java.lang.StackTraceElement class comes from a real JDK!I am very happy with what I have learned, about Rust and about how to implement a virtual machine. In particular, I am super happy about having implemented a real, working, garbage collector. It\u2019s quite mediocre, but it\u2019s mine and I love it. \ud83d\udc98 Given that I have achieved what I set out to do originally, I have decided to stop the project here. I know there are bugs, but I do not plan to fix them.OverviewIn this post, I will give you an overview of how my JVM works. In further articles, I will go into more detail about some of the aspects discussed here.Code organizationThe code is a standard Rust project. I have split it into three crates (i.e. packages):reader, which is able to read .class files and contains various types that model their content;vm, which contains the virtual machine that can execute the code as a library;vm_cli, which contains a very simple command-line launcher to run the VM, in the spirit of the java executable.I\u2019m considering extracting the reader crate in a separate repository and publishing it on crates.io, since it could actually be useful to someone else.Parsing a .class fileAs you know, Java is a compiled language - the javac compiler takes your .java source files and produces various .class files, generally distributed in a .jar file - which is just a zip. Thus, the first thing to do to execute some Java code is to load a .class file, containing the bytecode generated by the compiler. A class file contains various things:metadata about the class, such as its name or the source file namethe superclass namethe implemented interfacesthe fields, along with their types and annotationsand the methods with:their descriptor, which is a string representing the type of each parameter and the method\u2019s return typemetadata such as the throws clause, annotation, generics informationand the bytecode, along with some extra metadata such as the exception handler table and the line numbers table.As mentioned above, for rjvm I have created a separate crate, named reader, which can parse a class file and return a Rust struct that models a class and all its content.Executing methodsThe main API of the vm crate is Vm::invoke, which is used to execute a method. It takes a CallStack, which will contain the various CallFrame, one for each method being executed. For executing main, the call stack will initially be empty, and a new frame will be created to run it. Then, each function invocation will add a new frame to the call stack. When a method\u2019s execution completes, its corresponding frame will be dropped and removed from the call stack.Most methods will be implemented in Java, and thus their bytecode will be executed. However, rjvm also supports native methods, i.e. methods that are implemented directly by the JVM and not in the Java bytecode. There are quite a few of them in the \u201clower parts\u201d of the Java API, where interaction with the operating system (for example, to do I/O) or the support runtime is necessary. Some examples of the latter you might have seen include System::currentTimeMillis, System::arraycopy, or Throwable::fillInStackTrace. In rjvm, these are implemented by Rust functions.The JVM is a stack-based virtual machine, i.e. the bytecode instructions operate mainly on a value stack. There is also a set of local variables, identified by an index, that can be used to store values and pass arguments to methods. These are associated with each call frame in rjvm.Modeling values and objectsThe type Value models a possible value of a local variable, stack element, or object\u2019s field, and is implemented as follows:/// Models a generic value that can be stored in a local variable or on the stack.#[derive(Debug, Default, Clone, PartialEq)]pub enum Value<'a> {  /// An unitialized element. Should never be on the stack,  /// but it is the default state for local variables.  #[default]  Uninitialized,  /// Models all the 32-or-lower-bits types in the jvm: `boolean`,  /// `byte`, `char`, `short`, and `int`.  Int(i32),  /// Models a `long` value.  Long(i64),  /// Models a `float` value.  Float(f32),  /// Models a `double` value.  Double(f64),  /// Models an object value  Object(AbstractObject<'a>),  /// Models a null object  Null,}As an aside, this is one place where a sum type, such as Rust\u2019s enum, is a wonderful abstraction - it is great for expressing the fact that a value might be of multiple different types.For storing objects and their values, I initially used a simple struct called Object containing a reference to the class (to model the object\u2019s type) and a Vec<Value> for storing fields' values. However, when I implemented the garbage collector, I modified this to use a lower-level implementation, with a ton of pointers and casts - quite C style! In the current implementation, an AbstractObject (which models a \u201creal\u201d object, or an array) is simply a pointer to an array of bytes, which contain a couple of header words and then the fields' values.Executing instructionsExecuting a method means executing its bytecode instructions, one at a time. The JVM has a wide list of instructions (over two hundred!), encoded by one byte in the bytecode. Many instructions are followed by arguments, and some have a variable length. This is modeled in the code by the type Instruction:/// Represents a Java bytecode instruction.#[derive(Clone, Copy, Debug, Eq, PartialEq)]pub enum Instruction {  Aaload,  Aastore,  Aconst_null,  Aload(u8),  // ...The execution of a method will keep, as mentioned above, a stack and an array of local variables, referred by the instructions via their index. It will also initialize the program counter to zero - that is, the address of the next instruction to execute. The instruction will be processed and the program counter updated - generally advanced by one, but various jump instructions can move it to a different location. These are used to implement all flow control statements, such as if, for, or while.A special family of instruction is made of those that can invoke another method. There are various ways of resolving which method should be invoked: virtual or static lookup are the main ones, but there are others. After resolving the correct instruction, rjvm will add a new frame to the call stack and start the method\u2019s execution. The method\u2019s return value will be pushed to the stack unless it is void, and execution will resume.The Java bytecode format is quite interesting and I plan to dedicate a post to the various kind of instructions.ExceptionsExceptions are quite a complex beast to implement since they break the normal control flow, and might return early from a method (and propagate on the call stack!). I am pretty happy with the way I have implemented them, though, and I am going to show you some of the relevant code.The first thing you need to know is that any catch block corresponds to an entry of a method\u2019s exception table - each entry contains the range of covered program counters, the address for the first instruction in the catch block, and the exception\u2019s class name which the block catches.Next, the signature of CallFrame::execute_instruction is as follows:fn execute_instruction(  &mut self,  vm: &mut Vm<'a>,  call_stack: &mut CallStack<'a>,  instruction: Instruction,) -> Result<InstructionCompleted<'a>, MethodCallFailed<'a>>Where the types are:/// Possible execution result of an instructionenum InstructionCompleted<'a> {  /// Indicates that the instruction executed was one of the return family. The caller  /// should stop the method execution and return the value.  ReturnFromMethod(Option<Value<'a>>),  /// Indicates that the instruction was not a return, and thus the execution should  /// resume from the instruction at the program counter.  ContinueMethodExecution,}/// Models the fact that a method execution has failedpub enum MethodCallFailed<'a> {  InternalError(VmError),  ExceptionThrown(JavaException<'a>),}and the standard Rust Result type is:enum Result<T, E> {  Ok(T),  Err(E),}Thus, executing an instruction can result in four possible states:the instruction was executed successfully, and the execution of the current method can continue (the standard case);the instruction was executed successfully, and it was a return instruction, thus the current method should return with (optionally) a return value;the instruction could not be executed, because some internal VM error happened;or the instruction could not be executed, because a standard Java exception was thrown.The code that executes a method is thus as follows:/// Executes the whole methodimpl<'a> CallFrame<'a> {  pub fn execute(    &mut self,    vm: &mut Vm<'a>,    call_stack: &mut CallStack<'a>,  ) -> MethodCallResult<'a> {    self.debug_start_execution();    loop {      let executed_instruction_pc = self.pc;      let (instruction, new_address) =        Instruction::parse(          self.code,           executed_instruction_pc.0.into_usize_safe()        ).map_err(|_| MethodCallFailed::InternalError(          VmError::ValidationException)        )?;      self.debug_print_status(&instruction);      // Move pc to the next instruction, _before_ executing it,       // since we want a \"goto\" to override this      self.pc = ProgramCounter(new_address as u16);      let instruction_result =         self.execute_instruction(vm, call_stack, instruction);      match instruction_result {        Ok(ReturnFromMethod(return_value)) => return Ok(return_value),        Ok(ContinueMethodExecution) => { /* continue the loop */ }        Err(MethodCallFailed::InternalError(err)) => {          return Err(MethodCallFailed::InternalError(err))        }        Err(MethodCallFailed::ExceptionThrown(exception)) => {          let exception_handler = self.find_exception_handler(            vm,            call_stack,            executed_instruction_pc,            &exception,          );          match exception_handler {            Err(err) => return Err(err),            Ok(None) => {              // Bubble exception up to the caller              return Err(MethodCallFailed::ExceptionThrown(exception));            }            Ok(Some(catch_handler_pc)) => {              // Re-push exception on the stack and continue              // execution of this method from the catch handler              self.stack.push(Value::Object(exception.0))?;              self.pc = catch_handler_pc;            }          }        }      }    }  }}I know that there are quite a few implementation details in this code, but I hope it gives an idea of how using Rust\u2019s Result and pattern matching maps really well to the description of the behavior above. I have to say I am rather proud of this code. \ud83d\ude0aGarbage collectionThe final milestone in rjvm has been the implementation of the garbage collector. The algorithm I have chosen is a stop-the-world (which trivially follows from not having threads!) semispace copying collector. I have implemented a (poorer) variant of Cheney\u2019s algorithm - but I really should go and implement the real thing\u2026 \ud83d\ude05The idea is to split the available memory into two parts, called semispaces: one will be active and used to allocate objects, and the other will be unused. When full, a garbage collection will be triggered and all alive objects will be copied to the other semispace. Then, all references to objects will be updated, so that they point to the new copies. Finally, the role of the two will be swapped - similar to how blue-green deployment works.This algorithm has the following characteristics:obviously, it wastes a lot of memory (half of the possible max memory!);allocations are super fast (bumping a pointer);copying and compacting objects means that it does not have to deal with memory fragmentation;compacting objects can improve performances, due to better cache line utilization.Real Java VMs use far more sophisticated algorithms, generally generational garbage collectors, such as G1 or the parallel GC, which use evolutions of the copying strategy.ConclusionsIn writing rjvm, I learned a lot and I had a lot of fun. Can\u2019t ask for more from a side project\u2026 but maybe next time I will pick something a bit less ambitious to learn a new programming language! \ud83e\udd2dAs an aside, I want to say that I had a lot of fun with Rust. I think it is a great language, as I have written before, and I have really enjoyed using it for implementing my JVM!If you are interested in further details on how rjvm is implemented (and on how the JVM actually works), stay tuned for the upcoming posts!",
    "summary": "- Author has created a JVM in Rust for learning purposes, named rjvm, which is a toy JVM and not a serious implementation.\n- The JVM in Rust supports control flow statements, primitive and object creations, method invocations, exceptions, garbage collection, and class resolution from a jar file.\n- The author plans to stop the project here and will provide more detailed explanations of how the JVM works in future articles.",
    "hn_title": "I have written a JVM in Rust",
    "original_title": "I have written a JVM in Rust",
    "score": 662,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginI have written a JVM in Rust (andreabergia.com)662 points by lukastyrychtr 1 day ago | hide | past | favorite | 154 commentsceleritascelery 18 hours ago | next [\u2013]I have a few questions about the garbage collection. One of the hard parts of implementing a garbage collector is making sure everything is properly rooted (especially with a moving collector). you have the `do_garbage_collection` method marked unsafe[1], but don't explain what the calling code needs to do to ensure it is safe to call. How do you ensure all references to the heap are rooted? This is not a trivial problem[2][3][4].Also note that I cloned the repo and tried to run `cargo test` every test fails with 'should be able to add entries to the classpath: InvalidEntry(\".../vm/rt.jar\")' vm/tests/integration/real_code_tests.rs:15:10[1] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...[2] https://manishearth.github.io/blog/2021/04/05/a-tour-of-safe...[3] https://without.boats/blog/shifgrethor-iii/[4] https://coredumped.dev/2022/04/11/implementing-a-safe-garbag...replymunificent 17 hours ago | parent | next [\u2013]It's pretty straightforward. Their VM maintains its own notion of a callstack instead of using the native callstack. That lets them iterate over it and find all of the parameters and locals on the VM's callstack and use them as roots.There is a performance cost for a VM having its own virtual callstacks like this, but it makes GC tracing much simpler. (It also makes implementing interesting concurrency and control flow primitives like coroutines or continuations much easier too.)replyceleritascelery 17 hours ago | root | parent | next [\u2013]Seems like that would take care of roots for the bytecode's themselves, but not for \"native\" functions[1]. Allocating a new object could call gc[2], and native functions are using the native callstack. It seems like it would be easy to allocate in a native function and any unrooted references would be invalidated. In fact I see a case like that here[3]. That method creates a reference with `expect_concrete_object_at` and then calls gc with `new_java_lang_class_object`. It avoids UB by not using `arg` after the call that gc's, but there is nothing stopping you from using `arg` again (and having an invalid reference).[1] https://github.com/andreabergia/rjvm/blob/main/vm/src/native...[2] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...[3] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...replyandreabergia 16 hours ago | root | parent | next [\u2013]Indeed you are right, this is definitely a bug and could cause errors.I guess the solution would be to add an explicit API to create a GC root, invoked by native methods (which is a bit complicated by the fact that I use a moving collector).Many years ago I was using SpiderMonkey in a c++ project and I seem to remember there were some APIs for native callbacks to invoke that rooted values. Same problem and similar solution. :-)replymunificent 15 hours ago | root | parent | next [\u2013]> I guess the solution would be to add an explicit API to create a GC root, invoked by native methods (which is a bit complicated by the fact that I use a moving collector).This is why I do in the Wren VM. Any time a native C function has the only reference to a GC-managed object and it's possible for a collection to occur, it calls a function to temporarily add the object to a list of known roots.replyamelius 12 hours ago | parent | prev | next [\u2013]GCs are pretty easy, and just a matter of good accounting. That is, until you start doing concurrent GC then it becomes hellishly difficult.replyChuckMcM 16 hours ago | prev | next [\u2013]That is pretty awesome! When I joined the Java effort in '92 (called Oak at the time) the group I was with was looking at writing a full OS in Java. The idea being that you could get to just the minimal set of things needed as \"machine code\" (aka native methods) you could reduce the attack surface of an embedded OS. (originally Java was targeted to run in things like TV's and other appliances). We were, of course, working in C rather than Rust for the native methods. The JVM in Rust though adds a solid level of memory safety to the entire process.replymshockwave 15 hours ago | parent | next [\u2013]> writing a full OS in JavaIMAO, Android kind of achieve that...kind of. They write lots of OS logics in Java (or Kotlin) but mixing lots of system services written in native code at the same time, interconnected by the famous (or infamous?) Bind IPC.replyActorNightly 13 hours ago | root | parent | next [\u2013]Android is mostly things that run java, not java itself. You can look at the source code, there is a relatively small amount of java in there.replysaagarjha 1 hour ago | root | parent | next [\u2013]Android has many lines of Java to support its frameworks and system services.replytgtweak 14 hours ago | root | parent | prev | next [\u2013]Embedded JVM is actually huge/pervasive and runs things as benign as the chip on your credit card.replylatchkey 6 hours ago | root | parent | next [\u2013]Don't forget the Java Ring!https://www.ebay.com/itm/300495374337replytgtweak 6 hours ago | root | parent | next [\u2013]Yeah they had these java buttons too. Not sure if she's j2me or javacard underneath but it's a proper OS.replyActorNightly 14 hours ago | root | parent | prev | next [\u2013]By the virtue of being the most convenient alternative, not because its actually good.replylazide 13 hours ago | root | parent | next [\u2013]How is that not actually good?Engineering is all about tradeoffs, and \u2018works\u2019 is pretty high praise frankly.replyActorNightly 3 hours ago | root | parent | next [\u2013]Compiling to native isn't exactly black magic and works just as well.JVM wastes cycles on things like classes, which is not necessary at all. Going forward, Rust has already proven that you can do things at compile time to guarantee things like memory safety.replypjmlp 2 hours ago | root | parent | next [\u2013]At the expense of productivity.ART also compiles to native since Android 5.Android 14 is around the corner, time to keep up with the times.replyinsanitybit 6 hours ago | root | parent | prev | next [\u2013]You can justify every project that has succeeded against any odds by saying \"but it did succeed\". It's true, but imo not a very good way of judging when a technology was a good fit or not.replylazide 5 hours ago | root | parent | next [\u2013]What other criteria do you suggest?Ideological purity is rather subjective, and has an unfortunately poor track record of real world success.replytgtweak 6 hours ago | root | parent | prev | next [\u2013]It's actually very well suited to low level extremely low power embedded systems. The toolkit and dev experience targeting these platforms is actually pretty good DX.32 bit 4mhz processor with ~64kb of nvram all running off of an induction charge!replyActorNightly 3 hours ago | root | parent | next [\u2013]I doubt its any better than native code. After all, modern jvm use is pretty much all jit anyways.replypjmlp 2 hours ago | root | parent | next [\u2013]There are plenty of native code options for Java as well.replypalata 13 hours ago | root | parent | prev | next [\u2013]Still better than ElectronJS, I would sayreplyIsolus 13 hours ago | root | parent | prev | next [\u2013]Also many SIM cards (UICCs) / embedded SIM modules as well as e.g. the Secure Element that Samsung uses for Knox run with Java Card.replytadfisher 5 hours ago | root | parent | next [\u2013]And Android recently added a Java API to talk to secure elements on your phone! We've come full circle.replypjmlp 2 hours ago | root | parent | next [\u2013]eSIMs still support Java Card modules.https://source.android.com/docs/core/connect/esim-overview?h...replylldb 14 hours ago | root | parent | prev | next [\u2013]Every blu ray player runs java for bonus features on the disk- they can even connect to the internet!replypseudosavant 12 hours ago | root | parent | next [\u2013]The very first feature I disable on every Blu-ray player I've ever used.replylocusofself 14 hours ago | root | parent | prev | next [\u2013]After reading your comment I was surprised to find out that credit card chips have any processing capabilities whatsoever, which they apparently do, though at least according to gpt4, they are far too basic to run java/jvm. ?replycayley_graph 14 hours ago | root | parent | next [\u2013]Google appears to be significantly more useful than GPT-4 here. [1] is the third result for me for the query \"credit card jvm\". [2] is the second result and gives a direct (and more importantly, actually correct) answer. That post links to the Oracle documentation for Java Cards [3] which is the fourth result.[1] https://en.m.wikipedia.org/wiki/Java_Card[2] https://superuser.com/questions/362567/are-there-any-credit-...[3] https://www.oracle.com/java/java-card/All of this is just as easy as, if not easier than, using ChatGPT. It's unclear that such a tool even serves this purpose (retrieval of basic facts) adequately, so it should probably be avoided in the future.replylocusofself 13 hours ago | root | parent | next [\u2013]Fair enough, there is a \"Java Card\". I'm not convinved that Java is running on any of my or your credit cards in your wallet today, though I'm not willing to bet on it.replyarllk 11 hours ago | root | parent | next [\u2013]It's running on many e-Passports and e-ID cards, i can't find the documentation from my e-ID card which runs on Java, but the chips are quite common like inhttps://www.cardlogix.com/product/cardlogix-credentsys-lite-...And on another source:Visa became the first large payment company to license JavaCard. Visa mandated JavaCard for all of Visa\u2019s smartcard payment cards. Later, MasterCard acquired Mondex, and Peter Hill joined as their CTO, licensed JavaCard, and ported the Mondex payment platform to JavaCard.Source: https://javacardforum.com/2022/07/28/the-birth-of-javacard/replykaba0 1 hour ago | root | parent | prev | next [\u2013]As far as I know even paying through Apple Pay with your credit card will run that Java Card program.Though mind you, it is a very limited subset of Java, not the standard one.replysaagarjha 1 hour ago | root | parent | next [\u2013]Yep, the Secure Element runs little Java appletsreplycayley_graph 13 hours ago | root | parent | prev | next [\u2013]This lists a few things using Java Cards (likely stuff that's in your wallet, surprisingly): https://stackoverflow.com/questions/47731005/practical-use-o...(fwiw I have a bit of prior experience here)replylocusofself 13 hours ago | root | parent | next [\u2013]That's pretty neat. It sounds like Java Card (or at least some other cards) actually \"boot up\" by way of inductive coupling, ie, via the \"contactless\" card readers where you just hold your card in proximity to the reader thing. Did not know that, I assumed it was just reading a key via NFC or something.replySharlin 11 hours ago | root | parent | next [\u2013]The whole reason there\u2019s a thing called a chip in the card is that it actually does computing (indeed they\u2019re called smart cards) and that it does the sort of computing (cryptographic challenge-response) that makes these cards much more secure than oldschool magnetic stripe cards.Even fully passive NFC tags contain logic that needs power to talk NFC back to the reader, there\u2019s no such thing as just reading data via NFC.replypests 11 hours ago | root | parent | prev | next [\u2013]This is a classic defcon talk about it. They developed their own cell network with their own sim cards for an event and even built custom JavaCard applications their users could use. They have released all their information and tools used to build and compile Java Card software.https://www.youtube.com/watch?v=_-nxemBCcmUreplyNursie 9 hours ago | root | parent | prev | next [\u2013]A lot of people assume this, but with contactless EMV there is a whole transaction flow between the card and the reader going on.You know those 4 lights on a contactless card reader? They indicate different transaction stages between the card and the terminal. I don\u2019t find them that useful because it\u2019s so fast they all appear to light at the same time, but that\u2019s what they are!If they were just passive tags, they wouldn\u2019t be very secure, they have cryptographic processors onboard with private keys that can sign stuff for the terminal and your bank. The specs for the interaction are all public if you\u2019re interested (I wouldn\u2019t be!) and lookup contactless EMV.replyxorcist 11 hours ago | root | parent | prev | next [\u2013]Just wait until you find out about the SIM card in your phone!It's almost bizarre what that thing does.replytjlingham 14 hours ago | root | parent | prev | next [\u2013]It feels like that should be true, I get it. However Java Card is very real.https://en.m.wikipedia.org/wiki/Java_Cardreplyunintendedcons 14 hours ago | root | parent | prev | next [\u2013]In what world did you convince yourself asking a chatbot was a source of real knowledge?respect yourself enough to look at primary sourcesreplylocusofself 13 hours ago | root | parent | next [\u2013]How about respect other people instead of rushing to condescending judgement? the stakes are incredibly low here, I asked ChatGPT for fun, like tens of millions of others are doing every day.replyxorcist 11 hours ago | root | parent | next [\u2013]It's not asking ChatGPT that is anti social but posting it, diluting the entropy of the conversation. Thousands of brains read every posted word before they can discard redundant information. Together we can keep a high quality shared medium, which benefits everyone!replyrefulgentis 11 hours ago | root | parent | prev | next [\u2013]For some reason you announced that you were subjecting us to a low quality information retrieval method, and after 6 months of this, people are irritable. The social norms is to do that sort of thing in private, doing it in public and seemingly proudly came across as coarse and impoliteIt didn't help any that it was clear from the initial post you were questioning someone with domain knowledge, which was later gently indicated to youreplycallalex 3 hours ago | root | parent | prev | next [\u2013]Why are you choosing to intentionally cripple your knowledge discovery so extremely?replyrcxdude 10 hours ago | root | parent | prev | next [\u2013]oh, yeah, they do. They often have multiple 'applications' on them, for different purposes (for example, withdrawing from an ATM with a card is a different application to making a purchase, which is different from the ill-conceved idea of using your card and PIN as a two-factor authentication token)replyeclipxe 9 hours ago | root | parent | prev | next [\u2013]\u201cAccording to gpt4\u201d\u2026. Uhhh. LLMs are text generators. Not a good source for facts or information, if accuracy is desired.replygrishka 12 hours ago | root | parent | prev | next [\u2013]Android isn't conventional Java. For starters, its runtime uses its own bytecode (dex) that's based on registers instead of a stack. But then, also, many things that aren't related to GUI are C++ with a thin Java wrapper on top.When I think about a \"Java OS\", I imagine a JVM running in kernel mode, providing minimal OS functionality (scheduler, access to hardware I/O ports) and there not being any kind of userspace.replypjmlp 2 hours ago | root | parent | next [\u2013]Just like Swing and JavaFX use a thin layer over whatever are the 3D APIas of the host.While Android isn't proper Java, converting JVM bytecodes into a better format for embedded deployment is quite common on embedded world.PTC, Aicas, Gemalto, microEJ, WebSphere Real Time, Aonix,....Current Java OS as per your definition, would be PTC and Aicas real time JVMs for bare metal deployments in embedded scenarios.replysoperj 13 hours ago | root | parent | prev | next [\u2013]It's a modified version of the linux kernel no? That'd be mostly C.replykaptainscarlet 12 hours ago | root | parent | next [\u2013]He might be referring to system services that manage hardware devices .etc BatteryService .rtcreplybpye 11 hours ago | parent | prev | next [\u2013]This idea has definitely been tried a few times [0, 1].[0] - https://en.wikipedia.org/wiki/Singularity_(operating_system)[1] - https://en.wikipedia.org/wiki/Midori_(operating_system)replyspullara 15 hours ago | parent | prev | next [\u2013]There was one for a while though wasn't really targeted at users:https://en.wikipedia.org/wiki/JavaOSreplytgtweak 6 hours ago | root | parent | next [\u2013]Still exists and thriving today as javacard.replypjmlp 15 hours ago | parent | prev | next [\u2013]Besides the sibling comments,- SavageJE- microEJ- PTC and Aonix bare metal Java runtimes- SunSPOT mit SquawkVMreplyhaspok 23 hours ago | prev | next [\u2013]Nice project, congrats!One thing struck me as a bit odd:> In particular, it does not support: genericsWhat kind of support is there for generics in the JVM? Maybe I'm too naive to assume that due to type erasure on bytecode level everything is just an Object, ie. a reference type? Or do you mean the class definition parser - but then, you don't really have any checks in place to see if the class file is valid (other than the basic syntax)?replyandreabergia 20 hours ago | parent | next [\u2013]Thanks!About the generics - some people have pointed out the same on reddit, and yeah, you are correct. The only thing that should be done is to read the Signature attribute that encodes the generic information about classes, methods, and fields (https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.ht...)As a matter of fact, I just did a test and the following code works! :-)  public class Generic {    public static void main(String[] args) {      List<String> strings = new ArrayList<String>(10);      strings.add(\"hey\");      strings.add(\"hackernews\");      for (String s : strings) {        tempPrint(s);      }    }    private static native void tempPrint(String value);  }replynewmana 22 hours ago | parent | prev | next [\u2013]They might be talking about the checkcast operation: https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.ht...This is generated when you do something like: final Main value = list.get(0);http://henrikeichenhardt.blogspot.com/2013/05/how-are-java-g...replyxxs 22 hours ago | root | parent | next [\u2013]The cast is added by javac, so it just needs to verify the object on the stack to be compatible w/ the provided class. That part is very simple.replyxxs 22 hours ago | parent | prev | next [\u2013]pretty much this - generics have (rare) implications to the reflection (but it's unsupported as well) but overall they are replaced with the nearest class/interface when compiled.OTOH lack of string interning is super strange [it's trivial to implement], and w/o it JVM is not a thing. String being equal by reference is important, and part of JLS.Lack of thread makes the entire endeavor a toy project.replywhizzter 21 hours ago | root | parent | next [\u2013]Not entirely correct, last I checked string interning was ONLY guaranteed for those strings defined in source and read in during class loading, strings created via the String constructor (f.ex. via StringBuilder) CAN duplicate those strings that you hardcoded in your sources, to get the \"canonical\" string in those cases you have to invoke String.intern() if memory serves me correct.https://docs.oracle.com/en/java/javase/11/docs/api/java.base...()Also interning strings to optimize equality checks to be able to use pointer comparison is dangerous for external inputs since iirc at some point interned strings could permanently be stored (unless implemented by a WeakSet) and attackers could fill up your heap (or cause other GC issues since the entire interning functionality is a cache) by filling up your interning lists with crap.replyxxs 20 hours ago | root | parent | next [\u2013]>String being equal by reference is important, and part of JLS.I never said String must be equal by reference when their content is. However string literals must be equal by reference. I thought Mentioning the JLS would make it obvious, esp. having 'intern' in the contextreplyywei3410 12 hours ago | root | parent | prev | next [\u2013]There's also the new JVM option which eludes me at the moment which sweeps the strings which are promoted to the older generation and interns them.Not certain about whether `String.intern` is permanently stored; I rather suspect that it sweeps the existing strings since iirc the java string has a hash associated with it anyway.replysenorrib 22 hours ago | root | parent | prev | next [\u2013]\u201cI want to stress that this is a toy JVM, built for learning purposes and not a serious implementation.\u201dreplyxxs 22 hours ago | root | parent | next [\u2013]The rest of the stuff, incl. I/O is actually on the trivial side - threads do require planning. This is what I meant by being a 'toy' project, threads (and JMM) would be impossible to bolt in later on.replyncallaway 18 hours ago | root | parent | next [\u2013]The reason you're being downvoted is you keep dismissing this as a \"toy\" project, and pointing out that it would be hard to make a real project.But, as the previous commenter attempted to point out to you this project is a *self-described* toy project.On the very page that is linked, the author of the JVM specifically says:\"I want to stress that this is a toy JVM, built for learning purposes and not a serious implementation.\"Thus, absolutely no one disagrees that its a toy JVM. They just want you to stop being dismissive of someone's toy project by repeatedly pointing out its a toy project and not a \"not a thing\"reply__jem 18 hours ago | root | parent | next [\u2013]Right, just because something is a \"toy\" doesn't mean it's not still impressive. If someone implemented a \"toy\" database that could parse and execute SQL queries, distribute data across nodes, etc., you would probably not want to use that in production, but it's still a very impressive project for a single person to pull off, even if it's riddled with bugs. Getting a very complex system to \"just barely functional\" is still a huge achievement and very cool!replyxxs 18 hours ago | root | parent | next [\u2013]Being impressing or otherwise is very subjective.SQL (ACID) over multiple non-cache-coherent nodes is extremely difficult to pull with regards to consistency, though.reply__jem 16 hours ago | root | parent | next [\u2013]> SQL (ACID) over multiple non-cache-coherent nodes is extremely difficult to pull with regards to consistency, though.Thats... why it's a toy! I'm really not sure what you're missing here.replygazarullz 13 hours ago | root | parent | prev | next [\u2013]you must be fun to work withreplyxxs 18 hours ago | root | parent | prev | next [\u2013]I've pointed the only part that makes it a toy project is the lack of Threading support, the rest is not hard to add. So the items in list of things missing after 'toy' thing should have totally different weights (with Threads being the added to the last).replylolinder 18 hours ago | root | parent | next [\u2013]You're still missing the point\u2014it was always intended to be a toy project, and the author has explicitly declared that they are completely done with it and won't be doing any more work. What does it matter how they sort the list of missing items? It's not a todo list in need of prioritization, it's just an \"FYI, these are some of the things I never got to\".reply3cats-in-a-coat 22 hours ago | root | parent | prev | next [\u2013]Java strings are compared by reference, if they do not match, they're compared by value. There's no guarantee every single string has a single instance. That would hurt performance.replymaverwa 22 hours ago | root | parent | next [\u2013]I think op meant \"String literals\". For those the spec seems to require interning:> Moreover, a string literal always refers to the same instance of class String. This is because string literals - or, more generally, strings that are the values of constant expressions (\u00a715.28) - are \"interned\" so as to share unique instances, using the method String.intern.And later:> Literal strings within different classes in different packages likewise represent references to the same String object.Source: https://docs.oracle.com/javase/specs/jls/se8/html/jls-3.html...But that does - as far as I can see - say nothing for non-literal strings.[edit]: formattingreply3cats-in-a-coat 21 hours ago | root | parent | next [\u2013]Thanks, makes sense yes. Still if the JVM look up in all cases defers to value after ref mismatch, it should work identically, no? Even if interning is mandatory as per spec, I'm not sure how it'd change the outcome of evaluation.replysimiones 19 hours ago | root | parent | next [\u2013]The problem is that, per the spec, the following must hold: if(\"abc\" == \"abc\") { System.out.println(\"correct\"); } if(new String(\"abc\") != new String(\"abc\")) { System.out.println(\"correct\"); }So, not having proper string interning support means that you mis-execute certain programs.replykelnos 15 hours ago | root | parent | next [\u2013]Sure, but also consider that this JVM (intentionally) lacks support for other things that all but the most trivial programs would use. I don't think it's expected by the author that you can throw any random program at it. It's really there just to run your own programs that you've written specifically for it in order to play around with things. And since you know you're writing for this particular JVM, you should know not to do anything that depends on string interning, among other things.replythfuran 20 hours ago | root | parent | prev | next [\u2013]It affects the result of ==, which is only a reference comparison.replyrobertlagrant 21 hours ago | root | parent | prev | next [\u2013]Yes - that is a performance optimisation. I don't think comparing everything by value makes or breaks the implementation.replyxxs 18 hours ago | root | parent | next [\u2013]>I don't think comparing everything by value makes or breaks the implementation.Nothing much to think -- distinct objects must have distinct references [e.g. new String(\"a\")!=new String(\"a')], literals must have the same references for the same values [e.g. \"a\"==\"a\"].replymaverwa 21 hours ago | root | parent | prev | next [\u2013]yeah, I'd assume as much. If it indeed falls back to a by-value comparison it would be slower, but should work.replyxxs 18 hours ago | root | parent | next [\u2013]nope - it'd be plain wrong. Literals must be equal by reference, comparing them by value would just break JLS, as they would be equal to any other composed string by reference as well.replyxxs 20 hours ago | root | parent | prev | next [\u2013]pretty much indeed.> say nothing for non-literal stringsyes, of course.replyznpy 20 hours ago | root | parent | prev | next [\u2013]> Lack of thread makes the entire endeavor a toy project.yeah, as stated by the author in the line that says \"I want to stress that this is a toy JVM, built for learning purposes and not a serious implementation.\"replyxxs 18 hours ago | root | parent | next [\u2013]Yeah, that's the only part that makes it a toy project - the rest can be added w/o too much of an effort. This is pretty much what makes it a toy project.replytechn00 22 hours ago | prev | next [\u2013]See also https://jacobin.org/ for JVM 17 written in Go.replyxmcqdpt2 22 hours ago | parent | next [\u2013]Also https://github.com/lihaoyi/Metascala for a JVM implemented in Scala running on the JVM.replydimgl 21 hours ago | root | parent | next [\u2013]Seems\u2026 redundant, no?replymike_hearn 19 hours ago | root | parent | next [\u2013]Nope. For a more realistic example of such a JVM, look at SubstrateVM (written in \"SystemJava\" and compiled to native code ahead of time along with the app it runs), and \"Java on Truffle\" (a.k.a. Espresso), which is a JVM written in Java designed to be compiled to run on top of SubstrateVM. Both projects are a part of Graal.The reason to do this, beyond the inherently neat Inception factor, is that JVMs are a PITA to work on because they're normally written in languages like C++ or Rust which optimize for performance and manual control over productivity. That makes it hard to experiment with new JVM features or changed semantics. If you could write a JVM in a high level very productive language like Java (or Kotlin or Scala) then the productivity of people writing and experimenting with JVMs would go up. It would also make it feasible for \"ordinary\" Java devs to actually fork the JVM and modify it to better suit their app, at least in some cases.There's also something conceptually cleaner about having a language and its runtime implemented purely in itself. As long as you don't mind the circularity, that is.Espresso for example has hot-swap features HotSpot doesn't have, so you can modify your program as it's running in more flexible ways than what regular Java allows.replybfrog 15 hours ago | root | parent | next [\u2013]I find that Rust is like maybe 1.5-2x more productive to code in than say C or C++. Part of that is the tooling has so much less arcane baggage, part of that is that I need to reach less for external tools for metaprogramming, part of that is fewer crazy macro/template compiler errors, and part of that is less time spent debugging.It all adds up.replymike_hearn 13 hours ago | root | parent | next [\u2013]I've heard very inconsistent things about this, which is interesting. Often people say Rust is less productive, as there's often \"makework\" involved with satisfying the borrow checker. I suspect a lot of it revolves around how you perceive that sort of thing: it can be cast as both productivity (satisfying it can potentially rule out bugs) or a loss of productivity (you were already satisfied the code was correct).But I don't have enough experience with Rust to really have formed an opinion on that yet.replyripley12 5 hours ago | root | parent | next [\u2013]I'm about 2 years into primarily writing Rust (after a long time in the .NET world).The borrow checker slowed me down a lot at the start but these days it's not a big deal. Eventually you internalize the easiest ways to make it happy (clone and pass references as needed) and can reserve tricky optimizations for hot paths where they actually matter.I would say that today, most of the times I sit down to write some Rust I'm nearly as productive as in higher-level languages... but then ~20% of the time I get bogged down in complicated type signature stuff (especially with async code, ugh) and it's a time suck.replydgunay 11 hours ago | root | parent | prev | next [\u2013]There is definitely a hump to get over (maybe you are never fully as \"productive\" as languages that just let you shoot yourself in the foot, I say as a full-time Go developer for a few years now). Simple, straightforward code is often harder to write. Don't even get me started on stuff that uses async.But IMO it's very worth it. What do you get out of wrestling with the unholy, fractured C/C++ ecosystem? The privilege of being able to _use other people's code_. You get that without much hassle in Rust.replypjmlp 15 hours ago | root | parent | prev | next [\u2013]And Jikes RVM as well.replynerpderp82 11 hours ago | root | parent | next [\u2013]Jikes is extremely popular in academia for being the basis of VM research because it is so easy to modify.https://github.com/JikesRVM/JikesRVMreplycmrdporcupine 21 hours ago | root | parent | prev | next [\u2013]\"The goal of Metascala is to create a platform to experiment with the JVM: a 3000 line JVM written in Scala is probably much more approachable than the 1,000,000 lines of C/C++ \"Seems like a reasonable goal.replyRcouF1uZ4gsC 19 hours ago | root | parent | next [\u2013]I seriously doubt the ratio of Scala vs C++ for implementing the JVM is 1:300.replypatrec 19 hours ago | root | parent | next [\u2013]He's not saying that. What he is saying is that are simple, non-production quality implementation in Scala is much more amenable to experimentation than a sophisticated, production-quality implementation in C++ that weighs in at 300x the LOC.replyRcouF1uZ4gsC 19 hours ago | root | parent | next [\u2013]But a simple non-production quality implementation in C++ would also be amenable to experimentation and not have the bootstrapping issues as well as provide an easier starting point to incorporate more of the existing optimizations as desired.replyvalenterry 17 hours ago | root | parent | next [\u2013]Probably not, because JVM users are much more likely to be more proficient in Scala/Java than in C++.replyeindiran 17 hours ago | root | parent | prev | next [\u2013]That is true, but the author of Metascala wanted to write it in Scala. Other people are free to write a simple C++ implementation of the JVM themselves.replycempaka 19 hours ago | root | parent | prev | next [\u2013]I'm sure it's not complete, but I also wouldn't be surprised if 99% of what's in HotSpot is optimization tweaks and performance boosts which aren't essential to the JLS.replyxmcqdpt2 9 hours ago | root | parent | next [\u2013]It's mostly GC and JIT and a huge amount of corner case interactions between them. And also the many supported instruction sets.replydgb23 21 hours ago | root | parent | prev | next [\u2013]apply evalreplyleshow 17 hours ago | parent | prev | next [\u2013]That is a very interesting name for a programming project lol. The Jacobins were a revolutionary political club during the French Revolution in the 1790's. It's also the name of a magazine at https://jacobin.comreplysnordgren 16 hours ago | root | parent | next [\u2013]It's starts with the letters \"ja\", that's all that matters for a Java-related project.replyceleritascelery 19 hours ago | prev | next [\u2013]I am curious if your ran into limitations due to the lifetimes on this signaturefn execute_instruction( &mut self, vm: &mut Vm<'a>, call_stack: &mut CallStack<'a>, instruction: Instruction, ) -> Result<InstructionCompleted<'a>, MethodCallFailed<'a>>When I try to add a lifetime to the `Err` variant of a `Result` and that lifetime is invariant (which it is due to `vm` and `call_stack`) it usually means that I can't use the question mark operator or have early returns in the code[1]. This makes error handling more verbose and less readable. Is that your experience as well?[1] https://users.rust-lang.org/t/nll-and-early-return-not-allow...replyceleritascelery 16 hours ago | parent | next [\u2013]EDIT: Looks like this is not an issue because the invariant lifetime 'a is not used for the mutable reference of vm or call_stack. So it's not the invariance that is the problem, but rather how Rust reasons about the lifetime of mutable references, which this avoids.In that case I don't understand what the point of 'a is on VM and CallStack. You can create[1][2] those with any unbounded lifetime (including 'static[3]), which means it is not constraining anything. What is the lifetime 'a doing here? Why not remove it?[1] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...[2] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...[3] https://github.com/andreabergia/rjvm/blob/be9c54066c64a82879...replyandreabergia 15 hours ago | root | parent | next [\u2013]I wanted to express the fact that everything that gets allocated (call stack, frames, classes, and objects) is alive and valid until the \"root\" VM is, thus I used 'a more or less everywhere.I also struggled with a got a ton of errors from the borrow checker initially, and I fixed many of those with a lot of explicit lifetimes, but it's not impossible that in some places they are unnecessary.replyceleritascelery 14 hours ago | root | parent | next [\u2013]> I wanted to express the fact that everything that gets allocated (call stack, frames, classes, and objects) is alive and valid until the \"root\" VM is, thus I used 'a more or less everywhere.That's not being expressed in the type system. The lifetime 'a is unbounded (meaning you can make it anything you want, including 'static) so anything that shares 'a can outlive the vm without rust complaining. it would be no different then if you removed 'a completely. If you wanted to ensure anything couldn't outlive the vm you could tie the lifetime to a reference to the vm, but then the vm can't hold those values (it would be a self-referential lifetime).replyskitter 12 hours ago | root | parent | next [\u2013]Funnily enough I did the same in an early wip version of my toy JVM. Ended up using unsafe to use 'static references internally but only hand out wrappers that include a reference to the JVM. This also ensures that objects/classes/\u2026 from one JVM can't be used in another one.replyaardvark179 14 hours ago | prev | next [\u2013]Very well done. Building VMs is always fun, and I\u2019m sure it was an interesting learning experience when combined with Rust\u2019s type system.If you\u2019re looking for a job then ping me on Twitter, Mastodon or my work email, I\u2019m sure you can figure them out from my user id here.replybingemaker 15 hours ago | prev | next [\u2013]When I see such cool projects, I feel very overwhelmed. How do you get started with Rust and master basics to even attempt doing such a thing? Can OP explain?replynop_slide 15 hours ago | parent | next [\u2013]Likewise. Not to go onto too much of tangent, but on a more personal note I've been generally struggling with this feeling a lot lately.I've been a professional software developer for almost 10 years, and I _know_ I'm competent (and not an impostor) as demonstrated by my current position and ability to ship things.However, lately after viewing developer blogs I become overwhelmed that I actually don't know enough and am not a \"real\" developer. I seem to have formed a notion of an ideal developer in my head and I compare myself against this imagined construct which leads to these feelings. I admire how these people have so much deep knowledge and can express themselves so clearly and concisely, then wonder why I am not like that.I barely have the energy after work after taking care of my family to do anything further, and I know programming isn't everything but I do have a desire to learn more and improve myself.I recognize this isn't healthy nor is it rational, but it's just a feeling I can't shake lately.replydist1ll 13 hours ago | root | parent | next [\u2013]What you're describing is very common amongst developers. So common in fact, that I've written a post about this https://alic.dev/blog/comparisonsIn short: recognizing your insecurities is the first step. The next step is figuring out what's important to you, shedding impossible to achieve and irrational ambitions, prioritizing your goals in life, and articulating concrete steps to further them.replynop_slide 12 hours ago | root | parent | next [\u2013]Thanks, appreciate the link and going to keep this in mind. Cheers.replytheLiminator 14 hours ago | root | parent | prev | next [\u2013]Well, you're probably comparing yourself against the top 1% of developers. It's okay to not be the very best, being in the top 30% of this field already is very rewarding.replyandreabergia 15 hours ago | parent | prev | next [\u2013]Well, _I_ feel impostor syndrome half the times I open HN honestly!I did have a bit of experience with VMs before, I wrote many years ago a short series of posts about it on my blog, and at my previous job I dabbled a bit in JVM byte code to solve one very unusual problem we had for a customer. I also read the _amazing_ https://craftinginterpreters.com/ years ago and that gave me some ideas.But this project was definitely big and complex. It took me a lot of time, and it got abandoned a couple of times, like many of my side projects. But I'm happy I finished it. :-)replynaltun 15 hours ago | parent | prev | next [\u2013]Not OP nor am I a Rust expert. I can speak regarding another technology: sockets.I've been deep-diving into sockets recently. 2 weeks ago I had only a high-level understanding of sockets (learned from casually reading manpages, docs, blog posts, etc.). I decided to read as much as possible because I wanted to understand networking fundamentals, and after a week I learned enough to write some sockets code in Python and C. I know Python quite well, so reviewing the ``sockets'' library made more sense after my deep dive.If you want to get better at technology A using language X, I suggest either reading/watching as much as you can about tech A, and build stuff with it in language Y. Then you can circle back to learning language X and you've already mastered much of the concepts around technology A.e: spellingreplyaardvark179 15 hours ago | parent | prev | next [\u2013]Break things down. A simple language VM is going to have a way to represent objects in memory, a byte code interpreter, a simple garbage collector, and a way to load things.A byte code interpret is a stack, some way to represent functions on that stack, and then a loop to interpret beach byte code and move the program counter.replysn9 11 hours ago | parent | prev | next [\u2013]How much do you code in your free time? Like average hours per week?If it's zero (and no judgement from me if it is; plenty of other things to focus on), then it shouldn't be surprising that someone for whom that number is (speculatively) 10-20 hours per week on average for years has impressive side projects.replytenaf0 21 hours ago | prev | next [\u2013]Shameless plug of my similar project: https://github.com/tenaf0/rust-jvm3replynine_k 16 hours ago | prev | next [\u2013]This project is like the ground floor of the JVM, not the whole tower. I like though how the project's page is direct and clear about that.A lot of the foundation and ground-floor mechanics are pretty interesting though.replyAgingcoder 18 hours ago | prev | next [\u2013]I'm doing a (free) operating system (just a hobby, won't be big and professional like gnu) for 386 (486) AT clones.:-)reply1letterunixname 14 hours ago | parent | next [\u2013]There's a no-std tutorial on how to write a demo kernel in Rust. https://os.phil-opp.comosdev.org, sandpile.org, RBIL, and freevga. The biggest PITA is hardware support. There are many good vintage hardcopy books with recipes for things like reliable port IO and undocumented hardware tricks.- Intel\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual Combined Volumes: 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D, and 4- Microsoft MS-DOS Programmer's Reference (also includes real-mode BIOS calls)- PC Interrupts- Undocumented PC- PC Intern- Programmer's Guide To The EGA, VGA, And Super VGA Cards- Graphics Programming Black Book Special EditionAlso, it's worth toying with advances in OS dev past the era of monolithic, microkernel, and hybrid.1. Capability-based like seL4. It has a number of inherent performance and security advantages including capabilities and excellent IPC.2. POSIX compatibility layer. Even embedded OSes without the concept of threads or processes can implement POSIX.3. Hypervisor. They're much easier to add with intel's VT-[xd]. Failing that, fall back to emulation. Translational emulation is very performant.4. Get good at generalizing interrupt handlers, making them fast, avoiding race conditions, and using lock-free patterns.Also:5. Rewriting or trapping unsupported instructions including x87 and MMX.6. The failure of pure microkernel was the added complexity and management of sequencing multiple resources in a transactional manner. There are great theoretical security and operational advantages in microkernel architectures but they never caught on widely in a pure form.replyvacuity 8 hours ago | root | parent | next [\u2013]> 2. POSIX compatibility layer. Even embedded OSes without the concept of threads or processes can implement POSIX.Do you have resources about this? I can't quite fathom how it would work, but then again I have no expertise.> 3. Hypervisor. They're much easier to add with intel's VT-[xd]. Failing that, fall back to emulation. Translational emulation is very performant.Speaking of which, QubesOS was on HN recently. The essence is having many VMs to minimize cross-app attack surface and privilege escalation.> 6. The failure of pure microkernel was the added complexity and management of sequencing multiple resources in a transactional manner. There are great theoretical security and operational advantages in microkernel architectures but they never caught on widely in a pure form.I recently saw an interesting brief article[0] about how memory-safe languages can supercede the compartmentalization that microkernels provide. I'm reminded of Theseus[1], written in rUsT, which happens to reflect the sentiment. I've actually been putting off rereading the Theseus USENIX paper. Again, I'm not nearly qualified to answer whether the security of this is comparable to the best of that of microkernels, barring formal verification. Still, I think it should be explored more. [0] https://catern.com/microkernels.html (Write modules, not microkernels) [1] https://www.usenix.org/conference/osdi20/presentation/boosreplyencody 20 hours ago | prev | next [\u2013]Missed opportunity to call it Justreplyorlp 19 hours ago | parent | next [\u2013]Just is already 'taken' in the Rust community as it is a command runner utility like make: https://github.com/casey/justreplyentropicdrifter 16 hours ago | root | parent | next [\u2013]Ooh, I like that. `just build` feels like a good plea to make to the Rust compiler lolreply1letterunixname 14 hours ago | root | parent | prev | next [\u2013]Haha. Shout out to homeboy Xoogler Rodarmor.replybrunoborges 14 hours ago | parent | prev | next [\u2013]JustVMreplymaverwa 22 hours ago | prev | next [\u2013]Great project, congrats! Mad respect.Started working on something very similar a few years back and gave up pretty soon for some stupid reason. Maybe I should try again, am getting better at getting stuff done.replyandreabergia 20 hours ago | parent | next [\u2013]Thanks!I know the feeling - this project, like most of my other side projects, got abandoned a couple of times. But I was really curious about implementing a GC and, for once, I managed to finish something. I'm glad I did! :-)replycmrdporcupine 21 hours ago | parent | prev | next [\u2013]You should. I've been doing this kind of stuff on the side for 25+ years, and nothing ever gets \"done.\" But the educational value is much higher than you think. And the skills learned can eventually propagate out into interesting paid work.I think of them as retirement projects before I retire. When I actually retire I'll maybe finish them.(That said, I have in the past tried taking jobs that were adjacent to my \"research\" interests, and found the joy of building these things from scratch is much better than fiddling with the levers on the side of someone else's thing they built from scratch years ago. I like working on and improving production systems, but if they intersect too closely to my personal interests, it can be demoralizing.)replyzote 22 hours ago | parent | prev | next [\u2013]Please doreplycmrdporcupine 22 hours ago | prev | next [\u2013]Great learning project, I'm glad the author is having fun. Implementing a VM from scratch is a blast, and I have learned so much in the past doing that kind of thing.If they're interested in bolting on a GC, it couldn't hurt to look at MMtk. (https://www.mmtk.io/) Some high quality collection algorithms, written to be pluggable to various VMs, and written in Rust.replyceleritascelery 19 hours ago | parent | next [\u2013]Note that MMTK is x86 only. I was going to use it for a toy project but I have a Mac.replycmrdporcupine 17 hours ago | root | parent | next [\u2013]That's a bummer -- I guess I never noticed that, when I played with it before it was on an M1 Mac, but compiled into an x86 Julia executable & running through Rosetta (which surprisingly did not suck).Haven't read, but I bet it's likely related to expectations around the x86_64 memory model & atomics. In the long run I see no reason why it couldn't be made portable, but I imagine the authors efforts are elsewhere for now.replysbt567 20 hours ago | parent | prev | next [\u2013]Uh, first time hearing mmtk. Thanks for the link!replycmrdporcupine 18 hours ago | root | parent | next [\u2013]I only became aware of it because a former employer (RelationalAI) was heavily interested in replacing Julia's GC with it (for some workloads): https://pretalx.com/juliacon2023/talk/BMBEGY/replyFrustratedMonky 21 hours ago | prev | next [\u2013]Just for kicks, has anybody tried to Rube-Goldberg it, and see how many VM's can stack on top of each other. Like have Java App running on JVM written in RUST, Running on WASM, Running on JVM, etc.. etc...replypost-it 20 hours ago | parent | next [\u2013]See also: The Birth & Death of JavaScript, A talk by Gary Bernhardt from PyCon 2014 (https://www.destroyallsoftware.com/talks/the-birth-and-death...)replyZambyte 20 hours ago | parent | prev | next [\u2013]This talk isn't about VMs, but it is about an infinite tower of interpreters. You may find it interesting: https://youtu.be/SrKj4hYic5Areply_joel 20 hours ago | parent | prev | next [\u2013]It's turtles, all the way down..replyPTOB 10 hours ago | root | parent | next [\u2013]And Logo drives the turtles.replynunobrito 19 hours ago | prev | next [\u2013]Good work!replysylware 20 hours ago | prev | next [\u2013]Can I compile it with the rust-written rust compiler?replybkkz5046 21 hours ago | prev | next [\u2013]but more importantly does edbrowse work here?replybabuloseo 18 hours ago | prev | next [\u2013]Oracle oracle oracle.replyhajmo97 21 hours ago | prev [\u2013]How often will this post be reposted on HN ?Recent posts:https://news.ycombinator.com/item?id=36735344 - 6 days agohttps://news.ycombinator.com/item?id=36717967 - 7 days agohttps://news.ycombinator.com/item?id=36710803 - 7 days ago (OP)Btw. nice project!replycapableweb 21 hours ago | parent | next [\u2013]Doesn't really count as a repost if none of the previous submissions didn't get any traction.replydgb23 21 hours ago | root | parent | next [\u2013]I agree, plenty of technically interesting projects don\u2019t get discussion on hn. There\u2019s always a bit of luck and context involved.replyfreedomben 18 hours ago | parent | prev [\u2013]Getting the attention needed for front page is a huge chance. I've seen great stuff get posted 5 or more times before it makes it out of obscurity. HN is highly non-deterministic in these things.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- A developer has written a JVM (Java Virtual Machine) in Rust.\n- The JVM uses its own virtual callstacks to simplify garbage collection tracing.\n- The project is a toy JVM built for learning purposes, not a serious implementation."
  },
  {
    "id": 36809565,
    "timestamp": 1689909016,
    "title": "Study finds billions of nanoplastics released when microwaving containers",
    "url": "https://news.unl.edu/newsrooms/today/article/nebraska-study-finds-billions-of-nanoplastics-released-when-microwaving/",
    "hn_url": "http://news.ycombinator.com/item?id=36809565",
    "content": "17 hours ago \u00b7 6 min readNebraska study finds billions of nanoplastics released when microwaving containersEXPOSURE TO PARTICLES FROM BABY FOOD CONTAINERS KILLS UP TO 75% OF CULTURED KIDNEY CELLSby Scott Schrage | University Communication and MarketingCraig Chandler | University Communication and MarketingKazi Albab Hussain (left) holds his son while removing a plastic container of water from a microwave. Hussain and colleagues at the University of Nebraska\u2013Lincoln have found that microwaving such containers can release up to billions of nanoscopic particles and millions of microscopic ones.The fastest way to heat food and drink might also rank as the fastest route to ingesting massive quantities of minuscule plastic particles, says new research from the University of Nebraska\u2013Lincoln.Experiments have shown that microwaving plastic baby food containers available on the shelves of U.S. stores can release huge numbers of plastic particles \u2014 in some cases, more than 2 billion nanoplastics and 4 million microplastics for every square centimeter of container.Though the health effects of consuming micro- and nanoplastics remain unclear, the Nebraska team further found that three-quarters of cultured embryonic kidney cells had died after two days of being introduced to those same particles. A 2022 report from the World Health Organization recommended limiting exposure to such particles.\u201cIt is really important to know how many micro- and nanoplastics we are taking in,\u201d said Kazi Albab Hussain, the study\u2019s lead author and a doctoral student in civil and environmental engineering at the University of Nebraska\u2013Lincoln. \u201cWhen we eat specific foods, we are generally informed or have an idea about their caloric content, sugar levels, other nutrients. I believe it\u2019s equally important that we are aware of the number of plastic particles present in our food.\u201cJust as we understand the impact of calories and nutrients on our health, knowing the extent of plastic particle ingestion is crucial in understanding the potential harm they may cause. Many studies, including ours, are demonstrating that the toxicity of micro- and nanoplastics is highly linked to the level of exposure.\u201dHussainThe team embarked on its study in 2021, the same year that Hussain became a father. While prior research had investigated the release of plastic particles from baby bottles, the team realized that no studies had examined the sorts of plastic containers and pouches that Hussain found himself shopping for, and that millions of other parents regularly do, too.Hussain and his colleagues decided to conduct experiments with two baby food containers made from polypropylene and a reusable pouch made of polyethylene, both plastics approved by the U.S. Food and Drug Administration. In one experiment, the researchers filled the containers with either deionized water or 3% acetic acid \u2014 the latter intended to simulate dairy products, fruits, vegetables and other relatively acidic consumables \u2014 then heated them at full power for three minutes in a 1,000-watt microwave. Afterward, they analyzed the liquids for evidence of micro- and nanoplastics: the micro being particles at least 1/1,000th of a millimeter in diameter, the nano any particles smaller.The actual number of each particle released by the microwaving depended on multiple factors, including the plastic container and the liquid within it. But based on a model that factored in particle release, body weight, and per-capita ingestion of various food and drink, the team estimated that infants drinking products with microwaved water and toddlers consuming microwaved dairy products are taking in the greatest relative concentrations of plastic. Experiments designed to simulate the refrigeration and room-temperature storage of food or drink over a six-month span also suggested that both could lead to the release of micro- and nanoplastics.\u201cFor my baby, I was unable to completely avoid the use of plastic,\u201d Hussain said. \u201cBut I was able to avoid those (scenarios) which were causing more of the release of micro- and nanoplastics. People also deserve to know those, and they should choose wisely.\u201dWith the help of Svetlana Romanova from the University of Nebraska Medical Center, the team then cultured and exposed embryonic kidney cells to the actual plastic particles released from the containers \u2014 a first, as far as Hussain can tell. Rather than introduce just the number of particles released by one container, the researchers instead exposed the cells to particle concentrations that infants and toddlers might accumulate over days or from multiple sources.Environmental Science & Technology / American Chemical SocietyA side-by-side comparison of embryonic kidney cells left untreated (left) versus those treated with micro- and nanoplastics (right) for 72 hours. (Click to zoom)After two days, just 23% of kidney cells exposed to the highest concentrations had managed to survive \u2014 a much higher mortality rate than that observed in earlier studies of micro- and nanoplastic toxicity. The team suspects that kidney cells might be more susceptible to the particles than are other cell types examined in prior research. But those earlier studies also tended to examine the effects of larger polypropylene particles, some of them potentially too large to penetrate cells. If so, the Hussain-led study could prove especially sobering: Regardless of its experimental conditions, the Husker team found that polypropylene containers and polyethylene pouches generally release about 1,000 times more nanoplastics than microplastics.The question of cell infiltration is just one among many that will require answers, Hussain said, before determining the true risks of consuming micro- and nanoplastics. But to the extent that they do pose a health threat \u2014 and that plastics remain a go-to for baby food storage \u2014 parents would have a vested interest in seeing that the companies manufacturing plastic containers seek out viable alternatives, he said.\u201cWe need to find the polymers which release fewer (particles),\u201d Hussain said. \u201cProbably, researchers will be able to develop plastics that do not release any micro- or nanoplastics \u2014 or, if they do, the release would be negligible.\u201cI am hopeful that a day will come when these products display labels that read \u2018microplastics-free\u2019 or \u2018nanoplastics-free.\u2019\u201dLiThe team reported its findings in the journal Environmental Science & Technology. Hussain and Romanova authored the study with the University of Nebraska\u2013Lincoln\u2019s Yusong Li, Mathias Schubert, Yongfeng Lu, Luc\u00eda Fern\u00e1ndez-Ballester, Bing Wang, Xi Huang, Jesse Kuebler, Dong Zhang and Ilhami Okur. The researchers received support from the National Science Foundation and the Buffett Early Childhood Institute.SHARENEWS RELEASE CONTACTSKazi Albab Hussain, Doctoral Student, Civil and Environmental EngineeringRELATED LINKSSee the studyNebraska EngineeringFood science and technology at NebraskaTAGSKazi Albab Hussain Yusong Li Mathias Schubert Yongfeng Lu Lucia Fernandez-Ballester Bing Wang Xi Huang Jesse Kuebler Dong Zhang Ilhami Okur civil and environmental engineering Electrical and Computer Engineering mechanical and materials engineering Engineering Food Science and Technology IANR students faculty researchHIGH RESOLUTION PHOTOS",
    "summary": "- Microwaving plastic baby food containers can release billions of nanoscopic particles and millions of microscopic ones, according to a study from the University of Nebraska\u2013Lincoln.\n- The health effects of consuming these micro- and nanoplastics are uncertain, but the study found that three-quarters of cultured embryonic kidney cells died after being introduced to the particles.\n- It is important to be aware of the number of plastic particles present in our food and to limit exposure to them. Researchers hope to develop plastics that release fewer or negligible amounts of micro- and nanoplastics.",
    "hn_title": "Study finds billions of nanoplastics released when microwaving containers",
    "original_title": "Study finds billions of nanoplastics released when microwaving containers",
    "score": 457,
    "hn_content": "- A study found that microwaving plastic containers releases billions of nanoplastics.\n- The researchers exposed cells to particle concentrations that infants and toddlers might accumulate over days or from multiple sources.\n- High concentrations of nanoplastics caused death in kidney cells during in vitro study, but the real-world impact remains unclear.\n- The study highlights the potential risks of exposure to micro- and nanoplastics but doesn't provide evidence of harm from normal exposure levels.\n- The effects of consuming micro- and nanoplastics are still not well understood, and more research is needed.\n- Using alternative materials like glass and stainless steel for food storage and cooking could help reduce exposure to plastics.- Microwaving plastic baby food containers can release billions of nanoplastics and millions of microplastics.\n- Some studies have shown that exposure to microplastics and nanoplastics can lead to cell death.\n- The long-term health effects of consuming plastic particles are still unknown.\n- It's important to consider the trade-offs of using plastic in the microwave, such as cost and convenience.\n- Regulators should conduct more testing and provide better communication about the safety of plastics.\n- Reusable containers made of alternative materials like glass, silicone, or steel could be a good solution.\n- The impact of plastic pollution on the environment and human health is a pressing concern.\n- The use of plastic in the food industry should be phased out and replaced with sustainable alternatives.",
    "hn_summary": "- Microwaving plastic containers releases billions of nanoplastics and millions of microplastics.\n- Exposure to micro- and nanoplastics can lead to cell death, but the long-term health effects are still unknown.\n- Using alternative materials like glass and stainless steel for food storage and cooking could help reduce exposure to plastics."
  },
  {
    "id": 36817305,
    "timestamp": 1689962983,
    "title": "Web Environment Integrity API Proposal",
    "url": "https://github.com/RupertBenWiser/Web-Environment-Integrity",
    "hn_url": "http://news.ycombinator.com/item?id=36817305",
    "content": "Web Environment Integrity APIThis repository details the proposal to add a new API for determining the integrity of web environments:const attestation = await navigator.getEnvironmentIntegrity(\"...\");The explainer goes gives a high level overview of the proposal.The spec currently describes how this is being prototyped in Chromium.",
    "summary": "- The post discusses a proposal for a new API called Web Environment Integrity API.\n- The API allows developers to determine the integrity of web environments.\n- The proposal is currently being prototyped in Chromium.",
    "hn_title": "Web Environment Integrity API Proposal",
    "original_title": "Web Environment Integrity API Proposal",
    "score": 423,
    "hn_content": "- The proposed Web Environment Integrity API is seen as the inevitable result of ad-based business models dominating the web and the push for more functionality in web browsers.\n- The API aims to prove the authenticity of users and prevent fraud, but critics argue that it could lead to a monopoly of Google Chrome and the restriction of competition in the web browser market.\n- The concerns raised highlight the potential threats to an open, fair, and free web, and the centralization of power in the hands of a few dominant companies.\n- The spec has been met with backlash from developers and privacy advocates who fear the erosion of user privacy and control over their own devices.\n- Some commenters suggest switching to alternative browsers like Firefox or contributing to open-source browser projects to resist the dominance of Chrome. However, others believe that these efforts may not be enough to counteract the influence of major tech companies.\n- The proposal has sparked discussions about the future of the web, the role of advertising, and the need for user-centric design and development.- Websites rely on human users to view ads and prove they're human through tasks or logins.\n- Users want to interact with real people on social websites, but bad actors want to promote posts with fake engagement.\n- Websites need to distinguish between trusted and untrusted environments to show real people popular content.\n- Google's proposal for a Web Environment Integrity API is controversial, with concerns about privacy, control, and DRM.\n- Some view this as a step towards the end of the open web and a potential monopoly by Google Chrome.\n- Open-source browser alternatives like BrowserBoxPro aim to protect the integrity of browsing and offer solutions.\n- Public awareness and opposition to this proposal may lead to a larger backlash and potential changes.\n- The proposal has sparked debates about trust, security, monopolization, and the future of the web.\n- Google's motives and the potential consequences of this proposal are being questioned and criticized.\n- The tech community is divided, with some advocating for user privacy and control, while others see benefits in better security and innovation.",
    "hn_summary": "- The proposed Web Environment Integrity API is a response to the dominance of ad-based business models and the demand for more functionality in web browsers.\n- Critics raise concerns about potential monopolization by Google Chrome and the restriction of competition in the web browser market.\n- The proposal sparks debates about privacy, control, and the future of the web, with discussions on user-centric design, open-source alternatives, and the impact of major tech companies."
  },
  {
    "id": 36818896,
    "timestamp": 1689969680,
    "title": "Journalists should be skeptical of all sources including scientists",
    "url": "https://natesilver.substack.com/p/journalists-should-be-skeptical-of",
    "hn_url": "http://news.ycombinator.com/item?id=36818896",
    "content": "Discover more from Silver BulletinEverything everywhere all at onceOver 10,000 subscribersSubscribeContinue readingSign inJournalists should be skeptical of all sources \u2014including scientistsA group of prominent scientists spread misinformation about COVID's origins. Mainstream journalists missed the story.NATE SILVERJUL 21, 202310371ShareI\u2019m not usually one for scandals. My eyes glaze over at Congressional hearings. I\u2019ve never read the Mueller Report. There are usually too many threads to unwind, and too many competing claims to evaluate. But I\u2019m going to make an exception here, because we have a scandal where the facts are relatively simple and clear \u2014 but which was nevertheless extremely consequential.SubscribeHere\u2019s the scandal. In March 2020, a group of scientists \u2014 in particular1, Kristian G. Andersen the of The Scripps Research Institute, Andrew Rambaut of The University of Edinburgh, Edward C. Holmes of the University of Sydney, and Robert F. Garry of Tulane University \u2014 published a paper in Nature Medicine that seemingly contradicted their true beliefs about COVID\u2019s origins and which they knew to be misleading. The paper, \u201cThe proximal origin of SARS-CoV-2\u201d, has been cited more than 5,900 times and was enormously influential in shaping the debate about the origins of COVID-19.We know this because of a series of leaked and FOIAed emails and Slack messages that have been reported on by Public, Racket News, The Intercept and The Nation along with other small, independent media outlets. You can find a detailed summary of the claims and a copy of the emails and messages here at Public. There\u2019s also good context around the messages here (very detailed) or here and here (more high-level).The messages show that the authors were highly uncertain about COVID\u2019s origins \u2014 and if anything, they leaned more toward a lab leak than a spillover from an animal source. But none of that was expressed in the \u201cProximal Origin\u201d paper, which instead said that \u201cwe do not believe that any type of laboratory-based scenario is plausible\u201d. Granted, there is a little bit of ass-covering \u2014 \u201cMore scientific data could swing the balance of evidence to favor one hypothesis over another,\u201d they also wrote in the paper. But the message \u2014 natural origin good, lab leak bad \u2014 was received clearly enough by mainstream news outlets. \u201cNo, the new coronavirus wasn't created in a lab, scientists say\u201d, reported the CBC in covering the paper. \u201cCOVID-19 coronavirus epidemic has a natural origin\u201d was the headline at Science Daily.In the Slack and email messages, the authors worked to manipulate the media narrative about COVID-19\u2019s origins and to ensure that their private uncertainty wasn\u2019t conveyed in conversations with reporters. They also thought they were going to get away with it. \u201cThe truth is never going to come out \u201d, wrote Rambaut in one message. This went beyond mere motivated reasoning. There was an enormous gap between what the authors believed privately and what they stated publicly, including in the \u201cProximal Origin\u201d paper \u2014 again, see the above links for more detail.What were the authors\u2019 motivations to mislead the public? I think that\u2019s also pretty straightforward. In fact, you can find prominent virologists quoted on record as to why the lab leak theory was so problematic \u2014 even if it wasn\u2019t necessarily wrong. The problems fall into three buckets:Evidence of a lab leak could cause a political backlash \u2014 understandably, given that COVID has killed almost 7 million people \u2014 resulting in a reduction in funding for gain-of-function research and other virological research. That\u2019s potentially important to the authors or the authors\u2019 bosses \u2014 and the authors were very aware of the career implications for how the story would play out;Evidence of a lab leak could upset China and undermine research collaborations;Evidence of a lab leak could provide validation to Trump and Republicans who touted the theory \u2014 remember, all of this was taking place during an election year, and medical, epidemiological and public health experts had few reservations about weighing in on political matters.To be clear, I\u2019m not sure how COVID originated either. I\u2019d \u201cbuy\u201d the lab leak at a 50 percent likelihood (I think this is pretty convincing) and sell it at 80 percent, which still leaves a lot of wiggle room for me to be persuaded one way or the other.But I think this is a big scandal either way. As someone who has spent a lot of time trying to convey statistical and epistemic uncertainty to the public, I\u2019m deeply disappointed by the scientists\u2019 conduct here and how unmoored they were from any attempt at truth-seeking.The COVID origins story has also been a journalistic fiasco, with the lab leak having been dismissed as a \u201cconspiracy theory\u201d and as misinformation even though many prominent scientists believed it to be plausible all along. Perhaps it\u2019s tempting to give the media a pass \u2014 they were manipulated by the \u201cProximal Origin\u201d authors, after all. But I\u2019m not inclined to, for two reasons.First, the coverage of the recently leaked emails and Slack messages at major center-left outlets like The New York Times has been pathetic. The Times portrayed Andersen as the victim of a Republican witch-hunt \u2014 rather than someone at the center of a major scientific scandal of his own making.And second, journalists ought to have decent bullshit detectors \u2014 including toward scientists, academics and other experts.2Maybe you think Andersen et. al. are bad apples, but the messages make clear that they were speaking for a pretty broad swath of the scientific community. Still \u2014 and maybe this is wishful thinking \u2014 but I\u2019m going to assert that people like him are in the minority among scientists. I fairly often speak with scientists and academics myself \u2014 especially when I\u2019m working on a research-driven book project, as I am now \u2014 and those experiences are overwhelmingly positive.3And yet, even if the incidence of bad apples is relatively rare among scientists and academics \u2014 rarer than it might be among politicians or other groups that journalists intrinsically treat with more skepticism \u2014 it\u2019s clearly not exceedingly rare. It was just this week that the president of Stanford was forced to resign in a research scandal. (Perhaps not coincidently, the scandal was broken by the student newspaper, The Stanford Daily, and not by a major center-left outlet like The Times.)I also think journalists are more prone toward being manipulated by bad apples in academia and science than they were ten or twenty years ago. As a result of increasing educational polarization, both journalists and the expert class of scientists and academics are far more aligned politically than they once were (the very large majority are left-of-center and vote Democratic in American elections). Even if \u201ctrust the science\u201d or \u201ctrust the experts\u201d is usually right \u2014 and I think it usually is right! \u2014 it leaves an opening for bad apples like Andersen to exploit the trust that honest scientists have worked so hard to earn.There\u2019s also a generational divide in journalism, with younger journalists tending to be more openly left/progressive than their older peers \u2014 and tending to be more Manichean in dividing the world between good and evil rather than proceeding from the notion that people and news stories are complicated and it\u2019s not particularly their job to pass moral judgment. It\u2019s slightly amusing that The Times fired their Pulitzer Prize-winning coronavirus reporter in middle of the pandemic \u2014 a reporter who saw the lab leak theory as credible \u2014 and replaced him with another reporter who dismissed discussion of the lab leak as \u201cracist\u201d.But this really isn\u2019t complicated. All I\u2019m suggesting is that journalists ought to treat scientists like they do any other source \u2014 that is to say, with an appropriate dose of skepticism.Thanks for reading Silver Bulletin! Subscribe for free to receive new posts and support my work.Subscribe1I mention these four by name because they were both co-authors of the \u201cProximal Origin\u201d paper and participated in a conference call with Frances Collins, Tony Fauci and others that the documents suggest was a turning point in how scientists\u2019 beliefs about COVID origins were portrayed to the public.2I certainly don't get everything right, but it\u2019s been obvious to me for a long time that Andersen is an huge bullshitter.3Perhaps we can have some sympathy for the authors for operating under the strain and stress of early stages of the pandemic; I don\u2019t think any of us were at our best.Subscribe to Silver BulletinBy Nate Silver \u00b7 Launched 8 months agoEverything everywhere all at onceSubscribe103 Likes\u00b78 Restacks10371Share",
    "summary": "- A group of prominent scientists published a paper on the origin of COVID-19 that contradicted their true beliefs, sparking a scandal.\n- Leaked emails and Slack messages reveal that the authors manipulated the media narrative to downplay the lab leak theory and promote the natural origin theory.\n- This scandal highlights the need for journalists to be skeptical of all sources, including scientists, and not to blindly trust expert opinions.",
    "hn_title": "Journalists should be skeptical of all sources including scientists",
    "original_title": "Journalists should be skeptical of all sources including scientists",
    "score": 413,
    "hn_content": "- Journalists should be skeptical of all sources, including scientists, to ensure accurate reporting\n- There are concerns about the quality of journalism and the impact on democracy when journalists lack expertise in the topics they cover\n- Suggestions for improving journalism include professional registration, stricter requirements for professional conduct, and better wages to attract talent\n- The conversation includes a discussion about the need for journalism to be a protected profession, similar to professions like medicine or law\n- The article highlights the importance of responsible journalism and the potential consequences of poorly researched reporting\n- The debate about the origin of COVID-19 is discussed, with conflicting views from scientists on the possibility of a lab leak\n- It is important for journalists to understand the context and nuances of scientific research when reporting on such topics\n- Science literacy and statistical literacy are important for journalists to critically evaluate research and present accurate information to the public\n- The article emphasizes the need for journalists to provide unbiased, objective reporting and avoid sensationalism or cherry-picking of information.- Journalists need to be skeptical and not take everything at face value, even when it comes from academics or experts.\n- It's important for journalists to read and understand scientific papers themselves, rather than relying on secondhand information or regurgitating other sources.\n- Skepticism doesn't mean dismissing everything, but rather asking questions, seeking multiple perspectives, and evaluating sources based on their credentials and the evidence they provide.\n- The scientific consensus should not be blindly accepted as gospel, but rather evaluated based on the expertise and evidence of those supporting it.\n- Contrarians can play a valuable role in scientific discourse, and their views should not be automatically dismissed just because they are contrarian.\n- Journalists should strive to be objective and verify information, especially when it comes to scientific topics.\n- It's important for journalists to have a basic understanding of the field they are reporting on, even if they don't have formal training in that area.\n- Not everything labeled as \"scientific consensus\" is broad enough or applicable to every specific situation, so it's important to be critical and consider the context.\n- The scientific method requires scrutiny and discussion, and different viewpoints should be explored to foster a better understanding of complex issues.\n- Journalists should be cautious about amplifying fringe voices without properly evaluating their claims, but this doesn't mean all contrarian views should be dismissed.\n- The public should have an open mind but also not blindly accept things as facts, and the field of science should strive for objectivity and trustworthy research methods.\n- The efficiency of reporting shouldn't overshadow the need for accuracy and thorough investigation, especially in urgent situations where policy decisions are being made.\n- Many journalists lack scientific education, which can hinder their ability to critically evaluate research and make informed reports.\n- Journalists should consult multiple sources and consider the credentials of experts when reporting on scientific topics.\n- Having specific training in a field is important for evaluating technical aspects of a subject, but non-experts can still ask questions and seek out multiple perspectives.\n- Skepticism and critical thinking are important in evaluating claims and preventing the spread of misinformation.\n- Journalists should strive to be accurate and objective, focusing on the evidence and facts rather than personal opinions.\n- The quality of journalism can vary, and audiences should be aware of biases and incentives that may influence reporting.\n- Public trust in journalists and media organizations has declined, and there is a need for improved standards and transparency in the industry.\n- Scientists should strive for transparency and rigorous research methods, and journalists should hold them accountable by asking questions and seeking clarification.\n- There is a need for more specialized science journalists who can accurately report on complex scientific topics and communicate them to a broader audience.\n- The funding and incentive structures in journalism can affect the quality and objectivity of reporting, and alternative funding models may be necessary to support quality journalism.\n- Journalists play an important role in society, but it's important for readers to be critical and verify information from multiple sources.\n- The lab leak theory and its investigation are complex and require more evidence before drawing definitive conclusions.\n- Journalists should be cautious when reporting on scientific topics and avoid sensationalism or promoting one theory over another without strong evidence.\n- Scientific papers should be evaluated based on their methodology, evidence, and contributions to the field, and not solely on the journal or the authors' credentials.\n- Public trust in journalism and science can be improved through transparency, integrity, and open discussions about the limitations and uncertainties of research.\n- Critical thinking, skepticism, and seeking multiple perspectives are key to understanding complex scientific topics and making informed decisions.- Journalists used to speak truth to power, but it's unclear how common this actually was.\n- Journalism is necessary for a functioning society, especially in the age of AI-generated fake evidence.\n- Being skeptical of all sources can be dangerous because it treats all sources as equal.\n- Scientists and journalists sometimes make mistakes, leading to misinformation.\n- The debate about the origin of the virus may be influenced by the controversy surrounding GoF research and not just the virus itself.\n- Trusting the scientific method is important, rather than blindly trusting experts or consensus.\n- Journalists may have biases due to career progression.\n- Being skeptical of Nate Silver is suggested.\n- The truth about the origin of the virus may never be fully known due to China's potential lack of transparency.",
    "hn_summary": "- Journalists should be skeptical of all sources, including scientists, to ensure accurate reporting.\n- The need for responsible journalism and the potential consequences of poorly researched reporting are highlighted.\n- Science literacy and statistical literacy are important for journalists to critically evaluate research and present accurate information to the public."
  },
  {
    "id": 36815255,
    "timestamp": 1689954544,
    "title": "In the LLM space, \"open source\" is being used to mean \"downloadable weights\"",
    "url": "https://www.alessiofanelli.com/blog/llama2-isnt-open-source",
    "hn_url": "http://news.ycombinator.com/item?id=36815255",
    "content": "Alessio FanelliAbout MeFollow MeLLaMA2 isn't \"Open Source\" - and why it doesn't matterPosted on 7/20/2023Almost a decade ago I started an open source company, and I\u2019ve since been involved in the OSS community as a founder, contributor, speaker, and investor. The internet wouldn\u2019t be what it is today if it wasn\u2019t for the amazing open source projects that power most of the digital infrastructure of our world, so it\u2019s a topic that has always been close to my heart.When LLaMA2 came out, many of the folks I respect in the community were upset about misusing the term \u201copen source\u201d when referring to the model.While it\u2019s mostly open, there are caveats such as you can\u2019t use the model commercially if you had more than 700M MAUs as of the release date, and you also cannot use the model output to train another large language model. These types of restrictions don\u2019t play well with the open source ethos. But while I agree that LLaMA2 cannot be called open source in the traditional meaning of the word, I also think that it doesn\u2019t matter. The term \u201copen source\u201d needs to evolve (once again) in the world of AI models.From Free to OpenI wrote a long history of the free software and open source movement here, so I won\u2019t bore you with the details again. What you need to know is that since the 1976 \u201cOpen Letter to Hobbyists\u201d, there\u2019s always been tension between the commercial interests of software companies and the curiosity of hackers who wanted to circumvent its restriction. The \u201cfree software\u201d movement started in the 70s in the MIT AI lab with Richard Stallman and eventually the GNU project in 1983. The GPL \u201ccopyleft\u201d license was created, and projects like Red Hat, MySQL, Git, and Ubuntu adopted it.The term \u201copen source\u201d came to be in 1998 thanks to MIT\u2019s Christine Peterson; at the \u201cFreeware Summit\u201d, the term \u201cfree software\u201d was officially deprecated in favor of \u201copen source software\u201d. As time went by, the \u201cfree\u201d and \u201copen source\u201d software communities diverged as they had different ideas of what free and open meant. Free software, as specified by the Free Software Foundation, is only a subset of open source software and uses very permissive licenses such as GPL and Apache.In the last decade, there was another bifurcation, this time created by the tension between commercial open source companies and the cloud hyperscalers. Elastic and MongoDB transitioned their open source projects to the \u201cServer-Side Public License\u201d (SSPL) which allows developers to use the product commercially, as long as what they are offering isn\u2019t a hosted version of the product. The goal was to block AWS from re-hosting their products as cloud services and profiting from them. The SSPL also infringes on the OSS ideals and is not recognized by the OSI as an open source license. Yet, the majority of developers still say that MongoDB is open source. More and more the term \"open source\" is losing its freedom connotations and turning almost synonymous with \"source available\" in developers' minds.From Source to WeightsWith the rise of open models like Dolly, MPT, LLaMA, etc., we are seeing a similar bifurcation in the community. For most AI engineers, \u201copen source\u201d today means \u201cdownloadable weights\u201d, nothing more. Heather Meeker has proposed a definition for \u201copen weights\u201d, but there\u2019s still no community consensus. The question is whether or not open weights are enough for a model to be called open source; a software analogy would be a project releasing its binaries without the source code to re-build it from scratch.For a model to be truly open source and retrainable from scratch, the creators would need to share all their training code, pre-training dataset, fine-tuning preferences, RLHF examples, etc. The problem is the cost of these training runs: even if someone were to release everything, it\u2019s cost-prohibitive to train models from scratch for most developers and companies, so having access to the final weights is preferred anyway.In the LLMs space, the term \"open source\" is used interchangeably to define a wide range of openness levels:Open models: these are models like RedPajama and MPT-7B, they have open weights available for commercial use (under Apache 2.0 license), but can also be re-trained from scratch since the dataset is open source. You can find a guide on how to train your own RedPajama model here.Open weights: StableLM is an open model trained by StabilityAI. While the weights are available and are licensed under Apache 2.0, the dataset used to train isn\u2019t available to the public. From their README: \u201cStableLM-Base-Alpha is pre-trained on a new experimental dataset built atop The Pile and is threes times larger at approximately 1.5T tokens.\u201dRestricted weights: this is LLaMA2. The pre-training dataset is also unavailable, and while the weights are supposed to be open for commercial use, they have specific limitations that we mentioned above.Contaminated weights: models like Dolly 1.0 and LLaMA1 are part of this category. The weights are released openly, but the dataset used to train them doesn\u2019t allow for commercial use, making it technically open but practically unusable.For the foreseeable future, open source and open weights will be used interchangeably, and I think that\u2019s okay. The important thing is that more and more of this work is done as openly as possible. It\u2019s okay to be disappointed with the LLaMA2 license, but Meta just packaged ~$2M worth of FLOPS into a Github repo, and I think that will be a net positive for the progress of this space.",
    "summary": "- The term \"open source\" is being used in the LLM (Large Language Model) space to refer to downloadable weights of AI models, rather than full access to the training code and dataset.\n- There is ongoing debate within the AI community about whether open weights are enough for a model to be considered open source, as some argue that true openness requires sharing all training resources.\n- The LLaMA2 model is an example of a model with restricted weights, as it has limitations on commercial use and training another large language model with its outputs. However, despite these limitations, the release of LLaMA2 on GitHub is seen as a positive development for the progress of the LLM space.",
    "hn_title": "In the LLM space, \"open source\" is being used to mean \"downloadable weights\"",
    "original_title": "In the LLM space, \"open source\" is being used to mean \"downloadable weights\"",
    "score": 370,
    "hn_content": "- In the LLM (Large Language Model) space, the term \"open source\" is being used to mean \"downloadable weights.\"\n- The author argues that calling LLaMA (Language Learning Model Archive) open source is deceptive, as it is a closed, proprietary set of weights.\n- The average person may still refer to LLaMA as \"open source\" due to a lack of understanding.\n- LLaMA 2.0 is a significant improvement over its predecessor in terms of user freedom, but it does not meet the bar of being truly open weights.\n- The debate over terminology and the erosion of the meaning of \"open source\" is seen in the context of the broader software industry.\n- The costs of training AI models using real data can be significant, raising questions about fairness and access.\n- The legality and enforceability of licensing agreements in the realm of LLMs, particularly in terms of training on outputs, is still unclear.\n- The use of synthetic data in training models is becoming increasingly important.\n- There are differences between copyright law and contract law in terms of their applicability to LLMs and the use of their outputs.\n- The relationship between LLMs and copyright law is still evolving and may require further legal examination.\n- The emergence of LLMs and their licensing agreements raises philosophical and ethical questions about creativity, ownership, and innovation in AI.\n- The inconsistencies between the stance of AI companies on copyright and their reliance on open access to data for training models are notable.\n- The restrictions imposed by the licenses of LLMs such as LLaMA have implications for the competitive landscape and access to AI technology.- The discussion revolves around whether LLaMa2 can be considered \"open source\" due to the restrictions placed on its use and distribution.\n- LLaMa2's weights are not available, which some argue goes against the spirit of openness in open source.\n- There are different interpretations of what \"open source\" means and what licenses qualify as open source.\n- The licensing complexities surrounding AI models involve multiple components such as source code, weights, and data, each with different licensing considerations.\n- The debate highlights the importance of transparency and access to training code and data in order to understand and reproduce AI models.\n- The restrictive licenses on LLaMa2 and similar models may impact their use in commercial applications and prompt the rise of API-based access rather than downloadable weights.\n- There is a need for a clear framework and terminology to address the licensing complexities in the AI industry.",
    "hn_summary": "- The term \"open source\" is being used in the LLM (Large Language Model) space to refer to downloadable weights, which some argue is deceptive.\n- The debate over the meaning of \"open source\" and the licensing complexities in the AI industry raises questions about fairness, access, and the relationship between LLMs and copyright law.\n- The restrictions on the use and distribution of LLMs like LLaMA2 may impact their commercial applications and lead to API-based access instead of downloadable weights."
  },
  {
    "id": 36815744,
    "timestamp": 1689956540,
    "title": "'World of Warcraft' players trick AI-scraping website into publishing nonsense",
    "url": "https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/",
    "hn_url": "http://news.ycombinator.com/item?id=36815744",
    "content": "MORE FROM FORBESJul 20, 2023,08:00pm EDTToday\u2019s Wordle #762 Hints, Clues And Answer For Friday, July 21stJul 20, 2023,07:19pm EDTThe Latest Story Trailer For \u2018Armored Core VI\u2019 Is All About Human PlusJul 20, 2023,06:30pm EDTToday\u2019s \u2018Quordle\u2019 Answers And Hints For Friday, July 21Jul 20, 2023,03:48pm EDTThe Cheesiest \u2018Warzone\u2019 And \u2018Modern Warfare 2\u2019 Operator Skin Bundle Is Free Right NowJul 20, 2023,03:32pm EDT\u2018Justified: City Primeval\u2019 Two-Part Series Premiere Review \u2014 Welcome Back, Raylan GivensJul 20, 2023,09:35am EDT\u2018Barbie\u2019 And \u2018Oppenheimer\u2019 Land Nearly Identical Critic Review ScoresFORBESINNOVATIONGAMES\u2018World Of Warcraft\u2019 Players Trick AI-Scraping Games Website Into Publishing NonsensePaul TassiSenior ContributorNews and opinion about video games, television, movies and the internet.Follow7Jul 21, 2023,08:13am EDTThe storyZLEAGUE, I MEAN REDDITAs someone who writes about video games for a living, I am deeply annoyed/terrified about the prospect of AI-run websites not necessarily replacing me, but doing things like at the very least, crowding me out of Google, given that Google does not seem to care whatsoever whether content is AI-generated or not.That\u2019s why it\u2019s refreshing to see a little bit of justice dished out in a very funny way from a gaming community. The World of Warcraft subreddit recently realized that a website, zleague.gg (I am not linking to it), which runs a blog attached to some of sort of gaming app which is its main business, has been scraping reddit threads, feeding them through an AI and summarizing them with \u201ckey takeaways\u201d and regurgitated paragraphs that all follow the same format. It\u2019s gross, and yet it generates an article long enough with enough keywords to show up on Google.Well, the redditors got annoyed and decided to mess with the bots. On r/WoW, they made a lengthy thread discussing the arrival of Glorbo in the game, a new feature that, as you may be able to guess from the name, is not real.PROMOTED\u201cI have to say, since they started hinting at it in Hearthstone in 1994, it was obvious that they would introduce Glorbo to World of Warcraft sooner or later. I feel like Dragonflight has been win after win so far, like when they brought back Chen Stormstout as the end boss of the new Karazhan? Absolutely amazing!\u201dAnd it\u2026worked. Zleague auto-published a post titled \u201cWorld of Warcraft Players Excited For Glorbo\u2019s Introduction. Here\u2019s are the \u201ckey takeaways\u201d:\u201cPlayers express excitement for Glorbo\u2019s arrival and its potential impact on the game.\u201d\u201cSome players have reservations about the mandatory item Klikclac and its effect on casual players.\u201d\u201cRumors of Stormsong Valley becoming the new location for the Halfhill Market and farming sim mini-game generate enthusiasm.\u201d\u201cAppreciation for previous game changes, such as the inclusion of Klaxxi as a playable race.\u201dMORE FOR YOU'Remnant 2' Skyrockets To Become Steam's Second Best Seller Before LaunchDiablo 4 s New Patch Accused Of Being The Worst In ARPG HistoryThe Cheesiest Warzone And Modern Warfare 2 Operator Skin Bundle Is Free Right NowThat is\u2026 all essentially nonsense. The article was left online for a while but has finally been taken down (here\u2019s a mirror, it\u2019s hilarious). All the authors listed as having bylines on the site are fake. It appears this entire thing is run with close to zero oversight.Forbes Daily: Get our best stories, exclusive reporting and essential analysis of the day\u2019s news in your inbox every weekday.Sign UpBy signing up, you accept and agree to our Terms of Service (including the class action waiver and arbitration provisions), and Privacy Statement.It\u2019s a weird situation because the site is not \u201cstealing\u201d in the traditional sense, directly plagiarizing without credit. It is citing reddit threads and their authors and even embedding the reddit post a lot of the time. But while getting story ideas from reddit and expanding on them is one thing, given that these are often the biggest communities for individual games on the internet, it\u2019s a different matter to simply auto-feed reddit threads into an AI and have them spit this out. But again, there\u2019s nothing to stop this. These subreddits can\u2019t only fill themselves with joke articles to screw up a site like this, even if this one specific example is good for a laugh.Forbes Innovation01:12Local Authorities\u2019 Thriving Cities Goal Clash WithGrocery Delivery RidesThe only way this will ever be stopped is if Google steps in and dramatically deranks or bans AI-based sites like this, as begging for Google traffic crumbs is the only reason these sites exist in the first place. But since Google has its own very obvious vested interest in AI, I am not holding my breath.Anyway, get hyped for Glorbo, I hear it\u2019s the best change since the quest to depose Quackion, the Aspect of Ducks.Follow me on Twitter, Threads, YouTube, and Instagram. Subscribe to my free weekly content round-up newsletter, God Rolls.Pick up my sci-fi novels the Herokiller series and The Earthborn Trilogy.Paul TassiFollowI\u2019ve been writing about video games, television and movies for Forbes for over 10 years, and you may have seen my reviews on Rotten Tomatoes and... Read MoreEditorial StandardsPrintReprints & PermissionsVideo Player is loading.PauseUnmuteCurrent Time 0:00/Duration 1:13Loaded: ShareFullscreen",
    "summary": "- The World of Warcraft subreddit discovered that a gaming website was scraping their threads and using an AI to summarize them into articles.\n- The subreddit users decided to prank the website by creating a fake thread about a non-existent feature called Glorbo, which the AI then turned into an article.\n- This incident highlights the issue of AI-generated content and the lack of oversight on some websites, and raises questions about the role of AI in journalism.",
    "hn_title": "\u2018World of Warcraft\u2019 players trick AI-scraping website into publishing nonsense",
    "original_title": "\u2018World of Warcraft\u2019 players trick AI-scraping website into publishing nonsense",
    "score": 351,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit login\u2018World of Warcraft\u2019 players trick AI-scraping website into publishing nonsense (forbes.com/sites/paultassi)351 points by mikhael 17 hours ago | hide | past | favorite | 187 commentsconstantly 16 hours ago | next [\u2013]I don\u2019t really play games at all and the only system I own is a Nintendo Switch. I played the new Zelda and am really enjoying it. When I get stuck or have a question I google it. When I google it, I note that the top say 10 sites that answer my question all have similarly-formatted articles and also have the same mistakes in the answer to the question.I expect nearly all the sites pointing to Zelda tips or FAQs are not original in any way and are instead just regurgitated from one another through AI to form a webring of shit.At least I use ad blockers and block JavaScript so they don\u2019t get some ad revenue.replyehnto 16 hours ago | parent | next [\u2013]Yep, game wikis and guides have been a cesspool of SEO bullshit for a little while now. I guess there's money in the ads.I find it hard to believe Google doesn't have the data required to figure out which sites should be getting domain authority, but I understand it's an antagonistic and ongoing battle between SEO spam and search engines.replybotulidze 12 hours ago | root | parent | next [\u2013]> I guess there's money in the ads.I owned a basic wordpress site with some guides written during COVID for a couple of popular (at that time) mobile games. It appeared in top 3 searches for the <game name> + <guide/event/best ...> combination.Ad revenue was around ~$100 per month peaking around ~$150 at the new content drops. I have abandoned the website since, but it still is generating $100 here and there without me actively working on it for the past 2 years.To the point - yes, there's lot of money if you own a network of similar websites. My competitors were paying $10-30 per guide submitted on their website because a few guides could easily get paid off in a couple of months from ad revenue and keep generating it years afer.I could write more detailed story if someone's interested.replyiamawacko 12 hours ago | root | parent | next [\u2013]I'd be interested in something like a blog post about thisreplybombcar 11 hours ago | root | parent | next [\u2013]Perhaps a guide? Might make $100/mo!replyFatnino 7 hours ago | root | parent | next [\u2013]Get paid to make the internet a shittier place and fleece some advertisers at the same time!replyCrazyStat 15 hours ago | root | parent | prev | next [\u2013]Recipes sites too. Recently I was looking at recipes for a dish I wanted to try and noticed that two blogs had identical recipes for \"Grandma's X\". I scrolled back up to the obligatory five page essay and those were almost identical too--one of them had clearly stolen the story from the other and run it through one of those AI \"paraphrase\" tools to change words here and there. It was pretty easy to tell which was the original and which the copycat based on some strange word choices in the paraphrased version.replychinchilla2020 7 hours ago | root | parent | next [\u2013]Recipe sites have become toxic. they deserve revenue loss. It's one area where chatGPT is rescuing us from bad actors.replymschild 3 hours ago | root | parent | next [\u2013]The bad actors are using ChatGPT. Besides, properly written, curated recipes are fantastic. Mommy blogs or the likes are not.replyliveoneggs 15 hours ago | root | parent | prev | next [\u2013]Recipes have been one application that OpenAI/ChatGPT is actually really good at. No ads, interactive substitutions/scaling/conversions.replyBaeocystin 14 hours ago | root | parent | next [\u2013]\"hey bot, I have {foodstuffs} available, I need to make dinner for n people. Give me some options in the x style\"Probably one of my most-used prompts, and it's batting close to 1.000.Every now and then it will make a mistake, like forgetting the salt, putting a step in the wrong order, or the like, but far less often than you'd think. If you already have even a middling amount of kitchen experience, it's a fantastic use case.replyRetric 10 hours ago | root | parent | next [\u2013]Seems like an oddly high risk process. Not only are you risking bad taste from major missing ingredients like salt, but also ruining things with the wrong temperature/ cooking times.A reasonably comprehensive cookbook like The Joy Of Cooking or something specific to your preferences seems like less effort overall vs Google or a LLM.replyweaksauce 9 hours ago | root | parent | next [\u2013]> Not only are you risking bad taste from major missing ingredients like salt, but also ruining things with the wrong temperature/ cooking times.they are operating under the assumption you are a decent cook. any decent cook will know how to taste for salt and what is safe temperature wise. if you blindly follow instructions you are not a decent cook.replyRetric 8 hours ago | root | parent | next [\u2013]I don\u2019t read \u201chave even a middling amount of kitchen experience\u201d as being a decent cook. IMO, a decent cook doesn\u2019t really need full recipes they can just wing it based on a basic idea, but it takes a long time to get to that level.replyBaeocystin 7 hours ago | root | parent | prev | next [\u2013]It really, honestly isn't a high-risk process at all. You just have to think a little bit. All I can say is try it yourself and see. For me, half the fun is seeing what it comes up with based on what I feed it, especially if I encourage fusion cuisine. I've hit some real winners that way.Also, portion adjustments are quite useful, as I mostly only cook for one or two people. Scaling isn't always linear, so that's been a helpful step.replys-lambert 7 hours ago | root | parent | prev | next [\u2013]Cooking times don't seem very reliable to me anyway, every recipe I try takes longer than it says in the recipe.replyjohnmaguire 4 hours ago | root | parent | next [\u2013]I am more skeptical of the ingredient proportions than the cooking times...replyRetric 7 hours ago | root | parent | prev | next [\u2013]That likely comes down to your preferences or equipment.replyBaeocystin 5 hours ago | root | parent | next [\u2013]That, and recipe writers lie like a rug when it comes to time. :Dhttps://news.ycombinator.com/item?id=27632835replycoding123 7 hours ago | root | parent | prev | next [\u2013]It is more likely going to have a pretty good grasp on ingredients that pair well than a random unrated post in allrecipes.com.Likely won't pair hot sesame oil with milk, for example. (someone please tell me that's not a thing).replyJohnFen 14 hours ago | root | parent | prev | next [\u2013]Yeah, I don't search the web for recipes, ever. There's no point. I just have a couple of big recipe sites I hit up when I need a new one, instead.replyrenewiltord 15 hours ago | root | parent | prev | next [\u2013]That's the old pre-AI tools. They just thesaurus substitute.replyehnto 4 hours ago | root | parent | next [\u2013]Yep, article spinners were the thing as early as 2010, probably earlier. Even more surprising that they are back in search results as I remember them being absent for a while.reply_delirium 3 hours ago | root | parent | next [\u2013]Back when I used to do Mechanical Turk now and then, I would see rewording tasks show up pretty often there too. I assume they were for this kind of purpose. Typically they were just one sentence out of context that you were supposed to reword. I guess they pasted the article back together out of the reworded sentences?reply0cf8612b2e1e 15 hours ago | root | parent | prev | next [\u2013]>\u2026 understand it's an antagonistic and ongoing battle between SEO spam and search enginesOn the other hand, those Stack Overflow clones get top billing all the time. I do not think this is a data problem, but an incentives issue. More ads=goodreplyDistractionRect 15 hours ago | root | parent | next [\u2013]Indeed. And if you have to click through a couple of results to find an actual answer, they get ad revenue X times over answering your question with the first result.There was a time when Google Search would nearly always nail it with the first result, but now it feels like you have to wade through several results and be a prompt engineer to find relevant results.replydekervin 14 hours ago | root | parent | next [\u2013]I use google out of habit. Bing is better and always find the exact result I was searching on google.replyArrath 13 hours ago | root | parent | prev | next [\u2013]I mourn the lost era of GameFAQs and rad ASCII art at the head of pure text walkthroughs.Now we have 45 minute youtube videos of \"100 new player tips and tricks for Red Dead 2!\"reply16bitvoid 7 hours ago | root | parent | next [\u2013]I just checked to see if GameFAQs was still active and thought that Tears of the Kingdom would be a good game to see if there were any active users still making guides.There's only one...for horse upgrade recipes. I also didn't know that GameSpot acquired them.I too mourn the lost era of GameFAQs.replyohdannyboy 5 hours ago | root | parent | next [\u2013]I was an active member when GameSpot merged then took over (my account missed the LUE cutoff by less than a year, if you know you know). It was something the owner promised would never happen, and then he repeatedly said it would never go farther then it did. GameFAQers hated GameSpoters. Merging was the beginning of the end IMO, it hurt the community and that was the main thing they had.replyjcpst 13 hours ago | root | parent | prev | next [\u2013]There are people I know where I try to remember how we met, and it\u2019d be because of some obscure corner of the gamefaqs forum.replylelanthran 15 hours ago | root | parent | prev | next [\u2013]But they do know. They are incentiviswd to send you to the sites with the most ads, not the site which is most relevant, because they make a ton money off those spam sites and less of dedicated fan sites.At some point I'm gonna say fuck it and simply maintain my own list of searchable links, which score each ad with a single negative point, and each relevant keyword or phrase with a single positive point.replyderriz 15 hours ago | root | parent | prev | next [\u2013]Yeah I don\u2019t get it - without search dominance google\u2019s entire business model is highly vulnerable. Why have they allowed search quality to stagnate while pouring billions into random tech areas where they have little competitive advantage?Nobody wants to see a page of copies/duplicates by SEO rank. I recall years ago there was, for a while, a similar issue with Wikipedia clones but that problem was addressed. Not just games, recipes, but music lyrics, chords, etc - googling almost evert niche interest is rife with it.replyautoexec 15 hours ago | root | parent | next [\u2013]> without search dominance google\u2019s entire business model is highly vulnerable.I think the massive amounts of data collected by android devices while we're not using the internet and all the data collected by chrome while we are browsing means that Google no longer needs to mine our internet searches to collect the most intimate details of our daily lives. That's why Google no longer cares about investing time and money into making their search useful for us.In fact, it's better for Google if a company's customers can't find their website due to all the spam because it means that company now has to pay Google to place an ad at the top of search results in order to be seen at all.replyskywhopper 14 hours ago | root | parent | prev | next [\u2013]Google earns money on all the ads on all those trash websites. So their immediate incentive is to drive traffic to them regardless of the longer-term reputation cost.replyp3rls 11 hours ago | root | parent | prev | next [\u2013]I have a platform for kpop at kpopping.comThe top domain for almost every result in my niche is a shitty wordpress with centered text on a purple background. It makes about $10-15k a month even with its lackluster content. It's had spyware ads and porn ads. Still #1 for every query.The funny part is, bing, ddg are even worse. Welcome to webapps in 2023.replysizzle 3 hours ago | root | parent | next [\u2013]$10-15k a month holy shiz how much traffic are you seeing? Any funny stories? Congrats on your success!replyAkronymus 4 hours ago | root | parent | prev | next [\u2013]> Yep, game wikis and guides have been a cesspool of SEO bullshit for a little while now. I guess there's money in the ads.I absolutely loathe to use fandom for that very reason. They game the system to appear first, even when another, better, wiki exists.And it is nigh on unusable. Sadly one game that really depends on the wiki, that I play only has a fandom site (warframe)replymschuster91 12 hours ago | root | parent | prev | next [\u2013]Oh Google certainly could moderate their search results or augment them with human knowledge. They'd need a dozen people per country, at most, for such a task. The problem is, Google is already threading a very fine line regarding anti-competition and bias especially in Europe... and say, they would choose \"Computer BILD\" (a German tabloid) over Heise or Golem (actually respectable media), or the other way around - the outcry would be massive and so would the coming lawsuits.Instead, it's better for Google to let the search go to utter dog shit, blame issues on \"algorithms\" and get sites to pay to play with ads.replyitscrush 15 hours ago | root | parent | prev | next [\u2013]It does get deeper than just your mentioned surface level of served ads.Many of those wiki ecosystems are used to view-pump twitch channels with embedded players, such as Fextralife's webring of wikis being bought up and built up, and don't forget those \"1-feature VIP memberships\".replyiamacyborg 15 hours ago | root | parent | prev | next [\u2013]Google get paid for the SEO spam though as those sites always run Google Ads.replyNexxxeh 11 hours ago | parent | prev | next [\u2013]Slightly off-topic, but sorta related.ToTK straight up sucks for accessibility, cognitive and sensory stuff especially.I find myself using the ZD TotK map more often than I'd like:https://www.zeldadungeon.net/tears-of-the-kingdom-interactiv...And trying to remember what specific enemies are where is not fun for me. Is it fun for anyone? The Compendium doesn't keep track of them when you fight, despite the fact they respawn every blood moon.I want another Savage Lynel Bow. Where did I see that Silver Lynel? I can't remember, but I'm not hunting it all across the map hoping for the vague ping of my Purah Pad sensor when I'm already on top of one. Should I be making my own notes as well?The log is a great idea, but there's lots of stuff it doesn't capture. The quest descriptions often aren't sufficient and markers are often the person that started the quest. Great(!)I appreciate the subtitles, but why is so much of the game unvoiced?Not a concern for me as I'm playing on PC, but why no button mapping?Even with internal FSR and AA disabled so it doesn't occasionally dip to smeared potato quality, it can be hard to spot things if you don't know explicitly where to look, even for hawkish eyesight. The Ultrahand glow can help, but it's a rubbish solution.No colour blind settings. WTAF.There are so many missed opportunities to make this amazing game vastly more accessible. Nintendo has made it clear they don't care about accessibility. It's a real shame, because accessibility makes things better for everyone.replysaghm 10 hours ago | root | parent | next [\u2013]> Not a concern for me as I'm playing on PC, but why no button mapping?I'm not sure if this would be exposed in whatever emulator you're using, but the Switch does have console-wide button remapping in the system settings. This obviously isn't sufficient though, since at the very least it presents a huge hassle for having different input settings per game or if multiple people are sharing the same profile. Unfortunately, Nintendo either doesn't recognize the limitations of only having a single system-wide remapping or doesn't think it's worth prioritizing better solutions within their first-party games.replyNexxxeh 10 hours ago | root | parent | next [\u2013]I think Yuzu has per-game emulation. I'm just playing on a 360 controller though, with mostly default mappings. So long as I remember X-Y and A-B are the wrong way around, I'm golden.I think it's pretty clear Nintendo just straight-up doesn't care. They do the bare minimum, if that.ToTK would want per-mechanic remapping ideally. Like the ability to remap vehicle stuff, archery stuff, throwing stuff, mecha spirit thingy separately.But per-game stuff would at least be a step towards this decade.The lack of colour blind settings and QoL stuff (that are accessibility for cognitive), and the lack of voice content, are the things that really rustle my jimmies.Stuff that would immediately make the game more accessible to everyone, not even just disabled players. Not doing that isn't just scummy, it's lazy.replycallalex 6 hours ago | root | parent | prev | next [\u2013]There are absolutely emulator mods that swap out the image assets in the game for any controller you would like, including the steam deck, steam controller, Xbox controller, and PlayStation controller. If you are feeling lazy, head to your preferred non-google search engine and type in \u201cTears of the Kingdom Mod Manager\u201d and you will find helpful software that enables one-click installation of many mods.I don\u2019t understand how you could fault the game developer for not supporting this feature, since it is made by a company that sells specific hardware that they guarantee support for.As far as color issues, I too share color vision deficiencies but everything I have encountered has been carefully designed with shapes in mind so that color is only an enhancement. I STRONGLY believe that this approach to design is much, much, much more accessible than any toggles and filters buried in menus. Could you share with me some examples of where color was key to solving a puzzle or identifying an enemy or item?replybrvsft 11 hours ago | root | parent | prev | next [\u2013]> Not a concern for me as I'm playing on PC...> No colour blind settings. WTAF.Do color blind settings through the OS work for gaming, or does the game have to be designed to accomodate to them in some manner?replyNexxxeh 10 hours ago | root | parent | next [\u2013]I don't know if a modder could make one that'd remap colours for certain effects, for PC users on Ryujinx/Yuzu.Not that it would help Switch players nor absolve Nintendo of their apathy towards accessibility.replynoitpmeder 11 hours ago | root | parent | prev | next [\u2013]The game usually needs to implement their own handling and color shifts.replyGroxx 7 hours ago | root | parent | prev | next [\u2013]And there are SO MANY named locations, and many things refer to them only by name, but no way to search through ones you've found! I've spent quite a lot of time browsing through the map at maximum zoom to try to find the named area, only to discover hours later that I wasn't even in the right quadrant.It's quite frustrating at times. I broadly have fun with it, but improving these things would make the game a lot more consistently enjoyable.replyPigalowda 6 hours ago | root | parent | prev | next [\u2013]Have you tried getting out a piece of paper and a pencil and making your own map? Or do you need a developer to do everything for you?replyjabroni_salad 11 hours ago | root | parent | prev | next [\u2013]Do you not use the map stamps?replyNexxxeh 11 hours ago | root | parent | next [\u2013]I do. But there are only ten different ones and they don't tell you what thing you've stamped. So if you're stamping enemies, which one is \"skull\"?Why doesn't the game do this, it obviously knows what enemies are where? If you've already encountered them, why not just let you filter that enemy on the map?Even if it made you take a photo like it does for the compendium, that'd be better than the \"sometimes vague locations\" we have now. Why not list map locations of that enemy for all enemies in the compendium? Or at least the special ones like Lynels, Hinox, Talus etc?replyduxup 13 hours ago | parent | prev | next [\u2013]What I find amusing is that even when ChatGPT responds to my gaming questions I find the response to be unusually wordy with a surprisingly heavy into paragraph before it answers my simple question.Very similar to those few advertisement sites with a huge block of wonky into text taking forever to get to the answer.replyjerf 9 hours ago | root | parent | next [\u2013]Moderating on a subreddit where people are definitely trying to spam their way in with LLMs, that's becoming on of my big tells. At least the way they are tuned now they are really prone to wordy and pointless intros and outros. (At least in my personal opinion, while intros and outros are fine they should do something more than just summarise again, especially the outro, even if it's just trying to end on a joke.) I recognise there's no reason to believe that is fundamental to the tech, but right now it's a tell. (Though \"subtle errors of the type humans don't make\" is both a stronger signal and more relevant one.)replycallalex 6 hours ago | root | parent | next [\u2013]What motivates you to continue volunteering your time to moderate a Reddit forum when the host has demonstrated a clear and repeated lack of respect or care for the time and concerns of moderation staff?replyRGamma 16 hours ago | parent | prev | next [\u2013]On Kagi I just block that shit since it's relatively obvious. Some trustworthy sites in this space are gamefaqs(!) and IGN (and game magazines and others I can't recall now).replymonkpit 8 hours ago | root | parent | next [\u2013]GameFaqs is an absolute gem. Load everything at once as text, no interstitial ads, no auto playing videos, no bs.replyomeze 11 hours ago | parent | prev | next [\u2013]Yea, its tragic. When I was a kid I would often just go to GameFAQs because that was the only real source, and the guides would be surfaced in google. Its still around but Google gives me 20 crappy ad riddled sites that require a new page click, listicle-style, to get through a 5 minute areareplysizzle 3 hours ago | parent | prev | next [\u2013]\u201cWebring of shit\u201d is simply an amazing description for this phenomenon. I hope this term catches on.replyhinkley 13 hours ago | parent | prev | next [\u2013]The other problem with static sites is that it's trivial for some jerkface to copy your content and repost it. The first case of that I heard about was almost 20 years ago when it happened to a friend. The social circle of the subject matter was small enough that she could name and shame to get it taken down. Today I don't know what you could do.replyautoexec 9 hours ago | root | parent | next [\u2013]It happened to me about that long ago too and I was just flattered, but it also wasn't done by some crappy scammer ripping random content to stuff it full of ads and SEO it to death hoping make a quick buck off of my writing. I have no desire to stop people from copying and sharing whatever they can, but when it's being done with a profit motive it feels a lot more exploitative and dirty.replyericmcer 14 hours ago | parent | prev | next [\u2013]It\u2019s identical to cooking websites. Take the actual ~100 words of relevant info and stretch it into a 10000 word article with 20 ads on itreplyBasedAnon 15 hours ago | parent | prev | next [\u2013]The only system I own is a PS2, the greatest console of all time is still going strong in 2023replydqh 10 hours ago | root | parent | next [\u2013]I keep one set up with a CRT TV just for \u201cWe Love Katamari\u201d :)When you say it\u2019s still going strong, are you referring to homebrew dev or something?replyBasedAnon 9 hours ago | root | parent | next [\u2013]I mean that in between them being solid machines, the amount of content that still gets put out around it, the custom hardware people are designing for it and homebrew software the scene is still very much alive.replymikepurvis 15 hours ago | root | parent | prev | next [\u2013]Undoubtedly it had many hits, but a lot of the greats have also since been remastered and can be enjoyed on newer platforms with HD graphics and modernized controls.replyBasedAnon 13 hours ago | root | parent | next [\u2013]There's a certain point where I just stop caring about further improvements honestly. My belly is full and I am satisfied.replystevenwoo 6 hours ago | root | parent | prev | next [\u2013]I broke mine out a few years ago and the load times are kind of irritating, and repeated unskippable cutscenes in some games cooled my retro enthusiasm.replygreggsy 11 hours ago | parent | prev | next [\u2013]I noticed the same thing with Zelda. The marketability of game FAQs was realised up to a decade ago, but AI content generators, optimised by time-honoured SEO, has evidently accelerated the time to market for new platforms.The success of TOTK, and the availability of articles and Reddit posts has made it ripe for the picking.replySimbaOnSteroids 8 hours ago | parent | prev | next [\u2013]Unrelated, but YouTube is less vague when it comes to walk-throughsreplyyieldcrv 12 hours ago | parent | prev | next [\u2013]add reddit to the end of your search queryreplynancyhn 14 hours ago | parent | prev | next [\u2013]You're spot on in noticing the phenomenon of 'content spinning' across gaming websites - it's an industry-wide issue as the internet becomes oversaturated with information. Despite this, even repackaged content can help players find solutions to gaming challenges. Still, it's crucial to encourage these sites to uphold content originality and properly credit their sources.The balance between user experience and content monetization is a tough one, given that many of these sites rely on ad revenue. Ad-blockers and JavaScript blocking can affect their financial sustainability. For more original discussions about the game, I'd suggest Reddit or game-specific forums, which often foster more engaged communities. If you're up for it, your keen observations could be invaluable in writing unique content on Zelda.replymvdtnz 12 hours ago | root | parent | next [\u2013]If I was dang I would permanently ban every user who did this stupid bit of posting chatgpt crap in threads about chatgpt. It's not funny, it's not clever, it's just obnoxious.replyautoexec 9 hours ago | root | parent | next [\u2013]I haven't posted anything that was accused of being generated by AI yet, but I assume it's just a matter of time. Having to create new accounts because of false positives would quickly get more annoying than the odd AI comment.replyn42 13 hours ago | root | parent | prev | next [\u2013]Why is this comment so obviously written by ChatGPT?replyShamelessC 13 hours ago | root | parent | next [\u2013]Satire right? They\u2019re doing what the game strategy sites are accused of? I don\u2019t know.replyn42 13 hours ago | root | parent | next [\u2013]Probably \u2014 it\u2019s just weird how much of an identifiable \u201cvoice\u201d ChatGPT hasreplybooleandilemma 12 hours ago | root | parent | next [\u2013]I wonder if it's the textual equivalent of looking at an \"average face\"?Is ChatGPT just blending all its sources together into a wall of text that always looks the same?https://www.researchgate.net/figure/Example-of-average-face-...replyrcxdude 10 hours ago | root | parent | next [\u2013]it's fine tuned specifically for that tone. The base model without fine-tuning will tend to be a lot less corporate, and respond more to the prompt (chatGPT can still imitate other styles reasonably well if you ask for it, so long as you don't trigger one if its safeties)replyrodoxcasta 8 hours ago | root | parent | prev | next [\u2013]The thing is, you (we) only identify chatGPT generated content when it has that generic voice. Maybe there's a lot more generated content here, but it isn't so obvious. It's a selection bias, we see mostly what's easy to see.replyAmericanChopper 7 hours ago | root | parent | next [\u2013]I don\u2019t think this voice is emergent, it learned this from its training data. If you gave me a video game review script written by ChatGPT and another one written by Ganeranx, I doubt I\u2019d be able to tell the difference. They both have a style of just vaguely referencing lots of different things that different people have said without really saying anything at all or offering any concrete opinions.replysushid 13 hours ago | root | parent | prev | next [\u2013]Absolutely, 'content spinning' in gaming is an issue, but it can still aid players. Encouraging original content and source acknowledgement is critical. Balancing user experience and ad revenue is tough for gaming sites. For unique discussions, try platforms like Reddit or game-specific forums. Your insights could greatly enrich Zelda content creationreplycallalex 6 hours ago | root | parent | prev | next [\u2013]What motivates you to waste so many peoples\u2019 time in this way?replynekoashide 13 hours ago | root | parent | prev | next [\u2013]Or pay to buy a trusty AI to help youreplyrpastuszak 14 hours ago | prev | next [\u2013]Haha, I made https://meat-gpt.sonnet.io (the site is my way of poking fun at crappy AI startups, I won't spoil how).Now, one of the biggest sources of traffic for me (ca 70-80% at times!) are crappy AI app catalogues which not just include my MeatGPT but also hallucinate the most beautifully stupid descriptions of what it does.I couldn't imagine this stuff working better to be fair: taking that juicy slab of meat from my site and then proceeding to repeatedly slap themselves in the face with it screaming \"please give me more\".I mean, I love generative art, and built a self-publishing medieval content farm[1], but this thing just writes itself, across multiple sites.[1] https://tidings.potato.horsereplyNoToP 9 hours ago | parent | next [\u2013]I am now fully convinced there is an alignment problem.replysizzle 2 hours ago | parent | prev | next [\u2013]Funny I made SpinGPT\u2026replyacomjean 5 hours ago | parent | prev | next [\u2013]Amazing but confusing\u2026replykromem 5 hours ago | prev | next [\u2013]This is happening on a lot more gaming news sites than just this one.I'm regularly seeing articles in my Google News feed that are summarizing Reddit threads with questionable accuracy in their coverage that are clearly AI generated.All that said, when it does work correctly it's actually kind of useful and timely.For about a year now since seeing the advent of decent generative text AI, I'm starting to dream of the day I no longer use my devices to go online and just get a phone call from an AI voice that tells me if I have anything urgent in my email or summarizes news I'd actually give a crap about.The web has gone from something I truly loved to an abusive relationship so entrenched in my day to day I can't boot it from my life.I for one welcome an AI intermediary that needs to suffer through reading SEO spam and click bait headlines and nonsense comments to synthesize a useful summary of what's important to me.replyvisarga 2 hours ago | parent | next [\u2013]Going online without your AI agent would be like not using a mask during COVID.replypolitelemon 17 hours ago | prev | next [\u2013]The crucial line:> But again, there\u2019s nothing to stop this. These subreddits can\u2019t only fill themselves with joke articles to screw up a site like this, even if this one specific example is good for a laugh.Most threads will be normal conversations, and reddit (and other discussion sites) can serve as a simple way of summarizing and generating news for 'free'.I'm thinking that HN too could serve as a source for tech related news, couldn't it? Summarize the target article, then join it up with summaries/sentiments of the top comments in the thread. I didn't say I'm doing it, but if I could think of it, someone's probably way ahead of me already and has tried it.replyedavison1 15 hours ago | parent | next [\u2013]I keep hearing this sentiment on HN and IRL. As a journalist I think it misses the mark somewhat by failing to account for the value of reporting.While some news can be generated exclusively from scraping Reddit threads or whatever, most decent journalism incorporates some form of reporting, i.e. the generation of novel information from trusted sources. Even without reporting, if you can't add to the store of knowledge in the world by writing the article, it doesn't offer any value to consumers or advertisers. That includes the the world of SEO spam. An effort has to be made to distinguish your work from the competition, or else your site isn't winning those top results.Reddit threads are often just full of emotional responses to news already generated in this way. At some point along the line, a human has gone out and spoken to another human, forming an novel angle or argument, pursuing a line of inquiry, connected dots no one else has yet etc. That's news, not a summary of existing attitudes.replyLevitz 14 hours ago | root | parent | next [\u2013]>I keep hearing this sentiment on HN and IRL. As a journalist I think it misses the mark somewhat by failing to account for the value of reporting.There is valor added by journalists in even niche sectors. A journalist that reports on cars knows about the industry itself and can give an informed take on different developments, he might know how a car works, he might know about different trends in design, or markets, or whatever else. That is his added value.When it comes to videogame journalism, though, they act as little more than spokespeople for corporations. They generally don't understand the product or how it works (mechanically or in terms of design), and in some cases aren't even adept at playing videogames themselves. The only thing the world would lose if no game journalist ever mentioned WoW again and the devs communicated directly with the playerbase would be the appearance of impartiality journalists give.replyedavison1 8 hours ago | root | parent | next [\u2013]I am hardly a luminary of my field but if you take a look at some of my features you\u2019ll see they are drastically different from the idea you may have in your head.Lots of folks more accomplished than me who hit way harder. All the coverage about crunch, for instance, or sexual harassment scandals at big companies\u2014-these are topics broken by games journos.If your only exposure to this world is shitty SEO spam or cleverly-disguised marketing, I could see why you\u2019d think the way you do. But there is so much good games journalism out there. I don\u2019t recommend writing off the field like that.replymike_d 10 hours ago | root | parent | prev | next [\u2013]> As a journalist I think it misses the mark somewhat by failing to account for the value of reporting.At a revenue level how do you quantify that value? Unless you are a brand (TIME, Washington Post, etc) the only metrics are page views and time spent reading the article that eyeballs wander across ads.Arguably a clear well written article may perform worse than an AI generated article that bleeds over on to a second page. Some of the most valuable content on the internet is not well written pieces on the political climate, but \"OMG YOU'LL NEVER GUESS HOW THIS CHILD CELEB TURNED OUT\" with a 75+ image one per page photo gallery.replyedavison1 7 hours ago | root | parent | next [\u2013]Edit: made a typo.How do I quantify the value of reporting? As a writer and reporter, not a finance dude, I'm really not qualified to answer that. But it's interesting you say 'unless you are a brand' because I feel like the brand is what you get from building up years and years of trust with excellent reporting.In your second paragraph, I don't think your assertion is correct. It isn't 2008. While you were correct at one time based on trends in the industry, \"OMG YOU'LL NEVER GUESS HOW THIS CHILD CELEB TURNED OUT\" content never cemented itself. It had a high-water mark and that kind of thing hasn't made good money in years. The New York Times is still the most valuable brand in journalism and it's thriving against its competition. Not only other legacy brands, but let's be real, look where Buzzfeed is at today. Shitty content lost revenue-wise as well as on a moral basis. The only way to reliably make good ad revenue is to spam articles but it's not a profitable (or serious imo) way to run a journalistic enterprise. I believe paywalls/subscription models will continue to dominate while the losers fight for scraps.replymike_d 4 hours ago | root | parent | next [\u2013]> While you were correct at one time based on trends in the industry, \"OMG YOU'LL NEVER GUESS HOW THIS CHILD CELEB TURNED OUT\" content never cemented itself. It had a high-water mark and that kind of thing hasn't made good money in years.The LA Times makes $380,116 per employee. Outbrain, one of the largest click farms makes $841,768 per employee. Taboola makes $784,780 per employee. Combined the latter two bring in enough revenue to equal 1/4 of the entire print media industry. That isn't even counting hybrid companies like media.net that do a combination of clickbait and traditional advertising.(This is all 2022 data)replyDalewyn 9 hours ago | root | parent | prev | next [\u2013]As a common man someone who hates what journalism has become: I hope \"AI\" swiftly replaces your industry which has become a cancer and plague upon society. I would rather deal with a used car salesman than a journalist.Journalists today only provide unnecessary exposition and emotional poetry (read: wasting my reading time) and actively cause more problems and conflicts in society than they address and resolve (sensationalism and fearmongering is what brings in the clicks and thus the money).I have no sympathy whatsoever for such a rotten, morally devoid, worthless industry, and while I doubt \"AI\" will bring about any fundamental difference or improvement it will at least make the process of journalism better reflect the actual value of the final product.replyTijdreiziger 8 hours ago | root | parent | next [\u2013]I think you might be reading the wrong journalistic publications.replyedavison1 7 hours ago | root | parent | prev | next [\u2013]You are commenting on an article written by a journalist. :)replyDalewyn 7 hours ago | root | parent | next [\u2013]In case it wasn't obvious, I didn't bother reading or even clicking on the article. Not the least because it comes from the cesspool known as Forbes, of all places.replyfrozenlettuce 16 hours ago | parent | prev | next [\u2013]I created a website that does the following:- pick HN items with more than 400 votes- gather their titles in a list- ask the AI to filter out the ones that are not tech-related (bay-area topics, politics)- scrape selected articles- write summaries- publish static websiteother sources are reddit subreddits and rss feeds (official languages' blogs and github's releases page). The AI is quite gullible. That can be avoided by giving it more context and having a review step where you make sure that you are enforcing your editorial rules. Another thing that I've been wondering is having a cheaper model (gpt-turbo-3.5) write articles and then use a more sophisticated to review them (gpt4)replyvogon_laureate 38 minutes ago | root | parent | next [\u2013]I particularly appreciate that you have a disclaimer at the top stating that the article was AI generated. I wish more sites that used AI did that. Nice execution too.replyfrozenlettuce 15 hours ago | root | parent | prev | next [\u2013]some additional info: this is the prompt that filters \"candidates\" to be scraped: https://github.com/lfarroco/news-radar/blob/main/src/candida...This is the prompt that generates the articles: https://github.com/lfarroco/news-radar/blob/main/src/writer....replythevinmeister 3 hours ago | root | parent | next [\u2013]I'm curious, can you ballpark how many tokens you use for the round trip of link ingestion and article creation? I haven't really tinkered with LLMs, so I'm trying to wrap my head around the cost of projects like this.replylostlogin 16 hours ago | root | parent | prev | next [\u2013]> I created a websiteI\u2019d really like to see this - any chance we could?replyfrozenlettuce 16 hours ago | root | parent | next [\u2013]It's https://dev-radar.com/, the repository is https://github.com/lfarroco/news-radarreplylostlogin 3 hours ago | root | parent | next [\u2013]This is really neat and way easier to read.I\u2019d like the inverse too (the rejected links! Politics, history etc).They are a great source of weekend reading. But you\u2019ve included the repo, so now that\u2019s on me.replyCrazyStat 15 hours ago | root | parent | prev | next [\u2013]Very difficult to read on mobile.replyfrozenlettuce 15 hours ago | root | parent | next [\u2013]that's true! added some responsive classes to the columnsreplyCrazyStat 9 hours ago | root | parent | next [\u2013]Thanks, looks much better now!replypdpi 17 hours ago | parent | prev | next [\u2013]Even if you don't want to just summarise the comments, you can view the comments section for most articles as crowd-sourced research on the topic. You can easily walk away from most interesting discussions here with a shortlist of topical articles, books, etc, and often some colour commentary straight from the horse's mouth.replylcnPylGDnU4H9OF 17 hours ago | parent | prev | next [\u2013]They can't only do that but they can embarrass someone who's passing an AI writer off as human. At minimum, they'll have to message in some way that the article was written by AI lest this trick is pulled to embarrass an author which was otherwise considered to be human.replyMagicMoonlight 29 minutes ago | prev | next [\u2013]And this article is literally the same shit word for word as the AI post that they are complaining about. A newspaper article about a reddit thread.replyynac 17 hours ago | prev | next [\u2013]Exciting! This looks and feels a lot like the counter culture experience I had in the 80s as a hacker. The sense of fighting The Man may now be taken up against The AI. Well played game nerds!replydylan604 16 hours ago | parent | next [\u2013]I always like how this just brings to the surface the lack of respect the creators of the thing, in this case AI, that it will be abused by the public. The public doesn't care how/what the devs want it to do. The public cares about what they can make it do. See hot rods, overclocking, or any of the millions of other examples.replyehnto 16 hours ago | root | parent | next [\u2013]Yep, and even if the US regulates it, the public will take it underground, and overseas will keep pushing on. The cat is out of the bag.I would still like to see these companies try and fix any negative externalities mind you. If they just throw their hands up at helping accelerate SEO spam then that'd be disappointing.replydylan604 16 hours ago | root | parent | next [\u2013]That's the thing that makes me laugh at the pageantry of this time waste. Do people really think that US companies are the only ones working on this tech? I love how the US still has the notion that the rest of the world gives one iota about its \"morality\" dictates.replyl33t233372 15 hours ago | root | parent | prev | next [\u2013]> The public doesn't care how/what the devs want it to do. The public cares about what they can make it doThis is _hacker_ news. I don\u2019t care about what it was \u201cintended\u201d to do either; I care about what it can do when pushed to its limits!replyApocryphon 16 hours ago | root | parent | prev | next [\u2013]Now that's hackingreplypksebben 16 hours ago | parent | prev | next [\u2013]I feel like we've seen this any time that the tools are new and powerful enough - the folks unburdened by hierarchical structure can and do move fast, so when there's a sea change they can get in there and do some good damage until the behemoths catch on and steer their resources towards shoring up what they perceive as defects (frequently identified as anything that reduces their control over any system or it's connected parts).My hope is that things get faster and more chaotic as we move forward. The best stuff happens when the empowered are scrappy and in it for the love and not the money.replycaseyf 16 hours ago | prev | next [\u2013]Deleting a now viral post is kind of a weird move from a spam site that is probably desperate for trafficreplycoffeefirst 16 hours ago | parent | next [\u2013]Yeah. But on the other hand, this is Made For Advertising (MFA) content. The worst thing that can happen to it isn't notoriety, it's getting on the naughty list with Google or the programmatic ad markets. The former can gut its traffic, the latter can gut its ability to monetize.Ironically, it's looking like the war on trash AI content is going to be fought by adtech firms who need to plausibly claim their customers aren't going to be wasting money on worthless inventory.replyMSFT_Edging 14 hours ago | root | parent | next [\u2013]Can we just make a new internet, and let the ad markets and AI fight it out on this internet?replycsense 13 hours ago | root | parent | next [\u2013]https://gemini.circumlunar.space/replytofuahdude 15 hours ago | root | parent | prev | next [\u2013]The jury is definitely still out on whether that content is actually worthless inventory to advertisers.Shit tier websites with \"quality\" ads (ie something I want to click on more) can be very valuable to advertisers.This fight needs to be fought by search, not ad tech. Ad tech has too many perverse incentives.replyPUSH_AX 16 hours ago | parent | prev | next [\u2013]Whatever it is they do for money, people visiting in this context are unlikely to convert, taking it down also mitigates a little of the reputational damage at least.replymmanfrin 16 hours ago | root | parent | next [\u2013]The site is run by a competitive game tournament company (that I briefly worked at) and I think eyeballs on the article would have actually converted since it's different branding.reply19h 14 hours ago | prev | next [\u2013]I was trying to find out about video stabilization options on Linux yesterday and stumbled over an article that extremely confidently was discussing a tool that\u2019s maintained by the \u201eauthors of ffmpeg\u201c \u2026 which surprised me. So I googled it and couldn\u2019t find it. Then I put the name into quotes and found three articles mentioning it, all by the same company.replyworrycue 13 hours ago | parent | next [\u2013]So it\u2019s actually starting to happen. LLM generated content filled with hallucinations are flooding the web. The internet will soon become completely useless as the signal to noise ratio plummets until it\u2019s practically impossible to sort the wheat from the chaff.That AI transformer paper really is Pandora\u2019s Box.replysogen 3 hours ago | root | parent | next [\u2013]At this rate LLM is going to mean Lazy Layman\u2019s Marketing.Maybe I should ask ChatGPT to help me come up with more ideas\u2026replysogen 3 hours ago | root | parent | prev | next [\u2013]And let\u2019s not forget Google\u2019s Snafu with Bard.replyzamadatix 17 hours ago | prev | next [\u2013]I hope the Warcraft developers call some real future addition Glorbo now.replyApocryphon 16 hours ago | parent | next [\u2013]Does Blizzard still do April Fool's jokes? If so they're all set for next year.replyjdwithit 16 hours ago | root | parent | next [\u2013]They aren't as funny and elaborate as they once were, but yeah, they still do post something every year. In the early days of WoW they used to publish really good fake patch notes that were right on the line of credibility with a couple fake bombshells mixed in. The forums would melt down with posts from people who forgot it was April 1. Good times.replyrickstanley 16 hours ago | root | parent | prev | next [\u2013]Yes, but only out of season April fool's jokes.replyApocryphon 15 hours ago | root | parent | next [\u2013]Is that a reference to the Diablo Immortal announcementreplyCrosseye_Jack 11 hours ago | root | parent | next [\u2013]Do you guys not have phones (to google the reference)?replyrickstanley 14 hours ago | root | parent | prev | next [\u2013]Yes.replyac2u 16 hours ago | prev | next [\u2013]Calling it now. Glorbo will be in the next patch.replyTechBro8615 16 hours ago | prev | next [\u2013]I don't doubt that the redditors caught this company using an AI, but frankly the generated text doesn't look that different from what an underpaid human would write. I'm sure most of these gaming websites have a \"content calendar\" and \"pipelines\" for paying their outsourced writers $0.80 per word with instructions to source new content from relevant subreddits. With AI they've just found a way to do it more cheaply.replyfalcor84 16 hours ago | parent | next [\u2013]$0.80 per word is actually really decent money; I'd expect them to be paying a lot less.replyStrictDabbler 16 hours ago | root | parent | next [\u2013]$0.08-$0.12/word is the rate for a quality short story in a moderately respectable science fiction magazine like Clarkesworld or Asimov's Science Fiction.This is also a generally-quoted rate for blogspam.The blogspam rate will crater in response to ML but still I expect the short story to become a dead format. Many good ones will be written but there will be nowhere valuable to share or find them.replyb800h 13 hours ago | root | parent | next [\u2013]They'll need to create some sort of reputation system to make it work. Alternatively, move back to typewriters and not publishing online. AI reversing the internet again.replydylan604 16 hours ago | root | parent | prev | next [\u2013]at first because of the context, I read it as \u00a20.80 cents per word, but my brain got all tripped up over the dollar sign. I then started thinking about looking for a way to apply for that job. For $0.80 cents per word, I could wax poetically for pages upon pages of nonsense. I could even make it more beneficial for me by never using more than 2 syllable words. Using 3+ syllable words would start costing me money.replyTechBro8615 11 hours ago | root | parent | prev | next [\u2013]Yeah, I think I dropped a zero :) For 80 cents a word I might just switch jobs.replymonkpit 16 hours ago | parent | prev | next [\u2013]The article quotes the OP saying they hope it gets picked up by bot-driven news sites. While it\u2019s possible, I don\u2019t think a human would include that bit.replyolyjohn 13 hours ago | parent | prev | next [\u2013]Great. So now that they can do it more cheaply, they can afford to do more of it.I don't get what's up with this attitude of \"It's already shit, so it doesn't bother me that AI makes it even shittier.\"replyfuryofantares 16 hours ago | parent | prev | next [\u2013]80 cents per word sounds amazing, your comment is worth like 50 bucks at that rate. If it took you half an hour to write you'd still be getting a pretty good rate.replyolyjohn 13 hours ago | root | parent | next [\u2013]It was probably just an example, not meant to be taken literally.replym3kw9 14 hours ago | prev | next [\u2013]No surprise if LLMs cannot verify because they have no access to the actual game. They bet on the data being goodreplyLiquix 17 hours ago | prev | next [\u2013]Link to the scraped post: https://snoo.habedieeh.re/r/wow/comments/154umm2/replyarcho 13 hours ago | prev | next [\u2013]https://archive.is/ws3pwreplyb800h 13 hours ago | prev | next [\u2013]Honestly at this point I'd be unsurprised if the Forbes article about the trick was written by AI as well.replygochi 17 hours ago | prev | next [\u2013]Every time someone has used an automatically publish feature of any type, it always ends poorly. Either personal information gets posted they didn't intend, incomprehensible grammatical errors, or as in this case completely falsified information gets released.It's a very old lesson we should have learned from newspaper days but I guess with how fast people in AI are moving they don't care about \"old lessons\".Outside of that, it's interesting to see how people try to combat and highlight AI platforms. Jokes like these, paywalls, limited invites, increasing API costs, and so on. Very interesting times for online information.replychiph 12 hours ago | parent | next [\u2013]About ten years ago there was an Agile conference that published a hashtag where anything that used that tag would automatically get shown on the monitors around the building. 4chan found out, and well, things went predictably.Automatic publishing is always going to be vulnerable to content poisoning.replypixl97 16 hours ago | parent | prev | next [\u2013]Old paradigm: A lie can travel halfway around the world before the truth can get its boots onNew paradigm: An AI can conquer half the world before the killswitch operator can pick their axe up.replylapetitejort 16 hours ago | root | parent | next [\u2013]That's why it's important to suspend the axe above the wires ahead of time. It's also important to to remind the AI that the axe exists. The Axe of dAImoclesreplyCupprum 15 hours ago | prev | next [\u2013]For a minute i thought it was supposed to be Glorzo from Rick and Morty. That would be fun, people in WoW running around with squids on their faces.replyastrea 7 hours ago | prev | next [\u2013]Imagine trying to explain the sheer amount of effort that goes into blogspam to someone from the 90s.replyrobertlagrant 17 hours ago | prev | next [\u2013]> Gaming sites traditionally employ human writers with a deep knowledge of the subjectCitation needed.replytekla 17 hours ago | parent | next [\u2013]\"IGN writers exciting to start playing game they just finished reviewing\"replysharkweek 15 hours ago | root | parent | next [\u2013]I know you're joking, but I do actually really enjoy a handful of their YouTube reviewers, and more than once have used their reviews to make a purchase decision for a game.Only gripe is the kind of always float between 7-8 scores for games that really should be ranked lower or higher, but the content of the videos are normally good enough outside of the score given.replyjabroni_salad 11 hours ago | parent | prev | next [\u2013]well this is a WoW thread, so I guess icy-veins is the citation:https://www.icy-veins.com/wow/fire-mage-pve-dps-rotation-coo...All of the guides on this site are written by top-ranked players and backed by simulation data. Most of the guides can be customized to your character's talent selections and the leveling guides let you set your current level so as not to show things you don't currently have.replybjacobel 14 hours ago | parent | prev | next [\u2013]Gamergate was almost a decade ago. Let it go.replylcnPylGDnU4H9OF 17 hours ago | parent | prev | next [\u2013]They didn't say how deep the knowledge is. Puddles have some depth.replydylan604 16 hours ago | root | parent | next [\u2013]Around here, we say more width than depth when politely insulting someone's lack of knowledge. I assume it has British influencereplyApocryphon 16 hours ago | root | parent | next [\u2013]More breadth than depth sounds better.replydylan604 16 hours ago | root | parent | next [\u2013]Breadth isn't a word a cowboy would typically use thoughEDIT: after further thought, height isn't a word a cowboy would use either. around here, there is a staggeringly large number of people that say \"width and heighth\"replyApocryphon 16 hours ago | root | parent | next [\u2013]Ah, well I was factoring in the British influence. I could see such a modified phrase being used in an academic setting for sniping between intellectuals.replydylan604 15 hours ago | root | parent | next [\u2013]With Breadth, I think you are moving past influence and flat out making it British.replyCpoll 16 hours ago | root | parent | prev | next [\u2013]But the analogous statement is \"puddles are deep.\"replylcnPylGDnU4H9OF 15 hours ago | root | parent | next [\u2013]I don't see the problem. They are deep. Not as deep as a lake but they are deep. They are also shallow. Not as shallow as a divot made into a sheet of paper (which doesn't go all the way through) but they are shallow.replyChrisArchitect 16 hours ago | prev | next [\u2013]More discussion here: https://news.ycombinator.com/item?id=36815902replydang 16 hours ago | parent | next [\u2013]We merged that one hither.replyWhereIsTheTruth 16 hours ago | prev | next [\u2013]Something tells me this is a hidden advertisement for WoW and it's upcoming xpac..I feel like journalism hit a new low every months, and it's not going to get better any time soon.. is 'AI' the new 'tech'?replyminimaxir 16 hours ago | parent | next [\u2013]There is no upcoming expansion for WoW announced. Literally everything in the meme post is made up.replyWhereIsTheTruth 15 hours ago | root | parent | next [\u2013]You must be new to WoW, blizzcon is just around the cornerreplyminimaxir 13 hours ago | root | parent | next [\u2013]I am currently an active WoW player (just got Keystone Hero for the first time this season!)It is unlikely given the current patch cycle and plot that a new expansion is announced this BlizzCon, but definitely next year if not before then.Either way, the argument that the BBC is doing this article as a sponsored advertisement is absurd. Other outlets have written up this story.replybrailsafe 13 hours ago | root | parent | prev | next [\u2013]There's nobody new to WoW, it's a billion years old at this point. Not that I'm not tempted to re-sub for the last bit of the current patch.replyAl0neStar 15 hours ago | root | parent | prev | next [\u2013]Last xpac was less than a year ago.replydylan604 16 hours ago | parent | prev | next [\u2013]AI is the new journalism. Forget this at your own perilreplyllm_nerd 15 hours ago | prev [\u2013]Weird article. The way it vilifies what this site does -- aggregating and summarizing social media activity -- but then does exactly the same thing is hilarious irony, and perfectly encapsulates the anti-AI contradiction.Similarly, it celebrates that some random site published wrong information, when the cause was a subreddit publishing wrong information. e.g. Some rando happening into that sub would be just as misled.All in all, very silly.replyminimaxir 15 hours ago | parent [\u2013]> Similarly, it celebrates that some random site published wrong information, when the cause was a subreddit publishing wrong information.If any legitimate journalism outlet posted wrong information, it would be the fault of the outlet and immediately be retracted with a profuse apology.replyllm_nerd 15 hours ago | root | parent | next [\u2013]\"Legitimate journalism outlet\"It's some crappy gaming app that aggregates \"news\". Who cares? This is such a meaningless bit of outrage about nothing of any consequence at all, beyond \"AI will not replace us!\" luddism.I think it's a bit hilarious that you work for Buzzfeed. The single and only reason I am aware of Buzzfeed's existence is that they endlessly post listicles that are simply aggregating reddit posts, tweets, etc.replyminimaxir 15 hours ago | root | parent | next [\u2013]> Who cares?The people Googling information about World of Warcraft who are getting misinformation.replymsla 11 hours ago | root | parent | prev [\u2013]I think we all know that doesn't occur.Retractions are printed in small type on an inside page, if at all. That's been the rule for decades, if not centuries.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- 'World of Warcraft' players tricked an AI-scraping website into publishing nonsense content.\n- Players noted that many gaming websites regurgitate the same information through AI-generated content.\n- The prevalence of SEO spam in gaming sites raises questions about Google's ability to filter reliable sources."
  },
  {
    "id": 36813564,
    "timestamp": 1689946451,
    "title": "Dementia risk linked to blood-protein imbalance in middle age",
    "url": "https://www.nature.com/articles/d41586-023-02374-2",
    "hn_url": "http://news.ycombinator.com/item?id=36813564",
    "content": "NEWS21 July 2023Dementia risk linked to blood-protein imbalance in middle ageAbnormal levels of certain proteins \u2014 many of which have roles outside the brain \u2014 could be an early hallmark of Alzheimer\u2019s disease or similar conditions.Lilly TozerTwitterFacebookEmailA slice through the brain of a person with Alzheimer\u2019s disease, the most common cause of dementia.Credit: Anatomical Travelogue/Science Photo LibraryA study that followed thousands of people over 25 years has identified proteins linked to the development of dementia if their levels are unbalanced during middle age.The findings, published in Science Translational Medicine on 19 July1, could contribute to the development of new diagnostic tests, or even treatments, for dementia-causing diseases.Most of the proteins have functions unrelated to the brain.\u201cWe\u2019re seeing so much involvement of the peripheral biology decades before the typical onset of dementia,\u201d says study author Keenan Walker, a neuroscientist at the US National Institute on Aging in Bethesda, Maryland.Conquering Alzheimer\u2019s: a look at the therapies of the futureEquipped with blood samples from more than 10,000 participants, Walker and his colleagues questioned whether they could find predictors of dementia years before its onset by looking at a person\u2019s proteome \u2014 the collection of all the proteins expressed throughout the body. They searched for any signs of dysregulation \u2014 when proteins are at levels much higher or lower than normal.The samples were collected as part of an ongoing study that began in 1987. Participants returned for examination six times over three decades, and during this time, around 1 in 5 of them developed dementia.The researchers found 32 proteins that, if dysregulated in people aged 45 to 60, were strongly associated with an elevated chance of developing dementia in later life. It is unclear how exactly these proteins might be involved in the disease, but the link is \u201chighly unlikely to be due to just chance alone\u201d, says Walker.\u201cNot all the proteins showed changes in both plasma and brain tissues,\u201d says Nicholas Seyfried, a biochemist and neurologist at Emory University in Atlanta, Georgia. For example, one of the proteins found with the strongest association with dementia risk \u2014 called GDF15 \u2014 was not detected in the brain, suggesting that \u201cmechanisms below the neck could also play a role\u201d, he adds.Walker says that although a person\u2019s proteome by itself cannot predict their risk of getting dementia, it could perhaps bolster the strength of existing predictors \u2014 such as age and family history.Protein balanceAs expected, some of the proteins that researchers identified are active in the brain \u2014 but most have other roles in the body. A handful were linked to proteostasis \u2014 the process of carefully balancing protein levels in the proteome.This regulation is important in preventing proteins from going rogue and clumping together, which is what happens to the amyloid and tau proteins in the brains of people with Alzheimer\u2019s disease, the most common cause of dementia.How to defeat dementiaThe study found altered levels of many of the proteins both in the brain tissues of those who had died with Alzheimer\u2019s disease, and in the blood of those still living with it. These were associated with the presence of amyloid and tau proteins, which suggests they are somehow involved in processes specific to the disease.Other proteins identified in the study were linked to the immune system, adding to \u201cgrowing evidence for the role of innate and adaptive immune function in dementia\u201d, says Jin-Tai Yu, a physician-scientist who specializes in dementia at Fudan University in Shanghai, China. Yu and his team have previously found that people with immune diseases are more vulnerable to Alzheimer\u2019s later in life2.There is still a long way to go in understanding exactly how any of these proteins fit into the physiology of dementia, and a much better understanding of the underlying mechanisms is needed before people can benefit. Such insights \u201ccould potentially open doors for early interventions\u201d, says Seyfried. For Walker, the aim in future is to determine whether these proteins could potentially be used as markers to identify various dysregulated pathways in people with dementia and to help provide more personalized treatments.doi: https://doi.org/10.1038/d41586-023-02374-2ReferencesWalker, K. A. et al. Sci. Transl. Med. 15, eadf5681 (2023).Article PubMed Google Scholar Zhang, Y.-R. et al. Alzheimers Res. Ther. 14, 130 (2022).Article PubMed Google Scholar Download referencesReprints and PermissionsLatest on:Medical researchProteomicsAs COVID-19 cases rose, so did diabetes \u2014 no one knows whyNEWS 21 JUL 23Had COVID but no symptoms? You might have this genetic mutationNEWS 19 JUL 23An atlas of healthy and injured cell states and niches in the human kidneyARTICLE 19 JUL 23JobsLab Head Position in NeuroscienceChinese Academy of Sciences, seeks exceptional, creative scientists to join its faculty.Shanghai, ChinaThe Institute of Neuroscience,Center for Excellence in Brain Science and Intelligence Technology,CASTenure Track Assistant Professor in the field of remodeling of brain connectUNIL is a leading international teaching and research institution, with over 5,000 employees and 15,500 students split between its Dorigny campus, ...Switzerland (CH)University of Lausanne (UNIL)Tenure Track Assistant Professor in neurodevelopment and disorders of the nervous systemUNIL is a leading international teaching and research institution, with over 5,000 employees and 15,500 students split between its Dorigny campus, ...Switzerland (CH)University of Lausanne (UNIL)Postdoctoral Position In Computational PsychiatryUniversity of Alberta in Edmonton is recruiting two postdoctoral fellows in computational psychiatryEdmonton (City), Alberta (CA)University of AlbertaHead of Facility \u2013 National Facility for GenomicsAPPLICATION CLOSING DATE: September 1st, 2023. Human Technopole (HT) is a new interdisciplinary life science research institute, created and suppor...Milan (IT)Human Technopole",
    "summary": "- Abnormal levels of certain proteins in middle age could be an early sign of Alzheimer's disease or similar conditions.\n- A study following thousands of people over 25 years identified 32 proteins that, if unbalanced between the ages of 45 to 60, were strongly associated with an elevated risk of developing dementia later in life.\n- The findings could potentially lead to the development of new diagnostic tests and treatments for dementia-causing diseases.",
    "hn_title": "Dementia risk linked to blood-protein imbalance in middle age",
    "original_title": "Dementia risk linked to blood-protein imbalance in middle age",
    "score": 330,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginDementia risk linked to blood-protein imbalance in middle age (nature.com)330 points by pseudolus 20 hours ago | hide | past | favorite | 102 commentsthereticent 19 hours ago | next [\u2013]Individual differences in neuronal and glial cell metabolism and excretion, and presumably toxic effects from those changes and associated inflammation.I just got funded as PI to study blood proteomics and long term cognitive outcomes after large vessel stroke, with a focus on early identification of post-stroke dementia. It's a very cool area to be in.replyAurornis 19 hours ago | parent | next [\u2013]What an awesome space to be working in. I have a lot of appreciation for people working on addressing unknown areas of human health and well-being. Always makes what I\u2019m working on feel insignificant in comparison.replyJPLeRouzic 19 hours ago | parent | prev | next [\u2013]As someone having a blog on neurodegenerative diseases (and someone in their 60s), thank you for working in this area.replyjxramos 11 hours ago | parent | prev | next [\u2013]I've always been curious about this. Can you briefly summarize how you take peripheral blood and fractionate it out to these small bits. What's the deal exactly? Is it like centrifuged and the plasma pulled out and everything is solution there or it's in the buffy coat or down deeper? Where are these proteins found exactly and how are they purified?replyjxramos 9 hours ago | root | parent | next [\u2013]sounds like this one would have been a great read https://pubmed.ncbi.nlm.nih.gov/3280421/Good overviews here https://comis.med.uvm.edu/vic/coursefiles/MD540/MD540-Protei...and https://www.promega.com/resources/guides/protein-analysis/pr...I always thought proteins were too big for some of these techniques but apparently not.replymrtomservo 15 hours ago | parent | prev | next [\u2013]As someone who has had a (brain stem) stroke, and also as someone with close family members that have/had dementia, thank you for your work.replytheptip 17 hours ago | parent | prev | next [\u2013]Any hints in the literature as to whether these protein imbalances are downstream of some other cause that is itself harmful, or harmful in themselves? (I.e. direction of causative arrow)replyhirvi74 19 hours ago | parent | prev | next [\u2013]Thank you for your efforts. It's unsung heroes like you and all the other researchers behind the scenes that improve the lives of countless individuals.replymoneywoes 17 hours ago | parent | prev | next [\u2013]AmazingThank you for your workAside from good sleep are there any evidence based practices for mitigating these risks?replyddorian43 13 hours ago | root | parent | next [\u2013]Kinda hard for evidence based. Maybe look into low carb diets. There are small studies for increase life quality and cognition (I do it).replyechelon 19 hours ago | parent | prev | next [\u2013]Congrats! That sounds amazing! Thank you for doing this important work.What are your thoughts and the general consensus within your field for how individuals might prevent dementia?Are there untested, but plausible hypotheses for the causal mechanisms -- perhaps chronic inflammation, liver or metabolic disease, bad gut microbiota, a multitude of factors? Or does more data need to be gathered?replyddorian43 12 hours ago | root | parent | next [\u2013]A hypothesis is also linked to metabolic psychiatry (having diabetes, mental illnesses like depression/paychosis), diabetes, insulin resistance in the brain.replySubiculumCode 15 hours ago | parent | prev | next [\u2013]Do you use neuroimaging as one of your outcome measures? I'm curious as a neuroimaging scientist.Also: Congrats on the funding!replysubmeta 18 hours ago | prev | next [\u2013]For those who, like me, tried to find ways to influence this imbalance positively, the article mentions one specific protein called GDF15 as having a strong association with dementia risk. The researchers identified 32 proteins in total that were strongly associated with an increased risk of developing dementia if their levels were unbalanced in middle age.The article doesn't provide specific steps on how to influence the levels of these proteins. The purpose of this research seems to be more about identifying potential biomarkers for early detection and risk assessment of dementia rather than outlining therapeutic interventions.Edit:GDF15, or Growth Differentiation Factor 15, is a protein that is naturally produced by our bodies. It's a stress-responsive cytokine, meaning that it's part of the body's response to conditions of stress or damage. It has roles in various physiological and pathological processes, including inflammation, metabolism, and apoptosis (a form of cell death).In terms of influencing GDF15 levels, most research so far has been in the context of pharmaceutical interventions, particularly in relation to conditions such as cancer and cardiovascular disease.replycroes 18 hours ago | parent | next [\u2013]The imbalance could just be a symptom of the reason for dementia not the reason as such.replywongarsu 17 hours ago | root | parent | next [\u2013]Which is a good argument against medication that just lowers GDF15 levels. But if you approach it as \"what lifestyle changes lower GDF15\" then there's a good chance that those changes would also attack the actual reason for dementia.replycroshan 17 hours ago | root | parent | next [\u2013]Exactly. I know if medication were to be developed, checking \"are GDF15 levels significantly lowered\" would be part of the trials.But how often does the medication development process check the result we care about: \"does this medication then go on to reduce the chance of dementia?\"replywbl 17 hours ago | root | parent | next [\u2013]Always. Secondary endpoints are heavily disfavored in FDA approval.replyautokad 16 hours ago | root | parent | prev | next [\u2013]yeah strongly agree. it was thought that those plaques in the brain was the cause of alz; however, some research has indicated that's the body's defense against what is going on, not the cause. so you could take a medication that lowers GDF15, and its possible it actually increases the onset of dementia.replyTaupeRanger 18 hours ago | parent | prev | next [\u2013]Well, it's just a correlation. No causal link has been established, and anything you do to get \"less\" GDF15 could put you at greater risk for other types of diseases, since we have no idea what the relationships between these things are. I wouldn't lose sleep over this - like many things in health and nutrition, we must simply admit our ignorance while seeking and hoping for a breakthrough.replysteelframe 17 hours ago | root | parent | next [\u2013]> I wouldn't lose sleep over thisGood, because poor sleep habits earlier in life have been strongly correlated with development of dementia later in life.replyTempest1981 17 hours ago | root | parent | next [\u2013]Ha! So raising kids is likely correlated. And attending college... (or maybe I was doing it wrong)replychad_c 16 hours ago | root | parent | next [\u2013]And just living!Our time is short.replygunapologist99 12 hours ago | root | parent | next [\u2013]Thankfully, we only have so long. Also thankfully, we have so long!replymfer 18 hours ago | parent | prev | next [\u2013]I think it would be really useful to understand what influences these proteins so we can potentially stop dementia from happening or reduce it.From other research, I suspect we can influence things. Certain populations (based on lifestyle choices / environment) have lower rates of dementia than other places.replyFollowingTheDao 18 hours ago | parent | prev | next [\u2013]GDF15 is a gene that is activated by NSAIDs.So avoiding them would be a good place to start.https://www.uniprot.org/uniprotkb/Q99988/entryhttps://www.sciencedirect.com/science/article/abs/pii/S01637....Is also causes insulin release.But NSAIDs have been linked to dementia in the past, so\u2026https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2690966/it would be pretty crazy if drug companies were causing all of the dementia and Alzheimer\u2019s, wouldn\u2019t it?replySupermancho 17 hours ago | root | parent | next [\u2013]> it would be pretty crazy if drug companies were causing all of the dementia and Alzheimer\u2019s, wouldn\u2019t itThis makes sense from 10k feet. If you perennially treat conditions in the body to reduce symptoms, but the conditions persist, aren't you just masking the inflammation/trauma that accumulates? Perhaps this is the best we can do for the human condition, with current technology.replycriddell 17 hours ago | root | parent | next [\u2013]There are a lot of conditions for which treatment of symptoms is really the only option. I take ibuprofen and tylenol fairly frequently to deal with cluster headaches. If anybody can recommend a different course of action, I'm all ears.Dementia terrifies me. My dad died last year with Lewy Body Dementia. After witnessing this, I totally understand why Robin Williams decided to end his life.replyGonzoVeritas 14 hours ago | root | parent | next [\u2013]I've taken Ibuprofen for years for my recurrent headaches, and only recently (after decades) discovered that I had two underlying issues that seemingly caused them. The first was gluten intolerance, which presented as inflammation, and apparently I was also chronically dehydrated. I cut out wheat and started drinking tons of water and the headaches, which plagued me all my life, have almost completely disappeared.Had I not found the cause, I would still be popping Advil almost daily. Of course, my issue and solution is almost certainly vastly different from yours or any other person, but the key was finally discovering the underlying cause. That was the tough part.All that said, the damage has been done, hopefully the dementia doesn't set in anytime soon. My mother just died this year with dementia, it was NOT an easy ride.replycriddell 14 hours ago | root | parent | next [\u2013]Dehydration is definitely one of my triggers. I think I'm fine on the gluten front (although I've never removed it from my diet). I think some dust or grass or mold allergies are another trigger of mine.I'm very sorry to hear about your mom.replySloopJon 10 hours ago | root | parent | prev | next [\u2013]For several years, I got cluster headaches for two months every two years or so. Thankfully, I haven't had a cycle for over four years, so whatever I tell you may be out of date, and of course everyone is different. I recommend you find a good neurologist, preferably one not too old--mine kept retiring at the most inconvenient times.Ibuprofen, Tylenol, and indomethacin have never helped me for cluster headaches, often leading instead to rebound headaches of a different kind. The three things that help me are oxygen, sumatriptan injection, and verapamil.The number one thing that helps stop my episode is oxygen: 15Lpm or so of pure oxygen through a non-rebreather mask. A concentrator probably won't do the trick. If you have daily episodes, you can go through an MM tank in a month.My second choice is an Imitrex (sumatriptan) injection with a STATdose pen. Pills are worthless. The 4mg dose is just as effective as 6mg, so I can take three doses if I'm having a bad day. (The daily limit is 12mg.) They sometimes make me feel funny, and the headache occasionally comes back in an hour or two.Verapamil helps reduce the frequency and intensity of my headaches. It has a tendency to lower my resting heart rate: I was below 40bpm one morning, and I'm not a runner.Good luck. Clusters aren't fun.replybebopfunk 15 hours ago | root | parent | prev | next [\u2013]This supplement stack + oxygen + verapamil + magic mushrooms has turned clusters into almost a non issue for me. I went through several years of being too broke to really address them, and too pig headed to think something as simple as vitamin D would help. But my last set of clusters was a walk in the park compared to the ones before it.https://web.archive.org/web/20210119212133/https://vitamindw...If you decide to try Verapamil make sure you get the extended release pills. I don\u2019t have the link handy but you can find research journal articles that help nail down dosage. As for the oxygen, you may have to get your own regulator and mask to get what you need. 15lpm and a rebreather mask works amazingly for me. If your doctor is difficult about it just get them to write a script for oxygen, find a local supplier and pay out of pocket. It was only $80 to rent the tanks I needed to get me through my last cluster season.A couple of home remedies I\u2019ve tested and found effective were cardio and putting my feet in some super hot water. Both sound silly but seem to work in my experience. So if you don\u2019t have the other stuff yet, or aren\u2019t able to get to it in time, give either a try. I do burpees as soon as I feel one coming one (and after I\u2019ve chugged a 5 hour energy).The last and most effective solution is LSD or Magic mushrooms. If you micro dose then periodically you can go a lot longer between cluster headaches. A tiny bit of mushroom also seems to work as an abortive for me when I feel one coming on.I\u2019m still experimenting and learning. But hopefully this info may give you some things to research or try (assuming you haven\u2019t already, but I\u2019d much rather share this information repetitively then not share something that could help you).Feel free to reach out if you ever want to chat. Always down to provide research I\u2019ve found out just lend an ear, I know how debilitating and isolating they can be.replycriddell 14 hours ago | root | parent | next [\u2013]Thank you so much for sharing all of this. I've copied it to my phone so I can refer to it later.I take quite a lot of vitamin D (6000 IUs daily), cetirizine (zyrtec), and nicotinamide riboside (300 mg), and a cheap multivitamin. I'm a little wary about adding stuff to that but I'm definitely going to look into all the things you've mentioned.Psychedelics are super interesting to me but I really wouldn't know where to start. I'm 53 ferchrisakes. Last time I was around people buying mushrooms was 35 years ago at a skate park.> just lend an earSay... that reminds me. Tinnitus isn't something you are dealing with as well, is it?replyhazmazlaz 15 hours ago | root | parent | prev | next [\u2013]There is some interesting early research into psilocybin and cluster headaches: https://americanmigrainefoundation.org/resource-library/can-....replyberdon 16 hours ago | root | parent | prev | next [\u2013]Have you tried diltiazem for cluster headaches? I got them after coming off of the medicine for heart related issues. Started taking it again and they vanished.replycriddell 15 hours ago | root | parent | next [\u2013]Nope, but I\u2019ll look into it. Thanks!replyFollowingTheDao 17 hours ago | root | parent | prev | next [\u2013]I agree that the modality of treating symptoms and not curing disease is probably causing more problems then just having the disease.I disagree that it is the best we can do. I have essentially cured my self of an \"incurable\" disease, one which was treated with drugs that masked the symptoms while my nervous system kept collapsing. when doctors see my labs and I tell them my story they are uninterested. That has nothing to do with technology and everything to do with curiosity and compassion.My mother was told to take a baby aspirin everyday for her heart. Then the doctor one day to her just to stop taking them. It turns out that \"just stopping\" casued her to have a mini stroke (TIAs) which was well known issue when stopping long term low dose aspirin. That, and the fact that psychiatrists killed my nephew with medications, has led me to truths about the medical and pharmaceutical industries that see them as an obstacle to human health.replySupermancho 17 hours ago | root | parent | next [\u2013]I happen to have been taking a blood thinner since I was 9 (almost 40 years now) due to a congenital defect and then the ongoing surgeries. I am aware of the evils of US pharma. Perhaps \"the best we can do\" was flippant. Apologies.replymarkstos 18 hours ago | parent | prev | next [\u2013]Is GDF15 found in animal foods, plant foods, both or maybe neither because we create it?replyFollowingTheDao 18 hours ago | root | parent | next [\u2013]not only do we create it, but it\u2019s stimulated by nonsteroidal anti-inflammatory drugs. You know like ibuprofen that everyone takes all the time.Edited to remove Tylenol and replace it with ibuprofen. For some reason I thought Tylenol wasn\u2019t ibuprofen. Thanks!replypetemill 18 hours ago | root | parent | next [\u2013]Tylenol / Acetaminophen / Paracetamol is not an NSAID. Ibuprofen and Aspirin is.replySpooky23 17 hours ago | root | parent | prev | next [\u2013]Best honestly to minimize use of this type of medication. Tylenol is rough on your liver.replyTerr_ 9 hours ago | root | parent | next [\u2013]It's creepy to read about the effects of too much Acetaminophen. (Active ingredient in Tylenol, and also known as Paracetamol.)People overdosing on it is actually the primary cause of liver-failure--sometimes associated with people trying to handle the pain of withdrawal from some other drug--and liver-failure is a terrible way to go.replyreducesuffering 15 hours ago | root | parent | prev | next [\u2013]NSAID's have issues with your stomach, ears, and stroke risk. Best to minimize them all, with the smallest combination dose of tylenol + 1 NSAID.replymcdonje 20 hours ago | prev | next [\u2013]Anyone know what could cause these types of protein imbalances?replyAurornis 19 hours ago | parent | next [\u2013]That is the question.These are correlated to dementia risk, but that doesn\u2019t mean they\u2019re directly involved causing dementia. They could be a related effect of the root cause(s) of dementia.There are many examples in medicine where we\u2019ve attempted to directly modify measurable markers like this without fixing the underlying disease.They could be useful clues for discovering the root cause, though!replycarbocation 19 hours ago | root | parent | next [\u2013]Bingo. More explicitly, there is no strong reason to think that the proteins from the correlational analysis are causal for dementia.The proteins from the Mendelian randomization also don't have to be (can be in a pleiotropic pathway) but there is at least reason to think that they could be causal.replymcdonje 18 hours ago | root | parent | prev | next [\u2013]If these are correlated, then not every treatment for them would necessarily be as effective against dementia. However, if the cause of the protein imbalances is something people can take steps to prevent, then doing so would logically have a greater than zero chance of mitigating dementia risk.replyAurornis 17 hours ago | root | parent | next [\u2013]> However, if the cause of the protein imbalances is something people can take steps to prevent, then doing so would logically have a greater than zero chance of mitigating dementia risk.Or correcting the protein imbalance could interfere with an important feedback loop that we don't yet understand, which could possibly make the situation worse. Or maybe the protein imbalances are involved in counteracting the issue that causes dementia, and that's why they're elevated.This is a common theme in biological systems. A good example would be cortisol, which has become known as the \"stress hormone\". Many people assume that lowering cortisol must therefore be a good thing, but if you were to indiscriminately lower cortisol during periods of stress you'd end up in a far worse condition than you were before. Cortisol is part of your body's reaction to stress and part of the system that responds to it, so artificially lowering it can interfere with your stress response process.replynonethewiser 17 hours ago | root | parent | next [\u2013]It makes me think of running a fever. Its easy to think of fevers as bad but I imagine it would be a lot worse to simply stop the fever (if that were even possible).replysmolder 17 hours ago | root | parent | next [\u2013]> (if that were even possible)Indeed it is. Tylenol, for instance, is marketed as a fever reducer.replynonethewiser 13 hours ago | root | parent | next [\u2013]Well perhaps this proves my intuition wrong. Is it OK to reduce a fever then? But how so if its purpose is to kill off something worse?replysmolder 12 hours ago | root | parent | next [\u2013]IANAD, so someone please correct me, but I think there's some truth that treating a mild fever will just interfere with what the immune system is doing, to its detriment. On the other hand, very high fevers in themselves are quite dangerous and so being able to lower someone's temperature is a benefit.replymcdonje 16 hours ago | root | parent | prev | next [\u2013]Good points. Thank you.replypetercooper 17 hours ago | parent | prev | next [\u2013]This is unscientific anecdata, but my dad had celiac disease. After a few years, he got \"bored\" of it and refused to go along with the diet. Within a couple of years, he got vascular dementia (at a relatively young age) and ended up having a brain haemorrhage. The studies are pretty early stage on finding connections between celiac disease and brain damage but the TGM6 protein, common in people with gluten related sensitivities, has been implicated. So, and this is all spitballing for now, I think diet, and inflammation in particular, could prove to be a big deal. At least, I believe it's not following the diet that \"got him\", as it were.replyaszantu 14 hours ago | root | parent | next [\u2013]I agree, I fall into depression after I eat anything seed basedreplypella 19 hours ago | parent | prev | next [\u2013](Guinea Pig) : diet, gut microbiota, ... ( ?? )\"The Effects of Different Diets on Guinea Pig Health, Hair Morphology and Blood Protein Concentration\"~ \"Guinea pigs (Cavia porcellus) have biological similarities to humans, which make them a suitable animal model in multiple fields of research. \"https://lsmu.lt/cris/handle/20.500.12512/115773reply1MachineElf 19 hours ago | parent | prev | next [\u2013]The HN submission Could leak in blood-brain barrier cause poor memory? (2021) may provide a clue: https://news.ycombinator.com/item?id=26520453>People with ApoE4 have a hard time getting rid of amyloid beta peptide in their brains, which causes an accumulation of plaque. With healthy aging, the pumps in the blood-brain barrier work less efficiently in getting rid of the amyloid beta peptide. The pumps work even less well in people with Alzheimer\u2019s disease.>Recent work suggests that the leak in the blood-brain barrier that occurs with Alzheimer\u2019s may be due to an age-related loss of pericytes. Astrocytes, by contrast, seem to be overactive. Recent work suggests that preserving pericyte function by giving the factors that they secrete or even transplanting them could lead to a healthier blood-brain barrier.>Other findings raise the question of whether the brain\u2019s source of nutrition and its grip on control of the immune and endocrine systems could deteriorate with aging. Another finding raises the possibility that the rate at which many drugs are taken up by the brain may explain why older folks sometimes have different sensitivities to drugs than their children or grandchildren.Pair that with this part of OP:>This regulation is important in preventing proteins from going rogue and clumping together, which is what happens to the amyloid and tau proteins in the brains of people with Alzheimer\u2019s disease, the most common cause of dementia.I'm just a layman, but it sounds like BBB health is a major factor for regulating this in the brain. In some individuals, including those with identified genetic biomarkers for increased Alzheimer's risk, the BBB ages faster, leading to decreased regulation of protein/peptides. So learning more about how to improve BBB health could eventually help people maintain a healthy brain longer.Avoiding excessive alcohol seems to be an important factor for BBB health, according to this 2021 study performed on mice: https://pubmed.ncbi.nlm.nih.gov/33516661/ ; also this research published in 2022: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9204474/OP refers to \"amyloid and tau proteins\" while the 2021 article I referenced refers to \"amyloid beta peptide\" - at this point, I'm really not sure how precisely these terms are being used. Are they interchangeable in this context, or is there an important nuance that I'm missing?replybitwize 15 hours ago | parent | prev | next [\u2013]Probably the usual suspects: inflammation, gut bacteria, the American diet.replyFollowingTheDao 18 hours ago | parent | prev | next [\u2013]Nonsteroidal anti-inflammatory drugs increase GDF15 which was one of the key markers in the studyreplygarganzol 16 hours ago | root | parent | next [\u2013]But NSAIDs do not worsen dementia. Quite the contrary, the symptoms improve due to lowered inflammation.So, as other posters suggested, those proteins can be the effect markers but not the root cause indicators.replyFollowingTheDao 15 hours ago | root | parent | next [\u2013]What?https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2690966/I\u2019m not saying that it isthe root cause at all either, I\u2019m saying they\u2019re a marker as well. I\u2019m saying there a marker as well, possibly from NSAIDS.replydsign 19 hours ago | parent | prev | next [\u2013]I learned a lot about aging by watching this Minecraft video[^1] and building the kelp farm. That farm stops working after some (long) time, given the way that kelp grows in Minecraft. If Avomance had done the math beforehand, he would have discovered that he needs a costly full row of observers for the farm to work forever.Biological systems are not designed, but evolved, and evolution ends up selecting systems (which we call \"organisms\" or \"individuals\") which are good enough for it to be reproductively successful. In practice that means \"low-maintenance\" and \"energy-efficient\". Functional errors and their organism-wide effects slowly accumulate, and although our biology has everything material it needs to fix each and every error[^2], its healing program/intelligence is far from perfect.[^1]: https://www.youtube.com/watch?v=Sf9I3YORSzM[^2]: Compare this with a car, for example. If your lights go bust, the car won't grow a new one; you need to change them. But biological organisms have a lot of self-healing capability.replypella 19 hours ago | prev | next [\u2013]related:\"Blood protein levels predict leading incident diseases and mortality in UK Biobank\"https://www.medrxiv.org/content/10.1101/2023.05.01.23288879v...( May 03, 2023 ; open, pre-print; not-yet peer-reviewed ; Alzheimer\u2019s dementia included .. )Abstract:\"The circulating proteome offers insights into the biological pathways that underlie disease. Here, we test relationships between 1,468 Olink protein levels and the incidence of 23 age-related diseases and mortality, ascertained over 16 years of electronic health linkage in the UK Biobank (N=49,234). We report 3,123 associations between 1,052 protein levels and incident diseases (PBonferroni < 5.4\u00d710\u22126). Forty-four proteins are indicators of eight or more morbidities. Next, protein-based scores (ProteinScores) are developed using penalised Cox regression. When applied to test sets, eight ProteinScores improve Area Under the Curve (AUC) estimates for the 10-year onset of incident outcomes (PBonferroni < 0.0025) beyond age, sex and additional health and lifestyle covariates. The type 2 diabetes ProteinScore outperforms HbA1c (P = 5.7\u00d710\u221212) \u2013 a clinical marker used to monitor and diagnose type 2 diabetes. A maximal type 2 diabetes model including the ProteinScore, HbA1c and a polygenic risk score has AUC = 0.90 and Precision-Recall AUC = 0.76. These data characterise early proteomic contributions to major age-related disease.\"Alzheimer dementia * 10 proteins:(jpg) https://www.medrxiv.org/content/medrxiv/early/2023/05/03/202...And you can check the data ( protein * disease ) :\"Our Shiny https://protein-disease-ukb.optima-health.technology app [Username: ukb_disease, Password: shinyappUKB] provides visualisations for sensitivity analyses run across cases over successive years of follow up, allowing for interrogation of individual protein-outcome relationships.\"reply98codes 18 hours ago | prev | next [\u2013]The article doesn't say anything to infer that it's odd, but the rate of incidence of dementia being 20% seems awfully high to me.replyskybrian 17 hours ago | parent | next [\u2013]How old are the people you're imagining? Among people who live long enough, it seems fairly common.replyjustsocrateasin 19 hours ago | prev | next [\u2013]Exciting pieces of research coming out right now. I could see using a blood test to find these specific biomarkers, and then getting started earlier on a drug like donanemab that has better results the earlier you start it. Combining a blood test with a preventative/early stage drug like donanemab or lecanemab would have a lot better results than just starting those immuno drugs at the first sign of symptoms.replyhirvi74 18 hours ago | parent | next [\u2013]> a drug like donanemab that has better results the earlier you start it.Do you think there will ever be a point where Donanemab or similar drugs will be recommended for all people after a certain age?If I am thinking of the same medication, doesn't it have pretty nasty side-effects -- 30% chance of brain bleeding, right?It's tough, because after a certain age, I think it would be worth the risks (in my non-medical professional opinion), but I am not sure if that is how medicine works in practice. I mean, you wouldn't want to give one medicine for a condition that he or she might never end up getting, but you probably also do not want to wait until it's too late.I am just hoping that we find some kind of treatment in our lifetimes.replyhirenj 19 hours ago | prev | next [\u2013]NDST1 is a funny one in the list. In principle it shouldn\u2019t be out in circulation, so it\u2019s probably a sign that actually what you are seeing is a dysregulation in activity of SPPL3 in shedding of this enzyme from the Golgi.More on reflection: Looks like NDST1 has a protective effect, so maybe this is reflecting the shedding going up for some reason. Would need to check what is regulating SPPL3 activity.replyFollowingTheDao 18 hours ago | parent | next [\u2013]NDST1 metabolizes glucosamine.I\u2019m wondering, if taking glucosamine supplements could increase the risk of dementia then.replyhirenj 17 hours ago | root | parent | next [\u2013]NDST1 is a bifunctional sulfotransferase and de-acetylase. It\u2019s a gatekeeper enzyme (well as much as it can gatekeep with other isoenzymes), that catalyses a sulfation on heparan sulfate (HS) chains. HS makes up a big chunk of the extracellular matrix, and it is this matrix that various signaling molecules travel through to get to the cell. Reducing availability of NDST1 in cells would likely reduce binding of growth factors etc (or increase it, who knows!). It\u2019s likely a bunch of subtle effects, and maybe this is actually pointing to some whole other thing that is happening. It\u2019s difficult to say without digging into the literature.reply3cats-in-a-coat 19 hours ago | prev | next [\u2013]This is literally the same cause as \"child dementia\", which was reportedly called this due to similar symptoms, despite the cause is different, a genetic anomaly that causes accumulation of protein in nerve tissue and the brain. Well, it was thought to be different, but I guess not.replymycall 18 hours ago | prev | next [\u2013]> Yu and his team have previously found that people with immune diseases are more vulnerable to Alzheimer\u2019s later in life [2]\"Does this include autoimmune issues like developing allergies in life?[2] Zhang, Y.-R. et al. Alzheimers Res. Ther. 14, 130 (2022).replySpaceManNabs 15 hours ago | parent | next [\u2013]Not a doctor or a researcher in this base, but I think they are using immune to include auto immune as a subset. lots of people call some subcases of Alzheimer's as diabetes 3.replydenial 19 hours ago | prev | next [\u2013](Paywalled link of paper: https://www.science.org/doi/10.1126/scitranslmed.adf5681)Abstract:A diverse set of biological processes have been implicated in the pathophysiology of Alzheimer\u2019s disease (AD) and related dementias. However, there is limited understanding of the peripheral biological mechanisms relevant in the earliest phases of the disease. Here, we used a large-scale proteomics platform to examine the association of 4877 plasma proteins with 25-year dementia risk in 10,981 middle-aged adults. We found 32 dementia-associated plasma proteins that were involved in proteostasis, immunity, synaptic function, and extracellular matrix organization. We then replicated the association between 15 of these proteins and clinically relevant neurocognitive outcomes in two independent cohorts. We demonstrated that 12 of these 32 dementia-associated proteins were associated with cerebrospinal fluid (CSF) biomarkers of AD, neurodegeneration, or neuroinflammation. We found that eight of these candidate protein markers were abnormally expressed in human postmortem brain tissue from patients with AD, although some of the proteins that were most strongly associated with dementia risk, such as GDF15, were not detected in these brain tissue samples. Using network analyses, we found a protein signature for dementia risk that was characterized by dysregulation of specific immune and proteostasis/autophagy pathways in adults in midlife ~20 years before dementia onset, as well as abnormal coagulation and complement signaling ~10 years before dementia onset. Bidirectional two-sample Mendelian randomization genetically validated nine of our candidate proteins as markers of AD in midlife and inferred causality of SERPINA3 in AD pathogenesis. Last, we prioritized a set of candidate markers for AD and dementia risk prediction in midlife.replyrefurb 19 hours ago | parent | next [\u2013]The key question is - how strong was the correlation? Was it associated with a 5% higher chance of dementia? Or several fold higher risk of dementia?replyramblerman 15 hours ago | prev | next [\u2013]Since protein is a key factor in building muscle, is there any reason to assume keeping up with strength training in middle age would direct most of that protein to a better use and keep the balance?I realize the question is \"bro-science\", but I'm genuinely interested, perhaps someone educated could expand on it.replyradicaldreamer 15 hours ago | parent | next [\u2013]Ever seen dementia in someone who lifts? Me neither...replyaszantu 14 hours ago | root | parent | next [\u2013]seen cancer in someone who'd eat white bread and banana in the morning, then go lift weights afterwards. Within 3 months he war breathing heavily when comming up the stairs. I noticed. Within 2 more months he was dead. Guy was 70 or so.replythomashabets2 19 hours ago | prev | next [\u2013]Is there a test for it?replyccvannorman 18 hours ago | parent | next [\u2013]+1 - How would one get bloodwork done to specifically test for these proteins?replytreeman79 17 hours ago | prev | next [\u2013]Got exposed to lot of natural gas over a 3 month period. (Long story) Eventually figured out that my blood begin clotting like crazy. I have factor 5, so I was predisposed to it, but I was having 2-3 TIAs a week for a couple of years. Huge cognitive decline.Only when a large clot showed up in lungs did they figure out what was going on.Week after being on blood thinners and simple programming problems that were taking me weeks to solve were back down to minutes.replyhn_throwaway_99 15 hours ago | parent | next [\u2013]Would definitely like to hear more about how they were able to narrow down to find a root cause. I also have factor 5 and have suffered some other non-specific symptoms (primarily extreme fatigue) but haven't been able to nail down a root cause. I'm curious if there was a test to find out how \"thick\" your blood was before you went on blood thinners.replytreeman79 12 hours ago | root | parent | next [\u2013]Trial and error. Symptoms start back up every-time I go off blood thinners. Visual issues , TIAs, cognitive. Clears up when I start back up. Covid started when I was just getting treatment so lost access to doctors, so no further investigating was done.replygarganzol 16 hours ago | parent | prev | next [\u2013]It has an official name - vascular dementia. A kind of dementia that is caused by vascular problems like blood clots in vessels making it hard to deliver the blood to the brain.Oftentimes it is close to impossible to spot this in a usual bloodwork, but were they able to spot D-dimer anomalies in your case?replyncr100 17 hours ago | parent | prev | next [\u2013]Wild.Blood clots can be scary. (personal exp). Glad to hear you know why they are happening and how to fix it.Happy clear-thinking !!!replyPr0ject217 17 hours ago | parent | prev | next [\u2013]That's crazy.replyelamje 17 hours ago | prev | next [\u2013]For those of you here that care about what's going on inside of you - Function is tracking 100+ biomarkers over time, bi-annually, and has additional testing available for state-of-the-art early cancer detection (Grail) and Alzheimer's risk.https://www.functionhealth.com/whats-includedI work here and it's amazing to watch this space unfold. Lots of great stuff going on in the diagnostic space. Measurement is the first step towards understanding your biochemistry and making changes!replyscottyah 16 hours ago | parent | next [\u2013]This looks great, I'm just hesitant to sign up with any startup-y looking company these days that says they're going to be around for my lifetime. You might get more traction from people like me if you guarantee that our data will be easily exportable and testing methods reproducible.I imagine the testing methods might be your bread & butter, but it's so hard to trust any claims if the results aren't auditable. I think about how these results will matter a lot more to me in 40-50 years, and how unlikely it is for ANY business to last that long.replyelamje 15 hours ago | root | parent | next [\u2013]Yeah, our internal engineering team in the US are members (me included) that want the same thing! Do you have any suggestions on file format with the ideal schema? I've done deep dives on PubMed and GitHub but haven't found a great answer for all use cases.I personally track a lot of my stuff in a spreadsheet right now but am on a personal hunt for a standard formatreplyhn_throwaway_99 15 hours ago | root | parent | prev | next [\u2013]I wouldn't really be concerned about the longevity of the business as long as I can get just a print out of the data, which I'm assuming is a pretty obvious feature because I'd want to share results with my doctor.Note that, on an individual level, the format of the export really doesn't matter much with the rise of LLMs. I had some past bloodwork results in PDF format, and I was amazed how I could just copy and paste the test results into ChatGPT and it was able to correctly parse and interpret the results. Others may have privacy concerns but I LLMs being able to read and parse a PDF dump of bloodwork is going to be an easy commodity.replyjohndavi 16 hours ago | parent | prev | next [\u2013]Any early access codes you're spraying around? Also how does Function compare to something like your out of the box test-ordering companies? https://www.ultalabtests.comreplyelamje 15 hours ago | root | parent | next [\u2013]Not at the moment, but the waitlist is a real waitlist that moves forward, not the typical smoke and mirrors email marketing grab.Not familiar with that provider, but our core offering tracks this over time. I would recommend comparing the pricing of their tests to the equivalent for us. We are bi-annual for biomarkers that our CMO selected - i.e. some aren't interesting to track in 6 month intervals. You can always add testing at higher frequency if you'd like.replydusanh 16 hours ago | parent | prev | next [\u2013]I got excited about this and then I noticed it's US only.replyyieldcrv 16 hours ago | parent | prev | next [\u2013]nice, like I always sayno conflict == no interestreplybilsbie 19 hours ago | prev | next [\u2013]How might this interact with the APOE4 genotype?replyboringuser2 9 hours ago | prev | next [\u2013]So, take anabolic steroids?I know that androgens can be neuroprotective in the brain.(I'm partially kidding, most current anabolic steroids aren't selective enough to be safe for any purpose).replyhospitalJail 20 hours ago | prev | next [\u2013]Huh, I wonder if this explains why Fasting could prevent Dementia. Although hard to imagine autophagy only targets the excess.replyYoric 19 hours ago | parent | next [\u2013]Is there any reason to believe that fasting could prevent dementia?replygarganzol 16 hours ago | root | parent | next [\u2013]Fasting increases insulin sensitivity, which in turn helps to prevent dementia. Fasting activates growth hormone, which in turn helps to heal damages that might lead to dementia. Fasting activates autophagy which eradicates marginal tissues, thus helping to prevent dementia.So fasting has quite a few cards upon its sleeve and the effect is enormous. But, a therapeutic fasting should be done right and should include water, minerals and vitamins. So it's not quite a full fasting per se, it's more about creating the right conditions for an organism to reboot the broken parts.replyccvannorman 18 hours ago | root | parent | prev | next [\u2013]There seems to have been a few studies as described here: https://www.discovermagazine.com/health/the-growing-science-...But, in my opinion there is more research to be done here to establish whether or not (and to what degree) there is a strong linkreplyolliej 15 hours ago | prev [\u2013]I know that's not what this is saying in any way, shape, or form, but I am waiting for FB posts using this as evidence support balancing humours to prevent dementia.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Researchers have discovered a link between blood-protein imbalance in middle age and an increased risk of dementia.\n- The study identified 32 proteins that were strongly associated with dementia risk if their levels were unbalanced.\n- The proteins are involved in proteostasis, immunity, synaptic function, and extracellular matrix organization.\n- Some of the proteins were also found to be abnormally expressed in postmortem brain tissue from Alzheimer's patients.\n- The findings suggest that dysregulation of specific immune and proteostasis pathways may contribute to dementia risk.\n- The study genetically validated nine of the candidate proteins as markers of Alzheimer's disease.\n- The research provides valuable insights into the biological mechanisms underlying the earliest phases of dementia.\n- More research is needed to understand the causal relationship between protein imbalances and dementia.\n- The findings could potentially lead to the development of early detection and risk assessment tools for dementia."
  },
  {
    "id": 36819906,
    "timestamp": 1689974265,
    "title": "Llama: Add grammar-based sampling",
    "url": "https://github.com/ggerganov/llama.cpp/pull/1773",
    "hn_url": "http://news.ycombinator.com/item?id=36819906",
    "content": "Skip to contentProductSolutionsOpen SourcePricingSearch or jump to...Sign inSign upggerganov/llama.cppPublicNotificationsFork 5kStar 35.5kCodeIssues366Pull requests87DiscussionsActionsProjects4WikiSecurityInsightsNew issuellama : add grammar-based sampling #1773Openejones wants to merge 19 commits into ggerganov:masterfrom ejones:grammar+969 \u22121Conversation 59Commits 19Checks 24Files changed 14ConversationCollaboratorejones commented on Jun 9Jun 9, 2023 \u2022editedEDITED after updatesInspired by #1397 and grantslatton's CFG work, this adds an API that takes a serialized context-free grammar to guide and constrain sampling. Also adds a sample Backus-Naur form (BNF)-like syntax in main for specifying a grammar for generations.Testing(M2 Max, 30B)Chess\"Chess\" without grammarArithmeticArithmetic - no grammarJSON\"JSON\" - no grammarJapaneseJapanese - no grammarApproachGrammar APIThe llama API accepts a data structure representing a context-free grammar over 32-bit code points:  // grammar element type  enum llama_gretype {    // end of rule definition    LLAMA_GRETYPE_END      = 0,    // start of alternate definition for rule    LLAMA_GRETYPE_ALT      = 1,    // non-terminal element: reference to rule    LLAMA_GRETYPE_RULE_REF    = 2,    // terminal element: character (code point)    LLAMA_GRETYPE_CHAR      = 3,    // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to    // be an inclusive range ([a-z])    LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,    // modifies a preceding LLAMA_GRETYPE_CHAR or    // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])    LLAMA_GRETYPE_CHAR_ALT    = 5,  };  typedef struct llama_grammar_element {    enum llama_gretype type;    uint32_t      value; // Unicode code point or rule ID  } llama_grammar_element;  LLAMA_API struct llama_grammar * llama_grammar_init(      const llama_grammar_element ** rules,                 size_t  n_rules,                 size_t  start_rule_index);SamplingThe grammar sampling code models a nondeterministic pushdown automaton, maintaining N stacks for the possible parse states. Sampling a token is done in two steps: a sampling API that filters candidates to those that match one of the parse stacks (llama_sample_grammar) and adding the chose token to the grammar (llama_grammar_accept_token).ExamplesAdds --grammar and --grammar-file arguments to main taking a simple extended BNF to constrain generations. The parser for this format is implemented in examples/grammar-parser.{h,cpp}:// ... Supports character// ranges, grouping, and repetition operators. As an example, a grammar for// arithmetic might look like://// root ::= expr// expr ::= term ([-+*/] term)*// term ::= num | \"(\" space expr \")\" space// num  ::= [0-9]+ space// space ::= [ \\t\\n]*The root rule identifies the start of the grammar.## Caveatsthe binary format makes the code harder to understand and more brittlethe grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currentlythe 1-char lookahead sampling is probably biasing generations in a weird way; further investigation on quality of outputs is probably needed49PapersAnon, FNsi, lin72h, tucnak, walking-octopus, zenixls2, Okabintaro, chakflying, bullno1, m1chae1bx, and 39 more reacted with thumbs up emoji11mudler, 1980Dragon, jagtesh, iceychris, bermanboris, bastos, SommerEngineering, mewwts, sylv, pplonski, and jerpint reacted with heart emoji25lin72h, Green-Sky, Alumniminium, xaedes, m1chae1bx, mudler, megupta, zakkor, Vuizur, AlphaAtlas, and 15 more reacted with rocket emojillama, main : constrain sampling to grammarfd0eb66ggerganov added the high priority Very important issue label on Jun 9Jun 9, 2023Collaboratorhoward0su commented on Jun 10Jun 10, 2023Suggest taking a file as grammar parameter and put several examples like what we did for prompts (in .\\prompts folder).5Green-Sky, lin72h, rreed-pha, MoffKalast, and schappim reacted with thumbs up emoji1lin72h reacted with eyes emojiSponsorCollaboratortobi commented on Jun 10Jun 10, 2023 \u2022editedIncredibly useful contribution. It's really amazing how much this simplifies many use cases.I agree that it would be better if the grammar came from a file.Two snags I hit while trying this out:it crashes with --prompt-cacheany empty lines in the grammar cause a crashSome additional thoughts:Would love to have the grammars support empty lines and commentsI wonder if the grammar could be compiled into a tensor of state transitions and run on the GPUI wonder if there is an optimization where the next token is already known form the grammar we could skip the inference and just add it? In many types of grammars like json or html that could really speed up generationI think it's worth allowing to reference full tokens form the grammar. Maybe something like @\u201c token\u201d or @13432 Id of token.9m1chae1bx, schappim, Flaque, transitive-bullshit, kwikiel, SSabev, msanterre, badcc, and georgewritescode reacted with thumbs up emojiCollaboratorslaren commented on Jun 11Jun 11, 2023Very nice! I am wondering what is the rationale for not including the parser in the llama.cpp API. Without it, most downstream users will be forced to manually make a copy of the parser in their code to support the feature, which is not great.Also for usability, I think it would be a good idea to keep a copy of the binary grammar in llama_grammar, rather than asking the users to keep the provided copy alive. The overhead would be minimal, and it would simplify the code of downstream users.5lin72h, xaedes, FNsi, Green-Sky, and FSSRepo reacted with thumbs up emojiejones added 6 commits last monthJune 11, 2023 23:44allow loading grammar from file834d423fix whitespace errors9e77f42handle & print parser errors674bb08add comments to grammar syntax and allow newlines where unambiguous98a9587Merge remote-tracking branch 'refs/remotes/upstream/master' into grammar56904caadd missing include3e78f00CollaboratorAuthorejones commented on Jun 12Jun 12, 2023Thanks all! Just added support for grammar files (with examples) and updated the grammar syntax to add shell-style comments and allow empty lines between rules, as well as newlines inside parenthesized groups.it crashes with --prompt-cacheI wonder if that was #1699 ? If so, should be fixed nowI wonder if the grammar could be compiled into a tensor of state transitions and run on the GPUSounds cool, I don't know enough about GPU programming to comment on that myself. The grammar participates in the sampling layer, and I'm not sure if that leverages the GPU currently.I wonder if there is an optimization where the next token is already known form the grammar we could skip the inference and just add it?This is definitely possible. That said, AFAIK the token would still need to be evaluated, and that seems to be the bottleneck. Maybe the optimization comes in being able to batch eval strings of such tokens?I think it's worth allowing to reference full tokens form the grammarNeat idea. Would that be more of an optimization or to reference tokens that can't be expressed textually?what is the rationale for not including the parser in the llama.cpp API.Honestly, I was trying to reduce the changes to llama.cpp itself. Agree it would be more convenient in the API.I think it would be a good idea to keep a copy of the binary grammarMakes sense. I left that out of this round of changes - if it's desired to have the grammar parser in the llama API, this may naturally fit with that change.1lin72h reacted with thumbs up emoji1Green-Sky reacted with hooray emojiContributorbullno1 commented on Jun 12Jun 12, 2023First, this is amazing work.This makes me wonder whether the entire sampling API should be pulled into something like llama_samplers instead.External samplers can evolve independently of the core API.The existing functions can be kept for compatibility.AFAIK, the only thing we need is to expose the RNG.And even then, the existence of that inside a state/context is debatable.The context window is already managed by user code so why not sampling?This reminds me a lot of: https://lmql.ai/.There is also https://github.com/1rgs/jsonformer where the input is a json schema which is not always easy to express in BNF.AFAIK the token would still need to be evaluatedWould it though?We just immediately add it to the context.It is done manually in user code now.Maybe the optimization comes in being able to batch eval strings of such tokens?AFAIK, that's the case.The initial prompt and the user input are submitted in a large batch.The inference loop just feed the single chosen token back until eos.The grammar participates in the sampling layer, and I'm not sure if that leverages the GPU currently.The current sampling is CPU.2KerfuffleV2 and lin72h reacted with thumbs up emojiCollaboratorGreen-Sky commented on Jun 12Jun 12, 2023This makes me wonder whether the entire sampling API should be pulled into something like llama_samplers instead.one of the discussion points for adding more llm generic tooling back into ggml(repo) was moving the sampler there. but afaik nothing happened yet :)CollaboratorAuthorejones commented on Jun 12Jun 12, 2023There is also https://github.com/1rgs/jsonformer where the input is a json schemaWas planning to tackle this next. I've got it more or less working locally in a branch off of this, at least with the examples on jsonformer's README. It uses a Python script to generate a JSON BNF that conforms to the schema.2lin72h and tobi reacted with thumbs up emojiejones added 4 commits last monthJune 14, 2023 23:53support alternates in root rule421c6e1fix bugs with empty token and EOSb876d19adjust JSON grammar58ca9bcremove swp file414f251howard0su reviewed on Jun 15Jun 15, 2023View reviewed changesllama.h@@ -263,6 +289,9 @@ extern \"C\" {  LLAMA_API void llama_sample_typical(struct llama_context * ctx, llama_token_data_array * candidates, float p, size_t min_keep);  LLAMA_API void llama_sample_temperature(struct llama_context * ctx, llama_token_data_array * candidates, float temp);  /// @details Apply constraints from grammar  LLAMA_API void llama_sample_grammar(struct llama_context * ctx, llama_token_data_array * candidates, const struct llama_grammar * grammar);Collaboratorhoward0su on Jun 15Jun 15, 2023Can we make llama_grammar as a structure with two callbacks? So the other implementation of it can support context aware state machine instead?CollaboratorAuthorejones on Jun 16Jun 16, 2023Do you mean like, the caller would provide the implementation of llama_grammar (via callbacks), from which the llama API determines which tokens are valid?Collaboratorhoward0su on Jun 16Jun 16, 2023yes, so llama code will not assume the grammar implementation.CollaboratorAuthorejones on Jun 18Jun 18, 2023Yeah, I'm open to that idea, assuming the grammar interface itself generalizes well to other implementations. I kind of designed this with the specific implementation in mind so that's not a guarantee.Ownerggerganov commented on Jun 15Jun 15, 2023Great stuff!I'm still wrapping my head around this.Yes, this can become part of a llama.cpp or ggml sampling API, but I guess for now we can keep it as example and see what are the pros and cons and learn how to use it most efficientlyWhat happens when then next N > 1 tokens are uniquely determined by the grammar? I guess we will sample them one by one, correct? What would it take to make it so that they are submitted to be processed as a batch? This would significantly speed up the inference in such cases2lin72h and PapersAnon reacted with thumbs up emojiCollaboratorAuthorejones commented on Jun 16Jun 16, 2023Yes, this can become part of a llama.cpp or ggml sampling API, but I guess for now we can keep it as example and see what are the pros and cons and learn how to use it most efficientlyTo clarify, this PR adds the core sampling functionality in llama.cpp, leaving the grammar parser out in examples. Should that all be moved to examples or just left as is?What happens when then next N > 1 tokens are uniquely determined by the grammar? I guess we will sample them one by one, correct? What would it take to make it so that they are submitted to be processed as a batch? This would significantly speed up the inference in such casesYes, that's correct. I think that's doable, I can take a stab at that.ejones mentioned this pull request on Jun 16Jun 16, 2023examples : generate JSON according to schema #1887DraftSponsorCollaboratorSlyEcho commented on Jun 16Jun 16, 2023 \u2022editedthe grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currentlyI don't understand this part. So it is converting to UTF-16?Another option would be to use token values but it will be more limiting.EDIT: I read through the code.The grammar doesn't care about the text encoding. It could work with any encoding, provided that the rules match the characters correctly.The parser doesn't understand UTF-8 so it will create rules that don't match as the user expects.For example, if I wanted to create a rule to match all Hiragana characters, I should be able to write:[\u3041-\u3096]However the parser doesn't see it as two characters separated by -, instead:[\\xe3\\x81\\x81-\\xe3\\x82\\x96]But the correct rule should be something like this?\"\\xe3\" [\\x81-\\x82] [\\x81-\\x96]SlyEcho reviewed on Jun 16Jun 16, 2023View reviewed changesllama.cppOutdatedShow resolvedSlyEcho reviewed on Jun 16Jun 16, 2023View reviewed changesexamples/grammar-parser.cppOutdatedShow resolvedCollaboratorivanstepanovftw commented on Jun 16Jun 16, 2023Just dont use repeat penalties to get best grammar as llama canOwnerggerganov commented on Jun 16Jun 16, 2023To clarify, this PR adds the core sampling functionality in llama.cpp, leaving the grammar parser out in examples. Should that all be moved to examples or just left as is?It's fine the way it is1lin72h reacted with thumbs up emojiSponsorburke commented on Jun 16Jun 16, 2023FWIW I'm adapting this code into an analogous feature for models running on torch. In my implementation, I'm doing grammar enforcement logit masking on the GPU across the full token set before selecting candidates: https://github.com/Shopify/torch-grammar/blob/df23e354083c909c70120e256ed34036c93f6714/grammar_sampler.py#L232-L239. The same strategy would probably work here if anyone was super motivated to try it.ggerganov reviewed on Jun 17Jun 17, 2023View reviewed changesllama.hOutdatedShow resolved21 hidden itemsLoad more\u2026Contributormudler commented 3 weeks agoJul 2, 2023 \u2022editedgreat contribution @ejones kudos! can't look forward to see this merged!Just for reference, been trying this locally and works like a charm! I've went a bit ahead and tried this with the golang bindings ( branch at: https://github.com/go-skynet/go-llama.cpp/tree/grammar ) and LocalAI (https://github.com/go-skynet/LocalAI), result is that now is possible to emulate OpenAI functions and run directly their examples:What I wanted to do is give more data points and highlight that it chooses correctly also to not use any of the functions, so from a first hands-on with it (and from a personal empirical set of tests) it looks that the 1-char lookahead sampling is good enough if the model is \"good\" enough (I've tested with WizardLM 7b), but it's very sensible to the prompt:5Green-Sky, ggerganov, lin72h, eliot-akira, and ejones reacted with rocket emojiThis was referenced 3 weeks agoJul 2, 2023feature: Chat completion functions go-skynet/LocalAI#588Closedfeature: constrained grammars go-skynet/LocalAI#354Closedwip: add constrained grammar support go-skynet/go-llama.cpp#124DraftContributormudler commented 3 weeks agoJul 4, 2023 \u2022editedJFYI After playing with it a bit more, I've bumped into this while trying on ARM64+CUDA:Jul 04 20:37:13 localhost local-ai[34380]: LLAMA_ASSERT: /usr/local/LocalAI/go-llama/llama.cpp/llama.cpp:2479: !new_stacks.empty()                                          Jul 04 20:37:13 localhost local-ai[34380]: SIGABRT: abort   This is me trying with the binding.Update: I can't reproduce with llama.cpp. Ignore me, must be something in the binding which is not correct.1lin72h reacted with eyes emojiMerge remote-tracking branch 'upstream/master' into grammar38fbd40CollaboratorAuthorejones commented 2 weeks agoJul 6, 2023@mudler thanks for the feedback! Re: OpenAI functions, I also have a draft up at #1887 with a script to convert JSON schemas to grammars. Re: that assertion, that is triggered when the sampled token doesn't match the grammar at all. If you do run into it on llama.cpp, let me know the inputs and happy to look into it :).1lin72h reacted with eyes emojiContributormudler commented 2 weeks agoJul 6, 2023 \u2022edited@mudler thanks for the feedback! Re: OpenAI functions, I also have a draft up at #1887 with a script to convert JSON schemas to grammars. Re: that assertion, that is triggered when the sampled token doesn't match the grammar at all. If you do run into it on llama.cpp, let me know the inputs and happy to look into it :).yes, awesome job! I've looked at that PR indeed, and slightly adapted to Golang to generate grammars directly from the requests - my first attempts where more simple though, with a chain of let first choose an action -> and then fill the params (to force it to some kind of 'reasoning' step)However, what I'm seeing is quite weird - it doesn't happen when using llama.cpp directly, but only when using it with the golang bindings (https://github.com/go-skynet/go-llama.cpp) on a particular setup I have (it just happens on ARM, on my x86_64 machine just runs fine). The same grammar (basically it's equivalent output from your sample in #1887 ) works fine on x86_64 but crashes with ARM+CUDA with the error above.I'm suspecting something weird going on in the toolchain package combination (gcc/nvcc) - I've tried to trace it with gdb back with no luck so far, seems indeed that there is no match with the grammar rules (even if it does match on x86_64!).I really appreciate your help! Thank you so much, but I don't want to bother you. It seems like running llama.cpp directly isn't causing any issues. I'll collect more data and see if I can figure out if it's something that can be replicated or not.1lin72h reacted with thumbs up emojimudler mentioned this pull request 2 weeks agoJul 6, 2023feat: LocalAI functions go-skynet/LocalAI#726Merged1 taskKerfuffleV2 mentioned this pull request 2 weeks agoJul 7, 2023Add optional llm_samplers sampler backend rustformers/llm#359OpenCollaboratorKerfuffleV2 commented 2 weeks agoJul 8, 2023Perhaps consider using a more standard BNF syntax? For example: https://mdkrajnak.github.io/ebnftest/The changes to existing grammars would be pretty minor:root    ::= jp-char+ (#'[ \\t\\n]' jp-char+)*jp-char   ::= hiragana | katakana | punctuation | cjkhiragana  ::= #'[\u3041-\u309f]'katakana  ::= #'[\u30a1-\u30ff]'punctuation ::= #'[\u3001-\u303e]'cjk     ::= #'[\u4e00-\u9fff]'Looks like the only change really is quoting character classes like #'[blah-blah]' instead of using bare [blah-blah]. You don't have to support EBNF on your side, just using a similar format for the features you do support would make reuse of existing EBNF grammars a lot easier.1lin72h reacted with thumbs up emojiadd unicode escapes014fbfdCollaboratorAuthorejones commented last weekJul 12, 2023@KerfuffleV2 when digging into EBNF (basically on Wikipedia), I concluded that there isn't a clear, single standard EBNF to follow. I opted for a format that would match typical modern regex syntax. For this, XML's EBNF was a good starting point, but using \\x/ \\u / \\U escapes in place of their #x.In the project you linked, the #'...' syntax seems to be an artifact of Clojure:This project uses the clojurescipt port of instaparse which provides an excellent EBNF parser with one quirk: regexs must be quoted as clojure regex literals. For example the regex for any character A-Z, [A-Z], is entered as #'[A-Z]'.I like the idea of reusing existing grammars. Perhaps it makes sense to implement alternate parsers or translators for the most popular formats? For example, it looks like ANTLR publishes a large set of example grammars, but I don't know that we'd want to tie our main format to ANTLR to benefit from that.CollaboratorAuthorejones commented last weekJul 12, 2023@SlyEcho gentle nudge - any comments on this?3lin72h, marclove, and gururise reacted with thumbs up emojiMerge remote-tracking branch 'upstream/master' into grammarb2e071dwanicca commented last weekJul 12, 2023 \u2022editedHi, after reading the code I came up with a question.Say we have a rule that the model must generate either apple or banana.Current implementation will reserve all tokens with prefix a as the filtered candidates, such as ant, ate, apple.So if ant is sampled, it will be truncated into a.Eventually, we may get a,p,p,l,e (five tokens) rather than apple (one token).Did I mistake something?1gururise reacted with eyes emojiSponsorCollaboratorSlyEcho commented last weekJul 12, 2023@SlyEcho gentle nudge - any comments on this?Sorry, I haven\u2019t found time to test it yet but it looks pretty good already.CollaboratorAuthorejones commented last weekJul 13, 2023@waniccaEventually, we may get a,p,p,l,e (five tokens) rather than apple (one token).Correct. Although even with this 1-char implementation, in cases where one or more longer tokens are uniquely determined by the grammar (e.g., \"a\" implies \"apple\"), the batch sampling optimization suggested by @ggerganov may also fix this.SponsorCollaboratorSlyEcho commented last weekJul 13, 2023I suppose we could have backtracking sometime in the future?2ggerganov and lin72h reacted with thumbs up emojiCollaboratorKerfuffleV2 commented last weekJul 14, 2023In the project you linked, the #'...' syntax seems to be an artifact of Clojure:Ah, fair enough. It seems like the Rust enbf crate conforms to that ENBF tester for what it's worth.Although even with this 1-char implementation, in cases where one or more longer tokens are uniquely determined by the grammar [...]Isn't this more of a problem than it might seem at first glance because models are trained with certain combinations of tokens? So causing the model to generate a,p,p,l,e piecemeal would likely cause the model to generate worse output and the reason why wouldn't really be apparent because it still just looks like \"apple\" to the user.marclove commented last weekJul 14, 2023In the project you linked, the #'...' syntax seems to be an artifact of Clojure:Ah, fair enough. It seems like the Rust enbf crate conforms to that ENBF tester for what it's worth.Although even with this 1-char implementation, in cases where one or more longer tokens are uniquely determined by the grammar [...]Isn't this more of a problem than it might seem at first glance because models are trained with certain combinations of tokens? So causing the model to generate a,p,p,l,e piecemeal would likely cause the model to generate worse output and the reason why wouldn't really be apparent because it still just looks like \"apple\" to the user.If you're constraining your output based on a grammar, isn't violating the grammar the worst possible output? At least in the use cases I can think of, if I'm constraining on grammar, that's my first priority; qualitative measures separate from that are secondary.Thanks for the work, @ejones. Looking forward to seeing this merged.1lin72h reacted with eyes emojiCollaboratorKerfuffleV2 commented last weekJul 15, 2023If you're constraining your output based on a grammar, isn't violating the grammar the worst possible output?It depends. That's certainly true sometimes, but unless the cons are clearly documented/apparent then users also might use grammar sampling to direct responses in the direction they prefer without necessarily understanding the tradeoff.if I'm constraining on grammar, that's my first priority; qualitative measures separate from that are secondary.I'd say it depends again, even if sticking to the grammar is paramount you still have to end up with a result with a quality level that's worth using for your application.Anyway, I want to be clear, I'm not opposing this pull or saying it shouldn't be merged or anything like that. My motivation for bringing up that point is in interests of improving llama.cpp either by considering/exploring other approaches that may not involve these tradeoffs or ensuring they're documented when they exist.I'm not just being negative/contrary.2lin72h and Rybens92 reacted with eyes emojiCollaboratorAuthorejones commented 4 days agoJul 18, 2023causing the model to generate a,p,p,l,e piecemeal would likely cause the model to generate worse output and the reason why wouldn't really be apparent because it still just looks like \"apple\" to the userYes, I agree. I think the instructions and examples in the prompt can reduce the likelihood of this, but it is a problem. Maybe I should revisit the 1-char assumption.3lin72h, KerfuffleV2, and Rybens92 reacted with thumbs up emojiejones added 2 commits 3 days agoJuly 18, 2023 22:34add inverse char ranges8d37755only sample full tokens (no peeking or truncation)c047e8aCollaboratorAuthorejones commented yesterdayJul 21, 2023@wanicca @KerfuffleV2 @ggerganov the latest update restricts sampling to complete token matches, removing the 1-char peeking and token truncation.I noticed it's still possible for the model to inadvertently split up tokens, as it may select a prefix of another token where specific sequences are expected (e.g., selecting the \"a\" or \"b\" tokens at \"apple\" | \"banana\"). There's probably a further improvement to select the longest matching token in such cases, or something.4KerfuffleV2, jeswin, marksteward, and lin72h reacted with thumbs up emoji5PapersAnon, Okabintaro, Rybens92, mudler, and lin72h reacted with hooray emojillama : minor style changes \u202611315b1ggerganov approved these changes yesterdayJul 21, 2023View reviewed changesOwnerggerganov left a comment \u2022editedGreat stuff! Looking forward to playing with thisMerge it when you wish15kvey, wokkaflokka, SalvatoreT, fermuch, berezovskyi, Emily, lin72h, esquire900, nikshepsvn, SommerEngineering, and 5 more reacted with rocket emojigithub-actions bot mentioned this pull request 4 hours agoJul 22, 2023Hacker News Daily Top 30 @2023-07-22 meixger/hackernews-daily#307Openxueyuanl mentioned this pull request 1 hour agoJul 22, 2023Daily Hacker News 22-07-2023 xueyuanl/daily-hackernews#1048OpenSign up for free to join this conversation on GitHub. Already have an account? Sign in to commentReviewershoward0suhoward0su left review commentsSlyEchoSlyEcho left review commentsggerganovggerganov approved these changesAssigneesejonesLabelsenhancementNew feature or requestgeneration qualityQuality of model outputhigh priorityVery important issueProjectsggml : roadmapStatus: In ProgressMilestoneNo milestoneDevelopmentSuccessfully merging this pull request may close these issues.None yet17 participantsFooter\u00a9 2023 GitHub, Inc.Footer navigationTermsPrivacySecurityStatusDocsContact GitHubPricingAPITrainingBlogAbout",
    "summary": "- The post introduces a new feature called \"grammar-based sampling\" in the Llama software.\n- The feature adds an API that takes a serialized context-free grammar to guide and constrain sampling.\n- This feature allows users to specify grammars for generating different types of data, such as chess moves, arithmetic expressions, JSON, and more.",
    "hn_title": "Llama: Add grammar-based sampling",
    "original_title": "Llama: Add grammar-based sampling",
    "score": 329,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginLlama: Add grammar-based sampling (github.com/ggerganov)329 points by davepeck 12 hours ago | hide | past | favorite | 88 commentssimonw 11 hours ago | next [\u2013]Here's my understanding of how this works (please someone correct me if I'm getting this wrong).Language models emit tokens one at a time, starting with the prompt that you give them.If you have a conversation with an LLM, effectively you can think of that as you giving it a sequence of tokens, then it generates some, then you generate more and so-on.This grammar trick effectively takes advantage of this by giving you much more finely grained control over the tokens. So you can do things like this:  Give me the address of the  White House as JSON:    {\"street\": \"Then the LLM can return:  1600 Pennsylvania Ave NW\"The moment you see that closing double quote, you take over again and inject:  \",  \"City\": \"It fills in:  Washington, DC\"And so on.But because this is all based on a grammar, you can do way more with it than just JSON.I saw a brilliant suggestion relating to this on Twitter a while ago:> @OpenAI should add an API argument allowing passing up a deterministic context free grammar.> [...]> While I think DCFL is what you want here in the short term, the really best thing is passing up a small WASM binary that simply is the sampler.> Allow a user to pass up a few KB of WASM binary and give it a few megabytes of RAM to run. Would enable next level LLM superpowers.https://twitter.com/grantslatton/status/1637692033115762688replyjiggawatts 11 hours ago | parent | next [\u2013]Not just that: the LLM outputs not individual tokens, but a weighted recommendation. The most probable (\u201cbest\u201d) token has the highest weight, but there may be many alternatives including JSON symbols like quote characters.The \u201ctemperature\u201d setting adjusts how likely it is that an output token is chosen that is not the top-rated option. That prevents repetitive output.Forcing an LLM to obey a grammar is mostly about filtering the list before the token choice is made. There may still be a random element controlled by the temperature!A more advanced feature not commonly used is to also enable back-tracking if the AI gets stuck and can\u2019t produce a valid output.replycontravariant 10 hours ago | root | parent | next [\u2013]> A more advanced feature not commonly used is to also enable back-tracking if the AI gets stuck and can\u2019t produce a valid output.Technically that part is mandatory if you don't just want it to produce an output but to make it produce an output that correctly matches the temperature (i.e. one that you could have gotten by randomly sampling the LLM until you got a correct one). Randomly picking the next tokens that isn't grammatically incorrect works but oversamples paths where most of the options are invalid. The ultimate example of this is that it can get stuck at a branch with probability 0.From a probabilistic standpoint what you'd need to do is not just make it backtrack but make it keep generating until it generates a grammatically correct output in one go.Maybe there is something clever that can be done to avoid regenerating from the start? What you'd need to achieve is that a token that has a x% probability of leading to an incorrect output also has x% probability to be erased.replynewhouseb 9 hours ago | root | parent | next [\u2013]The way LLMs work is they output probabilities for every _token_, so you don't really need to backtrack you can just always pick a token that matches the provided grammar.That said, you might want to do something like (backtracking) beam-search which uses various heuristics to simultaneously explore multiple different paths because the semantic information may not be front-loaded, i.e. let's say we had a grammar that had a key \"healthy\" with values \"very_unhealthy\" or \"moderately_healthy.\" For broccoli, the LLM might intend to say \"very_healthy\" and choose \"very\" but then be pigeonholed into saying \"very_unhealthy\" because it's the only valid completion according to the grammar.That said, there are a lot of shortcuts you can take to make this fairly efficient thanks to the autoregressive nature of (most modern) LLMs. You only need to regenerate / recompute from where you want to backtrack from.replyVetch 8 hours ago | root | parent | next [\u2013]Whether or not backtracking is needed is really down to the grammar's ambiguity.The auto-regressive nature of LLMs is actually something that counts against them, at least as some tell it. Although, really, the root problem is generating autoregressively from LLMs precludes planning ahead while also lacking any iterative refinement stage.Backtracking, look-ahead, early failure pruning and staged generation are all very useful for fitting both concepts (refinement and planning ahead) in an auto-regressive generation framework.replyjiggawatts 9 hours ago | root | parent | prev | next [\u2013]This is what Google Mind is working on: treating the output of LLMs as tree to be searched instead of just linearly outputting tokens in a \"greedy\" manner and hoping for the best.Apparently GPT-4 gets a lot of its quality from generating many alternatives (16?) and then picking the best one, but this is 16x as much computer power.A clever tree search (which itself could be a neural net!) could improve the efficiency of this many-fold while simultaneously improving the quality by a huge factor as well.replycontravariant 9 hours ago | root | parent | next [\u2013]Arguably a '1 token at a time' model is itself a tree search, so it's more of a perspective than anything. It's really when you start pruning this tree that this distinction becomes interesting. And of course treating the tree as an explicit object may allow the model to do interesting stuff like jumping to a different branch entirely (deletions insertions etc.).Generating 16 alternatives and picking the best one only makes sense to me if your standard for picking one is orthogonal to the model itself, if you just pick the one that your model deems the most likely you've just figure out a very crude and expensive way to lower the temperature.replyZacharias030 35 minutes ago | root | parent | next [\u2013]Isn\u2019t that the whole point of using RL with these things, that the chain of likeliest tokens one by one doesn\u2019t lead to the best overall generation by the model (according to the model itself)? I believe that is one reason the rlhf is using rl and not supervised learning; credit assignment for a good sentence to each token is not trivial after all.replyVetch 7 hours ago | root | parent | prev | next [\u2013]That is stretching arguably too far. If you are taking 1 sample path, you are not in any meaningful sense searching a tree. In the context of sampling a probability distribution, which is what LLMs do in effect, there is extra depth to this. Any random response need not be representative of what the model \"thinks\". And maybe counter-intuitive to some but the most likely generation might actually be unrepresentative as well.Drawing lots of samples and then marginalizing (as a kind of vote) is methodologically more principled where appropriate. Constraining generation according to some gating function, continually redrawing samples, can be used to significantly reduce error rates at the cost of longer generation times.LLMs are not being used to their full potential because it is too costly to do so.replyjoaogui1 7 hours ago | root | parent | prev | next [\u2013]When we talk about tree search we allow for backtracking, so if a node has 3 children all 3 will be explored generally, or at least a subsample of the children will be, in LLM sampling you generally pick a single token/child and then just go on with that until the end of the generation.If DeepMind is indeed doing something similar to AlphaZero to language modelling one would expect they would generate multiple \"rollouts\" from the current context and then use some kind of function/network to predict which next token will lead you to the best final generation and then output that token. How to do all of that using a sensible amount of compute is what remains to be seenreplytwo_in_one 5 hours ago | root | parent | next [\u2013]Talking about efficiency. LLMs are often more efficient running batches. Sort of several lines at a time. Which means we can at some point branch new lines and run them in parallel. It will be more efficient than running one after another. More over, with some tricks we can share the 'history' instead of recomputing. This requires going deep into the model though.replyZacharias030 31 minutes ago | root | parent | next [\u2013]What tricks are you thinking about? Sharing the history still means you need to save the state of the autoregressive transformer, which is usually prohibitively large?replyaljungberg 49 minutes ago | root | parent | prev | next [\u2013]We already do tree searches: see beam search and \u201cbest of\u201d search. Arguable if it is a \u201cclever\u201d tree search but it\u2019s not entirely unguided either since you prune your tree based on factors like perplexity which is a measure of how probable/plausible the model rates a branch as it stands so far.In beam search you might keep the top n branches at each token generation step. Best of is in a sense the same but you take many steps using regular sampling at a time before pruning.replyrefulgentis 9 hours ago | root | parent | prev | next [\u2013]This isn't true, it's a telephone game version of \"it's a mixture of experts model\" that was used to explain the impossible claim that \"it's a 1 trillion parameter\" in fall 22replyjiggawatts 8 hours ago | root | parent | next [\u2013]Apparently it's both. There's a bunch of experts, and then those output many alternatives, of which you see the \"best\" one as selected by a final quality-check neural net.replyakomtu 8 hours ago | root | parent | prev | next [\u2013]Well, if LLM suggests \"moves\", and an Expert Model judges the whole output, then combining the two with a tree search suspiciously resembles the AlphaGo idea.replybrucethemoose2 10 hours ago | root | parent | prev | next [\u2013]> Maybe there is something clever that can be done to avoid regenerating from the start? What you'd need to achieve is that a token that has a x% probability of leading to an incorrect output also has x% probability to be erased.Like giving the llm a backspace token? There is a paper related to this:https://news.ycombinator.com/item?id=36425375replycontravariant 10 hours ago | root | parent | next [\u2013]I mean you're going to need to include a probability to backtrack one way or another, but simply having a backtrack character seems more like a trick to make fitting the model easier than a way to make constraining it more accurate.Simply having the probability to backtrack does turn the whole generation process into a ergodic Markov chain though, so you might be able to use something like MCMC to make it work. Technically those only start sampling the distribution eventually but picking the first or nth full output might be good enough for all practical purposes. Especially at low temperatures where there aren't many reasonable options in the first place.replySCHiM 10 hours ago | parent | prev | next [\u2013]No, the way it works is that the current output + potential next tokens to be sampled are checked with the grammar. All potential tokens that don't match are removed. Then, with the list of valid tokens left, normal sampling strategies are used.replypshc 11 hours ago | parent | prev | next [\u2013]I don't think this is correct; previously you could already control output by reading tokens one at a time from the LLM until you hit a stop character.My take from the grammar-based sampling PR is that you ask llama.cpp to constrain the next output token, to a restricted set of possible tokens, using the grammar.replysimonw 11 hours ago | root | parent | next [\u2013]Right, which is the same idea - it's just that the code in llama.cpp is running your grammar as part of its token generation decisions as opposed to pausing and waiting for your other code to pick the next token.(I'm trying for a very high level explanation here.)replyswyx 1 hour ago | root | parent | prev | next [\u2013]you could also always specify the logit bias parameter in openai apisreplythomasahle 10 hours ago | parent | prev | next [\u2013]Another detailed description of how to do this: https://github.com/normal-computing/outlines/pull/131That's one of the developers of the Outlines library, another cool LLM workflow library.replyfarissbahi 9 hours ago | root | parent | next [\u2013]There's a paper as well. :) https://arxiv.org/pdf/2307.09702.pdfreplyIAmNotACellist 11 hours ago | parent | prev | next [\u2013]I'm struggling to understand what he's talking about. Starting with \"passing up,\" did he invent this terminology? The only input you have to an LLM is the prompt, which gets tokenized. And if you were to send DCFG rules or a compiled version of it as part of the request, how would that fundamentally alter the way that the tokens are predicted? If the model predicts something that doesn't conform to the grammar you require, is he proposing re-prompting until it gets it right?replybaobabKoodaa 10 hours ago | root | parent | next [\u2013]You have more inputs to an LLM than just the prompt. For example, people commonly pass parameters which control the sampling of tokens.Implementing grammar based sampling does NOT require \"re-prompting until it gets it right\". Imagine a point in time when the LLM is generating some particular token. Which token will it produce? To decide that, it evaluates and assigns a score to each potential token. Then it chooses one of these options based on some rules. Rules could be as simple as \"pick the token with the highest score\". That is called a greedy strategy. Usually more complex strategies are used and they typically have some randomness. That is called sampling. You can imagine a grammar based sampling strategy to force specific tokens at specific positions in the output, for example, to close a bracket in json.replysimonw 10 hours ago | root | parent | prev | next [\u2013]I think he's proposing this kind of API:  POST /openai/gpt4  {    \"prompt\": \"The address of the White House\",    \"sampler_wasm\": \"base64 encoded WASM binary blob here\"  }That WASM would be a program that you write yourself that is run as part of the tokenizer - so it could be a grammar but it could be anything else too.It's WASM which means it can be safely and performantly run in a sandbox by the OpenAI servers as part of their execution of your prompt.replynewhouseb 9 hours ago | root | parent | next [\u2013]I think you mean \"run as part of the sampler,\" the tokenizer (and tokenization) is fixed for a given model. The sampler blob would basically:1. Modify the output token probabilities to fit any arbitrary use case2. Perhaps do trigger some sort of backtracking / beam-search(I'm not Grant but we've chatted on twitter and built similar things)replysimonw 9 hours ago | root | parent | next [\u2013]Yes, I meant sampler, not tokenizer.replylyjackal 10 hours ago | root | parent | prev | next [\u2013]The model returns probabilities across the full set of tokens. This restricts the tokens to those that conform to the grammar, and samples from thosereplyeightysixfour 11 hours ago | parent | prev | next [\u2013]Isn\u2019t this what Microsoft Guidance does?https://github.com/microsoft/guidancereplyttul 9 hours ago | root | parent | next [\u2013]I read the code. Guidance seems designed to work well with OpenAI's chat completion API. When you ask Guidance to choose from a set of options, it breaks the list into a tree of tokens and then walks this tree, providing the next set of possible tokens in the logit_bias parameter with value set to +100.For example, suppose that you specify this as your Guidance \"program\" and suppose (for sake of simplicity) that the token for \"lea\" is 1300, the token for \"ther\" is 1500, and the token for \"ves\" is 5300: \"armor\": \"{{#select 'armor'}}leather{{or}}leaves{{/select}}\",Guidance will send OpenAI a chat completion starting with \"armor\": \"... providing a logit_bias map {\"1300\": \"100\"}. This bias forces the model to choose \"lea\" as the next token. Following this call, we have the prefix \"armor\": \"lea... and now Guidance calls chat completion again setting the logit_bias map to {\"1500\": \"100\", \"5300\": \"100\"} to indicate that the tokens for \"ther\" or \"ves\" are equally probable and really the only tokens the model is allowed to select between, unless some other token is maximally probable given the context. OpenAI now replies with token \"1500\" (let's say) and Guidance completes the string as follows: \"armor\": \"leather... because \"ther\" is represented by token number 1500. Guidance then tacks on the closing quote and other stuff specified by the user: \"armor\": \"leather\",... and it sets the value of \"armor\" to \"leather\" so that you can use that value later in your code if you wish to. Guidance is pretty powerful, but I find the grammar hard to work with. I think the idea of being able to upload a bit of code or a context-free grammar to guide the model is super smart.https://github.com/microsoft/guidance/blob/d2c5e3cbb730e337b...replymmoskal 9 hours ago | root | parent | next [\u2013]OTOH, AFAIK when running a model locally Guidance does something really similar to what OP is doing.replysimonw 9 hours ago | root | parent | prev | next [\u2013]Thank you! I finally get what Guidance is doing now.replybarbazoo 10 hours ago | parent | prev | next [\u2013]Thank you for laying it out like that.replyanothernewdude 10 hours ago | parent | prev | next [\u2013]So does this mean I can detect \"Sorry\" at the start of a response and prevent it?replysvc0 11 hours ago | prev | next [\u2013]I think it should be noted that this enforces grammatical constraints on the model's generated text, but it doesn't do anything to properly align the content. This would be useful if you needed to ensure a server delivered well-formatted JSON, but it I suspect it wont solve a lot of alignment issues with current language generation. For example current iterations of Llama and GPT often do not label markdown code-blocks correctly. Using grammar-based sampling, you could enforce that it labels code blocks but you couldn't enforce correct labeling since this is context-dependent. You also couldn't invent a novel domain-specific language without aligning against that language and expect good output.replynewhouseb 9 hours ago | parent | next [\u2013]Also important to call out that anytime you have a freeform string it's pretty much an open invitation for the LLM to go completely haywire and run off into all sorts of weird tangents. So these methods are best used with other heuristics to bias sampling once you get to free-form text territory (i.e. a repetition penalty etc)replybrucethemoose2 10 hours ago | parent | prev | next [\u2013]But since its llama, some examples could be trained into a lora.I can imagine a system where, for instance, a markdown lora and a markdown grammar file can be hotswapped in and out.replyburke 9 hours ago | prev | next [\u2013]I implemented this for PyTorch too at https://github.com/Shopify/torch-grammar. I have a hacked version of text-generation-inference that uses it\u2014happy to share that if it\u2019s useful to anyone.replybrucethemoose2 11 hours ago | prev | next [\u2013]This grammar \"library\" was cited as an example of what the format could look like:.https://github.com/antlr/grammars-v4There is everything from assembly and C++ to glsl and scripting languages, arithmetic, games, and other weird formats like freedesktop shortcuts, llvm ir or verilog.replyttul 9 hours ago | parent | next [\u2013]A convenience feature in any inference API would be to specify a shortcut to a standardized grammar such as HTML, JSON, Python, etc. It is frankly strange to me that OpenAI have not already done this, considering the obvious effort they undertook to fine-tune the Code Interpreter model.replyRossBencina 6 hours ago | parent | prev | next [\u2013]It would be awesome if they supported ANLTR4 grammar syntax. Such a great tool.replyspion 12 hours ago | prev | next [\u2013]Specifically for multi-choice string enums (essentially dropdowns), I wonder if this would work better if the full (joint/product) probability given the logits is considered when picking the final choice, rather than using a greedy algorithm. This will favor the right choice, as opposed to e.g. one of the choices that contain the most common start token - if a start token are shared among many items in the list.Of course the probability needs to be adjusted once a subset of the logits goes to zero so it actually makes sense...replykarmasimida 2 hours ago | prev | next [\u2013]This is great and all.But LLM's are usually very good at following grammars. I rarely see LLM generating code that is OOD. Ofc, this is only true for popular language (JSON/Python/Java, etc), I can see how this is handy for more niche and in house DSL.You still need quite a lot of prompt engineering to get desired outputs, this just add another layer of output verification IMO. But does it really save much as comparing to get the output then parse and reject the output that doesn't follow the grammar? Might be debateable.But great work regardless.reply1024core 11 hours ago | prev | next [\u2013]Can someone ELI5 what's going on here? I'm reasonably familiar with LLMs, but I can't quite grok what Georgi is doing here and why it's so exciting for some.replytylerhou 10 hours ago | parent | next [\u2013]An LLM does not generate \"the next token\" - from an input text, it generates a vector of probabilities where each slot in the vector corresponds to a token. The value in a token's slot is (approximately) the probability that that particular token might appear next in the text.Programs like ChatGPT \"interpret\" that vector of probabilities to generate text by selecting (sampling) one of the top tokens. But sometimes this is too flexible -- for example, ChatGPT might generate invalid JSON when you want JSON output because it chose a token that does not conform to the JSON grammar.A way to \"force\" an LLM to generate e.g. JSON is to change the sampling process. Instead of choosing any top token, we first filter the tokens to just those that conform to the JSON grammar. Then, we sample one of the top tokens from that subset.replybryan0 9 hours ago | root | parent | next [\u2013]And to build on this, take a look at the code change. Currently in llama.cpp there are many techniques for sampling the next token:llama_sample_token_greedy - just take the top probabilityllama_sample_top_k - sample only from the top k probabilitiesetc ...this code change adds a new sample:llama_sample_grammar - sample only from tokens which match the grammarreplydave1010uk 3 hours ago | root | parent | next [\u2013]If the performance was ok, is there any reason why a sampler couldn't call an API or use a separate fine tuned model?replyttul 9 hours ago | root | parent | prev | next [\u2013]And given that the inference code has access to the entire vector, it's the logical place to put this filtering... OpenAI and other LLM APIs probably don't want to return the entire token probability vector to the user because it's a lot of data. That being said, it wouldn't surprise me if Microsoft has such access as part of their deal because of the obviously superior position this puts them in vs. regular API customers.replymodeless 11 hours ago | parent | prev | next [\u2013]If you ask an LLM to generate JSON or another language that has a grammar, it will sometimes produce invalid syntax. This pull request constrains the LLM so that it can only output valid syntax according to whatever grammar you supply. It's a modification to the sampling procedure.What is the sampling procedure? Well, the way an LLM generates text is one token (short sequence of characters) at a time. First the giant neural net assigns a probability to every possible token (this is the hard part). Then a sampling procedure uses the probabilities to pick one of the tokens, and the process repeats.The sampling procedure is not a neural net and can be modified in many different ways. You might think that the sampling procedure should always simply pick the token with the highest probability (greedy sampling). You can do that, but it's usually better to pick at random weighted by the probabilities. This gives more diversity and is less likely to get stuck in loops. But this means that literally any token with nonzero probability might get picked, so you can see how this might lead to invalid JSON being generated sometimes. This pull request zeros out the probabilities of all the tokens that wouldn't be valid according to your grammar, so they can't be picked.BTW there are lots of other interesting modifications to the sampling process you could consider. For example, maybe you can see that in the process of sampling tokens one after the other you might paint yourself into a corner and end up with no good options to choose from. So maybe it makes sense to allow backtracking. In fact, maybe at each sampling step we can consider multiple options, making a tree of possible outputs, and at the end we can pick the path through the tree with the highest overall probability. Of course we can't consider every option; it would be a complete tree with a branching factor of the number of possible tokens, which would grow exponentially. Let's prune the tree at each step and only consider the top, say, five paths we've seen so far. This is called \"beam search\". It's not normally used for LLMs because the neural net that generates the probabilities is very expensive to run and multiplying that cost by a factor of e.g. five is unpalatable. But it can be done, and produces somewhat better results. You could also consider using MCTS like chess engines do.replyastrange 11 hours ago | root | parent | next [\u2013]This is a sort of modern version of https://wiki.c2.com/?AlternateHardAndSoftLayers, one of the most useful software patterns.replyturnsout 8 hours ago | root | parent | next [\u2013]Say more\u2026 I read the link, and it seems to be advocating for replacing specific business logic with a generic code interpreter?reply6gvONxR4sf7o 11 hours ago | parent | prev | next [\u2013]LLMs are happy to generate arbitrary strings. You might want it to spit out something along the lines of \"Alice: 42\" and then it spits out \"hi, i'm helpful and Alice is exactly forty two, as far as I can tell, but I'm just a language model.\"So you give it a grammar that says the response has to be an uppercase letter followed by lowercase letters, then a colon, then a space, then digits, then it's done. Now, when it looks for that first token, it will only consider tokens that are compatible with that pattern. Then it'll continue with only next tokens that are compatible with the next parts of the pattern.These grammars do that with a flexible and useful kind of pattern.replysimonw 11 hours ago | parent | prev | next [\u2013]See my comment here https://news.ycombinator.com/item?id=36820884replyversion_five 12 hours ago | prev | next [\u2013]I'm interested in this and I'm going to try incorporating it into something I'm doing. That said, I feel like this could be one of those Bitter Lesson situations where it's not the most effective approach in anything but the very short term: http://www.incompleteideas.net/IncIdeas/BitterLesson.htmlreplywoah 11 hours ago | parent | next [\u2013]Not an expert at all, but I believe that OpenAI uses this in some of their GPT apis which are meant for programmatic use. I've seen it theorized that offloading the rote grammar stuff to a simple process that is meant for it lets the LLM use it's \"brainpower\" on the complicated stuff more effectively. No idea if this is true.replyTechBro8615 11 hours ago | root | parent | next [\u2013]It makes sense to my uninformed intuition, which is that a strict grammar reduces the search space for the token generation and so the AI can eliminate possibilities that would otherwise be ambiguous.replyDer_Einzige 11 hours ago | parent | prev | next [\u2013]It may be a stop-gap, but its an important one as it is not obvious that LLMs in the next few years will \"organically\" solve their issues with generating text with constraints.replysandkoan 10 hours ago | prev | next [\u2013]Also using a similar method: https://github.com/automorphic-ai/trexPlayground: https://automorphic.ai/playgroundreplypainted-now 11 hours ago | prev | next [\u2013]Can anyone recommend some paper or overview on how \"sampling\" / \"decoding\" is done in the e2e neural network age? I know how decoding was done for machine translation and speech recognition back in the HMM times (i.e. https://en.wikipedia.org/wiki/Viterbi_algorithm and https://en.wikipedia.org/wiki/Beam_search). These days I get the impression people just do \"greedy\" - but I don't really know. Any recommendations for info on that topic?Edit: Forgot Viterbireplyspion 11 hours ago | parent | next [\u2013]Its greedy and random :) Instead of a paper, I would recommend the algorithms of most LMM implementations (rwkv.cpp has a relatively clean implementation in python https://github.com/saharNooby/rwkv.cpp/blob/master/rwkv/samp...)replypainted-now 11 hours ago | root | parent | next [\u2013]I guess I need to sit down and study this stuff in more detail, but do I understand correctly that the code you shared makes the decisions for each position independently? I am just astonished that this produces any coherent output. Also it is not clear to me how the length of the output sequence is determined.replypizza 11 hours ago | root | parent | next [\u2013]Once the stop token is likeliestreplyjanalsncm 11 hours ago | parent | prev | next [\u2013]Just reading through the GPT4 documentation it doesn\u2019t seem like there\u2019s a ton of difference with what you\u2019ve mentioned.https://platform.openai.com/docs/api-reference/completions/c...Of course we now know that GPT4 is a Mixture of Experts, so under the hood they\u2019re parallelizing computation. They also include a way to modify the logits with presence/frequency penalty terms.replyIcko 10 hours ago | prev | next [\u2013]How is this different from Guidance and LMQL?replyjameshart 6 hours ago | parent | next [\u2013]Looks like a tool Guidance could use to make better use of the sampling from a local llama model.replyQuantumG 10 hours ago | prev | next [\u2013]So, umm, if you want to walk BNF and emit likely tokens you can do that without any \"machine learning\" or whatever you want to call it. So what is being added here? Training to tie the prompt to the output?replysp332 10 hours ago | parent | next [\u2013]The difference is in the word \u201clikely\u201d. You can put unstructured data in the prompt and get structured data out. You could put in the beginning of a list and ask for a continuation.replyQuantumG 9 hours ago | root | parent | next [\u2013]I get thatreplyDer_Einzige 11 hours ago | prev | next [\u2013]I am in love with this, I tried my hand at building a Constrained Text Generation Studio (https://github.com/Hellisotherpeople/Constrained-Text-Genera...), and got published at COLING 2022 for my paper on it (https://paperswithcode.com/paper/most-language-models-can-be...), but I always knew that something like this or the related idea enumerated in this paper: https://arxiv.org/abs/2306.03081 was the way to go.I will have to think about how I can build grammars that force things like syllable counts or syntactic rules. Current LLMs do very poorly on those kinds of tasks due to the tokenization schemes...replysp332 10 hours ago | parent | next [\u2013]I was surprised, but Nous Hermes does a half decent job at writing haikus.replyilaksh 11 hours ago | prev | next [\u2013]Has anyone tested FreeWilly2 (the new Llama2 fine-tune released today by Stable Foundation) on code generation?replyahupp 9 hours ago | prev | next [\u2013]Interesting that the second commentor is Tobias L\u00fctke, CEO of Shopify.reply0xDEF 9 hours ago | parent | next [\u2013]Also interesting how Shopify is making a lot of moves in this space using both the OpenAI APIs and using self-hosted models.replylachlan_gray 9 hours ago | prev | next [\u2013]Something I\u2019m wondering lately is if you are generating tokens fast enough, is restricting the logits actually worth it computationally? If tokens are cheap enough it might be more efficient to validate/discard them as they come rather than place constraints on how they come out. I don\u2019t know how this one works, but the sampling or renormalizing scheme would cost something too right?replymmoskal 9 hours ago | parent | next [\u2013]There is at least 6 orders of magnitude difference in computation cost of computing a token (pass through a multi-B model) and doing a single step of a program. Even if your validation is really naive, it's hard to beat 6 orders of magnitude.So no, you're not generating tokens fast enough.replybavarianbob 11 hours ago | prev | next [\u2013]Could someone help me with context? I'm OOTL and don't understand what is going on here.replybrucethemoose2 10 hours ago | parent | next [\u2013]This can constrain an LLM's output to an arbitrary grammar/format as it is generated, rather than asking the model to output a specific format and hoping it outputs something valid.replyTostino 8 hours ago | root | parent | next [\u2013]This is important for \"smaller\" models, because you don't have to waste some of the potential \"intelligence\" (parameter space) on training it how to generate valid JSON or YAML or anything like that.replybrucethemoose2 6 hours ago | root | parent | next [\u2013]You still do... The model has to know JSON and YAML, its just more reliable when the generation is enforced by grammarreplyTostino 5 hours ago | root | parent | next [\u2013]Right, but there is a big difference between \u201dgenerally knows what JSON looks like and gets it right most of the time\" and \"generates perfect JSON every time\".replymeepmorp 11 hours ago | prev | next [\u2013]Does anyone know Japanese well enough to comment on the output from the Japanese example?replyvore 11 hours ago | parent | next [\u2013]It is vaguely Japanese, I guess, but pretty incoherent: 1. What is the purpose? 2. Remember the customer 3. About the customer [incomplete sentence?]replybrucethemoose2 10 hours ago | parent | prev | next [\u2013]Note that there are actual Japanese llama finetunes that would be much more coherent with these grammar constraintsreplymoffkalast 11 hours ago | prev [\u2013]Ah finally, this was discussed a lot and is well overdue. Remains to be seen how well the models will adapt to this new constraint, though the demo seems promising.replyec109685 11 hours ago | parent [\u2013]Isn\u2019t this approach forcing the LLM to adapt? E.g. it is throwing tokens away that don\u2019t match the grammar.replymoffkalast 11 hours ago | root | parent [\u2013]Well the grammar will be correct as enforced by the sampler, but the content it's filled with could be anything at all. Sort of how when you change the prompt template the output can be garbage for some models. I haven't tried it out yet myself, but apparently even OpenAI's implementation of this exact principle on their API still has function hallucination issues even with GPT 4.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- \"Llama: Add grammar-based sampling\" is a new feature that allows for more control over the output of language models like GPT.\n- The feature uses a grammar to constrain the tokens generated by the model, resulting in more finely-grained control over the output.\n- The addition of grammar-based sampling can help ensure that the generated text adheres to specific syntax or format requirements."
  },
  {
    "id": 36813086,
    "timestamp": 1689943094,
    "title": "Show HN: Primo \u2013 a visual CMS with Svelte blocks, a code editor, & SSG",
    "url": "https://primocms.org",
    "hn_url": "http://news.ycombinator.com/item?id=36813086",
    "content": "primoStar on GithubAboutDocsThemesWhite GloveNewCloudPrimo is a visual CMS that makes it a blast to build pages, manage content, and edit code - one block at a time.Try itGet StartedWatch the introductionThe modern monolithic CMSPrimo combines delightful content management with the power of modern developmentDrag-n-drop page buildingBuild your site's pages by dragging and dropping your directly blocks onto the page, unencumbered by overwhelming design options.Visual content editingUpdate your text, images, and links directly on the page or open up the Fields view to manage your content from a structured view.Integrated developmentAccess each block's code with a click - right from your browser. And since each block is a Svelte component, there's no limit to what you can make.Static SitesYour websites are secure, scalable to millions, and fast-loading - no fancy plugins necessary.Real-time collaborationInvite any number of collaborators as developers or content editors and edit your pages together.Multisite to the maxCreate an unlimited number of websites on a single server and start new sites in seconds.Deploy to GithubDeploy your site to a Github repository. From there you can easily deploy it to any web host.ThemesHit the ground running with one of Primo's free themes and customize it in seconds using CSS variables.Primo LibraryAccess a growing library of pre-built blocks which automatically adapt to your site's design.Spin up speedy, secure, scalable static sites in seconds.Set up your own Primo server in under 5 minutes and manage unlimited sites with ease. Don't want to manage your own server? Try Primo Cloud for free.Self-hostPrimo CloudFrequently Asked QuestionsIs Primo open-core? VC-funded open source? Side project?Primo is MIT licensed, under full-time development, and is in the process of moving under a nonprofit organization. Any funds generated from White Glove and Cloud will go towards funding further development, in the same vein as Ghost CMS.How does this compare to WordPress?Can I use Primo with SvelteKit? Next, Nuxt, Astro?How far along is Primo's development?How can I contribute or donate?How much will it cost to host or use Primo?Hear about future updates, including:Using it headless alongside SvelteKit, NextJS, etc.Design fields to give content editors predefined style options.Cloud functions for writing backend code from Primo.SubscribeChangelog",
    "summary": "- Primo is a visual CMS that allows you to easily build pages and manage content using blocks.\n- It combines content management with the power of modern development and offers features like drag-and-drop page building and visual content editing.\n- Primo also allows for real-time collaboration, deployment to Github, and the option to self-host or use Primo Cloud for free.",
    "hn_title": "Show HN: Primo \u2013 a visual CMS with Svelte blocks, a code editor, and SSG",
    "original_title": "Show HN: Primo \u2013 a visual CMS with Svelte blocks, a code editor, and SSG",
    "score": 313,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginShow HN: Primo \u2013 a visual CMS with Svelte blocks, a code editor, and SSG (primocms.org)313 points by mmmateo 21 hours ago | hide | past | favorite | 107 commentsnobleach 17 hours ago | next [\u2013]The drag-n-drop blocks/slices of content CMSes look cool in demos. As someone who has an in-house developed CMS editor just like this, it's a nightmare of constant updates. \"Can we right align text and turn it blue?\", \"sure we'll add more and more props to each block\". The actual content creators have a hard time using it effectively. So the results are almost always unsatisfactory. More training could possibly help but there's still a constant tradeoff between freedom and maintaining brand identity.A headless CMS in our case would be a better approach. Simply provide the content and let a few professional folks code it up to match designs. Not everyone has that luxury I realize - so there's definitely a place for this type of CMS. I'm just pointing out how it can go horribly wrong.replydid 16 hours ago | parent | next [\u2013]Context: I'm the creator an open source page builder in Ruby on Rails named Maglev (https://www.maglev.dev), pretty much similar to Primo (congrats for their product, looks amazing!).A couple of months, I used my own tool (Maglev) when revamping an e-commerce site of a client who didn't have a content management system to edit the marketing part of her site. So I sliced the site into editable \"Maglev\" sections/blocks. The result was great in terms of editing experience BUT a couple of months later after the launch, my client hired another marketing person with HTML/CSS \"skills\" (I'd say 101 HMTL/CSS level). And I had a hard time to convince her that it was a bad idea to write HTML/CSS code herself but instead to let me (or another developer) write the missing sections she wanted.A solution would have been to add in Maglev some kind of dev editor like in Primo. However, based on my long experience, you really don't want your client to touch the HTML/CSS of your site. And I don't believe in the \"you break it, you pay for it\" mojo or at least this is not the kind of relationship I want with my clients.On a higher level, any kind of CMS has the same issue. For instance, I helped a company with a broken Webflow site and it was the typical issue: a designer built their site and later the marketing person tried to \"improve\" the UI and broke everything.replymmmateo 16 hours ago | root | parent | next [\u2013]> However, based on my long experience, you really don't want your client to touch the HTML/CSS of your site.Certainly, and in the same vein you don't want your client touching the design of the site. Clients can barely write good copy, much less make good design decisions. My freelance projects go a lot more smoothly now that I can hand off the site to the client knowing that they're restricted to adding/removing blocks and updating content (and that they can't see the 'open code' button).replyandrei_says_ 15 hours ago | root | parent | prev | next [\u2013]Thank you for Maglev - looks awesomereplyscientaster2 11 hours ago | parent | prev | next [\u2013]I'm building a GraphQL based headless CMS currently, ~2 months away from an official launch. It's currently wholly lacking official documentation but feel free to give the index page a peek and see if it's something you'd be interested in trying out!(or if you just have general feedback or learnings from your own experience, I'd love to hear that too!)https://brick-cms.com/replymmmateo 17 hours ago | parent | prev | next [\u2013]I definitely understand with the struggle to balance design freedom and brand identity (or good design). But wouldn't you still have the issue of content editors wanting to right align text and turn it blue regardless of the CMS you're using?replyimadj 15 hours ago | root | parent | next [\u2013]> But wouldn't you still have the issue of content editors wanting to right align text and turn it blue regardless of the CMS you're using?OP mentioned the ultimate solution in their comment, it's Headless CMS (provide content) + fully custom frontend.replyhoofhearted 9 hours ago | parent | prev | next [\u2013]How do you feel about a Shopify approach where you use a pre crafted template, and have developers make tweaks to it if you need further features?replyFireInsight 21 hours ago | prev | next [\u2013]Github: https://github.com/primocms/primoPrevious discussions: https://news.ycombinator.com/item?id=23820201 https://news.ycombinator.com/item?id=25301040Show HN with some text attached from what seems to be OPs alt account: https://news.ycombinator.com/item?id=36801101replyklaussilveira 20 hours ago | prev | next [\u2013]I wish there was something like this, but for serial dynamic content, like blog posts, reviews, etc. People are really attached to WP, but customization and themes are a nightmare.replygochi 17 hours ago | parent | next [\u2013]Take your pick https://jamstack.org/headless-cms/replymanuelmoreale 17 hours ago | parent | prev | next [\u2013]Not sure if this is what you\u2019re after but give https://getkirby.com/ a tryreplyAeolun 10 hours ago | root | parent | next [\u2013]That\u2019s a bit more expensive than I\u2019m open to for some random personal website.replylukeholder 9 hours ago | root | parent | next [\u2013]Try https://craftcms.comreplykykeonaut 20 hours ago | parent | prev | next [\u2013]I think people are attached to Wordpress for the same reason we are attached to Javascript. At the time, it was one of the only ways of easily creating a blog.The problem with Wordpress is that once you need to do something outside of the norm then all of the sudden you need deep knowledge of Wordpress's inner workings.replypc86 20 hours ago | root | parent | next [\u2013]There was never a time when WordPress was the only easy way for even a non-technical person to create a blog, they just did a great job marketing that that was the case.I spent a very brief time as a contributor to WP internals (not core by any means but a handful of contributions) and not only do you need a lot of internal knowledge to do anything outside of point-and-click, like you said, a lot of the core folks had never worked on any other large software projects, didn't do anything outside of WordPress, and had very little desire to make sure what they were doing was sound from a software engineering / code quality standpoint. It's a pretty great example of the big ball of mud / spaghetti code cliche.replyactionfromafar 20 hours ago | root | parent | next [\u2013]From a social standpoint, it was though. You could ask a lot of non-expert people for help on Wordpress and get it.replypc86 20 hours ago | root | parent | next [\u2013]That's exactly what I mean. They did a great job making people think that if you wanted a blog and weren't a programmer, WP was your only choice.replycodegeek 19 hours ago | root | parent | next [\u2013]Ok I will bite. What was an alternative to WordPress especially back then that actually was as easy to use as WP AND had the ecosystem of plugins that WP has. Focus on non technical users only who have no idea how to write code.reply_jal 18 hours ago | root | parent | next [\u2013]The main competitor was Movable Type.I recall there being several other also-rans, but am having trouble recalling names.replyeropple 15 hours ago | root | parent | next [\u2013]Movable Type was pretty great, but it also cost money. The open-source era of MT was brief and after its primary period of relevance.replychiefalchemist 19 hours ago | root | parent | prev | next [\u2013]You're correct. Alternatives were slim. But in retrospect, perhaps that was part of the problem? WP had zero incentive for clean code, QA, industry standards, etc. The more it grew, ironically the less it cared. The embedded base of site and dev as well as the plugin and theme ecosystem maintain the momentum forward, somehow.replystOneskull 3 hours ago | root | parent | prev | next [\u2013]wp can be the choice for an e-commerce site.. woocommerce is pretty good and hard to matchreplycivilitty 17 hours ago | root | parent | prev | next [\u2013]I don't think it was even the marketing but the product placement. I remember in the 2000s if you wanted hosting that wasn't a dedicated server, the scene was dominated almost entirely by CPanel with a one click installer for Wordpress.Once the plugin ecosystem sprung up around it, WP was off to the races.replymmmateo 20 hours ago | parent | prev | next [\u2013]Definitely possible in the future, although to keep the project focused I'd imagine using a plugin or fetching that content from a separate CMS tailor-made for that kind of content would be ideal.replyjordienr 18 hours ago | root | parent | next [\u2013]That\u2019s what I\u2019m building :)https://zendo.blogreplymmmateo 18 hours ago | root | parent | next [\u2013]This looks perfect! Just signed upreplydgudkov 18 hours ago | root | parent | prev | next [\u2013]Looks neat! Signed up.replyJiocus 15 hours ago | parent | prev | next [\u2013]Did you https://github.com/TryGhost/Ghost ?replycontravariant 20 hours ago | parent | prev | next [\u2013]That sounds like static content to me, what's wrong with just HTML?replyklaussilveira 20 hours ago | root | parent | next [\u2013]It's not really static. It grabs data from a database, or an API, and renders using entity-specific templates, both from a single entity perspective (post.php theme) and listing (search.php, index.php).What I mean is: having something like Primo that allows visual management of such dynamic blocks and themes would be nice, so Editors can just play around with the result of their content calls (which the CMS handles transparently, doesn't matter if a SQL query or an API call).replypc86 20 hours ago | root | parent | next [\u2013]That is static - none of it is based on user input so it can be compiled into a static HTML page every time you publish a new post or edit a page theme or anything. There's no reason the system needs to pull that 5 year old blog post from the database every time.replyjohnnyworker 19 hours ago | root | parent | next [\u2013]That depends on the desired features. E.g. if you have a tag cloud displayed in the sidebar on each page, author list, etc., any change to any post could potentially mean all pages have to be rebuilt. Or if you have different ways to display items (full, thumbnail), different ways of sorting them, and maybe even variable pagination (i.e. \"show me page 7 with 15 items per page\"), and it can very easily become unfeasible to statically generate all possible permutations. In the context of \"systems that allow newbies to get results\" this may not be as important, even there you might want to have little neat things like displaying relative dates. Dynamic doesn't have to mean user input, it just means dynamic. And then there's search, in case you want/need to handle that yourself.A probably very naive solution to that I came up with and experimented with is keeping track of all things that go into a page, and tag the cache of it with them, so I could invalidate all cached items that refer to a thing that was just changed (where that thing can be anything, a tag, the site title, whatever), but I ended up scrapping in favor of caching everything for 1 hour no questions asked, because it was just total overkill for my use case.replyklaussilveira 19 hours ago | root | parent | prev | next [\u2013]How is it not user input? Editor can opt to show whatever in his list, playing with the external source filters: most visited, or last published, or less visited.Once the editor is done with his work, if you want to compile a bunch of HTML/CSS and push to Netlify, that's fine. But his interaction with the CMS is not static at all.replycontravariant 19 hours ago | root | parent | next [\u2013]Hmm, well if you consider that to be dynamic then editing html files in notepad is dynamic as well I suppose.replyandybak 18 hours ago | prev | next [\u2013]Sigh.I presume SSG = Static Site Generator(Does anyone actually try to write clearly for people who even slightly not keeping up with their specific domain? I do webdev and even I had to think for a moment to decode the acronym)replyEspressoGPT 15 hours ago | parent | next [\u2013]I think most people who know they need an SSG know what SSG means. But yes, it might be more helpful for users who don't know that yet.replyandybak 13 hours ago | root | parent | next [\u2013]I know what a static sure generator is and I've used one (briefly).But the acronym is unfamiliar to me and it took me a moment or two. It's bad form and we should do it less often.replymmmateo 17 hours ago | parent | prev | next [\u2013]good point, shame I can't edit the titlereplymmmateo 21 hours ago | prev | next [\u2013]Hey HN, it\u2019s been about three years since you sent my open source CMS, Primo, to the front page (https://news.ycombinator.com/item?id=23820201), inspiring me to quit my cushy remote job at the height of the pandemic to work on it full-time (naive and impulsive, I agree). Life has been pretty interesting since then. I\u2019ve burned through my savings, lost my primo.af domain name to the Taliban, and convinced my wife to become a dev/designer to help me.But I\u2019m proud of what we\u2019ve built over that time, and seeing the incredible effect it\u2019s had on people learning web development, putting up personal websites, and managing client sites has further solidified our belief in the power and simplicity of this approach. Today we\u2019re excited to announce the public beta for Primo version 2, which introduces full on-page content editing, page building, and more.I initially created Primo because I was fed up with building websites, and the nontechnical people I was building them for struggled to manage them. My freelance projects involved brittle WordPress themes and poking around dashboards and juggling plugins; accessing the site\u2019s code was so complex that it wasn\u2019t even in the question. As an agency dev, I experienced the complexity of building custom sites in monolithic CMSs and the heavy-handedness of using meta-frameworks and headless CMSs for landing pages and brochure sites. And as a coding instructor, I saw my students face the daunting landscape that people learning to leverage the web face today - CLIs and APIs, package managers and bundlers, frameworks and meta-frameworks . No approach existed that provided a streamlined and approachable path to building, managing, developing, and hosting websites - particularly for common websites (i.e. 90% of the internet) like blogs, landing pages, and brochure sites.Primo is our attempt to build that tool. At a basic level, Primo is a CMS - it gives you the ability to easily manage website content - but its functionality includes the other concerns that also go into running a website, like page building, code editing, static site generation, and deploying to Github/hosting. Blocks are written in Svelte (i.e. HTML, CSS, and JS), so they\u2019re reactive and style-encapsulated. By combining all these elements into a single interface, you can create, manage, modify, and deploy new websites in a fraction of the time. And since they\u2019re static sites, you get all the cost, security, scaling, and speed benefits of serverless too.Primo isn\u2019t intended for people that prefer the WYSIWYG design controls of SquareWixFlow but instead for anybody who wants to leverage HTML, CSS, and JavaScript to fully control and customize their websites while providing a dead-simple content editing experience to themselves and their nontechnical friends/clients/collaborators. It\u2019s for people who feel frustrated by no-code tools and proprietary platforms, and those who want something simpler that still offers the power of code.Beyond that, Primo is an effort to keep the web in the hands of individuals. Our hope is that providing a more approachable tool for web publishing will move the needle on technical literacy and put free expression on the web in the grasp of anyone who wants it so they can\u2019t be as readily corralled into black boxes and walled gardens.If you\u2019d like to be a part of that mission, or just want an easier way to build websites, I hope you'll consider Primo.Mateoreplyleokeba 20 hours ago | parent | next [\u2013]Hi Mateo, nice to see the project is still alive and evolving. I personally tried it about a year ago, and I found it really good for designing simple web pages with reusable and customisable components. But the content management system was the issue for me, I was hoping there would be a way to just drop markdown files in a folder for it to generate articles or blog posts following a template like a regular SSG. We even talked about it briefly, and I then forked the primo repo and started implementing a custom method to convert the database entries into a files / folder structure, which was going alright but the reverse operation seemed tricky to implement and I ended up going down another road, building my own custom markdown SSG inspired by this guide : https://joshcollinsworth.com/blog/build-static-sveltekit-mar... Anyway, my use case is probably not the one you are targeting, but I still think it would be a dope product if everything worked the same but instead of writing the project into a database it would be a dynamic files / folder structure that could be edited and versioned like a regular sveltekit project. Basically it would be a svelte-based SSG framework with a components library and a dedicated UI to complement the regular text editor. Just dropping this in case someone reads it and wants to build it, keep up the good work.replymmmateo 19 hours ago | root | parent | next [\u2013]Thanks! I could definitely see the value in that. Once we make it possible to fetch content dynamically it should be easy to fetch Markdown from a repo and render it anywhere on the page. Or it might be simpler to keep SvelteKit/Astro for that since it does it so well and just use Primo for the non-blog pages, which is currently possible.replyp-e-w 20 hours ago | parent | prev | next [\u2013]> lost my primo.af domain name to the TalibanI had no idea it used to be possible to register Afghan domain names from outside of Afghanistan.replyswyx 16 hours ago | parent | prev | next [\u2013]so, so excited to see you on the front page again Mateo! you're succeeding in an incredibly tough market which takes the full set of founder skills to execute. congrats!replymmmateo 15 hours ago | root | parent | next [\u2013]thanks so much swyx!replyevantbyrne 19 hours ago | parent | prev | next [\u2013]Great work! I also come from an agency background, and it's refreshing to see content management systems that support flexible page layouts becoming more popular.replyspankalee 18 hours ago | parent | prev | next [\u2013]Would love to see this where blocks are standard web components and use native encapsulation!replymmmateo 18 hours ago | root | parent | next [\u2013]I just tried it out with web components using Lit and it seems to work pretty well (https://i.imgur.com/PFvMgFp.png), allowing you to pass in on-page editable fields. But I'd be interested to hear where web components would work better than static/hydrated components.replyspankalee 16 hours ago | root | parent | next [\u2013]Looks like that's using lit-html templates inside Svelte, but not any custom elements.Web components would be good because they're an interface that Primo could work with without relying on specific implementation details. They're also encapsulated with shadow DOM, and support interoperable composition (components can have child elements made from any other frameworks or library).So you could still build blocks with Svelte, but also Lit, Preact, Stencil, Vue, etc.In a similar situation, I was advising the https://blockprotocol.org/ folk on how to define some interfaces on top of HTMLElement to allow standardized passing down of data to blocks, instead of requiring React in their case. I don't know how far they've gotten with that.replystOneskull 17 hours ago | parent | prev | next [\u2013]it's working for me :) i've been using primo for the last week to make my blog, and i feel more productive, and i've learned a lot. the forum is cool too. answers to a couple questions i had were already there. thank you for making primo.replymmmateo 17 hours ago | root | parent | next [\u2013]That's awesome! So glad you like itreplybrylie 3 hours ago | prev | next [\u2013]Looks like an interesting project and compelling alternative to Gutenberg.Remember to check the project website content for grammar mistakes, e.g. using Grammarly, since small mistakes can tarnish the project image of professionalism.replynathabonfim59 19 hours ago | prev | next [\u2013]This incredible! I've worked with WordPress for a long time and have been tinkering with Svelte recently.This is what I was looking for! Mad props to you for putting the effort into building this.replymmmateo 18 hours ago | parent | next [\u2013]Thanks so much! Would love to hear how it works for you & help where I can. Lots still to come :)replyrsp1984 13 hours ago | prev | next [\u2013]While I think the combination of drag-and-drop / blocks and Svelte is really awesome, this unfortunately sits at the wrong end of the spectrum for me.What is is: a visual website builder where I can customise blocks using an online editor.What I'd like: an online interface that clients can use to add / change text, or make other small adjustments, for Svelte websites that I build offline using my own tools. The idea would be that, as long as I build the website according to certain interface standards, it is readable by Primo and the client can modify using the visual interface. For any bigger modifications the client would come back to me and I have all the speed and freedom of my offline workflow.Some might suggest that what I need is a headless CMS, but I have tried those and they are all over-engineered and giving me a big headache just for setup and maintenance.replykeybits 2 hours ago | parent | next [\u2013]You might like https://github.com/michael/editable-websitereplymmmateo 13 hours ago | parent | prev | next [\u2013]Is your concern with the fact that clients can lay out their sites with blocks? Note that they can't edit any of the visual aspects unless you create a field for those specifically (e.g. making an image a circle or square).If it's with not being able to use a local IDE - that is something that's currently possible by bundling your Svelte components into vanilla JS and importing them into your Primo blocks & passing along data as fields - but I'd give it a couple weeks before using it in production until we smooth it out.But what you've described is essentially how I do my client projects - I build it all with code (usually reusing blocks from other projects) and hand off a site that literally any of my clients can edit on day one with minimal training.replypromiseofbeans 12 hours ago | parent | prev | next [\u2013]You might like Builder.io (https://www.builder.io/m/developers) - they let you embed drag-n-drop powered sections within your regular page markup, and it looks like they support most frameworks like svelte.replythomasqbrady 13 hours ago | parent | prev | next [\u2013]What you say you\u2019d like is what I\u2019m looking for, too, but what you say Primo is doesn\u2019t sound far enough off that I understand your complaint. When you say \u201ccustomize blocks\u201d I guess that doesn\u2019t include changing the text? Or perhaps it doesn\u2019t constrict the possible actions enough for you to feel safe handing it over to a client?replyjaequery 11 hours ago | prev | next [\u2013]It's almost unbelievable that more than a decade has passed since I created Stiqr, a site creator back in 2010. Although the site is no longer active, you can catch a glimpse of its remnants in a YouTube video here:https://www.youtube.com/watch?v=B-ff53t8TuU&t=224sResponsive designs got hot during that time (2010) and it made me shut down the project. But I still believe this is the way to go to build websites in the near future.replytamimio 17 hours ago | prev | next [\u2013]Great project. But honestly, I reached to the point of \u201cless JS\u201d or even no js is better for developers and also users. I\u2019m currently migrating my old blog to a new one that gets generated by Zola [1], and even my main portfolio site, which funnily enough I newly made it with React/Gatsby, but I\u2019m redoing it again with Zola because of the performance gap is just unmatched, not to mention I personally sometimes browse the web with js disabled so if a website is completely non-functional or doesn\u2019t even load because of that is a deal breaker. My old site years ago used to use jquery and I was annoyed by it to some degree, trying react and the likes was a nightmare![1] https://www.getzola.orgreplymmmateo 17 hours ago | parent | next [\u2013]I agree! That's why Primo generates static HTML & CSS & only includes [vanilla] JS when its necessary to hydrate any interactive components. All using the Svelte compiler under the hood.replytamimio 17 hours ago | root | parent | next [\u2013]Awesome, thanks, love the project I already signed up! Might give it a try on my company site if I found some templates for commercial sites.replyDanielKehoe 20 hours ago | prev | next [\u2013]Thank you. At last some glimpse of sanity among the freaking complex world of web dev. More power to the Rule of Least Power. [0][0] https://en.wikipedia.org/wiki/Rule_of_least_powerreplymmmateo 20 hours ago | parent | next [\u2013]I\u2019ve always appreciated how Svelte keeps things as simple as possible without sacrificing capability, and how that results in more productivity and enjoyment in building. Really this is a visual layer over that to make it even more approachable.replyransackdev 18 hours ago | prev | next [\u2013]Y'all remember Macromedia Dreamweaver?Nothing against this particular project, but how many times are we going to recreate a wysiwyg cms. There must be hundreds at this point.replymmmateo 18 hours ago | parent | next [\u2013]Totally understand the interpretation, but if you take a closer look I think you'll find Primo is actually the opposite. Site builders like Dreamweaver, Squarespace, Wix, Webflow, Weebly, etc. (and even WordPress now) replace code with visual controls - bridging the gap between users and their websites, but also putting up a wall that keeps them from modifying the code directly (or at best, applying some custom CSS on top of it). Primo, on the other hand, bridges the gap directly to the code, which means the interface doesn't get bogged down by toggles, sliders, and color pickers and users are never limited to just the subset of the underlying platform pre-ordained by whoever built the tool. That's the beauty of code, and it's what excites me most about Primo - that people who would otherwise think code was outside of their reach would realize it's actually something they'd be good at and enjoy.replyransackdev 18 hours ago | root | parent | next [\u2013]Primo is not the opposite. From the primo site, the 3 main bullet points- Drag-n-drop page building> Build your site's pages by dragging and dropping your directly blocks onto the page, unencumbered by overwhelming design options.- Visual content editing> Update your text, images, and links directly on the page or open up the Fields view to manage your content from a structured view.- Integrated development> Access each block's code with a click - right from your browser. And since each block is a Svelte component, there's no limit to what you can make.That is functionality that existed in Dreamweaver since ~2000[1]- Quick Tag Editor> Bring the HTML source directly into the visual design environment. Use a keyboard shortcut to quickly access and modify HTML tags around the selected object on the page.- HTML styles and cascading style sheets> Dreamweaver styles give you desktop-publishing-level control over the text in your Web site. Quickly apply combinations of character and paragraph styles to text with the new HTML Style palette. Easily configure character and paragraph level styles for a site and share them with the entire development team with cascading style sheets. The choice between HTML styles or CSS styles gives you unparalled flexibility and control.- HTML Inspector> Roundtrip HTML lets you visually design your Web site without sacrificing control over HTML source. The HTML inspector gives you total visibility and access to HTML source. Edit, drag and drop, or copy and paste directly in the HTML inspector (which now displays line numbers).1.https://web.archive.org/web/20001012150931/http://macromedia...Regardless of the dreamweaver comparison, please explain how this is different, or as you said, the opposite, from any other site builder out there?replymmmateo 17 hours ago | root | parent | next [\u2013]Ah yeah I forgot Dreamweaver does give you access to the code, in that regard it's similar. But, speaking as a user of Primo (and echoing what I've heard from a lot of other users), I haven't found anything that rides the line between no-code and code quite like this (especially open-source).Yes Primo offers visual content editing and page building, because that's the only way to make a page flexibly editable by a non-technical user. Abstraction is only a negative thing when it stands in the way of what you want to do. Page building abstracts copy-pasting code. Visual content editing abstracts writing editorial content in HTML. Styling & building is the one thing that's left up to code because it has so many more possibilities than laying out blocks or writing content. So in the sense of building, Primo is the opposite to visual site builders like Webflow, Squarespace, Wix, etc.I think that's why a new site builder pops up every other day - because they're all attacking the problem from different ends of the spectrum. Some give you more control, but are more complex/professional (like Webflow), while others are easier to use but offer less control (like Squarespace), and others are tailored to particular industries.replyransackdev 17 hours ago | root | parent | next [\u2013]From what I see they all offer drag and drop UI elements with the ability to dig into the underlying code if you want to. I'm not seeing a difference between all of them other than what the flavor of the week is in terms of lanugage powering the CMS. I remember when ghost was all the rage, and many others. Again, not crapping on your project, props to you for the dedication, and if you're happy working on it that's all that mattersreplyhedgehog 13 hours ago | parent | prev | next [\u2013]I do, and about 20 other projects since. In my experience far from a solved problem. I mean, I remember IE3 too, how many times are we going to recreate the web browser?replywishinghand 19 hours ago | prev | next [\u2013]Great project though it reminds me of my desire to see a node based flat file CMS like Kirby, preferably with Vue as the flavor of templating.replyIceWreck 20 hours ago | prev | next [\u2013]Huh nice. Looks like it uses Supabase as a backend.replycal85 15 hours ago | parent | next [\u2013]And as a frontend! I mean, I don\u2019t mean this as a dunk, maybe it\u2019s all cool with Supabase, but aesthetically it looks extremely similar, not just a little bit. Is that intentional? Do they encourage sharing their styles or something?replymmmateo 15 hours ago | root | parent | next [\u2013]haha good point, but no it wasn't intentional. Wanted to replace the hot red & black design I had before with something besides blue.replykiwicopple 13 hours ago | root | parent | next [\u2013]Don\u2019t worry, we don\u2019t mind. Thanks for using supabase! Let us know if you need anything to help with Primo - it looks amazingreplymmmateo 13 hours ago | root | parent | next [\u2013]Thanks for making it! And that's great to know - I've always wonderedreplymmmateo 20 hours ago | parent | prev | next [\u2013]Yup! Makes it super easy to spin up a server. We're working on making it backend-agnostic to open it up to more people, but Supabase has always been my go-to.replyzote 18 hours ago | root | parent | next [\u2013]It would indeed, you clearly worked long, and hard on this as such I'd like to ask (since you've used Svelte). What is something you wish you knew earlier (a feature or an approach) with Svelte that you've found invaluable?replymmmateo 16 hours ago | root | parent | next [\u2013]It's hard to think of something I wish I knew earlier tbh. Svelte (and SvelteKit) are just so simple and approachable that I feel like whenever I need to do something new I can just try what feels most intuitive and it just works. I've heard the same thing from a lot of other people too. If anything I would just keep an eye on reactive statements; I wouldn't trade them for the world but they can be dangerous if you don't keep an eye on them.replyeole666 20 hours ago | prev | next [\u2013]Nice project! I was a bit disappointed that you need a supabase account for \"self hosting it\".. And this is supposed to work only on some hosting service that can connect to Supa base, and also it encourages to fetch your pages content from github.. So it's more a CMS to run with specific service providers rather than something you can actually self host.replycchance 6 hours ago | parent | next [\u2013]Gotta agree, i'd prefer to use planetscale or turso, i mean supabase is cool too, but i'd rather have the option, or even just loading stuff to a local db on a webhost of my own.replymmmateo 20 hours ago | parent | prev | next [\u2013]Thanks! And yeah I agree it's a bit mislabeled; the goal was to enable people to put up their own server as easily as possible, which meant plugging into those services. We are working on decoupling the backend so you could self-self-host it though.replyransackdev 18 hours ago | root | parent | next [\u2013]sqlite or flat html files would enable the ease of self hosting without any third party external service dependenciesreplymmmateo 17 hours ago | root | parent | next [\u2013]Possibly for the database but authentication and file storage would still need to be taken care ofreplyrallisf1 19 hours ago | parent | prev | next [\u2013]True but still, you can self host supabase as well. The only service really required is GitHub but I guess other providers (e.g. gitlab) can be added down the line.replykykeonaut 20 hours ago | prev | next [\u2013]Thank you for using an MIT license :)replymmmateo 20 hours ago | parent | next [\u2013]Sure thing! Just changed it from AGPL actually. It would be ideal if anyone forking it would contribute changes, but I was worried that would keep them from using it to build internal tools or separate products, and all the underlying tech is MIT anyway.replykykeonaut 20 hours ago | root | parent | next [\u2013]Yep, that is actually a big problem (benefit?) with Wordpress, were all the code is redistributable because of the GPL license. So paid plugin developers are in this weird limbo were they are charging people for their plugins without telling them that the code is freely redistributable.replyransackdev 18 hours ago | root | parent | next [\u2013]A plugin is a separate code module that wordpress loads, surely those are not bound to the wordpress core license. Extending wordpress with non-wordpress owned code does not grant them the right to push their license onto somebody else's completely unrelated code. If that were true, nobody would ever be able to sell a proprietary app on any linux distro. GitLab is open core yet extends the functionality with enterprise under a different, proprietary license.replymthoms 16 hours ago | root | parent | next [\u2013]There's no legal precedent yet, but WordPress plugins/themes are widely considered as being GPL because they're a \"derivative\" work.Or, at least the PHP code in those plugins/themes are - possibly not the CSS + assets.https://kinsta.com/learn/wordpress-gpl/replyjermberj 19 hours ago | prev | next [\u2013]One of your themes shows an \u201cemail subscribe\u201d field like one might expect for a blog with a newsletter. Does this have a concept of email subscribers and management related to such? Does this support transactional/batch emailing?replymmmateo 19 hours ago | parent | next [\u2013]No, you\u2019d use an external service for stuff like that (I use Getform for emails).replyransackdev 18 hours ago | parent | prev | next [\u2013]Ghost has this functionality and is used by many https://ghost.org/replymdrzn 21 hours ago | prev | next [\u2013]Looks interesting, will give it a try for a personal landing page.replymmmateo 20 hours ago | parent | next [\u2013]Sweet! Let me know if you need any helpreplyKalpeshbhalekar 19 hours ago | prev | next [\u2013]Great product!How is this different from Strapi or Ghost?replymmmateo 19 hours ago | parent | next [\u2013]The biggest difference from any existing CMS is the integration of a code-editor and Svelte components, but also the on-page editing is more user-friendly than most CMSs or site builders.Specifically: It\u2019s a monolithic CMS, unlike Strapi, so you don\u2019t need to include an SSG to turn your content into code. And Ghost is more of a full-featured service for online publications where Primo would be better suited for smaller bags, landing pages, and brochure sites.replyrobbiejs 21 hours ago | prev | next [\u2013]Looks great, very snappyreplynailer 16 hours ago | prev | next [\u2013]> Is Primo open-core? VC-funded open source? Side project?> Primo is under full-time development and is in the process of becoming a nonprofit organization. Any funds generated from White Glove and Cloud will go towards funding further development, in the same vein as Ghost CMS.The above is a stupid answer, it\u2019s open source and MIT licensed: https://github.com/primocms/primo/blob/master/LICENSEreplymmmateo 15 hours ago | parent | next [\u2013]Could you elaborate? Tailwind CSS is MIT but it's still under a for-profit company.replynailer 15 hours ago | root | parent | next [\u2013]Orthogonal. Many open source projects have companies behind them, that doesn\u2019t restrict what you can do with the license.replymmmateo 15 hours ago | root | parent | next [\u2013]That's true, but it does communicate something important to companies and individuals looking to use, contribute, or build on the project to say what kind of open source it is, rather than just saying its open-source IMO. Would be interested to hear if you think it could be clarified though.replypcthrowaway 12 hours ago | root | parent | next [\u2013]Your answer completely sidesteps the question though and doesn't mention that it's open source, which makes it sound like it's notreplymmmateo 11 hours ago | root | parent | next [\u2013]Ahh okay that makes sense. Just updated it, thanks.replyjurimasa 17 hours ago | prev [\u2013]As someone who has been working with WP since the beginning... Seems fun. Can you deploy it on a classic LAMP server? If not, it's not really a WP replacement for me. And I'm really looking for one.replymmmateo 17 hours ago | parent [\u2013]Primo itself is a SvelteKit application, so I don't know how possible it would be to run it on a LAMP server, but you could certainly deploy the static sites it generates on one.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The drag-and-drop blocks/slices of content in CMS systems can be difficult to manage and maintain, leading to unsatisfactory results for content creators.\n- A headless CMS that separates content creation and design may be a better approach for some projects.\n- Primo is a visual CMS with Svelte blocks, a code editor, and a static site generator that aims to provide a streamlined and approachable way to build and manage websites."
  },
  {
    "id": 36810818,
    "timestamp": 1689922863,
    "title": "Nanosecond timestamp collisions are common",
    "url": "https://www.evanjones.ca/nanosecond-collisions.html",
    "hn_url": "http://news.ycombinator.com/item?id=36810818",
    "content": "Nanosecond timestamp collisions are commonabout | archive[ 2023-July-20 17:39 ]I was wondering: how often do nanosecond timestamps collide on modern systems? The answer is: very often, like 5% of all samples, when reading the clock on all 4 physical cores at the same time. As a result, I think it is unsafe to assume that a raw nanosecond timestamp is a unique identifier.I wrote a small test program to test this. I used Go, which records both the \"absolute\" time and the \"monotonic clock\" relative time on each call to time.Now(), so I compared both the relative difference between consecutive timestamps, as well as just the absolute timestamps. As expected, the behavior depends on the system, so I observe very different results on Mac OS X and Linux. On Linux, within a single thread, both the absolute and monotonic times always increase. On my system, the minimum increment was 32 ns. Between threads, approximately 5% of the absolute times were exactly the same as other threads. Even with 2 threads on a 4 core system, approximately 2% of timestamps collided. On Mac OS X: the absolute time has microsecond resolution, so there are an astronomical number of collisions when I repeat this same test. Even within a thread I often observe the monotonic clock not increment.See the test program on Github if you are curious.",
    "summary": "- Nanosecond timestamp collisions are common on modern systems, occurring in approximately 5% of all samples when reading the clock on all 4 physical cores at the same time.\n- This means that a raw nanosecond timestamp cannot be assumed to be a unique identifier.\n- The behavior of timestamp collisions varies between different operating systems, with Linux showing consistent increases in both absolute and monotonic times within a single thread, while Mac OS X has a high number of collisions with microsecond resolution.",
    "hn_title": "Nanosecond timestamp collisions are common",
    "original_title": "Nanosecond timestamp collisions are common",
    "score": 298,
    "hn_content": "- Nanosecond timestamp collisions are common.\n- UUIDv7 has a milliseconds time component and a field that increments for each event in the same millisecond.\n- UUIDv7 works great at scale but has limitations such as sequence overflow and collisions between machines.\n- UUIDv7 was first drafted a bit over a year ago.\n- ULID is listed as having 1.21e+24 unique per millisecond.\n- Using a time component in IDs allows for sorting or filtering records by time.\n- Adding random bits to UUIDs increases entropy and reduces the chance of collisions.\n- Timestamps should probably never be used as a \"unique\" ID.\n- Timestamps with millisecond precision can be used as sort keys in DynamoDB, but caution is needed to avoid collisions.\n- Using a random component in UUIDs increases entropy and helps minimize collisions.\n- The proposed UUIDv7 standard follows a time + random component model.\n- Snowflake IDs are another option for unique IDs with time-based sorting.\n- Using a timestamp as a sort key in DynamoDB can be risky due to potential collisions.\n- Timestamps can be combined with other components to increase entropy and reduce collisions.\n- CPUs have clocks with precision down to the nanosecond range, but actual precision may vary.\n- Truncating high-resolution timers can reduce collisions and improve entropy.\n- Using a hash function can add entropy and reduce collisions in timestamp-based IDs.\n- Timestamps should not rely solely on the CPU counter, as it may introduce bias or imprecisions.\n- Timestamps are commonly used in conjunction with other components to achieve locality and sorting order.\n- Using hash functions can concentrate entropy from low bits and CPU counters, reducing collisions.\n- Consider truncating high-resolution timers for better entropy and improved performance.- The post discusses the use of nanosecond timestamps as unique identifiers.\n- There is a debate about the accuracy and uniqueness of raw nanosecond timestamps.\n- Some argue that a hash function could improve the uniqueness of timestamps, but others disagree.\n- It is mentioned that RDTSC is influenced by frequency scaling and may not provide constant or deterministic results.\n- Different clock systems of a computer could be tied to a reference clock like a GPSDO to ensure accuracy.\n- UUIDs are brought up as a solution for generating unique IDs without the need for coordination.\n- There is a discussion about the limitations and trade-offs of using UUIDs.\n- The idea of hierarchical sequential IDs is proposed as an alternative to flat address spaces like UUIDs.\n- The post mentions ULIDs as a variation of UUIDs with extra random bits.\n- A reference to Logical Physical Clocks (LPCs) is made as an alternative to physical/NTP clocks for maintaining logical clock synchronization in distributed systems.\n- The issue of scalability and coordination in generating IDs is mentioned.\n- The use of a central registry for assigning IDs is debated.\n- The post addresses the trade-off between accuracy, speed, and cost in ID generation.",
    "hn_summary": "- Nanosecond timestamp collisions are common and can lead to issues with generating unique identifiers.\n- UUIDv7 is a proposed standard that combines a time component with a random component to create unique IDs.\n- There is a debate about the accuracy and uniqueness of raw nanosecond timestamps, and alternative solutions like ULIDs and hierarchical sequential IDs are proposed."
  }
]
