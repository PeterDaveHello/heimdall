[
  {
    "id": 38498109,
    "title": "Creating a Tiny Volumetric Display: DIY with LED Matrix and Pick & Place Machine",
    "originLink": "https://mitxela.com/projects/candle",
    "originBody": "POV Candle 1 Dec 2023 Progress: Completed A tiny volumetric display! Video Demo Naturally you can't really feel the volumetric effect on camera. It looks a lot more 3D in real life. Idea I was recently fortunate enough to find myself in the pub with some very creative and talented people. The discussion turned to electronic candles, and how one might create something that would look like a flickering candle from any angle. I suggested a persistence-of-vision display, but the general consensus was that those require too much in the way of supporting machinery to make them work: bearings, and probably slip rings and so on. Afterwards I had a think and figured that if the motor and battery were small enough, the whole thing could spin. I was ordering some other circuit boards the following day, so I quickly threw together a simple LED matrix board and combined that with the other orders. Small circuit boards from China are essentially free, fast postage is the only thing that matters. Some time ago, I got access to a pick and place machine (a Charmhigh CHM-T36VA). I have it on semi-permanent loan. It's specifically for another project, which I will write up eventually, but my feelings on it can be summarised as follows: Robots are the Future. I've spent enough of my life manually assembling circuit boards that to have a machine that can build a board in seconds right in front of me is bliss. The one drawback to it is that loading the reels takes a long time. For each unique component you have to tediously load the reel, which can sometimes take the best part of 20 minutes. The circuit I borrowed the machine for has 26 unique components, so loading the reels was a full day of work. However. This LED matrix has precisely one component, and so loading the reels was as short as technically possible. Then we can crank out the boards at break-neck speed! I didn't get a proper stencil, I just laser-etched one in acetate. This project was still very much at the minimal-investment stage, where I'm just idly throwing ideas around. But a generic tiny LED matrix seemed like a worthwhile thing to have a handful of, it will almost certainly come in handy. I did some with 0603 and also some with 0805, as I had some of those already loaded. If the circuit board design hadn't been a rush job, I'd have also made a circular PCB to support it at a right angle. The pads along the bottom were to solder directly between the boards. When I come to building the next version, that's what I'll do. For now I was playing with ideas. I knew that I wanted a microcontroller with a fair bit of flash memory on it, as we may want a fair bit of volumetric video data. The temptation was to go with a Pico, that's dual core 125MHz (or more) and up to 16MB flash (and importantly, it's cheap). One of the main drawbacks to the Pico is that it's a pain to use the bare RP2040 chip on its own. It has no onboard flash memory, so at the very least you need to wire up a QSPI flash chip, and almost always you'll need an external crystal and a fair amount of supporting caps. The Pico board on its own is far too large for our situation. However, a bunch of people have produced minimal RP2040 boards catering to exactly this sort of situation. Most of them were inappropriate, either too big or not breaking out enough of the GPIO. I found one that looks promising called the Waveshare RP2040-tiny. Here they've essentially cut the pico board in half, putting the bare minimum on the main board and having a secondary board, connected by a flat flex cable, with the USB port, reset and boot buttons. This seemed perfect for our prototype. It's still a little too big, and still doesn't break out all the GPIO, but we should be able to get by. As for the battery, I immediately grabbed a LIR2450. It's lithium-ion rechargeable, and can deliver well over 100mA. You can get smaller Li-ion batteries, but their capacity and current capability are much reduced. I also get a bit nervous having LIR2032 batteries lying around, as I feel like I'm going to accidently put one into something expecting a CR2032 (same physical dimensions) and possibly break it (LIR batteries are 4.2V fully charged). And besides, that RP2040 board is about 29mm diagonally, so going with a smaller battery isn't going to make the end result any smaller. I 3D-printed the most minimal holder for the battery in PETG. I was definitely too frugal here, printing with a wall thickness of 0.5mm. It's printed in two parts, with the top glued on. I think it would make more sense to thicken up all of the parts and print in one go at 90 degrees, which is something I played with later. This 3D printed part is definitely the weakpoint, every time I drop the prototype it breaks and I have to glue it back together. Anyway, we got as far as our first mockup: That's a TCRT5000 IR sensor I've soldered on, with tiny surface mount resistors. The sensor is a little on the big side but it's all I had to hand. The output is analog, the detector is just a photodiode, but we can use a pullup and connect this straight to a GPIO pin. There are schmitt triggers on the inputs of the RP2040 (that can be disabled through software) so we essentially get a comparator for free. There's a WS2812 LED on the board, connected to GPIO16. I would much rather just have an extra GPIO pin for my matrix, so I snapped off the LED and soldered some enamel wire to it. I wasn't sure if it would be needed but now is the only chance we have to do this. I then started soldering our matrix. The idea with the tabs at the bottom of the matrix was to have slots in the board I connect it to, which would keep everything aligned. Instead, it seems they work well as little legs to keep the board just above the components. I soldered solid-core wire to the pads and wired it up so that everything would be very rigid at the end. It's possible to correct the angle between the boards, but it takes enough force that it won't happen by accident. That's half the connections done, there's another ten wires to solder on the back, but before we do that I wanted to wire up the motor. I have a handful of motors approximately the right size. The one I opted for is labelled RF-410CA. Most of the similar motors from CD and DVD drives are all slightly different diameters and different shaft lengths. I also had a think about RPM. Most of these motors have a no-load speed of 5000 to 10000RPM, which is far too fast. We can PWM the speed down, but it also says something about their starting torque. To get to 30FPS, I'd need an RPM of 1800. It's quite hard to make decisions here, because as soon as it starts spinning there will be air-resistance and it will probably hit some equilibrium. Eh, if the motor's no good we can switch it out later. I deadbugged a little sot-23 mosfet and a flyback diode onto our creation. The IR LED was wired straight to the power line. Ideally we'd have software control over it to save power while it isn't spinning, but for this prototype I didn't want to waste a GPIO on that. The matrix is 8x10, so 18 GPIO, plus one for the sensor input and one for the motor control, and I also wanted to keep one for monitoring the battery voltage. I think it's possible to wire up a couple more of the GPIO on the RP2040-tiny board which have been broken out as \"user mode selection pads\" but the current thought process was to not worry and get this to a working prototype as quick as possible. Notice I'm wiring the matrix directly to the GPIO pins. There's no current limiting or driver transistors. The RP2040 can source/sink about 50mA total across all its GPIO. I have learned that the risky, but oh-so-appealing way to drive LEDs from microcontrollers is to skip the current limiting resistors and drive them with PWM. The inherent on-resistance of the GPIO pin is enough to limit current – maybe not to a safe level for continuous illumination, but predictably. As long as you limit the duty cycle it's fine. Here we'll be flickering all of the matrix very quickly, with a lot of careful timing around it. I think it's unlikely we'll overdrive an LED, unless the chip crashes and the matrix freezes. I wired up the rest of the matrix using enamel wire, threading it underneath. We didn't need any further rigidity and it looks pretty cool this way. There is something surprisingly appealing about the naked wires. It has a kind of cyberpunk vibe. The vibe was only enhanced when I powered up the matrix with a checkerboard test pattern for the first time. I glued our 3D printed battery holder onto the motor, and attached the rest of the prototype with squidgy 3M tape. I then had to shorten the wires to the motor and connect up the battery terminals. I wired the battery's positive terminal straight to VBUS of the board. The RP2040 is behind the 3.3V regulator, but with the battery connected this means that connecting the USB cable would put 5V across the battery terminals. We can worry about that later. For now I just want to know if the hacky prototype has any hope of working. Amusingly, once I configured it to light up the matrix in response to the IR photodiode, it would light up the matrix whenever the camera flash fired. With the battery removed you can see my connection to it, just some of the enamel wire stripped and tinned and threaded through a couple of small holes. At this point the battery snapped in with a positive action. It was only after it had been dropped a few times and the plastic cracked that I needed to use a rubber band to hold it in place. I drilled a small hole at the back in order to be able to eject the battery, just poke it out with a pointy thing. Software We monitor the IR sensor and use the time between triggers to set the speed of the matrix display. It's all the usual stuff for a persistence-of-vision display, except with another dimension. One thing I like about the RP2040 is that you can set (or input) every gpio pin in the same clock cycle. STM32 chips, despite having 32 bit processors, group the IO into 16-bit registers that suffer from bus contention if you try to change them all at once. Here we can pre-process everything we need to send to the GPIO and step through it at a speed proportional to the measured rotation. The processor is dual core ARM Cortex-M0. One thing to note is that both cores have separate SysTick hardware. Rather than do this with interrupts, we can use both cores in busy-wait loops. The first core monitors the IR sensor, and uses its systick to measure the exact number of cycles between triggers. The second core waits on the signal to illuminate, and once it gets it, steps through the volumetric buffer using its own systick timer for cycle-accuracy. In terms of motor control, I was reasonably confident we didn't need to do anything too complicated. It's important that the device spins at a constant speed to get a consistent framerate, but it should be fairly self-regulating. Paddle wheels were often used as regulators in old mechanical devices. I made the very simplest speed control logic possible: if the RPM is below 1200, set the motor to 90% power, else set it to 60% power. Later I might upgrade it to proper PID control but so far there's enough inertia and air resistance that the simple control seems totally fine. The first time I got this thing to spin I was giddy with excitement. Within moments I had it drawing a simple volumetric checkerboard pattern. Here's one of the very first tests: The plan was to machine a base for this device, with a little signpost that would stick up for the IR sensor to catch glimpses of. I realised it worked fine by just holding a finger near it, so never got around to that part. The motor had a very small pulley attached, which was just enough to let it spin up without falling over. I later laser-cut a disk of delrin, just a push-fit over the shaft, which was only supposed to be a stop-gap until I made something on the lathe. The code steps through the matrix in a columnwise fashion. Looking at the device top-down, each radial line is very slightly spiralled, but that's a lot easier to correct for (if we cared) than having the whole thing be a helix. The duty cycle on the LEDs in the centre is proportionally reduced compared to the periphery. I quickly got this thing displaying a static test volume. It was only a matter of time before I let it fall on the floor. The 3D print cracked along the glue line. No worries, we can just keep gluing it back together. It's invincible! Battery Level One thing that worried me is that we have no protection circuit for the battery. If it drops much below 3V it will get permanently damaged. (In practice the limit is more like 2.7V, but it depends on the cell. I've destroyed a few through this process.) Most lithium batteries have protection circuits built in, that will disconnect when it reaches a dangerously low level. Not so, with a bare cell. At the very least I wanted to monitor the battery voltage so we can alert and fail to run if we think it's too low. The normal way of monitoring supply voltage level is to add a potential divider to get it into a readable range of the ADC. The Pico boards I think normally have this wired to one of their GPIO, but not the RP2040-tiny. I added two 100K resistors to power and ground to our last available GPIO. The problem is, there's no reference voltage on the Pico. There's an external pin (not broken out on the RP2040-tiny) that can be used, but if the ADC reference is just its supply voltage, then when the supply voltage dips we won't be able to detect that. At least, not well. The 3.3V LDO regulator has part number RT9193-33, and a dropout of 220mV at 300mA. That means when the battery voltage reaches 3.52V, our RP2040 supply voltage will start to droop as well. The ADC reading as a function of battery voltage will end up something like this: Of course, the dropout voltage is a function of current load, so it isn't even as predictable as that. For this prototype, I made the device show a warning when it reaches just under 3.6V. That's the only thing we can really do here. For the next version, we'll add a reference voltage. It may even be possible to connect the ADC ref to the Pico's internal 1.8V regulator. That would be enough. Battery charger The concept was to pop out the LIR2450 when it gets low and stick it into a standalone charger. I bought a standalone charger. It broke the very first time I used it. I was pretty pissed off that a brand new charger would let me down (it wasn't even the cheapest!). And this, at my most excited moment, ready to display more volumetric data! Woe is me! I 3D printed another battery holder, this time in the other plane. The spring tabs are technically flexing in the weakest direction, but they're generous enough and the wall thickness is all 1mm now. I wasn't planning to use this for the display, this is just my new battery charger. I set the bench power supply to current limit of 50mA and constant voltage of 4.2V. This is enough to charge a single lithium-ion cell. The constant current is on the conservative side, I wasn't sure if this was a 120mAh battery or a 60mAh battery. It's best to charge no faster than about 1C unless the battery says otherwise. But it's generally never a problem to charge slower than 1C. This got me fired up again, and the volumetric journey continued. But before we resume the narrative, let me just add that removing the battery and connecting to a power supply is the least convenient way of charging the device, especially after the prototype cracked and I had to add that rubber band to stop the battery flying out. The RP2040-tiny USB adapter board was still being used to load code onto the chip. If we build a kind of USB-intercept board, we can lift the 5V line, and expose the pins for the battery. This sits between the USB cable from the PC to RP2040-tiny programming board. Now we can connect the power supply to the battery without removing it from the prototype. The data lines are still connected underneath, so we can program it with the battery in place as well. I realised that soldering this up was a waste of time as I could have simply put wires on the RP2040-tiny adapter board. However in the mad frenzy induced by the working volumetric display, and the kicking of myself for only having one LIR2450 in stock, I found this still too inconvenient for rapid development. In a drawer somewhere, I had some lithium-ion charging ICs. It took me a moment to find them. These are quite nice quality ones, which cost about 90p each. The part number is BQ21040DBVR. I went back to that USB intercept board, and smashed the charging IC into the middle of it. With this, we can leave the programming cable connected and it will be charging the battery while we think. Of course, it won't ever fully charge the battery this way because the prototype never turns off. The IR LED alone is constantly drawing about 9mA. There was a very bright power LED on the RP2040-tiny adapter board, I swapped out the resistor to a 20K to stop it wasting power there. But still, I think even when the prototype isn't running it's drawing about 15mA overall. The charging IC, in the constant-voltage phase, will wait until the charging current drops to 0.1C. As our charging current is set to 54mA, that'll never happen. Also, with the voltage drop across the cable the battery probably won't get above 4.1V. None of this really matters, it's just stuff to keep in mind for the next version. At last we could start doing fluid simulations! Generating volumetric data We need to create our volumetric data in 3D polar coordinates, that is, r, theta and z. I started with a wireframe cube, which should at least be somewhat recognisable. I deliberately rotated it to be on-end, to maximise the awkwardness of displaying it. Really I suppose we should write a vector display routine for the device, that would perform some kind of 3D polar coordinate Bresenham interpolation. There's plenty of info out there about applying Bresenham to 3D, and drawing circles, but we want to draw straight lines in polar coordinates. This sounds like a fun thing to think about but for now let's focus on exporting polar voxel data from Blender. That's the default cube with a wireframe modifier. To rotate a cube to be on-end, with a corner facing directly upwards, we need to first rotate x by 45 degrees, then rotate y by atan(1/sqrt(2)). One of the lovely things about Blender is you can just type in formulas anywhere. To get slices of this wireframe cube, I added another cube, reshaped it to be somewhat slice-like, and did a boolean modifier between them. I then parented both the camera and this slice to an empty, and animated the empty's Z rotation. I configured the camera projection to be orthographic, and its resolution to be our tiny 8x10. I set the background to black and the cube's material to emissive. In the compositor, we can use a colour ramp to threshold this. The volumetric display currently has only a bit-depth of 1, so each voxel is just on or off. Thresholding it here lets us visually pick the best cutoff. \"Render animation\" now generates 24 images, 24 slices of the wireframe cube. I used a quick python script to chew those up into a header file that can be included in the code. In Blender, not only can any input accept a formula, and not only can virtually all of them can be keyframed, you can also set up a driver. Rather than resolve the formula as you enter it, it will recalculate the result for each frame. So instead of keyframing the rotation of the camera and manually setting it to linear interpolation, I just typed in (frame/24)*2*pi which will loop indefinitely. For the y-rotation of the cube, I now typed in floor(frame/24)*pi/24 so it will rotate a fraction for each full loop of the camera. Honestly it would have been fine for the rotation to be continuous, but I wanted each frame of data to be discrete, just in case we wanted to adjust playback speed based on motor RPM. You'll simply have to take my word for it that the display seems a lot more three-dimensional in real life. Looking at the pictures and watching the video it does seem just like a bunch of random dots illuminated. If only you, dear reader, had a volumetric display to experience it on! Fluid simulations Running a fluid simulation in Blender is both easy and difficult. Easy to get started, difficult to get just right. There are an awful lot of parameters involved. Liquid simulation is slightly easier to port to the volumetric display as it's trivial to convert the fluid particles to a mesh. In theory, we should be able to run a fluid simulation at 1/24th speed, and use the same technique as above to extract polar volumetric data. Unfortunately using extreme parameters like a very slow time scale leads to instabilities. There doesn't seem to be a straightforward way to play back a simulation at a slower rate, and the very slow simulation speed looks entirely wrong when sped up. I did fiddle around with this for a while with no luck. On the plus side, we're targeting a very low spatial resolution, so the fluid simulations are all fast enough to run in real-time on my desktop machine. I looked into other ways to render the volumetric data. There's a feature known as Multi-view, or Stereoscopy, that's intended for rendering 3D video. This lets you add two cameras and render a scene from both perspectives simultaneously. It's possible to add any number of cameras, and output all of them based on their naming suffix. I'm not sure if there's a quick way to add 24 cameras and evenly rotate them (sadly you can't apply an array modifier to a camera, I'm not sure if anyone has ever asked for that before) but a further problem with this tactic is that we also need the boolean modifiers of our slices to be rendered at the same time. Instead of the boolean modifier and a slice, we could cheat a little and use the built-in clipping distances. By setting the camera to only render a 0.1 slice of the scene we get almost the right output. The problem is that only surfaces are drawn, not solid fill for the clipped objects. I thought that maybe applying volumetric material to the objects could make them at least partially filled, but after playing about for a bit I had no luck. Instead, let's go for a more generic (but more involved) approach: just write a python script. In the scripting tab in blender, I wrote the following: import bpy import os from math import pi obj = bpy.data.objects['Empty'] output_path = bpy.context.scene.render.filepath for i in range(24): obj.rotation_euler[2] = (i/24)*2*pi bpy.context.scene.render.filepath = os.path.join(output_path, f\"###_{i:02}.png\") bpy.ops.render.render(animation=True) bpy.context.scene.render.filepath = output_path This way we run the fluid simulation in real time, and simply re-render the whole animation 24 times with different rotations of the Empty (parent to the camera and the slice). The concept proven, I ploughed ahead with the fire simulation. The way to render this is basically the same but with a couple more steps. We set up our fire simulation, and then bake it in OpenVDB format. Here I set a small cube on fire. Then start over, and import the OpenVDB data back into Blender. We can then create a new mesh and apply a Volume to Mesh modifier on it, which lets us threshold the volume data. Finally, another boolean modifier with our camera slice, and re-run the script above. Again, I feel the photograph doesn't really capture the feeling here, but you hopefully get the idea. It occurs to me that the LED alignment could be corrected for in software, if it were predictable. We could offset the boolean slice either closer or further away from the camera, so that it doesn't spin around the exact centre. If it matched the movement of the real display we should be golden. Similarly, instead of a stretched cube, we could make it a slightly curved shape to compensate for the matrix scanning pattern as the board rotates. At this level of resolution however, I don't think any of these improvements would be visible. The only thing that really matters is that illuminating an individual voxel near the perimeter should look like a single dot, not a double dot from some angles. You can see it in the image below, where the voxel nearest the camera is elongated because the two illuminations as the matrix rotates didn't quite line up: The letter \"m\" in the centre is perfectly clear, because I deliberately cheated there. To make the text readable from all directions, the text voxels are rendered differently. I made it so the text scrolls in the readable orientation regardless of if you're looking at the front or back of the display. Anyway this voxel discrepancy can only really be noticed on the periphery of the display, where both illuminations are visible at once. Conclusion, for now There is plenty of work to do on my fire simulation, but perhaps I'll delay a little until I crank out the next prototype which might be a little better aligned and a little higher-resolution. If I had a tiny slide-switch in stock, I would have added it to this prototype, to disconnect the battery without removing it. I started searching my boxes for something suitable before realising I could simply insert a small piece of acetate between the battery and the contact, like they do with coin cells for IR remotes and so on. That works fine. On the subject of IR remotes, it would be quite nice to have a remote control for this. We already have an IR sensor, although it's not a demodulating type. As shown in the video, I simply advance to the next mode after a timeout of no activity. Here are some vanity shots of the device. The IR is of course totally invisible to the naked eye, but the digital camera picks it up as a faint purple glow. I have stuck the source code on github as usual. ~ mitxela.com » Projects » Hardware » POV Candle Questions? Comments? Check out the Forum Support mitxela.com",
    "commentLink": "https://news.ycombinator.com/item?id=38498109",
    "commentBody": "Tiny volumetric displayHacker NewspastloginTiny volumetric display (mitxela.com) 1228 points by ttesmer 21 hours ago| hidepastfavorite139 comments weinzierl 7 minutes ago\"Small circuit boards from China are essentially free[..]\"A little later:\"Some time ago, I got access to a pick and place machine (a Charmhigh CHM-T36VA). I have it on semi-permanent loan.\"Why is it, that it still makes sense to assemble boards yourself while outsourcing PCBs is a no-brainer?It doesn&#x27;t have to be \"essentially free\", but isn&#x27;t there an assembly service that is suitable for hobby projects like this?I assembled a fair share of PCBs, both for hobby and professionally (in R&D), but I neither have the time nor the space to do it anymore. reply sowbug 16 hours agoprevA couple ideas for improvement. If you have extra identical motors and disassemble two, you can fashion a rotating power transmission system from the brushes in two assemblies. You sacrifice two motors for each unit, but it&#x27;s a perfect fit and very reliable (with a cap and rectifier), and you don&#x27;t have to worry about batteries anymore.The rectifier also provides a signal that the assembly has completed a rotation, so you can maintain image stability based on actual position, rather than guessing how long a cycle is.Transmitting power via induction might work, but I was never able to deliver it efficiently enough, so to make it work I had to turn up the source voltage so high that I worried about fires.This advice comes from my 2001 Burning Man art project. A very sad early prototype is pictured here: https:&#x2F;&#x2F;github.com&#x2F;sowbug&#x2F;tqw&#x2F;blob&#x2F;master&#x2F;photos&#x2F;side.jpg. The final installation worked great. reply defterGoose 5 hours agoparentThat&#x27;s all true, but I liked his solution of using an IR sensor for the sync. It was so cool how he was able to rotate the display by changing the position of his finger. No guessing involved. reply amelius 8 hours agoparentprevAnother idea: why not put a tiny TFT display on the motor? You can get cheap ones at aliexpress. reply krenzo 7 hours agorootparentStandard displays are 60 Hz. You need a much higher framerate because not only do you want 60 frames a second, but you also want some number of frames per angular rotation. For 1° of angular resolution, you would need: 360°*60 Hz = 21,600 Hz display. Liquid crystals can be modulated at KHz speeds, but you&#x27;re not going to find associated driving circuitry to do that. It&#x27;s not easy, and there&#x27;s no demand for it.A TI DLP DMD can modulate at those high speeds, and there&#x27;s readily available driving circuitry for it. However, it&#x27;s a small reflective based display designed for projectors, and you would then need a light source to reflect off of it.MicroLEDs would let you increase your pixel pitch with fast modulation frequency, but the display area is still small at the moment because of low yields. You also need a custom chip to drive the microleds at the required high framerate. reply Rebelgecko 4 hours agorootparentI saw a cool design where they stacked transparent displays reply pyinstallwoes 4 hours agorootparentprevYou seem to know a lot about this. Have you worked on similar things? reply wayvey 8 hours agorootparentprevWould be cool to see how that would look like. Or even a transparent OLED or such. reply elcritch 12 hours agoparentprevThat is a pretty good idea! The brushes will last a long time. Luckily now the rise of wireless phone charging means you can get kits like [1] or [2].It makes me wonder how different LIDAR vendors manage it.1: https:&#x2F;&#x2F;www.adafruit.com&#x2F;product&#x2F;1407 2: https:&#x2F;&#x2F;www.adafruit.com&#x2F;product&#x2F;2162 reply enva2712 10 hours agoparentprevIf the drive motor was asynchronous you could use the inductive windings on the rotor to power your rotating electronics, but the phase difference may get pretty extreme reply mhb 5 hours agoparentprevWhat about keeping the motors intact and using the second as a generator? reply sowbug 2 hours agorootparentI might be misunderstanding the idea, but I don&#x27;t think it addresses the original problem that wires can&#x27;t connect the two parts of something that rotates in a single direction. reply twoodfin 20 hours agoprevOne of those brilliant ideas that seems obvious in retrospect.Given that the results are so compelling even when pulled together by hand out of relatively primitive discrete components, I’m wondering why we shouldn’t expect to see full color, high resolution versions from every random 7-letter drop shipper on Amazon next Christmas? reply crazygringo 18 hours agoparentIt&#x27;s not a new idea -- they&#x27;re called swept-volume volumetric displays, and they&#x27;ve been around for a long time [1].But they&#x27;re mostly kind of just toys. When you&#x27;re limited to transparent glowing surfaces and you can&#x27;t even touch them, there&#x27;s really not a whole ton you can do. You can see a much larger non-spinning version made of LEDs suspended on cables [2] and it&#x27;s very cool, but the novelty kind of wears off after a while, and you realize it&#x27;s not the kind of display you&#x27;re going to use for anything productive.If you actually want real 3D visualization that can render anything at high quality and that you can interact with, it seems like VR&#x2F;AR headsets are the way. (Though there are also the new 3D monitors that don&#x27;t require glasses, but not a lot of people have gotten to see those in person yet.)Maybe there&#x27;s some kind of toy you could make with them to sell on Amazon though? Not really sure if there&#x27;s a \"killer app\" for these things.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Volumetric_display#Swept-volum...[2] https:&#x2F;&#x2F;www.ledpulse.com&#x2F; reply noduerme 13 hours agorootparentThe killer app is clearly sending messages via R2-D2. reply crazygringo 11 hours agorootparentThis... is true.It would actually make a fantastic Princess Leia message toy! reply drcode 10 hours agorootparentprevThe innovation is spinning the entire computer, instead of just the display, reducing complexity reply dekhn 10 hours agorootparentIt seems more likely that a mechanical engineer would end up using a slip ring, so the computer doesn&#x27;t need to spin. reply doubleg72 7 hours agorootparentThis is exactly what would be used, a Moog slip ring. reply draugadrotten 47 minutes agorootparentThanks. Enjoyed the explanation of a Moog ring in this video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bBrZw9CKDZo reply djmips 15 hours agorootparentprevFor [2] it does not look swept. Appears static. reply jessriedel 12 hours agorootparentYea, specifically it looks like the LEDs suspended on threads and statically fill the volume. reply 8n4vidtmkvmk 11 hours agorootparentprevThey said as much. reply m3kw9 17 hours agoparentprevfor a 32 inch display, you gonna get a motor that may need to spin like a mofo in an area of pi*32^2. reply aj7 9 hours agorootparentI’ve seen 1kW Chinese closed loop servomotors, with driver for ) after you&#x27;ve just picked it up. But the time to play an instrument so that at least you can tolerate your own sounds and have fun is much shorter -- and frankly, necessary I think not to give up before you can play really well (if that matters at all). reply MrsPeaches 12 hours agoprevFor anyone based in or visiting London, exhibitions at 180 Studios [1] often use this kind of tech for art shows. Well worth checking out if you are into art and tech.[1] https:&#x2F;&#x2F;www.180studios.com&#x2F; reply namuol 17 hours agoprev(Great YouTube channel if you’re into this sort of thing!)I wonder if a cheap oled display could be updated fast enough to achieve a much higher resolution. It might work but could look worse since the space between radial slices would be much larger than the pitch of the pixels, most likely. reply tromp 19 hours agoprevThe centering issue could be solved by putting two led boards on top, back to back.Perhaps one board could shift the leds over by half to create an interlacing effect while doubling resolution. reply o11c 15 hours agoparentOr just ... don&#x27;t center, and change the math to acknowledge that the LEDs aren&#x27;t centered? reply yafbum 14 hours agorootparentThere&#x27;s another similar thing needing correction, which is that the LEDs near the center sweep a much smaller volume than the ones at the edge, and should be dimmed in order to yield equivalent luminance. LEDs describing tiny circles very close to the center would need to be dimmed a lot since they&#x27;d essentially be stationary. Wouldn&#x27;t it be better then to sweep slightly larger circles at the middle anyways? reply o11c 10 hours agorootparentIf we&#x27;re going there, note also that all the LEDs not on the edge are blocked by other LEDs (or the board) part of the time; LEDs on the edge are visible even past 90°. reply swayvil 19 hours agoparentprevThere&#x27;s gotta be some way to replace the rack-of-leds-spinner with something lighter. Mirrors? Acrylic light pipe matrix? reply lstodd 18 hours agorootparentI wonder if it would be simpler to just spin two phone screens glued back-to-back. You get higher resolution in about the same weight. Bandwidth would be a problem though. reply mistercow 18 hours agorootparentThe fundamental problem is refresh rate. If you have two phones that refresh at 240Hz (the fastest I know of), and you want your frame rate to be 12 Hz, you’ll still only be getting 20 refreshes per 180 degree rotation. So your angular resolution will only be 9 degrees. Assuming you use portrait mode, that will make your outermost voxels ~5 mm arcs.And even there, 12 Hz is probably pushing it in terms of flicker. reply lstodd 17 hours agorootparentYeah, well, that&#x27;s not going to work. Interesting problem all the same.For a 1 meter diameter and height cylinder at 60Hz voxel refresh and say 1mm resolution at the edge one would need the plane rotating at obviously 3600 rpm, and edge pixels switching at about 380KHz. Since rgb is nice to have that&#x27;s 10 gigabit for a somewhat coarse display. Nothing impossible, but not a DIY territory yet.I think one&#x27;d want the LEDs either on the receding or the advancing halves of the plate, depending on which is best for the cooling -- not all on the same side or on both -- that would be just a waste.Or even just on one half of the plate, the other being just a countermass. This way cuts the bandwidth in two. reply dsr_ 16 hours agorootparentNote that in your hypothetical 1m 60Hz display, the edge of the cylinder is moving at 422 miles per hour. I&#x27;m going to recommend an evacuated transparent bell jar for safety, at a minimum... reply lstodd 15 hours agorootparentOf course it has to be evacuated and maybe filled with helium or something less viscous than air at low pressure; this has to be calculated wrt the heat rejection from the leds. Also centrifugal force shearing and tearing off components, imagine the fun.All in all, this is what makes it interesting, no? 1x1 meter holo tank, not those tiny Voxon shakers. reply CrazyStat 16 hours agorootparentprev> For a 1 meter diameter and height cylinder at 60Hz voxel refresh and say 1mm resolution at the edge one would need the plane rotating at obviously 3600 rpmThe edge of such a display would also be moving at several hundred miles per hour, which creates it own whole set of problems. reply mistercow 14 hours agorootparentprevI wonder if anyone has built multi-speed “layered” swept volumetric displays. For the center part, you would still just have one screen, but as you go further out, you’d have “spokes”, so that each screen only has to sweep a small angle (and roughly constant distance) during a frame, so that it rotates at lower RPM, and has to update fewer times.You would still need a bare minimum of 1-2 kHz, and a lot of screens, and balancing every layer would be super difficult, but I don’t think anything about it is fundamentally impossible with current technology. reply zrezzed 14 hours agorootparentNot exactly sure what the details, but there high quality, commercial products that are probably doing something like this: https:&#x2F;&#x2F;voxon.co&#x2F;products&#x2F; reply swayvil 13 hours agorootparentprevDoesn&#x27;t it have to be transparent?Are phone screens (minus the phone etc) transparent? reply jacquesm 14 hours agorootparentprevWhy do you think the weight is the problem? reply swayvil 13 hours agorootparentBecause EVIL = RPM X WEIGHT.And we can&#x27;t reduce RPM.Get it light enough and you don&#x27;t even have to center it that good. reply jacquesm 13 hours agorootparentAh ok, I figured that by casting the whole thing in resin and adding a top bearing it would get rid of the air flow issue completely at the expense of some extra work and a bit less light output. replyorbital-decay 12 hours agoprevMake an acrylic cube or a sphere, put inside a projection surface that&#x27;s able to rotate around one axis. Pump the air out for it to be silent and to be able to use a really thin sheet. Spin it with an external magnetic field. Project the distortion-corrected and spin-synchronized image to it with 2-3 projectors under different angles. Bang, you have your own Star Wars display that&#x27;s entirely doable by a hobbyist. reply late2part 11 hours agoparentCool! Can you do this and write up the steps like the article? reply d_tr 15 hours agoprevAnother recently posted cool volumetric display project which did not receive much attention:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38406824 reply Tenemo 19 hours agoprevI would pay $200+ for a bigger (50x50?), rugged, RGB version of this that you can make to display different images without coding. reply leetbulb 18 hours agoparentIt&#x27;s not volumetric, but it&#x27;s still really cool and may fit your use case https:&#x2F;&#x2F;spinprojector.com&#x2F; reply alright2565 17 hours agorootparentOnly place I&#x27;ve seen these before is at the Atlanta airport, where they use them to show a 3d-animated sign to remind you not to bring your gun through the security checkpoint. reply wongarsu 17 hours agorootparentI sometimes see them at trade fairs as an eye catcher. With the right background you can get a pretty convincing 3d effect out of them despite the \"display\" only being 2d reply crashmat 13 hours agorootparentprevI saw some poi that worked like that. The performer did a very good show with them reply sigil 13 hours agoprevMany years ago, someone did a similar holographic hack with a spinning hard drive motor, a piece of reflective plexiglass mounted upright on it, and a small projector. As the plexiglass carved out a cylinder, the projector sent a series of frames adjusted for each little slice of 3D space. [0]This gave me a wild idea: what if you could encode a low-resolution 3D video on the left channel of a stereo vinyl groove? [1] A special record player with a spinning plexiglass plate could then play holographic albums. The hologram would stay perfectly in sync with the music if you changed speeds or did turntable scratching.[0] If anyone can find a link to the original spinning hard drive hologram project please drop it![1] I assume this wild idea isn&#x27;t feasible given vinyl data rates? reply Someone 12 hours agoparent> assume this wild idea isn&#x27;t feasible given vinyl data rates?Data rates go up if you spin the disk faster, and can get fast enough for 2D video. I don’t think it was vinyl, but https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Television_Electronic_Disc:“Program information was stored in the form of ridges in the surface of a thin, flexible foil disc, which was claimed to be sufficiently robust to withstand being played 1,000 times. The main technological breakthrough was the vertical recording method that reduced the track pitch to 0.007 mm, and increased the rotation speed to 1,500 rpm, making it possible to record 130–150 grooves per millimeter, compared with the typical 10–13 grooves on an audio disc. This increased the available bandwidth from around 15 kHz to 3 MHz.” reply sigil 11 hours agorootparentAmazing, first I&#x27;ve heard of this. Here&#x27;s footage of someone playing a Television Electronic Disc: https:&#x2F;&#x2F;youtu.be&#x2F;XkP4ZJnMVOs?si=QbT4EXrE1dpq-Rtz reply gs17 13 hours agoparentprevThere&#x27;s a low tech version of the vinyl hologram: https:&#x2F;&#x2F;youtu.be&#x2F;aEbAaL7fPl4 reply sigil 11 hours agorootparentDifferent but pretty cool idea! reply fortran77 12 hours agoparentprevThere&#x27;s no \"Left Channel\" on a stereo vinyl groove. There&#x27;s an A+B channel (horizontal) and A-B Channel (vertical). Left and Right are created electronically from these two signals. reply sigil 11 hours agorootparentRight, I forgot this detail. Thanks for the correction. reply tgsovlerkhgsel 8 hours agoprevI wonder how much this could be improved&#x2F;sized up.Each pixel on such a setup travels along a circle. Spinning at 1200 rpm = 20&#x2F;second, a 1000 Hz display would have a resolution of 50 segments along this circle. With a 10 cm diameter, this would make the outer \"pixels\" in the virtual 3D display around 6mm long.The outer edge of the display would also experience a force of 80 G at that point, so bigger and&#x2F;or faster spinning quickly becomes challenging (although it&#x27;s only linear).Driving monochrome OLED displays at 500+ Hz has already been done https:&#x2F;&#x2F;blog.adafruit.com&#x2F;2012&#x2F;02&#x2F;03&#x2F;adafruit-ssd1306-monoch... reply aj7 9 hours agoprevWhy waste time with a bunch of discrete LED chips mounted at very coarse pitch when there are small LED DISPLAYS? reply TulliusCicero 4 hours agoparentAccording to other comments, refresh rate.When each pixel actually represents multiple pixels in a circle, you need a much higher refresh rate than 60 Hz. reply francisduvivier 18 hours agoprevPretty cool, but the bigger the display, the more that refresh rate becomes an issue. Say you can refresh the outer pixels on the horizonal axis at 100 fps. Then if you want to have 50 pixels on the outer half circle, then you can change them at 2fps. reply kragen 16 hours agoparentconventional leds can be driven at several megahertz pretty easily. the white type uses a yellow phosphor that fades slowly but they can still do kilohertz reply derac 15 hours agoprevThat&#x27;s so cool! It would be interesting to see how it would perform in a vacuum. I wonder how big you could feasibly make it with vacuum containment. reply jacquesm 14 hours agoparentSize is mostly about balance and engineering, if you cast the whole thing in resin you can spin it as fast as you want (or until the resin breaks apart). reply joelegner 12 hours agoprevEven if you never intend to attempt a project like this, there is something valuable to be gained by reading narratives like this: humility. Not many folks could pull this off. I sure could not. It’s a good reality check. reply tasty_freeze 18 hours agoprevholy hell is this guy productive. it is worth scrolling through the various one-off projects he has completed and documented:https:&#x2F;&#x2F;mitxela.com&#x2F;projects reply fallat 16 hours agoparentI thought so too but look at the dates and the scope of the projects. They&#x27;re just good at managing their time :) I probably have just as many projects accumulated over the years. reply davidw 14 hours agoparentprevI feel like a bit of an incompetent after looking through all that. reply jacquesm 11 hours agorootparentJust a catalogue of all the skills on display is already the stuff of a couple of lifetimes. reply DesiLurker 15 hours agoparentprev. reply bigbonch 11 hours agoprevReminds me of this 20Q toy I had as a kid: https:&#x2F;&#x2F;youtu.be&#x2F;2C1No7cv84o?si=xAFibiv9LeVxM-rF reply LAC-Tech 14 hours agoprevThat&#x27;s beautiful. Nothing intelligent to add, just a very neat, clever and aesthetic project. reply papichulo4 13 hours agoparentHa, came here with similar feelings. Put it on a stick! Is what I thought… Could it be on a handle of sorts? reply 55555 18 hours agoprevThis would look better with the LEDs on a transparent PCB, right? reply bee_rider 18 hours agoparentI bet you could to it with those little fiber-optic wires. Not the fancy telecommunications ones, the cheap stuff they use to make decorations.I wonder how they respond to being dunked in epoxy. reply blincoln 16 hours agorootparentLEDs connected directly by rigid wires (no PCB at all), then encased in resin might be worth considering too. reply nothacking 10 hours agoprevI wonder if inductive power transfer could be used to eliminate the need for a battery. It would only have to power the LEDs, not the motor as that could be mounted to the base. Additionally, both coils could be placed right inside of each other, and on a ferrite core. reply s0rce 10 hours agoprevAre micro LED panels commercially available yet? Seems perfect for something like this. reply isuckatcoding 15 hours agoprevThis makes me wonder if anyone has tried to create the Las Vegas sphere on a smaller scale themselves because that would be awesome reply augustulus 7 hours agoprevyou might be able to improve the image with something like this, or a plastic version of ithttps:&#x2F;&#x2F;thepihut.com&#x2F;products&#x2F;ito-indium-tin-oxide-coated-gl... reply dsalzman 19 hours agoprevNice example of persistence of vision display. You can use large stick versions of this to “paint” images by waving them around. reply blincoln 16 hours agoprevThis is a neat project. With such a low resolution, am I wrong in thinking that the flame simulation could be done in real time on-chip using a cellular automata algorithm? It would still be nice to support pre-rendered video for other purposes, of course. reply Retr0id 19 hours agoprevIt would be hard to manufacture at scale, but what if the LEDs were mid-mounted into a slot cut into the PCB? reply alright2565 17 hours agoparentnot at all hard to do, they make \"reverse mount\" leds, where the diode faces into the PCB: https:&#x2F;&#x2F;www.digikey.com&#x2F;en&#x2F;products&#x2F;detail&#x2F;sunled&#x2F;XZMYK55W-3...compatible with the exact same pick-and-place machines, you just need to drill a hole in the PCB reply atticora 18 hours agoparentprevOr suspended in a wire net. reply skibz 17 hours agoprevI love projects like this that exploit the POV phenomenon.Here&#x27;s another cool one I found a while ago: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wM_Byrv9iBI reply merelysounds 16 hours agoprevI’d prefer this kind of spatial computing, I like it more than AR&#x2F;VR – especially that this relies more on human sensory input, as opposed to working against it. E.g. no need to simulate head tracking. reply lordwiz 18 hours agoprevLooks Pretty cool, Interesting how blender was integrated into such workflows for animation in hardware reply falker 18 hours agoprevThe RP2040 tiny is a Nintendo Switch modchip in disguise (47 ohm resistors on 3 specific pins). reply intrasight 15 hours agoprevNo video? Or did I miss it? reply bobsmooth 18 hours agoprevUsing blender to generate the frames is really clever. reply FredPret 18 hours agoprevThe rest of the site is filled with dozens of similar very cool projects reply blkhawk 13 hours agoprevanybody know if it would have been better to put half the LEDs on each side of the PCB in alternating lines? reply imdsm 20 hours agoprevI love this. Must be a lot of fun to work on it! reply K0balt 18 hours agoprevIt seems like this might Work even better with a two sided OLED screen (2 screens back to back) rather than led array, for better resolution? I think that are sufficiently wide angle, at least the monochrome ones. reply sporeray 18 hours agoparentI think OLEDs might have a refresh rate issue. The nice thing about LEDs is that you can drive them at a very high refresh rate. reply buildbot 17 hours agorootparentDon’t oled displays support pretty high refresh rates? And also have way lower GtG latency? reply throwawayben 11 hours agorootparentwith this kind of spinning display you&#x27;d need to multiply the frame rate you want by the angular resolution you want. So if you&#x27;re happy with only 20 different angular views and only a 20fps refresh rate of the 3d display then that&#x27;s 400fps required of the flat display reply IAmGraydon 16 hours agoprevThis is so awesome. reply Solvency 17 hours agoprevOk I just went down the rabbit hole of this guys projects over the last decade and I am now thoroughly impressed and utterly depressed that I&#x27;ll never have as much free time as he does. reply djmips 15 hours agoparentFree time is an excuse for most people - I&#x27;m not calling you out because I don&#x27;t know you but most people spend a lot of time on YouTube - Hn - Watching TV etc and they could be working on a cool project instead. reply garaetjjte 12 hours agorootparentHe even has entry on this topic: https:&#x2F;&#x2F;mitxela.com&#x2F;rants (scroll down to \"Spare Time and Hard Work\") reply julianpye 11 hours agorootparentHis work is even more inspirational after reading this rant, as he describes the therapeutic aspect of his projects and his base emotions. Still, I can&#x27;t help but excuse my inferior output by admiring his incredible fine motor skills and pre-existing expertise in electronics. reply jacquesm 11 hours agorootparentThose fine motor skills will go though, use them while you have them! Especially for fine soldering work you need a very steady hand and that which used to be trivial suddenly is a real challenge. reply julianpye 11 hours agorootparentIndeed! His soldering work is of the highest art. reply Solvency 14 hours agorootparentprevWatching TV? YouTube? Sounds like your peer group is biasing you. How about struggling to work from home for 8 hours a day with two kids with zero familial support, an endless array of bills, and every possible life obstacle coming your way 24&#x2F;7? reply djmips 14 hours agorootparentI wasn&#x27;t calling you out. I don&#x27;t know you. (look what I wrote) - best of luck in your situation! reply pcdoodle 19 hours agoprevThat is cool.The code is lean too, seems like one could learn a lot by trying to do this themselves. reply swayvil 19 hours agoprevThis is tight. Presently working on a list of uses.Need one the size of a 5gal bucket.As it is, I&#x27;d stick one on my gimcrack cabinet. reply ilaksh 19 hours agoparenthttps:&#x2F;&#x2F;youtu.be&#x2F;CCuybyAO8fs?si=xBLYy5zKEEcloqeA reply leetbulb 18 hours agorootparentWow this one is cool. First time I&#x27;ve seen it. Reciprocating screen? How the hell do they get it to move that quickly? That is very high energy.Edit found another video showing it starting up https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=SMz4bJA47JsNow that I think about it, I suppose if you match the resonate frequency of the display component and its carrier it should be fairly efficient. Really cool stuff. reply eichin 14 hours agorootparentOther videos say that the bubble is just to protect the screen because (unsurprisingly, I would) people try to touch it - so it&#x27;s not evacuated; doesn&#x27;t that mean it&#x27;s going to be a fairly loud 30hz speaker, effectively? (or is it just not well coupled because \"speakers need to actually be designed\" and it&#x27;s not that bad in practice?) reply swayvil 15 hours agorootparentprevIt&#x27;s so smooth! reply ilaksh 19 hours agoparentprevhttps:&#x2F;&#x2F;youtu.be&#x2F;mxyw6LkAtiQ?si=xK0x8-rEoG0KvzPp reply fortran77 12 hours agoparentprevHaving electronic candles that display a real 3D image of a burning flame seems like a great use for me! People would love these for outdoor \"candle\" displays. reply brilee 16 hours agoprev [–] geohot built one of these in high schoolhttps:&#x2F;&#x2F;www.forbes.com&#x2F;forbes&#x2F;2007&#x2F;0723&#x2F;060.html?sh=3c183bcb... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has successfully built a small volumetric display using a LED matrix board and a pick and place machine.",
      "They explain their decisions on selecting the microcontroller and battery for the project.",
      "The author goes into detail about the assembly, wiring, and software setup for the prototype, as well as challenges they faced with the battery charger and rendering animations.",
      "They provide suggestions for future improvements and offer the source code on GitHub."
    ],
    "commentSummary": [
      "The article and discussion focus on volumetric displays, microLEDs, holographic technology, and persistence of vision (POV) displays.",
      "Participants share their experiences, challenges, and suggestions for improvement in these projects.",
      "Virtual reality/augmented reality headsets are seen as a preferable option for real 3D visualization compared to these technologies."
    ],
    "points": 1228,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1701519785
  },
  {
    "id": 38503486,
    "title": "Rejected as Not a Real Engineer: Mythical Abilities Not Enough",
    "originLink": "https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html",
    "originBody": "Not a real engineer by Richard Marmorstein - May 29, 2019 ← Home You are not a real engineer. You are a creature with a terrible countenance the stature of a man and the head of a lion with sixteen wings about you white as fresh snow hundreds of eyes that flicker like torches and dart in all directions the belt at your waist is a serpent your breath is the gathering of stormclouds your voice is the roar of the wind the grass withers before your footsteps and your writhing, ponderous tongue black as the abyss brings apocalypse upon everything it touches We regret to inform you we will not be offering you the role at this time – we’re looking for somebody more technical Thanks for reading! To read more by me, you can subscribe to the Atom feed or follow my Twitter. You might be interested in my next post, \"life is too short for jenkins\". The worst thing about Jenkins is that it works. Home",
    "commentLink": "https://news.ycombinator.com/item?id=38503486",
    "commentBody": "Not a real engineer (2019)Hacker NewspastloginNot a real engineer (2019) (twitchard.github.io) 244 points by lakesare 9 hours ago| hidepastfavorite34 comments exclusiv 5 hours agoI just recently got into Steve Howe. He&#x27;s considered one of, if not the best guitarist of all time and I came across a quote he had that said something like he wished guitarists would focus on being musicians. Same thing as coders to engineers.I&#x27;ve come across more technically able programmers than I am. But they aren&#x27;t better engineers. And a lot of that is because I&#x27;m an entrepreneur and have a marketing secondary background as well.So many companies discount non coding skillsets that actually make one an engineer in my opinion.They hire the butcher instead of the chef and then wonder why it tastes like shit when it&#x27;s cooked. reply uguuo_o 3 hours agoparentJust a minor note. Howe is good, one of the best yes, but Paco De Lucia reigns far above them all. reply l33t7332273 3 hours agorootparentCan you add some qualitative comparisons that make you say that? reply Lexforce 1 hour agorootparentHere’s a fantastic display of Paco de Lucia’s music: https:&#x2F;&#x2F;youtu.be&#x2F;0o8vszqVL2U?si=XtT-dhzaQZuKOoyN reply appplication 9 hours agoprevThis was quite entertaining and not the direction I thought it was going. Thanks for sharing. reply Aeolun 9 hours agoparentI had no idea where it was going all the way until the end. reply shermantanktop 45 minutes agoprevI’ve lived both sides of this. I’ve been subjected to the mysterious whims and casual insults of the job-seeking process. I’ve also interviewed and rejected experienced candidates who talked a great game but couldn’t demonstrate the ability to code FizzBuzz-level problems in any language.It’s not a choice between “the tech interview sucks” and “the job market has many unqualified candidates.” Both can be true, and in fact I think they are related in a market-for-lemons way. reply t43562 1 hour agoprevThe people doing hiring make mistakes - it&#x27;s a bloody difficult thing to do successfully. They also sometimes save you from working in a place with people you wouldn&#x27;t like much anyhow. They&#x27;re not really good at coming up with excuses why they didn&#x27;t select you - it&#x27;s a crap shoot. Perhaps they get a \"not a Trump supporter\" impression from you and that makes them feel like you&#x27;ll never fit comfortably. If you really aren&#x27;t their kind of person why would one want to work there?The search for a job always puts me in a depression and I haven&#x27;t got any answer except that you have to not hope too much about any one job - or be too dismissive of one that doesn&#x27;t seem quite so amazing. You just cannot tell what will happen - my first boss in my current job turned out to be horrendous and there were not nice people working there and ...... they left the company! I got promoted. How could I predict that? The hiring people cannot predict you either - it&#x27;s all a bit of a random and uncomfortable process.When I&#x27;m on the other side of the table I&#x27;ve got some priorities:1. My boss gave me a short bit of advice which is \"try to hire nice people.\" I&#x27;d rather work with good developers who can be friendly and help each other and get along without always having to get their way than people who think they are highly productive geniuses and deserve to be in total control.2. Is the candidate interested in software, or indeed anything. If they are not a bit enthusiastic about software, technology or something relating to the work then how will they learn the things they need to know that aren&#x27;t on their CV? One should expect people to need to learn and not come \"ready made.\" reply LaGrange 1 hour agoparent> If you really aren&#x27;t their kind of person why would one want to work there?I like to be able to afford my rent. Some food sometimes, as a treat. reply t43562 38 minutes agorootparentI think that people in the software industry usually have quite a lot of options. Sometimes you might have to be prepared to move or to take a salary hit, but of all professions it seems to be quite a good one to be in at the moment - at least where I am and compared to everyone else. reply OldGuyInTheClub 7 hours agoprevAn avatar of Vishnu can&#x27;t get hired? Sounds about right.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Narasimha reply AdieuToLogic 6 hours agoparentThe problem with Vishnu is he is limited to only having four arms and two ears, which of course limits Vishnu to supporting at most two production systems and, therefore, not being able to handle \"web scale.\"[0]0 - https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=b2F-DItXtZs reply OldGuyInTheClub 5 hours agorootparentAh, yes. Minimum of ten years experience in a tool that&#x27;s only been around for five.I miss Xtranormal. reply madcocomo 5 hours agoprevdraw it by SD https:&#x2F;&#x2F;poe.com&#x2F;s&#x2F;LbD6hkWaxr1qMNtBwAVQ reply Tcepsa 6 hours agoprevI love it! Reminds me a bit of the protagonist of Aphyr&#x27;s Verb-ing the Technical Interview series, with the parentheses of salt and bough of cloud pine and deep arcane knowledge. reply teddyh 3 hours agoparentI think this is what you are referring to:reply rosquillas 9 hours agoprevIt&#x27;s strangely beautiful reply hschne 2 hours agoprevHilarious and unexpected twist at the end. Can&#x27;t believe I haven&#x27;t seen this before. reply quickthrower2 9 hours agoprev> the belt at your waist is a serpentAh..... you could have just said it wasn&#x27;t a Python position. Are you after a crustacean or a gopher? reply clbrmbr 8 hours agoparentOmg. Crustacean. I just got it! (Doing AoC this year to develop my exoskeleton.) reply metabagel 6 hours agorootparentI’m doing AOC as well to learn python, just for fun. reply AdieuToLogic 7 hours agoprevMy favourite, slathered with a generous amount of sarcasm gravy, is: They feel they have candidates who are a bit stronger coding wise that fit their needs right now that they want to proceed with.This said twice.Once before any interaction at all and the same after an initial meeting when the technical interviewer had not bothered to review any of multiple FOSS projects made available beforehand. reply henriquez 5 hours agoprevI was recently unemployed and this hits home. The morons who rejected me had no fathom of an inkling of a tenth of what I’m capable of. reply brianpan 3 hours agoprevThat person&#x27;s website DEFINITELY does not try to drive you insane with CSS that slowly changes second-by-second.It&#x27;s fine. It&#x27;s normal. It&#x27;s fine. It&#x27;s fine. It&#x27;s fine. reply jongjong 7 hours agoprevSo it&#x27;s not just me then. Is it implying that software engineer job adverts are fake?If the problem is oversupply of talent, you&#x27;d think salaries should drop as people compete for limited jobs... But that would only be the case if we had a free market.I feel like to get a job as a software engineer, you have to pretend to be brainwashed. Just act very friendly and optimistic, pretend to be member of a minority group and make sure you tell them that you&#x27;re fully vaccinated and boosted. Also, use a stage name on your resume instead of your real name and a separate email address. reply kazinator 7 hours agoparentThe way I interpret the poem&#x27;s message is that sometimes hiring can concentrate on the wrong estimators of ability, ignoring indicators that the applicant can open a can of whoop-ass. reply klik99 7 hours agorootparentInteresting - I interpreted it as how it feels to take rejection very personally - someone not getting the job feeling like there is something deeply wrong with themselves reply appplication 6 hours agorootparentI also interpreted it this way. Despite your knowledge of who you are and what you believe you have to offer, job interview rejection can feel like a personal attack.Of course you’re not a fit for this role, why would you ever apply? We considered you before we knew who you were. But now we see you as you truly are. Monstrously unqualified. Your 15 years of experience in distributed systems is nice, but we’re really looking for someone who could invert a binary tree in 10 minutes, and, well, you were on track for 20+ before we kindly stepped in and asked if you had any questions for us. reply OldGuyInTheClub 7 hours agorootparentprevI thought this as well. At my shop, everyone in the hiring chain has adopted the \"Talent Acq\" mindset. Even engineering managers just do Keyword matching for skills. No one thinks about the problem needing to be solved and that maybe, just maybe, complex problems require people who can \"open a can of whoop-ass\" on them. That&#x27;s a gift, not a skill and it does NOT fit the process. reply numpad0 3 hours agoparentprevBusinesses desire either money printing machines or money printing operators. Generic printer architects are rarely needed because they’re not specialized in printing money fast. Nevertheless postings say they’re looking for architects. reply raincom 9 hours agoprev [–] “we’re looking for somebody more technical” = Yes, they are looking for that savior to solve all problems—-problems that hiring manager&#x2F;hiring group&#x2F;hiring company want to solve. Yes, where is that person? where is he&#x2F;she? reply 082349872349872 8 hours agoparent\"The job posting clearly asks for seven stars and seven candlesticks, yet the candidate only demonstrated five stars and no candlesticks during the interview. Hard Pass.\" reply nine_k 8 hours agoparentprev [–] Usually somewhere in Unaffordabland. reply mysterydip 8 hours agorootparent [–] \"Our salary range actually tops out at half what we posted. If we posted the real range, we wouldn&#x27;t get enough qualified candidates!\" replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts receiving an email rejecting their application for an engineering role.",
      "They use a metaphorical description of themselves as a mythical creature with impressive qualities.",
      "The reason given for not being selected is that they were not considered technically proficient enough."
    ],
    "commentSummary": [
      "The article addresses the hiring process for software engineers and the focus on technical skills at the expense of other important traits.",
      "The author argues that skills like entrepreneurship and marketing are often undervalued but are crucial for success in engineering.",
      "The article highlights the frustration of qualified job seekers who feel rejected due to the heavy emphasis on technical abilities."
    ],
    "points": 244,
    "commentCount": 34,
    "retryCount": 0,
    "time": 1701561903
  },
  {
    "id": 38500906,
    "title": "Singing to Babies Aids Language Learning via Rhythm and Tone",
    "originLink": "https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists",
    "originBody": "The study said dyslexia and developmental language disorder may be associated with rhythm perception. Photograph: Dobrila Vignjevic/Getty Images Language Singing to babies is vital to help them learn language, say scientists Study finds infants first understand language via rhythm and tone rather than individual sounds Jamie Grierson @JamieGrierson Fri 1 Dec 2023 07.32 EST A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P … How many would read this to that tune? According to scientists from the University of Cambridge, there’s more to the earworm than infuriating parents across the English-speaking world – they have found that singsong speech is crucial to helping babies learn language. The study concluded that infants learn languages from rhythmic information – the rise and fall of tone – as seen in nursery rhymes or songs, such as the ubiquitous alphabet song. The team at Cambridge also discovered that babies do not begin to process phonetic information – the smallest sounds of speech – until they are about seven months old. The researchers said that the findings, which have been published in the journal Nature Communications, challenge the view that phonetic information – typically represented by the alphabet – is the key to language learning. They said it also suggests that dyslexia and developmental language disorder may be associated with rhythm perception rather than difficulties with processing phonetic information. Prof Usha Goswami, a neuroscientist at the University of Cambridge who is the study’s author, said: “Our research shows that the individual sounds of speech are not processed reliably until around seven months, even though most infants can recognise familiar words like ‘bottle’ by this point. “From then individual speech sounds are still added in very slowly – too slowly to form the basis of language. We believe that speech rhythm information is the hidden glue underpinning the development of a well-functioning language system. “Parents should talk and sing to their babies as much as possible or use infant-directed speech like nursery rhymes because it will make a difference to language outcome.” It has previously been thought that infants learn small sound elements and add them together to make words. To understand whether that was the case, the researchers recorded the brain activity of 50 infants at four, seven and 11 months old as they watched a video of a primary school teacher singing 18 nursery rhymes. The team used special algorithms to interpret how the infants were encoding this information in the brain. The scientists found that phonetic encoding in babies emerged gradually over the first year of life, beginning with dental sounds (produced by the upper front teeth) – such as “d” for “daddy” – and nasal sounds (produced when airflow is directed through the nose) – such as “m” for “mummy”. Goswami said: “Infants can use rhythmic information like a scaffold or skeleton to add phonetic information on to. For example, they might learn that the rhythm pattern of English words is typically strong-weak, as in ‘daddy’ or ‘mummy’, with the stress on the first syllable. “They can use this rhythm pattern to guess where one word ends and another begins when listening to natural speech.” She said rhythm is a universal aspect of every language where all babies “are exposed to … a strong beat structure with a strong syllable twice a second”, adding: “We’re biologically programmed to emphasise this when speaking to babies.” The study forms part of the BabyRhythm project led by Goswami, which is investigating how language is related to dyslexia and developmental language disorder. She said there was a long history of trying to explain these in terms of phonetic problems but the evidence does not add up, and individual differences in children’s language learning skills may originate with rhythm. Explore more on these topics Language Children Neuroscience Parents and parenting Family news Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=38500906",
    "commentBody": "Infants understand language via rhythm and tone rather than individual soundsHacker NewspastloginInfants understand language via rhythm and tone rather than individual sounds (theguardian.com) 202 points by im_dario 15 hours ago| hidepastfavorite82 comments gnicholas 11 hours agoI wonder how this squares with the research on cultures where parents scarcely talk to babies, and they turn out fine? [1]1: https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;parents-in-a-remo... reply crooked-v 11 hours agoparentThe article notes that the babies are with their mothers most of the time, so they&#x27;re probably exposed to plenty of language even if it not specifically aimed at them. reply gnicholas 11 hours agorootparentOh sure, but they&#x27;re presumably not using sing-song baby language, or perhaps singing songs all that much. reply theNJR 4 hours agorootparentIm in the midst of reading Pinkers the Language Instinct and the basic thesis is that language is innate. Preventing language would be like preventing eating.The sing-song thing is cultural but powerful. It’s hard (for me) to not default to it with my one year old.Edit: LOL I clearly commented before reading the article. reply OfSanguineFire 1 hour agorootparentWe know of cases where, due to living early years in isolation, a human being was prevented from learning full-fledged language, e.g. Genie.[0][0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Genie_(feral_child) reply EGreg 2 hours agorootparentprevWho says that sing-songy language is necessary? Kids actually crave being taken seriously like adults and teachers who do that are often well liked!My actual question is … how to develop good humor and playfulness in kids? Some people grow up with somewhat stunted senses of humor it seems. Is there something one can do? Research? reply GenerocUsername 1 hour agorootparentDifference between toddlers and kids. replyearlygray 7 hours agoprevMy parents were deaf, so there wasn&#x27;t much singing to me when I was a baby. But I managed to pick up spoken language anyhow so I doubt that singing is vital as the headline suggests. Generally as long as babies aren&#x27;t deprived or abused when they are young, they&#x27;ll grow up fine. reply dzolob 12 hours agoprevI just sang, sang, sang anything that came to my mind. About mountains, clouds, courage, poo… It was just love pouring out of my heart, and I don’t know if it had something to do with it, but my kid started talking very early on and very well.The best thing is was that I got to know him very soon, while my peers and their daughters&#x2F;sons still were kind of communicating. reply mattlondon 11 hours agoparentIt seems to vary a lot in my experience. I have two kids who basically got the same treatment. One was eloquently talking in coherent sentences of 4 or 5 words by 18 months (\"plane in the sky\", \"teddy come downstairs\", \"want something to eat\" etc) and was understandable by others outside the family, the other kid was barely able to grunt single words at the same age (\"mukk\" instead of milk, \"nur-sa\" instead of nursery etc) that only we really understood as it was just incomprehensible sounds to everyone elseSinging made fuck all difference in that case (FWIW, the grunter is now totally fine as an older kid). Both were walking at 10 months so it was not like one was just \"slow\" at their milestonesAs they say, every baby is different. reply pstuart 10 hours agorootparentnext [14 more] Yep. Having more than one kid disabuses us of the notion that our parenting was the driver in how awesome the kid turns out.That said, I believe it&#x27;s nature and nurture in the end. reply e1g 10 hours agorootparentSame here, two kids and zero strategies that worked with one apply to the other. Might as well be raising a dog and a dolphin. reply CSMastermind 9 hours agorootparent> Might as well be raising a dog and a dolphin.That made me chuckle.But it&#x27;s possible for siblings not to share any genetic material right?A brother and a sister would obviously get different genes from their father and presumably there would be a 50&#x2F;50 chance of them getting different genes from their mother.There&#x27;s four unique prototypes of children any two people can produce together. reply harry_ord 2 hours agorootparent> But it&#x27;s possible for siblings not to share any genetic material right?Kinda but the mother always provides the mitochondria. reply CSMastermind 1 hour agorootparentI think that&#x27;s an area of open research: https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;full&#x2F;10.1073&#x2F;pnas.1810946115But yes, that&#x27;s a good distinction I should have made! reply darkerside 9 hours agorootparentprevFour prototypes? reply danwills 8 hours agorootparentGamete cells get a random half of all genes from each parent so there&#x27;s about 2 unique possible &#x27;sets&#x27; from each parent, and 2*2=4. However because it&#x27;s random I think you can only say there are 4 distinct completely unique possibilities in theory, but it would be very unlikely for that to actually happen in practice. reply darkerside 6 hours agorootparentAhh, as in fully exclusive sets of genes reply fsckboy 7 hours agorootparentprev>Four prototypes?gp said four unique prototypes reply rand0mx1 7 hours agorootparentprevProbably genotype. Isn&#x27;t it reply caseymarquis 8 hours agorootparentprevI thought it was more like 2^23 unique prototypes? reply tbcj 9 hours agorootparentprevMy experience as well. My two are so different it’s hard to even parent at times as they need different kinds of attention. You can’t really give yourself in different ways at the same time. We recognize that one - being born in the lockdown environment - is likely different in meaningful ways than our first. Our first is helpful in she almost recognizes a difference. reply jascination 8 hours agorootparentprevSame. Have twins (fraternal) and their milestones are completely different despite pretty much identical treatment all things considered. They&#x27;re also naturally better at certain things (twin A better at physical milestones, twin B better at social milestones). reply pstuart 6 hours agorootparentFraternal twins as well -- night and day. reply Loughla 10 hours agoparentprevWe talked constantly to ours. Not about anything in particular. Just narrating everything we did. Constantly.Our oldest was talking in full sentences at 1 year. It was astounding. Now, granted, it was stuff like, \"I&#x27;m dunna det da fwad\" but he was communicating in full thoughts at about the time he walked.People always asked what system we used for teaching him. Our answer was always, \"it&#x27;s boring at our house so we talk a lot.\" reply gardenhedge 8 hours agorootparentEveryone talks to their babies a lot. What does \"it&#x27;s boring at our house\" mean? reply Loughla 8 hours agorootparentIt&#x27;s a joke. We live in a very rural area. So there&#x27;s not much going on. We also don&#x27;t do personal consumption devices (tablet&#x2F;phone) in the home. reply jacobolus 3 hours agorootparentprev> Everyone talks to their babies a lotMost people talk to their babies at least sometimes, but observing families there are huge differences between how much people talk to their babies, how they talk to them, what subjects they talk about, how many different languages they use, etc. reply EGreg 2 hours agorootparentIf they have a lot of siblings there is even more speech reply 2Gkashmiri 2 hours agorootparentI have a family with a lot of kids. Their neighbour was living with his small family somewhere else for a year where their kids had the sibling and grandparents to talk to.The younger of two had speech problems.Then they returned home and the neighbour kids made both of them to talk in a matter of weeks and months. reply EGreg 2 hours agorootparentSo is this confirming my point? Sorry, I am a bit confused who made who talk etc. reply 2Gkashmiri 1 hour agorootparentMy relatives who had the bunch of kids and their neighbour who had two kids who wouldnt talk. replyjeffbee 12 hours agoparentprevAccording to the article it would seem to be a matter of just throwing in as much variety of tone, inflection, and articulation as you can manage. The don&#x27;t understand what you&#x27;re saying anyway.My career as a singer-to-babies was heavy on the Broadway tunes. \"On the Street Where You Live\" was big. reply ghostpepper 12 hours agorootparentThere is something magical about hearing a toddler mumble out an entire verse of Fly Me To The Moon or Autumn Leaves reply player1234 44 minutes agoprevWhat total bs, infants try to guess the next token like all intelligent beings, everyone knows that. reply j45 11 hours agoprevThis is 100% my experience.The amount of vocabulary that is learned through the experience and play of song is astounding. Similar to a song tied to a memory. Exposure to diverse cuisine and music before birth both seems to be helpful too to the degree possible.The number of words I have seen the little ones in my life absorb and use before age 1.5 to 3 leaves you a little speechless.So many words, syllables, full sentences, and a way to reduce some of the little frustrations of not being able to express yourself.So many words seem to musically originating in a few ways in hind sight:First is reading, talking and singing anything you can as much as one can. Learning the sound of the voices around them is super valuable if present from the start.Next is ending up being children of the digital co-parent and teacher Miss Rachel. Her content on YouTube was irreplaceable during the pandemic, and the bonus of speaking in song was one of the biggest gifts to learn.Last, but not least is a Reggio Emilia child development &#x2F; care program. If a parent has a chance to check out a Reggio Emilia centric child care program in regards to this topic of learning expression, more than not it’s an invitation to explore and play with lots of music and vocabulary. What’s neat is no place can be Reggio Emilia certified because it’s a town in Italy, so the methods can be freely taught, learned and used at home too.What stands out is all of the children in Reggio Emilia programs are not the same, they are very ok with structure but just as adaptable with going with the flow of the fire alarm goes off. The rigour in fuelling music, dance, craft, curiosity, imagination, exploration, interaction and expression.There will be some parents who find this approach a fit for them, (it’s a little different than Montessori which can be tough for some children to switch into a regular world program) as it focuses on helping each child bring out their uniqueness at their own pace. reply tomcam 12 hours agoprevOr not. I can sing but all my kids hated it. On the other hand, I always spoke to them using non-baby language, humor, and mannerisms, and they turned out to be incredibly good communicators. reply dymk 12 hours agoparentOr maybe the scientists who specialize in child development and linguistics know something you don’t reply tomcam 12 hours agorootparentZany thought! I’m deeply offended you weren’t immediately convinced by my single piece of anecdotal data ;) reply zagrebian 10 hours agoprevThey should do a study to test if letting babies watch a show like Last Airbender instead of Teletubbies has a positive effect. reply Loughla 10 hours agoparentReal talk though. Kids and babies aren&#x27;t stupid. So if you take the time to explain things, they pick up on more than you would believe.Where many people go wrong is that they assume little kids are stupid instead of understanding that they lack context. reply shadowfoxx 9 hours agorootparentYeah it seems to me like a human bias against ignorance. We have this notion that if people that don&#x27;t know the knowledge that we know they must be dumb because, \"everybody knows ____\".Kids are literally just the definition of inexperienced. reply bitwize 10 hours agoparentprevPerhaps because they were highly, highly experimental, the early little kids&#x27; edutainment shows, like Sesame Street and Mister Rogers&#x27; Neighborhood, just struck me as much better because they didn&#x27;t insult children&#x27;s intelligence, spoke to them as full persons, and had relatively rich and complex imagery, music, story, and humor. Which is why they&#x27;re so watchable and beloved by adults.And then Elmo happened and then Barney happened, and things have been on kind of a downhill slide into brightly colored, C-major MIDI music Cocomelon happyland. reply xattt 9 hours agorootparentCocomelon songs give me some sort of whole-body repulsion if it comes on on shuffle in the car.Classics that sound great sung by Raffi, Ella Jenkins and even Caspar Babypants are some sort of ear mush when done by Cocomelon, Kidz Bop et al. reply kaetemi 4 hours agorootparentCocomelon are all sung in this weird smug condescending tone. It&#x27;s really unpleasant.Compare with Pokémon Kids TV, which sounds really cheerful, and you can hear the singer is really enjoying themselves. Also mostly the same classic children songs, but so much more enjoyable to listen to.The generic midi versus funny experimental instrumentation play a part too. reply jacobolus 3 hours agorootparentMister Rogers had an excellent jazz pianist doing all the music live in studio throughout. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Johnny_Costa replyTerr_ 5 hours agoprev> Infants understand language via rhythm and tone rather than individual soundsI feel this must explain something about the Pingu stop-motion animations, which feature a made-up babble-language that some people think is real-but-foreign. reply markdown 2 hours agoprevReminds me of the chicken boy who spent four years as an infant in a chicken coop.> he communicates by making a rapid clicking noise with his tonguehttps:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2004&#x2F;jul&#x2F;11&#x2F;fiji.jennyfors... reply ourmandave 7 hours agoprevDoes it count if we watch musicals together? Classics, like What&#x27;s Opera Doc?https:&#x2F;&#x2F;www.facebook.com&#x2F;watch&#x2F;?v=1199392770567826 reply ceeam 12 hours agoprevBut try avoiding death metal growl. reply parasti 4 hours agoparentI&#x27;ve been doing that as well as beatboxing (inward bass, subharmonics). The baby is seemingly trying to replicate some of it, but obviously they&#x27;re not word-like sounds. reply ipnon 13 hours agoprevThis seems to be why people naturally default to sing-song when speaking to babies. reply rowyourboat 3 hours agoparentI thought that was cultural. There are cultures that don&#x27;t talk to babies at all. reply gardenhedge 11 hours agoparentprevDoes it explain why people do that? Are you suggesting we intrinsically know that singing to a baby is beneficial for learning? reply gumby 11 hours agorootparentIf you believe that speech is a survival skill (which I would think most people believe) then anything that increases its prevalence or effectiveness would be evolutionarily selected for, right? We’re talking a 300-500+ Ky period, probably almost 2X that (depending upon the speech capabilities of our hominid ancestors), so plenty of time for evolutionary pressure to apply. reply animitronix 11 hours agorootparentprevYes, some shit comes built-in. reply vr46 14 hours agoprevPersonal recommendations are:* Elmo’s Song* Feist’s Sesame Street version of 1-2-3-4 reply lostmsu 13 hours agoparentI did the dwarf song (Far over the misty mountains) reply tomrod 13 hours agoparentprev\"I love the mountains I loved the rolling hills.\"I love the flowers I love the daffodils.\"I love the fire side when all the lights are low.\"Boom dee Yada boom dee Yada boom.\" reply owenpalmer 13 hours agorootparentMy sisters and I always loved playing the duet of this song on piano. reply corethree 13 hours agoparentprevMaybe more complex songs and songs with big words can make the baby more articulate. Maybe rap will have other effects.I wonder what&#x27;s the effect of playing baby songs and exposing the baby to dumbed down versions of everything. reply jstarfish 12 hours agorootparentHaven&#x27;t there been a bunch of studies about this sort of thing? Lyrics aren&#x27;t relevant to someone who doesn&#x27;t understand language. Voice is just another instrument. Syllables are just notes.Classical music is frequently cited as beneficial to learning and it has no lyrics. Nobody has ever suggested rap music is intellectually stimulating in any context, and they use a lot of words.Even on rats in mazes, blasting them with Metallica seems to result in worse performance than Mozart. Myself, I can&#x27;t work while listening to rap, rock or metal. Techno or classical only. Inducing a state of aggression&#x2F;heightened arousal never leads to cogent thought (I can&#x27;t work to Lords of Acid either!). There&#x27;s a reason generals lead from afar.I suspect music exposure may be related to autism in children, as a product of the spectrum of stimulation they&#x27;re exposed to-- too much overall (urban life), too much of one type (war, domestic violence), or too little of any (\"frigid mother\"). The classical arts (a form of expression) are another thing that dropped off as diagnoses rose. We do not value art like we used to. Who owns a piano anymore? reply OfSanguineFire 1 hour agorootparent> Nobody has ever suggested rap music is intellectually stimulating in any contextIt has been many years now since some American inner-city schools made use of rap to help teach poetry to children, as those children might not respond to the literary canon until they were first presented with something more familiar in their immediate cultural context. reply eyelidlessness 10 hours agorootparentprev> Nobody has ever suggested rap music is intellectually stimulating in any contextYou’re allowed to be obnoxiously ignorant, but don’t fool yourself into thinking you speak for anyone but yourself. reply bloopernova 9 hours agorootparentprevI am deeply offended on behalf of Aesop Rock right now.When braggadocio to go from mostly jokey to grossCorrode a homie &#x27;til his probity is notably ghost reply civilitty 11 hours agorootparentprev> Nobody has ever suggested rap music is intellectually stimulating in any context, and they use a lot of words.You need less DMX and more Wu-Tang [1][1] https:&#x2F;&#x2F;pudding.cool&#x2F;projects&#x2F;vocabulary&#x2F;index.html reply krapp 8 hours agorootparentOr Sage Francis: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U-9uhUBKah8Or Killah Priest: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Bu1ObsgF6tsOr Run the Jewels (El-P and Killer Mike): https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Sff7Kc77QAYOf course Aesop Rock: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KNrB6--KBqsGraydon Square: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8qJop-w0YAYJoyner Lucas: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_WrMzFlLk7QMF Doom: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=e_QQamQt5x4Deltron 3030: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=34k3GwQtbbsImmortal Technique: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kLBNMhzn8VI reply jamiek88 7 hours agorootparentI jumped on your comment to say what, no immortal technique?!And he was there. Of course.What an asinine comment dismissing an entire culture that was from jstarfish.Don’t forget Common and also Arrested development &#x2F; Speech too. reply NegativeLatency 13 hours agorootparentprevSounds like some can be unhelpful: https:&#x2F;&#x2F;content.time.com&#x2F;time&#x2F;health&#x2F;article&#x2F;0,8599,1650352,...Although IDK about the quality of this study reply thesausageking 14 hours agoprevAbstract:\"Even prior to producing their first words, infants are developing a sophisticated speech processing system, with robust word recognition present by 4–6 months of age. These emergent linguistic skills, observed with behavioural investigations, are likely to rely on increasingly sophisticated neural underpinnings. The infant brain is known to robustly track the speech envelope, however previous cortical tracking studies were unable to demonstrate the presence of phonetic feature encoding. Here we utilise temporal response functions computed from electrophysiological responses to nursery rhymes to investigate the cortical encoding of phonetic features in a longitudinal cohort of infants when aged 4, 7 and 11 months, as well as adults. The analyses reveal an increasingly detailed and acoustically invariant phonetic encoding emerging over the first year of life, providing neurophysiological evidence that the pre-verbal human cortex learns phonetic categories. By contrast, we found no credible evidence for age-related increases in cortical tracking of the acoustic spectrogram.\"Paper: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-023-43490-x reply jncfhnb 11 hours agoprevThe actual article simply says babies pick up on phonetic differences featured in rhyme and song. It says nothing about being crucial to learning. reply dang 6 hours agoparentWe&#x27;ve changed the headline to a (shortened) version of the subtitle, which is more neutral. This is often the case. reply nitwit005 9 hours agoparentprevYep, the headline is a deliberate lie to make the story more appealing. reply seizethecheese 8 hours agorootparentIronically, you also added the word “deliberately” to make your comment more appealing without any evidence reply nitwit005 6 hours agorootparentYou believe they accidentally misrepresented the scientists who never mentioned the concept in the headline? Come on.There is an endless stream of these headlines that misrepresent the scientific claims in a way that just happens to seem designed to make the article more appealing. I&#x27;m sure it&#x27;s all pure coincidence. reply worik 7 hours agorootparentprevJoining in a trivia dive...> Ironically, you also added the word “deliberately” to make your comment more appealing without any evidenceYes.Fun.A short comment is not the place for evidence.I could criticise it for hyperbole but actually the thing I do not like is mor e gratuitous unesecsary adjectives....Given a startling crisp headline for a mild wishy washy article it is reasonable to assume deliberation.But is it a lie? Or measly an exaggeration?I care a lot, it&#x27;s good reply jaredhallen 7 hours agorootparentprevI don&#x27;t know, I can&#x27;t imagine they accidentally wrote that bit in the headline. reply fsckboy 7 hours agorootparentprevyou turned> \"you added the word “deliberately”into> Ironically, you also added the word “deliberately” to make your comment more appealing without any evidencewith no evidence, theory of mind, nor sense of irony apparent. reply rossdavidh 9 hours agoparentprevYeah the quote from the researcher is “Parents should talk and sing to their babies as much as possible or use infant-directed speech like nursery rhymes because it will make a difference to language outcome.”Which, you know, sure, why not. Nursery rhymes are, I&#x27;m sure, great. But the idea that it is \"vital\" seems preposterous, as I&#x27;m sure many infants do not have anyone singing to them, and they still learn to speak.Again, I&#x27;m sure singing to your baby is good stuff, but the headline seems like a stretch. reply dudul 11 hours agoprev\"Vital\" seems a little strong after reading the article. reply dang 6 hours agoparentWe&#x27;ve changed the headline to a (shortened) version of the subtitle, which is more neutral. This is often the case. reply xkekjrktllss 14 hours agoprev [2 more] [flagged] corethree 13 hours agoparent [–] That&#x27;s just the title. Which is normal. The article itself is quite reasonable.That being said it could very much be vital. That is a valid possibility. We simply don&#x27;t have enough information yet to verify a causal connection. But we do have enough data to verify the possibility of one. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Singing to babies is an important factor in helping them learn language, according to a study from the University of Cambridge.",
      "The research indicates that infants initially understand language through rhythm and tone, rather than individual sounds.",
      "The study challenges the belief that processing phonetic information is the primary aspect of language learning and suggests that dyslexia and developmental language disorder may be linked to rhythm perception."
    ],
    "commentSummary": [
      "Infants understand language through rhythm and tone, not individual sounds, challenging the need for \"baby language\" for language development.",
      "Language deprivation can hinder language acquisition, but as long as babies are not deprived or abused, they will develop language skills normally.",
      "Parenting strategies are not the only factor in a child's language development; individual experiences and genetic differences also play a role."
    ],
    "points": 202,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1701543028
  },
  {
    "id": 38498688,
    "title": "GQL: A Query Language for Git Files",
    "originLink": "https://github.com/AmrDeveloper/GQL",
    "originBody": "GQL - Git Query Language GQL is a query language with a syntax very similar to SQL with a tiny engine to perform queries on .git files instance of database files, the engine executes the query on the fly without the need to create database files or convert .git files into any other format, note that all Keywords in GQL are case-insensitive similar to SQL. Samples SELECT 1 SELECT 1 + 2 SELECT LEN(\"Git Query Language\") SELECT \"One\" IN (\"One\", \"Two\", \"Three\") SELECT \"Git Query Language\" LIKE \"%Query%\" SELECT DISTINCT title AS tt message FROM commits SELECT name, COUNT(name) AS commit_num FROM commits GROUP BY name ORDER BY commit_num DESC LIMIT 10 SELECT commit_count FROM branches WHERE commit_count BETWEEN 0 .. 10 SELECT * FROM refs WHERE type = \"branch\" SELECT * FROM refs ORDER BY type SELECT * FROM commits SELECT name, email FROM commits SELECT name, email FROM commits ORDER BY name DESC, email ASC SELECT name, email FROM commits WHERE name LIKE \"%gmail%\" ORDER BY name SELECT * FROM commits WHERE LOWER(name) = \"amrdeveloper\" SELECT name FROM commits GROUP By name SELECT name FROM commits GROUP By name having name = \"AmrDeveloper\" SELECT * FROM branches SELECT * FROM branches WHERE is_head = true SELECT name, LEN(name) FROM branches SELECT * FROM tags SELECT * FROM tags OFFSET 1 LIMIT 1 Documentation: Full Documentation Install or Build Tables Types Statements Expressions Transformations Aggregations As Libraries License MIT License Copyright (c) 2023 Amr Hesham Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "commentLink": "https://news.ycombinator.com/item?id=38498688",
    "commentBody": "GQL – Git Query LanguageHacker NewspastloginGQL – Git Query Language (github.com/amrdeveloper) 189 points by amrdeveloper 19 hours ago| hidepastfavorite57 comments ebfe1 12 hours agoLovely! I only learnt today that clickhouse has a git-import tool from my colleagues at ClickHouse. So if you also want to give it a go:Download clickhouse: curl https:&#x2F;&#x2F;clickhouse.com&#x2F;shCheck out documentation for git-import: .&#x2F;clickhouse git-import --helpThen the tool can be run directly inside the git repository. It will collect data like commits, file changes and changes of every line in every file for further analysis. It works well even on largest repositories like Linux or Chromium.Example of a trivial query:SELECT author AS k, count() AS c FROM line_changes WHERE file_extension IN (&#x27;h&#x27;, &#x27;cpp&#x27;) GROUP BY k ORDER BY c DESC LIMIT 20Example of some non-trivial query - a matrix of authors, how much code of one author is removed by another:SELECT k, written_code.c, removed_code.c, round(removed_code.c * 100 &#x2F; written_code.c) AS remove_ratio FROM ( SELECT author AS k, count() AS c FROM line_changes WHERE sign = 1 AND file_extension IN (&#x27;h&#x27;, &#x27;cpp&#x27;) AND line_type NOT IN (&#x27;Punct&#x27;, &#x27;Empty&#x27;) GROUP BY k ) AS written_code INNER JOIN ( SELECT prev_author AS k, count() AS c FROM line_changes WHERE sign = -1 AND file_extension IN (&#x27;h&#x27;, &#x27;cpp&#x27;) AND line_type NOT IN (&#x27;Punct&#x27;, &#x27;Empty&#x27;) AND author != prev_author GROUP BY k ) AS removed_code USING (k) WHERE written_code.c > 1000 ORDER BY c DESC LIMIT 500 reply koolba 11 hours agoparent> Download clickhouse: curl https:&#x2F;&#x2F;clickhouse.com&#x2F;shDoes this check the useragent to change the response? Clicking that link shows their home page. reply ebfe1 11 hours agorootparentthat is exaxtly what it does ;) if you don&#x27;t feel comfortable with curlsh , you can download clickhouse binary from the repo here https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;releases;) reply pcthrowaway 7 hours agorootparentChanging the content from an html page to a shell script based on user-agent is a pretty bad abuse of HTTP. Why not at least require `-H &#x27;Accept: text&#x2F;x-shellscript&#x27;`? Or be more basic and give the script its own URL reply SomaticPirate 6 hours agorootparentBased on what reasoning? (Honestly curious) reply never_inline 5 hours agorootparentBecause someone may want to preview the script in browser.Because someone may not have curl and use another tool your server doesn&#x27;t know. reply remram 5 hours agorootparentprevIf I want to download your homepage with curl to read offline, I get a script? If I use a tool you don&#x27;t know you get the installer, I execute HTML?If I run curl on Windows, do I get this script? A PowerShell version?Why not make it https:&#x2F;&#x2F;clickhouse.com&#x2F;linux-installer? reply ebfe1 3 hours agorootparentThese are totally legit concerns, while the behaviour of the site has been around for quite sometimes and many ClickHouse installation script may have them so we will keep it for backward compatibility, we will add the usual install.sh url later and start sharing them more often.(Pull request is in ... it should be deployed on Monday and you can use https:&#x2F;&#x2F;clickhouse.com&#x2F;install.sh ). Love the feedbacks, please keep them coming! reply dotancohen 2 hours agorootparentprevTo what Resourse does this URL (universal Resourse locator) refer? A web page or a script? replychx 16 hours agoprevThe concept is interesting but the data exposed makes it kind of hard to run interesting queries. Like, do we have a branch where the last commit was a year ago?Also it seems up arrow doesn&#x27;t work to recall the previous command? reply grogenaut 6 hours agoparentWe have a data lake with our commits at work. I use it to look at developer activity data. Not for performance reasons but to see which of our code bases are active or not. I look at things like iteration time or length a PR&#x2F;CR sits, number of revisions, etc. This lets me see where we have opportunities to speed up development loops for engineers. Also lets me understand if a service that is having poor performance or growing in cost is under active development. I&#x27;ll find outliers and go dig into them. This also lets me justify work on tooling because I can quantify the problems and thus the benefits. reply zffr 14 hours agoprevHave you considered using SQLite vtables for this? reply amrdeveloper 2 hours agoparentSQLite VTables is great but i want also to have some customization inpsired by MySQL for example user defined variables and functions, maybe add PUSH or PULL Statement and control the features reply savolai 13 hours agoparentprev+1 Being able to browse with an sqlite ui would be lovely. reply nikeee 5 hours agoparentprevSQLite’s source itself is being managed using Fossil, which uses an SQLite DB as a backing store (instead of a .git directory or similar). That’s a clever use, since the .git dir basically reinvents a database. reply bastardoperator 13 hours agoprevI like the idea, and I like sql, but I feel like this is a lot more typing for the same information you could extract using just git commands. Am I missing something? Take for instance:The commit example: select name, count(name), from commits group by nameis actually: git shortlog -snThe tag example: select * from tagsis actually: git tagThe branch example: select * from branchesis actually: git branch reply snordgren 13 hours agoparentIt may be more typing but I can write SQL in my sleep whereas the git CLI I cannot.Though if I regularly needed the information that this tool retrieves I would probably have memorized the relevant CLI commands by now. reply avgcorrection 10 hours agoparentprev> git branchYep. And to list worktrees you use: $ git worktree error: need a subcommandOh woops. But to show all refs instead of just the branches you surely just: $ git show-ref 0003692409f153dd725b3455dfc2e128276cfbe2 refs&#x2F;branchless&#x2F;0003692409f153dd725b3455dfc2e128276cfbe2No. But I can just cut(1) out that SHA1...These SQL-like commands are probably meant to be familiar and guessable. Not terse. And then you can change the query instead of using all sorts of utility commands in some ad hoc pipeline (or look up whatever switch they threw in to turn on and off things like SHA1 as first column). If you don’t like the latter. reply willtemperley 10 hours agoparentprev‘select * from branches’ is explicitly and unambiguously going to give me information, not change state. I always feel apprehensive with ‘git branch’ and end up reading the git-branch man page with its 500 options. For an SQL native GQL looks wonderful. reply weaksauce 9 hours agoparentprevI mean you intentionally chose the most basic of the queries and translated them into different git gui commands. SELECT name, COUNT(name) AS commit_num FROM commits GROUP BY name ORDER BY commit_num DESC LIMIT 10something like that is more complex and less easily gleaned by the git gui. or something else that&#x27;s dead simple to remember how to do in sql vs probably having to open up the git manpages or cobble some script together to do: SELECT name, commit_count FROM branches WHERE commit_count BETWEEN 0 .. 10 reply bastardoperator 4 hours agorootparentI used the examples they provided on the repo README. I would still argue I can get the same results with less typing. git shortlog -snsort -rhead -n 10If I run the 2nd command example against the chromium repo, it takes several minutes where a shell script using git for-each-ref takes about 8 seconds. I would also argue that this might be better expressed as commit_count <= 10 but I realize you&#x27;re also using an example. This is the script I ran: git for-each-ref --format=&#x27;%(refname:short)&#x27; refs&#x2F;heads&#x2F;while read branch; do commit_count=$(git rev-list --count $branch) [ \"$commit_count\" -le 10 ] && echo \"Branch: $branch, Commit Count: $commit_count\" done reply esafak 11 hours agoparentprevThis approach falls flat when you start doing analytical queries, and it assumes you already know the git incantations, which most people don&#x27;t. reply dtgriscom 12 hours agoparentprevThe git CLI is notoriously irregular, as can be seen by your examples. Having a clean, regular language to query git objects seems valuable. reply amrdeveloper 2 hours agoparentprevThe Goal is to provide most of the SQL features so if one query can replaced by command we should support it so user is free to choice any tool also to do filter on git branch you need to get it in format and use grep on linux but it&#x27;s very easy for most developer to filter with SQL language reply michaelsalim 8 hours agoparentprevSurprised by the variety of answers here. My view on this is that I won&#x27;t use this on a daily basis. I doubt most will. But I&#x27;d love to remember about this when I want to extract a very specific information from git reply umvi 12 hours agoparentprevSql is a more well known DSL than git CLI reply paulddraper 11 hours agoparentprev1. SQL is more consistent2. SQL is more capable3. SQL is more well-known reply Too 2 hours agoparentprevThe existence of this GQL is yet another example showing the failure of the unix model, where programs output text instead of structured data. Now we need a new query language and a new external adapter program just to do a basic select. Yet we call it progress.Imagine instead if there was a standard xQL that could run on any tool. reply joshuanapoli 11 hours agoparentprevAt least the SQL-like syntax is more consistent. It might be easier to figure out how to make any given query starting from the SQL “schema”. reply quickthrower2 10 hours agoparentprevIt reduces the amount to learn. If you know SQL you need to remember the command to list the tables and describe them. Then you are productive.In addition SQL is a powerful functional programming language with joins! So that is handy too. reply cglendenning 9 hours agoprevYESSSS!! All those years of tuning queries paid off. I knew SQL was immortal. reply hot_gril 9 hours agoparentWe have a special language for monitoring our metrics at work. It&#x27;s fussy and obscure. I replaced it with SQL on our team, which despite \"not being good for timeseries data\" works fine for this. reply setheron 12 hours agoprevApache Calcite has this as an integration as does SQLite though virtual tables.Nonetheless nice work reply gingerwizard 6 hours agoprevSome good examples and docs on this data https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;getting-started&#x2F;example-datas... reply dafelst 14 hours agoprevThis is a super cool idea, I&#x27;ve been playing with Git internals and having this as a tool&#x2F;reference will be super helpful. Thanks for sharing!I don&#x27;t see it in the code, but have you considered creating secondary indexes to speed up some operations? Things like looking up the path of a deleted file in a large repo? reply Sargos 4 hours agoprevUnfortunately this is going to need a name change, or at least modified initials, as GQL is for Graph Query Language [https:&#x2F;&#x2F;www.gqlstandards.org&#x2F;] which is being standardized and will be the primary way the world uses Property Graphs like Neo4j. Can&#x27;t compete with that. reply grogenaut 5 hours agoprevWould be cool to have duckdb be able to read git commit history as a data source. reply fragmede 13 hours agoprevUnfortunate name, given that GraphQL already exists.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Graph_Query_Language reply paulddraper 10 hours agoparentYou say \"GraphQL\" but link to \"Graph Query Language (GQL).\"Those are two entirely separate things.EDIT: And neither of these should be confused with \"Graph Query Language (GSQL)\" by TigerGraph: https:&#x2F;&#x2F;www.tigergraph.com&#x2F;gsql&#x2F; reply fragmede 3 hours agorootparentmy mistake points out just how bad a name gql is! reply ghusbands 13 hours agoparentprevI&#x27;ve always seen it written as GraphQL, rather than GQL, though that wikipedia page indeed calls it GQL multiple times. reply 8n4vidtmkvmk 11 hours agorootparentBecause that one is apparently unrelated to GraphQL. Horrible naming. reply jakewins 13 hours agoparentprevAlso an ISO track thing https:&#x2F;&#x2F;www.gqlstandards.org&#x2F; reply Hamuko 12 hours agoparentprevI guess it&#x27;s not the only unfortunate name considering your link begins with the words \"Not to be confused with GraphQL\". reply pokstad 16 hours agoprevLooks very cool. Does this produce a shell snippet with the appropriate git commands? I like the idea of this being a very thin frontend to git. reply pornel 9 hours agoparentit uses gix library, which is a ground-up reimplementation of git, so there&#x27;s no git CLI involved there at any point. reply ellisv 11 hours agoprevLooks cool. Reminds me of Steampipe except this works on a local git repository. reply it 7 hours agoprevAnd it will be called \"geequal\". reply nittanymount 11 hours agoprevthis seems converting graph&#x2F;tree data model to relational data model ? hmm... reply lloydatkinson 12 hours agoprevWhat would a more complex query look like with that, for example, querying for any commit that affected any file in a list of files, by a specific author? reply jakubmazanec 12 hours agoprev [–] Why would someone use SQL, famously bad language, as a query language for git, famously badly designed CLI? reply mpalmer 12 hours agoparent\"Famously bad\" is an opinion cloaked in adverbial authority. Plenty of people like both, and even if they don&#x27;t like them, they think better in one vs the other. reply avgcorrection 10 hours agorootparentThat git(1) (the user interface) is badly designed is an opinion shared by many people, including many on the Git mailing list. Backwards compatibility is mostly used to argue for the status quo, not that the status quo is good. reply mpalmer 10 hours agorootparentAll the more reason for alternative interfaces. reply 8n4vidtmkvmk 11 hours agorootparentprevSQL is ok, it just needs to be refined a bit. This was such an opportunity but they didn&#x27;t cease it. reply onionisafruit 9 hours agorootparentprevI like your phrase “adverbial authority” reply amrdeveloper 2 hours agoparentprev [–] For Me I Think SQL is great for most of the features here and the most important is that people don&#x27;t need to learn a new full language to use GitQL replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GQL is a query language that resembles SQL and enables querying .git files directly, eliminating the need for a separate database.",
      "It offers a range of query operations including selection, aggregation, filtering, and ordering.",
      "GQL is case-insensitive and has a syntax similar to SQL. The software is released under the MIT License."
    ],
    "commentSummary": [
      "The post explores the use of GQL, a data analysis tool for git repositories, and suggests the need for more user-friendly analytical queries.",
      "It discusses the potential benefits and drawbacks of a SQL-like query language for Git and presents mixed opinions on its usefulness.",
      "The confusion between GQL and GraphQL is addressed, along with alternative interfaces and refined SQL approaches."
    ],
    "points": 189,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1701526008
  },
  {
    "id": 38498775,
    "title": "Comparing Memory Management, Safety, and Adoption: Ada vs Rust",
    "originLink": "https://old.reddit.com/r/rust/comments/17miqiu/is_ada_safer_than_rust/",
    "originBody": "jump to content my subreddits edit subscriptions popular -all -random -usersAskReddit -gaming -pics -movies -mildlyinteresting -todayilearned -worldnews -funny -explainlikeimfive -news -videos -DIY -aww -TwoXChromosomes -OldSchoolCool -nottheonion -tifu -LifeProTips -Music -Futurology -dataisbeautiful -books -askscience -science -Jokes -Showerthoughts -sports -IAmA -space -gifs -gadgets -history -food -nosleep -UpliftingNews -InternetIsBeautiful -announcements -WritingPrompts -GetMotivated -philosophy -Documentaries -creepy -EarthPorn -photoshopbattles -listentothis -blog more » rust comments other discussions (4) Want to join? Log in or sign up in seconds.| English limit my search to r/rust [-] use the following search parameters to narrow your results: subreddit:subreddit find submissions in \"subreddit\" author:username find submissions by \"username\" site:example.com find submissions from \"example.com\" url:text search for \"text\" in url selftext:text search for \"text\" in self post contents self:yes (or self:no) include (or exclude) self posts nsfw:yes (or nsfw:no) include (or exclude) results marked as NSFW e.g. subreddit:aww site:imgur.com dog see the search faq for details. advanced search: by author, subreddit... this post was submitted on 03 Nov 2023 170 points (89% upvoted) shortlink: remember mereset password login Submit a new link Submit a new text post Get an ad-free experience with special benefits, and directly support Reddit. get reddit premium rust joinleave259,785 readers 950 users here now Please read The Rust Community Code of Conduct The Rust Programming Language A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. Rules Observe our code of conduct Strive to treat others with respect, patience, kindness, and empathy. We observe the Rust Project Code of Conduct. Details Submissions must be on-topic Posts must reference Rust or relate to things using Rust. For content that does not, use a text post to explain its relevance. Post titles should include useful context. For Rust questions, use the stickied Q&A thread. Arts-and-crafts posts are permitted on weekends. No meta posts; message the mods instead. Details Constructive criticism only Criticism is encouraged, though it must be constructive, useful and actionable. If criticizing a project on GitHub, you may not link directly to the project's issue tracker. Please create a read-only mirror and link that instead. Details Keep things in perspective A programming language is rarely worth getting worked up over. No zealotry or fanaticism. Be charitable in intent. Err on the side of giving others the benefit of the doubt. Details No endless relitigation Avoid re-treading topics that have been long-settled or utterly exhausted. Avoid bikeshedding. This is not an official Rust forum, and cannot fulfill feature requests. Use the official venues for that. Details No low-effort content No memes or image macros. Details Useful Links Latest Megathreads Alternative Rust Discussion Venues 🎉 Announcing 1.74.0 🎉 Got a Question? What's Everyone Working On? Who's Hiring? Jobs Thread for 1.74.0 This Week in Rust 523 We'll do our best to keep these links up to date, but if we fall behind please don't hesitate to shoot us a modmail. Official Resources Official Website Official Blog This Week In Rust Installers Source Code Bug Tracker Learn Rust The Rust E-Book Stdlib API Reference Rust By Example Rustlings Online Playground Discussion Platforms Official Users Forum Official Discord Community Discord Mozilla Matrix Chat Stack Overflow Chat a community for 13 years MODERATORS message the mods discussions in r/rustX 157 · 88 comments Async is hard... but what if we avoid shared state? 48 · 11 comments rustls 0.22 is out with pluggable crypto providers and better CRL support 47 · 13 comments Is `std` generally expected to be a default feature? 27 · 7 comments Loole, the safe sync/async multi-producer, multi-consumer channel, just got a significant performance bump! 🎉 76 · 82 comments Who hurt this guy? 31 · 35 comments String manipulation in RustAdvent of Code 20 · 6 comments Quick Steps for Axum 0.6 to 0.7 49 · 15 comments I recently started exploring the AWS SDK for Rust and thought I try to share something that I learnt here. Hope this helps! 9 How to fight the borrow checker... and win. 2 · 16 comments Is this a Rusty way of solving yesterday's advent of code? Welcome to Reddit. Where a community about your favorite things is waiting for you. Become a Redditor and subscribe to one of thousands of communities. × 169 170 171 Is Ada safer than Rust?🎙 discussion (self.rust) submitted 1 month ago * by we_are_mammals I saw a comment by u/Kevlar-700 that said: Ada without Spark is actually safer than Rust due to it's richer type system without the pain of borrowing by using the stack, which is also faster than the heap. I never use the heap and the stack is memory safe for all general purposes in Ada. Pools in full Ada such as on Linux are used for safe heap use. Spark has some basic borrowing support which may be where the confusion is coming from. (SPARK is basically a theorem prover that you can use with Ada, but it's very tedious, as I understand it. And \"memory pools\" are what Ada calls arenas) I'm not interested in language advocacy. I would just like to get to the bottom of this question: Is Ada (without SPARK) safer than Rust, while also being faster and easier to use? Edit: There is a fairly small number of people who have used both Rust and Ada extensively. I was hoping that they'd see this post and share their insights, but I guess it was not to be -- downvoted. Edit2: I also crossposted this in r/ada, in case anyone's interested in their take on this. safety 138 comments share save hide report all 138 comments sorted by: best topnewcontroversialoldrandomq&alive (beta) Want to add to the discussion? Post a comment! Create an account [–]trevg_123 110 points111 points112 points 1 month ago (15 children) It has some interesting features that Rust does not have, e.g.: Restricted types, saying that a value will always be within 5..100. I think there is a WIP effort for this sort of thing in Rust Pre- and postconditions. Essentially you annotate your functions saying what the inputs and outputs must look like, throwing an exception if it fails. Sorta like how assert_unsafe_precondition is used internally. (I’ve thought in the past that Rust might be able to add something like this to where clauses for unsafe functions) Instead of using pointers / references, you just tell it which function arguments are input and which are outputs. Then it figures out how best to handle it under the hood A minimal number of exception types (panics): constraint (bound checks / overflow / null), storage (OOM or out of stack), program, and tasking (not really sure what those two are). And you can handle them separately, which is cool I think you could maybe make the argument that it’s more straightforward to do some of these things than in Rust, but I don’t know if you could say specifically that anything other than range types make it safer. And I don’t know about the author’s comment about Rust being safe on the stack without allocation - that is specifically an area that Rust shines compared to every other language. Nor are panics meant to be unrecoverable on systems that need to stay up, Rust for embedded typically has a panic_handler that lots, resets, and keeps going. In general, I would love some knowledge sharing between the Ada and Rust communities: we’re pretty new, they’ve been doing this safety stuff for a long time, and their static analysis tooling is pretty incredible. We might get some of that since Adacore’s GNAT is adding Rust support https://www.adacore.com/gnatpro-rust, will be interesting to see See also some a thread posted by the same author here, there was some good discussion: https://www.reddit.com/r/rust/s/JXP5Td1nMD permalink embed save report reply [–]protestor 30 points31 points32 points 1 month ago (0 children) Pre- and postconditions. Essentially you annotate your functions saying what the inputs and outputs must look like, throwing an exception if it fails. Sorta like how assert_unsafe_precondition is used internally. (I’ve thought in the past that Rust might be able to add something like this to where clauses for unsafe functions) Rust has a plethora of crates for this, in special the contracts crate https://crates.io/crates/contracts There's also a number of static analyzers that can verify such conditions at compile time. Mirai can integrate with the contracts crate itself, here is an example Prusti also has this feature too (seen here), also creusot (here), it seems that kani is adding this feature too (here), and some other verification projects too (hard to keep track of them all). And anyway, that's also how Ada's SPARK works too, right? At this point I'm not sure this needs to be integrated in the language itself or rather what benefit would upstreaming this stuff bring - maybe more widespread usage of those tools? permalink embed save parent report reply [–]phazer99 7 points8 points9 points 1 month ago (0 children) Restricted types, saying that a value will always be within 5..100. I think there is a WIP effort for this sort of thing in Rust You can get static checks for this already on nightly using const generics. Of course it's somewhat more cumbersome to use than normal integers. permalink embed save parent report reply [–]matthieum[he/him] 1 point2 points3 points 29 days ago (0 children) I don't see anything there that seems related to safety, though... permalink embed save parent report reply [–]mattr203 3 points4 points5 points 1 month ago (4 children) Restricted types, saying that a value will always be within 5..100. I think there is a WIP effort for this sort of thing in Rust you mean dependent types in Rust??? can you please link to any kind of source for this because that's crazy if true permalink embed save parent report reply [–]FantaSeahorse 26 points27 points28 points 1 month ago (0 children) This is refinement type, not dependent type permalink embed save parent report reply [–]trevg_123 7 points8 points9 points 1 month ago (0 children) Pattern types is what I was thinking of: https://github.com/rust-lang/rust/pull/107606 it’s really mostly theoretical at this point, there’s a Zulip discussion about it somewhere permalink embed save parent report reply [–]kibwen 2 points3 points4 points 29 days ago (0 children) There are some people want to use Rust's const generics to create APIs that statically guarantee that a value will always be within a given range. However, const generics aren't powerful enough for that yet, and in the meantime you can also just implement it via runtime checks, which is what Ada does. permalink embed save parent report reply [–]U007Drust · twir · bool_ext 0 points1 point2 points 28 days ago (0 children) I've not been able to work on this for a while, but have met someone interested in moving it forward. https://crates.io/crates/arranged permalink embed save parent report reply [–]jmhimara 0 points1 point2 points 1 month ago (6 children) It has some interesting features that Rust does not have, e.g.: And an assignment operator that isn't '=' (ada uses := I think). This should have been the default, lol. permalink embed save parent report reply [–]OS6aDohpegavod4 4 points5 points6 points 29 days ago (4 children) I'm unfamiliar with that. What's the difference besides syntax? permalink embed save parent report reply [–]kibwen 10 points11 points12 points 29 days ago (2 children) Back in the day, the goal would have been to avoid confusing = for an equality check, which is a classic footgun in C-like languages in combination with the truthiness of booleans and the fact that assignment returns the assigned value, e.g. if (foo = 2) { will both enter the branch unconditionally and corrupt the value stored in foo. Note that this isn't a problem in Rust, despite the fact that Rust uses = for assignment, because assignment always returns unit and because nothing coerces to bool, so if foo = 2 { is guaranteed to be a compiler error. permalink embed save parent report reply [–]barbouk 7 points8 points9 points 29 days ago* (1 child) offbeat somber fly offer unwritten wild voracious saw dog worm this message was mass deleted/edited with redact.dev permalink embed save parent report reply [+]zzzzYUPYUPphlumph comment score below threshold-7 points-6 points-5 points 29 days ago (0 children) This is worth any safety measure rust has. That's just crazy talk. permalink embed save parent report reply [–]jmhimara 1 point2 points3 points 29 days ago (0 children) No difference. It's just an inside joke / pet peeve among some programmers who don't like code like: x = x+ 1 which makes no sense mathematically. permalink embed save parent report reply [–]Barefoot_Monkey 1 point2 points3 points 29 days ago (0 children) It's a small thing, but something I strongly agree with. = assignments really are not great. It's nowhere near as bad as C, where deliberate side-effect expressions are so expected that there's nothing stopping you from doing them by accident, but I'd really prefer := for all assignments. (let variable: type = value; is fine though) permalink embed save parent report reply [–]Array2D 44 points45 points46 points 1 month ago (1 child) I don’t think that this is strictly correct. In safe rust, use of the heap isn’t unsafe, because it’s managed automatically with help from the type system. They are making arguments about speed and ergonomics, which imo are rather silly to be arguing about. “The pain of borrowing” sounds to me like the “fighting the borrow checker” phase of learning rust. As for performance, you can write slow code in any language, and using the heap doesn’t automatically make things slower. It may even enable much better performance for some use cases. permalink embed save report reply [–]Xelaxander 5 points6 points7 points 1 month ago (0 children) Yeah, really depends if you can amortize the slight overhead for a heap allocation. In many cases you can and it's nice being able to write a program generically over data size. permalink embed save parent report reply [–]Untagonist 110 points111 points112 points 1 month ago (26 children) I can't speak to the Ada part but I'll speak to this: Even Ada can handle out of bounds and integer overflow exceptions, nicely and easily for when software has to work. Rust does not offer that. You are not supposed to recover from a panic in Rust. That's not really true in Rust. You can easily opt into checked indexes and checked arithmetic. You can also enable clippy lints to catch accidental use of the unchecked versions. It's fair to say that these are tedious and not the path of least resistance for Rust code, but it's not fair to say that Rust does not offer such features. A better argument would be that falliable allocator APIs aren't stable yet. There's definitely room for improvement there, but the attention and effort are commensurate. It remains to be seen how ergonomic and widely used they'll be. Seeing its lack of familiarity with Rust, I would not weigh that comment heavily for this decision. Talking about tooling bugs. The rust compiler has had bugs that lead to memory unsafety due to borrowing protection failures. These do get fixed, though, and formally certified compiler work is under way for industries that need it. I don't expect that to be good enough for many industries today, I do expect it to be good enough in future. It's fantastic that Ada is out there, but decades of industry usage have shown that people are not interested in replacing most C or C++ projects with Ada. For those use-cases, it doesn't matter if Ada is safer than Rust, it has been safer than C and C++ for decades and the industry still didn't feel its tradeoffs were worthwhile for most forms of software development. It makes perfect sense that many industries continue to use Ada and Rust isn't ready to replace it yet, and I think people know whether they're in such an industry or not. Even if Ada is demonstrably safer in important ways, potential users still have to weigh that against the factors that have kept it marginalized in the broader software industry. How exactly these factors play into a particular project is best determined by the developers scoping the project. permalink embed save report reply [–]dnew 54 points55 points56 points 1 month ago (18 children) the industry still didn't feel its tradeoffs were worthwhile for most forms of software development [...] kept it marginalized in the broader software industry A big part of this is that Ada compilers (for quite some time) were guaranteed and warranted to actually compile the code into correct machine code. In order to call yourself Ada, you had to undergo an audit and an extensive set of tests that prove every aspect of the language is implemented correctly. You know, the sort of thing you're worried about when coding targeting software for missiles, space craft, and other things where a flaw would be catastrophic. That made Ada compilers tremendously expensive, and the documentation was similarly expensive. permalink embed save parent report reply [–]eggyal 44 points45 points46 points 1 month ago (2 children) Isn't this what the Ferrocene project is intending to do for Rust? permalink embed save parent report reply [–]TheNiceGuy14 4 points5 points6 points 29 days ago (1 child) Ferrocene is targeting ISO 26262 (automotive) and IEC 61508. ISO 26262 is a complex certification for safety-critical automotive systems. It defines how development is done at every design level. It is not enforced. Having worked for a major automobile maker, we were not ISO 26262 compliant, nor tried. Suppliers usually are, because it somewhat gives a marketing advantage. We didn't even used ISO 26262 compliant toolchains. From what I understand, ADA compiler certifications is different. It only makes sure the compiler is actually a valid ADA compiler. It looks rigorous and a pain to certify as well. But doesn't seems to imply ISO 26262 or IEC 61508 certifications. permalink embed save parent report reply [–]aworks 0 points1 point2 points 15 hours ago (0 children) In my career, I worked on development of Ada toolchains as well as for ISO-26262 C/C++ products. Ada certification was about passing compile-time and run-time tests to ensure conformance to the language standard. ISO-26262 was a broader standard with multiple dimensions - development process evaluation, software tool validation etc. The former was mostly a technical problem of fixing bugs and deciding about language behavior, the latter was very process oriented. And yes, both were rigorous and a pain to certify. permalink embed save parent report reply [–]ascendingnode 20 points21 points22 points 1 month ago (0 children) I know from experience of one case where C++ was certified for a safety-critical system for a spacecraft, and Ada wasn’t even considered for a moment. The trade-off in development ease and speed was drastically in favor of C++, even considering the extra testing and review of the code in the less-safe language. permalink embed save parent report reply [–]SV-97 4 points5 points6 points 1 month ago (1 child) You know, the sort of thing you're worried about when coding targeting software for missiles, space craft, and other things where a flaw would be catastrophic. Just to expand on this: even in those domains it's often times not that critical. If you're not exactly sending people to the ISS or landing rovers on mars, chances are that you're mostly writing pretty standard C (or something similar). permalink embed save parent report reply [–]dnew 0 points1 point2 points 29 days ago (0 children) True. But government contracts often required it, because the feds didn't want 23 different languages on different projects, so they standardized on one that could do everything they needed. Which is why it's more powerful and more portable than C or C++ (I mean, obviously, for places the compiler is available). permalink embed save parent report reply [–]PlasmaWind 2 points3 points4 points 1 month ago (9 children) There is gnu Ada, would that make the compiler cost not an issue and seriously if you are writing software For expensive things you can afford a commercial license permalink embed save parent report reply [–]dnew 2 points3 points4 points 29 days ago (8 children) Right. That started after it was no longer illegal to sell unverified Ada compilers. (I believe they used trademark law to prevent you from claiming you sell an Ada compiler without being certified.) And certainly, if you're coding weapons or aircraft or something like that, you can afford it. But if you're just trying to learn on your own, you can't. And that is a big part of why Ada didn't take off - nobody learned it because the compilers all cost thousands of dollars. permalink embed save parent report reply [–]EasterWesterner 0 points1 point2 points 29 days ago (5 children) Not really, you can use free GNU Ada tools. GNAT should be enough to learn the language and it even pass all the ACATS tests. However, I have never heard anyone wanted to learn Ada as a primary working language. Maybe because of quite narrow market usage. Back in college we did quick overview of Ada 95 (relatively new standard back then) and wrote some hello worlds. And switched to the C++ immediately permalink embed save parent report reply [–]dnew 3 points4 points5 points 29 days ago (4 children) Yes. How long was Ada around before GNU Ada was released? That's my point. By the time GNU was allowed to make an Ada compiler, Ada's window of opportunity to be the Latest Greatest had passed. I met one person who used it in university. I asked why, and he said \"It does everything I need it to.\" Also, there weren't a whole lot of modern-tech libraries around for it when I was playing with it. Stuff like base64 or XML parsers or GUIs or etc just weren't around. And Ada83 at least didn't unify OOP with tasks, so writing an interface for a task was kind of clunky, so making generic frameworks that involved tasks was quite difficult. permalink embed save parent report reply [–]OneWingedShark 1 point2 points3 points 27 days ago (2 children) Yes. How long was Ada around before GNU Ada was released? GNU Ada has been around for more than 20 years; I think it's 25, now. Meaning that it was released very shortly after the Ada 95 standard came out —and, the GNU Ada Translator (GNAT) project was intended for Ada 95. The Ada Standard goes back to 1983, so the language goes back 40 years. (There are some notes/papers on pre-standard Ada, from the \"\"final report\" on the language to a \"Beta-test\" \"Ada 1979/1980\", but let's exclude those.) permalink embed save parent report reply [–]dnew 1 point2 points3 points 27 days ago (1 child) Thanks. But it was kind of a rhetorical question. :-) permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (0 children) I do not need latest. Greatest suits me just fine 😉 permalink embed save parent report reply [–]ben_bai 0 points1 point2 points 12 hours ago (0 children) The answer to \"Why do you use Ada?\" is always \"Because i work in aerospace.\" permalink embed save parent report reply [–]_kst_ 0 points1 point2 points 12 hours ago (1 child) Right. That started after it was no longer illegal to sell unverified Ada compilers. (I believe they used trademark law to prevent you from claiming you sell an Ada compiler without being certified.) It was never illegal to sell unvalidated Ada compilers. Trademark issues might have imposed some restrictions on what you could call it, but you could sell a compiler that didn't (yet) pass all the tests. (Source: I worked for a company that did that.) permalink embed save parent report reply [–]dnew 0 points1 point2 points 12 hours ago (0 children) Right. It just wouldn't be AdaTM and you couldn't use it for government contract stuff. I imagine the \"Ada\" compiler I used in university wasn't validated either. permalink embed save parent report reply [–]rbanffy 0 points1 point2 points 13 hours ago (1 child) That made Ada compilers tremendously expensive, and the documentation was similarly expensive. I've seen this before with Java, and it always feels odd. Couldn't all those tests be encoded as code and/or code generation tools that could cover all possible cases of legal language syntax and behavior and run automatically checking results? Certification in this case would be a trusted party running those tests and asserting that specific toolchain generated code that's correct as per the language spec. permalink embed save parent report reply [–]dnew 0 points1 point2 points 13 hours ago (0 children) I believe most of the tests were indeed done this way. Not all aspects of Ada's specification are specifically the language. For example, if you compile a header file, then compile the corresponding body, then recompile the header file, you cannot link the newly compiled header file and the old body object code into the same executable. (I.e., you changed the header without recompiling the body to make sure it matches, and that's disallowed.) And yes, that trusted party is the people who charged you lots of money. :-) And then you had to submit the results to the DOD to get permission to use the trademark, so at least half the cost was lawyers. I remember reading a story about someone complaining the compiler was terribly slow. Compiler author asked to see the code that compiles slowly, and it was using like 15 nested instantiations of templates (or whatever the terminology was). When the compiler author asked them why they were doing something so foolish, the customer answered they saw it 17 layers deep in the sample code. The compiler author then pointed out it wasn't sample code, but compiler stress testing ensuring you could nest templates at least 16 levels deep. (I forget exactly what the \"template\" thing was, but it was like nesting C++ templates, so I'll call it that.) permalink embed save parent report reply [–]we_are_mammals[S] 5 points6 points7 points 1 month ago (0 children) factors that have kept it marginalized Apparently Ada was in the top 10 in 1979-1995, and number 1 in 1985-1986: https://www.youtube.com/watch?v=qQXXI5QFUfw Not sure where his data comes from or how reliable it is. permalink embed save parent report reply [–]mok000 1 point2 points3 points 1 month ago (2 children) Fortran and Pascal also handles out of bounds and integer overflow exceptions. Originally, the advantage of C over these other languages was the ability to dynamically allocate exactly the amount of memory that was needed, so that the program didn't need to be recompiled with larger array dimensions. Also, the size of the running executable was smaller, because it wasn't compiled with fixed memory allocations. permalink embed save parent report reply [–]OneWingedShark -1 points0 points1 point 27 days ago (1 child) Also, the size of the running executable was smaller, because it wasn't compiled with fixed memory allocations the bounds-checks (which must be manually done) were left out by most programmers. FTFY permalink embed save parent report reply [–]mok000 0 points1 point2 points 27 days ago (0 children) So, the various Fortran programs I was running back then were typically dimensioned 50.000 atoms, because that was the largest number anyone could ever imagine would ever be necessary, and indeed, most structures we worked with at the time was around 5.000 atoms. So the programs allocated memory for 45.000 atoms that was not needed. Programming the algorithms in C and allocating memory for exactly the number atoms required reduced the memory footprint of those programs and made them run faster. permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (2 children) That's not really true in Rust. You can easily opt into checked indexes and checked arithmetic. You can also enable clippy lints to catch accidental use of the unchecked versions. It's fair to say that these are tedious and not the path of least resistance for Rust code, but it's not fair to say that Rust does not offer such features. I am no Rust expert but it is the Rust website that states that panics should not be recovered. I know there is code that looks hackish to do so. In Ada you handle all exceptions including runtime generated ones with a simple exception block. At the same time it might be dangerous logically to handle a librarys unhandled exceptions without detailed knowledge. One thing I like about Rusts stance is that they acknowledge that deciding whether to panic is a grey area and context dependent. Adaists can be extremely conservative. permalink embed save parent report reply [–]Untagonist 1 point2 points3 points 25 days ago (1 child) What I'm talking about does not cause a panic in the first place. Checked slice index: https://doc.rust-lang.org/std/primitive.slice.html#method.get Checked arithmetic: https://doc.rust-lang.org/std/primitive.u32.html#method.checked_add In Rust panics really are a last resort, to get out of a situation where you can no longer maintain invariants. Using Option and Result types is the idiomatic way to handle diverging states of various kinds, and they're even monadic. https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html As I mentioned in the above comment, the part that needs the most work is that memory allocation APIs (and thus the container types built on top of them) can still panic on allocation failure. There are clearly environments where that's not acceptable, so it's being worked on. permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 25 days ago (0 children) Okay but in Ada all exceptions can be handled without this effort and fragility. permalink embed save parent report reply [–]OneWingedShark 67 points68 points69 points 1 month ago (16 children) Ada without Spark is actually safer than Rust due to it's richer type system without the pain of borrowing by using the stack, which is also faster than the heap. The type-system is excellent and helps you to model the problem at-hand, rather than the C-ish mindset of forcing the problem through the computer [at a low-level] — to illustrate, a C programmer might use char for a percentage, but with Ada declaring the type is as trivial as Type Percent is range 0..100;. The subtype in Ada is an excellent feature which further enhances the ability of the type-system by allowing you to add further constraints to the values a type can take: Subtype Natural is Integer range 0..Integer'Last; (The attribute 'Last returns the last valid value in the Integer type.) Subtype Positive is Integer range Natural'Succ(Natural'First)..Natural'Last; (The 'Succ attribute returns the next value to the one given, in this case the first valid value, zero, is given; this shows how you can \"build\" subtypes in a set/subset manner.) Subtype Real is Interfaces.IEEE_Float_64 range Interfaces.IEEE_Float_64'Range; (This confines Real to only the numeric values of the 64-bit IEEE float.) Type/subtype constraints are checked on passing as a parameter as well as a value returning from a function — though the compiler is allowed to forgo the checks when it is provable that they cannot fail. I never use the heap and the stack is memory safe for all general purposes in Ada. Pools in full Ada such as on Linux are used for safe heap use. Spark has some basic borrowing support which may be where the confusion is coming from. Ada's use of the stack is quite good, because of the above plus the ability to easily use it via unconstrained types — something like Type Bits is Array(Positive range ) of Boolean;, where the exact size is unknown, can have that size set by initialization in a declarative region: Vector : Bits := ( True, False, False, True ); defines a vector of four bits in that declarative region, and when it goes out of scope the memory is automatically reclaimed. There's a FOSDEM presentation about Memory Management in Ada 2012 that really walks through the issue. (SPARK is basically a theorem prover that you can use with Ada, but it's very tedious, as I understand it. And \"memory pools\" are what Ada calls arenas) Meh, I wouldn't call SPARK tedious, in comparison with other methods; though it certainly is compared to the by-the-seat-of-your-pants style programming. Besides, if you're doing anything to a fixed specification, the implementation cost of having proofs is frontloaded: you only pay once. — I have a Base-64 encoder/decoder here, which I wrote to teach myself the basics of SPARK, and while there are a few warts from having to work around a compiler-bug (since fixed), the result is fairly easy to follow along. I'm not interested in language advocacy. I would just like to get to the bottom of this question: Is Ada (without SPARK) safer than Rust, while also being faster and easier to use? Ada out-of-the-box is basically on-par with the high-integrity C++ standard, there's no wrestling with the borrow-checker and no need to learn a completely different paradigm [e.g. Functional], which are pluses — Ada also tries to make correct easier than incorrect, so the language and compiler help guide you, and make \"memory safety\" much less of an issue: you don't have that set of issues nearly as bad when you have a strong-typing, parameter-modes, and access-types (pointers) are not confused with Address and/or Integer. (In C this confusion is illustrated in arrays and how they devolve to a pointer at the slightest glance; C++ adopted much of this to be backwards-compatible with C, and that is why \"memory safety\" is such a big deal.) Edit: There is a fairly small number of people who have used both Rust and Ada extensively. I was hoping that they'd see this post and share their insights, but I guess it was not to be -- downvoted. I hope I gave some insights. permalink embed save report reply [–]trevg_123 8 points9 points10 points 1 month ago (5 children) Very well said! Hopefully we will get range/pattern types in Rust at some point (see the experiment: https://github.com/rust-lang/rust/pull/107606). I assume dynamic stack-based arrays are VLAs under the hood, do you know if this is the case? If so the details are probably interesting, since kernel has been moving away from them https://outflux.net/slides/2018/lss/danger.pdf permalink embed save parent report reply [–]Kuraitou 2 points3 points4 points 1 month ago (0 children) I assume dynamic stack-based arrays are VLAs under the hood, do you know if this is the case? Depends on the implementation. I believe GNAT uses a second stack allocated separately from the program stack so it isn't subject to the same problems as VLAs, but there are locality tradeoffs. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 29 days ago (3 children) I assume dynamic stack-based arrays are VLAs under the hood, do you know if this is the case? This is not the case: the arrays are statically-sized [after initalization], but can be allocated on the stack at runtime; the following allocates a string of user-input on the stack and reclaims the stack after the procedure exits: Procedure Print_It is -- I'm using renames to give the value a name, so it \"fits\" the -- keyword's name; this particular use acts just as CONSTANT does. Input : String renames Ada.Text_IO.Get_Line; Begin Ada.Text_IO.Put_Line( \"User input \"\"\" & Input & \"\"\".\" ); End Print_It; The video I mentioned (on memory-management) in the original post is here. permalink embed save parent report reply [–]Additional-Boot-2434 0 points1 point2 points 29 days ago (2 children) Doesn't it allocate on the so-called secondary stack? I.e. the value behaves as if it was on the stack but gets malloc'd under the hood. The compiler performs some interesting rewrite rules there. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 28 days ago (1 child) Doesn't it allocate on the so-called secondary stack? I.e. the value behaves as if it was on the stack but gets malloc'd under the hood. There's no need for malloc, though. The secondary stack is used, but IIRC it's as a temporary store (i.e. intermediate value) before pushing it onto The Stack. The compiler performs some interesting rewrite rules there. There certainly are some of those! permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (0 children) I could be wrong but I think the secondary stack is only used for returning unconstrained arrays from functions in this regard. I run with pragma no_secondary_stack and create the arrays to pass to procedures up front. permalink embed save parent report reply [–]matthieum[he/him] 1 point2 points3 points 29 days ago (5 children) Thanks for chiming in, when I saw the post title I immediately wished to hear your thoughts. I am curious as to memory safety claims, still. I'm not sure whether Ada has sum types (enum in Rust). One of the key problems faced by sum types is that if you can obtain a reference to the payload of an enum, override that payload with another type, and then still access the former payload... you're in uncharted territory. Rust solves this with the borrow checker, how does Ada handle it? permalink embed save parent report reply [–]OneWingedShark 3 points4 points5 points 29 days ago (4 children) Thanks for chiming in, when I saw the post title I immediately wished to hear your thoughts. You're welcome. Quite welcome. I am curious as to memory safety claims, still. As /u/jrcarter010 says: \"access-to-object types and values are almost never needed in Ada (so rarely that it is a reasonable approximation to say that they are never needed)\" — link. The FOSDEM video of Memory Management in Ada 2012 is here. But, if you want a quick and dirty, oversimplified paragraph or two, I'm game: First off, Ada simply doesn't need as much protection on memory because apart from the intentional manipulation (e.g. setting the Address, etc) there isn't the stomp-happy tendencies to contend with: a type has valid values and even if unconstrained, the value isn't (unconstrained) — this means that things like parameters (along with modes: in/out/in out) don't have the same sort of problems that C's \"an array is really just the address of the first element\" parameter-notion engenders. (Ada's arrays \"knowing their own size\" is what enables that to be sidestepped in Ada; as well as allowing FOR to iterate over indefinite-array parameters as well as slices being passed in, as well as allowing it to be returned.) So, as an example, you could have a buffer for a user-string —Command : Constant String:= Ada.Text_IO.Get_Line;— within a declare-block, perfectly sizing the buffer to the input, rather than trying to \"guestimate\" or allocate-large some arbitrary-size, whic will be reclaimed upon exiting the declare's scope. The combination of having the ability to handle that sort of \"undetermined until run-time\" value, both in allocation and in processing (returning from a function and/or passing [directly or indirectly] into a parameter) leads you to just not need access like you would have to use pointers in C/++, and that makes it easy and natural to avoid unnecessary access values/parameters. I'm not sure whether Ada has sum types (enum in Rust). Variant records. Type Weapon_Style is (Melee, Ranged); Type Weapon(Style : Weapon_Style) is record Max_Damage : Natural; -- Common field. Case Style is when Ranged => Effective_Range : Positive; -- in yards. when others => Null; -- No components. End case; end record; Bow : Weapon( Style => Ranged ); The discriminant of bow, Style, cannot be changed after initialization (w/ one exception, involving defaulted discriminant and whole-record replacement, IIRC; I really haven't had much need to use that feature) — the compiler ensures that you can't access fields that aren't valid as per the discriminant (IIRC, called a tagged-union in some languages) which means you generally can't access fields that aren't valid... the exception of course being if you do something like Unchecked_Conversion, or use For Style_Variable use Bow.Style'Address; to alter the \"tag\", or some similar intentional manipulation. One of the key problems faced by sum types is that if you can obtain a reference to the payload of an enum, override that payload with another type, and then still access the former payload... you're in uncharted territory. See above. You can't, in general, stop that if you have unchecked-conversion, memory-overlaying or similar. In Ada, there's a great reduction in the need for [explicit] references/pointers (and, to some degree, addresses), which means that you simply can't accidentally create Heartbleed... there's also the Pragma Restrictions which allows you to enlist the compiler to enforce restrictions on the language; e.g.: Pragma Restrictions( No_Implicit_Heap_Allocations ); & Pragma Restrictions( No_Anonymous_Allocators ); will act exactly \"as it says on the tin\" and, respectively, forbid implicit heap allocations and anon. allocators. Rust solves this with the borrow checker, how does Ada handle it? The language disallows altering the discriminant, enforces validity checks on accessing fields, and makes those attempts obvious/non-accidental. permalink embed save parent report reply [–]we_are_mammals[S] 1 point2 points3 points 29 days ago (1 child) Are these kinds of holes in Ada's type safety well-known to Ada developers: http://www.enyo.de/fw/notes/ada-type-safety.html ? permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 28 days ago (0 children) Yes, it is well-known. However, it should be noted that it is dependent on \"bounded errors\" —instead of having undefined-behavior, Ada uses the notion of \"bounded error\" described in the Rationale as \"The general idea is that the behavior is not fully determined but nevertheless falls within well-defined bounds. Many errors which were previously classed as erroneous (which implied completely undefined behavior) are now simply bounded errors. An obvious example is the consequence of evaluating an uninitialized scalar variable; this could result in the raising of Program_Error or Constraint_Error or the production of a value not in the subtype, see [RM95 4.4, 11.6].\" (as opposed to undefined behavior)— and that it is using the aforementioned exception to the strict checking/enforcement of discriminants. permalink embed save parent report reply [–]matthieum[he/him] 0 points1 point2 points 28 days ago (1 child) Thanks for the in-depth response! It looks to me that the \"intentional manipulation\" of variants is somewhat similar to whipping out unsafe in Rust then. permalink embed save parent report reply [–]OneWingedShark 2 points3 points4 points 28 days ago (0 children) It pretty much is. When you see something like: Subtype String_4 is String(1..4); Function To_Hex( Object : Interfaces.Integer_16 ) return String; -- Implementation/Body Function To_Hex(Object : Interfaces.Integer_16) return String is Type Nybble is range 0..15, Size => 4; Temp : Array(String_4'Range) of Nybble with Import, Address => Object'Address, Component_Size => 4; Begin Return Result : String_4 do For I in Result'Range loop Declare C : Character Renames Result(I); V : Nybble Renames Temp(I); Begin C:= Character'Val( V + (Case V is when 16#0#..16#9# => Character'Pos('0') - 16#0#, when 16#A#..16#F# => Character'Pos('A') - 16#A# )); End; End loop; End return; End To_Hex; You know there's low-level, possibly unsafe manipulation going on. In this case it's using the type Nybble and the array overlaying the 16-bit integer in order to facilitate converting from integer to hex... The nice thing about this particular formulation is that its only requirement for correctness is that '0'..'9' and 'A'..'F' are contiguous and increasing. (Meaning it works under EBCDIC, as well as ASCII/Unicode.) While the above certainly is a contrived example, I trust that it shows how such inherently low-level (\"unsafe\") features can be used with a bit more confidence than, say, C/C++'s bitmask/bitshift low-level approaches due to the type-system: there's no access/pointer, the Nybble and Temp-array are well-defined and constrained to the scope they are needed, the Temp-array's range being exactly String_4's and the FOR loop acting thereon eliminates index-mismatches, and so on. (Though perhaps a better illustration of the lack of need for bitshift/bitmask can be shown with a record defining the registers for a VM or CPU: you can do something like naming the protection-rings (Kernel, Driver, Protected, User) instead of using 0..3, and access fields of that type within a record without any of the bit-manipulation.) permalink embed save parent report reply [–]we_are_mammals[S] 0 points1 point2 points 29 days ago (3 children) I wouldn't call SPARK tedious Some theorems are harder to prove than others. I imagine that proving that, say, an open-addressing hash table actually works as a container (returning the stuff you put into it) will be hard. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 29 days ago (2 children) Which is why I qualified it with \"in comparison with other methods\" — certainly there's going to be some approaches that are wonderful [for some application/problem] precisely because you're acting in accordance with the tool's design-philosophy for a good proving-tool (similar to how APL's Game of Life is to GoL due to its focus on arrays), but given what I've seen of other proof-systems, SPARK's integration is top-notch and decently easy to use. permalink embed save parent report reply [–]we_are_mammals[S] 1 point2 points3 points 29 days ago (1 child) Things that are somewhat non-trivial but understandable by humans (e.g. how a hash table works) will be quite hard to explain to SPARK or other formal proof systems. That's what I meant by \"tedious\". permalink embed save parent report reply [–]OneWingedShark 1 point2 points3 points 28 days ago (0 children) Ah, I understand now. permalink embed save parent report reply [–]rohel01 14 points15 points16 points 29 days ago (3 children) TLDR: I would prefer Rust over Ada nowadays. But I think one should not focus only on the technical merits of both languages to choose one or the other. I have significant Ada professional experience (~5 years) for embedded real-time critical SW development. I think the language is a formidable piece of engineering and a vast improvement over C, which I had used previously for similar developments but in another field. I stopped using Ada when I joined a C-focused company. Note this was before the general availability of SPARK. Since then, I had no opportunity to program in Ada again despite joining the aerospace industry where it is more common place. Nowadays, I consider Rust a better alternative for my team. From a technical point of view, I think both languages follow a similar approach, with some interesting differences. For example, I very much prefer Ada's approach to generics while I believe excluding the tasking system from the Rust standard runtime was the right call. But, Rust \"wins\" for me not because of its technical merits, but because Ada lacks traction. On the job market for instance, big names are openly recruiting Rust developers, which means young students are more likely to request Rust training in the upcoming years. Also, Rust SW ecosystem, in terms of libraries and frameworks, seems to be thriving so my teams can rely mostly on Rust code, with some C assets on the side. By contrast, I see Ada as a niche community. I would even argue it was marketed as such for a long time, at least by Adacore. You joined a small but elite community, whereas Rust has explicitly targeted everyone from the start. Back in the day (2010-2014), it was surprisingly difficult to download an Ada distribution with a permissive licence. It was available, just not advertised much. On the SW side, most Ada code we worked on was either written in-house, or provided with the distribution. For specific business needs, we spent a considerable amount of time wrapping 3rd party C/C++ libraries. permalink embed save report reply [–]Kevlar-700 1 point2 points3 points 26 days ago* (2 children) Well I co-run my own company and traction doesn't matter much to me and actually Ada is more developed than Rust. I always re-wrote half the vendors quite terrible C code anyway as well as the drivers for other hardware. Though, I would point out that Ada is used behind closed doors more than you may realise. Adas open source eco system is improving rapidly too. I chose Ada because I believe it to be the easier, safer more capable language for technical reasons and prefer it's syntax and maintainability. WRT tasks. I use the zero footprint runtime so tasking is excluded. There is no good reason to exclude Adas excellent tasking aside from that it is easiest to get zfp running on a new micro with a zero footprint runtime. I admit that you do have to adapt some cide to work with a zfp runtime such as removing protected types. For me, Adas record overlays are a killer feature for embedded or network protocols. As well as Adas ranged types for input validation. And of course Spark is second to none. Rather than wrapping unsafe in embedded crates. Adas type system describes and checks hw register or network protocol sizes in record overlays. All the actual code is safe and easy to use. The recent news is that Adacore are working on bi-directional bindings between Ada and Rust. I have no idea of the details but it will be of interest to me. permalink embed save parent report reply [–]rohel01 0 points1 point2 points 24 days ago (1 child) What is the typical scale of your projects? Mine usually involve up to five developers for up to three years for the initial development phase. My company can run up to three such projects in parallel at a given time. In that context, traction matters. Recruiting Ada developers has been a consistent pain point, at least in my country (France). For similar scale-related reasons, we cannot afford to rewrite half of our drivers or 3rd party libraries in Ada. This is just not reasonable. A tasking systems directly integrated in the language syntax and runtime is obviously really useful for developers. The downside here concerns the language long term maintenance and evolution. For example, several tasking models have emerged to suit different needs. Ada (implicitly) picked one, but is it possible to implement another model without impact the language syntax and standard runtime? tasking systems are extremely complex beasts, especially given Ada design constraints. It integrates with many other language and runtime features. This has made the language significantly more difficult to improve or extend as one now needs to consider the potential impacts of each change to this central systems. Maintaining backward compatibility is that much harder. In that regard, Rust can be more flexible (support multiple models) and can evolve more efficiently. permalink embed save parent report reply [–]Kevlar-700 1 point2 points3 points 24 days ago* (0 children) A lot of our code base is shared across our products and so I do not see the context issue. Perhaps you need to provide more context. You mention \"our drivers\". Are they community supported or ones that you have already written and do not want to re-write. I am sure your context is different to mine. In our case we have drivers in Ada. In some cases they are based on drivers in the AdaCore repository and in others they would have to be written from scratch in Rust, too. I haven't found anything lacking so far to be honest. As I say re-writing the vendor C code was a must for me but perhaps the Rust embedded libraries are production ready and complete? Though that wouldn't be even close to convincing me to switch to Rust personally. Especially when Rust support may be here soon enough. C interfacing is excellent but I haven't needed it yet and I try to steer clear. WRT tasking. I use single core micros and do not really need it beyond scheduling. I also use zero footprint runtimes personally so tasking isn't available to my micro code. However, I don't but you can run Ada code on an RTOS and this is a recent development so yes it appears Ada is flexible here. https://forum.ada-lang.io/t/lightweight-parallelism-library-based-on-ada-2022-features/516?mobile_view=0 permalink embed save parent report reply [–]deeplywoven 13 points14 points15 points 1 month ago (1 child) I'd wager that 98% of Rust users have never used Ada and at least 50-60% haven't even heard of it. permalink embed save report reply [–]matthieum[he/him] 0 points1 point2 points 29 days ago (0 children) I used Ada when studying Comp Sci... only for a few weeks, and nigh on 20 years ago now. All I remember is that the syntax was painful :/ permalink embed save parent report reply [–]wintrmt3 8 points9 points10 points 1 month ago (2 children) I never use the heap and the stack is memory safe for all general purposes in Ada. This is key, if you are okay with never using heap all heap related unsafety goes away. What it only implies is that using the heap in ada is actually unsafe, you don't get more help than in C. permalink embed save report reply [–]Lucretia9 1 point2 points3 points 29 days ago (1 child) Null exclusion in access types is much safer than C. permalink embed save parent report reply [–]Kevlar-700 1 point2 points3 points 26 days ago (0 children) Spark also has a basic form of borrowing now. permalink embed save parent report reply [–]shadow31 4 points5 points6 points 1 month ago (5 children) Here are two relevant posts from the Ada subreddit: https://www.reddit.com/r/ada/comments/mme3jk/is_ada_memory_safe/ https://www.reddit.com/r/ada/comments/mfle4d/not_counting_readbeforewrite_is_ada_memorysafe/ It seems that without SPARK, Ada is mostly memory safe but not completely. Further, I've never seen any kind of systematic benchmarks showing Ada to be faster than Rust and the ease of use claim is extremely subjective at best. If you want to learn Ada, by all means learn Ada! If you want to learn Rust, learn Rust! permalink embed save report reply [–]Kevlar-700 2 points3 points4 points 26 days ago (4 children) At the low level especially in embedded. Rust relies on unsafe constructs far more than Ada actually. So if you argue Ada is not \"memory safe\". Is rust \"memory safe\", actually? permalink embed save parent report reply [–]shadow31 0 points1 point2 points 25 days ago (3 children) Yes, Rust is memory safe, unsafe Rust is not. The delineation between safe and unsafe code is critical and something Ada appears to lack. permalink embed save parent report reply [–]Kevlar-700 1 point2 points3 points 25 days ago (2 children) l can appreciate that but it is far from critical. That doesn't change the fact that Adas type system enables safer memory manipulation than Rust at the low level but I guess that you do not understand what I am talking about anyway. Not only that but memory manipulation becomes very nice with the compiler doing the work for you. Timer.these_4_bits := some_enum_name Instead of what the rust embedded libs are doing at a low level, which is vulnerable to typos. permalink embed save parent report reply [–]shadow31 1 point2 points3 points 25 days ago (1 child) I do understand what you're talking about, I just don't agree with your conclusions. Making code look \"nice\" does not actually improve safety. Delineating, encapsulating and abstracting unsafe code does. Further, you absolutely can do the same thing you've shown with the various bitflags crates that are out there. That embedded Rust tends not to do that is a library issue, not a language one. permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 25 days ago* (0 children) I believe that you are mistaken because rust does not have bit precise types of every size (problem domain typing). On top of this all of the sizes are checked in record overlays. So long as the hardware documentation or svd file is correct (which can be wrong and Ada has pointed out some of those documentation and/or svd mistakes) all bit manipulation is safe. That is not true of Rust. The best rust can do is code generation which isn't far from re-using macros in C. It is far more fragile and more error prone and not protected under every compilation. Another important point is that the user gets to implement these tricky records beautifully with compiler aid for e.g. Network protocol packets and use compiler built in range validity checks. This is all right there in easy to read standard Ada code for any user to mimick and utilise. Also, making code more readable absolutely does increase safety. permalink embed save parent report reply [–]burntsushi 7 points8 points9 points 29 days ago (18 children) The red (or perhaps yellow) flag here in my opinion is the statement \"I never use the heap.\" At this point, IMO, you should insist to see what kinds of code they're writing. Never using the heap is very likely a quite large constraint on the kinds of code one is writing. I don't mean to say that \"I never use the heap\" can't possibly be true. But rather, it makes their claims and statements a lot less broadly applicable than I think you're assuming here. There are certainly domains where \"I never use the heap\" is a reasonable way to go about things. Anyway, IMO, the right response here is to ask for code and real world examples. permalink embed save report reply [–]Mountain_Custard 1 point2 points3 points 29 days ago (16 children) To a C/C++ or Rust programmer never using the heap would imply really tying your handing behind your back when you program. Ada gives a lot of control on stack allocation that C/C++ and Rust do not. Most of the Ada structures like strings and vectors can be dynamically allocated on the stack at runtime. You just don’t need to use the heap very much when you program in Ada. permalink embed save parent report reply [–]burntsushi 2 points3 points4 points 28 days ago (15 children) I would still insist on seeing real programs that don't use the heap. Where are the CLI tools written in Ada that make zero use of the heap? What happens when your data grows bigger than what the stack can give you? permalink embed save parent report reply [–]ajdude2 2 points3 points4 points 28 days ago (14 children) I almost exclusively use the stack in Getada (with the exception of controlled types that are provided in the standard library and two times where I had to use a GNAT extension that required a pointer, and soon that's going to be gone). It's pretty easy because I can create a function that returns an array such as type My_Array is array (Positive range ) of Integer; function Dynamic_Ints (Size : Positive; Init_Val : Integer := 0) return My_Array is Result : My_Array (1 .. Positive) := (others => Init_Val); begin return Result; end Dynamic_Ints; I can also create the result value later on; a simplified example of what I'm actually doing in my shells program (check shells.ads/shells.adb): type Shell_Array is array (Positive range ) of Shell_Config; -- Returns the shells available for a given platform. function Available_Shells (Current_Platform : Platform) return Shell_Array; The function can look like: function Available_Shells return Shell_Array is Shell_Amount : Natural := 0; -- Amount of shells discovered begin -- Calculate how large of an array I need, store value in Shell_Amount Shell_Amount := 5; -- e.g. declare Result : Shell_Array (1 .. Shell_Amount) := ...; begin return Result; end; end Available_Shells; And then declare a new variable on the stack in the declaration part of my Installer function and assign it to the value of that function with (link to actual code): Our_Shells : constant Shell_Array := (if not Our_Settings.No_Update_Path and then Our_Settings.Current_Platform.OS /= Windows then Available_Shells (Our_Settings.Current_Platform) else (1 => (Null_Unbounded_String, null_shell))); I pretty much do this with everything that would otherwise normally require dynamic allocation. The function it calls allocates it onto the stack, and assigns it between a declare /is and begin. Ada is pretty rigid with scope, so I'm only declaring a variable specifically when needed, and then it no longer lives after it's no longer needed, so while it's possible for a lot of data to come about, it's usually not around very long. I've honestly never exhausted the stack unless I've specifically tried to do something like An_Array : My_Array (1 .. Positive'Last);. For example, if I wanted to read some user input and store it in a string, I can just create that string at the time that I read the input, e.g. loop Put_Line (\"Enter a length of the array\"); declare Response : Integer := Get_Line; begin exit when Response = \"\"; Put_Line (\"You entered '\" & Response & \"'\"); end; end loop; This could easily be extended to take user input and \"dynamically\" create an array to work with, e.g. loop Put_Line (\"Enter a word or press enter to exit:\"); Put (\"> \"); declare Response : String := Get_Line; Numbers : My_Array (1 .. Positive'Value (Response)); begin Put_Line (\"Length of the array is '\" & Numbers'Length'Image); end; end loop; (none of this has error checking, but if you used a different index type instead of Positive then you can further constrain a maximum size of the array and prevent overflows to the maximum size of the stack) permalink embed save parent report reply [–]burntsushi 4 points5 points6 points 28 days ago (13 children) I'm not necessarily asking about how to prevent overflowing the stack. I somewhat assume Ada has some facilities for guarding against that. What I'm keen to know is how you deal with data that is in and of itself too big for the stack. Like maybe you want to read 50MB from a file on to the heap. Or maybe you want to build a regex that is enormous. Or any one of a number of other things. Where do you put that stuff if it would otherwise overflow the stack? I don't completely grok everything you said, but thank you for showing some code. It sounds like the key trick here is \"safe dynamic stack allocation.\" That leads me to another question, which is what happens when you want to create data that outlives the scope of the function that created it? permalink embed save parent report reply [–]solstice333 1 point2 points3 points 27 days ago* (0 children) Huh, interesting coincidence. I've been having some fun writing a generational arena recently in cpp and have been running into a similar path of thinking. I'm going to diverge from Ada for a bit, but I think the following is somewhat related. Feel free to ignore if it's too much design rambling :). Re:\"what if large data that eats up stack capacity\". So if the data is large, but few, normally I would just use the heap for those few things, and as a result, eat the (de)alloc overhead. I also just found out that I can adjust the stack size in visual studio project properties linker configuration. Re:\"data outlives scope of function\". I have this case where when alloc some data in my arena and return a \"result\" (pointer to the thing allocated in the arena), the \"result\" stores a reference/pointer to the arena that owns it. The arena (and I also mean its objects) can get allocated on the stack. If the arena was to hit the end of its lifetime before the \"result\" does, I require an abort/panic to occur. permalink embed save parent report reply [–]ajdude2 1 point2 points3 points 26 days ago (10 children) I'm not necessarily asking about how to prevent overflowing the stack. I somewhat assume Ada has some facilities for guarding against that. What I'm keen to know is how you deal with data that is in and of itself too big for the stack. Like maybe you want to read 50MB from a file on to the heap. Or maybe you want to build a regex that is enormous. Or any one of a number of other things. Where do you put that stuff if it would otherwise overflow the stack? There's ways to get the stack to allocate to the heap, such as declaring it directly in a package (but you'll need to know how much you need at compile time, I think). Also kind of related, if you pass -fstack-check to the compiler, it will try to predict overflows at compile time. Obviously this doesn't help with dynamic allocations. To compliment what u/OneWingedShark said, Ada provides an extensive container library to handle allocation to the heap. If you want to create a vector, you can create one using that library and reap the benefits of the heap while still being memory safe. If I want a vector of integers, I could do something like: with Ada.Containers.Vectors; procedure My_Proc is package Integer_Vectors is new Ada.Containers.Vectors (Index_Type => Natural, Element_Type => Integer); V : Integer_Vectors.Vector; begin V.Append(1); V.Append(2); V.Append(9001); for X of V loop Put_Line (X'Image); end loop; end My_Proc; Behind the scenes, the container library is initializing the vector, during append you end up with new and finally, once it goes out of scope, it calls the destructor which handles the free. You're not going to have anything like the borrow-checker unless you use SPARK, but I consider controlled types to be very competent, especially if you stick with the standard library for them. If you wanted to create your own controlled type you can, and you can do so without the API ever touching the internals. For example, here is something for Integers in a controlled types and dynamic allocation in the ads (like a .h) file: package My_Lib is type My_Type is tagged private; function Is_Empty (This : My_Type) return Boolean; procedure Allocate (This in out : My_Type; Amount : Integer) with Pre => This.Is_Empty; function Read (This : My_Type) return Integer with Pre => not This.Is_Empty; private type IntPtr is access all Integer; type My_Type is new Controlled with record Element : IntPtr := null; end record; function Finalize (This : in out My_Type); end My_Lib; And the body (like a .c file) package body My_Lib is procedure Allocate (This in out : My_Type; Amount : Integer) is begin This.Element := new Integer (Amount); end Allocate; function Is_Empty (This : My_Type) return (This.Element = null); function Read (This : My_Type) return Integer is begin return This.Element.all; end Read; -- Called when the object goes out of scope function Finalize (This : in out My_Type) is Ptr : IntPtr := This.Element; begin This.Element := null; Ada.Unchecked_Deallocation (Ptr); end Finalize; end My_Lib; Note: The with Pre => Is_Empty basically will cause a runtime error if Allocate is called when it isn't already empty. If I rewrite this example for a larger audience I'd probably use a Stack or something, but the point isn't the allocation, it's the de-allocation. Now I can use this like so: with My_Lib; Procedure Testing is use My_Lib; begin Put_Line (\"Allocating:\"); declare My_Item : My_Lib.My_Type; begin My_Item.Allocate(5); Put_Line (My_Item.Read'Image); end; Put_Line (\"I'm all done.\"); end Testing; By the time that first end is reached, My_Item automatically goes out of scope, and then Finalize is called and the deallocation is handled. This doesn't exactly answer your question with \"How do you prevent overflowing the stack if you're dealing with large enough data to overflow the stack\" and I'm curious what others do. I personally tend to like finite state machines in my parsers, and I tend to read and process a file line-by-line (or group by group), but I know several libraries just load a whole file into a container and be done with it, and others like json-ada use a mix, e.g. a stack-allocated array of dynamic vectors: package Array_Vectors is new Ada.Containers.Vectors (Positive, Array_Value); package Object_Vectors is new Ada.Containers.Indefinite_Vectors (Positive, Key_Value_Pair); type Array_Level_Array is array (Positive range ) of Array_Vectors.Vector; type Object_Level_Array is array (Positive range ) of Object_Vectors.Vector; type Memory_Allocator (Maximum_Depth : Positive) is record Array_Levels : Array_Level_Array (1 .. Maximum_Depth); Object_Levels : Object_Level_Array (1 .. Maximum_Depth); end record; As mentioned in a sibling comment, you can pass parameters to datatypes (struct in C) directly, thus dynamically allocating an array in a struct on the stack during initialization. That leads me to another question, which is what happens when you want to create data that outlives the scope of the function that created it? Ada likes you to be very specific when it comes to scope. Normally you declare the variables that you only plan on using in that body of the program, and if you need more local variables that don't have to be accessed outside a specific block, you either use a function or create another block in the body. If I need the data to come out of a function that created it to be accessed later in the program, I have two options: I either return the data, or pass it to the program in an out parameter (if the variable contained some data before that function that I want to utilize, I use the in out keyword). E.g. procedure Add (A, B : in Integer; C out Integer); allows C to be some data passed out of the procedure and into the next level up. Now I can do something like: declare Num : Integer; begin Add (2, 2, Num); Put_Line (Num'Image); -- Should say \"4\" end; I think someone else already went more in-depth over how you can pass things in/out of procedures and functions, which is an added benefit of utilizing \"by reference\" type arguments without actually having to work with reference types. permalink embed save parent report reply [–]burntsushi 0 points1 point2 points 26 days ago (9 children) I think my issue here is that the original prompt for this entire discussion was \"never used the heap.\" I understand Ada has containers that allocate on the heap, but presumably the person who said they \"never use the heap\" doesn't use such things? permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (8 children) I write code for micro controllers where the whole ram is available as stack. If a package level global such as I use for logging is placed on the heap then it is transparent to me. I wouldn't read a whole file into memory anyway though. My micros do handle 128 gig sd cards. The stack is faster too. Some adaists only use the heap because Linux imposes stack limits unless you have root. permalink embed save parent report reply [–]burntsushi 0 points1 point2 points 26 days ago (6 children) I write code for micro controllers It would be very helpful if you could share this when you share your programming experience. It is critical context. And my guess is that if you had shared it, the OP of this post would have been less confused. permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (5 children) I understand your thought process due to heap avoidance with embedded C. However you have missed the points made above. I do not avoid using the heap with Ada. Coding is more straight forward. OS memory management, might be a useful counter context. Spark only has basic ownership and pools require runtime support. permalink embed save parent report reply continue this thread [–]Kevlar-700 0 points1 point2 points 26 days ago (0 children) Actually I think a package level global might go in the data section (bss). Atleast in my use cases. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 27 days ago (0 children) That leads me to another question, which is what happens when you want to create data that outlives the scope of the function that created it? Typically you'd use Ada.Containers.Whatever to hold the data and manage the cleanup when the object itself goes out of scope or is manually reset. Where do you put that stuff if it would otherwise overflow the stack? This is arguably a case for using an access type, and while you certainly can it's easier to use the containers... though another option is to use controlled-types to automatically deallocate an internal access when Finalize is called. — I do something similar (though with closing files) in a little utility library I'm working on: spec & body. permalink embed save parent report reply [–]we_are_mammals[S] 0 points1 point2 points 29 days ago (0 children) Yes, never using the heap sounds very restrictive. But only using it via arenas/pools/regions - that sounds interesting. I'm not sure if all programs can be structured like this though. permalink embed save parent report reply [–]kibwen 9 points10 points11 points 1 month ago* (16 children) Difficult to say. I've tried to learn Ada but I found the barrier to entry to be high; I couldn't find any good, free, comprehensive online resources that weren't just a dry language reference. After asking around the recommended way to learn modern Ada appeared to involve paying for a book that costs hundreds of dollars, and I stopped there. As far as I understand, it's difficult to compare Rust to Ada (relative to comparing Rust to C) because they seem to have different approaches. For example, Ada seems to rely on GC in order to make heap allocation safe, whereas Rust doesn't, and the line \"the stack is memory safe for all general purposes in Ada\" immediately makes it sound as though stack allocation in Ada is unsafe in certain contexts. I don't know much about Ada's type system, but I tend to doubt that it has linear/affine types like Rust does, which means that even if Ada's type system is \"richer\" than Rust's by some measure, Rust's is also richer than Ada's by a different measure. Most of the time when I see Ada users criticize Rust, it's because it doesn't have built-in ranged integer newtypes (the ability to declare that the value of a numeric type must be within a certain range, which is enforced via runtime checks); it wouldn't be too difficult to write a proc macro for Rust to do the same thing, and I started to do so myself (which is why I wanted to learn Ada in the first place, in order to match the featureset it provides here). At the end of the day, I'm sure Ada is a fine language, and I commend it for being the torchbearer of \"we should care about writing safer, more reliable systems software\" for so many decades, but until the onboarding experience is better I don't know how anyone is expected to learn it outside of having a big company pay to send you to training. permalink embed save report reply [–]we_are_mammals[S] 11 points12 points13 points 1 month ago (3 children) Ada seems to rely on GC in order to make heap allocation safe I'm no Ada expert, but to quote Wikipedia: Though the semantics of the language allow automatic garbage collection of inaccessible objects, most implementations do not support it by default, as it would cause unpredictable behaviour in real-time systems. Ada does support a limited form of region-based memory management; also, creative use of storage pools can provide for a limited form of automatic garbage collection, since destroying a storage pool also destroys all the objects in the pool. permalink embed save parent report reply [–]crusoe 4 points5 points6 points 1 month ago (2 children) Ada is intended for basically programming weapon systems. So things like storage pools ( allocating storage up front like embedded ) and other such features make it good for that niche. It's otherwise a kinda weird ans awkward language to use outside of that area. permalink embed save parent report reply [–]WhyDoIExistPlsTellMe 5 points6 points7 points 1 month ago (0 children) no, not really. You dont need dynamic allocation in most cases. When you do, you make an object with a finalizer. It can use whatever storage pool you want to. Simple stuff. permalink embed save parent report reply [–]Lucretia9 5 points6 points7 points 29 days ago (0 children) Ada is intended for basically programming weapon systems. More misinformation. Ada was designed to replace thousands of languages in use all over the DoD so they could focus on one. That ranged from databases to flight simulators to weapons to flight control, etc. Cars have hundreds of mcu's running in them, and some cars (toyota) use Ada on these chips, the DSA was invented so that multiple chips running Ada partitions (programs) could talk to each other. FYI, SGI's had OpenGL and the *.spec were created so that bindings to Ada could be generated by machine. permalink embed save parent report reply [–]OneWingedShark 8 points9 points10 points 1 month ago (0 children) I've tried to learn Ada but I found the barrier to entry to be high; I couldn't find any good, free, comprehensive online resources that weren't just a dry language reference. Here. It's a set of three papers describing (1) Ada's packages [w/ a refresher on the type-system], (2) Ada's Object Oriented Programming [which builds on the features of the type-system], and (3) Ada's Generic system. permalink embed save parent report reply [–]Mountain_Custard 2 points3 points4 points 1 month ago (4 children) There’s no garage collector in most Ada compilers. It has pointers called access types and pools which are arenas. The prefers way to manger memory in Ada is to use stack based objects provided by the Std library first and foremost. If you need to manage memory you should use memory pools (arenas) or wrap the pointers in a container for the equivalent of a smart pointer. If you need them Ada does have raw pointers that are unsafe but it’s extremely rare that you’d have to use them. Here’s a slide show on memory management in Ada. https://people.cs.kuleuven.be/~dirk.craeynest/ada-belgium/events/16/160130-fosdem/09-ada-memory.pdf permalink embed save parent report reply [–]eras 1 point2 points3 points 1 month ago (3 children) So it looks like Ada solves dangling pointers with \"Dereference is checked for validity\"? Seems like this could have performance implications? Is the check robust regarding memory reuse? permalink embed save parent report reply [–]Lucretia9 1 point2 points3 points 29 days ago (2 children) The same performance implications in other languages if they were written correctly and had checks in place, which most do not. But if you use SPARK, you can possibly prove you don't need them. permalink embed save parent report reply [–]eras 1 point2 points3 points 29 days ago (1 child) Which languages other than Ada check invalid pointer dereferences? I wasn't familiar with any; GC-based languages as well as Rust ensure you can't have such pointers in the first place. So there's no such checking cost for what you can't have. permalink embed save parent report reply [–]ImYoric 0 points1 point2 points 29 days ago (0 children) I seem to remember that (some versions of?) FORTRAN also rely on this. permalink embed save parent report reply [–]Lucretia9 -3 points-2 points-1 points 29 days ago* (5 children) I've tried to learn Ada but I found the barrier to entry to be high; I couldn't find any good, free, comprehensive online resources that weren't just a dry language reference. Seems like you didn't look at all, so you could make this argument maybe? ada-lang.io literally points you at a learning resource, second word in the menu \"learn,\" then there's AdaCore's learning platform. For example, Ada seems to rely on GC Just proves my point. Ada 83 RM allows for a GC, not one Ada compiler, EVER implemented GC. permalink embed save parent report reply [–]kibwen 3 points4 points5 points 29 days ago (2 children) Seems like you didn't look at all, so you could make this argument maybe? I literally asked the Ada users on all the Ada-specific IRC channels and mailing lists that I could find. Please don't leap to assume slanderous intent. permalink embed save parent report reply [–]Lucretia9 -2 points-1 points0 points 29 days ago (1 child) Really? When I don't remember. permalink embed save parent report reply [–]kibwen 0 points1 point2 points 29 days ago (0 children) Based on the commit dates to the defunct repo containing my ranged-integers proc macro, this would have been 2019 at the latest. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 27 days ago (1 child) not one Ada compiler, EVER implemented GC. Ada for DOTNET and for Java both had GC. permalink embed save parent report reply [–]Lucretia9 0 points1 point2 points 27 days ago (0 children) That was the dotnet and java runtimes, not the compiler, the compiler just had to be modified to work with them. permalink embed save parent report reply [–]Trader-One 4 points5 points6 points 1 month ago (16 children) Yes, Ada is safer than rust, but its not practical. For embedded use where Ada should shine everybody is using C/C++ because its close to hardware. In school we had Ada course but even teacher never used it in real embedded project. I also never used it, I do not even know what IDE supports Ada. permalink embed save report reply [–]pjmlp 10 points11 points12 points 1 month ago (11 children) Ada is as close to the hardware as C and C++. Many people use C and C++, because their compilers are cheaper, or they are the only ones provided by the chip vendor. permalink embed save parent report reply [–]Trader-One 4 points5 points6 points 1 month ago (10 children) Yes, there are no ADA sdk for microcontrollers and it should be area where Ada will shine. Ukraine war showed us that newly quickly developed suicide drones runs Python with OpenCV, NumPy, scikit. 60k Python LOC can run drone and control station. permalink embed save parent report reply [–]EasterWesterner 3 points4 points5 points 29 days ago (0 children) Actually interesting topic: friend of mine was developing non-military drones with some sort of computer vision long before the war and higher demand. At some point it was easier and cheaper to build drones with more powerful chips and use python, than suffer with pure C or C++ approach and CV integration permalink embed save parent report reply [–]Lucretia9 1 point2 points3 points 29 days ago (8 children) there are no ADA sdk for microcontrollers FFS. permalink embed save parent report reply [–]Trader-One 3 points4 points5 points 29 days ago (7 children) management will not approve random github SDK. It has to be official from manufacturer. When I download SDK/IDE from manufacturer I haven't seen ADA there. For example AVR devkit is ASM/C/C++ - https://www.microchip.com/en-us/tools-resources/develop/microchip-studio Adacore now supports rust - https://www.adacore.com/gnatpro-rust permalink embed save parent report reply [–]Lucretia9 0 points1 point2 points 29 days ago (0 children) management will not approve random github SDK. It has to be official from manufacturer. Then look at the very top repo in the link I gave you. permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (5 children) The manufacturer sdks are usually horribly bad. permalink embed save parent report reply [–]Trader-One 0 points1 point2 points 26 days ago (4 children) It doesn't matter. Management wants them otherwise insurance company would raise prices. Welcome to corporate world. permalink embed save parent report reply [–]Kevlar-700 1 point2 points3 points 26 days ago (3 children) Bad management has lead to C being everywhere and weekly exploits. permalink embed save parent report reply [–]Trader-One 0 points1 point2 points 26 days ago (2 children) C is everywhere because devkits are for C and people are easy to hire. permalink embed save parent report reply [–]Kevlar-700 1 point2 points3 points 26 days ago (1 child) I think, it is because it is faster to write crap buggy code and deal with the cost of the shipped code later or in the case of devkits, it isn't actually shipped by them anyway. Ada compilers were expensive whilst C gained traction, too. Ada was so sophisticated they gained a reputation for being buggy in the early years too, creating animosity especially when forced to use them for d.o.d. projects. permalink embed save parent report reply continue this thread [–]Lucretia9 5 points6 points7 points 29 days ago (2 children) Why does the name Ada always bring out people commenting who have zero knowledge of it? Look at VSCode, has an Ada LS, so does vi(m) and emacs (afaik). permalink embed save parent report reply [–]yel50 3 points4 points5 points 29 days ago (1 child) to be fair, the Ada VSCode extension is easily the worst language extension I've ever used. a year ago, it was bad to the point of unusable. they fixed some things and now it's usable, but still horribly annoying. constant messages popping up that an LSP request failed. given that the extension is written and maintained by the same people who write the compiler, it's not a good look. I've also found SPARK unusable due to bugs in the prover. I've hit two, both related to loops. one would cause the prover to go into an infinite loop and the other caused it to crash. I've yet to hit a bug in rust's borrow checker. permalink embed save parent report reply [–]Lucretia9 0 points1 point2 points 29 days ago (0 children) the worst language extension I've ever used. a year ago, it was bad to the point of unusable Have you tried telling it which gpr file to use in the workspace settings? permalink embed save parent report reply [–]Kevlar-700 0 points1 point2 points 26 days ago (0 children) Ada is the best language for embedded use by far. I guess you have never used a hardware register record overlay. I use Gnat Studio community release as my Ada IDE. \"https://github.com/AdaCore/gnatstudio\" permalink embed save parent report reply [+]matusaleeem 2 points3 points4 points 1 month ago (0 children) Of course Ada is safe as heck, it's the whole point of the language and it has been used in avionics and stuff. permalink embed save report reply [–]robottron45 -1 points0 points1 point 29 days ago (0 children) Don‘t know how similar Ada and VHDL are, but I find it very difficult to work with complex types in VHDL. Yes, I know, hardware is generated, but its still a synthesis, and describing buses in VHDL at a high level was very difficult, hence SystemC more popular for it I guess. permalink embed save report reply [+]binaryfireball comment score below threshold-9 points-8 points-7 points 1 month ago (0 children) Is a circle jerk safer than a reach around? After a couple months of reading this subreddit that's all I've gotten from the community. permalink embed save report reply [–]rseymour 0 points1 point2 points 29 days ago (3 children) Speculation: Ada (I've barely ever even compiled an Ada program, but I talked with some NYU folks who had to learn it as a main language) always seemed like it was safer than anything and only easy to use if you consider a binder full of deep specifications what you're trying to do. It was/is very good for fighter aircraft, and was famously used on those golden age cold war fighters. I think the reason it isn't heard of much (sadly) was that the double-entry accounting style of coding was too laborious. permalink embed save report reply [–]Kevlar-700 1 point2 points3 points 26 days ago (2 children) I guess that you are referencing Spark as Ada isn't like that at all. It has actually been shown time and again to be more cost effective overall than C or Java. It is optimised for the reader however and you can spend time on type design but it is optional and beneficial. permalink embed save parent report reply [–]rseymour 0 points1 point2 points 26 days ago (1 child) I think you’re correct based on when I heard about this. Apparently contracts were added to Ada 2012. permalink embed save parent report reply [–]OneWingedShark 0 points1 point2 points 23 days ago (0 children) Apparently contracts were added to Ada 2012. This is correct, and IMO Ada's aspect-system does a superb job here. (I think it's the best system, precisely because it avoids the source/comment impedance-mismatch in the annotated-comment style, and [for SPARK] the system is opt-in at a fine grained level.) A trivial example: Package Example is -- An indefinite-length array of non-negative integers. Type Vector is Array(Positive range ) of Natural; -- A floating-point number, with non-numeric values eliminated. Subtype Real is Float range Float'Range; Difference_Delta : Constant Float; -- Returns true if the difference is within the above constant. Function \"-\"(Left, Right : Float) return Boolean; -- Sums the given object. Function \"+\"( Object : in Vector) return Natural; -- Returns the average of the given object. Function Avg( Object : in Vector) return Real with Pre => Object'Length /= 0, Post => Object'Length*Avg'Result - (+Object); -- NOTE: Using the user-defined \"-\" and \"+\". Private Difference_Delta : Constant Float:= 0.75; End Example; Package Body Example is Function \"-\"(Left, Right : Float) return Boolean is ( Abs(Left - Right) <= Difference_Delta); Function \"+\"( Object : in Vector) return Natural is Begin Return Result : Natural := 0 do For Value of Object loop Result:= @ + Value; End loop; End return; End \"+\"; Function Avg( Object : in Vector) return Real is ( Return (+Object) / Object'Length); End Example; permalink embed save parent report reply [–]AllowFreeSpeech 0 points1 point2 points 16 hours ago (0 children) It may also be worth noting that Idris is more structured than Rust. permalink embed save report reply about blog about advertising careers help site rules Reddit help center reddiquette mod guidelines contact us apps & tools Reddit for iPhone Reddit for Android mobile website <3 reddit premium Use of this site constitutes acceptance of our User Agreement and Privacy Policy. © 2023 reddit inc. All rights reserved. REDDIT and the ALIEN Logo are registered trademarks of reddit inc. π Rendered by PID 200169 on reddit-service-r2-loggedout-dbcc8b4b7-bdljh at 2023-12-03 10:02:34.031313+00:00 running a450159 country code: US.",
    "commentLink": "https://news.ycombinator.com/item?id=38498775",
    "commentBody": "Is Ada safer than Rust?Hacker NewspastloginIs Ada safer than Rust? (reddit.com) 159 points by ajdude 19 hours ago| hidepastfavorite102 comments docandrew 10 hours agoBoth of them are a lot safer than just about everything else, with each having their own strong areas. I think it’s fair to compare the SPARK subset of Ada with the “safe” subset of Rust.Rust has a great story with memory safety though it’s worth noting that SPARK is adding pointer ownership analysis (inspired heavily by the borrow checker, which really is a big deal). In practice, as others mentioned, heap allocation isn’t needed that much with Ada, and passing by reference without needing pointers is common using “in out”.Ada’s contracts and strong type system make it easier to design correct programs - is that “safer”? I don’t know. I wish _both_ languages were in wider use. I really enjoy Ada programming but envy the excitement and community being built around Rust. Hopefully Rust’s popularity leads to more enthusiasm for Ada and the unique correctness and safety advantages it brings.Maybe the next GNAT release will have a “Rust” FFI import mechanism (like it does now for C and Fortran) so Ada code can more easily take advantage of all the great Rust libraries being written. reply blub 2 hours agoparentThe “safety” Rust offers is just avoiding C and C++ specific memory access pitfalls, similar to pretty much any mainstream programming language except C and C++. It can also prevent data races, I’ll give it that.The novelty is doing the above at near C and C++ performance levels, not the protection offered.Rust is for the move fast and break things mainstream, where such “safety” is good enough.Ada and SPARK are for safety-critical systems. In other words, it’s playing in a different league. reply jph 17 hours agoprevIMHO preconditions and postconditions are a big win for Ada. I missed them in Rust, so wrote the Rust \"assertables\" crate, which provides runtime assert expressions for a bunch of typical cases such as comparing numbers, strings, lists, IO, etc.Rust code to assert a runtime precondition or postcondition a > b then handle it as you wish: assert_gt_as_result!(a, b) -> Resulthttps:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;assertables reply mostlylurks 13 hours agoparentPreconditions and postconditions seem like the wrong way to go about solving the issue they try to solve. They are essentially a secondary type system that tries to express information not expressed by the primary type system in a way that is awkwardly disconnected from the primary type system. You could instead just implement the functionality needed to incorporate that information into the primary type system. In practice this would result in an implementation of dependent types, which is fine. reply kaba0 12 hours agorootparent> implementation of dependent types, which is fine.Which you have to prove, which is absolutely non-trivial. I guess it could be made into a runtime check as well where static analysis is not possible, but that seems to be a quite hard to reason about language regarding performance. reply mycall 10 hours agorootparent.NET Code Contracts has both compile time and runtime checks, although it always felt like a bolted on solution even though it is baked into the framework. I guess this is why it didn&#x27;t carry forward into the .NET Core rewrite. reply HacklesRaised 12 hours agorootparentprevBetrand Meyer is coming for you... ;-)He&#x27;s not, he would respect your opinion, but design by contract was on of the key foundations of Eiffel, and I have a soft spot for Eiffel. reply throwawaymaths 11 hours agorootparentprevMaybe you don&#x27;t have to encode everything in the type system?Also: Maybe not everything goes in the compiler? reply nextaccountic 15 hours agoparentprevRust has thishttps:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;contracts reply nextaccountic 13 hours agorootparentAnd I can&#x27;t edit but, Rust can statically check contracts toohttps:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;17miqiu&#x2F;is_ada_safer_... reply kaba0 12 hours agorootparentprevIsn’t it its own language to a degree? Which may or may not be a bad thing in itself, but I do think there is value in having it natively available. reply GuB-42 16 hours agoparentprevI wish more languages supported that natively, starting with C and C++.The most typical example, in C, output arguments, passed by pointer, a pattern that I also use in C++ because I find passing by non-const reference error-prone since it is not obvious looking at the calling code that an argument may be modified.But what about NULL? Sometimes it is a good thing that NULL is allowed, sometimes, it doesn&#x27;t make sense. So again, not obvious. So what to we do? You can document it of course, but the problem is that compilers don&#x27;t read the docs, and therefore can&#x27;t tell you if you are doing it wrong. You can play it safe, and design your API so that NULL is always an option, and avoid NULL when using others APIs, but it leads to unnecessary and performance-impacting checks. Preconditions and postconditions would solve that problem: if you pass an argument that can be NULL to a function that doesn&#x27;t accept NULL, the compiler can warn you. Plus, there is optimization potential, in the same way that C&#x2F;C++ does with undefined behavior, but this is explicit. You also can also get the choice between safe (runtime checks) or fast (undefined behavior) at compile time.Making it a core feature of the language rather than an extension (like your rust crate) will help compilers and other tools to take full advantage of what it brings. reply summerlight 16 hours agorootparenthttps:&#x2F;&#x2F;www.open-std.org&#x2F;jtc1&#x2F;sc22&#x2F;wg21&#x2F;docs&#x2F;papers&#x2F;2023&#x2F;p29... C++ is preparing this for years, though it&#x27;s uncertain when it will actually land in C++. reply mhh__ 15 hours agorootparentprevD has contract programming e.g. `in(paramI find passing by non-const reference error-prone since it is not obvious looking at the calling code that an argument may be modified.VS code makes it pretty obvious by adding a visual & prefix to the argument. I hope that kind of visual help becomes widely adopted. reply adrianmonk 11 hours agoparentprevIt seems like there&#x27;s a very minor error under the \"Why use this?\" section: assert_gt!(value1, value2); &#x2F;&#x2F; value1 ≥ value2That should be \">\" rather than \"≥\". (Or \"assert_ge\" rather than \"assert_gt\".) reply mmoskal 17 hours agoparentprevThere is also anyhow::ensure!() (which is more of a requires() but anyhow...) reply saagarjha 17 hours agoparentprevWhy the specialized API, rather than (say) precondition(foo == bar)? reply jph 15 hours agorootparentMerely because the \"assert\" wording is more familiar to more Rust developers because it&#x27;s similar to typical test code, and can create better error messages with details.For what you&#x27;re asking, the assertables crate has a macro that will handle any condition: assert_as_result!(condition) -> ResultAnd you can alias it as you wish such as: use assertables::assert_as_result as precondition;And now you can write what you&#x27;re suggesting: precondition(a == b) reply masklinn 16 hours agorootparentprevProbably to get better error messages, same as assert_eq, otherwise you need a procedural macro to take appart the entire expression which is way more complicated and more expensive. reply skyde 16 hours agoparentprevC# used to have postconditions and verify them at compile time. But this has been deprecated :( I wish I knew why they removed it.https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;dotnet&#x2F;framework&#x2F;debug-tra... reply pjmlp 14 hours agorootparentIt was only available on enterprise versions, and most likely Microsoft has concluded not enough people were paying for it, nor they wanted to keep it for free, porting them into modern .NET runtime. reply BirAdam 13 hours agoprevI’ve used Ada. I’ve not used Rust beyond a few hello world type programs. Personally, I like Ada quite a bit, and I really do like Spark. But I think that Ada and Rust are aiming at similar problems in entirely different ways. One of the key design choices in Ada was to emphasize maintainability. Rust’s answer was to emphasize memory safety. While the Ada compiler does quite a few safety checks, these aren’t part of the spec so that will vary by compiler. I am not sure that direct comparisons between the two languages are entirely useful. Ada is used for things like cruise missiles and jets. Rust is used for things like browsers and reimplementing GNU. Both are important, but they aren’t exactly similar. reply 0x69420 15 hours agoprevada has some things that rust doesn&#x27;t. a lot of them (bounded numbers, pre&#x2F;post conditions) are really good but do not present a case for writing the category of program rust targets. nor the other way round, really.when the dust settles and hindley-milner types, rank-n types, substructural types, etc, all complete their respective journeys from \"weird thing the academics came up with\" to \"state of the art in hip new language that managed to compellingly package it\" to \"fact of life\", it is my hope that dependent types will follow suit -- something that bridges the ux gap between theorem prover and general-purpose language where anything from ownership and borrowing to refinement types lives under one HOL umbrella and lets you make just about any guarantee you like. i recommend anyone reading follows the f* project reply quag 14 hours agoparentFor the curious (as f* is hard to search for): https:&#x2F;&#x2F;fstar-lang.org&#x2F; reply zozbot234 14 hours agoparentprevDependent types are actually quite natural in the \"compile time evaluated\" subset of a programming language like Ada or Rust. For ordinary program code, they run into the obvious issue that dependent typing subverts the usual phase separation between compile and run time, in the absence of an ad-hoc \"code extraction\" step. Dependent types and contracts also promote \"code\" to what is effectively the typing level, which introduces thorny API-stability concerns - i.e. the exact way you express a pre&#x2F;post-condition or invariant in a library API becomes something that downstream users can end up relying on. Apart from that, Rust is already getting there with their advanced const-generics work. reply Buttons840 14 hours agoparentprevOne problem with dependant types is having to write the proofs, but perhaps AI can help with this. The type system can be the world the AI lives in, and we don&#x27;t have to check the proofs too closely, only know that they proved our high level assertions. reply kaba0 12 hours agorootparentI would definitely want a CI pipeline that randomly fails depending on what day ChatGPT has(Yeah, I know about temperature, but AIs are dumb as hell especially at logical inference stuff, so I just went with the comment in a satirical way) reply Buttons840 11 hours agorootparentYou misunderstand. When working with dependent typed languages sometimes you have to prove things. For example, my function might receive a sorted array, but it has to be proved that the array is sorted, otherwise this is a compile time error--remember, all of this is happening at compile time. So, you write the proof using code and check it in with the rest of your code. It&#x27;s not something that&#x27;s going to fail randomly, it&#x27;s just code.If AI wrote the proof, this would be no different than having Copilot fill in some code, it&#x27;s just code you check into the repo.These proofs often involve writing code, any code, that will pass the type checker. If you can write code, no matter what that code is, and it passes the type checker, the assertion is proved. It&#x27;s such a well structured problem, \"just write code that satisfies these type constraints, any code will do, as long as it type checks\", that I think AI might be able to do it quite well.I&#x27;ve commented on this before and it wasn&#x27;t well received then either. I think most people have never coded in dependently type language and don&#x27;t appreciate how often you simply want to fill in the holes and connect the dots with any code that type checks. It&#x27;s been several years since I experimented with dependent types, so I forgot a lot of the details, but I do remember often wanting to just \"fill in the gaps\", and indeed, there are IDE tools that can often fill in the gaps for you.(Another thing I was surprised to realize about languages with strong type systems is how often there is literally only one possible implementation of a function.) reply kaba0 11 hours agorootparentI have seen demos of Idris where just the type signature itself allows for automatic function implementation, which is very cool and almost magical.And you are probably right that many of the trivial cases can perhaps be guessed by some AI — but I think in these cases a simple, more deterministic algorithm could also find a match, iterating through a few proving strategies (I believe this is how the aforementioned idris demo worked). What might have resulted in your downvote (I didn’t downvote your comment, I think it adds to the discussion!) is that many people are tired of the over-hype of LLMs, and taken your comment blindly as support of that.With that said, I do think that you overestimate the capabilities of LLMs, as my go to example: they can’t solve even Sudokus. And any other similar, “recursive” thought is simply fundamentally impossible by LLMs in a single step.It is also the barrier in the popularity of dependently types languages - it is easy to give a proof of List::head. Database::connect on the other hand goes through multiple layers of the whole stack, and function proofs do not compose — two trivial to prove functions composition might be impossible to prove, e.g. I can compose 2 such functions and get some unsolved math problem of your choice. reply Buttons840 10 hours agorootparentLLMs can&#x27;t solve Sudoku, but neural networks plus tree search can solve Go. As you say, traditional techniques, like a simple tree search can already solve a lot of the \"holes\" that come up in dependent languages. Perhaps something like AlphaGo combined with a LLM (to accept human guidance using language) could work? reply fragmede 10 hours agorootparent> LLMs can&#x27;t solve SudokuSeems like ChatGPT-4 can? And that&#x27;s not the advanced data analysis model, either.https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;3126e737-3ae5-4f63-996b-b5a768... reply Buttons840 5 hours agorootparentI was curious. I generated a very hard Sudoku puzzle and gave it to GPT4, which proceeded to write and execute a Python program to find the solution. reply kaba0 2 hours agorootparentWhich is not the same as it solving it, as there are a million sudoku solvers in its training set. replywoodruffw 17 hours agoprevI’m glad that domain-limited integer types are called out: I wish more languages had that.At the same time: there’s a reasonable practical argument that both have essentially safe semantics, and that “safer” one is really just the more successful (easier to integrate into existing codebases, more online resources, &c.) one. Rust is (thus far) winning at that. reply okl 15 hours agoparentThat feature really helps when you use integers for indexing, e.g., like an enum. Say you are parsing a file format with a type field which can have values 5, 6, 7, you can easily check if that&#x27;s valid with a single call and lookup something, like a corresponding length in an array without having to translate those field values to array indices first. reply woodruffw 15 hours agorootparentYep, although Rust manages to get there just fine with sum types and fallible conversion traits. reply Animats 14 hours agoprevIf you don&#x27;t use the heap, which is common in real-time control, Ada has real advantages. That&#x27;s what Ada is for, after all. reply fuzztester 14 hours agoprevEiffel had design by contract from way back.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Eiffel_(programming_language...https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Design_by_contractUnfortunately it suffered from some of the same issues as Ada:For a long time, only expensive implementations available, and a somewhat verbose syntax. reply ajxs 12 hours agoprevThe proof of the pudding is in the tasting. I can&#x27;t find any evidence online that anyone has ever used Rust in software where its correctness needs to be certified, and audited with something like DO-178C. I think that settles the debate. Maybe Rust could be as safe as Ada, once the Rust type system has been proven, and there&#x27;s a verified compiler. Those things haven&#x27;t happened yet though, so it&#x27;s not likely to be used in a safety-critical environment anytime soon. Ada has been used in this area for decades. reply Faaak 12 hours agoparentYou might be interested in https:&#x2F;&#x2F;ferrous-systems.com&#x2F;ferrocene&#x2F;, which \" is a ISO 26262 (ASIL D) and IEC 61508 (SIL 4) qualified version of the existing open-source compiler, rustc, based on Rust 1.68.\" reply jeffreygoesto 12 hours agorootparentYou were one minute faster :). Golf clap. reply jeffreygoesto 12 hours agoparentprevIt is just a matter of time and one important step has been achieved recently.https:&#x2F;&#x2F;ferrous-systems.com&#x2F;blog&#x2F;officially-qualified-ferroc... reply ajxs 11 hours agorootparentOh, pardon me. I didn&#x27;t realise Rust had a qualified compiler already. It looks like this is what Ferrous Systems was working on with AdaCore. reply cpeterso 10 hours agoprevDo any languages besides Ada use an identifier naming convention that merges PascalCase and snake_case like Ada_Identifier_Name? Popular languages like Python, Ruby, and Rust already mix both PascalCase and snake_case (for class and function names, respectively), so consistency isn’t the reason.This naming convention avoids acronym capitalization ambiguities and reads more like natural written language. For example, instead of normalizing the inconsistently-capitalized identifier XMLHttpRequest as XMLHTTPRequest, XmlHttpRequest, or xml_http_request, you would use XML_HTTP_Request. reply inamberclad 4 hours agoparentI like it quite a lot while reading, but it&#x27;s a holy hell to keep reaching between shift and underscore. Besides, what do you call an iterator variable? I? i? Idx? Index? Iterator_Index? reply cpeterso 4 hours agorootparentMap shift + space to underscore?In my .vimrc, I mapped space to ; to enter VIM command mode: noremap: reply armchairhacker 10 hours agoprevThere&#x27;s a solid argument that memory-managed languages like Java are safer than Rust, because although your program can crash, it can&#x27;t segfault unless you&#x27;re doing something especially weird. Safe Rust programs can also crash via `panic!`, and unsafe Rust programs can segfault and create wonky UB just like C programs if the safety invariants aren&#x27;t manually enforced.The safest language would be something like Elm or Datalog, where the type system ensures crashes aren&#x27;t even possible. But then you just make up your own idea of failure, where instead of crashing the program produces unexpected output, almost like UB. reply pornel 9 hours agoparentRust&#x27;s panic is technically very similar to a Java exception. It does not lead to any unsafety. It throws before executing anything that would be unsafe.Safe Rust can&#x27;t segfault, unless you&#x27;re using unsafe code that is buggy, which isn&#x27;t that much different from using buggy JNI.Beyond just memory safety, Rust has a stronger type system than Java — tracks mutability, ownership, and thread safety that Java doesn&#x27;t. reply dezgeg 10 hours agoparentprevCan&#x27;t you segfault in Java via stuff in sun.misc.Unsafe? reply rurban 12 hours agoprevEasy to compare:Search the gnat bug tracker for stack overflow: 14 bugs https:&#x2F;&#x2F;gcc.gnu.org&#x2F;bugzilla&#x2F;buglist.cgi?quicksearch=Ada%20s...Rust: 243 (plus 830 closed) https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;issues?q=is%3Aissue+is%3Ao...Choose by yourself which seems safer reply Smaug123 12 hours agoparentCertainly a compelling demonstration that Rust is much more popular than Ada. reply kaba0 12 hours agoparentprevSo I guess the safety belt is also much more dangerous than not having it, as more people have accidents with seatbelts on? Similarly faulty logic. reply xcdzvyn 3 hours agoparentprevWell I&#x27;ve never blown through the stack in Assembly. reply peppermint_gum 17 hours agoprevI noticed that many people praising Ada on the internet don&#x27;t actually know the language.It&#x27;s odd. Why advocate for a language you don&#x27;t use?Here are some common giveaways:- \"Ada has a garbage collector\" - It&#x27;s optional part of the specification, in practice most compilers don&#x27;t implement it.- Confusing SPARK (the formal verifier) with Ada, or even claiming that SPARK is now part of the Ada spec. This is simply not true.- Not knowing that contracts are enforced at runtime and they&#x27;re typically disabled in release builds.- Claiming that Ada is memory safe. Ada doesn&#x27;t have a borrow checker. Ada doesn&#x27;t have smart pointers out of the box (unique_ptr is actually unimplementable due to lack of move semantics). Typical non-embedded codebase is full of \"new\" and \"Unchecked_Deallocation\", usually wrapped with controlled types, much like C++ RAII. reply eggy 16 hours agoparent>>Ada doesn&#x27;t have smart pointers out of the boxI am a novice-intermediate Ada user (and I started with SPARK before moving to just Ada), but a lot of the arguments in favor of Rust mention that \"there is a crate for that\". I would say you need to compare vanilla Rust \"out-of-the-box\" with Ada for a fair comparison.Another reason I prefer Ada is because I find it boringly simple like Pascal even though it is verbose, whereas I find Rust very obtuse, and I have a personal bias for array languages and ML languages. I wish Rust were more F#-like. reply codys 15 hours agorootparentFor the case of \"smart pointers\", and the larger point of \"safety\": rust has that included out of the box: Box, Rc, Arc, RefCell are all smart pointers included in the standard library. On safety of the language: the borrow checker exists, move semantics are the default (ie: included in the language) and copy is explicit, and real programs that isolate unsafety effectively (ie: so it doesn&#x27;t need to be known outside of the module it exists in) are common. reply kaba0 12 hours agorootparentBasically unique_ptr is the default in Rust. I also like to say that Rust is “just” the compile-time enforcement of C++’s smart pointers, which is technically not 100% correct, but gives a good mental image for the uninitiated, I guess. reply codys 8 hours agorootparentprevedit: actually not RefCell. That&#x27;s more Mutex like. Which is another place rust solves: the tooling for eliminating data races at compile time is mature and pretty complete. The race elimination in Ada appears to rely on using SPARK (as noted elsewhere: not universally used from others experiences), but I&#x27;m not too familiar, possible I&#x27;m wrong there. reply masklinn 15 hours agorootparentprev> but a lot of the arguments in favor of Rust mention that \"there is a crate for that\". I would say you need to compare vanilla Rust \"out-of-the-box\" with Ada for a fair comparison.Smart pointers are vanilla rust shrug.But also, it&#x27;s pretty fair to mention the availability of crates, because they&#x27;re easy to integrate, liberally used by the project itself (go browse https:&#x2F;&#x2F;github.com&#x2F;rust-lang and you&#x27;ll see a number of projects for libraries distributed as crates rather than part of the stdlib), and there&#x27;s a large breadth of available packages.The internet tells me Alire is a (the?) package manager for Ada, its listing has 373 entries right now (https:&#x2F;&#x2F;alire.ada.dev&#x2F;crates.html).Simple odds say you&#x27;re more likely to find a crate for that than an ada package. reply worik 13 hours agorootparent> But also, it&#x27;s pretty fair to mention the availability of crates, because they&#x27;re easy to integrate, liberally used by the project itselfYesThis is a strength and a weakness in RustThe crate ecosystem is broad an deep. It is seemless to integrate crates if you are connected to the internet. That is a strengthBut it is also a weaknesses. \"seemless to integrate crates if you are connected to the internet\" but of unknown provenance and varying quality.There are steps you can take, tools you can use to ameliorate the issue, but it is a real dangerIt depends what you are working on. For systems which must be secure and reliable -weapons, flight control, banking, maybe Ada is a better choiceFor me I make musical instruments, and I will stick with Rust for thatI know Rust, not Ada. A very interesting discussion for me to reply ksec 3 hours agoparentprev>I noticed that many people praising Ada on the internetNot seen that anywhere, on Reddit or HN. I mean Ada is rarely even mentioned. On HN, Ada sometimes is hated by many. And this is speaking as someone who gets all the fingers for bringing up Ada whenever someone said Rust is the only PL for safety critical applications.I am actually rather surprised this Submission gets some many people commenting.And to be honest I think most of those point aren&#x27;t because they dont know the language, it seems to be more like lacking in context. ( Which is often the case in any online discussions ) reply galangalalgol 16 hours agoparentprevYour last point is the largest thing I noticed in the one large codebase I looked at. Ada with a borrowchecker and linear types (aka austral) would be great. Rooting for austral, though I actually prefer obtuse dense syntax to verbose simple syntax. Not sure why. I think I may have a mental cache size related to the number of characters on a screen vs the number of tokens. reply tikhonj 15 hours agorootparentI figure the preference in syntax is a trade-off between how hard it is to learn and how hard it is to read day-to-day.More regular and verbose syntax is easier to learn, but requires more actual reading when you use it.More concise but complex syntax takes longer to internalize, but then you can see more at a glance, so it lets you do more visual pattern matching and puts less strain on working memory. reply zozbot234 14 hours agoparentprevC++03 had no move semantics either, it got added in a later version of the standard. Controlled types&#x2F;RAII is also the basic building blocks of smart pointers, and it&#x27;s quite normal that they be implemented with unsafe code under the hood. reply comonoid 16 hours agoparentprevA garbage collector was also part of C++ spec from C++11 to C++23. reply skyde 15 hours agoparentprevWell when people say \"Ada\" they usually mean SPARK not old or feature limited version of Ada.-Spark do verify contract using static analysis and proof. -While Ada is not as memory safe as Rust it&#x27;s a lot more memory safe than popular languages. -Its one of the easiest languages to get compliance with safety standard DO-178C or DO-333 ... reply pcwalton 15 hours agorootparent> -While Ada is not as memory safe as Rust it&#x27;s a lot more memory safe than popular languagesPopular languages typically have garbage collectors and are memory safe. If a language is not memory safe, like Ada, then it&#x27;s automatically one of the least memory safe languages, measured by amount of use. reply worik 13 hours agorootparent> Popular languages typically have garbage collectors and are memory safe. IYesAnd those languages are unsuitable for real time systemsWhere Rust, and it seems Ada, excell reply kaba0 12 hours agorootparentFor hard real-time normal Rust (and I guess also Ada) is insufficient. This is such a niche of a sub-niche, that you no longer write the same language as for everything else, most OSs already preclude hard real-time by their very existence, etc.Soft real-time is absolutely doable with a GC, depending on the required targets. Java’s low-lat GC (ZGC) hasFor hard real-time normal Rust (and I guess also Ada) is insufficientReally? Expand on that please. I did not think so> Soft real-time is absolutely doable with a GCSome slippery definitions here. Clearly there is a middle ground (where I live) where rust works. GC languages do notOne GC pause, ever, is too many reply kaba0 11 hours agorootparentYou have 1ms pauses easily from simply the OS context-switching away from your program, so as I mentioned, unless you explicitly tune your OS, you have this kind of pauses, no matter the language, even if it’s hand-written assembly.Regarding the non-normal language: with hard real-time you wouldn’t want to allocate willy-nilly and rust doesn’t yet have generics for allocators (correct me if I’m wrong on this, I am not up-to-date here), so careless usage of the standard lib, or other crates is a no-go. For illustrative purposes, this is the same with C++ and `noexcept`.> Some slippery definitions hereI don’t see the slippery part - it is a slope, though. Depending on what’s the latency requirements and to what percentile should it happen, you can use Rust (and other low-level languages) on the lower end (audio processing), some managed languages in the middle (many kind of games are absolutely fine with that - a single drop of frame is more than fine, hence the soft rt), and pretty much any managed language on the high end. reply hollerith 10 hours agorootparent>You have 1ms pauses easily from simply the OS context-switchingIt is routine for Rust code to run without an OS (e.g., on microcontrollers). reply kaba0 2 hours agorootparentA subset of Rust. You can’t just write ordinary Rust for microcontrollers. replyokl 15 hours agorootparentprev> Well when people say \"Ada\" they usually mean SPARK not old or feature limited version of Ada.Having worked on several Ada projects professionally I can tell you that this is definitely not true.DO-178C applies to the process and does not make assumptions about programming languages. reply frank_bb 17 hours agoprevAda is awesome! One of the greatest languages. Should be much more popular. reply pjmlp 17 hours agoparentSadly it suffered from high prices, and being extra tooling even on UNIX SDKs, until GNAT came to be.Still, not all languages can assert having 7 commercial vendors in business, lasting 40 years and counting. reply fulafel 15 hours agorootparentIn case others were curious to look up the timeline, WP says first validated GNAT release was in 1995, vs 1983 for the earliest validated implementation.(but perhaps the earlier stuff wasn&#x27;t practical: \"Early Ada compilers struggled to implement the large, complex language, and both compile-time and run-time performance tended to be slow and tools primitive\" ... \"By the late 1980s and early 1990s, Ada compilers had improved in performance\") reply pjmlp 14 hours agorootparentAnother issue that delayed adoption in regards to GNAT specially was the licence, somehow debatable, similarly to what happened with Qt, or Java implementations. reply jjgreen 15 hours agoparentprevPretty much any job using it will require security clearance ... reply CyberDildonics 14 hours agoparentprevThis is your first comment in 11 months and 1 of only 4 over 10 years. What is great about it? What do you like? reply zogrodea 10 hours agorootparentIt might be because I have \"showdead\" enabled but I see that there are many frequent comments from this user when clicking their page. Every comment I see from them seems to be flagged&#x2F;dead though... reply onetimeuse92304 15 hours agoprevnext [10 more] [flagged] PhilipRoman 14 hours agoparentThere is a lot of value in constraining what the programmer can do. It&#x27;s not always about getting to minimum viable product as fast as possible, in some fields you actually need to care about reliability and security. We keep finding security vulnerabilities in \"battle tested\" foundational software - it would be great if we could stop, or at least severely reduce that some day.The state of software today is more like having several layers of swiss cheese and hoping that the holes don&#x27;t happen to match anywhere. reply euW3EeBe 15 hours agoparentprev> I roll my eyes every time I hear about yet another programming language for which the biggest invention is that it does not allow null pointers.> It is even worse when a programming language manages to solve an easily preventable problem by creating additional workload on the programmer.What programming languages are you referring to here? Both Rust and Ada do more than disallow nulls, and help solve some non-trivial problems. Of course at the expense of additional constraints, but that&#x27;s probably unavoidable. reply youerbt 14 hours agoparentprev> Programming languages are tools to get shit done.I, on the other hand, find it baffling that some programmers, despite the fact that programmers generally make computers useful for other people, don&#x27;t care how computers can be more useful for them.Those guys in the \"square wheels comic\"[0] are also getting shit done.[0] easy to google reply Kamq 12 hours agorootparent> don&#x27;t care how computers can be more useful for themMy guess is that the OP doesn&#x27;t see this as a computer being more useful for them, but instead sees it as being less useful as it requires more work to get the same result.And if you&#x27;re in a domain where crashes aren&#x27;t necessarily a problem, or where security isn&#x27;t a top priority (non-public facing tools often fall into this category), correctness (in the general case) and safety don&#x27;t automatically map to utility. reply orangetuba 14 hours agoparentprevI always wondered why you brilliant people who \"get Lisp\" never actually released anything written in Lisp. reply tmtvl 12 hours agorootparentRight, and those C programmers talk big but there&#x27;s no software written in C, where do they get off?...I really don&#x27;t understand this comment, there&#x27;s so much Lisp code out there being used for everything from airfare search to video games, it seems willfully ignorant to say nothing is released in Lisp. I know, lucky 10,000, but still... reply Capricorn2481 9 hours agorootparentNo there really isn&#x27;t. Naughty dog used it 30 years ago, but lisp is not used in gaming reply Jtsummers 13 hours agorootparentprevNo one pays me to. reply jjgreen 15 hours agoparentprevWell in theory, honestly, we hacked most of it together with Perl. reply oglop 12 hours agoprevnext [2 more] [flagged] rowanG077 11 hours agoparentI mean there are few languages as safe as Haskell. Idris maybe even safer. Depending on what \"safe\" means for you. reply charcircuit 17 hours agoprev [–] Having a more expressive type systems does not make a language automatically safer. reply IshKebab 15 hours agoparent [–] In the same way that thicker armour isn&#x27;t necessarily safer. reply charcircuit 14 hours agorootparent [–] No, it is more like having the tools that can technically create better armor does not neccessarily mean you will on average create better armor than someone with tools less capable. reply IshKebab 11 hours agorootparent [–] Ok but when people say \"is Ada safer than Rust\" they obviously mean when both languages are used by competent people who are familiar with the language. So no, it is not like that. reply charcircuit 10 hours agorootparent [–] Even competent people make mistakes and not everyone working on the project will be competent in everything. reply IshKebab 2 hours agorootparent [–] That&#x27;s exactly what \"safer\" means in this context.A safer language is one in which the probability of a competent person making a mistake (that makes it into production) is lower. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Reddit post in the Rust programming language subreddit outlines the rules and guidelines for posting, along with a discussion on the differences between Ada and Rust.",
      "The post seeks insights from individuals with knowledge in both programming languages, focusing on topics like memory management, safety features, performance, and adoption rates of Ada in different industries.",
      "The comments and discussion shed light on the strengths, limitations, and future prospects of both Ada and Rust as programming languages."
    ],
    "commentSummary": [
      "The Reddit discussion delves into the safety, features, and applications of programming languages such as Ada and Rust.",
      "Ada is praised for its strong type system and contracts, while Rust is lauded for its focus on avoiding memory access errors.",
      "Topics explored include dependent types, integrating Rust libraries with Ada, AI assistance in proof writing, language models, and the use of smart pointers in Rust.",
      "The limitations and suitability of different languages for safety-critical and real-time applications are thoroughly examined.",
      "The discussion provides contrasting opinions on the effectiveness and usefulness of various programming languages."
    ],
    "points": 159,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1701526954
  },
  {
    "id": 38500065,
    "title": "Fiber optic cables 'hear' loud cicadas, offer new insect monitoring method",
    "originLink": "https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/",
    "originBody": "MATT SIMON SCIENCENOV 30, 2023 10:00 AM Cicadas Are So Loud, Fiber Optic Cables Can ‘Hear’ Them In 2021, scientists experimenting with fiber optics picked up a strange signal: the cacophony of cicadas. It could lead to a new way of monitoring insects. PHOTOGRAPH: AIMEE DILGER/GETTY IMAGES One of the world’s most peculiar test beds stretches above Princeton, New Jersey. It’s a fiber optic cable strung between three utility poles that then runs underground before feeding into an “interrogator.” This device fires a laser through the cable and analyzes the light that bounces back. It can pick up tiny perturbations in that light caused by seismic activity or even loud sounds, like from a passing ambulance. It’s a newfangled technique known as distributed acoustic sensing, or DAS. Content To honor your privacy preferences, this content can only be viewed on the site it originates from. Because DAS can track seismicity, other scientists are increasingly using it to monitor earthquakes and volcanic activity. (A buried system is so sensitive, in fact, that it can detect people walking and driving above.) But the scientists in Princeton just stumbled upon a rather … noisier use of the technology. In the spring of 2021, Sarper Ozharar—a physicist at NEC Laboratories, which operates the Princeton test bed—noticed a strange signal in the DAS data. “We realized there were some weird things happening,” says Ozharar. “Something that shouldn’t be there. There was a distinct frequency buzzing everywhere.” The team suspected the “something” wasn’t a rumbling volcano—not in New Jersey—but the cacophony of the giant swarm of cicadas that had just emerged from underground, a population known as Brood X. A colleague suggested reaching out to Jessica Ware, an entomologist and cicada expert at the American Museum of Natural History, to confirm it. “I had been observing the cicadas and had gone around Princeton because we were collecting them for biological samples,” says Ware. “So when Sarper and the team showed that you could actually hear the volume of the cicadas, and it kind of matched their patterns, I was really excited.” Add insects to the quickly growing list of things DAS can spy on. Thanks to some specialized anatomy, cicadas are the loudest insects on the planet, but all sorts of other six-legged species make a lot of noise, like crickets and grasshoppers. With fiber optic cables, entomologists might have stumbled upon a powerful new way to cheaply and constantly listen in on species—from afar. “Part of the challenge that we face in a time when there’s insect decline is that we still need to collect data about what population sizes are, and what insects are where,” says Ware. “Once we are able to familiarize ourselves with what’s possible with this type of remote sensing, I think we can be really creative.” DAS is all about vibrations, whether they be the sounds of a singing brood of cicadas or the shifting of a geologic fault. Fiber optic cables transmit information, like high-speed internet, by firing pulses of light. Scientists can use an interrogator device to shine a laser down a cable and then analyze the tiny amounts of light that bounce back to the source. Because the speed of light is a known constant, they can pinpoint where along the cable a given disturbance happens: If something jostles the cable 100 feet down, the light will take slightly longer to return to the interrogator than something that happens at 50 feet. “Every 1 meter of fiber, more or less, we can turn it into a kind of microphone,” says Ozharar. MOST POPULAR SCIENCE How to Set Your Thermostat—According to Science CHRIS BARANIUK GEAR Coffee Lovers, It’s Time to Stop Using K-Cups MICHAEL CALORE SECURITY It's Time to Log Off THOR BENSON SECURITY Google Fixes a Seventh Zero-Day Flaw in Chrome—Update Now KATE O'FLAHERTY COURTESY OF JOURNAL OF INSECT SCIENCE/ENTOMOLOGICAL SOCIETY OF AMERICA Ozharar’s team focused on a loop of the cable atop one of the utility poles, which you can see in the photo above. (The loop is highlighted in red.) “If the fiber is in a linear shape, a sound interacts with the fiber just once and then keeps traveling,” says Ozharar. “But if you have a coil, the same signal travels multiple times through the fiber.” That makes the system much more sensitive, like recording a concert with multiple microphones, instead of one fan in the crowd bootlegging it with their smartphone. When Brood X emerged in the spring of 2021, Ozharar’s DAS system was accidentally listening in. This kind of “periodical cicada” develops underground and emerges every 13 or 17 years to mate, depending on the species. “Because of perhaps climate change—although we’re not exactly sure the reason—there have been stragglers, so populations that have come out early and populations that have come out later than what they’re metabolically timed to do,” says Ware. “Having a way to over time monitor those can be really helpful.” Male cicadas have an organ, called the tymbal, that vibrates like a drum to produce that unmistakable song. Each species has its own variation on the song, allowing the right males and females to find each other. There’s extra information embedded in that sound, too: Males tend to call during the hottest time of day, which is energetically expensive. That allows females to assess the quality of their mates—they want to choose the fittest males so they can pass primo genes to their offspring. MOST POPULAR SCIENCE How to Set Your Thermostat—According to Science CHRIS BARANIUK GEAR Coffee Lovers, It’s Time to Stop Using K-Cups MICHAEL CALORE SECURITY It's Time to Log Off THOR BENSON SECURITY Google Fixes a Seventh Zero-Day Flaw in Chrome—Update Now KATE O'FLAHERTY Hence all the noise. DAS can listen from the very beginning of the emergence through the peak and into the decline as the mass mating ritual wanes. The volume of noise is a solid indicator of the number of cicadas, so entomologists can work out the population size of the brood. They can even see the effect of temperature: When it’s hotter, it’s more difficult for the male cicadas to sing. “You can see that as you go across the five days from which we have monitoring data, that when it’s slightly colder temperatures they have slightly different frequencies in hertz of the calling,” says Ware. Dead and dying cicadas from Brood X in Columbia, Maryland. PHOTOGRAPH: CHIP SOMODEVILLA/GETTY IMAGES Fiber optic cables are already all over the place, just waiting for scientists to tap into them. They are abundant in cities, of course, but they also run between them, which would be handy for entomologists who want to monitor insects in more rural areas. “We use them just to transmit the data—zeros and ones—but we can do much more,” says Ozharar. “That’s why fiber sensing will become more and more important, and more widely used, in the near future.” MOST POPULAR SCIENCE How to Set Your Thermostat—According to Science CHRIS BARANIUK GEAR Coffee Lovers, It’s Time to Stop Using K-Cups MICHAEL CALORE SECURITY It's Time to Log Off THOR BENSON SECURITY Google Fixes a Seventh Zero-Day Flaw in Chrome—Update Now KATE O'FLAHERTY Not that anyone’s suggesting DAS will replace other ways of monitoring insects—fiber optics are widespread, but they’re not everywhere. Instead, DAS could complement other techniques. A field called bioacoustics already uses microphones to listen for species in remote areas, sometimes assisted by AI to parse the data. This method could help confirm the data coming from the fiber optics. Scientists are also experimenting with “environmental DNA,” or eDNA, for instance using air quality stations to gather the biological material floating in a given area. And entomologists like Ware still need to collect specimens from the field to physically examine the health of individual animals. “What seems really cool about this new technology is that you have this single cable that can cover potentially many kilometers, and all of the information is getting recorded by a single device,” says Elliott Smeds, an entomologist and research associate at the California Academy of Sciences, who wasn’t involved in the research. “Especially now that insects are declining, we’re realizing that we don’t even know what the baseline is for a lot of these species, to keep track of how they’re doing. The biggest obstacle is having enough boots on the ground to be collecting this kind of data.” The trick will be adapting DAS to monitor species that aren’t the loudest insects on Earth. “In this case, it was very clear these were cicadas, because there were—without exaggeration—millions of them that suddenly descended,” says Ware. “But in most cases, the populations are much smaller for each species. Knowing whether or not we can actually distinguish among insects will be an interesting question.”",
    "commentLink": "https://news.ycombinator.com/item?id=38500065",
    "commentBody": "Cicadas are so loud, fiber optic cables can ‘hear’ themHacker NewspastloginCicadas are so loud, fiber optic cables can ‘hear’ them (wired.com) 156 points by nixass 10 hours ago| hidepastfavorite58 comments hristov 8 hours agoFiber cable can actually be a very good sensor. Some light gets reflected back from the most minute bends of the cable. By sensing reflections and comparing them with previous reflections you can see whether the cable has experienced any new bends. By timing the arrival of reflections you can calculate exactly where the new bends are. By sensing the intensity of reflections you can calculate how sharp the bend is.And this is not a research project anymore. Well, the fiber the article talks about is a research project, but there is a company called luna innovations that sells production fiber sensors that operate in commercial environments. There are underground fibers that sense whether someone steps in a restricted area. There are fibers stuck to pipelines that sense whether someone is trying to drill a hole in the pipeline to steal some oil (or any other vibrations or ruptures). There are fibers glued to the undersides of bridges that sense whether the bridge vibrates and bends too much.It is a very useful sensor, because you can essentially get sensing along a large area without paying for multiple sensors and trying to figure out how you are going to power them, how they are going to communicate back, etc.The electronics for extracting data from the fiber are complex but they do not have to be out in the wild in the area being sensed, they can be safely housed at one end of the fiber. reply isaacdl 8 hours agoparentI’ve had a fiber line for residential internet buried in my yard. At one point it stopped working and a tech was able to pinpoint the exact location that it had a slight kink using a device that measured the reflection. They just dug up that section with hand tools to unkink it. reply mlyle 7 hours agorootparentYup-- an optical time domain reflectometer.Though TDRs are in common use for copper cable, too. You send the pulse down the line and get a reflection back. They&#x27;re a little worse than optical ones because there&#x27;s more uncertainty of the speed pulses travel down a random network cable than a piece of optical fiber. reply I_Am_Nous 7 hours agorootparentThey make some really cool in-line OTDRs these days, but the one we use was about $10k I believe and it&#x27;s had a broken screen for years. Still works if you plug a mouse in! reply hunter2_ 5 hours agorootparentprevDoes varying twist rate contribute to that uncertainty? I imagine that a cable with a high twist rate is slower because the twist means the individual conductors are longer (maybe just by a couple percent) than one with a lower twist rate. And if the test equipment isn&#x27;t configured for the pinout scheme being used (A vs B) then it might not even be pulsing a single pair at a time (each pair has a different twist rate) although perhaps that issue is automatically avoided. reply mlyle 4 hours agorootparent> Does varying twist rate contribute to that uncertainty?Yes, but beyond the effect that you&#x27;re saying. The distance between conductors affects speed down the cable. Tighter twisting also changes the distance and the amount of dielectric around, which also varies speed of propagation.These effects can be massive; a typical cat 7 cable has a velocity factor of 80% of the speed of light, varying by a couple of percent; a cat 5e cable more is often more like 65%. If you launch a pulse into a mess of mixed wiring to find out where something is unplugged or cut, you could be off by 20% or more. replyaaviator42 16 minutes agoparentprevIt&#x27;s insane how cool humans are to be coming up with this insane stuff. reply closeparen 7 hours agoparentprevI worked for a local IT contractor in a small Midwestern city 10 years ago. We had a handheld Fluke TDR device in the truck, for locating fiber breaks. reply thrtythreeforty 5 hours agorootparentI wouldn&#x27;t be surprised if the Fluke cost as much as the truck. reply jes 5 hours agorootparent\"If you drop your DVM and it still works, it&#x27;s a Fluke.\" reply thsksbd 7 hours agoparentprevA professor I knew would measure temperature and gas species along the entire length of a fiber at refractory temperatures.Fibers are incredibly accurate devices reply nimish 6 hours agorootparentAll of modern technology owes its origin to measuring light precisely. Optics is an ancient science. It&#x27;s quite low tech, surprisingly so. reply acidburnNSA 5 hours agoparentprevWe use similar sensors in test flow loops to see how prototype electrically heated nuclear fuel rods jiggle. reply andrewstuart 4 hours agoprevThe cicadas can&#x27;t be heard any more where I live.When I was a kid they were so loud your ears buzzed.It makes me very sad that we have ruined the eden that was the earth. reply jjeaff 1 hour agoparentWhile you usually will hear a few cicadas every summer, they are all normally on a 13 or 17 year cycle. You may simply live in an area that is in the middle of a cycle. when that 13 or 17 year mark hits, you will likely hear them everywhere again. You can look up the \"brood\" cycle for your area online. reply lukas099 4 hours agoparentprevWe haven’t completely ruined it. Build native habitat in your yard, be vocal about your concerns, donate to land preservation and get involved in your local politics and you can make a huge difference. reply Mtinie 4 hours agoparentprevYou are welcome to join us in Northern Virginia in the summer if you’d like to experience the halcyon days of cicadas you remember.On the plus side, they compete with my tinnitus and make it far less noticeable. reply brightlancer 3 hours agorootparentI heard them once in a Maryland suburb of DC: there were so many that it was just a constant whine in the background, unlike what I&#x27;ve heard elsewhere.Thankfully I was just passing through or it would&#x27;ve given me a headache. reply weregiraffe 4 hours agoparentprev>It makes me very sad that we have ruined the eden that was the earth.Are you the Platitude Man? I think I just died of cringe. reply latentcall 4 hours agoparentprevYes but we get a new iPhone every year! The Internet can write poems for us! We have electric cars! Who needs God’s green Earth when we can have…stuff! &#x2F;s reply brnt 1 hour agorootparentIn so many parts of the world that part of Cyberpunk is already true: _everything_ is human made, even the plants and animals are purpose bred. You can live a life where the only natural thing you ever see is the grass between street pavement. reply inasio 3 hours agoprevNo kidding about cicadas being loud. We were in the south of France earlier this year and it&#x27;s incredible how much of the soundscape is dominated by the cicadas. I have no idea if it was just a couple or a couple billion, but it seemed to just come from everywhere above us reply ctoth 9 hours agoprevWonder what else you could use this sensing capability for ...It sounds like you can turn any arbitrary underground fiber into a microphone with a certain sensitivity. reply ccakes 8 hours agoparentFibreSense have commercialised hardware and software that does just this in an insane amount of detail, it’s very coolhttps:&#x2F;&#x2F;fibersense.com&#x2F;Not affiliated, just a fan reply foobarbecue 9 hours agoparentprevYes, you can. This was first used by the Navy to record &#x2F; detect submarines, many decades ago.You can also use the cable for distributed temperature sensing (some of my research used this). reply RowanH 5 hours agoparentprevI was listening to a YouTube ( I think it was 60 minutes of all things ) where volcanologists are burying them deep down in icelandic volcanoes to help detect when volcanoes might blow. Sensing the underground magma movement.. reply _kb 6 hours agoparentprevThere’s a network under Melbourne [0] that’s in use for research what’s possible for city scale sensing. Seems to be an option for seismology, traffic, rainfall, drainage etc.[0]: https:&#x2F;&#x2F;www.rmit.edu.au&#x2F;research&#x2F;centres-collaborations&#x2F;mult.... reply aidenn0 9 hours agoparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Microphone#Fiber-optic reply imposterr 8 hours agoparentprevLots! https:&#x2F;&#x2F;lunainc.com&#x2F;solutions reply thsksbd 7 hours agoparentprevGyroscopes, accelerometers, and magnetic field sensors reply colechristensen 9 hours agoparentprevThey’re definitely used to detect earthquakes and such. reply softfalcon 3 hours agoprevWe did this at Pure Technologies (now Xylem) running fibre cables over infrastructure to listen for wire breaks in underground pipes, and on bridges to listen for micro-fractures in the concrete structure and steel cabling.The analysis and install was called \"AFO Analyst\" [0].[0] https:&#x2F;&#x2F;www.xylem.com&#x2F;en-us&#x2F;products--services&#x2F;pipeline-asse... reply tomcam 9 hours agoprevFirst time we traveled to Texas when I was a young lad, and we heard cicadas, they were very close to us and I thought it was a vacuum cleaner. reply pbj1968 8 hours agoparentWe used to call them locusts in Texas. I still miss it. Yes, I know they aren’t locusts. We’re all suburban tv babies sharing the same accent these days. reply jhot 6 hours agorootparentThey were called locusts in my area as well. Wasn&#x27;t until college zoology that I learned we were calling them the wrong thing.Anyways, I had a dog that would watch from the back porch and when he saw one flying low across the back yard would run out and catch it out of mid air. The things would be flapping and croaking about until they were crushed mid-swallow. It was a gross but impressive feat to behold. reply BenjiWiebe 5 hours agorootparentI grew up calling them zeezer-bugs. Or cicadas if you wanted to be fancy. reply 1letterunixname 4 hours agorootparentprevMy grandmother in N TX called them that too. They&#x27;re cicadas and they&#x27;re damn loud. Since 1980, all grasshopper species remaining in N America are too rare now to enter a gregarious phase. reply lacrimacida 9 hours agoparentprevCicadas make different sounds, in my area hard to confuse with anything else. Here’s a video(1) with various samples of cicadas. Was any of these sounding like a vacuum cleaner?(1)-https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=thbgObpfoNs reply kadoban 9 hours agorootparentWhen you have no concept of insects being able to make that much noise, the brian just maps it to something else. When you&#x27;re familiar with them, you can pick out the patterns in the frequencies and the ebb and flow, when you&#x27;re first exposed to it it&#x27;s just generic _loud_. reply tomcam 8 hours agorootparentThat was exactly it. reply tomcam 8 hours agorootparentprevIt was that sound but it was right next to my head, camouflaged by the tree it was occupying. I had no idea what it was and didn’t detect its visible presence. I assumed it was many feet away. Wasn’t for days that I understood it was an insect. reply RowanH 4 hours agoparentprevNew Zealander checking in - our February (summer) is insane if you&#x27;re close to certain types of bush. Deafening. Not sure if it was in the article (paywalled) but the little mofos can get up to 100db. There&#x27;s a good couple of weeks I avoid the bush for sure. reply boyter 3 hours agorootparentWe had a big year for them in 2021 in Australia. I was testing an Apple Watch at the time and since exercise was one of the reasons at that time to be allowed out I went for bush walks in my local area.In quite a few areas the noise was so loud the watch informed me I was going to damage my hearing if I remained in the area. reply 1letterunixname 4 hours agoparentprevWhen I first heard them, I thought some power lines were damaged. reply quantisan 4 hours agoprevI worked with Fiber Bragg grating [1] technology in the 2000s, exploring its applications in diverse fields. This included biomedical applications, where a fibre optic cable inserted inside a catheter measured temperature and pressure at specific points within a person&#x27;s body. And in deep oil drilling, where the same fibre optic cable could extend kilometers down a well.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fiber_Bragg_grating reply irrelative 6 hours agoprev(slightly) less pop science version: fiber optic cables are so sensitive, they can even detect the sounds of cidadas. reply echelon 9 hours agoprevApart from fireflies and mantises, cicadas are one of my favorite insects.The sound of cicadas is a hallmark of summer. Whether you&#x27;re inside or outside, it envelops the senses and recalls the nostalgia of endless childhood summers and adventure.I&#x27;m looking forward to Brood XIX [1] hatching next year in Atlanta. It should me amazing.I&#x27;m hoping to see the synchronous fireflies [2] next year. Together with the total solar eclipse, there&#x27;s a lot of good nature and science to take in.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brood_XIX[2] https:&#x2F;&#x2F;www.firefly.org&#x2F;synchronous-fireflies.html[3] https:&#x2F;&#x2F;science.nasa.gov&#x2F;eclipses&#x2F;future-eclipses&#x2F;eclipse-20... reply halfmatthalfcat 8 hours agoparentDefinitely relate to this - quintessential summer sound and almost relaxing at this point. They’re some dumb insects though, run into anything and everything. reply quickthrower2 8 hours agoparentprevHow do their noise compare to crickets? reply bhk 5 hours agorootparentSomething like comparing a whisper to a jet engine, at least when there is a big brood.https:&#x2F;&#x2F;housegrail.com&#x2F;how-loud-is-cicada-in-decibels&#x2F; reply brainbag 7 hours agorootparentprevI enjoy the sound of crickets and cicadas (which are much louder) except for the one particular kind of cicadas we get occasionally in Texas that make a singular unwavering high pitched ambient buzzing sound, like the whine of an old tv cranked to 11, coming from everywhere. It&#x27;s a horribly unpleasant sound, but thankfully they don&#x27;t stick around long. The other cicada sounds are nice. reply I_Am_Nous 7 hours agorootparentprevCrickets chirp (mostly a single kind of chirp) while Cicadas grind. The grinding lasts for half a minute or so, and they rhythmically pulsate the frequency, ending in a descending slowing of the grinding. Like a long WEEEEhoooWEEEEhoooWEEEEEeeee... reply 1letterunixname 4 hours agorootparentCicadas sound like a defective transformer. reply I_Am_Nous 3 hours agorootparentFor clarification, are you meaning an electrical transformer or a Transformer robot? Because I can imagine both being possible lol reply kadoban 8 hours agorootparentprevSubjectively: cicadas are louder but far less annoying. reply cperciva 6 hours agoprevRemember, keep Cicadas away from your hard drives. reply ptek 42 minutes agoprev56k dialup, here we go again. I still have a external USR 56k reply ofslidingfeet 7 hours agoprev [–] > It could lead to a new way of monitoring insects.Hm! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Scientists have found that fiber optic cables can pick up the sound of cicadas, leading to a potential new method for monitoring insect populations.",
      "Using distributed acoustic sensing (DAS), researchers can analyze the light bouncing back from a laser fired through the cables to detect disturbances caused by loud sounds or seismic activity.",
      "This technique could allow entomologists to remotely monitor cicadas and collect data on their population sizes and locations, using the already abundant fiber optic cables. However, monitoring quieter insect species with DAS may be more challenging."
    ],
    "commentSummary": [
      "Fiber optic cables can be utilized as sensors to detect bends and gather information about them in applications like intrusion detection and vibration monitoring.",
      "Optical time domain reflectometers (OTDRs) are commonly employed to measure reflections in fiber optic cables, but uncertain cable speed can affect the accuracy of these measurements.",
      "Various factors, such as twist rates in the cables, can contribute to the uncertainty in cable speed and affect the accuracy of the sensing technology."
    ],
    "points": 156,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1701537074
  },
  {
    "id": 38502340,
    "title": "Bug Report: Sign-in Issue with FIDO2 Key on office.com via Firefox",
    "originLink": "https://bugzilla.mozilla.org/show_bug.cgi?id=1824831",
    "originBody": "Copy Summary ▾ View ▾ Open Bug 1824831 Opened 8 months ago Updated 2 hours ago Can't sign in with FIDO2 key on office.com Categories (Core :: DOM: Web Authentication, defect, P5) Product: Core ▾ Component: DOM: Web Authentication ▾ Version: Firefox 113 Platform: x86_64 Linux Type: defect Priority: P5 Severity: S3 Tracking (UNCONFIRMED bug which will not be worked on by staff, but a patch will be accepted) Status: UNCONFIRMED People (Reporter: code, Unassigned) References Details Attachments (2 files) 2023-03-27 21-47-05.mkv 8 months ago Reto Schneider 336.76 KB, video/x-matroska Details 301123131437.png 3 days ago Rahul Rameshbabu 210.19 KB, image/png Details Bottom ↓ Tags ▾ Timeline ▾ Reto Schneider ReporterDescription • 8 months ago Attached video 2023-03-27 21-47-05.mkv — Details +++ This bug was initially created as a clone of Bug #1820016 +++ Since #1820016 is fixed, I am able to log in on live.com using my FIDO2 security key. However, on office.com I still am unable to do so (using a different business/paid account which works when using Chrome). Flags: needinfo?(tim.cappalli) Tim Cappalli Comment 1 • 8 months ago This is not a Firefox issue. A fix for AAD accounts on the Microsoft side is being worked on. Flags: needinfo?(tim.cappalli) Reto Schneider ReporterComment 2 • 8 months ago Any chance to follow the progress as an outsider? Luna Stadler Updated • 8 months ago Duplicate of this bug: 1826055 John Schanck [:jschanck] Updated • 8 months ago Duplicate of this bug: 1827096 BugBot [:suhaib / :marco/ :calixte] Comment 5 • 8 months ago The severity field is not set for this bug. :jschanck, could you have a look please? For more information, please visit auto_nag documentation. Flags: needinfo?(jschanck) Reto Schneider ReporterComment 6 • 6 months ago With Firefox 114.0 on Linux, I am able to log into by business account using a YubiKey on office.com. However, only when in private browsing mode of my day-to-day-profile. Using regular mode or a totally fresh profile (private or regular browsing mode), it does not work either (\"We had a problem authenticating you. Please try again.\"). Any chance to get an update here? It feels like this is really close to be usable. Rahul Rameshbabu Comment 7 • 6 months ago My understanding is that office.com is a weird exception because it can use the live.com personal account login flow for business accounts too. office.com works for me too, but I wouldn't say that's an indication of usability. I believe the AAD login flow fix by MSFT is still needed. John Schanck [:jschanck] Updated • 6 months ago Severity: -- → S3 Flags: needinfo?(jschanck) Priority: -- → P5 Rahul Rameshbabu Comment 8 • 5 months ago I opened an issue on Microsoft's feedback portal with regards to this. https://feedbackportal.microsoft.com/feedback/idea/67ecb749-d320-ee11-a81d-0022484cae1d John Schanck [:jschanck] Comment 9 • 3 days ago Is this still an issue, Rahul? Flags: needinfo?(sergeantsagara) Rahul Rameshbabu Comment 10 • 3 days ago Attached image 301123131437.png — Details Hi John, Unfortunately, it is. Sharing a screenshot to demonstrate. Our company is working internally to push Microsoft to resolve this (it's not an issue with Firefox's implementation. This can be demonstrated by spoofing the useragent as a Chromium-based browser and attempting the same login flow or just using webauthn.io for validation testing). We unfortunately are not having much luck on our end with our support requests. If possible though, I would like to leave this issue open here for both Firefox users and Microsoft's reference. Thanks, Rahul Rameshbabu Flags: needinfo?(sergeantsagara) Reto Schneider ReporterComment 11 • 12 hours ago I can confirm, still an issue. M$ at its best. :/ Reto Schneider ReporterComment 12 • 12 hours ago (In reply to Rahul Rameshbabu from comment #8) I opened an issue on Microsoft's feedback portal with regards to this. https://feedbackportal.microsoft.com/feedback/idea/67ecb749-d320-ee11-a81d-0022484cae1d I do not think such feedback have ever worked. Not with Microsoft (e.g. Support non-RSA keys for SSH authentication). Upvoted anyway. Neel Chauhan Comment 13 • 5 hours ago I work at Microsoft, but not on the service in question. I can attest that Microsoft's authentication systems are in fact weird. When I joined in 2020, I was shocked to see a FreeBSD system can let me access anything in Microsoft's intranet, when a Windows user agent forces me to use InTune on a corporate PC. I no longer use FreeBSD, but was a big user until last year. Later, Microsoft blocked Firefox from their intranet, even on Windows, but I got in with a Chromium on Linux user agent, even when my work system ran Windows. I even suggested this to a coworker having issues with Chrome. Then they banned Linux from most of their intranet, requiting InTune \"zero trust\", so I temporarily used Vivaldi to use the MS intranet (they saw Vivaldi as \"Chrome\"). MS later re-allowed Firefox with MS authentication in 2021, so I switched back to Firefox with no UA switching. My team at MS, Viva Insights, requires me to attest code with a YubiKey on Azure DevOps. I attest code all the time with Firefox. In fact once, Edge didn't work but Firefox did. While MS might claim to \"love Linux\", they're still mostly a Windows company. I had an entirely Linux-based skillset coming in, hardly ever using WIndows post-2012, yet was made to work on on C# and .NET. Even now, Linux is almost always an afterthought outside of some areas where being Windows-only is \"bad business\" (read: suicidal). Whereas at Google, Linux is mostly a first-class citizen outside of a few areas (e.g. Widevine). However, I don't use Microsoft products at home, due to a mostly FOSS legacy growing up. My personal laptop is a M2 MacBook Air running Fedora Asahi, and my personal \"cloud\" runs Postfix, Roundcube, and Nextcloud on Rocky Linux. To convert to all-MS products at home means having to learn Windows Server and MS365 administration when there's better things to do outside of work. You need to log in before you can comment on or make changes to this bug. Top ↑",
    "commentLink": "https://news.ycombinator.com/item?id=38502340",
    "commentBody": "Can&#x27;t sign in with FIDO2 key on office.comHacker NewspastloginCan&#x27;t sign in with FIDO2 key on office.com (bugzilla.mozilla.org) 151 points by rettichschnidi 12 hours ago| hidepastfavorite71 comments esafak 12 hours agoMeanwhile their TOTP uses a nonstandard \"ms-msa\" protocol, forcing you to use their authentication application.https:&#x2F;&#x2F;1password.community&#x2F;discussion&#x2F;139501&#x2F;one-time-passw... reply jcrawfordor 9 hours agoparentThose ms-msa URLs are for bootstrapping the system formerly know as PhoneFactor. It&#x27;s not a TOTP at all, it&#x27;s a two-way random value challenge. Microsoft supports TOTP as well, but Authenticator push challenges are more resistant to several types of attacks than TOTP, so some Azure AD admins may make it the only option. There&#x27;s also a convenience factor since manually entering numbers isn&#x27;t necessarily required. reply rollcat 9 hours agorootparentMFA via push notifications is vulnerable to the \"keep spamming them until they tap allow\" attack. You can make the user type a code (like Apple does), but that&#x27;s it for convenience. reply jcrawfordor 8 hours agorootparentMicrosoft allows the administrator to configure either \"select one of three\" or have the user enter a two-digit code. The default is \"select one of three,\" but there is also some risk scoring to tune which mode a user gets. reply jmprspret 1 hour agorootparentprevThey also don&#x27;t work at all when there&#x27;s a network outage and you have no mobile data on your phone. (Whereas TOTP would work). An issue I have run into before. reply franga2000 10 hours agoparentprevThere&#x27;s a \"use different authenticator app\" button, but it can be disabled by the domain admin and that might be the default depending on when your Azure AD domain was set up.The fact that you can set a domain to MSA&#x2F;TOTP or MSA-only, but not TOTP-only, is an incredibly scummy, but incredibly predictable move by MS. reply miohtama 9 hours agorootparentBill Gates would laugh in his grave reply jacooper 9 hours agorootparentHe&#x27;s still alive reply layer8 7 hours agorootparentHence tne subjunctive? reply olyjohn 11 hours agoparentprevI use Keepass with it just fine. reply adhesive_wombat 10 hours agoparentprevFortinet do the same, you need their own app to generate the codes. Infuriating. reply aetherspawn 11 hours agoparentprevWorks fine with 1Password One Time password. reply taspeotis 11 hours agoparentprevI use it with 1Password? reply esafak 10 hours agorootparentAre you sure you tried reading a URL with the ms-msa protocol? I&#x27;m on 1PW MacOS 8.10.20 reply okasaki 12 hours agoparentprevI use FreeOTP with it just fine. reply lousken 9 hours agoprevI have opened ticket with them for couple months about this now. I am pissed. To be honest, the fix is to switch the user agent to Chrome on Linux, but still.Even their Edge does not work, just Chromium. If possible, avoid MS login (or all their products in general) reply grenoire 12 hours agoprevDo these guys run integration tests of any kind? Makes it easy to assume malice in breaking fundamental features. reply Rygian 11 hours agoparentNow that you mention malice, here&#x27;s a smoking gun, from the linked bug report:> (it&#x27;s not an issue with Firefox&#x27;s implementation. This can be demonstrated by spoofing the useragent as a Chromium-based browser and attempting the same login flow […]). reply toomuchtodo 11 hours agorootparentFile an FTC complaint. This is potentially anti competitive behavior with a digital paper trail. Microsoft will ignore randos, so engage a regulator. Include the bugzilla post link in the complaint.https:&#x2F;&#x2F;reportfraud.ftc.gov&#x2F; reply jacquesm 10 hours agorootparentMicrosoft and uncompetitive behavior? No way! reply heavyset_go 8 hours agorootparentprevSame thing goes with your state&#x27;s AG and Microsoft&#x27;s AG. reply bscphil 9 hours agorootparentprevI don&#x27;t think this is a smoking gun at all, because we don&#x27;t know the story of why the difference in behavior was implemented. What not-infrequently happens is that Firefox is late to add support for some new web standard, so sites gate their usage on the user agent (which indicates that they actually bothered to test on Firefox!), and then it takes time for them to get around to removing the check after Firefox adds support.In fact it&#x27;s not completely unlikely that that is what happened here. Firefox still has incomplete support for the web authentication API [1], and in particular FIDO2 devices did not work if a PIN is set until Firefox 114 - only a few months ago! I&#x27;m not sure if this could be related, but Firefox also still does not support passkeys [2], so I&#x27;m sure someone will get blamed for anti-competitive behavior for that at some point.[1] https:&#x2F;&#x2F;caniuse.com&#x2F;webauthn[2] https:&#x2F;&#x2F;caniuse.com&#x2F;passkeys reply dymk 11 hours agorootparentprevSmoking gun is a leaked memo indicating the behavior is meant to break Firefox in this specific way reply swells34 11 hours agorootparentprevHow is that a smoking gun indicating malice? reply Rygian 11 hours agorootparentChanging behavior based on user agent is necessarily intentional on the part of Microsoft.That check lies somewhere along the line between \"having the direct goal of breaking authentication flow (pure malice)\" and \"is a completely legitimate programming error (pure incompetence).\"I am not ready to assume pure incompetence (and here&#x27;s where I might be wrong). reply eNV25 11 hours agorootparentprevIt means that the website doesn&#x27;t work in Firefox intentionally. The website was proframmed to not work with Firefox user agent string. reply 13of40 11 hours agorootparentIs firefox blacklisted or are chrome and edge whitelisted? reply swells34 11 hours agorootparentprevAh I see, I thought the parent poster meant malice on the part of Mozilla, got confused by bouncing between comment threads. I could see malice, since it is Microsoft, but what&#x27;s the \"why\" of it? I don&#x27;t really see any motivation that M$ would have to block Mozilla, all it&#x27;s going to do is piss off users. It&#x27;s not like people are gonna get fed up and switch to Edge, they&#x27;ll get fed up and switch to Chrome. If anything, M$ has a great incentive to improve Firefox adoption. The market that uses FF is the same market that is never going to choose Edge. FF and Edge both have a much better position if they can damage Chrome&#x27;s market share. reply Rygian 11 hours agorootparentThe cynic in me says we will understand the motivation in some antitrust trial one of these years. reply DoctorOW 11 hours agorootparentprevBecause it is not a bug or mistake in the code but a deliberate loss in functionality based only on the name of the browser. reply jiggawatts 11 hours agoparentprev> integration tests of any kindNo!Microsoft famously fired their entire QA team. Also… their technical writing team. And then they outsourced both support and the bulk of their development to India.You get what you pay for, and right now Microsoft is variously paying either zero or very little. reply makeitdouble 8 hours agorootparentI&#x27;d see Microsoft hiring contractors, but do they outsource product development to external companies ? reply jiggawatts 5 hours agorootparentNot sure about development, but Azure support is almost entire outsourced. reply campbel 12 hours agoparentprevRandom stuff breaking or things not working quite right is to be expected with Microsoft products. reply Waterluvian 12 hours agorootparentOffice 365 Calendar broke for me a few weeks back and is still unusable. It forcibly leaps me weeks ahead whenever I try to scroll to today’s date. I literally cannot view my work calendar on my phone anymore.I often wonder if they’re even capable of knowing there’s an issue. reply ilrwbwrkhv 11 hours agoparentprevMicrosoft devs have a reputation of being quite sub par. reply bastard_op 11 hours agoprevIt&#x27;s Microsoft&#x27;s typical passive-aggressive way of trying to drum up users for edge being a chrome clone now, since begging you to stay didn&#x27;t work when the only thing you use edge for is to download another browser. What else is new? reply Analemma_ 12 hours agoprevCan someone from Microsoft share why the login flow on all things Office&#x2F;O365 is such a disaster? No other major company is so bad about this. You get bounced between a half-dozen domains (which I assume is somehow the root cause of the issue here), the \"keep me signed in\" check box literally does nothing, and so on. And you can&#x27;t even blame it on trying to integrate incompatible legacy systems, this is all on Microsoft&#x27;s first-party services. reply jiggawatts 11 hours agoparentThe latest madness is that logging on to Azure Portal with Firefox requires about ten clicks on the user name.As in: I log in, jump through the MFA hoops, and then it goes back to the list of user names to make me re-select the account I just used to log in.Mind you, it always did this, which meant that I couldn’t just open a Portal link in a new tab — I’d have to select my account (again) for each tab.But now I have to click at least ten times!It’s broken.Authentication is broken and there’s no one at the wheels. reply nathanaldensr 11 hours agorootparentThere are probably no actual wheels to begin with, knowing Microsoft. reply easton 10 hours agoparentprevMy AAD account is permanently screwed up because I left and rejoined the company I’m at (intern conversion, so I got a new AAD account with the same email).I get signed out constantly, especially on mobile where my coworkers do not. Trying to sign into ADO sends me to a screen prompting me to configure a new org because it gets confused by two accounts existing with the same email in the same org even though one of them was deleted along with the underlying AAD account. It also just 500s sometimes when trying to login saying there’s something weird happening during authentication, I have to restart the browser to make it work.As far as I know there’s no way to fix any of it, so I’m stuck with half working SSO. reply kstrauser 9 hours agorootparentAh, their famous Stochastic Sign-On. reply tremon 11 hours agoparentprevSame with the Azure Portal, I can regularly DoS microsoft by opening the portal from a bookmark in Edge, or by switching Azure tenants (via the official button, which has also seen three different locations in the past year). It signs in, loads the intended page, then redirects to the home page, which performs the sign-in again, then redirects to the Azure portal welcome screen, which redirects to the home page, which performs the sign-in again -- at which points Microsoft usually \"solves\" the redirect loop by informing me that I&#x27;ve tried to login too many times and I should try again in five minutes.With the additional bonus that even after things miraculously stabilize, I&#x27;m not on the page I wanted to go but on the welcome screen. Pasting the intended link again in the browser bar seems to have a 10% chance of triggering the redirect loop again. It&#x27;s so comically bad, I&#x27;m glad my employer is paying me for my time and not my productivity. reply leokennis 11 hours agoparentprevAnd the domains look ancient or shady as well. Live.com, aka.ms, msn.com…if you didn’t already know they were genuine Microsoft accounts you’d be smart to assume you were being scammed. reply magicalhippo 11 hours agoparentprev> You get bounced between a half-dozen domainsAt work one of the cdn domains they use fails to resolve until it suddenly works. Haven&#x27;t bothered to look into it yet, but generally takes about 10-15 minutes to sign into anything related to Azure AD &#x2F; Office365.Can resolve it just fine on the command line, just in the browser where it doesn&#x27;t work. reply tredre3 10 hours agoparentprevAlso some of that bouncing around involves passing your email into the URL (?account=you@outlook.com) which is just bizarre in current day (tm). reply ano-ther 11 hours agoparentprevThey also introduced 2F verification pop ups that don’t show up in the task bar and are therefore not selectable when they are behind another window. reply esafak 11 hours agoparentprevI have spent weeks just trying to log onto Teams to communicate with an MS contracting shop. I still have not managed to log in. It is infuriating beyond belief. reply snitch182 10 hours agoprevI have tried to use a fido2 key years ago and it did not work. I think you need some proprietary sort-of standard key. reply taspeotis 10 hours agoprevIt’s probably some sort of intrusion detection system saying Firefox + passkey has been seen 0.1% of the time … abort. reply Macha 10 hours agoparentHumble Bundle seems to have started doing that to me at times with a Firefox on Linux user agent. Support just gaslights me about clearing cookies and checking I typed the password correctly, even though it will work if I use Chrome or just wait a few days. reply riffic 12 hours agoprev8 months old too reply 13of40 10 hours agoparentIf you filter by status, there&#x27;s nothing in that feedback channel that&#x27;s had its status changed for several months, and none of the issues there are marked fixed, so there&#x27;s probably some other way this sort of thing is meant to be reported. According to their help page in outlook.com:\"Microsoft 365 subscriptions include premium customer support, so if you need to contact Microsoft for help, you&#x27;ll get our highest level of service.\" reply Waterluvian 12 hours agoprevSo is it definitely not a Mozilla issue but there’s no sensible issue tracker for it as a Microsoft issue?You seem understandably frustrated. :&#x2F; reply badrabbit 11 hours agoprevDamn, I depend on this. I tried to use fido2 on my flipperzero, MS blocks that as well. Kind of a bummer when you think about it with companies picking and choosing what keys&#x2F;clients to allow when it should be up to the user. reply solardev 11 hours agoprev [–] Unpopular question: At what point should companies officially deprecate support for a minority browser?Firefox is down to like 6% marketshare, barely above (what&#x27;s left of) Opera. Even Edge has nearly twice the usage.Is reasonable to expect a company to go out of their way to spend resources fixing something that works fine for 94% of their users, using any of several alternate browsers?And this is Microsoft after all, the same company that&#x27;s been through multiple browser wars and finally caved and joined the Blink family. Why should they care about Firefox? reply forgotmypw17 11 hours agoparentMy personal opinion, as a foss developer who does more than 90% of the commits on a relatively complicated Web aplication, is: NEVER. I have committed myself to supporting every browser in every configuration, because anything less is non-inclusive and assumptive about the user&#x27;s abilities and capabilities. I will always bend over backwards to accommodate every user, because I want the experience of visiting my websites to be like that of a luxury hotel that caters to every need, rather than project housing or prison that forces to conform. I also think it is rather rude to assume that the user can change anything about their setup. I think of this type of accommodation as wheelchair ramps, which serve only a small demographic, but are pretty much universally agreed upon as being necessary.And yes, I support Internet Explorer, Lynx, and NetSurf. reply kstrauser 9 hours agorootparentI disagree. While I appreciate the thinking, it’s not at all like wheelchair ramps. Supporting IE actively made life worse for everyone else. Resources are limited, so dragging that junk heap along meant that developer time was wasted on it instead of adding new features people wanted. Wheelchair ramps are useful for everyone at some time, even if it’s just helping someone push a cart a little more easily. reply forgotmypw17 5 hours agorootparentIf a user only has IE and no ability to upgrade it, should I make extra effort to provide them with accessibility, or should I just tell them to fuck off, blocking them from information that is critical for them to access?I choose the former, because I think the extra effort is worth it. Resources are not unlimited, but it&#x27;s also quite feasible, if you are creative and not lazy.And if you cannot even support IE, I guess you think that textmode browsers, visually impaired support, slow network connections, and other accessibility modes are also not worth your time? reply kstrauser 4 hours agorootparentThat’s so unfair of you not to support Mosaic. What about the people who can’t upgrade past HTML1 browsers?My point being, it’s great to support all modern browsers (which excludes IE altogether, but definitely including screen readers). If you’re a library, go ahead and support dialup and Lynx, too, if you can afford the dev time. If you’re an e-commerce site, and spending more than hobby time supporting Lynx and 56k, I might think you’re nuts for doing it. reply forgotmypw17 3 hours agorootparentI actually do support Mosaic in the framework, although it is challenging to get working on a live server. replysgift 11 hours agoparentprev> Is reasonable to expect a company to go out of their way to spend resources fixing something that works fine for 94% of their users, using any of several alternate browsers?Out of their way implies they have to do anything more than implement the standard and don&#x27;t do browser sniffing, which has always been a bad practice and especially since feature testing has become more widespread. A sibling comment highlighted the part that it works if the user-agent is changed to Chrome.So, here&#x27;s my take to your original question: If a feature has a backing standard, companies, especially those above a certain size, should be forced to follow the standard for that feature and not include any kind of \"only allow using this feature if we have tested it in the browser\" code. If the company states they cannot do that (cause they have a policy to only allow features in browsers they&#x27;ve tested or whatever), they should be forced to support everyone.Another good reason to force support for everyone should be if the company has their own browser. reply int_19h 2 hours agoparentprevI would say that there&#x27;s a moral imperative to support Firefox for as long as it remains the only major open source alternative implementation of HTML&#x2F;CSS&#x2F;JS to Blink. We&#x27;ve been there before, and monocultures are just bad all around, so it&#x27;s important for something like this to exist and be supported for the eventual inevitable day it will be needed. reply db48x 11 hours agoparentprevThey actually went out of their way to block Firefox here. The authentication protocol is a standard supported by all browsers, and if you change the user–agent string to look like Chrome’s then magically it starts working again. reply kstrauser 11 hours agoparentprev6% of 5 billion is disregarding about 300 million users.Should MS care enough about 300 megausers to make sure their login flow works? Uh, yeah. reply recursive 11 hours agoparentprevSo I guess Safari would go too? reply realusername 11 hours agoparentprev> Why should they care about Firefox?Maybe that&#x27;s a question for them to answer since they actively block it with user agent checksIf they truely did not care about Firefox, it would have worked. reply worble 11 hours agorootparentAt what point are Firefox going to drop having a unique user-agent and just adopt chromes? There are so many support issues they could avoid if they just did this, I really don&#x27;t see what the benefit is anymore. reply mdaniel 11 hours agorootparentwhat&#x27;s old is new again: https:&#x2F;&#x2F;webaim.org&#x2F;blog&#x2F;user-agent-string-history&#x2F;so, what I&#x27;m hearing is that FF should change its current U-A from `Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko&#x2F;20100101 Firefox&#x2F;120.0` to just `Mozilla&#x2F;5.0` and skip the pretense :-)In all seriousness, Chrome&#x2F;Chromium actually had a plan to do some U-A simplificationbut it doesn&#x27;t appear they&#x27;re going as far as evicting the Chrome branding from it, nor (confusingly enough) dropping the Safari misnomer (since they don&#x27;t use WebKit anymore) reply realusername 11 hours agorootparentprevI&#x27;m not against the idea personally, the user agent doesn&#x27;t have a purpose anymore and probably is the number one cause of \"bugs\" only affecting Firefox.It&#x27;s the same issue on mobile as well, Google still serves the dumbed down search version to Firefox whereas the one they serve on Chrome fully works with a user agent change. reply hooverd 11 hours agoparentprev [–] They care enough to make to it specifically &#x2F;not&#x2F; work on Firefox, because it works if Firefox lies about what it is. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Users are experiencing difficulty signing in on office.com using Firefox browser with a FIDO2 key, according to a bug report.",
      "The severity level of the bug is stated as low, and Microsoft has been notified about the issue.",
      "The bug remains unresolved, and efforts are underway to prompt Microsoft to address it, with multiple users verifying that the problem persists. The bug report also references Microsoft's authentication systems as complex and inconsistent."
    ],
    "commentSummary": [
      "Users are frustrated with Microsoft's login system on Firefox and suspect anti-competitive behavior and intentional blocking by Microsoft.",
      "Complaints include Microsoft's lack of quality assurance and technical support, as well as navigation and compatibility issues with certain browsers.",
      "There is a debate on whether Microsoft should continue to support minority browsers like Firefox, with some emphasizing inclusivity, while others discuss the adoption of Chrome's user-agent string to avoid compatibility issues."
    ],
    "points": 151,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1701553525
  },
  {
    "id": 38504134,
    "title": "Clang's default behavior causes issue with running binaries on original Pi B+",
    "originLink": "https://rachelbythebay.com/w/2023/11/30/armv6/",
    "originBody": "Writing Software, technology, sysadmin war stories, and more. Thursday, November 30, 2023 clang now makes binaries an original Pi B+ can't run I have a bunch of Raspberry Pi systems all over the place, goofy things that they are. They do dumb and annoying jobs in strange locations. I even have one of the older models, which is called just the B+. You can think of it as the \"1B+\" but apparently it was never officially branded the 1. If you have one of these, or perhaps an original Pi Zero hanging around, you might find that C++ programs built with clang don't work any more. I ran into this as soon as I started trying to take binaries from my \"build host\" (a much faster Pi 4B) to run them on this original beast. It throws an illegal instruction. This used to work in the old version (bullseye). It now breaks in the current one (bookworm). I figured, okay, maybe it's doing some optimization because it was built on the 4B. So, I went and did a build on the B+ natively. It also broke. So I backed off another level to a much simpler reproduction case: just declare main() and return. That still broke. Looking this up, there are a bunch of screwy dead-end forum posts where people go back and forth asserting this package is installed and that's making the compiler go stupid, or it's because they did the \"lite\" install vs. the \"recommended\" install, or who knows what. I wanted to do better than that, so this afternoon I picked up a brand new SD card, blew the whole \"desktop + recommended\" OS image onto it, booted *that*, then installed clang, and... raspberrypi:~/prog$ cat t.cc #includeint main() { return 0; } raspberrypi:~/prog$ clang++ -Wall -o t t.cc raspberrypi:~/prog$ ./t Illegal instruction Awesome. It can compile something it can't even run. What's the bad instruction? gdb will answer that in a jiffy. (gdb) disassemble Dump of assembler code for function main: 0x004005a4 : sub sp, sp, #4 => 0x004005a8 : movw r0, #0 movw. That's not in armv6l, apparently. So yeah, this compiler is effectively cross-compiling for armv7 (or something) by default. That's not very useful. You can work around this by grabbing the compiler by the lapels and saying \"build for armv6, punk\", and it will give you a working binary: raspberrypi:~/prog$ clang++ --target=armv6-unknown-linux-gnueabihf -Wall -o t t.cc raspberrypi:~/prog$ ./t raspberrypi:~/prog$ How and why did it get to that point? I can only imagine it's some default that got bumped from version 11 to version 12, and somehow nobody noticed? I guess nobody still runs these old things anywhere? So weird. More writingContact / send feedback",
    "commentLink": "https://news.ycombinator.com/item?id=38504134",
    "commentBody": "Clang now makes binaries an original Pi B+ can&#x27;t runHacker NewspastloginClang now makes binaries an original Pi B+ can&#x27;t run (rachelbythebay.com) 144 points by FPGAhacker 7 hours ago| hidepastfavorite48 comments stephen_g 2 hours agoWow, looking at the history of the ARM generation the original versions of the Raspberry Pi uses, it’s hard to believe it’s so old! When the Raspberry Pi B+ was released (2014), the ARM core it used was already 11 years old (using the ARM1176 core from 2003). So it’s not unbelievable that you might need to start supplying an arch flag to produce compatible code building on a different platform (like the newer Raspberry Pi the article says they first built on).As others have said, it does seem like a misconfiguration (perhaps in the defaults shipped by their distribution) that the correct arch is not picked by default when building on the Raspberry Pi B+ itself. reply yjftsjthsd-h 2 hours agoparent> When the Raspberry Pi B+ was released (2014), the ARM core it used was already 11 years old (using the ARM1176 core from 2003).IIRC the original Pi used leftover chips from a TV box, which is the kind of product that IME never ships more compute than they have to, for price reasons. reply RantyDave 1 hour agorootparentPhones, not TV&#x27;s, but that&#x27;s pretty much the idea. Even better, the ARM core was tacked on as a sort of \"dammit, I supposed we&#x27;ll have to run applications\" kinda thing and isn&#x27;t even necessarily initialised during boot.Raspberry Pi&#x27;s actually boot on a really fringe processor called a VideoCore. Arguably the GPU bootstraps the CPU, which makes my brain hurt. reply phendrenad2 1 hour agorootparentI guess technically a CPU core within the GPU ASIC block loads code into the main CPU. What a weird design. Feels like the kinda of things that Wozniak would come up with to shave cost from the Apple Macintosh. reply einr 1 hour agorootparentprevTV boxes IME usually ship with less compute than they have to [in order to provide reasonable UX] ;) reply adhesive_wombat 42 minutes agorootparentAnything to satisfy whichever law it is that says \"lagginess remains constant\". reply yjftsjthsd-h 1 hour agorootparentprevEh, the result may suck, but I don&#x27;t think it&#x27;s usually a hardware problem. reply kazinator 1 hour agoparentprevShe&#x27;s not building on the B+, though.Quote:I started trying to take binaries from my \"build host\" (a much faster Pi 4B) to run them on this original beast. It throws an illegal instruction.This is like building something with the latest MSVC on Windows 11 and trying to run the .EXE on an old PC running Windows XP. :)I suspect the entire Pi distro she&#x27;s running on the Pi 4B itself won&#x27;t run on the B+, since all of it is probably compiled the same way, possibly down to the kernel. reply kelnos 55 minutes agorootparentBut at the end, she puts together a new SD card for the B+, boots it, and tries to compile an empty program on the B+ itself. \"It can compile something it can&#x27;t even run\", she says. reply mid-kid 55 minutes agorootparentprevShe was building on the B+ in the later example of the blog. reply kazinator 43 minutes agorootparentAh I see that now.The interesting question there is why does the clang binary itself run on the old hardware?It must be that the distro build uses a different compiler configuration for itself from the configuration imbued into the installed clang.Maybe it even builds clang twice: once to produce a clang that runs on the machine that builds the distro, which then compiles the packages, including the clang to run on the Pi. reply schemescape 3 hours agoprevI didn&#x27;t see it addressed here or in the article: this is a bug, right?Edit: oddly, after searching LLVM bugs, I found a bug that sounds pretty much exactly like this issue... but it&#x27;s from 2012 and is closed (although the final couple of comments make it sound like maybe it wasn&#x27;t actually fixed--note: I only skimmed the comments and I probably misunderstood):https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;issues&#x2F;13989Edit again: I forgot about the comment at the end of the article that clarifies that explicitly passing the target results in a working program. In that case, it sounds like some sort of configuration bug--I would assume (but am not certain) that the default target would be the current processor, at least on Unix. That bug I linked was probably about producing incorrect code even when the target was set correctly which, thankfully, isn&#x27;t happening today. reply Arnavion 2 hours agoparentYes, your bug is about the compiler emitting armv7 instructions despite being told to target armv6. Rachel fixed her problem by telling the compiler to target armv6. So I assume your bug is indeed already fixed and not related to Rachel&#x27;s problem. reply wmf 3 hours agoparentprevYeah, this is not the behavior people expect. reply opello 44 minutes agoprevSeems like the problem is likely a configuration target change in the clang-13 package that&#x27;s current for bookworm.Specifically because under bullseye (and clang-11) the default target is armv6k-unknown-linux-gnueabihf while under bookworm (and clang-13) the default target is arm-unknown-linux-gnueabihf.Or maybe the default changed for the given build configuration on the LLVM side? reply opello 15 minutes agoparentI really wish I understood the Debian change management process better. I guess I don&#x27;t even really know if Raspbian is actually maintained by Debian.But, when comparing [1] to [2], the rules file has a nice test that says \"if DEB_HOST_ARCH is armhf, set the LLVM_HOST_TRIPLE to armv6k...\" which seems to confirm a build configuration change.[1] http:&#x2F;&#x2F;raspbian.raspberrypi.org&#x2F;raspbian&#x2F;pool&#x2F;main&#x2F;l&#x2F;llvm-to...[2] http:&#x2F;&#x2F;raspbian.raspberrypi.org&#x2F;raspbian&#x2F;pool&#x2F;main&#x2F;l&#x2F;llvm-to... reply orra 5 minutes agorootparentTo answer your incidental question, Raspian is maintained by Raspberry Pi folks, not Debian. reply matja 2 hours agoprevclang&#x2F;clang++ read from &#x2F;etc&#x2F;env.d&#x2F;gcc to get the target flags&#x2F;profile, it&#x27;s up to the OS to maintain them and make sure they&#x27;re correct, looks like that didn&#x27;t happen for this OS.My Gentoo ARM SBC based on an even more ancient armv4 arch has been chugging along just fine with the latest gcc&#x2F;clang updates: grep CTARGET &#x2F;etc&#x2F;env.d&#x2F;gcc -r &#x2F;etc&#x2F;env.d&#x2F;gcc&#x2F;armv4tl-softfloat-linux-gnueabi-11.3.0:CTARGET=\"armv4tl-softfloat-linux-gnueabi\" reply Arnavion 1 hour agoparent&#x2F;etc&#x2F;env.d is a Gentoo-specific directory to define default env vars for user sessions. It&#x27;s not a feature of clang to read that directory, so it&#x27;s not correct to assume other distros would have it. It&#x27;s just that Gentoo&#x27;s compiler setup reads the CTARGET env var to select the target, and Gentoo uses &#x2F;etc&#x2F;env.d to set it. reply matja 1 hour agorootparentIs that why other distros break? :) reply contingencies 2 hours agoparentprevGentoo always works .. it just takes longer :) reply teddyh 3 hours agoprevIt would probably be helpful to know the output of the command “dpkg-architecture” and the contents of the file “&#x2F;etc&#x2F;os-release”. Otherwise it will be hard to make any useful comments. reply frizlab 3 hours agoprevTitle is misleading reply usr1106 1 hour agoparentAka called clickbait. Although the bug and the workaround are useful to know for everyone working with that machine. reply blahgeek 1 hour agoparentprevYes. It should be “clang does not correctly detect host architecture in raspberry pi B+” reply eimrine 3 hours agoparentprevBecause \"as a default\" statement is missing? reply jenadine 3 hours agorootparentYes.It now sounds like it is completely broken. But you can just fix it with a flag. And the change of default was probably an unintentional bug. reply johnklos 3 hours agoprevYou&#x27;ll see a whole bandwagon of people saying things like, \"supporting old hardware is BAD! It takes time and money that nobody has!\", as though someone needs to be hired to sit around and do nothing but pore over code and constantly rewrite code for old hardware.There&#x27;s plenty of evidence to the contrary, but since when has evidence mattered when it comes to defending the right of big business &#x2F; big distro to do whatever they want? ;)Really, this is just laziness and sloppiness on the Linux distro makers&#x27; part. Any amount of testing would catch this. Thanks, Rachel! reply bee_rider 2 hours agoparentBig distro. These fat-cat volunteer kernel devs are just trying to keep us down by giving us so much free software that we collapse under the weight of it. reply zmgsabst 1 hour agorootparentAren’t a lot of kernel devs paid by large corporations?Eg, this article.https:&#x2F;&#x2F;thenewstack.io&#x2F;contributes-linux-kernel&#x2F; reply Elucalidavah 3 hours agoparentprev> sit around and do nothing but pore over code and constantly rewrite code for old hardwareIn case of refactoring &#x2F; restructuring, that&#x27;s exactly so.But \"drop support for this old hardware\" is meant to be an intended decision with a clear deprecation warning, not accidentally. reply atemerev 2 hours agorootparentThe bazaar doesn’t work like this. There are no incentives to support old hardware. If there are enough people with old hardware, their activity might be enough to do something. Otherwise — puff, gone.Open source is already a miracle. The fact that something works somewhere is a miracle. I don’t tempt the powers and I don’t demand even more miracles to satisfy some perfectionist urges. reply yellow_lead 2 hours agoparentprev> You&#x27;ll see a whole bandwagon of people saying things like, \"supporting old hardware is BAD! It takes time and money that nobody has!> Any amount of testing would catch this.Who is paying for the testing? I&#x27;m not suggesting supporting old hardware is bad, but we must recognize it takes some effort to uphold backwards compatibility. Stuff gets broken accidentally always, and testing isn&#x27;t free. reply kaba0 2 hours agoparentprev> when it comes to defending the right of big business &#x2F; big distro to do whatever they want? ;)Anything else about your alternative reality?Also, why don’t you go and take on support for this given target, if it’s so important for you? Or pay for someone to do it? I’m sure the project wouldn’t mind supporting it if someone would have stepped up, but I’m sure it’s still not too late. reply woodruffw 1 hour agoparentprevThis has nothing to do with the distro; it looks like an upstream LLVM bug. And it does demonstrate the problem: old code doesn’t change, but interfaces and invariants do. Those external changes do represent maintainer burden.Armv6 isn’t really “old hardware” in the “disused, actively rotting” sense. That’s reserved for things like Itanium or HPPA, which distributions (and upstreams) would do perfectly well to remove unless paid buckets of money by their respective corporations. reply jenadine 3 hours agoparentprevThe thing with free software is that you are in no position to demand anything. If the maintainer don&#x27;t feel like supporting your hardware, they don&#x27;t have to.But the beauty of free software is that you can always do it yourself. (Or pay someone to do it) reply wmf 3 hours agoparentprevI think RPi has struck a reasonable balance where the mainstream Linux community doesn&#x27;t really support ancient ARMv6 so RPI themselves maintains forked software (e.g. Raspbian). This way the cost of legacy is borne by those who benefit from it, not everyone. reply deaddodo 2 hours agorootparentRaspbian existed well before ARMv6 support dropped off. It&#x27;s been their main distro from the outset, but mainstream distros with ARM builds only removed support for ARMv6 in the last 1-3 years (depending on distro). reply ninepoints 3 hours agoprevnext [8 more] [flagged] ajb 3 hours agoparentIt&#x27;s not explicitly stated but in her reproduction she is actually running it on the pi, and compilers very much do normally compile for the arch that they are running on by default.A compiler which compiles for a different arch is called a cross-compiler. Unless you explicitly asked for a cross compile, it is indeed surprising for a compiler to emit a binary that won&#x27;t run on the same machine. reply wmf 3 hours agoparentprevIt sounds like clang running on the RPi 1 generates code that doesn&#x27;t run. Usually compilers default to targeting whatever ISA it&#x27;s running on but that doesn&#x27;t seem to be the case here. reply vient 3 hours agorootparentUsually compilers default to the ISA they were built on. In the case of Clang this is controlled by LLVM_DEFAULT_TARGET_TRIPLE cmake option - maybe a weird mix of options occurred where Clang for armv6 was built on armv7 but the default triple was not adjusted correctly.Current docs about this option:> LLVM target to use for code generation when no target is explicitly specified. It defaults to “host”, meaning that it shall pick the architecture of the machine where LLVM is being built. If you are building a cross-compiler, set it to the target triple of your desired architecture. reply ajb 3 hours agorootparentYes this could very well be a packaging&#x2F;build error of clang, rather than a code bug. It&#x27;s quite usual to cross compile for pi1 because it&#x27;s so slow to build on it. reply westurner 2 hours agorootparentprevraspberrypi.com&#x2F;documentation&#x2F;computers&#x2F;linux_kernel.html#cross-compiling-the-kernel: https:&#x2F;&#x2F;www.raspberrypi.com&#x2F;documentation&#x2F;computers&#x2F;linux_ke...89luca89&#x2F;distrobox: https:&#x2F;&#x2F;github.com&#x2F;89luca89&#x2F;distrobox #quick-start89luca89&#x2F;distrobox&#x2F;blob&#x2F;main&#x2F;docs&#x2F;useful_tips.md#using-a-different-architecture: https:&#x2F;&#x2F;github.com&#x2F;89luca89&#x2F;distrobox&#x2F;blob&#x2F;main&#x2F;docs&#x2F;useful_...lukechilds&#x2F;dockerpi: https:&#x2F;&#x2F;github.com&#x2F;lukechilds&#x2F;dockerpi : RPi 1, (2,3,) in QEMU emulating ARM64 on x86_64E.g. the Fedora Silverblue rpm-ostree distro has \"toolbox\" by default because most everything should be in a containercontainers&#x2F;toolbox: https:&#x2F;&#x2F;github.com&#x2F;containers&#x2F;toolboxFrom https:&#x2F;&#x2F;containertoolbx.org&#x2F;distros&#x2F; :> Distro support: By default, Toolbx creates the container using an OCI image called `-toolbox:`, whereandare taken from the host’s `&#x2F;usr&#x2F;lib&#x2F;os-release`. For example, the default image on a Fedora 36 host would be `fedora-toolbox:36`.> This default can be overridden by the `--image` option in `toolbox create`, but operating system distributors should provide an adequately configured default image to ensure a smooth user experience.The compiler arch flags might should be correctly specified in a \"toolbox\" container used for cross-compilation, too.There are default gcc and&#x2F;or clang compiler flags in distros&#x27; default build tools; e.g. `make` specifies additional default compiler flags (that e.g. cmake, ninja, gn, or bazel&#x2F;buck&#x2F;pants may not also specify for you). reply amatecha 3 hours agoparentprevUh, what? It&#x27;s weird to assume \"clang++ -Wall -o t t.cc\" should produce a binary that runs on the architecture we&#x27;re currently using? reply ninepoints 55 minutes agorootparentYou think most clang devs test on pre arm7 architectures? (And I don&#x27;t mean in a cross-compiling sense) reply auselen 1 hour agoprev [–] Confused article? You make a host&#x2F;native build instead of cross and expect it to work on some other machine? reply daviddoran 1 hour agoparent [–] No. Half way through the article she specifically starts doing everything on the B+ (the old RPI with the issue). reply auselen 1 hour agorootparent [–] Thanks for that. I didn’t notice she switch to B+ later. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their experience using clang to compile C++ programs on a Raspberry Pi B+.",
      "Binaries built with clang cannot run on the B+ due to a default behavior change.",
      "The author identifies a workaround by specifying the target architecture, but questions why this default behavior change went unnoticed and suggests that older Raspberry Pi models are not widely used anymore."
    ],
    "commentSummary": [
      "There was a discussion about compatibility issues between the Clang compiler and the original Raspberry Pi B+ due to its older ARM1176 core.",
      "A bug in the LLVM compiler was resolved by specifying the target as armv6.",
      "The conversation also touched upon the challenges of supporting old hardware in Linux distributions, the concept of free software, and emulating ARM64 on x86_64 using QEMU and Docker. Properly configuring the default image for the toolbox container was highlighted as crucial."
    ],
    "points": 144,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1701569241
  },
  {
    "id": 38499375,
    "title": "Excalidraw: The Open-Source Drawing Tool for Hand-Drawn Style Diagrams",
    "originLink": "https://github.com/excalidraw/excalidraw",
    "originBody": "Excalidraw EditorBlogDocumentationExcalidraw+ An open source virtual hand-drawn style whiteboard. Collaborative and end-to-end encrypted. Create beautiful hand-drawn like diagrams, wireframes, or whatever you like. Features The Excalidraw editor (npm package) supports: 💯 Free & open-source. 🎨 Infinite, canvas-based whiteboard. ✍ Hand-drawn like style. 🌓 Dark mode. 🏗 Customizable. 📷 Image support. 😀 Shape libraries support. 👅 Localization (i18n) support. 🖼 Export to PNG, SVG & clipboard. 💾 Open format - export drawings as an .excalidraw json file. ⚒ Wide range of tools - rectangle, circle, diamond, arrow, line, free-draw, eraser... ➡ Arrow-binding & labeled arrows. 🔙 Undo / Redo. 🔍 Zoom and panning support. Excalidraw.com The app hosted at excalidraw.com is a minimal showcase of what you can build with Excalidraw. Its source code is part of this repository as well, and the app features: 📡 PWA support (works offline). 🤼 Real-time collaboration. 🔒 End-to-end encryption. 💾 Local-first support (autosaves to the browser). 🔗 Shareable links (export to a readonly link you can share with others). We'll be adding these features as drop-in plugins for the npm package in the future. Quick start Install the Excalidraw npm package: npm install react react-dom @excalidraw/excalidraw or via yarn yarn add react react-dom @excalidraw/excalidraw Don't forget to check out our Documentation! Contributing Missing something or found a bug? Report here. Want to contribute? Check out our contribution guide or let us know on Discord. Want to help with translations? See the translation guide. Integrations VScode extension npm package Who's integrating Excalidraw Google Cloud • Meta • CodeSandbox • Obsidian Excalidraw • Replit • Slite • Notion • HackerRank • and many others Sponsors & support If you like the project, you can become a sponsor at Open Collective or use Excalidraw+. Thank you for supporting Excalidraw Last but not least, we're thankful to these companies for offering their services for free:",
    "commentLink": "https://news.ycombinator.com/item?id=38499375",
    "commentBody": "Open-source drawing tool – ExcalidrawHacker NewspastloginOpen-source drawing tool – Excalidraw (github.com/excalidraw) 139 points by dmezzetti 10 hours ago| hidepastfavorite29 comments cuuupid 8 hours agoJust want to chime in and say this is one of the best tools, I have this permanently pinned in Arc and it makes it really, really easy to collaborate.Some more dots:- free, open source, encrypted and private- I hated this at first because the shortcuts weren’t intuitive. IMO shortcuts are the #1 most important feature of a whiteboarding tool because you never want the interface to be a process step. This has improved drastically and it’s best in class now!- very stable and widely used for systems design interviews, basically every startup is on this now and even Meta uses this white-labelled for their interviews- the easy collaboration and easy jump in (going to their homepage opens up a whiteboard) makes this an ideal pair for new-age tools like Arc- the scribbly design style humanizes system design and makes it seem lower stakes, IMO makes a big difference in my process- seems to have a small footprint, I’ve used this on airplane wifi before without latency reply Veuxdo 8 hours agoprevPrevious discussions:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25608336https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23525648https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27034119https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22101381 reply dang 8 hours agoparentThanks! Macroexpanded:Excalideck – Use Excalidraw to make slides - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29139581 - Nov 2021 (24 comments)Why is Excalidraw so good? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29109995 - Nov 2021 (267 comments)Excalidraw+ - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27034119 - May 2021 (31 comments)Eraser — Excalidraw-based visual meeting canvas - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26330288 - March 2021 (8 comments)It was fun generating version distributions charts for Excalidraw - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25792169 - Jan 2021 (1 comment)One Year of Excalidraw - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25608336 - Jan 2021 (19 comments)Create a Slideshow with Excalidraw - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25081914 - Nov 2020 (1 comment)Excalidraw whiteboard – easily sketch diagrams with a hand-drawn feel - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23525648 - June 2020 (54 comments)Building Excalidraw&#x27;s P2P Collaboration Feature - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22719576 - March 2020 (1 comment)End-to-end encryption in the browser - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22663435 - March 2020 (107 comments)End-to-End Encryption in the Browser and how we did it in Excalidraw - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22655009 - March 2020 (4 comments)Excalidraw – Sketch Hand-Drawn Like Diagrams - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22146973 - Jan 2020 (6 comments)Excalidraw – a whiteboard tool to sketch hand-drawn diagrams (excalidraw.com) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22104502 - Jan 2020 (3 comments)Excalidraw – a whiteboard tool that lets you sketch hand-drawn diagrams - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22101381 - Jan 2020 (21 comments) reply azeemba 8 hours agoprevI like excalidraw for live discussions but if I want to make more detailed or better looking diagrams, I really enjoy these two tools:- For drag-and-drop&#x2F;WYSIWYG, I really like DrawIO. They have a web version https:&#x2F;&#x2F;app.diagrams.net&#x2F; but I strongly recommend the desktop version https:&#x2F;&#x2F;github.com&#x2F;jgraph&#x2F;drawio-desktop&#x2F;releases&#x2F;- For text-as-diagram, I think Mermaid wins this by default since GitHub added markdown support for these: https:&#x2F;&#x2F;mermaid.live&#x2F; (This was github&#x27;s announcement https:&#x2F;&#x2F;github.blog&#x2F;2022-02-14-include-diagrams-markdown-fil... ) reply dilawar 7 hours agoparentkroki.io maintains a collection of text to image tool. niolesk is a great frontend for kroki.Love plantuml as my goto for diagram-aa-code.Yesterday I learnt about d2lang. It looks better as a language. Nothing beats TiKZ when it comes to look of diagram. reply VTimofeenko 8 hours agoprevLove the tool, been using it for several years now for live whiteboarding. A self-hosted version integrates really well with org-mode through org-excalidraw witg kroki-cli used for svg rendering reply cybrox 8 hours agoparentSame. I&#x27;ve also used it for quite a few larger pieces of work in the last few years and was very happy with it.The handdrawn-looking but still tidy diagrams really give a 100+ page document a more approachable feel when used consistently than other more \"sterile\" diagrams. reply moribvndvs 4 hours agoprevMy office is predominantly WFH. I’ve found that Excalidraw spans the divide between collaborative white boarding and traditional diagramming effortlessly.I can do back-of-the-napkin drawing sessions with my peers in realtime and flip that into c4, UML, and Balsamiq-style wire framing with very little effort, and little friction when pulling in both local team members and outside contributors. You can get a hell of a lot of mileage out of the free&#x2F;oss offerings, but if you use it consistently with a small team Plus is a slam dunk. My office has fought tooth and nail over collaborative tools like this for years and got little traction, when I threw Excalidraw at ‘em it was like brandy on an infant’s gums: instant pacification and desired effect. I feel a little embarrassed fawning over it but it’s real fucking good. reply abledon 9 hours agoprevOne of the apps that acknowledges hotkeys are paramount to quick productive diagram making sessions. reply chatmasta 9 hours agoparentIt doesn&#x27;t have a command palette though, which has always surprised me... reply ccakes 2 hours agoprevI love Excalidraw but I feel like at some point recently the text inside a box aligns to the grid separately to the box it’s in. The effect being that drawing a box, writing in it then dragging it around breaks the alignmentIt’s still functional but my brain hates it reply replete 9 hours agoprevThe excalidraw plugin is one of the best in Obsidian. Very good for note-taking reply rosquillas 9 hours agoprevGoogle Cloud made an architecture diagram tool based on this reply esafak 8 hours agoparenthttps:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;topics&#x2F;developers-practitioner... reply j1elo 8 hours agorootparentWould have been nice to see the Google logo under the Sponsors list of Excalidraw, eh, Google?Would also have been nice their page even spelled it correctly... currently it says \"Exclaidraw project\" reply alexforster 8 hours agoprevI&#x27;m constantly DM&#x27;d at work about how I&#x27;m able to create the \"cool drawings\" in my blog&#x2F;wiki posts, and I enthusiastically point to excalidraw.com.I have a background in vector illustration, which is all about creating subpixel-perfect designs. I&#x27;m also a bit of a perfectionist, which I think a lot of people here can relate to. I mention this because the reason Excalidraw really works for me is that it frees me from worrying about design. When you literally can&#x27;t create something that looks \"perfect\", you&#x27;re freed up to just sketch your idea without worrying about the visual representation. reply sarchertech 8 hours agoprevI love Excalidraw before I switched over to an iPad Pro I was using it to do the illustrations for my book https:&#x2F;&#x2F;www.networksfromscratch.com&#x2F; reply jmarchello 8 hours agoprevThis tool is absolutely fantastic. I’ve used it for years and makes communication and thinking so much easier. I know that really applies to any diagraming tool but excalidraw is particularly simple with a non-existent barrier of entry. reply chrisweekly 6 hours agoprevExcalidraw is awesome. Also, if you&#x27;re into Obsidian (local filesystem markdown superpowers) its Excalidraw integration is fantastic. Drawings in your notes, notes in your drawings, whatever you want, however you want it. reply zekenie 8 hours agoprevi love this product and at one point wrote down why https:&#x2F;&#x2F;offbyone.us&#x2F;posts&#x2F;why-is-excalidraw-so-good&#x2F; reply Brajeshwar 8 hours agoprevFor those using Obsidian, the Excalidraw plugin plays really well within it.https:&#x2F;&#x2F;github.com&#x2F;zsviczian&#x2F;obsidian-excalidraw-plugin reply dmezzetti 8 hours agoprevIt&#x27;s a great tool. I&#x27;ve used it to design all my documentation for txtai.https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;txtai reply singhrac 7 hours agoprevLately I&#x27;ve been finding tldraw.com a better tool. I hope they don&#x27;t mess up the tool with changes to the license. reply mlhpdx 8 hours agoprevI have to agree this a a great tool. I had low expectations, but I found it easy to use and the AI diagram generator actually worked on my experiments. reply treesciencebot 8 hours agoprevExcalidraw itself is also pretty cool as an embeddable widget, we recently built a cool real-time AI-accelerated drawing playground [1] (source [2]) and the experience was super fun![1]: https:&#x2F;&#x2F;fal.ai&#x2F;dynamic [2]: https:&#x2F;&#x2F;gist.github.com&#x2F;turbo1912&#x2F;9f553287e64250790ac53baa03... reply pentagrama 7 hours agoprevLooks awesome! There is a way to install it as a Windows app and run locally? reply yodon 7 hours agoparentVS Code has a great Excalidraw plugin, as does Obsidian reply smcleod 6 hours agoprevHonestly Excalidraw got me back into being motivated to create more diagrams in my documentation.draw.io is a pain in ass at times and it&#x27;s just not \"fun\" to use like Excalidraw is.Highly recommend trying it out if you haven&#x27;t - you can also self-host. reply iJohnDoe 6 hours agoprev [–] Can this tool import JSON files to create diagrams, like tree or flow diagrams? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Excalidraw is an open-source virtual whiteboard for creating hand-drawn style diagrams and wireframes.",
      "Features include an infinite canvas, customizable tools, image support, and end-to-end encrypted collaboration.",
      "The Excalidraw.com app offers PWA support, real-time collaboration, and local-first functionality, while the Excalidraw npm package provides additional features. The project is sponsored and integrates with various platforms and services."
    ],
    "commentSummary": [
      "Excalidraw is a popular open-source drawing tool known for its collaborative features, user-friendly interface, and hand-drawn style.",
      "It is widely used for systems design interviews and remote collaboration, particularly by startups who appreciate its simplicity and focus on design.",
      "Google Cloud has even developed an architecture diagram tool based on Excalidraw, and users have recommended similar tools like DrawIO and Mermaid."
    ],
    "points": 139,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1701531946
  },
  {
    "id": 38499824,
    "title": "Unveiling Dark Patterns: Recognizing and Preventing UX Manipulation",
    "originLink": "https://dodonut.com/blog/10-dark-patterns-in-ux-design/",
    "originBody": "Blog / Design principles 10 Dark Patterns in UX Design and How to Avoid Them Sign up to our newsletter Author Alexander Varela Alex is a freelance UX/UI designer, content writer, and architect. Passionate about design in all its forms. Date added September 14, 2023 Read time 11 min Design principles UX Design Share this article To the top Dark patterns in UX design are manipulative tactics that deceive and trick users into taking actions that primarily benefit companies, often at the expense of the user's experience. Common dark patterns include confirmshaming, fake urgency, bait and switch, privacy suckering, nagging, sneaking, disguised ads, intentional misdirection, the roach motel pattern, preselection, price comparison prevention, trick questions, sneaking into the basket, friend spam, and forced continuity. These patterns exploit human psychology to drive profits but can harm user trust and engagement. To avoid dark patterns, designers should prioritize transparency, user control, and ethical design practices, fostering positive user experiences and long-term customer loyalty. Table of contents: What Are Dark Patterns in User Experience? What are the common types of dark patterns? Confirmshaming Fake Urgency and the Fear of Missing Out Nagging Sneaking Disguised Ads Intentional Misdirection The Roach Motel Pattern Preselection Friend Spam Negative Option Billing or Forced Continuity How to Avoid Dark Patterns in UX Design Conclusion What Are Dark Patterns in User Experience? A dark pattern is a term created by designer Harry Brignull. These patterns urge or persuade the user to perform actions or accept conditions they did not intend to. Companies use them to trick users into doing things that can bring them profits. For example, some dark patterns trick users or pressure them to buy additional items, subscribe to newsletters, or spend more time on an app. Designer Sally Woellner, as part of her TED talk about Dark Patterns, calls them “worryingly effective,” and this is because they are. They focus on human psychology and marketing to hit the user’s most primitive emotional and neurological response. Dark patterns are not present in user experiences by mistake. They are carefully crafted to appear during a certain moment of the user interaction process. Sometimes, there are design errors, and, by mistake, the interface or user flow happens to benefit the company and confuse or mislead the user. But when companies realize this creates a benefit for them and then intentionally keep it that way, it becomes a dark pattern. Why do people fall for dark patterns? Users often fall for dark patterns because of emotional or contextual ‘triggers,’ such as: Fear of missing out (your friend tagged you in this post; open the app to check it out!), Sunk-cost fallacy (having to accept terms and conditions or subscribing to newsletters to finish a signing-up process) Frustration (desisting from actions that are hidden or unnecessarily complicated). Confusion (ambiguous or hidden content or results from actions). Guilt (\"Are you sure you want to leave? Your friends will miss you!\"). This newsletter subscription is extremely ambiguous and poorly written on purpose. If dark patterns are bad, why do companies use them? At this point, it’s common to think: Why would companies use them in the first place? And you won’t be surprised to learn that the answer is money. Industries generate more profit by creating a user experience that manipulates users to buy more, stay longer, or invite their friends to use their platforms. This usually only works in the short term, often at the expense of creating a frustrating experience. People remember bad experiences and negative emotions rather than positive ones. “We receive negative or bad information more quickly, process that information more thoroughly, and remember and respond to that information more swiftly and consistently than is the case for positive or good information.” — Howard Lax, Bad is Stronger than Good: Lessons for Customer Experience and Employee Engagement (and Life) LinkedIn (2018) What are the common types of dark patterns? Let’s discuss some of the most common dark patterns in UX and what to do instead. Confirmshaming This is one of the most common dark patterns. Confirmshaming means appealing to emotional blackmail to persuade people to confirm or stop actions from taking place. It’s okay to ask users if they are aware of and wish to proceed with their decisions. However, the wording and the way that it is presented can quickly turn into a dark pattern. For example, the platform Duolingo sends you an email with their signature pet (an owl) crying. This is one of the most universal -yet effective- communication methods: showing sadness or vulnerability. We know an owl can’t feel sad because we’re leaving a service. Most importantly, we know the owl is not even real! However, there is something that goes beyond logic and goes straight to our emotional core. According to The Verge, they have even redesigned Duolingo’s signature pet over the years to widen their (apparent) facial expressions and cause an emotional reaction. You made our digital drawing resembling a bird sad. Fake Urgency and the Fear of Missing Out Similarly, creating fake urgency is another typical dark pattern in UX. Dark patterns focus solely on the interest’s company while disregarding the user’s interest. However, they use wording and emotional manipulation to present this urgent notification as something valuable to the user. Most social media platforms nowadays create this fear of missing out (FOMO) by hinting that something is happening within the app but without explaining in detail what that means. A good example is a notification along the lines of “Your friends miss you” or “You have been invited to an event” to encourage you and find out what this is. Once you click or tap on the notification, you are inside the app, and it can show you endless content and make you stay for hours. We all know and understand that companies want their customers to spend as much time as possible on their apps. But this gets out of scale often, and in reality, it invades the user’s lives while providing very little value. Facebook lets you know many things are happening right now, they just won’t tell you what those are. Source: Reddit Nagging Nagging is, in other words, not accepting a ‘No’ for an answer. The most obvious example is suggesting premium subscriptions or newsletters but without allowing the user to refuse permanently. Replacing the “No” option with a “Not now,” “Not yet,” or “Maybe later” removes the choice from the user to benefit the company. The user, eventually, may accept those conditions because they give up in a way after the platform has nagged them once a day, for example. This example shows nagging and contact theft. Source: Chris Oliver / Medium Sneaking Also called obstruction, sneaking is the act of including a secondary action in the middle of (usually towards the end of) a primary action. The user wants to complete the primary action but is not entirely aware of or is manipulated into accepting the secondary action. In the past, companies, mostly from e-commerce, have already used sneaking to include additional cheap products (such as mugs) or hidden costs in the final step of the action. Because the additional amount is so small, most users won't complain or ask for a refund. The Deceptive Patterns page has talked about this in the past with the Sports Direct case. Companies can (and should) suggest items that may be valuable to the user, either by common sense or by data (e.g., items that users buy in tandem). But it becomes a dark UX pattern when they outright place products or services that the user does not care for, and would have never thought of getting them otherwise. Sports Direct used to put an extra £1 mug on their customer’s online baskets. That is now illegal. Disguised Ads Social media sites disguise ads very easily nowadays because they present the content, as cards or “blocks” with infinite scrolling. This allows them to “sneak” an ad seamlessly and present it as another post. They disclose the fact that they are including ads, but in a very discreet way that goes unnoticed. The user ends up confusing ads with the “real” content they want to see. This often causes the user to end up on a different website than intended. Other times, they just end up viewing content they are not interested in, or that provides no value. Disguised ads cause confusion because the user doesn’t know which one is the ‘real’ download button. Intentional Misdirection Intentional misdirection is the use of visual or text content that creates an outcome that is ambiguous, vague or, even worse, the opposite of the desired or expected outcome. Let’s think of an example: a user wants to cancel a subscription to a newsletter. When asking to confirm this action, a button with the word ‘Cancel’ may have two meanings: either ‘confirm’ the cancellation or ‘cancel’ the cancellation. This can happen by unintentional or poor wording or visual indicators (color, shape). Nextdoor’s unsubscribe panel has an ambiguous switch button. The Roach Motel Pattern We see the roach motel pattern when actions that benefit the company are sometimes intuitive, enticing, and even pushy. Conversely, actions that benefit the user and not the company are complex, ambiguous, and tedious. Companies often use this pattern to ‘lure’ the user into taking an action by confusing or manipulating them. They make this process extremely smooth and direct; once they perform those actions, it’s hard to cancel or undo them. In most companies, subscribing to a newsletter is easy, straightforward, and pointed out with a big CTA. However, unsubscribing is done via email, and users need to find the word Unsubscribe with a small, gray font that goes easily unnoticed. Even after users try to unsubscribe, they are asked to confirm several times and fill out surveys that discourage them from continuing this process. Sometimes, they even need to make a phone call or even go to a physical office. Amazon’s users have had issues when canceling their Amazon Prime subscription, and with deleting their accounts as well. In fact, the company recently had to simplify the process required for canceling their Prime membership, to meet EU regulations. Amazon Prime puts endless barriers to canceling a membership. Source: Martyn Reding / Twitter Preselection We see this dark pattern often in conjunction with the roach motel pattern. With preselection, users aren’t even enticed or manipulated into taking actions: the platform already ‘pre-selected’ these actions for them. Again, this pattern applies to actions that benefit the company and that users wouldn’t usually choose by themselves. With preselection, users end up subscribing to newsletters or getting premium travel insurance without noticing, for example. When the company creates actions that only benefit them and not the user, it should be completely up to them to agree to that action after being informed of the possible benefits and conditions. Pre-selected newsletter sign-up checkboxes are illegal in the EU. Friend Spam Companies use friend spam to manipulate users into giving them social media permissions and access to their contacts. They often disguise this action as ‘inviting your friends’ or similar actions that seem to offer a positive outcome to the user. IIn 2013, LinkedIn received a lawsuit for harvesting some of their user’s contacts, going as far as sending an email on the user’s behalf to all the people in their email contact list. This could go anywhere from their boss to a friend from high school. LinkedIn’s infamous friend spam. Jonathan Shariat speaks about this experience in his book: “I will never forget how I felt when LinkedIn tricked me into inviting everyone on my Gmail contact list to join. Gmail adds to this list anyone that you’ve ever emailed—so it sent invitations from me to everyone I had emailed since I first created my email account five years prior. It was terrible! My contacts included old teachers, customer service representatives, business contacts, extended family, and many others who did not appreciate the spam it sent out on my behalf. I felt embarrassed and betrayed.” — Jonathan Shariat and Cynthia Savard Saucier, “Tragic Design”, O’Reilly Media 2017 Negative Option Billing or Forced Continuity With this another dark pattern, companies manipulate the user into giving their billing data or information, sometimes even promising a free trial or a discount in exchange for a product or service. With time, they start charging a recurring billing or subscription with no chance to opt-out. They use wording and manipulation to assure the user they won’t be charged anything right now. They start charging money after a month or two when the user forgets the subscription. In UX, it’s important to give the user control and freedom to the actions taking place on the platform. If these actions involve billing, it’s even more critical. This can be fixed easily by emailing the user to let them know they will start charging money 3-5 days before the end of the free trial. This is a (potentially) dark pattern. Warning the user they are going to be billed a few days beforehand would be a significant improvement to the user experience. How to Avoid Dark Patterns in UX Design If we want to avoid dark patterns and deceptive design, we need a good combination of research and common sense. Following research data to avoid Dark Patterns Competitive Analysis: For research, it's essential to be aware of the competition. What are some good examples of UX from similar platforms? Do their users complain about UX dark patterns? How do they convince users to subscribe to newsletters or buy their products or services? User Testing is a great way to detect design errors that can potentially become dark patterns and also to see how users react to the wording, interface, and user flow (e.g., suggesting a premium subscription is too pushy or the wording makes them feel manipulated). Following common sense to avoid Dark Patterns As designers and users of digital products, it’s safe to say we have increased our attunement and common sense over time. Platforms usually have similar dark patterns because they share similar goals: sell a product, offer a service, or increase outreach (e.g., newsletters, followers). Here are some common sense tips to avoid dark patterns in UX: Be transparent with the user to earn their trust and give them control and freedom to make an informed decision before taking an action. Test and iterate your product until there’s a balance between the user’s and the company’s best interests. Follow the best design principles and usability heuristics to keep the design user-centered and avoid common mistakes. Create design patterns that benefit the user, even if it harms the company. At some point, the user wants to feel valued and heard and that they control the platform, not the other way around. There are many ways to make the user feel valued and heard, even if it doesn’t directly benefit the company. YouTube included two reminders to take a break and close the app every X minutes and also a bedtime reminder to stop using the app between 11 p.m. and 8 a.m., for example. The YouTube app encourages users to take breaks from the app to balance their experience and avoid burnout. The YouTube mobile app includes tools to manage time spent on the app. Even though the platform encourages the user to spend more time, these reminders help balance the user’s experience and avoid burnout. Ryanair has a dark pattern history, hiding their “Don’t insure me” option inside an unrelated dropdown menu. This was heavily criticized in the past and is now illegal in the UK and the European Union. Since then, they have changed it for a much more friendly user interface. With these strategies, users will leave a genuine, positive impression. This leads to satisfaction, positive reviews, and profit in the long term. Also, it helps to create more sustainable websites because it reduces content on a website, emails, newsletters, and unnecessary information in general. Conclusion We all know that companies want to make money by offering products and services, and there’s nothing wrong with that! But there’s a difference between inviting the user to interact with the platform in a certain way while still giving them a positive experience and pressuring the user to do things that do not benefit them or punishing them for acting in a way that does not benefit the company. Companies can find several reasons to avoid dark patterns. By following best design practices, they can build a positive brand image, maintain customer trust, and adhere to legal and ethical standards. In a long-distance it promotes transparency and a long-term focus on customer satisfaction and loyalty, ultimately benefiting the company's growth and sustainability. As UX designers, it’s not easy to balance out company profit and positive user experiences. Sometimes, we don’t even notice the design process we create causes frustration and even makes people lose money. But by learning more about dark patterns, we can understand further how to avoid them and enhance the user experience. After all, we can always strive to be more transparent and ethical to our target audience and, why not, to ourselves as well. References Brignull, Harry (2023). Deceptive Patterns: exposing the tricks tech companies use. Testimonium Ltd. Royal-Lawson James and Axbom, Per, hosts. “#150 Dark Patterns with Harry Brignull”. UXPodcast. February 03, 2017 Shariat, Jonathan and Savard, Cynthia (2017). Tragic Design: the impact of bad design and how to fix it. O’Reilly Media. Woellner, Sally (2021, November). Dark Patterns: How design seeks to control us. TedxSydney. Retrieved August 01, 2023 See all dodonut.com references Author Alexander Varela Alex is a freelance UX/UI designer, content writer, and architect. Passionate about design in all its forms. Date added September 14, 2023 Read time 11 min Design principles UX Design Share this article To the top",
    "commentLink": "https://news.ycombinator.com/item?id=38499824",
    "commentBody": "Dark patterns in UX design and how to avoid themHacker NewspastloginDark patterns in UX design and how to avoid them (dodonut.com) 124 points by night-rider 17 hours ago| hidepastfavorite55 comments karaterobot 14 hours agoThis article shouldn&#x27;t be addressed to designers, it should be addressed to product managers, or to leadership who sets OKRs. The issue is not designers not knowing this is wrong, or being able to think of alternatives. The issue is not that the designer, on their own initiative, decides to make a user-hostile product. The issue is that product teams are being strongly incentivized or even directly ordered to implement dark patterns like this. If it was just the designer calling for the use of dark patterns, and everybody else in the organization was against it, it wouldn&#x27;t happen. Likewise, if the designer is the only one in the organization who advises against it, guess what? It&#x27;s happening anyway. reply MaxBarraclough 13 hours agoparentAgree. The article even states:> Dark patterns are not present in user experiences by mistake. They are carefully crafted to appear during a certain moment of the user interaction process.Despite this, there&#x27;s a section named How to Avoid Dark Patterns in UX Design. This section doesn&#x27;t really deliver on its title, as of course the real answer is that you simply don&#x27;t adopt dark patterns.Most of the article is a tour of the most common dark patterns. The 10 Dark Patterns in UX Design part is fine, but the and How to Avoid Them part doesn&#x27;t make much sense. reply RecycledEle 12 hours agoparentprev\"OKR” stands for Objectives and Key Results. OKRs are an effective goal-setting...Source: https:&#x2F;&#x2F;www.whatmatters.com&#x2F;faqs&#x2F;okr-meaning-definition-exam... reply yawnxyz 11 hours agorootparentif you set aggressive goals, people will start cheating or abusing a system to hit those goals reply handy2000 7 hours agorootparentIt&#x27;s really not about aggressive goals. OKRs are always tied to a single metric (in some cases secondary metrics exist, too). So if no one on the team has a strong ethical compass, the way that goal is reached is not a concern, the only thing that matters is reaching that goal. At every step the participating roles would bump the responsibility to think about the ethics of the proposed solution to the next role in the process. So at the end, no one cares or speaks up because the ethics are not embedded in any process, and are not included in OKRs. reply mitthrowaway2 13 hours agoprevI think dark patterns mostly work against the long-term interests of the companies that deploy them. But a big problem is that dark patterns drive measurable benefits but are associated with unmeasurable costs. So metrics-driven teams can end up deploying them to the long-term detriment of the company itself. Management needs to ensure that teams are not sacrificing intangible soft capital in order to meet measurable goals.For example, a dark pattern might increase subscription conversion rate, time spent on a page, and so on -- which can be directly measured and appear in OKRs -- but may also result in people developing negative associations with your brand and gradually avoiding visiting your site in the first place, when they see it in a linked URL.Think of a website that is relatively free of dark patterns -- maybe McMaster-Carr or something -- and notice how often you might find yourself looking there first. That&#x27;s good-will, a valuable but ephemeral resource which is be very hard for a company to quantify, and therefore easy and tempting to spend down in pursuit of short-term gains. reply ProxCoques 13 hours agoparentI&#x27;m a UX designer who has worked at large online brands for the last 15 years and I completely agree with this. For all the millions companies spend on \"analytics\", they have no ability to measure the effect of any given design intervention over anything more than the duration of a test. So they don&#x27;t care - because they can&#x27;t.As a designer, you have to accept that. If a design you know customers hate has shown a positive effect for the business (and no, they don&#x27;t re-test these things - it&#x27;s first past the post my friends), then that design is there to stay. You can try your best to persuade everyone otherwise, but only the law courts can save you.This, along with the usually quite early realisation that the people you work for couldn&#x27;t tell a good design if it exploded in their custard, is probably about the worst thing about working as a designer in a commercial context. Just about. reply handy2000 7 hours agorootparent> they have no ability to measure the effect of any given design intervention over anything more than the duration of a testIt&#x27;s actually pretty common to have a holdout group that&#x27;s basically a long term control group for a series of experiments. This way companies are able to measure long-term impacts, including negative ones. reply ProxCoques 1 hour agorootparentAre we talking about the same thing? Not only have I never encountered any business back-testing experiments in any way, but purposefully running \"losing\" variants on a percentage of traffic would be anathema. reply esafak 10 hours agoparentprevThat&#x27;s the quantitative fallacy: that which can&#x27;t be measured easily doesn&#x27;t matter.To be clear, long term effects can be measured, but they typically aren&#x27;t because it&#x27;s more complicated, expensive, and capable of disproving hypotheses, blocking promotions.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;McNamara_fallacy reply arun-mani-j 13 hours agoprevLinkedIn deserves an entire article to list their each and every dark pattern. Some of the few that come to my mind:- Asking you to install app when browsing from mobile (which goes away when you use \"Desktop Mode\").- Saying that you have a message in your inbox but not the very message itself.BTW, Do we have an open source alternative to LinkedIn like there is Mastodon to Twitter? :(Another teeth-biting favorite is Adobe&#x27;s \"free\" online tools (like PDF pages splitter etc.) where you will be able to do everything and once you click \"Download\", Adobe asks you to create an account to continue. :&#x2F; reply andersrs 12 hours agoparentLinkedIn cannot hold a candle Booking.com and their artificial scarcity fear mongering. reply yawnxyz 11 hours agorootparentjust tried Booking.com the other day and seems like... most of those have gone away? Or maybe they&#x27;re gone in Australia b&#x2F;c of the consumer protection laws here? reply andersrs 14 hours agoprevIt&#x27;s the e-commerce equivalent of putting the finger on the scale. Maybe there should be some laws against it but can you imagine politicians understanding any of this? Every undo action such as un-subscribing should be equally as easy as the original action.Neal.fun has an entire page of dark patterns in one demo: https:&#x2F;&#x2F;neal.fun&#x2F;dark-patterns&#x2F; reply Nextgrid 12 hours agoparentPoliticians understand this very well, in the sense that every time there’s wind of pro-consumer regulations, companies are happy to spoil the politician in money and benefits if he stands against said regulation. reply SPBS 14 hours agoprev> Companies can find several reasons to avoid dark patterns. By following best design practices, they can build a positive brand image, maintain customer trust, and adhere to legal and ethical standards.I don&#x27;t think Amazon Prime or New York Times making it hard to cancel subscriptions is putting a dent in their brand image. Big companies can and will get away with it. reply charlieyu1 14 hours agoparent> I don&#x27;t think Amazon Prime or New York Times making it hard to cancel subscriptions is putting a dent in their brand image. Big companies can and will get away with it.People should complain more and there should be more outrage. This is one of very effective way to keep the big companies in line. We are in a society that discourages complaining even if it is completely justified. reply ghostpepper 13 hours agorootparentI&#x27;m a paying subscriber to NYT but if I click a link when I&#x27;m not logged in, this is what I get:A screen that tries to offer me an introductory rate with a big subscribe now button and a small log in link. When I click log in,A username form only - ie. no password form until I&#x27;ve submitted my username, which means I need to invoke my password manager twice. Then before I see the original articleA fullscreen modal wanting me to upgrade my subscription to get \"All of the times\" which includes News, Games, Cooking, Wirecutter and the Athletic (no pricing info), just a big Upgrade Now button or a small \"continue without upgrading\" linkbefore finally allowing me to access the article. reply handy2000 7 hours agorootparent> A username form onlyThis is such an annoying pattern that was adopted by almost all websites. It almost always breaks password managers (requiring 2 invocations). I guess it \"helps\" people who can&#x27;t differentiate between \"log in\" and \"sign up\"... at the cost of annoying everyone else. reply handy2000 7 hours agoparentprevI read about Prime being hard to cancel several times now. It&#x27;s not harder than any other membership. It feels weird defending Amazon, but just go to your Account, you will see a large card right at the top saying Prime. Click that, on the next screen, again, right at the top it says \"Membership. Update, cancel, and more\". Click that and it will open a large popup with the End membership button.Yes, it&#x27;s true, that on the next screen it will tell you how much you saved using Prime and will offer to look at other plans or to continue cancelling. So this screen is sort of a dark pattern, I guess. Even then, privacy-oriented companies like Proton show a similar upsell screen on cancellation.Overall Prime cancellation is very straightforward, compared to scummy companies that require you to email or call them to cancel membership. Unless the (unreasonable) expectation is that the CANCEL PRIME button should be front and center on every page on amazon.com. And clicking it should immediately cancel the membership without any confirmation.Edit: the shaming element of the cancellation process was removed by Amazon long time ago. reply alentred 14 hours agoprevKudos to the author for actually pointing these out. A lot of those are the patterns that everyone got used to: they can be seen universally across the Internet, and some have been used for so long that it is probable that many users (and developers, and designers) don&#x27;t even realize they are the dark patterns. Some are of course used intentionally, but I would guess some of the new web sites and web apps use them \"just because everyone else does it\".Unfortunately for us, there is no easy solution, though. I think that the suggested solutions are too lightweight to be convincing, although I agree with the general idea: do your research, get the real competitive advantage. But this is easier said than done, while the dark patterns are easier to use. Like the Dark Force. Not sure the Force wins in real life eventually, but I surely hope so. reply aidos 13 hours agoprevI had a lovely one the other day when trying to contact FreshWorks support. I just want to cancel an account but as far as I can tell they’ve sunset the service so I’m forced to go through the support process.I couldn’t even submit the form without ticking the following:> I would like to receive marketing communications related to Freshworks&#x27; business, services, and events. I can unsubscribe from these communications at any time.The only email I’ve received since has been a fake real sales email with no unsubscribe link. reply oooyay 14 hours agoprevAre there folks who work on front ends and in design here who have been explicitly told to implement these? reply pstorm 13 hours agoparentThese are tame compared to some of the stuff I have been tasked with at a previous company. I don&#x27;t want to go into specifics really, but I can tell you that it sort of became normal. Should we test out defaulting the newsletter checkbox? Sure, oh great, it improved newsletter conversions! Should we show a fake \"X amount of people viewed this product\"? Sure, if it works we can actually implement it! Etc. etc.Until I was outside of the culture of the company for a bit, I didn&#x27;t see any issue. Improvement of metrics was all that mattered. reply mock-possum 13 hours agoparentprevI was doing some contract work with an ad agency, client was Cisco, and part of the site was a ‘sign up for this thing’ page - and of course they wanted the ‘subscribe to promotional emails’ box checked by default when the form was presented to the user.And I was like - nobody actually likes that though. Nobody likes that, people resent it, it’s basically a way to trick people into giving you permission to send them spam.Everyone kind of laughed and agreed, but the account supe was like “yeah, but it’s what the client wants, so”Tech lead was walking past my desk on his way out at the end of the day, and he was like, “the thing about the subscription box? Let’s just ‘forget’ to do it and see if anybody notices.”Seemed like a good thing to do, so we did - but it came back as a QA ticket, and we deprioritized it, until finally the account guy swung by my desk and was like, “I know we don’t like the checkbox thing, but we do actually need to do it.”And I was like alright fine I’ll do the checkbox thingwah-wah. reply sanitycheck 13 hours agorootparentI don&#x27;t even bother raising it as a problem these days. More effective is to implement it exactly as specified so the designer is happy and the the managers are happy and the client is happy.Then a month or so later, \"accidentally\" introduce a regression. Oops, the checkbox isn&#x27;t checked by default any more! Nobody is thinking about it by then, nobody is checking it, and nobody will notice. reply oooyay 13 hours agorootparentSmells like https:&#x2F;&#x2F;grugbrain.dev&#x2F;#grug-on-saying-ok reply handy2000 7 hours agorootparentprevI had success in the past hampering the process by linking to various legislations (e.g. GDPR, CCPA) and asking my PM to reach out to legal to approve the implementation. At larger companies legal is usually pretty cautious and takes a very long time to respond. reply russelldjimmy 16 hours agoprevIt feels to me like the author compiled a list of 10 things that annoyed them the week prior, gave each of them an important sounding name and made an article of it.Not that I support any of these patterns, but there’s a reason companies do them. Just telling someone to not do them will not stop companies from doing them. reply arendtio 14 hours agoparentSounds like you want more sources to prove that the author didn&#x27;t make up that term ;-)Obligatory Wikipedia page: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dark_patternA study about dark pattern usage from my bookmarks: https:&#x2F;&#x2F;webtransparency.cs.princeton.edu&#x2F;dark-patterns&#x2F;The page I have always in my mind when the term comes up: http:&#x2F;&#x2F;darkpattern.org -> redirects to https:&#x2F;&#x2F;www.deceptive.designJust for fun (it has some gems): https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=false&qu...From the results: &#x27;I was let go for refusing to deploy a dark pattern&#x27; https:&#x2F;&#x2F;www.peachesnstink.com&#x2F;p&#x2F;6pJoCuczOj8cxCUQDMlfQv reply timeon 15 hours agoparentprev> there’s a reason companies do themYes modern UX (or what we just call &#x27;UX&#x27;) is based on dark patterns and psychological manipulation. Even something as innocent as gamification is manipulation exploiting same thing as gambling. So yes there is reason companies doing them: trapping user. reply klabb3 16 hours agoparentprevHonestly I think this content is a bit educational for us techies, but yes, it’s mostly just “business as usual” these days.However, if this type of content was aimed towards grandmas, boomers, etc it could have a huge positive effect. The people most susceptible to dark patterns are those who don’t know better.As I’ve written in another comment, my mom has needed help to make “her computer work again” after Microsoft has changed her default browser to edge. It happens (seemingly) on every meaningless update.It should be illegal. reply unconed 14 hours agoparentprevYes, they do them because they are scummy.\"Maybe later\" is the best example.No excuse for this other than them refusing to understand.Which is why, when companies try to apply dark patterns to you, you should bug the fuck out of their support channel.Slack changed the design again to push features you never use? Ask support how to get the old design back. Be incessant. Act like it&#x27;s the most sensible possible request and they are just not getting it. reply lopkeny12ko 14 hours agoprevThe premise of this article makes no sense to me. It&#x27;s suggesting that one needs to actively expend effort to avoid \"accidentally\" implementing dark patterns. You could just...not build them. If I click yes, I mean yes, if I click no, I mean no--it&#x27;s more complex for developers and designers alike to add friction to that flow. reply handy2000 7 hours agoparentMy guess is that the author chose to approach this in a softer way, without shaming the designers. He is leaning into education without assuming bad intent.Not going to lie, this might be more effective than shaming designers. reply tempodox 15 hours agoprevIt&#x27;s not like dark patterns happen by accident. I don&#x27;t think perpetrators have any interest in avoiding them. reply GuB-42 15 hours agoparentYes, that&#x27;s the difference between dark patterns and regular anti-patterns. reply charles_f 16 hours agoprevMurder weapons in daily life and how to avoid murdering people.Step 1. Murder weapons allow to murder people. Murdering is bad.Step 2. Avoid using murder weapons to murder people.Next week: Manipulative techniques in psychology and how to avoid manipulating people. reply danjc 17 hours agoprevA great unpacking of dark patterns but it&#x27;s not exactly like you&#x27;ll accidentally build them yourself. reply cuu508 16 hours agoparentYou can accidentally lull yourself into thinking a particular pattern is not so bad when everyone does it and growth hackers recommend it with a straight face. Calling them out removes [any potential] ambiguity. reply Version467 16 hours agoparentprevI actually wouldn’t be too sure about that. Some dark patterns have become so ubiquitous that a new developer might just think that that’s the way to implement certain features. reply FinnKuhn 15 hours agoparentprevsome of them look like someone just didn&#x27;t think it all the way through, for example the nextdoor email unsubscribe switch would have been clear had it been a checkbox or with clearer wording, but only in combination it is unclear. reply rabbits_2002 17 hours agoprevyou can avoid them by not being a horrible person reply arendtio 14 hours agoparentSadly, it is not that simple. E.g. if your boss wants to see the numbers, and the dark pattern performs better. Just yesterday we discussed how the &#x27;business&#x27; trumps the &#x27;user&#x27;: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38483181Sometimes, measuring long-term effects might be an option, but that might also not help. I am still in favor of fighting for a good UX, but you should not categorize everybody as a horrible person who builds such crap (even though I want to too) ;-) reply adamjc 16 hours agoprevDark patterns are never accidental. reply 6stringmerc 13 hours agoprevBumble&#x27;s platform is a Dark Pattern.OnlyFans is a Dark Pattern via Tools.It needs a new name. It&#x27;s not a Dark Pattern if so many firms are employing it successfully for profit.Obviously the community isn&#x27;t self policing. Cartels do a better job down in Mexico overall in my opinion. Rather it&#x27;s clear the incentive in this sector in particular (new tech &#x2F; apps) only leads to further development and twisting and bending into it becoming normalized somewhat or somehow.See also: the success of microtransactions and who made money on them reply jzombie 16 hours agoprevIf a newsletter subscription really has a \"don&#x27;t not opt in\" checkbox, I can&#x27;t imagine how horribly worded and confusing the actual crappy freaking newsletter must be. reply n8cpdx 15 hours agoprevAside: I absolutely adore the design of this website. I’ve tried to do something like it in my personal projects, but I’m not a designer and it always comes out as the wish.com version. Props and respect.Serious: I think this actually highlights the importance of ethics as a field of study for everyone going into computing&#x2F;software&#x2F;information work professionally.I don’t think any of us want to live in a world where our computers are lying, tricking, deceiving, fooling, shaming, or manipulating us. Yet so many of us ignore the ethical implications of our work to make a quick buck.It is clear as day to me that these things are wrong. It wasn’t always like that. In college I thought the idea of teaching ethics was stupid, and we should do whatever we can to fuck people over (I wouldn’t have used those terms). I don’t know why I grew out of that, but I did, and I think the world might be better off if the people who knew better intervened earlier in people’s careers.This is your sign to reflect on how many times you have been an enemy to your fellow man through your work (and if your work scales, an enemy to thousands to billions of people), and start your job search if that number bothers you. reply matchbok 16 hours agoprevFunny that this website has the ever-annoying scroll indicator. Why don&#x27;t web designers understand we already have a scroll indicator? It&#x27;s called the scroll bar. There is literally no function for these things. reply FinnKuhn 15 hours agoparentHad the scroll indicator in the heading excluded the massive footer might have offered something of value, but with this lazy implementation ist shows that you haven&#x27;t finished the article even though you have and only completes when you scroll through the giant footer. reply lopkeny12ko 15 hours agoparentprevI take it you&#x27;ve never used a Mac, for which--by Apple&#x27;s infinite wisdom--scroll bars are not visible by default.It&#x27;s one of the most asinine design decisions (of many more) of Macs, and leads to web designers adding equally asinine scroll indicators on websites. reply butz 14 hours agorootparentWe should probably add \"scrollbar\" to @supports CSS queries to fix that. reply arpowers 15 hours agoprevThis article should be called “how to get fired as a UX designer” reply amatecha 14 hours agoparent\"How to get fired from an unethical employer because you didn&#x27;t create the manipulative designs they expected\" and&#x2F;or \"how to surface whether your employer is garbage and you should start looking for a better place to work\". :) reply butz 14 hours agoprev [–] Talking about dark patterns: what is \"Statsy\" and why is it trying to send out \"a beep\" every second? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dark patterns are manipulative tactics used by companies in UX design to deceive and exploit users for their benefit.",
      "Common types of dark patterns are identified, and their exploitation of human psychology for profit is explored.",
      "The article emphasizes the importance of transparency, user control, and ethical design practices in avoiding dark patterns and maintaining user trust and engagement."
    ],
    "commentSummary": [
      "Dark patterns in UX design have a negative impact on user experience, as discussed in this article and comment thread.",
      "Examples of dark patterns used by companies like LinkedIn and Adobe are highlighted, along with strategies to avoid or undermine them.",
      "The conversation emphasizes the importance of ethics in the technology industry and the frustration caused by certain design decisions."
    ],
    "points": 124,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1701535250
  }
]
