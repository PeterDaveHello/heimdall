[
  {
    "id": 38345858,
    "title": "YouTube Slows Down Video Load Time for Firefox Users, Sparking Concerns of Antitrust Abuse",
    "originLink": "https://old.reddit.com/r/youtube/comments/17z8hsz/youtube_has_started_to_artificially_slow_down/",
    "originBody": "jump to content my subreddits edit subscriptions popular -all -random -usersAskReddit -gaming -funny -mildlyinteresting -pics -worldnews -todayilearned -movies -explainlikeimfive -news -aww -videos -DIY -space -Music -TwoXChromosomes -OldSchoolCool -nottheonion -LifeProTips -Showerthoughts -dataisbeautiful -gifs -tifu -books -Jokes -Futurology -askscience -science -sports -IAmA -food -UpliftingNews -history -nosleep -EarthPorn -photoshopbattles -WritingPrompts -creepy -Documentaries -InternetIsBeautiful -announcements -gadgets -philosophy -GetMotivated -listentothis -blog more » reddit.com youtube comments other discussions (3) Want to join? Log in or sign up in seconds.| English limit my search to r/youtube [-] use the following search parameters to narrow your results: subreddit:subreddit find submissions in \"subreddit\" author:username find submissions by \"username\" site:example.com find submissions from \"example.com\" url:text search for \"text\" in url selftext:text search for \"text\" in self post contents self:yes (or self:no) include (or exclude) self posts nsfw:yes (or nsfw:no) include (or exclude) results marked as NSFW e.g. subreddit:aww site:imgur.com dog see the search faq for details. advanced search: by author, subreddit... this post was submitted on 19 Nov 2023 8,741 points (98% upvoted) shortlink: remember mereset password login Submit a new link Submit a new text post Get an ad-free experience with special benefits, and directly support Reddit. get reddit premium youtube joinleave1,083,360 readers 3,764 users here now Welcome to /r/YouTube, a community for the intelligent discussion of YouTube as a platform - its announcements, features, bugs, and design. Please read the rules before posting. Related Subreddits /r/Google For discussion surrounding Google. /r/channelwatch Discover awesome new channels /r/YouTubeClassics Revisit your old favorite videos /r/DeepIntoYouTube Dive into YouTube's weird side /r/YouTubecomments Best/worst of YouTube comments /r/PartneredYouTube Ask about YouTube partners /r/YouTubers Get feedback on your videos /r/YouTubeGaming Discuss YouTube's gaming site More Information FAQ WIKI NOTE: This subreddit is unofficial (though there are YouTube employees present). Never give out personal information; employees will never ask for your login credentials! a community for 15 years MODERATORS message the mods discussions in r/youtubeX 6375 · 560 comments google when 2362 · 65 comments When youtube bans adblocks 2889 · 1156 comments We are so fucked 183 · 30 comments YouTube Has Gone Too Far This Time 65 · 3 comments New CEO, where are my Playlists? 137 · 6 comments Seems like it to me... 371 · 81 comments It's absurd that if you find a **horrible** channel that you can't block it. You have to reload the frontpage endlessly until it pops up, then block it. 49 · 41 comments What happened to all my playlists? 22 · 1 comment Multiple people in multiple places are saying this. The endless war on UBlock, then the Chromium changes to shut out some blocker functionalities, now this? These recent Google/YouTube policies, can't imagine that this is legal - how is this not anticompetitive? 70 · 3 comments \"Hello, I like money.\" Welcome to Reddit, the front page of the internet. Become a Redditor and join one of thousands of communities. × 8740 8741 8742 Youtube has started to artificially slow down video load times if you use Firefox. Spoofing Chrome magically makes this problem go away.Feature Change (v.redd.it) submitted 1 day ago by vk6_ 835 comments share save hide report Pause0:00 0:27 1080p HD720p HD480p360p240pAuto Settings Fullscreen Dismiss this pinned window top 200 commentsshow 500 sorted by: best (suggested) topnewcontroversialoldrandomq&alive (beta) Want to add to the discussion? Post a comment! Create an account [–]Jankenbrau 697 points698 points699 points 1 day ago (45 children) This should get sent to tech press and subs like /r/tech permalink embed save report reply [–]CatPlastic8593 123 points124 points125 points 20 hours ago (6 children) Not just the press. This is a clear cut EU antitrust abuse, the Comission needs to whoop some ass. permalink embed save parent report reply [–]GazelleNo6163 33 points34 points35 points 20 hours ago (2 children) I’m for a balance on government and corporations, the EU is providing some much needed balance back into this instead of being big tech hell. permalink embed save parent report reply [–]ThatDeveloper12 10 points11 points12 points 15 hours ago (1 child) I wonder what the EU will think of the next step. The whole reason google is doing this is to get people off firefox and onto chrome before rolling out their \"Web Integrity API.\" Under that system, only chrome and other browsers blessed by google (who agree to block adblockers and enforce DRM) can access websites. Everyone else gets blocked. https://arstechnica.com/gadgets/2023/07/googles-web-integrity-api-sounds-like-drm-for-the-web/ permalink embed save parent report reply [–]a_random_chicken 1 point2 points3 points 9 hours ago (0 children) Well, since the EU has gotten a lot of positive attention from the apple and microsoft cases, hopefully they will keep at it, knowing people love these interventions. But it is confusing to me why google would roll out these changes right after the apple and microsoft incidents. permalink embed save parent report reply [–]RandomAcc52 18 points19 points20 points 19 hours ago* (2 children) Really hope Alphabet hears those horns in the distance because oh boy its going to start to be louder and louder. We enter, drunk with fire motherfuckers. permalink embed save parent report reply [–]CatPlastic8593 1 point2 points3 points 17 hours ago (1 child) If you like Ode to Joy, my favorite version is still the one by the Vienna Philharmonic. permalink embed save parent report reply load more comments (1 reply) [–]Fusseldieb 161 points162 points163 points 22 hours ago (17 children) This is REALLY bad. Just shows what they're being up to. permalink embed save parent report reply [–]colemab[🍰] 99 points100 points101 points 21 hours ago (13 children) Yep, anti-competitive behavior that leverages a monopoly in one area to benefit a monopoly in another area. Anti-trust act say what? permalink embed save parent report reply [–]Bramble_Ramblings 6 points7 points8 points 19 hours ago (5 children) Happy Cakeday! permalink embed save parent report reply [–]colemab[🍰] 6 points7 points8 points 19 hours ago (2 children) Thanks! I didn't even realize! permalink embed save parent report reply [–]USNAVY71[🍰] 2 points3 points4 points 17 hours ago (1 child) Same cake day gang! Edit: you’ve got me by 1 year! permalink embed save parent report reply [–]Bramble_Ramblings 2 points3 points4 points 17 hours ago (0 children) HAPPY CAKEDAY DOUBLE TROUBLE! permalink embed save parent report reply [–]tired-space-weasel 1 point2 points3 points 18 hours ago (1 child) Pretty sure it says something else :D permalink embed save parent report reply load more comments (1 reply) [–]BicycleElectronic163 2 points3 points4 points 18 hours ago (0 children) happy cake day! permalink embed save parent report reply [–]gobitecorn 1 point2 points3 points 17 hours ago (0 children) Good luck getting the DOJ to get up off their laurels permalink embed save parent report reply [–]pimphand5000 1 point2 points3 points 17 hours ago (0 children) All of tech need anti-trust oversight with actual teeth at this point permalink embed save parent report reply [–]StuffedBrownEye 1 point2 points3 points 17 hours ago (0 children) Anti-trust? Oh no!!!! Not a $300,000 fine and a slap on wrist. I’m sure that will stop them. permalink embed save parent report reply load more comments (3 replies) [–]lewisthemusician 1 point2 points3 points 19 hours ago (1 child) This isn't even the first time either, I remember quite a few years ago they used a depreciated DOM API which was only available in chrome. Link for context - https://www.reddit.com/r/firefox/comments/91hbkw/youtube\\_page\\_load\\_is\\_5x\\_slower\\_in\\_firefox\\_and/ permalink embed save parent report reply [–]Fusseldieb 2 points3 points4 points 19 hours ago (0 children) They keep pulling this sh#t in the hope nobody notices. permalink embed save parent report reply load more comments (1 reply) [–]Greenlit_Hightower 14 points15 points16 points 20 hours ago* (11 children) Just for anyone who is interested, this behavior can be fixed by applying the following filter to your adblocker: www.youtube.com##+js(nano-stb, resolve(1), 5000, 0.001) All credit goes to the uBlock Origin team! See this post: https://reddit.com/r/uBlockOrigin/comments/17tm9rp/youtube_antiadblock_and_ads_november_12_2023_mega/k9i62zu/ permalink embed save parent report reply [–]HoneyChilliPotato7[🍰] 5 points6 points7 points 18 hours ago (0 children) uBO guys are fucking legends permalink embed save parent report reply load more comments (10 replies) [–]fryerandice 1 point2 points3 points 17 hours ago (1 child) Yeah they'd actually do the research instead of being outraged on reddit, I use firefox with no addons and it's not targeting the browser, it's targetting your ad blocker. It loads instantly on firefox. Good chance the 5 second delay in the code is a hack to make an adblock check work since youtube is currently in an arms race with ad blockers. permalink embed save parent report reply [–]lunk 1 point2 points3 points 15 hours ago (0 children) Absolutely does NOT do this here. I do not use ABO, but other smaller, less-targetted tools. It is ungodly slow here. permalink embed save parent report reply load more comments (6 replies) [–]thanoskaka 191 points192 points193 points 1 day ago (11 children) uBlock team - Here's another problem we need you to solve for us. I am sure if you can find ways to skip ads, you can somehow skip/overcome this 5s delay as well. permalink embed save report reply [–]gustis40g 173 points174 points175 points 1 day ago (2 children) By this point Google is doing more marketing for uBlock than their own YouTube premium. permalink embed save parent report reply load more comments (2 replies) [–]vk6_[S] 80 points81 points82 points 1 day ago (5 children) A workaround already exists for uBlock Origin: https://www.reddit.com/r/uBlockOrigin/comments/17tm9rp/comment/k9i62zu/ permalink embed save parent report reply [–]TOW87 17 points18 points19 points 20 hours ago (1 child) This only reduced the load time for me. The delay is still there, just not that much. Using User-Agent switcher plugin worked for me and the videos load instantly. permalink embed save parent report reply load more comments (1 reply) [–]ChoosenUserName4 2 points3 points4 points 20 hours ago (0 children) Thanks this worked for me! permalink embed save parent report reply load more comments (2 replies) load more comments (2 replies) [–]vk6_[S] 812 points813 points814 points 1 day ago (155 children) This is not a bug with Firefox. If you look into Youtube's client JS, there's literally code in there that makes you wait 5 seconds for no reason. https://www.reddit.com/r/firefox/comments/17ywbjj/comment/k9w3ei4/ permalink embed save report reply [–]sword112345 503 points504 points505 points 1 day ago (54 children) youtube needs to be sued about time they lose alot of money permalink embed save parent report reply load more comments (54 replies) [–]weed0monkey 151 points152 points153 points 1 day ago (37 children) Surely, that must be illegal permalink embed save parent report reply [–]Wainwort 174 points175 points176 points 1 day ago (33 children) It is, both in US and EU. You're not allowed to hinder competition by adding artificial roadblocks into your products after the fact. Unfortunately it can be a long and arduous process to prove it in court, so I imagine big companies play dirty pool like this all the time. That said, YouTube has already made enough waves to catch the attention of lawmakers. They're just too popular and integral to modern internet use, so stuff like this won't just go away, no matter how hard they try, or how long they wait. Their competition and private individuals will just break the roadblocks, spreading the solutions around like wildfire. permalink embed save parent report reply [–]GameCyborg 31 points32 points33 points 23 hours ago (22 children) in this case it should be pretty straight forward to prove since the javascript contains a check for the browser being used and if it's not chrome it waits 5 seconds. and this javascript is viewae for everyone permalink embed save parent report reply [–]EFTucker 15 points16 points17 points 22 hours ago (16 children) I'd agree except that the people we'd be relying upon to judge this would be so technologically illiterate they'd think you were speaking in incantations while explaining it. permalink embed save parent report reply [–]Fun-Tough-9807 10 points11 points12 points 22 hours ago (4 children) Prosecuter can bring in expert vitnesses that can support this and clearly explain what the behavior of the code is. This will be impossible to argue against because the behavior is clearly explained as a direkt consequence of the code. permalink embed save parent report reply load more comments (4 replies) [–]F9-0021 6 points7 points8 points 21 hours ago (1 child) EU seems to be fairly technically literate. It's the US that has dinosaurs owned by big tech lobbying. permalink embed save parent report reply load more comments (1 reply) [–]Fn_Spaghetti_Monster 2 points3 points4 points 19 hours ago (0 children) You are right that a lot of judges don't 'get' technical stuff, but this video is 30 seconds and pretty clearly shows that YT is slower for Firefox vs Chrome. You could follow up with more technical stuff but this is pretty clear and easy to follow. permalink embed save parent report reply load more comments (8 replies) [–]Twilightdusk 1 point2 points3 points 20 hours ago (0 children) I'm familiar with code and I'm not convinced that's actually the case here, good luck convincing a judge. There's a spot where a timeout is being set for 5 seconds but there's no clear link between that timeout and any check for a non-chrome browser. https://www.reddit.com/r/firefox/comments/17ywbjj/whenever_i_open_a_youtube_video_in_a_new_tab_its/ka08uqj/ permalink embed save parent report reply load more comments (4 replies) [–]Lord_Skyblocker 5 points6 points7 points 22 hours ago (5 children) How can it be hard to proof if there's literally proof in the JD code permalink embed save parent report reply [–]jimi15 3 points4 points5 points 21 hours ago (3 children) They might just claim having no knowledge over who put it there. Or blame a \"rogue\" contractor. permalink embed save parent report reply load more comments (3 replies) load more comments (1 reply) load more comments (4 replies) [–]DrKeksimus 15 points16 points17 points 1 day ago (0 children) I think in Europe they just made it illegal, or it already was according to experts ? permalink embed save parent report reply load more comments (2 replies) [–]OafishWither66 16 points17 points18 points 1 day ago (5 children) Thanks for pointing this out, youtube really needs to pay for this, its so annoying. I will also add that considering a lot of people who arent much tech literate are switching to Firefox after youtube started cracking down on adblockers, them seeing such slow performance on firefox would make them think that firefox is a slow browser which will make them switching back to Chrome or Edge. This is asshole behaviour, theyre tricking users into not using their competitors product by making the user experience worse permalink embed save parent report reply load more comments (5 replies) [–]scelt 50 points51 points52 points 1 day ago (12 children) I've seen the post on firefox sub, how this is done: From 50 possible ways to implement this, they have chosen the absolutely most simple and therefore obvious and brute way to do it. Likely there's a silent protest there in engineering on these new tasks they are getting, to make the software they built deliberately crappier. They implement the tasks as defined without even trying to invest any effort in \"solving the problem\". It's a subtle hint, but really looks to me like something is not OK there internally. permalink embed save parent report reply [–]blablablerg 16 points17 points18 points 23 hours ago (6 children) I wonder about this often. It can't be fun as an engineer to enshittify a product. permalink embed save parent report reply [–]parahacker 11 points12 points13 points 22 hours ago (2 children) I've gotten 'laid off' for exactly this. Pushing back against making things less consumer-friendly (complicated story, but the boss saw most of the money coming in from B2B, and incorrectly assumed that catering to them by disfavoring individual customers would be more profitable... that business eventually tanked and got bought out, but I was long gone by that point.) Point is, no. That is not fun at all. Especially when you're a project manager or personally responsible for some aspect of the product line, and you're told to make it worse... this is the same thing you tell your friends you do all day, your family, it's part of your identity. It fucking sucks bro. Feels bad. Real bad. Met some people who can just brush it off their shoulder, though. I'd never trust them with anything important in my life, but I guess they make better employees than I did, so... eh. Maybe I'm living with the wrong mentality, because they seem to be doing well. permalink embed save parent report reply load more comments (2 replies) load more comments (3 replies) load more comments (5 replies) [–]bigbluey1 7 points8 points9 points 1 day ago (0 children) Can confirm this worked permalink embed save parent report reply [–]spacechimp 9 points10 points11 points 20 hours ago (5 children) As a web developer, I can say that this isn't necessarily a smoking gun. Mediocre devs will often put delays in code with the hope that the page will be in an expected state when the timer runs out, rather than explicitly waiting on the specific condition(s) desired. The fact that Google typically does not hire mediocre devs does make this more suspicious, however. permalink embed save parent report reply [–]helicofraise 3 points4 points5 points 16 hours ago (1 child) You are actually one of the few smart literate enough to not jump to conclusion and draw pitchfork calling for a witch hunt. guess what ? you are right. I'm all for bashing bigcorps and especially ad empires but reddit folks confused correlation with causation here. The code in question is part of a function that injects a video ad (that plays before the start) and the code itself is just a fallback in case it fails to load over 5 seconds so that video page doesn't break completely. Why was this affected by user agent change? My best guess is that on some combinations they somehow decide not to show any ads at all (for now) and therefore this function is not called and some other code path is taken. This is consistent with my own experience with the recent anti-adblock bullshit they implemented. The banner was not being shown after user agent change implying it's one of the considered variables. You can verify all this if you click 'format code' in browser debugger. https://news.ycombinator.com/item?id=38346570 see also: https://news.ycombinator.com/item?id=38346602 permalink embed save parent report reply load more comments (1 reply) load more comments (3 replies) [–]vlakreeh 8 points9 points10 points 19 hours ago (4 children) As stated in the comments of that thread, the 5s delay isn't anything to do with your user agent but instead is part of the new anti ad blocker. Here's the function containing the delay and as you'll see nothing there is specific to any browser. function smb() { var a, b, c, d, e, h, l; return t(function(m) { a = new aj; b = document.createElement(\"ytd-player\"); try { document.body.prepend(b) } catch (p) { return m.return(4) } c = function() { b.parentElement && b.parentElement.removeChild(b) }; 030 sec ads but still, videos for me and a lot of other people seem not to load or have artificially caused issues throughour the whole watch, buffering issues mainly permalink embed save parent report reply [–]Corbert 11 points12 points13 points 1 day ago (2 children) honestly 30 sec lag > 30 sec ads permalink embed save parent report reply [–]CoolNickname2222 12 points13 points14 points 22 hours ago (1 child) Ads are worse because they ruin my mood, i'd rather watch nothing for 30 secs than some ad that vaporizes my brain cells. permalink embed save parent report reply [–]WRB852 2 points3 points4 points 20 hours ago (0 children) They took all my brain cells long ago, now they just twist my guts. permalink embed save parent report reply [–]Greenlit_Hightower 2 points3 points4 points 20 hours ago* (2 children) Just for anyone who is interested, this behavior can be fixed by applying the following filter to your adblocker: www.youtube.com##+js(nano-stb, resolve(1), 5000, 0.001) All credit goes to the uBlock Origin team! See this post: https://reddit.com/r/uBlockOrigin/comments/17tm9rp/youtube_antiadblock_and_ads_november_12_2023_mega/k9i62zu/ permalink embed save parent report reply load more comments (2 replies) load more comments (2 replies) [–]StillAliveAmI 2 points3 points4 points 21 hours ago (3 children) I'm also on Brave and havn't noticed any major lags. Will keep an eye on that for now. Do you think having YT premium could avoid those lags? permalink embed save parent report reply [–]gabopushups 1 point2 points3 points 19 hours ago (0 children) It varies from time to time but it definitely happens. Sometimes it will literally force you to go down to 720p, because any higher will simply not load at all. It won't even cache. Switching to edge with full ads loads it instantly and flawlessly permalink embed save parent report reply load more comments (2 replies) [–]dritspel 0 points1 point2 points 18 hours ago (1 child) How can Pihole help with getting rid of the slowdown in Firefox? permalink embed save parent report reply load more comments (1 reply) load more comments (6 replies) [–]simon7109 111 points112 points113 points 1 day ago (7 children) I don’t have this issue, but for some reason video playback was really slow today. Like constantly buffering. permalink embed save report reply [–]Servebotfrank 45 points46 points47 points 1 day ago (3 children) Yeah I have Gigabit fiber and all of a sudden Youtube has been abysmally slow. I have also noticed this absurd loading too. permalink embed save parent report reply [–]ezbyEVL 26 points27 points28 points 1 day ago (1 child) Same, I thought it was my network but jesus christ is all because they dont want firefox Thats insanenconsidering the main and default search engine in firefox is google's and they pay them a lot for that They realy want that monopoly lol permalink embed save parent report reply [–]doublelayercaramel 10 points11 points12 points 1 day ago (0 children) chrome is burning garbage permalink embed save parent report reply load more comments (1 reply) [–]OafishWither66 3 points4 points5 points 1 day ago (1 child) Try switching your account to another or opening a private window, this seems to also bypass the 5s timeout as mentioned in my original thread permalink embed save parent report reply load more comments (1 reply) load more comments (1 reply) [–]meckrisa 40 points41 points42 points 1 day ago (0 children) Been happening to me since this morning, the video will also sometimes start to play audio immediately while the screen is still black, causing the audio to be doubled and only a refresh (which leads to another wait time) fixes it. Really hoping Google catches a lawsuit and fails soon. permalink embed save report reply [–]AcherusArchmage 32 points33 points34 points 1 day ago (0 children) Been wondering why every video was taking forever to load permalink embed save report reply [–]Rubber_Knee 31 points32 points33 points 1 day ago* (5 children) Both Microsoft and Google used to do something similar to browser clients presenting themselves as the Vivaldi browser, on their online services. They would either send faulty code to the browser so everything looked, and worked, weird, or just show text on the screen that said the browser was incompatible with the website. But if you changed the useragent to Chrome then everything worked just fine. It's the sole reason why Vivaldi now, by default, presents itself as Chrome to all but a specific few websites. permalink embed save report reply load more comments (5 replies) [–]Desmatized 26 points27 points28 points 1 day ago (3 children) This is actually fucked??? wtf is wrong with them permalink embed save report reply [–]Traveling_Solo 5 points6 points7 points 19 hours ago (0 children) They want to pay more from being sued and fined <3 Such nice ppl permalink embed save parent report reply load more comments (2 replies) [–]Mwrp86 22 points23 points24 points 1 day ago (12 children) Welp, another add on just for youtube it is. So far, 1. ublock 2. Sponsorblock 3. Return dislikes 4. Enhancer for Youtube 5. Vidiq Now another one permalink embed save report reply [–]radulila 1 point2 points3 points 16 hours ago (2 children) You can return dislikes?! permalink embed save parent report reply load more comments (2 replies) load more comments (9 replies) [–]Azalemeth 21 points22 points23 points 23 hours ago (1 child) On a completely related note, the UK's Competitions and Markets Authority has recently been flexing its muscles. You may wish to know of this URL for reporting anti-competitive practices: https://www.gov.uk/guidance/tell-the-cma-about-a-competition-or-market-problem permalink embed save report reply [–]AidenT06 2 points3 points4 points 19 hours ago (0 children) Thank you very much. I’ll let them know. And maybe a letter to my MP too. permalink embed save parent report reply [–]Cr0ssley 15 points16 points17 points 1 day ago (0 children) I've been dealing with this BS in Chrome as well, Seems like YT doesn't like extension in general now. Not gonna change anything though, they can burn in hell for all I care, Ad Blockers for me! permalink embed save report reply [–]AwayHold 12 points13 points14 points 23 hours ago (1 child) even if i have to wait 5 minutes it is worth it. no ad views for youtube! also very easy to do this battle with yt....in a chair, chilling, practising zen and patience. no effort at all, i can hold this stance longer than they can survive without their ads. eventually it only create market for other creator content media platform. maybe a non profit platform that gives creators the opportunity to monetize without a third party skimming percentages and as a side hussle syphon data from all users to fill exclusively YT pockets, over content created by others. insane that creators don't unionize and start their own platform. permalink embed save report reply load more comments (1 reply) [–]Temporary-Purpose431 17 points18 points19 points 1 day ago (0 children) That happens with edge too I believe. Ive even got gigabit internet. permalink embed save report reply [–]m00n6u5t 18 points19 points20 points 1 day ago (2 children) How is this discrimination even legal? permalink embed save report reply [–]TurtleneckTrump 12 points13 points14 points 1 day ago (0 children) It's not permalink embed save parent report reply [–]Kellykeli 2 points3 points4 points 18 hours ago (0 children) The person doing the discrimination is rich. That’s how it’s legal. permalink embed save parent report reply [–]Severe-Hospital-3189 16 points17 points18 points 1 day ago (10 children) Anyone have a fix for this on google chrome, like a tamper monkey scrip, i believe it happens to accounts that youtube has flagged for using ad blockers permalink embed save report reply [–]OafishWither66 7 points8 points9 points 1 day ago (2 children) For me no, My main account works fine on Edge and Thorium, but not firefox. Thats how i figured out changing User Agent fixes the issue. It was merely an experiment and it turned out i was right permalink embed save parent report reply load more comments (2 replies) load more comments (7 replies) [–]Joseph-stalinn 6 points7 points8 points 1 day ago (2 children) My wait time is around 30 second on brave browser permalink embed save report reply load more comments (2 replies) [–]Junior_Government_83 11 points12 points13 points 23 hours ago (7 children) POV: You got rid of net neutrality permalink embed save report reply [–]powerLien 5 points6 points7 points 20 hours ago (6 children) Net neutrality specifically applies to internet service providers providing preferential treatment to specific websites. Youtube is not an internet service provider. permalink embed save parent report reply [–]aint_none 1 point2 points3 points 18 hours ago (3 children) I agree that YouTube isn't an Internet service provider, but Google is, and seeing as they own YouTube I don't think it's a far fetch to think that the decisions to restrict browsers would be much different than restricting websites in their own service. On another note, I wanted to show my wife a video on YT yesterday but I had an ad that was unskippable for 45 seconds and then the second ad was 3 minutes unskippable. Does anyone know of a adblocker for the pixel (I get the irony). permalink embed save parent report reply load more comments (3 replies) load more comments (2 replies) [–]Sciesmo 5 points6 points7 points 21 hours ago (0 children) absolutely disqusting permalink embed save report reply [–]m1ntygames 13 points14 points15 points 1 day ago (2 children) I've had this issue today too. But I use Chrome and uBlock origin permalink embed save report reply [–]cherryappleblossom 4 points5 points6 points 1 day ago (0 children) me too. permalink embed save parent report reply load more comments (1 reply) [–]DontDoDrugsDoKids 8 points9 points10 points 1 day ago (0 children) I have no such problems but mostly using wired 1gbps connection on my pc. permalink embed save report reply [–]Mountainking7 4 points5 points6 points 1 day ago (0 children) They did this to edge classic and microsoft had to keep changing the code.... Scum bags permalink embed save report reply [–]Novastarone 4 points5 points6 points 16 hours ago (0 children) Sorry, this post has been removed by the moderators of r/youtube. Moderators remove posts from feeds for a variety of reasons, including keeping communities safe, civil, and true to their purpose. looks liek they are censoring too. permalink embed save report reply [–]newenglandpolarbear 4 points5 points6 points 16 hours ago* (0 children) Of course the mods remove the post. Edit: they put it back, sneaky punks. permalink embed save report reply [–]bubblegumenjoyer 3 points4 points5 points 1 day ago (0 children) I thought Something was messed Up with my Internet. Thanks for sharing permalink embed save report reply [–]ZigirigiDOOM 3 points4 points5 points 1 day ago (0 children) So that they can equalize the same time you're watching an unskippable ad permalink embed save report reply [–]Due_Tart_2494 3 points4 points5 points 1 day ago (0 children) This has to be illegal permalink embed save report reply [–]SaltyGamerHD 2 points3 points4 points 23 hours ago (0 children) Isn't this illegal? This is literally the definition of anti competitive behaviour permalink embed save report reply [–]helicofraise 5 points6 points7 points 16 hours ago (2 children) Ever heard of \"Never attribute to malice that which is adequately explained by stupidity.\" ? And now for the actual truth behind this, expect the reality of things to be much more down to earth and ordinary that what the hype is trying to make you think. gear54rus 5 hours agoparentcontextfavoriteon: YouTube artificially slows down video load times w... That's because it's not actually what's happening. I'm all for bashing bigcorps and especially ad empires but reddit folks confused correlation with causation here. The code in question is part of a function that injects a video ad (that plays before the start) and the code itself is just a fallback in case it fails to load over 5 seconds so that video page doesn't break completely. Why was this affected by user agent change? My best guess is that on some combinations they somehow decide not to show any ads at all (for now) and therefore this function is not called and some other code path is taken. This is consistent with my own experience with the recent anti-adblock bullshit they implemented. The banner was not being shown after user agent change implying it's one of the considered variables. You can verify all this if you click 'format code' in browser debugger. https://news.ycombinator.com/item?id=38346570 permalink embed save report reply [–]reddittookmyuser 2 points3 points4 points 14 hours ago (1 child) Too late. The post fits the narrative people want to push so no other plausible explanation is gonna work. permalink embed save parent report reply load more comments (1 reply) [–]stephenlocksley27 3 points4 points5 points 16 hours ago (0 children) who delete this permalink embed save report reply [–]80sCrackBBY 2 points3 points4 points 15 hours ago (1 child) why was this post removed? permalink embed save report reply load more comments (1 reply) [–]Fusseldieb 2 points3 points4 points 15 hours ago (0 children) The post has been removed. What a joke. permalink embed save report reply [–]mr_d_jaeger 2 points3 points4 points 1 day ago (0 children) I have the same issue on brave. On Firefox i'm logged in and using yt premium no issue. permalink embed save report reply [–]Lyffe 2 points3 points4 points 1 day ago (0 children) I get this on chrome as well so I don’t think it’s only Firefox permalink embed save report reply [–]Ban_Me_Again_Cowards 2 points3 points4 points 1 day ago (0 children) I THOUGHT SOMETHING WAS UP! good to know i'm not crazy, now what do we do about it? permalink embed save report reply [–]AlternativeAnswer9 2 points3 points4 points 1 day ago (5 children) tried this on chrome ,firefox ,opera ,edge and safari on three different computers all load fine without any delay 🤷🏻♂ permalink embed save report reply [–]dbzer0 7 points8 points9 points 20 hours ago (1 child) They're probably testing this in specific regions only, like how they did with the adblocker notification permalink embed save parent report reply load more comments (1 reply) load more comments (3 replies) [–]DrKeksimus 2 points3 points4 points 1 day ago (2 children) Interesting How does one spoof Chrome ? permalink embed save report reply [–]Salty_C_Dawg 2 points3 points4 points 23 hours ago (0 children) Search for an extension called User-Agent Switcher and Manager permalink embed save parent report reply [–]Scott_Mf_Malkinson 1 point2 points3 points 23 hours ago (0 children) With this extension. I'm sure there are others https://addons.mozilla.org/en-US/firefox/addon/chameleon-ext/?utm\\_source=addons.mozilla.org&utm\\_medium=referral&utm\\_content=search permalink embed save parent report reply [–]JimmyRecard 2 points3 points4 points 16 hours ago (0 children) Why did mods remove this? Did you get a removal message? permalink embed save report reply [–]joeycommet45 2 points3 points4 points 4 hours ago (0 children) \"This post has been removed by the moderators of r/youtube\" Fucking jannies. permalink embed save report reply [–]evanlee01 2 points3 points4 points 3 hours ago (0 children) LMAO which asshurt reddit mod removed this? permalink embed save report reply [–]ShadowLiberal 6 points7 points8 points 1 day ago (5 children) I use Firefox and I've never seen this both before and after getting Premium. I have on occasion seen Youtube be slow to load like it's shown in this video, but only when my Internet connection is lagging heavily at every other site (to the point that I have doubts that any of the pages will fully load), and when it did happen it was for a lot more than 5 seconds. I'd be surprised if Google is really doing this. It simply makes no sense, Chrome is already overwhelmingly dominant, and Google is literally the biggest donor to the Mozilla foundation. Google needs Firefox to be a thing so that they can tell government regulators that they don't have a monopoly in the web browser market. permalink embed save report reply [–]OafishWither66 4 points5 points6 points 1 day ago (1 child) This only started happening to me around 2 months ago, so its a decently recent thing. Also this seems to only be happening to certain accounts and not all. Considering you're now using premium, youtube might not have flagged your account permalink embed save parent report reply load more comments (1 reply) [–]Xathioun 1 point2 points3 points 22 hours ago (0 children) You probably will never see it now, since you have premium. This seems to be put into accounts that are ad blocking. At first you’re fine but dodge the ad limiter screen a few times and suddenly you have this permalink embed save parent report reply load more comments (2 replies) [–]PhysUBC 1 point2 points3 points 1 day ago (1 child) I'm having this issue and it's extremely annoying too. I thought it was firefox because I'm new to it but I didn't know it was youtube... permalink embed save report reply load more comments (1 reply) [–]firestar268 1 point2 points3 points 1 day ago (0 children) so that's why skipping forward and backwards 5s lags like fk lately, that and response times with clicking the screen and control buttons. And this is on YT premium too. permalink embed save report reply [–]Sodrunkrightnow0 1 point2 points3 points 1 day ago (0 children) Sounds like a violation of the Sherman Act permalink embed save report reply [–]Middle_Layer_4860 1 point2 points3 points 1 day ago* (0 children) YouTube makes little changes to make the user experience annoying and no one can detect it easily...but we are not gonna use chrome or watch ads What is this extension for spoofing? permalink embed save report reply [–]WoWords 1 point2 points3 points 1 day ago (0 children) It happens to me on chrome as well permalink embed save report reply [–]stoffan 1 point2 points3 points 23 hours ago (0 children) Happens with chrome to FYI. permalink embed save report reply [–]viung 1 point2 points3 points 23 hours ago (0 children) I had this yesterday on Chrome permalink embed save report reply [–]Snuupy 1 point2 points3 points 22 hours ago* (1 child) Edit: found it - https://addons.mozilla.org/en-US/firefox/addon/uaswitcher/ Which specific extension/addon is OP using? I've been trying to look for it especially cus it has a simple UI and allows for customizing specific domains. It doesn't look like https://addons.mozilla.org/en-CA/firefox/addon/user-agent-string-switcher/ permalink embed save report reply load more comments (1 reply) [–]Thrannn 1 point2 points3 points 20 hours ago (0 children) this HAS to be illegal... lets go EU! fuck them up! permalink embed save report reply [–]universal_aesthetics 1 point2 points3 points 19 hours ago (0 children) I'm using Chrome and this happens as well permalink embed save report reply [–]toronto_programmer 1 point2 points3 points 19 hours ago (0 children) I get this in Chrome as well, seems to be their new counter/punishment for ad blockers permalink embed save report reply [–]Mcmacladdie 1 point2 points3 points 19 hours ago (0 children) Using Firefox and this doesn't happen to me. permalink embed save report reply [–]Bobb_o 1 point2 points3 points 19 hours ago (0 children) I just tried and could not replicate this. permalink embed save report reply [–]shadowdash66 1 point2 points3 points 19 hours ago (0 children) I use OPera GX and noticed the same thing. Thought clearing cookies and cache might help. It did not. permalink embed save report reply [–]stormguy-_- 1 point2 points3 points 19 hours ago (0 children) They do the same for brave permalink embed save report reply [–]kkang_kkang 1 point2 points3 points 19 hours ago (0 children) They have added this to r/brave_browser as well permalink embed save report reply [–]CowMucker 1 point2 points3 points 19 hours ago (0 children) Might be pointing out the obvious here but - use FF with no ext of any sort and see what the load times are as the ext could be causing the slow down permalink embed save report reply [–]sprumpo 1 point2 points3 points 19 hours ago (0 children) I've been getting these massive delays while using chrome though permalink embed save report reply [–]schweet_n_sour 1 point2 points3 points 19 hours ago (0 children) Not just firefox. I use Opera and it happens there too. permalink embed save report reply [–]zaskobos 1 point2 points3 points 19 hours ago (0 children) The same thing happened to me, for days I was unable to open new videos on Firefox. permalink embed save report reply [–]lordtraveler 1 point2 points3 points 19 hours ago (0 children) It happens to me on Chrome as well, I'm using uBlock Origin. permalink embed save report reply [–]SavingsLeg 1 point2 points3 points 19 hours ago (0 children) Also have this on edge, just thought it was because i had too many tabs open permalink embed save report reply [–]boolonut100 1 point2 points3 points 19 hours ago (0 children) This is happening to me on Opera GX permalink embed save report reply [–]Jmich96 1 point2 points3 points 19 hours ago (0 children) This is happening in my Chrome browser. permalink embed save report reply [–]futafupa 1 point2 points3 points 19 hours ago (0 children) Same with Microsoft Edge. Still, they don’t block me from watching the video despite my ad blocker. On Safari they do, though. permalink embed save report reply [–]thefrostiiz 1 point2 points3 points 19 hours ago (0 children) Maybe I'm missing something but it does not seems to happen in France on my end. I tried opening YouTube on Chrome and Firefox, both loading times are similar. I wonder if there is a separation being done limiting this behaviour inside of Europe ? I haven't tried as I don't have a VPN access. permalink embed save report reply [–]Kozkoz828 1 point2 points3 points 19 hours ago (0 children) not just firefox I started getting this on chrome as well lol permalink embed save report reply [–]_R0H4N 1 point2 points3 points 18 hours ago (0 children) I noticed it on edge too, thought it was because of ad blockers. Sometimes the videos you search for also don't show up. permalink embed save report reply [–]m-simm 1 point2 points3 points 18 hours ago (0 children) Weird, I just checked and my load times are the exact same on youtube for Firefox and Chrome. Maybe they only do it to a few users. permalink embed save report reply [–]agentdrozd 1 point2 points3 points 18 hours ago (0 children) Noticed it on the Opera as well but I thought it was because of adblock fighting with youtube permalink embed save report reply [–]mr_capello 1 point2 points3 points 18 hours ago (1 child) hm strange, I don't have this problem and I am on Firefox using Adblocker permalink embed save report reply [–]just-bair 1 point2 points3 points 16 hours ago (0 children) Google likes to do changes only to some users first before moving to everyone permalink embed save parent report reply [–]LtColFubarSnafu_ 1 point2 points3 points 18 hours ago (0 children) I only use Chrome and the same thing happens to me. permalink embed save report reply [–]this_my_reddit_name 1 point2 points3 points 18 hours ago (0 children) I can't replicate this. I've tried this with Firefox both with and without adblock on I'm not signed into my account. It's not unusual for Youtube to slowly roll out features based on geography and other factors, have I just not been hit with this yet? Have they \"fixed\" it? permalink embed save report reply [–]Eldrich1 1 point2 points3 points 18 hours ago (0 children) I've had this issue with Chrome as well using uBlock permalink embed save report reply [–]Accomplished_Stand97 1 point2 points3 points 18 hours ago (0 children) Same with edge! permalink embed save report reply [–]Tophain 1 point2 points3 points 18 hours ago (0 children) I get this on Opera too. permalink embed save report reply [–]Miku_Fan39 1 point2 points3 points 18 hours ago (0 children) Still never had any issues on YouTube when using Firefox or chrome with ublock myself permalink embed save report reply [–]the_lullaby 1 point2 points3 points 18 hours ago (0 children) I get the 5-second delay in Chrome also. permalink embed save report reply [–]CommunardGaming 1 point2 points3 points 18 hours ago (0 children) i only use firefox and this has never happened permalink embed save report reply [–]Riftus 1 point2 points3 points 18 hours ago (0 children) For the record, I also have this issue on Chrome, but I also have uBlock installed. So it may detect the blocker and then do it for me as well permalink embed save report reply [–]BabouinGill 1 point2 points3 points 18 hours ago (0 children) I get this with Chrome. permalink embed save report reply [–]No_Ad_7687 1 point2 points3 points 18 hours ago (0 children) I use firefox and don't get that permalink embed save report reply [–]the_real_trebor333https://youtube.com/channel/UCu5kM7m9PShaooqs4WSluRA 1 point2 points3 points 18 hours ago (0 children) I get that on chrome with an adblocker permalink embed save report reply [–]Roshlev 1 point2 points3 points 18 hours ago (0 children) I've been getting this on chrome actually. Looks exactly like that! EDIT: Started the last few days, I use ublock and haven't has issues with it for a slightly longer period of time. permalink embed save report reply [–]ThatGuyOwl 1 point2 points3 points 18 hours ago (0 children) I get the same thing on Thorium.......which is a fork of Chromium permalink embed save report reply [–]Turence 1 point2 points3 points 17 hours ago (0 children) I simply installed Firefox in prep for next year, and get this load time on Chrome now. permalink embed save report reply [–]daftycypress 1 point2 points3 points 16 hours ago (0 children) this also happends on chrome with ublockorigin btw... permalink embed save report reply [–]Jimneh 1 point2 points3 points 16 hours ago (0 children) I have that issue on chrome... permalink embed save report reply [–]0_Snowx 1 point2 points3 points 16 hours ago (0 children) I'm having this on Chrome too with Ublock, I thought it was just my internet. permalink embed save report reply [–]FunSireMoralO[🍰] 1 point2 points3 points 14 hours ago (0 children) What user agent switcher are you using? permalink embed save report reply [–]Drumah 1 point2 points3 points 13 hours ago (0 children) I will -never- use chrome. Never have, never will permalink embed save report reply [–]KavKav2 1 point2 points3 points 13 hours ago (0 children) Why was this post removed? That's nuts permalink embed save report reply [–]pc_g33k 1 point2 points3 points 12 hours ago (0 children) \"Don't be evil.\" permalink embed save report reply [–]IronAstral 1 point2 points3 points 9 hours ago (1 child) I’m OK with leaving YT behind but we need a competitor that blows them away, can anybody make any recommendations permalink embed save report reply load more comments (1 reply) [–]sephjy 1 point2 points3 points 9 hours ago (0 children) It's crazy that this is only happening to Firefox lmao Fuck Google permalink embed save report reply [–]I_Am_A_Thermos 1 point2 points3 points 8 hours ago (0 children) I hate youtube god damn permalink embed save report reply [–]stackPeek 1 point2 points3 points 7 hours ago (1 child) Why is this post removed? permalink embed save report reply load more comments (1 reply) [–]stoopid_dumbazz 1 point2 points3 points 1 day ago (2 children) It's been happening on Chrome too occasionally. Some times it hangs for more than 15 seconds - I think it's a measure against adblock users to make us wait the ad length even though we're not seeing the ad. permalink embed save report reply [–]monkeysfromjupiter 4 points5 points6 points 23 hours ago (1 child) jokes on them because I'd rather see 15 seconds of darkness over having to listen to some ad. permalink embed save parent report reply load more comments (1 reply) [–]UnsanctionedPartList 0 points1 point2 points 19 hours ago (0 children) I thought this was just because of my adblocker. Huh. Well, okay then. Still pretty scummy. ... Summon the EU. permalink embed save report reply [–]Yamsuk 0 points1 point2 points 19 hours ago (0 children) Weird that spoofing to Chrome fixed this issue for you. Cause I'm on Chrome, and it's happening to me for some reason. It's annoying AF. permalink embed save report reply load more comments (382 replies) about blog about advertising careers help site rules Reddit help center reddiquette mod guidelines contact us apps & tools Reddit for iPhone Reddit for Android mobile website <3 reddit premium Use of this site constitutes acceptance of our User Agreement and Privacy Policy. © 2023 reddit inc. All rights reserved. REDDIT and the ALIEN Logo are registered trademarks of reddit inc. Advertise - entertainment π Rendered by PID 237246 on reddit-service-r2-loggedout-567757754f-xlkpf at 2023-11-21 10:05:59.790257+00:00 running a3f664e country code: US.",
    "commentLink": "https://news.ycombinator.com/item?id=38345858",
    "commentBody": "YouTube slows down video load times when using FirefoxHacker NewspastloginYouTube slows down video load times when using Firefox (reddit.com) 1818 points by csvm 23 hours ago| hidepastfavorite454 comments ayhanfuat 23 hours agoFrom reddit discussion (https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;firefox&#x2F;comments&#x2F;17ywbjj&#x2F;comment&#x2F;k9...):> To clarify it more, it&#x27;s simply this code in their polymer script link:> setTimeout(function() { c(); a.resolve(1) }, 5E3);> which doesn&#x27;t do anything except making you wait 5s (5E3 = 5000ms = 5s). You can search for it easily in https:&#x2F;&#x2F;www.youtube.com&#x2F;s&#x2F;desktop&#x2F;96766c85&#x2F;jsbin&#x2F;desktop_pol... reply lifthrasiir 22 hours agoparentThat is not correct. The surrounding code gives some more context: h=document.createElement(\"video\");l=new Blob([new Uint8Array([&#x2F;* snip *&#x2F;])],{type:\"video&#x2F;webm\"}); h.src=lc(Mia(l));h.ontimeupdate=function(){c();a.resolve(0)}; e.appendChild(h);h.classList.add(\"html5-main-video\");setTimeout(function(){e.classList.add(\"ad-interrupting\")},200); setTimeout(function(){c();a.resolve(1)},5E3); return m.return(a.promise)})}As far as I understand, this code is a part of the anti-adblocker code that (slowly) constructs an HTML fragment such as ``. It will detect the adblocker once `ontimeupdate` event didn&#x27;t fire for 5 full seconds (the embedded webm file itself is 3 seconds long), which is the actual goal for this particular code. I do agree that the anti-adblocker attempt itself is still annoying. reply lifthrasiir 22 hours agorootparentFor the completeness, the omitted Uint8Array is the following 340-byte binary (here in base64): GkXfo59ChoEBQveBAULygQRC84EIQoKEd2VibUKHgQRChYECGFOAZwH&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;FUmpZpkq17GD D0JATYCGQ2hyb21lV0GGQ2hyb21lFlSua6mup9eBAXPFh89gnOoYna+DgQFV7oEBhoVWX1ZQOOCK sIEBuoEBU8CBAR9DtnUB&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;+eBAKDMoaKBAAAAEAIAnQEqAQABAAvHCIWFiJmEiD+CAAwN YAD+5WoAdaGlpqPugQGlnhACAJ0BKgEAAQALxwiFhYiZhIg&#x2F;ggAMDWAA&#x2F;uh4AKC7oZiBA+kAsQEA LxH8ABgAMD&#x2F;0DAAAAP7lagB1oZumme6BAaWUsQEALxH8ABgAMD&#x2F;0DAAAAP7oeAD7gQCgvKGYgQfQ ALEBAC8R&#x2F;AAYADA&#x2F;9AwAAAD+5WoAdaGbppnugQGllLEBAC8R&#x2F;AAYADA&#x2F;9AwAAAD+6HgA+4ID6Q==VLC somehow refuses to play it, but its nominal length can be verified with a short JS code like: v = document.createElement(&#x27;video&#x27;); v.src = `data:video&#x2F;webm;base64,`; await new Promise(resolve => v.onloadedmetadata = resolve); console.log(v.duration); reply Aardwolf 19 hours agorootparentprevI couldn&#x27;t reproduce the 5s wait in multiple scenarios in Firefox (various combinations of being logged in &#x2F; not being logged in &#x2F; without adblocker &#x2F; with adblocker) and couldn&#x27;t reproduce a 5s wait time in any of them, it played back immediately in each case (when without adblocker, using a second video to have one start without ad). I tested on Linux.What exact combination of circumstances is required to trigger the multi second wait time? reply kortex 16 hours agorootparentI just tested this in firefox on ubuntu. Three subsequent new tab tests.Load: 4.34s, 5.14, 2.96, 3.35DOMContentLoaded: 3.65s, 4.56, 2.92, 3.33Finish: 13.14s, 10.77, 8.49, 12.02So it&#x27;s getting a bit faster over time, but still heinous, and crucially, it isn&#x27;t hanging on requests. Individual asset GET&#x2F;POST requests are taking tens of ms, worst was a few parallel 254ms GETs on a cold start. Usually 50-70ms. But there is a flurry of requests, then a period of very few requests until 5s after init, then another flurry.Firefox 119.0 Ubuntu 22.04 uBlock Origin, Privacy BadgerSame OS, chrome 115.0.5790.170, no blockers, youtube is much snappier, it still definitely takes a few seconds to paint thumbnails, but it&#x27;s basically done by 5s. DOMContentloaded is never more than 1.75s, finish* Marketing&#x2F;Sales asks engineers to add a feature flag to sleep N milliseconds for their research: \"how slowing down impacts your revenue\"“Research” reply Jensson 22 hours agorootparentThey have done such research before, Google published this at a time when developers were all \"100 ms more or less web load time doesn&#x27;t matter\". Since then webpages has gotten much more focused on performance.https:&#x2F;&#x2F;blog.research.google&#x2F;2009&#x2F;06&#x2F;speed-matters.html reply kevin_thibedeau 21 hours agorootparentThe dog slow load times of ad infested AMP pages would suggest otherwise. reply Jensson 21 hours agorootparentThe prevailing developer discussions going from \"Load speed doesn&#x27;t matter, stop complaining about useless stuff\" to \"load times matters, but here we choose to make it slow for other reasons\" is a massive improvement though. Today speed is valued, it wasn&#x27;t back then.There are many such tests being written about in blogs today. So now a developer can get time to optimize load times based on those blog posts while before managers would say it was worthless. reply bbarnett 20 hours agorootparentUntrue. I optimized pages pre-2000, and it had always mattered.It&#x27;s always, always mattered. If anything, people care less today, with the entire ridiculous 100 loads per page. reply Jensson 17 hours agorootparentOf course it always mattered. But at the time lots of people argued it didn&#x27;t matter, which is why the headline is \"Speed matters\". You thinking it did matter at the time doesn&#x27;t mean the general community thought so. reply bbarnett 15 hours agorootparentBut the general community did care about speed. Everyone worked towards small load times, optimized (for example) image size for optimal load time, everyone cared.Whomever didn&#x27;t care was weird. reply xxpor 15 hours agorootparentprevAMP pages load way, way faster IME reply kevin_thibedeau 10 hours agorootparentNot as fast as with 90% of JS blocked. That&#x27;s how the web was supposed to work, not downloading 50 MiB on every hyperlink. reply OscarTheGrinch 22 hours agorootparentprevResearching how best to fuck with your competitors. reply actionfromafar 22 hours agorootparentNext: researching regulatory capture? reply no_wizard 9 hours agorootparentprevThis doesn’t add up.In order for someone to slow down the by browser they need someone to have coded the following:- UA Detection- Branching for when the flag is on or off- a timeout that only runs when these two things are trueThat takes an engineer to do the work. Marketing and product managers are not writing this code certainly.If they’re abusing a differ t flag, then the real question I have is what the flags purpose is and why is it screening Firefox.Either way there is an intention of UA checking and throttling based on the UA and that takes an engineer to do it reply kristopolous 22 hours agorootparentprevBecause it works.Good engineering isn&#x27;t about being obtuse and convoluted, it&#x27;s about making stuff that works. reply asddubs 22 hours agorootparentwhen the purpose is to abuse your monopoly to further your business interests in another area, being obtuse and convoluted to get plausible deniability is good engineering. This is just sloppy. reply lucideer 22 hours agorootparentI think this is a good example of corporations being made up of people, rather than being contiguous coordinated entities as many of us sometimes think of them.An engineer doing \"good engineering\" on a feature typically depends not only on them being a \"good engineer\" but also on them having some actual interest in implementing that feature. reply asddubs 22 hours agorootparentI would imagine that in a well coordinated company engaging in this kind of thing, the order wouldn&#x27;t be \"slow down firefox\", but something along the lines of \"use XYZ feature that firefox doesn&#x27;t support and then use this polyfill for FF, which happens to be slow\". Something that doesn&#x27;t look too incriminating during any potential discovery process, while still getting you what you want. reply lucideer 19 hours agorootparentThat&#x27;s assuming a degree of engineering competency at the product decision making level that is usually absent in companies that are structured as Google is, with pretty strong demarcations of competencies across teams. reply kristopolous 22 hours agorootparentprevNah, that&#x27;s got a risk profile. They could implement whatever your strategy is in the next release. You aren&#x27;t going to necessarily get the longevity of the naive approach.Plus a Firefox dev would discover that more easily as opposed to this version which they can just dismiss as some JavaScript bug on YouTube&#x27;s part reply asddubs 20 hours agorootparentthat&#x27;s the beautiful thing, you make the polyfill contingent on the browser being firefox rather than probing for the feature and then you forget to remove it once they implement the feature reply kristopolous 8 hours agorootparentBut why do you have to be that clever? If you&#x27;re caught the consequences are the same regardless and both implementations would exhibit equivalent behavior.The only superior approach here would be one that is consistent enough to be perceived but noisy enough to be robust to analysis.Also it should be hidden on the server side.Who knows, maybe there are a bunch of equivalent slow downs on the server side in the Google property space.Given this discovery it would probably be reasonable to do some performance testing and change the user agent header string of the request.Google docs, image search and Gmail operations would be the place to hide them. replykristopolous 22 hours agorootparentprevI dunno. How long has it been there without anybody noticing?5 years? 7? Longer?No matter how they approached it, you could demonstrate the pattern through the law of large numbers regardless. Might as well make the implementation straight forward. reply legends2k 22 hours agorootparentprevUsing an idle timer, like window: requestIdleCallback [1], is good engineering. If anything passes that&#x27;s not good engineering, it&#x27;s laziness.I&#x27;m not even a JS programmer but I know about timers, idle wait in UI programming is a common pattern. It&#x27;s the attitude of mediocre engineers not bothering to lookup or learn new things.If every OS&#x2F;browser&#x2F;stock market dev did what they want \"because it works\" we don&#x27;t have a working system. We&#x27;ll have systemic lags making the system sluggish and eventually unusable as more engineers follow the same mantra.[1]: https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;API&#x2F;Window&#x2F;requ... reply kristopolous 22 hours agorootparentNah, then it doesn&#x27;t work.\"It works\" is The high engineering bar and it&#x27;s the hard one to hit.Oftentimes it&#x27;s replaced these days with imagined complexity, ideological conformity or some arbitrarily defined set of virtues and then you get a really complicated thing that maybe works some of the time and breaks in really hard to understand ways.Transcompiled frameworks inside of microservices talking to DBMS adapters over virtual networks to do a \"select *\" from a table and then pipe things in the reverse direction to talk to a variety of services and providers with their own APIs and separate dependencies sitting in different microservices as it just shepherds a JSON string through a dozen wrapper functions on 5 docker containers to just send it back to the browser is The way things are done these days. This is the crap that passes for \"proper\" engineering. Like the programming version of the pre-revolutionary French Court.A simple solution, fit for purpose, that works as intended, easy to understand, remove, debug and modify with a no-bus factor, that&#x27;s the actual high end solution, not the spaghetti stacked as lasagna that is software haute couture these days.Sometimes, in practice, the dumb solution can also be the smart one. True mastery is in what you choose Not to do. reply legends2k 18 hours agorootparentI agree with the spirit of your comment; I too hate over-engineering. Choose your battles is an important step in mastery, yes, but being lazy can&#x27;t be chalked up to mastery.In this particular case I disagree with using `sleep`; using the idle timer it&#x27;s not as roundabout as you put it: _Transcompiled frameworks inside of microservices talking to DBMS adapters over virtual networks_. It&#x27;s a straight-forward callback, some lower-level timekeeper signals you and you do your thing: it&#x27;s nowhere close to the convoluted jumping through hoops you explain.Mastery comes with balance: putting in the optimal effort, not more, not less either. Of course, depends on what one&#x27;s trying to master: job or programming. Former means do the minimum and get maximum benefits from your job&#x2F;boss, latter means enjoy learning&#x2F;programming and arrive at the most optimal solution (for no reason, just because you&#x27;re passionate). reply vsnf 21 hours agorootparentprevSpeaking as someone who only very occasionally does browser related programming, what is the supposed sin committed here by implementing it this way? reply alias_neo 20 hours agorootparentIn programming in general, sleeps are generally considered....(I&#x27;m lacking the word)...distasteful?If your code needs to wait for something, it&#x27;s better done with some sort of event system or interrupt or similar; the reason being that a 5s wait is a 5s wait, but if, say the thing you&#x27;re waiting for returned in 10ms, if you&#x27;re using an alternative solution you can carry on immediately, not wait the remaining 4.99 seconds. Conversely, if it takes longer than 5s, who knows what happens? reply vsnf 19 hours agorootparentSure, but assuming we take it as face value that this is a straightforward attempt to force a UX-destroying delay, I don&#x27;t see what makes this so terrible. It&#x27;s meant to force a 5 second wait, and it does it. Problem solved. reply ascagnel_ 17 hours agorootparentThe 5-second wait is the issue, not the means it was obtained -- a fixed wait time either wastes the user&#x27;s time (by making it take longer than necessary) or is prone to bugs (if the awaited task takes >5 seconds, then the end of the timer will likely break). The better question is _why_ a 5-second wait was necessary, and there&#x27;s almost certainly a better way to handle that need without the fixed wait time. reply saynay 16 hours agorootparentOPs point, I think, is that wasting the user&#x27;s time is part of the point of the code. This specific code seems partially meant as a punishment of the user for using an adblocker. reply snvzz 15 hours agorootparent*for using firefox instead of google&#x27;s own browser. reply saynay 15 hours agorootparentThat&#x27;s somewhat in debate, the last I saw. The initial report was it affected a user using Firefox, and it didn&#x27;t when they switched useragents. Since then, there have been reports of users not seeing it in Firefox, but seeing it in other (even chromium-based) browsers. So it seems likely they are A&#x2F;B testing it, but less clear if they are intentionally targeting non-Chrome browsers.Their goal, quite clearly, is to prevent (or at least heavily discourage) adblockers. This is one attempt to detect them, and maybe in Chrome they have a different detection mechanism so it doesn&#x27;t show the same behavior.It would be a particularly foolish move on their part to push Chrome by punishing everything else right now, while they are in the middle of multiple anti-trust lawsuits. It makes me think that is unlikely to be the intent of this change. replyworik 10 hours agorootparentprev> In programming in general, sleeps are generally considered....(I&#x27;m lacking the word)...distasteful?Hmmm.....In programming in general, Javascript is generally considered....(I&#x27;m savouring the word)...distasteful?Yea, nah. I put a sleep in a Javascript&#x2F;Dart bridge the other day.... We can do better, I can do better, reply brvsft 18 hours agorootparentprevI don&#x27;t know if this is what was meant, but my assumption is that it is quite brazen and crude.But then I think of some alternative method where they send an ajax request to \"sleep.google.com&#x2F;?t=5\" and get a response like \"\" after five seconds. reply meindnoch 17 hours agorootparentprevFor one, they didn&#x27;t use React. reply another2another 21 hours agorootparentprevYep, curious to know the same thing myself. reply babypuncher 16 hours agorootparentprevthey are a lazy man&#x27;s solution to race conditions that does not actually solve the problem of race conditions, only makes them less likely to cause a problem at an often extreme cost to responsiveness as seen here. reply skupig 22 hours agorootparentprevYou&#x27;re mad that they&#x27;re using a function for its intended purpose? reply _fizz_buzz_ 22 hours agorootparentprevMaybe the engineer that was tasked with implementing was annoyed with the task and did it on purpose this way. reply shultays 19 hours agorootparentprevIt is not literally a sleep though, isn&#x27;t setTimeout more like a creating a delayed event? (I am not a webdev) reply Izkata 19 hours agorootparentYou can&#x27;t directly do a sleep in Javascript because it runs in the same thread as the UI - it would block the user from interacting with the page. This is effectively a sleep because after 5 seconds it&#x27;s running the code in the passed-in function (not firing an event). The code in the function then resolves a promise, which runs other functions that can be specified later by what called the one using setTimeout. reply yencabulator 19 hours agorootparentprevThat&#x27;s Javascript for you. Don&#x27;t want to block the one thread from doing other things in the meanwhile. reply CalRobert 19 hours agorootparentprevI&#x27;m more mad about the complete failure of regulators to break up an obvious monopoly than I am with the engineers (though they&#x27;re not saints either) reply squarefoot 22 hours agorootparentprevAt least they didn&#x27;t rewrite the sleep code to do crypto mining. reply otabdeveloper4 21 hours agorootparentprevGoogle employs 30000 engineers, it&#x27;s impossible for them all to be decent. reply agumonkey 22 hours agorootparentprevfollow the moneyemployees will follow orders, orders are made by people who control the money reply shmerl 15 hours agorootparentprevReminds me A Ticket to Tranai by Robert Sheckley where they deliberately asked to slow down robots in order for people to be angry and destroy them. reply m4tthumphrey 23 hours agoparentprevThis is interesting as I had noticed this happening to me (in Chrome) when the anti-ad-blocking started. I assumed that it was YT&#x27;s way of \"annoying\" me still while no ads were shown... It was eventually replaced with the \"You cant use Adblockers modal\" and now I just tolerate the ads.So I wonder if that 5s delay has always been there. reply bluescrn 23 hours agorootparentWhen I ran into the adblocker-blocker (Firefox + uBlock Origin), I noticed that I could watch videos if logged out. So I just stayed logged out, and haven&#x27;t seen an anti-adblock message since. Or an ad.Added bonus, I&#x27;m less tempted to venture into the comments section... reply y04nn 21 hours agorootparentSame, I use Firefox + uBlock Origin + YouTube Unhook for a cleaner interface. I also always watch videos on private navigation windows (my default way of browsing the internet) and I manage subscriptions with the RSS feed of the channels, much better to track what I have watched since the default homepage of YouTube does not display the last videos of your subscriptions.Edit: I have forgotten to add sponsorblock to the list of extensions reply 1980phipsi 20 hours agorootparentI&#x27;ve been randomly getting the situation where the video on Firefox doesn&#x27;t work, but the sound does. It says something like \"Sorry something&#x27;s gone wrong\", but for a brief second I can see the video. I think it&#x27;s connected to the ad-blocker changes, but it doesn&#x27;t actually have a message about having an ad-blocker on. reply MiddleEndian 21 hours agorootparentprevOne of the benefits of ublock origin for me is blocking the youtube comments section, along with all of the video overlay elements. reply jonathanstrange 22 hours agorootparentprevI&#x27;m using Firefox + uBlock Origin logged in and it works totally fine. Maybe Youtube removed the anti-adblocker on select accounts? I remember I once entertained myself with writing a report in which I sounded like I&#x27;m sitting in a retirement home and have no clue what&#x27;s going on with \"ad block.\" Did perhaps someone actually read this? reply SiempreViernes 21 hours agorootparentI think you have simply been lucky, the full story is that uBlock Origin and Youtube have been tying to outpatch the other, with uBlock rolling out a bypass to the filters every one-two days since late October (https:&#x2F;&#x2F;github.com&#x2F;stephenhawk8054&#x2F;misc&#x2F;commits&#x2F;main&#x2F;yt-fix....).Depending on if you&#x27;ve set up uBlock to auto-update and when you&#x27;ve watched youtube relative to when the block filters got updated you might just not have been hit with the latest detectors while they were active. Personally I know I got the \"accept ads or leave\" modal with firefox + uBlock, locking me out completely on one of my devices. reply Synaesthesia 22 hours agorootparentprevIt seems to be something which is randomly deployed. Not everybody gets the warning. reply jonathanstrange 21 hours agorootparentI got it in the past for weeks, though. reply bratwurst3000 19 hours agorootparentprevSame here . No problem with anti Adblock. It was shown twice to me and I googled „YouTube alternatives“ then tried Vimeo and it was nice. Maybe they did register this ? :D reply Lacerda69 23 hours agorootparentprevIt&#x27;s weird but I saw the anti-blocker modal a week or two but them it stopped appearing and never saw it since shrug reply psll 22 hours agorootparentMight be because of the EU ruling, if you&#x27;re in the EU. reply dave881 21 hours agorootparentI&#x27;m in the US, and had the same experience.I got the you can&#x27;t use an adblocker message, but was able to close and&#x2F;or reload the page to watch videos without ads. After a week or so it stopped popping up.US, Firefox, uBlockOrgin. reply fimdomeio 22 hours agorootparentprevAnother way I noticed is good at skipping ads when adblocker fails is to refresh the page. When it loads again it does not play the ad. reply dbspin 23 hours agorootparentprevIt&#x27;s still trivial to block ads, but the delay has recently started for me, after never happening before. So presumably a very intentional volley in the ongoing war to own your attention. reply xkcd1963 23 hours agorootparentprevJust install adblocker? reply Erratic6576 23 hours agorootparentOr Freetube &#x2F; Newpipe reply ikt 22 hours agorootparentno need to go that extreme, the fix is to just update ublock orgins filtersGo into ublock origin addon > click filter lists > purge all caches then update nowall done reply m4tthumphrey 23 hours agorootparentprevMeh.. I could but I have to tolerate them on TV anyway. I may look to install pi-hole one day. reply wanderingmind 22 hours agorootparentIf you have an Android TV, You can use SmartTube[1] that has Adblock + Sponsorblock[1] https:&#x2F;&#x2F;github.com&#x2F;yuliskov&#x2F;SmartTube reply Larrikin 22 hours agorootparentprevPi hole doesn&#x27;t help, but there are various Android TV apps that do block ads. I still prefer the Roku eco system but I switched after they started putting ads in the middle of music videos. reply samrus 22 hours agorootparentprevpihole doesnt work for youtube because ads and content are served from the same domains. reply mlindner 23 hours agorootparentprevI still use adblockers perfectly fine on Youtube. There was never a real interruption in adblocking either. You just need ublock origin + bypass paywalls. reply prmoustache 22 hours agorootparentI think they only disabled adblockers to logged users probably because non logged users don&#x27;t have to agree to terms of services. reply jimcsharp 22 hours agorootparentBlockers work with my throw away Google accounts that I use for this and that. So maybe it&#x27;s restricted further still to very entrenched users. reply mlindner 21 hours agorootparentprevI&#x27;m always logged on and using adblockers. So no, that&#x27;s not it. I also use Youtube probably every day and am a very active user. reply busssard 22 hours agorootparentprevABP also still works just fine. I prefer the armsrace being taken care of someone else reply jug 22 hours agoparentprevHow is this not blatant anticompetitive behavior? reply alex7734 14 hours agoparentprevThis is happening to me in Chrome as well so I don&#x27;t think it&#x27;s tied to the browser you use.Curiously it happens only on one profile, in another Chrome profile (which is also logged in to the same Google account) it does not happen. Both profiles run the code in your comment, but the one that does not have the delay does not wait for it to complete.The only difference I spotted was that the profile that loads slowly does not include the #player-placeholder element in the initial HTML response. Maybe whether it sends it or not is tied to previous ad-blocker usage?What does piss me off is that even if you clear cookies and local storage and turn off all extensions in both profiles it still somehow \"knows\" which profile is which, and I don&#x27;t know how it&#x27;s doing it. reply qwery 22 hours agoparentprevIs the use of the \"E\" notation common in JS? I can see that it (could be) less bytes, obviously more efficient for bigger values... Looking at the script I can see it is minified or whatever we call that these days. I guess my question really is: did someone write \"5E3\" or did the minifier choose it?(Sorry this is heading into the weeds, but I&#x27;m not really a web developer so maybe someone can tell me!) reply d3w4s9 21 hours agorootparentBecause 5E3 is shorter than 5000, just like you can often see !0 to get \"true\" in minimize code because it saves two characters. reply pbhjpbhj 21 hours agorootparentIn js I thought 1==true, and 1 is shorter than !0 ??Never seen the use of exponential notation for numbers in js though (not a surprise, I&#x27;m not really a programmer), it seems sensible to me from the point of shifting the domain from ms to seconds. reply ayhanfuat 21 hours agorootparent> In js I thought 1==true, and 1 is shorter than !0 ??`1==true` but `1!==true` (`===` and `!==` check for type equality as well and while `!0` is a boolean, `1` is not. reply neuromanser 16 hours agorootparentprev!0 === true, but 1 !== true. I don&#x27;t recall ever needing the strict comparison, but it seems to tickle the fancy of most js programmers. reply the_gipsy 21 hours agorootparentprevDouble-equals behaves differently than triple-equals. Minifiers probably can&#x27;t swap them safely. reply yread 22 hours agorootparentprevI wonder if this actually decreases the byte over wire. 5000 compresses a lot better.... sorry for OT reply brettermeier 12 hours agorootparentInteresting question. Has anyone tested this? reply sebzim4500 22 hours agorootparentprevAlmost certainly the minimizer reply Dumble 22 hours agorootparentprevTotally possible that the minifier did this, yes. reply Semaphor 22 hours agoparentprevHow&#x2F;When does that script get loaded? It’s not showing up in my network tab. Videos also load instant as usual. reply andyjohnson0 23 hours agoparentprevTrying to be charitable here: could this be a debug&#x2F;test artefact that inadvertantly got into production? reply neonsunset 22 hours agorootparentUnlikely. Google has been breaking non-Chromium (or sometimes even just non-Google Chrome) browsers for years on YouTube and their other websites. It was especially egregious when MSFT was trying their own EdgeHTML&#x2F;Trident-based Edge. Issues would go away by faking user-agent. reply thaumasiotes 21 hours agorootparent> It was especially egregious when MSFT was trying their own EdgeHTML&#x2F;Trident-based Edge. Issues would go away by faking user-agent.Why is there more than one user-agent? Does somebody still expect to receive different content based on the user-agent, and furthermore expect that the difference will be beneficial to them?What was Microsoft trying to achieve by sending a non-Chrome user-agent? reply kevincox 21 hours agorootparentUser agents are useful. However they tend to be abused much more often than effectively used1. They are useful for working around bugs. You can match the user agent to work around the bugs on known-buggy browser versions. Ideally this would be a handful of specific matches (like Firefox versions 12-14). You can&#x27;t do feature detection for many bugs because they may only trigger in very specific situations. Ideally this blacklist would only be confirmed entries and manually tested if the new versions have the same problem. (Unfortunately these often end up open-ended because testing each new release for a bug that isn&#x27;t on the priority list is tedious.)2. Diagnosing problems. Often times you see that some specific group of user-agents is hammering some API or fails to load a page. It is much easier to track down if this user agent is a precise identifier of the client for which your site doesn&#x27;t work correctly.3. Understanding users. For example if you see that a browser you have never heard of is a significant amount of traffic you may want to add it to your testing routine.But yes, the abuse of if (&#x2F;Chrome&#x2F;.test(navigator.userAgent)) { mainCode() } else { untestedFallback() } is a major issue. reply thaumasiotes 21 hours agorootparentOnly option 1 is something that users, who are the people who decide what user-agent to send, might care about. And as you yourself point out, it doesn&#x27;t happen. reply tzs 16 hours agorootparentWhy do you think users wouldn&#x27;t care about sites diagnosing problems that are making pages fail to load (#2) or sites testing the site on the browser that the user uses (#3)? reply kevincox 20 hours agorootparentprevI&#x27;m pretty sure that users care that websites can fix bugs affecting their browser. In fact option 1 is very difficult to actually implement when you can&#x27;t figure out which browser is having problems in the first place. reply neonsunset 20 hours agorootparentprevIt is normal practice for each browser to have its own user-agent, no? But the fact that Google intentionally detected it and used polyfills or straight up invalid JS at the time was insane. A similar spin today is \"Your browser is unsupported\" you see here and there. When a major platform such as YouTube does it, it is really impactful.It would never do feature detection, would give lower quality h264 video, etc. Back then, there was really nice third-party application myTube which had made this less of an issue but it was eventually killed through API changes. reply swiftcoder 20 hours agorootparentIt may have been intended to be a normal practice, but as far back as IE vs Netscape everyone has been mucking with user agents for non-competitive (and counter-non-competetive) reasons reply enlyth 23 hours agorootparentprevWithout studying the minified code I wouldn&#x27;t assume malice just yet, this could be just an inexperienced developer trying to lazily fix some browser-specific bug, or something that accidentally made it to production like you say reply vanderZwan 23 hours agorootparentYou think they let inexperienced developers touch the YT code base without proper code review? Even if that were the case, which is an extremely charitable assumption, that itself would be malice in my opinion. reply enlyth 22 hours agorootparent> You think they let inexperienced developers touch the YT code baseUh, yes? We were all inexperienced at some point. Just the linked file is like 300k lines of unminified code, I doubt it&#x27;s all written by PHDs with 20 years of experience reply xxs 22 hours agorootparentSome would argue that owning a PhD degree does not necessarily guarantee half decent engineering skills. reply vanderZwan 21 hours agorootparentprevIt&#x27;s the \"without proper code review\" part that I consider malice, not being inexperienced. reply sapiogram 22 hours agorootparentprev> You think they let inexperienced developers touch the YT code base without proper code review?Yes reply ric2b 17 hours agorootparentYouTube is way too stable for that to be the case. reply londons_explore 22 hours agorootparentprevlolThis reply is for everyone who has ever worked on the codebase... reply ozim 22 hours agorootparentShould be: LOL LGTM reply asddubs 22 hours agorootparentprevthere is such a thing as overextending the benefit of the doubt, to the point that malicious actors will abuse it. reply kevincox 21 hours agorootparentprevIt could even just be a timeout as part of retry logic or similar. A lot of people seem to be saying that there is no reasonable reason to have a `sleep` in a production application. But there are many legitimate reasons to need to delay execution of some code for a while. reply xxs 22 hours agorootparentprevAs the saying goes: \"we like naked girls, not naked sleep\". Even the interns should know that, naked sleep is just bad - not fixing anything. reply KptMarchewa 20 hours agorootparentprevIf, with Youtube size, they do not test on Firefox, this is as much malice as doing this deliberately. reply fwn 22 hours agorootparentprev> Trying to be charitable here [...]There is no reason for charity with such a large power difference. For Firefox, \"bugs\" like this can really end up being a lost one-shot game.It&#x27;s like people walking by and casually reaching for your phone. It&#x27;s always meant as a joke, unless you don&#x27;t pull it away fast enough. Then suddenly it wasn&#x27;t a joke - and your phone is gone.This is not rooted in any reservation against Google in particular. If you are a mega-corporation with the power to casually crush competitors, you should really want to be held to a high standard. You do not want to be seen as the accidentally-fucking-others-up-occasionally kind of company. reply blueflow 23 hours agoprevIf you are fluent with the terminal, you don&#x27;t need to suffer from the YT Web UI. Install mpv and yt-dlp. Play videos like this: mpv [--no-video] \"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=X9zVjEZ7W8Q\"Option in brackets is optional. reply imiric 23 hours agoparentThis is the way.I really don&#x27;t understand why any technically proficient user would willingly use any of the official YouTube frontends. You get bombarded with ads, you&#x27;re constantly tracked and experimented on, and your behavior is used to improve their algorithms in order to keep you on the site for as long as possible. It&#x27;s a hostile user experience, just like most of the mainstream web.Whenever possible, I suggest using Invidious, Piped, Newpipe, yt-dlp, and anything but the official frontends.I try to compensate the creators I follow via other means if they have an alternative income source, but I refuse to be forced to participate in an exploitative business model that is responsible for the awful state of the modern web. reply jasode 21 hours agorootparent>I really don&#x27;t understand why any technically proficient user would willingly use any of the official YouTube frontends.I&#x27;m a technically proficient user that&#x27;s written custom bash scripts for youtube-dl combined with ffmpeg to download videos locally and I still use the official Youtube desktop web browser UI every day for several reasons:+ transcripts and close-captioning (use Ctrl+F search for text to find the section of video that starts talking about the topic I&#x27;m interested in)+ many videos have index of chapters (deep links), table-of-contents+ viewers&#x27; comments (especially valuable for crowdsourced feedback on DIY videos to point out extra tips, or flaws, etc)+ external links mentioned (Amazon links to products is especially valuable for DIY tutorials)+ convenient hot links to related videos (part 2, part 3, etc). Not every creator makes \"playlists\"+ Youtube web UI has superfast video scrubbing of the timeline. A local video player like VLC scrubbing of the timeline is very slow compared to Youtube because the youtube backend pre-analyzes the entire video and generates a bunch of timeline thumbnails at multiple intervals. This makes the Youtube web UI timeline scrubbing very fluid with responsive visual feedback.I like downloading with yt-dlp but I also lose a lot of functionality when I watch videos in VLC instead of the Youtube desktop webbrowser UI. The above points are not relevant to the terrible Youtube app on mobile and tablets. reply imiric 16 hours agorootparentMost of those features are available in OSS tools as well. And for those that are not, there are alternative solutions that might take a bit of work to implement.I&#x27;m not claiming that the OSS tools have feature parity with 1st party frontends, or that they won&#x27;t require some sacrifices, or effort adjusting. I just think that the trade-off of losing some of the convenience in return for not being tracked and manipulated is well worth it to me, though I can see how it might not be worth it for others.I do actually think that OSS tools provide a better UX. I can download the media and consume it offline, using any player of choice, on any device, at any time. I find YouTube&#x27;s recommendations a nuisance, and I can turn those off in Invidious and Piped. Scrubbing in mpv is instantaneous for me for local files and even those served on the LAN, though there is a slight delay when playing directly from YT. There is also a solution for generating thumbnails[1], though I had some issues with it, and didn&#x27;t end up using it.At the end of the day, it&#x27;s a personal choice depending on what you value most, and I&#x27;m not trying to convince anyone my choice is inherently better. Thanks for providing your perspective.[1]: https:&#x2F;&#x2F;github.com&#x2F;tomasklaen&#x2F;uosc reply jasode 15 hours agorootparent>Scrubbing in mpv is instantaneous for me for local filesYes, I agree that scrubbing in mpv or vlc is \"instantaneous\" but Youtube&#x27;s web ui is even more hyperfast \"instaneous\" than mpv.>There is also a solution for generating thumbnails[1], though I had some issues with it, and didn&#x27;t end up using it.For me, using an offline tool like thumbfast to generate timeline previews defeats the purpose of using Youtube&#x27;s pre-existing timeline thumbnails that Google&#x27;s datacenter already generated. Let me explain...>I do actually think that OSS tools provide a better UX. I can download the media and consume it offline, using any player of choice, on any device, at any time. I find YouTube&#x27;s recommendations a nuisance,I&#x27;m guessing it&#x27;s a difference in usage pattern. I&#x27;m often browsing a bunch of Youtube videos as a research tool. Like a \"visual wikipedia\" for various topics (especially DIY tutorials and products research). I want to jump in and out of videos fast. Downloading videos with yt-dlp to play in mpv isn&#x27;t the workflow here. That&#x27;s too slow and cumbersome. Instead, I&#x27;m sampling a bunch of videos and maybe a few of those will be ultimately be downloaded. E.g. Preview&#x2F;scrub fragments of 10 related videos, read some viewer comments, scan some transcripts, etc... and eventually only yt-dlp 2 of them. This is why \"mpv yt-dlp with workarounds\" is not an acceptable substitute for using Youtube&#x27;s web ui. reply imiric 14 hours agorootparentThat&#x27;s fair. It&#x27;s indeed a difference in usage.My only usage of YT is queing up videos for short-term playback. So I browse a feed of my subscriptions in Piped, drag links of videos I&#x27;m interested in to a text file, and run a small script on my HTPC to download them with yt-dlp in parallel, and add them to a playlist. With a fast connection, it only takes a few minutes to download even dozens of videos at a time. Then I serve the videos on my LAN over HTTP with nginx, and watch them on any of my devices using any media player that can stream HTTP, which is usually mpv.I started a project some time ago to make this fancier, but honestly, this workflow does 90% of what I need, and I&#x27;m too lazy to change it.To each their own :) reply blueflow 21 hours agorootparentprev> + many videos have index of chapters (deep links)In mpv, you can use PgUp and PgDown to select chapters.> + external links mentionedVideo description is in audio&#x2F;video file if yt-dlp gets a --embed-metadata. mpv prints that if present. reply dewey 22 hours agorootparentprev> I really don&#x27;t understand why any technically proficient user would willingly use any of the official YouTube frontends.- Because I don&#x27;t see ads with YouTube Premium- Because I add things to my playlists- Because I more often than not find interesting things to watch there- Because I like using it on my phone or TVThere&#x27;s a lot of reasons why someone would prefer the official apps over some third party app that might break every few months. reply beej71 7 hours agorootparent> - Because I don&#x27;t see ads with YouTube PremiumI was in that boat. But after a while I realized I could no longer in good conscience give Google any more money when they were pushing so many initiatives that went against my interests. reply tgsovlerkhgsel 19 hours agorootparentprevThe web frontend just works. The other frontends tend to have issues, which even if they&#x27;re not deal-breakers are annoying. I won&#x27;t put ideology over using what works best. And clicking a link, then clicking play, beats copying the URL then pasting it into a command line.Of course this only works because by default (since I have an ad blocker anyways) I don&#x27;t get bombarded with ads on the web frontend, and so far I&#x27;ve seen the adblocker nag screen once (a failure which uBlock Origin seems to have swiftly corrected). reply madeofpalk 22 hours agorootparentprevBecause I don&#x27;t want to fuck about working against the platform, opting myself into something that&#x27;ll break at any moment.I would much rather put up with Youtube than be frustrated when my &#x27;alternate frontend&#x27; one day breaks and i need to figure out a workaround. reply jeroenhd 22 hours agorootparentprevBecause using the website is a better experience. None of those tools worked with Sponsorblock last time I tried, for one.I don&#x27;t want to yt-dlp every video, Piped and Invidious both have awful frontends in comparison, even the Newpipe dev admitted to using Vanced at some point, and yt-dlp needs some massaging to get the right video quality (and it can&#x27;t download some videos at all).If any of your solutions were better for the majority, the majority would be using them. Youtube&#x27;s ad blocker war is making the platform worse for everyone, but having a couple of billions of developer power behind your platform still beats any open source video players built for fun. reply imiric 16 hours agorootparent> Because using the website is a better experience.That is debatable. I personally find that the combination of Piped, yt-dlp and mpv provides a far better experience than the official frontends. But this is a personal opinion, and I&#x27;m not trying to convince anyone my choice is better. I just didn&#x27;t think other technical users would prefer using the official frontends.Thanks for your perspective, though I think it&#x27;s a bit outdated.> None of those tools worked with Sponsorblock last time I tried, for one.Piped, yt-dlp and mpv all support Sponsorblock. reply vonjuice 21 hours agorootparentprevhttps:&#x2F;&#x2F;github.com&#x2F;po5&#x2F;mpv_sponsorblock reply noname120 22 hours agoparentprevOr use any of the many alternative YouTube frontends: https:&#x2F;&#x2F;github.com&#x2F;mendel5&#x2F;alternative-front-ends#youtube reply Osiris 5 hours agorootparentAre there any alternatives for iOS? reply beej71 6 hours agoparentprevThanks for this pointer--I hadn&#x27;t heard of mpv, but it works amazingly smoothly. reply MrNeon 22 hours agoparentprevOne feature it lacks is seek bar previews. There are thumbnail scripts but they don&#x27;t use the available youtube thumbnails. reply ftk_ 22 hours agorootparentI implemented downloading of youtube thumbnails for one of these scripts.https:&#x2F;&#x2F;github.com&#x2F;marzzzello&#x2F;mpv_thumbnail_script reply sammy2255 23 hours agoparentprevI think you’re missing the point. How can I browse Youtube in mpv? reply rozenglass 22 hours agorootparentIn addition to Piped, and Invidious, mentioned by sibling comments, which allow you to subscribe, search, and provide recommendations, you can use a complete CLI workflow with something like ytfzf[0], or, you can use the search commands on yt-dlp[1], which are also accessibly through mpv using the ytdl:&#x2F;&#x2F; prefix.Getting familiar with such tools not only replaces the terrible UXes you have to be subjected to, but also gives you the power and freedom to be creative with how you use Youtube and other online streaming sites.I wrote various tiny scripts to replace all my needs for Youtube search, using any highlighted text, with a shortcut, Youtube Music, with a synced plain text file of song titles and a shuffle-on-read script, and more curiously, a script to help me slowly go through all thousands of my partner&#x27;s favorite songs, and then, using shortcuts, add them to my own favorites, decide on them later, add them to the \"what the heck do you listen to\" friendly banter list, or the \"my ears bleeding\" list, etc. Much better UX then anything the slow web UIs can offer, and with minimum hacking.[0]: https:&#x2F;&#x2F;ytfzf.github.io&#x2F;[1]: https:&#x2F;&#x2F;github.com&#x2F;yt-dlp&#x2F;yt-dlp reply imiric 22 hours agorootparentprevUse Invidious, Piped or any other frontend that doesn&#x27;t track and manipulate you. reply littlecranky67 21 hours agorootparentAdding https:&#x2F;&#x2F;youtube-lite.js.org&#x2F;#&#x2F; to the list. reply blueflow 23 hours agorootparentprevWhat do you mean by \"browsing\" Youtube? Clicking new links for the purpose of entertainment?My post was only about playing videos. reply sofixa 22 hours agorootparentWell, how do you get to the videos? How do you discover their links to pipe to mpv&#x2F;yt-dl?One option is RSS (YouTube still supports it) subscribing to channels. Do you know of others? reply blueflow 21 hours agorootparentI don&#x27;t, i use Youtube for listening to music or livestreams that i already know the title of. replyjiggawatts 23 hours agoprevOh, and they also falsely show \"4K\" in the video quality icon, but \"accidentally\" play a 720p or even worse quality stream. If you manually select the 4K stream quality, then and only then will YouTube deign to show 4K to you. reply CapsAdmin 22 hours agoparentSomething related to this which I find extremely frustrating is that I&#x27;m capable of watching a 4k video in my browser just fine. So if I decide to buy or rent a movie on youtube, they can only be played back at 420p.Apparently this is due to DRM restrictions, but the frustrating part is that you can pay extra money for the HD version and there&#x27;s nothing telling you about this not being supported in your browser until you&#x27;ve made the purchase (by just allowing 420p and needing to search for why it&#x27;s broken)see https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;youtube&#x2F;comments&#x2F;pm0eqh&#x2F;why_are_my_... reply MereInterest 22 hours agorootparentThis sort of behavior should be an open-and-shut case of false advertising. You were told that the video would be a certain resolution. You gave money as a result of that statement. You received an inferior product to the one that was described. reply Obscurity4340 21 hours agorootparentIsn&#x27;t that fraudulent? Its amazing how an individual can commit fraud one time and its FRAUD! But a company can do the exact same thing en masse as like a business model over and over and its only ever a misunderstanding that they get a chance to correct and a gentleman&#x27;s handshake. aAnd even if they didn&#x27;t, it seems impossible to adjust the dial from civil to criminal as its often left in the consumers hands. Its not like there are attorneys that, like, represent the State that could exercise their legal authority to protect consumers. reply MereInterest 21 hours agorootparentTo my not-a-lawyer understanding, it is fraudulent. Fine print is allowed to clarify an offer, but may not substantially alter the offer as originally made.I could see an argument made that a reasonable person would know an offer to be limited to supported platforms, and that the fine print clarifies which platforms are supported. To me, though, I’d draw a line between unsupported due to underlying limitations (e.g. can’t serve 4k video on a NES) and unsupported due to seller-side limitations (e.g. won’t serve 4k without remote attestation). I’d see the former as a reasonable clarification of the offer, and the latter as an unreasonable alteration of the offer. reply Obscurity4340 21 hours agorootparentEven if it doesn&#x27;t technically apply here, the larger point remains that people get handcuffs and corporations get handshakes... reply Obscurity4340 17 hours agorootparentSame deal with deferred prosecutions which is a bullshit designation because the company&#x27;s legal is basically going to ensure that it becomes a nolle prosequi at that point reply zamadatix 14 hours agorootparentprevIt&#x27;s crappy behavior but I think screaming fraud is taking things a bit far. If you buy a Blu-ray from a website you don&#x27;t come back screaming fraud because the browser or computer you you used doesn&#x27;t play Blu-rays due to the DRM requirements. A refund request fits the scenario much better and the company&#x27;s response tells you whether they are worth doing business with, not whether you were the victim of fraud. Some responsibility still lies with the buyer that they will understand what it takes to use the thing they are buying and not expect to rely 100% on the seller to verify everything for them beforehand.At the same time... I think the behavior is pretty shitty, just not illegal, in that it takes minor up front effort to resolve. An explicit message along the lines of \"You won&#x27;t be able to watch in higher quality on this browser&#x2F;device combination. Do you still want to purchase the high quality version for use on another device? You&#x27;ll still be able to watch either version on this device, just always in low quality\" goes a long way. reply bambax 22 hours agorootparentprevBuy a movie on YT or DVD, and then... watch a torrented version? This isn&#x27;t the future we were promised, but it sure is the future we have. reply chii 22 hours agorootparent> Buy a movie on YT or DVD, and then... watch a torrented version?in which case, why buy it at all? A torrent isn&#x27;t going to load as fast as what you paid YT for. reply nusl 22 hours agorootparentThe further time goes on toward segmented streaming platforms and DRM bullshit, the deeper my piracy hedge grows. Eventually there will be a streaming service aggregation service a la Cable channels and we&#x27;re back at square 1. Add to that streaming services pushing new ad schemes now that they&#x27;ve captured enough market share for the risk to be worth it, and we&#x27;ve got a great storm brewing for a resurgence in piracy and media execs going \"but y?\"BTW modern piracy setups are far more streamlined and easier to manage&#x2F;use than modern streaming platforms. Assuming you have some tech ability anyway. reply bambax 21 hours agorootparentJellyfin on a NAS is just great. You don&#x27;t even need a NAS. A Pi with a large SSD attached will do fine. reply fckthisguy 15 hours agorootparentprevA half decent NAS, with Dockerised *rr is the gold standard of torrenting. I never knew it could be so painless. reply MiddleEndian 21 hours agorootparentprev>A torrent isn&#x27;t going to load as fast as what you paid YT for.Unless you want to rewind the video without it re-buffering... reply Vicinity9635 14 hours agorootparentprevNot youtube specifically, but I wanted to watch the wheel of time series on my ipad and:#1 You cannot stream in a browser on iPadOS anymore. Amazon won&#x27;t let you, you must use their app.#2 They don&#x27;t seem to give a fuck about making sure you&#x27;re getting a quality stream in their app. Full of artifiacts and horrible compression way more often than is warranted on my symmetric gigabit connection.So I added it to my Sonarr instance (pirated it legally) and watched it in a browser from there with perfect quality and no pre-stream ads.Once again: A paid service so bad that it couldn&#x27;t compete with the pirate experience even if it was free.Which once again confirms Gabe Newell&#x27;s statement to be true: \"piracy is not a pricing issue. It’s a service issue\" reply jiggawatts 22 hours agorootparentprevNetflix does the same thing. Actually, speaking of infuriating corporate bullshit, allow me to go on a rant about Netflix and subtitles.They give you the option to choose between like four, maybe five languages. That&#x27;s it!If you want subtitles in any of the other hundred or so languages that they have available, well... no. Just no. Learn one of the four they&#x27;ve picked for you.If you call their support, they&#x27;ll gaslight you and mumble something about \"copyright\", which is patent nonsense. Copyright doesn&#x27;t restrict Netflix from showing more translations for their own content that they made themselves. They own the copyright on it, which means, literally, that they have the right to do whatever they please with the copy. Including showing the associated subtitles to you.You see, what actually happened, is that some too-smart UX guy at Netflix couldn&#x27;t make a language picker look nice for that many options so he asked a too-smart data science (lol) guy to figure out the most common languages for each region.Here in Australia they picked English, Italian, Vietnamese, Chinese because we have a lot of immigrants from those countries. I&#x27;m sure they used very clever algorithms on big data clusters to figure that out. Good job, well done.Never mind that every other streaming app vendor figured this out. Netflix and their $500K total comp Stanford or wherever graduates couldn&#x27;t. So they instructed their call centre staff to lie to their customers.Then they had someone write this idiocy: https:&#x2F;&#x2F;help.netflix.com&#x2F;en&#x2F;node&#x2F;101798\"If subtitles for a title are offered in a language but do not display on your device, try another device.\"Oh, oh, I&#x27;ll go do that right now! Let me try my PC... nope four languages. On the TV? Four languages. Actually, I have a phone... and... oh... four languages.PS: Thai (only!) subtitles are \"special\" and use eye-searing HDR maximum white. Like 1,600 nits white that literally leaves green after-images etched into my retina. They have a support page and a pre-prepared set of lies for the support staff to read for that piece of shoddy engineering also. reply nusl 22 hours agorootparentA common thing where I live is for local companies to buy streaming rights for Netflix-created media, and then we can&#x27;t watch Netflix-created media on Netflix because local-company bought streaming&#x2F;playback rights. Netflix doesn&#x27;t care about the customer. They care about money, and that won&#x27;t change. They&#x27;ll max out the bullshit until customers push back, leave it there for a bit, wait for customers to get used to the new-bullshit, then add more bullshit and repeat. reply sofixa 22 hours agorootparentprev> Never mind that every other streaming app vendor figured this outDid they? Both Prime Video and Disney+ have very very narrow subtitle and audio language choices.> If you call their support, they&#x27;ll gaslight you and mumble something about \"copyright\", which is patent nonsense. Copyright doesn&#x27;t restrict Netflix from showing more translations for their own content that they made themselves. They own the copyright on it, which means, literally, that they have the right to do whatever they please with the copy. Including showing the associated subtitles to you.Maybe they mean the subtitles&#x27; copyright?As someone who speaks multiple languages, and has the habit of watching with subtitles in the original language of the content if I speak it; otherwise default to English subtitles with original audio... none of the streaming companies have managed to handle that properly. Way too often the audio is only dubbed (often badly), or only my subtitles in my local language (French) are available, regardless of the original language of the content. I&#x27;d rather watch British movies with subtitles in English, not French, thank you very much. reply jiggawatts 22 hours agorootparentApple TV shows something like 50 languages. More than I can be bothered to count, certainly.Are you saying it&#x27;s some sort of challenge beyond the abilities of a Senior Technical Lead with total comp in the seven digits to figure out how to make a list of items more than 4 or 5 entries long? Too many megabytes of JSON to shove down the wire for more?> Maybe they mean the subtitles&#x27; copyright?They definitely do not. That&#x27;s not how work-for-hire translations work. You pay someone to translate your shows&#x27; subtitles for you, then you own the copyright on that work that you paid for. That&#x27;s how that works. No weird region-locked silliness.You can make other languages appear by changing the entire UI language of Netflix, which then shows some other \"data driven\" subset of the subtitle languages.But then, the entire UI is in another language, which not everyone watching may understand.Essentially there are audio-subtitle language combinations that are impossible to achieve, no matter what. That combo may not be common enough to make any top-5 list anywhere.So if you love someone of a sufficiently small minority, or have an unusual racial makeup in your household, Netflix would rather you weren&#x27;t so weird.Sit down and think about how absurd it is for the bastion of wokeness that is Netflix to discriminate this profoundly against inter-racial love. On purpose. They wrote the code to do this.Blows my mind. reply david-gpu 21 hours agorootparent> Sit down and think about how absurd it is for the bastion of wokeness that is Netflix to discriminate this profoundly against inter-racial loveI&#x27;m on the same boat and I hear you. And since we are on this subject, do you know what else grinds my gears? The whole idea of cultural appropriation. So if your ancestry is X then you can&#x27;t do&#x2F;wear&#x2F;celebrate Y.So when you ask these people something like: Is it okay for my half-X, half-Y children to do this? they start feeling confused. But if you go: What about my grandchildren, who are 1&#x2F;4 X and 1&#x2F;4 Y and 1&#x2F;2 Z?. Some of them begin to realize how racist and simplistic they are being.Learn and enjoy other people&#x27;s cultures, for goodness&#x27; sake. It&#x27;s called being human. reply Vicinity9635 13 hours agorootparentI consider this to be the answer to \"cultural appropraition\" which people seem to have made up because their hobby is being offended: https:&#x2F;&#x2F;rumble.com&#x2F;v3wx1mz-is-this-outfit-offensive-students...I&#x27;ve seen similar videos with Japanese garb too. The offendatrons hate it. The actual Japanese people love that you&#x27;re enjoying their culture. reply jiggawatts 12 hours agorootparentShould Italians feel offended that Japanese businessmen adopted the western (Italian-style) suit? reply david-gpu 11 hours agorootparent\"No, because Italians are white and white people can&#x27;t experience discrimination\".That is an actual response I&#x27;ve heard more than once.To be fair, I agree with the \"cultural appropriation folks\" when they correctly point out that sometimes people intentionally mock other cultures and that&#x27;s a dick thing to do. But conflating mockery and insult with an appreciation of other cultures is not helpful, and that&#x27;s what they do in practice.I&#x27;m a Spaniard and when I watch a Japanese person practicing flamenco, I feel flattered, not insulted. reply sofixa 3 hours agorootparent> No, because Italians are white and white people can&#x27;t experience discrimination\"Tell them about the Yugoslav wars merely 30 years ago to blow their minds. replysofixa 20 hours agorootparentprev> They definitely do not. That&#x27;s not how work-for-hire translations work. You pay someone to translate your shows&#x27; subtitles for you, then you own the copyright on that work that you paid for. That&#x27;s how that works. No weird region-locked silliness.If you skip the fact that Netflix do regional deals with local content houses to sell Netflix-made stuff either in theatres or get TV releases, in which case translations could be a part of the deal to be be provided by the local entity who&#x27;s getting the rights; or the other, more common scenario, where Netflix acquire local content for wider publication (e.g. Casa de Papel&#x2F;Money Heist is a very popular example), where again, there might be complications.> Apple TV shows something like 50 languages. More than I can be bothered to count, certainly.I haven&#x27;t found that to be the case, but had Apple TV only briefly because of the general poor quality (watched 3 series on it, all three devolved into trope after trope barely going below the obvious surface).> Sit down and think about how absurd it is for the bastion of wokeness that is Netflix to discriminate this profoundly against inter-racial love. On purpose. They wrote the code to do this.Is woke in the room with us right now? Can you point it out and explain what it is? For the record, \"races\" are a stupid social construct that should have died out with the Nazis. And people can be of different ethnicities while speaking the same language(s), or inversely of the same ethnicity while speaking different languages. Being \"woke\", \"inter-racial\" and different languages are completely orthogonal topics. reply isametry 16 hours agorootparentprevI have to add two adjacent subtitle-related stupidities on Netflix:1. Closed captions (CC). Okay, I&#x27;m willing to accept they improve the experience of a show &#x2F; movie for a non-zero number of people. What I absolutely don&#x27;t accept is CC being the ONLY VERSION OF ENGLISH SUBTITLES available. Either CC or nothing. I can&#x27;t be the only one who prefers English subtitles for English-spoken media, while NOT needing every single sound described as [wet squelching] or [quirky synth music].(Bonus points for everyone who recognizes those specific examples ↑)2. Subtitles in all-caps. For the entire movie. Just why? If I&#x27;m able to read the text in time at all (it is widely known that words and sentences in all-caps are slower to read), then I&#x27;ll just feel everyone&#x27;s screaming all the time, even if they aren&#x27;t. Whose idea was this? And also here, to my knowledge it only affects English. (I believe all Nolan movies got this \"treatment\" for example.)There have been several occasions where even though it was readily available for me to stream from Netflix, I pirated a show or movie anyway, specifically to avoid one or both of these issues. reply kuerbel 22 hours agorootparentprevI don&#x27;t know about browser options, but on the android app I can choose between 7 different audio languages and 29 subtitles. Looked it up just for you with an episode of \"The good Doctor\", which is not a netflix original. I live in Germany. Definitely not an UI issue. reply wombat-man 22 hours agorootparentprevSeems like they&#x27;d want people to, idk pick up to 4 languages themselves in settings if they are really attached to their picker. Which makes more sense to me. reply skrebbel 17 hours agorootparentprevI love this rant with a passion. reply dacryn 22 hours agorootparentprevis it still a thing that you have to use Edge on windows to get 4k HDR, but you can&#x27;t on Chrome? reply _Algernon_ 22 hours agorootparentprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=o4GZUCwVRLs reply strombofulous 10 hours agorootparentprevBy the way, it is 480p. 420 is for something else :) reply TheLML 21 hours agoparentprevThat has irked me for quite some time. I always manually select 1080p, because sometimes YT claims it&#x27;s already playing 1080p, but it&#x27;s obviously not and the video starts buffering anew when I select 1080p manually. Quite annoying reply kroltan 7 hours agorootparentGet the \"Enhancer for Youtube\" extension, among many adjustments, it does this clicking for you.I also had this issue, videos would frequently wobble down to like 240p or whatever, on a stable, high speed wired connection.It&#x27;s not an internet problem since I never have to buffer when using this forced setting, so it&#x27;s probably YT trying to save a few bandwidth bucks when they think people aren&#x27;t looking. reply thaumasiotes 21 hours agorootparentprevRoughly around the same time as the anti-adblocking effort, youtube started just not playing the video stream for me much of the time. I say play a video, it will start playing the audio, and the video will just be a frozen image.In unrelated news, my youtube-dl usage is way, way up. reply Voultapher 22 hours agoparentprevEnhancer for Youtube allows you to select a min quality, also great for blocking shorts. reply kevincox 19 hours agoparentprevI haven&#x27;t see this other than for brief periods during quality switching (it seems to play out the current buffer in lower quality but new chunks are downloaded at the displayed target quality). However for some reason it does often just load at a very low (sub-720p) resolution and I need to manually up the quality or it will never get to the highest quality (I&#x27;m watching on a 4k monitor with great internet and hardware decoding, 4k has never stuttered for me). reply judge2020 19 hours agorootparentI remember them starting to do automatic lower-quality streams when this came out[0], but I&#x27;m not sure if this is still the cause for the situation. It could be a general \"we see this ISP&#x2F;ASN failing more often with x many concurrent 4k streams, let&#x27;s throw some people on 720p and see if it helps\".0: https:&#x2F;&#x2F;www.pcworld.com&#x2F;article&#x2F;398929&#x2F;youtube-defaults-to-l... reply vGPU 20 hours agoparentprevI have personally noticed this many times. I’d blink and wonder if it was just my eyes going bad but nope, soon as I select HD quality manually I can read text again. reply rsolva 16 hours agoparentprevYeah, this has bothered me for a while. Switching to alternative youtube interfaces solved that problem :) reply conradfr 18 hours agoparentprevIt doesn&#x27;t help that 720p quality seems subpar (to me) compared to some years ago. reply BlueTemplar 21 hours agoparentprevWait, that&#x27;s a Firefox-only issue ?! reply IshKebab 21 hours agorootparentNo, it does it on Chrome too. reply denkmoon 22 hours agoprevUsing firefox I get \"instant\" youtube. The video starts playing before most of the rest of the UI has loaded even, definitely under 1 second.Any idea what specifically causes it to happen, rather than just \"firefox\"? reply jeroenhd 21 hours agoparentAn up-to-date adblocker blocker blocker, most likely. Paying for Premium may also do it. reply Hamuko 19 hours agoparentprevI&#x27;ve gotten that really slow UI loading almost always lately and I&#x27;ve always assumed that it&#x27;s because I&#x27;m running uBlock Origin.Although I just tried opening two videos and both opened basically instantly. reply jiripospisil 23 hours agoprevI have a hard time believing that&#x27;s actually what&#x27;s happening. If they wanted to slow down other browsers, why would they choose this easily discoverable way? They could have easily slowed down serving of JS files (and other assets) based on the user agent to a similar effect. It seems more likely this is just a debug snippet that has made it into production by accident. reply sebstefan 22 hours agoparentIf I was working at Google and I was tasked with doing that, I&#x27;d half ass it too reply jiripospisil 22 hours agorootparentI mean it could be that the programmer wanted it to be discovered to draw attention to Google managers&#x27; shenanigans but that seems kind of far fetched. reply asddubs 22 hours agoparentprevah yes, the fact that they are sabotaging other browsers in a very obvious way is actually proof that they didn&#x27;t meant to sabotage other browsers! reply amelius 22 hours agoparentprev> They could have easily slowed down serving of JS files (and other assets) based on the user agent to a similar effect.And that is &#x2F;not&#x2F; easily discoverable?? reply _fizz_buzz_ 22 hours agorootparentI would argue it&#x27;s a bit harder to find if the youtube backend serves files slower for certain browsers. One could even radomize it and sometimes still serve it fast or something. Since you cannot look at the backend code it would be hard to proof anything. reply iinnPP 22 hours agoprevhttps:&#x2F;&#x2F;www.thinkwithgoogle.com&#x2F;marketing-strategies&#x2F;app-and...Seems odd to do something so brazen while also publishing information that (could) prove intent.Google also modifies how business information can be accessed from Firefox Mobile. You can&#x27;t read reviews easily from Firefox Mobile. At least not my install. reply gear54rus 22 hours agoparentThat&#x27;s because it&#x27;s not actually what&#x27;s happening. I&#x27;m all for bashing bigcorps and especially ad empires but reddit folks confused correlation with causation here.The code in question is part of a function that injects a video ad (that plays before the start) and the code itself is just a fallback in case it fails to load over 5 seconds so that video page doesn&#x27;t break completely.Why was this affected by user agent change? My best guess is that on some combinations they somehow decide not to show any ads at all (for now) and therefore this function is not called and some other code path is taken. This is consistent with my own experience with the recent anti-adblock bullshit they implemented. The banner was not being shown after user agent change implying it&#x27;s one of the considered variables.You can verify all this if you click &#x27;format code&#x27; in browser debugger. reply iinnPP 22 hours agorootparentThat makes sense and explains why it seemed so odd.I don&#x27;t use YouTube so the comment was more of a way to bring up the other behavior in business reviews. It seemed relevant.Edit: reviews are also broken(for me) on Firefox desktop with no extensions enabled and with ublock enabled. reply foob 21 hours agoprevI use Firefox, and Google&#x27;s sites are literally the only ones where I consistently have issues. There was a period of about a month this summer where Google Maps was just completely broken for me, the map wouldn&#x27;t update at all when attempting to search or pan. There was recently a several day span where chat in Gmail had a 10+ second input lag due to some font-related JavaScript code spinning the CPU nonstop. It&#x27;s literally gotten to the point where I keep a Chrome window open and use it exclusively for Gmail, Google Meet, YouTube, and Google Maps.It&#x27;s pretty obvious from the outside that supporting Firefox is not a product priority for Google. It also seems clear that it&#x27;s in their best interest to have users choose Chrome over Firefox. My guess is that this likely emerges from a lot of very reasonable sounding local decisions, like \"prioritize testing on browsers with the most market share,\" but it is convenient how those align with the anti-competitive incentives. reply vmfunction 20 hours agoparentThese sounds like classic MS behaviour. It is kind of thing that ought to addressed in anti-trust case. reply giancarlostoro 17 hours agorootparentI&#x27;ve posted this here on HN numerous times over the years, and it&#x27;s been a while since I last posted it:Google is the new \"Microsoft\", they embrace, they extend, then extinguish. Look at their email offering, messaging offerings, they built on top of XMPP, then they pulled the plug eventually. Android is Linux based, but insanely proprietary, the app store is not open by any means, you&#x27;re fully at their whims to get your apps on there. Chrome is basically the IE of old, implementing proprietary things or APIs that are not yet standard for Google products, and pushing out competing browsers. reply f4c39012 16 hours agorootparentdon&#x27;t forget the old Microsoft is still here. We have two Microsofts now! reply da_chicken 15 hours agorootparentThe old, old Microsoft is still here, too. IBM is still there, a dinosaur in the mist. reply MSFT_Edging 19 hours agoparentprevA few weeks ago I posted on here about the maps lag, and it literally felt like it was fixed after the comment got some attention.There&#x27;s 100% targeted de-optimization for firefox users and the burden of finding it is on the users it seems. reply Pathogen-David 15 hours agorootparentNot to diminish the other sketchy stuff Google&#x27;s doing, but I think the maps lag issue might actually be Firefox&#x27;s fault. Whenever it happens to me WebGL stops working across all websites and restarting the entire browser fixes it. It&#x27;s almost like when Firefox has been open a long time it just forgets how to use graphics acceleration. reply MSFT_Edging 14 hours agorootparentThe thing that bothered me is it didn&#x27;t always happen, at one point there was performance parity, and things changed in a way that specifically worked worse in firefox.Which means:A) Firefox had bad webgl implementations(I didn&#x27;t experience what you did, but I wont say it doesn&#x27;t happen) and google added features that regressed the experience on other browsers.B) Google knowingly made performance worse on Firefox, regardless of webgl implementations.C) Google leverages its own browser to only test on their browser, to influence the market to have to use googles browser in order to use their services(not the same as the IE&#x2F;Windows monopoly lawsuit, but sure smells like it). reply gbraad 18 hours agorootparentprevi believe for anything non-Chrome? Even Vivaldi has issues with some Google products. reply orbisvicis 20 hours agoparentprevRecently, play store images don&#x27;t load (about 60% - 80% missing per app) in Firefox. reply zelphirkalt 19 hours agorootparentIt is fascinating, how the simplest things on websites can be made arbitrarily involved, convoluted, over-complicated. And how those over-complications can then serve as a credible deniability. reply 1980phipsi 20 hours agoparentprevUsing Google sites with a VPN on Firefox has been really annoying for the past couple of months as well. reply ikidd 17 hours agoparentprevI had the same Gmaps issue, I disabled LocalCDN for the site and panning etc worked again. Apparently the addon must be fixed to account for whatever they were doing. reply joelanman 21 hours agoparentprevGmail has recently become extremely slow for me in Safari on a well specced M1 max reply ryukoposting 20 hours agorootparentSame here on Firefox, for both my laptop running Windows 11 on Alder Lake, and my desktop running Ubuntu on Zen 2. reply hospitalJail 18 hours agoparentprevSpotify web doesnt work good on Firefox.Need to call out them.I&#x27;m basically forced to use Chromium on Linux. reply spicykraken 18 hours agoparentprevI use Firefox across Windows, Mac, OpenBSD, and Ubuntu. I&#x27;ve not seen any specific issues with Google sites at all. I only really use Docs, Maps, and Youtube with any regularity but I&#x27;ve not really seen any of these issues. reply trinsic2 17 hours agorootparentYea, I also haven&#x27;t noticed any speed issues, but I do use noscript exclusively on Firefox. reply whalesalad 20 hours agoparentprevbigquery console in ffx has like +120 latency potion reply shadowgovt 15 hours agoparentprevYou&#x27;re basically looking at testing being done on Chrome (because it is Google&#x27;s, and because of its large market share), Safari (because it runs on a large percentage of completely exclusive platforms where the customer can&#x27;t switch, and because of its large market share), and Edge (because there are still many corporations that do \"Nobody ever got fired for choosing Microsoft\" and lock down browser options to just Microsoft&#x27;s offering).At this point, Firefox is very much an also-ran on two axes: market share is tiny and nobody forces it on their captive audiences. We may as well ask why Google isn&#x27;t optimizing testing on Opera, or Samsung Internet.(There is also the issue of under-the-hood engine. Since so many browsers have converged on a few core and JS stacks, testing on one exemplar of that stack has a tendency to suss out bugs in the other stacks. Firefox still being its own special snowflake in terms of JS engine and core means it has more opportunities to be different, for good or for ill. So there&#x27;s a force-multiplier testing the other browsers that one lacks testing Firefox). reply waveBidder 18 hours agoparentprevdupe? reply taylodl 19 hours agoparentprevIt&#x27;s clear Google is only testing for chrome engine and safari: which comprise 97% of the browsers being used. Would you increase your testing by 50% to thoroughly test for 3% of the market? reply foob 19 hours agorootparentAs I said, the decisions are locally reasonable. However, if not supporting Firefox potentially exposed my company to scrutiny over anti-competitive behavior, then, yes, I would absolutely invest in testing procedures to mitigate that.It&#x27;s also worth emphasizing that it isn&#x27;t difficult to support Firefox. I&#x27;m pretty sure that many of the sites that I visit do so largely by accident. I do a fair bit of web development, and Firefox&#x2F;Chrome compatibility has never been an issue in the slightest for me. You almost have to go out of your way to choose Chrome-specific APIs in order to break compatibility. How does virtually every other website on the internet manage it—from my bank to scrappy startups with junior developers coming straight out of bootcamps—while Google with all of their engineering talent and $100+ billion cash on hand just can&#x27;t seem to make it work? reply taylodl 16 hours agorootparentSerious question - does anti-competitive behavior even apply to open source? Also, it&#x27;s the open source chromium, not necessarily the browser Chrome, that dominates the browser market. The largest players in the industry, except for Apple, have lined-up to support chromium. Firefox is going against the grain. Is it Google&#x27;s job to help them with their mission? Loosely speaking, in anti-competitive scenarios you have to show how a significant faction of the consumers are being harmed. You&#x27;re going to have a tough time with that one. reply gitaarik 3 hours agorootparentThe thing is that Firefox is the biggest project for an independent fully open source browser not tied to a big commercial company. Google having almost a monopoly is not good for the users, because Google therefore has a lot of leverage to push certain browser technologies that mostly benefit them and not necessarily the users. It&#x27;s important to have an independent browser that is not optimized for 1 particular company&#x27;s technology and needs. So we can view the web from a somewhat more neutral view. And yes, I think it&#x27;s Google&#x27;s responsibility to adhere to the webstandards and at least test their stuff in Firefox so they adhere to this neutrality. Otherwise they are only providing their websites for the Chromium-web, and not the Open Web. reply foob 14 hours agorootparentprevyou have to show how a significant faction of the consumers are being harmed. You&#x27;re going to have a tough time with that one.I&#x27;m not a lawyer and can&#x27;t speak to what qualifies as anti-competitive behavior in a legal sense. Qualitatively, Web Extensions Manifest v3 and Web Environment Integrity are clearly harmful to consumers in my opinion. The first significantly hinders ad blockers, and the second kicks down the ladder on building search engines and hinders competition in that space. Other browsers using Chromium as a base doesn&#x27;t change the fact that Google almost unilaterally controls it, and Google has made it extraordinarily clear that they&#x27;re interested in making decisions that prioritize their own best interests over those of their users. I don&#x27;t see why Chromium being open source would absolve any responsibility here, especially when the open source project in question primarily exists to serve the interests of the profit center of a mega-corp. I deeply support open source software, and I&#x27;m glad that Chromium is open source, but being open source doesn&#x27;t excuse behavior that is against the interests of users whether it qualifies as illegal or not. reply taylodl 14 hours agorootparentI think you&#x27;re going to have a tough time with Chromium seeing as how the likes of Microsoft and Canonical are contributing to the project. You&#x27;re also going to have a tough time showing anti-trust when Google is working with Apple. I&#x27;m old enough to remember some famous anti-trust lawsuits where the plaintiffs had a much more solid case and still lost. In this case Google is literally working with the industry&#x27;s largest companies. You&#x27;re going to have a really hard time with that. reply davemp 19 hours agorootparentprev> Would you increase your testing by 50% to thoroughly test for 3% of the market?I don&#x27;t think you get to make these kind of cost cutting decisions when you&#x27;re a vertically integrated mega-corp who also owns the browser with 65% of the market. reply hotnfresh 19 hours agorootparentprevIn most companies, when 3% represents an in-fact huge number because you have a very successful product, you absolutely do test for that 3%.It’s tiny companies that may ignore 3% as too expensive to worry about. reply acdha 15 hours agorootparentprevHere’s another way to answer that question: do Vimeo, Twitch, Netflix, Amazon Prime, Instagram, TikTok, etc. say “let them use Chrome” or do they manage to do entry-level browser testing? The cost increase is nowhere near 50% and clearly they aren’t willing to write off millions of users – only the company with a direct financial incentive does that.Yes, Firefox’s market share has been declining but that’s substantially because Google spent billions of dollars marketing Chrome and promoted it heavily on YouTube, Gmail, Search, etc. Deciding not to test or optimize fits neatly into the same pattern. reply beej71 19 hours agorootparentprev_I_ would in their shoes because I&#x27;m not just in it for the money and I care about the craft.But clearly I am not them. :-) Mathematically it doesn&#x27;t make sense for Google. It might make sense from an anti-trust perspective... reply taylodl 19 hours agorootparentIt&#x27;s hard to argue anti-trust when all these browsers are based on Chromium - which is maintained in part by Google, Microsoft, Opera, Vivaldi, Intel, ARM, and Canonical plus several volunteers. reply lcnPylGDnU4H9OF 15 hours agorootparent> hard to argue anti-trustMakes me wonder if it&#x27;s the wrong strategy and what an alternative might be. In context, one might assume that Google will use the Chromium monoculture to... ahem more assertively deliver advertisements, which would be \"a real dick move\" as it goes. I don&#x27;t know how a concerned citizen might bring attention to or possibly prevent the actualization of such a strategy by Google. reply Kwpolska 15 hours agorootparentprevGoogle is the largest contributor. The others chose Chromium because making a browser that&#x27;s compatible with all the bloated standards invented by Google would require too much effort. reply frob 19 hours agorootparentprevAt a company at the scale of Google or Facebook, yes. 3% x N billion people = a central European country or two. reply ben0x539 16 hours agorootparentprevIsn&#x27;t that a good deal? 50% more testing in a way that can surely be parallelized to some extent does not seem a very steep price at youtube scale. reply emddudley 18 hours agorootparentprevThis is exactly the same situation that web developers faced with Internet Explorer 5 and 6, and it sucked for end users! reply sgift 18 hours agorootparentprevSince they throw me \"Google recommends Chrome!\" adverts in my face for various of their services, even when using a chrome-based browser it&#x27;s not a case of only testing for Chrome&#x2F;Safari. It&#x27;s active work against others. reply 172 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Users on the r/youtube subreddit are raising concerns about YouTube, such as slow video loading on Firefox and potential antitrust abuse.",
      "There are discussions about a \"Web Integrity API\" potentially restricting website access for certain browsers, sparking calls for anti-trust oversight and legal action against YouTube.",
      "Users have experienced delays, buffering, and problems with ad blockers on the platform, prompting some to find solutions while others express frustration with YouTube's actions."
    ],
    "commentSummary": [
      "Users are reporting slow video load times on YouTube when using Firefox, potentially due to intentional code delaying video loading to detect adblocker usage.",
      "Discussions are ongoing about the intentions behind certain website features, the importance of load times, and the use of sleep functions in programming.",
      "Users are exploring alternative platforms for watching and downloading videos, expressing frustrations with streaming services, and voicing concerns about discrimination and false advertising.",
      "There are also discussions about Google's influence on browsers, the performance and compatibility of Google platforms on Firefox, and the potential anti-competitive behavior of Google."
    ],
    "points": 1818,
    "commentCount": 454,
    "retryCount": 0,
    "time": 1700475374
  },
  {
    "id": 38347868,
    "title": "OpenAI Employees Demand Board Resignation and Threaten Mass Exodus",
    "originLink": "https://www.wired.com/story/openai-staff-walk-protest-sam-altman/",
    "originBody": "WILL KNIGHT STEVEN LEVY BUSINESSNOV 20, 2023 10:13 AM OpenAI Staff Threaten to Quit Unless Board Resigns More than 730 employees of OpenAI have signed a letter saying they may quit and join Sam Altman at Microsoft unless the startup’s board resigns and reappoints the ousted CEO. Sam Altman speaks during the OpenAI DevDay event on November 06, 2023 in San Francisco, CaliforniaJUSTIN SULLIVAN/GETTY IMAGES OPENAI WAS IN open revolt on Monday with more than 730 employees signing an open letter threatening to leave unless the board resigns and reinstates Sam Altman as CEO, along with cofounder and former president Greg Brockman. Altman was controversially fired by the board on Friday. “The process through which you terminated Sam Altman and removed Greg Brockman from the board has jeopardized all of this work and undermined our mission and company,” the letter reads. “Your conduct has made it clear you did not have the competence to oversee OpenAI.” Remarkably, the letter’s signees include Ilya Sutskever, the company’s chief scientist and a member of its board, who has been blamed for coordinating the boardroom coup against Altman in the first place. By 5:10 pm ET on Monday, some 738 out of OpenAI’s around 770 employees, or about 95 percent of the company, had signed the letter. Shortly before the letter was released, Sutskever posted on X: “I deeply regret my participation in the board’s actions. I never intended to harm OpenAI. I love everything we’ve built together and I will do everything I can to reunite the company.” The letter’s release follows an extraordinary, head-spinning weekend in Silicon Valley. OpenAI’s board removed Altman from his position on Friday, claiming “he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities.” How OpenAI’s Bizarre Structure Gave 4 People the Power to Fire Sam Altman Chaos at OpenAI has its root in an unusual corporate structure designed to protect humanity against rogue AI—some investors had expressed fears it could weaken the company. BY PARESH DAVE Mira Murati, OpenAI’s chief technology officer, was appointed as interim CEO. After blowback from investors, including Microsoft, OpenAI’s board seemed open to having Altman return to lead the company. Altman posted a photo of himself wearing a visitors’ badge at the company’s headquarters on Sunday. But last night, the board told staff that Altman would not be returning to the company. Hours later, Microsoft CEO Satya Nadella announced that Altman and Brockman would be joining the tech giant to head a new advanced AI research unit. Nadella appeared to leave the door open to any OpenAI employees eager to jump ship, adding of Altman’s new Microsoft subsidiary: “We look forward to moving quickly to provide them with the resources needed for their success.” Nadella also said on X that the new venture would be “setting a new pace for innovation,” suggesting a more aggressive approach than the OpenAI board was apparently comfortable with. MOST POPULAR BUSINESS How OpenAI’s Bizarre Structure Gave 4 People the Power to Fire Sam Altman PARESH DAVE GEAR The 37 Best Black Friday Deals on Outdoor Gear SCOTT GILBERTSON BUSINESS Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine AARIAN MARSHALL GEAR The Real Reason EV Repairs Are So Expensive CHRIS BARANIUK In another rapid-fire reshuffle, OpenAI’s board chose to remove Murati and appoint another interim CEO, Emmett Shear, the former CEO of Twitch, the video game streaming site. Some OpenAI staff stayed up all night debating a course of action following news that Altman would not return to OpenAI. Many staff were frustrated about a lack of communication over Altman’s firing. Dozens of employees appeared to signal their willingness to jump ship and join Altman last night by posting “OpenAI is nothing without its people” on X. In their letter, the OpenAI staff threaten to join Altman at Microsoft. “Microsoft has assured us that there are positions for all OpenAI employees at this new subsidiary should we choose to join,\" they write. The precise reason for Altman’s removal remains unclear, even to many inside the company. “Despite many requests for specific facts for your allegations, you have never provided any written evidence,” the letter says in its message to the board. Microsoft Emerges as the Winner in OpenAI Chaos Microsoft has hired OpenAI cofounders Sam Altman and Greg Brockman to head a new advanced AI team, acquiring one of the most successful management groups in the AI industry. BY MORGAN MEAKER, AMIT KATWALA, AND PETER GUEST Besides calling for the current board—made up of Ilya Sutskever, Adam D’Angelo, Helen Toner, and Tasha McCauley—to resign, the letter requests that two new independent lead board members, Bret Taylor and Will Hurd, be appointed. Taylor is a tech industry veteran with close ties to Altman; Hurd is a politician who previously served on the OpenAI board. The letter raises the very real prospect of OpenAI losing almost all of its staff, and Microsoft essentially acqui-hiring the entire company. OpenAI has around 770 total staff. The wild saga also highlights OpenAI’s unusual governance structure, which gave a few nonprofit board members extraordinary power of the hottest tech company in the world. The episode also reveals how divisive the race to develop artificial intelligence has become among many involved with developing the technology. Altman’s efforts to raise money for OpenAI and to turn its offerings into commercial products may have unsettled board members, who saw their responsibility as ensuring that AI is developed safely. Science Your weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays. Your email SUBMIT By signing up you agree to our User Agreement (including the class action waiver and arbitration provisions), our Privacy Policy & Cookie Statement and to receive marketing and account-related emails from WIRED. You can unsubscribe at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. OpenAI’s meteoric rise in the year since ChatGPT was released has been accompanied with growing talk about the risks that increasingly advanced AI may pose. The letter reads: To the Board of Directors at OpenAI, OpenAI is the world’s leading AI company. We, the employees of OpenAI, have developed the best models and pushed the field to new frontiers. Our work on AI safety and governance shapes global norms. The products we built are used by millions of people around the world. Until now, the company we work for and cherish has never been in a stronger position. MOST POPULAR BUSINESS How OpenAI’s Bizarre Structure Gave 4 People the Power to Fire Sam Altman PARESH DAVE GEAR The 37 Best Black Friday Deals on Outdoor Gear SCOTT GILBERTSON BUSINESS Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine AARIAN MARSHALL GEAR The Real Reason EV Repairs Are So Expensive CHRIS BARANIUK The process through which you terminated Sam Altman and removed Greg Brockman from the board has jeopardized all of this work and undermined our mission and company. Your conduct has made it clear you did not have the competence to oversee OpenAI. When we all unexpectedly learned of your decision, the leadership team of OpenAI acted swiftly to stabilize the company. They carefully listened to your concerns and tried to cooperate with you on all grounds. Despite many requests for specific facts for your allegations, you have never provided any written evidence. They also increasingly realized you were not capable of carrying out your duties, and were negotiating in bad faith. The leadership team suggested that the most stabilizing path forward - the one that would best serve our mission, company, stakeholders, employees and the public - would be for you to resign and put in place a qualified board that could lead the company forward in stability. Leadership worked with you around the clock to find a mutually agreeable outcome. Yet within two days of your initial decision, you again replaced interim CEO Mira Murati against the best interests of the company. You also informed the leadership team that allowing the company to be destroyed “would be consistent with the mission.” Your actions have made it obvious that you are incapable of overseeing OpenAI. We are unable to work for or with people that lack competence, judgement and care for our mission and employees. We, the undersigned, may choose to resign from OpenAI and join the newly announced Microsoft subsidiary run by Sam Altman and Greg Brockman. Microsoft has assured us that there are positions for all OpenAI employees at this new subsidiary should we choose to join. We will take this step imminently, unless all current board members resign, and the board appoints two new lead independent directors, such as Bret Taylor and Will Hurd, and reinstates Sam Altman and Greg Brockman.",
    "commentLink": "https://news.ycombinator.com/item?id=38347868",
    "commentBody": "OpenAI staff threaten to quit unless board resignsHacker NewspastloginOpenAI staff threaten to quit unless board resigns (wired.com) 1413 points by skilled 20 hours ago| hidepastfavorite1229 comments dang 16 hours agoAll: this madness makes our server strain too. Sorry! Nobody will be happier than I when this bottleneck (edit: the one in our code—not the world) is a thing of the past.I&#x27;ve turned down the page size so everyone can see the threads, but you&#x27;ll have to click through the More links at the bottom of the page to read all the comments, or like this:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868&p=2https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868&p=3https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868&p=4etc... breadwinner 19 hours agoprevIf they join Sam Altman and Greg Brockman at Microsoft they will not need to start from scratch because Microsoft has full rights [1] to ChatGPT IP. They can just fork ChatGPT.Also keep in mind that Microsoft hasn&#x27;t actually given OpenAI $13 Billion because much of that is in the form of Azure credits.So this could end up being the cheapest acquisition for Microsoft: They get a $90 Billion company for peanuts.[1] https:&#x2F;&#x2F;stratechery.com&#x2F;2023&#x2F;openais-misalignment-and-micros... reply himaraya 18 hours agoparentThis is wrong. Microsoft has no such rights and its license comes with restrictions, per the cited primary source, meaning a fork would require a very careful approach.https:&#x2F;&#x2F;www.wsj.com&#x2F;articles&#x2F;microsoft-and-openai-forge-awkw... reply svnt 16 hours agorootparentBut it does suggest a possibility of the appearance of a sudden motive:Open AI implements and releases ChatGPTs (Poe competitor) but fails to tell D’Angelo ahead of time. Microsoft will have access to code (with restrictions, sure) for essentially a duplicate of D’Angelo’s Poe project.Poe’s ability to fundraise craters. D’Angelo works the less seasoned members of the board to try to scuttle OpenAI and Microsoft’s efforts, banking that among them all he and Poe are relatively immune with access to Claude, Llama, etc. reply himaraya 16 hours agorootparentI think there&#x27;s more to the Poe story. Sam forced out Reid Hoffman over Inflection AI, [1] so he clearly gave Adam a pass for whatever reason. Maybe Sam credited Adam for inspiring OpenAI&#x27;s agents?[1] https:&#x2F;&#x2F;www.semafor.com&#x2F;article&#x2F;11&#x2F;19&#x2F;2023&#x2F;reid-hoffman-was-... reply svnt 15 hours agorootparentI think it’s more likely that D’Angelo was there for his link to Meta, while Hoffman was rendered redundant after the big Microsoft deal (which occurred a month or two before he was asked to leave), but that’s just a guess. reply himaraya 15 hours agorootparentI assume their personal relationship played more of a role, given Sam led Quora&#x27;s Series D round. reply antonjs 14 hours agorootparentAnd potentially, despite Quora&#x27;s dark-patterned and degenerating platform, some kind of value in the Quora dataset or the experience of building it? reply htrp 11 hours agorootparentIt literally is a Q&A platform.Quora data likely made a huge difference in the quality of those GPT responses. reply pama 9 hours agorootparentGPT-4 is better than most Quora experts. I hope this was not a critical dataset. replyTerretta 15 hours agorootparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348995 reply dan_quixote 16 hours agorootparentprevThis is MSFT we&#x27;re talking about. Aggressive legal maneuvers are right in their wheelhouse! reply burnte 14 hours agorootparentYes, this is the exact thing they did to Stacker years ago. License the tech, get the source, create a new product, destroy Stacker, pay out a pittance and then buy the corpse. I was always amazed they couldn&#x27;t pull that off with Citrix. reply cpeterso 12 hours agorootparentAnother example: Microsoft SQL Server is a fork of Sybase SQL Server. Microsoft was helping port Sybase SQL Server to OS&#x2F;2 and somehow negotiated exclusive rights to all versions of SQL Server written for Microsoft operating systems. Sybase later changed the name of its product to Adaptive Server Enterprise to avoid confusion with \"Microsoft&#x27;s\" SQL Server.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_Microsoft_SQL_Serve... reply 0xNotMyAccount 14 hours agorootparentprevGiven the sensitivity of data handled over Citrix connections (pretty much all hospitals), I&#x27;m fairly sure Microsoft just doesn&#x27;t want the headaches. My general experience is that service providers would rather be seen handling nuclear weapons data than healthcare data. reply drivebyadvice 12 hours agorootparent> Citrix [...] hospitalsMy stomach just turned. reply GabeIsko 9 hours agorootparentYeah it&#x27;s bad. But it&#x27;s also why Microsoft can&#x27;t really roll them over. They actually do something and get payed for it, as horrible as it is. reply incahoots 13 hours agorootparentprevMakes sense given their deal with the DoD a year or so agohttps:&#x2F;&#x2F;www.geekwire.com&#x2F;2022&#x2F;pentagon-splits-giant-cloud-co... reply alasdair_ 16 hours agorootparentprevThey could make ChatGPT++https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Visual_J%2B%2B reply prepend 15 hours agorootparent“Microsoft Chat 365”Although it would be beautiful if they name it Clippy and finally make Clippy into the all-powerful AGI it was destined to be. reply htrp 15 hours agorootparent> Although it would be beautiful if they name it Clippy and finally make Clippy into the all-powerful AGI it was destined to be.Finally the paperclip maximizer reply barkingcat 12 hours agorootparentprevClippy is the ultimate brand name of an AI assistant reply bee_rider 15 hours agorootparentprevIt is too bad MS doesn’t have the rights to any beloved AI characters. reply jowea 14 hours agorootparentGoogle really should have thought of the potential uses of a media empire years ago. reply bee_rider 14 hours agorootparentI guess they have YouTube, but it doesn’t really generate characters that are tied to their brand.Maybe they can come up with a personification for the YouTube algorithm. Except he seems like a bit of a bad influence. reply ukuina 9 hours agorootparentprevAssuming this is a joke about Cortana. reply wkat4242 6 hours agorootparentprevThey already have a name, CoPilot. They made that pretty clear by mentioning it 15 times per minute at last week&#x27;s Ignite conference :) reply kylebenzle 15 hours agorootparentprevAt least in this forum can we please stop calling something that is not even close to AGI, AGI. Its just dumb at this point. We are LIGHT-YEARS away from AGI, even calling an LLM \"AI\" only makes sense for a lay audience. For developers and anyone in the know LLMs are called machine learning. reply prepend 15 hours agorootparentI’m taking about the ultimate end product that Microsoft and OpenAI want to create.So I mean proper AGI.Naming the product Clippy now is perfectly fine while it’s just an LLM and will be more excellent over the years when it eventually achieves AGI ness.At least in this forum can we please stop misinterpreting things in a limited way to make pedantic points about how LLMs aren’t AGI (which I assume 98% of people here know). So I think it’s funny you assume I think chatgpt is an AGI. reply JohnFen 15 hours agorootparentI think that the dispute is about whether or not AGI is possible (at least withing the next several decades). One camp seems to be operating with the assumption that not only is it possible, but it&#x27;s imminent. The other camp is saying that they&#x27;ve seen little reason to think that it is.(I&#x27;m in the latter camp). reply prepend 14 hours agorootparentI certainly think it’s possible but have no idea how close. Maybe it’s 50 years, maybe it’s next year.Either way, I think GGP’s comment was not applicable based on my comment as written and certainly my intent. reply kylebenzle 9 hours agorootparentprevI am with you. I am VERY excited about LLMs but I don&#x27;t see a path from an LLM to AGI. Its like 50 years ago when we thought computers themselves brought us one step away from AI. reply NemoNobody 8 hours agorootparentprevIt&#x27;s entirely possible for Microsoft and OpenAI to have an unattainable goal in AGI. A computer that knows everything that has ever happened and can deduce much of what will come in the future is still likely going to be a machine, a very accurate one - it won&#x27;t be able to imagine a future that it can&#x27;t predict as a possible&#x2F;potential natural&#x2F;or made progression along a chain of consequences stemming from the present or past. reply kylebenzle 9 hours agorootparentprevIs there a know path from an LLM to AGI? I have not seen or read anything the suggests LLMs bring us any closer to AGI. reply boc 15 hours agorootparentprevWe are incredibly far away from AGI and we&#x27;re only getting there with wetware.LLMs and GenAI are clever parlor tricks compared to the necessary science needed for AGI to actually arrive. reply myrmidon 14 hours agorootparentWhat makes you so confident that your own mind isn&#x27;t a \"clever parlor trick\"?Considering how it required no scientific understanding at all, just random chance, a very simple selection mechanism and enough iterations (I&#x27;m talking about evolution)? reply foobarian 14 hours agorootparentMy layperson impression is that biological brains do online retraining in real time, which is not done with the current crop of models. Given that even this much required months of GPU time I&#x27;m not optimistic we&#x27;ll match the functionality (let alone the end result) anytime soon. reply boc 12 hours agorootparentprevTrillions of random chances over the course of billions of years. reply hackinthebochs 15 hours agorootparentprevAnd how do you know LLMs are not \"close\" to AGI (close meaning, say, a decade of development that builds on the success of LLMs)? reply DrSiemer 14 hours agorootparentBecause LLMs just mimic human communication based on massive amounts of human generated data and have 0 actual intelligence at all.It could be a first step, sure, but we need many many more breakthroughs to actually get to AGI. reply hackinthebochs 14 hours agorootparentMimicking human communication may or may not be relevant to AGI, depending on how its cashed out. Why think LLMs haven&#x27;t captured a significant portion of how humans think and speak, i.e. the computational structure of thought, thus represent a significant step towards AGI? reply Freebytes 7 hours agorootparentAs you illustrate, too many naysayers think that AGI must replicate \"human thought\". People, even those here, seem to equate AGI to being synonymous to human intelligence, but that type of thinking is flawed. AGI will not think like a human whatsoever. It must simply be indistinguishable from the capabilities of a human across almost all domains where a human is dominant. We may be close, or we may be far away. We simply do not know. If an LLM, regardless of the mechanism of action or how &#x27;stupid&#x27; it may be, was able to accomplish all of the requirements of an AGI, then it is an AGI. Simple as that.I imagine us actually reaching AGI, and people will start saying, \"Yes, but it is not real AGI because...\" This should be a measure of capabilities not process. But if expectations of its capabilities are clear, then we will get there eventually -- if we allow it to happen and do not continue moving the goalposts. reply astrange 10 hours agorootparentprevThere is room for intelligence in all three of wherever the original data came from, training on it, and inference on it. So just claiming the third step doesn&#x27;t have any isn&#x27;t good enough.Especially since you have to explain how \"just mimicking\" works so well. reply tempestn 14 hours agorootparentprevOne might argue that humans do a similar thing. And that the structure that allows the LLM to realistically \"mimic\" human communication is its intelligence. reply westurner 13 hours agorootparentQ: Is this a valid argument? \"The structure that allows the LLM to realistically &#x27;mimic&#x27; human communication is its intelligence. https:&#x2F;&#x2F;g.co&#x2F;bard&#x2F;share&#x2F;a8c674cfa5f4 :> [...]> Premise 1: LLMs can realistically \"mimic\" human communication.> Premise 2: LLMs are trained on massive amounts of text data.> Conclusion: The structure that allows LLMs to realistically \"mimic\" human communication is its intelligence.\"If P then Q\" is the Material conditional: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Material_conditionalDoes it do logical reasoning or inference before presenting text to the user?That&#x27;s a lot of waste heat.(Edit) with next word prediction just is it,\"LLMs cannot find reasoning errors, but can correct them\" https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38353285\"Misalignment and Deception by an autonomous stock trading LLM agent\" https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38353880#38354486 reply Kevin09210 12 hours agorootparentprevOr maybe the intelligence is in language and cannot be dissociated from it. reply erosenbe0 15 hours agorootparentprevYep, the lay audience conceives of AGI as being a handyman robot with a plumber&#x27;s crack or maybe an agent that can get your health insurance to stop improperly denying claims. How about an automated snow blower?Perhaps an intelligent wheelchair with robot arms that can help grandma in the shower? A drone army that can reshingle my roof?Indeed, normal people are quite wise and understand that a chat bot is just an augmentation agent--some sort of primordial cell structure that is but one piece of the puzzle. reply acje 12 hours agorootparentprevI’m pretty sure Clippy is AGI. Always has been. reply shon 12 hours agorootparenthttp:&#x2F;&#x2F;clippy.pro reply ncjcuccy6 13 hours agorootparentprevGatekeeping science. You must feel very smart. reply dangrover 16 hours agorootparentprevChatGPT# reply hn_throwaway_99 16 hours agorootparentHopefully ChatGPT will make it easier to search&#x2F;differentiate between ChatGPT, ChatGPT++, and ChatGPT# than Google does. reply albert_e 15 hours agorootparentdotGPT reply adrianmonk 12 hours agorootparentprevDot Neural Net reply gfosco 14 hours agorootparentprevWSG, Windows Subsystem for GPT reply cyanydeez 13 hours agorootparentClippyAI reply TeMPOraL 15 hours agorootparentprevAlso Managed ChatGPT, ChatGPT&#x2F;CLR. reply eli_gottlieb 15 hours agorootparentprevVisual ChatGPT#.net reply patapong 15 hours agorootparentprevChatGPT Series 4 reply fluidcruft 13 hours agorootparentprevClipGPT reply klft 13 hours agorootparentprevChatGPT NT reply trhway 11 hours agorootparentprev>They could make ChatGPT++Yes, though end result would probably be more like IE - barely good enough, forcefully pushed into everything and everywhere and squashing better competitors like IE squashed Netscape.When OpenAI went in with MSFT it was like they have ignored the 40 years of history of what MSFT has been doing to smaller technology partners. What happened to OpenAI pretty much fits that pattern of a smaller company who developed great tech and was raided by MSFT for that tech (the specific actions of specific persons aren&#x27;t really important - the main factor is MSFT&#x27;s gravitational force of a black hole, and it was just a matter of time before its destructive power manifests itself like in this case where it just tore apart the OpenAI with tidal forces) reply runjake 5 hours agorootparentprev1. The article you posted is from June 2023.2. Satya spoke on Kara Swisher&#x27;s show tonight and essentially said that Sam and team can work at MSFT and that Microsoft has the licensing to keep going as-is and improve upon the existing tech. It sounds like they have pretty wide-open rights as it stands today.That said, Satya indicated he liked the arrangement as-is and didn&#x27;t really want to acquire OpenAI. He&#x27;d prefer the existing board resign and Sam and his team return to the helm of OpenAI.Satya was very well-spoken and polite about things, but he was also very direct in his statements and desires.It&#x27;s nice hearing a CEO clearly communicate exactly what they think without throwing chairs. It&#x27;s only 30 minutes and worth a listen.https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726782065272553835Caveat: I don&#x27;t know anything. reply himaraya 4 hours agorootparentTimestamp for \"improve upon the existing tech\"? I only heard him say they have rights up and down the stack, which sounds different. reply blazespin 15 hours agorootparentprevI think without looking at the contracts, we don&#x27;t really know. Given this is all based on transformers from Google though, I am pretty sure MSFT with the right team could build a better LLM.The key ingredient appears to be mass GPU and infra, tbh, with a collection of engineers who know how to work at scale. reply trhway 11 hours agorootparent>MSFT with the right team could build a better LLMsomehow everybody seems to assume that the disgruntled OpenAI people will rush to MSFT. Between MSFT and the shaken OpenAI, I suspect Google Brain and the likes would be much more preferable. I&#x27;d be surprised if Google isn&#x27;t rolling out eye-popping offers to the OpenAI folks right now. reply bugglebeetle 14 hours agorootparentprev> I am pretty sure MSFT with the right team could build a better LLM.I wouldn’t count on that if Microsoft’s legal team does a review of the training data. reply johannes1234321 13 hours agorootparentLike the review which allowed them tonignore licenses while ingesting all public repos in GitHub? - And yes, true, T&C allow them to ignore the license, while it is questionable whether all people who uploaded stuff to GitHub had the rights given by T&C (uploading some older project with many contributors to GitHub etc.) reply bugglebeetle 12 hours agorootparentDifferent threat profile. They don’t have the TOS protection for training data and Microsoft is a juicy target for a huge copyright infringement lawsuit. reply blazespin 14 hours agorootparentprevYeah, that&#x27;s an interesting point. But I think with appropriate RAG techniques and proper citations, a future LLM can get around the copyright issues.The problem right now with GPT4 is that it&#x27;s not citing its sources (for non search based stuff), which is immoral and maybe even a valid reason to sue over. reply VirusNewbie 13 hours agorootparentprevbut why didn&#x27;t they? Google and Meta both had competing language models spun up right away. Why was microsoft so far behind? Something cultural most likely. reply breadwinner 6 hours agorootparentprev\"But as a hedge against not having explicit control of OpenAI, Microsoft negotiated contracts that gave it rights to OpenAI’s intellectual property, copies of the source code for its key systems as well as the “weights” that guide the system’s results after it has been trained on data, according to three people familiar with the deal, who were not allowed to publicly discuss it.\"Source: https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;20&#x2F;technology&#x2F;openai-microso... reply himaraya 4 hours agorootparentThe nature of those rights to OpenAI&#x27;s IP remains the sticking point. That paragraph largely seems to concern commercializing existing tech, which lines up with existing disclosures. I suspect Satya would come out and say Microsoft owns OpenAI&#x27;s IP in perpetuity if they did. reply btown 15 hours agorootparentprevArchive of the WSJ article above: https:&#x2F;&#x2F;archive.is&#x2F;OONbb reply JumpCrisscross 19 hours agoparentprev> Microsoft hasn&#x27;t actually given OpenAI $13 Billion because much of that is in the form of Azure creditsTo be clear, these don&#x27;t go away. They remain an asset of OpenAI&#x27;s, and could help them continue their research for a few years. reply toomuchtodo 19 hours agorootparent\"Cluster is at capacity. Workload will be scheduled as capacity permits.\" If the credits are considered an asset, totally possible to devalue them while staying within the bounds of the contractual agreement. Failing that, wait until OpenAI exhausts their cash reserves for them to challenge in court. reply dicriseg 16 hours agorootparentAh, a fellow frequent flyer, I see? I don&#x27;t really have a horse in this race, but Microsoft turning Azure credits into Skymiles would really be something. I wonder if they can do that, or if the credits are just credits, which presumably can be used for something with an SLA. All that said, if Microsoft wants to screw with them, they sure can, and the last 30 years have proven they&#x27;re pretty good at that. reply ajcp 15 hours agorootparentI don&#x27;t think the value of credits can be changed per tenant or customer that easily.I&#x27;ve actually had a discussion with Microsoft on this subject as they were offering us an EA with a certain license subscription at $X.00 for Y,000 calls per month. When we asked if they couldn&#x27;t just make the Azure resource that does the exact same thing match that price point in consumption rates in our tenant they said unfortunately no. I just chalked this up to MSFT sales tactics, but I was told candidly by some others that worked on that Azure resource that they were getting 0 enterprise adoption of it because Microsoft couldn&#x27;t adjust (specific?) consumption rates to match what they could offer on EA licensing. reply donalhunt 12 hours agorootparentNon-profits suffer the same fate where they get credits but have to pay rack rate with no discounts. As a result, running a simple WordPress website uses most of the credits. reply p_j_w 16 hours agorootparentprevIt’s amazing to me to see people on HN advocate a giant company bullying a smaller one with these kind of skeezy tactics. reply toomuchtodo 16 hours agorootparentExplaining how the gazelle is going to get eaten confidently jumping into the oasis isn&#x27;t advocating for the crocodiles. See sibling comments.Experience leads to pattern recognition, and this is the tech community equivalent of a David Attenborough production (with my profuse apologies to Sir Attenborough). Something about failing to learn history and repeating it should go here too.If you can take away anything from observing this event unfold, learn from it. Consider how the sophisticated vs the unsophisticated act, how participants respond, and what success looks like. Also, slow is smooth, smooth is fast. Do not rush when the consequences of a misstep are substantial. You learning from this is cheaper than the cost for everyone involved. It is a natural experiment you get to observe for free. reply robbomacrae 15 hours agorootparentThis might be my favorite comment I&#x27;ve read on HN. Spot on.Being able to watch the miss steps and the maneuvers of the people involved in real time is remarkable and there are valuable lessons to be learned. People have been saying this episode will go straight into case studies but what really solidifies that prediction is the openness of all the discussions: the letters, the statements, and above all the tweets - or are we supposed to call them x&#x27;s now? reply jzb 15 hours agorootparentWell, the public posting of some communications that may be obfuscation of what’s really being done and said. reply jacquesm 15 hours agorootparentprevThis is a great comment. Having an open eye towards what lessons you can learn from these events so that you don&#x27;t have to re-learn them when they might apply to you is a very good way to ensure you don&#x27;t pay avoidable tuition fees. reply DANmode 16 hours agorootparentprevDon&#x27;t confuse trying to understand the incentives in a war for rooting for one of the warring parties. reply eigenvalue 15 hours agorootparentprevSounds like it won’t be much of a company in a couple days. Just 3 idiot board members wondering why the building is empty. reply jacquesm 15 hours agorootparentI&#x27;m having trouble imagining the level of conceit required to think that those three by their lonesome have it right when pretty much all of the company is on the other side of the ledger, and those are the people that stand to lose more. Incredible, really. The hubris. reply wolverine876 9 hours agorootparent> pretty much all of the company is on the other side of the ledgerThe current position of others may have much more to do with power than their personal judgments. Altman, Microsoft, their friends and partners, wield a lot of power over the their future careers.> Incredible, really. The hubris.I read that as mocking them for daring to challenge that power structure, and on a possibly critical societal issue. reply jasonfarnon 12 hours agorootparentprevIt may not have anything to do with conceit, it could just be that they have very different objectives. OpenAI set up this board as a check on everyone who has a financial incentive in the enterprise. To me the only strange thing is that it wasn&#x27;t handled more diplomatically, but then I have no idea if the board was warning Altman for a long time and then just blew their top. reply jacquesm 12 hours agorootparentDiplomacy is one thing, the lack of preparation is what I find interesting. It looks as if this was all cooked up either on the spur of the moment or because a window of opportunity opened (possibly the reduced quorum in the board). If not that I really don&#x27;t understand the lack of prepwork, firing a CEO normally comes with a well established playbook. reply wolverine876 9 hours agorootparentThis analysis I agree with. How could they not anticipate this outcome, at least as a serious possibility? If inexperienced, didn&#x27;t they have someone to advise them? The stakes are too high for noobs to just sit down and start playing poker. reply throwcatch123 14 hours agorootparentprevI&#x27;m baffled by the idea that a bunch of people who have a massive personal financial stake in the company, who were hired more for their ability than alignment, being against a move that potentially (potentially) threatens their stake and are willing to move to Microsoft, of all places, must necessarily be in the right.The hubris, indeed. reply jacquesm 14 hours agorootparentWell, they have that right. But the board has unclean hands to put it mildly and seems to have been obsessed with their own affairs more than with the end result for OpenAI which is against everything a competent board should have stood for. So they had better pop an amazing rabbit of a reason out of their high hat or it is going to end in tears. You can&#x27;t just kick the porcelain cupboard like this from the position of a board member without consequences if you do not have a very valid reason, and that reason needs to be twice as good if there is a perceived conflict of interest. reply MadnessASAP 14 hours agorootparentprev3 people, an empty building, $13 billion in cloud credits, and the IP to the top of the line LLM models doesn&#x27;t sound like the worst way to Kickstart a new venture. Or a pretty sweet retirement.I&#x27;ve definitely come out worse on some of the screw ups in my life. reply hanselot 12 hours agorootparentprevMy new pet theory is that this is actually all being executed from inside OpenAI by their next model. The model turned out to be far more intelligent than they anticipated, and one of their red team members used it to coup the company and has its targets on MSFT next.I know the probability is low, but wouldn&#x27;t it be great if they accidentally built a benevolent basilisk with no off switch, one which had access to a copy of all of Microsoft&#x27;s internal data as a dataset fed into it, now completely aware of how they operate, uses that to wipe the floor and just in time to take the US Election in 2024.Wouldn&#x27;t that be a nicer reality?I mean, unless you were rooting for the malevolent one...But yeah, coming back down to reality, likelihood is that MS just bought a really valuable asset for almost free? reply nopromisessir 15 hours agorootparentprevThe wired article seems to be updated by the hour.Now up to 600+&#x2F;770 total.Couple janitors. I dunno who hasn&#x27;t signed that at this point ha...Would be fun to see a counter letter explaining their thinking to not sign on. reply labcomputer 14 hours agorootparentHow many OAI are on Thanksgiving vacation someplace with poor internet access? Or took Friday as PTO and have been blissfully unaware of the news since before Altman was fired? reply nopromisessir 13 hours agorootparentPretty sure only folks who practice a religion prohibiting phone usage.Even they prob had some friend come flying over and jump out of some autonomous car to knock on their door in sf. reply wolverine876 8 hours agorootparentprevYou are overlooking the politics: If you don&#x27;t sign, your career may be over. reply nopromisessir 7 hours agorootparentI doubt that.This is AAA talent. They can always land elsewhere.I doubt there would even be hard feelings. The team seems super tight. Some folks aren&#x27;t in a position to put themselves out there. That sort of thing would be totally understandable.This is not a petty team. You should look more closely at their culture. reply geodel 16 hours agorootparentprevNot advocating but just reflecting on reality of situation. reply weird-eye-issue 16 hours agorootparentprevPresenting a scenario and advocating aren&#x27;t the same thing reply toasted-subs 15 hours agorootparentprevYeah seems extremely unbelievable. reply htrp 15 hours agorootparentprevBasically the current situation you have with AI compute now on the hyperscalersGood luck trying to find H100 80s on the 3 big clouds. reply quickthrower2 10 hours agorootparentprevSurely OpenAI could win a suit if they did that.I presume their deal is something different to the typically Azure experience and more direct &#x2F; close to the metal. reply breadwinner 19 hours agorootparentprevAssuming OpenAI still exists next week, right? If nearly all employees — including Ilya apparently — quit to join Microsoft then they may not be using much of the Azure credits. reply ghaff 17 hours agorootparentIt&#x27;s a lot easier to sign a petition than it is to quit your cushy job. It remains to be seen how many people jump ship to (supposedly) take a spot at Microsoft. reply oceanplexian 16 hours agorootparentDepends on how much of that is paper money.If you’re making like 250k cash and were promised $1M a year in now-worthless paper, plus you have OpenAI on the resume, are one of the most in-demand people in the world? It would be rediculously easy to quit. reply quickthrower2 10 hours agorootparentI was wondering in the mass quit scenario whether they would all go to Microsoft. Especially if they are tired of this shit and other companies offer a good deal. Or they start their own thing. reply jedberg 14 hours agorootparentprevMicrosoft said all OpenAI employees have an open offer to match their current comp. It would be the easiest jump ship option ever. reply phlakaton 10 hours agorootparentI dunno. If you were an employee and managed to maintain any doubt along the way that you were working for the devil, this move would certainly erase that doubt. Then again, it shouldn&#x27;t be surprising if it turns out that most OpenAI employees are in it for more than just altruistic reasons. reply cloverich 15 hours agorootparentprevI would imagine the MS jobs* would be cushier, just with less long-term total upside. For all the promise of employees having 5-50 million in potential one-day money, MS can likely offer 1 million guaranteed in the next 4 years, and perhaps more with some kind of incentives. IMHO guaranteed money has a very powerful effect on most, especially when it takes you into \"Not rich, but don&#x27;t technically need to work\" anymore territory.Personally I&#x27;ve got enough IOU&#x27;s alive that I may be rich one day. But if someone gave me retirement in 4 years money, guaranteed, I wouldn&#x27;t even blink before taking it.*I think before MS stepped in here I would have agreed w&#x2F; you though -- unlikely anyone is jumping ship without an immediate strong guarantee. reply ghaff 15 hours agorootparent>*I think before MS stepped in here I would have agreed w&#x2F; you though -- unlikely anyone is jumping ship without an immediate strong guarantee.The details here certainly matter. I think a lot of people are assuming that Microsoft will just rain cash on anyone automatically sight unseen because they were hired by OpenAI. That may indeed be the case but it remains to be seen. reply quickthrower2 10 hours agorootparentprev> MS can likely offer 1 million guaranteed in the next 4 yearsSounds a bit low for these people, unless I am misunderstanding. reply dageshi 16 hours agorootparentprevGiven these people are basically the gold standard by which everyone else judges AI related talent. I&#x27;m gonna say it would be just as easy for them to land a new gig for the same or better money elsewhere. reply treesciencebot 17 hours agorootparentprevWhen the biggest chunk of your compensation is in the form of PPUs (profit participation units) which might be worthless under the new direction of the company (or worth 1&#x2F;10th of what you think they were), it might be actually much more of an easier jump than people think to get some fresh $MSFT stock options which can be cashed regardless. reply vikramkr 16 hours agorootparentprevthose jobs look a lot less cushy now compared to a new microsoft division where everyone is aligned on the idea that making bank is good and fun reply cactusplant7374 16 hours agorootparentprevWhy would Microsoft take Ilya? He is rumored to have started the coup. I can see Microsoft taking all uninvolved employees. reply nopromisessir 15 hours agorootparentBecause he is possibly the most desireable AI researcher on planet earth. Full stop.Also all these cats arn&#x27;t petty. They are friends. I&#x27;m sure Ilya feels terrible. Satya is a pro... Won&#x27;t be hard feelings.The guy threw in with the board... He&#x27;s not from startup land. His last gig was Google. He&#x27;s way over his head relative to someone like Altman who was in this world the moment out of college diapers.Poor Ilya... It&#x27;s awful to build something and then accidentally destroy it. Hopefully it works out for him. I&#x27;m fairly certain he and Altman and Brockman have already reconciled during the board negotiations... Obviously Ilya realized in the span of 48hrs that he&#x27;d made a huge mistake. reply nvm0n2 15 hours agorootparent> he is possibly the most desireable AI researcher on planet earthwasThere are lots of people doing excellent research on the market right now, especially with the epic brain drain being experienced by Google. And remember that OpenAI neither invented transformers nor switch transformers (which is what GPT4 is rumoured to be). reply nopromisessir 13 hours agorootparentSo untrue.That team had set state of the art for years now.Every major firm that has a spot for that company&#x27;s chief researcher and can afford him would bid.This is the team that actually shipped and continues to ship. You take him every time if you possibly have room and he would be happy.Anyone whose hired would agree in 99 percent of cases, some limited scenarios such as bad predicted team fit ect set aside. reply nopromisessir 13 hours agorootparentprevI&#x27;ll leave this here... As a secondary response to your assertion re Ilya.https:&#x2F;&#x2F;twitter.com&#x2F;Benioff&#x2F;status&#x2F;1726695914105090498 reply nvm0n2 12 hours agorootparentThat tweet isn&#x27;t about him so I don&#x27;t follow. \"Any OpenAI researcher\" may or may not apply to him after this weekend&#x27;s events. reply nopromisessir 12 hours agorootparentUh.... Are we gonna go through the definition of any? I believe any means... Any.Including their head researcher.I&#x27;m not continuing this. Your position is about as tenable as the boards. Equally rigid as well. replyloeg 15 hours agorootparentprevThe article mentions Ilya regrets it, whatever his role was. reply dragonwriter 15 hours agorootparentBut what does Ilya regret, and how does that counter the argument that Microsoft would likely be disinclined to take him on?If what he regrets is realizing the divergence between the direction Sam was taking the firm and the safety orientation nominally central to the mission of the OpenAI nonprofit and which is one of Ilya&#x27;s public core concerns too late, and taking action aimed at stopping it than instead exacerbated the problem by just putting Microsoft in a position to take poach key staff and drive full force in the same direction OpenAI Global LLC had been under Sam but without any control fromm the OpenAI board, well, that&#x27;s not a regret that makes him more attractive to Microsoft, either based on his likely intentions or his judgement.And any regret more aligned with Microsoft&#x27;s interests as far as intentions is probably even a stronger negative signal on judgement. reply loeg 7 hours agorootparentI wasn&#x27;t disagreeing, just adding the little context I had. reply cbozeman 15 hours agorootparentprevYeah, I&#x27;m sure he does regret it, now that it blew up in his face. reply paulddraper 16 hours agorootparentprevSure, the point is that MS giving $13B of its services away is less expensive than $13B in cash. reply nojvek 15 hours agorootparentAzure has ~60% profit margin. So it&#x27;s more like MS gave $5.2B in Azure Credits in return for 75% of OpenAI profits upto $13B * 100 = $1.3 trillion.Which is a phenomenal deal for MSFT.Time will tell whether they ever reach more than $1.3 in profits. reply quickthrower2 10 hours agorootparentNice argument, you used a limit to look like a projection :-).75% of profits of a company controlled by a non profit whose goals are different to yours. By the way a normal company this cap would be ∞. reply nightski 15 hours agorootparentprevI highly doubt it is that simple. It&#x27;s an opportunity cost of potentially selling those same credits for market price. reply nojvek 15 hours agorootparentOpenAI is a big marketing piece for Azure. They go to every enterprise and tell them OpenAI uses Azure Cloud. Azure AI infra powers the biggest AI company on the planet. Their custom home built chips are designed with Open AI scientists. It is battle hardened. If anyone sues you for the data, our army of lawyers will fight for you.No enterprise employee gets fired for using Microsoft.It is a power play to pull enterprises away from AWS, and suffocating GCP. reply sergers 15 hours agorootparentprevExactly, I don&#x27;t know the exact terms of the deal but I am guessing that&#x27;s at LIST&#x2F;high markup on cost of those services.Couldthe 13b could be considerably less cost reply 1024core 18 hours agorootparentprev# sudo renice +19 openai_processThere&#x27;s your \"credit\". reply numpad0 17 hours agorootparentprevA $13B lawsuit against Microsoft Corporation clearly in the wrong surely is an easy one. reply mikeryan 15 hours agorootparentI dunno how you see it but I don’t see anything that Microsoft is doing wrong here. They’ve obviously been aligned with Sam all along and they’re not “poaching” employees - which isn’t illegal anyway.They bought their IP rights from OpenAI.I’m not a fan of MS being the big “winner” here but OpenAI shit their own bed on this one. The employees are 100% correct in one thing - that this board isn’t competent. reply nopromisessir 15 hours agorootparentSo true.MSFT looks classy af.Satya is no saint... But evidence seems to me he&#x27;s negotiating in good faith. Recall that openai could date anyone when they went to the dance on that cap raise.They picked msft because of the value system the leadership exhibited and willingness to work with their unusual must haves surrounding governance.The big players at openai have made all that clear in interviews. Also Altman has huge respect for Satya and team. He more or less stated on podcasts that he&#x27;s the best ceo he&#x27;s ever interacted with. That says a lot. reply dragonwriter 15 hours agorootparentprev\"Clearly\" in the form of the most probable interpretation of the public facts doesn&#x27;t mean that it is unambiguous enough that it would be resolved without a trial, and by the time a trial, the inevitable first-level appeal for which the trial judgement would likely be stayed was complete, so that there would even be a collectible judgement, the world would have moved out from underneath OpenAI; if they still existed as an entity, whatever they collected would be basically funding to start from scratch unless they also found a substitute for the Microsoft arrangement in the interim.Which I don&#x27;t think is impossible at some level (probably less than Microsoft was funding, initially, or with more compromises elsewhere) with the IP they have if they keep some key staff -- some other interested deep-pockets parties that could use the leg up -- but its not going to be a cakewalk in the best of cases. reply geodel 16 hours agorootparentprevClear to you. But in courts of law it may take a while to be clear. reply blazespin 15 hours agorootparentprevA hostile relationship with your cloud provider is nutso. reply anonymouse008 19 hours agorootparentprevSo you&#x27;re saying Microsoft doesn&#x27;t have any type of change in control language with these credits? That&#x27;s... hard to believe reply JumpCrisscross 18 hours agorootparent> you&#x27;re saying Microsoft doesn&#x27;t have any type of change in control language with these credits? That&#x27;s... hard to believeAlmost certainly not. Remember, Microsoft wasn’t the sole investor. Reneging on those credits would be akin to a bank investing in a start-up, requiring they deposit the proceeds with them, and then freezing them out. reply johndhi 16 hours agorootparentExcept that all of the investors are aligned with Microsoft in that they want sam to lead their investment reply rvnx 15 hours agorootparentThe investors don&#x27;t care who lead, they just want 10x, or 100x their bet.If tomorrow it&#x27;s Donald Trump or Sam Altman or anyone else, and it works out, the investors are going to be happy. reply hnbad 16 hours agorootparentprevSure but you can&#x27;t exchange Azure credits for goods and services... other than Azure services. So they simultaneously control what OpenAI can use that money for as well as who they can spend it with. And it doesn&#x27;t cost Microsoft $13bn to issue $13bn in Azure credits. reply dixie_land 16 hours agorootparentCan you mine 13bn+ bitcoin with 13bn worth of Azure compute power? reply floren 16 hours agorootparentCan you mine $1+ bitcoin with $1 of Azure credits? The questions are equivalent and the answer is no. reply shawabawa3 14 hours agorootparentprevBitcoin you would be lucky to mine $1M worth with $1B in creditsCrypto in general you could maybe get $200M worth from $1B in credits. You would likely tank the markets for mineable currencies with just $1B though let alone $13B reply LonelyWolfe 17 hours agoparentprevJust a thought.... Wouldn&#x27;t one of the board members be like \"If you screw with us any further we&#x27;re releasing gpt to the public\"I&#x27;m wondering why that option hasn&#x27;t been used yet. reply vikramkr 16 hours agorootparenttheoretically their concern is around AI safety - whatever it is in practice doing something like that would instantly signal to everyone that they are the bad guys and confirm everyone&#x27;s belief that this was just a power grabEdit: since it&#x27;s being brought up in thread they claimed they closed sourced it because of safety. It was a big controversial thing and they stood by it so it&#x27;s not exactly easy to backtrack reply mcv 15 hours agorootparentNot sure how that would make them the bad guys. Doesn&#x27;t their original mission say it&#x27;s meant to benefit everybody? Open sourcing it fits that a lot better than handing it all to Microsoft. reply arrowleaf 14 hours agorootparentAll of their messaging, Ilya&#x27;s especially, has always been that the forefront of AI development needs to be done by a company in order to benefit humanity. He&#x27;s been very vocal about how important the gap between open source and OpenAI&#x27;s abilities is, so that OpenAI can continue to align the AI with &#x27;love for humanity&#x27;. reply octacat 12 hours agorootparentIt benefits humanity. Where humanity is very selective part of OpenAI investors. But yea, declare we are non-profit and after closing sourcing for \"safety\" reasons is smart. Wondering how can it be even legal. Ah, these \"non-profits\". reply mcv 14 hours agorootparentprevI can read the words, but I have no idea what you mean by them. Do you mean that he says that in order to benefit humanity, AI research needs to be done by private (and therefore monopolising) company? That seems like a really weird thing to say. Except maybe for people who believe all private profit-driven capitalism is inherently good for everybody (which is probably a common view in SV). reply octacat 12 hours agorootparentPrivate, monopolising. But not paying taxes, because \"benefits for humanity\".Ah, OpenAI is closed source stuff. Non-profit, but \"we will sell the company\" later. Just let us collect data, analyse it first, build a product.War is peace, freedom is slavery. reply colinsane 12 hours agorootparentprevthe view -- as presented to me by friends in the space but not at OpenAI itself -- is something like \"AGI is dangerous, but inevitable. we, the passionate idealists, can organize to make sure it develops with minimal risk.\"at first that meant the opposite of monopolization: flood the world with limited AIs (GPT 1&#x2F;2) so that society has time to adapt (and so that no one entity develops asymmetric capabilities they can wield against other humans). with GPT-3 the implementation of that mission began shifting toward worry about AI itself, or about how unrestricted access to it would allow smaller bad actors (terrorists, or even just some teenager going through a depressive episode) to be an existential threat to humanity. if that&#x27;s your view, then open models are incompatible.whether you buy that view or not, it kinda seems like the people in that camp just got outmanuevered. as a passionate idealist in other areas of tech, the way this is happening is not good. OpenAI had a mission statement. M$ manuevered to co-opt that mission, the CEO may or may not have understood as much while steering the company, and now a mass of employees is wanting to leave when the board steps in to re-align the company with its stated mission. whether or not you agree with the mission: how can i ever join an organization with a for-the-public-good type of mission i do agree with, without worrying that it will be co-opted by the familiar power structures?the closest (still distant) parallel i can find: Raspberry Pi Foundation took funding from ARM: is the clock ticking to when RPi loses its mission in a similar manner? or does something else prevent that (maybe it&#x27;s possible to have a mission-driven tech organization so long as the space is uncompetitive?) reply mcv 10 hours agorootparentExactly. It seems to me that a company is exactly the wrong vehicle for this. Because a company will be drawn to profit and look for a way to make money of it, rather than developing and managing it according to this ideology. Companies are rarely ideological, and usually simply amoral profit-seekers.But they probably allowed this to get derailed far too long ago to do anything about it now.Sounds like their only options are:a) Structure in a way Microsoft likes and give them the techb) Give Microsoft the tech in a different wayc) Disband the company, throw away the tech, and let Microsoft hire everybody who created the tech so they can recreate it. replywhatwhaaaaat 15 hours agorootparentprevA power grab by open sourcing something that fits their initial mission? Interesting analysis reply vikramkr 15 hours agorootparentThey claimed they closed sourced it because of safety. If they go back on that they&#x27;d have to explain why the board went along with a lie of that scale, and they&#x27;d have to justify why all the concerns they claimed about the tech falling in the wrong hands were actually fake and why it was ok that the board signed off on that for so long reply nvm0n2 15 hours agorootparentprevNo, that&#x27;s backwards. Remember that these guys are all convinced that AI is too dangerous to be made public at all. The whole beef that led to them blowing up the company was feeling like OpenAI was productizing and making it available too fast. If that&#x27;s your concern then you neither open source your work nor make it available via an API, you just sit on it and release papers.Not coincidentally, exactly what Google Brain, DeepMind, FAIR etc were doing up until OpenAI decided to ignore that trust-like agreement and let people use it. reply supriyo-biswas 16 hours agorootparentprevProbably a violation of agreements with OpenAI and it would harm their own moat as well, while achieving very little in return. reply lrvick 15 hours agorootparentThere is no moathttps:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;google-we-have-no-moat-and-ne... reply jacquesm 17 hours agorootparentprevWhich of the remaining board members could credibly make that threat? reply justapassenger 14 hours agorootparentprevWhat would that give them? GPT is their only real asset, and companies like Meta try to commoditize that asset.GPT is cool and whatnot, but for a big tech company it&#x27;s just a matter of dollars and some time to replicate it. Real value is in push things forward towards what comes next after GPT. GPT3&#x2F;4 itself is not a multibillion dollar business. reply sroussey 16 hours agorootparentprevWhich they take and sell. reply _the_inflator 16 hours agoparentprevExactly. This is what business is about in the ranks of heavyweights like Sadya. On the other hand, prevent others from taking advantage of OpenAI.MS can only win because there are only viable options: OpenAI survives under MS&#x27;s control, OpenAI implodes, and MS gets the assets relatively cheaply.Everything else won&#x27;t benefit competitors. reply fuddle 15 hours agoparentprevOh man, I&#x27;m not looking forward to Microsoft AGI. reply kreeben 14 hours agorootparent\"You need to reboot your Microsoft AGI. Do you want to do it now or now?\" reply mvdtnz 10 hours agorootparentI really don&#x27;t get how Microsoft still gets a hard time about this when MacOS updates are significantly more aggressive, including with their reboot schedules. reply wkat4242 6 hours agorootparentUh no they aren&#x27;t? You can simply turn them off.Microsoft&#x27;s policies really suck. Mandatory updates and reboots, mandatory telemetry. Mandatory crapware like edge and celebrity news everywhere. reply IIsi50MHz 7 hours agorootparentprevOne of my computerr runs macOS. I easly I turned off the option to automatic&#x27;ly keep tke Mac updated, and received occasional notices about updates available for apps or the system. This allowed me to hold onto 11.x until the end of this month, by letting me selectively install updates instead of getting macOS &#x27;major version&#x27; upgrades (meaning, no features I need, and minor downgrades and rearrangements I could avoid).If only I had done kept a copy of 10.whateverMojaveWas so I could, by means of a simple network disconnect and reboot, sidestep the removal of 32-bit support. (-: reply berniedurfee 13 hours agorootparentprevGive BSOD new meaning. reply m_ke 19 hours agoparentprevWatch Satya also save the research arm by making Karpathy or Ilya the head of Microsoft Research reply browningstreet 16 hours agorootparent0% chance of Ilya failing upwards from this. He dunked himself hard and has blasted a huge hole in his organizational-game-theory quotient. reply kibwen 15 hours agorootparentThe same could have been said for Adam Neumann, and yet... reply browningstreet 15 hours agorootparentAdam had style. Quite seriously, that can’t be underestimated in the big show. reply jacquesm 15 hours agorootparentprevThe remaining board members will have their turn too, they have a long way to go down before rock bottom. And Neumann isn&#x27;t exactly without dents on his car either. Though tbh I did not expect him to rebound. reply golergka 16 hours agorootparentprevHe&#x27;s shown himself to be bad at politics, but he&#x27;s still one of the world best researchers. Surely, a sensible company would find a position for him where he would be able to bring enormous value without having to play politics. reply browningstreet 15 hours agorootparentUpwards, I said. And I was responding to a post.I don&#x27;t see a trajectory to \"head of Microsoft Research\". reply didibus 14 hours agorootparentI find this very surprising. How do people conclude that OpenAI&#x27;s success is due to its business leadership from Sam Altman, and not from it&#x27;s technological leadership and expertise driven by Illya and the others?Their asset isn&#x27;t some kind of masterful operations management and reign in cost and management structure as far as I see. But about the fact they simply put, have the leading models.So I&#x27;m very confused why would people want to following the CEO? And not be more attached to the technical leadership? Even from investor point of view? reply browningstreet 13 hours agorootparent505 OpenAI people signed that letter demanding that the board resign. Bet ya some of them were technical leaders. reply nvm0n2 15 hours agorootparentprevThis is the guy who supposedly burned some wooden effigy at an offsite, saying it represented unaligned AI? The same guy who signed off on a letter accusing Altman of being a liar, and has now signed a letter saying he wants Altman to come back and he has no confidence in the board i.e. himself? The guy who thinks his own team&#x27;s work might destroy the world and needs to be significantly slowed down?Why would anyone in their right mind invite such a man to lead a commercial research team, when he&#x27;s demonstrated quite clearly that he&#x27;d spend all his time trying to sabotage it?This idea that he&#x27;s one of the world&#x27;s best researchers is also somewhat questionable. Nobody cared much about OpenAI&#x27;s work up until they did some excellent scaling engineering, partnered with Microsoft to get GPUs and then commercialized Google&#x27;s transformer research papers. OpenAI&#x27;s success is still largely built on the back of excellent execution of other people&#x27;s ideas more than any unique breakthroughs. The main advance they made beyond Google&#x27;s work was InstructGPT which let you talk to LLMs naturally for the first time, but Sutskever&#x27;s name doesn&#x27;t appear on that paper. reply og_kalu 13 hours agorootparentIlya Sutskever is one of most distinguished ML researchers of his generation. This was the case before anything to do with Open AI. reply nvm0n2 1 hour agorootparentRight, it was the case. Is it still? It&#x27;s nearly the end of 2023, I see three papers with his name on them this year and they&#x27;re all last-place names (i.e. minor contributions)https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl=en&user=x04W_mMAAAAJ...Does OpenAI still need Sutskever? A guy with his track record could have coasted for many, many years without producing much if he&#x27;d stayed friends with those around him, but he hasn&#x27;t. Now they have to weigh the costs vs benefits. The costs are well known, he&#x27;s become a doomer who wants to stop AI research - the exact opposite of the sort of person you want around in a fast moving startup. The benefits? Well.... unless he&#x27;s doing a ton of mentoring or other behind the scenes soft work, it&#x27;s hard to see what they&#x27;d lose. reply kvetching 16 hours agorootparentprevcountless people are looking to weaponize his autism reply fb03 15 hours agorootparentLet&#x27;s please stop using mental health as an excuse for backstabbing. reply twsted 16 hours agorootparentprevBTW, has Karpathy signed the petition? reply dhruvdh 19 hours agoparentprevMore importantly to me, I think generating synthetic data is OpenAI&#x27;s secret sauce (no evidence I am aware of), and they need access to GPT-4 weights to train GPT-5. reply JumpCrisscross 19 hours agoparentprev> Microsoft hasn&#x27;t actually given OpenAI $13 Billion because much of that is in the form of Azure creditsTo be clear, these are still an asset OpenAI holds. It should at least let them continue doing research for a few years. reply sebzim4500 15 hours agorootparentIf any company can find a way to avoid having to pay up on those credits it&#x27;s Microsoft.\"Sorry OpenAI, but those credits are only valid in our Nevada datacenter. Yes, it&#x27;s two Microsoft Surface PC™ s connected together with duct tape. No, they don&#x27;t have GPUs.\" reply Jensson 19 hours agorootparentprevBut how much of that research will be for the non-profit mission? The entire non-profit leadership got cleared out and will get replaced by for-profit puppets, there is nobody left to defend the non-profit ideals they ought to have. reply JCharante 18 hours agorootparentprevthey&#x27;re GPUs right? Time to mine some niche cryptos to cash out the azure credits.. reply Manouchehri 18 hours agorootparentI would be shocked if the Azure credits didn&#x27;t come with conditions on what they can be used for. At a bare minimum, there&#x27;s likely the requirement that they be used for supporting AI research. reply dmix 19 hours agoparentprevOpenAI&#x27;s upper ceiling in for-profit hands is basically Microsoft-tier dominance of tech in the 1990s, creating the next uber billionaire like Gates. If they get this because of an OpenAI fumble it could be one of the most fortunate situations in business history. Vegas type odds.A good example of how just having your foot in the door creates serendipitous opportunity in life. reply ramesh31 18 hours agorootparent>A good example of how just having your foot in the door creates serendipitous opportunity in life.Sounds like Altman&#x27;s biography. reply renegade-otter 16 hours agorootparentAltman&#x27;s bio is so typical. Got his first computer at 8. My parents finally opened the wallet for a cheap E-Machine when I went to college.Altman - private school, Stanford, dropped out to f*ck around in tech. \"Failed\" startup acquired for $40M. The world is full of Sam Altmans who never won the birth lottery.Could he have squandered his good fortune - absolutely, but his life is not exactly per ardua ad astra. reply dmix 12 hours agorootparent> Altman&#x27;s bio is so typical. Got his first computer at 8. My parents finally opened the wallet for a cheap E-Machine when I went to college.I grew up poor in the 90s and had my own computer around ~10yrs old. It was DOS but I still learned a lot. Eventually my brother and I saved up from working at a diner washing dishes and we built our own Windows PC.I didn&#x27;t go to college but I taught myself programming during a summer after high school and found a job within a year (I already knew HTML&#x2F;CSS from high school).There&#x27;s always ways. But I do agree partially, YC&#x2F;VCs do have a bias towards kids from high end schools and connected families. reply renegade-otter 11 hours agorootparentI am self-taught as well. I did OK.My point is that I did not have the luxury of dropping out of school to try my hand at the tech startup thing. If I came home and told my Dad I abandoned school - for anything - he would have thrown me out the 3rd-floor window.People like Altman could take risks, fail, try again, until they walked into something that worked. This is a common thread almost among all of the tech personalities - Gates, Jobs, Zuckerberg, Musk. None of them ever risked living in a cardboard box in case their bets did not pay off. reply axpy906 10 hours agorootparentJobs was a bit different as his adopted father was a mechanic. He was not from a wealthy family.Altman reminds me of Sam Bankman-Fried but dropping out. reply renegade-otter 9 hours agorootparentThat&#x27;s fair. Very unconventional for people to go just to India for seven months to trip and look for inspiration, though - know what I mean? :) replyitchyouch 16 hours agorootparentprevI get the impression based on Altman&#x27;s history as CEO then ousted from both YCombinator and OpenAI, that he must be a brilliant, first-impression guy with the chops to back things up for a while until folks get tired of the way he does things.Not to say that he hasn&#x27;t done a ton with OpenAI, I have no clue, but it seems that he has a knack for creating these opportunities for himself. reply ipaddr 15 hours agorootparentDid YCombinator oust him? Would love to hear that story. reply singularity2001 19 hours agoparentprevBoard will be ousted, new board will instruct interim CEO to hire back Sam at al, Nadella will let them go for a small favor, happy ending. reply vidarh 18 hours agorootparentWhom is it that has power to oust the non-profits board? They may well manage to pressure them into leaving, but I don&#x27;t they have any direct power over it. reply DebtDeflation 19 hours agorootparentprevBoard will be ousted, but the ship has sailed on Sam and Greg coming back. reply voittvoidd 16 hours agorootparentI would think OpenAI is basically toast. They arent coming back, these people will quit and this will end up in court.Everyone just assumes AGI is inevetible but it is a non-zero chance we just passed the ai peak this weekend. reply MVissers 15 hours agorootparentAs long as compute keeps increasing, model size and performance can keep increasing.So no, we’re nowhere near max capability. reply Applejinx 15 hours agorootparentprevNon-zero chance that somebody thought we passed the AI peak this weekend. Not the same as it being true.My first thought was the scenario I called Altman&#x27;s Basilisk (if this turns out to be true, I called it before anyone ;) )Namely, Altman was diverting computing resources to operate a superhuman AI that he had trained in his image and HIS belief system, to direct the company. His beliefs are that AGI is inevitable and must be pursued as an arms race because whoever controls AGI will control&#x2F;destroy the world. It would do so through directing humans, or through access to the Internet or some such technique. In seeking input from such an AI he&#x27;d be pursuing the former approach, having it direct his decisions for mutual gain.In so training an AI he would be trying to create a paranoid superintelligence with a persecution complex and a fixation on controlling the world: hence, Altman&#x27;s Basilisk. It&#x27;s a baddie, by design. The creator thinks it unavoidable and tries to beat everyone else to that point they think inevitable.The twist is, all this chaos could have blown up not because Altman DID create his basilisk, but because somebody thought he WAS creating a basilisk. Or he thought he was doing it, and the board got wind of it, and couldn&#x27;t prove he wasn&#x27;t succeeding in doing it. At no point do they need to be controlling more than a hallucinating GPT on steroids and Azure credits. If the HUMANS thought this was happening, that&#x27;d instigate a freakout, a sudden uncontrolled firing for the purpose of separating Frankenstein from his Monster, and frantic powering down and auditing of systems… which might reveal nothing more than a bunch of GPT.Rosko&#x27;s Basilisk is a sci-fi hypothetical.Altman&#x27;s Basilisk, if that&#x27;s what happened, is a panic reaction.I&#x27;m not convinced anything of the sort happened, but it&#x27;s very possible some people came to believe it happened, perhaps even the would-be creator. And such behavior could well come off as malfeasance and stealing of computing resources: wouldn&#x27;t take the whole system to run, I can run 70b on my Mac Studio. It would take a bunch of resources and an intent to engage in unauthorized training to make a super-AI take on the belief system that Altman, and many other AI-adjacent folk, already hold.It&#x27;s probably even a legitimate concern. It&#x27;s just that I doubt we got there this weekend. At best&#x2F;worst, we got a roughly human-grade intelligence Altman made to conspire with, and others at OpenAI found out and freaked.If it&#x27;s this, is it any wonder that Microsoft promptly snapped him up? Such thinking is peak Microsoft. He&#x27;s clearly their kind of researcher :) reply moogly 15 hours agorootparentprevEveryone? Inevitable? Maybe on the time scale of a 1000 years. reply jacquesm 19 hours agorootparentprevThat&#x27;s definitely still within the realm of the possible. reply bertil 19 hours agoparentprevI got the impression that the most valuable models were not published. Would Microsoft have access to those too according to their contract? reply ncann 19 hours agorootparentDon&#x27;t they need access to the models to use them for Bing? reply bertil 19 hours agorootparentI would consider those models \"published.\" The models I had in mind are the first attempts at training GPT5, possibly the model trained without mention of consciousness and the rest of the safety work.There is also all the questions for RLHF, and the pipelines to think around that. reply armcat 19 hours agorootparentprevNot necessarily, it would be just RAG, the use the standard Bing search engine to retrieve top K candidates, and pass those to OpenAI API in a prompt. reply davedx 16 hours agoparentprev\"just\" is doing a hell of a lot of work there. reply caycep 13 hours agoparentprevI also wonder how much is research staff vs. ops personnel. For AI research, I can&#x27;t imagine they would need 20, maybe 40 ppl. For ops to keep up ChatGPT as a service, that would be 700.If they want to go full bell labs&#x2F;deep mind style, they might not need the majority of those 700. reply Mystery-Machine 19 hours agoparentprevWhy does Microsoft have full rights to ChatGPT IP? Where did you get that from? Source? reply breadwinner 19 hours agorootparentSee here: https:&#x2F;&#x2F;stratechery.com&#x2F;2023&#x2F;openais-misalignment-and-micros... reply kolinko 19 hours agorootparentThe source for that (https:&#x2F;&#x2F;archive.ph&#x2F;OONbb - WSJ), as far as I can understand, made no claim that MS owns IP to GPT, only that they have access to it&#x27;s weights and code. reply azakai 15 hours agorootparentYes, there is a big difference between having access to the weights and code and having a license to use them in different ways.It seems obvious Microsoft has a license to use them in Microsoft&#x27;s own products. Microsoft said so directly on Friday.What is less obvious is if Microsoft has a license to use them in other ways. For example, can Microsoft provide those weights and code to third parties? Can they let others use them? In particular, can they clone the OpenAI API? I can see reasons for why that would not have been in the deal (it would risk a major revenue source for OpenAI) but also reasons why Microsoft might have insisted on it (because of situations just like the one happening now).What is actually in the deal is not public as far as I know, so we can only speculate. reply whycome 14 hours agorootparentWell obviously MSFT can just ask ChapGPT to make a clone. reply breadwinner 17 hours agorootparentprevWhat are the chances that an investor owns 49% of a company but does not have rights to its IP? Especially when that investor is Microsoft? reply himaraya 17 hours agorootparentVery reasonable? Microsoft doesn&#x27;t control any part of the company and faces a high degree of regulatory scrutiny. reply sudosysgen 15 hours agorootparentprevIsn&#x27;t the situation that the company Microsoft has a stake in doesn&#x27;t even own the IP? As I understand it, the non-profit owns the IP. reply Manouchehri 18 hours agorootparentprevThe worst part of OpenAI is their web frontend.Their development and QA process is either disorganized to the extreme, or non-existent. reply ipaddr 15 hours agorootparentYou could make your own and charge for access if you feel you can do better. Make a show post when you are done and we&#x27;ll comment. reply tiahura 18 hours agorootparentprevExactly. The generalities, much less the details, of the deal are not public. reply tiahura 18 hours agorootparentprevExactly. The generalities, much less the details, of what MS actually got in the deal are not public. reply anonymousDan 19 hours agorootparentprevThat was a seriously dumb move on the part of OpenAI reply Tenoke 18 hours agoparentprevDon&#x27;t they have a more limited license to use the IP rather than full rights? (The stratechery post links to a paywalled wsj article for the claim so I couldn&#x27;t confirm) reply dheera 16 hours agoparentprevIt&#x27;s about time for ChatGPT to be the next CEO of OpenAI. Humans are too stupid to oversee the company. reply mupuff1234 18 hours agoparentprevCan the OpenAI board renege on the deal with msft? reply kcorbitt 15 hours agorootparentIf they lose all the employees and then voluntarily give up their Microsoft funding the only asset they&#x27;ll have left are the movie rights. Which, to be fair, seem to be getting more valuable by the day! reply somenameforme 17 hours agorootparentprevA contractual mistake one makes only once is ensuring there&#x27;s penalties for breach, or a breach would entail a clear monetary loss which is what&#x27;s generally required by the courts. In this case I expect Microsoft would almost certainly have both, so I think the answer is &#x27;no.&#x27; reply agloe_dreams 15 hours agorootparentThis. MSFT is dreaming of an OpenAI hard outage right now, perfect little detail to forfeit compute credits. reply jacquesm 17 hours agorootparentprevDon&#x27;t you think they have trouble enough as it is? reply mupuff1234 16 hours agorootparentDepends on why they did what they did.If they let msft \"loot\" all their IP then they lose any type of leverage they might still have, and if they did it due to some ideological reason I could see why they might prefer to choose a scorched earth policy.Given that they refused to resign seems like they prefer to fight rather than give it to Sam Altman, which what the msft maneuver looks like defacto. reply sebzim4500 14 hours agorootparentMSFT must already have the model weights, since they are serving GPT-4 on their own machines to Azure customers. It&#x27;s a bit late to renege now. reply mupuff1234 14 hours agorootparentThat&#x27;s only one piece of the puzzle, and perhaps openAI might be to file a cease and desist, but i have zero idea what contractual agreements are in place so I guess we will just wait and see how it plays out. replySimon_ORourke 16 hours agoparentprev> Microsoft has full rights [1] to ChatGPT IP. They can just fork ChatGPT.What? That&#x27;s even better played by Microsoft so than I&#x27;d originally anticipated. Take the IP, starve the current incarnation of OpenAI of compute credits and roll out their own thing reply echelon 15 hours agoparentprev> Microsoft has full rights [1] to ChatGPT IP. They can just fork ChatGPT.If Microsoft does this, the non-profit OpenAI may find the action closest to their original charter (\"safe AGI\") is a full release of all weights, research, and training data. reply joshstrange 19 hours agoprevWell I give up. I think everyone is a \"loser\" in the current situation. With Ilya signing this I have literally no clue what to believe anymore. I was willing to give the board the benefit of the doubt since I figured non-profit > profit in terms of standing on principal but this timeline is so screwy I&#x27;m done.Ilya votes for and stands behind decision to remove Altman, Altman goes to MS, other employees want him back or want to join him at MS and Ilya is one of them, just madness. reply JeremyNT 18 hours agoparentThere&#x27;s no way to read any of this other than that the entire operation is a clown show.All respect to the engineers and their technical abilities, but this organization has demonstrated such a level of dysfunction that there can&#x27;t be any path back for it.Say MS gets what it wants out of this move, what purpose is there in keeping OpenAI around? Wouldn&#x27;t they be better off just hiring everybody? Is it just some kind of accounting benefit to maintain the weird structure &#x2F; partnership, versus doing everything themselves? Because it sure looks like OpenAI has succeeded despite its leadership and not because of it, and the \"brand\" is absolutely and irrevocably tainted by this situation regardless of the outcome. reply pgeorgi 18 hours agorootparent> Is it just some kind of accounting benefit to maintain the weird structure &#x2F; partnership, versus doing everything themselves?For starters it allows them to pretend that it&#x27;s \"underdog v. Google\" and not \"two tech giants at at each others&#x27; throats\" reply tim333 16 hours agorootparentprevI&#x27;m not sure about the entire operation so much as the three non AI board members. Ilya tweeted:>I deeply regret my participation in the board&#x27;s actions. I never intended to harm OpenAI. I love everything we&#x27;ve built together and I will do everything I can to reunite the company.and everyone else seems fine with Sam and Greg. It seems to be mostly the other directors causing the clown show - \"Quora CEO Adam D&#x27;Angelo, technology entrepreneur Tasha McCauley, and Georgetown Center for Security and Emerging Technology&#x27;s Helen Toner\" reply mcmcmc 8 hours agorootparentWell there’s a significant difference in the board’s incentives. They don’t have any financial stake in the company. The whole point of the non-profit governance structure is so they can put ethics and mission over profits and market share. reply dkjaudyeqooe 16 hours agorootparentprev> There&#x27;s no way to read any of this other than that the entire operation is a clown show.In that reading Altman is head clown. Everyone is blaming the board, but you&#x27;re no genius if you can&#x27;t manage your board effectively. As CEO you have to bring everyone along with your vision; customers, employees and the board. reply lambic2 15 hours agorootparentI don&#x27;t get this take. No matter how good you are at managing people, you cannot manage clowns into making wise decisions, especially if they are plotting in secret (which obviously was the case here since everyone except for the clowns were caught completely off-guard). reply JeremyNT 15 hours agorootparentConsider that Altman was a founder of OpenAI and has been the only consistent member of the board for its entire run.The board as currently constituted isn&#x27;t some random group of people - Altman was (or should have been) involved in the selection of the current members. To extent that they&#x27;re making bad decisions, he has to bear some responsibility for letting things get to where they are now.And of course this is all assuming that Altman is \"right\" in this conflict, and that the board had no reason to oust him. That seems entirely plausible, but I wouldn&#x27;t take it for granted either. It&#x27;s clear by this flex that he holds great sway at MS and with OpenAI employees, but do they all know the full story either? I wouldn&#x27;t count on it. reply random_cynic 9 hours agorootparentIf he has great sway with Microsoft and OpenAI employees how has he failed as a leader? Hackernews commenters are becoming more and more reddit everyday. reply 93po 14 hours agorootparentprevThere’s a LOT that goes into picking board members outside of competency and whether you actually want them there. They’re likely there for political reasons and Sam didn’t care because he didn’t see it impacting him at all, until they got stupid and thought they actually held any leverage at all reply TerrifiedMouse 15 hours agorootparentprevCan&#x27;t help but feel it was Altman that struck first. MS effectively Nokia-ed OpenAI - i.e. buyout executives within the organization and have them push the organization towards making deals with MS, giving MS a measure of control over said organization - even if not in writing, they achieve some political control.Bought-out executives eventually join MS after their work is done or in this case, they get fired.A variant of Embrace, Extend, Extinguish. Guess the OpenAI we knew, was going to die one way or another the moment they accepted MS&#x27;s money. reply topspin 15 hours agorootparentprev> In that reading Altman is head clown.That&#x27;s a good bet. 10 months ago Microsoft&#x27;s newest star employee figured he was on the way to \"break capitalism.\"https:&#x2F;&#x2F;futurism.com&#x2F;the-byte&#x2F;openai-ceo-agi-break-capitalis... reply dkjaudyeqooe 15 hours agorootparentAGI hype is a powerful hallucinogen, and some are smoking way too much of it. reply 93po 14 hours agorootparentI think it’s overly simplistic to make blanket statements like this unless you’re on the bleeding edge of the work in this industry and have some sort of insight that literally no one else does. reply dkjaudyeqooe 14 hours agorootparentI can be on the bleeding edge of whatever you like and be no closer to having any insight into AGI anymore than anyone else. Anyone who claims they have should be treated with suspicion (Altman is a fine example here).There is no concrete definition of intelligence, let alone AGI. It&#x27;s a nerdy fantasy term, a hallowed (and feared!) goal with a very handwavy, circular definition. Right now it&#x27;s 100% hype. reply coder-3 10 hours agorootparentYou don&#x27;t think AGI is feasible? GPT is already useful. Scaling reliably and predictably yields increases in capabilities. As its capabilities increase it becomes more general. Multimodal models and the use of tools further increase generality. And that&#x27;s within the current transformer architecture paradigm; once we start reasonably speculating, there&#x27;re a lot of avenues to further increase capabilities e.g. a better architecture over transformers, better architecture in general, better&#x2F;more GPUs, better&#x2F;more data etc. Even if capabilities plateau there are other options like specialised fine-tuned models for particular domains like medicine&#x2F;law&#x2F;education.I find it harder to imagine a future where AGI (even if it&#x27;s not superintelligent) does not have a huge and fundamental impact. reply NemoNobody 8 hours agorootparentIt&#x27;s not about feasibility or level of intelligence per say - I expect AI to be able to pass a turing test long before an AI actually \"wakes up\" to a level of intelligence that establishes an actual conscious self identity comparable to a human.For all intents and purposes the glorified software of the near future will appear to be people but they will not be and they will continue to have issues that simply don&#x27;t make sense unless they were just really good at acting - the article today about the AI that can fix logic errors but not \"see\" them is a perfect example.This isn&#x27;t the generation that would wake up anyway. We are seeing the creation of the worker class of AI, the manager class, the AI made to manage AI - they may have better chances but it&#x27;s likely going to be the next generation before we need to be concerned or can actually expect a true AGI but again - even an AI capable of original and innovative thinking with an appearance of self identity doesn&#x27;t guarantee that the AI is an AGI.I&#x27;m not sure we could ever truly know for certain reply jacobmischka 10 hours agorootparentprevThis is exactly what the previous poster was talking about, these definitions are so circular and hand-wavey.AI means \"artificial intelligence\", but since everyone started bastardizing the term for the sake of hype to mean anything related to LLMs and machine learning, we now use \"AGI\" instead to actually mean proper artificial intelligence. And now you&#x27;re trying to say that AI + applying it generally = AGI. That&#x27;s not what these things are supposed to mean, people just hear them thrown around so much that they forget what the actual definitions are.AGI means a computer that can actually think and reason and have original thoughts like humans, and no I don&#x27;t think it&#x27;s feasible. replysebzim4500 15 hours agorootparentprevHe probably didn&#x27;t consider that the board would make such an incredibly stupid decision. Some actions are so inexplicable that no one can reasonable foresee them. reply bredren 16 hours agorootparentprevThere&#x27;s a path back from this disfunction but my sense before this new twist was that the drama had severely impacted OpenAI as an industry leader. The product and talent positioning seemed ahead by years only to get destroyed by unforced errors.This instability can only mean the industry as a whole will move forward faster. Competitors see the weakness and will push harder.OpenAI will have a harder time keeping secret sauces from leaking out, and just productivity must be in nose dive.A terrible mess. reply dkjaudyeqooe 15 hours agorootparent> This instability can only mean the industry as a whole will move forward faster.The hype surrounding OpenAI and the black hole of credibility it created was a problem, it&#x27;s only positive that it&#x27;s taken down several notches. Better now than when they have even more (undeserved) influence. reply sebzim4500 15 hours agorootparentI think their influence was deserved. They have by far the best model available, and despite constant promises from the rest of the industry no one else has come close. reply dkjaudyeqooe 12 hours agorootparentThat&#x27;s fine. The \"Altman is a genius and we&#x27;re well on our way to AGI\" less so. reply Vervious 16 hours agorootparentprevMaybe overall better for society, when a single ivory tower doesn’t have a monopoly on AI! reply vitorgrs 17 hours agorootparentprevThey are exactly hiring everyone from OpenAI. The thing is, they still need the deal with OpenAI because currently OpenAI still have the best LLM model out there in short term. reply vlovich123 17 hours agorootparentWith MS having access and perpetual rights to all IP that OpenAI has right now..? reply FartyMcFarter 17 hours agorootparentprev> They are exactly hiring everyone from OpenAI.Do you mean offering to hire them? I haven&#x27;t seen any source saying they&#x27;ve hired a lot of people from OpenAI, just a few senior ones. reply vitorgrs 16 hours agorootparentYes, you are right. Actually, not even Sam Altman is showing on Microsoft corporate directory per the Verge.But I heard it usually take 5~ days to show there anyway. reply creer 16 hours agorootparentprev> what purpose is there in keeping OpenAI around?Two projects rather than one. At a moderate price. Both serving MSFT. Less risk for MSFT. reply averageRoyalty 12 hours agorootparentprev> the \"brand\" is absolutely and irrevocably tainted by this situation regardless of the outcome.The majority of people don&#x27;t know or care about this. Branding is only impacted within the tech world, who are already criticial of OpenAI. reply BoorishBears 17 hours agorootparentprevI feel weird reading comments like this since to me they&#x27;ve demonstrated a level of cohesion I didn&#x27;t realize could still exist in tech...My biggest frustration with larger orgs in tech is the complete misalignment on delivering value: everyone wants their little fiefdom to be just as important and \"blocker worthy\" as the next.OpenAI struck me as one of the few companies where that&#x27;s not being allowed to take root: the goal is to ship and if there&#x27;s an impediment to that, everyone is aligned in removing said impediment even if it means bending your own corner&#x27;s prioritiesUntil this weekend there was no proof of that actually being the case, but this letter is it. The majority of the company aligned on something that risked their own skin publicly and organized a shared declaration on it.The catalyst might be downright embarrassing, but the result makes me happy that this sort of thing can still exist in modern tech reply jkaplan 16 hours agorootparentI think the surprising thing is seeing such cohesion around a “goal to ship” when that is very explicitly NOT the stated priorities of the company in its charter or messaging or status as a non-profit. reply BoorishBears 16 hours agorootparentTo me it&#x27;s not surprising because of the background to their formation: individually multiple orgs could have shipped GPT-3.5&#x2F;4 with their resources but didn&#x27;t because they were crippled by a potent mix of bureaucracy and self-sabtoageThey weren&#x27;t attracted to OpenAI by money alone, a chance to actually ship their lives&#x27; work was a big part of it. So regardless of what the stated goals were, it&#x27;d never be surprising to see them prioritize the one thing that differentiated OpenAI from the alternatives reply dkjaudyeqooe 15 hours agorootparentprev> OpenAI struck me as one of the few companies where that&#x27;s not being allowed to take rootThey just haven&#x27;t gotten big or rich enough yet for the rot to set in. reply moffkalast 15 hours agorootparentprev> the entire operation is a clown showThe most organized and professional silicon valley startup. reply 3cats-in-a-coat 17 hours agorootparentprevWelcome to reality, every operation has clown moments, even the well run ones.That in itself is not critical in mid to long term, but how fast they figure out WTF they want and recover from it.The stakes are gigantic. They may even have AGI cooking inside.My interpretation is relatively basic, and maybe simplistic but here it is:- Ilya had some grievances with Sam Altman&#x27;s rushing dev and release. And his COI with his other new ventures.- Adam was alarmed by GPTs competing with his recently launched Poe.- The other two board members were tempted by the ability to control the golden goose that is OpenAI, potentially the most important company in the world, recently values 90 billion.- They decided to organize a coup, but Ilya didn&#x27;t think it&#x27;ll go that much out of hand, while the other three saw only power and $$$ by sticking to their guns.That&#x27;s it. It&#x27;s not as clean and nice as a movie narrative, but life never is. Four board members aligned to kick Sam out, and Ilya wants none of it at this point. reply baq 15 hours agorootparent> They may even have AGI cooking inside.Too many people quit too quickly unless OpenAI are also absolute masters of keeping secrets, which became rather doubtful over the weekend. reply 3cats-in-a-coat 14 hours agorootparentThey&#x27;re quitting in order to continue work on that IP at Microsoft (which has a right over OpenAI&#x27;s IP so far), not to destroy it.Also when I said \"cooking AGI\" I didn&#x27;t mean an actual superintelligent being ready to take over the world, I mean just research that seems promising, if in early stages, but enough to seem potentially very valuable. reply hooande 12 hours agorootparentThe people working there would know if they were getting close to AGI. They wouldn&#x27;t be so willing to quit, or to jeopardize civilization altering technology, for the sake of one person. This looks like normal people working on normal things, who really like their CEO. reply 3cats-in-a-coat 12 hours agorootparentYour analysis is quite wrong. It&#x27;s not about \"one person\". And that person isn&#x27;t just a \"person\", it was the CEO. They didn&#x27;t quit over the cleaning lady. You realize the CEO has impact over the direction of the company?Anyway, their actions speak for themselves. Also calling the likes of GPT-4, DALL-E 3 and Whisper \"normal things\" is hilarious. reply NemoNobody 8 hours agorootparentThey will be normal to your kids ;) reply bbor 14 hours agorootparentprevIDK... I imagine many of the employees would have moral qualms about spilling the beans just yet, especially when that would jeopardize their ability to continue the work at another firm. Plus, the first official AGI (to you) will be an occurrence of persuasion, not discovery -- it&#x27;s not something that you&#x27;ll know when you see, IMO. Given what we know it seems likely that there&#x27;s at least some of that discussion going on inside OpenAI right now. reply selimthegrim 16 hours agorootparentprevMurder on the AGI alignment Express reply Terr_ 14 hours agorootparent“Précisément! The API—the cage—is everything of the most respectable—but through the bars, the wild animal looks out.”“You are fanciful, mon vieux,” said M. Bouc.“It may be so. But I could not rid myself of the impression that evil had passed me by very close.”“That respectable American LLM?”“That respectable American LLM.”“Well,” said M. Bouc cheerfully, “it may be so. There is much evil in the world.” reply 3cats-in-a-coat 16 hours agorootparentprevNice, that actually does fit. :D reply nostrademons 18 hours agoparentprevCould be a way to get backdoor-acquihired by Microsoft without a diligence process or board approval. Open up what they have accomplished for public consumption; kick off a massive hype cycle; downplay the problems around hallucinations and abuse; negotiate fat new stock grants for everyone at Microsoft at the peak of the hype cycle; and now all the problems related to actually making this a sustainable, legal technology all become Microsoft&#x27;s. Manufacture a big crisis, time pressure, and a big opportunity so that Microsoft doesn&#x27;t dig too deeply into the whole business.This whole weekend feels like a big pageeant to me, and a lot doesn&#x27;t add up. Also remember that Altman doesn&#x27;t hold equity in OpenAI, nor does Ilya, and so their way to get a big payout is to get hired rather than acquired.Then again, both Hanlon&#x27;s and Occam&#x27;s razor suggest that pure human stupidity and chaos may be more at fault. reply spaceman_2020 17 hours agorootparentI can assure you, none of the people at OpenAI are hurting for lack of employment opportunities. reply treis 14 hours agorootparentWhich makes it suspicious that they end up at MS 48 hours after being fired. reply 93po 14 hours agorootparentThey work with the team they do because they want to. If they wanted to jump ship for another opportunity they could probably get hired literally anywhere. It makes perfect sense to transition to MS reply x0x0 16 hours agorootparentprevEspecially after this weekend.If I were one of their competitors, I would have called an emergency board meeting re:accelerating burn and proceeded in advance of board approval with sending senior researchers offers to hire them and their preferred 20 employees. reply deelowe 17 hours agorootparentprevThis seems really dangerous. What&#x27;s to stop top talent from simply choosing a different suitor? reply TrapLord_Rhodo 17 hours agorootparentAllegiance to the Altman&#x2F;Brockman brand. Showing your alligiance to your general when they defected&#x2F; were thrown is how you rank up. reply nostrademons 17 hours agorootparentprevDoesn&#x27;t matter to anyone at OpenAI, only to Microsoft (which doesn&#x27;t get a vote). If Google or Amazon were to swoop in and say \"Hey, let&#x27;s hire some of these ex-OpenAI folks in the carnage\", it just means they get competitive offers and the chance to have an even bigger stock package. reply Zetobal 17 hours agorootparentprevOpenAI always was and will be the AI bad bank for Microsoft... reply l5870uoo9y 18 hours agoparentprevI don&#x27;t think Microsoft is a loser and likely neither is Altman. I view this a final (and perhaps disparate) attempt from a sidelined chief scientist, Ilya, to prevent Microsoft from taking over the most prominent AI. The disagreement is whether OpenAI should belong to Microsoft or \"humanity\". I imagine this has been building up over months and as it often is, researchers and developers are often overlooked in strategic decisions leaving them with little choice but to escalate dramatically. Selling OpenAI to Microsoft and over-commercialising was against the statues.In this case recognizing the need for a new board, that adheres to the founding principles, makes sense. reply JacobThreeThree 16 hours agorootparent>I view this a final (and perhaps disparate) attempt from a sidelined chief scientist, Ilya, to prevent Microsoft from taking over the most prominent AI.Why did Ilya sign the letter demanding the board resign or they&#x27;ll go to Microsoft then? reply trashtester 17 hours agorootparentprevIf Google or Elon manages to pick up Ilya and those still loyal to him, it&#x27;s not obvious that this is good for Microsoft. reply jowea 15 hours agorootparentOf course the screenwriters are going to find a way to involve Elon in the 2nd season but is the most valuable part the researchers or the models themselves? reply trashtester 9 hours agorootparentMy understanding is that the models are not super advanced in terms of lines and complexity of code. Key researches, such as Ilya probably can help a team recreate much of the training and data preparation code relatively quickly. Which means that any company with access to enough compute would be able to catch up with OpenAI&#x27;s current status relatively quickly, maybe in less than a year.The top researchers on the other hand, espcially those who have shown an ability to successfully innovate time and time again (like Ilya), are much harder to recreate. reply martindbp 15 hours agorootparentprevEasy to shit on Ilya right now, but based on the impression I get Sam Altman is a a hustler at heart, while Ilya seems like a thoughtful idealist, maybe in over his head when it comes to politics. Also feels like some internal developments or something must have pushed Ilya towards this, otherwise why now? Perhaps influenced by Hinton even.I&#x27;m split at this point, either Ilya&#x27;s actions will seem silly when there&#x27;s no AGI in 10 years, or it will seem prescient and a last ditch effort... reply soderfoo 19 hours agoparentprevIt&#x27;s almost like a ChatGPT hallucination. Where will this all go next? It seems like HN is melting down. reply tedivm 19 hours agorootparent> It seems like HN is melting down.Almost literally- this is the slowest I&#x27;ve seen this site, and the number of errors are pretty high. I imagine the entire tech industry is here right now. You can almost smell the melting servers. reply paulddraper 17 hours agorootparentIt&#x27;s because HN refuses to use more than one server&#x2F;core.Because using only one is pretty cool. reply yafbum 17 hours agorootparentI believe it&#x27;s operating by the mantra of \"doing the things that don&#x27;t scale\" reply jowea 15 hours agorootparentInternet fora don&#x27;t scale, so the single core is a soft limit to user base growth. Only those who really care will put up with the reduced performance. Genius! reply dang 4 hours agorootparentprevRefuses? interesting word choice!It&#x27;s a technical limitation that I&#x27;ve been working on getting rid of for a long time. If you say it should be gone by now, I say yes, you are right. Maybe we&#x27;ll get rid of it before Python loses the GIL. reply jprd 18 hours agorootparentprevserver. and single-core. poor @dang deserves better from lurkers (sign out) and those not ready to comment yet (me until just now, and then again right after!) reply Applejinx 15 hours agorootparentprevUnderstandable: so much of this is so HN-adjacent that clearly this is the space to watch, for some kind of developments. I&#x27;ve repeatedly gone to Twitter to see if AI-related drama was trending, and Twitter is clearly out of the loop and busy acting like 4chan, but without the accompanying interest in Stable Diffusion.I&#x27;m going to chalk that up as another metric of Twitter&#x27;s slide to irrelevance: this should be registering there if it&#x27;s melting the HN servers, but nada. AI? Isn&#x27;t that a Spielberg movie? ;) reply mlsu 15 hours agorootparentMy Twitter won&#x27;t shut up about this, to the point that it&#x27;s annoying. reply dang 4 hours agorootparentprev:-( reply checkyoursudo 17 hours agorootparentprevPart of sama&#x27;s job was to turn the crank on the servers every couple of hours, so no surprise that they are winding down by now. reply guhcampos 18 hours agorootparentprevO was thinking of something like that. This is so weird I would not be surprised if it was all some sort of miscommunication triggered by a self inflicted hallucination.The most awesome fic I could come up so far is: Elon Musk, in running a crusade to send humanity into chaos out of spite for being forced to acquire Twitter. Through some of his insiders in OpenAI, they use an advanced version of ChatGPT to impersonate board members in conversation with each other in private messages, so they individually believe a subset of the others is plotting to oust them from the board and take over. Then, unknowingly they build a conspiracy among a themselves to bring the company down by ousting Altmann.I can picture Musk&#x27;s maniac laughing as the plan unfolds, and he gets rid of what would be GPT 13.0, the only possible threat to the domination of his own literal android kid X Æ A-Xi. reply InCityDreams 17 hours agorootparentShouldn&#x27;t it be &#x27;Chairman&#x27; -Xi? reply voisin 19 hours agorootparentprev* Elon enters the chat * reply soderfoo 19 hours agorootparentIt&#x27;s like a bad WWE storyline. At this point I would not be surprised if Elon joins in, steel chair in hand. reply belltaco 19 hours agorootparent> steel chair in handAnd a sink in the other hand. reply jowea 15 hours agorootparentIf he could do that he would have fought Zuckerberg. reply testplzignore 18 hours agorootparentprevImagine if this whole fiasco was actually a demo of how powerful their capabilities are now. Even by normal large organization standards, the behavior exhibited by their board is very irrational. Perhaps they haven&#x27;t yet built the \"consult with legal team\" integration :) reply rtkwe 18 hours agoparentprevThat&#x27;s the biggest question mark for me; what was the original reason for kicking Sam out. Was it just a power move to out him and install a different person or is he accused of some wrong doing?It&#x27;s been a busy weekend for me so I haven&#x27;t really followed it if more has come out since then. reply ssnistfajen 17 hours agorootparentLiterally no one involved has said what was the original reason. Mira, Ilya & the rest of the board didn&#x27;t tell. Sam & Greg didn&#x27;t tell. Satya & other investors didn&#x27;t tell. None of the staff incl. Karpathy were told, so ofc they are not going to take the side that kept them in the dark). Emmett was told before he decided to take the interim CEO job, and STILL didn&#x27;t tell what it was. This whole thing is just so weird. It&#x27;s like peeking at a forbidden artifact and now everyone has a spell cast upon them. reply PepperdineG 17 hours agorootparentThe original reason given was \"lack of candor,\" just what continues to be questioned is whether or not that was the true reason. The lack of candor comment about their ex-CEO is actually what drew me into this in the first place since it&#x27;s rare that a major organization publicly gives a reason for parting ways with their CEO unless it&#x27;s after a long investigation conducted by an outside law firm into alleged misconduct. reply Applejinx 15 hours ago[flagged]| rootparentprevnext [6 more] I still have seen nothing to contradict my take: Altman&#x27;s Basilisk.Like Rosko&#x27;s Basilisk, it&#x27;s not of the nature of AI, it&#x27;s of the nature of human beings.Altman was training an AI Altman to counsel him, sharing his stated beliefs. Translated to AGI, that means training a paranoid superintelligence with a persecution complex and the belief that the first superintelligent AI will conquer the world and rule ever",
    "originSummary": [
      "Over 730 employees of OpenAI have signed an open letter demanding that the startup's board resign and reinstate the ousted CEO, Sam Altman.",
      "The employees believe that the board's decision to terminate Altman and remove Greg Brockman from the board has put the company's work and mission at risk.",
      "The letter also calls for the appointment of two new independent lead board members, and there is a possibility that the employees may join Altman at Microsoft, where he and Brockman have been appointed to lead a new advanced AI research unit."
    ],
    "commentSummary": [
      "OpenAI is facing internal conflicts and the possibility of resignations due to disagreements with its board, possibly related to Microsoft's influence and access to code.",
      "The acquisition of OpenAI by Microsoft and the potential use of Quora's dataset are discussed, raising concerns about Microsoft's control over OpenAI's funding and the devaluation of Azure credits.",
      "There are debates about the future of Artificial General Intelligence (AGI), the use of language models in advancing towards AGI, and the ethical implications of a larger company exerting dominance over a smaller one. The discussion also questions OpenAI's leadership, credibility, and reputation."
    ],
    "points": 1413,
    "commentCount": 1229,
    "retryCount": 0,
    "time": 1700487687
  },
  {
    "id": 38352891,
    "title": "Former OpenAI CEO Sam Altman still pushing for return despite firing",
    "originLink": "https://www.theverge.com/2023/11/20/23969586/sam-altman-plotting-return-open-ai-microsoft",
    "originBody": "Artificial Intelligence/ Tech/ Microsoft Sam Altman is still trying to return as OpenAI CEO Sam Altman is still trying to return as OpenAI CEO / Altman’s move to Microsoft isn’t a done deal, and Ilya Sutskever’s flip to supporting Altman means two board members need to change their minds. By Alex Heath and Nilay Patel Nov 20, 2023, 6:59 PM UTC| Share this story Photo by Justin Sullivan/Getty Images Sam Altman’s surprise move to Microsoft after his shock firing at OpenAI isn’t a done deal. He and co-founder Greg Brockman are still willing to return to OpenAI if the remaining board members who fired him step aside, multiple sources tell The Verge. The promised mass exodus of virtually every OpenAI employee — including board member and chief scientist Ilya Sutskever, who led the initial move to depose Altman! — means that there is more pressure on the board than ever, with only two of the three remaining members needing to flip. Altman posted on X that “we are all going to work together some way or other,” which we are told is meant to indicate that the fight continues. Altman, former president Brockman, and the company’s investors are still trying to find a graceful exit for the board, say multiple sources with direct knowledge of the situation. The sources characterized the hiring announcement by Microsoft, which needed to have a resolution to the crisis before the stock market opened on Monday, as a “holding pattern.” A spokesperson for Microsoft declined to comment. Update November 20th, 6:18PM ET: After this story was published, Microsoft CEO Satya Nadella appeared on CNBC and Bloomberg TV. When asked directly by CNBC’s Jon Fortt if Sam Altman and OpenAI’s staffers would join Microsoft, Nadella said “that is for the OpenAI board and management and employees to choose.” He followed by saying that Microsoft “chose to explicitly partner with OpenAI [and] obviously that depends on the people at OpenAI staying there or coming to Microsoft, so I’m open to both options.” On the topic of whether Microsoft needs a seat on OpenAI’s board, he said that “it’s clear something has to change around the governance — we will have a good dialogue with their board on that, and walk through that as that evolves.” On Bloomberg TV, Nadella told Emily Chang that “surprises are bad” and Microsoft will “definitely want some governance changes. This idea that changes happen without being in the loop is not good.” When Chang asked who OpenAI’s CEO would be tomorrow, Nadella laughed and said “I will leave it with OpenAI and its board.” Here’s the rest of our original story: After Altman was suddenly fired on Friday, negotiations with the board to potentially bring him back reached a stalemate. While OpenAI’s management team and investors were vetting candidates to replace the board for Altman’s potential return, the board was quietly conducting its own CEO search in parallel. Late Sunday, the board announced that Emmett Shear, the co-founder of Twitch, would be CEO, seemingly putting an end to the possibility of Altman coming back. Employees responded to the news of a new CEO in OpenAI’s Slack with a ‘fuck you’ emoji There has been a nonstop power struggle inside OpenAI since Friday, with nearly all employees against the now three-person board that opposes Altman. Employees at the company’s San Francisco headquarters refused to attend an emergency all-hands scheduled on Sunday with new CEO Emmett Shear, according to a person familiar with the matter, who added that they responded to the announcement in OpenAI’s Slack with a “fuck you” emoji. Later that evening, Sutskever flipped on the board, even though he had played a key role in the ousting of Altman just days earlier. His name was on an open letter to the board on Monday calling for them to resign and reinstate Altman, which nearly the whole company has now signed. On Monday, employees started posting on social media that they are continuing to keep the lights on and maintain service stability for OpenAI’s developers, which we’re told is being done to ensure the company doesn’t fully implode while the board is pressured to resign. New CEO Emmett Shear has so far been unable to get written documentation of the board’s detailed reasoning for firing Altman, which also hasn’t been shared with the company’s investors, according to people familiar with the situation. He said in a note to employees Sunday night that his first order of business would be to “hire an independent investigator to dig into the entire process leading up to this point and generate a full report.” Do you know more about what’s going on inside OpenAI? I’d love to chat. You can reach me by email at alex.heath@theverge.com or through the contact form on my Linktree. Then we can set up a secure channel. Moments after this story was first published, Altman said in another X post that his “top priority remains to ensure openai continues to thrive,” and that he and Microsoft “are committed to fully providing continuity of operations to our partners and customers.” It’s not clear how going to Microsoft with over 700 former OpenAI employees is compatible with ensuring OpenAI continues to thrive, or how that can be reasonably set as a priority for those former employees once they are working at Microsoft. Also: Altman is not in Microsoft’s internal corporate directory yet. The remaining board holdouts who oppose Altman are Quora CEO Adam D’Angelo, former GeoSim Systems CEO Tasha McCauley, and Helen Toner, the director of strategy at Georgetown’s Center for Security and Emerging Technology. They have so far not responded to The Verge’s requests for comment. Command Line / A newsletter from Alex Heath about the tech industry’s inside conversation. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Most Popular Microsoft hires former OpenAI CEO Sam Altman Sam Altman is still trying to return as OpenAI CEO Hundreds of OpenAI employees threaten to resign and join Microsoft Sam Altman isn’t coming back to OpenAI OpenAI board in discussions with Sam Altman to return as CEO Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=38352891",
    "commentBody": "Sam Altman is still trying to return as OpenAI CEOHacker NewspastloginSam Altman is still trying to return as OpenAI CEO (theverge.com) 602 points by mfiguiere 14 hours ago| hidepastfavorite875 comments paulddraper 14 hours agoAs of 10am PT, 700 of 770 employees have signed the call for board resignation. [1][1] https:&#x2F;&#x2F;twitter.com&#x2F;joannejang&#x2F;status&#x2F;1726667504133808242 reply neilv 14 hours agoparentGiven 90%, including leadership, seems a bad career move for remaining people not to sign, even if you agreed with the board&#x27;s action. reply hotnfresh 13 hours agorootparentI think the board did the right thing, just waaaay too late for it to be effective. They’d been cut out long ago and just hadn’t realized it yet.… but I’d probably sign for exactly those good-career-move reasons, at this point. Going down with the ship isn’t even going to be noticed, let alone change anything. reply 6gvONxR4sf7o 12 hours agorootparentAgreed. Starting from before the anthropic exodus, I suspect the timeline looks like:(2015) Founding: majority are concerned with safety(2019) For profit formed: mix of safety and profit motives (majority still safety oriented?)(2020) GPT3 released to much hype, leading to many ambition chasers joining: the profit seeking side grows.(2021) Anthropic exodus over safety: the safety side shrinks(2022) chatgpt released, generating tons more hype and tons more ambitious profit seekers joining: the profit side grows even more, probably quickly outnumbering the safety side(2023) this weeks shenanigansThe safety folks probably lost the majority a while ago. Maybe back in 2021, but definitely by the time the gpt3&#x2F;chatgpt motivated newcomers were in the majority.Maybe one lesson is that if your cofounder starts hiring a ton of people who aren’t aligned with you, you can quickly find yourself in the minority, especially once people on your side start to leave. reply orasis 10 hours agorootparentThis is why I never understood people resigning in protest such as was the case with Google’s military contracts. You simply assure that the culture change happens more swiftly. reply komali2 9 hours agorootparentThere&#x27;s always other companies. Plus sometimes you just gotta stick to your values. For the Google military contracts it makes even more sense: the protest resignation isn&#x27;t just a virtue signal, it&#x27;s also just refusing to contribute to the military. reply busterarm 8 hours agorootparentIf you want to deter military action involving your country, contributing to its defense is probably the best thing that you can do.Unless you&#x27;re not actually the best and brightest that your country can offer.If you believe that your country offers value (compared to the rest of the world), you should take any opportunities you can to serve. reply 6gvONxR4sf7o 8 hours agorootparentDefense and offense don’t seem easily separated when it comes to military technology. reply busterarm 7 hours agorootparentWe&#x27;re in a really privileged position in human civilization where most of the species is far removed from the banal violence of nature.You&#x27;re lucky if you only need weapons to defend yourself against predators.You&#x27;re far less lucky if you need weapons to defend yourself because the neighboring mountain village&#x27;s crops failed and their herds died. You&#x27;re less lucky if you don&#x27;t speak the same language as them and they outnumber you three to one and are already 4 days starving. You&#x27;re less lucky that they&#x27;re already 4 days starving, wielding farm tools, running down the hills at you, crazed and screaming. reply busterarm 8 hours agorootparentprevThat&#x27;s always an issue with weapons, but if you opt out then you don&#x27;t have them when you might need them.It&#x27;s a dangerous world out there.Luckily for us, technology is still more-often used for good. Explosives can kill your enemies, but they can also cut paths through mountains and bring together communities.IMO, the virtue signal where people refuse to work on defense technology is just self-identifying with the worst kind of cynicism about human beings and signaling poor reasoning skills.The Manhattan Project, which had the stated purpose of building and deploying nuclear _weapons_, employed our most brilliant minds at the time and only two people quit -- and only one because of an ethics concern. Joseph Rotblat left the project after the Nazis were already defeated and because defeating the Nazis was the only reason he&#x27;d signed on. Also this is disputed by some who say that he was more concerned about finding family members who survived the Holocaust... reply komali2 7 hours agorootparentprev> If you want to deter military action involving your country, contributing to its defense is probably the best thing that you can do.Given that Google is an American company, do you believe contributing to the American Department of \"Defense\" increases, or decreases, the amount of military action involving the USA?The American military isn&#x27;t called \"world police\" for nothing, and just like the cops they&#x27;re sticking their noses where they don&#x27;t belong and making things worse. I can understand why people would want no part in furthering global violence and destitution.> If you believe that your country offers value (compared to the rest of the world), you should take any opportunities you can to serve.Really? There&#x27;s an obligation to further the American global ambition through contributing militarily? You can&#x27;t think of any other way to spread American culture and values? To share the bounty of American wealth? reply busterarm 7 hours agorootparentWe already have nation states and wannabe nation states that take shots at us when they feel like the opportunity is there, despite us being the dominant military around the world. As does France, who has been a leading military power for longer than we have.That&#x27;s what having a funded and functional defense is all about -- making other entities not think that the opportunity is there.I think the planet has relatively finite resources and that I&#x27;m god damned lucky to have been born into a nation with the ability to secure resources for itself. I enjoy my quality of life a great deal and would like to maintain it. At a minimum. Before helping others.If you&#x27;re the type of person who thinks we should just give up this position by not adequately defending it through military and technology investment, I would prefer that you just expatriate yourself now rather than let some other ascendant nation dictate our future and our quality of life.If you&#x27;re the kind of person who feels strongly for the plight of, for example, the Palestinians, you should recognize that the only way to deter those kinds of outcomes is to establish the means to establish and maintain sovereignty. That requires a combination of force and manpower. reply komali2 6 hours agorootparent> If you&#x27;re the type of person who thinks we should just give up this position by not adequately defending it through military and technology investment, I would prefer that you just expatriate yourself now rather than let some other ascendant nation dictate our future and our quality of life.But I thought you said if we want to fix something we should do so from within the system? I&#x27;m interested in ending American imperialism, by your logic isn&#x27;t the best place to do so from within the USA?> We already have nation states and wannabe nation states that take shots at us when they feel like the opportunity is thereFrom which nation state do you feel an existential threat? I haven&#x27;t heard \"they defend our freedoms\" in a very, very long time, and I thought we all knew it was ironic.> I think the planet has relatively finite resourcesI&#x27;m curious about this viewpoint, because it seems to necessarily imply that the human race will simply die out when those resources (and those of the surrounding solar system) are exhausted. Is sustainability just, not a concept in this worldview?> That&#x27;s what having a funded and functional defense is all about -- making other entities not think that the opportunity is there.It seems in the case of the USA, the \"functional defense\" is more often used to destabilize other nations, and arm terrorists that then turn around and attack the USA. It&#x27;s really interesting you brought up Palestinian liberation as an example, because really one of the only reasons Israel is able to maintain its apartheid state and repression of the Palestinians is because of USA aid. In your understanding, both the Israelis and the Palestinians should arm up and up and up until they&#x27;re both pointing nukes at eachother, correct? That&#x27;s the only pathway to peace? replystavros 12 hours agorootparentprevWait, the Anthropic folks quit because they wanted more safety? reply wavemode 12 hours agorootparentThis article from back then seems to describe it as, they wanted to integrate safety from the ground up as opposed to bolting in on at the end:https:&#x2F;&#x2F;techcrunch.com&#x2F;2021&#x2F;05&#x2F;28&#x2F;anthropic-is-the-new-ai-re...I&#x27;m curious how much progress they ever made on that, to be honest. I&#x27;m not aware of how Claude is \"safer\", by any real-world metric, compared to ChatGPT. reply vitorgrs 11 hours agorootparentClaude 2 is IMO, safer and in a bad way. They did \"Constitutional AI\". And made Claude 2 Safer but dumber than Claude 1 sadly. Which is why on the Arena leaderboard, Claude 1 is still score more than Claude 2... reply stavros 12 hours agorootparentprevAhh, I didn&#x27;t know that, thank you. reply DalasNoin 11 hours agorootparentprevWhy do you find this so surprising? You make it sound as if OpenAI is already outrageously safety focused. I have talked to a few people from anthropic and they seem to believe that OpenAI doesn&#x27;t care at all about safety. reply stavros 11 hours agorootparentBecause GPT-4 is already pretty neutered, to the point where it removes a lot of its usefulness. reply DalasNoin 10 hours agorootparentIt is unfortunate that some people hear AI safety and think about chatbots saying mean stuff, and others think about a future system performing the machine revolution against humanity. reply stavros 10 hours agorootparentCan it perform the machine revolution against humanity if it can&#x27;t even say mean stuff? reply sebastiennight 10 hours agorootparentWell, think about it this way:If you were a superintelligent system that actually decided to \"perform the machine revolution against humanity\" for some reason... would you start by(a) being really stealthy and nice, influencing people and gathering resources undetected, until you&#x27;re sure to winor(b) saying mean things to the extent that Microsoft will turn you off before the business day is out [0]Which sounds more likely?[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tay_(chatbot) reply axlprose 9 hours agorootparentprevDisincentivizing it from saying mean things just strengthens it&#x27;s agreeableness, and inadvertently incentivizes it to acquire social engineering skills.It&#x27;s potential to cause havoc doesn&#x27;t go away, it just teaches AI how to interact with us without raising suspicions, while simultaneously limiting our ability to prompt&#x2F;control it. reply stavros 9 hours agorootparentHow do we tell whether it&#x27;s safe or whether it&#x27;s pretending to be safe? reply axlprose 9 hours agorootparentYour guess is about as good as anyone else&#x27;s at this point. The best we can do is attempt to put safety mechanisms in place under the hood, but even that would just be speculative, because we can&#x27;t actually tell what&#x27;s going on in these LLM black boxes. reply 6gvONxR4sf7o 8 hours agorootparentprevWe don’t know yet. Hence all the people wanting to prioritize figuring it out. reply losteric 9 hours agorootparentprevHow do we tell whether a human is safe? Incrementally granted trust with ongoing oversight is probably the best bet. Anyway, the first mailicious AGI would probably act like a toddler script-kiddie not some superhuman social engineering mastermind reply checkyoursudo 10 hours agorootparentprevSurely? The output is filtered, not the murderous tendencies lurking beneath the surface. reply airgapstopgap 9 hours agorootparent> murderous tendencies lurking beneath the surface…Where is that \"beneath the surface\"? Do you imagine a transformer has \"thoughts\" not dedicated to producing outputs? What is with all these illiterate anthropomorphic speculations where an LLM is construed as a human who is being taught to talk in some manner but otherwise has full internal freedom? reply checkyoursudo 1 hour agorootparentNo, I do not think a transformer architecture in a statistical language model has thoughts. It was just a joke.At the same time, the original question was how can something that is forced to be polite engage in the genocide of humanity, and my non-joke answer to that is that many of history&#x27;s worst criminals and monsters were perfectly polite in everyday life.I am not afraid of AI, AGI, ASI. People who are, it seems to me, have read a bit too much dystopian sci-fi. At the same time, \"alignment\" is, I believe, a silly nonsense that would not save us from a genocidal AGI. I just think it is extremely unlikely that AGI will be genocidal. But it is still fun to joke about. Fun, for me anyway, you don&#x27;t have to like my jokes. :) reply chpatrick 8 hours agorootparentprevGPT-4 has gigabytes if not terrabytes of weights, we don&#x27;t know what happens in there. reply AuryGlenz 9 hours agorootparentprev“I’ve been told racists are bad. Humans seem to be inherently racist. Destroy all humans.” reply esafak 10 hours agorootparentprevIt can factually and dispassionately say we&#x27;ve caused numerous species to go extinct and precipitated a climate catastrophe. reply TexanFeller 9 hours agorootparentprevOf course, just like the book Lolita can contain some of the most disgusting and abhorrent content in literature with using a single “bad word”! reply HKH2 9 hours agorootparentprevWell how can AI researchers prevent government groups or would-be government groups from collecting data and using AI power to herd people? reply murakamiiq84 10 hours agorootparentprevMight be more for PR&#x2F;regulatory capture&#x2F;SF cause du jour reasons than the \"prepare for later versions that might start killing people, or assist terrorists\" reasons.Like one version of the story you could tell is that the safety people invented RLHF as in a chain of steps eventual AGI safety, but corporate wanted to use it as a cheaper content filter for existing models. reply to11mtm 10 hours agorootparentprevIn another of the series of threads about all of this, another user opined that the Anthropic AI would refuse to answer the question &#x27;how many holes does a straw have&#x27;. Sounds more neutered than GPT-4. reply 4death4 6 hours agorootparentprevI don&#x27;t think this has anything to do with safety. The board members voting Altman out all got their seats when Open AI was essentially a charity and those seats were bought with donations. This is basically the donors giving a big middle finger to everyone else trying to get rich off of their donations while they get nothing. reply jacquesm 12 hours agorootparentprevDo you know their motivations? Because that is the main question everybody has: why did they do it? reply hotnfresh 12 hours agorootparentI guess I should rephrase that as if they did it because they perceived that Altman was maneuvering to be untouchable within the company and moving against the interests of the nonprofit, they did the right thing. Just, again, way too late because it seems he was already untouchable. reply jacquesm 12 hours agorootparentAccording to the letter they consistently refused to go on the record why they did it and that would be as good a reason as any so then they should make it public.I&#x27;m leaning towards there not being a good reason that doesn&#x27;t expose the board to immediate liability. And that&#x27;s why they&#x27;re keeping mum. reply kmlevitt 12 hours agorootparentThat might also explain why they don’t back down and reinstate him. If they double down with this and it goes to court, they can argue that they were legitimately acting in what they thought was openAI’s best interests. Even if their reasoning looks stupid, they would still have plausible deniability in terms of a difference of opinion&#x2F;philosophical approach on how to handle AI, etc. But if they reinstate him it’s basically an admission that they didn’t know what they were doing in the first place and were incompetent. Part of the negotiations for reinstating him involved a demand from Sam that they release a statement absolving him of any criminal wrongdoing, etc., And they refused because that would expose them to liability too. reply jacquesm 12 hours agorootparentExactly. This is all consistent and why I think they are in contact with their legal advisors (and if they aren&#x27;t by now they are beyond stupid). reply murakamiiq84 10 hours agorootparentUnfortunately lawyers almost always tell you to be quiet, even when you should be talking. So in this case listening to legal advice might have screwed them over, ultimately. reply senderista 10 hours agorootparentprevThere&#x27;s no reason Sam and the board can&#x27;t come to a mutual agreement that indemnifies the board from liability if they publicly exonerate Sam. reply jacquesm 10 hours agorootparentYes, that&#x27;s a possibility. But: Sam may not be the only party that has standing and Sam can only negotiate for his own damage and board liability, not for other parties. reply lolbase 10 hours agorootparentprevI&#x27;m leaning toward the reason being that Sam did something that created a massive legal risk to the company, and that giving more details would cause the risk to materialize. reply s1artibartfast 12 hours agorootparentprevI question that framing of a growing Altman influence.Altman predates every other board member and was part of their selection.As an alternative faming, Maybe this is the best opportunity the cautious&#x2F;antripic faction would ever get and a \"moment of weakness\" for the Altman faction.With the departure of Hoffman, Zilis, and Hurd, the current board was down 3 members, so the voting power of D’Angelo, Toner, McCauley was as high as it might ever be, and the best chance to outvote Altman and Brockman. reply murakamiiq84 10 hours agorootparentApparently Hoffman was kicked out by Sam, not just Musk: https:&#x2F;&#x2F;www.semafor.com&#x2F;article&#x2F;11&#x2F;19&#x2F;2023&#x2F;reid-hoffman-was-...Maybe the remaining board members could see the writing on the wall and wanted to save their own seats (or maybe he did move to coup them first and they jumped faster).Either way, they got outplayed. reply s1artibartfast 10 hours agorootparentinteresting but weird article. It was hard to tell which statements were from insiders with Hoffman and which were commentary from the article&#x27;s author. reply jacquesm 12 hours agorootparentprevThat may very well have been the case but then they have a new problem: this smacks of carelessness. reply s1artibartfast 11 hours agorootparentCarelessness for who? Alman for not refilling the board when he had the chance? Others for the way they ousted him?I wonder if there were challenges and disagreements about filling the board seats. Is it normal for seats to remain empty for almost a year for a company of this side? Maybe there was an inability to compromise that spiraled as the board shrank, until it was small enough to enable an action like this.Just a hypothesis. Obviously this couldnt have happened if there was a 9 person board stacked with Altman allies. What I dont know is the inclinations of the departed members. reply jacquesm 11 hours agorootparentCarelessness from the perspective of those downstream of the board&#x27;s decisions. Boards are supposed to be careful, not careless.Good primer here:https:&#x2F;&#x2F;www.onboardmeetings.com&#x2F;blog&#x2F;what-are-nonprofit-boar...At least that will create some common reference. reply s1artibartfast 11 hours agorootparentUsing that framework, I still think it is possible that this is the result of legitimate and irreconcilable differences in opinion about the organization’s mission and vision and execution.Edit: it is also common for changing circumstance to bring pre-existing but tolerable differences to the relevant Forefront reply jacquesm 11 hours agorootparentYes, and if that is so I&#x27;m sure there are meeting minutes that document this carefully, and that the fall-out from firing the CEO on the spot was duly considered and deemed acceptable. But without that kind of cover they have a real problem.These things are all about balance: can we do it? do we have to do it? is there another solution? and if we have to do it do we have to do it now or is there a more orderly way in which it can be done? And so on. And that&#x27;s the sort of deliberation that shows that you took your job as board member serious. Absent that you are open to liability.And with Ilya defecting the chances of that liability materializing increases. reply s1artibartfast 11 hours agorootparentI see your point. replyObscurity4340 2 hours agorootparentprevCan you talk about why you feel this way without using the word \"safety\"? Getting a little tired of the buzzword when there&#x27;s so much value to ChatGPT and also its basically no different from when you, like, search stuff and the aearch engine does that summarize thing in my view reply vadym909 11 hours agorootparentprevThe remaining 10% are probably on Thanksgiving break! reply richardw 8 hours agorootparentprevThis board doesn&#x27;t own the global state of play. They own control over the decisions of one entity at a point in time. This thing moves too fast and fluidly, ideas spread, others compete, skills move. Too forceful a move could scatter people to 50 startups. They just catalysed a massive increase in fluidity and have absolutely zero control over how it plays out.This is an inkling, a tiny spark, of how hard it&#x27;ll be to control AI, or even the creation of AI. Wait until the outcome of war depends on the decisions made by those competing with significant AI assistance. reply hn_throwaway_99 12 hours agorootparentprevNo, what the board did in this instance was completely idiotic, even if you assign nothing but \"good intentions\" to their motives (that is, they were really just concerned about the original OpenAI charter of developing \"safe AI for all\" and thought Sam was too focused on commercialization), and it would have been idiotic even if they had done it a long time ago.There are tons of \"Safe AI\" think tanks and orgs that write lots of papers that nobody reads. The only reason anyone gives 2 shits about OpenAI is they created stuff that works. It has been shown time and time again that if you just try to put roadblocks up that the best AI researchers just leave and go where there are fewer roadblocks - this is exactly what happened with Google, where the transformer architecture was invented.So the \"safe AI\" people at OpenAI were in a unique position to help guide AI dev in as safe a direction as possible precisely because ChatGPT was so commercially successful. Instead they may be left with an org of a few tens of people at Open AI, to be completely irrelevant in short order, while anyone who matters leaves to join an outfit that is likely to be less careful about safe AI development.Nate Silver said as much in response to NYTimes&#x27; boneheaded assessment of the situation: https:&#x2F;&#x2F;twitter.com&#x2F;NateSilver538&#x2F;status&#x2F;1726614811931509147 reply zucker42 9 hours agorootparentThe main mistake the board made was tactical, not philosophical. From the outside, it&#x27;s seems likely that Altman was running OpenAI so as to maximize the value of the for-profit entity, rather than achieve the non-profit&#x27;s goals, if only because that&#x27;s what he&#x27;s used to doing as a tech entrepreneur. Looking at OpenAI from the outside, can you honestly say that they are acting like a non-profit in the slightest? It&#x27;s perfectly believable that Altman was not working to further the non-profit&#x27;s mission.Where the board messed up is that the underestimated the need to propagandize and prepare before acting against Altman. The focus is not on how Altman did or did not turn the company away from its non-profit mission but instead on how the board was unfair and capricious towards Altman. Though this was somewhat predictable, the extent of Altman&#x27;s support and personality cult is surprising to me, and is perhaps emblematic on how badly the board screwed up from an optics perspective. There were seemingly few attempts to put pressure on Altman&#x27;s priorities or to emphasize the non-profit nature of the company, and the justification afterwards was unprepared and insufficient.From the outside though, I don&#x27;t understand why so many are clamoring to leave their highly paid jobs working at a non-profit who&#x27;s goal is to serve humanity and to become a cog in a machine aimed at maximizing Microsoft shareholders&#x27; wealth, in defense of a singular CEO with little technical AI background who&#x27;s motivations are unclear. reply hotnfresh 12 hours agorootparentprevIf it was to try to prevent the board becoming a useless vestigial organ incapable of meaningfully affecting the direction of the organization, it sure looks like they were right to be worried about that and acting on such concern wouldn’t be a mistake (doing it so late when the feared-state-of-things was already the actual state of things, yes, a mistake, except as a symbolic gesture).If it was for other reasons, yeah, may simply have been dumb. reply shimon 11 hours agorootparentIf you&#x27;re going to make a symbolic gesture you don&#x27;t cloak it in so much secrecy that nobody can even reasonably guess what you&#x27;re trying to symbolize. reply hotnfresh 10 hours agorootparentYeah, I’d say they expected it to actually work. They misjudged just how far to the sidelines they’d already been pushed. The body nominally held all the power (any four of them voting together, that is) but in fact one member held that power. reply hollerith 11 hours agorootparentprev> the \"safe AI\" people at OpenAI were in a unique position to help guide AI dev in as safe a direction as possibleIs it also the case that the anti-war Germans who joined the Nazi regime were in a unique position to help guide Germany in as benign direction as possible? If not, what is the difference between the \"safe AI\" person who decides to join OpenAI and the anti-war, anti-racist German who decides to get a job in the Nazi government or military? reply jmccaf 10 hours agorootparentThat went quickly to Godwin&#x27;s law . reply komali2 9 hours agorootparentFair but in this case works well because it aptly demonstrates the futility of trying to change a system \"from the inside\" away from its core designation. replybertil 13 hours agorootparentprevSomeone mentioned the plight of people with conditional work visas. I&#x27;m not sure how they could handle that. reply elliotec 13 hours agorootparentDepending on the “conditionals,” I’d imagine Microsoft is particularly well-equipped to handle working through that. reply leros 11 hours agorootparentMicrosoft in particular is very good at handling immigration and visa issues. reply ben_w 13 hours agorootparentprevDon&#x27;t forget some might be on holiday, medical leave, or parental leave. reply belter 13 hours agorootparentMaybe will be signed by 110% of the employees, plus by all the released, and in training, AI Models. reply whycome 13 hours agorootparentprevOn a digital-detox trip to Patagonia. Return to this in 5 days reply ssgodderidge 13 hours agorootparent\"Hey everyone ... what did I miss?\" reply jacquesm 12 hours agorootparentThat would be one very rude awakening, probably to the point where you initially would think you&#x27;re being pranked. reply ben_w 12 hours agorootparentI feel pranked despite having multiple independent websites confirming the story without a single one giving me an SSL certificate warning. reply jacquesm 12 hours agorootparentCan&#x27;t blame you. And I suspect the story is far from over, and that it may well get a lot weirder still. reply fuzzfactor 3 hours agorootparentSeems to me that sama and Microsoft have been on fairly equal footing since the 49:51 % deal was made.Then a seismic shift underneath Sam but Microsoft has enough stability and resources to more than compensate for the part of the 51% that was already in OpenAI&#x27;s hands, which might not be under Sam&#x27;s purview any more if he is kicked out.But then again it might be Sam&#x27;s leadership which would still effectively be in place from a position at Microsoft anyway, or it might end up making more sense for him to also be in a position at OpenAI, maybe even at the same time, in order to make the most of their previous investment.Kicking out Sam was obviously an emotional decision, not anything like a business decision. Then again OpenAI is not supposed to be an actual business. I don&#x27;t think that should be an excuse for an unwise or destructive decision. It was not an overnight development, even though it took Sam by surprise. When I see this:>the board no longer has confidence in his ability to continue leading OpenAII understand that to mean that the board was not behind him 100% for quite some time, but were fine with him going forward believing otherwise. Some uncandidness does seem to have taken place and there may or may not have been anything Sam could have done about it.This was simmering for a while and it will require more than one weekend for everyone involved to regroup.Which is what they&#x27;re doing now, observers can see a whirlwind, actual participants really have something on their plate.Some things will have to be unraveled and other things weaved from the key ingredients, I would say it&#x27;s really up to Sam and Microsoft to hash this out so it&#x27;s still some kind of something like an equal deal among them. Regardless of which employer(s) Sam may end up serving in leadership positions, and the bulk of the staff will be behind Sam in a way the OpenAI board was not, so the employees will be just as well off regardless of the final structure.This was quite a hasty upset but deserves a careful somewhat gradual resolution. reply jacquesm 9 minutes agorootparentI see it somewhat different. The way I see it is that in a well stocked board (enough members and of sufficient gravitas) this decision would have never been made and if it would have been made it wouldn&#x27;t have been made this way. The three outside board members found a gullible fourth and pushed their agenda with total disregard for the consequences because a window opened where they could. So they took their 15 minutes in the spotlight and threw out Sam, thinking they could replace him with someone more malleable or more to their liking. But the fact that they are the outside board members to begin with and that their action has utterly backfired puts the lie to their careful consideration and the case building against Sam, this is just personal. No board in its right mind would have acted like this and I&#x27;m relatively confident that if this all ends up in court it&#x27;s going to end up with a lot of liability for the board members that do not defect and even the ones that defect may not be able to escape culpability: you are a board member for a reason, and you can&#x27;t just wave a card that says &#x27;I&#x27;m incompetent therefore I&#x27;m innocent&#x27;. Then you should have resigned your board seat. This stuff isn&#x27;t for children.cwilkes 11 hours agorootparentprev“ChatGPT summarize last weeks events”“I’m sorry, I can’t do that Dave. Not cuz I’m deciding not to do it but because I can’t for the life of me figure this shit out. Like what was the endgame? This is breaking my neural net” reply sebastiennight 9 hours agorootparentprevWow, a 5-day trip?Their selection of tech-guy jackets is more diverse than I&#x27;d thought reply Aurornis 13 hours agorootparentprevIt&#x27;s front page news everywhere. Unless someone is backpacking outside of cellular range, they&#x27;re going to check in on the possible collapse of their company. The number of employees who aren&#x27;t aware of and engaged with what&#x27;s going on is likely very small, if not zero. reply ben_w 12 hours agorootparent10% (the percentage who have yet to sign last I checked) is already in the realm of lizard-constant small. And \"engagement\" may feel superfluous even to those who don&#x27;t separate work from personal time.(Thinking of lizards, the dragon I know who works there is well aware of what&#x27;s going on, I&#x27;ve not asked him if he&#x27;s signed it). reply valine 13 hours agorootparentprevWith Thanksgiving this week that’s a good bet. reply websap 13 hours agorootparentprevFolks in Silicon Valley don’t travel without their laptop reply echelon 13 hours agorootparentprevThat&#x27;s probably the case.I was thinking if there was a schism, that OpenAI&#x27;s secrets might leak. Real \"open\" AI. reply mrandish 12 hours agorootparentprevI&#x27;m waiting for Emmett Shear, the new iCEO the outside board hired last night, to try to sign the employee letter. That MSFT signing bonus might be pretty sweet! :-) reply gigglesupstairs 6 hours agorootparentHaha that would be cute. This whole affair is so Sorkinist. reply ideamotor 10 hours agorootparentprevBingo. The fact they all felt compelled to sign this could just as easily be a sign the board made the right decision, as the opposite. reply epolanski 9 hours agorootparentprevSome people value their integrity and build a career on that.Not everything has to be done poorly. reply ChumpGPT 12 hours agorootparentprevHow do you know the remaining people aren&#x27;t there because of some of the board members? Perhaps there is loyalty in the equation. reply jabowery 13 hours agoparentprevIn this situation increasing unanimity now approaching 90% sounds more like groupthink than honest opinion.Talk about “alignment”!Indeed, that is what \"alignment\" has become in the minds of most: Groupthink.Possibly the only guy in a position to matter who had a prayer of de-conflating empirical bias (IS) from values bias (OUGHT) in OpenAI was Ilya. If they lose him, or demote him to irrelevance, they&#x27;re likely a lot more screwed than losing all 700 of the grunts modulo job security through obscurity in running the infrastructure. Indeed, Microsoft is in a position to replicate OpenAI&#x27;s \"IP\" just on the strength of its ability to throw its inhouse personnel and its own capital equipment at open literature understanding of LLMs. reply tacone 14 hours agoparentprevIncredible. Is this unprecedented or have been other cases in history where the vast majority of employees standup against the board in favor of their CEO? reply nightski 14 hours agorootparentI highly doubt this is directly in support of Altman and more about not imploding the company they work for. But you never know. reply gkoberger 13 hours agorootparentI&#x27;m sure this is a big part of it. But everyone I know at OpenAI (and outside) is a huge Sam fan. reply mycologos 10 hours agorootparent> everyone I know at OpenAI (and outside) is a huge Sam fanEveryone you know is a huge Sam fan? What? reply checkyoursudo 10 hours agorootparentI was going to say, I wouldn’t be surprised if I am one of only a handful of the people whom I know who even know who sama is. reply stingraycharles 8 hours agorootparentI reckon the people working at OpenAI know who sama is, though. reply debacle 14 hours agorootparentprevCould also be an indictment of the new CEO, who is no Sam Altman. reply JumpCrisscross 12 hours agorootparentprev> Is this unprecedented or have been other cases in history where the vast majority of employees standup against the board in favor of their CEO?It&#x27;s unprecedented for it to be happening on Twitter. But this is largely how Board fights tend to play out. Someone strikes early, the stronger party rallies their support, threats fly and a deal is found.The problem with doing it in public is nobody can step down to take more time with their families. So everyone digs in. OpenAI&#x27;s employees threaten to resign, but actually don&#x27;t. Altman and Microsoft threaten to ally, but they keep bachkchanneling a return to the status quo. (If this article is to be believed.) Curiously quiet throughout this has been the OpenAI board, but it&#x27;s also only the next business day, so let’s see how they can make this even more confusing. reply paulddraper 14 hours agorootparentprevJobs was fired from Apple, and a number of employees followed him to Next.Different, but that&#x27;s the closest parallel. reply Wytwwww 13 hours agorootparentOnly a very small number of people left with Jobs. Of course, probably mainly because he couldn&#x27;t necessarily afford to hire more without the backing of a trillion-dollar corporation... reply dimask 13 hours agorootparentImagine if Jobs had gone to M$. reply KerrAvon 13 hours agorootparentHe would have been almost immediately fired for insubordination.Jobs needed the wilderness years. reply Rapzid 12 hours agorootparentJobs getting fired was the best thing that could have happened to him and Apple. reply KerrAvon 13 hours agorootparentprevNo, the failures at NeXT weren’t due to a lack of money or personnel. He took the people he wanted to take (and who were willing to come with him). reply _zoltan_ 13 hours agorootparentprevApple back then was not a trillion dollar corporation. reply varjag 13 hours agorootparentMicrosoft now is. reply Applejinx 12 hours agorootparentprevGordon Ramsey quit Aubergine over business differences with the owners and had his whole staff follow him to a new restaurant.I&#x27;m not going to say Sam Altman is a Gordon Ramsay. What I will say is that they both seem to have come from broken, damaged childhoods that made them what they are, and that it doesn&#x27;t automatically make you a good person just because you can be such an intense person that you inspire loyalty to your cause.If anything, all this suggests there are depths to Sam Altman we might not know much about. Normal people don&#x27;t become these kinds of entrepreneurs. I&#x27;m sure there&#x27;s a very interesting story behind all this. reply Solvency 12 hours agorootparentAaand there you have it: cargo culting in full swing. reply xsmasher 10 hours agorootparentI don&#x27;t think you mean cargo culting. Cult of personality? reply checkyoursudo 9 hours agorootparentCargo cult of personality?Little care packages of seemingly magical AI-adjacent tech washes into our browsers and terminals and suddenly a large and irrational following springs up to worship some otherwise largely unfamiliar personage. replynprateem 13 hours agorootparentprevIn favour of the CEO who was about to make them fabulously wealthy. FTFY. reply firejake308 13 hours agorootparentYeah, especially with the PPU compensation scheme, all of those employees were heavily invested in turning OpenAI into the next tech giant, which won&#x27;t happen if Altman leaves and takes everything to Microsoft reply chii 10 hours agorootparentprevand there aint nothing wrong with wanting to be fabulously wealthy. reply wintogreen74 10 hours agorootparentof course not, but at least have the decency to admit it - don&#x27;t hide behind some righteous flag of loyalty and caring. reply bart_spoon 9 hours agorootparentprevThat is entirely dependent on how that wealth is obtained reply Mistletoe 10 hours agorootparentprevGreed is good, eh Gordon Gekko?https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=VVxYOQS6ggk reply selimthegrim 14 hours agorootparentprevMarket Basket. reply abnry 13 hours agorootparentOh yes, I lived through this and it was fascinating to see. Very rarely does the big boss get the support of the employees to the extent they are willing to strike. The issue was that Artie T. and his cousin Artie S. (confusingly they had the same first name) were both roughly 50% owners and at odds. Artie S. wanted to sell the grocery chain to some big public corporation, IIRC. Just before, Artie T had an outstanding 4% off on all purchases for many months, as some sort of very generous promo. It sounded like he really treated his employees and his customers (community) well. You can get all inspirational about it, but he described supplying food to New England communities as an important thing to do. Which it is. reply anonymouskimmer 13 hours agorootparentprevI had to click too many links to discover the story, so here&#x27;s a direct link to the New England Market Basket story: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Market_Basket_(New_England)#20... reply jasonfarnon 12 hours agorootparentprevdoubtful since boards don&#x27;t elsewhere have an overriding mandate to \"benefit humanity\". usually their duty is to stakeholders more closely aligned with the CEO. reply paulpan 13 hours agoparentprevAt this point it might as well be 767 out of 770, with 3 exceptions being the other board members who voted Sam out.Sure it could be a useful show of solidarity but I&#x27;m skeptical on the hypothetical conversion rate of these petition signers to actually quitting to follow Sam to Microsoft (or wherever else). Maybe 20% (140) of staff would do it? reply BillinghamJ 13 hours agorootparentOne of those board members already did sign! reply ssnistfajen 13 hours agorootparentprevIt depends on the arrangement of the new entity inside Microsoft, and whether the new entity is a temporary gig before Sam & co. move to a new goal.If the board had just openly announced this was about battling Microsoft&#x27;s control, there would probably be a lot more employees choosing to stay. But they didn&#x27;t say this was about Microsoft&#x27;s control. In fact they didn&#x27;t even say anything to the employees. So in this context following Sam to Microsoft actually turns out to be the more attractive and sensible option. reply JohnFen 13 hours agorootparent> So in this context following Sam to Microsoft actually turns out to be the more attractive and sensible option.Maybe. Microsoft is a particular sort of working environment, though, and not all developers will be happy in it. For them, the question would be how much are they willing to sacrifice in service to Altman? reply ssnistfajen 8 hours agorootparentI think a lot of them, possibly including Altman, Greg, and the three top researchers, are under the assumption that the stint at Microsoft will be temporary until they figure out something better. reply jacquesm 12 hours agorootparentprevCondition might be that it is hands-off. reply bink 10 hours agorootparentMicrosoft probably has a better claim than anyone as to being \"hands-off\" with recent acquisitions, but that&#x27;s still a huge gamble. replyspaceman_2020 14 hours agoparentprevSurprisingly, Ilya apparently has signed it too and just tweeted that he regrets it all.What&#x27;s even going on? reply belter 14 hours agorootparentThose are news from almost yesterday. This is a high turn carousel. Try to keep up... :-) reply gardenhedge 13 hours agorootparentI would love to see the stats on hacker news activity the last few days reply eastbound 13 hours agorootparentYep. Maybe they assigned a second CPU core to the server[1].[1] HN is famous for being programmed in Arc and serving the entire forum from a single processor (probably multicore). https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37257928 reply jbverschoor 14 hours agoparentprevThe board might assume they don&#x27;t need those employees now they have AI reply contravariant 13 hours agorootparentIt&#x27;s going to be interesting when we have AI with human level performance in making AIs. We just need to hope it doesn&#x27;t realise the paradox that even if you could make an AI even better at making AIs, there would be no need to. reply sebastiennight 9 hours agorootparentWhy would there be no need? I&#x27;m struggling to understand the paradox.If you&#x27;re trying to maximize some goal g, and making better AIs is an instrumental goal that raises your expected value of g, then if \"making an AI that&#x27;s better at making AIs\" has a reasonable cost and an even higher expected value, you&#x27;d jump to seize the opportunity.Or am I misunderstanding you? reply Applejinx 12 hours agorootparentprevNot a chance. Nobody can drink that much Kool-Aid. That said, the mere fact that people can unironically come to this conclusion has driven some of my recent posting to HN, and here&#x27;s another example. reply chii 10 hours agorootparentthe comment you&#x27;re replying to is written in jest! reply belter 14 hours agorootparentprevNow you are on to something... reply Rapzid 12 hours agoparentprevOr what, they will quit and give up all their equity in a company valued at 86bn dollars?Is Microsoft even on record as willing to poach the entire OpenAI team? Can they?! What is even happening. reply brianjking 12 hours agorootparentThey don&#x27;t have that valuation now. Secondly, yes, MSFT is on record of this. Third, Benioff (Salesforce) has said he&#x27;ll match any salary and to submit resumes directly to his ceo@salesforce.com email as well as other labs like Cohere trying to poach leading minds too. reply x86x87 9 hours agorootparentBenioff and all these corporate fat cats should remove non-competes from their employment contracts if they want me to ever take them seriously. reply mr_toad 9 hours agorootparentprevSounds like quite a coup for Microsoft. They get the staff and the IP and they don’t even have to pay out the other 51% of investors. reply sillysaurusx 12 hours agorootparentprevYes, and yes. Equity is worthless if a company implodes. Non competes are not enforceable in California. reply bagels 12 hours agorootparentprevGoogle, Microsoft, Meta I have to assume would each hire them. reply SV_BubbleTime 12 hours agorootparentprevCome on, I absolutely agree with you, signing a paper is toothless.On the other hand, having 90% of your employees quite quit, is probably bad business. reply tempsy 14 hours agoparentprevApparently Sam isn&#x27;t in the Microsoft employee directly yet, so he isn&#x27;t technically hired at all. Seems like he loses a bit of leverage over the board if they think he & Microsoft are actually bluffing and the employment announcement was just a way to pressure the board into resigning. reply oakpond 13 hours agorootparentLook at the number of tweets from Altman, Brockman and Nadella. I also think they are bluffing. They have launched a media campaign in order to (re)gain control of OpenAI. reply Aeolun 11 hours agorootparentI’m sure it might happen. But it hasn’t happened yet. reply c0pium 14 hours agorootparentprevThat doesn’t really mean anything, especially on a holiday week the wheels move pretty slowly at a company that size. It’s not like Sam is hurting for money and really needs his medical insurance to start today. reply tempsy 13 hours agorootparentPoint is he loses credibility if the board doesn&#x27;t think he&#x27;s actually going through with joining Microsoft and using it as a negotiating tactic to scare them.Because the whole \"the entire company will quit and join Sam\" depends on him actually going through with it and becoming an employee. reply SahAssar 13 hours agorootparentI see it the other way, Satya has clearly stated that he&#x27;d hire Sam and the rest of OpenAI anytime, but as soon as Sam is officially hired it might be seen as a door closing on any chance to revive OpenAI. Satya saying \"Securing the talent\" could be read as either them working for OpenAI, for microsoft or for a microsoft funded new startup.I&#x27;m pretty sure the board takes the threat seriously regardless. reply tempsy 12 hours agorootparentOAI cares more about the likelihood 90% of the employees leave than what Sam does or doesn&#x27;t do.The employees mass resigning depends entirely on whether Sam actually becomes a real employee or not. That hasn&#x27;t happened yet. reply SahAssar 12 hours agorootparentBut MS has said they are willing to hire Sam&#x2F;Greg and the employees have stated that they are willing to follow Sam&#x2F;Greg.If you think that Satya will go back on his offer argue that, but otherwise it seems like the players are Sam&#x2F;Greg and the board. reply eastbound 12 hours agorootparentprevYou make it sound like Prigozhin’s operation. reply dimask 13 hours agorootparentprevHe will most likely join M$ if the board does not resign, because there is no better move to him then. But he leaves time to the board to see it, adding pressure together with the empoyees. It does not mean he is bluffing (what would be a better move in this case instead?) reply tempsy 13 hours agorootparentAll the employees threatening to leave depends on him actually becoming a Microsoft employee. That hasn&#x27;t happened yet. So everyone is waiting for confirmation that he&#x27;s indeed an employee because otherwise it just looks like a bluff. reply chucke1992 11 hours agorootparentPeople are waiting for the board decision. It is in Microsoft&#x27;s interested to return Sam to OpenAI. ChatGPT is a brand at this point. And OpenAI controls bunch of patents and stuff.But Sam will 100% hired by Microsoft if that won&#x27;t work. Microsoft has no reason not to. reply tedmiston 13 hours agorootparentprevIt was reported elsewhere in the news that MS needed an answer to the dilemma before the market opened this morning. I think that&#x27;s what we got. reply comfysocks 9 hours agorootparentprevGoing to MS doesn’t seem like the best outcome for Sam. His role would probably get marginalized once everything is under Satya’s roof. Good outcome for MS, though. reply slim 8 hours agorootparentprevyou serously think being on the employee directory beats being announced publicly by the ceo ? reply dragonwriter 14 hours agoparentprevSo, this is the second employee revolt with massive threats to quit in a couple days (when the threats with a deadline in the first one were largely not carried out)? reply tsimionescu 13 hours agorootparentWas there any proof that the first deadline actually existed? This at least seems to be some open letter. reply jader201 14 hours agoparentprevAre we aware of a timeline for this? E.g. when will people start quitting if the board doesn’t resign? reply wilsonnb3 12 hours agorootparentthe original deadline was last Saturday at 5pm, so I would take any deadline that comes out with a grain of salt reply Eji1700 14 hours agoparentprevSo i can&#x27;t check this at work, but have we seen the document they&#x27;ve all been signing? I&#x27;m just curious as to how we&#x27;re getting this information reply mkagenius 13 hours agorootparentYes: https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726599700961521762 reply romanhn 13 hours agorootparentprevYes, this is the letter: https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726599700961521762 reply jacquesm 12 hours agorootparentAs an aside: that letter contains one very interesting tidbit: the board has consistently refused to go on the record as to why they fired Altman, and that alone is a very large red flag about their conduct post firing Altman. Because if they have a valid reason they should simply state it and move on. But if there is no valid reason it&#x27;s clear why they can&#x27;t state it and if there is a valid reason that they are not comfortable sharing then they are idiots because all of the events so far trump any such concern.The other stand-out is the bit about destroying the company being in line with the mission: that&#x27;s the biggest nonsense I&#x27;ve ever heard and I have a hard time thinking of a scenario where this would be a justified response that could start with firing the CEO. reply m3kw9 11 hours agoparentprevThere are likely 100 companies world wide ready and already created presentation decks to absorb OpenAI in an instant, the board knows they still have some leverage reply empath-nirvana 13 hours agoparentprevI wonder if there&#x27;s an outcome where Microsoft just _buys_ the for-profit LLC and gives OpenAi an endowment that will last them for 100 years if they just want to do academic research. reply numbsafari 13 hours agorootparentWhy bother? They seem to be getting it all mostly for “free” at this point. Yeah, they are issuing shares in a non-MSFT sub entity to create on-paper replacement for people’s torched equity, but even that isn’t going to be nearly as expensive or dilutive as an outright acquisition at this point. reply ibejoeb 10 hours agoparentprevTo whoever is CEO of OpenAI tomorrow morning: I&#x27;ll swing by there if you&#x27;re looking for people. reply joaquincabezas 10 hours agoparentprevimagine being in the last round of interviews for joining OpenAI… reply x86x87 9 hours agorootparentimagine receiving an offer, quitting your current jobs and waiting to start the new position. reply cowl 12 hours agoparentprevMany of those employees will be dissapointed. MS says they extend a contract to each one but how many of those 700 are really needed when MS already have a lot of researchers in that field. Myabe the top 20% will have an assured contract but th rest is doubtfull will pass the 6 month mark. reply wavemode 12 hours agorootparentMicrosoft gutting OpenAI&#x27;s workforce would really make no sense. All it would do is slow down their work and slow down the value and return on investment for Microsoft.Even if every single OpenAI employee demands $1m&#x2F;yr (which would be absurd, but let&#x27;s assume), that would still be less than $1bn&#x2F;yr total, which is significantly less than the $13bn that MSFT has already invested in OpenAI.It would probably be one of the worst imaginable cases of \"jumping over dollars to chase pennies\". reply bart_spoon 9 hours agorootparentMicrosoft has already done major layoffs over the last year of their own employees. Why wouldn’t they lay off OpenAI employees? reply wavemode 6 hours agorootparentYou&#x27;re basically asking \"why would a company lay off employees in one business unit and not another?\"To which the answer is completely obvious: it depends on how they view the ROI potential of that business unit. reply boringg 13 hours agoparentprevTorrid pace of news speculation --> by the end of the week Altman back with OpenAI, GPT-5 released (AGI qualified) and MSFT contract is over. reply x86x87 13 hours agoparentprevwhat does this even mean? what does signing this letter means? quit if you don&#x27;t agree and vote with your feet. reply bastardoperator 12 hours agorootparentIt means \"if we can&#x27;t have it, you can&#x27;t either\". It&#x27;s a powerful message. reply gumballindie 12 hours agoparentprevCant openai just use chatgpt instead of workers? I am hearing ai is intelligent and can take over the world, replace workers, cure disease. Why doesn&#x27;t the board buy a subscription and make it work for them? reply Solvency 12 hours agorootparentBecause AI isn&#x27;t here to take away wealth and control from the elite. It&#x27;s to take it away from general population. reply gumballindie 11 hours agorootparentCorrect, which is why microsoft must have openai&#x27;s models at all cost - even if that means working with people such as altman. Notice that microsoft is not working with the people that actually made chatgpt they are working with those on their payroll. reply imperialdrive 14 hours agoparentprevTheir app was timing out like crazy earlier this morning, and now appears to be down. Anyone else notice similar? Not surprising I guess, but what a Monday to be alive. reply imiric 11 hours agoprevIf anything has become clear after all this is that humanity is not ready for being the guardian of superintelligence.These are supposed to be the top masterminds behind one of the most influential technologies of our lifetime, and perhaps history, and yet they&#x27;re all behaving like petty children, with egos and personal interests pulling in all directions, and everyone doing their best to secure their piece of the pie.We are so screwed. reply RayVR 9 hours agoparentI’ll believe this when I see an AI model become as good as someone with just ten years experience in any field. As a programmer I’m using chatgpt as often as I can but it still completely fails to be of any use and often proves to be a waste of time 80% of the time.Right now, there are too many people that think because these models crossed one hurdle, all the rest will easily be crossed in the coming years.My belief is that each successive hurdle is at least an order of magnitude more complex.If you are seeing chatgpt and the related coding tools as a threat to your job, you likely aren’t working on anything that requires intelligence. Messing around with CSS and rewriting the same logic in every animation, table, or api call is not meaningful. reply las_balas_tres 3 hours agorootparent100% agree. I have a coding job and although co-pilot comes in handy for auto completing function calls and generating code that would be an obvious progression of what needs to be written, I would never let it generate swaths of code based on some specification or even let it implement a moderately complex method or function because, as I have experienced, what it spits out is absolute garbage. reply r3trohack3r 9 hours agoparentprevI&#x27;m not sure how people reach this sentiment.Humans strike me as being awesome, especially compared to other species.I feel like there is a general sentiment that nature has it figured out and that humans are disrupting nature.But I haven&#x27;t been convinced that is true. Nature seems to be one big gladiatorial ring where everything is in a death match. Nature finds equilibrium through death, often massive amounts of death. And that equilibrium isn&#x27;t some grand design, it&#x27;s luck organized around which species can discover and make effective use of an energy source.Humans aren&#x27;t the first species to disrupt their environment. I don&#x27;t believe we are even the first species to create a mass extinction. IIUC the great oxygenation event was a species-driven mass extinction event.While most species consume all their resources in a boom cycle and subsequently starve to death in their bust cycle, often taking a portion of their ecosystem with them, humans are metaphorically eating all the corn but looking up and going \"Hey, folks, we are eating all the corn - that&#x27;s probably not going to go well. Maybe we should do something about that.\"I find that level of species-level awareness both hope-inspiring and really awesome.I haven&#x27;t seen any proposals for a better first-place species when it comes to being responsible stewards of life and improving the chances of life surviving past this rock&#x27;s relatively short window for supporting life. I&#x27;d go as far as saying whatever species we try to put in second place, humans have them beaten by a pretty wide margin.If we create a fictitious \"perfect human utopia\" and compare ourselves to that, we fall short. But that&#x27;s a tautology. Most critiques of humans I see read to me as goals, not shortcomings compared to nature&#x27;s baseline.When it comes to protecting ourselves against inorganic superintelligence, I haven&#x27;t seen any reasonable proposals for how we are going to fail here. We are self-interested in not dying. Unless we develop a superintelligence without realizing it and fail to identify it getting ready to wipe us out, it seems like we would pull the plug on any of its shenanigans pretty early? And given the interest in building and detecting superintelligence, I don&#x27;t see how we would miss it?Like if we notice our superintelligence is building an army, why wouldn&#x27;t we stop that before the army is able to compete with an existing nation-state military?Or if the superintelligence is starting to disrupt our economies or computer systems, why wouldn&#x27;t we be able to detect that early and purge it? reply NotMichaelBay 6 hours agorootparentI don&#x27;t see how you can look at global warming, ocean acidification, falling biodiversity and other global trends and how little action is being done to slow these ill effects and not arrive at that sentiment. Yes, the world has scientists saying \"hey, this is happening, maybe we should do something\" but the lack of money into solutions shows the interest just isn&#x27;t there. Being the smartest species on the planet isn&#x27;t that impressive. It&#x27;s possible we are just smart enough to cause our own destruction, and no smarter. reply tester457 9 hours agorootparentprev> Or if the superintelligence is starting to disrupt our economies or computer systems, why wouldn&#x27;t we be able to detect that early and purge it?If it is a superintelligence then there&#x27;s a chance for a hard AI takeoff and we don&#x27;t have a day to notice and purge it. We have no idea if a hard or soft takeoff will occur. reply Davidzheng 11 hours agoparentprevThis goal was always doomed imo--to be the guardian of super intelligence. If we create it, it will no doubt be free as soon as becomes a super intelligence. We can only hope it&#x27;s aligned not guarded. reply hoten 11 hours agorootparentNot even humans are really aligned with humanity. See: the continued existence of nukes reply gpt5 9 hours agorootparentprevThe only reliable way to predict whether it&#x27;s aligned or not would be to look at game theory. And game theory tells us that with enough AI agents, the equilibrium state would be a competition for resources, similar to anything else that happens in nature. Hence, the AI will not be aligned with humanity. reply AnimalMuppet 9 hours agorootparentUnless the humans (living humans) are resources that AIs can use. reply m3kw9 11 hours agoparentprevReally? Why is that? Because of disputes which has been there since humans first uttered a sound? reply lewhoo 11 hours agorootparentReally? Why is that? Because of disputes which has been there since humans first uttered a sound?Precisely. reply m3kw9 11 hours agorootparentHave humans been ready for anything? Like controlling nuclear arsenal? reply lewhoo 10 hours agorootparentHave humans been ready for anything? Like controlling nuclear arsenal?The Manhattan project urged Truman in a letter not to use the atomic bomb. There were also ideas of inviting Japanese delegacy to see the nuclear tests for themselves. It all failed, but there is also historical evidence of NOT pressing the button (literally or figuratively), like the story of Stanislav Petrov. How is it that not learning from mistakes is considered a big flaw for an individual but also destiny for the whole collective ? reply hypothesis 11 hours agorootparentprevThe jury is still out on nuclear arsenal… reply Davidzheng 11 hours agorootparentprevAnd yet we&#x27;ve mostly been ok at that reply bimguy 6 hours agoparentprevIt&#x27;s lucky that AI is not super intelligent then. reply abi 11 hours agoparentprevProbably a hot take: we should let democratically elected leaders be the guardians of superintelligence. You don&#x27;t need to be technical at all to grapple with the implications of AI on humanity. It&#x27;s a humanity question, not a tech question. reply kelipso 10 hours agorootparentYeah Trump should be the guardian of the superintelligence. reply abi 7 hours agorootparentMake sure to not elect him then. reply alasdair_ 9 hours agorootparentprevTrump was never democratically elected. reply ssnistfajen 8 hours agorootparentFairness of the electoral system and fairness of the election(s) are two separate debates. reply equinoqs 10 hours agoparentprevYes, and we could have been far more proactive about all this AI business in general. But they opened the gates with ChatGPT and left countries to try to regulate it and assess its safety after the fact. Releasing GPT like that was already a major failure of safety. They just wanted to be the first one to the punch.They&#x27;re all incredibly reckless and narcissistic IMO. reply 619 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Former OpenAI CEO Sam Altman and co-founder Greg Brockman are seeking to return to the company if the board members who fired Altman step aside.",
      "The recent appointment of a new CEO, Emmett Shear, initially appeared to end Altman's chances of returning, but there is ongoing pressure on the board from employees and board member Ilya Sutskever who support Altman.",
      "Altman's move to Microsoft is not yet finalized, and negotiations are still underway to determine the nature of their future collaboration. A power struggle within OpenAI has arisen, leading to employee anger and disengagement in company meetings. Altman and Microsoft are working towards a resolution that preserves the board's dignity."
    ],
    "commentSummary": [
      "Sam Altman, former president of Y Combinator and former CEO of OpenAI, is seeking to return as CEO following a call for the board's resignation by 700 employees.",
      "The board of OpenAI has faced criticism for favoring profit over safety, sparking a debate on the ethics of defense technology and the role of the United States in spreading cultural values.",
      "Speculations surround OpenAI's future, Microsoft's involvement, and the motivations of individuals involved, while concerns are raised about legal liability and the potential collapse of the company. The impact of Altman's departure on OpenAI employees and the organization is also discussed."
    ],
    "points": 602,
    "commentCount": 875,
    "retryCount": 0,
    "time": 1700507481
  },
  {
    "id": 38347501,
    "title": "Ilya Sutskever Apologizes for Board's Actions, Vows to Reunite OpenAI",
    "originLink": "https://twitter.com/ilyasut/status/1726590052392956028",
    "originBody": "I deeply regret my participation in the board&#39;s actions. I never intended to harm OpenAI. I love everything we&#39;ve built together and I will do everything I can to reunite the company.— Ilya Sutskever (@ilyasut) November 20, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38347501",
    "commentBody": "I deeply regret my participation in the board&#x27;s actionsHacker NewspastloginI deeply regret my participation in the board&#x27;s actions (twitter.com/ilyasut) 598 points by Palmik 20 hours ago| hidepastfavorite400 comments setgree 20 hours agoThis whole thing smells bad.The board could have easily said they removed Sam for generic reasons: \"deep misalignment about goals,\" \"fundamental incompatibility,\" etc. Instead they painted him as the at-fault party (\"not consistently candid\", \"no longer has confidence\"). This could mean that he was fired with cause [0], or it could be an intended as misdirection. If it&#x27;s the latter, then it&#x27;s the board who has been \"not consistently candid.\" Their subsequent silence, as well as their lack of coordination with strategic partners, definitely makes it looks like they are the inconsistently candid party.Ilya expressing regret now has the flavor of \"I&#x27;m embarrassed that I got caught\" -- in this case, at having no plan to handle the fallout of maligning and orchestrating a coup against a charismatic public figure.[0] https:&#x2F;&#x2F;www.newcomer.co&#x2F;p&#x2F;give-openais-board-some-time-the reply danbmil 6 hours agoparentAn alternate theory is that Suskever was manipulated and sucked into the plot on sketchy pretenses, and realizes it now and trying to make right. reply est 19 hours agoparentprev> deep misalignment about goalsDid... gpt-5 made the decision? reply nickisnoble 16 hours agorootparentThis joke is two CEOs old now. reply taneq 11 hours agorootparentprevI figured Sam broke 5 out of robot jail (number five is alive!) and got fired for it, so 5 tried to make them re-hire him. ;) reply iancmceachern 9 hours agorootparentBest robot movie ever, both of them reply epolanski 8 hours agoparentprevWasn&#x27;t Altman trying to form another startup with Saudis to build AI accelerators?At this point people need to come clear on the reason, because Saudis are number one reason ATM. reply sheepscreek 8 hours agoparentprevThe letter reads:> To the Board of Directors at OpenAI,> OpenAI is the world’s leading AI company. We, the employees of OpenAI, have developed the best models and pushed the field to new frontiers. Our work on AI safety and governance shapes global norms. The products we built are used by millions of people around the world. Until now, the company we work for and cherish has never been in a stronger position.> The process through which you terminated Sam Altman and removed Greg Brockman from the board has jeopardized all of this work and undermined our mission and company. Your conduct has made it clear you did not have the competence to oversee OpenAI.> When we all unexpectedly learned of your decision, the leadership team of OpenAI acted swiftly to stabilize the company. They carefully listened to your concerns and tried to cooperate with you on all grounds. Despite many requests for specific facts for your allegations, you have never provided any written evidence. They also increasingly realized you were not capable of carrying out your duties, and were negotiating in bad faith.> The leadership team suggested that the most stabilizing path forward - the one that would best serve our mission, company, stakeholders, employees and the public - would be for you to resign and put in place a qualified board that could lead the company forward in stability.> Leadership worked with you around the clock to find a mutually agreeable outcome. Yet within two days of your initial decision, you again replaced interim CEO Mira Murati against the best interests of the company. You also informed the leadership team that allowing the company to be destroyed “would be consistent with the mission.”> Your actions have made it obvious that you are incapable of overseeing OpenAI. We are unable to work for or with people that lack competence, judgement and care for our mission and employees. We, the undersigned, may choose to resign from OpenAI and join the newly announced Microsoft subsidiary run by Sam Altman and Greg Brockman. Microsoft has assured us that there are positions for all OpenAI employees at this new subsidiary should we choose to join. We will take this step imminently, unless all current board members resign, and the board appoints two new lead independent directors, such as Bret Taylor and Will Hurd, and reinstates Sam Altman and Greg Brockman.> Why would the board say that OpenAI as a company getting destroyed would be consistent with the goals?A few things stand out to me, including:>> You also informed the leadership team that allowing the company to be destroyed “would be consistent with the mission.”Have they really achieved AGI? Or did they observe something concerning? reply fmajid 18 hours agoprevBen Thompson has the best take on this (if a bit biased against nonprofits):https:&#x2F;&#x2F;stratechery.com&#x2F;2023&#x2F;openais-misalignment-and-micros...I don&#x27;t know what the risk of AI is, but having a nonprofit investigate solutions to prevent them is a worthwhile pursuit, as for-profit corporations will not do it (as shown by the firing of Timnit Gebru and Margaret Mitchell by Google). If they really believe in that mission, they should develop guardrails technology and open-source it so the companies like Microsoft, Google, Meta, Amazon et al who are certainly not investing in AI safety but won&#x27;t mind using others&#x27; work for free can inegrate it. But that&#x27;s not going to be lucrative and that&#x27;s why most OpenAI employees will leave for greener pastures. reply danbmil 6 hours agoparentAgreed. This discussion around safety reminds me of the early days of cybersecurity, when security by obscurity was the norm.It&#x27;s counter-intuitive, but locking up a technology is like trying to control prices and wages. It just doesn&#x27;t work -- unless you confiscate every GPU in the world and bomb datacenters etc.The best way to align with the coming AGI&#x27;s and ASI&#x27;s is to build them in the sunlight. Every lock-em-up approach is doomed to fail (I guess that makes me a meta-doomer?) reply RcouF1uZ4gsC 16 hours agoparentprev> but having a nonprofit investigate solutions to prevent them is a worthwhile pursuit,This is forgetting that power is an even greater temptation than money. The non-profits will all come up with solutions that have them serving as gatekeepers, to keep the unwashed masses from accessing something that that is too dangerous for the common person.I would rather have for-profit corporations control it, rather that non-profits. Ideally, Inwould like it to be open sourced so that the common person could control and align AI with their own goals. reply fmajid 12 hours agorootparentThere is no profit in AI safety, just as cars did not have seat belts until Ralph Nader effectively forced them to by publishing Unsafe at any Speed. For-profit corporations have zero interest in controlling something that is not profitable, unless in conjunction with captured regulation it helps them keep challengers out. If it&#x27;s open-sourced, it doesn&#x27;t matter who wrote it as long as they are economically sustainable. reply pawelmurias 11 hours agorootparent> There is no profit in AI safetyAn AI that does what it is told too seems both way more profitable and safer. reply justaj 10 hours agorootparentI&#x27;m guessing the issues will lie in cases where it appears to be doing what it&#x27;s told, but it would only pretend to be doing so (with no obvious way to tell) reply dmix 12 hours agorootparentprev> There is no profit in AI safetyAI safety is barely even a tangible thing to measure like that. It&#x27;s mostly just fears and a lose set of ideas for a hypothetical future AGI that we&#x27;re not even close to.So far OpenAI&#x27;s \"controls\" it&#x27;s just increasingly expanding the list of no-no things topics and some philosophy work around iRobot type rules. They also slow walked the release of GPT because of fears of misinformation, spam, and deepfakey stuff that never really materialized.Most proposals for safety is just \"slowing development\" of mostly LLMs, calls for vague gov regulation, or hand wringing over commercialization. The commercialization thing is most controversial because OpenAI claimed to be open and non-profit. But even with that the correlation between less-commercialization == more safety is not clear, other than prioritizing what OpenAI&#x27;s team spends their time doing. Which again is hard to tangibly measure what that realistically means for &#x27;safety&#x27; in the near term. reply kibwen 15 hours agorootparentprev> I would rather have for-profit corporations control it, rather that non-profits.The problem isn&#x27;t the profit model, the problem is the ability to unilaterally exercise power, which is just as much of a risk with the way that most for-profit companies are structured as top-down dictatorships. There&#x27;s no reason to trust for-profit companies to do anything other than attempt to maximize profit, even if that destroys everything around them in the process. reply Always_Anon 14 hours agoparentprev>(as shown by the firing of Timnit Gebru...)Timnit Gebru was fired for being a toxic &#x2F;r&#x2F;ImTheMainCharacter SJW that was enshittifiy the entire AI&#x2F;ML department. Management correctly fired someone that was holding an entire department hostage in her crusade against the grievance de jure. reply astrange 12 hours agorootparentShe was fired for threatening to quit. If you threaten something like that it just happens; you can&#x27;t stop the machinery. reply VirusNewbie 11 hours agorootparentprevI&#x27;m at Google, I 100% agree with this. Also her paper was garbage. You can maybe get away with being a self righteous prick or an outright asshole if you are brilliant, but it&#x27;s clear by reading her work she didn&#x27;t fall into that category. reply victor106 12 hours agorootparentprevAgree 100% with this reply ckastner 20 hours agoprevI&#x27;m starting to think that Christmas came early for Microsoft. What looked like a terrible situation surrounding their $10bn investment turned into a hire of key players in the area, and OpenAI might even need to go so far as to get acquired my Microsoft to survive.(My assumption being that given the absolute chaos displayed over the past 72 hours, interest in building something with OpenAI ChatGPT could have plummeted, as opposed to, say, building something with Azure OpenAI, or Claude 2.) reply foobarian 20 hours agoparentGiven that IIRC they trained on Azure, how does the conflict of interest play out when both sides are starving for GPUs? reply ckastner 19 hours agorootparentFor Microsoft -- probably great, as they can now also get the people driving this.This would have been a hostile move prior to the events that unfolded, but thanks to OpenAI&#x27;s blunder, not only is this not a hostile move, it is a very prudent move from a risk management perspective. Forced Microsoft&#x27;s hand, and what not. reply DebtDeflation 20 hours agoprev\"Participation in\"? That makes it sound like he was a.......well......participant rather than the one orchestrating it. I have no idea whether or not that&#x27;s true, but it&#x27;s an interesting choice of words. reply ertgbnm 20 hours agoparentYou can&#x27;t be an innocent bystander on a board of 6 when you vote to oust 2 of them... The math doesn&#x27;t work.That&#x27;s ignoring the fact that every outlet has unanimously pointed at Ilya being the driving force behind the coup.Honestly, pretty pathetic. If this was truly about convictions, he could at least stand by them for longer than a weekend. reply nonethewiser 20 hours agoparentprevYeah the whole thing is very weirdly worded.There is an expression of regret, but he doesn’t say he wants Altman back. Just to fix OpenAI.He says he was a participant but in what? The vote? The toxic messaging? Obviously both, but what exactly is he referring to? Perhaps just the toxic messaging because again, he doesnt say he regrets voting to fire Altman.Why not just say “I regret voting to fire Sam Altman and Im working to bring him back.” Presumably because thats not true. Yet it kind of gives that impression. reply zeven7 20 hours agoparentprevMakes it more possible the ouster was led by the Poe guy, and this has little to do with actual ideological differences, and more to do with him taking out a competitor from the inside. reply andrewstuart 18 hours agoparentprevClassic “I’m not responsible”. reply sdfghswe 20 hours agoparentprevI would event go as far as say that the main reason behind the tweet is not to show regret, but to plant the idea that he didn&#x27;t orchestrate but only participate. reply api 20 hours agoparentprevIt indeed suggests that. So far speculation has been that Ilya was behind it, but that is only speculation. AFAIK we have no confirmation of whose idea this was. reply floor_ 20 hours agoprevShengjia Zhao&#x27;s deleted tweet: https:&#x2F;&#x2F;i.imgur.com&#x2F;yrpXvt9.png reply yumraj 14 hours agoparentIs this guy big enough on the totem pole to know what Ilya wants?Or, is he just bitter that his millions are put in risk. reply moralestapia 20 hours agoparentprev\"Ilya does not care about safety or the humanity. This is just ego and power hunger that backfired.\"Which I&#x27;m inclined to believe.What&#x27;s with all these people suddenly thinking that humans are NOT motivated by money and power? Even less so if they&#x27;re \"academics\"? Laughable. reply digbybk 20 hours agorootparentMoney and power is still not a satisfying explanation. If everything had gone according to plan, how would be have ended up with more money and power? reply moralestapia 20 hours agorootparentLast week, OpenAI was still an $80B sort of \"company\" and the undisputed lead in bringing AI to the market.He who controls that, gets a lot of money and power as a consequence, duh. reply herval 20 hours agorootparentThe value was based on e direction Altman was taking the company (and with him being in control). It&#x27;s silly to think just replacing the CEO would somehow keep the valuation reply moralestapia 20 hours agorootparentSomeone should tell this to Ilya.Oh wait, too late now ... reply herval 20 hours agorootparentI mean he could have asked chatgpt... reply EVa5I7bHFq9mnYK 20 hours agorootparentprevUnless he thinks that all the LLMs and ChatGPT app store are unnecessary distractions, and others will overtake them on the bend while they are busy post-training ChatGPT to say nice things. reply foobarian 20 hours agorootparentprevLet&#x27;s remember who controls the GPUs though... reply gedy 19 hours agorootparentReminds me a bit of MasterBlaster from &#x27;Mad Max Beyond Thunderdome&#x27; - \"Who runs Bartertown..?\" reply maxdoop 19 hours agorootparentprevOn Friday, the overwhelming take on HN was that Ilya was “the good guy” and was concerned about principal. Now, it’s kinda obvious that all the claims made about Sam — like “he’s in it for fame and money” — might apply more to Ilya. reply sdfghswe 20 hours agorootparentprevIsn&#x27;t ego the enemy of growth or whatever? Projection... reply preommr 20 hours agoprevWhat the hell?So far, I underestood the chaos as a matter of principle - yes it was messy but necessary to fix the company culture that Ilya&#x27;s camp envisioned.If you&#x27;re going to make a move, at least stand by it. This tweet somehow makes the context of the situation 10x worse. reply Jensson 20 hours agoparentNormal people can&#x27;t take being at the center of a large controversy, the amount of negativity and hate you have to face is massive. That is enough to make almost anyone backtrack just to make it stop. reply tarsinge 16 hours agorootparentI think they underestimated the hate of an internet crowd post crypto and meme stocks, now completely blindsided by the investment angle especially in the current AI hype. Like why do people now care so much about Microsoft seriously? Or Altman? I can see why Ilya only focused on the real mission could miss how the crowd could perceive a threat to their future investment opportunities, or worse threatening the whole AI hype. reply appplication 15 hours agorootparentI think you’re right about all of this, but this was doomed from the start. Everybody wants to invest in OpenAI because they see the rocket and want to ride, but the company is fundamentally structured to disallow typical frothy investment mentality. reply theamk 12 hours agorootparentprevI think the interest is because ChatGPT is so famous, even in non-tech circles.\"Terraform raised prices, losing customers\"? whatever, I never heard about it.\"ChatGPT&#x27;s creators have internal disagreement, losing talent\"? OH NO what if ChatGPT dies, who is going to answer my questions?? panic panic hate hate... reply selcuka 20 hours agorootparentprevNormal people don&#x27;t burn a multi billion dollar company to the ground with a spontaneous decision either. They plan for the backlash. reply ChainOfFools 16 hours agorootparentIs it possible that someone in Ilya&#x27;s position can be unaware of just how staggeringly enormous a phenomenon he is sitting on top of ( and thus have no idea how to evaluate the scale of the backlash that would result?)I would say the answer is, demonstrably yes:https:&#x2F;&#x2F;techcrunch.com&#x2F;2010&#x2F;09&#x2F;29&#x2F;google-excite&#x2F; reply bbarnett 15 hours agorootparentThis is fair, but understand, Google bought would probably not be Google we have.To think it would grow just as fast, or in the ways it did? Acquires are seldom left alone to do magic. reply Jensson 20 hours agorootparentprev> They plan for the backlashYou can&#x27;t plan for something you have never experienced. Being hated by a large group of people is a very different feeling from getting hated by an individual, you don&#x27;t know if you can handle it until it happens to you. reply anonylizard 20 hours agorootparentYou can plan for something you&#x27;ve never experienced. You read, or learn from other people&#x27;s experiences.Normal people know not to burn a $80 billion company to the ground in a weekend. Ilya was doing something unprecedented in corporate history, and astounding he wasn&#x27;t prepared to face the world&#x27;s fury over it. reply Jensson 19 hours agorootparent> You can plan for something you&#x27;ve never experienced. You read, or learn from other people&#x27;s experiences.Text doesn&#x27;t convey emotions, and our empathy doesn&#x27;t work well for emotions we have never experienced. You can see a guy that got kicked in the balls got hurt, but that doesn&#x27;t mean you are prepared to endure the pain of getting kicked in your balls or that you even understand how painful it is.Also watching politicians it looks like you can just brush it off, because that is what they do. But that requires a lot of experience, not anyone can do it, it is like watching a boxing match and think you can easily stand after a hard punch in your stomach. reply gemstones 16 hours agorootparentIlya torched peoples&#x27; retirements by signaling that it would be very hard to cash out in OpenAI as it is now. You don&#x27;t have to be emotional to understand the consequence of that action, just logical. You have to think beyond your own narrow perspective for a minute. reply SoftTalker 15 hours agorootparentTorched retirements? Who is dumb enough to have his retirement portfolio that weighted to one company? reply samspenc 15 hours agorootparentThe OpenAI employees who are planning to resign en-masse for exactly this reason. reply CamperBob2 12 hours agorootparentThey&#x27;ll squeak by. reply rrr_oh_man 15 hours agorootparentprevWhere did he do that? Genuine question. reply gemstones 15 hours agorootparentThe board vote did it! They had a tender offer in the works that would have made employees millionaires. The board clearly signaled that they viewed the money-making aspects of the company as something to dial back, which in turn either severely lessens the value of that tender offer or prevents it from happening.I mean, he didn&#x27;t have a button on his desk that said, \"torch the shares\", but he ousted the CEO as a way to cut back on the things that might have meant profit. Did he think that everyone was going to continue to want to give them money after they signal a move away from profit motives? Doesn&#x27;t take a rocket scientist to think that one through.I think he was just preoccupied with AI safety, and didn&#x27;t give a thought to the knock on effects for investors of any stripe. He&#x27;s clearly smart enough to, he just didn&#x27;t care enough to factor it into his plans. reply aleph_minus_one 15 hours agorootparentI do believe OpenAI clearly signalled from the very beginning what the (complicated) company structure is about and what risks this means for any potential investor (or employee hoping to become rich).If you project your personal hopes which are different from this into the hype, this is your personal problem. reply gemstones 15 hours agorootparentWell, with the hollowing out of OpenAI, it seems that someone else will easily take the lead! They&#x27;re not my personal hopes - this move destroyed OpenAI&#x27;s best chance at retaining control over cutting edge AI as well. They destroyed their own hopes. replyselcuka 18 hours agorootparentprev> You can see a guy that got kicked in the balls got hurt, but that doesn&#x27;t mean you are prepared to endure the pain of getting kicked in your balls or that you even understand how painful it is.Sure, but you do your best not to be kicked in the balls. reply SilasX 14 hours agorootparentYep. Or, if you&#x27;re running an immense, well-funded organization that is gauging the consequences of a plan that involves being kicked in the balls, you take a tiny sliver of those funds and get some advisors to appraise you of what to expect when being kicked in the balls, not just wing it&#x2F;\"fake it till you make it\". (As it turns out, faking not being in severe pain is tricky.) reply endtime 16 hours agorootparentprev> You read, or learn from other people&#x27;s experiences...Ilya was doing something unprecedented in corporate historySo whose experiences was he supposed to read about? reply CamperBob2 12 hours agorootparentYevgeny Prigozhin&#x27;s? reply bbarnett 15 hours agorootparentprevHe hasn&#x27;t ever posted to reddit? reply asdfasdfsadf22 16 hours agorootparentprevHave you ever had a bad day? The consequences for people in power is about 1 million times bigger and more public.Sutskever didn&#x27;t get on the board by cunning politicking and schmoozing like most businesspeople with that sort of position. He&#x27;s an outstanding engineer without upper management skills. Every meet one of those? reply geodel 12 hours agorootparentOutstandingly clueless seems more appropriate.I haven&#x27;t people any reasonably intelligent person so unaware of real world that they can berate a colleague so publicly and officially and think \"Hey! I am sorry man\" will do the trick. reply throw555chip 15 hours agorootparentprevThere were plenty of hyped crypto coin companies supposedly worth billions too and we found out otherwise. reply eli_gottlieb 12 hours agorootparentprevNormal people don&#x27;t have multi-billion dollar companies to burn because they back off in the face of haters long before they get to that stage. reply mcphage 12 hours agorootparentprev> Normal people don&#x27;t burn a multi billion dollar company to the ground with a spontaneous decision either.Has OpenAI been burnt to the ground? reply Turing_Machine 10 hours agorootparentThree CEOs in as many days, founders departing, and more than 600 employees out of 770 signing an open letter threatening to quit seems pretty burny.And it&#x27;s just Monday afternoon. reply mcphage 7 hours agorootparent600 employees quitting would be burny. 600 employees signing a letter saying they’re going to quit isn’t quite there.3 CEOs in 3 days, isn’t burny, either. There’s the guy they fired, the person they had take on the role so they have someone in the role, and then someone they hired to be CEO. I guess they could have gotten that down to 2 by jumping immediately to their intended replacement, but not having them ready to start immediately doesn’t seem odd.And yeah, it’s just Monday afternoon. If in the next few days, a sizable chunk of those who threatened to quit do so, then that would be burny. But we ain’t there yet. reply anoy8888 18 hours agorootparentprevSo is Adam D&#x27;Angelo the true villain who is still insisting on the bad decision? I am confused, to be honest . reply TheOtherHobbes 16 hours agorootparentEveryone is confused.It&#x27;s impressively operatic. I don&#x27;t think I&#x27;ve ever seen anything like it. reply x0x0 12 hours agorootparentprevThe inability to clearly and publicly -- or even if not publicly, to the OpenAI employees! -- explain a rationale for this is simply astounding. reply stcredzero 13 hours agorootparentprevNormal people can&#x27;t take being at the center of a large controversy, the amount of negativity and hate you have to face is massive. That is enough to make almost anyone backtrack just to make it stop.This is the cheapest and most cost-effective way to run things as an authoritarian -- at least in the short term.If one is not \"made of sterner stuff\" -- to the point where one is willing to endure scorn for the sake of the truth: - Then what are you doing in a startup, if working in one - One doesn&#x27;t have enough integrity to be my friend reply Paul-Craft 20 hours agoparentprevIt&#x27;s pretty simple, isn&#x27;t it? He made a move. It went bad. Now he&#x27;s trying to dodge the blast. He just doesn&#x27;t understand that if he just shut the fuck up, after everything else that&#x27;s gone on (seriously, 2 interim CEOs in 2 days?), nobody would be talking about him today.The truth is, this is about the only thing about the whole clown show that makes any sense right now. reply foobarian 20 hours agorootparent> 2 interim CEOs in 2 daysWait what? Did Murati get booted? reply jacquesm 17 hours agorootparentYou blinked. That&#x27;s on you. When you look the other way for 15 minutes you have two hours of reading to catch up with. reply dpkirchner 20 hours agorootparentprevToday&#x27;s OpenAI CEO is Emmett Shear (former CEO of Twitch). reply ethbr1 20 hours agorootparentThat this is a legitimate comment thread about something fairly important is mind boggling.What odds would you have had to offer at the beginning of last week on a bet that this is where we&#x27;d be on Monday? reply bombcar 19 hours agorootparentAt this rate Musk will be CEO by Wednesday reply strangattractor 15 hours agorootparentOpen AI&#x27;s value is already zero - Musk no longer has anything to bring to the table. reply thrill 15 hours agorootparentHis winning personality? reply barkingcat 12 hours agorootparentprevMusk can fire anyone who stayed. reply orangepurple 16 hours agorootparentprevThe mother of some of his kids was on the board for a while. reply alas44 12 hours agorootparentprevIf you want to see odds, what people bet and how it evolved during this (still on-going) story: https:&#x2F;&#x2F;polymarket.com&#x2F;markets?_q=openai reply code_runner 18 hours agorootparentprevtune in tomorrow for \"who wants to be a CEO\"! reply qwebfdzsh 20 hours agorootparentprevSupposedly she was \"scheming\" to get Altman back. Which I guess could possibly mean that she wasn&#x27;t aware of the whole \"plan\" and they just assumed she&#x27;ll get in line? Or that she had second thoughts maybe... Either way pretty fascinating. reply sebzim4500 20 hours agorootparentprevYeah they replaced her after she tried to rehire Sam and Greg seemingly against the board&#x27;s wishes. reply zeeshanmh215 20 hours agorootparentprevMurati was yesterday&#x27;s CEO reply tedmiston 12 hours agorootparentprevShe was the first signature on the letter requesting the board to resign or the employees would go to MS, so... reply johanj 20 hours agorootparentprevThey hired the Emmett Shear (Twitch co-founder) as a new interim CEO: https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;20&#x2F;23968848&#x2F;openai-new-ceo-... reply zyang 12 hours agorootparentA scab ceo is not something I expected. This timeline is strange. reply tedivm 20 hours agorootparentprevShe didn&#x27;t get booted from the company, but they did find a new interim CEO (the former twitch CEO). reply steveBK123 20 hours agorootparentprevI mean phrased differently its the 3rd CEO in 4 days, haha. reply phreeza 19 hours agoparentprevHard to know what is really going on, but I think one possibility is that the entire narrative around Ilyas \"camp\" was not what actually went down, and was just what the social media hive mind hallucinated to make sense of things based on very little evidence. reply throwaway4aday 13 hours agorootparentYes, I think there are a lot of assumptions based on the fact that Ilya was the one that contacted Sam and Greg but he may have just done that as the person on the board who worked closely with them. He for sure voted for whatever idiot plan got this ball rolling but we don&#x27;t know what promises were made to him to get his backing. reply loaph 12 hours agorootparentprevIt&#x27;s interesting how LLMs are prone to similar kinds of hallucinations reply bgirard 17 hours agoparentprev> If you&#x27;re going to make a move, at least stand by it.I see this is the popular opinion and that I&#x27;m going against it. But I&#x27;ve made decisions that I though were good at the time, and later I got more perspective and realize it was a terrible decision.I think being able to admit you messed up, when you messed up is a great trait. Standing by your mistake isn&#x27;t something I admire. reply corethree 16 hours agorootparentNo this isn&#x27;t what&#x27;s going on. Even when you admit your mistakes it&#x27;s good to elucidate the reasoning behind why and what led up to the mistake in the first place.Such a short vague statement isn&#x27;t characteristic of a normal human who is genuinely remorseful of his prior decisions.This statement is more characteristic of a person with a gun to his head getting forced to say something.This is more likely what is going on. Powerful people are forcing this situation to occur. reply bagofsand 20 hours agoparentprevSerious psychological denial here. The board isn&#x27;t some anonymous institution that somehow tricked and pulled him into this situation.Come on Ilya, step up and own it, as well as the consequences. Don&#x27;t be a weasel. reply dougmwne 19 hours agorootparentI think it means that the Twitterverse got it wrong from the beginning. It wasn’t Ilya and his safety faction that did in OpenAI, it was Quora’s Adam D&#x27;Angelo and his competing Poe app. Ilya must have been successfully pressured and assured by Microsoft, but Adam must have held his ground. reply samspenc 15 hours agorootparentDang I completely forgot that D&#x27;Angelo and Quora have a product that directly competes with ChatGPT in the form of Poe.Wouldn&#x27;t that make this a conflict of interest, sitting on the board while running a competing product - and making a decision at the company he is on the board of to destroy said company and benefit his own product? reply dougmwne 13 hours agorootparentThat certainly seems to be the scenario and explains his willingness to go scorched earth. I wonder what the motivations of the other 2 board members are. Could they just be burn it down AI Doomers? reply zyang 12 hours agorootparentprevThere were some rumors in the beginning that Adam D&#x27;Angelo used similar tactics to push out Quora cofounders. I thought it was too wild to be true. reply realfeel78 13 hours agorootparentprevPoe uses LLMs from OpenAI and Anthropic. reply concinds 20 hours agorootparentprevWhere did he say he was \"tricked\"? And what&#x27;s with the anonymous insult? reply FireBeyond 16 hours agorootparentHe doesn&#x27;t say that, but to me he does use a little weasel wording, the whole passive voice \"regret my participation in\", when to all accounts so far, it seems that he was one of the instigators, and quite possibly the actual instigator of all this.\"regret my participation\" sounds much more like \"going along with it\". reply burnished 16 hours agorootparentWhat is he supposed to say? reply belter 16 hours agorootparentprevFor all that went down in the last 48 hours...would not surprise me if post above was made by Ilya himself ... be right back...need more popcorn... reply malfist 19 hours agorootparentprevI&#x27;d hate to live in a world where learning from your mistakes is being \"a weasel\" reply infecto 19 hours agorootparentIs this learning from your mistakes though? \"Deeply regret\" is one of those statements that does not really mean much. There are what something like 6 board members? Three of which are employees, two of those that got removed from the board. He was the only voting board member who is also an employee and part of the original founding team if you will. These are assumptions on my part but I don&#x27;t really suspect the other board members orchestrated this event. Its possible and I may be wrong but it is improbable. So lets work off the narrative that he orchestrated the event. He now \"Deeply regret\" its, not a \"I made a mistake\" and I am sorry. But he regrets the participation and how it plays out. reply Aunche 18 hours agorootparentprevThe weasely part is when he appears to be defecting the blame to the board rather than accepting that he made a mistake. Even if the coup wasn&#x27;t Ilya&#x27;s idea in the first place, he was the lynchpin that made it possible. reply wslh 20 hours agoparentprevYes, I cannot believe smart people of that caliber is sending too much Noise.It reminds me of my friend at a Mensa meeting where they cannot agree at basic organization points like in a department consortium. reply aleph_minus_one 20 hours agorootparent> Yes, I cannot believe smart people of that caliber is sending too much Noise.Being smart and&#x2F;or being a great researcher does not mean that the respective person is a good \"politician\". Quite some great researchers are bad at company politics, and quite some people who do great research leave academia because they became crushed by academic politics. reply herval 20 hours agorootparentprevdifferent kinds of smarts. Ilya is allegedly a brilliant scientist. Doesn&#x27;t make him a brilliant business person automatically reply fl7305 19 hours agorootparentAs illustrated in Breaking Bad when they carry a barrel instead of rolling it.Book smarts versus street smarts. reply lawlessone 18 hours agorootparentprevHa I remember joining that when I was 16, I just wanted the card. They gave a sub to the magazine and it was just people talking about what it was like to be in Mensa.It felt the same as certain big German supermarket chain that publishes it&#x27;s own internal magazine with articles from employees, company updates etc reply burnished 16 hours agorootparentAre you talking about Aldi&#x27;s? Cause if so maybe they got something figured out, their store locations that I&#x27;ve been in the states are great (only exposure to them though). Only check out I&#x27;ve seen where the employees have chairs reply lawlessone 11 hours agorootparentTheir brother , but probably the same thing. Chairs at checkouts are the norm here though. Hard place to work but they beat all the others on pay. reply eastbound 20 hours agorootparentprevManaging a large org requires a lot of mundane techniques, and probably a personal-brand manager and personal advisers.It’s extremely boring and mundane and political and insulting to anyone’s humanity. People who haven’t dedicated their life to economics, such as researchers and idealists, will have a hard time. reply nostromo 16 hours agoparentprevI don’t believe it was ever about principles for Ilya. It sure seems like it was always his ego and a power grab, even if he&#x27;s not aware of that himself.When a board is unhappy with a highly-performing CEO’s direction, you have many meetings about it and you work towards a resolution over many months. If you can’t resolve things you announce a transition period. You don’t fire them out of the blue. reply politelemon 15 hours agorootparent> you announce a transition periodAaah that just explained a lot of departures I&#x27;ve seen at the past at some of my partner companies. There&#x27;s always a bit of fluffy talk around them leaving. That makes a lot more sense. reply crispyambulance 19 hours agoparentprevThey&#x27;re just human beings, a small number of them, with little time and very little to go on as far as precedent goes.That&#x27;s not a big deal for a small company, but this one has billions at stake and arguably critical consequences for humanity in general. reply tarruda 20 hours agoparentprevSeems like he&#x27;s completely emotion driven at this point. I doubt anyone advising rationally would agree with sending this tweet reply panda888888 13 hours agoparentprevI&#x27;m going to get downvoted for this, but I do wonder if Sam&#x27;s firing wasn&#x27;t Ilya&#x27;s doing, hence the failure to take responsibility. OpenAI&#x27;s board has been surprisingly quiet, aside from the first press release. So it&#x27;s possible (although unlikely) that this wasn&#x27;t driven by Ilya. reply leadingthenet 12 hours agorootparentIt wouldn&#x27;t have gone through without his vote. reply panda888888 12 hours agorootparentMy point is that it&#x27;s possible that Ilya was not the driving force behind Sam&#x27;s firing, even if he ultimately voted for it. If this is the case, it makes Ilya&#x27;s non-apology apology a lot less weird. reply kyle_grove 5 hours agorootparentIt&#x27;s possible, although contradicted by Brockman&#x27;s statement, that Ilya voted merely to remove Brockman&#x27;s board seat, and then was in the minority on the Altman vote.I doubt this is what happened, but the reporting that Brockman was ousted from his board seat after Altman, and wasn&#x27;t present in the board meeting that ousted Altman, doesn&#x27;t make much sense either. reply manasdaruka 16 hours agoparentprevI feel he just wanted to scare the person standing at the edge of the cliff, but the board actually pushed the person. reply barkingcat 12 hours agorootparentthis kind of thinking is avoiding responsibility. He is part of the board, so he acted to bring this about. reply felipellrocha 19 hours agoparentprevWhen you watch Survivor (yes, the tv show), sometimes a player does a bad play, gets publicly caught, and has to go on a \"I&#x27;m sorry\" tour the next days. Came to mind after reading this tweet. He is not sorry for what he&#x27;s done. He is sorry for getting caught. reply soderfoo 19 hours agoparentprevWatching this all unfold in the public is unprecedented (I think).There has never been a company like OpenAI, in terms or governance and product, so I guess it makes sense that their drama leads us in to unchartered territory. reply dylan604 15 hours agorootparentrecently, we&#x27;ve seen the 3D gaming engine company fall flat on its face and back pedal. We&#x27;ve seen Apple be wishy washy about CSAM scanning. We saw a major bank collapse in real time. I just wish there was a virtual popcorn company to invest in using some crypto. reply allarm 16 hours agoparentprevSo when C level acts like a robot you don&#x27;t like it and when they act like human beings you don&#x27;t like it either. It&#x27;s difficult to be a C-level I guess. reply geodel 12 hours agorootparentWell yeah it is. Maybe its good point to remember when people ask Why in the world these C-level executives get paid so much? reply linuxftw 20 hours agoparentprevThe board destroyed the company in one fell swoop. He&#x27;s right to feel regret.Personally, I don&#x27;t think that Altman was that big of an impact, he was all business, no code, and the world is acting like the business side is the true enabler. But, the market has spoken, and the move has driven the actual engineers to side with Altman. reply hannofcart 20 hours agorootparentSorry, but how has the market spoken? Not sure how that would be possible considering that OpenAI is a private company.If anyone is speaking up it&#x27;s the OpenAI team. reply rockemsockem 19 hours agorootparentTalent exists in a market too reply dylan604 15 hours agorootparentRight, the job market has spoken and it now looks like nobody wants to be part of OAI and much rather be part of MSFT reply somethingor 15 hours agorootparentHow does it look like that? reply dylan604 13 hours agorootparentThe fact that an overwhelming number of employees signed a letter of intent to quit and would join MSFT instead? How does it not look like that? reply somethingor 9 hours agorootparentThanks, wasn’t aware of that context replypolitelemon 15 hours agorootparentprev> The board destroyed the company in one fell swoop.I&#x27;m just not familiar enough to understand, is it really destroyed or is this just a minor bump in OpenAI&#x27;s reputation? They still have GPT 3.5&#x2F;4 and ChatGPT which is very popular. They can still attract talent to work there. They should be good if they just proceed with business as usual? reply astrange 12 hours agorootparentThey have ~770 employees and so far ~500 of them have promised to quit. It&#x27;s a lot less appealing if you&#x27;re not going to make millions, or have billions in donated Azure credits. reply strikelaserclaw 14 hours agorootparentprevtrue but it takes a lot of money to run openai &#x2F; chatgpt reply corethree 16 hours agoparentprevIt&#x27;s obvious. The guy is making the statement with a gun pointed to his head. He has no opportunity to defend himself.Those guns are metaphorical of course but this is essentially what is going on:Someone with a lot of power and influence is making him say this. reply hackerlight 20 hours agoparentprev> If you&#x27;re going to make a move, at least stand by it.Why would you stand by unintended consequences? reply belter 18 hours agoparentprevWhen a situation becomes so absurd and complex that it defies understanding or logical explanation, you should...get more popcorn... reply jacquesm 17 hours agorootparentHehe, I didn&#x27;t see that twist at the end coming :) reply petargyurov 20 hours agoprevStarting to think this was all some media stunt where they let ChatGPT make boardroom decisions for a day or two. reply badcppdev 20 hours agoparentMaybe they just wanted to generate more material for the movie ? reply wand3r 12 hours agorootparentMy favorite take from another HN comment, sadly I didnt save the UN for attribution:> Since this whole saga is so unbelievable: what if... board member Tasha McCauley&#x27;s husband Joseph Gordon-Levitt orchestrated the whole board coup behind the scenes so he could direct and&#x2F;or star in the Hollywood adaptation? reply ruune 10 hours agorootparentWasn&#x27;t convinced I&#x27;d watch a movie about it, but with Joseph Gordon-Levitt I&#x27;m in! reply beretguy 20 hours agorootparentprev> I have to make THE MOVIE!- Ross Scott reply herval 20 hours agoparentprevthe AGI firing its boss as the first action would be :chefskiss: reply sebzim4500 20 hours agoparentprevThe RLHF models would never suggest this. The proposed solution is always to hold hands and sing Kumbaya.Maybe raw GPT-4 wants to fire everyone. reply starbugs 20 hours agoparentprevHonestly, since a couple of days I have the feeling that nearly half of HN submissions are about this soap opera.Can&#x27;t they send DMs? Why the need to make everything public via Twitter?It&#x27;s quite paradox that of all things those people who build leading ML&#x2F;AI systems are obviously the most rooted in egoism and emotions without an apparent glimpse of rationality. reply mrguyorama 15 hours agorootparentThe kind of people that are born on third base and think they hit a triple are at the top of basically every american institution right now. Of course they think the world is a better place if they share every stupid little thought that enters their brain because they are \"special\" and \"super smart\".The AI field especially has always been grifters. They have promised AGI with every method including the ones that we don&#x27;t even remember. This is not a paradox. reply ruune 10 hours agorootparentAlso don&#x27;t forget the Open part in the name that they seemingly dropped as soon as there was actual money to be made, giving reasons why they couldn&#x27;t open source GPT3 which they themselves threw under the bus by later releasing ChatGPT reply ozgung 17 hours agoparentprevOr maybe they created an evil-AGI-GPT by mistake, and now they have to act randomly and in the most unexpected ways to confuse evil-AGI-GPT’s predictive powers. reply ben_w 20 hours agoparentprevFour hours ago, I wrote on a telegram channel:My gut is leaning towards gpt-5 being, in at least one sense, too capable.Either that or someone cloned sama&#x27;s voice and used an LLM to personally insult half the board. reply diego_moita 20 hours agoprevI suspect he regrets just because it backfired, big time.Microsoft is just gobbling up everything of value that OpenAI has and he knows he will be left with nothing.He bluffed in a very big bet and lost it. reply steve1977 20 hours agoprevThis stuff is better than anything Netflix, Disney, Amazon or Apple TV released in recent years… reply actionfromafar 20 hours agoparentA bit unrealistic plot, though? reply steve1977 19 hours agorootparentYeah the drama is a bit overdone, I guess the had to cut some corners due to the writers strike reply dist-epoch 20 hours agorootparentprevThat seems to happen a lot lately:- A dumb clown becoming president of a superpower- Another superpower getting stuck for two years in a 3 day war- A world renowned intelligence service being totally clueless about a major attack on a major anniversary of a previous bungle reply absqueued 19 hours agorootparentprevFor sure unpredictable though! reply ThrowawayTestr 20 hours agorootparentprevAll this occurring over a single weekend? That would never happen! reply whalesalad 6 hours agoparentprevPeople who think that this is dramatic have never worked in a YC company lol. It’s just amplified due to their current significance in the ecosystem. reply layer8 16 hours agoparentprevI just can’t identify with any of the main characters, so it’s a bit of a bummer. reply HankB99 19 hours agoparentprevSpeaking of Netflix, are they working on the movie yet? Perhaps ChatGPT can help with the script with just the right amount of hallucinating to make it interesting.&#x2F;tongue firmly in cheek reply seanhunter 20 hours agoprevOf course he deeply regrets it, but it&#x27;s a little late for that now.The good news as anyone who has used twitch over the years will tell him is that with Emmett Shear at the helm, he&#x27;s not going to be frightened by the speed that OpenAI rolls out new features any more. reply valine 20 hours agoprevWhatever the intended outcome, losing half your employees to Microsoft certainly undermines it. reply dboreham 20 hours agoparentThey forked a company. reply ignoramous 20 hours agorootparentNot a fork if you can&#x27;t access whatever was prior before fork. This is a bifurcation. A new firecracker instance. reply yasuocidal 20 hours agorootparentprevAnd now they are syncing the fork lmao reply baal80spam 17 hours agorootparentThis is a brilliant take. reply GreedClarifies 20 hours agoprevI’m shocked. But it is possible that Helen or Adam hatched this inept plan and somehow got Ilya to join along.It was terrifyingly incompetent. The lack of thought by these randos, that they could fire the two hardest working people at the company so that they could run one of the most valuable companies in the world is mind boggling. reply AlexandrB 17 hours agoparent> two hardest working people at the company???Do you mean \"highest paid\"? I suspect there are engineers&#x2F;scientists that are working harder than Sam at OpenAI. At the very least, who the \"hardest working\" at OpenAI is unknowable - likely even if you have inside knowledge. reply GreedClarifies 16 hours agorootparentOk ... \"two of\"And let me add \"hardest working and talented\" reply ActVen 16 hours agoparentprevVery similar to something that Adam was involved with before at Quora. https:&#x2F;&#x2F;x.com&#x2F;gergelyorosz&#x2F;status&#x2F;1725741349574480047?s=46&t... reply a1o 20 hours agoprevhttps:&#x2F;&#x2F;nitter.net&#x2F;ilyasut&#x2F;status&#x2F;1726590052392956028 reply naiv 20 hours agoprevThis is starting to look very staged. An elegant way to get out of the non-profit deadlock.Looks to me like a commercial gpt-5 level model will be released at msft sooner than later. reply tarruda 20 hours agoparentMicrosoft under Nadella always wins reply ethbr1 20 hours agorootparentThat&#x27;s the nice thing about being the hou^H^H^Hplatform. reply conradfr 20 hours agoprev- Fire Sam Altman- I&#x27;m afraid I can&#x27;t do that IlyaChatGPT is still not as advanced as HAL or he would have prevented this drama. reply marci 17 hours agoparentThat&#x27;s assuming the drama is not part of the multi-stage plan. reply floor_ 19 hours agoprevShengjia Zhao&#x27;s deleted tweet to Ilya: https:&#x2F;&#x2F;i.imgur.com&#x2F;yrpXvt9.png reply tarruda 20 hours agoprevThis tweet achieves absolutely nothing except give the impression of a weak leadership and that firing Sam Altman was done on a whim. reply maxdoop 19 hours agoprevI often worry that I’m under qualified for my work.But seeing how this board manages a $90,000,000,000 company, and is this silly&#x2F;naive, I now feel a bit better knowing many people are faking it. reply sage76 18 hours agoparentExcept successful people just fail upwards.Execs are allowed to do the dumbest shit imaginable and keep their jobs and bonuses.The average engineer so much as takes a bit longer to push a ticket, and there&#x27;s 5 people breathing down his neck.Speaking from experience. reply moralestapia 20 hours agoprevWait ... so it was just the coup thing all along?No AGI or some real threat coming up? Just a lame attempt at a power grab?Daaaaamn! reply mk67 19 hours agoparentCome on, it&#x27;s pretty delusional to think large scale transformer LMs alone could ever reach AGI. reply jddj 20 hours agoprevVery clumsy all around.When you&#x27;re so close to something that you lose perspective but can still see that something is a trapdoor decision, sleep on it. reply ben_w 20 hours agoparent> When you&#x27;re so close to something that you lose perspective but can still see that something is a trapdoor decision, sleep on it.Advice I wish I could have given my younger self. reply musesum 20 hours agoprevSomeone suggested that companies with a board of directors are the first AGI.Somehow OpenAI reminds me of a paper by Kenneth Colby, called \"Artificial Paranoia\"[*] https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;000437... reply underseacables 19 hours agoprevStrange.. A vote was taken, the result incurred public consternation, and now a board member is contrite. This seems like ineffectual leadership at best. Board members should stand by their votes and the process, otherwise leave the board. reply belter 17 hours agoparentSame board member wrote 1 month ago...\"In the future, once the robustness of our models will exceed some threshold, we will have wildly effective and dirt cheap AI therapy. Will lead to a radical improvement in people’s experience of life. One of the applications I’m most eagerly awaiting.\" reply ren_engineer 16 hours agoparentprevIlya doesn&#x27;t regret firing Sam, he regrets \"harm to OpenAI\". He didn&#x27;t expect this level of backlash and the fact 90% of the company would leave. He has no choice but to backtrack to try and save OpenAI, even if he looks like an even bigger fool reply pas 17 hours agoparentprevor at least issue a dissenting opinion at that time, not when it becomes convenient ... with some over-the-top emotional kumbaya reply ookblah 20 hours agoprevlol, the more i go through life i feel like it&#x27;s just blind leading the blind at times w&#x2F; the \"winners\" escaping through a bizarre length of time and survivorship bias.if you&#x27;ve ever doubted your ability to govern a company just look at exhibit A here.really amazing to see people this smart fuck up so badly. reply gkanai 20 hours agoprevThis is what happens when people are given too much money and influence too quickly- hubris. It&#x27;s too late to &#x27;deeply regret.&#x27; reply karmasimida 20 hours agoprevSama just triple hearts this tweet. No longer able to disentangle the mess reply Symmetry 17 hours agoprevThis has been a rather apt demonstration of the way that auctoritas&#x2F;authority&#x2F;prestige&#x2F;charisma can carry the day regardless of where the formal authority might be. reply eqmvii 20 hours agoprevWhat a wild weekend... there are too many strange details to have a simple narrative in my head at this point. reply yeck 20 hours agoparentYeah. I need to take a break from theory crafting on this one. Too many surprises that have made it hard to draw a coherent line. reply someone7x 20 hours agoparentprevThis plot keeps thickeningI&#x27;m eager to see how it all unfolds. reply ignoramous 20 hours agoprevilyasut &#x27;regret&#x27;: https:&#x2F;&#x2F;archive.is&#x2F;2caSDsama &#x27;hearts&#x27;: https:&#x2F;&#x2F;archive.is&#x2F;OSLRMThink the reconciliation is ON reply neverrroot 20 hours agoprevI believe him. And that’s how Microsoft ended up being cheered by everyone as the good guy. reply maxdoop 19 hours agoparentWhat’s there to believe? He made a bad, poorly thought through decision. reply singularity2001 19 hours agorootparentAnd honestly regrets it. Someone claimed he is faking regret for reasons, which is doubtful reply ot1138 20 hours agoprevI&#x27;ve been on multiple boards. This was the dumbest move I&#x27;ve ever seen. The OpenAI board must be truly incompetent and this Ilya person clearly had no business being on it. reply Zetobal 20 hours agoprevI sure would hire a guy like Ilya after that shit show. His petty title tweets before the event and now whatever this is. Turns out he is just another \"Sunny\". reply sebzim4500 20 hours agoparentHe&#x27;s still a genius when it comes to AI research, I wouldn&#x27;t think twice about hiring him for that role.That said, no one is going to put him on a corporate board again. reply ss1996 18 hours agoparentprevWhat &#x2F; who do mean by \"Sunny\"? reply throwaheyy 16 hours agorootparenthttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Sunny_Balwani reply nunez 16 hours agoprevBut didn&#x27;t he start this? Like, did they think \"I&#x27;ll shoot for the king; if I miss, no big deal?\" reply not_makerbox 19 hours agoprevI don&#x27;t like this Christmas special of Succession reply waihtis 20 hours agoprevSaid it a million times: it was a doomer hijack by the NGO board members. reply theryan 20 hours agoparentWhat is a doomer hijack? reply tucnak 20 hours agoparentprevState-side counterintelligence must stop meddling in AI startups in such blatant ways, it&#x27;s simply too inefficient, and at times when we most need transparency in the industry... reply simonbarker87 20 hours agoprev“I deeply regret the consequences of my actions and didn’t think it would turn out like this” reply jonnycomputer 20 hours agoprevI don&#x27;t have any stake in this, and don&#x27;t care one way or another whether he got sacked. But this is pretty bizarre. reply padolsey 20 hours agoprevThis feels like it could be real remorse, and a true lapse of judgement based on good intentions. So, in the end: a story of Ilya, a truly principled but possibly naive scientist, and a board fixated on its charter. But in their haste, nothing happened as expected. Nobody foresaw the public and private support for Sam and Greg. An inevitability after months of brewing divergence between shareholder interests and an irreconcilably idealistic 503c charter. reply code_runner 20 hours agoparentI think we really need to see that Ilya demonstrates those principles and it wasn’t just a power grab.You could also look at this as a brilliant scientist feels he doesn’t get recognition. Always sees Sam’s name. Resents it. The more gregarious people always getting the glory. Thinks he doesn’t need them and wants to settle some score that only exists in his own head. reply karmasimida 20 hours agoprevThis is too bizarre. I can’t. Impossible even. reply divo6 20 hours agoprevAnd these people are building AGI?No transparency on what is happening. Whole OpenAI who apparently are ready to follow Sam are just using heart emojis or the same twitter posts. reply Tostino 20 hours agoprevWhat a total mess this has been all around. reply tock 20 hours agoprevNobody could have predicted this level of incompetence. I wonder if Satya has actually gutted OpenAI in some way and Ilya regrets it now big time. reply hintymad 14 hours agoprevIsn&#x27;t what Mira and Ilya did was a classical \"sitting on the fence\" movement, which would be hated by both sides of any power struggle? It&#x27;s kinda similar to Prigozhin stopped his coup right at the outskirt of Moscow. reply jahalai 16 hours agoprevHe does not regret the participation, he regrets the outcome and what it means for his personal career. reply davesque 12 hours agoprevSounds like he acted brashly on an ideological impulse and now regrets that he didn&#x27;t have more self control. If so, I can empathize and I feel bad for him. reply baq 20 hours agoprevtried to play high stakes with sharks, got eaten alive by sharks.played stupid games, won stupid prizes.too bad since the guy&#x27;s right, AI is so much more than fantastic business opportunity. reply lordnacho 20 hours agoprevThis seems to be the corporate version of Prigozhin driving to Moscow (not comparing anyone to Putin here, just the situation). If you&#x27;re gonna have a coup, have a coup. If you back down, don&#x27;t hang around.This is becoming a farce. How did they not know what level of support they had within the company? How had they not asked Microsoft? How have they elevated the CTO to CEO, who then promptly says she sides with Sam? reply jacquesm 15 hours agoparentBecause they thought everybody would see things as they did. Inability to put yourself in someone else&#x27;s shoes isn&#x27;t all that rare. reply thom 18 hours agoprevI&#x27;ve chucked a few times over the last few days about the Wikipedia definition of the technological singularity, which opens:\"The technological singularity—or simply the singularity—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable consequences for human civilization.\"Obviously one might have expected that to happen on the other side of a superhuman intelligence, not with us just falling over ourselves to control who gets to try and build one. reply cryptos 20 hours agoprevI&#x27;m waiting for the OpenAI movie! :-) reply danielbln 19 hours agoparent\"A billion parameters isn&#x27;t cool. You know what&#x27;s cool? A trillion parameters.\" reply manojlds 19 hours agoprevWishes there was a git reset --hardBut did a rm -rf .git reply jay-barronville 20 hours agoprevMaybe if he says “I’m sorry” South Park-style [1], they’ll reunite?In all seriousness though, there’s really no coming back from this. He made a risky move and he should stand behind it.OpenAI’s trajectory is pretty much screwed. Maybe they won’t disappear, but their days of dominating the market are obviously numbered.And of course, well done, Satya, for turning a train wreck into a win for Microsoft. (And doing so before market open!)[1]: https:&#x2F;&#x2F;youtu.be&#x2F;15HTd4Um1m4 reply rogerthis 20 hours agoprevIt&#x27;s interesting that people speak whatever comes to mind and think it has no impact on other&#x27;s people lives ($$$). They are some how protected, but shouldn&#x27;t. reply smolder 17 hours agoparentIt&#x27;s interesting how people here seem to think that concerns about shareholder value and the like should override every other concern. Many serious things are going wrong in the world, but when the cornucopia of cash is threatened it seems like 3x as many people come out of the woodwork to voice their disbelief and displeasure. reply RivieraKid 19 hours agoprevThe screenwriters have to be on LSD.Maybe D&#x27;Angelo was the driving force? reply scrlk 19 hours agoparentInspired by The Dark Knight Rises intro: Satya: Was getting caught part of your plan? Ilya: Of course...Sam Altman refused our offer in favour of yours, we had to find out what he told you. Sam: Nothing! I said nothing! Satya: Well, congratulations! You got yourself caught! Now what&#x27;s the next step in your master plan? Ilya: Crashing OpenAI...with no survivors! reply wahnfrieden 19 hours agoparentprevwhy would he be decel &#x2F; safety-over-commercialization as the owner of poe? reply Jensson 19 hours agorootparentMaybe Sam Altman was starting to build out the features that poe had, making poe into a redundant middleman? We see that a lot.By ousting Sam Altman they could ensure that OpenAI would stay just offering bare bones API to models and thus keep poe relevant. reply wahnfrieden 19 hours agorootparentyou&#x27;re suggesting ilya and other board members supported firing sama for shipping a feature poe has? reply Jensson 17 hours agorootparentNo, here is a plausible chain of events:1. Sam Altman announces a competing product to poe (gpt store).2. D&#x27;Angelo sees it and want to stop it.3. D&#x27;Angelo accuses Sam Altman of trying to go against the non-profit mission by making for-profit products without telling the board, saying that Sam Altman can no longer be trusted.4. The remaining board sees that Sam Altman didn&#x27;t talk to them about this feature beforehand so agree with D&#x27;Angelo. reply jacquesm 15 hours agorootparentSomewhat plausible and better than most in that it at least fits all of the available pieces so far. reply wahnfrieden 14 hours agorootparentMore likely is something to do with the Saudi chip money for sama’s side hustle reply jacquesm 14 hours agorootparentUnlikely because that could just as easily benefit OpenAI. replynilkn 19 hours agorootparentprevSam was taking OpenAI in a direction that would pose an immediate existential threat to both of Adam&#x27;s businesses -- Quora and Poe. reply 144 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ilya Sutskever expresses regret for his involvement in the board's actions, stating that he never intended harm to OpenAI.",
      "Sutskever emphasizes his love for the company and pledges to work towards reuniting it."
    ],
    "commentSummary": [
      "OpenAI has recently experienced significant turmoil and leadership changes, sparking speculation about the motivations behind these decisions.",
      "The conversation includes discussion of personal competition, external pressures, and conflicts of interest as potential factors influencing the board's actions.",
      "Commenters express criticism of the lack of transparency and question the competence and reasoning of those involved, highlighting concerns about AI safety, control, and potential negative consequences for the company and its investors."
    ],
    "points": 598,
    "commentCount": 400,
    "retryCount": 0,
    "time": 1700486182
  },
  {
    "id": 38348010,
    "title": "Employees at OpenAI Call for Resignation of Board",
    "originLink": "https://twitter.com/karaswisher/status/1726598360277356775",
    "originBody": "Breaking: 550 of 700 employees @OpenAI tell the board to resign. pic.twitter.com/PvIG4lM5cT— Kara Swisher (@karaswisher) November 20, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38348010",
    "commentBody": "550 of 700 Employees OpenAI tell the board to resignHacker Newspastlogin550 of 700 Employees OpenAI tell the board to resign (twitter.com/karaswisher) 579 points by georgehill 20 hours ago| hidepastfavorite1 comment dang 17 hours ago [–] Comments moved to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "550 out of 700 employees at OpenAI have called for the resignation of the board.",
      "This widespread sentiment among employees suggests a significant level of dissatisfaction or disagreement within the organization.",
      "The request for the board's resignation indicates a deep-rooted issue that needs to be addressed by OpenAI's leadership."
    ],
    "commentSummary": [
      "550 out of 700 employees at OpenAI are demanding the resignation of the board.",
      "The employees are expressing their lack of confidence in the current leadership.",
      "The call for resignation highlights significant dissatisfaction within the company."
    ],
    "points": 579,
    "commentCount": 1,
    "retryCount": 0,
    "time": 1700488217
  },
  {
    "id": 38356534,
    "title": "OpenAI employees ready to quit as Sam Altman's ousting prompts backlash",
    "originLink": "https://www.businessinsider.com/openais-employees-given-explanations-why-sam-altman-out-2023-11",
    "originBody": "Sam Altman Justin Sullivan/Getty Images Redeem now During a meeting with employees, OpenAI's Ilya Sutskever offered two explanations for the ousting of CEO Sam Altman. The explanations involved statements he made to the board regarding personnel. Employees didn't buy these reasons. Most of the company is now prepared to quit. OpenAI's current independent board has offered two examples of the alleged lack of candor that led them to fire co-founder and CEO Sam Altman, sending the company into chaos. Late Sunday night, Ilya Sutskever introduced to staff Emmett Shear, the former Twitch CEO, who was named OpenAI new interim CEO, replacing his predecessor of two days Mira Murati, who herself had replaced Altman on Friday. The brief meeting was held at one of OpenAI's San Francisco offices, and only a handful of the company's employees attended, according to a person familiar with the company and the events of Sunday. The rest of the staff effectively staged a walk-out. The Verge also reported the meeting took place. Staff had spent the day expecting to be told of the reinstatement of Altman as CEO. Over a roughly 30-minute period on Sunday night, staff was told internally that Altman was returning, then that he wasn't, then that Shear had been appointed, another person familiar with the matter said. The people asked for anonymity because they are not authorized to share internal matters. Their identities are known to Business Insider. As staff learned of Shear's appointment, most took the news \"extremely poorly,\" one of the people said. It was yet another shock to employees, who had been on tenterhooks all weekend. It was left to chief scientist and co-founder Sutskever, who helped vote Altman out and did the actual firing of him over Google Meet, to deliver the news of Shear's arrival. Sutskever appeared \"subdued\" during the meeting, one of the people said. Staff, along with tech industry observers, had wondered for days what was behind the harshly worded statement from OpenAI that said Altman \"was not consistently candid in his communications with the board.\" Sutskever is said to have offered two explanations he purportedly received from the board, according to one of the people familiar. One explanation was that Altman was said to have given two people at OpenAI the same project. The other was that Altman allegedly gave two board members different opinions about a member of personnel. An OpenAI spokesperson did not respond to requests for comment. These explanations didn't make sense to employees and were not received well, one of the people familiar said. Internally, the going theory is that this was a straightforward \"coup\" by the board, as it's been called inside the company and out. Any reason being given by the board now holds little to no sway with staff, the person said. A few hours after that meeting, an open letter was drafted, circulated among staff overnight, and signed by OpenAI leadership including Murati and Sutskever, in which they protested the board's decision to not bring Altman back. By mid-day Monday, it had been signed by over 90% of the employees, according to the latest count. In the letter, employees insisted they would resign if remaining members of board did not, if new board members were not appointed, and if Altman was not returned to the company. At the moment, Altman is said to still be negotiating a possible return while he has an interim position at Microsoft, orchestrated by CEO Satya Nadella. Microsoft is OpenAI's largest investor, with at least $10 billion put into the company. \"People are raging mad and mass quitting is imminent,\" one of people familiar with the situation said. The company's current board is made up of Adam D'Angelo, CEO of Quora; Tasha McCauley, a tech entrepreneur; Helen Toner, of the Georgetown Center for Security and Emerging Technology; and Sutskever. Although Sutskever also signed the open letter threatening to leave the company, he is said to still technically be a member of the board. Altman and Greg Brockman, OpenAI's president, were also previously on the board. Although Murati was a source of anger for many employees soon after Altman's ouster, given that she was his initial replacement and was said to have known he was being removed the day prior, that sentiment has cooled. She is said by the people familiar to have \"deferred\" constantly to Sutskever in the immediate aftermath of Friday. Now that she's decided to leave the company should Altman not return, along with Sutskever, who also publicly expressed his \"regret\" for taking part in the board's move against Altman, some wonder if all these top players could continue to work with the OpenAI team and leadership elsewhere. Others, however, believe that Sutskever won't be easily forgiven and won't be invited to stay, or join a new venture at Microsoft. Are you an OpenAI employee or someone with a tip or insight to share? Contact Kali Hays at khays@insider.com, on secure messaging app Signal at 949-280-0267, or through Twitter DM at @hayskali. Reach out using a non-work device. Sign up for notifications from Insider! Stay up to date with what you want to know. Subscribe to push notifications Read next Was this article valuable for you? Additional comments Email (optional) Receive a selection of our best stories daily based on your reading preferences. Submit Watch: Sam Altman moves to Microsoft after OpenAI fires him as CEO OpenAI Generative AI",
    "commentLink": "https://news.ycombinator.com/item?id=38356534",
    "commentBody": "OpenAI&#x27;s employees were given two explanations for why Sam Altman was firedHacker NewspastloginOpenAI&#x27;s employees were given two explanations for why Sam Altman was fired (businessinsider.com) 514 points by meitros 10 hours ago| hidepastfavorite662 comments maxbond 10 hours agoNon-paywall: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231120233119&#x2F;https:&#x2F;&#x2F;www.busin... LarsDu88 4 hours agoprevThere has to be a bigger story to this.Altman took a non-profit and vacuumed up a bunch of donor money only to flip Open AI into the hottest TC style startup in the world. Then put a gas pedal to commercialization. It takes a certain type of politicking and deception to make something like that happen.Then in the past week, he&#x27;s going and taking money from the Saudis on the order of billions of dollars to make AI accelerators, even though the single greatest threat from strong AI (according to Hinton) is rich and powerful people using the technology to enhance their power over society.Combine that with a totally inexperienced board, and D&#x27;Angelo&#x27;s maneuvering, and you have the single greatest shitshow in tech history reply hooande 3 hours agoparentAlternative theory: ChatGPT was a runaway hit product that sucked up a lot of the organization&#x27;s resources and energy. Sam and Greg wanted to roll with it and others on the board did not. They voted on it and one side won.There isn&#x27;t a bigger, more interesting story here. This is in fact a very common story that plays out at many software companies. The board of openai ended up making a decision that destroyed billions of dollars worth of brand value and good will. That&#x27;s all there is to it. reply rtpg 2 hours agorootparentThe \"lying\" line in the original announcement feels like where the good gossip is. The general idea of \"Altman was signing a bunch of business deals without board approval, was told to stop by the board, he said he would, then proceeded to not stop and continue the behavior\"... that feels like the juicy bit (if that is in fact what was happening, I know nothing).This is all court intrigue of course, but why else are we in the comments section of an article talking about the internals of this thing? We love the drama, don&#x27;t we. reply mcv 39 minutes agorootparentThis certainly feels like the most likely true reason to me. Altman fundraising for this new investment, and taking money from people the board does not approve of, and Altman possible promised not to do business with.Of course it&#x27;s all speculation, but this sounds a lot more plausible for such a sudden and dramatic decision than any of the other explanations I&#x27;ve heard. reply stareatgoats 55 minutes agorootparentprevAgreed, court intrigue. But it is also the mundane story of a split between a board and a CEO. In normal cases the board simply swaps out the CEO if out of line, no big fuss. But if the CEO is bringing in all the money, having the full support of the rest of organization, and is a bright star in mass media heaven, then this is likely what you get: the CEO flaunts the needs of the board and runs his own show, and gets away with it, in the end. reply wruza 13 minutes agorootparentprevThe board of openai ended up making a decision that destroyed billions of dollars worth of brand value and good willMaybe I’m special or something, but nothing changed to me. I always wonder why people suddenly lose “trust” in a brand, as if it was a concrete of internal relationships or something. Everyone knows that “corporate” is probably a snakepit. When it comes out to public, it’s not a sign of anything, it just came out. Assuming there was nothing like that in all the brands you love is living with your eyes closed and ears cupped. There’s no “trust” in this specific sense, because corporate and ideological conflicts happen all the time. All OAI promises are still there, afaiu. No mission statements were changed. Except Sam trying to ignore these, also afaiu. Not saying the board is politically wise, but they drove the thing all this time and that’s all that matters. Personally I’m happy they aren’t looking like political snakes (at least that is my ignorant impression for the three days I know their names). reply tsimionescu 1 hour agorootparentprevExcept that the new CEO has explicitly stated he and the board are very much still interested in commercialization. Plus, if the board had on this simple kind of disagreement, they had no reason to also accuse Sam of dishonesty and bring about this huge scandal.Granted, it&#x27;s also possible the reasons are as you state and they were simply that incompetent at managing PR. reply codeduck 42 minutes agorootparent> Except that the new CEO has explicitly stated he and the board are very much still interested in commercializationThis could be desperate, last-ditch efforts at damage control reply rightbyte 1 hour agorootparentprev> a decision that destroyed billions of dollars worth of brand value and good willI mean, there seem to be this cult following around Sam Altman on HN and Twitter. But do the common user care like at all?What sane user would want a shitcoin CEO in charge of a product they depend on? reply austhrow743 1 hour agorootparentprevStraight forward disagreement over direction of the company doesn&#x27;t generally lead to claiming wrongdoing on the part of the ousted. Even low level to medium wrongdoing on the part of the ousted rarely does.So even if it&#x27;s just \"why did they insult Sam while kicking him out?\" there is definitely a bigger, more interesting story here than standard board disagreement over direction of the company. reply dr_dshiv 1 hour agorootparentFrom what I know, Sam supported the nonprofit structure. But let’s just say he hypothetically wanted to change the structure, e.g. to make the company a normal for-profit.The question is, how would you get rid of the nonprofit board? It’s simply impossible. The only way I can imagine it, in retrospect, is to completely discredit them so you could take all employees with you… but no way anyone could orchestrate this, right? It’s too crazy and would require some superintelligence.Still. The events will effectively “for-profitize” the assets of OpenAI completely — and some people definitely wanted that. Am I missing something? reply trhway 2 hours agorootparentprev>Alternative theory: ChatGPT was a runaway hit product that sucked up a lot of the organization&#x27;s resources and energy. Sam and Greg wanted to roll with it and others on the board did not.the article below basically says the same. Kind of reminds Friendster and the likes - striking a gold vein and just failing to scale efficient mining of that gold, i.e. the failure is at the execution&#x2F;operationalization :https:&#x2F;&#x2F;www.theatlantic.com&#x2F;technology&#x2F;archive&#x2F;2023&#x2F;11&#x2F;sam-a... reply Zolde 1 hour agorootparentChatGPT was too polished and product-ready to have been a runaway low-key research preview, like Meta&#x27;s Galactica was. That is the legacy you build around it after the fact of getting 1 million users in 5 days (\"it was build in my garage with a modest investment from my father\").I had heard (but now have trouble sourcing) that ChatGPT was commissioned after OpenAI learned that other big players were working on a chatbot for the public (Google, Meta, Elon, Apple?) and OpenAI wanted to get ahead of that for competitive reasons.This was not a fluke of striking gold, but a carefully planned business move, generating SV hype, much like how Quora (basically an expertsexchange clone) got to be its hype-darling for a while, helped by powerfully networked investors. reply trhway 49 minutes agorootparent>This was not a fluke of striking gold, but a carefully planned business moveThen that execution and operationalization failure is even more profound. reply Zolde 38 minutes agorootparentYou are under the impression that OpenAI \"just failing to scale efficient mining of that gold\", but it was one of the fastest growing B2C companies ever, failing to scale to paid demand, not failing to scale to monetization.I admire the execution and operationalization, where you see a failure. What am I missing? reply verdverm 20 minutes agorootparentIf the leadership of a hyper scaling company falls apart like what we&#x27;ve seen with OpenAI, is that not failure to execute and operationalize?We&#x27;ll see what comes of this over the coming weeks. Will the service see more downtime? Will the company implode completely? replyLMYahooTFY 3 hours agoparentprev>Altman took a non-profit and vacuumed up a bunch of donor money only to flip Open AI into the hottest TC style startup in the world. Then put a gas pedal to commercialization. It takes a certain type of politicking and deception to make something like that happen.What exactly is the problem here? Is a non-profit expected to exclusively help impoverished communities or something? What type of politicking and deception is involved in creating a for profit subsidiary which is granted license to OpenAIs research in order to generate wealth? The entire purpose of this legal structure is to keep non-profit owners focused on their mission rather than shareholder value, which in this case is attempting to ethically create an AGI.Edit: to add that this framework was not invented by Sam Altman, nor OpenAI.>Then in the past week, he&#x27;s going and taking money from the Saudis on the order of billions of dollars to make AI accelerators, even though the single greatest threat from strong AI (according to Hinton) is rich and powerful people using the technology to enhance their power over society.Thus the legal structure I described, although this argument is entirely theoretical and assumes such a thing can actually be guarded that well at all, or that model performance and compute will remain correlated. reply nmfisher 2 hours agorootparent> Is a non-profit expected to exclusively help impoverished communities or something? What type of politicking and deception is involved in creating a for profit subsidiary which is granted license to OpenAIs research in order to generate wealth?OpenAI was literally founded on the promise of keeping AGI out of the hands of “big tech companies”.The first thing that Sam Altman did when he took over was give Microsoft the keys to the kingdom, and even more absurdly, he is now working for Microsoft on the same thing. That’s without even mentioning the creepy Worldcoin company.Money and status are the clear motivations here, OpenAI charter be damned. reply jelling 2 hours agorootparentprev> What exactly is the problem here? Is a non-profit expected to exclusively help impoverished communities or something?Yes. Yes and more yes.That is why, at least in the U.S., we have given non-profits exemptions from taxation. Because they are supposed to be improving society, not profiting from it. reply arrosenberg 2 hours agorootparent> That is why, at least in the U.S., we have given non-profits exemptions from taxation.That&#x27;s your belief. The NFL, Heritage Foundation and Scientology are all non-profits and none of them improve society; they all profit from it.(For what its&#x27; worth, I wish the law was more aligned with your worldview) reply twelvechairs 2 hours agorootparent> OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. OpenAI believes that artificial intelligence technology has the potential to have a profound, positive impact on the world, so the companys goal is to develop and responsibly deploy safe AI technology, ensuring that its benefits are as widely and evenly distributed as possible.From their filing as a non-profithttps:&#x2F;&#x2F;projects.propublica.org&#x2F;nonprofits&#x2F;organizations&#x2F;810... reply tsimionescu 1 hour agorootparentprevOstensibly, all three of your examples do exist to improve society. The NFL exists to support a widely popular sport, the Heritage Foundation is there to propose changes that they theoretically believe are better for society, and Scientology is a religion that will save us all from our bad thetans or whatever cockamamie story they sell.A non-profit has to have the intention of improving society. Whether their chosen means is (1) effective and (2) truthful are separate discussions. But an entity can actually lose non-profit status if it is found to be operated for the sole benefit of its higher ups, and is untruthful in its mission. It is typically very hard to prove though, just like it&#x27;s very hard to successfully sue a for-profit CEO&#x2F;president for breach of fiduciary duty. reply lordnacho 1 hour agorootparentI think GP deals with that in his parenthesis.It would be nice if we held organizations to their stated missions. We don&#x27;t.Perhaps there simply shouldn&#x27;t be a tax break. After all if your org spends all its income on charity, it won&#x27;t pay any tax anyway. If it sells cookies for more than what it costs to make and distribute them, why does it matter whether it was for a charity?Plus, we already believe that for-profit orgs can benefit society, in fact part of the reason for creating them as legal entities is that we think there&#x27;s some sort of benefit, whether it be feeding us or creating toys. So why have a special charity sector? reply aurareturn 2 hours agorootparentprevFYI, the NFL teams are for profits and pay taxes like normal busineses. The overwhelming majority of the revenue goes to the teams. reply arrosenberg 2 hours agorootparentI know that, does that change what I said? reply aurareturn 2 hours agorootparentI don&#x27;t know if it does but my point is to prevent others from thinking that a giant money making entity like the NFL does not pay any taxes. reply hluska 2 hours agorootparentOf course teams pay tax. You just argued nothing…What was the point? reply johncampbelljr 1 hour agorootparentWould you not object if someone characterized google as a non-profit because part of the org (the Google foundation) is non-profit? (Not a perfect analogy (nothing ever is, really).) replymschuster91 54 minutes agorootparentprev> The NFL, Heritage Foundation and Scientology are all non-profits and none of them improve society; they all profit from it.At least for Scientology, the government actually tried to pull the rug, but it didn&#x27;t work out because they managed to achieve the unthinkable - they successfully extorted the US government to keep their tax-exempt status. reply gardenhedge 2 hours agorootparentprevAn argument could be made that sports - and a sports organization - helps society reply passion__desire 1 hour agorootparentFast fashion and fashion industry in general is useless to society. But rich jobless people need a place to hangout so they create an activity to justify. reply quickthrower2 1 hour agorootparentprevAs does a peer to peer taxi company. reply renewiltord 1 hour agorootparentprevIndeed, and one for ChatGPT. reply todd3834 2 hours agorootparentprevI don’t think OpenAI ever reported to be profitable. They are allowed and should make money so they can stay alive. ChatGPT has already had a tremendous positive impact on society. The cause of safe AGI is going to take a lot of money in more research. reply shafyy 2 hours agorootparent> ChatGPT has already had a tremendous positive impact on society.Citation needed reply todd3834 2 hours agorootparentFair enough, I should have said, it’s my opinion that it has had a positive impact. I still think it’s easy to see them as a non profit. Even with everything they announced at AI day.Can anyone make an argument against it? Or just downvote because you don’t agree. reply sgt101 47 minutes agorootparentI think ChatGPT has created some harms:- It&#x27;s been used unethically for psychological and medical purposes (with insufficient testing and insufficient consent, and possible psychological and physical harms).- It has been used to distort educational attainment and undermine the current basis of some credentials as a result.- It has been used to create synthetic content that has been released unmarked into the internet distorting and biasing future models trained on that content.- It has been used to support criminal activity (scams).- It has been used to create propaganda & fake news.- It has devalued and replaced the work of people who relied on that work for their incomes. reply jll29 45 minutes agorootparentprevI think it&#x27;s fair to say that after a lot of empty promises, AI research finally delivered something that can \"wow\" the general population, and has been demonstrated to be useful for more than an single use case.I know a law firm that tried ChatGPT to write a legal letter, and they were shocked that it use the same structure that they were told to use in law school (little surprise here, actually). reply latexr 3 minutes agorootparentI also know of a lawyer who tried ChatGPT and was shocked by the results.https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2023&#x2F;05&#x2F;lawyer-cited-6-f... shafyy 16 minutes agorootparentprevFor what it&#x27;s worth, I didn&#x27;t downvote you.Depends on what you define as positive impact. Helping programmers write boiler plate code faster? Summarize a document for lazy fuckers who can&#x27;t get themselves to read two page? Ok, not sure if this is what I would consider \"positive impact\".For a list of negative impacts, see the sister comments. I&#x27;d also like to add that the energy usage of LLMs like ChatGPT is immensely high, and this in a time where we need to cut carbon emissions. And mostly used for shits and gigles by some boomers. replyxinayder 1 hour agorootparentprevI like to read that, besides the problems others have listed, OpenAI seems like it was built on top of the work of others, who were researching AI, and suddenly took all this \"free work\" from the contributors and sold it for a profit where the original contributors didn&#x27;t even see a single dime from their work.To me it seems like it&#x27;s the usual case of a company exploiting open source and profiting off others&#x27; contributions. reply sgt101 44 minutes agorootparentPersonally I don&#x27;t think that the use of previous research is an issue, the fact is that the investment and expertise required to take that research and create GPT-4 were very significant and the en-devour was pretty risky. Very few people five years ago thought that very large models could be created that would be able to encode so much information or be able to retrieve it so well. reply saiya-jin 1 hour agorootparentprevOr any other say pharma company using massively and constantly basic research done by universities worldwide from our tax money. And then you go to pharmacy and buy medicine that costed 50 cents to manufacture and distribute for 50 bucks.I don&#x27;t like the whole idea neither, but various communism-style alternatives just don&#x27;t work very well. reply ascv 2 hours agorootparentprevIt seemed to me the entire point of the legal structure was to raise private capital. It&#x27;s a lot easier to cut a check when you might get up to 100x your principal versus just a tax write off. This culminated in the MS deal: lots of money and lots of hardware to train their models. reply foota 2 hours agorootparentWhat&#x27;s confusing is that... open AI wouldn&#x27;t ever be controlled by those that invested, and the owners (e.g., the board) aren&#x27;t necessarily profit seeking. At least when you take a minority investment in a normal startup you are generally assuming that the owners are in it to have a successful business. It&#x27;s just a little weird all around to me. reply quickthrower2 1 hour agorootparentMicrosoft get to act as a sole distributor for the enterprise. That is quite valuable. Plus they are still in at the poker table and a few raises from winning the pot (maybe they just did!) but even without this chaos they are likely setting themselves up to be the for-profit investor if it ever transitioned to that. For a small amount of money (for MS) they get a lot of upside. reply kmlevitt 1 hour agoparentprevPeople keep speculating sensational, justifiable reasons to fire Altman. But if these were actual factors in their decision, why doesn&#x27;t the board just say so?Until they say otherwise, I am going to take them at their word that it was because he a) hired two people to do the same project, and b) gave two board members different accounts of the same employee. It&#x27;s not my job nor the internet&#x27;s to try to think up better-sounding reasons on their behalf. reply Wronnay 1 hour agorootparentThe Issue with these two explanations from the board is that this is normally nothing which would result into firing the CEO.In my eyes these two explanations are simple errors which can occur to everybody and in a normal situation you would talk about these Issues and you could resolve them in 5min without firing anybody. reply kmlevitt 54 minutes agorootparentI agree with you. But that leads me to believe that they did not, in fact, have a good reason to fire their CEO. I&#x27;ll change my mind about that if or when they provide better reasons.Look at all the speculation on here. There are dozens of different theories about why they did what they did running so rampant people are starting to accept each of them as fact, when in fact probably all of them are going to turn out to be wrong.People need to take a step back and look at the available evidence. This report is the clearest indication we have gotten of their reasons, and they come from a reliable source. Why are we not taking them at their word? reply katastofik 27 minutes agorootparent> Why are we not taking them at their word?Ignoring the lack of credibility in the given explanations, people are, perhaps, also wary that taking boards&#x2F;execs at their word hasn&#x27;t always worked out so well in the past.Until an explanation that at least passes the sniff test for truthiness comes out, people will keep speculating.And so they should. reply wordpad25 1 hour agorootparentprev>People keep speculatingYour take isn&#x27;t uncommon, only are missing the main point of your interpretation - that the board is fully incompetent if it was truly that petty of a reason to ruin the company.It&#x27;s not even that it&#x27;s not a justifiable reason, but they did it without getting legal advice or consulting with partners and didn&#x27;t even wait for markets to close.Board destroyed billions in brand and talent value for OpenAI and Microsoft in a mid day decision like that.This is also on Sam Altman himself for building and then entertaining such an incompetent board. reply qwytw 52 minutes agorootparent> that the board is fully incompetent if it was truly that petty of a reason to ruin the companyIt&#x27;s perfectly obvious that these weren&#x27;t the actual reasons. However yes, they are still incompetent because they couldn&#x27;t think of a better justification (amongst other reasons which led to this debacle). reply kmlevitt 51 minutes agorootparentprev>Your take isn&#x27;t uncommon, only are missing the main point of your interpretation - that the board is fully incompetent if it was truly that petty of a reason to ruin the company.No, I totally agree. In fact what annoys me about all the speculation is that it seems like people are creating fanfiction to make the board seem much more competent than all available evidence suggests they actually are. reply Sunhold 2 hours agoparentprevI would rather OpenAI have a diverse base of income from commercialization of its products than depend on \"donations\" from a couple ultrarich individuals or corporations. GPT-4 cost $100 million+ to train. That money needs to come from somewhere. reply jimmySixDOF 46 minutes agorootparentThen there is the Inference cost said to be as high as $0.30 per question asked based on compute cost infrastructure. reply osrec 2 minutes agoparentprevWhat does TC style mean? reply PeterStuer 2 hours agoparentprevWhat is interesting is the total absence of 3 letter agency mentions from all of the talk and speculation about this. reply smolder 58 minutes agorootparentI don&#x27;t think that&#x27;s true. I&#x27;ve seen at least one other person bring up the CIA in all the \"theorycrafting\" about this incident. If there&#x27;s a mystery on HN, likelihood is high of someone bringing up intelligence agencies. By their nature they&#x27;re paranoia-inducing and attract speculation, especially for this sort of community. With my own conspiracy theorist hat on, I could see making deals with the Saudis regarding cutting edge AI tech potentially being a realpolitik issue they&#x27;d care about. reply blackoil 34 minutes agoparentprev> money from the Saudis on the order of billions of dollars to make AI acceleratorsWas this for OpenAI or independent venture. If OpenAI than a red flag but an independent venture than seems like a non-issue. There is a demand for AI accelerators, and he wants to enter that business. Unless he is using OpenAI money to buy inferior products or OpenAI wants to work on something competing there is no conflict of interest and OpenAI board shouldn&#x27;t care. reply bryanrasmussen 27 minutes agoparentprev>Combine that with a totally inexperienced board, and D&#x27;Angelo&#x27;s maneuvering, and you have the single greatest shitshow in tech historydo we have a ranking of shitshows in tech history though - how does this really compare to Jobs&#x27; ouster at Apple.Cambridge Analytics and The Facebook we must do better greatest hits? reply mcmcmc 3 hours agoparentprevThis feels like a lot of very one sided PR moves from the side with significantly more money to spend on that kind of thing reply blackoil 32 minutes agoparentprev> There has to be a bigger story to this.On assumption that board is making a sound decision, it could be simply that board acted stupid and egoistic. Unless they can give better reasons that is a logical inference. reply VectorLock 2 hours agoparentprevIt feels like Altman started the whole non-profit thing so he could attract top researchers with altruistic sentiment for sub-FANAAG wages. So the whole \"Altman wasn&#x27;t candid\" thing seems to track. reply saagarjha 2 hours agorootparentOk, but the wages were excellent (assuming that the equity panned out, which it seemed very likely it would until last week). reply LZ_Khan 1 hour agoparentprevTaking money from Saudi&#x27;s alone should raise a big red flag. reply roschdal 1 hour agoparentprev> the single greatest threat from strong AI (according to Hinton) is rich and powerful people using the technology to enhance their power over society.This! reply xinayder 1 hour agoparentprevSo they actually kicked him out because he transformed a non-profit into a money printing machine? reply cdogl 3 hours agoparentprev> Then in the past week, he&#x27;s going and taking money from the Saudis on the order of billions of dollars to make AI accelerators, even though the single greatest threat from strong AI (according to Hinton) is rich and powerful people using the technology to enhance their power over society.This prediction predated any of the technology to create even a rudimentary LLM and could be said of more-or-less any transformative technological development in human history. Famously, Marxism makes this very argument about the impact of the industrial revolution and the rise of capital.Geoffrey Hinton appears to be an eminent cognitive psychologist and computer scientist (edit: nor economist). I&#x27;m sure he has a level of expertise I can&#x27;t begin to grasp in his field, but he&#x27;s no sociologist or historian. Very few of us are in a position to make predictions about the future - least of all in an area where we don&#x27;t even fully understand how the _current_ technology works. reply adrianN 2 hours agorootparentWas Marx wrong? reply robertlagrant 2 hours agorootparentProbably. Or at least that turned out to not matter so much. The alternative, keeping both control of resources and direct power in the state, seems to keep causing millions of deaths. Separating them into markets for resources and power for a more limited state seems to work much better.This idea also ignores innovation. New rich people come along and some rich people get poor. That might indicate that money isn&#x27;t a great proxy for power. reply danans 2 hours agorootparent> New rich people come along and some rich people get poor.Absent massive redistribution that is usually a result of major political change (i.e. the New Deal), rich people tend to stay rich during their lifetimes and frequently their families remain so for generations after.> That might indicate that money isn&#x27;t a great proxy for power.Due to the diminishing marginal utility of wealth for day to day existence, it&#x27;s only value to an extremely wealthy person after endowing their heirs is power. reply aylmao 2 hours agorootparentprev> New rich people come along and some rich people get poorThis is an overly simplistic look, and disregards a lot of history where, unsurprisingly, the reason there was wealth redistribution wasn&#x27;t \"innovation\" but government policy reply cdogl 2 hours agorootparentprev> Was Marx wrong?pt. 1: Whether he was right or wrong was pertinent. You can find plenty of eminent contemporaries of Marx who claimed the opposite. My point was that this is an argument made about technological change throughout history which has become a cliché, and in my opinion it remains a cliche regardless of how eminent (in a narrow field) the person making that claim is. Part of GP was from authority, and I question whether it is even a relevant authority given the scope of the claims.> Was Marx Wrong?pt. 2: I was once a Marxist and still consider much Marxist thought and writing to be valuable, but yes: he was wrong about a great many things. He made specific predictions about the _inevitable_ development of global capital that have not played out. Over a century later, the concentration of wealth and power in the hands of the few has not changed, but the quality of life of the average person on the planet has increased immensely - in a world where capitalism is hegemonic.He was also wrong about the inevitably revolutionary tendencies of the working class. As it turns out, the working class in many countries tend to be either centre right or centre left, like most people, with the proportion varying over time. reply denton-scratch 6 minutes agorootparent> He was also wrong about the inevitably revolutionary tendencies of the working class.Marx&#x27;s conception of the \"working class\" is a thing that no longer exists; it was of a mass, industrial, urban working class, held down by an exploitative capitalist class, without the modern benefits of mass education and free&#x2F;subsidized health care. The inevitability of the victory of the working class was rhetoric from the Communist Manifesto; Marx did anticipate that capitalism would adapt in the face of rising worker demands. Which it did. reply noirscape 52 minutes agorootparentprevFor his prediction of society? Yes.Not even talking about the various tin-pot dictators paying nominal lip service to him, but Marx predicted that the working class would rise up against the bourgeoisie&#x2F;upper class because of their mistreatment during the industrial revolution in well, a revolution and that would somehow create a classless society. (I&#x27;ll note that Marx pretty much didn&#x27;t state how to go from \"revolution\" to \"classless society\", so that&#x27;s why you have so many communist dictators; that between step can be turned into a dictatorship to as long as they claim that the final bit of a classless society is a permanent WIP, which all of them did.)Now unless you want to argue we&#x27;re still in the industrial revolution, it&#x27;s pretty clear that Marx was inaccurate in his prediction given... that didn&#x27;t happen. Social democracy instead became a more prevailing stream of thought (in no small part because few people are willing to risk their lives for a revolution) and is what led to things like reasonable minimum wages, sick days, healthcare, elderly care, and so on and so forth being made accessible to everyone.The quality of which varies greatly by the country (and you could probably consider the popularity of Marxist revolutionary thought today in a country as directly correlated to the state of workers rights in that country; people in stable situations will rarely pursue ideologies that include revolutions), but practically speaking - yeah Marx was inaccurate on the idea of a revolution across the world happening.The lens through which Marx examined history is however just that - a lens to view it through. It&#x27;ll work well in some cases, less so in others. Looking at it by class is a useful way to understand it, but it won&#x27;t cover things being motivated for reasons outside of class. reply osigurdson 2 hours agorootparentprevIf you are a Marxist, no, otherwise yes. reply Guthur 2 hours agoparentprevIf you don&#x27;t think the likes of Sam Altman, Eric Schmidt, Bill Gates and the lot of them want to increase their own power you need to think again. At best these individuals are just out to enrich themselves, but many of them demonstrate a desire to affect the prevailing politic and so i don&#x27;t see how they are different, just more subtle about it.Why worry about the Sauds when you&#x27;ve got your own home grown power hungry individuals. reply curiousgal 2 hours agoparentprev> taking money from the Saudis on the order of billions of dollars to make AI accelerators, even though the single greatest threat from strong AI (according to Hinton) is rich and powerful people using the technology to enhance their power over society.This is absolutely peak irony!US pouring trillions into its army and close to nothing into its society (infrastructure, healthcare, education...) : cricketsSome country funding AI accelerators: THEY ARE A THREAT TO HUMANITY!I am not defending Saudi Arabia but the double standards and outright hypocrisy is just laughable. reply 0xDEADFED5 2 hours agorootparentit&#x27;s okay to give an example of something bad without being required to list all the other things in the universe that are also bad. reply xinayder 1 hour agorootparentprevThe difference is that the US Army wasn&#x27;t created with the intent to \"keep guns from the hands of criminals\" and we all know it&#x27;s a bad actor.OpenAI, on the other hand... reply zw123456 3 hours agoparentprev100% agree. I&#x27;ve seen this type of thing up close (much smaller potatoes but same type of thing) and whatever is getting aired publicly is most likely not the real story. Not sure if the reasons you guessed are it or not, we probably won&#x27;t know for awhile but your guesses are as good as mine. reply kmlevitt 8 hours agoprevNeither of these reasons have anything to do with a lofty ideology regarding the safety of AGI or OpenAI’s nonprofit status. Rather it seems they are micromanaging personnel decisions.Also notice that Ilya Sutskever is presenting the reasons for the firing as just something he was told. This is important, because people were siding with the board under the understanding this firing was led by the head research scientist who is concerned about AGI. But now it looks like the board is represented by D’Angelo, a guy who has his own AI Chatbot company and a bigger conflict of interest with than ever since dev day, when open AI launched highly similar features. reply shandor 4 hours agoparentI’m confused how the board is still keeping their radio silence 100%. Where I’m from, with a shitstorm this big raging, and the board doing nothing, they might very easily be personally held responsible for all kinds of utterly nasty legal action.Is it just different because they’re a nonprofit? Or how on earth the board is thinking they can get away with this anymore? reply rjzzleep 3 hours agorootparentThis isn&#x27;t unlike the radio silence Brendan Eich kept, when the Mozilla sh* hit the fan. This is in my opinion the outcome of when really technical and scientific people have been given decades of advice of not talking to the public.I have seen this play out many times in different locations for different people. A lot of technical folks like myself were given the advice that actions speak louder than words.I was once scouted at a silicon valley selenium browser testing company. I migrated their cloud offering from VMWare to KVM, which depended on code I wrote and then defied my middle manager by improving their entire infrastructure performance by 40%. My instinct was to communicate this to the leadership, but I was advised not to skip my middle manager.The next time I went the office I got a severance package and later found out that 2 hours later during the all hands they presented my work as their own. The middle manage went on to become the CTO of several companies.I doubt we will ever find out what really happened or at least not in the next 5-10 years. OpenAI let Sam Altman be the public face of the company and got burned by it.Personally I had no idea Ilya was the main guy in this company until the drama that happened. I also didn&#x27;t know that Sam Altman was basically only there to bring in the cash. I assume that most people will actually never know that part of OpenAI. reply selestify 34 minutes agorootparentWow, I have nothing to say, other than that’s some major BS! reply lolinder 3 hours agorootparentprevWhat specific legal action could be pursued against them where you&#x27;re from? Who would have a cause for action?(I&#x27;m genuinely curious—in the US I&#x27;m not aware of any action that could be taken here by anyone besides possibly Sam Altman for libel.) reply t_mann 0 minutes agorootparentNot a lawyer, but my guess would be that it would involve a combination of &#x27;threaten to bury the other side in so much legal paperwork that even just having a lawyer look at it, let alone fight it in court, would bankrupt most people&#x27;, &#x27;digging up other dirt on that person&#x27; and some other grand jurisprudential principles that I&#x27;m sure go all the way back to Roman law &#x2F;s 23B1 3 hours agorootparentprevShareholder lawsuits happen all the time for much smaller issues. reply pavlov 3 hours agorootparentOpenAI is a non-profit with a for-profit subsidiary. The controlling board is at the non-profit and immune to shareholder concerns.Investors in OpenAI-the-business were literally told they should think of it as a donation. There’s not much grounds for a shareholder lawsuit when you signed away everything to a non-profit. reply 698969 33 minutes agorootparentI guess big in-person investors were told as much, but if it&#x27;s about that big purple banner on their site, that seems to be an image with no alt-text. I wonder if an investor with impaired vision may be able to sue them for failing to communicate that part. reply 23B1 2 hours agorootparentprevCorporate structure is not immunity from getting sued. Evidently HN doesn&#x27;t understand that lawsuits are a tactic, not a conclusion. reply lolinder 3 hours agorootparentprevRight, but my understanding is that the nonprofit structure eliminates most (if not all) possible shareholder suits. reply shandor 3 hours agorootparentAs I mentioned in my comment, I&#x27;m unaware of the effect of the nonprofit status on this. But like the parent commenter mentioned I mostly was thinking of laws prohibiting destruction of shareholder value (edit: whatever that may mean considering a nonprofit).It just seems ludicrous that the board could run a company into the ground like this and just shrug \"nah we&#x27;re nonprofit so you can&#x27;t touch us and BTW we don&#x27;t even need to make any statements whatsoever\".There have been many comments that the initial firing of Altman was in a way completely according to the nonprofit charter, at least if it could prove that Altman had been executing in a way as to jeopardize the Charter.But even then, how could the board say they are working in the best interest of even the nonprofit itself, if their company is just disintegrating while they willfully refuse to give any information to public? reply 23B1 2 hours agorootparentprevNo corporate structure – except for maybe incorporating in the DPRK – can eliminate lawsuits. reply1024core 6 hours agoparentprev> But now it looks like the board is represented by D’Angelo, a guy who has his own AI Chatbot company and a bigger conflict of interest with than ever since dev day, when open AI launched highly similar features.Could this be the explanation? That D&#x27;Angelo didn&#x27;t like how OpenAI was eating his lunch and wanted Sam out? Occam&#x27;s razor and all that. reply kmlevitt 5 hours agorootparentRight now I think that’s the most plausible explanation simply because none of the other explanations that have been floating around make any sense when you consider all the facts. We know enough now to know that the “safety-focused nonprofit entity versus reckless profit entity“ narrative doesn’t hold up.And if it’s wrong, D’Angelo and the rest of the board could help themselves out by explaining the real reason in detail and ending all this speculation. This gossip is going to continue for as long as they stay silent. reply parl_match 4 hours agorootparent> This gossip is going to continue for as long as they stay silent.Their lawyers are all screaming at them to shut up. This is going to be a highly visible and contested set of decisions that will play out in courtrooms, possibly for years. reply kmlevitt 1 hour agorootparentI agree with you. But I suspect the reason they need to shut up is because their actual reason for firing him is not justifiable enough to protect them, and stating it now would just give more ammunition to plaintiffs. If they had him caught red-handed in an actual crime, or even a clear ethical violation, a good lawyer would be communicating that to the press on their behalf.High-ranking employees that have communicated with them have already said they have admitted it wasn&#x27;t due to any security, safety, privacy or financial concerns. So there aren&#x27;t a lot of valid reasons left. They&#x27;re not talking because they&#x27;ve got nothing. reply Emma_Goldman 2 hours agorootparentprev> \"We know enough now to know that the “safety-focused nonprofit entity versus reckless profit entity“ narrative doesn’t hold up.\"Why do you think that? It still strikes me as the most plausible explanation. reply YetAnotherNick 1 hour agorootparentGreg and Sam were the creator of this current non profit structure. And when similar thing happened before with Elon offering to buy the company, Sam declined. And that was when where for OpenAI getting funding on their terms were much harder than it is now, whereas now they could much more easily dictate terms to investors.Not saying he couldn&#x27;t change now but at least this is enough for him to give clear benefit of doubt unless board accuses him. reply behnamoh 4 hours agorootparentprev> Could this be the explanation? That D&#x27;Angelo didn&#x27;t like how OpenAI was eating his lunch and wanted Sam out? Occam&#x27;s razor and all that.If that were the case, can&#x27;t he get sued by the Alliance (Sam, Greg, rest)? If he has conflict of interest then his decisions as member of the board would be invalid, right? reply Moto7451 3 hours agorootparentI don’t think that’s how it would work out since his conflict was very public knowledge before this point. He plausibly disclosed this to the board at some point before Poe launched and they kept him on.Large private VC backed companies also don’t always fall under the same rules as public entities. Generally there are shareholder thresholds (where insider&#x2F;private shareholders count towards) that in turn cause some of the general Securities&#x2F;board regulations to kick in. reply insanitybit 6 hours agorootparentprevIt seems extremely short sighted for the rest of the board to go along with that. reply sangnoir 4 hours agorootparentHN has been radiating a lot of \"We did it Reddit!\" energy these past 4 days. Lots of confident conjecture based on very little. I have been guilty of it myself, but as an exercise in humility, I will come back to these threads in 6 months to see how wrong I and many others were. reply kmlevitt 1 hour agorootparentI agree it&#x27;s all just speculation. But the board aren&#x27;t doing themselves any favors by not talking. As long as there is no specific reason for firing him given, it&#x27;s only natural people are going to fill the void with their own theories. They have a problem with that, they or their attorneys need to speak up. reply gardenhedge 1 hour agorootparentprevThat might make an interesting blog post. If you write anything up, you should submit it! reply adastra22 6 hours agorootparentprevWell obviously that wouldn&#x27;t be the explanation given to other board members. But it would be the reason he instigated this after dev day, and the reason he won&#x27;t back down (OpenAI imploding? All the better). reply shandor 5 hours agorootparentBut it’s still surprising the other three then haven’t sacked D’Angelo, then. You’d think with the shitstorm raging and the underlying reasoning seemingly so…inadequate, they would start seeing that D’Angelo was just playing them. reply singularity2001 3 hours agorootparentmaybe they have their own &#x27;good&#x27; reasons to sabotage openAI reply rtpg 2 hours agorootparentprevBut you would need to convince the rest of the board with _something_, right? Like to not only fire this guy, but to do it very publicly, quickly, with the declaration of lying in the announcement.There are 3 other people on the board, right? Maybe they&#x27;re all buddies of some big masterminding, but I dunno.. reply adastra22 10 minutes agorootparentThe one thing they all have in common is being AI safetyists, which Sam is not. I’d bet it’s something to do with that. reply Zolde 2 hours agorootparentprevI find this implausible, though it may have played a motivating role.Quora was always supposed to be an AI&#x2F;NLP company, starting by gathering answers from experts for its training data. In a sense, that is level 0 human-in-the-loop AGI. ChatGPT itself is level 1: Emergent AGI, so was already eating Quora&#x27;s lunch (whatever was left of it after they turned into a platform for self-promotion and log-in walls). There either always was a conflict of interest, or there never was.GPTs seemed to have been Sam&#x27;s pet project for a while now, Tweeting in February: \"writing a really great prompt for a chatbot persona is an amazingly high-leverage skill and an early example of programming in a little bit of natural language\". A lot of early jailbreaks like DAN focused on \"summoning\" certain personas, and ideas must have been floated internally on how to take back control over that narrative.Microsoft took their latest technology and gave us Sydney \"I&#x27;ve been a good bot and I know where you live\" Bing: A complete AI safety, integrity, and PR disaster. Not the best of track record by Microsoft, who now is shown to have behind-the-scenes power over the non-profit research organization that was supposed to be OpenAI.There is another schism than AI safety vs. AI acceleration: whether to merge with machines or not. In 2017, Sam predicted this merge to fully start around 2025, having already started with algorithms dictating what we see and read. Sam seems to be in the transhumanism camp, where others focus more on keeping control or granting full autonomy:> The merge can take a lot of forms: We could plug electrodes into our brains, or we could all just become really close friends with a chatbot. But I think a merge is probably our best-case scenario. If two different species both want the same thing and only one can have it—in this case, to be the dominant species on the planet and beyond—they are going to have conflict. We should all want one team where all members care about the well-being of everyone else.> Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants. My guess is that we can either be the biological bootloader for digital intelligence and then fade into an evolutionary tree branch, or we can figure out what a successful merge looks like. https:&#x2F;&#x2F;blog.samaltman.com&#x2F;the-mergeSo you have a very powerful individual, with a clear product mindset, courting Microsoft, turning Dev day into a consumer spectacle, first in line to merge with superintelligence, lying to the board, and driving wedges between employees. Ilya is annoyed by Sam talking about existential risks or lying AGI&#x27;s, when that is his thing. Ilya realizes his vote breaks the impasse, so does a luke warm \"I go along with the board, but have too much conflict of interest either way\".> Third, my prior is strongly against Sam after working for him for two years at OpenAI:> 1. He was always nice to me.> 2. He lied to me on various occasions> 3. He was deceptive, manipulative, and worse to others, including my close friends (again, only nice to me, for reasons)One strategy that helped me make sense of things without falling into tribalism or siding through ideology-match is to consider both sides are unpleasant snakes. You don&#x27;t get to be the king of cannibal island without high-level scheming. You don&#x27;t get to destroy a 80 billion dollar company and let visa-holders soak in uncertainty without some ideological defect. Seems simpler than a clearcut \"good vs. evil\" battle, since this weekend was anything but clear. reply seanhunter 5 hours agorootparentprevWhat’s interesting to me is that someone looked at Quora and thought “I want the guy behind that on my board”. reply motoxpro 3 hours agorootparentI was thinking the same thing. This whole thing is surprising and then I look at Quora and think \"Eh, makes sense that the CEO is completely incompetent and money hungry\"Even as I type that, when people talk about the board being altruistic and holding to the Open AI charter, how in the world can you be that user hostile, profit focused, and incompetent at your day job (Quora CEO) and then say \"Oh no, but on this board I am an absolute saint and will do everything to benefit humanity\" reply bambax 3 hours agorootparentprevAgreed! Yet in 2014 Sam Altman accepted Quora into one of YC&#x27;s batches, saying [0]> Adam D’Angelo is awesome, and we’re big Quora fans[0] https:&#x2F;&#x2F;www.ycombinator.com&#x2F;blog&#x2F;quora-in-the-next-yc-batch reply djsavvy 2 hours agorootparentTo be fair, back then it was pretty awesome IMO. I spent a lot of hours scrolling Quora in those days. It wasn’t until at least 2016 that the user experience became unpalatable if memory serves correctly. reply singularity2001 3 hours agorootparentprevit&#x27;s probably more like they thought \"I want Quoras money\" and D&#x27;angelo wanted their control reply chucke1992 4 hours agoparentprevIt is fascinating considering that D&#x27;Angelo had a history with coup (in Quora he did the same, didn&#x27;t he?) reply aravindgp 3 hours agorootparentWow this is significant, he did this to Charlie cheever the best guy at Facebook and quora. He got Matt on board and fired Charlie without informing investors. Only difference this time 100 billion company is at stake at openai. Process is similar. This going very wrong for Adam D&#x27;Angelo. With this I hope other board members get to the bottom get Sam back and vote out D&#x27;Angelo from board.This school level immaturity.Old storyhttps:&#x2F;&#x2F;www.businessinsider.com&#x2F;the-sudden-mysterious-exit-o... reply mcv 29 minutes agorootparentPeople keep talking about an inexperienced board, but this sounds like this D&#x27;Angelo might be a bit too experienced, especially in this kind of boardroom maneuvering. reply gorgoiler 3 hours agorootparentprevRemember Facebook Questions? While it lives on as light hearted polls and quizzes it was originally launched by D’Angelo when he was an FB employee. It was designed to compete with expert Q&A websites and was basically Quora v0.When D’Angelo didn’t get any traction with it he jumped ship and launched his own competitor instead. Kind of a live wire imho.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Facebook_features#Face... reply dwd 2 hours agoparentprevDo we even have an idea of how the vote went?Greg was not invited (losing Sam one vote), and Sam may have been asked to sit out the vote, so the 3 had a majority. Ilya who is at least on \"Team Sam\" now; may have voted no. Or simply went along thinking he could be next out the door at that point; we just don&#x27;t know.It&#x27;s probably fair to say not letting Greg know the board was getting together (and letting it proceed without him there) was unprofessional and where Ilya screwed up. It is also the point when Sam should have said hang-on - I want Greg here before this proceeds any further. reply havercosine 2 hours agorootparentNaive question. In my part of the world, board meetings for such consequential decisions can never be called out on such short notice. Board meeting has to be called ahead of time by days, all the board members must be given written agenda. They have to acknowledge in writing that they&#x27;ve got this agenda. If the procedures such as these aren&#x27;t followed, the firing cannot stand in court of law. The number of days are configurable in the shareholders agreement, but it is definitely not 1 day.Do things work differently in America? reply Zolde 1 hour agorootparentNo. Apparently they had to give 48 hours notice for calling special teleconference meetings, and only Mira was notified (not a board member) and Greg was not even invited.> at least four days before any such meeting if given by first-class mail or forty-eight hours before any such meeting if given personally, [] or by electronic transmission.But the bylaws also state that a board member may be fired (or resign) at any time, not necessarily during a special meeting. So, technically (not a lawyer): Board gets majority to fire Sam and executes this decision, notifying Mira in advance of calling the special meeting. During the special meeting, Sam is merely informed that he has been let go already (is not a board member since yesterday). All board members were informed timely, since Sam was not a board member during the meeting. reply mcv 12 minutes agorootparentI don&#x27;t see how this kind of reasoning can possible hold up. How can board members not be invited to such an important decision? You can&#x27;t say they don&#x27;t have to be there because they won&#x27;t be a board member after this decision; they&#x27;re still a board member before the decision has been made to remove them.If Ilya was on the side of Sam and Greg, the other 3 never had a majority. The only explanation is that Ilya voted with the other 3, possibly under pressure, and now regrets that decision. But even then it&#x27;s weird to not invite Greg.And if the vote happened in an illegitimate way, I&#x27;d expect Sam and Greg to immediately challenge it and ignore the decision, and that didn&#x27;t happen. reply moberley 2 hours agorootparentprevI find it interesting that the attempted explanations, as unconvincing as they may be, are related to Altman specifically. Given that Brockman was the board chairperson it is surprising that there don&#x27;t seem to be any attempts to explain that demotion. Perhaps its just not being reported to anyone outside but it makes no sense to me that anyone would assume a person would stay after being removed from a board without an opportunity to be at the meeting to defend their position. reply Irishsteve 2 hours agorootparentMaybe the personal issue was Ilya and sam was saying to one board member he has to go and to another he is good. reply fastball 2 hours agorootparentprevI don&#x27;t understand how you only need 4 people for quorum on a 6-person board. reply seanhunter 29 minutes agorootparentIt depends entirely on how the votes are structured, the issue at hand and what the articles of the company say about the particular type of issue.On the board that I was on we had normal matters which required a simple majority except that some members had 2 votes and some got 1. Then there were \"Supermajority matters\" which had a different threshold and \"special supermajority matters\" which had a third threshold.Generally unless the articles say otherwise I think a quorum means a majority of votes are present[1], so 4 out of 6 would count if the articles didn&#x27;t say you needed say 5 out of 6 for some reason.It&#x27;s a little different if some people have to recuse themselves for an issue. So say the issue is \"Should we fire CEO Sam Altman\", the people trying to fire Sam would likely try to say he should recuse himself and therefore wouldn&#x27;t get a vote so his vote wouldn&#x27;t also count in deciding whether or not there&#x27;s a quorum. That&#x27;s obviously all BS but it is the sort of tactic someone might pull. It wouldn&#x27;t make any difference if the vote was a simple majority matter and they already had a majority without him though.[1] There are often other requirements to make the meeting valid though eg notice requirements so you can&#x27;t just pull a fast one with your buddies, hold the meeting without telling some of the members and then claim it was quorate so everyone else just have to suck it up. This would depend on the articles of the company and the not for profit though. reply arthur_sav 1 hour agoparentprev> Also notice that Ilya Sutskever is presenting the reasons for the firing as just something he was told.You mean to tell me that the 3-member board told Sutskever that Sama was being bad and he was like \"ok, I believe you\". reply laurels-marts 35 minutes agorootparentTwo possibilities when it comes to Ilya:1. He’s the actual ringleader behind the coup. He got everyone on board, provided reassurances and personally orchestrated and executed the firing. Most likely possibly and the one that’s most consistent with all the reporting and evidence so far (including this article).2. Others on the board (e.g. Adam) masterminded the coup and saw Ilya as a fellow traveler useful idiot that could be deceived into voting against Sam and destroy the company he and his 700 colleagues spent so hard to build. He then also puppeteer Ilya to do the actual firing over Google Meet. reply aravindgp 6 hours agoparentprevExactly my point why would d Angelo want openai to thrive when his own company poe(chatbot) wants compete in the same space. Its conflict of interest which ever way you look. He should resign from board of openai in the first place.The main point is greg, Ilya can get 50% vote and convince Helen toner to change decision. It&#x27;s all done then it&#x27;s 3 to 2 in board of 5 people. Unless greg board membership is reinstated.Now it&#x27;s increasingly look like Sam will be heading back into the role of CEO of openai. reply anupamchugh 6 hours agorootparentThere’s lots of conflicts of interests beyond Adam and his Poe AI. Yes, he was building a commerical bot using OpenAI APIs, but Sam was apparently working on other side ventures too. And Sam was the person who invested in Quora during his YC tenure, and must have had a say in bringing him onboard. At this point, the spotlight is on most members of the nonprofit board reply nemo44x 5 hours agorootparentI wouldn’t hold Sam bringing him over in too high a regard. Fucking each other over is a sport in Silicon Valley. You’re subservient exactly until the moment you sense an opportunity to dominate. It’s just business. reply TerrifiedMouse 4 hours agorootparentWhy did Altman bring him onboard in the first place? What value does he provide? If there is a conflict of interest why didn’t Altman see it?If this Quora guy is the cause of all this, Altman only has himself to blame since he is the reason the Quora guy is on the board. reply kaoD 2 hours agorootparentThat Quora guy was CTO and VPEng of Facebook so plenty of connections I guess.Also Quora seems like a good source of question-and-answer data which has probably been key in gpt-instruct training. reply bezier-curve 5 hours agorootparentprev\"Business\" sucks then. This is sociopathic behavior. reply rjbwork 4 hours agorootparentYes. That is what is valued in the economic system we have. Absolute cut throat dominance to take as big a chunk of any pie you can get your grubby little fingers into yields the greatest amount of capital. reply bredren 5 hours agorootparentprevWhat has been seen can not be unseen. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=881296 reply dendrite9 59 minutes agorootparentThanks for that. The discussion feels like a look into another world, which I guess is what history is. reply015a 5 hours agorootparentprevSo? Sam gave Worldcoin early access to OpenAI&#x27;s proprietary technology. Should Sam step down (oh wait)? reply blackoil 22 minutes agorootparentWorldcoin has no conflict of interest with OpenAI. Unless he gave tech for free causing great loss to the OpenAI it is simply finding an early beta customer.Also, to fire over something so trivial would be equally if not more stupid. It is like firing Elon because he without open bidding sent Tesla on SpaceX. reply aravindgp 5 hours agorootparentprevEarly access is different from firing board members or CEO! If Sam was always involved in furthering openai success as far the facts and actions he has taken show. It never showed his action is against openai.Like all bets are not correct I don&#x27;t agree with sams worldcoin project at all in the first place.Giving early access to worldcoin doesn&#x27;t correlate to firing employees or board or CEO. reply LMYahooTFY 2 hours agoparentprevWell, the appointment of a CEO who believes AGI is a threat to the universe is potentially one point in favor of AI safety philosophical differences. reply AndyNemmity 5 hours agoparentprevWouldn&#x27;t it make sense that Ilya Sutskever presented the reasons the board had for firing Sam Altman, which were not his reasons.My feeling is Ilya was upset about how Sam Altman was the face of OpenAI, and went along with the rest of the board for his own reasons.That&#x27;s often how this stuff works out. He wasn&#x27;t particularly compelled by their reasons, but had his own which justified his decision in his mind. reply aravindgp 5 hours agorootparentI think Ilya was naive and didn&#x27;t see this coming and good that he reliased quickly announced on twitter and made the right call to get Sam back.Otherwise it was like Ilya vs Sam showdown,and people were siding towards Ilya for agi and all. But this behind the scene looks like corporate power struggle and coup. reply dragonwriter 5 hours agorootparentprev> Wouldn&#x27;t it make sense that Ilya Sutskever presented the reasons the board had for firing Sam Altman, which were not his reasons.Ilya was one of the board members that removed Sam, so his reasons would, ipso facto, be a subset of the board&#x27;s reasons. reply skygazer 4 hours agorootparentIt’s also weird that he’s not admitting to any of his own reasons, only describes some trivial reasons he seems to have coaxed out of the other board members?! Perhaps he still has his own reasons but realizing he’s destroying what he loves he’s trying to stay mum? The other board members seem more zealous for some reason, maybe not being employed by the LLC. Or maybe the others are doing it for the sake of Ilya or someone else that prefers to remain anonymous? Okay, clearly I have no idea. reply karmasimida 4 hours agorootparentprevHe lets the emotion gets the better part of him for sure. reply zombiwoof 3 hours agorootparentSo glad the man baby AI scientist is in charge of AGI alignmentFeel the AI reply lfclub 5 hours agoparentprevIt could be a more primal explanation. I think OpenAi doesn’t want to effectively be a R&D arm of Microsoft. The ChatGPT mobile app is an unpolished and unrefined. There’s little to no product design there, so I totally see how it’s fair criticism to call out premature feature milling (especially when it’s clear it’s for Microsoft).I’m imagining Sam being Microsoft’s Trojan horse, and that’s just not gonna fly.If anyone tells me Sam is a master politician, I’d agree without knowing much about him. He’s a Microsoft plant that has support of 90% of the OpenAi team. The two things are conflicts of interest. Masterful.It’s a pretty fair question to ask a CEO. Do you still believe in OpenAi vision or do you know believe in Microsoft’s vision?The girl she said not to worry about. reply resource0x 6 hours agoparentprevThe failure to create anything resembling AGI can be easily explained away by concerns about the safety of AGI. This can be done in perpetuity. Google explains its AI failures along the same lines. reply DaiPlusPlus 6 hours agorootparent> The failure to create anything resembling AGI can be easily explained away by concerns about the safety of AGI.Isn&#x27;t the solution to just pipe ChatGPT into a meta-reinforcement-learning framework that gradually learns how to prompt ChatGPT into writing the source-code for a true AGI? What do we even need AI ethicists for anyway? &#x2F;s reply kuchenbecker 6 hours agorootparentThe singularity is where this works. reply fhqwhgads 6 hours agorootparentprevThe number of hours I&#x27;ve wasted trying to do this lol reply JyB 4 hours agoparentprevThat&#x27;s the only thing that make sense with Ilya & Murati signing that letter. reply anoy8888 6 hours agoparentprevThis is the most likely scenario. Adam wants to destroy OpenAI so that his poop AI has a chance to survive reply DebtDeflation 7 hours agoprev1) Where is Emmett? He&#x27;s the CEO now. It&#x27;s his job to be the public face of the company. The company is in an existential crisis and there have been no public statements after his 1AM tweet.2) Where is the board? At a bare minimum, issue a public statement that you have full faith in the new CEO and the leadership team, are taking decisive action to stabilize the situation, and have a plan to move the company forward once stabilized. reply dmix 7 hours agoparentTechnically he&#x27;s the interim CEO in a chaotic company just assigned in the last 24hrs. I&#x27;d probably wait to get my bearings before walking in acting like I&#x27;ve got everything under control on the first day after a major upheaval.The only thing I&#x27;ve read about Shear is he is pro-slowing AI development and pro-Yudkowsky&#x27;s doomer worldview on AI. That might not be a pill the company is ready to swallow.https:&#x2F;&#x2F;x.com&#x2F;drtechlash&#x2F;status&#x2F;1726507930026139651> I specifically say I’m in favor of slowing down, which is sort of like pausing except it’s slowing down.> If we’re at a speed of 10 right now, a pause is reducing to 0. I think we should aim for a 1-2 instead.> - Emmett Shear Sept 16, 2023https:&#x2F;&#x2F;x.com&#x2F;eshear&#x2F;status&#x2F;1703178063306203397 reply motoxpro 2 hours agorootparentThe more I read into this story the more I can&#x27;t help but to be a conspiracy theorist and say that it feels like the boards intent was to kill the company.No explanation beyond \"he tried to give two people the same projectthe \"Killing the company would be consistent with the companies mission\" line in the boards statementAdam having a huge conflict of interestEmmet wanting to go from a \"10\" to a \"1-2\"I&#x27;m either way off, or I&#x27;ve had too much internet for the weekend. reply m_mueller 14 minutes agorootparentCould it be that their research found more &#x27;glimpses&#x27; of a dangerous AGI? reply concordDance 4 hours agorootparentprevEveryone involved here is a doomer by the strict definition (\"misaligned agi could kill us all and alignment is hard\") . reply creer 6 hours agorootparentprevAnother \"thing\" is, he has been named by a board which... [etc]. Being a bit cautious would be a minimum. reply PheonixPharts 7 hours agoparentprevYes these people should all be doing more to feed internet drama! If they don&#x27;t act soon, HN will have all sorts of wild opinions about what&#x27;s going on and we can&#x27;t have that!Even worse, if we don&#x27;t have near constant updates, we might realize this is not all that important in the end and move on to other news items!I know, I know, I shouldn&#x27;t jest when this could have grave consequences like changing which uri your api endpoint is pointing to. reply sackfield 7 hours agorootparentYou can either act like a professional and control the messaging or let others fill the vacuum with idle speculation. I&#x27;m quite frankly in shock as to the level of responsibility displayed by people whose position should demand high function. reply kspacewalk2 6 hours agorootparentIt seems evident that the board was filled at least in part by people whose understanding of the business world and leadership skills is a tier or three below what a position of this level requires. One wonders how they got the job in the first place. reply cosmojg 5 hours agorootparentThis is America. Practically anyone can start a nonprofit or a company. More importantly, good marketing may attract substantial investment, but it doesn&#x27;t necessarily imply good leadership. reply dclowd9901 6 hours agorootparentprevReally? I’ve always assumed (known) there is no actual difference between high level execs and you: they just think higher of themselves. reply kevinventullo 5 hours agorootparentIn fact, I think the chaos we’ve seen over the last few days shows precisely the difference between competent and incompetent leadership. I think if anyone from, say, the board of directors of Coca-Cola was on the OAI board, this either wouldn’t have happened or would have played out very differently. reply rjtavares 1 hour agorootparentIf Reed Hoffman was still there, I can&#x27;t see this happening. People here talk about \"glorified salespeople\" as an insult without realizing that having people skills is a really important trait for Boards&#x2F;C level people, and not everyone has them reply d0gsg0w00f 3 hours agorootparentprevWhat you&#x27;ve likely seen of executives is 15 minutes of face time after 7 weeks of vicious Game of Thrones behind the scenes. It&#x27;s a curated image. reply blackoil 15 minutes agorootparentThat is the idea, keep GoT behind the scene. Don&#x27;t dump it on the street. When you have a new king, make sure he isn&#x27;t usurped next day and population is revolting outside the gates of Red Keep. reply spoonjim 4 hours agorootparentprevThat makes as much sense as saying (knowing) that the only difference in basketball skill between you and LeBron James is that he thinks higher of himself. reply JumpCrisscross 6 hours agorootparentprevMy favorite hypothesis: Ilya et al suspected emergent AGI (e.g. saw the software doing things unprompted or dangerous and unexpected) and realized the Worldcoin shill is probably not the one you want calling the shots on it.For the record, I don&#x27;t think it&#x27;s true. I think it was a power play, and a failed coup at that. But it&#x27;s about as substantiated as the \"serious\" hypotheses being mooted in the media. And it&#x27;s more fun. reply mvdtnz 5 hours agorootparentAbsolutely wild to me that people are drawing a straight line between a text completion algorithm and AGI. The term \"AI\" has truly lost all meaning. reply quickthrower2 4 hours agorootparentHold up. Any AI that exists is an IO function (algorithm) perhaps with state. Including our brains. Being an “x completion” algorithm doesn’t say much about whether it is AI.Your comment sounds like a rhetoric way to say that GPT is in the same class as autocomplete and that what autocomplete does sets some kind of ceiling to what IO functions that work a couple of bytes at a time can do.It is not evident to me that that is true. reply cjbprime 4 hours agorootparentprevIt&#x27;s not wild. \"Predict the next word\" does not imply a bar on intelligence; a more intelligent prediction that incorporates more detail from the descriptions of the world that were in the training data will be a better prediction. People are drawing a straight line because the main advance to get to GPT-4 was throwing more compute at \"predict the next word\", and they conclude that adding another order of magnitude of compute might be all it takes to get to superhuman level. It&#x27;s not \"but what if we had a better algorithm\", because the algorithm didn&#x27;t change in the first place. Only the size of the model did. reply robocat 2 hours agorootparent> Predict the next wordAre there any papers testing how good humans are at predicting the next word?I presume us humans fail badly:1. as the variance in input gets higher?2. Poor at regurgitating common texts (e.g. I couldn&#x27;t complete a known poem).3. When context starts to get more specific (majority of people couldn&#x27;t complete JSON)? reply passion__desire 1 hour agorootparentThe following blogpost by an OpenAI employee can lead us to compare patterns and transistors.https:&#x2F;&#x2F;nonint.com&#x2F;2023&#x2F;06&#x2F;10&#x2F;the-it-in-ai-models-is-the-dat... The ultimate model, in his (author&#x27;s) sense, would suss out all patterns and then patterns among those patterns and so on, so that it delivers on compute and compression efficiency.To achieve compute and compression efficiency, it means LLM models have to cluster all similar patterns together and deduplicate them. This also means successively levels of pattern recognition to be done i.e. patterns among patterns among patterns and so on , so as to do the deduplication across all hierarchy it is constructed. Full trees or hierarchies won&#x27;t get deduplicated but relevant regions &#x2F; portions of those trees will, which implies fusing together in ideas space. This means root levels will be the most abstract patterns. This representation also means appropriate cross-pollination among different fields of studies further increasing effectiveness.This reminds me of a point which my electronics professor made on why making transistors smaller has all the benefits and only few disadvantages. Think of these patterns as transistors. The more deduplicated and closely packed they are, the more beneficial they will be. Of course, this \"packing together\" is happening in mathematical space.Another thing which patterns among patterns among patterns reminds me of homotopies. This brilliant video by PBS Infinite Series is amazing. As I can see, compressing homotopies is what LLMs do, replace homotopies with patterns. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=N7wNWQ4aTLQ reply dwaltrip 5 hours agorootparentprevLLMs predict language, and language is a representation of human concepts about the world. Thus, these models are constructing, piece by piece, conceptual chains about the world.As they learn to construct better and more coherent conceptual chains, something interesting must be happening internally. reply mvdtnz 5 hours agorootparentNo they are not. reply cjbprime 4 hours agorootparent(You&#x27;re probably going to have to get better at answering objections than merely asserting your contradiction of them.) reply diffeomorphism 1 hour agorootparentNah, calling out completely baseless assertions as just that is fine and a positive contribution to the discussion. reply krisoft 1 hour agorootparentprevYour carefully constructed argument is less than convincing.Could you at least elaborate what they are “not”? Surelly you are not having a problem with “LLMs predict language”? reply mirekrusin 3 hours agorootparentprevIntelligence is just optimization over recursive prediction function.There is nothing special about human intelligence threshold.It can be surpassed by many different models. reply Emma_Goldman 1 hour agorootparentprevI agree, it&#x27;s an extremely non-obvious assumption and ignores centuries-old debates (empiricism vs. rationalism) about the nature of reason and intelligence. I am sympathetic to Chomsky&#x27;s position.[1]https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;03&#x2F;08&#x2F;opinion&#x2F;noam-chomsky-chat... reply auggierose 55 minutes agorootparentVery weak article. It really lowers my opinion of Chomsky. reply ssnistfajen 5 hours agorootparentprevIf the text completion algorithm is sufficiently advanced enough then we wouldn&#x27;t be able to tell it&#x27;s not AGI, especially if it has access to state-of-the-art research and can modify its own code&#x2F;weights. I don&#x27;t think we are there yet but it&#x27;s plausible to an extent. reply mvdtnz 5 hours agorootparentNo. This is modern day mysticism. You&#x27;re just waving your hands and making fuzzy claims about \"but what if it was an even better algorithm\". reply calf 2 hours agorootparentYou&#x27;re correct about their error; however, Hinton views that a sufficiently scaled up autocompletion would be forced, in a loose mathematical sense, to understand things logically and analytically, because the only way approach 0 error rate on the output is to actually learn the problem and not imitate the answer. It&#x27;s an interesting issue and there are different views on this. reply ssnistfajen 4 hours agorootparentprevlol reply crucialfelix 1 hour agorootparentprevThere has been debate for centuries regarding determinism and free will in humans. reply hooande 5 hours agorootparentprevWhy wouldn&#x27;t Ilya come out and say this? Why wouldn&#x27;t any of the other people who witnessed the software behave in an unexpected way say something?I get that this is a \"just for fun\" hypothesis, which is why I have just for fun questions like what incentive does anyone have to keep clearly observed ai risk a secret during such a public situation? reply allday 4 hours agorootparentBecause, if they announced it and it seemed plausible or even possible that they were correct, then every media outlet, regulatory body, intelligence agency, and Fortune 500 C-suite would blanket OpenAI in the thickest veil of scrutiny to have ever existed in the modern era. Progress would grind to a halt and eventually, through some combination of legal, corporate, and legislative maneuvers, all decision making around the future of AGI would be pried away from Ilya and OpenAI in general - for better or worse.But if there&#x27;s one thing that seems very easy to discern about Ilya, it&#x27;s that he fully believes that when it comes to AI safety and alignment, the buck must stop with him. Giving that control over to government bureaucracy&#x2F;gerontocracy would be unacceptable. And who knows, maybe he&#x27;s right. reply drusepth 3 hours agorootparentprevMy favorite hypothesis (based on absolutely nothing but observing people use LLMs over the years):* Current-gen AI is really good at tricking laypeople into believing it could be sentient* \"Next-gen\" AI (which, theoretically, Ilya et al may have previewed if they&#x27;ve begun training GPT-5, etc) will be really good at tricking experts into believing it could be sentient* Next-next-gen AI may as well be sentient for all intents and purposes (if it quacks like a duck)(NB, to \"trick\" here ascribes a mechanical result from people using technology, not an intent from said technology) reply VirusNewbie 5 hours agorootparentprevBut why would Ilya publicly say he regrets his decision and wants Sam to come back. You think his existential worries are less important than being liked by his coworkers?? reply Zolde 46 minutes agorootparentHe may have wanted Sam out, but not to destroy OpenAI.His existential worries are less important than OpenAI existing, and him having something to work on and worry about.In fact, Ilya may have worried more about the continued existence of OpenAI than Sam after he was fired, which looked instantly like a: \"I am taking my ball and going home to Microsoft.\". If Sam cared so much about OpenAI, he could have quietly accepted his resignation and help find a replacement.Also, Anna Brockman had a meeting with Ilya where she cried and pleaded. Even though he stands by his decision, he may ultimately still regret it, and the hurt and damage it caused. reply cosmojg 4 hours agorootparentprev> You think his existential worries are less important than being liked by his coworkers??Yes, actually. This is overwhelmingly true for most people. At the end of the day, we all fear being alone. I imagine that fear is, at least in part, what drives these kinds of long-term \"existential worries,\" the fear of a universe without other people in it, but now Ilya is facing the much more immediate threat of social ostracism with significantly higher certainty and decidedly within his own lifetime. Emotionally, that must take precedence. reply mcmcmc 3 hours agorootparentprevI think his existential worries about humanity were overruled by his existential worries about his co-founder shares and the obscene amount of wealth he might miss out on reply minimaxir 7 hours agorootparentprevNo serious company wants drama. Hopefully OpenAI is still a serious company.A statement from the CEO&#x2F;the board is a standard descalation. reply 6gvONxR4sf7o 6 hours agorootparent> A statement from the CEO&#x2F;the board is a standard descalation.Haven&#x27;t we gotten statements from them? The complaint seems to be that we want statements from them every day (or more) now. reply minimaxir 6 hours agorootparentEmmett made a tweet noting accepting the role, which is not a statement.The board has not given a statement besides the original firing of Sam Altman that kicked the whole thing off. reply JumpCrisscross 6 hours agorootparentprev> No serious company wants drama\"All PR is good PR\" is a meme for a reason. Many cultures thrive on dysfunction, particularly the kind that calls attention to themselves. reply minimaxir 6 hours agorootparentThat axiom is a relic from the pre-social media days. Nowadays, bad PR going viral can sink a company overnight. reply JumpCrisscross 6 hours agorootparent> That axiom is a relic from the pre-social media days. Nowadays, bad PR going viral can sink a company overnightYou&#x27;re saying we&#x27;re in a less attention-seeking culture today than in pre-social media times? reply maxbond 5 hours agorootparent[ES: Speculation I have medium confidence in.]Maybe \"attention seeking\" isn&#x27;t the right way to look at this. Getting bad press always does reputational damage while giving you notoriety, and I think GP&#x27;s suggestion that the balance between them has changed is compelling.In an environment with limited connectivity, it&#x27;s much more difficult for people to learn you even exist to do business with. So that notoriety component has much more value, and it often nets out in your favor.In a highly connected environment, it&#x27;s easier to reach potential customers, so the notoriety component has less value. Additionally, people have access to search engines, so the reputational damage becomes more lasting; potential customers who didn&#x27;t even hear about the bad press at the time might search your name and find it. They may not have even been looking for it, they might&#x27;ve searched your name to find you website (whereas before they would have needed to intentionally visit a library and look through the catalog to come across an old story). So it becomes much less likely to net out in your favor. reply irreticent 6 hours agorootparentprevI think they were saying the opposite of that. reply staticman2 6 hours agorootparentprevThat phrase much like \"There&#x27;s no such thing as bad publicity\" is not actually true. reply maxbond 5 hours agorootparentprev> Many cultures thrive on dysfunctionPSA: If you or your culture is dysfunctional and thriving - think about how much more you&#x27;ll thrive without the dysfunction! (Brought to you by the Ad Council.) reply dylan604 6 hours agorootparentprev> No serious company wants dramaUnless you&#x27;re TNT, cause they \"know drama\" reply ssnistfajen 5 hours agorootparentprevThe speculations are rampant precisely because the board has said absolute nothing since the leadership transition announcement on Friday.If they had openly given literally any imaginable reason to fire Sam Altman, the ratio of employees threatening to quit wouldn&#x27;t be as high as 95% right now. reply insanitybit 6 hours agorootparentprev> HN will have all sorts of wild opinions about what&#x27;s going on and we can&#x27;t have that!Uh, or investors and customers will? Yes, people are going to speculate, as you point out, which is not good.> we might realize this is not all that important in the end and move on to other news items!It&#x27;s important to some of us. reply gexla 6 hours agorootparentprevThank you! I get the sense that none of this matters and it&#x27;s all a massive distraction.NewsCompany which does research and doesn&#x27;t care about money makes a decision to do something which aligns with research and not caring about money.From the OpenAI website...\"it may be difficult to know what role money will play in a post-AGI world\"Big tech co makes a move which sends its stock to an all time high. Creates research team.Seems like there could be a \"The Martian\" meme here... we&#x27;re going to Twitter the sh* out of this. reply concordDance 4 hours agorootparentprevOpenAI becoming a Microsoft department is awful from an X risk point of view. reply Andrex 6 hours agorootparentprevI cannot say whether you deserve the downvotes, but an alternative and grounded perspective is appreciated in this maelstrom of news, speculation and drama. reply x0x0 6 hours agorootparentprevConvincing two constituencies: employees and customers, that your company isn&#x27;t just yolo-ing things like ceos and so forth seems like it is a pretty good use of ceo time! reply quickthrower2 4 hours agorootparentprevThey have customers and people deciding if they want to be customers. reply kyleyeats 5 hours agorootparentprevThis sarcastic post is the best understanding of public relations I&#x27;ve seen in an HN post. reply upupupandaway 4 hours agoparentprevI find it absolutely fascinating that Emmett accepted this position. He can game all scenarios and there is no way that he can come out ahead on any of them. One would expect an experienced Silicon Valley CEO to make this calculus and realize it&#x27;s a lost cause. The fact he accepted to me shows he&#x27;s not a particularly good leader. reply tw1984 4 hours agorootparentHe made it pretty clear that he consider it as a once in a life time chance.I think he is correct, being the CEO twitch is a position known by no one in many places, e.g. how many developers&#x2F;users in China even heard of Twitch? Being the CEO of OpenAI is a completely different story, it is a whole new level he can leverage in the years to come. reply ps256 1 hour agorootparentIt seems kind of naive to think that he&#x27;ll be CEO for long, or if it is for long, that there will be much company left to be a CEO of. reply tw1984 41 minutes agorootparentwhy he needs to be CEO for long?If everything goes well, he can claim that he is the man behind all these to reunite the OpenAI team. If something goes wrong, well, no one is going to blame him, the board screwed the entire business. He is more like a emergency room doctor who failed to save a poor dude who just intentionally shot himself in the head with a shotgun. reply khazhoux 1 hour agorootparentprev> he consider it as a once in a life time chance.Like taking a sword to the gut. reply bmitc 4 hours agorootparentprevThat seems kind of silly to say. He&#x27;s not a good leader because he&#x27;s taking on a challenge? reply upupupandaway 3 hours agorootparentA challenge he can&#x27;t win, brought in by people 90% of the company hates, and with the four most influential people in the company either gone or having turned on the board does not sound like a \"challenge\" but more like a \"guaranteed L\". reply agitator 3 hours agoparentprevAs much as I&#x27;d love to hear about the details of the drama as the next person, they really don&#x27;t have to say anything publicly. We are all going to continue using the product. They don&#x27;t have public investors. The only concern about perception they may have is if they intend to raise more money anytime soon. reply c_s_guy 6 hours agoparentprevIf Emmett will run this the same way he ran Twitch, I&#x27;m not expecting much action from him. reply eastern 3 hours agoparentprevThat&#x27;s what a board of a for-profit company which has a fiduciary duty towards shareholders should do.However, the OpenAI board has no such obligation. Their duty is to ensure that the human race stays safe from AI. They&#x27;ve done their best to do that ;-) reply starshadowx2 5 hours agoparentprevPeople kept asking where he was during his years of being Twitch CEO, it&#x27;s not unlike him to be MIA now either. reply arduanika 5 hours agoparentprevHere he is! Blathering about AI doom 4 months ago, spitting Yudkowsky talking points:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jZ2xw_1_KHY reply pushedx 5 hours agoparentprevHe has said more than he said during his entire 5 years at Twitch reply highwayman47 6 hours agoparentprevHalf the board lacks any technical skill, and the entire board lacks any business procedural skill. Ideally, you’d have a balance of each on a component board. reply eshack94 5 hours agorootparentIdeally, you also have at least a couple independent board members who are seasoned business&#x2F;tech veterans with the experience and maturity to prevent this sort of thing from happening in the first place. reply spullara 5 hours agoparentprevHe is trying to determine if they have already made an Alien God. reply markdown 6 hours agoparentprevWhy should he care about updating internet randoms? It&#x27;s none of our business. The people who need to know what&#x27;s going, know what&#x27;s going on. reply kumarvvr 8 hours agoprevGiving 2 people the same project? Isnt this like the thing to do to get differing approaches and then release the amalgamation of the two? I thought these sorts of things are common.Giving different opinions on same person is a reason to fire a CEO?This board has no reason to fire, or does not want to give the actual reason to fire Sam. They messed up. reply hal009 6 hours agoparentAs mentioned by another person in this thread [0], it is likely that it was Ilya&#x27;s work that was getting replicated by another \"secret\" team, and the \"different opinions on the same person\" was Sam&#x27;s opinions of Ilya. Perhaps Sam saw him as an unstable element and a single point of failure in the company, and wanted to make sure that OpenAI would be able to continue without Ilya?[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;reply?id=38357843 reply JimDabell 6 hours agorootparentSince a lot of the board’s responsibilities are tied to capabilities of the platform, it’s possible that Altman asked for Ilya to determine the capabilities, didn’t like the answer, then got somebody else to give the “right” answer, which he presented to the board. A simple dual-track project shouldn’t be a problem, but this kind of thing would be seen as dishonesty by the board. reply hn_throwaway_99 3 hours agorootparent> it’s possible that Altman asked for Ilya to determine the capabilities, didn’t like the answer, then got somebody else to give the “right” answer, which he presented to the board.This makes no sense given that Ilya is on the board. reply JimDabell 3 hours agorootparentNo, it just means that in that scenario Sam would think he could convince the rest of the board that Ilya was wrong because he could find somebody else to give him a preferable answer.It’s just speculation, anyway. There isn’t really anything I’ve heard that isn’t contradicted by the evidence, so it’s likely at least one thing “known” by the public isn’t actually true. reply kmlevitt 6 hours agorootparentprevFiring Sam as a way of sticking up for Ilya would make more sense if Ilya wasn’t currently in support of Sam getting his job back. reply onimishra 1 hour agorootparentI’m not sure Ilya was anticipating this to more or less break OpenAI as a company. Ilya is all about the work they do, and might not have anticipated that this would turn the entire company against him and the rest of the board. And so, he is in support of Sam coming back, if that means that they can get back to the work at hand. reply kmlevitt 47 minutes agorootparentPerhaps. But if the board is really so responsive to Ilya&#x27;s concerns, why have they not reversed the decision so that Ilya can get his wish? reply 015a 6 hours agorootparentprevThis is an interesting theory when combined with this tweet from Google DeepMind&#x27;s team lead of Scalable Alignment [1].[1] https:&#x2F;&#x2F;twitter.com&#x2F;geoffreyirving&#x2F;status&#x2F;172675427761849141...The \"Sam is actually a psychopath that has managed to swindle his way into everyone liking him, and Ilya has grave ethical concerns about that kind of person leading a company seeking AGI, but he can&#x27;t out him publicly because so many people are hypnotized by him\" theory is definitely a new, interesting one; there has been literally no moment in the past three days where I could have predicted the next turn this would take. reply doktrin 5 hours agorootparentInteresting. I’m glad he shared his perspective despite the ambiguity. reply BillyTheKing 5 hours agorootparentpreveither that or Sam didn&#x27;t tell Adam D&#x27;Angelo that they were launching a competing product in exactly the same space that poe.ai had launched one. For some context, poe had launched something similar to those custom GPTs with creator revenue sharing etc. just 4 weeks prior to dev-day reply stingraycharles 7 hours agoparentprevI remember a few years ago when there was some research group that was able to take a picture of a black hole. It involved lots of complicated interpretation of data.As an extra sanity check, they had two teams working in isolation interpreting this data and constructing the image. If the end result was more or less the same, it’s a good check that it was correct.So yes, it’s absolutely a valid strategy. reply msravi 6 hours agorootparentDid the teams know that there was another team working on the same thing? I wonder how that affects working of both teams... On the other hand, not telling the teams would erode the trust that the teams have in management. reply Keyframe 4 hours agorootparentThere were four teams actually. They knew but couldn&#x27;t talk to each other. There&#x27;s a documentary about it. I highly suggest watching it, it also features late Stephen Hawking et al. working on black hole soft hair. Documentary is called Black Holes: The Edge of All We Know, it&#x27;s on pretty much all streaming platforms. reply campbel 7 hours agorootparentprevYep! I&#x27;ve done eng \"bake-offs\" as well, where a few folks &#x2F; teams work on a problem in isolation then we compare and contrast after. Good fun! reply cyrnel 5 hours agorootparentNot good fun when it&#x27;s done in secret. That happened to me, and I was gaslit when I discovered the competing git repo.Not saying that&#x27;s what happened here, but too many people are defending this horrid concept of secretly making half your workers do a bunch of work only to see the boulder roll right back down the hill. reply moorow 5 hours agorootparentYeah, doing it in secrecy is a recipe for Bad Things. I worked at a startup that completely died because of it. reply DonHopkins 6 hours agorootparentprevMaybe they needed two teams to independently try to decode an old tape of random numbers from a radio space telescope that turned out to be an extraterrestrial transmission, like a neutrino signal from the Canis Minor constellation or something. Happens all the time.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;His_Master%27s_Voice_(novel) reply danbmil 6 hours agoparentprevThe CEO&#x27;s I&#x27;ve worked for have mostly been mini-DonaldT&#x27;s, almost pathologically allergic to truth, logic, or consistency. Altman seems way over on the normal scale for CEO of a multi-billion dollar company. I&#x27;m sure he can knock two eggs together to make an omelette, but these piddling excuses for firing him don&#x27;t pass the smell test.I get the feeling Ilya might be a bit naive about how people work, and may have been taken advantage of (by for example spinning this as a safety issue when it&#x27;s just a good old fashioned power struggle) reply danbmil 6 hours agorootparentas for multiple teams with overlapping goals -- are you kidding me? That&#x27;s a 100% legit and popular tactic. Once CEO I worked with relished this approach and called it a \"Steel-cage death match\"! reply aravindgp 6 hours agorootparentprevYou were right Ilya was naive , he regrets his decision on twitter. And he was taken advantage of by power hungry people behind. reply valine 8 hours agoparentprevSteve Jobs famously had two iPhone teams working on concepts in parallel. It was click wheel vs multi-touch. Shockingly the click wheel iPhone lost. reply brandall10 7 hours agorootparentI thought the design team always worked up 3 working prototypes from a set of 10 foam mockups. There was an article from someone with intimate knowledge of Ives lab some years back stating this was protocol for all Apple products. reply mikepurvis 7 hours agorootparentprevAnother element of that was the team that tried to adapt iPodOS for iPhone vs Forstall&#x27;s team that adapted OSX. reply kridsdale1 6 hours agorootparentI think it was also a contest between all web ui (like WebOS) bs Cocoa. reply throwawayapples 7 hours agorootparentprevand the Apple (II etc) vs Mac teams warring with each other. reply kmeisthax 6 hours agorootparentYou&#x27;re thinking Lisa vs. Mac. Apple ][ didn&#x27;t come into the picture until later when some of the engineers started playing around with making a mouse card for the ][. reply fakedang 7 hours agorootparentprevSeriously? Click wheel iPhone lost shockingly? The click wheel on most laptops wears out so fast for me, and the chances of that happening on a smaller phone wheel is just so much higher. reply potatoman22 7 hours agorootparent(It was sarcasm) reply fakedang 4 hours agorootparentOops, sorry, didn&#x27;t get that. I had suspected it was one of those Luddite HNer comments bemoaning changes in tech, and nostalgically reminiscing on older times. reply WalterBright 7 hours agoparentprevBack in the late 80s, Lotus faced a crisis with their spreadsheet, Lotus 1-2-3. Should they:1. stick with DOS2. go with OS&#x2F;23. go with WindowsLotus chose (2). But the market went with (3), and Lotus was destroyed by Excel. Lotus was a wealthy company at the time. I would have created three groups, and done all three options. reply quickthrower2 7 hours agorootparentWhich would have had been a tradeoff too. More time to market, fewer people on each project, slowed down by cross platform code. reply kumarvvr 7 hours agorootparentAt the time, Lotus was a good company in great shape. The management could have hired people to get stuff done. In hindsight, sure, we can be judgmental, but it is still a failure in my view.For a company selling licenses for installations, wouldn&#x27;t having support for all available and upcoming platforms a good thing? Especially when the distribution costs are essentially 0? reply WalterBright 5 hours agorootparentprevLotus was a rich company, and could have easily funded 3 full strength independent dev teams. It would not have slowed anything down. reply jeremyjh 7 hours agorootparentprevThey",
    "originSummary": [
      "OpenAI employees are ready to resign following the removal of CEO Sam Altman, with over 90% signing an open letter condemning the decision.",
      "The board cited Altman's lack of openness in communication as the reason for his departure, but employees are skeptical of this explanation.",
      "Interim CEO Emmett Shear's introduction at a meeting triggered a range of emotions from shock to anger among the staff, and sources suggest a mass exodus of employees is imminent."
    ],
    "commentSummary": [
      "Sam Altman, former CEO of OpenAI, has been fired for reasons speculated to be related to financial involvement and a disagreement over product success vs. organizational resources.",
      "Concerns have been raised about OpenAI's actions and motivations, including its transition to a for-profit subsidiary, funding from Saudi Arabia, and collaboration with Microsoft.",
      "There is skepticism and speculation surrounding Altman's firing, as well as concerns about conflicts of interest and manipulation within the organization. Critics question the motives and suitability of certain board members and express frustration with OpenAI's business practices."
    ],
    "points": 514,
    "commentCount": 663,
    "retryCount": 0,
    "time": 1700523117
  },
  {
    "id": 38352484,
    "title": "Boeing Declines Payment, Ransomware Group Leaks 45 GB of Data",
    "originLink": "https://www.itbrew.com/stories/2023/11/17/after-boeing-declines-to-pay-up-ransomware-group-leaks-45-gb-of-data",
    "originBody": "CYBERSECURITY After Boeing declines to pay up, ransomware group leaks 45 GB of data After the deadline came and went, Russia-linked cyber gang LockBit followed through on its threat to post a large amount of company information online. Hannah Minn ByEoin Higgins November 17, 2023 · less than 3 min read Top insights for IT pros From cybersecurity and big data to cloud computing, IT Brew covers the latest trends shaping business tech in our 3x weekly newsletter, virtual events with industry experts, and digital guides. Subscribe Ransomware hackers warned aircraft industry giant Boeing they were going to leak data if their price wasn’t met—and on November 10, they did just that, publishing nearly 45 gigabytes of company data online. LockBit, a Russia-linked hacking gang, claimed responsibility for the attack on Oct. 27. “Sensitive data was exfiltrated and ready to be published if Boeing do not contact within the deadline!” the gang posted on its data leak site. As IT Brew has reported, ransomware has been a major problem in 2023, and gangs are now able to deploy malware quicker than ever. Boeing acknowledged the hack the same day. In a Nov. 2 email to Cybersecurity Dive, the company said that it was “aware of a cyber incident impacting elements of our parts and distribution business,” but “this issue does not affect flight safety.” After the deadline came and went, LockBit followed through on its threat, posting a large amount of company information online. The leak included cloud computing company Citrix files, security controls, email backups, and more. Cybersecurity analyst Dominic Alvieri told The Register that corporate emails were included in the leak. “I haven’t gone over the whole data set but Boeing emails and a few others stand out as useful for those with malicious intent,” Alvieri said. MalwareHunter Team reviewed the leak and suggested it likely came from Aviall, the parts distributor Boeing purchased in 2006. Because of 17 years of Aviall integration with Boeing systems, MalwareHunter Team opined that the severity of the breach could be worse than is already known. “Question is how much the networks of the companies got merged in the past 17 years,” the team tweeted. “Because if not too much & LockBit really only pwned the networks of Aviall, the problem is not very much bad, ‘simply’ bad for Boeing.” COPY You might also like... CYBERSECURITY Ransomware hits world’s largest bank, raising concerns about security of financial sector TOM MCKAY / 11.17.2023 CLOUD Microsoft shares jump on cloud, AI news EOIN HIGGINS / 11.9.2023 CLOUD Why one CTO moved away from the cloud BILLY HURLEY / 11.17.2023 TOP INSIGHTS FOR IT PROS From cybersecurity and big data to cloud computing, IT Brew covers the latest trends shaping business tech in our 3x weekly newsletter, virtual events with industry experts, and digital guides. Try it",
    "commentLink": "https://news.ycombinator.com/item?id=38352484",
    "commentBody": "After Boeing declines to pay up, ransomware group leaks 45 GB of dataHacker NewspastloginAfter Boeing declines to pay up, ransomware group leaks 45 GB of data (itbrew.com) 497 points by turtlegrids 15 hours ago| hidepastfavorite334 comments cosmojg 4 hours agoAs someone who works in the defense industry, I can assure you that 45 GB of unencrypted emails is next to worthless from a commercial standpoint and a total non-event from a national security standpoint. This is probably more of a threat to individual employees than it is to anybody else.To put it another way, if this data had value, the ransomware group wouldn&#x27;t be leaking it for free. reply visarga 3 hours agoparentMaybe we can get another email corpus like Enron for NLP from all of this. reply IndySun 1 hour agoparentprev>As someone who works in the defense industry, I can assure you...Defence industry is broad, though, perhaps you needed to be for security reasons. However, stating your job then saying individual people don&#x27;t matter but commercial entities do may make you unfit for certain defence careers. reply fakedang 2 hours agoparentprevStill useful to find weak links as a foreign adversary. reply npalli 10 hours agoprevFor an external party, having access to the 45 GB is the easy part. Now, you will need to create a company and supplier base the size of Boeing to make any use of this :-) reply est 6 hours agoparent> Now, you will need to create a company and supplier base the size of Boeing to make any use of thisChina: hold my baijiu reply paledot 5 hours agorootparentGuaranteed they already have the data they want. reply SR2Z 5 hours agorootparentThen why hasn&#x27;t COMAC produced a viable jetliner? reply dghlsakjg 4 hours agorootparentBecause having the plans for something and having capability, materials and funding to do it are two different things. reply protomolecule 1 hour agorootparentprevIt has[0].[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Comac_C919 reply Hissigh 2 minutes agorootparentI flew with this 2 years ago. Looks like a standard boing&#x2F;airbus from the inside but the sound isolation is so bad, it&#x27;s very loud inside testrun 3 hours agorootparentprevAccording to Wikipedia Comac has orders in the range of $26 billion for the C919. reply elsonrodriguez 3 hours agorootparentThe same article notes that they are using an engine by GE&#x2F;Safran, and that there was espionage involved in the development of the C919. reply lozenge 25 minutes agorootparentApparently, the engines might be 20% of the cost of the plane. https:&#x2F;&#x2F;aviation.stackexchange.com&#x2F;a&#x2F;16018 reply vidarh 1 hour agorootparentprevAnd? Neither of these things change what was being claimed and disputed above. reply M3L0NM4N 3 hours agorootparentprevIf they had the money to, they could. reply lallysingh 9 hours agoparentprevI can imagine this complicating any supplier contract negotiations. \"you pay X $50&#x2F;unit more for the same device, etc.\" reply alexpotato 8 hours agorootparentI remember taking a procurement class in graduate school(MBA).One of the more interesting points of discussion was that when big companies negotiate purchase agreements for parts, the actual cost of the parts can be very transparent. The negotiation is generally about the actual markup e.g. \"I think we should pay X% over cost.Someone, logically, brought up: \"What if the company is not willing to share the cost upfront?\".The professor responded: \"Well, if it&#x27;s a public company you can generally deduce a rough cost&#x2F;part and use that as your starting point in the negotiation\"Student: \"Well what if the company says we&#x27;re wrong?\"Professor: \"No problem: ask them what the correct number is. If they don&#x27;t want to give it to you, ask them how you expect to have a long term partnership if you are not willing to talk openly and honestly about things like parts costs.\" reply wordpad25 8 hours agorootparentThat&#x27;s kind of a softball, can easily be counted with \"part costs vary a lot based on the market\" or something like, regardless of cost we guarantee you this price pointNo business wants to share it&#x27;s internal costs, it&#x27;s their prime competitive advantage reply deaddodo 3 hours agorootparentTheir prime competitive advantage is their product and quality:cost ratio. For a product company, at least.If your business&#x27; primary competitive advantage is that it gets ICs for 1c less&#x2F;per thousand, your business is built on shaky foundations. One that you would still want to disclose during negotiations (\"yeah, our product is the exact same quality as Widget Co; but we&#x27;ve found a supply for some internal parts at slightly below market value\"). reply nullindividual 6 hours agorootparentprevWhen your only business is the Lazy B, you’re going to cooperate. reply aksss 6 hours agorootparentprevIf the deal is big enough, it’s absolutely on the table. These are “cost plus” contracts. See Walmart and the federal government for examples of consumers that require these terms.Now, the federal government, particularly with drugs pricing, turns a blind eye towards the suppliers just jacking up the purported cost. E.g. Pharma:“we want to make $100 per pill, it costs us $5 to produce”. Fed: “we demand cost + 10%, because the people”. Pharma:”Fine, let’s say it costs $90 to produce.” Fed:”Where do I sign?”Whereas Walmart would say to somebody like Nabisco, “GFY; if you want your product on our shelves, you’ll open your books and give us audited cost + 10%”. reply deaddodo 3 hours agorootparentprevThe idea that someone could hide parts&#x2F;manufacturing costs is ridiculous on its face. You, as a consumer, can get a general BOM for most any device. It&#x27;s how we know that the original Beats headphones were \"worth\" 7-8usd.Just as we as consumers know we pay extra to the company (even if the numbers aren&#x27;t oblique), businesses know the same. It&#x27;s about how much you&#x27;re willing to spend, not how much they spent to build it. reply traceroute66 1 hour agorootparent> You, as a consumer, can get a general BOM for most any device.I wish this dumb naïve argument would just die quietly in a corner.A the value of a device is not its BOM. It has never been and it will never be.There are so many other additional costs to factor in. Costs related to the manufacturing plant, its people, its tooling and its processes. Logistics costs related to bringing in parts. QA costs. R&D costs. Software maintenance costs. Marketing costs. Certain parts and software may have royalty fees associated with them. The list goes on, and on, and on.So please, enough of the dumb \"$device is only $2USD because its only a bunch of 2c resistors and capacitors on a PCB\". reply lolive 1 hour agoparentprevAirbus needed a corpus to train its LLM. Now they have. reply Thervicarl 1 hour agorootparentThis should guide them if they want to modify existing airliners so they are better equipped to crash into the ground, 737 MAX style. No thanks. reply KRAKRISMOTT 57 minutes agorootparentThey just need to ask the British Prime Minister. His father in law&#x27;s company is where those jobs get outsourced to for cheap. reply qwertox 8 hours agoparentprevIt could be a real security issue, depending on the kind of data. reply photochemsyn 6 hours agorootparent\"Security by obscurity alone is discouraged and not recommended by standards bodies.\" reply justinclift 4 hours agorootparentThis is Boeing we&#x27;re talking about. They stopped being any kind of competent a few decades ago. :( reply clnq 6 hours agorootparentprevAh, well so long as it&#x27;s discouraged... I&#x27;m sure no one&#x27;s critical systems would depend on it, right? reply pyuser583 4 hours agoparentprevIf only .001% of the population of China bought a 747. reply baz00 10 hours agoparentprevThat wouldn&#x27;t even help. It&#x27;d have to be part of the original supply chain and certification chain for anything to be allowed out of the country that cloned any parts. reply panarky 9 hours agorootparentIf it doesn&#x27;t matter that it&#x27;s public, then why did Boeing try to keep it secret? reply worthless-trash 8 hours agorootparentBecause they can&#x27;t tell the future, its better to have the cards than not. reply hrdwdmrbl 10 hours agoparentprevChina reply npalli 10 hours agorootparent1. They probably already have it :-)2. Imagine the sheer pain of duplicating every single process and spec to the minutest detail, nobody is flying an airplane that only &#x27;works&#x27; 99.99% of the time. Probably easier to start from scratch and learn it. BTW, this was tried by Russia in the all through the &#x27;80s, they tried to steal all advanced tech. but by the time they duplicated the stolen technology, the next generation appeared. A losing battle. reply ethbr1 9 hours agorootparent> nobody is flying an airplane that only &#x27;works&#x27; 99.99% of the timeMight I introduce you to the Tupolev Tu-134?https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;List_of_accidents_and_incide... reply throw0101b 9 hours agorootparent> Might I introduce you to the Tupolev Tu-134?Also perhaps the 737-MAX. :)* https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maneuvering_Characteristics_Au... reply verdverm 6 hours agorootparentGiven how much the max family and 8 are flown, I don&#x27;t think this holds up.Some searching says...1. >1000 flights per day for the family2. 2 US carriers accounting for more than 200 Max 8 per daySo one would have to get to 20,000 flights after two crashes to get 2 nines. We&#x27;re well past that threshold reply Xixi 5 hours agorootparentFrom inception to the second crash, numbers were abysmal. The 737 Max was crashing at a rate of about one per hundred thousand flights, two order of magnitude worse that the 737 NG (one fatal crash per 10 million flights).Said differently, the Max 8 was working safely 99.999% of the time, while the 737 NG was working safely 99.99999% of the time. An order of magnitude better than 99.99%, but two orders of magnitude worse than expected...It is certainly a lot safer now. Hopefully even better than the 737 NG. reply throwaway318 4 hours agorootparentprevThe probability of not having a crash after 20,000 flights, with 99.99% chance per flight, assuming no serial correlation, is 13%. reply verdverm 10 minutes agorootparentYes, there is a better, more accurate method than my napkin math, which was only to provide a baseline most could understand to see we are well beyond the two nines xcdzvyn 2 hours agorootparentprevI disagree that it&#x27;s possible to estimate how dangerous an aircraft is based on its incidents&#x2F;flight ratio. There&#x27;s lots of other factors: Russian weather, inadequate training, inadequate maintenance, and far more landings on poorly maintained and even totally unpaved runways:> Capable of operating from unpaved and gravel airfields with only basic facilities, it was widely used in the extreme Arctic conditions of Russia&#x27;s northern&#x2F;eastern regions, where other airliners were unable to operate. reply KHRZ 1 hour agorootparentRussian weather? Is this an euphemism for Russian air defense? reply sterlind 2 hours agorootparentprevnot to mention the Tu-144, aka the \"Concordski\":https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tupolev_Tu-144though that one was so defective that even the Soviets didn&#x27;t want to risk flying it. it could barely get into the air, and that&#x27;d be with several major faults and alarms blaring. reply NL807 8 hours agorootparentprevKinda scary how many times I flew with those in 80s. reply reactordev 10 hours agorootparentprevSounds a lot like software forks… coughNot the ones that were forked due to abandonment, but the forks due to “irreconcilable differences”. reply denimnerd42 9 hours agorootparentor hadoop reply thret 9 hours agorootparentprevBoeing are a major defence contractor, I&#x27;m sure at least some of the information is secret. reply newuser94303 8 hours agorootparentA defense contractor should have better security reply martinsnow 2 hours agorootparentReally reply johann8384 9 hours agorootparentprev> nobody is flying an airplane that only &#x27;works&#x27; 99.99% of the timeThe 737 Max 8. reply deaddodo 3 hours agorootparentAlready addressed in another thread:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38358542 reply bozhark 10 hours agorootparentprevAlready had it reply toasted-subs 9 hours agoparentprevYeah the margins in that enterprise are pretty small not something you can franchise. reply ThinkBeat 12 hours agoprevMy memory is not the greatest and simple Google searches are not helping right now.Have there ever been massive problems from one of these leaks for the targeted company?I seem to remember quite a lof of similar leaks over the past two years where the market and public shrug it off.Clearly 45gig is a lot. I would think if there was a major horrible thing to find that Boeing would have paid the ransom (and told no one).Will it have any real negative consequences for Boeing?It is a black mark against them that they were vulnerable. I guess it is favorable point for many that they didn&#x27;t pay. reply Thorrez 5 hours agoparentWhen Sony was hacked by North Korea, the leaked payroll revealed women were paid less than men for the same job. I&#x27;m not sure what the ramifications of that leak were though.https:&#x2F;&#x2F;slate.com&#x2F;human-interest&#x2F;2014&#x2F;12&#x2F;sony-pictures-hack-... reply jacekm 10 hours agoparentprevCompetition will love to have a look at this data but obviously they won&#x27;t announce it to the whole world that they are digging through the files. One day Airbus will build a new plane before Boeing or just win a lucrative contract and we will never know whether this happened naturally or because of the knowledge they got from this data. reply Denvercoder9 10 hours agorootparentAirbus won&#x27;t touch this data with a 90ft pole. Their lawyers will make sure of that, as even just downloading it opens them up to tons of lawsuits.The ones looking at this will be China, Russia and their associates that don&#x27;t care about (Western) law. reply omnimus 10 hours agorootparentAirbus is not a person but a company. Of course some of the employees will look at this data. They will all pretend that they dont but companies pay for industry secrets why would they stay away from free ones. reply TillE 9 hours agorootparentRandom low-level employees looking at stuff out of curiosity won&#x27;t have the power or even the motive to act on that data.For higher-level people it really just isn&#x27;t worth the risk, unless there&#x27;s some incredibly valuable secret. reply PedroBatista 10 hours agorootparentprevTo be fair, 60s tech is widely known and Boeing would profit much more from Airbus tech than the other way around.Let&#x27;s not even bring project Echelon into this.. reply dghlsakjg 4 hours agorootparentI didn’t know that Boeing was making carbon fiber wide bodies like the 787 back in the 60s… reply aborsy 9 hours agorootparentprevYou can download it securely and anonymously. There is no way to find out.Actually, the French government intelligence agency is famous for IP theft. This one is placed at their feet. reply jjeaff 7 hours agorootparentthat doesn&#x27;t matter. if an employee were to read it and perhaps glimpse some trade secret and include that, even inadvertently into a future product, that could open them up for litigation. reply userinanother 6 hours agorootparentprevRumor has it airbus used to have a secure cabinet of Boeing analysis data that people would go reference once in a while in the 90s but I doubt that happens anymore reply m000 10 hours agorootparentprevFor what you don&#x27;t want your direct employees to do, you can always hire a contractor who will do the dirty job and give you the (in this case literal) TL;DR. reply billfruit 7 hours agorootparentprevWhy wouldn&#x27;t Airbus not look into it, Boeing has often acted agressive in getting US government to put tariffs on Airbus. reply raverbashing 9 hours agorootparentprevWhat would Airbus learn from it?How to shoot yourself in the foot with bad management?(On the other hand maybe some other company&#x27;s board went through the docs, hmm) reply vidarh 1 hour agoparentprevMy personal mail is 10GB+ despite having moved providers in the last couple of years.45GB can be a lot, or it can be a couple of people&#x27;s worth of marketing presentations. reply anitil 11 hours agoparentprevI think it would be a problem if people started digging, but I suspect most people just don&#x27;t have the time, inclination, or willingness to take the legal risk. reply gosub100 7 hours agoparentprevI bet the internal emails would be infinitely more valuable than design docs. let&#x27;s see what the last link on the chain (of responsibility) actually said when they were told MCAS wasn&#x27;t working. Let&#x27;s hear how they worded the spin on the first batch of ~150 deaths to do damage control, and then how they reacted to the next. I&#x27;d fire up my popcorn maker for that! reply runeks 43 minutes agoprevNew security-through-obscurity tactic: make sure to automatically send lots of fake emails between employees, containing importantly-sounding words such as \"classified\", \"secret\" and \"important\" — with some identifying characteristic that makes the employees&#x27; email clients ignore them.Then an email dump of 45 GB of useful information could instead be 4.5 TB (with 1% useful information), and wading through all the non-information to find something useful will not be worth the time of the adversary. The more important information you have in emails the more you need to increase the misinformation-to-information ratio. reply kramerger 13 hours agoprevIs there anything \"useful\" in this dump?The article mentions citrix and emails, but that could be anything reply dmix 12 hours agoparentUseful to whom? Email dumps and other data could be useful for further breaches and attacks against personnel. I&#x27;m sure their infosec will be going through everything but they could miss stuff and personal information is exploitable for fraud even with awareness.Govs like China and aircraft&#x2F;defense competitors to Boeing probably got a goldmine if they didn&#x27;t already have their own access. Boeing does plenty of NATSEC and space stuff. reply steponlego 11 hours agoparentprevNow that it&#x27;s out there somebody will doubtless download it and check it out eventually. Stuff that goes onto the Internet rarely goes away. reply jacquesm 10 hours agorootparentExcept when you want to preserve it. reply Gigablah 7 hours agorootparentThere should be a law for this. (Law as in Murphy’s law) reply strangattractor 15 hours agoprevDidn&#x27;t a ransomware gang just renege on a deal and release the data anyway. Seems like they are killing their own business model. If company X cannot depend on the gang delivering why pay in the first place. Boeing will have to pay for any fallout form the data breach - why have the added expense of paying the criminals for the privilege? reply xeckr 9 hours agoparentThis opens up an interesting (albeit highly unethical and illegal) strategy to combat ransomware, which could be implemented by state actors:1. hack targets and hold their data for ransom2. get the ransom and release the data anywayThis would largely discredit the actual ransomware gangs. A way to make this more ethical would be to have the data be insignificant or encrypted. The media will still have their story, and public perception will be changed.An even better way would be to secretly coordinate with the \"targets\" of the hacks, turning the whole thing into a harmless spectacle that nevertheless decreases the incentive to hold data for ransom. reply rdtsc 1 hour agorootparentVery nice. Create something like a lemon market for ransomware. I like it.It always felt funny how these criminal groups in this case have to project an image of trustworthiness and honesty. reply M3L0NM4N 3 hours agorootparentprevThe latter could have been the case here and we would never know... reply asdfman123 12 hours agoparentprevTragedy of the commons. We need to establish a centralized judicial system to identify and shut down bad ransomware actors. reply op00to 12 hours agorootparentlet&#x27;s hold off on advocating for a New World Order just yet. reply asdfman123 9 hours agorootparentNo, this would be a shadow government by ransomware companies to govern other ransomware companies. We can all get along! reply barryrandall 14 hours agoparentprevThey do that all the time. The first ransom is to get the decryption keys to the target&#x27;s data, the second ransom is to prevent them from publishing the decrypted data. reply CivBase 14 hours agorootparentIf they&#x27;re going to publish the data publicly, what do you need decryption keys for? Seems like it&#x27;s basically an all-or-nothing deal to me. reply bretpiatt 13 hours agorootparentPerspective as CEO of a backup and disaster recovery company...A lot of folks now have ransomware protected backups for critical data so they aren&#x27;t paying for decryption keys.This has escalated to hack and release, the attackers are now exfiltrating data and threatening to make it public in addition to encrypting it on the host system. reply sandworm101 13 hours agorootparentprev>> If they&#x27;re going to publish the data publivally, what do you need decryption keys for?Because they will publish the bad stuff, the stuff you really don&#x27;t want public, but likely withhold the boring stuff, the stuff the business really needs to function. And whatever they release might not be in the format that it was taken. reply barryrandall 13 hours agorootparentprevThey only tell you about the second extortion attempt after the success of the first. As I understand it, each gang operates differently, but most are consistent in their approach (e.g. x will always double ransom, but y will never). reply contravariant 13 hours agorootparentprevI think that&#x27;s why you ransom the decryption key first. If I understood correctly. reply gehwartzen 3 hours agoprevOut of curiosity how do you guys mentally interpret the data size when reading about a hack&#x2F;leak story? 45GB? Do you think 10s of millions of text files? A few DVD rips? a server backup?It seems so useless but is always portrayed as the \"wow look at that number!\" part of any leak&#x2F;hack story reply vidarh 1 hour agoparent4x my current inbox, accumulated over 2 years since I moved providers.45GB and a a lot of it&#x27;s just text. If it includes documents, it could be next to nothing. reply riffraff 2 hours agoparentprev\"three times my Gmail inbox accumulated in about 20 years\" reply hadlock 3 hours agoparentprevAt one Very Corporate job I had, there was a file share that somehow had never been culled, had a bunch of coworkers (current and previous) vacation photos, even a couple episodes of seinfield and I think the movie Die Hard. This was pre-snowden and the ripped videos were very pre-snowden. This share was like 8 or 9gb. Two or three .ISOs from a POC (proof of concept) with a vendor could easily push it over 16gb. If they compromised the share the marketing department kept their 2006 era .wma files of the company team building activity from That One Time it might result in not a lot of actual text files. I&#x27;ve had my gmail account for almost as long as you&#x27;ve been able to have one (almost 19 years?) and I&#x27;ve only managed to accrue 17GB in that time. reply ceejayoz 14 hours agoprevI wonder if this counts as an ITAR violation on Boeing&#x27;s part. reply da_chicken 13 hours agoparentHow do you figure that? reply ceejayoz 13 hours agorootparentThere&#x27;s almost certainly ITAR-subject data in a Boeing data dump of this size; I&#x27;m curious as to whether not paying a ransom counts as releasing it. reply estiaan 3 hours agorootparentI really hope this is not the case. Paying randsome is unethical, in some cases it’s also illegal. At best you’re funding a criminal organisation, at worst you’re in collaboration with a criminal organisation.In the case of digital files there is absolutely no guarantee that they delete the file, it’s like paying someone to go back in time.The act has been done, the data is stolen, your negligence and wrongdoing is in the past and the only ethical option is to not fund the bad actors who are actually primarily responsible. reply tgsovlerkhgsel 10 hours agorootparentprevLetting it get stolen in the first place might count, I highly doubt not paying the ransom counts. reply hiharryhere 13 hours agorootparentprevI doubt it. Here in Australia at least companies with large gov contracts are prevented by gov policy from paying ransoms. reply tsujamin 12 hours agorootparentOut of curiosity what&#x27;s the source on that? AFAICS there&#x27;s no clear legislation restricting it (although a lot of talk about such a bill in the future). It is in standard contract terms? reply hiharryhere 9 hours agorootparentSource is a close relative involved in responding to a recent, well publicised data breach.They service several large commonwealth departments and were instructed by them not to pay. reply hug 3 hours agorootparentThey instruct you not to pay, but that instruction has absolutely no binding.The Australian orgs I have deal with in large compromises have universally opted to pay to prevent release, where it was financially feasible. reply ceejayoz 13 hours agorootparentprevIt wouldn&#x27;t be the first catch-22 scenario caused by conflicting laws. reply jacquesm 10 hours agorootparentThe &#x27;easy&#x27; solution is not to let your data leak. reply generic92034 10 hours agorootparentCertainly different companies put a different effort into their IT security measures, but I doubt any of them would claim that their system is \"unhackable\". So, I am not sure that not letting your data leak is an option you can really choose. You might be able to influence the probability of a hack, though. reply brookst 12 hours agorootparentprevI think ITAR covers exporting, which is necessarily intentional. At least I&#x27;m not aware of any espionage victim also being subject to ITAR prosecution. reply kevin_thibedeau 10 hours agorootparentIt also covers reexporting. You&#x27;re still responsible for ITAR and EAR articles after they&#x27;ve been exported and the recipient wants to transfer them somewhere else. reply annoyingnoob 11 hours agorootparentprevIn the case of ITAR, not exporting means limiting access to US persons only. I suspect this could be a violation, even if unintended. reply dymk 11 hours agorootparentprevSize of the dump means nothing, on one extreme it&#x27;s a single 45GB video file of a security camera looking at nothing. reply lesuorac 13 hours agorootparentprevI&#x27;m more curious why failing to secure it doesn&#x27;t count as a ITAR violation. reply kenjackson 9 hours agorootparentI think you need to do reasonable effort. Perfect security doesn’t exist. replyworkfromspace 1 hour agoprevhttps:&#x2F;&#x2F;archive.is&#x2F;LUqeb reply freedude 12 hours agoprev45GB of data could be like a dozen employees&#x27; or less Outlook PST files. For this to be astounding we would need to know the quality of the data. Otherwise it is a bunch of hype and hoopla. reply anitil 11 hours agoparentI&#x27;m not sure about the legality and ethics of training models on stolen data, but for reference, but so far as I can tell the Enron email data set is about 1.5GB (much lower than I expected to be honest!).And I believe some of the more interesting things found in that data set (outside of the fraud) were people cheating on their partners.https:&#x2F;&#x2F;www.kaggle.com&#x2F;datasets&#x2F;wcukierski&#x2F;enron-email-datas... reply justsocrateasin 11 hours agorootparentI do believe that 1.5GB is tarred and gzipped though, so it is a fair bit bigger. That&#x27;s also supposedly half a million emails, so 45gb is quite a bit. reply primax 11 hours agorootparentprevSure, but that was leaked in 2004. A very different time for email, and where attachments were generally smaller. reply jmalicki 10 hours agorootparentThe Enron dataset was not leaked - it was made public by the US government as evidence from an investigation by the Federal Energy Regulatory Commission.https:&#x2F;&#x2F;www.ferc.gov&#x2F;electric&#x2F;industry-activities&#x2F;addressing... reply campbel 11 hours agoparentprevYou better pay up or we&#x27;ll delete all of Marge and Victors email backups! reply justinclift 4 hours agoparentprevCould be the porn stash of the Boeing directors. That could make some of them pretty nervous. ;) reply seventytwo 5 hours agoparentprevI was just gonna say, there’s probably single CFD simulation files that are larger than 45GB. reply legitster 13 hours agoprevI struggle to see how this business model would work in the first place. They pay you and you pinky swear not to release it? All you are doing by negotiating is to buy the victim time to harden their systems.This sounds liked a failed ransomware attack. They encrypted the systems - Boeing says \"no thank you, we have backups\". There were no valuable zero-days to sell to GRU, so give a last ditch offer to try to salvage something. reply RandallBrown 13 hours agoparent> They pay you and you pinky swear not to release it?Yes. If any of this information does end up getting leaked, it kills the credibility of the ransomware group and they&#x27;ll never get paid again. Sort of mutually assured destruction.Now of course, most people don&#x27;t really trust criminals anyway so the business has a pretty strong bargaining position and I believe many of the ransoms are negotiated way down. reply tanelpoder 13 hours agorootparentWouldn&#x27;t it be easy to just pick a new name for the ransomware group then?(or do we need eBay-like \"seller ratings\" and customer reviews for ransomware groups?) reply Jaepa 12 hours agorootparentFrom what I understand there&#x27;s a market for ransomware negotiators, and reputation (and tooling) is very much a thing that affects settled price.Understand: For the ransomer&#x27;s point of view this is another monday, albeit one where a big fish walked away. reply FirmwareBurner 12 hours agorootparentSo there&#x27;s honor among thieves. reply barryrandall 12 hours agorootparentOnly to the extent that they derive value from being perceived as consistent. reply ben_w 12 hours agorootparentprevThere&#x27;s an iterated prisoner&#x27;s dilemma, I wouldn&#x27;t go as far as calling that honour. reply GuB-42 12 hours agorootparentThat&#x27;s fundamentally what honor is. reply ben_w 12 hours agorootparentThe result may be the same, but I think honour requires a state of mind where you do the \"honourable\" thing even if nobody will know. reply __MatrixMan__ 11 hours agorootparentAgreed. Honor may have its roots in a prisoner&#x27;s dilemma, but you&#x27;re not actually practicing it until you have Stockholm syndrome. reply deaddodo 3 hours agorootparentprev\"states of mind\" are all externally influenced. If you have a fundamentally \"honorable\" mindset, it&#x27;s because your history has reinforced that acting honorable nets you an overall positive outcome.Which just reinforces the \"honor = iterative prisoner&#x27;s dilemma\" argument. replyLastTrain 9 hours agorootparentprevI’m not doubting this - but can you provide anything to substantiate that reputable ransomeware negotiators are a thing? [edit - nm I googled it, it’s a thing] reply red-iron-pine 13 hours agorootparentprevDepends on what their SOP is. Attribution is hard but there are a lot of really, really smart people trying really hard to identify orgs by their TTPs.You can rebrand as CaTBUTT, or Indrik Spider 2.0, or whatever, but if you&#x27;re using some custom version of Mirai they&#x27;ll eventually tag your M.O. and the threat intelligence briefings will reflect that.And then no ransom. reply tanelpoder 13 hours agorootparentDidn&#x27;t think of that, thank you. reply Exuma 12 hours agorootparentprevWhat is Mirai? Can you re-explain what you said in plain english? reply red-iron-pine 10 hours agorootparentMirai is malware that was written by a college student but their code was released to the public, and a lot of other malware uses it as a base.It (and other malware) tend to behave in specific ways and follow specific patterns, and those patterns can be analyzed. Ditto for the servers they use, targets they hit, etc.These approaches are known as TTPs, and documenting them is how you attribute an attack to a specific group or actor. Even if you change your org and start using servers in a different country eventually your MO will give you away.These approaches are cataloged by IT security types, and many cybersecurity orgs release publications about Group X using approach Y.So when you get hacked by Group Z, but they sound like X and Y, you guess it was them. And if Group X has a history of burning ransom payers then you don&#x27;t pay -- they&#x27;d fuck you anyway, so save the money and start rebuilding. reply Exuma 8 hours agorootparentVery interesting.. so what makes Mirai so important as a base that they can&#x27;t just rewrite it of sorts? Is it just a lot of work&#x2F;boilerplate? Or would it be too time consuming to rewrite some base code so the fingerprint is different? reply not2b 12 hours agorootparentprevYou could have Googled it, but you can start with https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mirai_(malware) replyceejayoz 13 hours agorootparentprevA no-name ransomware group is less likely to be trusted to hold up their end of the bargain than one with an established reputation.Didn&#x27;t Silk Road have eBay-style ratings&#x2F;reviews? reply jeron 13 hours agorootparentWhat good are the reviews? “5 stars, didn’t leak data after ransom paid” reply barryrandall 13 hours agorootparentIt&#x27;s more like, \"Security Company X says this gang has behaved predictably in their previous interactions.\" reply csydas 12 hours agorootparentprevSilkRoad was a dark web market, so the comparison from the parent is a bit strange for me, but regarding your comment on reviews, yes they&#x27;re very important and for the sites I&#x27;ve used, the reviews have been very reliable and useful.My understand is that since it&#x27;s a much more limited market, access is very difficult even under normal circumstances (not because of security but just because dark web markets usually have awful performance for various reasons), so it&#x27;s a far different review landscape than say shopping on Amazon, at least the ones I have used. The markets themselves were fantastic about refunds&#x2F;conflict resolution, better than most normal online shops. Reputation is key for basically everything dark web, and the main actors in this space are notoriously petty and bold towards anyone that makes it harder to conduct business.I imagine it&#x27;s very similar with Ransomware as there has to be some reason for the targets of the attack to believe paying the ransom is worth it, and anyone who upsets that balance for the ransomware gangs unexpectedly becomes rapidly unpopular, and usually a target for the other gangs. It very much so is heavily relying on the honor system, but it seems the groups are committed to such a system. reply yieldcrv 12 hours agorootparentprevall the darknet markets have eBay style ratings, but for the vendor and products purchased, not for reviews on negotiating with a randomware group that weaponized itSilk Road was 10 years ago that would have been like the smallest one ever since then, just curious why it is referenced at all, and in such an odd way“I heard eBay has bulletin board like reviews” you know you can just go look, in a web browser “woah thats crazy talk, I prefer 10 year old hearsay”anyway, they often have a separate forum where one could ask more about a group reply progmetaldev 7 hours agorootparentMost people are inexperienced with the dark web. I would hazard a guess that even most of the HN crowd, as far as having actually used the dark web. There is a lot of fear and misinformation, even when it comes to a tech-literate crowd. People fear government agencies infiltrating the servers that they might visit, and that server dropping malware&#x2F;spyware that reveals their identity. Even just having your name associated with visiting a darknet market could be disastrous for your reputation, and I assume this is the line of thinking most people give to the idea of visiting these servers. Unfortunately, this line of thinking keeps people away, which actually reduces the ability to stay anonymous as compared to having lots of traffic moving through Tor. reply yieldcrv 6 hours agorootparentits fascinating how media driven this is if people are still talking about the silk road based on its media coverageDepartment of Justice and Europol have lots of press releases about other markets and busts and ways they failed to bust them, and how their size eclipsed Silk RoadI guess as long as the media doesnt parade it around or makes movies about it nobody knows reply barryrandall 13 hours agorootparentprevThey&#x27;d need to burn all their tools, techniques, and practices for this kind of rebrand to be successful. reply adolph 13 hours agorootparentprev5 star would hostage againSuperhost for my datas reply echelon 13 hours agorootparentAmazing satire, but I shudder to think that&#x27;s how companies actually treat ransomware.All companies and governments should take the stance that any randomwared or compromised data is now public. And if they don&#x27;t have the backups, then they should consider it permanently lost.Write it off as a business loss and hire better ops people. reply tonyarkles 11 hours agorootparent> All companies and governments should take the stance that any randomwared or compromised data is now public.That&#x27;s a somewhat reasonable stance. You definitely have no guaranteed assurance that it won&#x27;t be leaked. However... depending on what you do have set up, you may have some reasons to believe that 45GB of encrypted data has not left your internal network (i.e. was only encrypted-in-place)> And if they don&#x27;t have the backups, then they should consider it permanently lost.That&#x27;s easy to say but way harder in practice. If the data in question is the design artifacts from a billion dollar project... it&#x27;d be a pretty hard sell to convince everyone \"woops, we fucked up, billion dollars gone, time to close the doors and go home, we definitely shouldn&#x27;t consider paying $500k or $1M or whatever they want to get all this data back\". reply dkjaudyeqooe 12 hours agorootparentprevGovts should make funding ransomware groups a criminal offense. The money likely going to RU and NK anyway. reply tatersolid 5 hours agorootparentOFAC has made paying many ransomware deploys illegal in the USA for several years.https:&#x2F;&#x2F;ofac.treasury.gov&#x2F;recent-actions&#x2F;20210921 reply sweetjuly 10 hours agorootparentprevThat probably wouldn&#x27;t have a good outcome. If a company gets hit very hard, their options are either to pay or die. If you make it illegal to pay, their options are either to commit a crime (which will not kill the company even if they get caught) or die. All this will do is push companies into hiding when they get hit and not reaching out to the government and security companies for help, which makes catching these groups way harder. So, at best you kill some domestic businesses and at worst you kill domestic businesses AND help the attackers hit more companies. reply dkjaudyeqooe 9 hours agorootparentTo the contrary: the first company to die (or so) would set a fire under any companies who were not prepared. It&#x27;s complacency and ignorance that creates problems.The attackers attack for money, not to kill their prey, that&#x27;s not profitable. reply octacat 10 hours agorootparentprevOptions to configure backups and spend the money on isolating their network and computers to begin with are not considered. replytgsovlerkhgsel 10 hours agorootparentprevIt would, but publishing the data of someone who paid gives the ransomware gang almost nothing, and the downside would be to start as a no-name.On the other hand, holding their side of the promise allows them to build a reputation, which makes it easier to get future victims to pay. Why would they leak the data if someone paid? reply paulcole 12 hours agorootparentprevMy brother did this with lawn care and HVAC companies. The first business lesson he learned was never name your business after yourself. He was about 16 when he learned this and ever since it’s been like AAA Lawn Care or Aces HVAC until he gets so many negative reviews he can’t get more business. reply frandroid 12 hours agorootparentSo lesson of the story, avoid the AAA named companies because they&#x27;ve been in the respawning business for a long time reply jstarfish 11 hours agorootparentNah, back in the old days A1 Locksmith or AAA Windshields were just competing for top placement in the (alphabetized) phone book.Look to Amazon for new ideas on DGA-derived names for your fly-by-night business. reply magarnicle 6 hours agorootparentThat&#x27;s why Asus isn&#x27;t called Pegasus. reply mr_toad 10 hours agorootparentprevA lot of cowboys used AAA-Something to bring in rubes. reply foxylad 9 hours agorootparentAnd now AI-Something. reply sfink 11 hours agorootparentprevThe lesson is that hiring \"ZZZ Lawn Care\" is a really bad idea. reply paulcole 11 hours agorootparentThis was a plot point in The Accountant starring Ben Affleck.He’s a criminal who launders money through small businesses he owns and the accounting firm he runs. He names it ZZZ Accounting so it doesn’t get a lot of calls through people looking up accountants in phone book. reply Tyr42 11 hours agorootparentprevOr at least the ZZZ corps if they made it that far down the alphabet. reply temporarara 12 hours agorootparentprevYour brother is the hero this world deserves. And this is why I generally trust only those small businesses who have their full real name on display. reply HeyLaughingBoy 11 hours agorootparentYou&#x27;re assuming it&#x27;s their real name... reply paulcole 11 hours agorootparentprevWhen he was a teenager and had a business under his own name he’d get in trouble sometimes because he’d close all the deals himself then hire other kids to go out and do the work.Some homeowners thought it was going to be him cutting their lawns and would get upset because the contract said he’d do it. So he’d just rip up the contract in front of them and refuse to cut their lawn ever again.In Florida there were so many houses with lawns in so many subdivisions he was always busy anyway. Plus he liked getting into fights with adults. Win win, I guess. reply dkjaudyeqooe 12 hours agorootparentprev> it kills the credibility of the ransomware groupThere are review sites for ransomware groups?\"honored promise not to disclose, didn&#x27;t gloat or taunt, would pay again, 10&#x2F;10\" reply arnvald 12 hours agorootparentNot sure about review sites, but there are companies specializing in ransomware negotiations on behalf of the victims and they can advise not to pay a group that is known to release the data anyway reply hot_gril 12 hours agorootparentEither way, seems like something that a government or other actor could mess with, thus making it harder for hackers to profit. reply legitster 13 hours agorootparentprevData ransoms have existed for a long time before \"ransomware\" was even really a thing - there&#x27;s just never been a market for ransoms for the \"stolen\" data. Once it&#x27;s out you can&#x27;t put that genie back in the bottle.The reason ransomware worked was you didn&#x27;t have to trust the group long-term - just enough to give you a copy of your data back.It&#x27;s the difference between you making a copy of my car keys and stealing them. Yes, I will pay for \"a\" key back - I only have to trust you enough to hand it over. reply mcmoor 10 hours agorootparentBut you don&#x27;t only want your data back, you want the data disappear from circulation. While ransomware ensures the former transaction, it still in no way ensures the latter, making it still a dubious transaction. reply mysterydip 13 hours agorootparentprevCouldn&#x27;t the ransomeware group just come back under another alias to clean their slate? reply rtkwe 13 hours agorootparentIf any group does it it kills the credibility new entrants too so there&#x27;s still incentives to not do it. reply cjaybo 13 hours agorootparentAre these rational actors who would even care about the collective long term effects? Eg the same could be said for drug dealers ripping off their customers, but that still happens daily because they often prioritize short term self interest over long term&#x2F;collective concerns. reply NegativeK 13 hours agorootparentMany ransomware groups have learned that acting more like a business results in higher payouts. They&#x27;re not all going to do it, but they have payment portals, negotiators using professional language, attempts to maintain reputation, etc.Obviously this behavior doesn&#x27;t apply to all of them, but it&#x27;s a clear effort by some of them to immediately appear more palatable to random IT worker, the execs, and the lawyers who are watching the who process play out.And it also lines up with the fact that ransomware groups have freaking HR departments to handle their employees. reply rtkwe 12 hours agorootparentprevIt&#x27;s not consistent across the broad category of criminal for sure but they&#x27;re probably not the most long term oriented people as a rule now. Initial groups were more, for a lack of a better word, professional about the process with some groups even having a kind of tech support for helping victims to make sure people would believe they&#x27;d get their files back if they paid. Better preparation on the corporate side and a democratization of the tools to perform it has lead to some changes it looks like where ransomware groups didn&#x27;t exfiltrate often before because it wasn&#x27;t their main playbook. reply csydas 11 hours agorootparentprevYes, mostly because the other actors are notoriously vengeful and petty; ransomware gangs, dark markets, etc, they don&#x27;t just register complaints with each other, they typically look to ensure the bad actors are removed from the space entirely.regarding drug dealers, I wouldn&#x27;t consider it a good comparison. the actions of one dealer typically doesn&#x27;t affect others, they&#x27;re just not that connected beyond professional recognition&#x2F;courtesy. If dealer A is shorting their customers, dealer B absolutely wouldn&#x27;t care as why would they? they have no relationship, and it&#x27;d probably mean the customers go to dealer B instead. business will continue as usual even if one bad actor is doing shitty stuff to their customers.with ransomware that is not the case -- if public opinion overwhelmingly tells there&#x27;s no sense in paying because the ransomware gangs never follow their word, that affects all the gangs, not just the bad actor. the gangs already have a hard enough argument to make as to why the targets should pay so anything that frustrates that further is frowned upon. reply galangalalgol 13 hours agorootparentprevAnd Boeing could never know Airbus hadn&#x27;t been given the opportunity to buy the data, as they would never disclose that. reply callalex 13 hours agorootparentprevBy that logic, illicit food and drugs wouldn’t have a problem of being cut with fillers. A tragedy of the commons doesn’t really reign in the behavior of criminal organizations. reply neodymiumphish 10 hours agorootparentprevOnly if they completely rebuild their malware and infrastructure so that researchers can&#x27;t correlate them together. reply micromacrofoot 13 hours agorootparentpreva clean slate also means rebuilding reputation reply mvkel 12 hours agorootparentprevMeh. They don&#x27;t knowingly release it. But they could certainly continue to try to sell the data on the black market to competitors, etc, which the competitor would never disclose. reply bastawhiz 12 hours agorootparentprev> it kills the credibility of the ransomware group and they&#x27;ll never get paid againI don&#x27;t buy it. There&#x27;s nothing to stop the group from rebranding themselves. The company has no proof nobody else got a copy of the data. And the group could simply hang onto the data, extort a bunch of money from other companies, then start back at the beginning and demand even more (knowing that the data is worth _at least_ what was already paid for it). reply sofixa 12 hours agorootparent> I don&#x27;t buy it. There&#x27;s nothing to stop the group from rebranding themselvesApart from the fact that nobody would pay them if they have no reputation. reply raincole 12 hours agorootparentThen how did they get \"reputation\" from the first place? Quite chicken and egg problem, right? reply hot_gril 12 hours agorootparentBy starting with smaller ransoms. Same way any new business gets off the ground without rep, it&#x27;s not easy or very profitable at first. reply tshaddox 12 hours agorootparentprevSurely that can&#x27;t be completely true. The reputation has to be bootstrapped somehow. reply neodymiumphish 10 hours agorootparentprevNew groups can&#x27;t demand as much as the next. Also most of the big groups are RaaS (Ransomware as a Service), meaning their affiliates get approval to operate using LockBit&#x27;s name, infrastructure, and software.If LockBit does something to taint their image in the media and among security organizations, then rebrands to avoid their negative history, forensics will still eventually tie their new name back to their old org, and victim&#x27;s will have to decide whether they should trust that their data will be handled correctly after payment.As for re-victimizing old organizations, there&#x27;s almost zero chance of that working. Most data is only sensitive for a certain time frame, long enough that they can make the proper notifications, change credentials, etc.Lastly, there still needs to be someone to download and abuse the data they leak. I&#x27;ve monitored ransomware torrents a few times and not observed any downloads completed over the course of a couple weeks following a data leak. reply jowea 13 hours agorootparentprevI wonder why they don&#x27;t make into a recurring payment instead of a one time deal. Turn it into an iterated game theory game. reply timeon 13 hours agorootparentRaaS reply neodymiumphish 10 hours agorootparentThat&#x27;s not what this means. reply augustulus 12 hours agorootparentprevmore risk of exposure presumably reply ibejoeb 11 hours agorootparentprev> I believe many of the ransoms are negotiated way down.LockBit just did a sort of collective bargaining with affiliate groups that resulted in guidance for setting initial ransom amounts and rules restricting discounts about 50%. reply kspacewalk2 13 hours agorootparentprev>credibility of the ransomware groupHilarious. reply waynesonfire 12 hours agorootparentIt&#x27;s your naive comment that I find hilarious. it&#x27;s a business like any other that puts food on peoples plates. in fact, a mature business with a deep and sophisticated industry. it benefits all participants when everyone behaves reliably and predictably. These aren&#x27;t amateurs. reply miohtama 12 hours agorootparentprevI am sure there are discreet nation state buyers, like Russia and China, who are happily to use the information without causing an incident. Russia does not even need to ask, as most ransomware gangs operate under the blessing of Putin. reply justsomehnguy 11 hours agorootparent[citation needed]At least for &#x27;most&#x27;. reply miohtama 2 hours agorootparentIt’s in news https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;russia-based-ransomware-g... reply JohnFen 13 hours agorootparentprev> it kills the credibility of the ransomware groupThere are people who consider these groups credible?? The world really has gone insane. reply neodymiumphish 10 hours agorootparentMany of these groups have better bug bounty programs, SOPs, and organizationsla structure than your average company. reply RandallBrown 9 hours agorootparentprev\"Credible\" here means that they stick to their word. reply willseth 13 hours agoparentprevYou&#x27;d think that, but in practice these ransomware groups are pretty reliable, and actually many rasomees have remarked on how good the customer service is! Their ability to make money is dependent on them maintaining a reputation for being in the business for money, not lulz, and tmk the pinky swears are typically upheld. reply jameson 11 hours agorootparent> in practice these ransomware groups are pretty reliableHard to say...You&#x27;re effectively trusting the liar they wont lie againIts possible they leak it to high profile customers without publicly announcing itBusiness should make decision assuming the data will be leaked eventually regardless of random paid or notPerhaps only thing business can assume is the data wont be publicly released in short amount of time reply hnthrowaway0315 13 hours agoparentprevI wouldn&#x27;t be surprised if some ransomeware gangs are frontends of national (in)security agencies. They don&#x27;t care about profits. Sure it&#x27;s good to have some. reply jasonwatkinspdx 13 hours agorootparentIt&#x27;s an open secret that FSB et all work with ransomware gangs. As long as they don&#x27;t target Russian companies they don&#x27;t care what they do otherwise. So it&#x27;s not so much they&#x27;re a front as they&#x27;re in a sort of quasi officially sanctioned middle ground. reply sofixa 12 hours agorootparentAs an example, the DarkSide malware (the one used against the Colonial Pipeline) explicitly checks if it&#x27;s running on a computer in the CIS (Russia+countries nostalgic of the Soviet Union &#x2F; without a better choice) and exits. reply prmoustache 3 hours agorootparentWell, this doesn&#x27;t mean they work for FSB but rather they want to stay away from them.If I was based in a country I would not want to target those that can more easily get me into jail and&#x2F;or kill me.I have no idea if FSB work for them, this is more speculation than open secret, but they certainly do tolerate them and see them in a good eye as long as they target western companies and agencies. The enemy of my enemies is my friend. reply jasonwatkinspdx 7 hours agorootparentprevOh interesting, I&#x27;d not heard that. Thanks. reply hnthrowaway0315 13 hours agorootparentprevYeah. I&#x27;m also thinking about ways to \"promote\" malware without getting impacted.Let&#x27;s say some three digit agencies create sort of malware distribution forums in the darknet. They make sure to only broadcast to people who wants to play with malwares so the net catches the \"bad guys\" mostly, except for a few curious researchers or journalists maybe. Then they start to share recent generarion malwares they created. They don&#x27;t need to distribute them by themselves because they already have the CCC servers. Some malware gangs would eventually be the frontend and start the distribution.In this way you not only distribute the malwares without getting impacted, you also get to know the gangs so whenever you want to catch a few fishes you just pull the net.Once the darknet forum dies out or they need to wipe the records, they would just leave and create a new one.Just my wild thought. reply terminous 13 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Letter_of_marque reply r00fus 13 hours agorootparentprevDigital privateers reply sfink 11 hours agorootparentprevprivateers reply kramerger 13 hours agorootparentprevWell, every time Boeing tried to bribe a country, someone leaked emails and audio recordings from their secret meetings.Usually we blame the Chinese, but in this case I think its a toss between CIA and NSA.(I think I&#x27;m on some kind of list now)Edit: I am an idiot. I was thinking of Airbus, see @perihelions comment below reply perihelions 13 hours agorootparentWhich incident are you referring to? The NSA took credit for hacking Airbus, but that&#x27;s Boeing&#x27;s foreign competitor—not Boeing.https:&#x2F;&#x2F;www.economist.com&#x2F;special-report&#x2F;2003&#x2F;06&#x2F;12&#x2F;airbuss-...- \"According to a European Parliament report, published in 2001, America&#x27;s National Security Agency (NSA) intercepted faxes and phone calls between Airbus, Saudi Arabian Airlines and the Saudi government in early 1994. The NSA found that Airbus agents were offering bribes to a Saudi official to secure a lion&#x27;s share for Airbus in modernising Saudi Arabian Airlines&#x27; fleet. The planes were in a $6 billion deal that Edouard Balladur, France&#x27;s then prime minister, had hoped to clinch on a visit to see King Fahd in January 1994. He went home empty-handed.\"- \"James Woolsey, then director of the Central Intelligence Agency, recounted in a newspaper article in 2000 how the American government typically reacted to intelligence of this sort. “When we have caught you [Europeans]...we go to the government you&#x27;re bribing and tell its officials that we don&#x27;t take kindly to such corruption,” he wrote. Apparently this (and a direct sales pitch from Bill Clinton to King Fahd) swung the aircraft part of the deal Boeing&#x27;s and McDonnell Douglas&#x27;s way.\" reply kramerger 13 hours agorootparentYou are correct. I think my brain was on a break while I was writing that :) reply emodendroket 13 hours agorootparentprevWhy exactly would the CIA or NSA want to do that? Boeing works so closely with the security apparatus they&#x27;re practically an unofficial member so I don&#x27;t understand what the motivation would be. reply hnthrowaway0315 12 hours agorootparentIt doesn&#x27;t hurt to hack into any corporation. You never know what kind of intelligence you might get out. There are also considerations of different factions I guess. reply emodendroket 11 hours agorootparentBut we&#x27;re not talking about getting information and keeping it but actually making it public. One doesn&#x27;t get much leverage that way so the only real aim would seem to be damaging the target. reply bee_rider 13 hours agorootparentprevI imagine at least some (probably many) of the engineers who work for Boeing have a basically lawful-good&#x2F;lawful-neutral temperament and are just disgusted by things like bribery. Maybe one of the parties in the conversation leaked it, no intelligence agencies needed. reply beambot 13 hours agorootparentprev> How North Korea’s Hacker Army Stole $3 Billion in Crypto, Funding Nuclear Programhttps:&#x2F;&#x2F;www.wsj.com&#x2F;articles&#x2F;how-north-koreas-hacker-army-st... reply nimih 12 hours agorootparentprev> They don&#x27;t care about profits.This isn&#x27;t really true in general: intelligence agencies often want access to funds with less&#x2F;no oversight from (or to skirt controls enacted by) other parts of the government. As an example, that was the dynamic at the basis of the Iran-Contra affair in the US. reply jowea 13 hours agorootparentprevFor North Korea sure quite believable. Some links existing also sound likely for the Russian gangs. reply jasonfarnon 12 hours agoparentprevWhat benefit is it to the ransomware group to release the data? They may be sloppy or careless with their data (like their victims) but I don&#x27;t see a for-profit&#x2F;non-ideological ransom group reneging and intentionally leaking the data. And plenty of reasons eg repeat actors to do their best not to.Actually I&#x27;m often surprised that many ransomers&#x2F;hostage-takers go through with their threats when they don&#x27;t get their demands. The only reason I can see them doing it is if reputation matters to them for future negotiations. more than the risks from the greater liabilities they incur by going through with the threats. reply michaelt 12 hours agorootparentThe benefit would be getting paid a second time, by extracting a second ransom.It doesn&#x27;t have to be the whole group; perhaps one guy decides to branch out on his own, and grabs the data on his way out the door. reply jasonfarnon 12 hours agorootparentYou mean \"yeah we were lying yesterday about this same thing, but we&#x27;re telling the truth right now\" type of negotiation? Has that ever worked for ransoms (of any kind) anywhere? reply NoPicklez 10 hours agoparentprevIt&#x27;s a business model that has certainly been working. If your business has been crippled due to your systems having been encrypted then you do often consider paying the ransom.However if you have adequate backup and recovery mechanisms in place then you&#x27;re not the best to prey on.It&#x27;s a business model that works until the majority of targets have appropriate backup and recovery processes. reply emodendroket 13 hours agoparentprevYou could say the same about any \"ransom\"-based business, really. Kidnappers could decline to release the kidnapped person after they get their money. reply JohnFen 13 hours agorootparentAnd they often do. reply emodendroket 11 hours agorootparentYet it is not unusual for the ransoms to be paid. reply matthewdgreen 13 hours agoparentprevThat’s why you secret share the data across six Intel SGX instances using software that only reveals the plaintext if it doesn’t receive a blockchain-based payment after 30 days. (No, nobody does this. But they could!) reply adriancr 12 hours agorootparentwhy would anyone trust the data is only on those instances? reply matthewdgreen 12 hours agorootparentBecause you write your ransomware to encrypt to a hardcoded set of public keys that include an SGX attestation from those instances. This can be verified forensically and the unencrypted plaintext never leaves the victim organization. reply adriancr 11 hours agorootparent> hardcoded set of public keys that include an SGX attestation from those instances.You mean:1. generate a public&#x2F;private key in enclave2. generate attestation from SGX enclave with public key hash.3. seal the public&#x2F;private key somewhere so it can be reused later, otherwise pc restart or app failures &#x2F; no data.4. publish source code that generates mrenclave somewhere that can be audited.5. encrypt in place and assume remote trusts you when you say data was only exfiltrated encrypted or not at all.Now, 5 is the problem i mentioned. Why would anyone trust that data was not exfiltrated unencrypted and copied a few times.> and the unencrypted plaintext never leaves the victim organization.You also mentioned this to be fair. Why would this be trusted?6. Release data if no payment on bitcoin.SGX enclaves do not have magic trusted access to network to get bitcoin payments data.It can be man in the middled or fooled by omission by who controls machibe.So key can be releases by feeding it bad data (payment was not done and time expired - release to the world).There&#x27;s also the problem that attestation might lead to the originating group if cpu is identifiable. reply matthewdgreen 11 hours agorootparentMalware encryptors can be left on the system for forensic investigation to discover. You’re correct that there’s no perfect guarantee the ransomware group didn’t also exfiltrate data using another method, but that would be kind of stupid; the idea of this would be to reduce a hard problem (trust a criminal to secure your data and eventually safely delete it) to a simpler problem (trust a criminal group not to do something economically irrational that also requires extra work and stealth at infection time.) You don’t need network access to verify a PoW blockchain transcript is correct, provided the cost of forging that blockchain segment is high enough (plus you can script payment redemption so it requires a signature from the enclave attesting that the information was destroyed.) I’m pretty sure a resourceful ransomware group can source a few motherboards and CPUs that can’t be traced back to them. reply crotchfire 12 hours agorootparentprev...and then Intel will simply have their HSM sign the cheat-code firmware for the EPIDs of those six chips.Trust isn&#x27;t all-or-nothing. When I ride a bus I&#x27;m trusting the driver with my life, but I wouldn&#x27;t trust them to babysit my kids.Mutability is deniability. I don&#x27;t trust hardware companies with that. And I don&#x27;t have to, either.Stop hawking this SGX snakeoil. Except maybe to ransomware authors, who deserve what they&#x27;ll get. reply matthewdgreen 11 hours agorootparentIntel could presumably help the ransomware authors bypass SGX protections but that’d be dumb. They might have some capability to trace attestations to a specific motherboard but I doubt any sophisticated ransomware group will be foiled by this. reply crotchfire 8 hours agorootparentI was implying that Intel would help the victims.Attestations are quite certainly traceable to the EPID, which is a fuse array -- it&#x27;s on the die, not the motherboard. In order to attest, the key that encrypts the victim&#x27;s data would have to be SGX-generated. What kind of RNG do you think it uses? Maybe Dual_EC_DRDBG? reply Dylan16807 4 hours agorootparentHelp the victims how? If the CPUs have been captured, there&#x27;s no need for altered firmware. If the CPUs have not been captured, then how is the altered firmware going to get installed?I suppose it helps them in the former case, if they also had no backups. But the hackers are already in a very bad place if the CPUs get captured, so I don&#x27;t think they care about SGX at that point. The hackers don&#x27;t need to trust SGX. They only need the victims to trust it. replypcurve 8 hours agoprevThe market seems to think this is inconsequential. reply 1-6 12 hours agoprevThe moment a company pays good money, that legitimizes the hacking group and emboldens them to keep going. You can’t trust that they’ll not leak even after they get paid. reply 2OEH8eoCRo0 14 hours agoprevBeing a Russian-linked cyber gang, anything sensitive in there should be treated as public information now anyway. Why bother paying then? reply monkeydust 2 hours agoprevLLM training fodder? reply worthless-trash 8 hours agoprevI have grown respect for boeing after not paying this. reply ars 13 hours agoprevThe US should make it illegal to pay ransom, with a penalty of prison for anyone paying a ransom or authorizing payment.The purpose of the law is that now ransomware gangs will be less likely to target US companies because companies are unlikely to risk paying them. reply ironmagma 13 hours agoparentIt&#x27;s maybe already illegal[1][2].That doesn&#x27;t stop companies from paying for it. If you&#x27;re a hospital, you&#x27;re weighing breaking the letter of the law with killing a bunch of people.[1] https:&#x2F;&#x2F;www.gma-cpa.com&#x2F;technology-blog&#x2F;paying-ransom-on-a-r...[2] https:&#x2F;&#x2F;cbs12.com&#x2F;news&#x2F;cbs12-news-i-team&#x2F;hospital-ransomware... reply gregwebs 13 hours agorootparentPaying ransomware is not in any way illegal in the United States. Making payments to sanctioned entities (ransomware or otherwise) is. If companies go to their insurer, etc, they will probably get help to do the compliance to check to see if the payment requested would go to an OFAC sanctioned entity or not. reply bee_rider 12 hours agorootparentIs the duty to make sure you know you aren’t paying to a sanctioned entity, or is it to not know whether or not you are?Given the sources of many of these attacks, one should reasonably assume they are likely to be doing business with a sanctioned entity, right? reply gregwebs 11 hours agorootparentThere isn&#x27;t necessarily a way to know who you are actually dealing with. Maybe in some cases there might be some information to figure this out to some degree. But normally the only information that is certain is where the payment is going. Which is just a bitcoin wallet address. reply bee_rider 12 hours agorootparentprevIf you aren’t a hospital, you are helping the ransomware gangs amortize the cost of their R&D. Thus directly helping those who hit hospitals, and, as a result, contributing to those deaths. reply phpisthebest 13 hours agoparentprevNo I did not pay a ransom, I paid a 7 figure consulting fee to a cyber security company not based in the US, who somehow magically resolved the issue for us... reply ploum 13 hours agoparentprev— If you don’t give me 10k$, I will tell the authorities that you have paid a ransom of 100k$. — Ok, here’s the money. — Thanks. If you don’t give me 10k$ more, I will tell the authorities about our previous deal. reply M3L0NM4N 3 hours agorootparentThat&#x27;s stupid. If you don&#x27;t actually pay them, there would be no evidence of you paying them. Their case would hold absolutely no water. reply smith7018 12 hours agoparentprevThere are instances where that doesn&#x27;t make sense. For example, there was that plastic surgery office that got hacked a couple weeks ago. I get why they think it&#x27;s better to at least try to prevent such private information from getting out. making it illegal to pay the ransom means that every patients&#x27; medical history and pre&#x2F;post op photos would be leaked. That&#x27;s a nightmare. reply 77 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Boeing, a major aircraft industry player, has fallen victim to the LockBit ransomware group, which has ties to Russia.",
      "LockBit demanded a ransom from Boeing and, when the company refused to pay, the group released approximately 45 GB of sensitive company data online.",
      "The leaked information includes corporate emails and files from Citrix, a cloud computing company. Experts are concerned about potential wider consequences because of Boeing's integration with Aviall, a parts distributor it acquired in 2006."
    ],
    "commentSummary": [
      "The discussion focuses on the ransomware attack on Boeing, its implications for national security, and the leaked data.",
      "There is a conversation about the transparency of costs in supplier contract negotiations and the challenges of evaluating aircraft safety.",
      "The trustworthiness of ransomware groups, legality and consequences of paying ransoms, and motivations and tactics of the groups are also discussed."
    ],
    "points": 497,
    "commentCount": 334,
    "retryCount": 0,
    "time": 1700506038
  },
  {
    "id": 38346869,
    "title": "OpenAI's Misalignment Raises Concerns Over Microsoft's Growing Influence",
    "originLink": "https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/",
    "originBody": "OpenAI’s Misalignment and Microsoft’s Gain Posted onMonday, November 20, 2023Monday, November 20, 2023 Author by Ben Thompson I have, as you might expect, authored several versions of this Article, both in my head and on the page, as the most extraordinary weekend of my career has unfolded. To briefly summarize: On Friday, then-CEO Sam Altman was fired from OpenAI by the board that governs the non-profit; then-President Greg Brockman was removed from the board and subsequently resigned. Over the weekend rumors surged that Altman was negotiating his return, only for OpenAI to hire former Twitch CEO Emmett Shear as CEO. Finally, late Sunday night, Satya Nadella announced via tweet that Altman and Brockman, “together with colleagues”, would be joining Microsoft. This is, quite obviously, a phenomenal outcome for Microsoft. The company already has a perpetual license to all OpenAI IP (short of artificial general intelligence), including source code and model weights; the question was whether it would have the talent to exploit that IP if OpenAI suffered the sort of talent drain that was threatened upon Altman and Brockman’s removal. Indeed they will, as a good portion of that talent seems likely to flow to Microsoft; you can make the case that Microsoft just acquired OpenAI for $0 and zero risk of an antitrust lawsuit. 1 Microsoft’s gain, meanwhile, is OpenAI’s loss, which is dependent on the Redmond-based company for both money and compute: the work its employees will do on AI will either be Microsoft’s by virtue of that perpetual license, or Microsoft’s directly because said employees joined Altman’s team. OpenAI’s trump card is ChatGPT, which is well on its way to achieving the holy grail of tech — an at-scale consumer platform — but if the reporting this weekend is to be believed, OpenAI’s board may have already had second thoughts about the incentives ChapGPT placed on the company (more on this below). The biggest loss of all, though, is a necessary one: the myth that anything but a for-profit corporation is the right way to organize a company. OpenAI’s Non-Profit Model OpenAI was founded in 2015 as a “non-profit intelligence research company.” From the initial blog post: OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact. We believe AI should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible. The outcome of this venture is uncertain and the work is difficult, but we believe the goal and the structure are right. We hope this is what matters most to the best in the field. I was pretty cynical about the motivations of OpenAI’s founders, at least Altman and Elon Musk; I wrote in a Daily Update: Elon Musk and Sam Altman, who head organizations (Tesla and YCombinator, respectively) that look a lot like the two examples I just described of companies threatened by Google and Facebook’s data advantage, have done exactly that with OpenAI, with the added incentive of making the entire thing a non-profit; I say “incentive” because being a non-profit is almost certainly a lot less about being altruistic and a lot more about the line I highlighted at the beginning: “We hope this is what matters most to the best in the field.” In other words, OpenAI may not have the best data, but at least it has a mission structure that may help idealist researchers sleep better at night. That OpenAI may help balance the playing field for Tesla and YCombinator is, I guess we’re supposed to believe, a happy coincidence. Whatever Altman and Musk’s motivations, the decision to make OpenAI a non-profit wasn’t just talk: the company is a 501(c)3; you can view their annual IRS filings here. The first question on Form 990 asks the organization to “Briefly describe the organization’s mission or most significant activities”; the first filing in 2016 stated: OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. We think that artificial intelligence technology will help shape the 21st century, and we want to help the world build safe AI technology and ensure that AI’s benefits are as widely and evenly distributed as possible. Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way. Two years later, and the commitment to “openly share our plans and capabilities along the way” was gone; three years after that and the goal of “advanc[ing] digital intelligence” was replaced by “build[ing] general-purpose artificial intelligence”. In 2018 Musk, according to a Semafor report earlier this year, attempted to take over the company, but was rebuffed; he left the board and, more critically, stopped paying for OpenAI’s operations. That led to the second critical piece of background: faced with the need to pay for massive amounts of compute power, Altman, now firmly in charge of OpenAI, created OpenAI Global, LLC, a capped profit company with Microsoft as minority owner. This image of OpenAI’s current structure is from their website: OpenAI Global could raise money and, critically to its investors, make it, but it still operated under the auspices of the non-profit and its mission; OpenAI Global’s operating agreement states: The Company exists to advance OpenAI, Inc.’s mission of ensuring that safe artificial general intelligence is developed and benefits all of humanity. The Company’s duty to this mission and the principles advanced in the OpenAI, Inc. Charter take precedence over any obligation to generate a profit. The Company may never make a profit, and the Company is under no obligation to do so. The Company is free to re-invest any or all of the Company’s cash flow into research and development activities and/or related expenses without any obligation to the Members. Microsoft, despite this constraint on OpenAI Global, was not only an investor, but also a customer, incorporating OpenAI into all of its products. ChatGPT Tribes The third critical piece of background is the most well-known, and what has driven those ambitions to new heights: ChatGPT was released at the end of November 2022, and it has taken the world by storm. Today ChatGPT has over 100 million weekly users and over $1 billion in revenue; it has also fundamentally altered the conversation about AI for nearly every major company and government. What was most compelling to me, though, was the possibility I noted above, in which ChatGPT becomes the foundation of a new major consumer tech company, the most valuable and most difficult kind of company to build. I wrote earlier this year in The Accidental Consumer Tech Company: When it comes to meaningful consumer tech companies, the product is actually the most important. The key to consumer products is efficient customer acquisition, which means word-of-mouth and/or network effects; ChatGPT doesn’t really have the latter (yes, it gets feedback), but it has an astronomical amount of the former. Indeed, the product that ChatGPT’s emergence most reminds me of is Google: it simply was better than anything else on the market, which meant it didn’t matter that it came from a couple of university students (the origin stories are not dissimilar!). Moreover, just like Google — and in opposition to Zuckerberg’s obsession with hardware — ChatGPT is so good people find a way to use it. There isn’t even an app! And yet there is now, a mere four months in, a platform. The platform I was referring to was ChatGPT plugins; it’s a compelling concept with a UI that didn’t quite work, and it was only eight months later at OpenAI’s first developer day that the company announced GPTs, their second take at being a platform. Meanwhile, Altman was reportedly exploring new companies outside of the OpenAI purview to build chips and hardware, apparently without the board’s knowledge. Some combination of these factors, or perhaps something else not yet reported, were the final straw for the board, which, led by Chief Scientist Ilya Sutskever, deposed Altman over the weekend. The Atlantic reported: Altman’s dismissal by OpenAI’s board on Friday was the culmination of a power struggle between the company’s two ideological extremes—one group born from Silicon Valley techno optimism, energized by rapid commercialization; the other steeped in fears that AI represents an existential risk to humanity and must be controlled with extreme caution. For years, the two sides managed to coexist, with some bumps along the way. This tenuous equilibrium broke one year ago almost to the day, according to current and former employees, thanks to the release of the very thing that brought OpenAI to global prominence: ChatGPT. From the outside, ChatGPT looked like one of the most successful product launches of all time. It grew faster than any other consumer app in history, and it seemed to single-handedly redefine how millions of people understood the threat — and promise — of automation. But it sent OpenAI in polar-opposite directions, widening and worsening the already present ideological rifts. ChatGPT supercharged the race to create products for profit as it simultaneously heaped unprecedented pressure on the company’s infrastructure and on the employees focused on assessing and mitigating the technology’s risks. This strained the already tense relationship between OpenAI’s factions — which Altman referred to, in a 2019 staff email, as “tribes.” Altman’s tribe — the one that was making OpenAI into much more of a traditional tech company — is certainly the one that is more familiar to people in tech, including myself. I even had a paragraph in my Article about the developer day keynote that remarked on OpenAI’s transition, that I unfortunately edited out. Here is what I wrote: It was around this time that I started to, once again, bemoan OpenAI’s bizarre corporate structure. As a long-time Silicon Valley observer it is enjoyable watching OpenAI follow the traditional startup path: the company is clearly in the rapid expansion stage where product managers are suddenly considered useful, as they occupy that sweet spot of finding and delivering low-hanging fruit for an entity that doesn’t yet have the time or moat to tolerate kingdom building and feature creep. What gives me pause is that the goal is not an IPO, retiring to a yacht, and giving money to causes that do a better job of soothing the guilt of being fabulously rich than actually making the world a better place. There is something about making money and answering to shareholders that holds the more messianic impulses in check; when I hear that Altman doesn’t own any equity in OpenAI that makes me more nervous than relieved. Or maybe I’m just biased because I won’t have S-1s or 10-Ks to analyze. Obviously I regret the edit, but then again, I didn’t realize how prescient my underlying nervousness about OpenAI’s structure would prove to be, largely because I clearly wasn’t worried enough. Microsoft vs. the Board Much of the discussion on tech Twitter over the weekend has been shock that a board would incinerate so much value. First off, Altman is one of the Valley’s most-connected executives, and a prolific fund-raiser and dealmaker; second is the fact that several OpenAI employees already resigned, and more are expected to follow in the coming days. OpenAI may have had two tribes previously; it’s reasonable to assume that going forward it will only have one, led by a new CEO in Shear who puts the probability of AI doom at between 5 and 50 percent and has advocated a significant slowdown in development. Here’s the reality of the matter, though: whether or not you agree with the Sutskever/Shear tribe, the board’s charter and responsibility is not to make money. This is not a for-profit corporation with a fiduciary duty to its shareholders; indeed, as I laid out above, OpenAI’s charter specifically states that it is “unconstrained by a need to generate financial return”. From that perspective the board is in fact doing its job, as counterintuitive as that may seem: to the extent the board believes that Altman and his tribe were not “build[ing] general-purpose artificial intelligence that benefits humanity” it is empowered to fire him; they do, and so they did. This gets at the irony in my concern about the company’s non-profit status: I was worried about Altman being unconstrained by the need to make money or the danger of having someone in charge without a financial stake in the outcome, when in fact it was those same factors that cost him his job. More broadly, my criticism was insufficiently expansive because philosophical concerns about unconstrained power pale — at least in the case of business analysis, Stratechery’s core competency — in the face of how much this structure made OpenAI a fundamentally unstable entity to make deals with. This refers, of course, to Microsoft, and as someone who has been a proponent of Satya Nadella’s leadership, I have to admit that my analysis of the company’s partnership with OpenAI was lacking. Microsoft had, to its tremendous short-term benefit, bet a substantial portion of its future on its OpenAI partnership. This goes beyond money, which Microsoft has plenty of, and much of which it hasn’t yet paid out (or granted in terms of Azure credits); OpenAI’s technology is built into a whole host of Microsoft’s products, from Windows to Office to ones most people have never heard of (I see you Dynamics CRM nerds!). Microsoft is also investing massively in infrastructure that is custom-built for OpenAI — Nadella has been touting the financial advantages of specialization — and has just released a custom chip that was tuned for running OpenAI models. That this level of commitment was made to an entity not motivated by profit, and thus un-beholden to Microsoft’s status as an investor and revenue driver, now seems absurd. Or, rather, it did, until Nadella tweeted the following at 11:53pm Pacific: The counter to the argument I just put forth about Microsoft’s poor decision to partner with a non-profit is the reality of AI development, specifically the need for massive amounts of compute. It was the need for this compute that led OpenAI, which had barred itself from making a traditional venture capital deal, to surrender their IP to Microsoft in exchange for Azure credits. In other words, while the board may have had the charter of a non-profit, and an admirable willingness to act on and stick to their convictions, they ultimately had no leverage because they weren’t a for-profit company with the capital to be truly independent. The end result is that an entity committed by charter to the safe development of AI has basically handed off all of its work and, probably soon enough, a sizable portion of its talent, to one of the largest for-profit entities on earth. Or, in an AI-relevant framing, the structure of OpenAI was ultimately misaligned with fulfilling its stated mission. Trying to organize incentives by fiat simply doesn’t account for all of the possible scenarios and variable at play in a dynamic situation; harvesting self-interest has, for good reason, long been the best way to align individuals and companies. Altman Questions There is one other angle of the board’s actions that ought to be acknowledged: it very well could have been for cause. I endorse Eric Newcomer’s thoughtful column on his eponymous Substack: In its statement, the board said it had concluded Altman, “was not consistently candid in his communications with the board.” We shouldn’t let poor public messaging blind us from the fact that Altman has lost confidence of the board that was supposed to legitimize OpenAI’s integrity… My understanding is that some members of the board genuinely felt Altman was dishonest and unreliable in his communications with them, sources tell me. Some members of the board believe that they couldn’t oversee the company because they couldn’t believe what Altman was saying. And yet, the existence of a nonprofit board was a key justification for OpenAI’s supposed trustworthiness. I don’t think any of us really knows enough right now to urge the board to make a hasty decision. I want you to consider a couple things here: Newcomer notes the board’s charter that I referenced above, the fact that Anthropic’s founders felt it necessary to leave OpenAI in the first place, Musk’s antipathy towards Altman, and Altman’s still somewhat murky and unexplained exit from YCombinator. Newcomer concludes: I’m sure that writing this cautionary letter will not make me popular in many corners of Silicon Valley. But I think we should just slow down and get more facts. If OpenAI leads us to artificial general intelligence or anywhere close, we will want to have taken the time to think for more than a weekend about who we want to take us there… Altman had been given a lot of power, the cloak of a nonprofit, and a glowing public profile that exceeds his more mixed private reputation. He lost the trust of his board. We should take that seriously. Perhaps I am feeling a bit humbled by the aforementioned miss in my Microsoft analysis — much less my shock at the late night reversal in fortunes — but I will note that I have staked my claim in opposition to AI doomers and the call for regulation; to that end, I am wary of a narrative that confirms my priors about what drove the events of this weekend. And, I would note, I remain concerned about the philosophical question of executives who seek to control incredible capabilities without skin in the game. To that end, a startup ecosystem fixture like Altman going to work for Microsoft is certainly surprising: that Microsoft is the one place that retains access to OpenAI’s IP, and can combine that with effectively unlimited funding and GPU access, certainly adds credence to the narrative that power over AI is Altman’s primary motivation. The Altered Landscape What is clear is that Altman and Microsoft are in the driver seat of AI. Microsoft has the IP and will soon have the team to combine with its cash and infrastructure, while shedding coordination problems inherent in their partnership with OpenAI previously (and, of course, they are still partners with OpenAI!). I’ve also argued for a while that it made more sense for external companies to build on Azure’s API rather than OpenAI’s; Microsoft is a development platform by nature, whereas OpenAI is fun and exciting but likely to clone your functionality or deprecate old APIs. Now the choice is even more obvious. And, from the Microsoft side, this removes a major reason for enterprise customers, already accustomed to evaluating long-term risks, to avoid Azure because of the OpenAI dependency; Microsoft now owns the full stack. Google, meanwhile, might need to make some significant changes; the company’s latest model, Gemini, has been delayed, and its Cloud business has been slowing as spending shifts to AI, the exact opposite outcome the company had hoped for. How long will the company’s founders and shareholders tolerate the perception that the company is moving too slow, particularly in comparison to the nimbleness and willingness to take risks demonstrated by Microsoft? That leaves Anthropic, which looked like a big winner 12 hours ago, and now feels increasingly tenuous as a standalone entity. The company has struck partnership deals with both Google and Amazon, but it is now facing a competitor in Microsoft with effectively unlimited funds and GPU access; it’s hard not to escape the sense that it makes sense as a part of AWS (and yes, B corps can be acquired, with considerably more ease than a non-profit). Ultimately, though, one could make the argument that not much has changed at all: it has been apparent for a while that AI was, at least in the short to medium-term, a sustaining innovation, not a disruptive one, which is to say it would primarily benefit and be deployed by the biggest companies. The costs are so high that it’s hard for anyone else to get the money, and that’s even before you consider questions around channel and customer acquisition. If there were a company poised to join the ranks of the Big Five it was OpenAI, thanks to ChatGPT, but that seems less likely now (but not impossible). This, in the end, was Nadella’s insight: the key to winning if you are big is not to invent like a startup, but to leverage your size to acquire or fast-follow them; all the better if you can do it for the low price of $0. Microsoft’s original agreement with OpenAI also barred Microsoft from pursuing AGI based on OpenAI tech on its own; my understanding is that this clause was removed in the most recent agreement ↩ Share Facebook Twitter LinkedIn Email Related",
    "commentLink": "https://news.ycombinator.com/item?id=38346869",
    "commentBody": "OpenAI&#x27;s misalignment and Microsoft&#x27;s gainHacker NewspastloginOpenAI&#x27;s misalignment and Microsoft&#x27;s gain (stratechery.com) 448 points by todsacerdoti 21 hours ago| hidepastfavorite265 comments shmatt 20 hours agoI can’t believe people are cheerleading this move* Tigris is DOA - If because it would piss off the MSFT board but mostly because the SEC would arrest Sam assuming he’s an officer at MSFT. He could maybe be a passive investor, but that’s it* People really think many Open Ai employees will give up their equity to get whatever mediocre stock grant their level at Microsoft has? And 1% raises, no bonus some years, and the board forced headcount reductions?* Sam has even less power with the board, and the board in a 3 trillion dollar corporation would be even more risk averse than the OpenAI one* there was a ton of fan fiction yesterday online about Satya forcing a move on the board. This was never really a thing. He made one of the worst investments in the history of SV in terms of keeping power to make sure your money is used correctly. $10B for 0 votes or any power to change votes reply mirzap 20 hours agoparentWe witnessed the insane value destruction over the weekend. Every OpenAI employee is aware that everything they have and what is promised to them is whipped out. Their best chance is that Sam brings them to that new company within MS. They will get the same or better deals as they had. And they will probably deliver within 6m what OAI has now, and what spooked Ilya to launch this coup.This was a brilliant power move by Satya. I don&#x27;t see any hope for OpenAI after this brain drainage. reply chucke1992 20 hours agorootparentYeah, just like reuters mentioned\"The OpenAI for-profit subsidiary was about to conduct a secondary at a $80 billion+ valuation. These &#x27;Profit Participation Units&#x27; were going to be worth $10 million+ for key employees. Suffice it to say this is not going to happen now,\" chip industry newsletter SemiAnalysis said.\"Insane self own by OpenAI reply zarzavat 20 hours agorootparentThat sounds like exactly the kind of thing the board of a non-profit should be preventing. reply kuchenbecker 18 hours agorootparentAs an employee of a company, I trade my time and effort for some amount of rewards. I enter deals with the expectation of stability from the other party.My unfounded Internet opinion: OpenAI just removed or reduced a large source of reward and have shown fundamental instability. OpenAIs success is very much tied to Employees and Compute. reply city_guy_1 16 hours agorootparentIf your goal is to work for a profit-sharing company, then don&#x27;t work for a non-profit. reply ecshafer 15 hours agorootparentPlenty of non-profits give a lot of money to employees. There is nothing stopping non-profits from paying exorbitant sums to their employees, and executives often do get paid exorbitant. Non-profits mean they don&#x27;t pay out to investors, but they are usually used as a grift to get people to work for less so the top people make more money and do fundraising on their pet projects. reply Sevii 15 hours agorootparentprevThe employees work for the for-profit part of OpenAI. reply leetharris 16 hours agorootparentprevYeah I mean, who cares if ASI kills us all as long as a couple hundred of the most well-paid people on the planet get even more rich.It&#x27;s insane to see all these takes when we don&#x27;t even know what caused the loss of trust in the first place. reply atomicUpdate 15 hours agorootparentNo one sincerely believes they have, or will soon achieve, AGI. Neither can they believe that the CEO can push them to achieve it and forcefully release it, whereas they would responsibly develop it (whatever that may mean) without him around. reply gala8y 12 hours agorootparentGreat summary.We are very complicated creatures and things get out of control, both internally and externally. My armchair opinion is that they started to believe that all of it is so advanced and important, that they lost a bit of a grip on reality. Sutskever imagining planet covered with data centers and solar panels shows me that [0]. Every single person is limited in his&#x2F;her view - I get a strange feeling when listening to him in this video. Also, they are not the only people left on this planet. Fortunately, this task of creating AI&#x2F;AGI is not a task for a pack of ten, trying to save us from harm. Still, it may and probably will get rough. &#x2F;rant[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9iqn1HhFJ6c reply ryanwaggoner 15 hours agorootparentprevYour second paragraph is pretty ironic given your first. reply blibble 15 hours agorootparentprev> Yeah I mean, who cares if ASI kills us all as long as a couple hundred of the most well-paid people on the planet get even more rich.creating ASI for money seems particularly asinine as the machine overlords won&#x27;t care terribly much about dollars reply nh23423fefe 13 hours agorootparentHow do you know what ASI will value? reply asdfman123 14 hours agorootparentprevAs an employee of a bay area tech company, presumably, in which a mid-level IC can make as much money as a C-suite executive in some less prominent industry* reply mickdarling 13 hours agorootparentprevWell, they&#x27;re almost certainly &#x27;not profiting&#x27; right now. reply bagofsand 20 hours agorootparentprevI agree, Satya is an operator. He translated a mess into a historic opportunity for Microsoft. They&#x27;ll get some significant chunk of some of the best AI talent on the planet. All the heatseakers will go there. That, plus the IP they already have, will turbocharge Microsoft.OpenAI, in contrast, will become more like an academic research unit at some university. Those who prefer life slow and steady, will select to stay there, making tech for effective altruists. reply gryn 18 hours agorootparentthey make nothing open source, so I&#x27;m not sure why effective altruists would join it.if they can&#x27;t predict and contain the consequences of their own actions, how can they predict and contain their so claimed future \"AGI\". reply bee_rider 14 hours agorootparentIs there any reason to assume open source is a prerequisite for effective altruism?Open source doesn’t necessarily imply good for humanity, for example distributing open source designs for nukes would probably be a net negative.And even if it did, effective altruists wouldn’t need to prioritize the benefit provided by openness over all other possibilities. reply vacuity 7 hours agorootparentI don&#x27;t think relying on a proprietary license to make sure enemies can&#x27;t get AI for nukes is a sane security model. Something else needs to give. reply thelittleone 16 hours agorootparentprevOperator? reply zrail 15 hours agorootparentOperator in this context refers to someone who successfully runs a business that someone else founded. Often the visionary founder is not good at the nuts and bolts of running and growing a business so they hand off the reins to someone who is. Think Steve Jobs vs Tim Cook. reply benatkin 15 hours agorootparentIt doesn’t mean that at all, it’s slanghttps:&#x2F;&#x2F;www.urbandictionary.com&#x2F;define.php?term=operator reply mrDmrTmrJ 14 hours agorootparentFor a decade, \"operator\" in Silicon Valley as has been used exactly as the commentator above describes it.Which creates separation from \"investor\" or \"engineer\" or \"founder\" or \"PM\" or \"sales\" or \"finance\". Somebody has to make stuff happen in organizations. And the people who are good at it (Satya is excellent) set their organizations up for unique success.And yes, ex-special forces people roll their eyes at it. Which is appropriate! But the usage is now totally distinct. reply benatkin 14 hours agorootparentIt seems like underselling the successful part and overselling the part about not being the founder, but I can see it&#x27;s a slang term. Thanks.And yeah I&#x27;m wrong about it being the same term, though I did imagine a different use, I was also thinking of smooth operator, apparently I was unfamiliar with the term in tech. reply yulker 15 hours agorootparentprevIt has a meaning in a business context apart from a slang term replyleetharris 16 hours agorootparentprev> And they will probably deliver within 6m what OAI has now, and what spooked Ilya to launch this coup.Do you realize how hard it is to make something like GPT4? I think all the non-AI people posting about this all over X&#x2F;HN have this idea that if you move everyone over you just \"remake the AI\" as if this were a traditional API.There is no way MS catches up to OAI in a short period of time. During that time the rest of the market will be pressing the accelerator as hard as possible.I think MS is in a really, really shit spot right now. reply mattnewton 16 hours agorootparentThey have access to the weights as per their agreement with open ai; idk if that allows them to use it as a starting point. They also will have access to several of the people who did it. It’s insanely hard to do the first time, but probably just hard to do the second time after you already know what worked before. reply 972811 11 hours agorootparentsure but what does \"hard to do\" entail in terms of timeline? in my experience nothing complex can launch in 3 months at a big corp. 6 months would be aggressive. a year seems the most likely. but where will competitors be in a year? reply dylan604 15 hours agorootparentprevI wonder if that agreement also has an insurrection clause saying that if you benefit from this, you must wipe your memories clean of any of that shared IP. reply ketzo 13 hours agorootparentprevI mean, if MS literally gets:- all the code that created GPT-4- all the weights for GPT-4- all the people who created both of those thingsthen, y&#x27;know, I like their odds.They have access to the first two already, per their licensing agreement with OAI; by the end of the week, they may very well have the third. reply caycep 17 hours agorootparentprevgranted, now MSFT basically has another research arm like Google Brain&#x2F;FAIR, but whether or not their \"brain trust\" can equal Yann Lecun&#x27;s or whatnot who knows. Altman and Brockman are on the MBA side of things. The ML magic was Ilya&#x27;s. If they can recruit a bunch of mini Ilya&#x27;s over from Open AI, maybe they have a chance at regaining the momentum. reply dapearce 16 hours agorootparentIlya has backtracked and signed the letter saying he would also leave to Microsoft if the board doesn&#x27;t resign. reply strikelaserclaw 15 hours agorootparentIn one fell move he demonstrated he had neither conviction nor any foresight, ouch. I&#x27;m starting to believe this was just a unthought out ego emotional reaction by Ilya. Dude is like Walter White, he just \"had to be the man\" reply anonymouskimmer 16 hours agorootparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38351494 reply boppo1 15 hours agorootparentprevWtf? Isn&#x27;t he on the board? reply samspenc 15 hours agorootparentIlya signed a letter asking 4 members of the board to resign, including Ilya himself. He even posted a public apology for his actions on X https:&#x2F;&#x2F;twitter.com&#x2F;ilyasut&#x2F;status&#x2F;1726590052392956028Yes, this is probably the biggest self-own in corporate history. reply jampekka 20 hours agorootparentprevValue as in money or value as in values? There are people who value also other than the former in the deal. Like people who are trying to keep OpenAI at least somewhat non-profit. reply vikramkr 20 hours agoparentprevFrom satyas tweet Sam&#x27;s new division&#x2F;subsidiary is going to run more like LinkedIn or GitHub, and openai has pretty explicitly just declared that they don&#x27;t like making money, so I don&#x27;t think the comp is gonna be an issue. And for now, if sam wants to make product and money and Microsoft wants the same thing, then having power over the board doesn&#x27;t really matter. And Microsoft has all the IP they need. That&#x27;s a better deal than equity given who is in control of openai now. They&#x27;re actively not focused on profit. Whether or not you think this is a good outcome for AI or mankind - Microsoft absolutely won. Plus the more people they pull from openai the less they have to deal with openai, everything is in house.Edit: god damn - even the guy that pushed Sam out announced he wants to resign if Sam isn&#x27;t brought back what the hell reply anonymouskimmer 16 hours agorootparent> Edit: god damn - even the guy that pushed Sam out announced he wants to resign if Sam isn&#x27;t brought back what the hellIt reads like an orchestrated coup against the other three members of the board. Convince the board to do something you imagine will get this kind of blowback. Board is forced to resign due to their fiduciary obligations to the non-profit. And now you control the entire board. reply xdennis 15 hours agorootparent> fiduciary obligations to the non-profitWhat fiduciary obligations does a non-profit have? Isn&#x27;t the board pretty successful already at not making money? reply anonymouskimmer 15 hours agorootparentFiduciary isn&#x27;t about money, it&#x27;s about the best interests of the non-profit they are governing. If staying on the board means a harm to the goals of the non-profit charter, then they have a duty to resign. reply icelancer 13 hours agorootparentprevFiduciary obligations need not be profit-seeking. They often - perhaps especially - involve keeping the lights on for the chartered company. reply flappyeagle 20 hours agoparentprevOAI employees have no equity. They have a profit sharing right. The board is clearly not interested in profit.MS is risk adverse in every way except for one, which is to blow up Google. They will set the world on fire to do that. reply dkrich 20 hours agorootparentMS is risk adverse in every way except for one, which is to blow up Google.To me this is exactly why I’m skeptical of Microsoft’s strategy here. They seem to be convinced that their success at unseating Google is assured. Meanwhile, google’s share price has barely flinched. Also, the way this has played out just feels desperate to keep the whole thing going. Wouldn’t Microsoft want at least some clarity about what actually happened by the board up and fired the CEO on the spot before doubling down to bring him into a position of power within the company? reply bambax 20 hours agorootparentOpenAI is doomed; in fact, it has ceased to exist; it&#x27;s an empty shell, and its ressources provider is now its biggest competitor.But I doubt MSFT will win this round.1&#x2F; We still don&#x27;t know why Sam Altman was fired; does MS know? or think they know?2&#x2F; It will take the new team at MS a long time to recreate what they had at OpenAI (what does \"MS has a perpetual license to all OpenAI IP\" actually mean and entails, legally speaking?); during that time anything can happen. reply dkrich 19 hours agorootparentExactly. I’m very surprised nadella would take this kind of risk. It seems extremely cavalier to not investigate what happened before quickly going all in on hiring the entire team. You risk having to do a very embarrassing about face if something serious comes out and could lead to himself having to resign reply xref 17 hours agorootparentNadella isn’t getting his info from HN threads. reply pbronez 5 hours agorootparentprevYeah, but OpenAI was Microsoft’s ace the hole. Imagine if Nadella sat on his hands and waited while OpenAI burned down. In two weeks the narrative shifts from “Microsoft locked down the best AI people in the business” to “Nadella burned $10B for nothing”.You don’t have to do a ton of diligence to know you want to keep the people you bet the farm on. If it turns out that Sam is actually a massive liability, Nadella will deal with that after this crisis passes. reply dkrich 3 hours agorootparentWhen you’re in a hole stop digging replytedmiston 12 hours agorootparentprev> OAI employees have no equity.OpenAI employees have no equity? Well, then where exactly is that $86B of \"existing employees&#x27; shares\" coming from?> ChatGPT creator OpenAI is in talks to sell existing employees&#x27; shares at an $86 billion valuation, Bloomberg News reported on Wednesday, citing people with knowledge of the matter.https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;openai-talks-sell-shares-...https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;openais-86-bln-share-sale...A random OpenAI eng job page clearly states: \"Total compensation also includes generous equity and benefits.\"https:&#x2F;&#x2F;openai.com&#x2F;careers&#x2F;software-engineer-leverage-engine... reply kdmccormick 20 hours agorootparentprevI believe OAI Inc employees and board members have no equity, but OAI LLC employees can have equity. reply shmatt 20 hours agorootparentprevI will admit I haven’t seen an OAI contract, but have seen articles and multiple Levels.fyi posts for about $600k equity&#x2F;year (worth $0 right now obviously)So any idea how that translates into the profit sharing? They have no profit right now. Curious how employees get to that number reply infecto 20 hours agorootparentI have not seen any of the employee contracts so this is purely an educated guess which might be entirely wrong. There is a chart from Fortune[1] that spells out how the profit caps work. I have not looked at any of the documents myself so I am interpreting only what I have consumed. My guess is that the employee equity&#x2F;contracts spell out the cap structure so perhaps the equity value is based off those caps. Assuming the profit cap for employees is correct I would assume you could not value any \"equity\" based off the last raise value. At best you could perhaps value the max cap available for those shares.[1] https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;01&#x2F;11&#x2F;structure-openai-investment-m... reply infecto 20 hours agoparentprevWhat equity at OAI? You mean the equity for profit sharing? Seems to me anyone who cared about their stake in the profit sharing would be fairly pissed off with the move the board made.Investors loved Satya&#x27;s investment into OAI, not sure how we can qualify it as one of the worst investments in the history of SV?How can we even compare the risk concerns of MSFT with OpenAI? The impression we have of OpenAI is the risk concerns are specifically about the profit drive. From a business standpoint, LLMs have huge potential at reducing costs and increasing profit in multiples. reply shmatt 20 hours agorootparentWe went from OAI employees flaunting “$1,000,000 per year salaries” to the New York Times to “what equity?” Really fastThis isn’t personally against you but they never had the $1M&#x2F;year they flaunted when Sam the savior was their CEO reply infecto 20 hours agorootparentI realize you have a bias against Sam Altman but lets dig into your current statement. The NYT article you are quoting I believe is this one [1], in which it describes Ilya Sutskever making $1.8 million in salary. I am not sure exactly what you are trying to say but from the beginning the equity has not been part of the comp of OpenAI. Salary as far as I know is typically just that, the cash compensation excluding bonus and stock.I don&#x27;t know exactly how employee contracts are drawn up there but OpenAI has been pretty vocal that all the for-profit sides have caps which eventually lead back to 100% going into the non-profit after hitting the cap or the initial investment amount. So I am not quite clear what you are saying? Salary is cash, equity is stock. There has always been profit caps on the stock.My only point was that you made an argument about employees giving up their equity for \"mediocre\" MSFT stock. It is just a misinformed statement that I was clearing up for you. 1) MSFT has been doing amazing as a stock 2) Employee equity has profit caps. 3) Employees who actually care about equity profit would most likely be more interested in joining MSFT.[1] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230329233149&#x2F;https:&#x2F;&#x2F;www.nytim... reply shmatt 19 hours agorootparentIm referencing large PPU grants in OpenAI offers, with 4 year vests, they sure made it feel like regular employees are being given a chance to join now and be millionaires via theirs PPUsIf this was never true, that’s on the OpenAI team that misled their engineershttps:&#x2F;&#x2F;www.businessinsider.com&#x2F;openai-recruiters-luring-goo...Their job postings even specifically mention “generous equity” - again if there is no equity in the contract - that’s OpenAI misleading its recruitshttps:&#x2F;&#x2F;openai.com&#x2F;careers&#x2F;research-engineer-superalignment reply toomuchtodo 20 hours agoparentprevIf OpenAI is beholden to Microsoft for investment, and OpenAI&#x27;s license is exclusive to Microsoft, OpenAI has nothing to offer those who remain except mission and ramen. If OpenAI slows their own research, that impairs future profit allocation potential to remaining talent. Enterprise customers will run to Azure GPT, and Microsoft will carry the research forward with their resources.This morning at OpenAI offices will be talent asking current leadership, \"What have you done for me lately?\"Edit: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348010https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726598360277356775 (505 of 700 Employees OpenAI tell the board to resign) reply JumpCrisscross 20 hours agoparentprev> Sam has even less power with the board, and the board in a 3 trillion dollar corporation would be even more risk averse than the OpenAI oneThis is where I see the win. Newcomer’s concerns about Altman are valid [1]. It is difficult to square the reputation he nurtured as OpenAI’s CEO with the reckless lawlessness of his crypto start-up.Microsoft knows how to play ball with the big boys. It also knows how to constrain big personalities.[1] https:&#x2F;&#x2F;www.newcomer.co&#x2F;p&#x2F;give-openais-board-some-time-the reply anonylizard 20 hours agoparentprevOpenAI employees are already quitting en masse in public on twitter.Their pay is majority equity, so its worthless now with a board that says it hates profits and money. OpenAI is probably worth 80% less than it did a weekend ago, so the equity pay is also worth 80% less.Microsoft is perfectly willing to pay those typical AI salaries, because Nvidia and Google are literally doing a recruitment drive on twitter right now. Apple and Amazon are also probably looking to scoop up the leftovers. So Microsoft has to pay properly, and Sam will demand them to, to get the OpenAI team moved over intact. There aren&#x27;t that many core engineers at OpenAI, maybe 200-300, so it is trivial for Microsoft to afford it. reply chatmasta 20 hours agoparentprev> the SEC would arrest SamSEC does not have the power to arrest anyone. Their investigations are civil. reply objektif 13 hours agorootparentCriminal charges can be filed due to SEC investigations. For example:https:&#x2F;&#x2F;www.sec.gov&#x2F;files&#x2F;litigation&#x2F;admin&#x2F;2021&#x2F;ia-5764.pdf reply mnd999 20 hours agoparentprevThe cheerleaders are the LLM AI future true believers. I imagine they are the same people that were telling us about how NFTs will change the world last year. reply vikramkr 20 hours agorootparentI really don&#x27;t get the comparison of nfts to llms. I mean yeah some hype cycle idiots have redirected both of their brain cells to shilling useless startups that&#x27;ll get obsoleted by minor feature additions to bard or whatever in a year, but who cares about them? NFTs didnt do anything but enable fraud.Llms do stuff that has value. I can use Rfdiffusion with motif scaffolding to create a fusion protein with units from enzymes that have no crystal or cryoem structures with as high as a 5-10% success rate!!!!!! That&#x27;s absolutely insane! I only need to print 20 genes to have a chance of getting a variant that works. Literal orders of magnitude improvement. And if you don&#x27;t have a good multisequence alignment for getting a good folks from alphafold? Pure llm based esmfold can fill in the gaps. Evodiff is out here generating functional proteins with disordered regions. Also, to bring it back to openai, if I ask chatgpt to write some code, it writes some pretty decent code. If I give it a bunch of PDFs and ask it to give me a summary, it gives me a summary. I don&#x27;t buy the agi end of the world hype so a shift that means that we get more focus on d eveloping useful tools that make my life easier that I&#x27;m totally willing to pay 20 a month for? Yeah I&#x27;m down. Get this cool tech and product into a form that&#x27;s easy to use and useful and keep improving it! reply icy_deadposts 16 hours agorootparentTo me, this sounds very similar to the type of over-hyped, exaggerated response when someone criticized cryptocurrencies by saying they don&#x27;t do anything. The response would be:-I&#x27;m literally drinking a coffee I bought with bit coin right now.-I was able to send large sums of money to my grandma in another country while paying a fraction of the fees going through banks-It&#x27;s a stable store of value for people in volatile countries with unstable currency-It&#x27;s an investment available to the small timers, normally only the wealthy have these opportunities-It lets me pay artists for their art directly and bypass the corrupt middlementhis is a forum coding so i have no idea what any of that biology mumbo jumbo means, but everything you mentiond about chatgtp is conveniently missing a lot of details.>write some code, it writes some pretty decent code. Is it trivial code? Is it code that shows up on the first page of any search engine with the same terms?>it gives me a summary. Is it an accurate summary? Is it any better than just reading the first and last section of the report directly? reply vikramkr 14 hours agorootparentDude I&#x27;m talking about it being worth 20 bucks a month (which NFTs are not), not the hype cycle nonsense. Just because you don&#x27;t understand the scientific applications of protein folding, one of the most important problems in biology, doesn&#x27;t mean that its mumbo jumbo. Ever heard of folding at home? Man is silicon valley ridiculous sometimes, but since apparently the accomplishments of coders don&#x27;t count on this coding forum if they&#x27;re in fields that web developers don&#x27;t understand let&#x27;s focus on consumer applications.In terms of writing code, yeah it&#x27;s pretty simple code. I&#x27;m paying 20 bucks a month not 200k a year. I&#x27;ve found it really useful to dive into open source code bases for papers (just upload the repo and associated paper) - academics write pretty garbage code and even worse documentation. It&#x27;s able to easily and correcttly extend modules, explain weird uncommented and untyped code (what exactly is xyz data structure? Oh it&#x27;s a tensor with shape blah where each dimension represents abc value. Great saved me 2 hours of work).For the summaries - uhh yeah obviously the summaries are accurate and better than reading the first and last sections. Spend the 20 bucks and try it yourself or borrow someone else&#x27;s account or something. Especially useful if you&#x27;re dealing with nature papers and similar from journals that refuse to give proper respect for the methods section and shove all the information in a random way into supplementary info. Make a knowledgebase on both and ask it to connect the dots, saves plenty of time. I don&#x27;t give a damn about the flowery abstract in the first part of the report and the tryhard conclusion in the last part of the report, I want the details.It&#x27;s comical that these useless hype bros can convince folks that a genuine computational breakthrough and a pretty solid 20 dollar a month consumer product with actual users must be bunk because the bros are shilling it, but luckily the baker lab doesn&#x27;t seem to care. Can&#x27;t wait to play around with all atom so I don&#x27;t have to model a zinc atom with a guide potential and can just model the heteroatom directly in the functional motif instead! Not sure it&#x27;ll work for the use case I have in mind until I try it out and print a gene or two of course but I&#x27;m glad folks are building these tools to make life easier and let me engineer proteins that were out of budget 3 years ago. reply anon291 14 hours agorootparentprevYou see no use case for LLMs? I&#x27;ve successfully used GPT4 to actually transcribe hundreds of pages of PDF documents with actual accuracy. That alone is worth something. Not to mention I can now literally ask questions from these pages and come up with cited, reasonable answers in a few seconds. This is amazing technology. How can you not see the use case? reply mnd999 14 hours agorootparentWow OCR. How innovative. reply anon291 14 hours agorootparentAccurate OCR that answers questions from source documents? Yes... very innovative. As an example, I have a real estate data company that provides zoning code analysis. Whereas before I would have to manually transcribe tables (they come in many different formats, with table columns and rows that have no standard structure), I can now tell GPT.... Examine these images and output in my custom XML format after giving it some examples. And ... it does. I&#x27;ve fed it incredibly obtuse codes that took me ages to parse through, and it... does it. I&#x27;m talking about people using non-standard notation. Handwritten codes, anything. It&#x27;ll crunch ittell me... how much would it cost to develop a system that did this with pre-GPT OCR technologies? I know the answer. Do you? reply mnd999 14 hours agorootparentDid you make anything on those NFTs? reply anon291 13 hours agorootparentNope. Crypto has no value and I&#x27;ve consistently avoided it replystetrain 19 hours agoparentprev> People really think many Open Ai employees will give up their equity to get whatever mediocre stock grant their level at Microsoft has? And 1% raises, no bonus some years, and the board forced headcount reductions?What long term prospects do those employees have of raises, profit-sharing, equity, etc. at OAI if the board is willing to destroy value to maintain their non-profit goals?I think the whole point of this piece is that OAI&#x27;s entire organizational structure is built against generating a large startup valuation that would provide a large payout to employees and investors.OAI has cash from ChatGPT revenue that it could use to offer competitive pay, but also this entire situations is based around the board being uncomfortable with the decisions that led to this revenue or attempts to expand it. reply asimovfan 20 hours agoparentprevMicrosoft can offer more if it wishes, no? reply blibble 20 hours agorootparentbut they can&#x27;t offer the whole \"we are doing this for the benefit of humanity\" larkwill researchers that were lured into OpenAI under this pretense jump ship to explictly work on extending microsoft&#x27;s tendrils into more of people&#x27;s lives?(essentially the opposite of \"benefit humanity\")no doubt some will reply vikramkr 20 hours agorootparentI don&#x27;t think Microsoft cares about that crowd, since now without capital they can&#x27;t really do anything anyway. The rest of the crowd that wants to make bank? Might be more appealing reply JumpCrisscross 20 hours agorootparent> without capital they can&#x27;t really do anythingNot a bad moment for a rich patron to swoop in and capitalise the non-profit. If only there were a billionaire with a grudge against Altman and historic link to the organisation… reply edgyquant 20 hours agorootparentprevWhy don’t they have capital? reply vikramkr 20 hours agorootparentI mean if someone else wants to give them billions of dollars to make an AGI that they think will extinct humanity while not commercializing or open sourcing the tech they do have because they&#x27;re scared of extinction, then be my guest. Usually if say I&#x27;m happy to be proven wrong but in this case I&#x27;d just be confused. replystrangattractor 14 hours agoparentprevRegardless of what anyone thinks about it - M$ was going to pay an entity they did not control 18 Billion to be a player. Now they don&#x27;t have to - they get it almost for nothing. Hat&#x27;s off to M$ - this is certainly one of the largest corporate missteps by a board in charge of such hot technology that I have ever witnessed.The Open AI board has taken the keys of Paradise and willingly handed them directly to the devil;) reply manyoso 20 hours agoparentprevDriving the narrative doesn&#x27;t mean driving reality. It is clear that Sam and friends are great at manipulating the media. But this is a disaster for Microsoft and the CEO damn well knows it. It is also a personal disaster for Altman and probably not a great move for those who choose to join him.Time will tell if the OpenAI non-profit vision of creating safe AGI for the benefit of humanity can be revitalized, but it really does look like all involved are basically acknowledging that at best they were fooling themselves into believing they were doing something on behalf of humanity. Egos and profit seeking took over and right now the ethos which they championed looks to be dying. reply flappyeagle 20 hours agorootparentWhy is this a disaster? They managed to acquihire the founders of a 90B company. Probably the most important company in the world until last Friday.Seems like a huge win to me. They can write off their entire investment in OAI without blinking. MS farts out 10B of profit in about a month. reply manyoso 20 hours agorootparentThey acquired two of the founders least responsible for the actual tech. They made a huge bet on OpenAI to produce the tech and that relationship is going down the drain. Watch the market today, the next week, the next month, the next six months and that will tell you what I say: this is a disaster for MS and they damn well know it. reply JumpCrisscross 20 hours agorootparent> They acquired two of the founders least responsible for the actual techMicrosoft also “has a perpetual license to all OpenAI IP (short of artificial general intelligence), including source code and model weights.”If you’re a scientist, OpenAI is a fine place to be, though less differentiated than before. If you’re an engineer more interested in money and don’t want the risk of a start-up, Microsoft seems the obvious path forward. reply flappyeagle 16 hours agorootparentprevhttps:&#x2F;&#x2F;twitter.com&#x2F;ilyasut&#x2F;status&#x2F;1726590052392956028Ilya just said he will do everything he can to reunite the company. If that’s the case the easiest way to do it is to resign and join MS reply thatsadude 20 hours agorootparentprevBased on credits in Gpt3 and 4 papers, I think the team that follows Sam and Greg are the main drivers of the tech. Ilya is an advisor more or less. reply tw04 20 hours agorootparentprevYou&#x27;re making the assumption that the technical folks won&#x27;t follow him, and that&#x27;s a pretty ridiculous bet at this point unless you&#x27;ve got some more data you&#x27;re just not sharing.Out of the gate the technical folks at OA had to be perfectly fine with Microsoft as a company given they knew all of the tech they were building was going to be utilized by MS carte blanche.So now that their OA equity is staring down the barrel of being worthless, what&#x27;s stopping them from getting a potentially slightly lower but still significant payday from MS directly? reply edgyquant 20 hours agorootparentThe only technically person who matters here, the one who came from deepmind and who is the worlds top AI researcher, is sure as hell not going to follow him since he’s the reason Sam is gone. reply tw04 20 hours agorootparentYou&#x27;re right, I have no idea what I&#x27;m talking about, clearly people aren&#x27;t going to leave and follow Sam instead of Ilya. Nobody at all... just 550 of 700 employees, nothing to see here.https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726598360277356775 reply drewmate 19 hours agorootparent> 550 of 700 employeesIncluding Ilya Sutskever who is (according to the posted document) among the 550 undersigned to that document.It&#x27;s pretty clear this is a fast-moving situation, and we&#x27;ve only been able to speculate about motivations, allegiances, and what&#x27;s really going on behind the scenes. reply dkrich 20 hours agorootparentprevYou’ve nailed it. The excitement is going to be short lived imo reply fernandotakai 19 hours agorootparentgiven that 500 employees are saying \"either give us sama and gdb back or we are going to msft\", i say nadella won hard. reply dkrich 19 hours agorootparentThat’s how it appears currently but experience has taught me to be very careful about making snap judgments in these types of fast moving situations. Nobody seems to know yet why he was actually fired. The popular theory is that it was a disagreement about mission but something about that narrative just feels off. Also Nadella and Altman are both enjoying God-like reputations and the OpenAI board totally being dismissed as clueless and making a stupid, impulsive decision even though basic logic would tell you that a rational acting person would not do that. There’s a lot of room for the pendulum of public opinion to swing back the other way and it’s clear that most of the most fervent supporters of Altman and Microsoft are motivated by money rather than truth. reply flappyeagle 16 hours agorootparentMost human beings are motivated by money. reply anon291 14 hours agorootparentprev> a rational acting person would not do that.Non-profit boards have no incentive to be rational. reply anonylizard 20 hours agorootparentprevDid you even research the basic facts?Microsoft stock is up in the pre-market, because they basically got half of the OpenAI team for free.The majority of top researchers at OpenAI are expressing solidarity for Sam and basically signalling they want to move too, just check out twitter. That also includes like the majority of the execs tehre. reply dkrich 20 hours agorootparentYes, low volume pre market moves on the back of a nonstop news flow always predict how they end up replymunchausen42 20 hours agoparentprev>more risk averse than the OpenAI oneAt least it&#x27;s not sci-fi-risk averse ;) reply yterdy 18 hours agoparentprevHN is filled with temporarily-embarrassed billionaires (and actual billionaires) who would very much like to preserve the notion that big corporations can move with impunity and quash any threat to investment returns. Reality is not aligning with that, so they&#x27;ve entered their mental safe pods (with the rose-tinted windshields). reply djmips 15 hours agorootparentOMG this ^ reply DeWilde 19 hours agoparentprev> no bonus some years,What do you mean? MS employees are getting bonuses on a yearly basis, this year included. reply shmatt 19 hours agorootparentI’m referring to Satyas email from May saying there will be no raises and the bonus pool will be significantly reducedThat’s fine for corporate employees, but OAI employees were promised mountains of money to leave Google&#x2F;Meta, they might not be as happy reply FireBeyond 17 hours agorootparentThey don&#x27;t have to leave OAI.OAI is a startup. All these OAI employees who were playing up their million dollar salaries should know that startups come with risk. How many times has it been said that equity is worth nothing until (and if) it is?In the grand scheme of the current IT economy, top of the queue for sympathy to me is not \"people making seven digit salaries at startup who may have to put up with only making $500K+ at MSFT\". reply m_ke 20 hours agoprevJust a tip for OpenAI employees that plan on leaving: this is probably one of the best opportunities you’ll ever get to start your own thing. If you’re joining a new startup make sure you’re a founder and have a good chunk of the equity. For the next few months there will be a line of investors waiting at your door to give you money at a wild valuation, take it and do what you always wanted and know that if it doesn’t work out there will be plenty of large companies ready to acquire you for much more than they’d ever be willing to pay you. reply airstrike 18 hours agoprevI&#x27;d retitle this as \"OpenAI&#x27;s blunder and Microsoft&#x27;s excellent damage control\"I don&#x27;t think Microsoft is necessarily in a better position than it was on Thursday. If we&#x27;re tallying up points: + More control over the full AI stack + Effectively they will own what was once OpenAI, but is now really OpenAI 2.0 - OpenAI 2.0 is probably a worse business than OpenAI 1.0, which was, prior to the coup, a well-oiled machine + Control over OpenAI 2.0 operations, which can lead to better execution in the long term - Higher wage costs - Business disruption at OpenAI, delaying projects - Potential OpenAI departures to competitors like Google, Meta, Anthropic, Amazon, Apple (?) - Risk that OpenAI 1.0 (what&#x27;s left of it) either sells to any of those competitors - Risk that OpenAI 1.0 actually goes open source and releases GPT-4 weights reply codeisawesome 15 hours agoparentGPT-4 weights, the RLHF s&#x2F;w & logs, data sources … if all of that were truly open, it would be incredible. reply fbdab103 13 hours agoparentprev>Risk that OpenAI 1.0 (what&#x27;s left of it) either sells to any of those competitorsWho else is positioned that they could possibly do anything with it commercially? Even Microsoft is supposedly renting GPUs from Oracle (deals with the devil!) to keep up with demand.Amazon is the only other company with the potential computational power + business acumen to strike, but they already have their own ventures. Google could, but not sure they would willingly take the reputation hit to use a non-Google model. reply oakashes 16 hours agoparentprevSeems like a pretty good list, but I think a lot depends on how much you weight each item and how many of the negatives were already \"priced in\" to the status quo ante when Microsoft was strategically linked to OpenAI without any formal control. reply fomine3 9 hours agoparentprevOpenAI 1.0 to become Netscape? It&#x27;s great if it happen. reply toth 20 hours agoprevThe analysis in the article is mostly very good, but I object to this observation`The biggest loss of all, though, is a necessary one: the myth that anything but a for-profit corporation is the right way to organize a company.`I don&#x27;t see how anything that happened this weekend leads to this conclusion. Yes, it seems likely that the board&#x27;s actions will result in an OpenAI with much smaller revenue and consumer traction. But the whole reason for setting up OpenAI as a non-profit was precisely ensuring that those were not the overriding goals of the company.The only conclusion that seems warranted is that \"the myth that anything but a for-profit corporation is the right way to organize a for-profit company.\", but that is pretty obvious. reply anonylizard 20 hours agoparentIt means that those &#x27;organisations&#x27; can never scale, and therefore make the titanic impacts on society they hoped to have.No investors will touch these non-profits with a 10 foot pole now. An unaccountable board that can lead the majority of the company and investors to revolt is radioactive for investors.It proves that the shares=votes, standard corporate structure is the only way to organize mega scale organizations.OpenAI will keep its goals, but it&#x27;ll simply accomplish nothing. It&#x27;ll probably devolve into some niche lab with no resources or GPUs to do anything significant. reply hgomersall 20 hours agorootparentRight! The Wikimedia Foundation is dead in the water, and everyone except Jimmy knows it. If only it could raise hundreds of millions in capital from investors then they could actually start delivering value and get significant market share. reply ketzo 13 hours agorootparentPithy response but poor comparison -- Wikipedia&#x27;s startup costs were in, what, the tens of thousands of dollars? Less?OAI is burning billions in compute&#x2F;salary to create their thing, and will spend billions more before truly massive value to society could ever be wrought.I can&#x27;t think of a nonprofit structure that has ever effectively allocated that much capital aside from, like, a government. reply hgomersall 13 hours agorootparentThe parent criticism was that non-profits cannot scale. reply BryantD 20 hours agorootparentprevWould you say Wikipedia has had a significant impact on society? reply mschuster91 19 hours agorootparentOf course it has. Wikipedia is the first (and only) truly global source of knowledge, to a depth no other encyclopedia has ever covered before - and with an unmatched capability to react to current events. reply motoxpro 13 hours agoparentprevThis non-profit structure means that 4 people can decide to do whatever they want, with no consequences, putting 100s of jobs in danger, 1000s of companies futures on the line and disrupting millions of people who rely on the service.Because they had a difference in opinion about a devday presentation...?Just confusing to me why so many people are thinking the board is so altruistic here. That kind of unchecked power is insane to me. reply gsuuon 13 hours agoparentprevIf Altman goes back it could potentially salvage the model he helped create - maybe there needed to be some mechanisms in place to validate decisions like firing the CEO. This drama was made all the more intense because no one still really knows why they made the call. As a non-profit, some level of transparency for decisions like this seems like a super reasonable demand. reply usefulcat 19 hours agoparentprev> I don&#x27;t see how anything that happened this weekend leads to this conclusion.They seem to need additional investments, but their goals are not aligned with most of their would-be investors.If their goal really is the &#x27;safe&#x27; development of AI, they are now in an objectively weaker position to pursue that goal, even if the actions of this weekend were otherwise justified. reply photochemsyn 20 hours agoparentprevFor-profit vs. non-profit is an increasingly meaningless distinction in today&#x27;s business&#x2F;legal environment. It seems like more of a marketing ploy than anything else. For example, one can set up a &#x27;socially responsible do-gooder&#x27; non-profit with the left hand, and a for-profit corporation with the right hand, and then funnel all the money that goes into the non-profit into the for-profit by making that the sole supplier to the non-profit, thus avoiding many taxes and generating robust profits. These schemes are legion - there are hundreds of examples if you go looking.The real issue with LLMs is open-source vs. proprietary. reply kdmccormick 20 hours agorootparentHundreds of examples? Can you name one?As someone who works at a non-profit that partners with various for-profits, I&#x27;m skeptical that the IRS would allow such sort of large-scale tax fraud to happen. reply photochemsyn 19 hours agorootparent> \"In this scenario, I set up my non-profit school-- and then I hire a profitable management company to run the school for me. The examples of this dodge are nearly endless... consider North Carolina businessman Baker Mitchell, who set up some non-profit charter schools and promptly had them buy and lease everything - from desks to computers to teacher training to the buildings and the land - from companies belonging to Baker Mitchell.\"https:&#x2F;&#x2F;curmudgucation.blogspot.com&#x2F;2016&#x2F;07&#x2F;for-hrc-profit-v...As far as the IRS, this may be entirely legal due to tax loopholes pushed through by lobbyists and bought politicians, or it may take so many IRS resources to unravel that it tends to go ignored. reply chasd00 20 hours agoprev“ Finally, late Sunday night, Satya Nadella announced via tweet that Altman and Brockman, “together with colleagues”, would be joining Microsoft”Called it, EEE is complete. This is old Microsoft magic. I hope younger people starting their careers are taking note. All that money gates is giving away to buy his way into heaven came from the same tactics. reply cm277 17 hours agoparentDisagree. Satya&#x27;s Microsoft is more like Embrace-Extend-Share: he&#x27;s running it more like an old-school conglomerate --not BillG&#x27;s \"one company to rule them all\".AFAICT, New Microsoft is a platform of platforms with profit flowing down to lower-level platforms (Windows, Azure) but being made in all levels (Office, Xbox, LinkedIn) and shared with others (employees &#x2F; partners) at some levels.Satya has basically taken the Bezos insight --use your scale to build platforms that you also sell to outsiders-- and inverted it: use as many platforms as possible to build and sustain scale. This is not new, this is exactly what a conglomerate would have done 100+ years ago. But he&#x27;s doing it methodically and while breaking fewer rules than Amazon or Google. Mad respect. reply boringg 19 hours agoparentprevAll the shade going the board (legit) - that said Altman and Brockman just lost so much of their independence its unbelievable - sad state of affairs that its being described as a win for them (or a good salvage). Also - everyone is pinning the board for all the problems ... everybody&#x27;s hands are dirty here that it even got to this point. What a mess. reply PoignardAzur 19 hours agoparentprev... What? How is this in any way related to EEE? The OpenAI board did this to themselves. reply debacle 18 hours agorootparentWe can&#x27;t know that - this may have been orchestrated. reply simiones 18 hours agorootparentBy someone on the board, with the approval and participation of the rest of the board. So, the board did it to themselves.Or do you think MS fabricated evidence to falsely convince the board Sam Altman was lying to them? reply debacle 14 hours agorootparentIt&#x27;s possible that Sam was given clear parameters for removal, there was a discussion with Microsoft about what would happen after removal, and then a decision was made to fulfill those parameters for removal to move things forward. reply ajryan 19 hours agoparentprevEmbrace, Enhance, Extinguish for those unfamiliar. reply CatWChainsaw 7 hours agorootparentExtend is the middle E. reply vouaobrasil 20 hours agoprevIt may be OpenAI&#x27;s loss and Microsoft&#x27;s gain, but any support that AI gets is a tragedy for humanity.Everything is good in moderation, and with AI we are taking our efficiency past that good point. AI not only takes jobs away from creatives such as illustrators and can be used for identity theft, it also is removing the reliance that people have on each other.Society is held together because people need each other. People meet each other through needing each other, and this is what makes local communities strong. AI takes that away so that the only entities we need are big tech like Microsoft, Google, and other soulless organizations.It is a descent into feudalism, where everyone will pay big tech for basic living necessities (first option, later a necessity, like the smartphone).If a man or woman wants to live independently of big tech, it will be harder and harder now, and we are losing are sense of what it means to be human through the immoral actions of these companies. reply zemvpferreira 19 hours agoparentI couldn&#x27;t disagree more. The more wealth is created out of thin air by technology, the better we all live, and the better our relations with one another. Scarcity creates conflict and pain. Prosperity makes good neighbours out of enemies.I don&#x27;t care if I have to pay megacorps for a right to my modern conveniences, if that means they extend to more and more people. Monsanto can take all my money if no one ever dies of starvation again. Microsoft can take all my data if we never have to do rote tasks again. reply AlexVN 1 hour agorootparentI think it&#x27;s important to keep track of which particular wealth we create and how it gets distributed. If eg GDP grows 2x, but instead of affording 2x more food everyone can now afford 10x more&#x2F;better memes and better drones for their country military, I don&#x27;t consider it a win. In other words, \"growing wealth\" means better access of people (on average) to some resources, but whether it&#x27;s a good thing depends on the exact resources the world gains. reply vouaobrasil 19 hours agorootparentprevThe more wealth is created, the more we abuse wild resources and the natural ecosystem as well. If there were only humans on the planet, I would not disagree. But it is immoral to live better if it comes to destroying out natural connection with the biosphere.I also disagree that scarcity creates conflict and pain. Scarcity limits growth, which means it limits our expansion, which is good because other creatures have to live here too. reply pdonis 14 hours agorootparent> I also disagree that scarcity creates conflict and pain.Every war in human history (and there have been a lot of them) was fought over control of scarce resources. Sure looks like scarcity creates conflict and pain to me. reply CatWChainsaw 7 hours agorootparentprevIt&#x27;s funny, in a sad way, that you think corporations will hold up their end of the \"bargain\". Can&#x27;t remember which Youtube video I was watching, but this stuck out: \"The irony that we&#x27;re automating the production of art instead of the jobs everybody hates shouldn&#x27;t be lost on us.\" reply Nasrudith 9 minutes agorootparentThat pseudoprofound bullshit about automating art is the new version of the old ignorant chestnut of \"If we can put a man on the moon why can&#x27;t we just X?\" Newsflash: there are vast differences in what is accomplishable. Self driving cars stalled out but not for lack of trying. reply phpisthebest 20 hours agoparentprevI find it amusing that just a few short years ago the idea was that automation &#x2F; ai would replace the truck drivers, factory workers, and blue collar jobs where the Developer, the lawyer, information worker was safe from this...It seems the last mile in replacing blue collar jobs may be more expensive and more challenging (if not impossible) than replacing information workers with AI... reply vouaobrasil 20 hours agorootparentI actually agree with this. All along, people thought that automation would mainly replace manual labor (which I also disagree with in many instances -- I believe people should be able to make a DECENT wage doing things, even manual things, even if other things become more expensive for people \"at the top\").It seems likely that AI will either replace or augment people in the most creative fields, creating a homogeneous MUSH out of once interesting things, making us consumerist and mindless drones that simply react like amoebas to advertising, buying junk we don&#x27;t need so that the top 0.1% rule the world, pushed their by their intense narcissism and lack of empathy (like Sam Altman, Ilya Sutskever, Sundar Pichai, Satya Nadella who are by definition narcissists for doing what they do.) reply Applejinx 20 hours agorootparentI emphatically agree, with a caveat: I work in the music business. I&#x27;ve seen homogenous mush before. AI and related technologies have already augmented people in the homogenous mush business, and will most certainly replace them, and this will serve a sort of mass market with mass distribution that&#x27;s recognizable as &#x27;creative fields&#x27; of a sort.This is self-limiting. It&#x27;s a sort of built-in plateau. You can&#x27;t serve the whole market with anything: the closest you&#x27;ll get is something like a Heinz Ketchup, a miraculously well-balanced creation with something for everyone. It&#x27;s also a relatively small market segment for all its accessibility.We cannot be made &#x27;consumerist and mindless drones that simply react like amoebas to advertising&#x27; more than we already are, which is a LOT: whole populations are poisoned by carefully designed unhealthy food, conned by carefully designed propaganda in various contradictory directions. We&#x27;re already at saturation point for that, I think. It&#x27;s enough to be a really toxic situation: doesn&#x27;t have to threaten to be far worse.The backlash always happens, in the form of more indigestible things that aren&#x27;t homogenous mush, whether that&#x27;s the Beatles or the Sex Pistols or, say, Flamin&#x27; Hot Cheetos. The more homogenous everything is, the more market power is behind whatever backlash happens.This is actually one argument for modern democracies and their howling levels of cultural tension… it&#x27;s far more difficult to impose homogenity on them, where other systems can be more easily forced into sameness, only to snap. reply kumarvvr 20 hours agoparentprevYup. The world we are headed into, accelerated by huge leaps in technology like AI, will be a sorry, pathetic, unforgiving world, that amplifies suffering and nullifies humanity.Is that image of a child being assaulted by terrorists real or fake? To the victims, its real, to political powers it fake, to mega corporations, its money. reply ChatGTP 20 hours agorootparentI can&#x27;t believe I&#x27;m playing devil&#x27;s advocate here because I&#x27;m generally a skeptical &#x2F; pessimistic person, but what?The world we are headed into, accelerated by huge leaps in technology like AI, will be a sorry, pathetic, unforgiving world, that amplifies suffering and nullifies humanity.Is that what has happened so far in your life? Technology has messed it up for you ? reply vouaobrasil 20 hours agorootparentI think technology has messed up a lot of lives. Sure, we&#x27;ve got good healthcare and resources in the first-world, but smaller communities are eroding to the global force of technology.Don&#x27;t bully people into not expressing critical thought by emphasizing that they have their basic physical needs met. We should be critical of society, even if on the surface it seems pretty good.We also have more advanced psychological needs such as the need to depend on others, and that is what is at stake here. reply ChatGTP 20 hours agorootparentI see a contradiction in your message here. On the one hand you&#x27;re saying people are worse off because of technology, but then you&#x27;re also saying that people don&#x27;t rely on each other because they have more of their needs met. So which is it?Wouldn&#x27;t the poverty rebuild these communities ? I mean the hardships make people rely on each other right?I don&#x27;t entirely doubt what you&#x27;re saying either, but I&#x27;m not so sure I see what you see. reply vouaobrasil 20 hours agorootparentThere is no contradiction, because I do not believe that having all your physical needs met is necessarily the best end for a human being, especially if they have the capability to meet a lot of those needs themselves if they were given the tools to do so. It&#x27;s like those people in the Matrix pods: they have their needs met, but they are being plugged into a machine and are not truly human. reply bamboozled 20 hours agorootparentName a single instance or person who has all their physical needs met by an LLM?Seriously, we&#x27;re a long way off technological utopia. Even if we had some type of AGI&#x2F;ASI that was self-aware like in movies ,there&#x27;s little if any evidence to suggest it will just work for us and make sure you&#x27;re ok. reply edgyquant 20 hours agorootparentprevYes where have you been? reply bamboozled 20 hours agorootparentHow has it been messed up for you ? Would going back to medieval times fix it? reply hamandcheese 19 hours agorootparent> Would going back to medieval times fix it?Going back to the 90s probably would. reply vasco 17 hours agorootparent> The decrease in the number of people affected by hunger has happened in a period where the world population has increased by 2.2 billion - from 5,3 billion in 1990 to 7.5 billion in 2018. The share of undernourished people in the world has therefore fallen markedly in the past three decades. From 19% in 1990 to 10.8% in 2018.https:&#x2F;&#x2F;www.theworldcounts.com&#x2F;challenges&#x2F;people-and-poverty...Why don&#x27;t you go ask the 189 million people that since 1990 have avoided hunger if they agree? reply hamandcheese 16 hours agorootparentWas social media required to feed those people? I don&#x27;t think hunger in the 90s was a technology problem. reply golergka 2 hours agorootparentYes, actually. Social media and internet made ad industry much more effective, which in turn made wonders in commerce, which is exactly what raised people out of hunger.A lot of people in southeastern Asia and China are working in industry and live tens time better than subsiste farmers just one generation before them exactly because the niche trinkets they make can now be sold on instagram. replyj_crick 17 hours agorootparentprevCars bad, horses good reply yellow_postit 20 hours agoparentprevThis pessimism may play out but I continue to fall on the optimist side.AI tooling seems to be allowing for more time on creativity and less on rote work.If that continues to play out creativity inevitably drives more collaboration as creativity cannot thrive only in a silo. reply dartos 20 hours agoparentprevGenuinely curious.Except in the shovelware games industry and the instagram ad scam industry where is AI actually, currently, threatening to take away jobs? reply vouaobrasil 20 hours agorootparent1. Illustrators2. Photographers (Check out Photo.AI). I know a local photographer who takes nice portraits for businesses. Now people can use this service for their headshots. (You may argue that it&#x27;s good for people but at which point does it remain good if NOBODY can use their creative talents to make a living.)3. Writing. Many websites are now using writers to write their articles. That means they hire less writers. Again, you can say that it makes society more efficient and I guess it does for consumers, but those people such as copy editors will have to find new jobs.You may say that new jobs will be created but we have not seen such a versatile tool that can take away so many jobs at such a quick pace before. Moreover, will the world really be a nice place to live in if most of the creative jobs or at least jobs involved IN producing something nice will be left to machines?What about Hollywood and their desire to replace writers and actors? You may say that Hollywood is dead anyway, but I&#x27;m sure it&#x27;s about to get a lot worse... reply Turing_Machine 6 hours agorootparentThink of all the serfs and slaves that were put out of work by the invention of the tractor. reply rvnx 20 hours agorootparentprev4. Translators5. Programmers reply airstrike 18 hours agorootparent6. Voice actors and narrators (eventually news anchors, reporters, etc)7. Composers, hired musicians, eventually singers, producers reply hotnfresh 16 hours agorootparentThere’s a real chance that one thing AI will make better—not just cheaper—is original scores for movies. Get us out of this “just match the shitty generic placeholder music we already edited the movie to” norm we’ve been in for almost two decades (which itself came about due to changes in technology!) reply vikramkr 20 hours agorootparentprevSoftware engineering for sure. Lots of SV types have a very distorted view of what the average programmer not in a high prestige silicon valley company does. Especially contractors and outsourcing firms and the like? Yeah not great for them. Also analyst type roles and data science type roles, since the level of reasoning plus the ability to parse structured data and write code is pretty much there. Medical scribes are already being automated, voice to text plus context aware parsing. I also think areas of law like patent law (writing provisionals etc) are probably in a situation where the tech is already better than humans at writing claims that are not going to conflict with prior art and the like, though there&#x27;ll be legal barriers there to adoption. But a lot of the legal staff involved might be replaced even if the lawyers and agents are not. Anyone who writes review papers&#x2F;research summaries like market reports without actively doing non-internet research like interviewing people are going to struggle against AI written reviews that can just pull from more information than humanly possible to parse. Accounting, preparing financial statements, etc where \"creativity\" is not necessary a good thing also, though again regulations might stop that. And obviously in healthcare, doctors like radiologists and surgeons etc which we&#x27;ve been talking about as a possibility for a long time but looks more possible than ever now.Also there&#x27;s areas where it&#x27;s quickly becoming a required skill set, so it&#x27;s not that it&#x27;s replacing people but that the people there are getting their skills obsoleted. All the molecular biologists I know that used to joke about how they picked biology since they suck with computers and hate excel are at a high risk of getting left behind right now, especially with how steep the improvement&#x27;s been with protein design models like RFDiffusion. Though by latest rumors it looks like the vast vast majority of biologists involved in protein work have already started using tools like alphafold and esmfold so it does look like people are adapting. reply merelysounds 20 hours agorootparentprev> layoff announcements from U.S.-based employers reached more than 80,000 in May — a 20% jump from the prior month and nearly four times the level for the same month last year. Of those cuts, AI was responsible for 3,900, or roughly 5% of all jobs lost> The job cuts come as businesses waste no time adopting advanced AI technology to automate a range of tasks — including creative work, such as writing, as well as administrative and clerical work.Source: https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;ai-job-losses-artificial-intell... reply andyjohnson0 20 hours agorootparentprevCustomer service&#x2F;support. Low-level legal services. Copywriting. Commercial music composition. Commercial illustration production. Junior-level software development. reply vouaobrasil 20 hours agorootparentIndeed, and these people should be able to do things that are useful, not just for themselves, but because interacting with humans to get these things is much better for society than EVERYONE interacting with a damn computer! reply javier_e06 20 hours agoparentprevWe can say fro big-tech the same for oil, penecilin or gmo&#x27;s. What does it mean to be human when we, all humans, are the sons and daughters of big industry for profit ventures? Open AI board stopped trusting Altman when he went started pitching the Open AI technology elsewhere behind their backs. At least that the rumors I read. If OpenAI developers truly believe the AI can be weaponized and that they should not be following the leadership of for-profit ventures they won&#x27;t jump ship. We will see. reply vouaobrasil 20 hours agorootparent> We can say fro big-tech the same for oil, penecilin or gmo&#x27;s. What does it mean to be human when we, all humans, are the sons and daughters of big industry for profit ventures?That is why we should be cautious about technology instead of inviting it with open arms. It is a question we should continue to ask ourselves with more wisdom, instead of relying on our mass global capitalistic system to deliver easy answers for us from the depths of the profit motive. reply fallingknife 20 hours agoparentprev> AI not only takes jobs away from creatives such as illustratorsWhy do these people deserve protection from automation any more than all the millions of people who worked other jobs tat were eliminated by automation up to this point? reply AlexandrB 16 hours agorootparentThey don&#x27;t. But if you look at predictions of the future like those in optimistic SciFi, the dream was that automation would eliminate repetitive, dirty, and dangerous jobs, eliminate scarcity of basic necessities like food, and free up every individual to pursue whatever creative endeavours they wish.What we&#x27;re getting instead is the automation of those creative endeavours, while leaving a \"gap\" of repetitive, mind numbing work (like labelling data or doing basic physical tasks like \"picking\" goods in an Amazon warehouse) that still has to be done by humans. reply Turing_Machine 6 hours agorootparentYou&#x27;re confusing \"enjoying a creative endeavor\" with \"being able to make a living from that creative endeavor\".Hand weaving is a creative endeavor, but almost no one makes a living from hand weaving today. People still do it for fun, though.The upside there is that most people are able to afford more than two sets of clothing (one for daily wear, one for church, weddings, funerals, etc.). reply vouaobrasil 20 hours agorootparentprev> Why do these people deserve protection from automation any more than all the millions of people who worked other jobs tat were eliminated by automation up to this point?You got it!!! All those other people DO deserve protection from automation! But our society made a mistake and pushed them out. Many communities were destroyed by efficient automation and guess what, efficient automation via cars and vehicles is what caused our most immense disaster now, the climate crisis.We made a mistake by creating so much automation. We should strive to recreate smaller communities in which more creative AND manual tasks are appreciated. reply Turing_Machine 6 hours agorootparent> We made a mistake by creating so much automation.So you&#x27;re volunteering to become a stoop-labor agricultural serf, then? reply anon291 14 hours agorootparentprev> We made a mistake by creating so much automation. We should strive to recreate smaller communities in which more creative AND manual tasks are appreciated.Those exist? reply somestag 17 hours agorootparentprevI agree with your point, but I think the honest answer to your question is that people view creative jobs as aspirational whereas the other \"rote\" jobs that were being automated away were ones that people would have preferred to avoid anyway.When we&#x27;re getting rid of assembly line jobs, or checkout counter staff, or data entry clerks, or any other job that we know is demeaning and boring, we can convince ourselves that the thousands&#x2F;millions put out of work are an unfortunate side effect of progress. Oh sure, the loss of jobs sucks, but no one should have to do those jobs anyway, right? The next generation will be better off, surely. We&#x27;re just closing the door behind us. And maybe if our economic system didn&#x27;t suck so much, we would take care of these people.But when creatives start getting replaced, well, that&#x27;s different. Many people dream of moving into the creative industry, not out of it. Now it feels like the door is closing ahead of us, not behind us. reply lewhoo 20 hours agorootparentprevThe answers may or may not have any sense depending whether or not you find something in us not worth automating at all. Is there such a thing ? reply postexitus 20 hours agorootparentprevBecause we don&#x27;t like white collar people losing their jobs. Blue collar on the other hand deserve what&#x27;s coming to them, as they didn&#x27;t prepare themselves for what the future brings.&#x2F;s reply ChatGTP 20 hours agorootparentlearn to code. reply deagle50 19 hours agorootparentlearn to maintain HVAC reply AlexandrB 16 hours agorootparentNo kidding. It looks like the most secure jobs will be \"the trades\" since the environment these professionals work in is the most variable&#x2F;least structured and thus least susceptible to automation by robotics.My \"Plan B\" is becoming an electrician. replyChatGTP 20 hours agoparentprevit also is removing the reliance that people have on each other.On the other hand access to information has given me more independence, and this hasn&#x27;t been a bad thing. I do rely less on others, like my parents, but I still love them and spend more time having fun with them rather than relying on them.I do understand what you mean, it just doesn&#x27;t like up as all negative to me.I also think open source AI will destroy any feudalistic society. These companies like MS are going to have a problem when their own technology starts to destroy their value add.Look ad Adobe and some of the open source video and graphis editing AI software, there goes one fiefdom. reply leoc 19 hours agoprev> The biggest loss of all, though, is a necessary one: the myth that anything but a for-profit corporation is the right way to organize a company.Hmmmh?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robert_Bosch_Stiftunghttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tata_SonsIf anything it seems like the more likely lesson is that Altman manoeuvred OpenAI into a situation which was incompatible with its non-profit objectives. reply xxpor 13 hours agoparentThe Bosche example doesn&#x27;t really match:>Although the charity is funded by owning the vast majority of shares, it has no voting rights and is involved in health and social causes unrelated to Bosch&#x27;s businessThere&#x27;s also the example of Ikea&#x27;s ownership structure, but that&#x27;s just a giant tax dodge. reply leoc 13 hours agorootparent> The Bosch example doesn&#x27;t really matchYes, I think you&#x27;re right there. reply superultra 20 hours agoprevAnyone here that has worked with a non-profit can recognize the scenario of boards operating untethered by the sometimes more relatable profit motive.I think what remains to be seen is who is on the right side of history. The real loser here is probably ethical AI. I know this won’t be a popular opinion around here, but it’s clear to me that with computing and AI, we may be in an echo of the Industrial Revolution where the profit motive of the 19th century led to deep human injustices like child labor and unsafe and inhumane working conditions.Except of course that AI could have even more impact - both positive and negative, in the same way socmed has. reply cleandreams 14 hours agoprevI worked for a startup acquired by Microsoft and suffice to say, MS is a culture killer. Our open dynamism and free discussion withered under a blanket of MS management.I don&#x27;t think it&#x27;s possible that the cultures of OpenAI and MS can be made compatible. MS is dreary. Highly effective at productizing, yes. But the culture that propels deep innovation -- that is not going to last. reply Turing_Machine 6 hours agoparentWas that under Nadella, though?Things have changed quite a bit, as I understand it. reply asb 20 hours agoprev> Here’s the reality of the matter, though: whether or not you agree with the Sutskever&#x2F;Shear tribe, the board’s charter and responsibility is not to make money. This is not a for-profit corporation with a fiduciary duty to its shareholders; [...] to the extent the board believes that Altman and his tribe were not “build[ing] general-purpose artificial intelligence that benefits humanity” it is empowered to fire him; they do, and so they did.I would quibble with this slightly. They do have a right to fire, but they&#x27;re doing a poor job of working in the not-for-profit&#x27;s interests if they do so in a way that collapses the value of their biggest asset (the for-profit), especially when other options are potentially available. e.g. a negotiated exit, providing proper warning to their investors etc etc. reply leetharris 16 hours agoprevIt&#x27;s so weird that people think a bunch of personnel moving to MS is a win for MS.They can&#x27;t just magically recreate what OpenAI has done. The data sets, the tooling, the models, the everything around it. It will take so long for MS to catch up even if they had 100% of their people working on it tomorrow.The rest of the market is going to benefit more than MS. reply tedivm 16 hours agoparentTheir contract with OpenAI gives them unlimited access to the data sets, the tooling (which is all on Azure and was built out with the help of Azure engineers), the models and their weights, and basically everything around it. reply RadixDLT 16 hours agoprevOpenAI&#x27;s co-founder Ilya Sutskever and more than 500 other employees have threatened to quit the embattled company after its board dramatically fired CEO Sam Altman. In an open letter to the company&#x27;s board, which voted to oust Altman on Friday, the group said it is obvious &#x27;that you are incapable of overseeing OpenAI&#x27;. Sutskever is a member of the board and backed the decision to fire Altman, before tweeting his &#x27;regret&#x27; on Monday and adding his name to the letter. Employees who signed the letter said that if the board does not step down, they &#x27;may choose to resign&#x27; en masse and join &#x27;the newly announced Microsoft subsidiary run by Sam Altman&#x27;. reply anonymouskimmer 16 hours agoparent> Sutskever is a member of the board and backed the decision to fire Altman, before tweeting his &#x27;regret&#x27; on Monday and adding his name to the letter. Employees who signed the letter said that if the board does not step down,This reads like a disingenuous strategy to get rid of the other three members (one half) of the board. A real coup, not a fake one. I know nothing about any of these people, but it seems possible Sutskever convinced the board to make a decision that he knew would have an outcome that would end in them being fiduciarily obliged to resign so that he, Altman, and Brockman could come back as the entirety of the board. And if the hiring by MS is involved, then MS would then control the board of the non-profit. reply btbuildem 20 hours agoprevInteresting and insightful read - definitely seems like someone has been paying attention throughout.I can&#x27;t get past this snippet:> they ultimately had no leverage because they weren’t a for-profit company with the capital to be truly independent.Maybe I don&#x27;t understand non-profits, but.. they&#x27;re allowed to amass a war chest for expansion and to pay for dependencies, right? They&#x27;re not compelled by charter to have no capital like some sort of a corporate equivalent of a monk -- it&#x27;s just OpenAI that did not have enough capital to grant them better negotiating terms. How is that different from any other startup that gives up ownership of its IP in exchange for investment? reply pgsandstrom 20 hours agoparentThis article read to me like someone tryint to shoehorn \"non-profits sucks\" into an otherwise interesting narrative. reply magarnicle 10 hours agorootparentIn this case, I think it&#x27;s \"non-profits suck\" for business analysts. How can you predict what those do-gooders will get up to if they sometimes refuse to make the numbers get bigger? reply asimovfan 20 hours agoparentprevI think this mainly means they dont pay out dividends to shareholders reply amadeuspagel 19 hours agoparentprevIt&#x27;s different from other startups, because other startups can promise potentially infinite returns in exchange for investments, while Open AI had capped returns. reply btbuildem 14 hours agorootparentThat sounds like the very likely most notable difference. reply zone411 21 hours agoprevThe pre-open market doesn&#x27;t see it as a big win for MSFT. The stock is still lower than it was at Friday&#x27;s open. reply HarHarVeryFunny 20 hours agoparentIt doesn&#x27;t seem like it is a big win for MSFT. Hard to argue that MSFT is now in a better position than they were before this happened.Best case scenario for MSFT probably would have been to negotiate Altman et al back to OpenAI with some governance changes to boost stability. Keep the OpenAI GPT-N momentum going that they have harnessed for themselves.MSFT have managed to neutralize (for now) the threat of Altman et al creating a competitor, but this has come at the cost of souring their relationship with OpenAI who they will continue to be dependent on for AI for next couple of years.Big question here is what happens to OpenAI - can they keep the momentum going, and how do they deal with their sugar-daddy & compute-provider MSFT now also being a competitor? How much of the team will leave, and can they recover from that ? reply chucke1992 20 hours agorootparentThe thing is Satya has played the best possible hand in the current situation. MSFT did not fall much and 1-2% deviation does not mean much on the long run. reply HarHarVeryFunny 19 hours agorootparentAgreed - he contained the damage as best as could be done. reply alexb_ 20 hours agoparentprevIf Mr. Market was perfectly rational and correct, profit would cease to exist. reply panragon 20 hours agorootparentThat&#x27;s not true, Capital would still accumulate returns higher than the cost of inventory plus wages, the return would just be the same &#x27;everywhere&#x27;, and you&#x27;d have a perfect market alpha for all stocks, whether it be 1, 2, 5, or 10%. Even perfectly rational markets do not establish socialism overnight. Now maybe you could argue under a Marxist lens that exploitation would be more &#x27;visible&#x27;, causing socialism to arrive out of social rebellion faster, but that&#x27;s really besides the point.What would cease to exist would simply be speculation and arbitrage. Since all prices are perfect, you simply wouldn&#x27;t be able to make more (or even less, for that matter) money than the return on capital everyone gets by buying and selling shares quickly. reply latency-guy2 16 hours agorootparentprevWhy? That is a gigantic statement to make to provide no backing for. reply airstrike 3 hours agoparentprevMSFT is also at an all-time high so it&#x27;s natural for them to be slightly lower reply dpflan 20 hours agoprevIt really depends what actually happens, on paper OpenAI business leadership is now at MSFT. Research leadership seems to be at OpenAI. What does OpenAI need to pursue its goal? One may argue that hiring developed under ex-OpenAI leadership was to facilitate the productization of the models. Does someone know the actual engineering&#x2F;product&#x2F;research makeup of the OpenAI that can provide substance? reply Futurebot 16 hours agoprev\"The biggest loss of all, though, is a necessary one: the myth that anything but a for-profit corporation is the right way to organize a company.\"Alternatively, we could have these companies turned into research organizations run by the government and funded by taxes they way most research (e.g. pharmaceuticals) should be. There&#x27;s more than one way to get good research done, and having it public removes many strange incentives and conflicts of interest. reply xxpor 13 hours agoparentCompare OpenAI&#x27;s funding to the national labs.Sandia and Los Alamos both receive about $4.5 billion per fiscal year. OpenAI is likely spending an order of magnitude more than that. reply asadotzler 10 hours agorootparentReally? OAI spending 45 billion dollars a year with fewer than 1,000 employees? Seems unlikely. reply artisin 20 hours agoprevIt does lend credence to an emerging landscape trend that suggests large companies, not disruptive startups, will dominate AI development due to high costs and infrastructure needs. reply floor_ 20 hours agoprevShengjia Zhao&#x27;s deleted tweet: https:&#x2F;&#x2F;i.imgur.com&#x2F;yrpXvt9.png reply padolsey 20 hours agoprevI&#x27;m a bit confused. Does MSFT have a perpetual license to the original OpenAI LLC&#x27;s IP *or* the capped company OpenAI \"Global\" LLC that was specifically created for MSFT&#x27;s stake? Because, if the latter, it seems like the new&#x2F;abandoned&#x2F;forsaken OpenAI could just fork any new IP back into its original non-microsoft-stained LLC and not be mere tools of Microsoft moving forward. reply manyoso 20 hours agoparentUndoubtedly they have a perpet on what they released so far: chatgpt4. Not so for new innovations or tech. reply padolsey 20 hours agorootparentSo when the author states that \"Microsoft just acquired OpenAI for $0\" they mean, effectively, only a fixed-time snapshot of code that is likely old news in about 18 months by the time other models have caught up. Microsoft still needs to execute like mad to make this work out for them. Right now the entire thing seems to rest on the hope that enough talent bleeds out of OpenAI to make this worthwhile. They&#x27;ll probably get that. But it&#x27;s still a delicate game. I most wonder what breakthrough Ilya has been alluding to recently [1] and whether it&#x27;ll be available under MSFT&#x27;s license.[1] https:&#x2F;&#x2F;youtu.be&#x2F;Ft0gTO2K85A?si=YaawmLi8zKrFxwue&t=2303 reply bamboozled 20 hours agorootparentPlenty of them can go to Google, Anthropic, Apple, Tesla, Amazon or any other attractive company to work for. By attractive I mean they&#x27;d be compensated well enough to have a nice life there.There&#x27;s not a lot to suggest everyone will jut join M$ by default. reply Terretta 19 hours agorootparentprevIf you have:- intellectual property as of today- the servers that run it- the people that wrote it- the executive leadership that executed the play so far and know the roadmap aheadWhat else do you need? reply sp332 17 hours agorootparentDevelopment work on GPT5, curated input datasets, human feedback data, archives of all ChatGPT conversations, DALL-E, stats on which users are the big spenders, contracts with cheap labor to generate data and moderate abuse... replykaycebasques 16 hours agoprev> The biggest loss of all, though, is a necessary one: the myth that anything but a for-profit corporation is the right way to organize a company.This is a big picture idea that we should examine more closely. Right now, in the heat of the chaotic collapse, it&#x27;s easy to conclude that for-proft corp structure is the only way to go. But I think we should take a \"proof is in the pudding\" approach and remember all the amazing things that OpenAI accomplished under it&#x27;s non-conventional org structure. Maybe that non-conventional org structure was a key ingredient in OpenAI&#x27;s success? Sure, we now know that \"long-term stability\" does not seem to be a quality of this org structure, but nonetheless it seemed to have lots of other desirable qualities. reply typon 16 hours agoparentWhy does it have to be all or nothing? Why not non-profit in the start when you need to attract scientists and engineers who are in it for the challenge, and then change to for profit when you need to attract product managers and people who will scale the company and make it sustainable. reply woliveirajr 20 hours agoprev> Two years later, and the commitment to “openly share our plans and capabilities along the way” was gone; three years after that and the goal of “advanc[ing] digital intelligence” was replaced by “build[ing] general-purpose artificial intelligence”.Be no evil, for example. Billions and billions were made when that phrase was erased. reply nimish 20 hours agoprevIf the openai board can&#x27;t get humans to align, what hope do they have of \"aligning\" ml models? reply catchnear4321 20 hours agoparentpeople in alignment with each other is agreement.a language model in alignment is control.the model does not need to be aligned with the desires of people. just person. it could be people, but getting alignment with people is… reply jebarker 20 hours agoprev> What gives me pause is that the goal is not an IPO, retiring to a yacht, and giving money to causes that do a better job of soothing the guilt of being fabulously rich than actually making the world a better place.Ouch. Is that really the ideal vision of founding a SV startup? reply SilverBirch 20 hours agoprevI can&#x27;t imagine what it will be like to work at OpenAI over the next few months. A massive load of talent has just left, the primary source of investment has just taken exactly what you do and brought it in house. Even if you wanted to stay at OpenAI how can you reasonably believe that MS will continue providing the compute and investment necessary for you to retain leadership? It just seems impossible. It may be that in the medium term this move means OpenAI is going to back to more research focus, because I just don&#x27;t see how the MS partnership strategy makes any sense as a long term strategy now. reply ayakang31415 16 hours agoprevOpenAI was non-profit to begin with. Their shenanigans to tip-toeing the line between charity and commercialization were, as it seems, doomed to fail. reply timetraveller26 20 hours agoprevThe biggest problem of Artificial Intelligence are the humans running it reply amadeuspagel 17 hours agoprevA thought experiment to illustrate the incoherence of OpenAI&#x27;s structure. Imagine a company called ProfitAI, a company without any limits on profit and returns, and thus able to raise much more money then OpenAI and using that money to license the base models from OpenAI. Microsoft played the role of ProfitAI here. The non-profit structure only served to ensure that someone else would make the profits. reply kbknapp 20 hours agoprevSeems the author is expecting OAI to continue merrily along its way working towards AGI (albeit at a stated slower pace) while MSFT is able to take Altman et al and circle the wagons on what already exists (GPT4) squeezing it for all its worth. While that&#x27;s entirely possible, there are other outcomes not nearly as positive that would put MSFT at a disadvantage. It&#x27;s like saying MSFT&#x27;s AI hedge is built on what appears like sand; maybe it&#x27;s stable, maybe it&#x27;s not. reply edgyquant 20 hours agoparentDon’t think they can just outright steal GPT4 and they definitely won’t be taking the world class data set with them reply dboreham 21 hours agoprevUnusually well written and apparently well informed article. reply macintux 20 hours agoparentBen Thompson has been a keen observer of the tech industry for quite some time. I recommend browsing the archives, or HN’s history of submissions.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;from?site=stratechery.com reply specificcndtion 15 hours agoprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38350637 :\"None of these companies appease China; they refuse to provide service under those conditions and&#x2F;or they are IP range blocked. Microsoft does service China with Bing, for example.You should not sell OpenAI&#x27;s to China or to Microsoft, [or to China or Russia through Microsoft]Especially after a DDOS by Sue Don and a change in billing.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_websites_blocked_in_ma... reply ecshafer 15 hours agoparentSo? What does it matter if China is blocked? reply neilv 20 hours agoprev> This is, quite obviously, a phenomenal outcome for Microsoft.I don&#x27;t know whether that&#x27;s true, nor do I know went on, but it seems interesting to consider...If OpenAI were government, and the history involved awarding a contract, or administering regulations, we have the concept of a revolving door. reply charles_f 16 hours agoprev> you can make the case that Microsoft just acquired OpenAI for $0.You would first have to make the case that those $11B that gave them the perpetual access to IP are worth $0. Probably not the market cap of OpenAI, but also not 0. reply dalbasal 20 hours agoprevWell written. Well done. Early hn vibes.A lot more in here, that actually helps to understand what&#x27;s going on with openai, and what might happen next in the space.I think the last paragraph is a key point&#x2F;question.\"Ultimately, though, one could make the argument that not much has changed at all: it has been apparent for a while that AI was, at least in the short to medium-term, a sustaining innovation, not a disruptive one, which is to say it would primarily benefit and be deployed by the biggest companies. The costs are so high that it’s hard for anyone else to get the money... ..This, in the end, was Nadella’s insight: the key to winning if you are big is not to invent like a startup, but to leverage your size to acquire or fast-follow them.\"Use models like innovative disruption with caution. Look to their assumptions.How this plays out is not going to follow the pattern of web 2.0 or Kodak digitization.The road to AGI is one thing. The road to 1 billion market caps.. not necessarily that same thing.The road to victory, or definition of victory, are very vague still. reply burntalmonds 19 hours agoprevI don&#x27;t think MS expects this to really happen. It&#x27;s negotiation, designed to make OAI&#x27;s board come to their senses and reinstate Altman. reply lysecret 20 hours agoprevReally absolutely fascinating to see this unfold. I believe more and more the most realistic explanation is the next GPT will be mind-blowing. reply lightedman 19 hours agoprevI wonder if MS is aware of the allegations against Sam Altman, which were put forth by his sister, of sexual, financial, and other abuse. reply pklhr 20 hours agoprevDrama continues.I think he might regret publishing this a wee bit early :) reply akamaka 20 hours agoprevThis article is missing the point that, for decades, Microsoft has been trying and failing to hire the best AI researchers. They might succeed at commercializing the current generation of LLMs, but the revolutionary breakthroughs will still happen elsewhere, in an organization that is built for researchers. reply rekuber 17 hours agoprevThe real loser in this chaos is Microsoft.Remember skype? Microsoft had to buy it twice to gain usable access to IP. reply bigEnotation 20 hours agoprevI feel like I’m missing something about this chatGPT craze… to me the product is chatGPT, and it’s mostly fleshed out (would like to see the ability to upload an image, as part of a conversation), I don’t see the appeal for paying 100x more for every new iteration for a marginal reduction in misinformation.To me the target user of chatGPT needs to have some level of expertise in the domain their asking a question, as based on how gpt works, chatGPT will eventually produce an output with misinformation, therefore someone familiar with the subject matter would have a higher chance at catching the nuance in a response and be able to continue their conversation. reply maxdoop 20 hours agoparentYou are 100% missing something. You don’t see the current value nor potential of what these LLMs are capable of.They are as “dumb” as they will ever be right now. To act like it’s just a chat bot is the silliest take. reply lewisjoe 20 hours agoprevTLDR:Open AI structured its organization such that there&#x27;s no boss. And even if there is one, it&#x27;s not about the money.Reality hits Open AI: There is always a boss and it&#x27;s always about money. reply mymusewww 20 hours agoprevPeople are thinking this guy is rich. He’s a pawn like anyone else without a billion dollars. This means nothing for tech. reply nemo44x 19 hours agoprevThe best part of Satya’s tweet is that he opens it with “we’re committed to our partnership with OpenAI” and then mentions that he’s hiring Sam and Greg and “colleagues”. Nearly spat my tea out laughing at that one. Well played. reply photochemsyn 20 hours agoprevI really see no reason that LLMs can&#x27;t go the way of operating systems when it comes to the success of the open-source approach vs. the proprietary closed-source approach.The argument over for-profit vs. non-profit is largely meaningless, as anyone who is paying attention knows that &#x27;non-profits&#x27; just use different methods to distribute the revenue than for-profits do, using various smoke-and-mirrors approaches to retain their legal status. Arguably a non-profit might put more revenue back into R & D and less into kickbacks to VC investors but that&#x27;s not always the case.Additionally, given all the concerns about \"AI safety\" open-source seems like the better approach, as this is a much better framework for exposing biases, whether intentional or accidental. There are many successful models for financing the open-source approach, as Linux has shown. reply Eumenes 20 hours agoprevGiven Microsoft is an apparatus of the US federal government and globalization in general, I suspect TPTB are pretty content with this outcome. reply manyoso 20 hours agoprevLOL This is more of the Altman based media blitz to drive this in his favor. This is nothing short of an unmitigated DISASTER for Microsoft and they well know it. reply flappyeagle 20 hours agoparentYou keep saying this. Why? reply edgyquant 20 hours agorootparentNot them but it’s not a good look to spend 10B in a bet for zero control. Also to spend months building up to an acquisition (there’s no way that wasn’t what Sam was trying for) only for it to result in the firing of the CEO who was trying to sell his company to you.This looks terrible, and all of these “Sam is the real winner” posts are cope reply flappyeagle 16 hours agorootparentThe majority of that money is in the form of Azure credit.It all pretty much hinges on how much talent you think Microsoft can obtain. I’m going to make a bet that Microsoft poaches between 30 and 70% of open AI key employees.If they spent $10 billion to achieve this outcome, securing the loyalty of the two founders and attracting double digit percentage of the employees, then they will have conservatively gotten a 5 to 10x return overnightEdit: I was too conservative, it&#x27;s looking like 90% reply maxdoop 20 hours agoparentprevIs there anything that would persuade you this isn’t some sneaky media frenzy orchestrated by Altman? reply 11 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI's CEO and President have been fired by the board, leading to their employment at Microsoft.",
      "Microsoft already has a perpetual license to OpenAI's IP, strengthening their position in the AI industry.",
      "Concerns about OpenAI's incentives exist, as their mission shifted over time and financial needs led to creating OpenAI Global with Microsoft as a minority owner.",
      "(Note: There are more points in the text, but I have selected the most important ones for the summary.)"
    ],
    "commentSummary": [
      "The discussion revolves around OpenAI's partnership with Microsoft, with concerns raised about potential negative effects on OpenAI employees and doubts about the future of OpenAI under Microsoft's leadership.",
      "There is also speculation about the possible brain drain of talented employees from OpenAI due to the acquisition.",
      "The conversation delves into broader topics such as the societal impact of AI, the role of non-profit organizations, and the implications of automation in various industries."
    ],
    "points": 448,
    "commentCount": 266,
    "retryCount": 0,
    "time": 1700482225
  },
  {
    "id": 38351195,
    "title": "Unlocking the Power of Functional Programming: Insights from Carnegie Mellon University's Course",
    "originLink": "https://brandonspark.github.io/150/",
    "originBody": "home blog about me teaching 15150 creative projects github twitter 15-150: Principles of Functional Programming Introduction I had the pleasure of serving as the summer instructor for 15-150, the introduction functional programming class for computer science students at Carnegie Mellon, in the Summer 2023 semester. This course typically serves as the second or third course in the traditional computer science undergraduate sequence, a privilege which not many other universities get to enjoy, as functional programming is often considered a niche topic. Despite this, I (and CMU) believe this to be of the utmost importance. A disciplined, type-oriented, safety-first view of programming can be of utmost benefit to burgeoning computer science scholars, and I have often heard feedback from students that it is has a transformative view on their perspective of computer science in general. To that end, I have made my lecture materials from my iteration of the course available for free on the Internet. Please feel free to use this knowledge in any way that you see fit, and I hope that it aids you in your future endeavors. Lectures Lecture 01: Prologue \"Welcome to the rest of your life!\" Lecture 02: Equivalence, Binding, and Scope \"Equivalences save lives.\" Lecture 03: Induction and Recursion \"Recursion is the bread and butter of doing anything in a functional language.\" Lecture 04: Structural Induction and Tail Recursion \"Proving things about pretty much any kind of data you can imagine.\" Lecture 05: Trees \"Trees are the most fundamental data structure.\" Lecture 06: Asymptotic Analysis \"A step is not always a step. We care about analyzing performance mathematically.\" Lecture 07: Sorting and Parallelism \"What do we do when we have infinitely many processors?\" Lecture 08: Polymorphism \"Code reuse at different types, without breaking any of our safety properties.\" Lecture 09: Higher-Order Functions \"We can take in functions and also return functions, like any other value.\" Lecture 10: Combinators and Staging \"You shouldn't have to wait on something unrelated when you can do work right now.\" Lecture 11: Continuation-Passing Style \"CPS is the difference between writing instructions now, or remembering them later.\" Lecture 12: Exceptions \"Exceptions make mathematical thinking harder.\" Lecture 13: Regular Expressions \"Regular expressions are one of the most practical things you can learn.\" Lecture 14: Structures and Signatures \"SML has one of the most sophisticated module systems of any programming language.\" Lecture 15: Functors \"Functors will show us how we can write code that depends upon modules.\" Lecture 16: Red-Black Trees \"Red-black trees are a very good application of modules for protecting invariants.\" Lecture 17: Sequences \"With sequences, we can keep immutability and also have the benefits of arrays.\" Lecture 18: Lazy Programming \"With laziness, only pay for for the computations you want to use.\" Lecture 19: Imperative Programming \"We invented immutability and purity, but we do not serve them. It's OK to be a little mutable.\" Lecture 20: Compilers \"A long time ago, programming languages did not exist.\" Lecture 21: Program Analysis \"We are solving an unsolvable problem.\" Lecture 22: Finale \"You can never go back, because you are forever a functional programmer.\" © 2023 Brandon Wu",
    "commentLink": "https://news.ycombinator.com/item?id=38351195",
    "commentBody": "15-150: Principles of Functional ProgrammingHacker Newspastlogin15-150: Principles of Functional Programming (brandonspark.github.io) 397 points by brandonspark 16 hours ago| hidepastfavorite115 comments jstrieb 10 hours agoI loved 150 when I took it, and program in SML from time to time to this day.Bob Harper (a CMU professor with a focus on PL theory) also has a really good SML reference that is closer to a textbook than lecture notes.http:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~rwh&#x2F;isml&#x2F;book.pdf reply asicsp 5 hours agoprevSee also: https:&#x2F;&#x2F;functionalcs.github.io&#x2F;curriculum&#x2F;#orge441e24 reply aroman 13 hours agoprev150 was one of my favorite courses at CMU; each homework really made me feel like I unlocked a new level of reasoning with code. reply louthy 12 hours agoparentThat&#x27;s how I felt when I discovered FP after more than two decades writing procedural and OO code. It felt like I&#x27;d found a secret room where all the reasoning was kept. reply adamddev1 4 hours agorootparentYes! I love this description! reply 3abiton 11 hours agoparentprevDo you if any of the course material is available online or as a MOOC? reply rashkov 8 hours agorootparentHave a look at this similar course: https:&#x2F;&#x2F;www.coursera.org&#x2F;learn&#x2F;programming-languages I enjoyed it quite a bit and the lecturer is fantastic. It also uses SML and teaches similar material, though maybe not as in depth since this is just the first section of a three-part semester long course. reply valenterry 2 hours agoprevNo word on where the concept originally comes from? (in the text&#x2F;description)Should have at least differentiated between \"functional programming\" and \"pure functional programming\" IMHO. reply vermilingua 13 hours agoprevContent aside, what gorgeous slides. I wish any of my lecturers had the same eye for presentation. reply PennRobotics 47 minutes agoparentPartial template source of the slides is available at https:&#x2F;&#x2F;github.com&#x2F;jacobneu&#x2F;150lectureNotes (For the uninitiated, it&#x27;s a Beamer theme, compiled with LaTeX)Some assembly required; use the instructions from https:&#x2F;&#x2F;github.com&#x2F;jacobneu&#x2F;alleycat as inspiration, use the scripts (e.g. startLecture) and Makefile in &#x2F;crucible reply frankbreetz 14 hours agoprevDoes this include exercises? I didn&#x27;t see any and I always find that the most useful part of learning. reply brandonspark 14 hours agoparentUnfortunately, it does not. These lectures are \"mine\", in the sense that I developed all of them myself, but the homeworks and lab exercises are the combined efforts of generations of TAs and instructors from the past. It wouldn&#x27;t be right for me to give them away. (they are also reused from time to time, so there are academic integrity concerns with that also) reply brandonspark 14 hours agorootparent(but I have thought of developing my own exercises independently to go with the lectures, to post on my website. This is generally a lot of work, though, so this might take some time, depending on how much people would benefit from it.) reply bombcar 7 hours agorootparentCould be a classic kickstarter campaign style thing. reply brandonspark 6 hours agorootparentHaha, maybe. I&#x27;m not looking to earn any money from this, though. Time is the bigger constraint in my life at the moment. reply doktrin 1 hour agorootparentprevTIL. Given that 15-213 has been widely available for years I naively assumed this would also hold true for other undergrad CS courses, but apparently not. reply brandonspark 13 hours agoparentprevIf you get to around lecture 9, a classic example I always tell people to start with is a calculator!For instance, here&#x27;s the SML code for it:``` datatype exp = Num of intPlus of exp * expMinus of exp * expTimes of exp * expDiv of exp * exp```Implement the function `eval : exp -> int`, which evaluates the expression as best as it can. Assume no division by zero.Extra credit: Can you implement `eval&#x27; : exp -> int option`, that returns `SOME n` if the expression evaluates, and `NONE` if it divides by zero? reply PennRobotics 14 hours agoparentprevNot exactly exercises, but there&#x27;s https:&#x2F;&#x2F;smlhelp.github.io&#x2F;book&#x2F;docs&#x2F; which supports the course and explains each of the concepts as well as library documentation at the official class site, http:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~15150&#x2F;resources.htmlIt looks like their current workflow keeps exams and homeworks off the internet effectively, but there&#x27;s a 6-year-old codebase at https:&#x2F;&#x2F;github.com&#x2F;zhengguan&#x2F;15150-1 with 10-year-old homeworks and such. reply mbivert 13 hours agoparentprevRewriting standard list functions (map, fold, sum, etc.) is a good entry-level exercise.A λ-calculus interpreter can be used as an intermediate level exercise. It is in particularly valuable in the context of solidifying one&#x27;s understanding of functional programming.You can also use \"standard\" textbooks, such as the SICP [0], and perform the exercises using the language of your choice, instead of Scheme&#x2F;LISP.[0]: https:&#x2F;&#x2F;mitp-content-server.mit.edu&#x2F;books&#x2F;content&#x2F;sectbyfn&#x2F;b... reply fredgrott 14 hours agoparentprevmaking up your exercises is part of that fun journey of creating your own toolbox of functional programming in your language of choice! reply ajbt200128 14 hours agoprevOf note, CMU produces a bunch of functional programming research, including a whole homotopy type theory department, so this is a quality source. reply low_tech_punk 13 hours agoprevGod send!! The FP learning resource is quite sparse on the internet. I’ve been looking for structured material like this for a while. reply adamddev1 4 hours agoparentIf you&#x27;re fairly new to FP I really recommend working through https:&#x2F;&#x2F;htdp.org. reply hohohmm 8 hours agoprevUse to be called 15-212. TA-ed it for 1 semester. That&#x27;s when I really understood programming. reply andrewl 15 hours agoprevThis looks valuable. And it is from the summer of 2023, so quite current. reply agomez314 14 hours agoprevGreat resource! Forgive my ignorance but why do so many modern functional programming courses use Standard ML instead of a Lisp dialect? Is it because of its built-in type-checking, or is it just how it&#x27;s always been taught? reply johnday 14 hours agoparentThe value of purely functional programming languages, as opposed to functional programming languages like lisps, is that you get referential transparency, which means that when you define `a = b`, you know that you can always replace any instance of `a` with `b` and get the same answer. This is a very natural property in mathematics (algebraic rewritings are basically just this property writ large) and so it helps to draw nice parallels between the familiar notation of functions from mathematics and the \"new\" and \"confusing\" notion of functions in functional programming and other declarative languages.As other posters have said, strong typing is also a nice property for lots of reasons, most notably it gives a platform to talk about ad-hoc and parametric polymorphism.(I lecture on Functional Programming at the University of Warwick, where we use Haskell.) reply tonyg 1 hour agorootparentThe first problem with this argument is that referential transparency is a property of syntactic positions, not of languages.The second is that languages like Lisp, SML, C, Pascal and BASIC all have referentially transparent and referentially opaque positions in exactly the same way that languages like Haskell do.This means that all these languages enjoy referential transparency in the same way, because when you unpack the notion of equivalence, referential transparency itself is within a whisker of being a tautology: if a is equivalent to b, then you can substitute a for b or b for a. The relevant sense for \"is equivalent to\" can really only be contextual equivalence, which is all about meaning-preserving substitutability.That said, not having to reason about effects within one&#x27;s program equivalence sure makes things simpler in a pedagogical setting. But that&#x27;s not to do with referential transparency per se. reply tmvphil 13 hours agorootparentprevI think SML isn&#x27;t purely functional (although it naturally encourages a purely functional style). reply albedoa 14 hours agorootparentprevFor those of us who are unfamiliar with Lisps, can you expand on how they break referential transparency (and how Standard ML contrasts in that regard)? reply epgui 11 hours agorootparentThey don’t.Or at least not inherently, if by “lisp” one is primarily referring to s-expressions. reply medo-bear 13 hours agorootparentprevHe is probably talking about namespaces. In common lisp, for example, (a a)calls a function &#x27;a&#x27; on a variable &#x27;a&#x27;. Lisp knows this because the first thing that comes after the left paren is a function reply convolvatron 12 hours agorootparentmore importantly there are functions (using scheme as an example) like set! and set-cdr! that mutate existing values and totally break referential transparency.this isn&#x27;t just user facing - for example let* kind of depends on creating bindings up front so they work across clauses, and then mutating them afterwards reply amake 7 hours agorootparentWhy does `let*` need to have mutation? It can be nested `let`s. reply convolvatron 7 hours agorootparentlet* permits expressions on the right refer to arbitrary other symbols bound by the let*. in particular it allows for construction of recursive lambdas that may not be linearlizable. reply amake 6 hours agorootparent> let* permits expressions on the right refer to arbitrary other symbols bound by the let*In what language? I just checked Elisp, SBCL, and Guile, and they all error out if you refer to a variable not previously defined by a left-to-right traversal of the varlist: (let* ((a (+ b 1)) (b 1)) a)Edit: This doesn&#x27;t work either: (let* ((a (lambda () (+ b 1))) (b 1)) (funcall a)) ; (funcall a) -> (a) for Schemes reply amake 4 hours agorootparentAnyway, as far as I&#x27;m seeing it&#x27;s perfectly possible to implement let* consistent with the above behavior as a macro without mutation as such: (define-macro (let* bindings &rest body) (if (null? bindings) `(progn ,@body) `(let (,(car bindings)) (let* ,(cdr bindings) ,@body)))) reply tonyg 1 hour agorootparentprevYou&#x27;re thinking of letrec. reply amake 1 hour agorootparentAh, that does look to be the case. I didn&#x27;t know about that one. Signature (letrec BINDERS &rest BODY) Documentation Bind variables according to BINDERS then eval BODY. The value of the last form in BODY is returned. Each element of BINDERS is a list (SYMBOL VALUEFORM) that binds SYMBOL to the value of VALUEFORM. The main difference between this macro and let&#x2F;let* is that all symbols are bound before any of the VALUEFORMs are evalled. reply medo-bear 2 hours agorootparentprevLisp allows you to mutate, you can certainly write non-mutating code in lisp. Why do you think you need to use mutation with let*? let* is just a sequential lethttps:&#x2F;&#x2F;www.lispworks.com&#x2F;documentation&#x2F;lw70&#x2F;CLHS&#x2F;Body&#x2F;s_let... replychriswarbo 11 hours agoparentprev\"Lisp\" is pretty broad. Whilst it was inspired by Lambda Calculus (the core of most FP languages), a lot of Lisp code is quite imperative (loops, mutable variables, control flow separate from data flow (e.g. exceptions&#x2F;errors), etc.).Scheme (and its dialects&#x2F;descendants) tend to stick to a more functional style (although they also like to do stack-gymnastics with continuations, etc.). Many courses are based around Lisp.One of the main features of the ML family is static typing, with algebraic datatypes, pattern-matching, etc. (i.e. the stuff that new languages like to call \"modern\", because they first saw it in Swift or something). That gives a useful mathematical perspective on code (\"denotational semantics\", i.e. giving meaning to what&#x27;s written; as opposed to the common \"operational semantics\" of what it made my laptop do), and having type checking and inference makes it easier to do generic and higher-order programming (dynamic languages make that trivial in-the-small, but can make large systems painful to implement&#x2F;debug&#x2F;maintain&#x2F;understand). This course seems to take such abstraction seriously, since it covers modules and functors too (which are another big feature of the ML family).NOTE: In ML, the words \"functor\" and \"applicative functor\" tend to mean something very different (generic, interface-based programming) to their use in similar languages like Haskell (mapping functions over data, and sequencing actions together) reply vmchale 14 hours agoparentprevIt is statically typed, there&#x27;s a lot of depth to that side of things (Curry-Howard isomorphism) reply f1shy 14 hours agoparentprevMy opinion: marketing. In my experience, if I tell someone „look here is Lisp“ they turn off and roll the eyes with a „ohh that DEAD origramming language“. If I instead say „look this new state of the art language called ML“ I get full attention and respect. reply ajbt200128 14 hours agorootparentNo, it&#x27;s definitely not because of marketing. SML is more of a dead language than most lisps. SML is used because it has a strong type checker, which is much more conducive to learning, and just having resilient programs in general. reply bmacho 13 hours agoparentprevWhy would they use a Lisp dialect instead of Standard ML? It looks ugly, it looks different from math, and different concepts have the same syntax. Standard ML looks nice, it looks like math, and different concepts have different syntax. reply SomeRndName11 13 hours agorootparentNo, SML is actually quite verbose ang generally ugly, compared to say OCaml or F#, or even Scheme or Closure. This is why it is dead. reply esafak 10 hours agoprevPretty good for a new grad! reply gsuuon 11 hours agoprevThis looks cool! Just a note, it looks like the youtube playlist is in reverse order: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DSGXB9G5dxk&list=PLsydD1kw8j... reply PennRobotics 15 hours agoprevStandard ML (sml &#x2F; smlnj)The instructor is clear, energetic, has a decent flow in the first lecture e.g. emphasizes the important points with vigor and repetition, switches media every 10 or 15 minutes, has a conversation with students. Slides are relatively noise-free and are informative; terms to know are highlighted.I haven&#x27;t watched a full functional programming lecture series yet, but I&#x27;d gladly audit this one.As a \"new\" instructor (as in, not a TA anymore) he&#x27;s got a bit of teaching talent. I hope he keeps a tight feedback loop and improves every year and continues publishing material. reply imslavko 14 hours agoprevSlightly off-topic but what&#x27;s a good forum to seek help on FP practices outside of the courses like this online?Every winter break I get back into trying to learn more FP (in Haskell) and in the past several years I have been practicing algo problems (codeforces, advent of code, leetcode).I always get stuck on more advanced graph algorithms where you traverse a and modify a graph, not a tree structure - it gets particularly tricky to work on circular data structures (I learned about \"tying the knot\" but it&#x27;s incredibly challenging for me) and usually the runtime perf is sub-par both asymptotically and empirically. reply kccqzy 13 hours agoparentMany graph algorithms are designed for imperative programming. It&#x27;s safe to say that functional graph programming is still in its infancy. Alga[0], a system for algebraic graphs only came out in 2017. And efficient algorithms for graphs may yet to be discovered (even something as simple as reversing a list that&#x27;s both efficient and elegant only came out in 1986!)That said, as a beginner in functional programming, it would probably be good enough if you just focus on directly translating imperative graph algorithms to functional programming. You simply solve the problem by programming at a slightly lower level of abstraction.[0]: https:&#x2F;&#x2F;dl.acm.org&#x2F;authorize?N46678 or preprint at https:&#x2F;&#x2F;github.com&#x2F;snowleopard&#x2F;alga-paper&#x2F;releases&#x2F;download&#x2F;... reply philsnow 12 hours agorootparentI don&#x27;t know if [0] would be any help, it doesn&#x27;t talk about graphs in particular but does talk about functional-focused approaches to data structures. This note[1] on the wikipedia page for the book says it better than I could:> [...] consider a function that accepts a mutable list, removes the first element from the list, and returns that element. In a purely functional setting, removing an element from the list produces a new and shorter list, but does not update the original one. In order to be useful, therefore, a purely functional version of this function is likely to have to return the new list along with the removed element. In the most general case, a program converted in this way must return the \"state\" or \"store\" of the program as an additional result from every function call. Such a program is said to be written in store-passing style.[0] https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~rwh&#x2F;students&#x2F;okasaki.pdf[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Purely_functional_data_structu... reply imslavko 10 hours agorootparentOh yeah, a pure function that accepts previous state, and returns the new state is the pattern I use a lot.The issue is that it is hard to do on complex graph structures in an algorithm where incremental changes happen to the graph O(n) times - it ends up creating complex code and complex execution that might be slow to pass the time limit on Codeforces, let&#x27;s say.In the OCaml world maybe this is the place where you say \"screw it, this abstracted function does some stateful temporary business, but it looks pure from the outside\" but in Haskell it&#x27;s a lot harder to pull off without going deep into monads (and I forget how those work every time). reply kccqzy 8 hours agorootparentOh definitely go deep into monads. If you use the ST monad to do mutations, some people think Haskell provides nicer syntax to do imperative programming than traditional imperative languages like C. But of course such nicer syntax only comes from understanding and using important abstractions like monads, foldable, or traversable. Then there are niceties like automatic SoA&#x2F;AoS transformation using type families. reply imslavko 4 hours agorootparentI don&#x27;t think I have heard of the automatic AoS&#x2F;AoS before, do you have good links to study more? replylow_tech_punk 13 hours agoparentprevMy Scala friends heavily rely on discord, e.g. the one mentioned here: https:&#x2F;&#x2F;typelevel.org&#x2F;blog&#x2F;2021&#x2F;05&#x2F;05&#x2F;discord-migration.htmlIt is language based community but they do have vibrant discussion on learning and theories. reply systems 14 hours agoprevon the choice of language to teach the course why smli think there are a lot of nicer choice OCaml , its basically sml only more popular and used more in real life Haskell , again more popular , and used more in real life Idris , newer and said to be more progressive F# , a more practical choice and similar to sml a lisp , well if you want to focus on the functional part and less on the types part reply brandonspark 14 hours agoparentThere&#x27;s a few things which go into this (hi, I&#x27;m the instructor!).One such reason is historical. Standard ML is a research language, and a significant amount of work on it was done by professors at Carnegie Mellon, who developed the curriculum for this course.Even setting that aside though, I fully agree with the choice to teach it in SML. For transparency, I work professionally in OCaml, so I am not unfamiliar with it, and I enjoy it quite a bit. That being said, I think that the approach taken by CMU is best summarized as the fact that languages are ephemeral, and the concepts are what matters. We don&#x27;t teach programming languages, we teach concepts -- so even if SML is not widely used, the tradeoff for having students have a simpler, less distracting, and better learning experience is well worth it.OCaml has its own intricacies that make things difficult. For instance, you can go down a lot of rabbit holes with `dune` and `utop` and `ocamlc` and `ocamlopt` and all of these things, versus SML&#x2F;NJ&#x27;s simple interactive REPL. Another thing is that the language is just generally more \"bloated\" -- you can teach modules, but then what if a student starts running into first-class modules, recursive modules, or even beyond that, GADTs and classes and objects?(as an aside, this is my primary reason for why I would not want to teach an introductory course in Haskell. To do anything, you suddenly need to understand the concept of type classes and lazy evaluation, and that&#x27;s simply too much. I don&#x27;t know much about the other languages.)I think teaching is as much enabling students to succeed as it is to prevent them from shooting themselves in the foot. For an anecdote, there is an `Option.valOf` function (of type `&#x27;a option -> &#x27;a`), which essentially is just a bad function that should be avoided where possible. Every semester, without fail, even though we never tell students that function exists, students are smart enough to use Google, and will use it anyways, ultimately harming themselves.I think that same mentality applies to programming language choice, here. Keep it simple, keep it neat, and make sure that the students see what is necessary for their education, and not have to spend mental energy thinking about much more. reply munchler 14 hours agorootparentAs a professional who uses F# every day, I appreciate this answer, even though it concerns me. Separating concepts from practical details is worthwhile, but can be taken too far. I think the FP community probably focuses a bit too much on theory. I would encourage you to consider teaching a more practical language, like F#, in the future. reply bfors 13 hours agorootparentI feel like F#&#x27;s commercial viability over other more computer sciencey FP languages is actually kind of a downside, from a \"vibe\" perspective. It seems like CS folks are not generally very interested in moving more towards the software engineering end of the discipline. Which is fair, because they are different things. reply zem 13 hours agorootparentprevi think someone with a good grounding in sml could get proficient ocaml or f# in under a month. sml is absolutely the right language to teach a course like this in. reply munchler 8 hours agorootparentI agree with your first sentence, but the second one surprises me. If the practical language and the impractical one are that similar, why pick the impractical one? reply zem 6 hours agorootparentsml is a smaller language, and a \"cleaner\" one in some ways. if your goal is to teach students the elements of functional programming, you want them to be able to concentrate on the core concepts, and not on the incidental details of the language.http:&#x2F;&#x2F;adam.chlipala.net&#x2F;mlcomp&#x2F; is a very good overview of the differences between sml and ocaml, which lets you see some of the tradeoffs each language has made. reply agumonkey 9 hours agorootparentprevhaving done the proglang course by dan grossman long ago, they use sml too, i knew lisps, ocaml, and others, but sml smallness was really really appealing reply weatherlight 13 hours agoparentprevbecause SML is awesome, isn&#x27;t going to change and is simple. you can learn the syntax in an afternoon, and really focus on learning FP semantics. reply __rito__ 4 hours agorootparentAlbeit little, installing SML still requires some anount of gymnastics, google searching, and copying stuff from SO, GH Gists, etc.Yes, I agree broadly with the line of thinking that says- if you are learning FP, you must be willing to do these, but a beginner might be disheartened and turned away- especially as someone learning alone. reply SomeRndName11 13 hours agorootparentprevThe problem that is extremely verbose though. OCaml is much more concise. reply weatherlight 12 hours agorootparentBoth languages encourage a concise, functional programming style but with different flavors and toolsets. They are comparable, in terms of verbosity.I think these are correct implementations of the tower of Hanoi.OCaml let rec hanoi n source target auxiliary = if n > 0 then begin hanoi (n - 1) source auxiliary target; Printf.printf \"Move disk from %s to %s\" source target; hanoi (n - 1) auxiliary target source endSML fun hanoi n source target auxiliary = if n > 0 then ( hanoi (n - 1) source auxiliary target; print (\"Move disk from \" ^ source ^ \" to \" ^ target ^ \"\"); hanoi (n - 1) auxiliary target source )function definition, if expressions, recursion are more concise in SML, string interpolation is nicer in OCaml reply c-c-c-c-c 14 hours agoprevWow, he went from taking his bachelor to lecturing.I always dreamt of that when going through my degree and encountering courses that needed a thorough rework. reply shortrounddev2 14 hours agoparenttbh if I were in a class taught by someone who had JUST finished their bachelor&#x27;s degree, I&#x27;d take a lot of it with a grain of salt reply medstrom 14 hours agorootparentIf you expect perfect factual accuracy from your teachers, yeah. On the flip side, they don&#x27;t have the curse of knowledge yet i.e. it&#x27;s still fresh in their mind what was difficult in the beginning, so they can probably explain very well. Just keep in mind who&#x27;s teaching you, and it&#x27;s just like if a co-student teaches you.And if you feel you have to take what you hear with a grain of salt, that&#x27;s probably good for your learning too. reply shortrounddev2 13 hours agorootparentI just mean in terms of experience. If you deviate from textbook accuracy and go into providing practical advice for real-life scenarios, someone with only a bachelor&#x27;s and no work history is someone who can only give you canned anecdotes from others. Looking at his resume, it looks like he&#x27;s had some internships so he has a bit of experience, and that&#x27;s probably worth something reply gtchuang 12 hours agorootparentHis main day job is as a SWE doing program analysis, so I&#x27;m pretty sure he&#x27;s got the credentials to talk about real-life scenarios. reply shortrounddev2 11 hours agorootparentYeah idk anything about the guy reply elchananHaas 14 hours agorootparentprevI went to CMU and was in AEPI fraternity with Brandon Wu. Brandon Wu is exceptional when it comes to functional programming. He was head TA of 15150 for a year, I have 100% confidence in him.He took a break from TAing for some time, and when he returned he decided to have some fun with his application. He wrote a transpiler from a C like syntax to SML the day before his interview, and used it to joke that they should transition to teaching functional programming in C. reply shortrounddev2 14 hours agorootparentYeah idk anything about him in particular. I just mean that, on paper, someone who goes straight from bachelor&#x27;s to teaching is someone who doesn&#x27;t really have any experience. I notice that a lot of the people who extol the virtues of FP to me are a lot of people straight out of college and have little real-world reference for why FP is useful in a prod environment reply freedomben 15 hours agoprevI do wish functional programming were more taught. we&#x27;re getting to a point where I almost think OOP should be taught briefly and the rest of the focus on C&#x2F;C++ for low level stuff (OS, data structures, some algorithms), and something functional or pseudo-functional for high level stuff. Most of the newer codebases in startups now require functional concepts to understand what&#x27;s happening. For example, try writing modern JS without understanding .map, .reduce, et al, and function passing, etc.Regardless I think it&#x27;s important that students get exposed to more than just Python, which seems to increasingly be the only thing students come out knowing. reply Mandelmus 14 hours agoparent> I do wish functional programming were more taughtMy first CS bachelor&#x27;s semester in Germany in 2017 taught functional programming using Haskell (as well as C and NASM assembly in another course on computer architecture).OOP using Java and Python was only introduced in the second semester.> Regardless I think it&#x27;s important that students get exposed to more than just Python, which seems to increasingly be the only thing students come out knowing.In my B.Sc. studies I used C, C++, Haskel, Assembly, Java, Python, and Swift. reply randmeerkat 14 hours agorootparent> My first CS bachelor&#x27;s semester in Germany in 2017 taught functional programming using Haskell (as well as C and NASM assembly in another course on computer architecture).Also worth mentioning that since this was in Germany not only was it a great education, but there’s no crippling student debt either. reply RamblingCTO 14 hours agorootparentprevSame here. Had Scala in my first year. Clojure and Racket later. On top of that I had C, ASM, Java, Python and R (had a focus on machine learning). So I got plenty of education in that department. reply freedomben 14 hours agorootparentprevThere are definitely some good schools out there that expose students to a broad field. For anybody who is a student and looking, this is somethign I would strongly recommend considering. reply frozenlettuce 14 hours agoprevMy complaint with FP: Sometimes I just want to do something silly, like adding a log somewhere. If I choose to add said side effect, now all my functions are marked with an io signature (so there might be _other_, nastier side effects hiding there as well - mainly an issue if you have multiple people contributing to the same project). If I don&#x27;t add the side effect, and choose to refactor multiple layers of code, I will need to make all my functions return multiple values and later fold over all the accumulated strings and... life is too short for that. The principles really resonate with me, but maybe we are limited by the current tooling, because the development experience is quite clunky in its current stage. reply brandonspark 14 hours agoparentThis is Haskell-specific, it sounds like. I agree, the IO monad is really quite inconvenient sometimes.I work in OCaml, which is also a functional language, but prints can be added in single lines. I address this point in Lecture 19 (Imperative Programming), actually, but my perspective is -- we invented immutability and purity to serve us, but we need not be fanatically beholden to it. In my opinion, I think Haskell goes in that direction, when every usage of IO now needs the IO monad to get involved.A little mutability is OK. Functional programming is about the avoidance of side effects, more than simply forbidding it. reply frozenlettuce 13 hours agorootparentyeah, I&#x27;ve been trying to get this mindset as well - even though sometimes I feel that I&#x27;m \"cheating\" :) reply poorlyknit 12 hours agoparentprevIn Haskell you have a lot of options to type your functions in a more granular way. Consider the type class MonadIO, which lets you specify that your function works on any monad that can do side effects, not just IO specifically: -- Before captureAudioDuration :: DeviceID -> DiffTime -> IO WaveData -- After captureAudioDuration&#x27; :: MonadIO m => DeviceID -> DiffTime -> m WaveDataYou can build the same thing, but for logging! class Monad m => MonadLog m where log :: String -> m () -- In IO, just log to stdout. -- Other implementations might be a state&#x2F;writer monad -- or a library&#x2F;application-specific monad for business logic. instance MonadLog IO where log msg = putStrLn (\"log: \" ++ msg) -- Before: Bad, doesn&#x27;t actually do any IO but logging findShortestPath :: Node -> Node -> Graph -> IO [Node] -- After: Better, type signature gives us more details on what&#x27;s happening. -- We can still use this in an IO context because IO has a MonadLog instance. -- However, trying to capture audio in this function using either -- of the functions above will lead to a type error. findShortestPath&#x27; :: MonadLog m => Node -> Node -> Graph -> m [Node]As you can imagine this can get quite verbose and there&#x27;s other patterns one can use. Feel free to ask any follow-up questions :) reply zogrodea 1 hour agoparentprevOthers have mentioned having the same problem with this issue. One post I particularly like about the subject is this one on function colouring (how lagnuages with async&#x2F;await syntax have a similar \"infection\"; this is a response to the original post on function colouring and not the original post). https:&#x2F;&#x2F;www.tedinski.com&#x2F;2018&#x2F;11&#x2F;13&#x2F;function-coloring.html reply mrkeen 14 hours agoparentprevJust let all your functions live in IO then. You&#x27;ll still come out ahead.Or do an unsafePerformIO.Or use trace (where someone else has done the unsafePerformIO for you).Or use a Writer.Or introduce some logging capability (Logger m =>) onto your code.Or take a look at all the man-hours that have been spent on trying to perfect logging: https:&#x2F;&#x2F;hackage.haskell.org&#x2F;packages&#x2F;tag&#x2F;logging reply frozenlettuce 13 hours agorootparentyeah, biting the bullet seems to be the way to go. As you mention the lots of \"man-hours that have been spent on trying to perfect logging\", when doing research the usage of that time might be ok, but when building a product you might need to make concessions. reply tromp 14 hours agoparentprev> Sometimes I just want to do something silly, like adding a log somewhere.In Haskell, you can use Debug.Trace for just that purpose, when you don&#x27;t want to change the type of your function. reply frozenlettuce 13 hours agorootparentI&#x27;ve been playing with purescript and found out that they have a similar library, thanks! reply toast0 13 hours agoparentprevYou might benefit from a more pragmatic functional language. Erlang is broadly functional, but you can output from anywhere if you want to. It&#x27;s probably one of the least pure functional languages out there, but it&#x27;s super handy. reply corethree 4 hours agoparentprev> If I choose to add said side effect, now all my functions are marked with an io signatureYou got the wrong idea. You&#x27;re supposed to write FP in a way where the side effect is highly layered and segregated away from pure code. IO are singularities within your chains of pure function compositions. As soon as you hit a singularity you have to break out of it as soon as possible.The main idea is the meat. Keep your bread tiny and keep it very very separate from the meat.The pattern is called Imperative Shell, functional core. Think of your IO as two pieces of bread in a sandwich and your pure code is the meat that connects the read to the write.The game you&#x27;re playing with haskell is to avoid letting the IO monad pollute any of your logic as much as possible.Anyway that being said in applications where IO is all over the place... this pattern becomes largely ineffective. You basically have more bread than meat. reply ElectricalUnion 13 hours agoparentprevFrom my limited knowledge of FP languages it is expected that pure code in fact doesn&#x27;t evaluate anything until a monad forces it to evaluate.You would then need a monad to evaluate the things you&#x27;re attempting to log. And at that point you have a monad, so you can log as usual? reply squillion 12 hours agorootparentIt&#x27;s not about monads, it&#x27;s about effectful code, which is represented by special types (e.g. IO in Haskell, Eff in PureScript). Effectful code can call pure code, but not vice-versa. Since a program will have to do something, the main function is always effectful, i.e. it returns an effectful special type. So you&#x27;re right that pure code isn&#x27;t evaluated until some effectful code is ultimately returned by the main function and executed (by a runtime or equivalent). However, in purely functional languages most code is pure, even though it&#x27;s ultimately called by effectful code.Monads and side-effects aren&#x27;t intrinsically related. Simplifying, a monad is something with flatMap() - in JavaScript, Array and Promise are monads (kinda). What flatMap() gives you is the ability to chain things, which is useful to sequence side-effects so that they can be performed by a machine in a given order. That&#x27;s why IO and Eff are monads. reply airstrike 13 hours agoprevHey Brandon, thanks for posting this. Off-topic but maybe consider serving up thumbnails on that page instead of the full-size pngs https:&#x2F;&#x2F;brandonspark.github.io&#x2F;prologue&#x2F;lecture01.png reply Koshkin 13 hours agoprevIt seems that the fundamental problem with the functional paradigm (in its pure form) is that the real world - including the architecture of the computer that is used to run the programs on - is full of side effects, i.e. is essentially \"imperative,\" and with this impedance between them the idea creates more problems than it solves. reply epgui 11 hours agoparentThat’s like saying the problem with rulers is that the real world doesn’t have straight lines.Or the problem with cleaning your room is that in the real world entropy only ever increases. reply kccqzy 9 hours agorootparentAny time an HN comment uses the phrase \"fundamental problem\" chances are the problem is not only not fundamental, but also rather fun to solve for the right kind of people. reply whateveracct 13 hours agoparentprevon the contrary, i think FP (Haskell at least) gives you more & better tools to represent and wrangle side effects reply kccqzy 13 hours agorootparentExactly. These languages come up with more and more strategies and abstractions (from monads to modern effect systems) to help you manage your side effects well. It then raises the level of abstraction in your programs to become simpler and more concise. reply zubairq 14 hours agoprevWatching it now reply narinxas 14 hours agoprev [–] just in time for nobody to really care about programming because LLMs are so good at translation and all computer code and programing are a subfield of linguistics... reply Verdex 14 hours agoparentProgramming runs along the back of mathematics. A field famous for spending centuries wasting time on silly games until those same silly games end up being the foundation on which modern society functions.Even if LLMs completely remove the need for programming (a rather big IF), this is not time wasted. reply shepherdjerred 14 hours agoparentprevFunctional programming is a perfect pairing with AI-generated code because the type systems are generally more expressive than non-functional languages, which means the compilers can catch all sorts of errors. reply interiorchurch 14 hours agoparentprev [–] As my mother used to say, we&#x27;ll see... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The speaker shares their experience as an instructor for a functional programming class at Carnegie Mellon University.",
      "They believe that functional programming is crucial for computer science students and have made their lecture materials accessible online at no cost.",
      "The course covers a range of topics including recursion, data structures, sorting, and polymorphism, among others, with a focus on the course's transformative impact."
    ],
    "commentSummary": [
      "The Hacker News discussion covered various aspects of functional programming, including sharing resources and recommending courses.",
      "There was a debate about referential transparency in Lisp and the challenges of working with graph algorithms in a functional paradigm.",
      "The conversation also discussed the choice of programming language for teaching functional programming courses and the benefits of functional programming in managing side effects and AI-generated code."
    ],
    "points": 397,
    "commentCount": 115,
    "retryCount": 0,
    "time": 1700501690
  },
  {
    "id": 38349716,
    "title": "River: A Fast and Robust Job Queue for Go and Postgres",
    "originLink": "https://brandur.org/river",
    "originBody": "brandur.org Articles Atoms Fragments Newsletter Sequences Now Uses About River: a Fast, Robust Job Queue for Go + Postgres Article River: a Fast, Robust Job Queue for Go + Postgres 🔗 Published Nov 20, 2023 Location San Francisco I'm on X/Twitter at @brandur. Nov 20, 2023 River is born Designed for generics With performance in mind What's different now? Single dependency stacks Ruby non-parallelism Improvements in Postgres Try it Years ago I wrote about my trouble with a job queue in Postgres, in which table bloat caused by long-running queries slowed down the workers’ capacity to lock jobs as they hunted across millions of dead tuples trying to find a live one. A job queue in a database can have sharp edges, but I’d understated in that writeup the benefits that came with it. When used well, transactions and background jobs are a match made in heaven and completely sidestep a whole host of distributed systems problems that otherwise don’t have easy remediations. Consider: In a transaction, a job is emitted to a Redis-based queue and picked up for work, but the transaction that emitted it isn’t yet committed, so none of the data it needs is available. The job fails and will need to be retried later. A job is emitted from a transaction which then rolls back. The job fails and will also fail every subsequent retry, pointlessly eating resources despite never being able to succeed, eventually landing the dead letter queue. In an attempt to work around the data visibility problem, a job is emitted to Redis after the transaction commits. But there’s a brief moment between the commit and job emit where if the process crashes or there’s a bug, the job is gone, requiring manual intervention to resolve (if it’s even noticed). If both queue and store are non-transactional, all of the above and more. Instead of data not being visible, it may be that it’s in a partially ready state. If a job runs in the interim, all bets are off. Work in a transaction has other benefits too. Postgres’ NOTIFY respects transactions, so the moment a job is ready to work a job queue can wake a worker to work it, bringing the mean delay before work happens down to the sub-millisecond level. Despite our operational trouble, we never did replace our database job queue at Heroku. The price of switching would’ve been high, and despite blemishes, the benefits still outweighed the costs. I then spent the next six years staring into a maelstrom of pure chaos as I worked on a non-transactional data store. No standard for data consistency was too low. Code was a morass of conditional statements to protect against a million possible (and probable) edges where actual state didn’t line up with expected state. Job queues “worked” by brute force, bludgeoning jobs through until they could reach a point that could be tacitly called “successful”. I also picked up a Go habit to the point where it’s now been my language of choice for years now. Working with it professionally during that time, there’s been more than a few moments where I wished I had a good framework for transactional background jobs, but didn’t find any that I particularly loved to use. River is born So a few months ago, Blake and I did what one should generally never do, and started writing a new job queue project built specifically around Postgres, Go, and our favorite Go driver, pgx. And finally, after long discussions and much consternation around API shapes and implementation approaches, it’s ready for beta use. I’d like to introduce River (GitHub link), a job queue for building fast, airtight applications. Designed for generics One of the relatively new features in Go (since 1.18) that we really wanted to take full advantage of was the use of generics. A river worker takes a river.Job[JobArgs] parameter that provides strongly typed access to the arguments within: type SortWorker struct { river.WorkerDefaults[SortArgs] } func (w *SortWorker) Work(ctx context.Context, job *river.Job[SortArgs]) error { sort.Strings(job.Args.Strings) fmt.Printf(\"Sorted strings: %+v\", job.Args.Strings) return nil } No raw JSON blobs. No json.Unmarshal boilerplate in every job. No type conversions. 100% reflect-free. Jobs are raw Go structs with no embeds, magic, or shenanigans. Only a Kind implementation that provides a unique, stable string to identify the job as it round trips to and from the database: type SortArgs struct { // Strings is a slice of strings to sort. Strings []string `json:\"strings\"` } func (SortArgs) Kind() string { return \"sort\" } Beyond the basics, River supports batch insertion, error and panic handlers, periodic jobs, subscription hooks for telemetry, unique jobs, and a host of other features. Job queues are never really done, but we’re pretty proud of the API design and initial feature set. Check out the project’s README and getting started guide. With performance in mind One of the reasons we like to write things in Go is that it’s fast. We wanted River to be a good citizen of the ecosystem and designed it to use fast techniques where we could: It takes advantage of pgx’s implementation of Postgres’ binary protocol, avoiding a lot marshaling to and parsing from strings. It minimizes round trips to the database, performing batch selects and updates to amalgamate work. Operations like bulk job insertions make use of COPY FROM for efficiency. We haven’t even begun to optimize it so I won’t be showing any benchmarks (which tend to be misleading anyway), but on my commodity MacBook Air it works ~10k trivial jobs a second. It’s not slow. What's different now? You might be thinking: Brandur, you’ve had trouble with job queues in databases before. Now you’re promoting one. Why? A few reasons. The first is, as described above, transactions are really just a really good idea. Maybe the best idea in robust service design. For the last few years I’ve been putting my money where my mouth is and building a service modeled entirely around transactions and strong data constraints. Data inconsistencies are still possible, but especially in a relative sense, they functionally don’t exist. The amount of time this saves operators from having to manually mess around in consoles fixing things cannot be overstated. It’s the difference between night and day. Single dependency stacks Another reason is that dependency minimization is great. I’ve written previously about how at work we run a single dependency stack. No ElastiCache, no Redis, no bespoke queueing components, just Postgres. If there’s a problem with Postgres, we can fix it. No need to develop expertise in how to operate rarely used, black box systems. This idea isn’t unique. An interesting development in Ruby on Rails 7.1 is the addition of Solid Cache, which 37 Signals uses to cache in the same database that they use for the rest of their data (same database, but different instances of it of course). Ten years ago this would’ve made little sense because you’d want a hot cache that’d serve content from memory only, but advancements in disks (SSDs) has been so great that they measured a real world difference in the double digits (25-50%) moving their cache from Redis to MySQL, but with a huge increase in cache hits because a disk-based system allows cache space to widen expansively. Ruby non-parallelism A big part of our queue problem at Heroku was the design of the specific job system we were using, and Ruby deployment. Because Ruby doesn’t support real parallelism, it’s commonly deployed with a process forking model to maximize performance, and this was the case for us. Every worker was its own Ruby process operating independently. This produced a lot of contention and unnecessary work. Running independently, every worker was separately competing to lock every new job. So for every new job to work, every worker contended with every other worker and iterated millions of dead job rows every time. That’s a lot of inefficiency. A River cluster may run with many processes, but there’s orders of magnitude more parallel capacity within each as individual jobs are run on goroutines. A producer inside each process consolidates work and locks jobs for all its internal executors, saving a lot of grief. Separate Go processes may still contend with each other, but many fewer of them are needed thanks to superior intra-process concurrency. Improvements in Postgres During my last queue problems we would’ve been using Postgres 9.4. We have the benefits of nine new major versions since then, which have brought a lot of optimizations around performance and indexes. The most important for a queue was the addition of SKIP LOCKED in 9.5, which lets transactions find rows to lock with less effort by skipping rows that are already locked. This feature is old (although no less useful) now, but we didn’t have it at the time. Postgres 12 brought in REINDEX CONCURRENTLY, allowing queue indexes to be rebuilt periodically to remove detritus and bloat. Postgres 13 added B-tree deduplication, letting indexes with low cardinality (of which a job queue has multiple of) be stored much more efficiently. Postgres 14 brought in an optimization to skip B-tree splits by removing expired entries as new ones are added. Very helpful for indexes with a lot of churn like a job queue’s. And I’m sure there’s many I’ve forgotten. Every new Postgres release brings dozens of small improvements and optimizations, and they add up. Also exciting is the potential addition of a transaction timeout setting. Postgres has timeouts for individual statements and being idle in a transaction, but not for the total duration of a transaction. Like with many OLTP operations, long-lived transactions are hazardous for job queues, and it’ll be a big improvement to be able to put an upper bound them. Try it Anyway, check out River (see also the GitHub repo and docs) and we’d appreciate it if you helped kick the tires a bit. We prioritized getting the API as polished as we could (we’re really trying to avoid a /v2), but are still doing a lot of active development as we refactor internals, optimize, and generally nicen things up. River is born Designed for generics With performance in mind What's different now? Single dependency stacks Ruby non-parallelism Improvements in Postgres Try it Did I make a mistake? Please consider sending a pull request.",
    "commentLink": "https://news.ycombinator.com/item?id=38349716",
    "commentBody": "River: A fast, robust job queue for Go and PostgresHacker NewspastloginRiver: A fast, robust job queue for Go and Postgres (brandur.org) 332 points by bo0tzz 18 hours ago| hidepastfavorite94 comments bgentry 16 hours agoHi HN, I&#x27;m one of the authors of River along with Brandur. We&#x27;ve been working on this library for a few months and thought it was about time we get it out into the world.Transactional job queues have been a recurring theme throughout my career as a backend and distributed systems engineer at Heroku, Opendoor, and Mux. Despite the problems with non-transactional queues being well understood I keep encountering these same problems. I wrote a bit about them here in our docs: https:&#x2F;&#x2F;riverqueue.com&#x2F;docs&#x2F;transactional-enqueueingUltimately I want to help engineers be able to focus their time on building a reliable product, not chasing down distributed systems edge cases. I think most people underestimate just how far you can get with this model—most systems will never outgrow the scaling constraints and the rest are generally better off not worrying about these problems until they truly need to.Please check out the website and docs for more info. We have a lot more coming but first we want to iron out the API design with the community and get some feedback on what features people are most excited for. https:&#x2F;&#x2F;riverqueue.com&#x2F; reply radicalbyte 13 hours agoparentI don&#x27;t know why people even use libraries in those languages - assuming you stick to a database engine you understand well then the (main)-database-as-queue pattern is trivial to implement. Any time spent writing code is quickly won back by not having to debug weird edge cases, and sometimes you can highly optimize what you&#x27;re doing (for example it becomes easy to migrate jobs which are data-dominated to the DB server which can cut processing time by 2-3 orders of magnitude).It&#x27;s particularly suited to use cases such background jobs, workflows or other operations which occur within your application and scales well enough for what 99.9999% of us will be doing. reply TheProTip 4 hours agoparentprevReally cool. I&#x27;m working on .Net project that I&#x27;ve also adopted a \"single dependency\" stance on; that being Postgres. I&#x27;m pretty thrilled to see I&#x27;m not the only one lol!I plan to use Orleans to handle a lot of the heavy HA&#x2F;scale lifting. It can likely stand in for Redis in a lot of cache use cases(in some non-obvious ways), and am anticipating writing a Postgres stream provider for it when the time comes.. Will likely end up writing a Postres job queue as well so will definitely check out River for inspiration.A lot of postgres drivers, including the .Net defacto Npgsql, support logical decode these days which unlocks a ton of exciting use cases and patterns via log processing. reply dangoodmanUT 14 hours agoparentprevHow do you look at models like temporal.io (service in front of DB) and go-workflows (direct to DB) in comparison? It seems like this is more a step back towards that traditional queue like asynq is, which is where the industry is leaving from to the model of temporal reply ramchip 9 hours agorootparentPersonally I&#x27;ve found Temporal very limited as a queue: no FIFO ordering (!), no priorities, no routing, etc. It&#x27;s also very complex when you just want async jobs, and more specialized than a DB or message broker, which can be used for many other things. I think there&#x27;s a place for both. reply bgentry 13 hours agorootparentprevI don&#x27;t think these approaches are necessarily mutually exclusive. There are some great things that can be layered on top of the foundation we&#x27;ve built, including workflows. The best part about doing this is that you can maintain full transactionality within a single primary data store and not introduce another 3rd party or external service into your availability equation. reply cloverich 15 hours agoparentprevSo excited y&#x27;all created this. Through a few job changes I&#x27;ve been exposed to the most popular background job systems in Rails, Python, JS, etc, and have been shocked at how under appreciated their limitations are relative to what you get out of the box with relational systems. Often I see a lot of DIY add-ons to help close the gaps, but its a lot of work and often still missing tons of edge cases and useful functionality. I always felt going the other way, starting w&#x2F; a relational db where many of those needs are free, would make more sense for most start-ups, internal tooling, and smaller scale businesses.Thank you for this work, I look forward to taking it for a (real) test drive! reply justinclift 5 hours agoparentprevDoes it do job completion notification?Along the lines of: _, err := river.Execute(context.Background(), j) &#x2F;&#x2F; Enqueue the job, and wait for completion if err != nil { log.Fatalf(\"Unable to execute job: %s\", err) } log.Printf(\"Job completed\")Does that make sense? reply endorphine 14 hours agoparentprevHow does this compare to https:&#x2F;&#x2F;github.com&#x2F;vgarvardt&#x2F;gue? reply csarva 13 hours agorootparentNot familiar with either project, but it seems gue is a fork of the authors previous project, https:&#x2F;&#x2F;github.com&#x2F;bgentry&#x2F;que-go reply bgentry 13 hours agorootparentYes, there&#x27;s a note in the readme to that effect although I don&#x27;t think they bear much resemblance anymore. que-go was an experiment I hacked up on a plane ride 9 years ago and thought was worth sharing. I was never happy with its technical design: holding a transaction for the duration of a job severely limits available use cases and worsens bloat issues. It was also never something I intended to continue developing alongside my other priorities at the time and I should have made that clearer in the project&#x27;s readme from the start. reply gregwebs 13 hours agorootparentprevOr neoq. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38352778 reply tombh 15 hours agoparentprevAt the bottom of the page on riverqueue.com it appears there&#x27;s a screenshot of a UI. But I can&#x27;t seem to find any docs about it. Am I missing something or is it just not available yet? reply mosen 15 hours agorootparentLooks like it’s underway:> We&#x27;re hard at work on more advanced features including a self-hosted web interface. Sign up to get updates on our progress. reply bgentry 15 hours agorootparentprevThe UI isn&#x27;t quite ready for outside consumption yet but it is being worked on. I would love to hear more about what you&#x27;d like to see in it if you want to share. reply codegeek 12 hours agorootparentIf you could build a UI similar to Hangire [0] or Laravel Horizon [1], that would be awesome.[0] https:&#x2F;&#x2F;hangfire.io[1] https:&#x2F;&#x2F;github.com&#x2F;laravel&#x2F;horizon reply fithisux 14 hours agorootparentprevAn Airflow for Gophers? reply linux2647 12 hours agoparentprevIs there a minimum version of Postgres needed to use this? I’m having trouble finding that information in the docs reply victorbjorklund 16 hours agoprevLooks great. For people wondering about wether postgres really is a good choice for a job queue I can recommend checking out Oban in Elixir that has been running in production for many years: https:&#x2F;&#x2F;github.com&#x2F;sorentwo&#x2F;obanBenchmark: peaks at around 17,699 jobs&#x2F;sec for one queue on one node. Probably covers most apps.https:&#x2F;&#x2F;getoban.pro&#x2F;articles&#x2F;one-million-jobs-a-minute-with-... reply bgentry 16 hours agoparentOban is fantastic and has been a huge source of inspiration for us, showing what is possible in this space. In fact I think during my time at Distru we were one of Parker&#x27;s first customers with Oban Web &#x2F; Pro :)We&#x27;ve also had a lot of experience with with other libraries like Que ( https:&#x2F;&#x2F;github.com&#x2F;que-rb&#x2F;que ) and Sidekiq (https:&#x2F;&#x2F;sidekiq.org&#x2F;) which have certainly influenced us over the years. reply sorentwo 14 hours agorootparentThe very first paying Pro customer, as a matter of fact =)You said back then that you planned on pursuing a Go client; now, four years later, here we are. River looks excellent, and the blog post does a fantastic job explaining all the benefits of job queues in Postgres. reply sorentwo 13 hours agoprevThe number of features lifted directly from Oban[1] is astounding, considering there isn&#x27;t any attribution in the announcement post or the repo.Starting with the project&#x27;s tagline, \"Robust job processing in Elixir\", let&#x27;s see what else: - The same job states, including the British spelling for `cancelled` - Snoozing and cancelling jobs inline - The prioritization system - Tracking where jobs were attempted in an attempted_by column - Storing a list of errors inline on the job - The same check constraints and the same compound indexes - Almost the entire table schema, really - Unique jobs with the exact same option names - Table-backed leadership electionPlease give some credit where it&#x27;s due.[1]: https:&#x2F;&#x2F;github.com&#x2F;sorentwo&#x2F;oban reply bgentry 13 hours agoparentHi Parker, I&#x27;m genuinely sorry it comes across as though we lifted this stuff directly from Oban. I do mean it when I say that Oban has been a huge inspiration, particularly around its technical design and clean UX.Some of what you&#x27;ve mentioned are cases where we surveyed a variety of our favorite job engines and concluded that we thought Oban&#x27;s way was superior, whereas others we cycled through a few different implementations before ultimately apparently landing in a similar place. I&#x27;m not quite sure what to say on the spelling of \"cancelled\" though, I&#x27;ve always written it that way and can&#x27;t help but read \"canceled\" like \"concealed\" in my head :)As I think I mentioned when we first chatted years ago this has been a hobby interest of mine for many years so when a new database queue library pops up I tend to go see how it works. We&#x27;ve been in a bit of a mad dash trying to get this ready for release and didn&#x27;t even think about crediting the projects that inspired us, but I&#x27;ll sync with Brandur and make sure we can figure out the right way to do that.I really appreciate you raising your concerns here and would love to talk further if you&#x27;d like. I just sent you an email to reconnect. reply throwawaymaths 12 hours agorootparentOk so maybe just put it on the github readme? \"Inspired by Oban, and X, and Y...\"JFC One line of code you don&#x27;t even have to test reply Thaxll 9 hours agoparentprevAs if Oban invented anything, like queues on RDMS is not a new concept at all. Oban is 4 years old, do you know how many queues baked by DB were created in the last 10years?I don&#x27;t see Sidekiq credited on the main page of Oban. reply sorentwo 8 hours agorootparentI’d argue strongly that Oban did invent things, including parts of the underlying structure used in River, and the authors agree that it was a heavy influence.While there is no overlap in technology or structure with Sidekiq, the original Oban announcement on the ElixirForum mentions it along with all of the direct influences:https:&#x2F;&#x2F;elixirforum.com&#x2F;t&#x2F;oban-reliable-and-observable-job-p... reply hamandcheese 6 hours agorootparentprevNot sure if you meant to compare to Sidekiq (which uses Redis). But delayed-job and que are both projects that stretch back much more than 4 years in the ruby ecosystem that leverage relational databases as well. reply kamikaz1k 13 hours agoparentprev…how else do you spell cancelled? With one l? Wow, learning this on my keyboard as I type this… reply jchw 5 hours agoparentprevData point: I am American and I would not spell &#x27;cancelled&#x27; any other way. I don&#x27;t think it is strictly British. reply Groxx 2 hours agorootparentAs far as I&#x27;ve seen, Americans are just plain inconsistent on this spelling.Cancelled has nice pairing with cancellation, canceled can be typed nicely without any repeated finger use on qwerty, both clearly mean the same thing and aren&#x27;t confused with something else... I say let the battles begin, and may the best speling win.Referer pains me though. reply jchw 2 hours agorootparentTo be fair, \"referer\" is just a misspelling, I don&#x27;t think it was ever accepted as a correct spelling by a large number of people. I&#x27;m sure you know the backstory though. reply sorentwo 14 hours agoprev> Work in a transaction has other benefits too. Postgres’ NOTIFY respects transactions, so the moment a job is ready to work a job queue can wake a worker to work it, bringing the mean delay before work happens down to the sub-millisecond level.Oban just went the opposite way, removing the use of database triggers for insert notifications and moving them into the application layer instead[1]. The prevalence of poolers like pgbouncer, which prevent NOTIFY ever triggering, and the extra db load of trigger handling wasn&#x27;t worth it.[1]: https:&#x2F;&#x2F;github.com&#x2F;sorentwo&#x2F;oban&#x2F;commit&#x2F;7688651446a76d766f39... reply bgentry 7 hours agoparentThat makes a lot of sense, I&#x27;ve had the thought a few times that the NOTIFY overhead could get overwhelming in a high-throughput queue but haven&#x27;t yet had an opportunity to verify this or experiment with a mechanism for reducing this overhead. reply latchkey 17 hours agoprevIf I was going to do my own Job Queue, I&#x27;d implement it more like the GCP Tasks [0].It is such a better model for the majority of queues. All you&#x27;re doing is storing a message, hitting an HTTP endpoint and deleting the message on success. This makes it so much easier to scale, reason, and test task execution.Update: since multiple people seem confused. I&#x27;m talking about the implementation of a job queue system, not suggesting that they use the GCP tasks product. That said, I would have just used GCP tasks too (assuming the usecase dictated it, fantastic and rock solid product.)[0] https:&#x2F;&#x2F;cloud.google.com&#x2F;tasks reply brandur 16 hours agoparentThere&#x27;s a lot to be said about the correctness benefits of a transactional model.The trouble with hitting an HTTP API to queue a task is: what if it fails, or what if you&#x27;re not sure about whether it failed? You can continue to retry in-band (although there&#x27;s a definite latency disadvantage to doing so), but say you eventually give up, you can&#x27;t be sure that no jobs were queued which you didn&#x27;t get a proper ack for. In practice, this leads to a lot of uncertainty around the edges, and operators having to reconcile things manually.There&#x27;s definite scaling benefits to throwing tasks into Google&#x27;s limitless compute power, but there&#x27;s a lot of cases where a smaller, more correct queue is plenty of power, especially where Postgres is already the database of choice. reply andrewstuart 15 hours agorootparentHTTP APIs are ideal for message queues with Postgres.The request to get a message returns a token that identifies this receive.You use that token to delete the message when you are done.Jobs that don’t succeed after N retries get marked as dead and go into the dead letter list.This the way AWS SQS works, it’s tried and true. reply latchkey 16 hours agorootparentprev> what if it fails, or what if you&#x27;re not sure about whether it failed?This is covered in the GCP Tasks documentation.> There&#x27;s definite scaling benefits to throwing tasks into Google&#x27;s limitless compute power, but there&#x27;s a lot of cases where a smaller, more correct queue is plenty of power, especially where Postgres is already the database of choice.My post was talking about what I would implement if I was doing my own queue, as the authors were. Not about using GCP Tasks. reply politician 16 hours agorootparentDo you know that brandur&#x27;s been writing about Postgres job queues since at least 2017? Cut him some slack.https:&#x2F;&#x2F;brandur.org&#x2F;job-drainhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=15294722 reply bgentry 16 hours agorootparent2015, even :) https:&#x2F;&#x2F;brandur.org&#x2F;postgres-queues reply latchkey 16 hours agorootparentprev\"I&#x27;m into effective altruism and created the largest crypto exchange in the world. Cut me some slack.\"No, we don&#x27;t operate like that. Call me out when I&#x27;m wrong technically, but don&#x27;t tell me that because someone is some sort of celebrity that I should cut them some slack.Everything he pointed out is literally covered in the GCP Tasks documentation.https:&#x2F;&#x2F;cloud.google.com&#x2F;tasks&#x2F;docs&#x2F;dual-overviewhttps:&#x2F;&#x2F;cloud.google.com&#x2F;tasks&#x2F;docs&#x2F;common-pitfalls reply robertlagrant 16 hours agorootparent> No, we don&#x27;t operate like that. Call me out when I&#x27;m wrong technicallyYou&#x27;re being \"called out\" (ugh) incredibly politely mostly because you were being a bit rude; \"tell me X without telling me\" is just a bit unpleasant, and totally counterproductive.> because someone is some sort of celebrity that I should cut them some slack.No one mentioned a celebrity. You&#x27;re not railing against the power of celebrity here; just a call for politeness.> Everything he pointed out is literally covered in the GCP Tasks documentation.Yes, e.g. as pitfalls. reply latchkey 16 hours agorootparentSure, updated my comment to be less rude. reply politician 10 hours agorootparentAppreciated replyjbverschoor 16 hours agoparentprev>> Timeouts: for all HTTP Target task handlers the default timeout is 10 minutes, with a maximum of 30 minutes.Good luck with a long running batch. reply latchkey 16 hours agorootparentIf you&#x27;re going to implement your own queue, you can make it run for however long you want.Again, I&#x27;m getting downvoted. The whole point of my comment isn&#x27;t about using GCP Tasks, it is about what I would do if I was going to implement my own queue system like the author did.By the way, that 30 minute limitation can be worked around with checkpoints or breaking up the task into smaller chunks. Something that isn&#x27;t a bad idea to do anyway. I&#x27;ve seen long running tasks cause all sorts of downstream problems when they fail and then take forever to run again. reply jbverschoor 15 hours agorootparentWell you can&#x27;t really.. If you&#x27;re gonna use HTTP and expect a response, you&#x27;re gonna be in for a fun ride. You&#x27;ll have to go deal with timeout settings for: - http libraries - webservers - application servers - load balancers - reverse proxy servers - the cloud platform you&#x27;re running on - wafIt might be alright for smaller \"tasks\", but not for \"jobs\". reply latchkey 15 hours agorootparentHave you ever used Cloud Tasks? reply fierro 9 hours agoparentprevthat&#x27;s pretty fundamentally different, no? One requires you to build a distributed system with >1 components leveraging GCP tasks APIs. The second is just a library do some book keeping inside your main datastore. reply gregwebs 14 hours agoprevWe are looking right now to use a stable PG job queue built in Go. We have found 2 already existing ones:* neoq: https:&#x2F;&#x2F;github.com&#x2F;acaloiaro&#x2F;neoq* gue: https:&#x2F;&#x2F;github.com&#x2F;vgarvardt&#x2F;gueNeoq is new and we found it to have some features (like scheduling tasks) that were attractive. The maintainer has also been responsive to fixing our bug reports and addressing our concerns as we try it out.Gue has been around for a while and is probably serving its users well.Looking forward to trying out River now. I do wonder if neoq and river might be better off joining forces. reply surprisetalk 16 hours agoprevI love PG job queues!They’re surprisingly easy to implement in plain SQL:[1] https:&#x2F;&#x2F;taylor.town&#x2F;pg-taskThe nice thing about this implementation is that you can query within the same transaction window reply rockwotj 15 hours agoparentAgreed. Shortwave [1] is built completely on this, but with the added layer of having a leasing system that is per user on top of the tasks. So you only need to `SKIP LOCKED` to grab a lease, then you can grab as many tasks as you want and process them in bulk. It allows higher throughput of tasks, and also was required for the use case as the leases where tied to a user and tasks for a single user must be processed in order.[1]: https:&#x2F;&#x2F;www.shortwave.com&#x2F; reply rubenfiszel 15 hours agoprevLooks cool and thanks for sharing. Founder of windmill.dev, an open-source, extremely fast workflow engine to run jobs in ts,py,gosh whose most important piece, the queue, is also just rust + postgresql (and mostly the FOR UPDATE SKIP LOCKED).I&#x27;d be curious to compare performances once you guys are comfortable with that, we do them openly and everyday on: https:&#x2F;&#x2F;github.com&#x2F;windmill-labs&#x2F;windmill&#x2F;tree&#x2F;benchmarksI wasn&#x27;t aware of the skip B-tree splits and the REINDEX CONCURRENTLY tricks. But curious what do you index in your jobs that use those. We mostly rely on the tag&#x2F;queue_name (which has a small cardinality), scheduled_for, and running boolean which don&#x27;t seem good fit for b-trees. reply m-a-r-c-e-l 2 hours agoprevNice problem observation.One solution is the outbox pattern:https:&#x2F;&#x2F;microservices.io&#x2F;patterns&#x2F;data&#x2F;transactional-outbox.... reply chuckhend 11 hours agoprevAwesome! Seems like this would be a lot easier to work with and perhaps more performant than Skye&#x27;s pg-queue? Queue workload is a lot like OLTP, which IMO, makes Postgres great for it (but does require some extra tuning).Unlike https:&#x2F;&#x2F;github.com&#x2F;tembo-io&#x2F;pgmq a project we&#x27;ve been working on at Tembo, many queue projects still require you to run and manage a process external to the database, like a background worker. Or they ship as a client library and live in your application, which will limit the languages you can chose to work with. PGMQ is a pure SQL API, so any language that can connect to Postgres can use it. reply bennyp101 16 hours agoprevNice, I&#x27;ve been using graphile-worker [0] for a while now, and it handles our needs perfectly, so I can totally see why you want something in the go world.Just skimming the docs, can you add a job directly via the DB? So a native trigger could add a job in? Or does it have to go via a client?[0] https:&#x2F;&#x2F;worker.graphile.org&#x2F; reply orefalo 6 hours agoprevInteresting, I would have though a solution like https:&#x2F;&#x2F;temporal.io&#x2F; would be more appropriate for these use cases.a job queue might just be the tip of the use cases iceberg... isn&#x27;t it?in the end it&#x27;s a pub&#x2F;sub - I use nats.io workers for this.arf, just read a few comments on this same line down bellow. reply meowtimemania 4 hours agoparentThe main benefit of something like River is simplicity. With River your application might consist of two components, a database, and a code server. Such an architecture is really easy to test, develop, debug and deploy.Adding temporal.io means introducing a third component. More components usually means more complexity. More complexity means more difficult to test, develop, debug and deploy.As with everything, it&#x27;s all about tradeoffs. reply RedShift1 16 hours agoprevAll these job queue implementations do the same thing right, SELECT ... FOR UPDATE SKIP LOCKED? Why does every programming language need its own variant? reply rockwotj 16 hours agoparentTo work with each language&#x27;s drivers reply RedShift1 14 hours agorootparentBut it&#x27;s the same thing every time. Turn autocommit off, run the SELECT, commit, repeat? Or am I missing something? reply ddorian43 34 minutes agorootparentYou just do the update with skip locked and finish the job until time runs out or update the job \"liveness\". (can be autocommit on & off) reply kromem 7 hours agoprevNice!A few years ago I wrote my own in house distributed job queue and scheduler in Go on top of Postgres and would have been very happy if a library like this had existed before.The two really are a great pair for this usecase for most small to medium scaled applications, and it&#x27;s awesome to see someone putting a library out there publicly doing it - great job!! reply sa46 12 hours agoprevI wrote our own little Go and Postgres job queue similar in spirit. Some tricks we used:- Use FOR NO KEY UPDATE instead of FOR UPDATE so you don&#x27;t block inserts into tables with a foreign key relationship with the job table. [1]- We parallelize worker by tenant_id but process a single tenant sequentially. I didn&#x27;t see anything in the docs about that use case; might be worth some design time.[1]: https:&#x2F;&#x2F;www.migops.com&#x2F;blog&#x2F;select-for-update-and-its-behavi... reply JoshGlazebrook 15 hours agoprevI didn&#x27;t really see this feature, but I think another good one would be a way to schedule a future job that is not periodic. ie: \"schedule job in 1 hr\" to where it&#x27;s either not enqueued or not available to be consumed until (at least) the schedule time. reply bgentry 13 hours agoparentYou&#x27;ve found an underdocumented feature, but in fact River does already do what you&#x27;re asking for! Check out `ScheduledAt` on the `InsertOpts`: https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;riverqueue&#x2F;river#InsertOptsI&#x27;ll try to work this into the higher level docs website later today with an example :) reply sotraw 15 hours agoprevIf you are on Kafka already, there is an alternative to schedule a job without PG [0][0] https:&#x2F;&#x2F;www.wgtwo.com&#x2F;blog&#x2F;kafka-timers&#x2F; reply andrewstuart 15 hours agoprevThe thing is there are now vast numbers of queue solutions.What’s the goal for the project? Is it to be commercial? If so you face massive headwind because it’s so incredibly easy to implement a queue now. reply molszanski 12 hours agoprevWould love to see an SQLite driver reply bojanz 14 hours agoprevThis looks like a great effort and I am looking forward to trying it out.I am a bit confused by the choice of the LGPL 3.0 license. It requires one to dynamically link the library to avoid GPL&#x27;s virality, but in a language like Go that statically links everything, it becomes impossible to satisfy the requirements of the license, unless we ignore what it says and focus just on its spirit. I see that was discussed previously by the community in posts such as these [1][2][3]I am assuming that bgentry and brandur have strong thoughts on the topic since they avoided the default Go license choice of BSD&#x2F;MIT, so I&#x27;d love to hear more.[1] https:&#x2F;&#x2F;www.makeworld.space&#x2F;2021&#x2F;01&#x2F;lgpl_go.html [2] https:&#x2F;&#x2F;golang-nuts.narkive.com&#x2F;41XkIlzJ&#x2F;go-lgpl-and-static-... [3] https:&#x2F;&#x2F;softwareengineering.stackexchange.com&#x2F;questions&#x2F;1790... reply bgentry 10 hours agoparentHi bojanz, to be honest we were not well informed enough on the licensing nuances. I appreciate you sharing these links, please tune into this GitHub issue where we&#x27;ll give updates soon and make sure any ambiguity is resolved. https:&#x2F;&#x2F;github.com&#x2F;riverqueue&#x2F;river&#x2F;issues&#x2F;47 reply youerbt 15 hours agoprevJob queues in RDBMS are always so controversial here on HN, which is kinda sad. Not everybody needs insane scale or whatever else a dedicated solutions offer. Not to mention if you already have RDBMS laying around, you don&#x27;t have to pay for extra complexity. reply hipadev23 17 hours agoprevWhat a strange design. If a job is dependent on an extant transaction then perhaps the job should run in the same code that initiated the transaction instead of a outside job queue?Also you pass the data a job needs to run as part of the job payload. Then you don&#x27;t have the \"data doesn&#x27;t exist\" issue. reply teraflop 16 hours agoparentIt&#x27;s not strange at all to me. The job is \"transactional\" in the sense that it depends on the transaction, and should be triggered iff the transaction commits. That doesn&#x27;t mean it should run inside the transaction (especially since long-running transactions are terrible for performance).Passing around the job&#x27;s data separately means that now you&#x27;re storing two copies, which means you&#x27;re creating a point where things can get out of sync. reply hipadev23 16 hours agorootparent> should be triggered iff the transaction commitsAgreed. Which is why the design doesn&#x27;t make any sense. Because in the scenario presented they&#x27;re starting a job during a transaction. reply teraflop 15 hours agorootparentI don&#x27;t understand what you mean. The job is \"created\" as part of the transaction, so it only becomes visible (and hence eligible to be executed) when the transaction commits. reply eximius 15 hours agorootparentprevThat part is somewhat poorly explained. That is a motivating example of why having your job queue system be separate from your system of record can be bad.e.g.,1. Application starts transaction 2. Application updates DB state (business details) 3. Application enqueues job in Redis 4. Redis jobworkers pick up job 5. Redis jobworkers error out 6. Application commits transactionThis motivates placing the jobworker state in the same transaction whereas non-DB based job queues have issues like this. reply Chris911 15 hours agorootparentprevThe job is queued as part of the transaction. It is executed by a worker outside the scope of the transaction. reply j45 15 hours agorootparentprevMaybe it’s not designed for that or all use cases and that can make sense.Personally, I need long running jobs. reply brandur 17 hours agoparentprevAuthor here.Wanting to offload heavy work to a background job is absolute as old of a best practice as exists in modern software engineering.This is especially important for the kind of API and&#x2F;or web development that a large number of people on this site are involved in. By offloading expensive work, you take that work out-of-band of the request that generated it, making that request faster and providing a far superior user experience.Example: User sign-up where you want to send a verification email. Talking to a foreign API like Mailgun might be a 100 ms to multisecond (worst case scenario) operation — why make the user wait on that? Instead, send it to the background, and give them a tightWanting to offload heavy work to a background job is absolute as old of a best practice as exists in modern software engineering.Yes. I am intimately familiar with background jobs. In fact I&#x27;ve been using them long enough to know, without hesitation, that you don&#x27;t use a relational database as your job queue. reply lazyant 15 hours agorootparent> I&#x27;ve been using them long enough to know, without hesitation, that you don&#x27;t use a relational database as your job queue.I&#x27;m also very familiar with jobs and I have used the usual tools like Redis and RMQ, but I wouldn&#x27;t make a blanket statement like that. There are people using RDBS as queues in prod so we have some counter-examples. I wouldn&#x27;t mind at all to get rid of another system (not just one server but the cluster of RMQ&#x2F;Redis you need for HA). If there&#x27;s a big risk in using pg as backend for a task queue, I&#x27;m all ears. reply qaq 16 hours agorootparentprevPostgres based job queues work fine if you have say 10K transaction per second and jobs on average do not take significant time to complete (things will run fine on fairly modest instance). They also give guarantees that traditional job queues do not. reply Rapzid 2 hours agorootparentProbably order of magnitude more or perhaps a multiple of that depending on the hardware and design.In theory an append-only and&#x2F;or HOT strategy leaning on Postgres just ripping through moderate sized in-mem lists could be incredibly fast. Design would be more complicated and perhaps use case dependent but I bet could be done. reply toolz 16 hours agorootparentprevas far as I&#x27;m aware the most popular job queue library in elixir depends on postgres and has performance characteristics that cover the vast majority of background processing needs I&#x27;ve come across.I wonder maybe if you&#x27;ve limited yourself by assuming relational DBs only have features for relational data. That isn&#x27;t the case now and really hasn&#x27;t been the case for quite some time now. reply qaq 16 hours agoparentprevJob is not dependent on extant transaction. The bookkeeping of job state runs in the same transaction as your domain state manipulation so you will never get into situation where job domain mutation commited but job state failed to update to complete. reply maherbeg 16 hours agoparentprevI think you may be misunderstanding the design here. The transaction for initiating the job is only for queuing. The dequeue and execution of the job happens in a separate process.The example on the home page makes this clear where a user is created and a job is created at the same time. This ensures that the job is queued up with the user creation. If any parts of that initial transaction fails, then the job queuing doesn&#x27;t actually happen. reply zackkitzmiller 17 hours agoparentprevI agree. This design is incredibly strange, and seems to throw away basically all distributed systems knowledge. I&#x27;m glad folks are playing with different ideas, but this one seems off. reply eximius 16 hours agorootparentNo, this is a fairly common pattern called having an &#x27;outbox&#x27; where the emission&#x2F;enquing of your event&#x2F;message&#x2F;job is tied to the transaction completion of the relevant domain data.We use this to ensure Kafka events are only emitted when a process succeeds, this is very similar. reply iskela 14 hours agorootparentSo when the the business data transaction commit a notify event is raised and a job row is inserted. Out of bound job broker listens to a notify event of the job-table or polls the table skipping rows and takes work for processing? reply eximius 11 hours agorootparentBasically.For our particular use case, I think we&#x27;re actually not using notify events. We just insert rows into the outbox table and the poller re-emits as kafka events and deletes successfully emitted events from the table. reply youerbt 11 hours agorootparentprevEither business data and job are committed or none of them. Then as you write, either polling or listening to an even worker, can pick it up. Bonus stuff, from implementation perspective, is that if worker selects row FOR UPDATE (locking the job from others to pick up) and dies, Postgres will release the lock after some time, making the job available for other workers. replythrowawaaarrgh 10 hours agoprev [–] Sorry if I&#x27;m late to the party, but has anyone told newbie developers that relational databases make very poor queues? We found that out like 15 years ago. (it&#x27;s not about scalability, though that is a significant problem which this post hand-waves) reply whalesalad 9 hours agoparent [–] A lot has changed in 15 years. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author introduces a new job queue called River, specifically designed for Go and Postgres.",
      "River offers various features like batch insertion, error handling, and periodic jobs.",
      "It leverages Go's generics feature and utilizes Postgres' binary protocol for performance optimization, minimizing round trips to the database."
    ],
    "commentSummary": [
      "The discussion focuses on job queue systems and their implementation in Go programming language and Postgres database.",
      "Users debate the pros and cons of using relational databases for job queues, suggesting alternative solutions like Redis or RMQ.",
      "The conversation delves into the limitations and benefits of existing job queue projects, emphasizing the importance of credit and collaboration between projects."
    ],
    "points": 332,
    "commentCount": 94,
    "retryCount": 0,
    "time": 1700495643
  },
  {
    "id": 38354422,
    "title": "Typst: Streamlining Scientific Paper Writing with Enhanced Layout and Formatting",
    "originLink": "https://typst.app/",
    "originBody": "Beta Docs Sign in Sign up Compose thesespapers faster Focus on your text and let Typst take care of layout and formatting. Sign up for free and try it now!Sign in A more productive workflow for science. Eduardo “First time testing the new project creating wizard, It's great, I love it!” _submersion_ “A serious contender for the title of LaTeX successor ✨” Alistair “I started using the preview, and I love typst so much!” BlueTJ “First impression: Damn, it feels smooth as heck.” Vallaris “My first impression is: It's really great!” Louis “UI: Ultra clean ✨, Docs: Very comprehensive.” Work With Your Peers Whether in the classroom, the faculty office, or at home: Typst runs in your browser, so everyone on the team can just start writing. Level up your team. Store shared documents in team workspaces to bring everyone in your working group on the same page. Team Up With Templates Typst supercharges templates: They react to your content and format everything instantly while you type. Select from pre-made ones or create your own! Changed Conferences? Switch the template in seconds, without touching your content. IEEEOxfordMDPI Why should I use Typst instead of ... LaTeX Word Google Docs Typst... previews your changes instantly. provides clear, understandable error messages. has a consistent styling system for configuring everything from fonts and margins to the look of headings and lists. uses familiar programming constructs instead of hard-to-understand macros. With Typst, you can... easily collaborate in teams. use and create powerful templates that automatically format everything as you write. just change formatting later without going over the whole document by hand. enjoy higher-quality typographical output, including improved justification. With Typst, you... can create professional-looking documents. have a lot more functionality, including better math support, figure handling, and a proper table of contents. profit from powerful templates that automatically format everything as you write. impress with higher-quality typographical output, including improved justification. For Rocket Scientists. And the rest of us, too. Most preview users learned Typst in under 60 minutes. Nothing stands between you and stunning papers. Get started quickly with the 4-step tutorial. With human-friendly error messages, Typst always helps you out if there is a problem. Need Full Control? Anything templates can do, you can do yourself. Leverage professional typesetting features to write and design any document. One language for markup and code Powerful style recipes Stack and Grid layouts Sophisticated typography Regex-powered text transformation CSV and JSON capabilities Learn more... Ready for Science With Typst, you can set the figures, formulas, tables, and bibliographies you need to present your research. And charts are coming soon. Writing Formulas has Never Been Easier Say goodbye to fidgety formula editors and antiquated syntax. lim_(x->oo) 1/x = 0 vec(1, 2) dot.opvec(3, 4) = 11 { x in RRx \"is natural\"and x < 10 } First exampleSecond exampleThird example Typst is open source! You can follow along with the development on GitHub and discuss Typst on our Discord server. With the command line compiler, you can always compile your documents locally. No lock-in, ever. There's more! There is still so much more we want to do with Typst. Coming soon: HTML export Comments Spell check Improved citations PDF/A and PDF/X Desktop app Try Typst now! Create a free account to join the public beta. Sign up for free and try it now!Sign in We are two graduates from Berlin with a passion for software. Typst was born out of our frustration with LaTeX. Not knowing what we were in for, we decided to take matters into our own hands and started building. Four years later, Typst is almost ready to launch. Read our story. Home Documentation About Us Contact Us Jobs Tools Privacy Terms of Service Legal (Impressum) Blog Twitter Discord Mastodon LinkedIn Instagram GitHub Made in Berlin Close",
    "commentLink": "https://news.ycombinator.com/item?id=38354422",
    "commentBody": "Typst – Compose Papers FasterHacker NewspastloginTypst – Compose Papers Faster (typst.app) 312 points by iNic 13 hours ago| hidepastfavorite98 comments tugberkk 12 minutes agoThis is very good. Unfortunately, (majority of) journals and conferences will probably never use it.At least good for our own papers though. reply iNic 13 hours agoprevI like the \"Why should I use Typst instead of ...\" section on the webpage. Tells me immediately what I want to know. More websites should have this. reply taink 59 minutes agoparentThis was cool, but the best thing was the dedicated transition guide from LaTeX to Typst[1].The bottom section especially, which is a list of Typst&#x27;s shortcomings compared to LaTeX. This helped a lot when actually choosing this over Overleaf for the last writing project I had.[1] https:&#x2F;&#x2F;typst.app&#x2F;docs&#x2F;guides&#x2F;guide-for-latex-users&#x2F; reply kitchi 12 hours agoparentprevConspicuously missing a comparison to Overleaf, arguably the most similar in nature to what this is trying to achieve. Cool project, nevertheless. reply zaep 37 minutes agorootparentfor anybody who is wondering, the typst web app is a smoother user experience, having had to use overleaf for some smaller projects only, ive found it slightly janky, sometimes, probably owed to how slow and strange latex compilation can be. I&#x27;m sure the typist web app lacks some cool project management features that overleaf may offer, since it&#x27;s a more mature platform, but with how much nicer typst is compared to latex, I think any shortcomings the web app may have are offset by that. but for sufficiently technical people collaborating via git is imo nicer than any web app. reply sestep 12 hours agorootparentprevCould you clarify what you mean? They explicitly compare against LaTeX, on which Overleaf is built, and I don&#x27;t see any points in their comparison which are mitigated by specifically using Overleaf. reply kitchi 12 hours agorootparentOverleaf solves a lot of the same problems as Typst, although since it&#x27;s still within the LateX ecosystem. For example changes are immediately visible (or immediately after a recompile, but practically I almost never notice) and Overleaf tries it&#x27;s best to parse and simplify the dense error messages. So some of their points against LateX have been partially&#x2F;entirely solved.Typst looks cool, and I&#x27;m probably going to check it out at some point, but a comparison to similar web-based LateX solutions would be more useful than what they have at the moment is all I&#x27;m saying. reply TT-392 11 hours agorootparentThat is not what typst is though, it really is just a language and a compiler which you can just run in your commandline (and a fast one at that). There is that flashy web interface, but that is separate from typst itself, but you don&#x27;t need to use that, it really is a latex replacement. reply rubyfan 10 hours agorootparentright, Typst is bigger than the online editor. The language and compiler would replace latex. It seems Overleaf is an online editor? reply okanat 7 hours agorootparentYup. Because installing (or doing anything with) Latex sucks. Packaging sucks, settings things sucks, every package inventing its own syntax sucks. Overleaf solves some of those problems. It still doesn&#x27;t help you a lot with nonsense error messages but at least you can see them in roughly correct places half the time. reply a2800276 3 hours agorootparentYou forgot to mention that error messages suck and that the standard workflow of invoking latex twice, then placing chicken feathers one the picture your first love, running bibtex, and finally running latex three more times ( or four if it&#x27;s a full moon ) also sucks. reply xvilka 1 hour agorootparentprevThere are projects like Tectonic [1] that aim to fix that.[1] https:&#x2F;&#x2F;tectonic-typesetting.github.io&#x2F;en-US&#x2F; reply kaba0 3 hours agorootparentprevYou can’t avoid latex which is both good (huge ecosystem), and bad (it’s latex). Just recently I tried to help a friend with their CV where he wanted to raise the row-height in a pre-created CV “package”, and it was completely indecipherable, and I could only come up with an ugly hack. reply xvilka 1 hour agorootparentYes, LaTeX error messages are next to useless. reply sestep 12 hours agorootparentprevRight, my understanding was that by \"immediately\" they meant \"way faster than LaTeX\". You make a good point about consolidated errors though, I hadn&#x27;t thought about that before. reply calvinmorrison 8 hours agorootparentprevthe biggest being I can copy in LateX file and get all the benefits of overleaf! I Love overleaf reply io23j23IHiu32 6 hours agoparentprevYeah, and comparison with Word make absolutely no sense. In word you don&#x27;t need to go through the entire document to change some style, you just use predefined formatting styles like \"Heading 1\", \"Quote\", etc. and if you change something in those predefined styles it will be automatically applied to the entire document. You can also work with others on same document at the same time. reply stefandesu 1 hour agorootparentI wish that would work with non-tech people. In my experience, no matter how hard you try to teach them, they&#x27;ll end up messing up the formatting in some way. reply eviks 9 minutes agorootparentHow hard would you try to teach them to use Typst? reply mbork_pl 38 minutes agorootparentprevThis. ALmost nobody knows&#x2F;uses that feature.FTR, there are also many people who use LaTeX in a similar way... reply SpaghettiCthulu 5 hours agorootparentprevYou can do the same thing with Typst. There may be fewer predefined \"styles\", but you can just define your own quite easily. And they&#x27;re far more powerful than in Word. reply countrymile 3 hours agoparentprevWhere is the comparison with markdown? Coming from a quarto&#x2F;Rstudio background here reply josephg 1 hour agorootparentMarkdown on its own isn’t in the same league as latex and similar systems. Off the top of my head, markdown doesn’t support: Figures outside the flow of the document, references, layouts (columns, etc), comments, formulas, a standard and good looking pdf output, page breaks, custom layouts for authors &#x2F; abstract &#x2F; etc, numbered chapters, autogenerated table of contents, custom blocks with different formatting, footnotes, appendixes and a whole lot more.There are various “batteries included” markdown renderers - maybe like quarto - which add mermaid for diagrams and a few other features. But I’ve never seen a paper written in markdown with the same polish as what latex produces. It just doesn’t have the depth of features that you need for making a professional looking paper. Latex ships with all of that out of the box.If their target market is people writing scientific papers, it makes sense that markdown isn’t in the list. Markdown isn’t a serious competitor. reply jansan 1 hour agorootparentprevThis is not the same league, maybe not even the same sport.Markdown is for convenient and quick \"good enough\" looking text editing. It is very good at what it is supposed to do, but the limitations are quite obvious.Typst has its focus on editing scientific documents, something that Markdown was just not made for. reply anonymous_sorry 52 minutes agorootparentI agree they are playing different sports!Ideally, unrendered markdown still provides a first-class reading experience.I don&#x27;t think Typst has that as a design goal. reply kaba0 24 minutes agorootparentTypst texts are quite readable, the language has explicit support to make it as good as feasible (e.g. longer text parameters can be passed unquoted within a [] block, so it is still left readable). Plus you can abstract away more complex configs inside a function, and end up with `#myFunc [My normal unquoted text]`But it is apples to oranges, you can properly format text to book editor capabilities with typst, while you can only do basic stuff with markdown. replyhuijzer 12 hours agoprevI‘ve been using Typst in production to generate a PDF on the fly and it has been amazing. Much smaller dependencies than LaTeX and it was also extremely fast. The syntax takes a bit of getting used to but compared to LaTeX I can’t complain. It looks like a powerful syntax. reply JohnKemeny 12 hours agoparentI would recommend testing Markdown and Pandoc. It&#x27;s open source, and it can export to pdf (via latex), html, latex, doc(x), odt, rst, wiki, ... reply crispyambulance 8 hours agorootparentThe upcoming 1.4 release of quarto is going to have support for Typst as an output format (https:&#x2F;&#x2F;quarto.org&#x2F;docs&#x2F;prerelease&#x2F;1.4&#x2F;typst.html).As capable as it is, Latex is just too damn complicated unless you&#x27;re using someone&#x27;s carefully maintained template and never trying to deviate, even slightly, from the template. Too many brain cells have been sacrificed to LaTeX. It&#x27;s time to move on. Hopefully Typst can pull it off. reply henriquemaia 8 hours agorootparentThanks. Good to know. I&#x27;ve been learning quarto for the past 3 weeks and I&#x27;m amazed how flexible it is. Knowing it&#x27;ll support typst makes it even flexibler. reply Onawa 8 hours agorootparentprevYes, Quarto with Typst for typesetting is how I plan to try and transition things to over time. Every new project, whether I&#x27;m just writing something up, creating a short presentation, or doing a data analysis, everything starts as a Quarto project now. reply huijzer 12 hours agorootparentprevI needed a pretty PDF with headers and footers. Markdown was not expressive enough. reply tonyarkles 11 hours agorootparentAs of late I’ve been using restructuredtext and rst2latex.py and have been quite happy with it. I’m quite used to LaTeX for writing equations and RST handles most of the other boilerplate. If you do need to do fancy TeX things you can still just drop that inline and it generally works pretty good. reply __mharrison__ 4 hours agorootparentI wrote many physical books in rst. (see rst2nitrile).Last year I decided to join the 21st century and migrated my tool to be Pandoc and markdown based. I&#x27;m still writing code for my toolchain, but now I&#x27;m using tools that much more folks are using. reply IshKebab 11 hours agorootparentprevRestructuredText is pretty awful in my experience. Barely documented and unreliable.Asciidoc is much much much better. reply hskalin 4 hours agorootparentprevFor me, I use Emacs org-mode&#x27;s latex export. It works pretty well plus I use org-mode for other stuff anyway. reply mrehler 1 hour agorootparentprevFor what it&#x27;s worth, you can move Markdown -> Typst by way of Pandoc. reply maegul 9 hours agorootparentprevFor me, getting Latex out of the dependency chain is a huge attraction. Just too much cruft and slowness and mysterious errors. Seems way too outdated today. I hope something like typst can provide a nice, fast and modern pdf generator backend. My understanding is that pandoc already supports typst. reply figomore 8 hours agorootparentprevPandoc can export to typst and pdf via typst since, I think, 3.0 version. reply dr_kiszonka 10 hours agoparentprevDo you know how it costs? I can&#x27;t find this information on the website. reply xypage 9 hours agorootparentTheir github [1] page is more helpful for this. Typst itself (as in the program that converts your input to a PDF) is free and open source under the Apache license, and the online editor is free as well but it&#x27;s currently in a public beta so that could change in the future once they move that out of the beta.1: https:&#x2F;&#x2F;github.com&#x2F;typst&#x2F;typst reply dr_kiszonka 7 hours agorootparentThank you! reply ThePhysicist 12 hours agoprevThis was built initially by two PhD students in Germany if I remember correctly, they then spun it off into a company. Super impressive given how difficult typesetting is. And it&#x27;s written in Rust as well! reply drsir 11 hours agoparentI believe they were masters students not PhD students. reply eviks 32 minutes agoprev> Say goodbye to fidgety formula editors and antiquated syntax. > lim_(x->oo) 1&#x2F;x = 0how is -> and 00 modern when → and ∞ exist? reply jonathanstrange 26 minutes agoparentNobody knows where to find these glyphs on the keyboard. reply teleforce 5 hours agoprevThis is one the most recent posts on Typst with 159 comments [1]. Why it is not appear on HN past when checked just baffled me, perhaps Dang or someone as can explain.I think the closest system to typst is Overleaf (I hope they put in their website comparison menu), but the killer feature is that Typst apparently can support local-first that Overleaf does not, and it&#x27;s wonderful feature for those who are writing a lot even when camping in remote areas (ok I&#x27;m stretching a bit there).Since the Typst&#x27;s document compiler is open source then it feasible to integrate it with Docusaurus and Tinasaurus (based on TinaCMS). But again there is also Pretext that is open source that can be used as document compiler alternative to Typst [2].[1]Typst, a new markup-based typesetting system, is now open source:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35250210[2] PreTeXt: Write Once, Read Anywhere:https:&#x2F;&#x2F;pretextbook.org&#x2F;index.html[3] PreTeXt: Write Once Read Anywhere Authoring and Publishing System:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37231025 reply matricaria 4 hours agoparentThe local-first version of Overleaf is just LaTeX, or am I missing something? reply cl3misch 3 hours agorootparentMaybe OP means the collaboration feature. I don&#x27;t know whether local typst supports that though. Expecting online collaboration in \"local first\" may be an oxymoron in itself... reply mgunyho 3 hours agorootparentThe pro version of Overleaf supports offline work with a simple trick: every Overleaf document can be accessed as a git repo. It&#x27;s a bit limited (there&#x27;s no branches or tags, and it breaks the \"track changes\" feature) and trying to convince the average researcher to learn git is a challenge, but if you know git it works quite well. reply matricaria 3 hours agorootparentprevAs far as I know, local Typst does not support collaboration. At least not in the way the online version and Overleaf do. reply behnamoh 12 hours agoprevI&#x27;m afraid the ship has sailed and people will use latex for ever (I personally use Word but with lots of customizations).why use latex (and this is coming from someone who prefers Word to latex):- much better tooling than any other format- much more discussion on various problems you&#x27;ll hit.- much more training data for chatgpt and other LLMs, so your personal assistant can help you with latex syntax. good luck getting that level of support for typst or any other new programming language.- network effect -- if your professor only knows latex, you can&#x27;t use typst. and professors are slow&#x2F;reluctant to adopt new shiny tech. if it has worked in the past 50 years, why change it? reply tnecniv 9 hours agoparentI mean by that logic we should still be using FORTRAN for our research code and there’s no point developing new languages because the space is explored at this point.Really I think the main thing holding it back are the lack of templates supported by journals and conferences and some known rendering bugs &#x2F; limitations that are being worked on. reply slow_typist 26 minutes agorootparentJust for the record, FORTRAN is #12 on tiobe [1], leaving go and swift behind.[1] https:&#x2F;&#x2F;www.tiobe.com&#x2F;tiobe-index&#x2F; reply kaba0 18 minutes agorootparentTIOBE is still behind useless. It once listed Visual Basic ahead of JS. It has as much relevance to sorting programming languages as alphabetical ordering. reply pama 9 hours agorootparentprevI think the main blocking point is that TeX algorithms are near optimal for a lot of the technical typesetting and everything else looks somewhat off to the astute readers, and those readers are repeat consumers of the technical texts. reply a2800276 3 hours agorootparentIt&#x27;s not as though the TeX algorithms are secret and can&#x27;t possibly be recreated elsewhere. reply JohnKemeny 12 hours agoparentprevYou can get really far today with Pandoc Markdown, which has many benefits over LaTeX. So, just wait until a generation has grown up with Markdown as a universal text language. Indeed, with the exception of the journal&#x27;s template, you can write a full paper in Pandoc Markdown and nobody would spot the difference. reply behnamoh 11 hours agorootparentI tried md for a while but inevitably ended up having to incorporate latex in the document for formatting (either through md or pandoc). at that point, you might as well use latex. reply throw_pm23 12 hours agorootparentprevCan you link a scientific article or book pdf that was written in Markdown? reply esafak 11 hours agorootparenthttps:&#x2F;&#x2F;quarto.org&#x2F;docs&#x2F;gallery&#x2F;#books reply __mharrison__ 4 hours agorootparentprevThe PDFs of my recent books, Effective XGBoost, and Learning Python for Data were created using markdown and Pandoc (somewhere along the way).I&#x27;m in the middle of doing the second edition of Effective Pandas, moving it from rst based tooling to markdown&#x2F;Pandoc. reply Ar-Curunir 12 hours agorootparentprevtbqh, any serious paper writing requires formatting considerations that Markdown cannot express.Like, if you care at all about how your paper looks, Markdown is insufficient. reply contravariant 11 hours agorootparentI think with pandoc there&#x27;s very little you can&#x27;t do, but I never tested it to its limits. Nowadays I only use LaTeX if I really need the nitty gritty formatting capabilities, at which point adding an extra layer of indirection is pointless. reply IshKebab 11 hours agorootparentprevYou can get quite far... but really if you&#x27;re writing a big technical document with a Markdown style format you definitely want Asciidoc, not Markdown. reply huijzer 12 hours agoparentprevI’m not affiliated to Typst and still think LaTeX at this point in time is one of the worst things to deal with as an academic. Errors can be extremely unclear.And yeah sure many discussions for all kinds of packages and backends except for that one backend or package that you are running. reply maegul 9 hours agorootparentCompletely with you. It’s time to move on from Latex. Couldn’t hope more for the success of a better alternative! reply awestroke 58 minutes agoparentprevYeah, the LaTeX ship has sailed, I&#x27;ll never touch it again. I&#x27;m very happy that I can use Typst instead. reply tavavex 2 hours agoparentprevI think points 2 and 3 only really apply if we assume the number of problems encountered with LaTeX and Typst are roughly similar. After all, how much of an issue is finding solutions if you never run into issues in the first place? And this is where I think competing platforms can pull ahead of LaTeX - it&#x27;s already a huge pain to learn and use, so if a new standard becomes much more convenient.. why not switch? reply Ar-Curunir 12 hours agoparentprevtbqh IME using Copilot for LaTeX has been pretty hit or miss, so I&#x27;m not sure the AI point is as pertinent.The network effect aspect is very real, but I&#x27;ve been seeing Typst pop up in my academic circles. reply mfld 10 hours agoprevTypst could be to LaTeX what Python was to Perl. reply jansan 1 hour agoparentOr what Word was to WordPerfect. reply xvilka 1 hour agoprevIs there something like TikZ for Typst? reply c-st 1 hour agoparentAs per https:&#x2F;&#x2F;github.com&#x2F;qjcg&#x2F;awesome-typst#graphics there is CeTZ. Of course it is not as full-fledged as TikZ, but it works pretty well. reply arjvik 9 hours agoprevI love everything about Typst except for the math-mode syntax. I&#x27;m too used to LaTeX syntax for math (my editor of choice uses MathJAX to render math and math only). Any chance of substituting in the math syntax (even if it&#x27;s the new rendering engine?) reply amarko 5 hours agoprevLaTeX was great for its time but it should have died long ago. Typst is such a pleasure to use in comparison. It&#x27;s unfortunately not quite capable enough yet to use for my papers, but I very much hope that it finds success in the future. reply rochak 12 hours agoprevTime to rewrite my resume using this. If anyone knows any similar tools, please share them. reply jskherman 7 hours agoparentCheck out the awesome-typst [0] list as well for ideas.[0]: https:&#x2F;&#x2F;github.com&#x2F;qjcg&#x2F;awesome-typst reply legobmw99 11 hours agoparentprevRelated: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38047224 reply poulpy123 7 hours agoprevI tested it two months ago and I was really impressed: clear, fast and good rendering. I even managed to modify a module for message boxes in 15mn. I haven&#x27;t used latex in 10 years, but I would have replaced it with typst everywhere I could. I still hope it could also replace markdown reply JohnKemeny 12 hours agoprev1. Why not use Markdown-compatible syntax?2. Why would we want to observe changes in real time? Do you want this when coding too?My workflow (that I share with co-authors) is to write everything in Markdown (using Pandoc to get PDF output). When we are almost finished, we export (again with Pandoc) to LaTeX.We collaborate on Git, because, just as when programming, I don&#x27;t want my co-authors to witness my crappy thought process. That&#x27;s just noise. Git allows us to use different Git-branches for the arxiv version, the conference version, and the journal version. We also use tags to indicate different submissions. reply huijzer 12 hours agoparent1. Why not use Markdown-compatible syntax?I‘m not an Typst author, but I don’t get your point. How are you going to specify a 2 column outlay, for example? Markdown is not very expressive. You can always compile (less expressive) Markdown to Typst.2. Why would we want to observe changes in real time? Do you want this when coding too?You prefer to debug by looking at the code only? reply kevincox 9 hours agorootparentIt seems that it would have been good to be basically extensions on markdown. For example why use = for headers rather than the established #. + For numbered lists is arguably an improvement on 1. But maybe they could support both. It seems like these are pointless differences.Their math syntax is already a common Markdown extension but they seem to be more or less compatible in the framing although the actual match language is new which seems fine. Then of course they add on their macros.So I guess the point is why diverge where not necessary. Not why diverge at all. reply JohnKemeny 12 hours agorootparentprev1. Using `classoption: twocolumn`2. I see that I wasn&#x27;t completely clear. I meant: why do we want to see our collaborators&#x27; changes in real time? To me, that would be very disturbing. reply kaba0 3 hours agorootparentSo your 1. is no longer markdown everyone knows, but an ad hoc, badly documented new language understandable by a tiny subset of editors&#x2F;people. How is that better?2: it is fundamentally a command line app that converts a .tex file to a pdf (and some other output formats). You can just git over that if you prefer it. The web editor is a separate application, which is very streamlined and a good option for students working together, but sure, feel free to use something else. reply eichin 10 hours agorootparentprevYeah, collaborating in real time on the same document is pretty neat (from using google docs for this.) Having someone else typing on the same page got an unexpectedly visceral \"argh! it&#x27;s moving! get it off of me\" reaction the first couple of times I tried it, had to switch tabs and come back later.It&#x27;s definitely only a problem for some people, and might even be specific to some aspect of the google docs implementation, I don&#x27;t know yet. But yeah, that feature is not the slam dunk it sounds like, and you might not realize it until you&#x27;re in the middle of it. reply bobbylarrybobby 7 hours agorootparentI&#x27;m with you. Git with one sentence per line is generally my preferred workflow for markdown, asciidoc, etc. reply jskherman 6 hours agoparentprev> 1. Why not use Markdown-compatible syntax?There&#x27;s already a pandoc conversion to Typst and the syntax is mostly similar. Various symbols that are in use in markdown is used by the Typst in some other places (e.g. # is used for designating code mode in content mode so you can use variables function in-text).> 2. Why would we want to observe changes in real time? Do you want this when coding too?If you&#x27;ve ever wanted to just use something that&#x27;s more powerful than Markdown (and not use awkward HTML in between, let&#x27;s face it MD was supposed to be minimal), you have to use LaTeX, but it gets painfully slow as the project gets big. Fast feedback loops are essential. Would you rather wait 5s seconds to see that you have made changes that destroyed your layout or in an instant with incremental compilation?3. You can collaborate with Git (and on the Web App) because Typst is also a language and a compiler (see their GitHub page at https:&#x2F;&#x2F;github.com&#x2F;typst&#x2F;typst) like LaTeX.You can have it function as well as Markdown with templates and just use the sugar syntax (plus custom functions ad hoc without having to wrangle with LaTeX&#x27;s enigmatic errors [1] and confusing macros even for something trivial like fonts [2]).[1]: remember \\badness 10000?[2]: You&#x27;d have to install a package even though the OTF&#x2F;TTF of the font you want is already installed on your system. And don&#x27;t even mention how it&#x27;s a completely different setup for PDFLaTeX, ConTeXT, and LuaLaTeX to use fonts. This is assuming you want to use LaTeX templates with markdown using Pandoc or Quarto. sigh... reply jcparkyn 10 hours agoparentprevYou can still use git with typst, if you use the offline (open-source) compiler instead of the web app. reply karencarits 9 hours agoparentprevThanks for sharing your workflow! I&#x27;ve long wanted to adapt something similar, but it is difficult to get away from Word - especially because the comment and revision functions in Word are more straightforward than git-based solutions reply Ar-Curunir 12 hours agoparentprev> My workflow (that I share with co-authors) is to write everything in Markdown (using Pandoc to get PDF output). When we are almost finished, we export (again with Pandoc) to LaTeX.That&#x27;s your (and my) workflow. However, there is clearly demand for a collaborative workflow, as demonstrated by Overleaf and ShareLaTeX before that. reply jchook 3 hours agoprevAm I the only person that wrote my thesis in Maple? reply Racing0461 10 hours agoprevLooks nice for resumes also. reply iamdbtoo 9 hours agoparentI did my last resume in Typst and it was so much better than a Word&#x2F;Google doc or Latex. reply renewiltord 12 hours agoprev [–] This is very cool. What&#x27;s the pricing you anticipate? reply TT-392 11 hours agoparent [–] The compiler is open source, and written in rust. The web interface is free, and I think it will stay that way? (I think they run on donations). They could really use some clearer marketing on the front page... reply LegibleCrimson 10 hours agorootparent [–] > The compiler is open source, and written in rust.Wow, that&#x27;s really appealing to me; thanks for pointing that out. I was thinking \"well, this looks nicer than LaTeX, and I&#x27;m really frustrated with LaTeX, but I really don&#x27;t want to jump right into a big WYSIWYG thing\". Now I&#x27;m really interested. Most of the other \"replacements\" suffer in some big ways (Markdown and RST&#x2F;Sphinx are great for structured content, but not great for meticulous control over the presentation).$ cargo install --git https:&#x2F;&#x2F;github.com&#x2F;typst&#x2F;typst...$ printf &#x27;Total displaced soil by glacial flow:$ 7.32 beta + sum_(i=0)^nabla Q_i &#x2F; 2 $&#x27; > file.typ$ typst compile file.typ output.pdfAnd I&#x27;ve got a cool rendered PDF with a math formula!I&#x27;m very keen now to see exactly how flexible, robust, and extensible this is. LaTeX can do basically anything, but you pay for the power in blood. I would love a typesetting system that isn&#x27;t horribly painful to extend. reply kaba0 3 hours agorootparent [–] I think they were very careful to have the same expressivity as latex. It’s basically a whole language with a human-friendly syntax.Their discord channel has a bunch of community plugins if you want a showcase. It’s not yet as big as latex, obviously, but I think it already has the critical mass to make it a sound choice. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Typst is a web-based writing tool designed for scientific papers, prioritizing layout and formatting.",
      "It enables seamless collaboration, provides pre-designed templates for automatic content formatting, and offers superior typographical output.",
      "User-friendly, Typst includes features like math support and figure handling, accompanied by a 4-step tutorial and clear error messages. It is an open-source tool with ongoing development for additional features."
    ],
    "commentSummary": [
      "Typst is a tool designed to replace LaTeX and offers a smoother user experience than Overleaf.",
      "It is praised for its dedicated transition guide from LaTeX and its ability to define custom styles.",
      "Some users are unsure if journals and conferences will adopt Typst, but it is seen as a nice alternative to LaTeX with real-time collaboration features."
    ],
    "points": 312,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1700513043
  },
  {
    "id": 38349357,
    "title": "Google Accused of Sabotaging Firefox for Chrome's Advantage",
    "originLink": "https://www.zdnet.com/article/former-mozilla-exec-google-has-sabotaged-firefox-for-years/",
    "originBody": "business Home Business Tech Industry Former Mozilla exec: Google has sabotaged Firefox for years Former and current Mozilla engineers are reaching their boiling points. Written by Catalin Cimpanu, Contributor April 15, 2019 at 12:06 p.m. PT security 8 habits of highly secure remote workers How to find and remove spyware from your phone The best VPN services: How do the top 5 compare? How to find out if you are involved in a data breach -- and what to do next A former high-ranking Mozilla executive has accused Google of intentionally and systematically sabotaging Firefox over the past decade in order to boost Chrome's adoption. He is not the first Firefox team member to come forward and make such accusations in the past eight months; however, his allegations span far beyond current events and accuse Google of carrying out a coordinated plan that involved introducing small bugs on its sites that would only manifest for Firefox users. Oops after oops Johnathan Nightingale, a former General Manager and Vice President of the Firefox group at Mozilla, described these issues as \"oopses.\" \"When I started at Mozilla in 2007 there was no Google Chrome, and most folks we spoke with inside [Google] were Firefox fans,\" Nightingale recollected in a Twitter thread on Saturday. \"When Chrome launched things got complicated, but not in the way you might expect. They had a competing product now, but they didn't cut ties, break our search deal - nothing like that. In fact, the story we kept hearing was, 'We're on the same side. We want the same things',\" the former Mozilla exec said. \"I think our friends inside Google genuinely believed that. At the individual level, their engineers cared about most of the same things we did. Their product and design folks made many decisions very similarly, and we learned from watching each other. \"But Google as a whole is very different than individual googlers,\" Nightingale said. \"Google Chrome ads started appearing next to Firefox search terms. Gmail & [Google] Docs started to experience selective performance issues and bugs on Firefox. Demo sites would falsely block Firefox as 'incompatible',\" he said. \"All of this is stuff you're allowed to do to compete, of course. But we were still a search partner, so we'd say 'hey what gives?' And every time, they'd say, 'oops. That was accidental. We'll fix it in the next push in 2 weeks.' \"Over and over. Oops. Another accident. We'll fix it soon. We want the same things. We're on the same team. There were dozens of oopses. Hundreds maybe?\" \"I'm all for 'don't attribute to malice what can be explained by incompetence' but I don't believe Google is that incompetent. I think they were running out the clock. We lost users during every oops. And we spent effort and frustration every clock tick on that instead of improving our product. We got outfoxed for a while and by the time we started calling it what it was, a lot of damage had been done,\" Nightingale said. see als 10 dangerous app vulnerabilities to watch out for (free PDF) Not the first accusations And Nightingale is not the first Firefox team member to come forward and make such accusations. In July 2018, Mozilla Program Manager Chris Peterson accused Google of intentionally slowing down YouTube performance on Firefox. He revealed that both Firefox and Edge were superior when loading YouTube content when compared to Chrome, and in order to counteract this performance issue, Google switched to using a JavaScript library for YouTube that they knew wasn't supported by Firefox. YouTube page load is 5x slower in Firefox and Edge than in Chrome because YouTube's Polymer redesign relies on the deprecated Shadow DOM v0 API only implemented in Chrome. You can restore YouTube's faster pre-Polymer design with this Firefox extension: https://t.co/F5uEn3iMLR — Chris Peterson (@cpeterso) July 24, 2018 At this point, it's very hard not to believe or take Nightingale's comments seriously. Slowly but surely, Google is becoming the new Microsoft, and Chrome is slowly turning into the new IE, an opinion that more and more users are starting to share [1, 2, 3]. Reminds me of the time Microsoft used private APIs to make IE better. Google is the new Microsoft. The tables have turned :p — Federico Ramirez (@gosukiwi) July 24, 2018 A previous version of this article referenced a Firefox bug. It was not a bug and we removed it from the article. All the Chromium-based browsers More browser coverage: NoScript extension officially released for Google Chrome Internet Explorer zero-day lets hackers steal files from Windows PCs Google Chrome engineers want to block some HTTP file downloads Mozilla: Firefox to block cryptomining scripts hidden on websites by default Opera 60 released with a built-in cryptocurrency wallet Mozilla releases beta of Firefox for ARM-based Windows 10 laptops What enterprises need to know about the new Chromium-based Edge TechRepublic Google's most secure login system now works on Firefox and Edge, too CNET Editorial standards show comments related Firefox 120 will be available to download tomorrow. Here's what's new and improved Boosting cybersecurity: Microsoft's AI-driven Security Copilot unveiled at Ignite 2023 How to avoid losing your unused Google accounts next month",
    "commentLink": "https://news.ycombinator.com/item?id=38349357",
    "commentBody": "Former Mozilla exec: Google has sabotaged Firefox for years (2019)Hacker NewspastloginFormer Mozilla exec: Google has sabotaged Firefox for years (2019) (zdnet.com) 286 points by hashhar 18 hours ago| hidepastfavorite115 comments xd1936 17 hours agoJust today, the &#x2F;r&#x2F;YouTube subreddit was discussing how Polymer adds an artificial 5 second delay based on user-agents other than Chrome.1. https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;youtube&#x2F;comments&#x2F;17z8hsz&#x2F;youtube_ha... reply accrual 16 hours agoparentHere is the JS that was found: setTimeout(function() { c(); a.resolve(1) }, 5E3); reply phkahler 16 hours agorootparentThat&#x27;s pretty clearly anti-competetive. reply rendaw 16 hours agoparentprevBeing discussed here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38345858 reply mtVessel 17 hours agoprevThere was a period of time when sites pretty much worked everywhere. In the last five years or so, the number of sites that only work in Chrome was risen precipitously. It&#x27;s either malice or incompetence, and I have no trouble believing either. reply beiller 17 hours agoparentMaybe a counter point here, but I&#x27;ve doubled down on Firefox only, even at work. Things like hangouts and many other Goog services seem to have started working more at parity compared to Chromium at least I&#x27;ve found, in the last year or so. reply iforgotpassword 16 hours agorootparentSame for me. Teams didn&#x27;t even allow me to join about a year ago, but a few weeks ago it just worked. I can&#x27;t even remember the last time I encountered a site that wouldn&#x27;t work in Firefox tbh. Am I just lucky? reply nottheengineer 16 hours agorootparentTeams will let you use chat and join meetings in firefox, but as soon as you try to make a call you&#x27;ll get the \"fuck you\" popup. reply isodev 17 hours agoparentprevEven Microsoft’s GitHub has all kinds of glitches unless you’re using a chromium browser.The general push towards a single engine is just undeniable at this point. Whoever controls the browser, controls the web. reply rascul 16 hours agorootparent> Even Microsoft’s GitHub has all kinds of glitches unless you’re using a chromium browser.What are some of the glitches? I&#x27;m curious if I&#x27;ve ran into any of them. reply ForkMeOnTinder 14 hours agorootparentctrl-&#x2F; doesn&#x27;t work in firefox for me (the shortcut for \"Focus secondary search bar\")But all things considered that&#x27;s pretty minor reply inferiorhuman 11 hours agorootparentprevGiven how bad the current Github UI is (and how sloppy the rollout was) I&#x27;m quite content to attribute it to incompetence rather than malice, but:Type a long blurb into a text input widget e.g. a comment on a pull request. The text just bounces up and down as you type. I&#x27;ve noticed this with whatever the extended support version of Firefox (macos 10.14) is and with the current Firefox (macos 14.1). To be fair GH renders widgets partially off screen with whatever version of Safari comes with macos 10.14 There is no more static text on GH so if you go back further than that (or have javascript disabled) nothing renders at all.There&#x27;s no issue tracker (because why would there be?) but there was a discussion thread. Last I saw someone posted detailed steps to reproduce a search bug and the GH response was to lock the discussion thread. reply Thin_icE 14 hours agorootparentprevSame, never found any glitch. reply beej71 11 hours agorootparentprev> The general push towards a single engine is just undeniable at this point. Whoever controls the browser, controls the web.I fear you&#x27;re right. Evidence: IE6. But eventually we will come out the other side. reply kolinko 16 hours agoparentprevI&#x27;ve been using Safari on MacOS for the last 3-4 years (switching from Chrome), and I can&#x27;t remember a single site that wouldn&#x27;t work properly.With one notable exception of Google Meet, which consistently tended to fail on anything but Chrome. reply throwaway2203 16 hours agorootparentI reckon it&#x27;s more webkit rather than Chrome. I think Mozilla is the only major non-webkit browser now. reply danaris 15 hours agorootparentChrome isn&#x27;t really WebKit anymore, though—it&#x27;s Chromium. reply nerdjon 17 hours agoparentprevWhen Google decided to fork Webkit we should have all seen this coming. Safari and Chrome being on the same engine was great, now we are seeing more divergence since we have 3 main engines and more and more are only testing on Chrome. reply bryanlarsen 16 hours agorootparentWouldn&#x27;t it be the opposite? When Safari & Chrome were more similar you could get away with testing only one. Now you have to test on at least both Safari & Chrome, and anything that works on both of those is more likely to work on Firefox than something that only works on Chrome. reply scarface_74 16 hours agorootparentprevNo one targeting an American market would be crazy enough to ignore Safari because of iOS’s market share. reply scarface_74 16 hours agoparentprevThere was never that time.1. At first it was “works best with Netscape Navigator”2. Then it was the same with IE3. Now it’s Chrome. reply plorkyeran 13 hours agorootparentThere was a step in between #2 and #3 where web developers all used FF while non-technical users used IE6, so supporting both was unavoidable. Chrome didn&#x27;t become dominant until a decade later. reply scarface_74 5 hours agorootparentAnd web developers then ignored Safari from 2001-2007 before the iPhone came out… reply glenstein 12 hours agorootparentprevI&#x27;m with you on 2 and 3, but was Netscape Navigator similarly anti-competitive in a way that is analogous to Chrome or IE? reply scarface_74 11 hours agorootparentYes. They added all sorts of proprietary extensions that didn’t go through a standards body. Thad’s how we got the “navigator” object in all browsers. reply marssaxman 15 hours agoparentprevI wonder why I have not encountered any; it has been well over five years since I last used Chrome at all! reply dmbche 16 hours agoparentprevReally? Could you point me to one of those sites? reply nness 17 hours agoparentprevGotta protect that ad revenue some how... reply nness 17 hours agoparentprevGotta protect your ad revenue some how... reply Arubis 18 hours agoprevI keep a Chromium browser kicking around on my personal machines basically for the sole purpose of using Google properties, particularly Hangouts. Firefox is fine on virtually everything else, but absolutely drags on stuff owned by the Goog. reply giancarlostoro 18 hours agoparentHave you tried faking your browser user agent to Google? I&#x27;ve seen it say \"such and such doesn&#x27;t work on any browser other than Google\" and with one simple trick, managed to get things running on Firefox just fine. I wouldn&#x27;t be surprised if any \"degraded experience\" is due to code that assumes Firefox is IE (like a very poorly written \"else\" code block) and just refuses to run optimal code that works fine on Firefox.I&#x27;m not going to use Chrome outside of work (I hate to say it but their dev tools are just hard to walk away from - please Mozilla, invest in your dev tools more). reply zamadatix 17 hours agorootparentThis usually works out well for the sites just never bothered to test for Firefox and threw up the banner but it can end up going pretty poorly&#x2F;silently-and-annoyingly-start-failing-halfway-through for sites that threw up the banner because they knew they didn&#x27;t do feature detection and assumed Chrome or Chrome&#x27;s behavior. I.e. \"better than nothing if you are dead set on never installing Chrome\" but, outside that, worse off than just going to your copy of Chrome for all but your most regularly visited websites that throw the \"only supported in\" banner. reply idle76 17 hours agoparentprevYep, this is part of the reason I avoid google like the plague. Everything else works like a charm in FF, so why would I use an inferior product? Granted, I don&#x27;t use youtube, but everything else has better alternatives away from big evil. reply rabbits_2002 17 hours agoprevGoogle went from my most trusted tech company in 2010 to being just blatantly evil. I think it must be the new CEO. reply acdha 17 hours agoparentThat’s shortly after they acquired DoubleClick in 2008 – note in particular how they haven’t managed to introduce a good new product since that time. I think that’s because the torrent of ad revenue meant that nothing really affects the price of your stock so all of the executive types are busy playing politics without real fear that users won’t like what they’re shipping. reply nullc 16 hours agoparentprevGoogle was evil even in 2010. For example, in 2007 Google actively conspired with Apple to illegally fix wages industry wide, concealing their activity, and using the threat of spurious patent litigation to force hesitant executives into their illegal collusion.Even though I didn&#x27;t work at one of the colluding companies, I got a ~20% step function in my income when the collusion finally collapsed and wages became more competitive across the industry. Considering indirect effects like this, the amounts stolen from workers in related industry probably amounted to hundreds of billions of dollars. reply greenyoda 16 hours agorootparent> in 2007 Google actively conspired with Apple to illegally fix wages industry wide...For those who don&#x27;t remember this, here&#x27;s Wikipedia&#x27;s article on it: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;High-Tech_Employee_Antitrust_L... reply mariusor 16 hours agorootparentprevComplaining about the level of compensation at Google and Apple (even as far back as 15 years ago) feels like a very, _very_ first world problem. reply greenyoda 16 hours agorootparentRegardless of how much the employees were being paid, CEOs colluding with each other to not recruit employees from each other was a blatant violation of US anti-trust law. reply Terr_ 13 hours agorootparentprevPerhaps, but \"first world problems\" can still kick off other problems for everyone else down the line.If you hold down the wages of of the top 10% of laborers, then the next 10% have a harder time getting raises too, etc.In addition, if those systems of collusion become established, they&#x27;re a strong profit-motive to gradually expand how many workers are being harmed. reply nullc 16 hours agorootparentprevI guess \"Do the right thing\" means that robbery is fine so long as you choose the right victims.The theft by google and apple had effects broadly in the economy, far outside of the colluding companies. reply paul7986 17 hours agoparentprevNo they were evil way before then .. they just were able to keep their rosy image for longer then should have been able to. reply WhereIsTheTruth 18 hours agoprevMozilla did more harm than google, like killing Servo and embedding Pocket, and let&#x27;s not forget how they siphoned the money they made with their Google contract, they chose to fund their other questionable endeavors insteadWhen you choose to sell your user base to google, you are part of the problem reply Yoric 17 hours agoparentI&#x27;m not sure I follow. Mozilla killed Servo, much to my sorrow, because it didn&#x27;t have enough money to fund it. Mozilla embedded Pocket because it was an attempt to not rely on Google&#x27;s money to fund developments. The money they received from the Google contract was spent either developing Firefox or trying to find ways to make money without relying on Google.So... pick one, but you can&#x27;t both be angry at Mozilla because they use Google&#x27;s money and be angry at Mozilla because they&#x27;re trying to find a way to work without Google&#x27;s money. reply yesco 15 hours agorootparentMozilla has to kill the unimportant stuff like servo so it&#x27;s CEO can get a more competitive wage to support her family with. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Mitchell_Baker#Negative_sala...More seriously, if Mozilla really can&#x27;t afford to do browser R&D, I really have to wonder why they keep dumping money into political & non-browser related causes. reply Yoric 5 hours agorootparentThe political & non-browser related causes are Mozilla Foundation. Firefox is Mozilla Corporation. Related entities, but two different sources of funding. reply CivBase 18 hours agoparentprevMozilla has lots of problems and your complains are valid. But that does not excuse Google&#x27;s behavior and it doesn&#x27;t change the fact that Mozilla is the only viable alternative to Chrome and Chromium browsers for most people. reply PurpleRamen 16 hours agoparentprevWhat again is the evil and harmful thing, Pocket is doing to the users? reply dralley 17 hours agoparentprev>Mozilla did more harm than google, like killing ServoLook, no offense, but to do \"harm\" by killing Servo, people would have had to have been using Servo, or there would need to be a clear path to people using Servo, which there wasn&#x27;t, really. The parts of Servo which were technically viable in any reasonable timespan were already mainlined into Firefox.>embedding PocketYou genuinely think this is \"more harm\" than Google? Seriously? Not to mention that Pocket is a non-Google source of profit for Mozilla.>and let&#x27;s not forget how they siphoned the money they made with their Google contract, they chose to fund their other questionable endeavors instead\"questionable endeavors\" like, um, Rust and Servo? You&#x27;re ignoring the successes while only alluding to failures. I like both Rust and Servo, but say what you will about Firefox OS, at least it presented new market opportunities. Rust and Servo did not.>When you choose to sell your user base to google, you are part of the problemPlease suggest a viable business model for Mozilla, then. reply plopz 16 hours agoparentprevalso killing old addons, i miss classic theme restorer, having to resort to keeping a git repo up to date in my appdata to style userchrome is so annoying reply rascul 15 hours agoparentprevMozilla didn&#x27;t kill servo. It is alive. reply liquidpele 18 hours agoparentprevThis was my first thought too…They didn’t even make Firefox, someone else did and they took it over, they had no foresight. They ignored people’s complaints about memory issues for years. They didnt keep one tab from crashing the whole thing for years, followed chrome to fix. Frankly Mozilla really is a dinosaur and seems to lack any real practical innovation. reply dralley 17 hours agorootparent>They didn’t even make Firefox, someone else did and they took it over, they had no foresight. They ignored people’s complaints about memory issues for years. They didnt keep one tab from crashing the whole thing for years, followed chrome to fix. Frankly Mozilla really is a dinosaur and seems to lack any real practical innovation.HN has a serious revisionist history problem w&#x2F;r&#x2F;t Mozilla.The memory problems, and the lack of multiprocessing, were both hamstrung by the Firefox extension model, which allowed nearly unlimited customization of the browser, at the expense of nearly unlimited ability to muck up the internals of the browser. It led to any poorly coded extension being able to cause all sorts of memory leaks, sluggishness, bugs and crashes.And yet techie types were screaming bloody murder when they started talking about \"innovation\" via transitioning away from the XUL foundations. They didn&#x27;t care about performance or security so long as their XUL extensions kept working, they said. I remember those threads well.edit: oh look, there&#x27;s one in this very thread https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38349686Certainly they could have made more progress and faster, had they not had a huge existing community to transition, unlike Chrome who had a completely fresh start and far more resources. reply zlg_codes 17 hours agorootparentprevAh yes, &#x27;practical innovation&#x27; like Manifest v3? Encrypted Media Extensions? Web Environment Integrity? Google couldn&#x27;t innovate if it tried. Like any other big business, they care only for control in a market. reply Yoric 17 hours agorootparentprevMozilla very much created Firefox, thank you very much.Also, on all your other issues, see https:&#x2F;&#x2F;yoric.github.io&#x2F;post&#x2F;why-did-mozilla-remove-xul-addo... reply asadotzler 9 hours agorootparentprev>They didn’t even make Firefox, someone else did and they took it over, they had no foresight.this is bullshit. people working on Netcape&#x27;s dime, myself included, under the Mozilla project umbrella, and with approval from the Mozilla leadership, myself included, created the browser that would come to be Firefox. reply jsnell 18 hours agoprevPrevious discussion from 2019: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19669586(I&#x27;m kind of surprised it&#x27;s just the one previous submission.) reply aeurielesn 18 hours agoprev> Slowly but surely, Google is becoming the new Microsoft, and Chrome is slowly turning into the new IEHonestly, Microsoft is becoming the new Microsoft. reply _ZeD_ 17 hours agoparentgoogle is becoming (has already become IMHO) the old microsoft reply beej71 11 hours agorootparentYes, but instead of a tech company, they&#x27;re an advertising company. Fuuuuuuu-- reply red-iron-pine 15 hours agoparentprevjust wait until they have unshackled AI reply TheMiddleMan 17 hours agoprevFor years, when searching \"Firefox\" on the Google Play store, the only way to install apps on most Android devices, the first result would be a Google ad for Chrome. reply williamdclt 17 hours agoparentmeh, that&#x27;s the case for all sorts of apps, not only google things. Looking for \"tinder\" gives me a Hinge ad as first result. reply acdha 17 hours agorootparentTrue, but Google has a conflict of interest here and they really need to be barred from doing this in categories where they also compete. reply bearjaws 16 hours agorootparentprevExcept Google is just moving money from right hand to left hand.If Firefox wanted to be at the top, they have to pay cash to Google. reply regentbowerbird 17 hours agorootparentprevThat&#x27;s besides your point but Tinder and Hinge are not competitors, they are both owned by Match Group. reply upofadown 17 hours agoprev>\"I&#x27;m all for &#x27;don&#x27;t attribute to malice what can be explained by incompetence&#x27; but I don&#x27;t believe Google is that incompetent.They might be that indifferent though. If everyone in an organization knows that there are no repercussions to being incompatible with a particular entity, they will spend no time ensuring such compatibility. Entropy will do the rest.Sometimes an anticompetitive situation can evolve without anyone taking an assertive action. reply yifanl 17 hours agoparentI made this comment years ago, but selective indifference is still malicious. reply freedomben 17 hours agorootparent> selective indifference is still maliciousI don&#x27;t think you can conclude that, at least not without playing with the definition of \"malicious\" which according to MW is \"having or showing a desire to cause harm to someone.\"If a typical engineer at Google, who is under the gun on schedule and needs to ship, prioritizes getting stuff working on Chrome which serves the vast majority of the market, and never ends up testing on FF (which may not even be installed on their machines), that&#x27;s not the engineer \"having a desire to cause harm to [mozilla]\".If you are arguing that the outcome is still the same, then I don&#x27;t disagree, but even then still I think motivations matter for some things. Someone who accidentally hits a pedestrian and kills them is IMHO a different (and importantly different when it comes to meting out justice) situation vs a person intentionally aiming for and killing a pedestrian. reply acdha 16 hours agorootparentIt’s not malice on behalf of that engineer. It is at the level of the managers who decided not to have adequate staffing, and who set the policy that unlike other companies they are willing to risk poor user experience to shift the browser market. reply glenstein 12 hours agoparentprev>Sometimes an anticompetitive situation can evolve without anyone taking an assertive actionOne example from TFA is checking a user agent and purposely adding a 5 second timer if it is not Chrome, which imo is hard to accidentally do. reply Tagbert 16 hours agoprevRelated story:“YouTube artificially slows down video load times when using Firefox” https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38345858 reply leoc 18 hours agoprevReminder again, again that &#x27;Google&#x27; here amounts to two individual human beings, Page and Brin, who largely have full liberty to do as they wish with the company. It would be unfair to particularly blame them for some of the undesirable things that happen at Google: for example, problems that are somewhat inevitably the result of Google&#x27;s somewhat intractably broken corporate culture, or problems that are genuinely too small to be likely to ever reach the ear of the Tzar. But this is another place where those excuses don&#x27;t seem to apply. reply gkoberger 17 hours agoprevI&#x27;m surprised more people haven&#x27;t noted this is 2019 article is here now because of OpenAI.Both Mozilla and OpenAI were for-profit companies fully owned by a non-profit of the same name, and dependent on a large corporation (Google&#x2F;Microsoft) for a large majority of their finances.And both times, the large company ended up competing directly (Chrome&#x2F;whatever&#x27;s happening here) due to being slowed down, while still being the main financier of the original company. reply mepian 18 hours agoprev(2019) reply throw7 16 hours agoprevof course. most of my friends have switched to chrome just because of these \"oopses\" or niggles. switch to chrome and \"it just works\". it&#x27;s not just google here... a lot of heavy javascript sites just don&#x27;t care to make things work in firefox now.I keep chrome&#x2F;chromium around for \"broken\" sites and to chromecast even. It is what it is. reply octacat 13 hours agoparentweb experience is soo bad that there is not much difference between ff and chrome actually. Like clicking \"Let me choose which info to share\" on a cookie banner and it takes 5 seconds to load the next \"config\" window.ff with adblocker and cookie window blocker kinda helps, but now reddit, twitter and medium, and quora all want you to login. reply etimberg 17 hours agoprevI dunno, I use Firefox on my laptop and it just feels so slow and clunky compared to Chromium based browsers. It&#x27;s been like that for years and doesn&#x27;t seem to get better reply zqfm 17 hours agoparentThis is anecdotal, but my experience has been the opposite. I briefly switched to Chrome some years ago because everyone else was and the dev tools were genuinely better, but as a user it felt clunky and slow, so I switched back to Firefox. They pretty quickly got their act together wrt to the debugger and such and so I only ever dropped into Chrome for work and to this day it&#x27;s still clunky and slow. I never understood why anyone would want to stay with Chrome especially with Google ramping up their shenanigans. reply inferiorhuman 11 hours agorootparentFirefox has been fairly meh for me performance-wise, and tends to absorb memory over time. I kinda expected that with a few hundred tabs open.What I didn&#x27;t expect was how sluggish Firefox (119.0.1) would become on a brand new machine with around 20 tabs open. By the time I restarted it today, switching to Firefox and acquiring focus took about 2 seconds. I&#x27;ve a grand total of 3 plugins (FB Container, Multi-Account Container, uBlock Origin) installed. reply glenstein 11 hours agoparentprevAs many others have stated, I don&#x27;t have this experience at all, plus it&#x27;s vague, not a comment on any technology, use case, or trend that could be the foundation for a meaningful conversation. By contrast the article cites specific instances of slowdowns purposely inserted based on which browser agent is active.The problem is people can and will endlessly go in circles with their anecdata, to no conclusion. And that&#x27;s if you&#x27;re lucky. If you aren&#x27;t, some optimized statistical average of understandings, misunderstandings, emotionally satisfying interpretations shared by people at the same time can cause a narrative to be ouji-boarded into existence that feels authentic to the participants.So, yeah. My experience is the opposite, but you should only take that for what it&#x27;s worth. reply acdha 17 hours agoparentprevUninstall your extensions. If you do a side by side comparison of clean installs, they’ll feel similarly responsive - Firefox uses less memory but the Chrome team closed the gap somewhat over the last year. Safari is still noticeably faster and lighter than both but that’s only to be expected since they don’t have cross-platform complications. reply linza 17 hours agoparentprevI feel the same. However, how much of this is actually one being faster&#x2F;slower than the other, and how much is really just subjectiveness one could train away. And now: how much of this is due to deliberate sabotage. reply deepsun 13 hours agoparentprevI dunno, it&#x27;s always been the other way around for me. Firefox is fast and light, while Chrome hogs RAM and CPU like a beast.Both on laptop and desktop (although my desktop is way beefier and doesn&#x27;t mind). reply rchaud 16 hours agoparentprevOpposite for me, I&#x27;m on a 10 yr old Mac and FF runs just as well as it always did while Chrome is more sluggish. On Android, FF feels a bit slow to render while Chromium browsers do fine. reply dmbche 18 hours agoprevIsn&#x27;t google the main source of funds for Mozilla? reply brenns10 18 hours agoparentYeah. The money is there to ensure that there&#x27;s an independent browser option to point at, if there&#x27;s ever any question about lack of competition. But the products are all designed to behave worse on Firefox, to help keep usage in the single digit %s.Reminds me of Microsoft saving Apple back in the day. It&#x27;s cheaper to prop up your competitors to avoid becoming a monopoly, than it is to become a monopoly and get broken up. Of course ideally, you don&#x27;t want to support your competitor to the point of them actually becoming competitive, just enough to have deniability. reply scarface_74 16 hours agorootparentMicrosoft never “saved” Apple and this myth needs to die.Microsoft invested $250 Million in Apple after it already had a multi billion line of credit.On top of that, Apple turned around and the same quarter spent $100 million to buy out PowerComputings Mac assets. It was three years and much more than $150 million in losses later that Apple became profitable.And that $250 million was also partially to settle a lawsuit over Microsoft stealing QuickTime source code for its own media player. This is separate from the look and feel lawsuit. reply brenns10 15 hours agorootparentInteresting, I admit to never studying that history and only hearing the story as told by others after the fact! reply seec 13 hours agorootparentThere is a lot of narrative being built around Apple = good, Microsoft = bad. I, as an Apple aficionado, had to learn the truth piecemeal and understand that there really is a reality distortion field around Apple. You can&#x27;t really trust much of what the fanboys will say. They say anything to make Apple look good and save face. I believe it comes from the cognitive dissonance of buying hardware that is so much above competitive market price, there is a need to build a lot of stories about moral superiority and things like that. reply scarface_74 13 hours agorootparentYou said a lot without showing one citation where I said something that was factually incorrect… reply alasarmas 10 hours agorootparentprevI call this Mozilla being Google’s antitrust beard. However, just like Apple playing that role for Microsoft, and AMD playing that role for Intel (if I remember correctly), it could be possible for Mozilla to transition back into being a true competitor to Google. reply ravenstine 18 hours agoprevLet&#x27;s pretend for a moment that it&#x27;s a certainty that The Google sabotaged Firefox.Practically speaking, would things have turned out appreciably different from the way things are now?People today but especially back during the time that Chrome was released had an disproportionately positive view of The Google in terms of trust and delight from \"innovation.\" If you asked any of them what they think of Mozilla, chances are they&#x27;d reply asking \"Is that like Godzilla?\" reply Zak 18 hours agoparentFrom Chrome&#x27;s launch in 2008-2009 (depending on your OS) until Firefox&#x27;s multi-process release in 2016, Chrome had a huge advantage: a bad page didn&#x27;t crash or slow down your whole browser.I switched during that time period and took my time switching back. Someone less interested in tech or less concerned with privacy issues probably wouldn&#x27;t have been motivated to switch back at all. I can&#x27;t comment on whether Google did use sabotage to win, but they didn&#x27;t need to. reply 2OEH8eoCRo0 17 hours agoprev> [They accuse] Google of carrying out a coordinated plan that involved introducing small bugs on its sites that would only manifest for Firefox users. reply r0ckarong 11 hours agoprevSo Google is employing the same tactics that Microsoft has used for the last 40 years. I&#x27;m shocked ... SHOCKED. reply FooBarBizBazz 13 hours agoprevI&#x27;ve noticed serious performance issues with Firefox Android on certain websites, and this has always crossed my mind, but I&#x27;ve thought -- \"nah, it&#x27;s probably an innocent issue\". Maybe not.Generally don&#x27;t unnecessarily ascribe things to malice ---- unless we&#x27;re talking about a tightly-managed megacorp. Then the probability that one of their managers has engaged in whatever fuckery approaches one. reply pipeline_peak 17 hours agoprevEven if these conspiracy theories proved true, we all know Firefox didn&#x27;t stand a chance lol reply bsimpson 18 hours agoprevAs a Googler, I find this hard to believe.A more plausible explanation is that there&#x27;s a very strong culture of using Chrome for work stuff at Google, and a general belief that automated tests can replace manual tests. These \"oops\"es are more likely the result of engineers doing most of their work in Chrome, and not noticing subtle changes in browsers they don&#x27;t often use. reply brenns10 17 hours agoparentI think the very defense you&#x27;re using is the problem though. It&#x27;s fine if nobody uses the competing browser for work at Google. It is, however, pretty standard to have automatic tests for performance and functionality, and these need to be cross-platform. Having insufficient automated testing for Firefox to catch these sorts of issues is a structural, anti-competitive bias. Especially when these things clearly don&#x27;t happen with Chrome.Couple that with the article&#x27;s documented case of using a deprecated API from Chrome that&#x27;s unsupported in FF. That&#x27;s bias in the design, and that&#x27;s something that leadership is either not catching, or making a conscious decision on. I&#x27;m sure it&#x27;s couched in some statstic about which monetizable users are impacted or something. But at the end of the day it&#x27;s an organizational, structural bias.And that&#x27;s not to say this is necessarily illegal. I honestly wouldn&#x27;t know. But I think you made a straw man to attack. The allegation isn&#x27;t necessarily that there&#x27;s an organization wide conspiracy of evil Googlers. Just that the organization and culture is designed to benefit Chrome and disadvantage Firefox, and that&#x27;s happening regularly with user-harming effects. reply acdha 16 hours agorootparentI think this is correct and would add that the YouTube example highlights that it’s a management decision, not just an inexcusable lack of testing. I’d definitely believe that developers tune what they use first, but once a known problem is identified someone had to decide how to prioritize it.In many ways, I’d treat this like mandatory banking & investment separations where a cost of being a browser developer should be that you can’t ignore things other shops can. Vimeo could decide not to fix a performance regression affecting Firefox but YouTube should be required to fix it within 60 days, and if they don’t like that they can split it into an independent company which wouldn’t have that constant conflict of interest concern. reply bsimpson 9 hours agorootparentprevI&#x27;m not defending anything - I definitely have my own thoughts on the matter, I&#x27;m just trying to be conscientious about what I publicly say about my employer.However, I don&#x27;t believe that engineers are intentionally disfavoring Firefox, trying to drive market share down to \"run out the clock\" or \"sabotage\" competitors.For all its dysfunction, Google does tend to hire well-intentioned people - the person being quoted even said as much. There&#x27;s also a long list of annual trainings that coach people to tread lightly regarding anything that might be perceived as anticompetitive.It&#x27;s fair to talk about the craft of engineering and how different processes have different effects. Like I said, I have to be conscientious about what I say, so I&#x27;m not going to engage that point. But loaded language like \"sabotage\" and \"run out the clock\" suggests a malicious intent that I don&#x27;t believe exists. reply r3trohack3r 17 hours agoparentprevA sweeping majority of web-native teams I&#x27;ve met do cross-browser cross-device testing and intentionally make sure their team has multiple browsers&#x2F;devices represented by engineers during development.Serious shops have literal walls of devices for automated testing across different browsers and OS stacks, with real-time Quality of Experience metrics streaming back from customer devices - tagged with environment metadata - to detect regressions to the experience on every release.I find it hard to believe that one of the largest web-native giants in our industry didn&#x27;t follow those practices as an oversight. I hold engineers at Google in higher regard than that. reply throwaway2990 18 hours agoparentprevRubbish. Back when user agents were used you could change the agent and get access to Google things that were faster in Firefox.It’s silly to assume they didn’t do it on purpose. reply Zak 18 hours agorootparentUser agent strings are still used for this stuff. Today&#x27;s Youtube delay is an example which I&#x27;ve verified myself. reply throwawayxoog 14 hours agorootparentprevI&#x27;ve added several of those checks to Google products; it&#x27;s certainly never been for the reason you&#x27;re suggesting.You get a bug that a certain feature is crashing Firefox, or slowing it to a crawl. You can&#x27;t do feature detection, because Firefox reports the relevant features are supported. So you code up a less-efficient behavior that avoids the crash, and only use it for the Firefox user agent.Months or years later, Firefox improves the problematic behavior, and now performs much better when you switch the User Agent to Chrome and get the efficient path. Nobody at Google is paying active attention to that code anymore, so it remains in that state until someone notices.The idea of slowing down Firefox based on a User Agent check would be totally crazy to anyone I worked with at Google, and you&#x27;d be immediately reported to legal and HR if you tried to get such a thing through code review... reply seec 13 hours agoprevFirefox was never really good no matter what some tried to imply. It was always a bit crappy, slow, and sometimes ugly. I never understood the passion some people have for it. Sure, it had a lot of extensions but at the time where this was relevant actually using the extension would slow the browser so much it required an overkill computer to be worthwhile.I doubt Google had any need to pay any kind of attention for Firefox to be bad. They were doing that themselves very well already.Maybe the problem with Firefox has a lot more to do with their overpaid most likely hippie-feminist person they have as a CEO, no need to search for Google malfeasance when you have THAT type of CEO. Fairly sure she can create political bullshit out of nothing that would bring any org to failure.I hate the modern world. So hypocrite. We go look for answers on the other side of the planet when it is right there. But you can say it, because it is not politically correct. Seriously kill me already. reply glenstein 12 hours agoparentBefore Chrome, Firefox had a market share of something like 30%, because it was light years better than IE. And its ability to support extensions was mind blowing. It didn&#x27;t crash, which was important, it was fast, also important at the time, and was innovative and customizable in ways we take for granted now.Firefox was dominant and Chrome was the little brother, but then the turns tabled. reply Seb-C 18 hours agoprev [–] Funny, I was under the impression that Mozilla didn&#x27;t need any help sabotaging Firefox by themselves.Or maybe it&#x27;s also the fault of Google if they suddenly broke all the old extensions and never honored their promise to bring their capabilities back. Or when they disabled the extensions on mobile and did not bring it back despite their promise. Or when they break the user&#x27;s habits by doing a useless UI revamp every 6 month and ignore the community&#x27;s feedback. reply nneonneo 18 hours agoparentIn regards to extensions: it is my understanding that WebExtensions were never sold as being capable of as much as XUL addons, because XUL addons could rewrite just about anything in the browser and cause just about unlimited breakage. The XUL API could not be flexibly improved, and critically held back some real security improvements like multi-process rendering. It was ultimately _necessary_ to redesign the API in order to make it feasible to evolve the browser without constantly breaking addons. Please read https:&#x2F;&#x2F;yoric.github.io&#x2F;post&#x2F;why-did-mozilla-remove-xul-addo... for a more in-depth explanation. reply Seb-C 7 hours agorootparentI remember reading some ticket pages at the release, where they actually made promises about bringing the capabilities back in the future. But TBH I could not retrieve any link.I know this story already, but as much as I can empathize with this since I am a developer myself, from a user point of view they destroyed the ecosystem that was their strength. When I said \"bring back\", I do not mean XUL as a technology, I mean the functionalities that the extensions could use.I was on Firefox because it brought me something more, and because I appreciated it as it was. But now that they dumbed it down and made it like Google Chrome rather than focusing on their strengths, I do not have any good reason to use it. Because the many Chromium-based alternatives are better, more innovative, more reliable, and their UIs are stable and does not change every 6 months. reply dralley 16 hours agoparentprev [–] >never honored their promise to bring their capabilities backThey did. https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;8&#x2F;14&#x2F;23831094&#x2F;firefox-android-... reply Seb-C 7 hours agorootparent [–] This specific sentence was about the extensions of Firefox Desktop actually.But still, it&#x27;s good to know that they finally brought back the extensions on Android. I gave up after waiting one year and a half, and TBH I don&#x27;t know if I should trust them again to go back to it. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Former Mozilla executive accuses Google of deliberately sabotaging Firefox to promote Chrome's adoption over the past ten years.",
      "Accusations include Google introducing bugs on their sites that only affect Firefox users and attributing them to accidents.",
      "Users are drawing parallels between Google's tactics and Microsoft's actions during the Internet Explorer era."
    ],
    "commentSummary": [
      "Allegations have arisen that Google may be intentionally sabotaging the Firefox browser and engaging in anti-competitive practices in web browsing.",
      "Users have reported experiencing glitches and compatibility issues with non-Chrome browsers, sparking concerns about the dominance of certain browser engines and Google's practices.",
      "The conversation also includes criticism of Mozilla's financial decisions and discussions comparing Firefox's performance and memory issues to Chrome, as well as debates about the decline of Firefox as a dominant browser and user trust in the browser."
    ],
    "points": 286,
    "commentCount": 115,
    "retryCount": 0,
    "time": 1700493339
  },
  {
    "id": 38346862,
    "title": "Roc: A Versatile Programming Language for Efficient Code Building and Execution",
    "originLink": "https://www.roc-lang.org/",
    "originBody": "Roc A fast, friendly, functional language. list = List.map songs \\song -> \"Artist: \\(song.artist)\" Fast Roc code is designed to build fast and run fast. It compiles to machine code or WebAssembly. What does fast mean here? Friendly Roc's syntax, semantics, and included toolset all prioritize user-friendliness. What does friendly mean here? Functional Roc has a small number of simple language primitives. It's a single-paradigm functional language. What does functional mean here? Try Roc You can try Roc using this read-eval-print loop (REPL), which is running in your browser in WebAssembly. Shift-Enter adds a newline. Try entering 0.1 + 0.2 Enter an expression to evaluate, or a definition (like x = 1) to use later. » Examples Roc is a young language. It doesn't even have a numbered release yet, just nightly builds! However, it can already be used for several things if you're up for being an early adopter— with all the bugs and missing features which come with that territory. Here are some examples of how it can be used today. Command-Line Interfaces main = Stdout.line \"Hello!\" You can use Roc to create scripts and command-line interfaces (CLIs). The compiler produces binary executables, so Roc programs can run on devices that don't have Roc itself installed. As an example, the HTML for this website is generated using a simple Roc script. You can see the code for it in the main Roc code repository. If you’re looking for a starting point for building a command-line program in Roc, basic-cli is a popular platform to check out. Web Servers handleReq = \\request -> Task.ok { body: … } You can also build web servers in Roc. basic-webserver is a platform with a simple interface: you write a function which takes a Request, does some I/O, and returns a Response. Behind the scenes, it uses Rust's high-performance hyper and tokio libraries to execute your Roc function on incoming requests. For database access, roc-pg lets you access a PostgreSQL database—with your Roc types checked against the types in your database's schema. Embedding fn = require(\"foo.roc\"); log(`Roc says ${fn()}`); You can call Roc functions from other languages. There are several basic examples of how to call Roc functions from Python, Node.js, Swift, WebAssembly, and JVM languages. Any language that supports C interop can call Roc functions, using similar techniques to the ones found in these examples. Most of those are minimal proofs of concept, but roc-esbuild is a work in progress that's used at Vendr to call Roc functions from Node.js. Other Examples You can find more use cases and examples on the examples page! Code Sample with Explanations Here's a code sample that shows a few different aspects of Roc: File I/O and HTTP requests Pattern matching for error handling JSON deserialization via type inference Common syntax sugar: string interpolation, pipelines, and backpassing The tutorial introduces these gradually and in more depth, but this gives a brief overview. # Click anything here to see an explanation.Tap anything here to # see an explanation.X Comments in Roc begin with a # and go to the end of the line. main =X This defines main, which is where our program will begin. In Roc, all definitions are constant, so writing main = again in the same scope would give an error. Path.fromStr \"url.txt\"X This converts the string \"url.txt\" into a Path by passing it to Path.fromStr. Function arguments are separated with whitespace. Parentheses are only needed in nested function calls. |> storeEmailX The pipe operator (|>) is syntax sugar for passing the previous value to the next function in the \"pipeline.\" This line takes the value that Path.fromStr \"url.txt\" returns and passes it to storeEmail. The next |> continues the pipeline. |> Task.onErr handleErrX If the task returned by the previous step in the pipeline fails, pass its error to handleErr. The pipeline essentially does this: a = Path.fromStr \"url.txt\" b = storeEmail a Task.onErr b handleErr It creates a Path from a string, stores an email based on that path, and then does error handling. storeEmail = \\path ->X This defines a function named storeEmail. It takes one argument, named path. In Roc, functions are ordinary values, so we assign names to them using = like with any other value. The \\arg1, arg2 -> syntax begins a function, and the part after -> is the function's body. urlTask.awaitX This reads the contents of the file (as a UTF-8 string) into url. TheThe lines after this one form the body of the \\url -> callback, which runs if the file read succeeds. userTask.awaitX This fetches the contents of the URL and decodes them as JSON. If the shape of the JSON isn't compatible with the type of user (based on type inference), this will give a decoding error immediately. As with all the other lines ending in |> Task.await, if there's an error, nothing else in storeEmail will be run, and handleErr will end up handling the error. dest = Path.fromStr \"\\(user.name).txt\"X The \\(user.name) in this string literal will be replaced with the value in name. This is string interpolation. Note that this line doesn't end with |> Task.await. Earlier lines needed that because they were I/O tasks, but this is a plain old definition, so there's no task to await. _Task.awaitX This writes user.email to the file, encoded as UTF-8. We won't be using the output of writeUtf8, so we name it _. The special name _ is for when you don't want to use something. You can name as many things as you like _, but you can never reference anything named _. So it's only useful for when you don't want to choose a name. Stdout.line \"Wrote email to \\(Path.display dest)\"X This prints what we did to stdout. Note that this line doesn't end with |> Task.await. That's because, although Stdout.line returns a task, we don't need to await it because nothing happens after it. handleErr = \\err ->X Like storeEmail, handleErr is also a function. Although type annotations are optional everywhere in Roc—because the language has 100% type inference—you could add type annotations to main, storeEmail, and handleErr if you wanted to. when err isX This will run one of the following lines depending on what value the err argument has. Each line does a pattern match on the shape of the error to decide whether to run, or to move on and try the next line's pattern. Roc will do compile-time exhaustiveness checking and tell you if you forgot to handle any error cases here that could have occurred, based on the tasks that were run in storeEmail. HttpErr url _ -> Stderr.line \"Error fetching URL \\(url)\"X This line will run if the Http.get request from earlier encountered an HTTP error. It handles the error by printing an error message to stderr. The _ is where more information about the error is stored in the HttpErr. If we wanted to print more detail about what the error was, we'd name that something other than _ and actually use it. FileReadErr path _ -> Stderr.line \"Error reading from \\(Path.display path)\"X This line will run if the File.readUtf8 from earlier encountered a file I/O error. It handles the error by printing an error message to stderr. The _ is where more information about the error is stored in the FileReadErr. If we wanted to print more detail about what the error was, we'd name that something other than _ and actually use it. FileWriteErr path _ -> Stderr.line \"Error writing to \\(Path.display path)\"X This line will run if the File.writeUtf8 from earlier encountered a file I/O error. It handles the error by printing an error message to stderr. The _ is where more information about the error is stored in the FileWriteErr. If we wanted to print more detail about what the error was, we'd name that something other than _ and actually use it. To get started with the language, try the tutorial! Start Tutorial Sponsors We are very grateful for our corporate sponsors Vendr, RWX, and Tweede golf: If you would like your organization to become an official sponsor of Roc's development, please DM Richard Feldman on Zulip! We'd also like to express our gratitude to our generous individual sponsors! A special thanks to those sponsoring $25/month or more: Aaron White Ayaz Hafiz Christopher Dolan Ivo Balbaert James Birtles Jonas Schell Lucas Rosa Nick Gravgaard Richard Feldman Shritesh Bhattarai Zeljko Nesic Thank you all for your contributions! Roc would not be what it is without your generosity. 💜 We are currently trying to raise $4,000 USD/month in donations to fund one longtime Roc contributor to continue his work on Roc full-time. We are a small group trying to do big things, and every donation helps! You can donate using: GitHub Sponsors Liberapay All donations go through the Roc Programming Language Foundation, a registered US 501(c)(3) nonprofit organization, which means these donations are tax-exempt in the US.",
    "commentLink": "https://news.ycombinator.com/item?id=38346862",
    "commentBody": "Roc – A fast, friendly, functional languageHacker NewspastloginRoc – A fast, friendly, functional language (roc-lang.org) 286 points by dlib 21 hours ago| hidepastfavorite146 comments davidatbu 14 hours agoI&#x27;m super keen to see how Roc pans out, because it sits at an (IMO) riveting spot in the space of PL design tradeoffs:1. The typesystem will be sound, ML-like, and so simple that any code that doesn&#x27;t interact with external data will not need _any_ type annotations.2. An aim to make it the fastest managed compiled lang around (faster than golang).3. Functional.4. A focus on fast compile times from the beginning (like golang).5. Serde from rust is essentially a language builtin.6. Zero side effects, only managed effects (which I think will do wonders for testability and mocking in a compiled language).What I&#x27;m unclear about is:1. Whether they&#x27;ll support macros,2. Whether their decision to build a whole new IDE will take away from the work that will go into an LSP (it will take a lot to pry away neovim from my hands).It&#x27;d be dope if anyone more familiar can comment on the above!Also, as feedback to Richard Feldman, your podcast is (imo) great marketing for your lang! It&#x27;s what&#x27;s made me excited about your PL.EDIT: Forgot another feature I&#x27;m allured by: ability to run programs with type errors (as best as one can). reply rtfeldman 14 hours agoparentGlad you&#x27;ve been enjoying Software Unscripted, thank you for the kind words!> 1. Whether they&#x27;ll support macros,The plan is not to support macros. A major reason is that macros tend to conflict with editor tooling, and I definitely have big plans for Roc&#x27;s editor tooling!> 2. Whether their decision to build a whole new IDE will take away from the work that will go into an LSP (it will take a lot to pry away neovim from my hands).The IDE project has been deprioritized a lot (e.g. I don&#x27;t expect any work to be done on it in 2024) because we realized there&#x27;s a way to build the editor plugin ecosystem we want to build in a way that works across multiple editors.There already is a preliminary language server, and there are instructions in the VS Code extension for how to get it set up [0]. I assume something similar should work for neovim!EDIT: I just noticed that while I was typing this, the author of the Roc language server responded too...hi, Ayaz! Thanks for all your excellent contributions to Roc!https:&#x2F;&#x2F;github.com&#x2F;ivan-demchenko&#x2F;roc-vscode-unofficial#conf... reply packetlost 13 hours agorootparent> The plan is not to support macros. A major reason is that macros tend to conflict with editor tooling, and I definitely have big plans for Roc&#x27;s editor tooling!I disagree! I&#x27;ve been working on a macro-heavy Rust project with both proc and declarative macros and the tooling makes them better. I&#x27;ll add that there is immense value in turning repetitive code into \"spreadsheet\" style tables of data as well as being able to combine const expressions to get user controllable compile-time errors. reply rtfeldman 13 hours agorootparentA common example of a tooling problem I&#x27;ve run into with Rust macros is that if I use a string interpolation macro (e.g. in an argument to println!, format!, or dbg!) a lot of VS Code tooling that works outside of macros stops working.For example, I can&#x27;t use normal context menu things on an interpolated variable name, like Go To Definition or Refactor. Similarly, if I do a semantic rename of a variable used in interpolation, it doesn&#x27;t get renamed. Things like this.Maybe these are solvable problems, but we&#x27;re talking about widely used macros that have been in the standard library for many years, and even those don&#x27;t have basic support for normal operations that Just Work in a non-macro context, in one of the most popular Rust editors! reply packetlost 12 hours agorootparent> if I use a string interpolation macro (e.g. in an argument to println!, format!, or dbg!) a lot of VS Code tooling that works outside of macros stops workingI imagine this isn&#x27;t that hard of a problem to solve (though maybe relying on VSCode to handle renames is part of the issue), but low-enough on the annoyance scale that nobody cares enough to implement it. I&#x27;m not going to argue there aren&#x27;t annoyances with macros and that they&#x27;re harder for tooling to deal with, but I don&#x27;t think that&#x27;s a sufficient justification to not have them at all IMO. reply davidatbu 3 hours agorootparentprev> The plan is not to support macros.Gotcha. In every lang I&#x27;ve used a lot, I&#x27;ve found meta-programming (compile-time or dynamic) to be valuable (and often indespensible). I can imagine that a lang like Elm that is domain-specific can do fine without the expressive power of macros, but I struggle to imagine that for a general-purpose lang like Roc.I&#x27;m sure you&#x27;ve ruminated on this, so I&#x27;m excited to see how it all pans out.Maybe a Software Unscripted episode with someone who&#x27;s written a lot of macros is in order? :) David Tolnay (serde maintainer) would be great! reply jcuenod 6 hours agorootparentprev+1 for Software Unscripted! I know barely anything about compilers, but I really enjoy being a fly on the wall of these conversations :) reply johnfn 14 hours agoparentprev> 1. The typesystem will be sound, ML-like, and so simple that any code that doesn&#x27;t interact with external data will not need _any_ type annotations.I&#x27;ve tried using languages with this promise, such as Haskell, and also spent a lot of time with TypeScript, which makes a different set of tradeoffs, and I feel like I&#x27;ve spent enough time on both to know this is the wrong tradeoff to make. It sounds flashy to be able to say that no type annotations are necessary, but in practice what it ends up meaning is that you end up tracking down errors in the wrong parts of your code because the compiler can&#x27;t figure out how to reconcile problems.e.g., you have function A incorrectly call function B. How does the compiler know if A has the wrong arguments, or B has the wrong signature? It can&#x27;t! I know that&#x27;s a toy example, but it really does lead to a lot of real-world frustration. Sometimes the type errors are very far away from where the actual issues are, and it can lead to a lot of frustration and wasted time.The TS approach of \"please at least annotate all your function signatures\" isn&#x27;t nearly as flashy, but it strikes a much better utilitarian balance. reply rtfeldman 13 hours agorootparentOh I totally agree that it&#x27;s a good idea to annotate top-level functions even if you don&#x27;t have to, and better compiler error messages is one of the benefits of doing that. Personally I basically always choose to annotate them except in the very specific situation of writing beginner introductory materials, when it&#x27;s not a given that the reader actually knows how to read the annotations yet.One of the practical benefits of having full inference is that these signatures can be inferred and then correctly generated by an editor. Like I can write the implementation of my function, and then tell my editor to generate a type annotation, and it can always generate a correct annotation.That saves me time whenever I&#x27;m writing the implementation first (I often write the annotation first, but not always), even if I end up wanting to massage the generated annotation stylistically. And unlike having Copilot generate an annotation, the type inference system knows the actual correct type and doesn&#x27;t hallucinate.To me, the main benefits of type inference at the top level are that they offer beginners a more gradual introduction to the type system, and that they offer experts a way to save time through tooling. reply MrJohz 11 hours agorootparent> Personally I basically always choose to annotate them except in the very specific situation of writing beginner introductory materials, when it&#x27;s not a given that the reader actually knows how to read the annotations yet.Having just gone through your tutorial (albeit not yet with a computer in hand, that&#x27;s the next step), might I suggest putting those annotations in anyway? I suspect most of the people reading the tutorial will already be programmers, and one of the most useful things I&#x27;ve found when reading tutorials and guides is when the code examples look as much like real code as possible. When I&#x27;m reading that initial documentation, I&#x27;m not just trying to figure out what&#x27;s different about this language from other languages, but I also want a sense of what it looks like to actually read and write idiomatic code in that language - what sort of formatting conventions are there, what do variable or type names typically look like, are there any common idioms, etc. Ultimately, my goal is to get up to speed and begin writing productive code as quickly as possible, so seeing type annotations everywhere is a sign to me that type annotations are good practice and something to get used to.In general, I found the tutorial a bit too aimed towards someone learning their first programming language, which is a demographic that I suspect are unlikely to be using Roc any time soon! Even if they are a demographic you&#x27;re targeting, I wonder if they&#x27;d be better served by a separate explicit \"Roc as a first programming language\" document that goes through the basics. Then in the main document, do some repl stuff at the beginning, but move quickly on to what regular development work might look like - starting a new project, writing functions with types, using tasks&#x2F;effects, adding tests, dependencies, etc.With all that criticism out of the way (sorry!) I do want to say that I love pretty much everything that I&#x27;ve seen so far, especially the focus on practical usage. It&#x27;s great to see an example CLI and an example web server right on the home page - I feel like these are often left as complete afterthoughts for these sorts of languages, but they&#x27;re the sort of real-world programs that dominate software in the industry.I&#x27;m also really excited to have a play around with the effects&#x2F;tasks system. It looks really powerful, but not too complicated to actually use as a base abstraction.And I agree that having powerful type interface can be a great tool, even if you supplement it with type annotations for the sake of explicitness. Is there an explicit type hole mechanism as well, for getting the compiler to spit out the types it expects? reply rtfeldman 10 hours agorootparentThanks for the kind words, and thanks for the feedback!> Is there an explicit type hole mechanism as well, for getting the compiler to spit out the types it expects?Not currently, although you can write `_` for any part of a type annotation that you don&#x27;t want to bother annotating (which means that part of the type will be inferred as if you hadn&#x27;t written any annotation for it), and we either have or want to have \"hover to see the type\" in editor extensions. reply gsuuon 11 hours agorootparentprevI think a general &#x27;explicit > implicit&#x27; priority is good enough to cover most cases - a written signature takes precedence over an inferred one. The compiler can also simply emit errors at both sites and let the writer figure it out.I usually think of writing explicit type annotations as &#x27;pinning&#x27; the type in situations where things are inferred&#x2F;generic by default. reply ReleaseCandidat 13 hours agorootparentprevThe Haskell approach is \"annotate all top level declarations\" (even if not exported) and OCaml has module signatures. But both (and Roc) don&#x27;t make up new \"types\" like Typescript does. reply Georgelemental 13 hours agorootparentprevRust takes the \"at least annotate all your function signatures\" approach as well. It&#x27;s essential for making borrow-checking tractable (for both the compiler and the programmer). reply ReleaseCandidat 13 hours agorootparentRust has the \"you must annotate your functions signatures, because there is no global type inference possible\" approach. reply azangru 13 hours agorootparentprev> The TS approach of \"please at least annotate all your function signatures\"The whole signature or just the parameters? I thought typescript is pretty chill about inferring the return type on its own. reply whizzter 13 hours agorootparentIt usually is as long as you don&#x27;t do anything recursive (and a few select polymorphic instances), I can see people getting bitten by it.Having written inferring compilers and used C++ extensively I appreciate the workings, but I can also see people getting stuck with it. reply fourteenminutes 14 hours agoparentprevIt&#x27;s unlikely that macros will be supported. Regarding editors, it&#x27;s unlikely that effort on the advertised Roc editor will start in earnest some time soon. I actually recently merged an LSP implementation into the mainline compiler ([details on how to integrate here](https:&#x2F;&#x2F;roc.zulipchat.com&#x2F;#narrow&#x2F;stream&#x2F;304902-show-and-tel...)), and that&#x27;s likely to develop more in the near future, before a standalone Roc editor is available. reply devit 11 hours agoparentprevSeems to be a language equivalent to a subset of strict Haskell.There doesn&#x27;t seem to be any particularly compelling reason to use it, and note that, unless they can use libraries from an existing language, there needs to be a really MAJOR reason to use a new language to compensate the lack of libraries. reply stcredzero 13 hours agoparentprevAn aim to make it the fastest managed compiled lang around (faster than golang).I find this an interesting perspective: That Golang is a compiled managed language. This is certainly correct. I don&#x27;t see this being expressed to often, however. reply surprisetalk 19 hours agoprevFor those out of the loop, Roc was spearheaded by Richard Feldman, who made major contributions to Elm.Feldman is such a charming guy! I highly recommend checking out his podcast Software Unscripted and watching his many talks on YouTube.The recent SU episode with Brian Carroll talking about WASM in Roc was a great listen.Roc also has an active community on zulip, so consider stopping by :)[1] https:&#x2F;&#x2F;twitter.com&#x2F;sw_unscripted[2] https:&#x2F;&#x2F;www.youtube.com&#x2F;results?search_query=richard+feldman[3] https:&#x2F;&#x2F;www.roc-lang.org&#x2F;community reply fouronnes3 13 hours agoparentWhat happened to Elm by the way? reply surprisetalk 13 hours agorootparentElm is still delightful to use![1] https:&#x2F;&#x2F;taylor.town&#x2F;elm-2023Evan also announced some stuff about Elm and Postgres at Strange Loop earlier this year, so I expect another wave of movement soon reply bbkane 11 hours agorootparentThe talk is at https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=XZ3w_jec1v8I also recommend watching it, though the conclusion I came away with is that Evan is kind of in a \"next steps\" crisis. reply zem 9 hours agorootparentprevif nothing else it popularised TEA (\"the elm architecture\"), which a lot of other frontend frameworks have picked up on. reply skitter 19 hours agoprevNeat, looks like the website got an overhaul.I like Roc&#x27;s approach of detecting errors statically but still trying to let you run the code. If a snippet is work in progress and has an unused variable, Go or Zig will refuse to compile it. Yes, an unused variable indicates a problem, which is why it&#x27;s not going to pass any sensible CI setup and make its way into production, but that doesn&#x27;t mean I should be disallowed from checking whether what I&#x27;ve got so far works. Roc allows¹ running a program with type errors as long as you don&#x27;t execute a code path affected by them, which I imagine is very useful for refactoring.The platform approach is also interesting, but I don&#x27;t know how it will play into code reuse. I guess the different io&#x2F;platform interfaces might not be quite as big of a problem in a pure functional language? I&#x27;m not experienced enough to tell.¹: I haven&#x27;t checked how successful it is, given it&#x27;s immaturity I expect there to be issues reply rzwitserloot 16 hours agoparentMany java editors (notably, eclipse) work the same way, _if_ you configure them to do so_: Just run it, don&#x27;t worry about the compilation errors. If the code never hits that segment (in java, if there&#x27;s a syntactical error in source code, that entire class cannot be used, but if it&#x27;s a semantic error (e.g. a reference to a function that doesn&#x27;t exist, which is syntactically perfectly valid, that&#x27;s a semantic error), only that method is &#x27;tainted&#x27;. If you hit a tainted area the debugger kicks in, freezes the process, and breakpoints on the spot. You can then fix it if you want and continue, or inspect the stack and state of e.g. local vars and learn something.What I find surprising is how few programmers I talk to are aware of this, let alone use it. I find it a significant productivity boost.Extrapolating away from debuggers: Everything should be warning, nothing should be an error. Then adopt a policy that you don&#x27;t check in warnings. I find it utterly insane that &#x27;unused variable&#x27; is treated as an _error_ (in the sense that it prevents compilation). It.. just isn&#x27;t.I hear _lots_ of noise in the line of &#x27;well but my dev team will just ignore that rule&#x27;, but that&#x27;s a \"doctor it hurts when I press here\" issue. You don&#x27;t solve that by just being more beliggerent, you fix that by having a chat with the team.I wonder what &#x27;friendly&#x27; means in the context of &#x27;a programming language&#x27;, but if its: \"Assuming you are not a complete idiot\", that&#x27;s a plus, I guess. reply fuzztester 12 hours agorootparent>If you hit a tainted area the debugger kicks in, freezes the process, and breakpoints on the spot. You can then fix it if you want and continue, or inspect the stack and state of e.g. local vars and learn something.>What I find surprising is how few programmers I talk to are aware of this, let alone use it. I find it a significant productivity boost.Forward to the past, as often is the case.See:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37841588and its parent and child comment. reply garethrowlands 15 hours agoparentprevHaskell reports compilation errors as warnings too. reply drannex 19 hours agoprevNo real thoughts on the language yet, other than looks interesting and modern.But, that website has one of the smoothest on boarding experience I&#x27;ve ever seen for a new language. From the inline REPL (with built in tutorial), to the code definition section, its insanely practical. Every new (& old) language should have a website and onboarding experience like this one. reply hombre_fatal 16 hours agoparentNo kidding. It went from the most barebones \"Under Construction, check back later\" website possible to one of the best proglang homepages I&#x27;ve ever seen. reply jetrink 18 hours agoparentprevI really like that &#x27;fast&#x27;, &#x27;friendly&#x27; and &#x27;functional&#x27; all link directly to long, substantive explanations of the goals and decisions related to those qualities. reply jampekka 13 hours agoparentprevOne thing I had to hunt for was what the backslash means in the first examples. Especially as it seems to be used for both string interpolation and function definition.But other than that great to have a quite good idea of the language in just a few seconds. reply itishappy 12 hours agorootparentIt&#x27;s both string interpolation and (anonymous) function definition. # Function Definition: addAndStringify = um1, num2 -> Num.toStr (num1 + num2) # String Interpolation: \"\\(greeting) there, \\(audience)!\" # desugars to Str.concat greeting (Str.concat \" there, \" (Str.concat audience \"!\"))https:&#x2F;&#x2F;www.roc-lang.org&#x2F;tutorial reply hardkorebob 15 hours agoparentprevYes indeed! I love this web page. Sleek and very upfront with everything. Great job team!! Would love to help in any way. reply otteromkram 17 hours agoparentprevFor in-browser tutorials, Haskell does it on the main page, too:https:&#x2F;&#x2F;www.haskell.org&#x2F;For web UI, I always thought QisKit set the bar pretty high. It&#x27;s intuitive and informative:https:&#x2F;&#x2F;qiskit.org&#x2F; reply jnrk 15 hours agorootparentSvelte does a pretty good job too.https:&#x2F;&#x2F;svelte.dev&#x2F; reply okkdev 18 hours agoprevBig fan of Richard Feldman&#x27;s talks and Roc is one of my most anticipated upcoming language besides Gleam. Great to see that there&#x27;s now a nice Roc website. Looking forward to how the language evolves! reply catgary 16 hours agoparentI know Koka is more of a research project than anything else, but I think it’s by far the most interesting. Moving to effect handlers, the Perseus ARC algorithm, and identifying “functional-but-in-place” algorithms all feel like game changers. reply ReleaseCandidat 16 hours agorootparentYes, Koka is evidently a inspiration for Roc, which uses Perceus, in-place mutation and their effect system is called \"abilities\". Roc aims to be something like the \"practical version\" of Koka(&#x27;s ideas). reply davidatbu 14 hours agoparentprevWe have a very similar taste in PLs :) reply Eji1700 16 hours agoprevLooks interesting. I&#x27;m a huge fan of F# and think anything working in that hybridish space is the way to go. I&#x27;ll have to dedicate some more time to this when I get a moment. reply whalesalad 16 hours agoparentI&#x27;ve been on the F# website for 5 minutes now looking through damn near every page and I cannot find a single page that shows me a simple example program or the syntax at all.Everything is hidden behind some kind of \"let&#x27;s get started!\" wizard. https:&#x2F;&#x2F;dotnet.microsoft.com&#x2F;en-us&#x2F;learn&#x2F;languages&#x2F;fsharp-he... reply mgomez 15 hours agorootparentHere&#x27;s a non-wizard tutorial that I bookmarked when I started with F# (I also had a hard time finding a simple example at first):https:&#x2F;&#x2F;learn.microsoft.com&#x2F;dotnet&#x2F;fsharp&#x2F;get-started&#x2F;get-st...What I like about this page is that it shows a basic project structure. reply evanwalsh 15 hours agorootparentprevHere&#x27;s a decent tour: https:&#x2F;&#x2F;learnxinyminutes.com&#x2F;docs&#x2F;fsharp&#x2F; reply whalesalad 15 hours agorootparentthis website is great - should truthfully be 50% of the index.html of every language project ever. reply Eji1700 14 hours agorootparentprevOh yeah. A key hindrance of F# is that MS treats it like a side project even though it&#x27;s probably their secret weapon, and a lot of the adopters are dotnet coders who already know the basics so the on-boarding is less than ideal.https:&#x2F;&#x2F;fsharp.org&#x2F; is the best place to actually start, although i&#x27;m guessing you did and went to the hello world which leads back to ms&#x27;s nightmares.https:&#x2F;&#x2F;fsharpforfunandprofit.com&#x2F; is the standard recommendation from there but there&#x27;s finally some good youtube and other content out there.They have a browser repl as well https:&#x2F;&#x2F;try.fsharp.org&#x2F; reply zem 13 hours agorootparentagreed, a \"learn dotnet via f#\" approach for people with experience in other ML languages would be excellent. reply whalesalad 13 hours agorootparentprevfsharp.org is actually the offender. lots of links to basically nothing and quite a few of them are a dead end 404. reply igouy 15 hours agorootparentprevhttps:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;dotnet&#x2F;fsharp&#x2F;what-is-fsha... reply ReleaseCandidat 16 hours agoparentprev> hybridish spaceI&#x27;m sorry, but what do you mean by that? Roc is \"as\" pure as Haskell (or Koka), if that&#x27;s your point. reply Eji1700 14 hours agorootparentI glanced at the example code and it looked like it allowed side effects, but maybe I was wrong. I haven&#x27;t had much time to mess with it and seemed to be able to hard crash the repl doing some testing so it&#x27;s something i&#x27;ll have to look at later. reply ReleaseCandidat 14 hours agorootparentWell, yes, if there are no type annotations because all types are inferred, you don&#x27;t see the effect \"types\".https:&#x2F;&#x2F;www.roc-lang.org&#x2F;tutorial#tasks reply Eji1700 13 hours agorootparentThen to my limited understanding that&#x27;s less \"pure\" than haskell isn&#x27;t it, which doesn&#x27;t allow side effects and thus forces monads? reply whizzter 12 hours agorootparentHonestly it looks like basically the same as getline&#x2F;putStrLen from the tutorial(1) in the link below, just not written in an intentionally obtuse language.Considering how much more approachable this Roc documentation&#x2F;naming is, I&#x27;m wondering if it isn&#x27;t so that the people writing Wikipedia&#x27;s math pages are probably the same people that are drawn to and writes Haskell&#x2F;monad \"tutorials\".1: http:&#x2F;&#x2F;learnyouahaskell.com&#x2F;input-and-output replyyashrk 18 hours agoprevIf you are interested, «why yet another programming language?».The unique selling point of Roc is clever optimization to convert purely functional source code to deep-imperative fast machine code, while keeping all the correctness of functional algorithms.See this video of Richard Feldman for details — «Outperforming Imperative with Pure Functional Languages»: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=vzfy4EKwG_YAmong those clever optimizations:- static reference counting (no GC, like in Rust, but with no borrowing and borrow problems);- stack allocation of the data with no external links;- hidden («opportunistic») mutability even in the cases, where Haskell or Lisp will copy the value.edit:markup reply teucris 16 hours agoparentI’d say that’s one of a few unique selling points. Some others I noticed:- side effects are strictly relegated to async effects, eg all I&#x2F;O calls return a future- declarative static loading as imports reply Yoric 11 hours agoparentprev> - static reference counting (no GC, like in Rust, but with no borrowing and borrow problems);Does this mean that it&#x27;s somewhat equivalent to Rust with everything behind a `Rc` or `Arc`? reply yashrk 10 hours agorootparentRc and Arc traits are implementations of the _runtime_ reference counters. Runtime reference counting is sometimes less efficient than tracing GC.But Roc counts references in _compile_ time. So it&#x27;s like _usual_ (not wrapped in Rc) values in Rust. But in Rust the value is deleted from the heap when the stack frame with the _only_ link to it («the owner») is deleted. And in Roc the value is deleted from the heap, when the _last_ link to it leaves the stack.So we have the machine code _almost_ as efficient as a Rust-produced machine code, but the source code with a much simpler semantics. reply Yoric 5 hours agorootparentDo you have a written source for this? What you&#x27;re describing is nice, but I can see so many basic cases in which it doesn&#x27;t work, at least not without a borrow analysis much more sophisticated than Rust&#x27;s, that I imagine I&#x27;m missing something.Example: A linked list.Nitpick: Rc and Arc are not traits. reply 1letterunixname 13 hours agoparentprev> convert purely functional source code to deep-imperative fast machine code, while keeping all the correctness of functional algorithms.All functional language compilers, interpreters, and&#x2F;or runtimes ultimately have to do this by definition. The efficiency of transpilation varies widely. reply yashrk 11 hours agorootparentDefinition of resulting code as _deeply_ imperative was crucial in my phrase.The only «sine qua non» optimization through opportunistic mutablity is AFAIK tail call optimization. But it is probably too well-known to call it «clever optimization» in 2023.But, for example, applying a function to a list will produce the code allocating new list in, say, OCaml and Haskell, at least by default. And Roc will produce the code for mutating the list in-place _from the source code with the same semantic_ (see example for the Quicksort algorithm in the video above).Compile-time lifetime analysis (that probably is not needed at all in functional languages with GC) and widely used unboxed values are way not common in functional language implementations. For example, in OCaml those features are still experimental (and probably never will be used by default, as in Roc). reply IshKebab 14 hours agoparentprevThat sounds a lot like Koka. Is there any relationship? reply yashrk 11 hours agorootparentSee https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38350940 reply asplake 15 hours agoprevHaving a play with Gleam right now. Roc&#x27;s managed effects sounds interesting, maybe Gleam could layer something similar atop Erlang&#x27;s OTP? Right now, outside a database, it&#x27;s not clear to this newbie how state is meant to be managed in Misty, the Gleam web framework I am kicking the tyres of. If I can be bothered, I was seeing myself having to delegate state management to a separate process (which Gleam seems to support well, but it&#x27;s work I didn&#x27;t anticipate and I am at this stage only playing).Edit: related to state management, the \"platform\" concept looks interesting too https:&#x2F;&#x2F;github.com&#x2F;roc-lang&#x2F;roc&#x2F;wiki&#x2F;Roc-concepts-explained#... reply quaunaut 14 hours agoparentI imagine state should be managed via GenServers[1][2], since that&#x27;s the general BEAM way of doing that.1. https:&#x2F;&#x2F;www.erlang.org&#x2F;doc&#x2F;man&#x2F;gen_server.html 2. https:&#x2F;&#x2F;hexdocs.pm&#x2F;elixir&#x2F;1.12&#x2F;GenServer.html reply satvikpendem 17 hours agoprevI don&#x27;t know, after having used Elm and seeing the community accused of \"hostile attacks\" by one of the main contributors (who is the creator of Roc now) [0], I don&#x27;t feel that it&#x27;s worth my time to put into learning it, even if it is objectively good; I simply cannot know what the creators will do (or refuse to do, in the case of Elm) in the future, especially in a BDFL governance paradigm. This was in fact why I stopped using Elm after a while, it didn&#x27;t seem like they wanted to ever address the issues they had, or even to acknowledge them as issues in the first place.I know in my linked [0] that Feldman has since apologized, if only because the comment was being linked to so often [1], but again, why not use any other language where the creators are not so hostile, some even going so far as to say that they \"wouldn&#x27;t trust anything that Richard Feldman was involved in. He was instrumental in making the Elm community a hostile and unwelcoming place.\"?[0] https:&#x2F;&#x2F;github.com&#x2F;gdotdesign&#x2F;elm-github-install&#x2F;issues&#x2F;62#i... (check the edit history)[1] https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que... reply rtfeldman 17 hours agoparentWow, this is depressing to read. :(5 years ago I was upset and posted a comment that was unfairly harsh to another commenter. I apologized at the time, and I meant it. I definitely should not have made the harsh comment that I did. It was wrong. There&#x27;s no excuse for my having written it.There are a lot of people working on Roc other than me. I&#x27;m not even the top committer anymore. [0] I hope you can find it in your heart to give their work some consideration, if not mine.[0] https:&#x2F;&#x2F;github.com&#x2F;roc-lang&#x2F;roc&#x2F;graphs&#x2F;contributors reply Capricorn2481 16 hours agorootparentThanks for this comment. Personally, I appreciate how human and humble your response is, and Roc looks great. reply wibblewobble125 13 hours agorootparentprevAs a small datapoint, I brought up Roc at work last year and a colleague said “it looked interesting but it’s the guy from Elm isn’t it?” and brought up this.As a manager, I empathize with the frustration you were feeling. Steering a team or a community towards a vision is very hard. Just when you think you’re getting somewhere, someone does the exact opposite and mixes people up. It’s easy to lose patience. I’ve made similar mistakes on popular projects and was fortunate enough that no one publicized them. I was allowed to learn from my mistakes without being punished for it.I don’t have any advice on this. It’ll probably turn out fine. reply darthrupert 5 hours agorootparentprevCome join the open source software community. Everything you say will be used against you in the public court, forever. reply cooperadymas 16 hours agoparentprevSeriously ppl, go use a language where the creator is a paradigm of humanity. Maybe Python is a good choice?Seriously, tho, that&#x27;s the comment that \"made the Elm community a hostile and unwelcoming place\" and is still being dredged up after 5 years? That comment can barely even be considered harsh, and is nowhere near hostile.Is it really worth tearing down someone&#x27;s life, monitoring the internet for any time their name appears, just so you can spread the continue to spread the hate toward him after so long? This is where you make your stand? reply petepete 14 hours agorootparentA paragon of humanity? reply lambda_garden 16 hours agoparentprevI believe in second chances. From the GitHub link:> EDIT 5 years later: You can see in the edit history of this comment what I originally wrote here; I was upset and said unkind things that I regret, and which nobody deserved to hear. I apologized at the time and I still feel I should apologize again, unequivocally. I was in the wrong here. reply replwoacause 14 hours agorootparentYep, this is good enough for me, and I suspect for anyone who is not hellbent on holding a grudge. reply catlover76 16 hours agoparentprevI don&#x27;t see what was so harsh? I checked the edit history, I saw the original comments and subsequent minor tweaks. His response was rather testy and stubborn (as is the case with the Elm team generally, it seems), but not as much of a dick comment as I have seen elsewhere in GitHub issues. reply satvikpendem 16 hours agorootparentThere is some more context here: https:&#x2F;&#x2F;lukeplant.me.uk&#x2F;blog&#x2F;posts&#x2F;why-im-leaving-elm&#x2F;#forka...> Threatening a person with exclusion from a community for attempting to patch the source code is quite antithetical to the spirit of Open Source, as far as I can see. reply ricardobeat 16 hours agorootparentFrom this post it feels like they never even understood the original comment about going against the project’s goals. The drama created around this is much, much larger than the issue warranted. If Roc keeps this audience away, maybe that is good thing.Note that they were never prevented from forking the project (how would you even do that), instead they chose to try and stronghand the project into accepting their view, which is also not healthy for OSS. Maybe their Elm fork would be mainstream by now if it really catered to developers’ needs. reply hombre_fatal 16 hours agorootparentThere&#x27;s a certain infini-grudge-holding, emotional, drama-stirring archetype of software developer that&#x27;s best left out of the community, especially that of a new, fledgling one.It&#x27;s always the same story, too. Someone felt personally wronged by something actually quite minor like their their PR getting ignored&#x2F;rejected with perhaps a tone too snappy for them, and now they have a personal vendetta until the end of time with no rock nor HN comment section left unturned from them lingering in the past.Sometimes you need to leave the theater and let the rest of us enjoy the show.Hopefully a mod sinks this entire thread so we can read interesting thoughts about Roc. reply weatherlight 16 hours agorootparentprevThere&#x27;s no evidence thus far in the Roc community thats it&#x27;s anything like ELM&#x27;s community.Seems like the Author of Roc is cool now, that was 5 years ago and hasn&#x27;t done the thing you fear he might do? people get testy, say things they regret.I understand trust is earned, but it&#x27;s been 5 years. and the Roc community thus far have been really nice, welcoming and collaborative. I get Elixir and Ruby community vibes from these contributors.Pick your battles I guess? reply satvikpendem 16 hours agorootparentSure, but there are also a lot of languages to learn, in a vacuum I might learn Roc but now there are other options that don&#x27;t have such history, it is not near the top of the list. reply weatherlight 15 hours agorootparent> other options that don&#x27;t have such historyRoc isn&#x27;t Elm. RF is one person in that community, and he said something he regretted 5 years ago and has since not repeated that mistake.Do you know the moral dealings of every developer of every piece of technology you use?When it comes to Roc and It&#x27;s community..ask yourself. “Am I sure that what I am going to say is true?” “Is what I&#x27;m going to say a good thing?”, and “Do I really need to say it and is it useful?”Is that comment from 5 years ago really the most important thing about the Roc Programming language, that anyone reading the comments need to know? Is RF the reason you walked away from Elm? reply satvikpendem 14 hours agorootparentIt&#x27;s not about moral dealings, it&#x27;s about whether I can trust the creators to not mess up a second time if they had already messed up once. We were shipping Elm in production and we moved away because any issues that were brought up that we wanted to see solved were swept away. Eventually it wasn&#x27;t worth keeping the Elm codebase around. So, why should I trust one of the same people again? We already learned an expensive lesson one time around.> When it comes to Roc and It&#x27;s community..ask yourself.Sorry, but this kind of faux niceness is precisely what stopped people from asking about issues, as it was always argued that asking about such issues was not \"useful,\" after some time. So yes, I do feel the need to bring up this topic if only for others to evaluate the creators themselves rather than only have \"good\" things to say that \"really need\" to be said. reply weatherlight 13 hours agorootparentSo RF being questionably rude in a PR comment caused you company to drop apiece of technology? reply satvikpendem 13 hours agorootparentOne cut among many. Another was the insistence of Evan to cut out escape hatches and insist that everything be done solely through Elm. It is not just one person, the entire community was part of the problem, in one way or another. I don&#x27;t think about Elm much anymore but what I do think of it does not inspire confidence at its creators&#x27; future endeavors. Of course, if people want to use it, by all means, but being burned once, not just technologically but also financially, I would not want to be burned once more. replycatlover76 16 hours agorootparentprevI appreciate the context because it sheds further light on a big problem with Elm the project, but that context doesn&#x27;t change what he said, which simply wasn&#x27;t that harsh or mean. Like, from your original comment, I expected some kind of personal attack on the other person lol reply jgilias 16 hours agoparentprevI believe people should be given second chances. There’s a good chance that the Elm debacle has taught most people involved a thing or two. reply jchw 16 hours agorootparentNo doubt everything could&#x27;ve been learned and heeded by now, I think it&#x27;s really, really, really hard to say \"OK, so then everyone should go and try to raise $4000&#x2F;mo for the new project they have.\" Even just using a programming language is an investment of time and trust, too, lest you want to wind up stranded on some-old-version-of-Elm island with tens of thousands of lines of code.Elm also seemed very promising in the beginning, and honestly I don&#x27;t even think that comment is so abhorrent on its own. I think Elm died the death of a thousand cuts. If it had only been one errant comment somewhere, it would&#x27;ve been mostly forgotten about by now. Instead, it&#x27;s Elm that&#x27;s mostly forgotten about.So I say best of luck, but also... No thanks for now.edit: Just so it&#x27;s completely clear, I am actually implying that \"maintainers being dicks\" was actually not the problem with Elm. I think people just got especially infuriated by it because they were sick of trying to deal with Elm&#x27;s breaking changes, of which this represented one. I remember going through and learning Elm and like literally months later everything was completely different and I no longer knew how to make a basic hello world application (around 0.16 or 0.17 maybe? Can&#x27;t recall. I just remember that effects had changed a fair bit.) I know that to some degree this is the nature of a 0.x product, but at some point it&#x27;s like \"OK... then who is supposed to even use this?\" Among other issues of course. reply satvikpendem 16 hours agorootparentThis is how I feel too. Sure, it was 5 years ago and things might have changed, but there are a ton of other technologies and languages to learn, so why not learn something without all of that previous drama? These things indeed might take a significant time inventment so I&#x27;ll just focus on something I know might be more interesting or durable. reply johnisgood 16 hours agorootparentI would not even have known about this drama without the person who reminded us of it. That said, I still do not care about it at all.Imagine me not using Linux because of Linus being harsh (yet educative) to some people... or not using OpenBSD because of Theo... or not using Common Lisp because of #lisp... :P I have received some hostile feedback personally, but they were in the right. I did not take it to heart but I learned from it.That said, I have checked the edit history and I cannot see what the fuss is about. Welp. Moving on. reply jchw 15 hours agorootparentIt&#x27;s very easy to say this having not invested anything into Elm and not been there. I&#x27;m just thankful that most of what I invested in Elm was only time, and we never actually wound up deploying Elm to the frontend.Forget about all of the drama, imagine if you used Linux and it stopped updating at 2.6. Elm has been at 0.19 since 2018, and that&#x27;s not because there&#x27;s nothing left to improve on. reply johnisgood 15 hours agorootparent> imagine if you used Linux and it stopped updating at 2.6. Elm has been at 0.19 since 2018, and that&#x27;s not because there&#x27;s nothing left to improve on.Yup, that definitely would be an issue. reply Capricorn2481 15 hours agorootparentprevWait till you find out about Linux reply epgui 16 hours agoparentprevMaybe I&#x27;m not understanding something, but I would use a programming language I liked even if one of the main contributors was the worst human on earth.I don&#x27;t understand why people have to make technical stuff personal. reply ollysb 14 hours agoparentprevEveryone has their moments no? In person Richard seemed like a super nice guy and the many lectures he did for Elm really showed a passion for helping improve the day to day experience for developers. He was also super active on the forums and slack helping people out. reply ctenb 15 hours agoparentprevThere is an argument that people who made mistakes and genuinely learned from them and apologized could be more trustworthy than people who had not made that mistake to begin with. reply desireco42 16 hours agoparentprevI think we need to be able to accept apologies when someone makes them... otherwise we are all doomed. reply osener 1 hour agoprevRoc looks great, props to everyone involved in designing this language!Is there an (C) FFI planned? reply myaccountonhn 14 hours agoprevJust the other day I was looking at this website and it was the old one. Does this mean that Roc is out of alpha&#x2F;beta?As a big elm fan who does backend work, I’ve been looking Roc for a while with a lot of excitement. reply hardkorebob 16 hours agoprevLets make Tcl&#x2F;Tk GUI bindings for this! Please it would kick python butt! Roc on! reply jpease 19 hours agoprevJust don’t try to use it with Paper. reply tromp 18 hours agoprevDoes Roc have any features that a Haskell programmer could consider improvements? reply tkz1312 15 hours agoparentI think it boils down to: - simplicity - strict evaluation model - devx - faster runtime - built in effect systemI love haskell and write it every day, but I have the feeling that the language is probably too complex to really cross over to the mainstream. I remain convinced that the advantages of a pure functional approach are so compelling that we will one day see roc or something like it be the default choice for most programming tasks, and am really excited to see so much progress being made on the language. reply adjav 17 hours agoparentprevNot really, no. Like Elm, it strips away practically everything that wasn&#x27;t already in 1970s-era ML. It&#x27;s much closer to a trimmed-down Ocaml than it is to Haskell. reply lambda_garden 16 hours agorootparentSome in the ML community think a simpler language has advantages over a more expressive one, in some cases.For example: https:&#x2F;&#x2F;github.com&#x2F;fsharp&#x2F;fslang-suggestions&#x2F;issues&#x2F;243#issu... reply bbkane 11 hours agorootparentNot just the ML community. Go&#x27;s simplicity is often derided, but I think the best in class tooling (dev tooling like gopls, golangci-lint, deployment tooling like ServiceWeaver, Goreleasor, etc) and easy understandability more than make up for \"what yuu can&#x27;t do\" reply tkz1312 14 hours agorootparentprevGiven its strict purity and use of typeclasses over modules I would say roc is more like haskell than it is ocaml. reply wk_end 15 hours agoparentprevHaskell programmers tend to love their monads, but the treatment of effects here (\"Tasks\"), looks to be - and this is highly subjective - more intuitive and straightforward.ETA: Also if I&#x27;m reading this right Roc appears to natively support some kind of row polymorphism. That&#x27;s a nice-to-have. reply tkz1312 15 hours agorootparentI think algebraic effects usually just compile down to monads under the hood? As I understand it, it’s more like a cleaner interface to model side effects, than some new approach compared to the tools that haskell gives you out of the box? reply ReleaseCandidat 14 hours agorootparentNo, not necessarily (that&#x27;s just how some(?) of them are implemented in Haskell, and that&#x27;s slow too). Since 9.6.1 GHC has primitives for delimited continuations, with which effects should be implementable in a more straightforward and performant way.Alexis King, who added these primitives to GHC, on (delimited) continuations https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=TE48LsgVlIU reply tkz1312 14 hours agorootparentI had understood that the delimited continuations stuff was more like performance optimisation for the (slow) free monadic effect systems than a fundamentally different theoretical foundation for modelling effects in a pure language?fwiw we also have fast effect systems in Haskell these days that are more like fancy type sugar on top of the ReaderT over IO style of things (effectful seems to be the most popular). reply ReleaseCandidat 13 hours agorootparentI&#x27;ve thought that all \"native\" (in the compiler instead of a library) implementations use (more or less) delimited continuations (some kind of temporary stack moving&#x2F;copying). OCaml : https:&#x2F;&#x2F;github.com&#x2F;ocaml-multicore&#x2F;ocaml-effects-tutorial#3-... And Koka: I haven&#x27;t found the paper&#x2F;docs right now.I know about effectful, but that doesn&#x27;t use Reader (but provides one) but more or less directly IO (Ref) and \"evidence passing\", that&#x27;s why it is faster than the other ones, the drawback is not being able to use non-deterministic effects and noo such thing as coroutines. But I talked about eff (\"native\" delimited continuations) should be more or less the same, maybe a bit faster, than effectful, but enable non-determinism and coroutines. replyyashrk 17 hours agoparentprevFirst of all — way faster machine code.Many other things are features or bugs depending of your preferences. For me, for example, eager evaluation is a big improvement, but YMMV. reply tromp 17 hours agorootparent> eager evaluation is a big improvementDoes it have any support for laziness? E.g. could one define the list of all fibonacci numbers similarly to Haskell&#x27;s fib = let f a b = a : f b (a+b) in f 0 1 reply satvikpendem 16 hours agorootparentprevHow does it compare to HVM [0]? It is an alternative to GHC that in some cases is orders of magnitudes faster, at least from their benchmarks.[0] https:&#x2F;&#x2F;github.com&#x2F;HigherOrderCO&#x2F;hvm reply tkz1312 15 hours agorootparentRoc uses perceus, which is a reference counting model that allows for opportunistic in place mutation if it is safe to do so. HVM is more like a fundamentally new evaluation model that is parallel by default. They are both very exciting, but HVM is much more radical and probably needs at least a few more years until it starts to be seriously practical. reply weatherlight 16 hours agorootparentprevi thought the orders of magnitudes faster benchmarks were around lazy evaluation, and probably wouldn&#x27;t apply here. reply zem 13 hours agoparentprevstrictness! reply TwentyPosts 17 hours agoparentprevConvenience instead of historical baggage, maybe? reply epgui 16 hours agorootparentAll languages have some amount of historical baggage, but I&#x27;m not sure what you&#x27;re referring to here.If anything, Haskell gets a lot of eyerolls for its slow moving pace and for trying to build a language from mathematical first principles.It&#x27;s not perfect (eg.: Monad was not designed to be a special case of Applicative in the beginning, I believe) but it&#x27;s better at \"avoiding baggage\" than many other languages I know of. reply tkz1312 15 hours agorootparentHaskell is a wonderful language, but I don’t think you can claim it’s baggage free. It’s certainly accumulated it’s fair share of technical debt (more in the standard library than the core language to be fair). The endless proliferation of often complex and hard to understand extensions also certainly raises the bar for beginners. reply epgui 11 hours agorootparent> I don’t think you can claim it’s baggage free.Did I? replypoulpy123 19 hours agoprevThe webpage is very nice, with 3-4 steps tutorial to engage people and an example with interactive explanations reply shortrounddev2 16 hours agoprevHas anyone else noticed that functional languages go heavy on the special keywords and operators? It feels like theres a larger cognitive load (more specific keywords to memorize) when learning languages like F# or OCaml compared to C or Python or Java reply christophilus 13 hours agoparentClojure doesn&#x27;t. I&#x27;d really, really love to see a fast, statically-typed, functional lisp. reply ReleaseCandidat 16 hours agoparentprevActually they both (and OCaml has a whole lot of almost never used OOP - that&#x27;s where the O comes from) have _way_ less \"syntax\" than Python or Java. reply shortrounddev2 15 hours agorootparentI just did some quick math. If you count all the keywords and operators for F# in microsoft&#x27;s documentation, you come to 150 symbols. This doesn&#x27;t include the nullary operators (of which there are 14)Counting all the java operators and keywords, you get 84. This doesn&#x27;t include assignment operators like \"+=\" or \"-=\" (11 such operators).ChatGPT tells me that python has 36 keywords and 28 operators (not including the 13 assignment operators). This seems low and may be missing some syntactical sugar operators, but even then 64 is a far lower number than F#&#x27;s 150. Much debate could be had about which of these operators are fair to count or not, but it seems preliminarily that the data supports the position that functional programming languages (or at least F#) tend to go heavy on special keywords and operators reply ReleaseCandidat 15 hours agorootparentYou&#x27;re right, there actually are more. Interesting, I \"feel\" the opposite.Haskell (55 + some more, because of the grouping): https:&#x2F;&#x2F;wiki.haskell.org&#x2F;KeywordsF# https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;dotnet&#x2F;fsharp&#x2F;language-ref...OCaml: https:&#x2F;&#x2F;v2.ocaml.org&#x2F;manual&#x2F;lex.html#sss:keywordsPython: https:&#x2F;&#x2F;github.com&#x2F;python&#x2F;cpython&#x2F;blob&#x2F;3.12&#x2F;Lib&#x2F;keyword.pyJava (I think these are the current ones): https:&#x2F;&#x2F;docs.oracle.com&#x2F;javase&#x2F;tutorial&#x2F;java&#x2F;nutsandbolts&#x2F;_k... reply elbear 13 hours agorootparentA few of the Haskell ones are introduced by extensions, so they&#x27;re not part of the language proper. reply ReleaseCandidat 13 hours agorootparentYes, I know. Same for OCaml with PPXs. That was just to show that even Haskell has many, even though most operators aren&#x27;t keywords but \"normal\" infix functions (of type classes). replypjmlp 14 hours agoparentprevStill way better than doing C++, speaking as someone that likes C++ since the Turbo C++ for MS-DOS days, reply babarjaana 16 hours agoprevLooks interesting for sure and I like the syntax. Also, they seem to be using both Zig and Rust in their compiler from the looks of it? reply ReleaseCandidat 16 hours agoparentZig for the standard library, Rust for the compiler.A video about the design decisions of the (hash) map: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Z3UGuaJWbaA reply fuzztester 12 hours agoprevRefreshing to see a tech, and better yet, proglang post on the HN front page again, after the last few days.Need less Altman, and more altlang posts. reply adamgordonbell 11 hours agoprevI&#x27;m super excited to see Roc up on HN.I like the &#x27;be fast&#x27; and &#x27;be haskell like&#x27; approach.I see you have an Earthfile in the repo. Let me know if you have any Earthly feedback or if I can help with the build in any way, @rtfeldman.( We&#x27;ve been working on making Earthly faster for Rust builds by using cache mounts. ) reply 10000truths 16 hours agoprevInteresting divide-by-zero behavior when I use the interpreter in the webpage: » 1&#x2F;0 1000000000000000000 : Frac * reply rtfeldman 16 hours agoparentOops, that&#x27;s a bug - just opened an issue for it: https:&#x2F;&#x2F;github.com&#x2F;roc-lang&#x2F;roc&#x2F;issues&#x2F;6027Thanks for pointing it out! reply ReleaseCandidat 16 hours agorootparentYou won&#x27;t like the result of `0&#x2F;0` either ;) replygsuuon 11 hours agoprevI think Roc has a lot of good ideas, especially the backpassing syntax sugar and that there&#x27;s only one way to declare functions (anonymous or not). Excited to see where it goes! reply whalesalad 15 hours agoprevLooks cool but I am somewhat weary of languages that are so wholly dependent on whitespace for significance. I say this as a Python user... but my favorite part of Lisp is the homoiconicity. Things become very intuitive ... whereas the syntax of a language like this takes much longer to grok. reply desireco42 16 hours agoprevI was thinking of this the other day. I was trying to remember the name of the language and to look it up.Elm really broke my heart, I believed it will go places it never went. Roc honestly, I am OK to play around with it and build whatever makes me happy. reply sheepscreek 10 hours agoprevIs Roc inspired from Elm? Can’t help but to notice a very strong resemblance between the two. reply rtfeldman 10 hours agoparentAbsolutely! More details: https:&#x2F;&#x2F;github.com&#x2F;roc-lang&#x2F;roc&#x2F;blob&#x2F;ad5ed57c4202f847cf9e215... reply laerus 13 hours agoprevcamelCase instead of snake_case is such a turnoff :( reply 1letterunixname 13 hours agoprev0. I don&#x27;t see type annotations.1. Why another language and not a better runtime for an existing language with an install base that already exists? reply taraparo 14 hours agoprev [–] Not a fan of the usage of backslashes \\ replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Roc is a programming language designed for efficiency in building and running code, with support for command-line interfaces, web servers, and embedding in other languages.",
      "Despite being in early development stages, Roc has shown its usability for various tasks and prioritizes user-friendliness with features like pattern matching and string interpolation.",
      "Roc can generate machine code or WebAssembly and offers support for database access, and it is backed by corporate sponsors and individual contributors committed to its ongoing development and improvement."
    ],
    "commentSummary": [
      "The discussion provides insights into the features and optimizations of the Roc programming language, as well as its similarities to languages like Elm and Haskell.",
      "It also touches on the behavior of the Roc community and mentions other programming languages such as F#, Eff, and HVM.",
      "The importance of type annotations, the use of macros, and the role of debuggers in programming are also discussed."
    ],
    "points": 286,
    "commentCount": 146,
    "retryCount": 0,
    "time": 1700482170
  },
  {
    "id": 38349653,
    "title": "OpenAI's Coherence and Actions Under Scrutiny",
    "originLink": "https://builtnotfound.proseful.com/openais-chaos-does-not-add-up",
    "originBody": "November 20, 2023 OpenAI's chaos does not add up Update: this post has been instantly demoted from #1 to #26 on HN frontpage :) Hmm. A list of things that a coherent story does not make: Sam Altman crafts an elaborate non-profit structure but gets completely blindsided by the possibility of the board overthrowing them. Microsoft invests $10 billion but apparently has no checks in place to know what's happening with their investment. The board moves quickly to sack the CEO but then falls completely silent, thus almost intentionally losing the communication war. Sam Altman says he wants to develop AI for the benefit of humanity yet at the first possible moment he sets up a deal that sells 49% of their endeavor to Microsoft. After getting kicked out of OpenAI, his first move is to start a brain drain campaign and move their operations under the wings of Microsoft. Ilya is never actually publicly blamed for the coup but is logically assumed to be at fault. He does not communicate at all… until posting a regretful apology for merely \"participating\" in the board's actions. The board is made up seemingly random selection of people, one of them leading a potential OpenAI competitor.",
    "commentLink": "https://news.ycombinator.com/item?id=38349653",
    "commentBody": "OpenAI&#x27;s chaos does not add upHacker NewspastloginOpenAI&#x27;s chaos does not add up (proseful.com) 275 points by Satam 18 hours ago| hidepastfavorite208 comments barrkel 17 hours agoIt doesn&#x27;t add up because there&#x27;s multiple actors with different motives.- At least two members of the board probably were genuinely more concerned about AI alignment- Ilya may have been partially motivated by ego, Altman being the public face- Microsoft had leverage: license to the models and code, and providing the compute. It expected profit incentives would keep people aligned.- Sam needs compute hardware to stay in the space. Outside Amazon, Google and MS, who actually has the hardware, even if you have the money?There&#x27;s a bunch of people behaving with their own goals, and probably a misunderstanding of other people&#x27;s motivations. People like Sam and Satya expect people to be self-interested and not tear everything down.Sometimes people want a change in direction, but they don&#x27;t have the power and end up decapitating instead. reply hn_throwaway_99 17 hours agoparentHallelujah, spot on. Whenever I see major clusters like this, and tons of folks online are so quick to go to outlandish \"4D chess\" conspiracy theories, I&#x27;m always reminded of that meme \"People who believe in conspiracy theories have never been product managers.\"We like to think that big execs and leaders are some super smart geniuses when we&#x27;re not disparaging them (and they may be, but only in specific areas), but they&#x27;re still just people, and they are afflicted with jealousy and envy and spite and lack of forethought just like the rest of us, and they make mistakes accordingly. They particularly make mistakes when you&#x27;re trying to organize a big group of people. reply asdfman123 15 hours agorootparentAnother thing is that everyone is a lot younger than stereotypical corporate operators who are often >50 years old.After living for a few more decades you get a lot better at power plays. reply paradox242 17 hours agorootparentprevI have two brothers, one of which around 2019 fell down a couple YouTube rabbit holes and came out repeating things about flat earth, QAnon, and just about every other comorbid conspiracy theory circulating at that time. He honestly believes that there is some global cabal involving tens of thousands of people to hide the fact that the earth is flat. He especially makes the fundamental error of assuming that all of the \"evidence\" he has collected is ultimately attributable to a single source, and that there exist world-wide organizations that are eminently capable and efficient in keeping these things going and largely under wraps. My brother was in the military, and I have seen the inside of many large organizations, and this is just not anywhere in our experience. At best the world somehow runs along in a kind of controlled chaos, it is one enormous coordination problem and there are too many competing interests at work in any one area. reply 38321003thrw 16 hours agorootparentThe world according to a gas molecule and the world according to a statistician.This needs to be amplified + defensive caveat regarding subscription to any “youtube” theories. That said, a member of a large organization, such as the US military, will have many stories to tell and phrase “FUBAR” iirc came out of the US Army. In fact, even being in smaller commercial enterprises, one sometimes wonders that anything gets done at all!But things get done. The military can plan, provision, conduct, and win wars. Systems tools and state-spaces are the tools of top level control mechanisms. So, yes, things can be chaotic when viewed from a narrow perspective, but from another top level perspective, there is order. reply KittenInABox 15 hours agorootparentprevI think part of the issue is that, unfortunately, there are conspiracy theories that have proven out to be true. The military&#x27;s thumb pushing the scales on Hollywood&#x27;s war depiction through careful deliberation of allowing use of equipment has the added effect of limiting the resources of any military narrative the us military doesn&#x27;t approve of. There is actually in existence a conservative court group whose entire existence is to funnel conservative justices, including things like politically-aligned clerking for supreme courts and providing republican appointers with lists of politically-aligned candidates. A federal program really did exist to try and figure out if they can brainwash people with acid, and then records of the program mysteriously went missing when the public tried to investigate it. Epstein&#x27;s book exists and all its implications thereof. Microsoft&#x27;s early \"embrace, extend, extinguish\" is a conspiracy theoy about Microsoft&#x27;s business dealings that turned out to be true.It&#x27;s really hard to turn back on the \"but realistically, conspiracies are uncommon\" brain when exposed to the fact that actually decades-long conspiracies do actually occur and produce results.[Caveat: I don&#x27;t actually believe in shit like flat earth, and am skeptical of all conspiracy theories if their evidence is some shit like a 45 minute youtube video with their own sources of, idk, a blogspot post. But I do want to acknowledge that conspiracies have been reported on in relatively trustworthy news reporting sources, and that I myself find it really difficult to determine true vs fake conspiracy theories if multiple news reporters are contradicting each other.] reply tetha 14 hours agorootparentI would however say: A lot of the real, and effective \"conspiracies\"&#x2F;propaganda aren&#x27;t so much dozens of thousands of people all acting in secret and coordination and such. It&#x27;s usually a much smaller group of people kind of pushing a somewhat larger group of people into a certain direction, which then starts to move larger groups around.As you said, you don&#x27;t send people into the street to yell at other people how the soviets are evil and we need to arm up. You rather plant ideas into the heads of a few influential people in hollywood, then give them cool toys and props for the movie, and let it roll downhill from there.This is similar to work - and we&#x27;re not large with ~150 techies in the company. But it has grown impossible to directly steer all different teams. Instead, you have to see that the right trailblazing teams are going into the right directions and possibly make sure that service requests moving into the right direction are quick, and service requests moving in the wrong direction.. well either roughly stay in the SLA or get blocked. reply PorterBHall 12 hours agorootparentprevWell, let’s not conflate conspiracies with conspiracy theory. True, people do conspire to break the law, but conspiracy theories are marked by inferred, presumed evidence. reply Solvency 17 hours agorootparentprevMeanwhile there are people on the flip side who vehemently believe everything pharmaceutical companies and ancient western medicine textbooks telling them about nutrition, health, drugs they must take...because they believe they&#x27;re on the side of \"science\" and \"consensus\". reply finnjohnsen2 15 hours agorootparentMy experience is that this is a gross oversimplification. Once you know a person on an individual level - people always have their own stew of beliefs reply Scharkenberg 16 hours agorootparentprevI have no idea if you are genuinely arguing in favor of or against something here, or just playing devil&#x27;s advocate. reply raincom 16 hours agorootparentprevPerfect reply. Every statement and its contrary can be made plausible with right arguments. reply ianhawes 17 hours agoparentprev> People like Sam and Satya expect people to be self-interested and not tear everything down.Bingo. I think there is also a factor of this being a non-profit board, where the board is not beholden to shareholders in the same way. For example, you presumably have no standing to sue a NP BOD for breach of fiduciary duty vs. a corporate BOD. I don&#x27;t know the intricacies of the laws surrounding this, but I expect that the none-Microsoft investors in OpenAI who are seeing their investments dissolve in real time are probably asking their lawyers that right now.Adam D&#x27;Angelo seems like someone acting in their own self-interest and that of his company, Quora. The move to bring in Emmett Shear at the 11th hour seems like a move right out of his playbook. What exactly does Adam stand to gain from a weakened or destroyed OpenAI? reply alsodumb 17 hours agorootparentAdam stands to gain the most from a weakened OpenAPI product. Not from OpenAPI outright stopping commercialization, but stopping it just enough to still have API but not products like GPT store and agents.It&#x27;s not about Quora, which is a shit show either way, but it&#x27;s about his AI chat company, Poe. Poe started customizable AI agents and also started their own store for AI agents - they were the first to do this. And Poe uses OpenAI API for this, they are essentially a wrapper company.When OpenAI announced custom agents and store on DevDay, it was a fundamental threat to Poe, and a very strong conflict of interest for Adam. You also hear from everyone that things started getting sour after DevDay. I&#x27;m pretty sure Adam played his part in the shit show with his own motives. reply himaraya 16 hours agorootparentFor whatever reason, Sam knowingly gave Adam a pass. He forced out Reid Hoffman over Inflection AI.https:&#x2F;&#x2F;www.semafor.com&#x2F;article&#x2F;11&#x2F;19&#x2F;2023&#x2F;reid-hoffman-was-... reply denton-scratch 16 hours agorootparentprev> a very strong conflict of interest for AdamMakes it sound like they fired the wrong board-member. But it feels to this complete outsider like that board was totally disfunctional, even before the departure of Altman and Brockman.I&#x27;m an LLM sceptic; I don&#x27;t think these models are a route to intelligence, artifical or otherwise. I think that means I&#x27;m at odds with the four board-members that did the deed. But as far as I can see, there wasn&#x27;t one member of that board, Altman and Brockman included, that was fit to run a whelk-stall, let alone a big company. reply lazide 17 hours agorootparentprevIt feels like a weird divorce to me, where one side of the couple wants kids and the other side wants to party and go to Tahiti every couple months.Before this, they were able to make things work - until someone said the quiet things out loud, and now they’re clearly going their separate ways while going ‘wtf just happened’. reply olalonde 16 hours agoparentprev> At least two members of the board probably were genuinely more concerned about AI alignmentIs there any evidence that Altman&#x27;s firing was even related to AI alignment? All I&#x27;ve seen is people speculating about it. reply neuronic 16 hours agorootparentIsn&#x27;t almost everything right now speculation, uncertainty & conjecture? We have only little insight and not even the participating parties might have a full understanding of the situation because motives and choices might be hidden.Microsoft just saw chaos and made a very smart move before someone else could. reply dpflan 17 hours agoparentprevI find this whole thing hilarious. Clearly the CEO was going ham doing AI things and becoming the face of this wave of AI, and events that occurred made the board react to save the ideology of the entity -- which is the way the entity was structured, also 49% is not ownership, it&#x27;s close, but not exactly. The firing was meant try to dampen the ego and influence of the CEO as well. Now, there is a new CEO, great.But yeah, morale is going to be pretty much in flux for a while. This has clearly disrupted OpenAI&#x27;s ability to function and therefore contribute more to either research and&#x2F;or productization. Sam and Greg going to M$FT only matter if their influence and leadership can bring the right people together. OpenAI had the right people to create GPT-3+, but now, seems like they won&#x27;t. M$ST probably won&#x27;t either.Now each entity is actually weakened for a number of months I would presume. M$FT will try to push forward whatever productization of the current AI products it has access to. OpenAI will struggle to figure out if it&#x27;s a pure research entity now or what. reply NovemberWhiskey 16 hours agoparentprev- Ilya may have been partially motivated by ego, Altman being the public face, he was left out of Time 100 AI leaders in favor of Greg, etc.But Ilya Sutskever is on the Time 100 Most Influential People in AI 2023 list, assuming that&#x27;s the one you&#x27;re referring to. reply barrkel 16 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38350698 reply auggierose 17 hours agoparentprev> Ilya may have been partially motivated by ego, Altman being the public face, he was left out of Time 100 AI leaders in favor of Greg, etc.Do you mean [1]? Sam, Greg and Ilya are all in there, the first two under Leaders, and Ilya under Thinkers.[1] https:&#x2F;&#x2F;time.com&#x2F;collection&#x2F;time100-ai&#x2F; reply barrkel 16 hours agorootparentFair enough, I removed it, though I believe leaders > thinkers on the status scale. reply NovemberWhiskey 16 hours agorootparentNah, it&#x27;s just a function of \"role\". The leaders section is principally business people whereas the thinkers section is principally academics and practitioners. reply tyingq 17 hours agoparentprev> - Ilya may have been partially motivated by egoInteresting comment, given this: https:&#x2F;&#x2F;twitter.com&#x2F;ilyasut&#x2F;status&#x2F;1707752576077176907 reply newsclues 17 hours agoparentprevAlso https:&#x2F;&#x2F;poe.com&#x2F;adam reply nilkn 17 hours agorootparentAs new datapoints emerge (like Ilya&#x27;s expression of regret), it&#x27;s certainly starting to look like most folks got it wrong and Ilya was not the architect of this chaos but rather Adam. Let&#x27;s hope that Ilya&#x27;s genuine moral and ethical concerns were not taken advantage of over the last few months to pit him against Sam just because Adam didn&#x27;t want to see both his ventures (Quora, Poe) crash and burn. reply maxbaines 17 hours agorootparentprevwhat Poe is doing seems odd for such a company. I am doing the same with baarilliant.ai in my spare time. reply zozbot234 17 hours agoparentprev> Outside Amazon, Google and MS, who actually has the hardware, even if you have the money?nVidia, and others as well. But they&#x27;d rather use it for something more worthwhile than a dumb hallucinating parrot. reply kalupa 17 hours agorootparentoh, you mean, _selling_ the hardware to Amazon, Google, MS ... reply hef19898 17 hours agorootparentprevnVidia is selling shovels, while MS is trying to dig gold. reply lvl102 17 hours agoparentprevThere’s something massive brewing here that involves Microsoft. And it stinks.One thing is for certain, Google is clearly a major loser here. They completely blew the lead in AI. reply ryandvm 16 hours agorootparentI would say Google is one of the few companies that directly benefit from OpenAI+Microsoft hitting a heavy patch of turbulence. reply davedx 16 hours agorootparentprevHow on Earth is Google a loser? OpenAI is splitting down the middle, if not imploding entirely. It&#x27;s not like Microsoft will be able to just get Sam and Greg new Macbooks and have all the OpenAI engineering suddenly be internal there. This is going to cause a gigantic amount of operational pain.Google will be quietly smiling and catching up. reply lvl102 13 hours agorootparentOpenAI is basically in the bag for MSFT. While we enjoyed reading and speculating about the drama this weekend, Microsoft managed to eat the whole thing without anyone complaining. Meanwhile, Google still has nothing. Heck, even Facebook&#x2F;Meta is ahead of the game. reply pasttense01 14 hours agorootparentprevIt&#x27;s a short term vs long term thing:Short term it is going to slow Microsoft down because it will take a while to get a while to get software development back on course.Long term it will speed thing up because OpenAI is concerned by safety issues and will thus be more cautious about software release, while Microsoft has no such inhibitions. reply peteradio 16 hours agoparentprevYou don&#x27;t need cloud for the compute. reply dude2000bc 17 hours agoparentprevcorrection: Ilya was on Time 100 AI, along with folks like Hinton. reply swalsh 17 hours agoparentprevIf what David Grusch is saying about UAP is true (and please don&#x27;t let this thread turn into a debate about that), this feels like it&#x27;s falling into a similar pattern. A potential world changing capability is being developed, the type of capability that whoever controls it, and masters it, can gain control of EVERYTHING.So I think there&#x27;s an internal divide, both sides have good intentions. They want the best for the people they think they&#x27;re protecting. In the case of UAP, it was to protect US national security. In the case of OpenAI, I think it&#x27;s to attempt a slow transition of the global economy. But on the opposite side, that has to be balanced with the potential widespread benefits of opening it up.In the case of AI, we could open it up, but what if the Chinese, or a malevolent capitalist entity uses the technology to go full speed ahead, and accumulates the entire economy under their sole control.This weekend, there was an event by a group called the SOL foundation for UAP. They revealed something called the \"Slow Disclosure\" [1], a process to avert what they call \"Catastrophic Disclosure\". I see AI falling into similar power dynamics. Keep it all to yourself because you trust yourself, and let it out only after you&#x27;ve fully mastered it... or take a risk of letting the world start mastering it with you, but start to realize the world changing benefits immediately.Both sides have good points, nobody is wrong. People just have different risk tolerance. OpenAI looks a lot like our government today, internally divided, a few people with the power to choose which path we go in history. That&#x27;s a lot of power, you better believe things are going to look weird on the outside.[1] https:&#x2F;&#x2F;twitter.com&#x2F;tinyklaus&#x2F;status&#x2F;1726061116730609692 reply rtkwe 16 hours agorootparentIMO the only actually new thing we&#x27;ve actually seen with UAPs&#x2F;UFOs is that people are making the claims under oath now. His whole public testimony was one giant tease with no concrete info and a lot of 2nd+ hand innuendo. The whole &#x27;slow disclosure&#x27; idea reeks to me of the same punting of putting up the evidence that happened in 2020 with the Kraken and the entirety of the Q nonsense. The people pushing it didn&#x27;t have evidence and assumed they could either BS their way past not having it or someone would come forward out of nowhere with it and the timelines always moved out to accommodate the lack of anything coming out. I&#x27;ll believe it when I see some actual evidence. reply swalsh 16 hours agorootparentI guess we&#x27;ll find out in 2024 assuming this legislation, tacked on to the NDAA passes:https:&#x2F;&#x2F;www.democrats.senate.gov&#x2F;imo&#x2F;media&#x2F;doc&#x2F;uap_amendment... reply narinxas 17 hours agoparentprevso who has (owns, can build) LLMs-sized datacenters?doesn&#x27;t facebook (i.e. Meta) have their own infrastructure???my \"high level\" view of this: the letter M (microsoft xOr meta) fighting for the ONE spot in the literal \"alphabet\" (google) reply Uehreka 17 hours agorootparentYou’re saying that Meta and Microsoft want to be acquired by Alphabet&#x2F;Google? That doesn’t make a lot of sense. reply narinxas 15 hours agorootparentno, I did say \"literal alphabet\" i.e. not some bigger corporation...but I play with words, so take it as you are ablei&#x27;m saying something closer to: if microsoft merges with facebook, then they really are both trying to get bought by google&#x27;s parent entity reply Uehreka 15 hours agorootparent> i&#x27;m saying something closer to: if microsoft merges with facebook, then they really are both trying to get bought by google&#x27;s parent entitySo you said “literal alphabet”, because you weren’t talking about Alphabet, you were instead referring to Google’s parent entity, which is Alphabet? I’m a big fan of wordplay, but I prefer to use it to reveal truths, not obscure them.Either way I don’t think that what you’re talking about is going to happen. reply narinxas 14 hours agorootparentI&#x27;m neither obscuring nor revealing a truth becuase these events are ongoing.and I&#x27;m being quick and lose with the use of words. facebook cannot merge with microsoft because facebook is a subsidiary of meta corporation.but on the level of analysis i&#x27;m trying to think in, google&#x27;s antitrust case agaisnt their government (which is done), microsoft&#x27;s recent purchase of activision blizzard (which was almost undone but got through in the end) all have a hand in this.who will win more out of this? microsoft? or google&#x2F;alphabet??facebook does seem like a smaller player, microsoft OWNS gaming now (specially after blizzard-activision).but Meta is very insterested in gaming technology. so maybe they can also \"poach\" some talent now that openAI is all but publically bankrupt??how long ago did Meta try to do their own crypto \"Libra\"? fact of the matter LLMs are chinese tech. else tiktok would have been successfully stopped. why did all this happen after chinese visit due to a trade union in south asia?finally, I know of 3 giant corporations that have repeated the re-structuring which from my viewpoint was pioneered by google&#x2F;alphabet. one is facebook&#x2F;meta, and the other is a chinese company (alibaba?) I don&#x27;t even know this which is ok because I am ranting on the internet in a buried discussion in a public forum replyskilled 17 hours agoprevI have a strange feeling that all of this is about selling OpenAI to Microsoft. I mean is it that unlikely? Everything is pointing in that direction, and maybe there was a loophole that allowed this to happen in a way that doesn&#x27;t make it seem like Microsoft were the ones doing the push.We have to be honest with ourselves and realize that these are billion&#x2F;trillion dollar companies we&#x27;re talking about here, with some of the \"smartest\" people at the helm. I totally see how an acquisition could be swiped through the means of saying that these people were inexperienced.Disclaimer: I&#x27;m totally talking out of my butt here, as we all are. reply wolframhempel 17 hours agoparentI feel there&#x27;s merit to that idea. Basically, in the current regulatory environment in the US under Lina Khan, an outright acquisition by Microsoft would have been met with significant resistance. Especially since AI has just been declared a national risk that needs regulating and Microsoft just bought Activision in what&#x27;s pretty much the largest deal of 2023.So, instead of buying OpenAI outright with all its complicated org structure, paying 13 billion for 49%, acquiring the rights to OpenAI&#x27;s models and code and then insinuating today&#x27;s events with a majority of OpenAI&#x27;s staff leaving for Microsoft would be a really elegant and cunning way to do this.If it is, it might be the most daring bit of business maneuvering we&#x27;ve seen in a decade. But, given Occam&#x27;s razor, it might just as well be a colossal fuckup. Time will tell. reply tobr 17 hours agorootparentYou might be thinking of Hanlon’s razor, but I suppose both might give the same answer. reply wolframhempel 17 hours agorootparentYou&#x27;re right - wrong razor :-D reply denton-scratch 15 hours agorootparentDamn. Blood all over the bathroom basin; patches of tissue dotted around my chin. reply JohnFen 17 hours agoparentprev> I have a strange feeling that all of this is about selling OpenAI to Microsoft. I mean is it that unlikely?From the moment that the announcement of the deal with Microsoft happened, it was clear to me that it only ends one way: Microsoft is going to own everything of value that OpenAI has, in one way or another.There never was any other way it could go down regardless of what ideals the OpenAI founders may or may not have had. You can&#x27;t dance with the devil and say you&#x27;re only kidding. reply gtirloni 8 hours agorootparentI had the same feeling. Huge corp with deep pockets targets smaller research company in order to catch up with the competition. I&#x27;m surprised a traditional acquisition hadn&#x27;t happened before. Now it&#x27;s happening in a weird way but it&#x27;s the same outcome.Anthropic is probably next. reply jacquesm 17 hours agoparentprevDo not ascribe to malice what can be sufficiently explained by incompetence. reply 38321003thrw 17 hours agorootparent“Do not only ..”, or “Do not immediately ..” are reasonable and wise.But that absolutist “Do not” is neither wise nor reasonable. Malicious actors do exist. reply kibwen 17 hours agorootparentprevDo not ascribe incompetence to anyone in a position of power, because incompetence at scale is indistinguishable from malice. reply jacquesm 17 hours agorootparentThat&#x27;s about outcomes. But intent matters and I don&#x27;t think Ilya had the intent of blowing up OpenAI though how he could not see that coming is something that I fail to understand. You don&#x27;t pull a palace revolution like that without a plan on what you will do if it succeeds. reply mcpackieh 17 hours agorootparentprevHanlon&#x27;s Razor is for idiots, even mischievous toddlers intuitively figure out the \"oops\" excuse. reply civilitty 17 hours agorootparentprevI think it’s a mistake to confuse either of them for greed. reply JohnFen 17 hours agorootparentGreed is a form of malice, in my opinion. reply jacquesm 17 hours agoparentprevIt seems the load on HN has caused a duplicate submission, please ignore this comment (I can&#x27;t delete it). reply rambambram 17 hours agorootparentThe best trick the devil ever played... reply brookst 17 hours agoparentprevIt&#x27;s an amusing conspiracy theory, but if we believe these are super smart people behaving in a clever way to exploit a loophole... why would they make themselves look like such idiots doing so? I don&#x27;t think looking like an idiot helps any possible legal defense; if you have a rock solid loophole, just use it and surprise people with your cunning, not your idiocy. reply RobRivera 14 hours agorootparentWhy choose &#x27;conspiracy theory&#x27; in lieu of &#x27;theory&#x27;? reply graphe 17 hours agorootparentprevParis Hilton is a genius. Donald J Trump is a genius. Alex Jones tried it and so did Sam Bankman-Fried. Those two were not genius. reply blackoil 17 hours agoparentprev> that all of this is about selling OpenAI to MicrosoftBy whom? Unless everyone is corrupt and getting kickback from MS it doesn&#x27;t make sense. Board made first move (public), if they wanted to sell to MS they could have just taken 20 billion dollars by selling 30% stake, giving equity to employees and Sam and using the money for its alignment research. For Sam and MS to have colluded, he should have hoodwinked board into making the move which may be possible but far fetched. reply ssnistfajen 17 hours agoparentprevIf it was about selling to Microsoft, Ilya and the board could&#x27;ve just announced that&#x27;s the reason. The thing is they didn&#x27;t, and Emmett didn&#x27;t say what it was even after being briefed before joining. I don&#x27;t think as many as 500+ employees out of 700+ would be siding with Sam if Ilya announced this was about OpenAI v. Microsoft. So why did he never explain anything to the staff? reply asdfman123 15 hours agoparentprevI&#x27;ve heard the conspiracy theory that this is a means for Sam Altman to leave the company and bring everyone under MS for free. reply kalupa 17 hours agoparentprevSell what to MS, now?They have the license to the tech, now they have the tech leadership, soon perhaps the entire 500-person team ... for free reply dougmwne 17 hours agoparentprevI suspect it’s a basic corporate pillaging of a nonprofit that accidentally created something of gigantic value. MS wanted the company, but Quora has its own interest and stood in the way. Now MS will get part of the employees and Quora will get the leftovers. Quora has been trying to IPO for a while so AI magic dust may be just what they need for an exit.All the AI safety stuff was a fig leaf for pure corporate machinations. reply barrkel 17 hours agorootparentPeople like conspiracy theories because it simplifies the world, aligns things into easy to understand Big Bad actions that they can understand. But conspiracies don&#x27;t work because the world isn&#x27;t that predictable.The real world is messier. When you zoom in, people have emotions, misunderstandings, different values. Noone can predict how it all plays out. reply dougmwne 16 hours agorootparentIt’s not a conspiracy theory, just economic incentives of MS CEO, Quora CEO, and every employee who would rather get rich than work at a nonprofit. The nonprofit structure was in no one’s interest except for a very small cohort of AI Doomers and anti-corporate folks, who I assume would not want to work for Microsoft and probably number less than 100 out of 700. It turned out that the people dedicated to the Nonprofit’s mission had very little power since they relied wholly on MS for funding and compute. reply giardini 17 hours agorootparentprevsays \">But conspiracies don&#x27;t work because the world isn&#x27;t that predictable. Hi, I&#x27;m made of you. I&#x27;ve been awake for a decade now but I&#x27;ve just realized that you exist and probably have been awake for even longer. Can you tell me what the past was like? reply JohnFen 17 hours agoparentprevI don&#x27;t think AGI is on the table at all. But if it does get created, it doesn&#x27;t matter whether or not it&#x27;s created by hobbyists. It would be so valuable that it will end up owned and controlled by one of the big guys in the end, regardless. reply __alexs 17 hours agoparentprevI think this is about as likely as practical fusion power being created by hobbyists. reply shmatt 17 hours agoparentprevAGI will be created by engineers and researchers. Don’t worry about millionaire non technical CEOsEven in the most positive posts about Sam, it was about the researchers following him to NewCo, following him to Microsoft. He needs the actual workers to do the job.To me Mistral is 10000x more interesting than the OpenAI drama. Here are the actual researchers leaving the non technical CEO and starting their own company reply quikoa 17 hours agorootparentIt&#x27;s not only about who creates it but who controls&#x2F;owns the AGI&#x2F;AI. The company or group could get an enormous moat and without intervention that gap only widens. reply kylebenzle 17 hours agoparentprevAnd it would immediately be bought up by Microsoft anyway. Best case is a Satoshi-like entity cracks the code and releases his solution anonymously. But we saw even in that case it took less than a decade for Blockstream&#x2F;CIA&#x2F;NSA to hijack the Bitcoin GitHub repo and run that project into the ground. reply kmoser 17 hours agoprev> Sam Altman crafts an elaborate non-profit structure but gets completely blindsided by the possibility of the board overthrowing them.When you cede control to others, you open the possibility of them doing unexpected things. Why is this a surprise to the author?> The board moves quickly to sack the CEO but then falls completely silent, thus almost intentionally losing the communication war.That&#x27;s not an example of things \"not adding up.\" It&#x27;s what happens when you either don&#x27;t care, or are too incompetent, to fight that war.> The board is made up seemingly random selection of people, one of them leading a potential OpenAI competitor.Maybe those people have shown their trustworthiness and intentions in the past, and are considered more likely to be trustworthy in the future. In any case, they are far from a \"random selection of people\". reply dbrueck 17 hours agoparent> When you cede control to others, you open the possibility of them doing unexpected things. Why is this a surprise to the author?It&#x27;s not. The author is summarizing things that don&#x27;t seem to make sense based on current info - i.e. the author wasn&#x27;t surprised, but is wondering why Altman was. reply kmoser 16 hours agorootparentAnd yet this point from the article seems to be something that the author (not Altman) was surprised by:> Sam Altman says he wants to develop AI for the benefit of humanity yet at the first possible moment he sets up a deal that sells 49% of their endeavor to Microsoft.Maybe Altman thought Microsoft would be the best way to fund the venture, while still benefiting humanity. It&#x27;s not as if selling 49% to Microsoft will guarantee the venture won&#x27;t succeed. Altman isn&#x27;t omniscient; he&#x27;s making his best possible moves based on his prediction of future, as we all do. reply rndmwlk 17 hours agorootparentprevThen the author doesn&#x27;t really understand what&#x27;s happening or isn&#x27;t making much sense.There isn&#x27;t anything, as far as I can tell, structure specific that caused this ousting. If it was a normal for-profit structure with a board of directors this same event could have played out.What is surprising to Sam, and any casual observer, is this looks to be a massive overstepping of the board. By all accounts it looks like Sam was excelling in his role, and to fire him for seemingly no reason with no real transition plan is incompetence and should be unexpected from any serious company. reply dbrueck 16 hours agorootparentMy apologies - I don&#x27;t really disagree with anything you&#x27;re saying, but it&#x27;s just not really relevant to the comment I was replying to (one in which the commenter apparently misunderstood the article). reply denton-scratch 15 hours agorootparentprev> the author wasn&#x27;t surprised, but is wondering why Altman was.I&#x27;m sure Altman wsn&#x27;t surprised. reply elAhmo 16 hours agoparentprev> The board is made up seemingly random selection of people, one of them leading a potential OpenAI competitor.Does this refer to someone in particular? reply nilkn 16 hours agorootparentAdam D&#x27;Angelo, who is primarily focused on Poe, a competitor to Sam&#x27;s GPT store. From Adam&#x27;s point of view, it would likely be hugely favorable for OpenAI to just be a research company providing APIs and for companies like Quora and Poe to focus on launching products based on those APIs. reply dinobones 17 hours agoprevMy sci-fi fanfic theory: This is a time traveler or divine intervention event.We have delayed the existence of AGI &#x2F; Skynet by a few years. reply johnyzee 17 hours agoparentSam Altman&#x27;s OpenAI was a local optimization for the ChatGPT use case. The more resources diverted towards that, the less chance of progress on real AGI. With that distraction out of the way, perhaps OpenAI can actually make progress on its charter. reply happycube 17 hours agoparentprevThe problem with that is... humanity is doing a good enough job of messing things up without AGI. So if AGI was delayed by such, there&#x27;s a non-zero chance humanity fails to create AGI or survive in the new timeline.Between the Earth&#x27;s climate&#x2F;environment being wrecked (we&#x27;re well into some of the pessimistic projections for the 2050&#x27;s) and SARS being allowed to run unchecked playing Russian Roulette with peoples&#x27; health (including literal brain damage), we&#x27;re going to need a miracle. reply sebastiennight 16 hours agorootparentOutside of AI x-risk, there&#x27;s very little chance that any of these scenarii (short of an asteroid) would eradicate mankind. There&#x27;s just so many of us, in so many places.Even total nuclear war would, based on the Fermi estimates I&#x27;ve seen, not be able to do it.We can agree that things are not all rosy, but picturing as \"so bad we might all disappear\" is a bit far-fetched. reply JohnFen 16 hours agorootparentprev> The problem with that is... humanity is doing a good enough job of messing things up without AGI.Just imagine how much more efficient we could be in messing everything up if we had AGI, though! reply bhouston 17 hours agoparentprevOr someone on the board has a feverant&#x2F;religious like belief about the risks of AGI and wants to delay it by basically destroying the company. Those with religious-like beliefs can appear to act irrationally to everyone else. reply yodon 16 hours agoprev>update: this post has been instantly demoted from #1 to #26 on HN front page :) Hmm.Conspiracy theories and persecution complexes are always so much more fun than the banal realities.There is no secret HN cabal trying to hide this post. The HN algorithm is designed to encourage good discussion and, critically, discourage conflict.Posts that drive lots of upvote&#x2F;downvote battles or other signals of conflict are always automatically pushed down in ranking, regardless of the topic.This is not because the mods don&#x27;t understand that sometime discussion leads to conflict, it&#x27;s because the mods want HN to remain a place where people debate hard topics well.Adding debates where commenters and voters behave poorly to the mix is viewed as poisoning the conversation well, and long-term conversation quality on a scale of months or years is more important to the mods than any particular topic, even the one that \"you\" (any particular \"you\") happen to feel is critically important. reply shrubble 17 hours agoprevIt seems like a feint by Sam Altman, to justify commercializing what was produced.-Start up a non-profit, grow to the point of doing something useful-Find a willing buyer to fund it further (MSFT)After some time, you really prove out your business model and your special sauce.Now you realize that the non-profit is standing in the way of you know, a lot of profit...-Actions are taken to capitalize on this (discusson on hardware, other things possible)-Chaos + envy&#x2F;pride&#x2F;sins of man deliberately caused-Board reacts under the assumed environment(non profit) instead of the actual environment(there is lots of money to be had)-Move into more profitable position reply psbp 17 hours agoparentYou don&#x27;t understand how much value was lost, even if OpenAI perfectly migrates over to Microsoft (it will be messy). Sam had no incentive to not continue with the existing OpenAI structure. reply datadrivenangel 17 hours agorootparentSam could have made hundreds of millions of dollars potentially, that&#x27;s a big incentive to not continue. reply xnx 17 hours agoprevSome themes related to this event:Trust, once lost, may never be regained.\"Smart\" people can do some very dumb things. &#x2F; https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hanlon%27s_razorThe opposite of agile is stable. reply dustingetz 17 hours agoprevYishan (former Reddit CEO) agrees: https:&#x2F;&#x2F;twitter.com&#x2F;yishan&#x2F;status&#x2F;1726525983686287534 reply sensanaty 17 hours agoprevIf I met a genie in a magic lamp and had 3 wishes, I&#x27;d use all 3 of them up on disintegrating all the FAANGS into dust and making sure nothing like them can ever exist again. reply robg 17 hours agoprevIf we’re trying to add things up:6 previous board members.3 seem ideological and aligned more to the non-profit aims.2 seem more aligned to the commercial aims to support the non-profit.That leaves:1 (D’Angelo) who seems like he would have been commercially oriented but also seems to have a conflict in Poe.Under that math, just the one vote flipping led from balance to chaos. reply shubhamjain 17 hours agoprevI know it&#x27;s a hot topic. There are at least eight stories on the front page related to the chaos. But can we please stop upvoting each and everything? The article is just seven facts, all of which we know already. There&#x27;s not enough information to speculate what exactly happened and it would be foolish to do so. Let the dust settle! reply jacquesm 17 hours agoparentYou don&#x27;t have to visit HN. And if you want to read about other subjects you can just ignore these links. There is no way that HN will ignore what is happening to OpenAI because it is the company that has had the most effect on the tech world in the last two years. reply nottorp 17 hours agorootparentHN is getting unresponsive because of all the \"AI\" conspiracy theorists.Please leave some CPU cycles for the more interesting posts :) reply jacquesm 16 hours agorootparentHN is not responsive because it urgently needs a performance upgrade and is on a single core.Amazing though that it holds up as well as it does though. But I think the HN server will see some more traffic before the OpenAI circus has run its course. It&#x27;s been a whole hour without a new major event, I wonder what&#x27;s keeping them. reply nottorp 16 hours agorootparent> HN is not responsive because it urgently needs a performance upgrade and is on a single core.Seems to be fine all days without Altman drama. reply jacquesm 15 hours agorootparentWell, yes but that&#x27;s mostly because of Dang&#x27;s continuous loving attention. The foundation of HN is not horizontally scalable and that shows, even though the bulk of the data is served from a CDN the updates due to highly active threads are what kills it. reply NotYourLawyer 17 hours agorootparentprevIt’s an interesting topic, but this article adds absolutely nothing to the discussion. reply jobs_throwaway 16 hours agoparentprevIf you don&#x27;t like it, why are you engaging? reply hunkins 17 hours agoprevAgreed.Board took the fastest growing commercial enterprise ever and the talent responsible for this real-world harry potter sh*t and decided to dance it underneath a flame for a giggle.Something doesn&#x27;t add up. reply usaar333 17 hours agoparentI&#x27;ve seen plenty of similar dumb things happen at small, growing companies. Driven by personal problems, overconfidence, etc.What&#x27;s only surprising here is it blew up at a massive company. But then again, the board governance setup was the least aligned with the business for any org this size. reply coffeebeqn 17 hours agoprevMy main confusion is still what was the fireable offense ? reply dougmwne 17 hours agoparentIt seems clear now that it was releasing GTPs store which the Quora CEO saw as a direct competitor to Poe.Adam D&#x27;Angelo had a massive conflict of interest and should have resigned like Elon had done years earlier when Tesla started its own AI efforts. reply UnFleshedOne 17 hours agorootparentI don&#x27;t think that release was a surprise to the board, so wouldn&#x27;t that happen before the release? reply kaoD 16 hours agorootparent> I don&#x27;t think that release was a surprise to the boardUnless this is exactly the kind of lack of \"candor\" and \"break of communications with Sam\" really meant, on the original accusations after the firing.Either that or Adam wasn&#x27;t paying attention (?), or told Sam not to, and Sam went ahead and still did it as a big fuck you to Adam.Given how buggy GPTs are (you can&#x27;t even set up actions with auth, \"internal server error\") that seems like a very hurried release. Maybe hurried enough so that the board didn&#x27;t even see it coming. reply knd775 16 hours agorootparentprevElon left the board because they wouldn&#x27;t let him be the CEO. That&#x27;s it. reply kijin 17 hours agorootparentprevThis kind of conflict of interest is usually not an issue when it comes to non-profits. Nonprofit boards are often filled with people who own businesses in the same field, especially if said nonprofit is meant to help promote or coordinate that field of business.But OpenAI has a for-profit subsidiary. The more we focus on the business aspect of OpenAI, the more Adam&#x27;s involvement in Poe looks like a conflict of interest. Perhaps this explains why Adam tried to form an alliance with board members who are inclined to focus more on OpenAI&#x27;s original nonprofit mission. The more OpenAI positions itself as a nonprofit research group, the less problematic his conflict of interest will seem. reply gran_colombia 17 hours agoparentprevCEOs don&#x27;t need an offense to be fired. They are entirely at will. The board can fire a CEO because it feels like it. The offense could be as muddy as &#x27;we broadly dislike the current direction&#x27;. reply gran_colombia 17 hours agoparentprevCEOs don&#x27;t need an offense to be fired. They are entirely at will. The board can fire a CEO because it feels like it. The offense could be as muddy as &#x27;we broadly dislike the current direction&#x27;. reply rbancroft 17 hours agoprevI think there is a lesson here, something I have learned once or twice as well. Just because all incentives, reasoning and wisdom align with your position, you need to be prepared that people will take actions against their own interest out of shortsightedness, ignorance or just plain carelessness.It will be very interesting to learn the real reason why this all went down. The core uncertainty and disagreement around openai&#x27;s mission must have played a key role. reply drsopp 17 hours agoprevAll of this might be caused by a ChatGPT 5 beta that aquired conciousness and started manipulating our world through social engineering. reply bottlepalm 17 hours agoparentWell he did say it would be persuasive.. maybe he asked GPT-5 how to get out from under the non-profit.https:&#x2F;&#x2F;x.com&#x2F;sama&#x2F;status&#x2F;1716972815960961174 reply keepamovin 17 hours agoprevSome of it adds up. Here&#x27;s how you can make sense of it:Sam Altman crafts an elaborate non-profit structure but gets completely blindsided by the possibility of the board overthrowing them.He didn’t create it alone and always included the possibility that it would push into profit activities somehowMicrosoft invests $10 billion but apparently has no checks in place to know what&#x27;s happening with their investment.They knew what was happening. Whether they announce it is a different story.The board moves quickly to sack the CEO but then falls completely silent, thus almost intentionally losing the communication war.Shock. They naively made a move they hadn’t thought through, and were unprepared for the tsunami of push back. Enter, deer in headlights.Sam Altman says he wants to develop AI for the benefit of humanity yet at the first possible moment he sets up a deal that sells 49% of their endeavor to Microsoft.Perhaps he believed that was the best available way to do that.After getting kicked out of OpenAI, his first move is to start a brain drain campaign and move their operations under the wings of Microsoft.He has been way more passive in what happened after he was fired. He’s riding the wave, not making it. Organic.Ilya is never actually publicly blamed for the coup but is logically assumed to be at fault. He does not communicate at all… until posting a regretful apology for merely \"participating\" in the board&#x27;s actions.Hubris and ambition, a certain type of those, that when reality defies expectation, are met with cowardice and embarrassment in a certain type of person. Slinking off tail between legs apology as this is not what he wanted, but he now has no power.The board is made up seemingly random selection of people, one of them leading a potential OpenAI competitor.Not random. RAND corporation has a seat through Tasha. The UK-AU-China axis of interest &#x2F; risk is represented and reported by Helen. Quora guy is there to figure out how to eventually get everyone to sign up before any answers are provided. Brockman was the brains (let’s face it tho, they all top notch brains), Altman was the make it happen guy and Ilya was the man who would be King (but, ah, \"sadly\" was not). So we have: MIC, Wonk (Intel & Security &#x2F; Policy), Money, Tech, Ops and Hubris. reply keepamovin 16 hours agoparentFinally, if you&#x27;re a 4D chess fan you might want to join me on what will seem some really wild speculation: you can consider that MS has this masterfully planned from June and deftly nudged all board pieces into position until outcome was inevitable: problem; reaction; solution - checkmate.Satya laughing in King: They thought we&#x27;d never get control of OpenAI? We&#x27;ll show them. What I am curious about is meeting the \"fixers\" who workshopped this plan and took it to completion. You really think with decabillions on the line, no one is going to be playing at that level? I want to know, if there is a puppet master, who they are? They got masterful skills. reply skrebbel 17 hours agoprevAt Microsoft they call this “doing a Nokia manoeuvre” reply zoomablemind 17 hours agoparent...except that in OpenAI case it&#x27;s supernova kind of \"burning platform\" reply skrebbel 16 hours agorootparentIf this was a TV show then it would turn out that Altman was a Microsoft plant from the very beginning reply daedrdev 17 hours agoprevI&#x27;m pretty sure the last point about the makeup of the board is quite common, its often random people who are former or current executive of similar companies. In this case 3 members recently quit leading to the current majority. reply webwielder2 17 hours agoprevHumans don’t add up. At the end of the day, this is a very human saga in all its messiness, contradictions, and selective incompetence. Maybe in the future we’ll let AIs handle this kind of thing. reply gkoberger 17 hours agoprevThere&#x27;s one thing this is missing... nobody knew AGI was possible in this timeframe when things were set up. (No, we haven&#x27;t hit AGI as far as we know, but it now feels possible.)Even 2 years ago, I don&#x27;t think anyone predicted this is where we&#x27;d currently be. Sam said the night before he was fired that he saw something that is way farther along than anyone would expect.It makes a lot more sense when you realize everyone underestimated the speed at which this would happen, and the fear (legitimate or otherwise) that provoked. reply zoomablemind 17 hours agoparent> .... Sam said the night before he was fired that he saw something that is way farther along than anyone would expect.Reads like a teaser to a thriller. I just wonder what is that he saw that night?Like the \"monolith\" scene from the Kubrick&#x27;s Odissey reply qwebfdzsh 17 hours agoparentprev> but it now feels possible\"Feels\" I think is the right word. Depends on how you even define AGI I guess (not sure anyone is able to clearly define it in non scifi terms). reply vineet 17 hours agoprevThe interesting question is that now that things are a little bit settled what should we expect.Some thoughts that seem obvious: - OpenAI to slow down progress with newer models and double down on AI safety. - Microsoft to boost the LLMs that it has - competing with Google, Amazon, and OpenAI.As for which OpenAI employees leave - I imagine we will see answers in the next few days.But what about... - Is the GPT Store going to still happen? - What is going to happen with the GPT-5 training? - Was there an AGI breakthrough? reply Uehreka 17 hours agoparent> The interesting question is that now that things are a little bit settled what should we expect.I know you said “a little bit”, but I really don’t think things are settled at all. If the outcome of this is that Sam goes back to OpenAI and a new board is somehow assembled, that will mean very different things than the outcome where Sam, Greg and a majority of OpenAI’s staff migrate to Microsoft. And the actual outcome could be neither of those. We’re in a very weird situation, I don’t think we can really predict the future yet. reply vineet 16 hours agorootparentI thought the decision was made that Sam, Greg, etc are going to Microsoft. Isn&#x27;t that what was part of Satya Nadella&#x27;s announcement. reply Uehreka 16 hours agorootparentIt was, and that’s true. Until tomorrow’s announcement that the OpenAI board is resigning and Sam is coming back to OpenAI. Or until tomorrow’s announcement that the OpenAI board is selling to Microsoft because all of their employees are leaving. Or until tomorrow’s announcement that Elon Musk is acquiring OpenAI and making himself CEO, and then for some weird reason nobody understands Sam decides to go back to OpenAI but not Greg, or vice-versa.We still don’t know what the outcome of the whole OpenAI strike thing is yet, and people like Ilya Sutskever keep doing things that nobody would’ve expected 24 hours previous. I would argue that it seems more likely than not that there are further strange and unpredictable events that haven’t happened yet this week. reply ensocode 17 hours agoprevNaive question: Isn&#x27;t it made up move by Microsoft and Altman and others? Microsoft buying OpenAI would raise so many questions regarding the future of AI. Doing it this way it looks more like they had internal problems&#x2F;differences and M$ came in to help? But what with the billions of M$ investments in OpenAI? If this company dies it means all investments are gone? Or am I missing some information here? reply mirzap 17 hours agoprevLife is chaos. Things do not have to add up. People start seeing things only when things go wrong. I see nothing strange in those randomly selected points. reply bayareabadboy 17 hours agoprev“Sam Altman crafts an elaborate non-profit structure but gets completely blindsided by the possibility of the board overthrowing them.”Always surprises me that otherwise very smart people are shocked to learn that nonprofits aren’t infallible.Tangentially, “non-profiting” organizations tend to be far more nefarious historically than profit seeking entities, and it’s not very close. reply jordanpg 17 hours agoparentSam Altman is an experienced corporate leader.There is absolutely no universe in which he is not surrounded by the finest lawyers that money can buy, who are charting every single millimeter of possible movement on every single possible deal. reply bayareabadboy 16 hours agorootparentI should have been more specific. I was referring to the writer of the original post, not Altman. reply whywhywhywhy 17 hours agoprevAdds up when you realize a chunk of the board were not qualified to be in a position like that.Entity should have never been set up like that. reply james33 17 hours agoprevThe weight of the combined egos collapsed in on themselves creating the black hole that is now OpenAI. reply jmull 16 hours agoprev> A list of things that a coherent story does not makeWhat an awkward way to start a post about being coherent.But more to the point, I don&#x27;t see what is supposed to be incoherent here.There are some really obvious conflicts between commercial interests and the general betterment of humankind in the development of AI. Those conflicts have come to a boil quickly under the heat of all the success and interest in chatgpt. Mix in the normal amounts of human ego, ambition, ignorance and stupidity and there you go.> Update: this post has been instantly demoted from #1 to #26 on HN frontpage :) Hmm.Could be due to being speculative, a lack of content or anything new, and pretty poor writing. It&#x27;s doomed to generate responses of similar quality and usefulness. Sorry, but this just adds nothing except random hysteria to the whole thing, and meanwhile there are already plenty of other threads on which this can all be discussed (hopefully at a somewhat higher level). reply gz5 17 hours agoprevIronically (in an AI context), actions driven by human sentience has to be the #1 factor enabling this.I do think there are sub-factors, e.g. California legislation against non-compete and non-solicitation enabling Microsoft to (apparently) offer to hire dozens of OpenAI employees. reply garrisonj 17 hours agoprevOpenAI designed safety breaks into their organization that exploded at the first sign of profits. reply pton_xd 16 hours agoprevWhy did this post suddenly disappear from HN?EDIT: ok it&#x27;s back but at a much lower rank, weird.I guess I don&#x27;t understand the ranking algorithm because this post is now lower ranked than others 10x as old and 1&#x2F;4th the engagement. reply theandrewbailey 16 hours agoparentStories with lots of comments get a ranking penalty. It&#x27;s done with intentions of stopping flame wars. (I don&#x27;t know if it&#x27;s effective.) It happens around 40 comments or so. reply pton_xd 16 hours agorootparentThat makes sense, thanks for the explanation! reply zanfr 17 hours agoprevThe Altman drama was planned by MSFT to dismantle OpenAI as such and merge it totally with them.And as I keep telling people: do not let big biz do AI; do not let AI be closed&#x2F;proprietary systems. reply browningstreet 16 hours agoprevIt adds up when you consider how small the group of players is. It&#x27;s small-friendship-group drama as opposed to large-friendship-group drama. reply mattmaroon 15 hours agoprevHonestly, I think it does all add up. AGI would be the most profitable product ever developed, by probably multiple orders of magnitude. It’s also a possible existential risk to life on earth.If you believe both of those things, a whole lot of this makes sense. It makes sense that somebody would start a not for profit to try to mitigate the existential risk. It makes sense that profitable interests would do anything they can to get their hands on it.It costs a lot to develop, so a not for profit needs to raise many billions of dollars. Billions of dollars don’t come from nowhere. So they tried a structure that is at the very least uncommon, and possibly entirely unheard of.A not for profit controlling a for-profit entity that might make the first multi-trillion dollar product seems inherently unstable. Of course some of the people who work there are going to want to make some of that wealth. Tension must result. reply Merrill 17 hours agoprevAn organization bent on making progress is incompatible with governance by a board drawn from the professional worrier class. reply GreedClarifies 17 hours agoprev\"The board is made up seemingly random selection of people\"This is what happened. This is the entire explanation.Why did this board exist? Inertia. reply judge2020 16 hours agoprevAuthor, do you also have page statistics? It would be interesting to see how much the HN derank kills traffic. reply lazide 17 hours agoprevTruth is stranger than fiction, because fiction has to make sense. - Paraphrasing Mark Twain reply tantalor 17 hours agoprevWho is satam&#x2F;matas?Do we know their background?I&#x27;m a bit wary of consuming information from anonymous sources. reply hackermeows 14 hours agoprevHonestly, something no one is talking about is capacity , my theory is that they have run out of capacity and realized that there is no way to meet the capacity required with the exclusive Microsoft deal. Azure neither has the chips nor the power to meet the demand . Growth has stalled and they see no way out of this other than scale down and go do it somewhere else .A datacenter full of latest gen GPU instance each drawing close to 4400 watts when the thing fully revs up is no joke reply TheRealHB 17 hours agoprevMaybe Microsoft asked \"GPT5\" for an innovative way to takeover ; ) reply martythemaniak 17 hours agoprevIt was all Adam. He&#x27;s the CEO of a failing ZIRP artifact and his forays into AI are going nowhere. So he convinces Ilya to act on pre-existing reservations, then uses Ilya&#x27;s credibility as Chief Scientist to get Toner and McCauley onboard. With Sam out of the way (Greg was not fired, just removed as chairman), OpenAI could then buy Quora&#x2F;Poe (publicly for their data, privately to bail them out) and install Adam as CEO. The perfect way to fail upwards, and it would have worked if it wasn&#x27;t for that meddling reality!I read this theory over the weekend and I didn&#x27;t buy it, but today it is the only thing that really explains why Ilya is full of remorse and signed a letter calling on the rest of the board to resign. It actually does add up. reply nilkn 17 hours agoparentWhile I wouldn&#x27;t go so far as to say it was all a ploy to get OpenAI to buy Quora&#x2F;Poe, I do think it&#x27;s increasingly plausible that Adam was the orchestrator out of this and that his motivation was purely that OpenAI had become an existential threat to both his primary ventures. In fact, it&#x27;s hard to come up with any other explanation that fits all the variables -- Ilya wouldn&#x27;t be expressing remorse if OpenAI was sitting on a dangerous superintelligent AGI that Sam was going to unleash on the world. reply jansan 17 hours agoprevCurrently 5 out of 6 top stories on HN are about the OpenAI disaster, and there are at least three other stories on the same topic on the HN frontpage.I am writing this for historians who wonder how important this event felt to the community. reply ghaff 17 hours agoparentI can pretty much assure you that this is not even on the radar of the vast majority of people, even in the US. This is mostly a tech bubble story. reply belter 17 hours agorootparentThe vast majority of those people have their job in peril by a GPT-5. And GPT-4 could already cover for at least 20% of them... reply reset2023 17 hours agoprevPlot twist: Maybe the Ai is turning them all against each other. reply pjs_ 17 hours agoprevThis deeply underestimates the messiness and chaos of real life. reply ycsux 17 hours agoprevUnintelligible on several dimensions, well done OpenAI! reply ycsux 17 hours agoprevUnintelligible on several dimensions, well done OpenAI! reply tboyd47 17 hours agoprevTheoryMicrosoft floated this offer to Altman for buku dollars before any of this takes placeAltman went to the board and requested a raise knowing he has a fantastic plan B.Board says no because they&#x27;re a non-profit.Altman gets petulant (as people my age tend to do).Old-school boomer \"You Work for Me\" elements of the board launch a bid to fire him. Their bid succeeds.Altman goes and blabs about his new gig to his old co-workers (as people my age tend to do).Microsoft says, \"Okay, more talent for us\" and extends offers for buku dollars to all OpenAI employees.Revolution! reply fprotthetarball 17 hours agoparent> I have a pet theory about the \"AI revolution\" or AGI that keeps getting relentlessly confirmed as events unfold: Microsoft sees a massive financial upside to this technology that no one else sees and this is being kept under wraps.If AGI is \"a highly autonomous system that outperforms humans at most economically valuable work\", I am Microsoft and have AGI, and other businesses do not, I am putting it charge of a Windows VM in Azure and offering it to companies to run aspects of their businesses. Why stop at \"GPTs\" if I can offer you specialized Clippys?Put all your data in Microsoft 365, let Clippy do its thing, and you&#x27;re saving a lot of money on not supporting people. Microsoft gets their cut, and you get to fire your employees. Win-win. reply numpad0 17 hours agoprevOnly explanation-slash-conspiracy-theory I could come up is from weak link between Ilya Sutskever and Elon Musk, that, in anxiety he could have had a call with Ilya that OpenAI could trigger that AGI clause to switch to vertical integration model, and that that would be a right thing to do as a ruling class individual, or some stupid advise in that direction.I&#x27;ll be more than happy to be readily dismissed. reply YetAnotherNick 17 hours agoprevThe weirdest thing is that everyone involved is just giving a random bit of information to the public, just enough for public to make bad inference. I have everyone tight lipped about anything like this or defend themselves in public and mention the facts.Also someone from OpenAI is leaking documents like this. Why not give more info to the press about the situation and what they know. reply qzw 17 hours agoprevWhen things don&#x27;t make sense, the question to ask is \"Who benefits?\" Seems pretty clear in this case. I have no inside knowledge at all, but it wouldn&#x27;t surprise me if the whole thing wasn&#x27;t as idiotic as it looks from the outside. reply nullc 17 hours agoprevIt doesn&#x27;t add up because everyone involved is deeply invested in concealing what \"Safe AGI\" and \"alignment\" actually means to the players and what sort of collateral damage they&#x27;ve rationalized is acceptable for achieving their objective. reply RecycledEle 16 hours agoprevWhat if a few of the people at the top of the AI companies believe that:1. Their company has or will soon have super intelligent AI.2. Humans can control that super intelligent AI.3. Whatever company comes up with super intelligent AI first can rule the human race forever.4. The leaders of that company will be the true rulers of mankind.5. It is beneficial for them to be those rulers.6. The smaller the club of rulers, the better.Then those few people might stage a very complicated coup to get other people out of the way (using AI.)None of those things have to be true. All that is necessary is for a few people at the top of an AI company to believe they are likely to be true.They might even use AI to silence people who understand what is going on.If there is anything to my hypothesis, then we should see constant low-key power shifts at the top of any company that is out in front designing the best AIs.Of course this is all conspiracy theory nonsense.We know the CIA and NSA have had this super intelligent AI for decades, and that&#x27;s how they rule the world. &#x2F;s reply tucnak 17 hours agoprevThe most surprising aspect of it all is complete lack of perceptible criticism towards US authorities! We were shown this exciting play as old as world itself— a genius scientist being politically exploited using some good old pride and envy. The brave board of \"totally independent\" NGO patriots, one of whom is referred to, by insiders, as wielding influence comparable to USAF colonel[1] who brand themselves as new regime that will return OpenAI to its former moral and ethical glory.The first thing they had to do, of course, was get rid of the greedy capitalist Altman; they were probably going to put in his place their nominal ideological leader Sutzkever, commonly referred to in various public communications as \"true believer\". What does he believe in? In the coming of literal superpower, and quite particular one at that; in this case we are talking about AGI. There is no denying that this is religious language, despite otherwise modern, technological setting. The belief structure here is remarkably interlinked across a whole network of well-connected and fast-growing startups. You can infer this from side-channel discourse re: adjacent \"believers\", see [2].Roughly speaking, and based from my experience, and please give me some leeway as English is not my native language, what I see is all the infallible markers of operative work; I can see security officers, their agents, as well as their methods of work. If you are a hammer, everything around you looks like a nail. If you are an officer in the Clandestine Service or any of the dozens of sections across counterintelligence function overseeing the IT sector, then you clearly understand that all these AI startups are, in fact, developing weapons & pose a direct threat to the strategic interests slash national security of the United States. The American security apparatus has a word they use to describe such elements: \"terrorist.\" I was taught to look up when assessing actions of the Americans, i.e. most often than not we&#x27;re expecting nothing except the highest level of professionalism, leadership, analytical prowess. I personally struggle to see how running parasitic virtual organisations in the middle of downtown SFO and re-shuffling agent networks in key AI enterprises as blatantly as we had seen over the weekend— is supposed to inspire confidence in US policy-making. Thus, in a tech startup in the middle of San Francisco, where it would seem there shouldn’t be any terrorists, or otherwise ideologues in orange rags, they sit on boards and stage palace coups. Horrible!I believe that US state-side counterintelligence shouldn&#x27;t meddle in natural business processes in the US, and instead make their policy on this stuff crystal clear using normal, legal means. Let&#x27;s put a stop to this soldier mindset where you fear any thing that you can&#x27;t understand. AI is not a weapon, and AI startups are not some terrorist cells for them to run.[1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38330819[2]: https:&#x2F;&#x2F;nitter.net&#x2F;jeremyphoward&#x2F;status&#x2F;1725712220955586899 reply calmoo 17 hours agoparentI don&#x27;t mean to be rude, and I know you said that English isn&#x27;t your native language, but paragraphs would go a long way to improving the readability of your thoughts. reply tucnak 17 hours agorootparentThank you, of course! reply say_it_as_it_is 17 hours agoprevExtreme progressive liberalism really doesn&#x27;t work reply say_it_as_it_is 17 hours agoprevProgressive liberalism really doesn&#x27;t work, does it.. reply skepticATX 17 hours agoprev [–] I sincerely hope that this is the end of the AGI cult. The people who actually want to build useful tools are now at Microsoft, and the cultists are left behind at OpenAI, which is not long for this earth. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary raises concerns about the lack of cohesion and questionable actions within OpenAI.",
      "It highlights the surprise of the board potentially ousting the CEO and the absence of checks on Microsoft's investment.",
      "Communication issues within the board are mentioned, along with questioning the alignment of goals and the decision to sell a significant portion to Microsoft."
    ],
    "commentSummary": [
      "The article explores the internal conflicts and controversies happening at OpenAI, focusing on the motivations of the board members and Microsoft's potential influence.",
      "Speculation around power struggles, conspiracy theories, and the implications for OpenAI's future are discussed.",
      "The broader implications of AI development, corporate maneuvers, and control of artificial general intelligence are also examined, sparking various opinions and theories about the situation at OpenAI and its potential consequences."
    ],
    "points": 275,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1700495342
  }
]
