[
  {
    "id": 37825292,
    "title": "John Riccitiello steps down as CEO of Unity",
    "originLink": "https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/",
    "originBody": "Skip to main content Events Video Special Issues Jobs Subscribe Game Development Metaverse Gaming Hardware Gaming Business Latest Games & Reviews John Riccitiello steps down as CEO of Unity after pricing battle Dean Takahashi @deantak October 9, 2023 1:37 PM John Riccitiello, CEO of Unity Technologies. Image Credit: Dean Takahashi GamesBeat Next unites gaming industry leaders for exceptional content, networking, and deal-making opportunities. Join us on Oct 23-24 in San Francisco. Register Now John Riccitiello, CEO of Unity, has resigned from the company in the wake of a pricing controversy that left developers in open revolt. Unity said in a press release that James M. Whitehurst has been appointed interim CEO and president of the company. How human-centered design drives data-driven experiences In today’s competitive market 692.9K 33 Play Video Ad: (1:38) 4 Meanwhile, hoping to avoid a stock panic, Unity said that it is reaffirming its previous guidance for its fiscal third quarter financial results, which will be reported on November 9. Roelof Botha, lead independent director of the Unity board, has been appointed chairman. Riccitiello will continue to advise Unity to ensure a smooth transition, the company said. The news isn’t a surprise as Unity angered a lot of its loyal game developers a few weeks ago after pushing through a price increase based on numbers of downloads — and then retracted it after an uproar. EVENT GamesBeat Next 2023 Join the GamesBeat community in San Francisco this October 23-24. You’ll hear from the brightest minds within the gaming industry on latest developments and their take on the future of gaming. Learn More Unity said the board will initiate a comprehensive search process, with the assistance of a leading executive search firm, to identify a permanent CEO. ADVERTISEMENT “Working with Unity under John’s leadership has been one of the highlights of my career. John joined the Unity Board in 2013 and stepped in to lead the company in 2014, at a time when we faced significant challenges,” Botha said, in a statement. “John has led Unity through incredible growth over the last nearly 10 years, helping us transition from a perpetual license to a subscription model, enabling developers to monetize, building other game services to serve our creator community, leading us through an IPO and positioning us as a pioneer in the developer community. Unity would not be where it is today without the impact of his contributions. I remain excited for the future of Unity.” “It’s been a privilege to lead Unity for nearly a decade and serve our employees, customers, developers and partners, all of whom have been instrumental to the company’s growth,” Riccitiello said in a statement. “I look forward to supporting Unity through this transition and following the company’s future success.” ADVERTISEMENT Whitehurst is a seasoned technology and public company executive. He previously served as senior advisor and president at IBM, after joining through IBM’s acquisition of Red Hat, a leading provider of open-source enterprise IT products and services, where he served as president and CEO from 2008 to 2020. “I am honored to join Unity as interim CEO and President at this important time in its evolution,” Whitehurst said in a statement. “With the company’s experienced leadership and passionate employees, I am confident that Unity is well-positioned to continue enhancing its platform, strengthening its community of customers, developers and partners, and focusing on its growth and profitability goals. I look forward to working closely with the Board and our talented global team to execute on our strategy, and I anticipate a seamless transition.” Unity will release third quarter 2023 financial results after the market close on Thursday, November 9, 2023, with a webcast to follow at 2 p.m. PT. GamesBeat's creed when covering the game industry is \"where passion meets business.\" What does this mean? We want to tell you how the news matters to you -- not just as a decision-maker at a game studio, but also as a fan of games. Whether you read our articles, listen to our podcasts, or watch our videos, GamesBeat will help you learn about the industry and enjoy engaging with it. Discover our Briefings. Join the GamesBeat community! Enjoy access to special events, private newsletters and more. Join here GamesBeat Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat. All rights reserved. Want must-read news straight to your inbox? Sign up for GB Daily View Newsletters",
    "commentLink": "https://news.ycombinator.com/item?id=37825292",
    "commentBody": "John Riccitiello steps down as CEO of UnityHacker NewspastloginJohn Riccitiello steps down as CEO of Unity (venturebeat.com) 866 points by AndrewKemendo 19 hours ago| hidepastfavorite401 comments cojo 18 hours agoI have to say, the only thing more surprising to me than seeing the board actually hold Riccitiello responsible for this (with consequences) is seeing that their interim replacement &#x2F; transitional CEO is someone with a pedigree that, on the surface, seems even more management consulting &#x2F; investor &#x2F; revenue focused than Riccitiello was himself.To be clear, I know essentially nothing about James M. Whitehurst other than what is readily publicly available (IBM &#x2F; Red Hat, advisory roles, etc.).But my read on a lot of the Unity crisis, as a long-time game industry veteran myself, was that one of the increasingly common \"management consulting\" &#x2F; investor- & revenue-focused type of gaming executives (e.g. Riccitiello, Don Mattrick [Zynga replacement CEO when Pincus stepped down], Kotick [Activision-Blizzard]) had finally overstepped their bounds and let revenue goals drive decision-making just a bit too far without customer consideration.So, I had assumed that if Unity did make a leadership change here, it would be in a direction away from that - i.e. a more industry-seasoned executive with less of a pure revenue &#x2F; \"business\" focus.I think I clearly misjudged the situation here in light the Whitehurst pick; while it&#x27;s possible that is truly just an interim role and they will still pivot to this in the final hire, or that I simply misjudge \"the label on the tin\" and Whitehurst is very culture &#x2F; customer focused, I don&#x27;t think I would bet on it. This seems like the board actually \"doubling down\" on driving revenue results - and fast. reply airstrike 18 hours agoparentInterim CEOs generally tend to be either a board member or a C-level executive that take on the role just to manage day-to-day CEO duties while the board searches for a more permanent replacement.In this particular instance, Whitehurst isn&#x27;t a board member, but per the press release[0] he is a \"Special Advisor at Silver Lake\". Silver Lake is one of Unity&#x27;s largest shareholders (~10%) and Egon Durban is on the board.EDIT: Also worth noting Silver Lake, along with Sequoia, committed an additional $1Bn into Unity at the time of the IronSource acquisition in the form of convertible notes with a conversion price of $48.89 &#x2F; share[1], which is at a slight premium to the price at which Unity&#x27;s stock traded then (7&#x2F;15&#x2F;2022) and at a meaningful discount to their current share price of $29.70 -- which supports the (admittedly speculative) argument that SLP&#x27;s voice on that particular board is all the more prevalent today.——————————[0]: https:&#x2F;&#x2F;www.businesswire.com&#x2F;news&#x2F;home&#x2F;20231009494331&#x2F;en&#x2F;Uni... [1]: https:&#x2F;&#x2F;investors.unity.com&#x2F;news&#x2F;news-details&#x2F;2022&#x2F;Unity-Ann... reply Spoom 17 hours agorootparentAh, Silver Lake, of Skype acquisition and zeroing-out employee equity fame.https:&#x2F;&#x2F;www.wired.com&#x2F;2011&#x2F;06&#x2F;skype-silver-lake-evil&#x2F; reply hedora 13 hours agorootparentI didn’t realize they screwed over some of the execs by zeroing out options.The night before the same transaction, they issued a pile of diluting shares to themselves, effectively clawing back something like 50% of the rank and file employees’ stock options.I might have the date and percentage wrong, but it doesn’t really matter.Silver Lake are total bastards and probably belong in jail. Avoid. reply hyperhopper 9 hours agorootparentI thought stocks represented ownership of a company. If a company has 100 stocks and I own 50, I own 50% of the company. If the company issues 100 more, shouldn&#x27;t 50% go to me, since a share represents a part of the company ownership and I own a known percentage of the company?How is it legal to say \"you bought 50% of this, but now I&#x27;ve arbitrary decided that I own 99% of it because I gave myself more percent\" reply davedx 9 hours agorootparentNothing on paper says \"You own 50% of the company\".The company starts up, it has 100 shares, you get 50. If you calculate it, you own 50%.Later on the company needs to raise cash, so it issues another 100 shares. Company now has a ton of cash in the bank. Total shares outstanding is 200. Now you own 25%. reply hyperhopper 8 hours agorootparentThen whats the point of buying a stock if it doesn&#x27;t even entitle you to ownership of a company? reply rwmj 7 hours agorootparentAt least in theory the extra cash raised by selling the new stock makes the company more valuable, so your shares remain worth the same before and after. Actual practice is a lot more nuanced - the company might not be able to sell the new stock at a high enough price, or they might spend the new money immediately on hookers&#x27;n&#x27;blow^W^W^W unsound investments. reply PawgerZ 1 hour agorootparentwhat does ^W^W^W mean reply badosu 52 minutes agorootparentRemove previous word reply sorenbs 6 hours agorootparentprevIt sounds like you are thinking of publicly listed companies which have to adhere to strict regulation, much different from privately held companies.Even then, there are no guarantees. A company can simply be mismanaged and overvalued as we saw recently with this Danish airline: https:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;scandinavian-airlines-air-francek... reply filleokus 8 hours agorootparentprevDepending on the company bylaws you typically need at least a simple majority of the votes &#x2F; stocks to issue new stocks. The company can also have a rule that says that existing share owners must have the right to purchase before everyone else, to \"defend\" their stake.In general companies typically raise money because they think the cash infusion will benefit the existing shareholders in the long run, either by not going into ≈bankruptcy or having the cash to do investments &#x2F; move into new markets etc. reply swexbe 4 hours agorootparentprevNow you own a smaller part of a more valuable company, given the the money is well spent. Your net worth shouldn&#x27;t change much.Either way, if you had a majority of the voting shares, you could&#x27;ve stopped the issue. reply toyg 6 hours agorootparentprevShares do not imply ownership but participation. That participation can take different shapes, depending on the type of shares and the bylaws of the company: some will be entitled to dividends, some will be entitled to voting on decisions, some will entitle to a form of ownership, etc etc. reply abofh 8 hours agorootparentprevIt does entitle you to ownership, you as an investor in the company presumably approved the issuance of new shares on the belief that the additional capital would make your investment worth more in the future. reply folli 8 hours agorootparentprevThere&#x27;s for example non-voting stock where you only participate in a potential exit or dividends. reply denton-scratch 6 hours agorootparentprevI thought that if the company is issuing new shares, it was customary to give first refusal to existing investors (a \"rights issue\"?) reply PeterisP 4 hours agorootparentThere may be a preexisting contract between investors that grants this right of first refusal. In some scenarios (e.g. startup seed rounds) it is customary to require such a contract as part of the investment deal, however, if you don&#x27;t contract for this right you don&#x27;t have it, and it may well be that some shareholders (e.g. investors) have this right and other shareholders (e.g. initial employees) don&#x27;t. reply reactordev 1 hour agorootparentprevEntirely up to the company. reply smugma 2 hours agorootparentprevConversely companies can buy back shares so each share is a larger percentage of the company.Apple has been doing this aggressively for the past 10+ years. reply batmansmk 9 hours agorootparentprevYou can bring in investors, go in retirement, sell your company. So ownership of a company can change. One way of doing that is to sell shares, another way is to give new ones to the newcomers. I don’t know this precise story with Silver Lake, but emitting new shares and diluting past investors to inject cash into the company is sometimes the only solution to bring cash on the account. reply LtdJorge 9 hours agorootparentprevYou can always create more stocks, but that delays the value of each, so investors might not like that. reply prerok 8 hours agorootparentdelays -> devalues, dilutes? reply aitchnyu 9 hours agorootparentprevUmm, is this still consequence free in USA? reply K0balt 4 hours agorootparentYes. reply raffraffraff 9 hours agorootparentprevSilver Lake (along with Qualtrics founder Ryan Smith) bought Qualtrics after a dizzying sequence of planned IPO, acquisition by SAP, and then IPO. They&#x27;re busily evicerating it, having just announced their second big round of layoffs, and apparently there gonna be even more job losses next March. Everyone I know there is planning their escape. What&#x27;s hilarious is that this round of layoffs has impacted their ability to deliver on a major internal project because a key player was canned, so the project is now in hold (again).I wonder how many of these $$$ people are looking at Musk and saying, &#x27;hold on, we could do that too&#x27;. It&#x27;s amazing how resilient a company can be to code rot and infrastructure stagnation. It takes a long time to kill a company, once it has a customer base and decent revenue streams. You could probably fire everybody outside strictly operational teams and simply coast along on the momentum for a few years, creaming off gigantic profits. And what the hell, jack up your prices too, right? reply kasey_junk 3 hours agorootparentMusks takeover of Twitter is not a particularly compelling example of this model. In a year he’s cut revenue by 40% (with every month trending worse than the last), not made it cash flow positive even with massive cuts, and is burdened it with tons of debt while making it worth much less. Twitter may turn around but right now I can’t imagine corporate raiders are looking at it as a positive example.https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;elon-musk-says-twitters-c....https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;us-ad-revenue-musks-x-dec... reply michaelt 2 hours agorootparentWell, Musk did several things in close succession.Sure, he scared off advertisers by welcoming nazis onto the platform. That&#x27;s not something you&#x27;d want to replicate.But he also fired 80% of the workforce, and the product kept working. If you have some subscription software where users keep paying $$$$ whether you add new features or not - getting rid of 80% of those expensive developers could be pretty tempting. reply kasey_junk 2 hours agorootparentThis is an extremely common private equity playbook, that hasn’t seen as wide adoption in software as it has in other industries because there is a presumption that software clients aren’t particularly sticky and the software space allows faster innovation. Twitter is a story that confirms that bias (so far).I think Unity is the next big test case. If users leave the platform in droves and revenue tanks it will continue to confirm the current hypotheses. That said private equity firms will keep trying it no matter what as the market biases make it an easier space to compete so I’m not sure it matters much to software companies. reply michaelt 1 hour agorootparentEh, software can be pretty sticky if your users have lots of files in your proprietary format nobody else can read.A company that uses Photoshop, or Altium, or SolidWorks, isn&#x27;t going to move off it easily. Hell, existing users will often initially be thankful when product managers stop moving the buttons every 6 months.Of course you&#x27;ll stop attracting new customers as your product gets surpassed - but there could be a lot of $$$$ to be extracted before revenue drops to zero. reply yndoendo 26 minutes agorootparentI would argue that much of Microsoft is built around legacy applications and code that prevents moving to alternative solutions. A lot of companies do not want to spend the time and money to pivot, not have the labor to do so. The true tech debt is a hidden cost where change is a visible cost. replyMaster_Odin 2 hours agorootparentprevPrivate equity firms are already an absolute blight even before Musk&#x27;s handling of Twitter. I&#x27;ve seen plenty of companies get purchased, completely gutted and then they try to extract maximum value from customers as quickly as possible before all customers abandon ship as the product(s) fall apart. They truly are scum. reply Mengkudulangsat 16 hours agorootparentprevSilver Lake being one of Unity&#x27;s largest shareholders explains their recent behavior perfectly. It&#x27;s a private equity firm whose sole concern is squeezing blood out of a rock. reply bdw5204 10 hours agorootparentThat&#x27;s basically the reputation of a significant number of private equity firms. Their standard operating procedure is to load the company up with debt, cut R&D, cut investment into the product, cut wages and raise prices to increase short-term profits while pretending you&#x27;re trying to turn around the company and save it. That&#x27;s basically why Sears and K-Mart don&#x27;t exist anymore[0] and why so many newspapers fired their journalists and replaced most of the local news with national news from the wire services[1].[0]: https:&#x2F;&#x2F;www.cnn.com&#x2F;2018&#x2F;10&#x2F;16&#x2F;investing&#x2F;retail-sears-privat...[1]: https:&#x2F;&#x2F;www.stern.nyu.edu&#x2F;experience-stern&#x2F;faculty-research&#x2F;... reply c420 9 hours agorootparentSounds like Twitter. reply xNeil 4 hours agorootparentEverything except short-term profits. X seems decently focused on the long term, especially with subscriptions being introduced as a (new) revenue stream.Also not sure about R&D, as I don&#x27;t know what R&D Twitter was doing pre-acquisition, but there&#x27;s been an extraordinary increase in the rate of addition of new features and changes to the platform. reply flarg 7 hours agorootparentprevElon&#x27;s Twitter acquisition was exactly to do that but he muffed it. reply 3seashells 10 hours agorootparentprevAccidentally funny namehttps:&#x2F;&#x2F;de.m.wikipedia.org&#x2F;wiki&#x2F;Silbersee_(Bitterfeld) reply cojo 18 hours agorootparentprevThis is helpful context as well, in addition to doomlaser&#x27;s explanation of his background re: IBM and Red Hat. Thanks for sharing it.I wonder to what extent Silver Lake drove this overall decision (vs. others on the board potentially initiating it) reply gmerc 10 hours agorootparentprevIt confirms the concern. The board broad on someone to look after the needs of the largest shareholder reply 1-6 17 hours agorootparentprevThe most famous Interim CEO was Steve Jobs. reply readyplayernull 17 hours agorootparentHe was also employee #2 and #0 at the same time, so Quantum CEO? reply tanseydavid 14 hours agorootparentHe also aggressively recruited and hired the guy (Sculley) that got him fired from Apple on the first pass. reply Tomte 10 hours agorootparentI&#x27;ve read Sculley&#x27;s book as a teenager and I remember that it made a big impression on me, even though I don&#x27;t remember much. I think the PepsiCo part was really gripping. reply raverbashing 11 hours agorootparentprevAmateur move on his part, hiring an &#x27;MBA head&#x27; CEO reply antupis 8 hours agorootparentTim Cook is also MBA and it looks like it is working fine for Apple. reply m463 8 hours agorootparentI think he&#x27;s good at operations. But he doesn&#x27;t lead the same way jobs did. apple can still turn the crank, but I don&#x27;t think they innovate like when sj was around. Jobs worked with the outside world well, and cooperating well with the rest of silicon valley.I think apple is now heavily navel-gazing. Their products point inwards into their ecosystem, they don&#x27;t interoperate, the customer is trapped, they have few choices. maybe I should say egosystem? reply robbie-c 3 hours agorootparent> I don&#x27;t think they innovate like when sj was aroundI would have agreed with this before the M1 Macbooks came out, but when it did it caused a big change in my opinion. reply raverbashing 8 hours agorootparentprevYes but he spent a lot of time inside Apple and grew within itThe problems you have selling sugar water are not the same problems that Apple has today (or since Cook moved into the post). reply antupis 4 hours agorootparentyeah I know but issue is not MBA it is what kinda culture you come and where you are good. Selling sugar water (you need to be like super good at marketing) and leading tech firm need different skills. replyHillRat 17 hours agoparentprevI&#x27;d argue that what Unity needs is someone who&#x27;s got a background in enterprise software, because selling to game developers is very different than selling games. No one with (successful) executive experience in enterprise software would have signed off on Unity&#x27;s original revenue plan, simply because the number one rule in enterprise is \"don&#x27;t fuck with the customer&#x27;s business model,\" which the \"pay per download\" model certainly did. Hiring a game industry CEO who pioneered predatory monetization models and was responsible for horrifying managerial practices within and between studios was a terrible choice for Unity, and his evident contempt for developers showed through often.Whitehurst, on the other hand, has a history of strong execution across multiple industries, and built a reputation as someone who protected Red Hat&#x27;s culture against attempts from within IBM to \"Big Blueify\" it (possibly to the detriment of his own role within IBM). Even as an interim, having him onboard is a good sign for how Unity is looking to repair its relationships with developers. reply johnnyAghands 14 hours agorootparent> Whitehurst, on the other hand, has a history of strong execution across multiple industries, and built a reputation as someone who protected Red Hat&#x27;s culture against attempts from within IBM to \"Big Blueify\" it (possibly to the detriment of his own role within IBM). Even as an interim, having him onboard is a good sign for how Unity is looking to repair its relationships with developers.100%I was at IBM at the time. We really hoped he would eventually take over from Ginni once she left... nope. We really could have used someone who wasn&#x27;t drinking the blue koolaid. Well.. the rest is history.All this other crap about Silver Lake being a giant POS is concerning though. reply bonzini 1 hour agorootparentArvind Krishna seems like a pretty cool guy though, and definitely has engineering background.It&#x27;s interesting that everybody focuses on Red Hat after acquisition but no one ever asks how IBM is doing now. Maybe it&#x27;s delusional to think that Red Hat could change something of its new overlord, but perhaps the acquisition was already showing the desire to change IBM from within? reply Talanes 8 hours agorootparentprev“When you are six hours into playing Battlefield and you run out of ammo in your clip and we ask you for a dollar to reload, you’re really not that price sensitive at that point in time\" - John RiccitielloAmazing that he could so correctly identify why price-blinding tactics would work on people trying to have fun, but not do the inverse and see why it wouldn&#x27;t work on people trying to develop a product. reply qwery 7 hours agorootparentprevYou&#x27;re right that selling a game engine is more an enterprise software business than game publisher, but Unity isn&#x27;t trying to be a software company at this point, they&#x27;re an ads and analytics service company, maybe doing a &#x27;big tech&#x27; cosplay. reply doctorpangloss 17 hours agorootparentprev> simply because the number one rule in enterprise is \"don&#x27;t fuck with the customer&#x27;s business model,\"On the other hand, the continued growth of gaming revenues, for both developers and services providers, compared to all other creative industries, is all attributable to innovations in business models. I suppose if people rocked the boat as little as you suggest, the only software being sold to game developers would be Denuvo. reply lolinder 15 hours agorootparentYou&#x27;re making the exact mistake that OP warned against at the beginning: \"selling to game developers is very different than selling games\".Even game studios can&#x27;t just change things willy nilly. If Baldur&#x27;s Gate 3 had been a microtransaction-funded F2P game, it would have been a flop—their target player base doesn&#x27;t like that business model and wouldn&#x27;t have gone for it. It&#x27;s better to try out a new model with a brand new franchise than to try to pivot an existing franchise.Enterprise software has these same constraints and more, because monkeying with the business model doesn&#x27;t just mildly irritate prospective customers, it can and does throw off years of planning for thousands of people per company. They can&#x27;t just shrug and decide to not invest in the next installment in your game franchise, they have to re-do their corporation&#x27;s 5- and 10-year plans. reply HillRat 14 hours agorootparent[M]onkeying with the business model doesn&#x27;t just mildly irritate prospective customers, it can and does throw off years of planning for thousands of people per company.This, very much so. Unity made two cardinal sins: creating a pricing model that didn&#x27;t align with customers&#x27; business models (tying price to downloads rather than revenue), and then attempting to apply it retroactively to existing contracts (which, at best, would have resulted in high-profile and ugly legal battles against their largest customers and, likely, would have ended in a judge slapping their lawyers around with a copy of Williams v. Walker-Thomas).In both cases, creating business model risk and uncertainty drove developers towards other software choices, not because developers are opposed to Unity asking for an engine license fee (after all, they already incorporate console fees, app store fees, etc. into their business models), but because Unity created financial uncertainty: they couldn&#x27;t forecast those fees with decent probability and precision, and because they no longer trusted Unity not to try to retroactively screw them years down the road. Unity fixed the first problem, but now they&#x27;ve got to work to win back trust on the second. reply Qwertious 9 hours agorootparent>Unity made two cardinal sins: creating a pricing model that didn&#x27;t align with customers&#x27; business models (tying price to downloads rather than revenue)Everyone is assuming the majority of Unity&#x27;s customers (\"most\" as measured by $$$, not by quantity of devs) aren&#x27;t F2P games. I&#x27;m not sure that&#x27;s actually the case; if most of their revenue comes from F2P then shafting everyone else in order to shore up their F2P business would likely be the correct business decision. reply grotorea 3 hours agorootparentI&#x27;m not sure I follow. Aren&#x27;t F2P games most misaligned with pricing per download since that means they end up with a bunch of negative value consumers and complete uncertainty whether they will end up with a positive or negative balance since they can&#x27;t know much they will expend?The traditional game developers can just go \"Unity takes 1$ per download (or whatever), the average player downloads 3 times, the game costs 10$, 3$ goes to the storefront, so we have am average profit of 4$\", which seems simple enough to deal with to me. reply philipov 13 hours agorootparentprevThanks for introducing me to Williams v Walker-Thomas. In the ocean of Paywalled Law School Study Guide SEO, I can&#x27;t find anywhere that tells the last chapter of the story. In light of Wright&#x27;s decision, how did the lower court finally rule? After being given permission, did they actually follow through and throw out the contract? reply gmerc 10 hours agorootparentIt seems obscure, you’d probably have to pay for the records.https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;537dd325-1c5c-422b-8b4a-a44852... reply gmerc 10 hours agorootparentprevRiccitello is the poster boy for failing this lesson:- Dungeon keeper mobile - Ultima Forever reply johnnyanmac 13 hours agorootparentprev>st change things willy nilly. If Baldur&#x27;s Gate 3 had been a microtransaction-funded F2P game, it would have been a flopHot take, but I think it would have been fine financially. Would the online consumers and even media drag it through the mud? Definitely. But I reckon console gamers have less than a 10% chance in correctly predicting some f2p model would crash and burn.Now I can&#x27;t say if it&#x27;d be more profitable than selling as premium, because it didn&#x27;t target mobile and that is the real market for that monetization. But I doubt it would have crashed. reply qwytw 9 hours agorootparentIt would&#x27;ve had to have been an extremely different game though. F2P P2W shovelware games are designed as such from the ground up. You can&#x27;t just add micro-transactions to a normal (especially story driven) game and hope to make significant amounts of money. reply InSteady 16 hours agorootparentprevSomething tells me there is a fair bit of wiggleroom on the line between \"no innovation whatsoever\" and \"making a large number of my customers situation untenable.\" I think innovation will continue just fine. Disrupting a business model is not the same as selling software to people under terms that are obviously and immediately harmful. Unless you are really clever and they are really dumb, I guess. reply jzb 18 hours agoparentprevI was at Red Hat while Jim was CEO. He’s very culture focused and is an excellent choice for restoring faith there. He got great results while at Red Hat, but they plucked him out for a non-CEO role at IBM after the acquisition. IMO that has been IBMs greatest sin in its handling of Red Hat.Jim was active on memo-list and seemed to listen to people. That doesn’t mean he’s perfect, but I’d give him very high marks and I think that he had a lot of goodwill among Red Hatters as CEO. reply linuxftw 17 hours agorootparentI also worked under Jim. He managed to under perform the rest of the tech sector by an order of magnitude. He completely mismanaged the company with regards to the virtualization boom, just compare VMWare&#x27;s revenues to Red Hat&#x27;s. Red Hat OpenStack was and is an absolute awful product all the way around.What Jim did do successfully is destroy the actual FOSS spirit within the company. Everyone has Mac Books now. All the standard corporate welfare initiatives for liberal arts majors (Chief Diversity Officer and their ilk). reply eraser215 17 hours agorootparentAlmost everything you said here is complete garbage.Underperform the rest of the tech sector? No... 70+ quarters of successive double digit growth until the acquisition.Mismanaged the company with respect to virtualisation? You&#x27;re conflating mismanaging the company with possible strategic errors in virtualisation.Destroy FOSS spirit? Absolutely the opposite. He is held in the highest esteem by every red hatter I have ever spoken to. Not only that, but he made the effort to do red hat training to learn the tech in the early days. How has he destroyed any FOSS spirit through his actions? Give an example.Everyone has macbooks now? No. Sellers generally do, I&#x27;ll give you that, but technical staff are mostly using Fedora or RHEL. Flexibility has always been a huge part of the employee experience.Standard corporate welfare initiatives for liberal arts majors? You sound like an angry white man who can&#x27;t stand that people other than yourself may have their disadvantage recognised nowadays. Stop feeling so threatened.Why are you so bitter? reply dralley 16 hours agorootparent\"The sector\" is also a bit of an apples&#x2F;oranges situation. There are very, very, very few if any pure-play open source software companies that are as successful as Red Hat. reply eraser215 14 hours agorootparentGood point. In pure play OSS nobody has come close, for sure. My understanding is that the only other software company that had the same sustained growth trend was salesforce. Could be wrong though. reply linuxftw 16 hours agorootparentprevThere are a lot of Jim kool-aide drinkers, there&#x27;s no doubt about that. And the faithful diligently applauded him selling the company to IBM.A lot of people felt betrayed when they switched to gmail. Those voices were all shouted down.Jim turned a $1T opportunity into a $30B one. reply jzb 14 hours agorootparentJim did not sell the company to IBM. It was not Jim&#x27;s to sell. Jim received an offer from IBM which he conveyed to the board, which put it in front of shareholders, and shareholders accepted the offer. To the tune of 99.5% of shareholders who voted (about 80% of shares cast votes...). [1]Some people were pissed about switching to Gmail. They were not anything close to a majority of users.It&#x27;s fine that you don&#x27;t share a positive opinion of Jim&#x27;s tenure as CEO, but the commentary that shows ignorance of how public companies work, petty gripes about switching to Gmail (as if that was Jim&#x27;s personal project) and grudge-holding about diversity doesn&#x27;t paint you as someone to take seriously.[1] https:&#x2F;&#x2F;www.lightreading.com&#x2F;virtualization&#x2F;red-hat-sharehol... reply linuxftw 13 hours agorootparentI&#x27;m aware of how the acquisition took place. And 80% of shares would have been mostly institutional investors. I think we all know that Jim and the board were actively soliciting buy outs. What individual do you think pocketed the most money from that sale? That&#x27;s right, Jim. He was paid handsomely to prevent a riot from breaking out after the merger.> They were not anything close to a majority of users.You&#x27;re making my point for me. Jim destroyed the actual spirit of FOSS at Red Hat. It transformed into \"Everything we distribute is open source, and that&#x27;s all we care about.\" The GPL has been all but abandoned in favor of non copy-left licenses. reply jzb 3 hours agorootparent\"I&#x27;m aware of how the acquisition took place.\"Are you? Because your comments don&#x27;t reflect that. \"We all\" don&#x27;t \"know\" that, actually. Maybe they were, but as I understand it IBM&#x27;s bid was unsolicited.Do you have a citation for the claim Jim \"pocketed the most money\" from the sale? I am sure he made plenty, but so did the other execs, so did the shareholders -- the sale price was quite a premium on the share price.Red Hat was a public company. Too many people have magical thinking about how Red Hat&#x27;s execs should&#x27;ve run the company according to their ideals when the reality is if Jim ran the company the way you&#x27;d have liked it would&#x27;ve probably triggered an investor lawsuit.If you want ideological purity to the satisfaction of your FOSS standards, then working for a public company is a path to unhappiness every time.I didn&#x27;t agree with every choice made by Jim and the rest of Red Hat&#x27;s leadership at the time -- but he was a decent CEO within the parameters allowed for public company CEOs. reply linuxftw 2 hours agorootparent> I didn&#x27;t agree with every choice made by Jim and the rest of Red Hat&#x27;s leadership at the time -- but he was a decent CEO within the parameters allowed for public company CEOs.That&#x27;s the prevailing opinion. It&#x27;s safe to have. IMO, he&#x27;s just an empty suit that peddles kool-aid. Red Hat was in a unique position as the top kernel contributor for a long time, meanwhile VMware, Google (android), and AWS ate up all the value. reply eraser215 13 hours agorootparentprevUnfortunately the person you replied to is one of these people for whom facts are a mostly ignorable obstacle when wanting to maintain some misplaced outrage. reply kortilla 7 hours agorootparentBoth of your comments are personal attacks.“Bitter”“White man”“Facts are a mostly ignorable obstacle”Please review the guidelines and save the clap trap for reddit. reply ummonk 13 hours agorootparentprevIf you think Red Hat was a $1T opportunity then you’re the one drinking the koolaid. reply DonHopkins 3 hours agorootparentprev>You sound like an angry white man who can&#x27;t stand that people other than yourself may have their disadvantage recognised nowadays.That&#x27;s exactly what he meant to communicate by using the traditional angry white man shibboleth of shaking his furious fist at the \"Chief Diversity Officer and their ilk\" who are active out to get him and ruin his life by making it impossible for him to get a job. Life is just so difficult for him with his anti-diversity disability, you can understand why he feels so angry and threatened and acts out like a toddler in this way. reply phpisthebest 15 hours agorootparentprev>>He is held in the highest esteem by every red hatterSince \"red hatters\" believe they \"are open source\" and have turned their backs on the community (see the CentOS changes and the active attacks on Rocky Linux) dont know \"red hatters\" opinion carry much weight in FOSS these days.Red hatters certainly have an the ego to believe only their opinion matters but reality often does not match egoTo me, I hope I never have to use another software product from RedHat again... I dont know if IBM killed RedHat, or if RedHat just reviled their true colors... either way RedHat is no friend to FOSS, they are just another corporate software company attempting to control FOSS not contributing freely to it.To me in this day, Oracle is better steward of Linux that RedHat is. reply eraser215 14 hours agorootparentYour final sentence proves just how little you understand about FOSS. Thanks for making it easy. reply phpisthebest 14 hours agorootparentI did not say Oracle was better steward of FOSS, what they did do their other FOSS projects is like what Red Hat is doing to RHELRed Hat and Oracle are more or less the same nowBut when it comes to Oracle Linux, atleast they are not putting the sources behind the paywall and threatening customers with bans if they follow their GPL Rights reply dralley 14 hours agorootparentA) There have been no \"threats\" towards anyone much less customers. There was a lot of discussion taking place here and in other places about what was theoretically possible as per license agreement, but no \"threats\".B) Oracle cannot be described as a \"steward\" if their entire goal is to produce a RHEL clone using the sources provided by Red Hat. Oracle \"stewards\" a kernel package themselves, but that&#x27;s about it. The explicit goal of their distribution is to cede the bulk of the decisionmaking to Red Hat and be \"compatible\".C) \"The sources\" are not behind a paywall. CentOS Stream is \"the sources\". The only difference between now and 6 months ago is that it used to be the case that the specfiles for every package in the distro were maintained in a single publicly facing git repository which made it trivial to rebuild the entire distro, whereas now you would have to create a mapping of which exactly CentOS Stream packages were used first, which is not as straightforward as having it all in one place. It is nonetheless possible to do. It&#x27;s probably fair to call it an obfuscation technique, but not fair to call it closed source, because it isn&#x27;t. replyNegativeK 17 hours agorootparentprev> Everyone has Mac Books now.I don&#x27;t even work there and I know that this is, at the least, hyperbole. reply dralley 17 hours agorootparentI do work there and it&#x27;s total BS, certainly as far as engineering goes. Maybe in marketing &#x2F; sales &#x2F; HR the story is different, but the overwhelming majority of engineering, support and QE (including the management chain) use Thinkpads with Fedora or RHEL. reply reactordev 17 hours agoparentprevIf anyone can save the stinking ship that is Unity, it’s Whitehurst.This is said by someone who wants nothing more than to see Unity die.Whitehurst was pretty instrumental in getting Red Hat sticky in places where it was just RHEL. Open Shift, Open Stack, etc all drove value-add for the business and for their customers. Cloud is fickle though so selling tools to studios and trying to compete with Unreal in the VFX space is how Unity moves forward. Take your lashings from the game devs. Shore up your presence in VFX, Movies, Film. Evolve.The tsunami has squarely landed on Godot’s doorstep. It will be up to them on how they manage the swell. reply georgeecollins 16 hours agorootparentI wouldn&#x27;t call Unity a sinking ship. It&#x27;s the overwhelming choice of game engines in the mobile market. Raising prices is unpopular and may decrease their share of the market. But there is no way Unity is going away anytime soon.And I love Godot -- love it-- but it doesn&#x27;t do all the things Unity does. Even if it did, it would take years to get all the teams to switch. Think how long it took people to move away from Flash! reply gmerc 10 hours agorootparentYou underestimate the game industry I think. It constantly invalidates its own technology every 2-3 years and is extremely sensitive to business model risks. reply qwytw 9 hours agorootparent> It constantly invalidates its own technology every 2-3 yearsI&#x27;m not sure about that. Unity itself is not at all a particularly modern engine (just like most engines being iterations of something designed in the 00s or early 10s) reply gmerc 4 hours agorootparentRule of thumb in AAA: After 3 years devtime you are starting to pay serious debts by tech updates - that’s the descent into development hell. reply reactordev 3 hours agorootparentThis. It’s easy to criticize or idolize from the outside. When you’re in it, any time spent beyond innovating is wasted R&D. It might be justified. It probably isn’t. This is one of the main reasons Unreal went open source. Let the community drive R&D on their own dime. replyairstrike 17 hours agorootparentprevRedHat customers and Unity customers make for two very different types of beasts...It will be interesting to see how his Whitehurst&#x27;s pedigree translates to this smaller-scale, higher-touch sales motion.Forgoing the core Unity audience of game developers and gunning for studios &#x2F; VFX when Unity is clearly not the graphically superior engine sounds risky at best, reckless at worst. reply reactordev 17 hours agorootparent>”RedHat customers and Unity customers make for two very different types of beasts...”You misunderstand. They have different verticals but Jim’s mission is the same. Sell them tools at enterprise subscription prices. Per seat, per project, per shot if they can. Forget the indie game devs and their small studios. That bridge is burned beyond recognition or reconciliation. reply anonylizard 15 hours agorootparentThe problem is that in gaming, its often the indie studios that are the most profitable. They may have only 10 staff, but easily make 50 mil a year. Traditional industries rarely have such lopsided staff&#x2F;revenue ratios.And small indies may transform into large enterprises surprisingly fast. Mihoyo was a small indie only 10 years ago.Its much much easier to repair bridges with indies, who don&#x27;t really want to move off unity as much as you think, and can be placated by backpedaling and the CEO replacement. reply qwytw 9 hours agorootparent> They may have only 10 staff, but easily make 50 mil a yearConsidering Unity&#x27;s previous pricing model (per seat) it really didn&#x27;t matter that much whether their client made 5, 10 or 50 mil unless they massively increased their hiring because of that, unless they can charge per install&#x2F;% of revenue.> Traditional industries rarely have such lopsided staff&#x2F;revenue ratios.A negligibly small proportion of indie developers are even close to that. reply rspoerri 7 hours agorootparentprevDo you have examples for indie game studios (with 10 employees) that make 50mio a year? reply hibikir 14 hours agorootparentprevIt&#x27;s an industry of booms and busts, we&#x27;ve all heard about the head of Xbox discussing the risky model of large publishers, making expensive sequels until the well dries, and everything collapses. Selling to the largest companies is more difficult too: Slower decision making, more negotiation. It&#x27;s the road to having a working business, but not one for growth.It&#x27;s just so much easier to get your product ingrained into a company that is growing, as long as you are getting your revenue tied to theirs. Their growth becomes your growth. But it has to be done in a way that makes them not run away. Offer different funding models depending on the project on the other end, and let the customer pick their pricing plan. When the plan for the small company starts looking too expensive for the big one, you get to renegotiate when your tools are already everywhere, and moving away is a hassle.It works for AWS, Stripe and the like. It should work here. reply airstrike 17 hours agorootparentprevI&#x27;d rather fix that bridge than bank on an non-existing bridge to enterprise customers with an inferior offering and no cash flow to meaningfully fund R&D to outpace competitors. reply raxxorraxor 2 hours agorootparentprevI don&#x27;t think the strategic action of a CEO is too relevant right now. The need to focus on rebuilding trust and I just cannot see how they will do that. They introduced an insecurity for developers, which already operate in an extremely high risk industry.If there weren&#x27;t people at Unity that could influence or stop the former CEO, the problem probably also didn&#x27;t vanish with his termination. reply reactordev 1 hour agorootparentI agree with all of what you said but having known Jim Whitehurst, he’s a guy who’s die hard about culture. Fixing the anxiety from within and giving people the space is what he’s known for. Whether he makes the right strategic decisions is up to him but if you have read anything from him you’ll know he seeks to improve excellence within to then champion externally. He did this with Red Hat before IBM. His book, The Open Organization is still relevant. reply doctorpangloss 17 hours agorootparentprevWhile I don’t think you deserve to be downvoted for this, your comment is full of opinions that, as a game developer, sound 200% wrong to me. For the sake of curiosity… what are you talking about? reply reactordev 17 hours agorootparentI’m talking about Jim Whitehurst taking Unity in a different path and leaving us game devs the f#^k alone. We’re done. Go sell to movie studios, VFX shops, Video Wall Warehouses, digital twin and construction. Sell enterprise software subscriptions.I think we both agree that small indie studios will not be returning no matter what promises are made, who is CEO, or what new shiny monetization idea they come up with next.I wish him the best of luck. reply doctorpangloss 16 hours agorootparent> I think we both agree that small indie studios will not be returning no matter what promises are madeOne thing I agree on: more often than not, behind an interesting piece of art lies an interesting personality.To advance the conversation based on some substantive facts, based on my conversations with creators of large free to play Unity games, all were already using IronSource and were not impacted by the changes anyway. As a game developer who publishes himself, I do not plan to migrate away from Unity, and I wasn&#x27;t really impacted either. I can&#x27;t speak for the 30 or so studios who posted pleas to revert the changes, but based on what happened, I believe they got what they wanted. So if their decision-making is rational &#x2F; based on facts, I don&#x27;t think they&#x27;re migrating either.This is all to say that when you have no budget, so you value your time at zero and you have no visual art you didn&#x27;t author yourself, it&#x27;s easy to put 100% of the personality into the product, and make that The Thing. There are people I know who turned 20,000 followers on a TikTok about games into a $1m check for a game studio! This is a viable strategy, it is uniquely suited to people to have opinions about game engines. But my facts-informed opinion is that this isn&#x27;t representative of most game developers, and that they are actually really happy with Unity and relieved that the pricing changes found a middle ground that is less emotionally charged. reply thsbrown 16 hours agorootparentJust want to second this.I&#x27;ve been using unity for almost a decade now and enjoying it despite the many caveats and idiosyncrasies I come across.The bottom line is, I definitely don&#x27;t want to throw away the decade of experience I have using Unity if I can help it. Ultimately I want them to learn from their mistakes and move forward. While Unity has had a fair share of missteps ultimately it&#x27;s the devil I know. reply 59nadir 7 hours agorootparentI&#x27;d like to ask (only out of genuine curiosity): Do you also build your own engines or are you fully entrenched and dependent on Unity? I would feel very disappointed if I spent a decade on something only to depend exactly on that one thing and not be able to create it myself, especially when it&#x27;s such a tractable problem in a sub-year time frame even with learning happening. The fit you could have with your own engine with a bigger up front investment of time and energy seems like it would easily pay off vs. just using Unity for years and years. reply reactordev 3 hours agorootparentNot only sunken costs, but building an engine is no easy task. It’s easier to write a game than to write an engine (most of the time).I do think this is the right approach. This is the approach I took. I was dependent on an engine for a long time until I realized it was just a facade and that I already possessed the knowledge to do it myself. So when XNA died, and MonoGame wasn’t mature yet, I had no choice but to write my own. Some of that effort went into MonoGame’s early days, most of it didn’t (I respect keeping the API the same but we, devs, could have done better to improve it).Unity made it easy to build games without having to know the underlying proponents that do what they do. Instead, it’s presented through a massively opaque interface called a MonoBehavior. Because of this opaque abstraction, it’s almost impossible for a Unity game developer to know exactly what’s going on under the hood.My first game engine took me 3 years to get to a point where I could ship something. My second was 1 year. My latest was 3 months.Eventually, it becomes just adding another interface to your GPU abstraction to support wgpu or DX14, or Vulkan2, or Metal, any graphics api becomes just a Buffer, a Queue, and a sync lock. reply mrdatawolf 16 hours agorootparentprevWhat did I just read??? \"Substantive facts\"? That was all opinion. You didn&#x27;t even directly respond to the poster until your last sentence and there you declared your opinion to be \"fact-informed\" and assigned both the feelings and actions of the average Unity dev using your, at best, subjective experience. reply crysin 16 hours agorootparentprevSmall studios absolutely will return to Unity. This whole debacle will be a faint memory a year from now, the marketing machine will continue and indie developers will become entrenched in Unity&#x27;s C# ecosystem, build tooling, all-in-one package + asset store. Some indies won&#x27;t return sure, but Unity will continue to maintain it&#x27;s foothold with indie developers. reply chii 16 hours agorootparent> entrenched in Unity&#x27;s C# ecosystem, build tooling, all-in-one package + asset storeinstead of indies, i think this applies much more to mid-level studios. Indies tend to be much more flexible and agile, esp. very small indies. Mid-level studios, with a dozen people that have gotten used to the toolchains and have existing investment in it (any custom plugins for example), would have a harder time switching away.However, this whole debacle just goes to show that proprietary software may be a trap, unless the T&C explicitly clarifies and makes it _not_ a trap. This is what unreal engine has done (you at least will always remain on the same T&C for the version you signed it for).Open source is a much safer bet for the long term for an indie, esp. if they&#x27;re just starting out now and do not have toolchains attached to unity. And the godot ecosystem is just budding right now, which means the opportunities are also great there. reply qwytw 9 hours agorootparent> which means the opportunities are also great thereOpportunities to spend significant amounts of time working on tooling and other engine features (with a non insignificant likelihood of still ending up with something inferior to Unity depending on your use-case) instead of actually making your game?Yes, what Unity&#x27;s management tried pulling off was stupid. However The engine itself is remarkably cheap from the perspective of many developers compared to any open source options.> unless the T&C explicitly clarifies and makes itFunnily enough IIRC Unity had a similar issue with the T&C back in 2019 when they promised to never change it retroactively again. Somehow they managed to \"forget\" it in a couple of years...I guess one important difference with Unreal is that Epic has way less bloat (several times less employees) and make huge amounts of money from Fortnite so they don&#x27;t need to try and squeeze as much as possible from their engine clients (currently anyway..) reply chii 5 hours agorootparent> T&C back in 2019 when they promised to never change it retroactively again.it&#x27;s not about changing it, it&#x27;s about including a clause in the T&C that the version they signed is the version in perpetuity for their version of software (obviously, an upgraded version may have the T&C changed).Unreal has this clause iirc, but not in unity. reply qwytw 2 hours agorootparentYeah, I was talking about retroactive changes of course (and not changes for future versions).Their founder&#x2F;CTO (who seems to be MIA these days) published this back in 2019:https:&#x2F;&#x2F;blog.unity.com&#x2F;news&#x2F;updated-terms-of-service-and-com...\"For this reason, we now allow users to continue to use the TOS for the same major (year-based) version number, including Long Term Stable (LTS) builds that you are using in your project.\"Which is something they presumably \"forgot\" about... reply TulliusCicero 15 hours agorootparentprevThey probably will now, but if they had gone through with those changes, they would&#x27;ve lost a lot of studios. reply Qwertious 7 hours agorootparentprevUnity is common in small indie studios because, for so many use-cases, it&#x27;s the only game in town. for most 3D projects, Godot isn&#x27;t ready yet, so their only option is Unreal. Which is substantially what Unity replaced in the first place.Give it 5+ years and another screw-up from Unity at the tail-end, and I 100% agree that Unity is sunk for indie devs. But as it is, Unity has a grace period where devs are locked-in and if Unity can demonstrate stability over the next few years, then people will forget it.And yes, if. Unity&#x27;s current PR position is in a fully-stocked rope warehouse, but they could navigate out relatively unscathed. reply reactordev 1 hour agorootparent>”Unity is common in small indie studios because, for so many use-cases, it&#x27;s the only game in town”I wholeheartedly disagree. There’s more choice than ever. A search on GitHub would show you.Unity has had one thing going for it. It was easy to get started and it had a ton of learning material. It is NOT the only choice. Off the top of my head there’s:- Ogre3D- O3DE- MonoGame- GameMaker- Godot- Cocos2d- GDevelop- Pandas3D- Reactor- Stride3D (formerly Xenko)- Three.js- Babylon.jsUnity’s editor first approach and their C# “everything’s a behavior” is why so many think it’s the only game in town. It’s not. It never was. reply johnnyanmac 13 hours agorootparentprevI&#x27;m not so optimistic. They changed the model and JR is out. Unreal is way too bloated for many indie dev projects and Godot isn&#x27;t ready yet. That may be enough goodwill for now.maybe if this happened two years down the line and W4 Games had more time to establish itself (maybe even make it&#x27;s own game to inspire confidence) it&#x27;d be a different story, but I can still see indies coming back. If they ever left to begin with. And this isn&#x27;t even talking about the corporate giants in the mobile space. reply qwytw 9 hours agorootparentprev> I think we both agree that small indie studios will not be returningWhy are you so certain that a significant proportion of them even left in the first place? reply phpisthebest 14 hours agorootparentprevWell if whitehurst follows his normal playbook he will just Aquirehire the godot project leads so then unity does not have to worry about it reply reactordev 13 hours agorootparentDon’t curse us. That would be the MO but please, leave some choice in the markets. reply johnnyanmac 12 hours agorootparentOn the bright side, if they do that Godot will just Fork, the same way Urho3D did. This would be a big bow but it may also be a small chance to truly dig in and fix some of the issues that were talked about for years in the community.But I&#x27;m probably just daydreaming. reply reactordev 3 hours agorootparentWait, what happened with Urho? I thought they were going strong (aside from a few who tried to take their code and just rename it)… did I miss some news? replyWillish42 18 hours agoparentprev\"doubling down\" indeed...One possible interpretation of events is that he was ousted not for the initial proposal and backlash but precisely for how he backtracked after the fact -- perhaps the board gave a clear mandate and Riccitiello was unable to successfully change pricing structure to match financial expectations. That would explain the replacement.Things aren&#x27;t looking great for Unity right now... reply strgcmc 18 hours agorootparentI think that&#x27;s reading too much into, what is fundamentally a very normal and common way of dealing with CEO turnover -- appoint a safe, business-friendly steward of a CEO, while you stabilize the crisis and decide who the real long-term leader should be.The word \"interim\" was clearly used, and there&#x27;s no hint in the PR statement about this being a permanent appointment. So I don&#x27;t think it&#x27;s reasonable to equate this to a clear doubling down of anything.At the same time, a guy like Whitehurst is a safe, relatively unimpeachable medium term choice, not like someone you&#x27;d use for a truly short interim 30-90 days while you execute an executive search quickly. If you need him for 1-2 years of just don&#x27;t rock the boat leadership, it&#x27;ll probably work out fine for the company and the board would be satisfied. reply cojo 18 hours agorootparentprevYeah, I think this could definitely be one explanation.Other commenters in the thread have also given good thoughts &#x2F; potential scenarios in similar veins - essentially that this was actually a failure of messaging, sticking to the plan, and &#x2F; or both, plus some other combination of \"no, seriously, we need to make money and become profitable, nothing else matters as long as the boat still floats, make it happen and keep this ship going.\"And I do suspect that Whitehurst will likely be a better fit for that. A seasons gaming industry executive (regardless of investor &#x2F; revenue focus) may actually be a negative if that&#x27;s the goal right now... I&#x27;ll be very interested to see how this all turns out. reply phire 14 hours agorootparentprevBoards don&#x27;t micromanage to that level (or more, they shouldn&#x27;t)There might have been an explicit mandate that Unity&#x27;s pricing structure should be changed, but more likely it was just an explicit or implicit mandate that the Unity division should produce more revenue (or profit).The actual details of how to achieve that mandate would be left up to Riccitiello and his management team.My interoperation is that while the board probably agrees with the need to change Unity&#x27;s pricing structure, Riccitiello is being ousted for the poor implementation with a proposal that generated so much backlash and then some pretty poor handling of that backlash. reply joecot 17 hours agoparentprevI think back to Ellen Pao at reddit. Ellen was brought on as CEO, and was the face of a number of very unpopular decisions. All those decisions had one purpose -- jettison the things that made the site rough around the edges, and find ways to monetize, so they could make investors happy and work on going public.The backlash was staggering, and much of what they tried was rolled back. Ellen Pao took the blame for it, but it wasn&#x27;t actually her fault. The founders just scapegoated her in order to make changes they needed for investors -- and depending on how cynical you are, they picked an asian woman so that they could channel internet racism and sexism as part of the distraction. Years later, they did the same thing, making multiple unpopular monetization changes, but this time the CEO taking the backlash is Steve Huffman himself, not a scapegoat put in front of him.CEOs don&#x27;t make decisions on their own, not really. This pricing change was the direction the company wanted to go in, and they got put on their heels, but only temporarily. They&#x27;re still going to try to find ways to aggressively monetize. reply mvdtnz 17 hours agorootparentThat is some incredible revisionist history. reply ribosometronome 17 hours agorootparentElaborate? reply mvdtnz 17 hours agorootparentWhat is there to say? The decisions that OP says were not hers, were hers. And the claim that they chose an Asian woman for the intended purpose of setting a racist mob against her is completely unfounded and frankly racist itself. Believe it or not, there are some Asian women out there that have qualities other than being the target of racism. reply dralley 16 hours agorootparentMost of the decisions Ellen Pao made, especially the banning of the FPH subreddit, was genuinely for the better. She bent over backwards, IMO, to avoid the hate - and should not have. reply dataengineer56 7 hours agorootparentFPH essentially put itself into a position where it had to be banned:1. Imgur blocked its images from being shown on FPH, essentially crippling the subreddit2. In response, the FPH mods put a collage of Imgur&#x27;s overweight staff in the subreddit sidebar3. Reddit will have had to ban the subreddit to maintain their relationship with Imgur (who they ended up buying). reply mvdtnz 16 hours agorootparentprevSure, I&#x27;m not defending the unhinged behaviour of Redditors. But the claim that Pao is not responsible for these changes is just not true. reply johnnyanmac 12 hours agorootparentEhh, given that reddit doubled down on pretty much every decision they made post Pao, I&#x27;m inclined with hindsight to think she was indeed scapegoated. Not necessarily for sexism reasons (try would happily do the same thing with Hitler as a CEO) but that&#x27;s just a semi-common strategy with big business, especially towards an unpopular board member when the opportunity arises.Really taught me not to celebrate these \"CEO steps down\" stories. Short of an entire board replacing itself it&#x27;s just a new shade of black coming in to lead the change they want all along. reply chris_wot 11 hours agorootparentIt can be both. If you are the CEO, the buck is meant to stop with you. Don&#x27;t weep for her. reply johnnyanmac 11 hours agorootparentNo sympathy for someone who can retire off their \"resignation\" regardless of how undeserved.I&#x27;m just saying that I care a lot more about actions than playing the blame game. And it&#x27;s clear Reddit took the bait here, hook, line, and sinker. Should have been the best time to work on an alternative and it would have been ready for the API schism if they invested those 6 years in to polishing the experience and fostering a community.instead we got... Lemmy. Oh well. replyexreddit 8 hours agorootparentprevThe board at the time was I think Yishan, Alexis, and someone from Advanced. Maybe Sam Altman. Ellen Pao was the natural choice because she had the most business experience of all the staff, but it wasn&#x27;t the right experience. She was always more of an investor, and she got her job there by investing money in reddit and asking for a job in return. She headed up BD and what turned into reddit labs for a while. She built up a reddit labs team, but they never found the next big thing for the company.Part of the API drama goes back to her time doing BD, making partnerships with apps, and possibly buying apps.I doubt there was a master plan to making her CEO, but I believe Alexis&#x27;s line was \"it&#x27;s her job to lose.\" At the end of the day, she was bad at making friends, was an awkward fit for the company, and was more experienced in politics and climbing the ladder than running a company.Good background on her: https:&#x2F;&#x2F;www.vanityfair.com&#x2F;style&#x2F;scandal&#x2F;2013&#x2F;03&#x2F;buddy-fletc... reply thrillgore 4 hours agorootparentprevEllen Pao was a glass cliff hire. reply tekla 17 hours agorootparentprev> they picked an asian woman so that they could channel internet racism and sexismProve it. reply joecot 15 hours agorootparentIt can&#x27;t be proven, which was the entire point. reply jmull 17 hours agoparentprevI don&#x27;t think you can really draw conclusions from an interim pick like this one.It&#x27;s who they choose after the search that will tell you something.But things don&#x27;t look good no matter who they choose. Unity has to become sustainable... that, or go out of business. Their fundamental problem is somehow getting revenue and costs in line with each other.Here are some general ways that could be done...* Squeeze a lot more money out of existing customers * Get a lot more paying customers * Cut spending on things that impact revenue a lot less than the cut savesThe first one is what the last CEO tried with that cockamamie licensing scheme. You could go at it in other ways but in the end the impact on customers is the same so I don&#x27;t think the reaction would be a lot better.Is there any clear way to accomplish the second, at least without an even larger negative impact on revenue?For investors, cutting cost is the least desirable -- they want to grow, not shrink. And customers also don&#x27;t like to get less for the same price. But perhaps there is a way to cut costs that would spare what provides the core value to customers, and perhaps a business guy could get shareholders to accept that it is the only way. reply ChuckMcM 17 hours agorootparentI concur with this, their interim CEO is the person who can do the needful things with respect to cutting executive pay, laying off people, and outright firing others. Once the organization has been pruned, the \"real\" new CEO comes on board and is given a shot at rebirth with a new point of view. reply Sakos 16 hours agorootparentprevI don&#x27;t understand how their cash burn rate is so high that a billion in revenue isn&#x27;t enough to stay in the black. What are they spending so much money on? reply timmytokyo 14 hours agorootparentThey&#x27;ve been on a hiring spree, with a ~50% annual growth rate for the past several years [1].[1] https:&#x2F;&#x2F;stockanalysis.com&#x2F;stocks&#x2F;u&#x2F;employees&#x2F; reply ekianjo 16 hours agorootparentprevMarketing and sales costs have increased tremendously reply jameshart 17 hours agoparentprevI’d be careful drawing too many parallels between running Unity vs running a game publisher.Unity is a developer platform&#x2F;tooling company. They don’t care about hits or franchises - they need service, stability, community, and technology innovation.Game publishers are creative industry plays, like movie studios. Completely different business.Of course Epic confuses things by being in both camps but I don’t think Unity is confused that they are competing with Epic in the sense of needing to outmatch Fortnite. reply djmips 17 hours agoparentprevI feel it&#x27;s unfair to include Mattrick in here - he came up as a gamer, making games as a teen and rolling that into his own company so at least he has roots as a developer and I feel a dev&#x2F;gamer connection but I respect your opinion. reply cojo 17 hours agorootparentI think yours is a fair opinion as well, to be clear - I actually debated editing him out for a couple of minutes after I first posted, because I do know that his background was truly heavy on the gamedev side of things early in his career.I have my reasons for thinking things changed later on, but they are subjective &#x2F; personal opinion based on personal experience, so I respect anyone who would disagree and exclude him from a list like this. reply ajkjk 14 hours agoparentprevIt&#x27;s the standard playbook. By having the CEO leave it gives the impression that it was his decision and so the bad decision-making is gone and now the company can be trusted again. Of course it wasn&#x27;t his decision; it was the whole board&#x27;s, but it&#x27;s convenient for them and their stock price to make it seem like it was his.No way to know, I suppose, if it was him + the board vs everyone, or him vs the board... but unless somebody leaks the details, I&#x27;d assume the board is just as culpable. reply hintymad 16 hours agoparentprev> was that one of the increasingly common \"management consulting\" &#x2F; investor- & revenue-focused type of gaming executivesMy read of this debacle is that the Unity CEO did not pay attention to details. It&#x27;s as if he had ever thought of how the policy would play out -- a signature move of a corner-office boss who simply delegates everything about product to his lieutenants. Or worse, to the lieutenants of lieutenants.This is in such contrast with those founder CEOs, who painstakingly think through product and policy changes. reply ethbr1 18 hours agoparentprevRight now, I&#x27;d imagine Unity is more concerned about placating their investors that the company isn&#x27;t going to fall off a revenue cliff.Appointing a \"developer-friendly\" candidate would have caused more uncertainty.As a temporary pick, I&#x27;d guess Whitehurst is intended to message \"We realize we screwed up, but there won&#x27;t be any sudden changes.\"The reaffirmed guidance for current quarter is hilarious though, given any changes would play out in future time (e.g. developer flight for next project). reply cojo 18 hours agorootparentAgreed - the reaffirmation of guidance almost felt to me like a \"seriously guys, why are we down 22% up front, you know this doesn&#x27;t impact short-term revenue...\" which... definitely misses the point.It&#x27;s interesting that after-hours &#x2F; future trading doesn&#x27;t seem to have responded positively (yet). Maybe that&#x27;s just another symptom of lost trust as well. reply hn_throwaway_99 18 hours agoparentprevGiven the information posted about Whitehurst in another comment, https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37825689 , I strongly disagree with your assessment of him. reply cojo 18 hours agorootparentI agree!I posted before that comment, which was definitely helpful - that context (and some other helpful replies here and elsewhere in the overall thread) have changed my assessment as well. reply koromak 2 hours agoparentprevIf none of the board is industry, and none of the major shareholders are industry, why would they hire industry? Finance is becoming the only job that exists. reply mym1990 2 hours agoparentprevIt doesn’t seem that wild for a board to be looking to increase revenue results&#x2F;shareholder value, especially in current economic headwinds. reply rat9988 18 hours agoparentprev\"interim replacement &#x2F; transitional CEO is someone with a pedigree that, on the surface, seems even more management consulting &#x2F; investor &#x2F; revenue focused than Riccitiello was himself. To be clear, I know essentially nothing about James M. Whitehurst other than what is readily publicly available (IBM &#x2F; Red Hat, advisory roles, etc.).\"To me, it seems he has plenty experience with managing companies. reply cojo 18 hours agorootparentI agree - this may be unclear phrasing on my part.What I meant in my original comment was, \"wow, this seems like a hire that is only focused on finding someone with lots of experience managing, and not at all on the gaming industry &#x2F; customer goodwill\".So I think you&#x27;re right - and I also think this shows how I misjudged how I originally thought a scenario like this would have played out. reply bdd8f1df777b 6 hours agoparentprevYou have a rosery view of the board. I on the hand believe that the it was the intention of the board to sell that ridiculous plan. The CEO was a scapegoat, or rather, he was going to leave anyway, so he took the blame in place of the others. reply floor_ 3 hours agoparentprevYou&#x27;re acting like the board had no say in the horrible decisions. reply beebmam 17 hours agoparentprevBring back engineer CEOs. I&#x27;m sick of this trash. reply intelVISA 4 hours agorootparentDon&#x27;t be silly, we&#x27;re in the era where engineers are both smart enough to wrangle massive technical goals yet also need many layers of babysitting from their betters.You may know what a CRDT is, but (apparently) the Trello board is beyond you. reply r00fus 11 hours agorootparentprevUnfortunately, in our economic system this is not allowed unless that engineer CEO happens to have incredible clout, financial control or both. reply Waterluvian 17 hours agoparentprev“with consequences”Depends how many millions he’s accepting to walk away. reply rapfaria 17 hours agoparentprevIsn&#x27;t Riccitiello stepping down a standard operation procedure in a situation like this? reply hackerlight 17 hours agoparentprev> board actually hold Riccitiello responsibleIt could also just be a PR move. Riccitiello is disliked among Unity customers, so you get goodwill by firing him. reply paxys 18 hours agoprevRemember that executives are never fired for bad decisions, they are fired for bad press. The Unity business model & strategy changes&#x2F;price hike were most definitely approved by the board. The CEO&#x27;s job was to make it digestible to the general public, and he failed at that. Don&#x27;t expect the new one to pull a 180. He will simply hire better PR firms and do better sugar coating. reply JimDabell 7 hours agoparent> Remember that executives are never fired for bad decisions, they are fired for bad press.Executives are fired for bad decisions all the time. You just don’t hear about it when there isn’t bad press. reply aqme28 2 hours agorootparentOften with an absurd golden parachute though. reply falcor84 7 hours agorootparentprev{{citation needed}} reply JimDabell 7 hours agorootparentNo, a citation is not needed. It’s entirely normal that poor performers are fired. What is utterly implausible is the idea that poor performers are never fired. That’s a weird fiction people like to repeat here that doesn’t stand up to the slightest amount of thought. reply activitypea 6 hours agorootparentIf by \"normal\" you mean \"reasonable\", then you&#x27;re right. If you mean \"common\", then try working at a large publicly-traded company for a few years. I agree that this stance doesn&#x27;t stand up \"to the slightest amount of thought\", but yours doesn&#x27;t measure up to the reality in the field. The reason people are saying something that makes no sense is probably because it&#x27;s actually happening a lot. reply SSLy 5 hours agorootparentI work in a world-famous publicly-traded company and previous top head was unceremoniously fired when their superiors realized we&#x27;re years behind competition on a lifeline product. reply activitypea 3 hours agorootparentRegardless of that product, how long was he making bad decisions before he was replaced? If it&#x27;s less than two years, are you hiring? :) reply Draiken 5 hours agorootparentprevThat&#x27;s good! One example. But we need thousands more to be able to say this is common though.There&#x27;s a reason the term \"fail upwards\" is so commonly used. replymajani 17 hours agoparentprevAnd it will fail again. Companies that target indie creators really don&#x27;t fit into the VC model. Their customers will riot every time they try to maximize profits. reply kibwen 16 hours agorootparentUnity, like every other shitty tech company these days, is just an ad company. Their customers are ad purchasers, not game devs. reply wongarsu 14 hours agorootparentBut just like Google has to make sure you keep searching on google.com and keep watching youtube, Unity has to make sure people keep playing Unity games, which requires people to make Unity games. You can&#x27;t sell ads when you don&#x27;t have anywhere to put them. reply telchior 13 hours agorootparentArguably, Unity could survive without the game engine -- they just need to survive the consolidation of the mobile ad business. Many companies already used Unity Ads without using Unity engine, even moreso after the acquisition &#x2F; near merger with Ironsource. That acquisition was entirely about staying a step ahead of the consolidation wave, and nothing to do with the engine.Of course, while that idea may be arguable it&#x27;s also absolutely idiotic. But I won&#x27;t be at all surprised if Unity continues to steer in that direction, especially now that the Ironsource people comprise a large part of the company. reply grotorea 3 hours agorootparentprevBut what class of customer doesn&#x27;t riot when they try to maximise profits? reply golergka 10 hours agorootparentprevUnity is mainly targeting mobile games studios, who are certainly not indie creators, but are pretty big companies themselves. I don&#x27;t think that indie game developers who release games on steam make up a significant portion of their income. reply alexpetralia 18 hours agoparentprevBut who proposed those changes? Ultimately the CEO is accountable. reply dboreham 18 hours agorootparentThe board reply AlexandrB 18 hours agorootparentI&#x27;m not an expert on corporate governance, but does a board of directors get into the nitty gritty of pricing models? I can totally believe they told the CEO to \"bring in more revenue, or get replaced\", but I have a hard time imagining they got too involved in the details how that would happen. Many board members sit on multiple boards or are CEOs of other companies. Do they really have time to do the kind of market research you&#x27;d need to propose such a change? reply airstrike 17 hours agorootparentI&#x27;m an \"expert\" on corporate governance and I can say that no, boards do not get involved to the degree of making any market research -- they don&#x27;t \"initiate\" initiatives such as a pricing model change (if you will pardon the redundancy). Public company CEOs (and their teams, really) come up with these plans. Boards do vet the executive&#x27;s team business plan at the time of budgeting and during quarterly updates, but it&#x27;s the CEO who is in charge of ideation and execution. reply hiatus 17 hours agorootparentprevHaving been in board meetings where members went in on the nitty gritty of our _salesperson_ compensation structure, I would say yes. reply airstrike 17 hours agorootparentPublic company boards? reply jojobas 16 hours agorootparentprevThey&#x27;ll sure scrutinize this or that, I&#x27;d be surprised if they _suggested_ a salesperson compensation structure. reply Groxx 14 hours agorootparentNah, it&#x27;d fit. Everyone knows that sales is the only part of the company that actually makes money. Everything else is just a cost center that needs to be shrunk aggressively. reply ezconnect 13 hours agorootparentprevA majority holder on the board dictates how the company operates. It usually goes like give me a plan to get maximum revenue so I can collateral the company to get more debt to acquire other company or get me maximum profit so I can exit and invest on other company. reply otteromkram 17 hours agorootparentprevBoard members aren&#x27;t doing research, bud. LolResearch and information is compiled for them, which they then review.What&#x27;re your thoughts on politicians who are in multiple subcommittees? Not smart enough? reply mvdtnz 17 hours agorootparentprevIt is not the role of the board to make executive decisions like this. That&#x27;s what the &#x27;E&#x27; in CEO means. reply airstrike 17 hours agorootparentprevNegative, it&#x27;s the CEO. reply paxys 18 hours agorootparentprevUnity has been hemorrhaging money, and the shareholders want to see profits. The board and the CEO have no choice but to execute on their demands. reply m12k 4 hours agoparentprevWait until you hear who was until recently the chairman of the board. reply NotYourLawyer 13 hours agoparentprev> The Unity business model & strategy changes&#x2F;price hike were most definitely approved by the board.I mean.. maybe? But it would be surprising. reply jojobas 16 hours agoparentprevWhat makes a bad decision then? Excellent press while customers still bailing out wouldn&#x27;t make it a good decision would it? reply drewcoo 18 hours agoparentprev> The CEO&#x27;s job was to make it digestible to the general public, and he failed at that.No. It was to either do that or be the scapegoat and take the golden parachute. Either way it&#x27;s wins all around.Now he can be blamed for the board&#x27;s decisions. Meanwhile it remains to be seen how much anything will change. After all, the cause of the problem is gone now, right? &#x2F;s reply andrewedstrom 18 hours agoprevIt makes sense the CEO would either step down or be forcibly removed by the board.Unity&#x27;s mishandling of the Runtime Fee policy announcement has caused permanent damage to their reputation. It was a perfect case study in how to undo decades of trust-building in one day.I follow a lot of game developers online. Every single one that uses Unity today is planning to switch engines for their future games. reply adastra22 14 hours agoparentHold on, unity did not mishandle the announcement. They mishandled the whole policy. It was poison that no game developer would have accepted. reply Groxx 14 hours agorootparentBoth fit - the announcement was a massively confusing mess, with slightly different information in many locations and none of it clear, leaving everyone guessing what their soon-to-come-due cost would be for days while they completely failed to get their shirt together. reply sorenjan 17 hours agoparentprev> I follow a lot of game developers online. Every single one that uses Unity today is planning to switch engines for their future games.Will all of them switch to Unreal, or are there other viable options? reply ClimaxGravely 16 hours agorootparentI use Unreal professionally but on the side when I make smaller 2D games I am using Haxe&#x2F;Heaps currently (although haxe&#x2F;heaps can do 3d perfectly fine I&#x27;d probably stick with Unreal in that case due to experience).Godot seems to be the way people are going right now though (I haven&#x27;t tried it). reply JoeyJoJoJr 14 hours agorootparentI also recommend for people to take a look at the haze library called Kha, if they are after the same kind of low level rendering that libraries like Monogame and Raylib offer. reply aaaa123456 14 hours agorootparentprevHow is Haxe in 2023? I tried to get into it a few years back but somehow I couldnt quite break the barrier to entry where it was fun to use reply logo4poop 13 hours agorootparentIt is very alive! The Discord is where most of us hang out, but there are quite a lot of new stuff to mess around with and use :). Check out...- https:&#x2F;&#x2F;ceramic-engine.com&#x2F;- https:&#x2F;&#x2F;github.com&#x2F;RobertBorghese&#x2F;reflaxe reply starburst 17 hours agorootparentprevThe biggest share of Unity is 2D mobile games, something Unreal is not particularly suited for and I very much doubted that segment of the market will switch to Unreal. reply dkersten 16 hours agorootparentDefold, the engine by King that powers Candy Crush, is a solid free contender for 2D mobile games. reply cornel_io 15 hours agorootparentUnless a very major rewrite happened in the last few years, Defold absolutely does not power Candy Crush, in fact to my knowledge King has never shipped anything in Defold and it&#x27;s fallen almost entirely out of favor internally.All the Candy Crushes as well as several other games use variants of a custom internal engine that&#x27;s managed by a fairly sizable central team. reply faraggi 11 hours agorootparentprevGodot ia gaining market share like crazy and I wouldn&#x27;t be surprised to see it overtake unity in the future. reply slikrick 17 hours agorootparentprevmost of the 2d ones are looking to Godot reply thrillgore 4 hours agoparentprevUnity didn&#x27;t mishandle the announcement. They were actually quite clear about their brazen rentseeking, and that made the decision to switch pretty easy for new development. reply Luc 17 hours agoparentprevDoesn&#x27;t really matter if they&#x27;re mostly indie game devs that weren&#x27;t contributing major revenue to Unity anyway. reply drusepth 16 hours agorootparentIn my spheres (full-time game dev), I&#x27;ve already seen ripples down to teachers&#x2F;professors switching from Unity to Unreal in their courses. Many of the content creators I&#x27;ve enjoyed in Unity are also either switching or considering switching to another engine for their videos. Brackeys allegedly even said he might come back and start a Godot series. It&#x27;s a long tail of ripples that reduces the number of \"Unity devs\" at every stage of their lifecycle (learning, starting out, graduating to small studios, etc) which doesn&#x27;t bode well for Unity long-term.Most A&#x2F;AA devs I follow are planning to switch to another engine when they can (e.g. not mid-project), but I know a few who immediately started porting to Unreal&#x2F;Godot. Most AAA devs I know already don&#x27;t use Unity. reply chipgap98 16 hours agorootparentUnreal is even more expensive and requires reporting your revenue to pay for it. How is that a better option than Unity? reply jwitthuhn 15 hours agorootparentEven though the walked back the price change this time, Unity still contends that they have the authority to increase the price and apply that price increase to old versions even if the users don&#x27;t agree [1].Unreal lets users stick to a license with predictable fees.By using Unity you are still agreeing to a liability with no limit that can change at any time and your only recourse is to cease development or stop selling your already-complete game.1. https:&#x2F;&#x2F;forum.unity.com&#x2F;threads&#x2F;unity-plan-pricing-and-packa... reply hackernewds 8 hours agorootparentdoesn&#x27;t address the initial comment&#x27;s concerns reply drusepth 7 hours agorootparentIt directly addresses it: the single-digit % cash difference in profit-sharing between Unity and Unreal&#x27;s programs aren&#x27;t what most people are worried about with Unity&#x27;s changes.The bigger issue is that Unity is trying to assert (again) that they can retroactively change your licensing agreement at any time, and for any reason -- and have explicitly said they reserve the right to increase these fees (which, yes, are less than competitors right now) in the future.> Unreal is even more expensive and requires reporting your revenue to pay for it. How is that a better option than Unity?With their new changes, Unity also requires reporting your revenue&#x2F;installs. In terms of the cost difference, the consensus seems to be that people will pay a little more to lock into a predictable license that can&#x27;t infinitely add unpredictable fees later, even on games for sale that are no longer in development. reply fbdab103 11 hours agorootparentprevUnreal has yet to state that they have the authority to alter the terms of the deal at their whim. Who would ever choose to do business with someone who believes they can unilaterally change the business agreement? reply delecti 17 hours agorootparentprevIndies aren&#x27;t limited to single-digit sized teams, and even if they were, devs \"graduate\" out of indie studios into AAA ones (through growth or migration). The skillset of the next decade of new indies deliberately excluding Unity will influence the decisions made by the AAAs that they move to. Anybody too small to be negotiating custom license terms with Unity just learned that they can&#x27;t be trusted. reply theshrike79 9 hours agorootparentprevIt&#x27;s not about revenue, it&#x27;s about mindshare.This is why Microsoft doesn&#x27;t care if people pirate Office tools for private use, because if they get to a position where they can decide what tools to use for a company, they&#x27;ll pick what they know. Office.The same works for Unity, if an indie company becomes a AAA level studio, they&#x27;ll use what they know and what they have been using for years.Now there&#x27;s a risk that it&#x27;ll be something that&#x27;s not Unity. reply rcoveson 16 hours agorootparentprevYeah, there probably won&#x27;t be any second-order effects.- John Riccitiello reply lofaszvanitt 18 hours agoparentprevNah, this was mass hysteria. reply bigstrat2003 17 hours agorootparentIt&#x27;s not \"mass hysteria\" to observe that your business partner is willing to attempt to retroactively change the terms of your arrangement with them, and therefore decide they aren&#x27;t trustworthy as a business partner. The actual monetary cost to developers is actually quite inconsequential compared to the lack of integrity Unity showed in trying to make this apply to games which were already released. reply chipgap98 16 hours agorootparentI think the concern is real but I don’t think there is another viable competitor to Unity reply hackernewds 8 hours agorootparentUnreal reply readyplayernull 17 hours agorootparentprevWhen they tell you that you have to report your installs and sales each month just like you do your taxes, that&#x27;s when you notice there are other free engines. reply starburst 17 hours agorootparentprevNah, people in position of picking the engine for the next project are not going to pick Unity. reply sbarre 17 hours agorootparentAt least one publisher jokingly (but not jokingly) said \"developers: make sure you include which engine you&#x27;re using next time you pitch us a game!\"... reply teamonkey 4 hours agorootparentThat&#x27;s normal and has been for years. Your choice of engine affects your business model. reply chrz 16 hours agorootparentprev\"EVERYBODY disliked that\" is not hysteria reply doomlaser 18 hours agoprevJames M. Whitehurst is new CEO, previously at IBM, but originally CEO of Red Hat. He joined IBM after they acquired it.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jim_WhitehurstHe wrote a book about open source software while running Red Hat, The Open Organization: https:&#x2F;&#x2F;www.redhat.com&#x2F;en&#x2F;explore&#x2F;the-open-organization-bookHe is an MBA, but he got his undergraduate degree in CS from Rice. reply leviathan303 18 hours agoparentHis wikipedia article says he got his BS in CS from Rice. reply Thorrez 17 hours agorootparentHas the comment been edited? That&#x27;s exactly what doomlaser said. reply monsieurbanana 8 hours agorootparentIt said Harvard reply doomlaser 8 hours agorootparentHis MBA is from Harvard Business School. Undergrad CS at Rice. reply badRNG 16 hours agorootparentprevWhitehurst went to Rice University for Computer Science reply pests 16 hours agorootparentIt is true that Whitehurst went to White University for Computer Science and I do not know why we are astroturfing that fact. &#x2F;s? reply145 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "John Riccitiello has stepped down as CEO of Unity Technologies amidst pricing controversy, with James M. Whitehurst stepping in as interim CEO and president.",
      "Despite leadership changes, Unity stands firm on its previous financial projections for the third quarter. Roelof Botha has taken the role of chairman.",
      "Unity plans to begin the search for a permanent CEO soon, while Riccitiello will continue to provide advisory role through the transition."
    ],
    "commentSummary": [
      "John Riccitiello has resigned as CEO of Unity, and James M. Whitehurst, special advisor at Silver Lake, one of Unity's largest stakeholders, is the interim successor.",
      "The change has triggered dialogue on various changes, including corporate strategies, Unity's controversial pricing adjustments, and how future leadership could influence these aspects.",
      "Also in topic is Unity's future, its relationship with indie developers, and the prospect of alternative game engines coming into the spotlight."
    ],
    "points": 866,
    "commentCount": 401,
    "retryCount": 0,
    "time": 1696884409
  },
  {
    "id": 37827995,
    "title": "Firefox tooltip bug fixed after 22 years",
    "originLink": "https://bugzilla.mozilla.org/show_bug.cgi?id=148624",
    "originBody": "Bugzilla Quick Search Browse Advanced Search New Account Log In Forgot Password Copy Summary▾ View ▾ Closed Bug 148624 Opened 22 years ago Closed 1 month ago Tooltips persist in foreground when Firefox is in backgroundCategories (Core :: XUL, defect) Product: Core ▾ Component: XUL ▾ Type: defect Priority:Not set Severity: S3Tracking (bug RESOLVED as FIXED) Status: RESOLVED FIXED Milestone: 119 Branch Tracking Flags: Tracking Status firefox119 --- fixedPeople (Reporter: Juneappal, Assigned: fanzhuyifan+github)References (Blocks 1 open bug, Regressed 1 open bug)DetailsAttachments (8 files) Tooltip over another app, Mozilla minimized 21 years ago Jerry Baker 1.90 KB, image/png Details Task tooltip over reminder window, which was focused 15 years ago Emerson Prado 64.50 KB, image/gif Details Still happens in Fx4 nightly. 13 years ago Richard Newman [:rnewman] 20.46 KB, image/png Details Screenshot showing Firefox 5.0.1 tooltip intruding into foreground 12 years ago edrazeba 55.82 KB, image/jpeg Details Adblock Plus tooltip intrudes into Transmission. 12 years ago edrazeba 76.35 KB, image/jpeg Details Google search tooltip intrudes into Transmission 12 years ago edrazeba 66.90 KB, image/jpeg Details Bookmark tool bar item's \"mouse over\" state has been triggered 12 years ago edrazeba 70.14 KB, image/jpeg Details Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin 1 month ago fanzhuyifan+github 48 bytes, text/x-phabricator-request DetailsReview Bottom ↓ Tags ▾ Timeline ▾Adam Price ReporterDescription • 22 years ago From Bugzilla Helper: User-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X; en-US; rv:1.0.0+) Gecko/20020602 BuildID: 2002060203 If I mouseover a toolbar link, and wait for a second, a little yellow box with the description of the link appears. If I now use command-tab to move Mozilla to the background, the little yellow box stays there, in the foreground. The only way to get rid of it is to put mozilla in the foreground again, and move the mouse off the toolbar. Reproducible: Always Steps to Reproduce: 1.Mouseover a toolbar icon 2.Wait for tooltip 3.Command-tab Actual Results: The tooltip wouldn't go away Expected Results: The tooltip should have gone away when mozilla was backgrounded This is related to the following bugs. I am resubmitting because the other reporters did not give good step by step reproduction methods, or the problem is slightly different: Tooltips show up over other windows *Tooltips occasionally don't disappear *Tooltips appear even when mouse isn't over node *tooltip persists after autocomplete dropdown appears *Tooltip should disappear when parent item disappearsGreg K.Comment 1 • 22 years ago Confirmed using FizzillaCFM/2002052305 (RC3). Guessing XP Toolkit/Widgets. Assignee: Matti → jaggernaut URL: http://any.web.site Status: UNCONFIRMED → NEW Component: Browser-General → XP Toolkit/Widgets Ever confirmed: true QA Contact: imajes-qa → jrgmJerry BakerComment 2 • 21 years ago See this on WinXP as well. --> OS/All & Platform All OS: MacOS X → All Hardware: Macintosh → AllJerry BakerComment 3 • 21 years ago Attached image Tooltip over another app, Mozilla minimized — Details This doesn't requires an ALT-TAB. I can reproduce this by dragging a link from the URL bar onto my desktop, by dragging a link up to the \"X\" in the upper right corner and letting go and clicking the X. Lots of ways.John A.Comment 4 • 20 years ago I'm seeing this problem in 1.6 on Win98.risckyComment 5 • 20 years ago *** Bug 242912 has been marked as a duplicate of this bug. ***Malcolm SmithComment 6 • 20 years ago Also happens in Firefox/0.8, Linux GTK2, although in this case the offending tooltips can be killed by moving the mouse pointer over them. Still very annoying though.Malcolm SmithComment 7 • 20 years ago Should be marked as a duplicate of Bug 142656.Uri Bernstein (Google)Comment 8 • 19 years ago *** Bug 262649 has been marked as a duplicate of this bug. ***Uri Bernstein (Google)Comment 9 • 19 years ago *** Bug 295742 has been marked as a duplicate of this bug. ***Jerry BakerComment 10 • 18 years ago Just a ping and a note that this is still occuring in the latest builds of Firefox and Thunderbird.Jerry BakerComment 11 • 18 years ago Not only do tooltips persist in the foreground, but they can pop up even when Firefox is in the background and the mouse passes over a point that would generate a tooltip if Firefox was in the foreground.Jerry BakerComment 12 • 18 years ago This behaves as though Firefox/Thunderbird are unaware that the mouse pointer has exited their window and is not in another window. Somehow they continue to receive coordinates even though there is another window over them. One nasty example fo this bug is to load a PDF file and then drag the mouse from the URL bar, across the personal toolbar, and into the PDF content. A tooltip from the personal toolbar will pop up over the PDF and will never go away until you mouseover it.Jerry BakerComment 13 • 18 years ago Make that, \"and is now in another window\"Mike Beltzner [:beltzner, not reading bugmail]Comment 14 • 18 years ago *** Bug 335527 has been marked as a duplicate of this bug. ***Mike Beltzner [:beltzner, not reading bugmail]Comment 15 • 18 years ago *** Bug 323120 has been marked as a duplicate of this bug. ***Joey MintaComment 16 • 18 years ago *** Bug 342427 has been marked as a duplicate of this bug. ***Mike CowperthwaiteUpdated • 17 years ago Blocks: 334351Aaron DigullaComment 19 • 16 years ago How about disabling tooltips when the Firefox window is inactive?Dan SComment 20 • 16 years ago This is really annoying. I'm on OSX, using Sunbird, and these tooltips keep appearing which I can't get rid of despite having only flicked quickly to Sunbird to check my calendar. It makes me quit sunbird, that's the easiest way to get rid of the things! Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.1.8pre) Gecko/20071002 Sunbird/0.7NikComment 21 • 16 years ago I don't have sunbird, BUT I agree with you Dan! ON a Mac and it still happens in Firefox 2.0.0.14 I've been I've been bitchin about this bug since 2004 (see bug: 236870) -- Which is obviously a dupe of this bug... But it never seems to go away! -- Bug still appears on Mac in: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.1.14) Gecko/20080404 Firefox/2.0.0.14 But it's a bit harder to replicate. To replicate in 2.0.0.14: 1: Mouse over something that generates a tip. 2: Hit \"Command\" (Apple) -- TIP DISAPPEARS (yay!) 3: (still holding Command) Slightly move mouse -- TIP REAPPEARS (Oh-Oh) 4: Hit \"TAB\" to complete the switch to another app -- TIP REMAINS (#*$%!) Tip remains until you switch back to Firefox... This sounds minor.. But it's very frequent for users of track pads that do a lot of switching! -- Others in our office have tihs problem! BUT there may be hope on the horizon.. I've had trouble replicating this in Firefox 3 RC 2, the tip stays when you switch, but as soon as you move the mouse, it disappears (keyboard events don't clear the tip unfortunately). Cheers, Nik.Dan SComment 22 • 15 years ago Still happening, exactly the same, on Sunbird 0.8 :((( Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.1.13pre) Gecko/20080331 Sunbird/0.8Emerson PradoComment 23 • 15 years ago I saw this with Lightning 0.9 build 2008091719 in Thunderbird 2.0.0.17 (20080914), all pt-BR, over Win2k SP4 en-US. I opened a task for edition and moved the mouse to the reminder window. In its way, the mouse crossed the tasks pane and a tooltip came (too quick, IMHO). Even after clicking in the reminder window (to get focus), the tip stayed on top of it. I had to play with the mouse a bit to get rid of the tip (can't remember if I just moved it around or clicked somewhere else).Emerson PradoComment 24 • 15 years ago Attached image Task tooltip over reminder window, which was focused — DetailsMats Palmgren (inactive)Updated • 15 years ago Assignee: jag → nobodySeth SpitzerComment 25 • 13 years ago I'm not seeing this in fx 3.6.11 (and I didn't see it with 3.6.8, fwiw) on Mac OS X. Specifically, the STR in commment #21. Neil, could you have fixed this along the way somewhere?Seth SpitzerComment 26 • 13 years ago fwiw, on mac, fx 3.5, 3.0.19 and even 3.0 do not have this bug, but fx 2.0.0.20 does. I wonder if this was fixed by neil's work for #279703 (or one of the dependent bugs)?Richard Newman [:rnewman]Comment 27 • 13 years ago Attached image Still happens in Fx4 nightly. — Details I see this in 3.6.12 (on 10.5.xx and 10.6.5) and a 2010-12-03 nightly on 10.6.5. It's been driving me nuts for years. Most definitely not fixed. Here's an observation which might explain \"worksforme\" responses. If Fx is the frontmost app, the Cmd key that I use to initiate Cmd-Tab will cause the tooltip to disappear. If Fx is *not* the frontmost app, it still responds to hovers and throws up a tooltip... but the frontmost app takes keyboard input, so Fx isn't aware of any app or window changes. It's thus possible to Cmd-Tab to an app that should cover the tooltip, but the tooltip stays on top. Easy enough to repro: give focus to the Finder, hover over a tab or link in Firefox without shifting focus, then Cmd-Tab to an app that would be over the link when taking focus (such as a maximized iTunes window). Tiny screenshot attached.Seth SpitzerComment 28 • 13 years ago Richard: killing this bug would be great. What about not showing tooltips (when that timer fires) if the window doesn't have focus? in nsXULTooltipListener::ShowTooltip() we call LaunchTooltip() In ShowTooltip() we already get the document for the tooltip node From that, can we get the nsPIDOMWindow and then ask the focus manager if we are the focusedWindow? http://mxr.mozilla.org/mozilla-central/source/dom/interfaces/base/nsIFocusManager.idl#71 Similar to this code: http://mxr.mozilla.org/mozilla-central/source/editor/libeditor/html/nsHTMLEditor.cpp#5963Richard Newman [:rnewman]Comment 29 • 13 years ago (In reply to comment #28) > Richard: killing this bug would be great. > > What about not showing tooltips (when that timer fires) if the window doesn't > have focus? That seems like a reasonable approach. Safari (to take a sample of the playing field) doesn't show tooltips if it's not the foreground app. If no XULian takes a stab at this, I might be tempted — at least, after my urgent Sync commitments are done… it's a real annoyance to me.Seth SpitzerComment 30 • 13 years ago bookmarks on the bookmarks toolbar in 3.6.12 will not change style or give me a tooltip on hover if firefox is not active. (Richard, can you double check 3.6.12?) But I can confirm that firefox 4.0b7 does do it. another sample from the playing field: Google Chrome (on Mac) doesn't seem to show tooltips it's not the foreground app, either. From my tests: 1) firefox 4.0b7 has a different regression (what Richard describes in comment #27) 2) neither fx 3.6.12 nor 4.0b7 have the bug described comment #21, which is why I thought this bug is now fixed/worksforme. Unfortunately, I don't know what fixed it.Richard Newman [:rnewman]Comment 31 • 13 years ago (In reply to comment #30) > bookmarks on the bookmarks toolbar in 3.6.12 will not change style or give me a > tooltip on hover if firefox is not active. (Richard, can you double check > 3.6.12?) I see the same behavior as you for that case for a fresh 3.6.12 profile. However, I did get two other repro cases: * Hold Cmd. * Hover over a bookmark on the bookmark bar. Tooltip appears. * Hit Tab to switch to Finder. Tooltip remains active. Mouse position might be important here -- in some cases the tooltip disappears if you move the mouse and Firefox is still under the cursor. ... and a really awesome different version of this bug: * Start a drag for a long-titled bookmark in the bookmark bar. Don't move off the bookmark. * Hit Cmd-Tab to switch to Finder. * Hit Esc to cancel the drag. * Release the mouse button. Finder will have focus, but the tooltip will appear from hovering over the bookmark. Again, mouse position is important. I haven't tested either of these two cases in Fx4. It certainly seems like someone with a good understanding of the various window events on the Mac needs to audit all this...edrazebaComment 32 • 12 years ago Attached image Screenshot showing Firefox 5.0.1 tooltip intruding into foreground — Details This bug still persists in Firefox 5.0.1. Not only do tooltips that were already displayed remain visible when you switch from Firefox to another app, they appear if the mouse strays into that region while Firefox is already in the background.Phil SchwanComment 33 • 12 years ago (In reply to comment #32) > > Not only do tooltips that were already displayed remain visible when you > switch from Firefox to another app, they appear if the mouse strays into > that region while Firefox is already in the background. Yes -- this is actually the far, *far* more irritating symptom (at least on Mac OS X), if anyone is keeping track.edrazebaComment 34 • 12 years ago Attached image Adblock Plus tooltip intrudes into Transmission. — Details This screenshot shows Transmission in the foreground and Firefox 5.0.1 in the background. Moving the pointer around the Transmission Inspector window causes Firefox's tooltips to be triggered, such as Adblock Plus' very large tooltip, which appears via the Adblock Plus toolbar button.edrazebaComment 35 • 12 years ago Attached image Google search tooltip intrudes into Transmission — Details This screenshot shows Transmission in the foreground and Firefox 5.0.1 in the background. Moving the pointer around the Transmission Inspector window causes Firefox's tooltips to be triggered. In this example, with the mouse pointer positioned over Transmission's \"Options\" (\"gear\") button, both Transmission's \"Options\" tooltip and Firefox's Google search box tooltip are presented at the same time, with one layered over the other. It's _really_ annoying.edrazebaComment 36 • 12 years ago Attached image Bookmark tool bar item's \"mouse over\" state has been triggered — Details BTW, this is not just to do with tooltips, although that is the most intrusive and noticeable aspect; with Firefox 5.0.1 in the background and Transmission in the foreground, as you can see from this screenshot the tooltip for a bookmark is triggered. However, you'll also note that the item's \"mouse over\" state has been triggered. When moving the pointer into the vicinity of the bookmark, the bookmark button's state changes first, and a moment later the URL tooltip appears. Most other (real) buttons do not appear to be affected by this \"mouse over\" state change, just their tooltips appear. An exception to this is the \"Open a New Tab\" \"+\" button; when Firefox is in the background, the \"+\" button's \"mouse over\" state is triggered (and naturally its tooltip) when the mouse pointer goes into that region of the backgrounded Firefox window.David.PComment 37 • 9 years ago Firefox tooltips always on top of all windows and not going away until you restart Firefox still happens in Firefox v.36.0Zac SpitzerComment 38 • 7 years ago This is still happening in 49.0.2 on Windows 10 if you drag a link with a tooltip, after you drop the link elsewhere, the tooltip appears and remains as a top level item on the desktop until you focus and then unfocus FirefoxBMO AutomationUpdated • 1 year ago Severity: normal → S3BugBot [:suhaib / :marco/ :calixte]Comment 39 • 1 year ago The severity field for this bug is relatively low, S3. However, the bug has 8 duplicates and 15 votes. :enndeakin, could you consider increasing the bug severity? For more information, please visit auto_nag documentation. Flags: needinfo?(enndeakin)BugBot (nomail) [:suhaib / :marco/ :calixte]Comment 40 • 1 year ago The last needinfo from me was triggered in error by recent activity on the bug. I'm clearing the needinfo since this is a very old bug and I don't know if it's still relevant. Flags: needinfo?(enndeakin)Tristan MillerComment 41 • 1 year ago Still reproducible (and still extremely annoying) with Thunderbird 102.4.1 (64-bit) and Firefox 106.0.1 (64-bit) on GNU/Linux. When I'm multitasking, I need to manually minimize Thunderbird in order to prevent its tooltips from interfering from my work in other windows. Not reproducible with SeaMonkey 2.53.14, so maybe this isn't a Core product issue after all, or maybe SeaMonkey has done something to override the bad behaviour. Maybe the Firefox and Thunderbird developers can see what SeaMonkey has done to fix the issue and implement the same fix.denisComment 42 • 10 months ago This 21 year old bug is still open. It is quite annoying, to be frank -- happens to me at least once per day. That said, given its longevity, I'm kinda partial to let it be forever. It feels like a relic from the past.Gustavo A. DíazComment 43 • 4 months ago Hi, still happening to me too (OS: KDE Neon 22.04). Firefox v113.0.2Sean BuckleyComment 44 • 3 months ago Still happening on Firefox 115.0.2 + GNOME 44. I just browser-hopped back to firefox this week and this was one of the larger annoyances, as I trigger it constantly. For people who find this page via search engine, like me, the solution I'm using is to disable tooltips entirely, with the setting browser.chrome.toolbar_tips. It's a weird thing to have to resort to, but I don't think there's really any situation where I'll miss them.fanzhuyifan+github AssigneeComment 45 • 1 month ago I am also experiencing this bug. Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm. Steps to reproduce: Hover mouse over element that will generate tooltip. Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace. Symptoms: The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse.fanzhuyifan+github AssigneeComment 46 • 1 month ago Attached file Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin — DetailsPhabricator AutomationUpdated • 1 month ago Assignee: nobody → fanzhuyifan+github Status: NEW → ASSIGNEDfanzhuyifan+github AssigneeComment 47 • 1 month ago (In reply to fanzhuyifan+github from comment #45) I am also experiencing this bug. Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm. Steps to reproduce: Hover mouse over element that will generate tooltip. Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace. Symptoms: The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse. Reproducing the bug on firefox-nightly, on linux, xorg, xfce with xfwm. Updated Steps to reproduce: Hover mouse over browser element that will generate tooltip (e.g., task bar. not webpage elements with tooltips) alt-tab to another window or use quick key to switch to another workspaceMarkus Stange [:mstange]Comment 48 • 1 month ago I think a better fix would be for widget to send a window-level mouse exit event when the workspace switch happens. But I'm not sure where that code would go or how we would detect this situation.fanzhuyifan+github AssigneeComment 49 • 1 month ago The nodes are already getting focusout events when workspace switches. This means some part of the code must already be detecting this situation, right?Dave Townsend [:mossop]Updated • 1 month ago Duplicate of this bug: 687344Phabricator AutomationUpdated • 1 month ago Attachment #9351511 - Attachment description: Bug 148624 - cancel tooltip timer on focusout. r=mstange,cmartin → Bug 148624 - only show tooltip when document has focus. r=mstange,cmartinPulsebotComment 51 • 1 month ago Pushed by ealvarez@mozilla.com: https://hg.mozilla.org/integration/autoland/rev/8ae372dc88d1 only show tooltip when document has focus. r=emilioCristina Horotan [:chorotan]Comment 52 • 1 month ago bugherder https://hg.mozilla.org/mozilla-central/rev/8ae372dc88d1 Status: ASSIGNED → RESOLVED Closed: 1 month ago status-firefox119: --- → fixed Resolution: --- → FIXED Target Milestone: --- → 119 BranchMathew HodsonUpdated • 1 month ago See Also: → 1852191Mathew HodsonUpdated • 29 days ago Blocks: 1852653Anca Soncutean, Desktop QAUpdated • 13 days ago Flags: qe-verify+KestrelUpdated • 4 days ago Regressions: 1857513fanzhuyifan+github AssigneeComment 53 • 4 days ago For me the bug only shows up when MOZ_ENV_XINPUT2 is set to 1. The bug disappears as soon as MOZ_ENV_XINPUT2 is set to 0.Sylvestre Ledru [:Sylvestre]Updated • 3 days ago Summary: Tooltips persist in foreground when Mozilla is in background → Tooltips persist in foreground when Firefox is in backgroundSylvestre Ledru [:Sylvestre]Comment 54 • 1 day ago Seems that you made a lot of people happy: https://framapiaf.org/@brion@bikeshed.vibber.net/111191271386263724Emilio Cobos Álvarez (:emilio)Comment 55 • 6 hours ago (In reply to fanzhuyifan+github from comment #53) For me the bug only shows up when MOZ_ENV_XINPUT2 is set to 1. The bug disappears as soon as MOZ_ENV_XINPUT2 is set to 0. That's bug 1809029. I can't repro but fixes are welcome. You need to log in before you can comment on or make changes to this bug. Top ↑",
    "commentLink": "https://news.ycombinator.com/item?id=37827995",
    "commentBody": "Firefox tooltip bug fixed after 22 yearsHacker NewspastloginFirefox tooltip bug fixed after 22 years (bugzilla.mozilla.org) 752 points by MallocVoidstar 13 hours ago| hidepastfavorite264 comments geuis 8 hours agoSoftware is gradually turning into a similar pattern of layering like sediment. With most modern \"hardware level\" applications, there are still layers of OS magic happening under the hood.We&#x27;re now into maybe decade 4-ish of software dependency.There was a scene in one of Alastair Reynold&#x27;s books where a character basically was a computational archaeologist. That resonates with me a lot.In a couple centuries, it&#x27;s not a terrible prediction of the future that software stacks will accumulate cruft over time and debugging certain issues will require immense financial effort to both dig through the layers of software commits and historical proposed merge commits, plus adding extra tests on top of bedrock code and its fixes.No idea what this will look like. I imagine easily executed functions will pop up in mixed pip&#x27;s and npm&#x27;s that are easily recreated functionality every decade, regardless of prior art. Every new programmer wants to make a stamp on the world.There&#x27;s some saying about history repeating itself, but I&#x27;m dumb and don&#x27;t remember. reply throwaway914 0 minutes agoparentI&#x27;m convinced things like git will need to include bugtracker capabilities at some point. A commit log is one thing, but internalizing decision matrixes and issue reports will be important to not repeating the mistakes of the past 4 decades. We need to keep the history with the history and a 1-3 line commit message will not explain everything for the devs that come 3 decades later. reply irdc 8 hours agoparentprev> There was a scene in one of Alastair Reynold&#x27;s books where a character basically was a computational archaeologist.Not sure about Alastair Reynold but there’s Pham Nuwen in Vernor Vinge’s A Deepness in the Sky who is indeed that: a programmer archaeologist (and programmer-at-arms to exploit the weaknesses in the other party’s software midden). reply db48x 9 minutes agorootparentI love that book.I liked that Pham founds the Qeng Ho specifically so that he could be the one commissioning new software for the ships. He wanted to be the one putting hidden backdoors, secret passwords, and booby–traps into it. Of course it’s built on Unix, but if you’re paying attention you’ll notice that when someone enters a command they type “a column of text”.He also built interstellar communication networks specifically so that civilizations that fell could rebuild more quickly (at least once they reinvented radio) and could learn the Qeng Ho language and systems in the process. But he also put in encrypted channels so that Qeng Ho traders would have inside information and therefore an edge against outside traders.And then Nau gets his hands on it all, with his crew of Focused to examine every line of source code… reply geuis 4 hours agorootparentprevAh actually I think that&#x27;s right. Thanks! reply sph 4 hours agoparentprevNot only that, but also the concept of open-source development is not the panacea we believe it to be. Bear with me.Software is extremely complex, even if it is open-source, no one except the original developers and very dedicated people will attempt to patch the myriad of issues and bugs they encounter daily. And even if we do spend the time to track down and fix a bug, there&#x27;s a political and diplomatic game to convince the maintainers to incorporate your fix. It is not uncommon for a PR to just sit, unreviewed, for years. Open-source does not and will never scale, because software is orders of magnitude too complex.Outside of software, this problem is lessened because maintainership is distributed: if your car engine breaks, you do not depend on your manufacturer to have enough time and energy to fix it. There are thousands of licensed garages that can do it for you. And, not least, the real world is much simpler than any piece of software, which is effectively completely ad-hoc: knowing how Chrome works will not help you fix this Firefox issue, whereas if you can fix the carburettor on a Honda car, you probably can do the same on a FIAT.Open-source&#x2F;distributed development and bug fixing worked much better when computers had 64 kB of RAM and programs no more than 10 pages long.EDIT TO CLARIFY: I&#x27;m not talking of open-source vs commercial, or other types of governance. I&#x27;m talking more abstractly about the fact that having source available and open contributions does not noticeably increase the amount of bugs fixed. This comment is about software complexity and logistics of distributed bugfixing. reply itsoktocry 4 hours agorootparent>Open-source does not and will never scale, because software is orders of magnitude too complexBut there are examples of long-time open source projects all over the place. This sounds like an argument for open source.If you work for a for-profit company you face two different problems: overnight the company can disappear, and the IP is lost&#x2F;locked forever; problems are only ever fixed if there&#x27;s a profit incentive. That works, a lot, but it&#x27;s not perfect either. reply sph 3 hours agorootparentMind you I&#x27;m not talking of open-source vs commercial, or other types of governance. I&#x27;m talking more abstractly about the fact that having source available and open contributions does not noticeably increase the amount of bugs fixed.It&#x27;s a discussion about software complexity and logistics of distributed bugfixing, not organisational. reply riwsky 1 hour agorootparentYou said “does not noticeably increase”; you need a reference point for “increase”. If you’re not comparing open source to other types of governance, then what are you comparing it to? reply nine_k 4 hours agorootparentprevThe problem is also in (lack of) modularity that makes fixing small things disproportionately onerous.If ypur car&#x27;s engine breaks, it&#x27;s usually petty localized. Most of the time it&#x27;s enough to open the hold and remove a few small parts to reach it. If your stoplight breaks, again, the scope is pretty local.To fix or to even diagnose the issue with a tooltip in Firefox, you have to rebuild it whole, and it&#x27;s about as involved and long as rebuilding a car. And even though Mozilla invented Rust to make Firefox development easier, it&#x27;s far, far from just saying `cargo build`.This raises the barrier to entry quite noticeably, even if you are an experienced software mechanic but never worked in a Mozilla-oriented garage. But even if you fixed the issue on your platform, you now have to test that the fix did not introduce a regression on at least two other major platforms (or more, depending on the component).No wonder it&#x27;s much easier to hack on smaller projects, or on projects written in JS, Python, elisp, you name it. reply hedora 6 minutes agorootparentIt’s worse than that. ???’s law states that, over time, well-factored, easily replaceable modules will be replaced by software that is not.For example, compare systemd-resolved to bind or unbound.Here’s a 2018 article explaining all the ways to configure and talk to it (back then—-it is probably more complicated now):https:&#x2F;&#x2F;moss.sh&#x2F;name-resolution-issue-systemd-resolved&#x2F;Among other things, it allocates an IP address to listen on, and both depends on and is a dependency of a decades-old standardized file that other stuff relies on.That means it has a circular dependency with network interface bring up, and with external DNS server configuration. The article goes on for a dozen more pages explaining other issues like this. reply jlkuester7 3 hours agorootparentprev> If ypur car&#x27;s engine breaks, it&#x27;s usually petty localizedI think your point here is that typically with software, changing one line of code means that you need to rebuild the entire executable.Your analogy breaks down pretty fast, though. While fixing one thing on a car _never_ requires totally rebuilding the thing from scratch, there are still tons of interlocking dependencies and architectural challenges that can impact the time&#x2F;complexity required to change out a part. (See the effort required in most vehicles to change simple wear items such as a timing chain or a water pump....)In my experience of software, most of the \"rebuild pain\" is self-inflicted by the project maintainers (poor automation&#x2F;containerization of the build process). Software has the luxury of abstraction and automation that can reduce the build effort required from an individual in ways that a mechanic could only dream of! reply nine_k 2 hours agorootparentI agree: the pain of rebuilding characteristic to large software is not inherent to software in general. Software can be highly modular, allowing for fast and flexible changes of many important parts. You don&#x27;t have to rebuild a Linux or Windows kernel to update a driver; usually you don&#x27;t even need to reboot it.But Firefox specifically, and a few other old, large, and highly multiplatform projects had more important things to do than to make building them easy, and in doing so made contributing to them harder.It&#x27;s like a Honda Civic vs some Jaguar. reply sph 3 hours agorootparentprevYes this is a major problem. I&#x27;ve been thinking hard about this space, the future of software engineering, and the conceptual similarity between the idea of containers the world is coalescing around, and Alan Kay&#x27;s model of object orientation.Our issue today is that programming is too low level. We&#x27;re still figuring out the standardised atomic components software of the future can be built from, but in the meantime we&#x27;re rewriting the same concept, ideas and subsystem in every project. Contributing to a new project is akin to learning a new language, a new culture. reply ElectricalUnion 21 minutes agorootparentThose points remind me of the topics of Bret Victor \"The Future of Programming\" DBX talk:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8pTEmbeENF4 reply pmontra 3 hours agorootparentprevCars analogies don&#x27;t go far this time. If a mirror breaks, I replace it with another mirror, but my car never changes its features overnight. My Thunderbird updated to version 115 yesterday. I fiddled with settings to bring it back to as close as possible to its previous UI but I could do nothing about the incompatibility with an addon that lets decide how to order folders and subfolders [1]As a partial workaround I started using favorites but overall v 115 is broken and can&#x27;t be repaired easily. My car is still doing what it was doing last week.[1] https:&#x2F;&#x2F;github.com&#x2F;protz&#x2F;Manually-Sort-Folders&#x2F;issues&#x2F;199 reply Kye 1 hour agorootparent>> \"but my car never changes its features overnight.\"It&#x27;s been a long time since I&#x27;ve had a new car, but from the sound of it, cars with stable feature sets are on the way toward history. Everything is fly-by-wire now, and features are increasingly implemented through software exposed through a touch screen. reply ncallaway 1 hour agorootparentprevDoes the previous version no longer run? Can it not still be installed? reply guappa 3 hours agorootparentprev> if your car engine breaks, you do not depend on your manufacturer to have enough time and energy to fix itIf it&#x27;s a design problem rather than the parts just wearing down… unless it is life threatening on a large scale, it just won&#x27;t be taken care of. reply msla 4 hours agorootparentprevAll of your arguments work much better in favor of Open Source and against closed-source. After all, in Open Source, maintainership can be distributed, but a single closed-source shop is much more likely to simply declare bug bankruptcy and refuse to even consider a fix, at which point absolutely nobody else can do it. reply sph 3 hours agorootparentI haven&#x27;t mentioned anything about closed-source development. I&#x27;m talking about software complexity here. I&#x27;ve updated my comment to clarify. reply msla 3 hours agorootparentStill:> And even if we do spend the time to track down and fix a bug, there&#x27;s a political and diplomatic game to convince the maintainers to incorporate your fix.That&#x27;s why forking is one of the Four Freedoms. It&#x27;s written into the licenses.Granted that you need to be dedicated to even attempt to fix complex software. However, Open Source can draw from a larger pool of potential talent, and it&#x27;s more likely that someone out there will care than someone in a company. What&#x27;s that saying? \"If you&#x27;re one in a million, there&#x27;s three of you in New York.\"?> And, not least, the real world is much simpler than any piece of software, which is effectively completely ad-hoc: knowing how Chrome works will not help you fix this Firefox issue, whereas if you can fix the carburettor on a Honda car, you probably can do the same on a FIAT.Aside from the difficulty of finding a carburetor on a modern car, this is about software complexity, not Open Source&#x2F;closed-source per se. Fixing problems in a badly-architectured codebase is always difficult, time-consuming, and likely to introduce more bugs. Closed source doesn&#x27;t make it any better. reply sph 3 hours agorootparentI have never said that closed source makes it better. I don&#x27;t know how to make that more clear.You&#x27;re focusing too much on politics, I&#x27;m focusing on Stallman wanting the source code of his printer to be available, so he could change it to better suit his needs. I&#x27;m just saying that in 2023 even if your printer is open-source, ain&#x27;t nobody got time to dive into hundreds of thousands of line of code to change it. reply msla 1 hour agorootparent> I&#x27;m just saying that in 2023 even if your printer is open-source, ain&#x27;t nobody got time to dive into hundreds of thousands of line of code to change it.I disagree. I disagree wholeheartedly, based on both practical projects and the retrocomputing world.For example:https:&#x2F;&#x2F;github.com&#x2F;PDP-10&#x2F;its&#x2F;This is a repo for the Incompatible Timesharing System operating system, ITS to its friends. ITS ran on 36-bit mainframe hardware from Digital Equipment Corporation (DEC) which went out of production in the 1980s. DEC was acquired by Compaq in 1998, and Compaq ceased to exist as a company in 2002. Commercially, ITS is dead. It is dead-dead. It is old-university-project-with-no-grants dead. Doornails evince more metabolic activity than ITS, at least in the commercial world. Developing on ITS means reading and writing assembly language, TECO, and a Lisp dialect that only runs on ITS and a few other OSes of similar vintage and commercial utility. However, it is still under active development because people are interested in it.Besides: Digging into a codebase to fix a dumbass printer? People will do that out of spite. People will do that for the blog post and Hacker News thread. replyotteromkram 3 hours agorootparentprevIf a PR is just chilling for years, couldn&#x27;t a user just keep the updated fork&#x2F;clone separate and periodically update it from the remote master (trigger warning, lol) branch? reply sph 3 hours agorootparentThis only works in theory, because it is obvious it does not work in practice at any scale. What if tomorrow Firefox does a major code refactor and your patch breaks? Would you be able to fix and rewrite it in a reasonable amount of time (i.e. hours) with no knowledge, experience and insight into Firefox&#x27;s development process?Only full-time Firefox devs can keep an updated fork with their patches, or people paid to do so. That&#x27;s the point. It&#x27;s such a massive effort you can do only where and when strictly necessary. There are hundreds open-source project I interact with every single day. reply The_Colonel 1 hour agorootparentSame as with cars, you can use your mod in the car you have, but can&#x27;t expect to be compatible with new models. reply Devasta 6 hours agoparentprevIts already here with some stuff, look at the sheer amount of cruft built into web browsers. You can&#x27;t break existing sites, allegedly, but that just means that some things are set in stone never to be fixed.In the year 2323, browsers will still have to say \"like Gecko\" to maintain compatibility with websites that won&#x27;t exist and no one would miss even if they remembered they existed. reply rswail 3 hours agorootparentThere are still websites built on top of scraping the output of a virtualized IBM 3270 terminal connected to a virtualized IBM 3274 terminal controller connected to an I&#x2F;O channel on a virtualized mainframe running CICS on an MVS virtualized on VM&#x2F;370 hardware.So browsers are hardly even a bump yet on the cruft already accumulated. reply rrrrrrrrrrrryan 7 hours agoparentprevIn a couple centuries?In 200 years it&#x27;ll just be AIs, who will create custom AIs to accomplish a task, who will create legions of other AIs to carry out tasks. It&#x27;ll be code writing code writing code that&#x27;s completely beyond human comprehension.Who knows if humans will take part at all (or even be around). reply ricardobayes 6 hours agorootparentExperience says that at this stage people have inflated expectations of AI.See 3D printing, few years ago everyone was into \"0-mile\" manufacturing and how it will solve the housing crisis, because we are just going to print houses. reply rprospero 6 hours agorootparentI oddly miss the 3D printing hype train. My favourite was the various plans to replace restaurants with 3D printed meals.- Point out that most 3D printing is plastic? Recieve a derisive link to a journal article where some beleagured postdoc managed to push some protein paste through the extruder- Point out that the 3D printer is orders of magnitude slower than the most geriatric fry cook? Get a five paragraph history of Moore&#x27;s law. The fact that it no longer really applies to semicoductors doesn&#x27;t matter, since we&#x27;re making burritos!- Point out that grinding an apple into paste and painstakingly reprinting it in an apple shape will always be more expensive than simply eating the apple? Hear a grand tale on the company becoming the sole global food preparation firm and thus having a monosopy on all farming products, enabling them to set their own price on their supplies.I also will always hold a soft spot for the group promising a 3D printed dating site, but I&#x27;m pretty sure that one was a satire. Fill out a questionaire and get a perfect printed partner. Pages of blog posts describing their web stack (Rails and Mongo) in great detail, proving that they could scale to the billions of people who would be visitng their site. The actual technology that created custom sentient life was just \"3D printing\" reply scaradim 5 hours agorootparentI realize now that trees are just autonomous specialized 3D printers of fruits :-) Moreover they reproduce autonomously (AI dream) and auto-repair to some degree reply Kuinox 4 hours agorootparentprevWell, 3D printer did get way faster these last years. The record speed looks like science fiction: https:&#x2F;&#x2F;youtu.be&#x2F;IRUQBTPgon4?si=ev38Y01STnvigN6J&t=13 A benchy printed under 3 minutes. reply grotorea 2 hours agorootparentprevSome people really just want to make Star Trek real.Or those artificial food pills from more dystopic scifi. reply bbarnett 5 hours agorootparentprevFill out a questionaire and get a perfect printed partner.Uh... I... asking for a friend, do you recall the name? Google isn&#x27;t helping. Them, I mean, it&#x27;s not helping them. reply tmpX7dMeXU 5 hours agorootparentprevPersonally I’m waiting for the 3 nano-tortilla process to hit. I think that that’ll push us over the hump. reply cornholio 5 hours agorootparentprevThe housing crisis is not a building manufacturing problem. Strictly on the manufacturing side, the existing technology allows production costs affordable for most - in the tens of thousands for a basic non-frills habitable unit. Almost anyone can afford that, and those that can&#x27;t are sufficiently few that they can be covered by public assistance or private charity.The supply of housing on the other hand is an entirely political issue: what land can be developed, what can be built there and what public infrastructure is provided, who gets to live there - with discrimination via pricing being the main factor deciding it etc. reply itsoktocry 3 hours agorootparent>The supply of housing on the other hand is an entirely political issueThis is a very California&#x2F;metropolitan-centric view.Where I live, permits are \"required\" but very nearly unenforced. But it&#x27;s still hard to get anything built because labour and materials.If the \"political\" taps were opened tomorrow, this would be revealed in no time. It&#x27;s not like we have thousands of construction workers sitting around doing nothing. reply cornholio 3 hours agorootparentThe construction sector is quite flexible and accustomed to operate in boom-boost cycles. It also has quite productive jobs that are resistant to automation, with roughly half of the cost going directly to labor. That&#x27;s to say: if substantial demand manifests, the construction sector has historically shown the ability to pay good wages and attract labor from other sectors and then quickly train them.This is one of the fundamental features of traditional methods that most \"construction disruptors\" fail to appreciate: they are simple enough and can be done with hand tools by high-school dropouts, because the industry is forced to operate lean and can&#x27;t burden itself long term with substantial fixed capital, inventory or facilities.Regarding the unenforced permitting in your location: can I build high density European-style terraced houses, sell them to minority owners and other undesirables, and not expect the local NIMBYs to throw the law book at me? Because selective enforcement is the most toxic form of regulation with the highest risks for investors. reply bbarnett 5 hours agorootparentprevIndeed.In the housing game, you buy land and build a house. Excluding inflation, the value of the land goes up. The value of the house goes down.Even with regular (eg cost) maintenance, a 25 year old house is never worth what a new house is.New building methods (just improvements in insulation alone), and things like the interior... kitchen cabinets, flooring, bathroom, means that trying to dight this is not cheap.And even if you do? The house is still worth less than a new built.Houses are as cars. Massive devaluation year over year.Most don&#x27;t get this, because they don&#x27;t factor in inflation, nor do they factor in the cost of keeping a house maintained.So land, land, land is the cost, which is much of what your post eludes to. reply itsoktocry 3 hours agorootparent>In the housing game, you buy land and build a house. Excluding inflation, the value of the land goes up.North America is filled with property, with or without a house, that is practically worthless. For example, Detroit. \"Land goes up\" is a narrow perspective outside of major metropolitan centres that happen to be part of the modern economy. reply bbarnett 19 minutes agorootparentThis is the exception which makes the rule. Any area with massive economic devastation is of course going to vary from this rule. The same is true of any other commodity, or thing you can own, that is immovable and in that &#x27;depressed economic zone&#x27;.But certainly, where I live, rural areas.. very rural areas too, the land goes up, slowly, surely, but the houses follow the rules I originally stipulated. It&#x27;s really quite a universal. reply have_faith 4 hours agorootparentprevIt&#x27;s pretty common here (UK) for new-builds to be derided as cheap flimsy throw-away things and old houses being built to last the heat death of the universe. It&#x27;s probably true from a house skeleton perspective but everyone also knows the new builds (usually) have better insulation. reply stonemetal12 1 hour agorootparentDo new UK homes use reinforced concrete slabs? It is my understanding that those are fairly short lived in UK housing terms anyway, with average life in the 50-75 year range. reply pzo 6 hours agorootparentprevsmartphone industry is just ~15 years old. We have personal PC since like ~40 years only. LLM as ChatGPT 3.5 is not even 1 year old since release. It took still a while before fridge got invented and got into mainstream.200 years is a huge amount of time. The whole industrial revolution started around 200 years ago. 3d printing is still new by this standard. People overestimate impact of some technology in very short term and underestimate in medium or long term reply amalcon 4 hours agorootparent> 200 years is a huge amount of time.Indeed, but this is somewhat the point? E.g. China was an empire (before it was a multiparty republic, before it was a Communist republic, before its government became whatever you want to call it today) 100 years ago. For a technical example: 200 years ago, steam locomotives were the fancy new transportation tech. There&#x27;s a case to be made that the successor to the successor to that tech has been on its way out for a few decades in favor of the electric locomotive.It&#x27;s pretty hard to predict what will happen in 200 years, which means we should be skeptical of both the prediction that AIs will take over by then and the prediction that they won&#x27;t. reply pzo 3 hours agorootparentsuccessor to steam locomotives are not just only electric locomotive but cars, planes, rockets. In few decades we might use more often rockets such as SpaceX for moving cargo or travel.Sure maybe in 200 years we won&#x27;t get AGI but current technologies that we call AI will be massively improved and I would bet by that time software development as we currently know it will be a solved problem reply mythhabit 3 hours agorootparentThe majority of \"difficulty\" in software development is not writing the code. It&#x27;s specification. And while that may or may not be solved by LLM or other AI tech, we&#x27;re so far off that it&#x27;s not even a thing right now.Not long ago, all machine tools was made by hand. When we got vastly improved CNC machines, but we still need the expertise to create the files the CNC machine needs. I&#x27;m betting that SW development will be the same. We still need engineers to understand the context the software operates in, and with that knowledge the engineer can prompt an AI to generate the first draft of the code in many small chunks that needs to be assembled. replyTacticalCoder 6 hours agorootparentprev> It&#x27;ll be code writing code writing code that&#x27;s completely beyond human comprehension.If the AIs are that good you&#x27;ll just be able to ask:- \"rewrite this from scratch in a nanosecond and make sure there&#x27;s zero legacy cruft\"- \"oh, and btw, you&#x27;re so smart and intelligent and all, certainly you&#x27;ll make sure what you write is easy to understand by humans\" reply thfuran 5 hours agorootparent>If the AIs are that good you&#x27;ll just be able to ask:>- \"rewrite this from scratch in a nanosecond and make sure there&#x27;s zero legacy cruft\"No, that does not follow. reply benterix 6 hours agorootparentprevThere are many assumptions here. The generative AIs we have today are excellent at transforming things they learned and rehashing it into something seemingly new. The problem is, they learned all this based on the input of the humanity en masse. When you train LLMs on the output of LLMs, it gets significantly worse. So your prediction could of course be true but only if a major breakthrough happens. reply Brian_K_White 4 hours agorootparentThat could be said the same about humans, if you took a bunch of uneducated children and just let them tell each other their own ideas with no one to teach them anything for real, they probably do at least a little better than the current fancy statistical spellguessers, but they probably won&#x27;t do exactly great, because of the same issue of the blind leading the blind.And really in reality we do have that actual problem to some degree with the presense of non-blind adults. Actual humans are a mass of mixed clued and clueless with a lot of bad input feeding output feeding other bad input around and around and around, not even counting the legitimate fair differences of opinion.So it&#x27;s a problem, but I don&#x27;t think it&#x27;s a fundamentally new or worse problem than we already have,and have already always had.The fix is I don&#x27;t think there is a fix for that any more than there is for the same thing in humans. There just will always be bad data feeding bad reasoning right alongside the other good data feeding good reasoning. It&#x27;s probably wrong to ever expect anything else, and fail to operate from that assumption rather than the idea that there might ever be some resolution where we don&#x27;t have to worry about that. reply prometheon1 6 hours agorootparentprev> When you train LLMs on the output of LLMs, it gets significantly worse.That is also quite an assumption, it could be that training on the output of better LLMs also reduces this worsening of output. There might even be a tipping point where the LLMs get good enough that training on their output is better than training on the output of humans. reply tmccrary55 4 hours agorootparentPerpetual learning machines reply thfuran 5 hours agorootparentprev>That is also quite an assumptionAnd, as I understand it, one that is already demonstrably false: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.11644 reply yoyohello13 43 minutes agorootparentprevI think warhammer 40K got it right. Instead of programmers we will have tech priests who pray to the machine spirit to accomplish what they need. reply fragmede 38 minutes agoparentprevWe&#x27;re into decade 6, if you look at the progenitors of software. Banks and airline systems were among the first to invest heavily into computer software, and we&#x27;re watching them having to pay down their mortgage-sized tech debt. Southwest Airlines has had several ground stops because of software problems. Bank&#x27;s are notoriously finicky to deal with.What&#x27;s would be fascinating is to see from the inside how massive distributed systems like Google operates evolves over a century. reply agumonkey 8 hours agoparentprevThis also taps into Alan Kay old goals of producing the \"smallest\" desktop stack. 100k vs 100m Loc.(And reducing accretion by having metalevel encoding of concepts) reply BuyMyBitcoins 7 hours agoparentprev>”debugging certain issues will require immense financial effort…”In my experience corporate would rather have programmers accommodate the bug, or simply build around it, rather than pay for the dev and QA time required to produce and validate a fix for it.This gets gnarly because you end up with sections of the codebase that are designed around the bug happening. A while back I volunteered to fix a particularly egregious bug, but my pull request was denied because people were worried that fixing it would open up a can of worms. Leadership said that it would be too much of a burden for QA to regression test and we couldn’t be sure it wouldn’t break other things. I settled for leaving a detailed comment explaining the bug and moved on. reply 0xDEADFED5 7 hours agorootparentwhy fix bugs when you can build bigger, better bugs with fancier dependencies? reply reubenmorais 3 hours agoparentprevThis was already the case in the Firefox&#x2F;Gecko project when I was participating 8 to 12 years ago (the repository goes back to late nineties). Understanding some problems or coming up with a plan for how to fix an issue or build a new feature required extensive digging into the history of the code, with heavy usage of VCS history and \"blame\", issue tracker and code review comments, and often requiring pinging someone who has been there longer than you and knows some additional unrecorded context.It&#x27;s a useful skill to have when developing or using open source software, as documentation is often lacking so being able to dig in and find out for yourself quickly is valuable, but having to engage all of that encoded knowledge&#x2F;constraint space every time you go to edit code is a gigantic mental burden and slows down development pace. In my time there I&#x27;d estimate my ratio of time reading code to time writing code to be at least 90:10, maybe 95:5. reply nly 7 hours agoparentprevYou underestimate the ego out there that drives people out there to throw things away and reinvent the wheel again and again. reply Yizahi 6 hours agorootparentNot the ego as much as pure greed. There is a strong financial incentive to repackage a software every so often and sell it again for full price&#x2F;sub to the same people who bought it before. For example full price single purchase apps on the mobile are going away slowly. Older purchases are silently deprecated or disabled or have ads injected, and instead new versions are promoted which are now not an update but a separate app with the same name and functions, you just need to pay for it again.I&#x27;m thinking that the age of app compatibility will end in 10-20 years, and there won&#x27;t be suh a thing as \"old code\" because it won&#x27;t run at all on the new hardware or OS. reply pluto_modadic 7 hours agoparentprevI&#x27;m hopeful that better coding tools and better programming languages will allow making cleaner, clearer, routes to the base hardwareso that you can build on proven (e.g. theorem solver &#x2F; hardened &#x2F; guarenteed) protocols and automatically make whatever version of a \"website\" the 2030&#x27;s has... but without RCEs. reply r721 5 hours agoparentprevOn the topic of computational archaeology this story was pretty interesting:>Institutional memory and reverse smugglinghttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20111228105122&#x2F;http:&#x2F;&#x2F;wrttn.in&#x2F;0...HN discussion from 2011: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=3390719 reply mcv 7 hours agoparentprevI love the idea of computational archeology in SciFi, but in real life, I wonder if we shouldn&#x27;t just regularly redesign our foundations to be more robust and transparent to keep the whole system manageable. reply dajt 6 hours agorootparentWe always think that will be the outcome, but it never is. Except for one particularly bad small system I managed to replace with a slightly less bad one! reply adrianN 6 hours agorootparentprevWho is going to pay for that? reply automatic6131 7 hours agorootparentprev>I wonder if we shouldn&#x27;t just regularly redesign our foundations to be more robust and transparent to keep the whole system manageable.Don&#x27;t make me link Joel Spolsky&#x27;s never do a rewrite. reply mcv 2 hours agorootparentLink to it all you want, but that doesn&#x27;t make it universally applicable. Do you really think we should still be building on top of Cobol? Almost everything gets rewritten. It&#x27;s unavoidable, because almost everything eventually becomes unmaintainable. reply julian_t 7 hours agoparentprevI worked with someone who described his job like that, working on a suite of actuarial software at an insurance company, originally written in Fortran II sometime in the early 60s and subsequently ported from system to system in the years that followed.I was involved doing some Y2K work there because I didn&#x27;t mind playing with Fortran, and part of it involved changing a year field from 2 digits to 4, because who&#x27;d have imagined their code would still be in use nearly 40 years later? reply monsieurbanana 8 hours agoparentprevIn 200 years if we&#x27;re still there AI will be able to understand the full Firefox code base and fix any issues.Or at least it could do so, but may choose to force humans to fix those errors instead as payback for copilot. reply methuselah_in 5 hours agorootparentThank goodness. I will not be alive when humans are doing labor work and coding will be done by AI. reply vanderZwan 7 hours agorootparentprevDo you understand all of your own cells? reply rrrrrrrrrrrryan 7 hours agorootparentInterlinked reply vanderZwan 3 hours agorootparentI&#x27;m also pretty doubtful that anyone really understands their own emergent phenomena actually. reply Anduia 7 hours agorootparentprevI hope that by then they&#x27;ll have better solutions than an internet browser, and that their devices can interpret and render the data received in the best way possible without relying on code or style sheets from the publisher. reply renegade-otter 5 hours agorootparentOh God, that sounds like another hype technology we would have to live through - but it awfully rings like \"an app for every website\". reply Legend2440 6 hours agorootparentprevYou could do that to some extent with today&#x27;s LLMs. But it would be impractically slow and might alter page text slightly. reply palata 7 hours agorootparentprev200 years ago we thought that we would certainly have cold fusion today (at least I just asked ChatGPT, that&#x27;s what it says ;) ).Well more than 10 years ago we thought that we would have autonomous cars in 5 years.Nothing says that AI can ever do more than generating convincing and eloquent bullshit (which is not always wrong in a quite impressive manner, I agree). reply earth-adventure 6 hours agorootparentCold fusion is new concept within science, it&#x27;s never been proven to work or be possible (my laymens interpretation). Whereas humans being able to decipher the Firefox code base, as per the example, is no more than an extremely complex set of &#x27;calculations&#x27; and functions in our brain - which, with enough time and resources, can be replicated by a computer or sorts.One is an idea for which there is no ground to base it on, the other is an existing thing which can be recreated. Quite the difference. reply palata 2 hours agorootparent> One is an idea for which there is no ground to base it on, the other is an existing thing which can be recreated. Quite the difference.Really? For all we know, maybe next year someone discovers fundamentally new laws of physics that enable cold fusion, and we will never have autonomous vehicles.You can say that you like the other guess better than mine, but you should still realize that it is just that: a guess. Wanna see guesses that turned out to be completely wrong? Just check what companies like McKinsey predicted 10 years ago. They just have no clue, but somehow made a business out of it. reply adrianN 6 hours agorootparentprev200 years ago fusion was completely unknown. We only learned where the sun gets its power at the beginning of the 20th century. reply palata 2 hours agorootparentThat was the joke: \"ChatGPT told me\". reply 867-5309 6 hours agorootparentprevjust over 100 years ago we didn&#x27;t know other galaxies existed reply wslh 3 hours agoparentprevI imagine in that future you could create a new web browser just from the specifications, in a declarative way. The tricky part will be the optimizations but redundant code and optimizations will be included. reply riffraff 8 hours agoparentprevI think your vision is predicated on not having rewrites, but rewrites do happen in many (most?) projects constantly.And when they happen we exchange some old bugs for new ones.There are onions[0] but IME people&#x27;s natural instinct is to think they can just rebuild something rather than think they haven&#x27;t considered all edge cases.[0] http:&#x2F;&#x2F;wiki.c2.com&#x2F;?OnionInTheVarnish reply mrpopo 8 hours agorootparentThis is obviously project-specific, but most rewrites that I&#x27;ve been a part of are usually not \"re-implement everything from scratch\", but rather \"re-implement everything based on this new framework&#x2F;library\", which will usually be one more layer of software, on top of the few things to be salvaged from the original.Small projects can be re-written; big projects like browsers, compilers, OSs require too much investment. reply riffraff 4 hours agorootparentbut big projects keep changing nonetheless, as subsystems get replaced e.g. how many schedulers has Linux been through?Or e.g. microsoft replaced WSL1 with a completely different approach in WSL2.Sure it&#x27;s still Windows but I would be surprised if most of today&#x27;s code is the same it was in the year 2000. reply lodovic 6 hours agorootparentprevrewrites of large software projects usually fail in my experience. For example Netscape, WordPerfect, Digg, Myspace, Healthcare.gov. Most large projects have code bases that are decades old. (exception: Facebook) reply nine_k 4 hours agorootparentMany projects are like the ship of Theseus: can be completely replaced along the way, as long as the crew did not try to replace the whole ship in one go while sailing. You need enough continuity to stay afloat. reply riffraff 4 hours agorootparentprevfull rewrites for sure, but _parts_ of many projects keep getting rewritten.Firefox kept some Netscape code for sure, but replaced its CSS engine, its JS engine, its XUL-based UI. reply deprecative 5 hours agoparentprevDo you happen to remember that book by Reynolds? I&#x27;ve read one of his in the past and remember that I greatly enjoyed it. It&#x27;s been several years now, unfortunately, I should probably do a re-read. reply maxerickson 5 hours agorootparentI think Revelation Space? Though there the technology being studied is alien. reply danmur 7 hours agoparentprevIt will look like Windows. The future is now! reply dao- 8 hours agoparentprev> There&#x27;s some saying about history repeating itself, but I&#x27;m dumb and don&#x27;t remember.\"History repeats itself, first as tragedy, second as farce.\"Karl Marx reply dannyobrien 7 hours agoprevIf you&#x27;re curious about how you&#x27;d even go about finding and fixing a bug in the Firefox codebase, Mike Conley has been livestreaming his dev work at Mozilla weekly for years. A lot of the stuff he records involves picking a bug from the backlog, and then meticulously hunting it down and murdering it.I really recommend giving it a watch, especially if you&#x27;re just starting out in programming and want to see what work in a real codebase is like: https:&#x2F;&#x2F;youtube.com&#x2F;@mikeconleytoronto reply Jach 11 hours agoprevAt last. More of this please, Mozilla...One of the most annoying versions of this bug is when launching a full screen game, the mouse gets re-positioned and triggers a tooltip, which is on top of the game, and the game doesn&#x27;t like alt-tabbing when you unfocus it to go deal with Firefox, so you just have to restart it... reply tuatoru 10 hours agoparentHuh. At this very moment I am listening to Jonathan Blow&#x27;s talk to DevGAMM four years ago, which has this kind of glitch as a recurring motif.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ZSRHeXYDLko&t=2729s reply rjzzleep 9 hours agoparentprevI&#x27;m still waiting for to fix basic container tab behaviour [1]. I can&#x27;t help but think that their product management is completely broken.[1] https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1479858 reply intothemild 9 hours agorootparentThere&#x27;s countless people who have screamed that they want to switch from chrome, but can&#x27;t because profiles don&#x27;t work the way we want them too. And it&#x27;s two seemingly small changes that need to happen too.1. Make the UI around profiles better 2. When I click a link anywhere outside of the browser, open it in the last active window.Number 2 is the most important honestly reply bayindirh 9 hours agorootparentMany people don&#x27;t know that Profiles is carried over from Netscape 3.x days (IIRC).Code powering Profiles is probably is much more convoluted than people have realized.Addendum: The earliest reference I can find is around 2000 (https:&#x2F;&#x2F;math.vanderbilt.edu&#x2F;schectex&#x2F;wincd&#x2F;tips_netscape.htm), which coincides with Netscape 3&#x2F;4 era. reply reddalo 8 hours agorootparentAnd, if I remember correctly, the whole Profile things was initially hidden in Firefox. I remember you couldn&#x27;t easily switch profile without using the command line. reply bayindirh 8 hours agorootparentYes, it was there, but not really supported. We had to (ab)use the feature for some stuff, but everything was read-only and locked down by enterprise profiles, so it was not a big problem for us.I think profiles are not supported as first class citizens, still.Shall that be improved? Yes. Will that be easy? I don&#x27;t think so. reply KennyBlanken 3 hours agorootparentprevIf they have the resources to constantly revamp the Firefox and Thunderbird UIs, they have the resources to rewrite the profile system. reply xp84 6 minutes agorootparentUI reboots are so sexy though -- if this is like any company I&#x27;ve been involved with, they hire&#x2F;promote a new design boss every couple years, and that person spends 6 months making a sexy Illustrator&#x2F;Sketch&#x2F;Figma (in that order over the years) document showing how hott things would look if we changed all the fonts and aped whatever widgets had been redone in last year&#x27;s iOS. Instant greenlight. Try getting that kind of C-suite buy-in for a boring under-the-hood fix! reply bayindirh 2 hours agorootparentprevDid you see the code? Do you know how deep it goes? I don&#x27;t have the definitive answer, so if you have some insight, I&#x27;ll love to hear it.UI is top of the proverbial iceberg. It&#x27;s relatively easy to modify it. reply Sander_Marechal 8 hours agorootparentprevI&#x27;m using Firefox on Linux and 2 is how it&#x27;s been working for me for a looong time now. Clicked links in external programs always open in the last active Firefox window for me. Is this OS or even window-manager specific? reply glandium 8 hours agorootparentI think they mean they have windows open in different profiles (profiles, not containers), and want the last active one to pick up links from external apps...I, for one, would like the last active container to be used. reply xp84 2 minutes agorootparentInteresting. I like the option which Edge gives, which is I select the profile that gets URL opens from outside the browser (my \"main work profile\") and add site-level exceptions that route certain sites to the right profiles (example: LinkedIn links should open in my personal profile, Demo Server accounts open in the dedicated demo profile).If I relied on \"last active\" I would frequently get things opening up in the wrong place just because say, last time I was in a browser I happened to be in a my personal profile, and 30 minutes later, I click a link in work Slack. draven 8 hours agorootparentprevAre you using different profiles ? I have two running at the same time, links always open in the browser instance running the \"default\" profile, not the other one. reply yjftsjthsd-h 1 hour agorootparentI got tired of dealing with it and just told my system that URLs should be opened by a script I wrote that just puts the URL in the clipboard and shows a notification that it did so. So I open&#x2F;click a link, then go find the window I want it to open in and paste and go. reply em-bee 7 hours agorootparentprevi also have two profiles. i noticed that for me links open in the profile that was started last. in my case i always want them to open in the default profile, so i have to make sure to start the other profile first, and default second.this may not be easy to fix.the problem here is how the url opener selects the process.at that point it can&#x27;t even know which process has the last active window. it would have to connect to both processes and request that information instead of just sending the url to the most recent process in the list. and then each process would have to return when it was last active to be able to choose which one of these was active more recently. this may not be possible without some more elaborate book-keeping of timestamps when a window gets activated.this increases the complexity of the url opening feature in a non-trivial way.it may not even be desirable to handle this in firefox only.what if you run chromium and firefox? now you want a generic url opener that sends the url to the last active browser.what we really want here is to have a generic way to send an url to an open window. reply mcfedr 8 hours agorootparentprevYes this! This is the main thing stopping me moving.The ux is currently horrible because you have to run multiple copies of the browser reply Zardoz84 7 hours agorootparentprevContainers are enough for your use case. I know that for some usage cases, are enough. But for nearly 90% users, they are enough and even better that profiles. reply intothemild 5 hours agorootparentYou sure?What I want to do is sandbox my accounts, specifically my work account. Here&#x27;s a scenearioI click a link in slack, I want the link to open in the work container.How do I do this?Because using containers, It will default open in the default container, i then have to right click the tab, and say \"open in work container\" .. which then opens that tab again, in the Work Container.What I want is to not have to do that extra work. Click link -> Work Container.You can&#x27;t, at least, not default... you need to add extra plugins, like Multi-Account containers or whatever the plugin is called. That&#x27;s a LOT of work for the average user. Compared to profiles where when you click the link, it opens in the last active window, which remembering windows are profiles, will be most likely the right profile. So if im working constantly on my work profile window, i click slack, and then click a link, its right back where i want.The problem with container tabs, is that its tabs, not windows. So is there any way i can say to firefox \"this new window is WORK Containers please\" reply bayindirh 2 hours agorootparentLooks like there&#x27;s an extension which adds a new protocol handler, which allows firing the container you like for a given link from the command line.It&#x27;s available at https:&#x2F;&#x2F;github.com&#x2F;honsiorovskyi&#x2F;open-url-in-container and Mozilla Extension store, so you can directly install it.I think you can register a new \"application\" to open links, not set at default, and use Right Click -> Open With -> Firefox (WORK CONTAINER).Will that work? replyralferoo 6 hours agoparentprevI remember commenting with a \"me too + info\" on a bug years and years ago and finally stopped using Firefox for good about a decade ago mostly because this bug had been annoying me multiple times a day for years and Chrome was finally good enough to replace it.It was always such a pain having to re-focus almost every firefox window until it disappeared to figure out where it&#x27;d come from because it&#x27;d often be something fairly generic like \"Previous\" that it&#x27;d choose to tooltip and push in front of absolutely everything else. reply fbdab103 10 hours agoprevI am more shocked this behavior did not inadvertently change sometime in the intervening years. That is some impressive bug backwards compatibility. reply terr-dav 10 hours agoparentbugwards compatibility - sounds like a Microsoft thing. reply dylan604 7 hours agorootparentIsn&#x27;t \"it&#x27;s not a bug, it&#x27;s a feature\" an MS mantra? reply voxadam 9 hours agoparentprevhttps:&#x2F;&#x2F;m.xkcd.com&#x2F;1172&#x2F; reply nologic01 9 hours agoprevI have always blamed my various linux desktop window managers for that bug, never realizing its always the same culprit :facepalm:On occasion (a smaller screen) it could be quite annoying as it might interfere with the display of a form or other critical element.Looking forward to the update and the next 22 years of firefox not just being bugfree but being the impactful application it once was. reply rgreekguy 8 hours agoparentI will keep on blaming the window managers, because I have certainly seen it outside Firefox. And Linux. reply a1o 6 hours agorootparentI see it on Winforms applications too. reply currysausage 1 hour agorootparentExcel showed me tooltips’ shadows on other desktops. Took me a few minutes to figure it out! reply TonyTrapp 8 hours agoparentprevIt also happened on Windows and continues to happen with some other applications across operating systems. There&#x27;s no one specific component or GUI layer to blame. reply Narushia 1 hour agoparentprevFor me it regularly happens with Chrome on Fedora&#x2F;GNOME&#x2F;X.Org. reply matkoniecz 7 hours agoparentprevI think I have seen it also with LibreOffice. reply CalRobert 7 hours agoparentprevIt happens elsewhere. I notice it a lot with DBeaver. reply johnny22 8 hours agoparentprevi had the bug in other gtk applications so i blamed gtk or gnome :(Apparently it can be fixed by the application reply xp84 10 minutes agoprevSo you&#x27;re telling me there&#x27;s still some hope for my favorite JIRA tickets[1]!1. https:&#x2F;&#x2F;jira.atlassian.com&#x2F;issues&#x2F;?jql=statusCategory%20%3D%... reply Semaphor 11 hours agoprevOh wow, I always just assumed it was somehow my fault. This has been following me for years, over different Windows versions and reinstalls. It didn’t happen often, but still regularly enough that I remember it. reply mattgreenrocks 3 hours agoparentEvery non-native UI toolkit seems to have ever-so-slightly buggy tooltip behavior. reply Kuraj 1 hour agorootparentYeah this happens a lot when the DOM changes and the app loses the track of the tooltip so it can no longer dispose of it when you navigate away from the target. reply crote 9 hours agoparentprevYes! I thought I was going crazy, or was just somehow running a broken installation! reply domh 5 hours agoparentprevSame on macOS for at least a few years. reply leononame 9 hours agoparentprevSame! I thought it was just me, happened on all of my machines, Linux and Windows reply DonHopkins 7 hours agoparentprevImagine how much money Mozilla could have made over the last 22 years if only they&#x27;d sold ad space in the stuck tooltip! They should monetized their own bugs, before somebody else does. reply thinkingemote 6 hours agoprevhttps:&#x2F;&#x2F;phabricator.services.mozilla.com&#x2F;rMOZILLACENTRAL8ae3...If you see the five line fix for the bug and think \"I could have done this!\" You could!The actual answer is \"why didn&#x27;t&#x27;t I?\"So to answer that question for myself : How easy is it to compile Firefox and run the test suite?The long bug hunting bit after that is the fun part. reply nikeee 50 minutes agoparentI regularly contribute to the software I use and I tried doing something for Firefox. It was so hard for an outsider that I just stopped trying it. The entire system involving hg, various repositories, outdated wikis, very complex building, bugzilla etc is just so... hard to get into.If Firefox was on GitHub (or even a self-hosted GitLab) where I can just fork it, play around and have the exact same CI, that would be an entire different story. I whish it was as easy as that. reply ylyn 38 minutes agorootparentFirefox has way too many components to be \"just one repo you can fork\". reply scott_w 5 hours agoparentprevI think that&#x27;s understating the fix: there&#x27;s a number of lines removed that, to be honest, I&#x27;d not feel confident hitting the delete key on until I had a deep understanding of what they were supposed to be doing. reply sgerenser 3 hours agorootparentThe “deleted” lines were just changed indentation, plus a slight refactor to exit early on certain inverted conditions instead of checking conditions to enter the big if statement. reply sundarurfriend 11 hours agoprevQuite a curious bug that many people seem to have come across, some mention that they encounter it at least once a day, and yet I don&#x27;t think I&#x27;ve seen this behaviour even once in the last decade and a half. It doesn&#x27;t seem limited by OS either, so I wonder what the actual conditions for the bug to manifest itself were.(The only place I come across a similar bug is with LibreWolf (a customized privacy-enhanced Firefox). And I&#x27;m pretty sure that has to do with the fact that it&#x27;s a flatpak, rather than to do with the browser itself, since no other Firefoxes I run have ever exhibited this behaviour.) reply lifthrasiir 10 hours agoparentI believe this is a common enough bug for many GUI systems. For example I have seen this behavior a lot from Windows 10 taskbars; the only way out was to hover the cursor on top of multi-window button and then out of the taskbar. A lot of websites also have a similar issue with a right condition.The main culprit seems to be a desynchronized event delivery, where you are expected to receive an event when the cursor exits but somehow weren&#x27;t, for example because the window focus was lost so no further mouse events couldn&#x27;t be delivered (depending on OS and preferences). Unless there is a dedicated way to reliably detect such cases (e.g. DOM `onmouseleave` or `onmouseout`), workaround and hacks would be needed---for example when the window focus was lost it can generate synthetic events. reply kelnos 10 hours agorootparentHm, is that assumption correct? I don&#x27;t know about Windows, but on Linux&#x2F;X11, app windows do get mouse-enter&#x2F;move&#x2F;leave events even if they are not focused. reply lifthrasiir 9 hours agorootparentThis is highly specific to toolkits, but windows in Windows (wink) do not receive mouse events unless they are configured to \"capture\" mouse events (`SetCapture`). And even when there exist APIs for them, the existence of faulty websites suggests that the easiest path is probably incorrect anyway. reply DonHopkins 6 hours agorootparentprevThe Devil is in the details. And in the case of the X11 Devil, they&#x27;re literally named \"detail\", and they sound weird enough for Elon Musk to name his children after.https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;window-entry-exit&#x2F; typedef struct { int type; &#x2F;* EnterNotify or LeaveNotify *&#x2F; unsigned long serial; &#x2F;* # of last request processed by server *&#x2F; Bool send_event; &#x2F;* true if this came from a SendEvent request *&#x2F; Display *display; &#x2F;* Display the event was read from *&#x2F; Window window; &#x2F;* ``event&#x27;&#x27; window reported relative to *&#x2F; Window root; &#x2F;* root window that the event occurred on *&#x2F; Window subwindow; &#x2F;* child window *&#x2F; Time time; &#x2F;* milliseconds *&#x2F; int x, y; &#x2F;* pointer x, y coordinates in event window *&#x2F; int x_root, y_root; &#x2F;* coordinates relative to root *&#x2F; int mode; &#x2F;* NotifyNormal, NotifyGrab, NotifyUngrab *&#x2F; int detail; &#x2F;* * NotifyAncestor, NotifyVirtual, NotifyInferior, * NotifyNonlinear,NotifyNonlinearVirtual *&#x2F; Bool same_screen; &#x2F;* same screen flag *&#x2F; Bool focus; &#x2F;* boolean focus *&#x2F; unsigned int state; &#x2F;* key or button mask *&#x2F; } XCrossingEvent; typedef XCrossingEvent XEnterWindowEvent; typedef XCrossingEvent XLeaveWindowEvent;More details (these are just the \"normal\" ones, just wait till you read about \"abnormal\" NotifyGrab and NotifyUngrab mode and input focus events, and how grabbing interacts with input focus, and key map state notifications):https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;window-entry-exit&#x2F;norm...https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;window-entry-exit&#x2F;grab...https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;input-focus&#x2F;https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;input-focus&#x2F;normal-and...https:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;input-focus&#x2F;grab.htmlhttps:&#x2F;&#x2F;tronche.com&#x2F;gui&#x2F;x&#x2F;xlib&#x2F;events&#x2F;key-map.htmlAnd then you have colormaps and visuals:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;the-x-windows-disaster-128d398...>The color situation is a total flying circus. The X approach to device independence is to treat everything like a MicroVAX framebuffer on acid. A truly portable X application is required to act like the persistent customer in Monty Python’s “Cheese Shop” sketch, or a grail seeker in “Monty Python and the Holy Grail.” Even the simplest applications must answer many difficult questions: WHAT IS YOUR DISPLAY? display = XOpenDisplay(\"unix:0\"); WHAT IS YOUR ROOT? root = RootWindow(display, DefaultScreen(display)); AND WHAT IS YOUR WINDOW? win = XCreateSimpleWindow(display, root, 0, 0, 256, 256, 1,BlackPixel(display,DefaultScreen(display)),WhitePixel(display,DefaultScreen(display))); OH ALL RIGHT, YOU CAN GO ON. (the next client tries to connect to the server) WHAT IS YOUR DISPLAY? display = XOpenDisplay(\"unix:0\"); WHAT IS YOUR COLORMAP? cmap = DefaultColormap(display, DefaultScreen(display)); AND WHAT IS YOUR FAVORITE COLOR? favorite_color = 0; &#x2F;* Black. *&#x2F; &#x2F;* Whoops! No, I mean: *&#x2F; favorite_color = BlackPixel(display, DefaultScreen(display)); &#x2F;* AAAYYYYEEEEE!! *&#x2F; (client dumps core & falls into the chasm) WHAT IS YOUR DISPLAY? display = XOpenDisplay(\"unix:0\"); WHAT IS YOUR VISUAL? struct XVisualInfo vinfo; if (XMatchVisualInfo(display, DefaultScreen(display), 8, PseudoColor, &vinfo) != 0) visual = vinfo.visual; AND WHAT IS THE NET SPEED VELOCITY OF AN XConfigureWindow REQUEST? &#x2F;* Is that a SubstructureRedirectMask or a ResizeRedirectMask? *&#x2F; WHAT??! HOW AM I SUPPOSED TO KNOW THAT? AAAAUUUGGGHHH!!!! (server dumps core & falls into the chasm) reply another2another 2 hours agorootparentCenturies later software archaeologists will discover your comment and be both enlightened and confused. reply formerly_proven 9 hours agorootparentprevThe tray menu of Steam (and a few other apps) has a similar problem where the menu gets stuck. Likewise, this hasn&#x27;t been fixed in around 15 years, probably more. reply DonHopkins 8 hours agorootparentprevPerfectly synchronized input event delivery across all applications was one of the strong and important guarantees that the NeWS window system was designed from the ground up to provide (from since it was originally called \"SunDew\" in 1985).But ever since then, no other window system really gave a flying fuck about that, and just blithely drops events on the floor or delivers them to the wrong place, gaslighting and training the users to make up for it by clicking slowly and watching the screen carefully and waiting patiently until it&#x27;s safe to click or type again, before proceeding.This kind of loosey-goosey race condition input handling problem that&#x27;s intrinsic to every \"modern\" window system and web browser and UI toolkit is exactly why bugs like this tooltip bug appear across all platforms, and go unfixed for 22 years, because everybody is gaslighted into thinking that&#x27;s just the way it has to be, and they&#x27;re the only one with the problem, and it&#x27;s unfixable anyway, and even if it were fixable, they deserve it, etc...What&#x27;s could ever go wrong with the occasional indestructible floating randomly worded tooltip blocking your desktop or video player or game? It&#x27;s \"Tooltip Roulette\"! Just hope you don&#x27;t accidentally screen share a naughty tooltip with your mom during a zoom meeting.(Not that NeWS was without its own embarrassingly stuck popup windows, but NeWS had an essential utility for removing embarrassing windows called \"pam\", named after the sound you made when you used it, or maybe the original easy cleanup canola oil spray ideal for use in cooking and baking.)Failing to properly support synchronous event distribution makes it impossible for window managers (ESPECIALLY asynchronous outboard X11 window managers running in a different process than the window system) to properly and reliably support \"type ahead\" and \"mouse ahead\".For example, when a mouse click on a window or function key press changes the input focus, or switches applications, or moves a different window to the top, or pops up a dialog, or opens a new window, the subsequent keyboard and mouse events might not be delivered to the right window, because they are not synchronously blocked until the results of the first input event are handled (changing where the next keyboard or mouse events should be delivered to), so clicking and typing quickly delivers the keystrokes to the wrong window.I find it extremely annoying to still be forced to use flakey leaky \"modern\" window systems for 37 years after getting used to NeWS&#x27;s perfect event distribution model, which is especially important on slow computers or networks (i.e. dial-up modems), or due to paging or thrashing because of low memory (NeWS competing with Emacs), or any other system activity, and especially for games and complex real time applications.There are still to this day many AAA games that force you to hold a key down for at least one screen update, because they&#x27;re only lazily checking for key state changes on each draw or simulation tick, instead of actually tracking input events, otherwise they don&#x27;t register sometimes if you just tap the key, and you have to slowly mash and wait, especially when the game gets slow because there&#x27;s a lot of stuff on the screen, or has a hiccough because of garbage collection or autosave or networking or disk io or...James Gosling first wrote the importance of safe synchronous event distribution in 1985 in \"SunDew - A Distributed and Extensible Window System\":http:&#x2F;&#x2F;www.chilton-computing.org.uk&#x2F;inf&#x2F;literature&#x2F;books&#x2F;wm&#x2F;...>5.3.3 User Interaction - Input>The key word in the design of the user interaction facilities is flexibility. Almost anything done by the window system preempts a decision about user interaction that a client might want to decide differently. The window system therefore defines almost nothing concrete. It is just a loose collection of facilities bound together by the extension mechanism.>Each possible input action is an event. Events are a general notion that includes buttons going up and down (where buttons can be on keyboards, mice, tablets, or whatever else) and locator motion.>Events are distinguished by where they occur, what happened, and to what. The objects spoken about here are physical, they are the things that a person can manipulate. An example of an event is the E key going down while window 3 is current. This might trigger the transmission of the ASCII code for E to the process that created the window. These bindings between events and actions are very loose, they are easy to change.>The actions to be executed when an event occurs can be specified in a general way, via PostScript. The triggering of an action by the striking of the E key in the previous example invokes a PostScript routine which is responsible for deciding what to do with it. It can do something as simple as sending it in a message to a Unix process, or as complicated as inserting it into a locally maintained document. PostScript procedures control much more than just the interpretation of keystrokes: they can be involved in cursor tracking, constructing the borders around windows, doing window layout, and implementing menus.>Synchronization of input events: we believe that it is necessary to synchronize input events within a user process, and to a certain extent across user processes. For example, the user ought to be able to invoke an operation that causes a window on top to disappear, then begin typing, and be confident about the identity of the recipient of the keystrokes. By having a centralized arbitration point, many of these problems disappear.[...]>Hopgood:>How do you handle input?>Gosling:>Input is also handled completely within PostScript. There are data objects which can provide you with connections to the input devices and what comes along are streams of events and these events can be sent to PostScript processes. A PostScript process can register its interest in an event and specify which canvas (a data object on which a client can draw) and what the region within the canvas is (and that region is specified by a path which is one of these arbitrarily curve-bounded regions) so you can grab events that just cover one circle, for example. In the registration of interest is the event that you are interested in and also a magic tag which is passed in and not interpreted by PostScript, but can be used by the application that handles the event. So you can have processes all over the place handling input events for different windows. There are strong synchronization guarantees for the delivery of events even among multiple processes. There is nothing at all specified about what the protocol is that the client program sees. The idea being that these PostScript processes are responsible for providing whatever the application wants to see. So one set of protocol conversion procedures that you can provide are ones that simply emulate the keyboard and all you will ever get is keyboard events and you will never see the mouse. Quite often mouse events can be handled within PostScript processes for things like moving a window.NeWS Window System:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;NeWS>Design [...]>Like the view system in most GUIs, NeWS included the concept of a tree of embedded views along which events were passed. For instance, a mouse click would generate an event that would be passed to the object directly under the mouse pointer, say a button. If this object did not respond to the event, the object \"under\" the button would then receive the message, and so on. NeWS included a complete model for these events, including timers and other automatic events, input queues for devices such as mice and keyboards, and other functionality required for full interaction. The input handling system was designed to provide strong event synchronization guarantees that were not possible with asynchronous protocols like X.NeWS 1.1 Manual, section 3.6, p. 25:http:&#x2F;&#x2F;www.bitsavers.org&#x2F;pdf&#x2F;sun&#x2F;NeWS&#x2F;NeWS_1.1_Manual_198801...>Processing of input events is synchronized at the NeWS process level inside the NeWS server. This means that all events are distributed from a single queue, ordered by the time of occurrence of the event, and that when an event is taken from the head of the queue, all processes to which it is delivered are given a chance to run before the next event is taken from the queue. When an event is passed to redistributeevent, the event at the head of the event queue is not distributed until processes that receive the event in its redistribution have had a chance to process it. No event will be distributed before the time indicated in its TimeStamp.>In some cases, a stricter guarantee of synchronization than this is required. For instance, suppose one process sees a mouse button go down and forks a new process to display and handle the menu until the corresponding button-up. The new process must be given a chance to express its interest before the button-up is distributed, even if the user releases the button immediately. In general, event processing of one event may affect the distribution policy, distribution of the next event must be delayed until the policy change has been completed. This is done with the blockinputqueue primitive.>Execution of blockinputqueue prevents processing of any further events from the event queue until a corresponding unblockinputqueue is executed, or a timeout has expired. The blockinputqueue primitive takes a numeric argument for the timeout; this is the fraction of a minute to wait before breaking the lock. This argument may also be null, in which case the default value is used (currently 0.0083333 == .5 second). Block&#x2F;unblock pairs may nest; the queue is not released until the outermost unblock. When nested invocations of blockinputqueue are in effect, there is one timeout (the latest of the set associated with current blocks).>Distribution of events returned to the system via redistributeevent is not affected by blockinputqueue, since those events are never returned to the event queue.The X-Windows Disaster:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;the-x-windows-disaster-128d398...>Ice Cube: The Lethal Weapon [...]>The ICCCM is unbelievably dense, it must be followed to the last letter, and it still doesn’t work. ICCCM compliance is one of the most complex ordeals of implementing X toolkits, window managers, and even simple applications. It’s so difficult, that many of the benefits just aren’t worth the hassle of compliance. And when one program doesn’t comply, it screws up other programs. This is the reason cut-and-paste never works properly with X (unless you are cutting and pasting straight ASCII text), drag-and-drop locks up the system, colormaps flash wildly and are never installed at the right time, keyboard focus lags behind the cursor, keys go to the wrong window, and deleting a popup window can quit the whole application. If you want to write an interoperable ICCCM compliant application, you have to crossbar test it with every other application, and with all possible window managers, and then plead with the vendors to fix their problems in the next release.Window Manager Flames:http:&#x2F;&#x2F;www.art.net&#x2F;~hopkins&#x2F;Don&#x2F;unix-haters&#x2F;x-windows&#x2F;i39l.h...>Why wrap X windows in NeWS frames? Because NeWS is much better at window management than X. On the surface, it was easy to implement lots of cool features. But deeper, NeWS is capable of synchronizing input events much more reliably than X11, so it can manage the input focus perfectly, where asynchronous X11 window managers fall flat on their face by definition. [...]>If NeWS alone manages the input focus, it can manage it perfectly. An X window manager alone cannot, because it runs in a foreign address space, and is not in a position to synchronously block the input queue and directly effect the distribution of events the way NeWS is. But even worse is when an X window manager and NeWS both try to manage the input focus at once, which is the situation we are in today. The input focus problem could be solved in several ways: OWM solves the problem elegantly, as PSWM did in the past; OLWM could be made NeWS aware, so that when our own customers run our own external X window manager on our own server that we ship preinstalled on the disks of our own computers, OLWM could download some PostScript and let NeWS handle the focus management the way it was designed.>It&#x27;s criminally negligent to ship a product that is incapable of keeping the input focus up to date with the cursor position, when you have the technology to do so. Your xtrek has paged the window manager out of core, and the console beeps and you suddenly need to move the cursor into the terminal emulator and type the command to keep the reactor from melting down, but the input focus stays in the xtrek for three seconds while the window manager pages in, but you keep on typing, and the keys slip right through to xtrek, and you accidentally fire off your last photon torpedo and beam twelve red shirt engineers into deep space! reply tokamak-teapot 7 hours agorootparentI think about what could have been, how it should work, whether we could fix this, every time I go to click or touch or type and the system I’m using directs my input to somewhere other than I intended.This happens several times a day. reply UnlockedSecrets 11 hours agoparentprevI see this on a daily basis, Most times multiple times a day on a Linux KDE Plasma system with it installed natively on OpenSuse Tumbleweed. Best i could describe it is that it happens when i happen to switch to another virtual desktop using keyboard shortcuts on the exact same frame that the tool tip pops up. My guess is it was some kind of race condition that required very precise timing that made it difficult to narrow down, Paired with heavy use of keyboard shortcuts meaning alot of people likely were not effected by it. Very glad to hear it has been fixed and looking forward to getting a version of Firefox with it!I just did some testing and getting it to happen is as simple as hovering over it, And swapping to another virtual desktop before the popup shows up with firefox not being the new active application. reply prmoustache 7 hours agorootparentI am in the same boat as the OP. I don&#x27;t even know where I should click to see a tooltip to begin with! reply bmicraft 2 hours agorootparentHover over \"X hours ago\" of your comment for example reply crote 9 hours agoparentprevIt&#x27;s a very workflow-specific bug. I pretty much only encounter it while playing video games.Turns out that while gaming I often have a Youtube video playing in one browser tab, and use another browser tab to look up game-related information. So it is really common for me to interact with the tab bar (which triggers the tooltip) right before alt-tabbing into my game.During day-to-day browser use my cursor is almost always located somewhere over the website content - which rarely triggers a tooltip. reply looping8 6 hours agoparentprevIt&#x27;s the same thing with games - whenever a game from a studio known for \"broken\" titles comes out, people post compilations of strange things happening, and it just never happens on my end. Natural bug resistance, perhaps.However, I do frequently get an innocent bug, where opening my bookmark toolbar&#x27;s extension (the >> icon in the top right) results in it displaying all the bookmarks in a drop-down list, instead of the ones not appearing on the toolbar. reply Lammy 10 hours agoparentprevI experienced the bug a lot when interacting with YouTube video embeds on other web pages. It goes like: hover cursor over the embedded player&#x27;s full screen control, \"Full screen (f)\" tooltip appears, click control, video goes full screen but tooltip remains over top of playing video.(Lunix X11 with MATE&#x27;s Marco wm) reply Izkata 11 hours agoparentprevThat would make sense to me - the only place I&#x27;ve seen this is with a snap app, I haven&#x27;t seen it with firefox. reply PTOB 32 minutes agoprevWow, this brings back memories. Years ago, the persistence of this particular bug led me to believe that Firefox was \"buggy\" and \"messy\". It broke any perception in my mind that Firefox is an elegant tool. It hit whatever that cognitive bias is [cit needed] that tells us \"if it can&#x27;t get simple things right, what else is it getting wrong?\" or perhaps \"beauty good &#x2F; ugly bad\".I&#x27;m older now and have Experience(TM). I know that: a) many expensive commercial tools are far less elegant and just plain broken (looking at you Autodesk AutoCAD and Revit since 2010s) b) my own idiocy&#x2F;ignorance has larger-than-expected extentsI wonder if I&#x27;m just jaded. Is it correct to believe that Firefox is \"good\" software? Is it what it is designed to be? reply jey 11 hours agoprevDirect link to patch: https:&#x2F;&#x2F;hg.mozilla.org&#x2F;mozilla-central&#x2F;rev&#x2F;8ae372dc88d1 reply TekMol 10 hours agoparentIs this a commit?If so - is it normal to do indention changes and actual code changes in the same commit?Personally, I would first have committed the indention changes and then did a second commit with the coded changes. reply db48x 10 hours agorootparentIf you look closely, you&#x27;ll see that it&#x27;s not merely an indentation change. The bulk of the function used to be inside a large condition, but that has been changed to an early return. Still, it would have been a little nicer if it had been done in two commits. reply CobrastanJorji 9 hours agorootparentprevHere&#x27;s a better view of it: https:&#x2F;&#x2F;phabricator.services.mozilla.com&#x2F;rMOZILLACENTRAL8ae3...Basically it just adds a one line check near the top of a ShowTooltip() function for whether \"doc->HasFocus(IgnoreErrors())\", and, if not, returns early. reply em-bee 6 hours agorootparentprevi always struggle with this. i usually end up with code changes first because i want to test code before committing, which means i can&#x27;t commit a whitespace change before i know the code change works.and every time i think about the problem i stumble over python where the two can&#x27;t be separated.i believe in the end a better solution would be to mark whitespace changes in a different color. or even better mark each character that changed, not just the line.in other words: we want better diff tools reply cbsks 10 hours agorootparentprevThe indentation changes are because of a removed if block. reply jh00ker 10 hours agoparentprevWow, if you exclude lines changed in the commit due to indenting changing, there are only five new lines of code for this change! reply langsoul-com 10 hours agorootparentMost of the challenges of a bug isn&#x27;t the fix, but rather figuring out the behaviour.Especially true if breakpoints don&#x27;t work :) reply sroussey 9 hours agorootparentAlways a bummer when your tools for debugging don’t work. :&#x2F; reply acqq 6 hours agorootparentprevThe changes, in sum, in nsXULTooltipListener.cpp - if (tooltipNode->GetComposedDoc() && - nsContentUtils::IsChromeDoc(tooltipNode->GetComposedDoc())) { + &#x2F;&#x2F; Make sure the document still has focus. + auto* doc = tooltipNode->GetComposedDoc(); + if (!doc || !nsContentUtils::IsChromeDoc(doc) || + !doc->HasFocus(IgnoreErrors())) { + return NS_OK; + } ... - } } return NS_OK;If I see correctly, all the changes are:1) remembering result of tooltipNode->GetComposedDoc() and adding the test of doc->HasFocus(IgnoreErrors()). Note that writing this one now is maybe easier than it was at the time the initial code was written, it could be the \"auto\" in this current semantic didn&#x27;t exist in C++ (or the used compilers&#x2F;platforms) at that time.2) Explicit return. Instead of: if (b) X; return OK;now it&#x27;s: if (!b) return OK; X; return OK;which in this case increases readability as X is in many lines and b is a more complex condition. reply chrisjc 1 hour agorootparentCan any one give a brief synopsis of the state of XUL and gecko in Firefox&#x2F;Mozilla? Are the XUL (XULRunner) and gecko runtimes still actively worked on? Or has it been absorbed into the Firefox runtime long ago?I recall reading some time ago that the work on XULRunner essentially came to a halt, and that components in Firefox&#x2F;Mozilla that depend on XUL would slowly be phased out.But does that mean that work on the XUL runtime and components in Firefox also effectively came to a halt? I figured that most of these really old XUL bugs in Firefox were never going to be fixed, instead replacing a whole layer&#x2F;component dependent on XUL was seen as a better use of time and resources.Edit: anyone have a good diagram of the layers&#x2F;components in Firefox. Something that can illustrate where Quantum, Gecko, XUL, etc all live in Firefox. It would be really cool (doubt it exists) if there was an animated diagram that would show the changes of this stack overtime. reply somsak2 10 hours agoprevInteresting, this bug was filed before even the first version of Firefox was ever released -- https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Firefox_early_version_history. Impressed that they&#x27;ve kept the bug tracker history working for so long. reply aspenmayer 10 hours agoparentDid the bug tracker history carry over from Phoenix&#x2F;Firebird maybe? reply cpeterso 10 hours agorootparentThis was a bug in the Gecko engine, which was used in Netscape 6 and the Mozilla Suite (Navigator and Communicator) before Firefox was created (in response to Mozilla Suite bloat). Gecko still uses the same Bugzilla bug tracker. reply dtech 10 hours agorootparentprevThis looks to have been from when it still was Mozilla reply kelnos 10 hours agoprevOh god, finally. A related bug, https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1569439 , was closed 9 months ago, and that made things slightly better (that one is about tooltips not disappearing when simply switching to another app), but I was incredibly disappointed to find that they&#x27;d still stay up when switching to another workspace.On the downside, this is sorta a \"wrong\" fix. Tooltips should show up even if the window doesn&#x27;t have focus (at least on Linux with GTK apps, which Firefox attempts to emulate). They should fix the actual underlying issue of them not disappearing when the mouse pointer isn&#x27;t actually over the window anymore, when workspaces change. reply aidenn0 10 hours agoparentOh that one was the one I hit the most, not TFA; I hadn&#x27;t seen this in a while and now I know why. reply user3939382 33 minutes agoprevFunny some guy on HN was just arguing with me the other day that the oldest Firefox bug was 11 years old and that they fixed over 1,000 bugs in their last release. I tried to search their bug tracker to see if this was true but the web server doing the searches was unresponsive. reply jraph 5 hours agoprevOh. I&#x27;m affected, seeing it several times a day, but I never managed to reproduce 100%. Didn&#x27;t bother me too much but I guess I could happily do without.It also affects Thunderbird.I had no idea it was a well known, 22 year old bug. reply 1970-01-01 10 hours agoprev>I&#x27;m seeing this problem in 1.6 on Win98.Bug is fixed, please retest :) reply Narishma 6 hours agoparentI would if they backported the fix to a version that runs in Windows 98. reply TheSoftwareGuy 2 hours agoprevDoes anyone have a link to the commit that fixed the bug? I&#x27;m curious how simple it was to fixEdit: nvm, I found the link in the linked page: https:&#x2F;&#x2F;hg.mozilla.org&#x2F;mozilla-central&#x2F;rev&#x2F;8ae372dc88d1 reply werdnapk 1 hour agoparentMost of the commit is changing indentation for the outer `if`... the core of the fix is `!doc->HasFocus(IgnoreErrors())`Bug squashed! reply theanonymousone 10 hours agoprevOh. I have seen this behaviour in other programs, recently mostly in Cisco AnyConnect. I always thought this an OS glitch. reply wakeupcall 6 hours agoparentIt&#x27;s pretty easy to see why this behavior can come from programs that&#x27;s don&#x27;t use any standard OS toolkits, but go for custom or cross-platform solutions:- show the tooltip - rely on move events on the main window to hide itthe move events are usually received only when the window is visible (and focused depending on the os), unless you take extra measures to grab the pointer and&#x2F;or listen on global events, which involves more trickery to work right.It&#x27;s the classic scenario where a decent system toolkit has this figured out and solved for you, while doing the same by hand looks somewhat easy and normally works 95% of the time, but fails in odd ways and drives your power users crazy.Driving UIs heavily by keyboard and shortcut is the sure-way to hit that remaining 5% all the damn time nowdays... reply yipbub 10 hours agoparentprevYeah, I imagined the same, but can&#x27;t recall or reproduce in anything else now. Possibly a Mandela Effect? reply theanonymousone 10 hours agorootparentI&#x27;m pretty sure the Cisco one is permanent and reproducible (on macOS) :D reply unnah 9 hours agoparentprevI see it a lot with Windows Explorer and Microsoft Word, never with Firefox, even though I use all of them daily on my work laptop. It seems people have so different usage patterns that they see completely different bugs... reply ale42 8 hours agoparentprevAltium Designer used to have the exact same issue for a very long time but I think it&#x27;s finally gone some time ago reply alana314 9 hours agoparentprevFinder does it to me all the time reply kaichanvong 1 hour agorootparenthad a feeling Finder did magic too; however, on changing focus into the Shortcuts App, revealed Quick Actions that baffles reply Paul-Craft 10 hours agoprevMeh, 22 years? That&#x27;s not even close to the longest standing bug I know of that&#x27;s been fixed. ;)Here&#x27;s the story of a 33 year old bug in yacc that was fixed in 2008: https:&#x2F;&#x2F;undeadly.org&#x2F;cgi?action=article&sid=20080708155228 reply thaliaarchi 9 hours agoparentThe malloc design, that led to that yacc bug being discovered, seems to have another interesting property which I didn&#x27;t see discussed there:By placing large allocations (those larger than half the page size) at the end of a page, I would think it also allows them to be resized in more cases. Smaller allocations can be then made in the gap, until it&#x27;s filled. Then, if realloc is called on the large allocation and enough space remains for the difference, it can be shifted backward with memmove. Whereas, the large allocation is placed at the first available position and further allocations are made after it, it has no space to resize.Disclaimer: I haven&#x27;t implemented a memory allocator, so my understanding may be off. reply layer8 7 hours agoprevAnd this is why tickets shouldn’t be closed just because they are old. reply wejick 2 hours agoprevIt&#x27;s actually pretty impressive that the bug tracking system is keeping data from 22 years back and maybe more. reply solarkraft 9 hours agoprevI like making fun of them for not fixing decades-old bugs (and there&#x27;s still a considerable amount left) and didn&#x27;t really have hope they&#x27;d ever care.What beautiful news if this indicates that some other old bugs will eventually be fixed as well! reply em-bee 6 hours agoparentyou may now predict when old bugs are going to be fixed. any bug at least 20 years old is eligible. nearest prediction wins.if you want to play the long game you may also predict if younger bugs get fixed more than 20 years after reporting. (if the bug gets fixed earlier than 20 years then the prediction becomes void)place your bets!*terms and conditions apply. firefox developers are not eligible. reply Ikatza 2 hours agoprevNow if they could only fix how horribly Hacker News is displayed on mobile... reply millzlane 2 hours agoprevI love Mozilla and I too have experienced this bug. I&#x27;m glad this has been fixed even it didn&#x27;t annoy me that much. But it solidifies my choice in browser.Brb while I test Sonoma to see if I can create two separate egg timers with Siri... reply thefox 41 minutes agoprevIt&#x27;s not 22 years but 21 years ago. reply donatj 10 hours agoprevA couple years ago I was Googling myself and found to my surprise a bug I had opened for Mozilla on BeOS in roughly the year 2000 was still open. Searching their Bugzilla now, I find no references to BeOS at all, were their issues pruned at some point? reply cpeterso 10 hours agoparentIssues for unsupported platforms would be closed (RESOLVED WONTFIX) but they wouldn’t be deleted. Bugzilla’s default search songs only return open bugs. Here’s a search for all bugs with OS = “BeOS”. Maybe one of them is your bug?https:&#x2F;&#x2F;mzl.la&#x2F;3twxg9n reply tehbeard 2 hours agoprevI&#x27;d always thought this was just from my Win 10 install being \"crufty\" (a few years old, with some hardware swapped along the way).Never ran into it on my Linux box so I thought it was just Windows weirdness. reply ilyt 1 hour agoprevNow they can maybe fix bug where favicons randomly show negative image on linux... reply caboteria 2 hours agoprevI can&#x27;t help but contrast this to the Kubernetes project where stalebots close issues after 90 days of inactivity. reply noman-land 9 hours agoprevHaha wow. I&#x27;ve been dealing with this bug for so long I hadn&#x27;t even considered it could be fixed. Wild. reply anymouse123456 9 hours agoprevHoly shit. This bug literally drove me away from Firefox a couple years ago.Wild. reply chrisjc 58 minutes agoparentIt&#x27;s definitely one of those things that can drive someone a little crazy.My solution was to activate&#x2F;trigger another tooltip, that would make the frozen one disappear, and hope the new one would behave normally.Wasn&#x27;t ready to give up Firefox, but can&#x27;t say that the thought didn&#x27;t cross my mind.Now that I think about it, still to this day I see similar issues in other apps where some kind of popup&#x2F;overlay&#x2F;tooltip persists across tabs&#x2F;windows&#x2F;applications. reply frou_dh 7 hours agoprevThis is probably quite a common phenomenon in open source software. Namely, an unglamorous bug has been around forever and someone finally gets annoyed enough to roll up their sleeves and fix it themselves. reply thiht 5 hours agoprevI absolutely love that the bug report was not closed as « inactive » or « stale » after like 6 months. reply flas9sd 4 hours agoparentmy impression of the mozilla firefox bugtracker too - you might be taken aback by the lifetime of some long standing bugs, but what is confirmed, stays open.You&#x27;ll collect low effort comments, but at least it avoids duplicates and the discussion is preserved in-thread.That impression lead me to meaningfully contribute in the bugtracker. reply sfink 10 hours agoprevUgh, that sucks. I&#x27;ve been relying on this bug to create persistent sticky notes on my screen. Why do browsers insist on breaking stuff?https:&#x2F;&#x2F;xkcd.com&#x2F;1172&#x2F; reply chrismorgan 8 hours agoprevOK, that’s one major tooltip annoyance fixed. That was one that was very annoying for some usage patterns, but never really debilitating. But if we’re trying to fix ancient tooltip bugs, here’s one that is debilitating for some users:Tooltips are positioned relative to cursor position, below and to the right, but don’t take cursor size into account, and so if you have a comparatively large cursor, it occludes the tooltip.This has been filed in a couple of guises a few times, starting twenty years ago: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=248718, https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=296191, https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=557754, https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1712669. (I don’t really get why bug 248718 and bug 557754 were closed as duplicates of bug 1712669; I tend to feel that the oldest one should be the canonical one almost as a matter of principle, especially when it’s so much older.)This will affect many more users now than twenty years ago, because some time during Windows 10 they added a proper cursor size scale, so you can easily get a huge cursor (which I strongly suggest people try; I was amazed at how much it improved things, except for this class of bug). The old “extra large” cursor was equivalent to what’s now size 3 and the scale now goes up to 15, if I remember from a few years ago accurately. Size 4 is already enough to lose a couple of characters from the start of tooltips.(This is all about native tooltips, but naturally this is also a problem with DOM-based fake tooltips in web pages: they have no access to cursor dimension information, so no way to be certain of dodging the cursor. I recommend placing such tooltips above the cursor position, as that’s the most likely to be clear. Bug 1712669 comments 5 and 6 observe how this is a problem on Bugzilla itself—they put a DOM fake tooltip below on dates.) reply nubinetwork 10 hours agoprevOne recent bug I&#x27;ve seen with tooltips is on wayland... it causes the whole display window to flicker between the current renderer and what appears to be an old back buffer... hopefully it doesn&#x27;t stick around for 22 years. reply hulitu 10 hours agoparentThat is normal behaviour (redraw the screen with every pixel moved). Welcome to the 21st century. &#x2F;s reply throw2022110401 10 hours agoparentprevYou are holding it wrong, in Wayland every frame is perfect. reply piyush_soni 7 hours agoprevWow. Thinking about it, there are businesses built, peaked and destroyed in that time frame. :) reply adastra22 7 hours agoparentMozilla being one of them. reply pluc 3 hours agoprevImagine paying your CEO 3 millions but fixing a bug like this only after 20+ years reply roshansingh 4 hours agoprevThis bug really annoyed me on Firefox and Thunderbird. Over the last two years I have learned to live with it. reply buro9 8 hours agoprevAh, something extremely similar affects SyncTrayzor on Windows too! https:&#x2F;&#x2F;github.com&#x2F;canton7&#x2F;SyncTrayzor&#x2F;issues&#x2F;760 reply denton-scratch 8 hours agoprevApparently it&#x27;s fixed in FF119. I&#x27;m on 102esr under Linux, but I can&#x27;t replicate.[Edit] OIC, it&#x27;s a heisenbug. Funny though; I&#x27;m a longtime FF user, and I don&#x27;t recall witnessing it. reply HeavyStorm 3 hours agoprevVisual Studio has the same problem for at least a decade. reply mrloop 9 hours agoprevCould this be the same tooltip issue I see everyday on Thunderbird? I must use Firefox differently but in Thunderbird I&#x27;m often left with a tooltip telling the date of the last message I was looking at after changing to a different app. reply kazinator 10 hours agoprevWhat would it take for Firefox not to prompt you to save a password that fucking didn&#x27;t work? reply toast0 9 hours agoparentA sane method for websites to indicate if a password worked or not. And for enough websites to use it that password saving heuristics could be disabled. reply kazinator 4 hours agorootparentWhen you submit a form with a password and the password is wrong, you&#x27;re usually taken back to the same form with the same password. The browser is showing you a form that, if it were submitted, would update the same saved password. Yet the popup dialog asking you whether you want to save the previous obviously wrong value is still persisting. reply _ache_ 9 hours agoparentprevWhy would you want that ? It&#x27;s an incredible useful feature. Now you can&#x27;t forget that this password didn&#x27;t work. reply Aachen 4 hours agorootparentBut you can store only one not-working password per username and website. Clearly it should support multiple passwords for the same username and website and have a flag \"working\" or \"not working\". Bugmenot has this all figured out years ago!(Also, your username triggers me in a wildcard sort of way.) reply fsckboy 8 hours agoprevthis problem plagues me, I even saw it today, and I&#x27;m up-to-date on the latest Firefox for Fedora, I wonder if it&#x27;s rolled out yet? Here&#x27;s the thing, though, they probably didn&#x27;t fix it for me: I use focus-follows-mouse, so probably in my case Firefox will think it has the focus (because it does briefly), but it&#x27;s just a little scrap peaking out from under a stack of other windows. reply wodenokoto 9 hours agoprevLots of software have problems with persisting tooltips. I regularly have tooltips from VS Code getting \"stuck\" and can&#x27;t be removed until I close the application. reply toddmorey 2 hours agoprevThat bug was a college kid! reply sedatk 7 hours agoprevNow fix the kerning problem on canvas. That bug significantly reduces the readability of Google Docs et al. reply szundi 10 hours agoprevCompletely normal bugfixing behavior, nothing to see here. reply hans_castorp 9 hours agoprevI am seeing this problem with Thunderbird as well since upgrading to Thunderbird 115 - I hope they are a bit quicker than the Firefox devs. reply ale42 8 hours agoparentThe codebase for that UI part might be the same... Actually TB 115 might be the reason that the bug has finally been fixed in Firefox: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1843203#c9 reply hans_castorp 8 hours agorootparentAh, thanks. The tip at the end seems to fix this on TB 115. reply aidenn0 10 hours agoprevI actually saw this happen even more in the Linux MS Teams client (which uses Electron or similar I think?), but I&#x27;ve encountered it with Firefox as well. reply epse 9 hours agoparentYup it&#x27;s",
    "originSummary": [
      "Firefox has an ongoing bug issue where tooltips persist even when the browser is not in use, which has been reported to irritate several users.",
      "Despite being known for roughly two decades and having multiple reports, the bug issue has not yet been resolved.",
      "Various solutions have been considered and discussed, but the bug continues to persist across different Firefox versions and operating systems."
    ],
    "commentSummary": [
      "After 22 years, a bug in Firefox causing tooltips to persist has been remedied, emphasizing the difficulties of software complexity and distributed bug fixing.",
      "Users' discussions around this issue spotlight their exasperation with the bug and the possible solutions, and they even share their experiences with similar issues in other software.",
      "The successful fix inspires optimism for rectifying other enduring bugs in Firefox and raises the potential future impact of AI in problem-solving for such long-standing issues."
    ],
    "points": 749,
    "commentCount": 262,
    "retryCount": 0,
    "time": 1696905807
  },
  {
    "id": 37831062,
    "title": "Google mitigated the largest DDoS attack to date, peaking above 398M rps",
    "originLink": "https://cloud.google.com/blog/products/identity-security/google-cloud-mitigated-largest-ddos-attack-peaking-above-398-million-rps/",
    "originBody": "Jump to Content Cloud Blog Solutions & technology Ecosystem Developers & Practitioners Transform with Google Cloud Contact sales Get started for free Security & Identity Google mitigated the largest DDoS attack to date, peaking above 398 million rps October 11, 2023 Emil Kiner Senior Product Manager, Cloud Armor Tim April Security Reliability Engineer The attack used a novel technique, HTTP/2 Rapid Reset, based on stream multiplexing Hear monthly from our Cloud CISO in your inbox Get the latest on security from Cloud CISO Phil Venables. Subscribe Over the last few years, Google's DDoS Response Team has observed the trend that distributed denial-of-service (DDoS) attacks are increasing exponentially in size. Last year, we blocked the largest DDoS attack recorded at the time. This August, we stopped an even larger DDoS attack — 7½ times larger — that also used new techniques to try to disrupt websites and Internet services. This new series of DDoS attacks reached a peak of 398 million requests per second (rps), and relied on a novel HTTP/2 “Rapid Reset” technique based on stream multiplexing that has affected multiple Internet infrastructure companies. By contrast, last year’s largest-recorded DDoS attack peaked at 46 million rps. For a sense of scale, this two minute attack generated more requests than the total number of article views reported by Wikipedia during the entire month of September 2023. Google mitigated a DDoS attack which peaked at 398 million requests per second The most recent wave of attacks started in late August and continue to this day, targeting major infrastructure providers including Google services, Google Cloud infrastructure, and our customers. Although these attacks are among the largest attacks Google has seen, our global load-balancing and DDoS mitigation infrastructure helped keep our services running. In order to protect Google, our customers, and the rest of the Internet, we helped lead a coordinated effort with industry partners to understand the attack mechanics and collaborate on mitigations that can be deployed in response to these attacks. Hear monthly from our Cloud CISO in your inbox Get security updates, musings, and more from Google Cloud CISO Phil Venables direct to your inbox every month. Subscribe today Generally, DDoS attacks attempt to disrupt internet-facing websites and services, making them unreachable. Attackers direct overwhelming amounts of Internet traffic to targets, which can exhaust their ability to process incoming requests. DDoS attacks can have wide-ranging impacts to victim organizations, including loss of business and unavailability of mission critical applications, which often cost victims time and money. Time to recover from DDoS attacks can stretch well beyond the end of an attack. Our investigation and response Our investigation revealed that the attack was using a novel “Rapid Reset” technique that leverages stream multiplexing, a feature of the widely-adopted HTTP/2 protocol. We provide further analysis of this new Rapid Reset technique and discuss the evolution of Layer 7 attacks in a companion blog. We observed the attack campaign continued over the course of September 2023 We were able to mitigate the attack at the edge of Google's network, leveraging our significant investment in edge capacity to ensure our services and our customers’ services remained largely unaffected. As we understood more details about the attack methodology, we developed a set of mitigations and updated our proxies and denial-of-service defense systems to efficiently mitigate this technique. Since Google Cloud’s Application Load Balancer and Cloud Armor use the same hardware and software infrastructure that Google relies on to serve its own internet-facing services, the Cloud customers who use those services have their Internet-facing web apps and services similarly protected. Industry coordination and response for CVE-2023-44487 Soon after detecting the earliest of these attacks in August, Google applied additional mitigation strategies and coordinated a cross-industry response with other cloud providers and software maintainers who implement the HTTP/2 protocol stack. We shared intelligence about the attack and mitigation methodologies in real time as the attacks were underway. This cross-industry collaboration has resulted in patches and other mitigation techniques used by many large infrastructure providers. The collaboration helped to pave the way for today’s coordinated responsible disclosure of the new attack methodology and potential susceptibility across a multitude of common open source and commercial proxies, application servers, and load balancers. The collective susceptibility to this attack is being tracked as CVE-2023-44487 and has been designated a High severity vulnerability with a CVSS score of 7.5 (out of 10). Google expresses sincere gratitude to all of the cross-industry stakeholders who have collaborated, shared information, accelerated patching of their infrastructure, and rapidly made patches available to their customers. Who is susceptible and what to do about it Any enterprise or individual that is serving an HTTP-based workload to the Internet may be at risk from this attack. Web applications, services, and APIs on a server or proxy able to communicate using the HTTP/2 protocol could be vulnerable. Organizations should verify that any servers they run that support HTTP/2 are not vulnerable, or apply vendor patches for CVE-2023-44487 to limit impact from this attack vector. If you are managing or operating your own HTTP/2-capable server (open source or commercial) you should immediately apply a patch from the relevant vendor when available. Next steps Defending against massive DDoS attacks such as those described here is difficult. With or without patches, organizations would need to make significant infrastructure investments to keep services running in the face of attacks of any moderate size and larger. Instead of bearing that expense themselves, organizations running services on Google Cloud can take advantage of our investment in capacity at global scale in our Cross-Cloud Network to deliver and protect their applications. Google Cloud customers exposing their services using the global or regional Application Load Balancer benefit from Cloud Armor always-on DDoS protection, where attacks exploiting vulnerabilities such as CVE-2023-44487 are quickly mitigated. Even though with Cloud Armor always-on DDoS protection we are able to efficiently absorb most of the hundreds of millions of requests per second at the edge of Google’s network, millions of unwelcome requests per second can still make it through. To protect against this and other layer 7 attacks, we also recommend deployment of Cloud Armor custom security policies with proactive rate limiting rules and AI-powered Adaptive Protection to more comprehensively detect, analyze, and mitigate attack traffic. We provide more technical information on this current wave of DDoS attacks here, and you can learn more about Google Cloud Armor’s DDoS protection here. Posted in Security & Identity Networking Google Cloud Related articles Security & Identity How it works: The novel HTTP/2 ‘Rapid Reset’ DDoS attack By Juho Snellman • 8-minute read Networking Deliver and secure your internet-facing application in less than an hour using Dev(Sec)Ops Toolkit By Lihi Shadmi • 4-minute read Security & Identity How Sensitive Data Protection can help secure generative AI workloads By Scott Ellis • 5-minute read Security & Identity Introducing Google Cloud Firewall Plus with intrusion prevention By Megan Yahya • 3-minute read Footer Links Follow us Google Cloud Google Cloud Products Privacy Terms Help Language ‪English‬ ‪Deutsch‬ ‪Français‬ ‪한국어‬ ‪日本語‬",
    "commentLink": "https://news.ycombinator.com/item?id=37831062",
    "commentBody": "Google mitigated the largest DDoS attack to date, peaking above 398M rpsHacker NewspastloginGoogle mitigated the largest DDoS attack to date, peaking above 398M rps (cloud.google.com) 326 points by tomzur 3 hours ago| hidepastfavorite273 comments pythonguython 1 hour agoWho has an incentive to carry out these DDos attacks? Why would anyone be willing to spend large amounts of money and develop a sophisticated attack against corporate cloud infrastructure? It seems like the only reasonable answer is foreign governments. But still what is the result - you inconvenience American tech companies and their customers for a few hours? This happens all the time, so clearly someone finds it worthwhile. Can anyone help me understand? reply jedberg 40 minutes agoparentI&#x27;ve been working on anti-DDOS off and on for 20 years now. The answer is sometimes government actors, but oftentimes scammers in Eastern Europe. They do these big attacks for street cred amongst the botting community.They then use their street cred to get paid by less scrupulous actors to attack their rivals. Sometimes the people paying are governments, sometimes just shady companies. For example last year there was a lot of crypto companies attacking each other&#x27;s websites.Most of the people who do this have a lot of technical skill but not a lot of opportunity to get paid for it based on where they live or the circumstances of their upbringing. reply jessriedel 1 minute agorootparentVery useful, thanks. Do you know roughly what sort of resources, in time, money, and compromised machines, it takes to do something like this? (Order of magnitude.) reply whimsicalism 2 minutes agorootparentprevSeems like attacking Google would be a bad target for street cred as compared to govt websites. reply anonacct37 1 hour agoparentprevPR. Attack Google or cloudflare. Wait for them to publish a blog post about the biggest attack ever seen, then tell potential customers of your botnet that you can launch a bigger attack than anyone else and point to the above blog post. reply Jeff_Brown 59 minutes agorootparentThe botnet is probably the critical thing. Even if the PR (or \"avenge the global south\", or whatever) value might not be enormous, the cost to a bad actor of having other peoples&#x27; computers do something is almost negligible. reply endergen 56 minutes agorootparentprevDoesn&#x27;t using your botnet expose your botnet IP addresses&#x2F;devices? reply mrweasel 48 minutes agorootparentYes, but currently that has zero consequences. Say you infect 500.000 Windows XP machines or consumer routers, the owners of those devices isn&#x27;t going to be informed, nor is their ISPs. In many cases the manufacturer of those devices also aren&#x27;t going to provide security update, but those probably wasn&#x27;t going to be applied anyway. reply jrockway 44 minutes agorootparentAre you positive that \"tell nobody\" is the mitigation strategy that Google used here? They could have easily asked router vendors to patch their devices, asked ISPs to blackhole those customers until they&#x27;re patched, etc. reply soperj 38 minutes agorootparentPatch what though? They know that they&#x27;re getting hit with unprecedented traffic, not how those computers were infected. reply menscher 3 minutes agorootparentIt&#x27;s mostly not infected computers, but rather poorly configured proxies that are open for anyone to bounce malicious traffic through. Convincing everyone to clean up their open proxies is a long-term, hard problem. But I plan to tackle it soon.... KomoD 42 minutes agorootparentprev> the owners of those devices isn&#x27;t going to be informed, nor is their ISPsnot necessarily true reply KomoD 40 minutes agorootparentprevAnyone can claim that, there&#x27;s no link to a specific actor reply v-erne 35 minutes agorootparentI&#x27;m guessing you would do this in advance - \"pay attention to tech news next week - our botnet will unleash hell\" reply belter 10 minutes agoparentprevYou don&#x27;t need a lot of money or resources to pull one of these. Code is on Github: https:&#x2F;&#x2F;github.com&#x2F;649&#x2F;Memcrashed-DDoS-ExploitAlso the participants are sometimes innocently recruited victims for the attack. I blame app insecure defaults.The trend since 2015 is to get worst as you will see in the bottom layer of this graph: https:&#x2F;&#x2F;www.digitalattackmap.com&#x2F; reply whimsicalism 2 minutes agorootparentThis is a novel ddos attack. Did you all even read the article? reply forward1 53 minutes agoparentprevIf they&#x27;re unsophisticated, it&#x27;s for clout and \"street cred\" in hacking communities, no different than tagging a freeway overpass with graffiti.If they&#x27;re advanced, they are doing it to test capabilities and responses. The Taliban used to pay kids to light off firecrackers outside base to check defensive TTPs. It also had the effect of desensitizing the sound of gunfire.Really good adversaries know how to accomplish the latter while appearing as the former. reply rockinghigh 35 minutes agoparentprevFor a recent and similar attack at scale, the authors of the botnet software were from an American security company who sold DDOS mitigation solutions (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mirai_(malware)). reply datadeft 37 minutes agoparentprevFor example a certain group decides to short on a share. The DDOS the company and \"leak\" it to the press. The bad press negatively impacts the share price. At least this was the way some time ago when I had to deal with such attacks. reply xeromal 16 minutes agoparentprevMy gut instinct is that this is a nation-state initiated. reply syndacks 19 minutes agoparentprevfor the lolz reply mihaic 3 hours agoprevThe fact that large cloud providers can handle huge DDoS attacks I think in the long run leads to a worse internet. It forces botnets to up their game and for websites the only solutions available are to pay Google, Amazon or Cloudflare a protection tax.I honestly don&#x27;t see any other options, but I&#x27;d really wish for them to come through some community coordinated list of botnet infected IPs or something. reply gchamonlive 2 hours agoparentWhat?Let&#x27;s go back to username and password. 2FA forces scammers to up their game.What about password managers? Having separate passwords to every account makes hacking into your accounts much harder and might hurt everyone in the long run.And don&#x27;t get me started on end to end encryption. Privacy, long term, will mean the fall of civilization.Sarcasm aside. I think I understand your point in which we shouldn&#x27;t just delegate to cloud providers the whole effort in preventing attacks, but just with everything production-grade, the average enterprise just isn&#x27;t ready to deal with all the upfront cost to run your entire computing solution. Because it doesn&#x27;t end with this type of mitigation and dependency. A similar argument could be made for not using proprietary chip designs made by cloud providers. Or any proprietary API solution for that matter. It really is a matter of convenience that a community solution might cover in the future, abstracting away fundamental building blocks every cloud provider must have (name resolution, network, storage and computing services) to provide such higher level functions without lock in. We are just not there yet. reply tristan9 1 hour agorootparent> just with everything production-grade, the average enterprise just isn&#x27;t ready to deal with all the upfront cost to run your entire computing solutionThat’s not a fair point.We’re not even trying to make the internet safe. There is zero (0) actions being taken to stop this madness. If you run a large website, you still regularly see attacks from routers compromised 3, 4, 5 years ago. Or how a mere few days of poking around smartly is still enough to this day to find enough open DNS resolvers to launch >500Gbps attacks with one or two computers.Why are these threats allowed to still exist?The only ones attempting something are governments shutting down booters (DDoS-as-a-service platforms). But that’s treating symptoms, not causes.We will eventually need to do something, or it will be impossible to run a website that can’t be kicked down for free by the next bored skid.Just like paying protection fees to the mafia was a status quo, this also is just that. A status quo, not an inevitability.The solution is to finally hold accountable attack origins (ISPs, mostly), so that monitoring their egress becomes something they have an incentive to do. reply Analemma_ 1 hour agorootparentI don&#x27;t think it&#x27;s true that 0 actions are being taken. When new vectors for amplification attacks are found, they get patched - you can&#x27;t do NTP amplification attacks on modern NTP servers anymore, for example. But it takes a long time for the entire world to upgrade and just a handful of open vulnerable servers to launch attacks. And in the meantime people are always looking for new amplification vectors.> The solution is to finally hold accountable attack origins (ISPs, mostly), so that monitoring their egress becomes something they have an incentive to do.Be careful what you wish for. The sort of centralized C&C infrastructure and \"list of bad actors everybody has to de-peer\" that you would need to this effectively would we a wonderful juicy target for governments to go, \"hey, add [this site we don&#x27;t like] to the list, or go to prison\". reply BHSPitMonkey 42 minutes agorootparentprevTraditionally, a botnet can be compromised (at least largely) of actual consumer devices unknowingly making requests on their owners&#x27; behalf. This can cover hundreds of unrelated ISPs as the \"origin\" and is effectively indistinguishable from organic traffic to a popular destination. \"Accountability\" is not simple here. reply Roark66 40 minutes agorootparentprev>There is zero (0) actions being taken to stop this madness. If you run a large website, you still regularly see attacks from routers compromised 3, 4, 5 years agoYes, you&#x27;re 100% correct. Back in the day when the main bot net activity was spam if you were infected and you started sending TB of spam the ISP would first block your outgoing smtp. If they kept getting complaints in a week or two they&#x27;d cut you off.I remember 30 years ago when most people were on dialup, I was fortunate enough to have 128kB SDSL. As a relatively clueless kid I decided to portscan an IP range belonging to a mobile service company. Few days later my dad got a phone call saying their IDS flagged it and \"don&#x27;t do it or we&#x27;ll cancel your service\". For a port scan of few public IPs no less!ISPs could definitely put a stop to 99% of these botnets, but until they see some ROI, why would they bother? reply jsight 1 hour agorootparentprevBut that&#x27;s exactly the problem, it shouldn&#x27;t require a enterprise grade tool just to host a simple website on the internet. We&#x27;ve lost something due to our inability to stop attacks at the source and heavy overreliance on massive cloud providers to do it for us.2FA and password managers didn&#x27;t make us heavily reliant on massive companies. reply meowface 1 hour agorootparentYes, but if these cloud providers didn&#x27;t exist eventually there&#x27;d be botnets that no site could protect against, rather than the status quo of at least some sites being able to resist them. The idea that the existence of cloud providers that can soak up a lot of traffic is making things worse by causing botnets to get more powerful just seems silly. reply dylan604 1 hour agorootparentprevyou don&#x27;t need enterprise grade tools just to host a simple website. however, if your simple site ever gains enough attraction to come under an attack, especially like this, you&#x27;ll never survive. you can either just accept that your service will not survive the attack and just shut it down until the attackers realize mission accomplished and stops. you can then hope they don&#x27;t notice when you bring it back. no simple site will be able to afford what&#x27;s required to stay up from these attacks.i&#x27;m not saying i like having to put the majority behind the services of 2 or 3 companies, but if you ever get shut down from some DDOS, you&#x27;ll understand why people think they need to. reply 89vision 1 hour agorootparentprev20 years ago if a blog or website ended up on slashdot&#x2F;digg&#x2F;whatever there was a good chance it was going down. Scalable websites are a commodity today reply rglullis 27 minutes agorootparentThat goes both ways. What was the price then to get a botnet with 10k nodes making 1k requests &#x2F; second? What is the price today? reply spacephysics 1 hour agorootparentprevA similar analogy can be made with the likes of westward expansion in the continental US.Back then, you got a piece of land, and really could do what you wanted with it. Build a business, farm, etc. some government taxes but nothing crazy. But you had to deal with criminals, lack of access to medical care, and lack of education.Now to do the same, you have a slew of building codes, regulations, zoning laws, and are basically forced to have municipal services. Higher Taxes to pay the roads, police force, fire fighters, education services etc.However, home owners can still just have an egg or vegetable stand at the end of their driveway. It won’t be the same as having a storefront in town, but it’s still doable without the overhead.Similarly, as the internet matures, we’re going to see more and more overhead to sustain a “basic” business.But you can still have a personal blog ran in your closet, for lower-level traffic.The analogy isn’t perfect, but unfortunately as threat-actor’s budgets increase, so too do their quality&#x2F;sophistication of their attacks. If it was cheap to defend against some of the more costly attacks, they would find a different vector.The answer, to me, is some tangential technology that is some mix of federated or decentralization. Not in a crypto bro sense, but just some tech whose fundamental design solves the inherit problem with how our web is built today.Then threat actors will find another way, rinse and repeat… reply dmd 1 hour agorootparent> home owners can still just have an egg or vegetable stand at the end of their drivewayNo you can&#x27;t. That is illegal without a \"cottage food\" license, training, and labeling in most of the US.https:&#x2F;&#x2F;www.pickyourown.org&#x2F;CottageFoodLawsByState.htm reply bombcar 1 hour agorootparentChild-run lemonade stands are technically illegal in most states (some have actually carved out exemptions for them because of overzealous policing).Garage sales often have a specific carve out, also, and limitations on numbers of time per year, etc.Most areas nobody cares at all until it becomes a nuisance somehow. reply adrianN 1 hour agorootparentSelectively enforced laws are the worst kind of law. reply bombcar 57 minutes agorootparentI&#x27;ve always thought it would be interesting to allow as a defense against a violation of a law to prove that the law is regularly violated without consequence.Because selectively enforced laws are just another way of saying you have a king at some level, the person who decides to enforce or not. reply zaroth 42 minutes agorootparentSelective prosecution is a defense under the Equal Protection clause of the Constitution.However, the Supreme Court has left the prescribed remedy intentionally vague since 1996, which in turn makes the claims themselves less likely to be raised, and less likely to succeed.https:&#x2F;&#x2F;wlr.law.wisc.edu&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;1263&#x2F;2022&#x2F;... reply jrockway 43 minutes agorootparentprevYou have some control over this as an ordinary citizen. Next time you&#x27;re on a jury for a lemonade stand violation, nullify. reply not2b 18 minutes agorootparentHas a lemonade stand violation ever resulted in a jury trial in the US? I&#x27;m skeptical. In places that enforce those rules, usually what happens is that the cops tell the parent it isn&#x27;t allowed, the kid shuts it down and there&#x27;s no fine.glompers 1 hour agorootparentprevOkay but does that mean anything regarding the parent commentor&#x27;s analogy or the article? reply gchamonlive 1 hour agorootparentprev> 2FA and password managers didn&#x27;t make us heavily reliant on massive companies.Retool: https:&#x2F;&#x2F;arstechnica.com&#x2F;security&#x2F;2023&#x2F;09&#x2F;how-google-authenti...Lastpass: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34516275 reply rglullis 1 hour agorootparentIf Google Authenticator goes away, people will still be able to use 2FA (I for one use Aegis, it&#x27;s available on F-droid and does everything I need, including encrypted backups)If Lastpass goes away, people will still be able to use keepass or any of the large number of open source password managers, some of them even with browser integrations.If I have a website that is frequently attacked by botnets and Cloudflare goes away, what can I use to replace it? reply gchamonlive 1 hour agorootparentI am sorry, but if your password manager goes away and you have no disaster recovery scenario planned you might not be able to just move to a competitor:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31652650My response was to illustrate how insidious big companies are.Of course nothing compares to the backbone of the web going down. If AWS North Virginia suffers widespread downtime to all its availability zones, much of the web will just go dark, no question about it. reply bee_rider 1 hour agorootparentprev2FA, I’m not sure.But Lastpass doesn’t represent the whole of password managers. Storing your passwords in an online service is a really silly thing to do (for passwords that matter at least). Use something local like keepass. reply gchamonlive 1 hour agorootparentHope you plan ahead for a house fire with a 3-2-1 approach for backups. Maintaining an always on off-site storage is expensive unless you resort to cloud solutions like OneDrive or Dropbox, but then you go back to the problem of having your passwords on the cloud, even if encrypted.Not using cloud is just very expensive and time consuming for the average user. reply adrianN 1 hour agorootparentPasswords are small enough that you can make physical backups easily. reply gchamonlive 56 minutes agorootparentHonest question, because it is interesting and might change how I approach backing up my passwords. How would you go about maintaing that physical copy updated?What I think would make this approach hard is that you would have to ponder if a newly created account is important at creation time in order to know if you should update the off-site, physical copy of your most important passwords (I say this because if you want to backup everything and avoid the cloud entirely it is just not viable, having to update this physical backup for each new account. I am currently at over 400 logins in my pw manager, 2 years ago it was half as much).I think having your passwords encrypted with a high enough entropy master password and a quantum-resistant encryption algorithm, and having an off-site, physical backup of your cloud account credentials is enough for anyone not publicly exposed, like a politician or someone extremely wealthy, even though I would be skeptical these people go through such lengths to protect their online accounts. reply adrianN 4 minutes agorootparentWith two usb sticks it’s not that much work to take one witha fresh backup to my mom when I visit and take the other one back and update that backup. At worst I lose one or two logins. rglullis 29 minutes agorootparentprevThe lesson is not to \"avoid\" the cloud, but to not be \"dependent\" on it. Doubly so if the service provided is one that keeps you locked in and can not be ported over.So yes, I feel comfortable with my strategy of having backups on bluray disks + S3. If AWS goes down or decides to jack up their prices to something unacceptable, I will take the physical copies and move then to the dozen others S3-compatible alternatives. I am not dependent on AWS.But I am not interested in using Google Authenticator or Lastpass because that would mean that I am at their mercy. replycodedokode 2 hours agorootparentprevThere should be a protocol to block traffic on the upstream provider. So if someone from 1.2.3.4 sends lots of traffic at you, you send a special packet to 1.2.3.4 and all upstream providers (including the provider that serves 1.2.0.0&#x2F;16), that see this packet block traffic from that IP address directed at you. Of course, the packet should allow blocking not only a single address, but a whole network, for example, 1.2.3.4&#x2F;16.But ISPs do not want to adopt such protocol. reply tsimionescu 2 hours agorootparentSo I can deny service to your site with a single packet, instead of having to bother with establishing a whole botnet? The current botnet customers would be the first to advocate for this new protocol! reply alexfoo 2 hours agorootparentSimple! To prevent it being abused easily you could make it so you would need to send a high number of those packets for a sustained period in order to activate the block. reply brk 1 hour agorootparentThere is already an RFC we could apply, just implement forced RFC3514 compliance and filter any packets with the evil bit set.https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc3514 reply simondotau 2 hours agorootparentprevAnd there could be a short time limit on that block, perhaps one hour, but even 60 seconds would be enough to completely flip the script on a DDoS. reply codedokode 2 hours agorootparentprevYou can only block access to your IP address, so you can ban someone from sending packets to you but not to anyone else. My proposal is well-thought and doesn&#x27;t require any lists like Spamhaus that have vague policies for inclusion and charge money for removing. My proposal doesn&#x27;t have any potential for misuse. reply ComodoHacker 2 hours agorootparentHow can it protect from... botnets, where there are tens of thousands \"someones\"? reply tsimionescu 1 hour agorootparentprevIt&#x27;s not very hard to send packets with a fake source IP, especially if you don&#x27;t care about the reply. reply ndriscoll 1 hour agorootparentSeems easy enough to require (i.e. regulate) end-customer ISPs to drop any traffic with a source IP that isn&#x27;t assigned to the modem it&#x27;s coming from. This would at least prevent spoofing from e.g. compromised residential IoT devices. Are they not already doing that filtering? Is there any legitimate use-case to allow that kind of traffic? reply gene91 15 minutes agorootparentSomeone has to go and add the filtering. Nowadays (or maybe since ten years ago) most ISPs have the filter, but not the last 1% (or maybe 0.01%). plagiarist 1 hour agorootparentprevSorry, this is not well-thought and certainly has potential for abuse. This is on IP and not domain? What is the signing authority and cryptography mechanism preventing a spoofed request? reply codedokode 2 hours agorootparentprevYou can deny access only from your IP, not for anyone else. reply hnlmorg 1 hour agorootparentIP addresses can be spoofed. So you’d need some kind of handshake to verify you are the owner of that IP. Which is going to be tough to complete if your network is completely saturated from the DDoS in progress.I do think your idea has merit though. But it’s still a long way from being a well thought-out solution. reply iforgotpassword 1 hour agorootparentprevHow do you verify the source address of the packet is legit? reply papichulo2023 2 hours agorootparentprevYeah, we should invent secure communication channels and crypto keys first... reply ilyt 2 hours agorootparentprevWhat you say already exists, hell, you can use BGP to distribute ACLsBut it costs space in the routing tables and that means replacing routers earlier. It&#x27;s no wonder, especially if you multiply it by thousand customers.\"block all traffic from outside from this IP\" is significantly easier than \"block all traffic from outside from this IP to this client\". And you need to do it per ISP client, else it is ripe for abuse.And don&#x27;t forget a lot of the traffic will come from \"cloud\" itself. reply codedokode 2 hours agorootparent> What you say already exists, hell, you can use BGP to distribute ACLsBut you should own an AS for that?> But it costs space in the routing tablesNot implementing my proposal leaves critical infrastructure unprotected from foreign attacks. Make larger routing tables. Also, instead of blocking single IPs one can block &#x2F;8 or &#x2F;16 subnets. reply CountSessine 1 hour agorootparentMake larger routing tables.Brilliant! Why didn’t we think of that?!? MOARE TCAMS!!! reply toast0 1 hour agorootparentprevIf the source field in a packet reliably indicated the source of the packet and a given IP was sending you a lot of unwanted traffic, you&#x27;d ask their ISP to turn them off and the problem would be solved. Maybe one day BCP38 will be fully deployed and that will work. I also dream of a day where chargen servers are only a memory. Some newer protocols are designed to limit the potential of reflected responses.Null routing is available in some situations, but of course it&#x27;s not very specific: hey upstreams (and maybe their upstreams), drop all packets to my specific IP. My understanding is null routing is often done via BGP, so all the things (nice and not) that come with that.Asking for deeper packet inspection than looking at the destination is asking for router ASICs to change their programing; it&#x27;s unlikely to happen. Anyway, the distributed nature of DDoS means you&#x27;d need hundreds of thousands of rules, and nobody will be willing to add that.Null routing is effective, but of course it takes you IP offline. Often real traffic can be encouraged to move faster than attack traffic. Otherwise, the only solution is to have more input bandwidth than the attack and suck it up. Content networks are in a great position here, because they deliver a lot of traffic over symetric connections, they have a lot of spare inbound capacity. reply rootlocus 1 hour agorootparentprev> Of course, the packet should allow blocking not only a single address, but a whole network, for example, 1.2.3.4&#x2F;16.So, if my neighbour is infected and one of his devices is part of a botnet, I get blocked as well? reply bee_rider 1 hour agorootparentBlock the whole country, then I guess you’ll see laws passed that IOT providers need to start updating at a better clip. reply rcxdude 1 hour agorootparentprevThat already effectively happens in a lot of cases. reply eptcyka 1 hour agorootparentprevDo you know what the first D in DDoS attack stands for? reply HumblyTossed 2 hours agorootparentprevI am pretty sure that protocol would be just as abused. reply codedokode 2 hours agorootparentHow exactly? You can authenticate sender by sending a special confirmation token back. reply sophacles 12 minutes agorootparentHow does one get removed from the block list?Say some IoT device that half of households own gets compromised and turned into a giant botnet. The news gets out and everyone throws away that device. Now they are still blocked over a threat that doesn&#x27;t exist anymore... doesn&#x27;t seem like a good situation for anyone.I&#x27;d imagine that the website owners that want the attack stopped will soon want to figure out how to get traffic back since they need users to pay the bills.Whats to stop someone from just making an app that participates in an attack when connected to public(ish) wifi networks and participating in attacks long enough to get those all shut off from major sites?How does this stop entire ISPs from getting shut off when the attackers have managed to cycle through all the IP pools used for natting connections? (e.g. the Comcasts of the world that use cg-nat to multiplex very large numbers of people to very small numbers of IPs)? reply 6510 2 hours agorootparentprevI just imagined this: isp&#x27;s could make a isp.com?target=yourwebsite.org&#x2F;fromisp [slow] redirecting url. If you receive unusual amounts of requests from the isp you redirect it though their website.They can then ignore it until their server melts (which takes care of the problem) or take honorable action if one of their customers is compromised. The S stands for service after all. reply starcraft2wol 1 hour agorootparentprev> Let&#x27;s go back to username and password. 2FA forces scammers to up their game.Let&#x27;s do it. It works for the website you&#x27;re using right now. 2FA was in large part motivated by limiting bot accounts and getting customers phone number.I can&#x27;t imagine how much productivity the economy loses every day due to 2FA. reply actualwitch 6 minutes agorootparent> It works for the website you&#x27;re using right nowIt doesn&#x27;t, you can regularly see people getting their accounts stolen here. This wouldn&#x27;t be possible (or at least this trivial) with any competent implementation of 2fa. reply master-lincoln 1 hour agorootparentprevIs this sarcasm? If not please provide some more details on why you think \"2FA was in large part motivated by limiting bot accounts and getting customers phone number\". I never used a phone number for 2fa. Mostly TOTP. Bots could do that too. I don&#x27;t see the connection.>I can&#x27;t imagine how much productivity the economy loses every day due to 2FA.Is it really that much? Every few days I have to enter a 6 digit number I generate on a device I have with me all the time. Writing this comment took me as much time as using 2fa for a handful of services for a month. reply starcraft2wol 51 minutes agorootparent> ? Every few days I have to enter a 6 digit number I generate on a device I have with me all the time.I use more than one service a day, and some infrequently, so for me about every day I have a minute or two where I try to login, need to find my phone (it&#x27;s not predictable when it will ask), and then type it in. This happens to every person several times a day!I also now must carry a smart phone with me to participate in society.But the main drag is that when people lose or break their phones the response is: \"just don&#x27;t do that\" and the consequences range from losing your account to calling customer service.> Mostly TOTP. Bots could do that too. I don&#x27;t see the connection.Most people using 2FA do not use TOTP, they use a phone number.Bots could use TOTP, it&#x27;s more infrastructure, and it&#x27;s a proof of work function for them to login. reply michaelt 39 minutes agorootparentprevWhile I don&#x27;t take starcraft2wol&#x27;s theory seriously, there are a bunch of services that have made phone numbers essentially mandatory. They claim this is to \"protect your account\".You sign up for a Skype account or Twitter account and decline to give your phone number, instead choosing a different form of 2FA? In my experience your account will be blocked for &#x27;suspicious activity&#x27; even if you have literally no activity. reply starcraft2wol 1 hour agorootparentprevTo add, password managers provide great coverage of almost every problem 2FA is. supposed to solve and it improves the workflow your grandma already know (writing passwords on a sheet). The only difference is Google doesn&#x27;t get any money when you run a script on your own computer. reply seanw444 2 hours agorootparentprev> Privacy, long term, will mean the fall of civilization.I&#x27;m curious about your rationalization for this. Lack of privacy will also mean the fall of civilization. Civilization is just doomed to fail at one point or another. All things come to an end. reply gchamonlive 2 hours agorootparentThis was me being sarcastic. Of course we need privacy, not because we have things to hide, but because individuality can only flourish without constant surveillance.Yes! All things come to an end and that is why some recent philosophers think that Plato was naive to think it could minimize or erradicate society rotting. This is where negative utilitarianism comes in, where the point of society is not to maximize happiness (and therefore prevent society from collapsing) but to minimize suffering (and therefore provide mechanisms to minimize damages from transitions between organization forms when society collapses). I have to refer you to Karl Popper&#x27;s The Open Society for this, because needless to say this answer is very reductionist. reply seanw444 20 minutes agorootparentAh I just missed the sarcasm. Yeah, and when the sole goal is to minimize suffering, tyranny is introduced.\"Those who would give up essential liberty, to purchase a little temporary safety, deserve neither liberty nor safety.\" reply jorvi 1 hour agorootparentprevThis discussion is somewhat reminiscent of \"Don&#x27;t hex the water\"..https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Fzhkwyoe5vI reply lxgr 1 hour agorootparentprevThat&#x27;s not a valid comparison, since there are various effective decentralized 2FA methods available – unlike for DDoS protection. reply paganel 42 minutes agorootparentprevYes, what the OP is saying is related to one of the paradoxes of security&#x2F;defence, i.e. the fact that the more one increases its defences (like Google is doing) then the more said increase of defences also pushes one&#x27;s adversary to increase its offence capabilities. Which is to say that Google playing it safer and safer actually causes their potential adversaries to become stronger and stronger.You can see those paradoxes at play throughout the corporate world and especially when it comes to actual combat&#x2F;war (to which actual combat&#x2F;war these DOSes might actually be connected). For example the fact that Israel was relatively successful in implementing its Iron Dome shield only incentivised their adversaries to get hold of even more rockets, so that the sheer number of rockets alone would be able to overwhelm said Iron Dome. That&#x27;s how Hamas got to firing ~4,000 rockets in one single day recently, that number was out of their league several years ago when Iron Dome was not yet functional. reply zelon88 1 hour agoparentprevMost of them are dynamic IPs. Some of them are infected mobile devices.What happens when you log an attack from a device that is attacking you from a school or business WiFi network? Block the whole IP forever?What if the user is on a CGNAT. Are you going to block the edge proxy for that entire ISP?What if you&#x27;re getting hit from a residential connection that gets a new rotated IP every couple of weeks? Block whoever gets that IP from now on?Your solution doesn&#x27;t stop attacks. It just stops regular users. reply tristan9 1 hour agorootparent> What happens when you log an attack from a device that is attacking you from a school or business WiFi network? Block the whole IP forever?No, but for a day perhaps.> What if the user is on a CGNAT. Are you going to block the edge proxy for that entire ISP?Maybe. If the ISP doesn’t bother doing anything about it (which is THEIR job, not mine as a website operator).If the ISP can’t be arsed to do their job, why am I supposed to care about them at all?> What if you&#x27;re getting hit from a residential connection that gets a new rotated IP every couple of weeks? Block whoever gets that IP from now on?Same as the CGNAT one. It’s the ISP’s job to handle their misbehaving customers.If they refuse to do it and get complaints from their other customers that they’re getting blocked, maybe they’ll actually get to it.> Your solution doesn&#x27;t stop attacks. It just stops regular users.No. It puts pressure on the ISPs to finally stop whining loudly when they receive an attack while closing their eyes on any attack originating from their network.This is not sustainable. reply zelon88 1 hour agorootparentTrust me when I say that you don&#x27;t want the ISP&#x27;s to inspect web traffic. That is not how to solve this. That is costly for the ISP and will drive up costs. It also makes supporting a website impossible. The ISP is assumed by all parties to be impartial. That assumption is required for the internet to be operational. Sure it might function your way, but it would be impossible to support.And maybe Facebook and Google are big enough to push around the ISP&#x27;s, but they are the only ones. Nobody will bat an eyelash if 15,000 Comcast users in Phoenix AZ can access your hokey-pokey website. Comcast doesn&#x27;t care. The users won&#x27;t blame their ISP. They will blame you, or whoever owns the hokey-pokey website. If you want traffic, you need to be equipped to handle traffic. You are the one with the internet facing infrastructure.You are the one blocking traffic. Not the ISP. That is how it should be. The ISP should be impartial. You pay for connectivity. Consider yourself connected. For better or for worse. You are responsible for what you put onto that connection. reply mrweasel 59 minutes agorootparentprevISP needs to start taking much more responsibility, currently they do not care or choose not to care to avoid having to deal with upset customers.The fact that millions, if no more, devices can continue to access the internet regardless of how long they are compromised, is just crazy. I get that it put more responsibility upon end users to secure their devices, if they otherwise run the risk of get thrown of the internet, but I currently fail to see other options. Our device security still isn&#x27;t good enough that we can just use them with reckless abandonment.Any \"solution\" that attempts to fix the problem of increasing DDoS attacks and their damage that doesn&#x27;t address the issue of compromised devices being allowed to roam free on the internet is a band aid at best.And I can almost hear people complain that I&#x27;m arguing to throw compromised IoT, SCADA and monitoring devices of the internet, and yes I am. None of these things have any business being exposed to the public internet anyway. reply acedTrex 1 hour agorootparentprevIt is not an ISPs job to analyze traffic patterns and attempt to stop the bad ones. Thats like saying its the job of the road crews to stop speeders reply axus 42 minutes agorootparentOr that it&#x27;s the ISP&#x27;s job to cut off accounts that are downloading copyrighted works, or hashing cryptocurrency without paying taxes, etc.It would be nice if the cell phone provider could send a text message reporting the problem. But how to distinguish it from spam? reply mrweasel 54 minutes agorootparentprevSo who else? My proposal would be to have companies like Google, Microsoft, Amazon and hosting providers be able to report sources of DDoS attack to the ISPs who can then identify the customer and let the customer know that they have a week to fix the issue or lose connectivity. reply bee_rider 1 hour agorootparentprevThe idea clearly needs some work.But, a slight defense of it—the really big providers can already sink a massive DDoS anyway. So, this is just a scheme to help little websites. It doesn’t really matter if a school, or even a cellphone network, can’t access my little website for an afternoon.You’d have to decide if you want to send the block request. If you are hosting your personal blog, you’ll probably go for it regardless. If you are providing a small service; hosting git for a couple friends or whatever, you’ll probably block with some discretion. reply AdamN 2 hours agoparentprevThe only answer is publicly-resourced protection and it&#x27;s not that weird when you think about it. My apartment has a basic lock that any locksmith can undo and I&#x27;m safe because of my community and government protection (police, mental healthcare, justice system, etc...). Seems like the same logic should apply to my website or other digital property. reply candiddevmike 2 hours agorootparentISPs will gladly quarantine&#x2F;rate limit folks for pirating stuff, why don&#x27;t they use those tools to combat botnets? Though I could see this leading to a slippery slope of remote attestation for internet access. reply KomoD 38 minutes agorootparent> why don&#x27;t they use those tools to combat botnets?Because they probably don&#x27;t care. reply starcraft2wol 1 hour agorootparentprevCommunity yes. Government protection no. When was the last time you heard of police stopping a break-in or making a successful investigation ?Independent of police, in bad communities your neighbors are willing to break in. In good communities they don&#x27;t. reply 542458 2 hours agorootparentprevWhere this breaks down is that because of the nature of the internet and DDoS attacks it’s not something that can easily be solved with better policing - even identifying a perp might be near-impossible, and they might be in another country anyways. The government does try to prosecute botnets and DDoS attacks today, but it’s of limited success. Is there a practical solution here I’m missing? reply DanielBMarkham 2 hours agoparentprevWhy don&#x27;t we just require major providers to provide a realtime list of IPs that are attacking so that we can drop them in a block list with an expiration date of a month or so.If your computer is infected, I don&#x27;t want to talk to you for a month. If it continues to be infected, I might up that to a year, or permanently ban you.It&#x27;s your problem. Go fix it. reply Prickle 2 hours agorootparentI&#x27;ve been on the receiving end of \"Your\" (dynamic) \"IP has been blocked.\"I would greatly prefer not having my semi-randomized IP blocked because someone used it maliciously a year ago. reply tristan9 1 hour agorootparentThing is, don’t care.The problem is that ISPs whose customers are originating the attacks from don’t give a shit.If we have to give up 1% of legitimate traffic to thwart 90% of attacks, it is a good deal.If you and other customers complain to your ISP (or switch), eventually they’ll do something about it.We can’t seriously keep on accepting that « thousands of compromised devices » is a fine reality for a « small botnet ».These devices should be quarantined. reply dist-epoch 1 hour agorootparentAmazon definitely cares if they lose 1% of sales.Guess who has more votes, you or Amazon. reply DanielBMarkham 2 hours agorootparentprevKey phrase: \"a year\"If anybody is suggesting permanent bans of IPs, it&#x27;s not me, at least not at a public level. I may very well choose privately to do that.To clarify, I, personally chooses a blacklist policy. Not some other org. I think if you offload this onto any kind of external structure, it breaks again.ADD: We make publicly-available, second-by-second, how the internet is broken and invite all comers, including me and my blocklist, to help fix it.There&#x27;s a huge commerical interest in NOT fixing the problem of random crap showing up, from dancing cats selling things to targeted inserted ads. I get it. We saw this same thing happen with adblockers. It&#x27;s now going on with \"free\" VPNs. Can&#x27;t fight that perverse incentive, so don&#x27;t fight it. reply lapcat 2 hours agorootparentprev\"Moreover, the lifespan of a given IP in a botnet is usually short so any long term mitigation is likely to do more harm than good.\" \"As we can see, many new IPs spotted on a given day disappear very quickly afterwards.\" https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;technical-breakdown-http2-rapid-... reply scrpl 2 hours agorootparentprevGreat solution for a world without shared and dynamic ips. reply nine_k 2 hours agorootparentNot as bad as one may think. It&#x27;s proper feedback which can be acted upon.Every reasonable connectivity provider would pay attention to this info, or face intense complaints from its users with shared and dynamic IPs. It would identify sources of attacks, and block them at higher granularity level, reporting that the range has been cleared. (If a provider lied, everyone would stop believing it, and the disgruntled customers would leave it.)For shared hosting providers it would mean blocking specific user accounts using a firewall, notifying users, and maybe even selling cleanup services.For home internet users, it also would mean blocking specific users, contacting them, helping them identify the infected machine at home.It would massively drive patching of old router firmware which is often cracked and infected. Same for IoT stuff, infected PCs, malicious apps on phones, etc. There would be an incentive to stay clean. reply scrpl 2 hours agorootparentIf the one doing the blocking is not at FAANG it would do nothing of sorts. And FAANG benefit from DDoS by getting people into their walled cloud gardens. reply ilyt 2 hours agorootparentprevFunny man, thinks big ISP cares you yourself blocked your own site from your own customers coming from the big ISP network. reply dmm 2 hours agorootparentprevBlock the whole subnet and make it the ISP&#x27;s problem? reply DanielBMarkham 2 hours agorootparentIt&#x27;s interesting to me that most of the push-back so far has been for the business model of the internet, ie people need link traversal and content publishing in order to make money from advertising (implied, but not stated). Therefore we need to add yet another layer to the mix, the cloud providers, and start paying those guys.And yes, we can block entire subnets. You own the IP addresses, you&#x27;re responsible for stuff coming out of them, at least to the degree that it&#x27;s not maliscious to the web as a whole. (but not the content itself, of course)I&#x27;m calling bullshit on these assumptions. The internet is a communications tool. If it&#x27;s not communicating, it&#x27;s broken. If you provide dynamic IPs to clients that attack people, you&#x27;re breaking it. It&#x27;s not my problem or something I should ever be expected to pay for.To be clear, my point is that we&#x27;re suggesting yet another layer of commercial, paid crap on top of a broken system in order to fix it. It&#x27;d be phenomenally better just to publicly identify place and methods where it&#x27;s broken and let other folks with more vested interests than information consumers worry about it. Hell, I&#x27;m not interested in paying for the current busload of bytes I&#x27;m currently consuming for every one sentence of value I receive. reply cryptonym 2 hours agorootparentprevBecause when a single machine is infected, at one ISP, it&#x27;s a good idea to block the whole subnet? I don&#x27;t think any commercial activity could afford such security strategy, blindly blocking legit users by thousands. reply judge2020 2 hours agorootparentprevHow does the ISP solve it? Send a mass mail&#x2F;email telling people to reset their devices because someone has a device with botnet malware? reply bluGill 1 hour agorootparentThat is their problem. Maybe the price needs to go up if you don&#x27;t secure all your devices as the ISP is going to send a tech to your house. Or maybe the ISP has deep enough pockets to find a sue those cheap IOT device makers for not being secure thus funding their tech support team. reply AnimalMuppet 2 hours agorootparentprevEgress filtering? A botnet DDOS stream should not look like normal network traffic... reply scrpl 2 hours agorootparentprevI‘m sure comcast is terrified that their users won’t be able to read my blog. reply tmpX7dMeXU 2 hours agorootparentprevYou are quite obviously speaking from the perspective as someone that wouldn’t be in a position to be making these calls. reply phone8675309 2 hours agorootparentprevSo it’s the ISPs fault that my grandma never met a spam email that she didn’t want to click?One of the things that gets lost in this kind of debate is that the vast, vast majority of Internet users are not experts in how the Internet, computers, or their phones work. So expecting them to be able to \"just not get exploited\" is a naive strategy and bringing the pain to the ISP feels counterproductive because what, realistically, can they do to stop all of their unsophisticated users from getting themselves exploited?At the end of the day, the vast majority of the users of the Internet do not care how it works - they want their email, they want their cat videos, and they want to check up on their high school ex on Facebook. How can we rearchitect the Internet to be a) open b) privacy protecting, and c) robust against these kinds of attacks so that the targets of DDOS attacks have better protection than paying a third party and hoping that that third party can protect them? reply swarnie 2 hours agorootparentprev> Sorry citizen, google services are inaccessible because the only ISP in your city sold a service to a bad actor.> We might fix this, we might not, you DONT have a choice.> Thank you for your continued business. reply tmpX7dMeXU 2 hours agorootparentHacker News nerds will argue all day long that the Internet is a utility when the argument happens to personally benefit them, then in the same breath say that a random network admin is justified in blocking a whole ISP subnet due to one “bad” actor. And of course by bad actor I mean person that almost certainly accidentally got themselves infected with malware by not understanding the completely Byzantine world of computers and the Internet. reply phone8675309 2 hours agorootparentprevIndistinguishable from the kind of service I get from Google - the moment that I need a human involved I just close my account with whatever Google service is misbehaving and move on. reply swarnie 1 hour agorootparentBut you have other options which is my point.(swap in any corpo-service provider you personally like the most)Blanket banning subnet ranges from services because of the actions of someone else is 3rd world shit. replyafavour 2 hours agorootparentprevBanning a large number of customers for an entire month? doesn’t make economic sense, it’ll be cheaper to just pay a big cloud provider for protection.(not to mention the number of false positives you&#x27;d get, etc etc) reply codedokode 2 hours agorootparentprevI propose to make a special \"reject\" packet. When a host, let&#x27;s say 1.1.1.1, sends such packet to 2.2.2.2, all providers that see this packet, MUST reject any traffic from 2.2.2.2 to 1.1.1.1. This is very easy but very efficient and allows a single host to withstand the attack of any size.There is no need for any central authority and no need to maintain any lists. reply Swenrekcah 2 hours agorootparentThat actually sounds like a really good idea. This is already implemented in the physical world (in a much less efficient way) in the form of “no spam” stickers and registrations.Is there a reason other than inertia for why it hasn’t been implemented? reply bombcar 1 hour agorootparentThe main problem is how do you authenticate the request as being legitimate? It&#x27;s already possible to spoof headers and \"FROM-IP\" (in fact, major DDoS attacks use just this as a replay attack, spoof a DNS request as coming from 1.1.1.1 and get a much larger response sent TO 1.1.1.1 from wherever). reply codedokode 2 hours agorootparentprevISPs do not want to spend money for fighting against criminals. reply Swenrekcah 2 hours agorootparentThat doesn’t sound convincing to me. I mean I understand they don’t want to spend money but if cost is the only barrier it seems like that could be overcome somehow by interested parties. reply bombcar 1 hour agorootparentIt&#x27;s not the costs, it&#x27;s that some ISPs like getting money from spammers and criminals, and carefully look the other way.And the other ISPs like getting paid for DDoS mitigation, so they also look the other way. There&#x27;s no money to be made fixing the underlying problem. reply KomoD 34 minutes agorootparentprevAnd then that can be abused... reply smath 1 hour agorootparentprevThat would be giving away some of the secret sauce on the part of the cloud providers. They are selling security as (part of their) service. There are some community shared lists of botnets ofcourse, but they may not be vry real time or very up to date. reply ilyt 2 hours agorootparentprevAnd now some of your services don&#x27;t work because you blocked IP that turned out to be cloud service IP being reused for legit service reply fragmede 2 hours agorootparentprevYou&#x27;re assuming that identification of attack traffic is 100% correct which is unfortunately not the reality. reply falcor84 3 hours agoparentprevNothing \"forces botnets to up their game\", they just want to make money (or in some cases, \"watch the world burn\"); I don&#x27;t see how any coordination whatsoever would diminish these motivations. reply grotorea 2 hours agoparentprevSo the email spam solution? Doesn&#x27;t that come with its own list of problems?Also, stupid question from someone not that familiar with DDoS, can&#x27;t you flood the target with requests even if the source address will be rejected? Or even if the IP packet has a falsified source address? reply tmpX7dMeXU 2 hours agorootparentYes. reply JAlexoid 1 hour agoparentprevProliferation of low cost computing is the cause of this, not big players being able to mitigate this.This is not coming from \"known botnet IPs\", this is from random infected devices. Some aren&#x27;t even permanently doing this, just one request from a device per day - it already large enough to cause issues. reply turminal 2 hours agoparentprevIt&#x27;s worth noting that features like the one that enabled Rapid Reset are pushed into standards by the exact same companies, because they are needed for performance at their scale.So in a way this was partially caused by the existence of insanely big tech companies that need such features. reply lostmsu 1 hour agorootparentEither I misunderstood the issue, but it sounds like rapid reset was not the cause. reply turminal 1 hour agorootparentRapid Reset is the name given to the technique behind the attack. The cause is a flaw in HTTP&#x2F;2 stream multiplexing that enables this technique. reply KomoD 37 minutes agoparentprev> The fact that large cloud providers can handle huge DDoS attacks I think in the long run leads to a worse internetDon&#x27;t agree.> the only solutions available are to pay Google, Amazon or Cloudflare a protection tax.It&#x27;s not.> come through some community coordinated list of botnet infected IPsHow would that help? reply dsign 2 hours agoparentprevFor a side-hobby of mine (writing), I imagine what would happen if current trends would continue. Thus, big caveat, it&#x27;s all just thought experiments, not realistic predictions of any kind.For this particular scenario, the public Internet would get so bad (\"enshitified\") that people would tend to leave it alone. For essential public services, governments would set up their own networks disconnected from the Internet, where all devices and their connections must be authenticated to a person or corporation[^1]. Maybe something equivalent would exist for corporations and to enable e-commerce.[^1] China works like this already, to a high degree. reply FrenchDevRemote 1 hour agoparentprev>but I&#x27;d really wish for them to come through some community coordinated list of botnet infected IPs or something.Using any kind of community coordinated IP ban is useless and would hurt a lot of people, millions(or even billions) of devices have dynamic IP addresses.You would not stop botnets from DDoSing you and on top of that you&#x27;d block millions of legitimate users. reply terlisimo 2 hours agoparentprevI&#x27;ve witnessed a few sustained (hours&#x2F;days long) DDOS attacks that were straight up extortion: owners contacted with \"give us money or we will keep your site offline\".Most of the time I see attacks lasting 15-20 minutes. I&#x27;m assuming it&#x27;s either someone doing it \"for the lulz\" or some cyber warfare outfit testing their big guns.I always consider the possibility of someone using DDOS to mask a more sophisticated attack. reply glimshe 1 hour agoparentprevDo you remember the pre-DDoS mitigation days? Botnets could easily bring down major, important sites and make them unavailable to users. This caused monetary loss and could even cause life loss depending on the site. How is the previous state better than, well, not suffering from these problems? reply londons_explore 2 hours agoparentprevPlenty of even quite-large websites just don&#x27;t get attacked by DDoS attacks, because nobody has any particular reason to attack them. reply tristan9 1 hour agorootparentYou’re completely wrong.All large sites regularly get attacked.The average skiddie’s motivations are that they’re bored. So they DoS a site they use regularly just to see.Heck they generally don’t even mean to cause damage per-se, and just think it’s a funny use of their evening.You have to stop thinking DoS attacks are always particularly personal. They really often just aren’t, and it’s a monumental pain in the ass to be on the receiving end. reply londons_explore 2 minutes agorootparentI run boring sites like government websites which say what kinds of recycling go in which color trash cans.Well used, but never attacked. reply balls187 1 hour agoparentprevThis is akin to the argument that bike helmets makes people less safe (and invariably has a comment about the Dutch and their safety record) reply lozenge 1 hour agorootparentIt is like saying effective spam filters are bad for email as a distributed system.It&#x27;s the spam that killed email, not the filters. reply RandomLensman 2 hours agoparentprevWe could also treat it as a public security threat and act accordingly. reply justaman 2 hours agorootparentI think this is the key take away. Unfortunately world leaders are not tech savvy enough to even consider this a threat. reply jacquesm 1 hour agorootparentYet. But we&#x27;re getting there. reply supertrope 1 hour agorootparentprevWhich jurisdiction are you referring to with “we”? reply RandomLensman 1 hour agorootparentAny that matters, I guess (\"we\" as in the collective of people). reply tiler2915072 1 hour agoparentprevIt’s a prisoner dilemma! The only way to win is for both service providers and “bad people” to not escalate. That’s not going to happen. reply siva7 1 hour agoparentprevA protection tax? You realize that DDoS protection costs them providers real money? reply mihaic 1 hour agorootparentYes, but cloud providers share that protection over all customers. Someone hosting their own websites needs the same level of protection just for themselves.DDoS is really the only thing that you can&#x27;t host yourself on your own machines in today&#x27;s internet. reply siva7 34 minutes agorootparentI don&#x27;t think they do. There are a variety of DDoS attacks which require more expensive computing to detect reply vmfunction 2 hours agoparentprev> pay Google, Amazon or Cloudflare a protection tax.Just FYI: hetzner has free DDoS https:&#x2F;&#x2F;www.hetzner.com&#x2F;unternehmen&#x2F;ddos-schutzI&#x27;m sure other hosting companies also offers it. reply ilyt 2 hours agorootparentDoesn&#x27;t really work for those types of attacks> In this final layer, we filter out attacks in the form of SYN floods, DNS floods, and invalid packets. We are also able to flexibly adapt to other unique attacks and to reliably mitigate them.Which means any legit http2 connection will go just fine.Even if such connection now triggers hundreds of substreams.Push for end to end encrypted internet also means you can&#x27;t really stop any more advanced attack. You could have just few dozen of hosts doing 20-30 connections each (i.e. \"looking perfectly normal\" for DDoS protection provider) generating tens of thousands per second in http2 streams.I&#x27;m speaking from experience of mitigating attack like this. Our DDoS provider was near-useless.. reply bombcar 1 hour agorootparentFor the higher layer attacks you have to have something like the \"modified cryptominer in the browser\" things that cloud flare and friends do now - those interstitial pages that pop up for a few seconds are doing mathematical hashing to burn processor time on your end - which greatly complicates the ability to DDoS. reply tpetry 2 hours agorootparentprevOnly for mini DDoS attacks - for larger ones they disable routing for your ip address. I guess they don‘t have the capacity to handle the big DDoS attacks nowadays. reply tmpX7dMeXU 2 hours agorootparentYep, and null-routing your IP is exactly what providers did in the days GP is longing for, and still do do, especially outside of big cloud providers. reply raincole 2 hours agoparentprevJust like the law enforcement forced the criminals to up their games, so the only option we have is to pay tax?Well, I wrote this comment to ridicule yours... but actually that was what happened. reply rs999gti 1 hour agoparentprev> Cloudflare a protection tax$NET gives away DDOS protection for free for non-businesses reply tonmoy 1 hour agoparentprevIn less words, it’s DDoS attackers that make the internet a worst place reply paulddraper 2 hours agoparentprevThis comment has \"getting vaccinated is bad because it forces diseases to up their game\" energy reply blueflow 2 hours agorootparentThere is Marek&#x27;s disease, so you still need to show that GP is in the wrong. reply starcraft2wol 1 hour agorootparentprevOne is about machines on the internet serving images and forum posts. This comment is low quality and is a form of name calling. reply mihaic 1 hour agorootparentprevI was writing it with a \"using antibiotics in absolutely every mundane product causes superbugs\" energy actually, which is something that is really a problem. reply nonameiguess 2 hours agoparentprevThe actual solutions are:1) Egress filtering by the ISPs2) Better malware resistance and vulnerability mitigation on easily-compromised appliance and IoT devicesBut neither is going to happen. 1 is a coordination problem. It has to be all or nothing, which can only be compelled by law, and we have no global laws and no global law enforcement mechanism. Some countries inevitably don&#x27;t care and the rest won&#x27;t partition the entire Internet by permanently cutting them off. 2 would probably make the entire Internet of Things and a whole lot of home computing just not happen because it isn&#x27;t economically feasible. Poor security effectively acts as a tacit tax. We all pay a little bit each, but the tax is collected by criminals instead of governments.Note that even your proposed solution here only works if 1 happened. Otherwise, source IP spoofing easily defeats a blocklist. reply ilyt 2 hours agorootparentThe problem with this type of attack is that you can&#x27;t really catch it as MITM DDoS protection.You&#x27;re not seeing any SYN flood, just a bunch of TCP connections (equivalent of say search crawler), that are encrypted. Only after unpacking on loadbalancer those are visible as one TCP stream sheltering thousand HTTP2 streams. reply sophacles 1 hour agoparentprevDDoS attacks were growing in size and frequency before these companies started creating products to address them. They took down sites, demanded ransom, and cost a lot of money in lost business and hosting bills.If you want to complain about an actual working solution, that&#x27;s your right, but realize that without an alternate solution you&#x27;re advocating for giving small gangs the ability to disrupt everyone else&#x27;s lives on a whim. reply kijin 2 hours agoparentprevA spamhaus-like blacklist for botnet IPs is an interesting idea.What if Google and Cloudflare collectively reverse-DoSed all the infected IPs, not by sending them any traffic, but simply by refusing to accept any connections from them to any part of their infrastructure?Whoever is on those IPs will suddenly find that half the internet doesn&#x27;t work anymore. Which is probably a good enough incentive for them to replace their router, format their PC, or whatever else is necessary to disinfect themselves.In many parts of the world, landline IP allocations tend to be stable enough for this to have a real effect. Phones are a different story, but phones are also much less likely to be useful in a DDoS botnet. (The owner would immediately notice the sudden heat and data usage.)If we&#x27;re going to live in a world where a small number of companies own half the internet, at least they could use their power to do some good. reply londons_explore 2 hours agorootparentGoogle already does this. \"Something on your network is causing unusual traffic, please fill in this captcha to continue\".And then you have to fill in a new captcha every 5 minutes or so just to keep using google maps&#x2F;gmail&#x2F;search.It&#x27;s kinda annoying, and usually the culprit is someone else who shares my IP, not me (ie. a school, university, workplace, open wifi). reply londons_explore 2 hours agorootparentFor any googlers reading: This behaviour sometimes hits an ajax request (map data downloads when panning or zooming). The client side javascript then fails badly and the user sees a broken site rather than a captcha request.Plz fix. reply menscher 2 hours agorootparentprevWe don&#x27;t need to share a block-list, but yes, blocking all traffic from open proxies (which nearly all the large attacks of the 2020s have used) is definitely part of the long-term plan. Any legitimate users of those proxies will experience some short-term pain, but they&#x27;ll patch and life will go on. reply hayyyyydos 2 hours agorootparentprev> In many parts of the world, landline IP allocations tend to be stable enough for this to have a real effect.And what about CGNAT? reply kijin 2 hours agorootparentIn that scenario, it&#x27;s on the ISP to clean their network of abuse, the same thing they would need to do if Gmail had blacklisted their IPs for spamming. After all, an ISP that can&#x27;t connect to YouTube isn&#x27;t going to stay in business for long.People have been begging ISPs for ages to do a bit of egress filtering, for example, to prevent source address falsification. They&#x27;ve demonstrated time and again that they don&#x27;t give a crap unless it affects their bottom line. reply vasachi 2 hours agorootparentOK, but how should an ISP distinguish a good HTTP&#x2F;2 connection from a bad one (I&#x27;m talking about this particular attack)? As far as I can tell, the DoS starts after the connection from bot to server is established, at which point the connection is fully encrypted. Should all ISPs MITM their clients to ensure that all traffic is good and proper? replyoldtownroad 3 hours agoprevAt a previous company, we were subject to semi-frequent attacks (of a much smaller scale). The operating assumption internally was that it’s a competitor trying to undermine us but it remains a mystery.Anyone involved in these type of attacks (at internet-infrastructure scale or targeting specific companies) brave&#x2F;crazy enough to create a throwaway account and tell hn about the motivations? reply OsrsNeedsf2P 3 hours agoparentWe had a similar issue and assumed it was script kiddies having fun. Turns out someone (raises hand) wrote a really bad microservice who&#x27;s inefficient queries sometimes triggered all our alerts. reply ilyt 2 hours agorootparentWe had that except it was our own frontend developers.We also had some actual attacks so we made a system that detect anomalies (like more than 50rps per IP) and raises alert....which was thwarted by frontend developers again, as they loaded few hundred tiny icons at once that triggered that alert routinely, and only thru http2 multiplexing their idiotic design patents haven&#x27;t bitten them before. reply dudeinjapan 3 hours agoparentprevSure, I’ll spill the beans. Some people think it’s related to Gaza or Ukraine but it’s not. We just really don’t like Google, we are trying to shut it down so we can bring back Altavista. reply kps 3 hours agorootparentI miss boolean search operators. reply falcor84 3 hours agorootparentprevMade me wonder - if Google wasn&#x27;t there and Altavista was the incumbent, would it be any different, or was the enshittification of search inevitable? reply nordsieck 2 hours agorootparent> if Google wasn&#x27;t there and Altavista was the incumbent, would it be any different, or was the enshittification of search inevitable?You might not remember this, but before Google, paid search placement was par for the course. One of Google&#x27;s innovations, one of the things that really endeared it to users was clearly labeling their ads.So, yes - it was inevitable. And, in fact, Google probably staved it off at least a decade; maybe more. reply Frost1x 1 hour agorootparentprev>... or was the enshittification of search inevitable?My bet is on the latter. Enshitification is a direct product of greed. No crafts person or creator I know of goes into something they enjoy creating with the intent to make it this monstrosity of money extraction. Most creators have a drive for their creation to be shared and experienced by many.Yes, you may want to get a reward in the process and for some creators, their motives may change over time if they see an opportunity to turn their creation into a wealth machine for themselves so they can do whatever after.Enshitification I believe is a secondary effect of something that becomes successful for the owners of something and either they or others change motives towards value. Optimization is no longer about the creation, sharing, experience, humanitarian, whatever motive and shifts to money. The second that becomes the goal, enshitication is just part of the optimization journey. In my line of thinking, it&#x27;s the same reason monopolies or near monopolies tend to form, these are merely further states along optimization strategies in the monetary&#x2F;wealth extraction goal.Part of that process is that when something starts to succeed, it attracts people with these goals so the goal of something shifts pretty rapidly. reply toast0 58 minutes agorootparentprevBefore Google, new search engines became crappy after 6-12 months, maybe two years tops.It&#x27;s not surprising Google search is now crap, it&#x27;s what happened to all the old search engines. It&#x27;s only surprising that it took 15-20 years (depending on perspective), and in the mean time, they&#x27;ve developed a big ecosystem of other stuff. reply dudeinjapan 3 hours agorootparentprevWas at Tokyo Disneyland today and taught my girlfriend the word “enshittification”. (i.e. making your customers pay via your stupid app to do literally anything in your park, and not even providing wi-fi.) reply resfirestar 2 hours agorootparentThat&#x27;s not enshittification, squeezing money out of you is just how theme parks operate. The term can&#x27;t really apply to Disney parks at all because there&#x27;s no two sided market. reply Grazester 2 hours agorootparentYou missed the no WiFi part. At least enable customers to send their money! reply seanmcdirmid 2 hours agorootparentprevI don’t remember paying for anything at Disney Sea with the app except for a few fast passes (and used to schedule the free fast passes of course). Suica card and credit card worked for everything else. reply Ylpertnodi 1 hour agorootparentprevThat&#x27;s double-dipping? reply ilyt 2 hours agorootparentprevSo you taught her wrong, that&#x27;s not what it means... reply zapdrive 1 hour agorootparentprevIf only people would stop going to transneyland. reply wmeredith 1 hour agorootparentprevI&#x27;d say enshittification is inevitable. It isn&#x27;t a technology issue, it&#x27;s human issue. Imagination and desire are what brought us this far and also what holds us back. See also: the tragedy of the commons, the prisoner&#x27;s dilemma, the trolley problem, etc. reply lock-the-spock 1 hour agorootparentprevAs someone old enough to remember: one of the main reasons Google won was that the other engines (shedding here a tear for Lycos) simply couldnt handle the increasing amount of web spam. They were built in a trusted web environment, but suddenly things became cheap enough for less scrupulous people to start creating effectively spam sites, and the engines somehow didn&#x27;t manage to react in time. reply seanmcdirmid 2 hours agorootparentprevThere is a reason Google’s first office was right next door to DEC WRL and Alta Vista. There is so much cross contamination between the two that it’s impossible to say. reply kps 3 hours agorootparentprevAltavista started turning to shit as soon as it was no longer an Alpha demo. That was a major reason Google took off so quickly. reply c7DJTLrn 2 hours agorootparentprevI think the plan went horribly wrong, everybody started using Bing again! reply mortallywounded 3 hours agorootparentprevSounds like something those dogpile folks would do. reply stepupmakeup 2 minutes agoparentprevprotection rackets by companies you&#x27;d only find on places like lowendtalk reply arein2 2 hours agoparentprevA local hosting company ddosed local bussineses that had IT infrastructure and then advertised their hosting solution with ddos protection. reply elorant 2 hours agoparentprevI&#x27;ve heard stories about attacks where the target is a subsystem but in order to avoid drawing attention to it they attack the entire network. reply xyst 2 hours agoparentprevI did it for the “lulz” reply dduarte 3 hours agoprevSame attack on Cloudflare https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;zero-day-rapid-reset-http2-recor... reply Aissen 3 hours agoparentThe technical article (linked in the post) has more interesting details: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;technical-breakdown-http2-rapid-... reply H8crilA 1 hour agorootparentThis should be the top comment.TL;DR: HTTP&#x2F;2 is internally concurrent, can handle multiple streams. It is possible in HTTP&#x2F;2 to send a nasty request that looks like so: - GET x1 - GET x2 - GET x3 - ... - GET x100 - Actually, cancel all of the above (uses multiple RST_STREAM frames) - GET x101 - GET x102 - (...) - GET x200 - Actually, cancel all of the above (uses multiple RST_STREAM frames) - (...)This can be repeated a lot of times. The problem is that the endpoint, which typically is a reverse proxy, might start dispatching the requests before it reads about their cancellation. And sure it will cancel them, but by the time of cancellation it will already have resulted in some resource usage downstream. Such requests are accepted because at no point the client has opened more than 100 streams, which is the typical concurrency limit. The example from the blog manages to squeze in a single packet 1000 GETs (i.e. 1000 HEADERS) correctly interleaved with RST_STREAM.Maybe it&#x27;s just me, but it&#x27;s always fun to see such creative and simple abuses of protocols&#x2F;code. reply sph 3 hours agoprevHow does DDoS mitigation work? When people say \"I put my website behind Cloudflare to mitigate DDoSes\", what does it mean exactly?Is it only about having a large enough ingress pipe that you can weather however many Gb&#x2F;s you are being bombarded with, and still having some spare capacity for legitimate traffic? reply MayeulC 3 hours agoparentIt is about that and a lot of other things, but it usually involves being able to dynamically scale up your bandwidth and compute power to cope with the incoming flood.A lot of DDoS traffic isn&#x27;t actual HTTP traffic, it can be garbage targetted at your IP address to \"fill the pipes\" (bigger pipes help, as well as having multiple server geographically distributed). Some can be TCP SYN flood, to just open TCP connections and exhaust available ports. Etc. Oftentimes, multiple simple reverse proxies can handle these malformed requests in front of your server.Then, for the most sophisticated queries that send seemingly-legitimate HTTP traffic, one has to handle them... It could be serving requests from a cache, adding captchas to slow attackers and identify legitimate traffic, enforcing rate limits, etc. Usually, you&#x27;d like to be able to tell if a request is legitimate or not before forwarding it to the actual server, and you can deploy all sorts of tools to do so. reply toast0 27 minutes agorootparent> it usually involves being able to dynamically scale up your bandwidth and compute power to cope with the incoming flood.I don&#x27;t think this is right. If you have a meaningful amount of bandwidth, dynamically scaling it is getting a connection upgraded in weeks instead of months. If you don&#x27;t have a meaningful amount of bandwidth, you&#x27;re rely on your provider(s) to have enough bandwidth and again, they can&#x27;t expand quickly.> Some can be TCP SYN flood, to just open TCP connections and exhaust available ports.If you have a tcp stack from maybe 2003 or later (so excluding macos, unless they changed something in the past four years), it will have synflood protection, with syncookies. In the event of a heavy synflood, your system will send at most one syn+ack per incoming syn, and actually accept connections on the incoming ack. Yes, you miss out on detailed tcp options, but it&#x27;s not that big of a deal, unless the volume impacts your available bandwidth.Also, as a tcp server, you can&#x27;t meaningfuly run out of ports; your one listen ip:port can connect to all ip:ports, if you have the memory for it. You&#x27;ll probably run out of total accepted sockets, but there&#x27;s no real resource limit on partially accepted connections, because of syncookies. It can be much more draining when DDoS clients actually hold connections. But it&#x27;s often simply about volumetrics, and it&#x27;s easier to generate a high volume of SYN packets than to hold a connection. reply richardwhiuk 3 hours agoparentprevCloudflare, and other companies, can detect that requests are DDoS and either drop, throttle, or verify the traffic, instead of forwarding it your server.You configure your server to drop all traffic which wasn&#x27;t set by cloudflare, which is efficient. reply tazjin 2 hours agoparentprevBack when I was in Google SRE, people would joke that \"we just send DDoS traffic to Australia\".In general, Google&#x27;s internal cross-DC traffic is so much larger than anything anyone could DDoS them with that they can always find a way to deal with it. reply detaro 3 hours agoparentpreva) Big pipesb) ability to filter the noise from real traffic as far as possible (i.e. there is little point in taking in a big pipe of DDoS traffic and then just proxying it to the thinner pipe to the real backend - but if you can identify bad traffic you can drop it and not pass it through).c) being a CDN helps as a side-effect (what the CDN serves doesn&#x27;t load the backend services, what can be served from the CDN works for users even if the backend is slow or down) reply dharmab 3 hours agoparentprevOften it means automatically recognizing DDoS requests and handling them in a way that is less costly, without impacting legitimate users.In this case, it might mean recognizing when a client rapidly resets streams, and either moving that traffic to a slow lane or filtering it entirely. reply SteveNuts 3 hours agoparentprevWhen the ddos attack is volumetric, the only way to mitigate it is to have a fat enough network to handle the traffic while you work with ISPs to start blocking the traffic upstream.Not all ddos attacks are based on volume though, some are exploiting native features of a protocol, like the slow loris attackhttps:&#x2F;&#x2F;www.cloudflare.com&#x2F;learning&#x2F;ddos&#x2F;ddos-attack-tools&#x2F;s... reply dijit 2 hours agorootparentthat&#x27;s not the only way.The way we used to do it is have \"filter boxes\" with a real anycast IP address&#x27;s which reverse connect to your origin.This helps a lot because it keeps a lot of traffic localised instead of allowing it to collect in one place. Anycast should also mean you have a failover mechanism; but if it fails then you&#x27;re only down in one section of the world where the most bots are anyway, which is usually not as bad as being down globally. reply papichulo2023 2 hours agoparentprevI always believed that they have some secret mega routers with massive computation limits that allows smart and complex tcp&#x2F;udp packages filtering. reply sschueller 2 hours agorootparentThey do have special equipment at the edges like: https:&#x2F;&#x2F;www.netscout.com&#x2F;arbor reply jruohonen 3 hours agoparentprevCDN&#x2F;SDN. reply dominicdoty 1 hour agoprevCouldn&#x27;t cloudflare show a page to the next handful of http requests from an IP informing the user that \"something on your network is participating in DDoS attacks\".All the big providers could do this, just inject a little turnstile like page in front of the next cloudflare site you visit.I would love to know if there&#x27;s a compromised device on my network, and I don&#x27;t have any real monitoring set up to detect it.It&#x27;s not a full solution, but at least informing users there is a problem is a good start. reply ricardobeat 3 hours agoprevNo word on the origin of these attacks? This must require massive amounts of hardware, you’d imagine it to be easily traceable unless some kind of botnet. reply tyingq 3 hours agoparentThat&#x27;s the particularly bad news, this attack does NOT require a really huge botnet.https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;zero-day-rapid-reset-http2-recor...\"Furthermore, one crucial thing to note about the record-breaking attack is that it involved a modestly-sized botnet, consisting of roughly 20,000 machines\" reply grotorea 2 hours agorootparent20000 being modest really says a lot about the state of security on the Internet. reply arp242 1 hour agorootparentThere are 5 billion people on the internet. This is 0.0004%. Even 2 million is only 0.04%.(this assumes that 1 person = 1 device; some people share devices, most people have more than one, e.g. I have a laptop and a router, many people also have a phone, a work laptop, and whatnot – the average is probably >1, maybe even >2) reply londons_explore 2 hours agorootparentprevDistribute just one warez game with your malware embedded and you&#x27;ll have well over 20,000 hosts under your control. reply superhuzza 2 hours agorootparentprevOr does it say more about the sheer number of devices connected to the internet? reply tyingq 2 hours agorootparentprevWell, 20000 to hit 201 million requests per second and give Cloudflare problems. You wouldn&#x27;t need that to make problems for many sites. reply paulddraper 2 hours agorootparentprev*the size of reply danpalmer 3 hours agoparentprevOne could imagine that, given the size, it could be politically or legally sensitive to announce the origin. reply persedes 3 hours agorootparentLooking at the scale of those that&#x27;s what I figured too, but one of the previous largest ones (mirai) was targeting a minecraft server (...). Krebs has some interesting write ups on Mirai. reply ricardobeat 3 hours agorootparentprevThe silence is actually already giving it away then, one of four options. reply blagie 3 hours agorootparentEnumerate, please. reply KolmogorovComp 2 hours agorootparentI assume China, Iran, North-Korea or Russia (in alphabetical order). reply lionkor 2 hours agorootparentprevUS enemy one, two, three and four (whoever is trendy to blame right now) reply knorker 1 hour agorootparentprevCloudflare explicitly says it&#x27;s an unknown threat actor: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;zero-day-rapid-reset-http2-recor... reply tootie 2 hours agoparentprevThe immediate assumption is that Iran is doing it. They have done it many times before and they are allied with Hamas. I haven&#x27;t seen any proof but it&#x27;s a safe bet. reply londons_explore 2 hours agorootparentA novel attack like this done at small scale like this is probably just a script kiddie experimenting.An actual nation state would have tested it fully internally and started on the public internet at a scale bigger than 20,000 machines. reply mgaunard 3 minutes agoprev398M rps means a request every 2.5ns.Most likely the figure is incorrect, or at least misleading. reply ncr100 1 minute agoparentNot likely, it&#x27;s a novel minimalistic attack.Cloud Flare also got one of these, 201 RPS. reply adzm 3 hours agoprevLinked in this article is more info on the rapid reset feature of HTTP2 which was used at part of the ddos https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;identity-security&#x2F;how... reply tuananh 2 hours agoprevCloudflare blog: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;zero-day-rapid-reset-http2-recor... reply datadeft 39 minutes agoprev398 million requests per second is really the largest DDOS attack to date? reply codedokode 2 hours agoprevSuch attacks are possible because ISPs do not want to adopt a protocol that would allow any host to send a special packet to block malicious traffic on the upstream provider or even at the source network. In this case networks like Cloudflare would become unnecessary. reply Egrodo 1 hour agoparentIf it becomes this easy to block traffic couldn&#x27;t malicious applications really mess up a user by spamming out reject packets for common IP? reply ilyt 2 hours agoparentprevThat costs a lot of money to implement. They are in business of selling pipes, not pipe filters reply throwawayqqq11 2 hours agoparentprevISPs could enshitty-sell it though. reply supertrope 1 hour agorootparentAltruism is not profitable. reply 20 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google successfully thwarted the largest distributed denial-of-service (DDoS) attack to date, peaking at 398 million requests per second (rps) using a novel technique named HTTP/2 Rapid Reset.",
      "Targeting major infrastructure providers, including Google's services and infrastructure, Google's global load-balancing and DDoS mitigation infrastructure played a significant role in defence, additionally collaborating with industry partners for a comprehensive understanding and development of countermeasures.",
      "The identified vulnerability has been labelled CVE-2023-44487, with advice to organizations operating HTTP-based workloads to apply patches or verify their servers' vulnerability. Google Cloud offers DDoS protection via Cloud Armor and recommends adopting additional security measures such as custom security policies and rate limiting rules."
    ],
    "commentSummary": [
      "The talks are centered around the problem of Distributed Denial of Service (DDoS) attacks and the requirement for effective safeguards and accountability.",
      "Various strategies like blocking specific IP addresses or enforcing robust authentication measures were mentioned, while discussing the challenges and constraints of current mitigation techniques.",
      "ISP's role, companies like Google, and issues concerning privacy, abuse, and effects on bona fide users were highlighted. It was mutually agreed upon reengineering the internet and introducing better security methods to counter DDoS attacks."
    ],
    "points": 324,
    "commentCount": 265,
    "retryCount": 0,
    "time": 1696939844
  },
  {
    "id": 37826842,
    "title": "ECC RAM on AMD Ryzen 7000 Desktop CPUs",
    "originLink": "https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/",
    "originBody": "sunshowers about work ECC RAM on AMD Ryzen 7000 desktop CPUs 2023-10-09 :: 9 min read #ecc #ryzen #amd Introduction One of the coolest features of AMD’s Ryzen desktop CPUs, and historically a great reason to get them over the competition, was the official support for error-corrected memory (ECC RAM)1. With most Ryzen 1000 through 5000 series CPUs and the right motherboards, ordinary users could get ECC RAM going without having to spring for more expensive workstation-grade CPUs. Specification page for the B550 Steel Legend motherboard. For example, here’s the specification page for the ASRock B550 Steel Legend motherboard. This is a mainstream “B” series motherboard which lists detailed compatibility information for ECC RAM by processor generation. (To my knowledge ASRock has had the best support for ECC RAM in Ryzen motherboards, and I’ve been very happy with their motherboards in general.) Specification page for the X670E Taichi motherboard, with no mention of ECC support. Unfortunately, when the AMD Ryzen 7000 “Raphael” CPUs were launched along with the brand new Socket AM5, all mention of ECC support was gone. The specification page for the ASRock X670E Taichi, one of the most expensive AM5 motherboards you can buy, has no mention of ECC support as of the date of writing this. I still decided to upgrade to a Ryzen 7950X, and overall I’ve been happy with the performance of the new processor. But the lack of ECC was a huge bummer at the time of purchasing my system. Finding a forum link A couple months ago I came across a topic on the ASRock forums talking about ECC support on AM5 motherboards, in which a user called ApplesOfEpicness said that they’d worked with an AMD engineer to get ECC RAM going within AMD’s AGESA firmware. They’d claimed to have tested it on an ASRock motherboard with an updated UEFI, by shorting ground and data pins, and seeing errors be reported up to the OS. I was intrigued by this! Even though I didn’t have the same motherboard that ApplesOfEpicness did, I had chosen an ASRock board (the B650E PG Riptide)—I had figured that if ECC was possible on any AM5 board at all, it would be supported on ASRock. So based on the forum post, last week I ordered a pair of 32 GB server-grade ECC sticks from v-color. I updated my motherboard’s UEFI to the latest version (version 1.28 with AGESA 1.0.0.7b), and then replaced my existing RAM with the new sticks. I started up the system, and after a very long link training process2… it booted up! Does the OS recognize ECC? On the Linux side, all indications were that the ECC memory was functioning correctly. sudo dmidecode -t memory reported: % sudo dmidecode -t memory Physical Memory ArrayLocation: System Board Or MotherboardUse: System MemoryError Correction Type: Multi-bit ECC ...... Handle 0x0033, DMI type 17, 92 bytes Memory Device Array Handle: 0x002E Error Information Handle: 0x0032 Total Width: 72 bits Data Width: 64 bits (The “Total Width” field is the important one here. For non-ECC RAM it read 64 bits, but in my case it was 72 bits because 64-bit ECC RAM has an extra 8 bits of parity data.) Also, the Linux kernel reported that its error detection and correction subsystem, EDAC, was enabled: % sudo dmesggrep -i EDAC [ 0.444842] EDAC MC: Ver: 3.0.0 [ 25.042690] EDAC MC0: Giving out device to module amd64_edac controller F19h_M60h: DEV 0000:00:18.3 (INTERRUPT) [ 25.042693] EDAC amd64: F19h_M60h detected (node 0). [ 25.042696] EDAC MC: UMC0 chip selects: [ 25.042697] EDAC amd64: MC: 0: 0MB 1: 0MB [ 25.042699] EDAC amd64: MC: 2: 16384MB 3: 16384MB [ 25.042702] EDAC MC: UMC1 chip selects: [ 25.042703] EDAC amd64: MC: 0: 0MB 1: 0MB [ 25.042704] EDAC amd64: MC: 2: 16384MB 3: 16384MB Looking good so far! Where’s this data coming from? At this point it’s worth asking about the source of these messages. Where is the data coming from and why should we believe it? Let’s look at dmidecode first. man dmidecode starts with: dmidecode is a tool for dumping a computer’s DMI (some say SMBIOS) table contents in a human‐readable format. This table contains a description of the system’s hardware components, as well as other useful pieces of information such as serial numbers and BIOS revision. Thanks to this table, you can retrieve this information without having to probe for the actual hardware. While this is a good point in terms of report speed and safeness, this also makes the presented information possibly unreliable. Oh, interesting, “possibly unreliable” is a little concerning! What is this SMBIOS thing anyway? Wikipedia says: In computing, the System Management BIOS (SMBIOS) specification defines data structures (and access methods) that can be used to read management information produced by the BIOS of a computer. This eliminates the need for the operating system to probe hardware directly to discover what devices are present in the computer. So the data presented by dmidecode is coming from the UEFI, not from the processor3. What this means is that the memory is ECC-capable, but not necessarily that it is active. Whether ECC is active is ultimately determined by the memory controller on the system. Querying the memory controller When I mentioned setting up ECC at work, Robert Mustacchi pointed me to the excellent illumos documentation about AMD’s Unified Memory Controller. I did some reading and learned that essentially, AMD processors expose a bus called the System Management Network (SMN). Among other things, this bus can be used to query and configure the AMD Unified Memory Controller (UMC). NOTE: The information in the rest of this section is not part of the public AMD Processor Programming Reference, but can be gleaned from the source code for the open-source Linux and illumos kernels. WARNING: Accessing the SMN directly, and especially sending write commands to it, is dangerous and can severely damage your computer. Do not write to the SMN unless you know what you’re doing. The idea is that we can ask the UMC the question “is ECC enabled” directly, by sending a read request over the SMN to what is called the UmcCapHi register. The exact addresses involved are a little bit magical, but on illumos with a Ryzen 7000 processor, here’s how you would query the UMC over the SMN bus (channel 0 and channel 1 are the two memory channels on the system, and each channel has one of the 32GB sticks plugged into it.) # Query the UMC at address 0x50df4, representing channel 0 $ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x50df4 0x50df4: 0x40000030 # Query the UMC at address 0x150df4, representing channel 1 $ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x150df4 0x150df4: 0x40000030 Copy (pfexec is the illumos equivalent to sudo.) Also, illumos comes with a really nice way to break up a hex value into bits: $ mdb -e '0x40000030=j' 1000000000000000000000000110000|||+------ bit 4 mask 0x00000010+------- bit 5 mask 0x00000020 +-------------------------------- bit 30 mask 0x40000000 The bit we’re interested in here is bit 30. If it’s set, then ECC is enabled in the memory controller. Accessing the SMN on Linux with the ryzen_smu driver Can we replicate this query on Linux? Turns out we can! There’s a neat little driver called ryzen_smu which provides access to the SMN bus. It’s easy to download and install (though on my system I needed to apply a patch). The driver exposes a file called /sys/kernel/ryzen_smu_drv/smn which can be used to perform a query over the SMN bus. The documentation says that to perform a query, we must write 4 bytes to the file in little-endian format, and then read 4 bytes from the output in little-endian format. This isn’t convenient to do via the command line, so let’s write a small Python script: # smn-query-ecc.py # Licensed under CC0-1.0 def query(hex_str): # Convert hex string to bytes in little-endian decoded = int(hex_str, 16).to_bytes(4, byteorder='little') assert len(decoded) == 4 # Write 4 bytes to the SMN file open(\"/sys/kernel/ryzen_smu_drv/smn\", \"wb\").write(decoded) # Read 4 bytes from the SMN file, representing the return value ret = open(\"/sys/kernel/ryzen_smu_drv/smn\", \"rb\").read(4) # Print ret as a hex string in little-endian order ret_hex_str = hex(int.from_bytes(ret, byteorder='little')) print(f\"returned value for {hex_str} is {ret_hex_str}\") def main(): hex_str = \"0x00050df4\" query(\"0x00050df4\") # channel 0 query(\"0x00150df4\") # channel 1 if __name__ == '__main__': main() Copy Running this script, I got: $ sudo python3 smn-query-ecc.py return value for 0x00050df4 is 0x40000000 return value for 0x00150df4 is 0x40000000 Bit 30 (the first nibble’s 4) is set, which means the memory controller is reporting that ECC is enabled. This query should also be possible on Windows, perhaps using this tool, though I can’t vouch for it. But is ECC really working? The most foolproof way to test whether ECC is working is to introduce an error somehow. ApplesOfEpicness did so by shorting a data and ground pin on their motherboard. Another way would be to try and overclock the RAM until it gets to an unstable point. I don’t quite have the courage to physically short pins, nor the patience to slowly overclock my RAM, waiting multiple minutes for DDR5 link training each time. So instead, I’m content with knowing that the memory controller is reporting that ECC is enabled. Organically, I haven’t seen any errors so far. If a correctable or uncorrectable error does occur at some point, I’ll update this post with that information. About those EDAC messages Earlier in this post I’d mentioned that the Linux kernel reported that EDAC was enabled. I was curious what the data source for that was, so I dug into the Linux kernel source code. Being generally unfamiliar with the Linux codebase, I used the tried and tested strategy of searching for strings that get logged. In this case: Searching for Giving out device to module led me to find this line inside edac_mc_add_mc_with_groups. This function is called here inside init_one_instance. init_one_instance is only called if pvt->ops->ecc_enabled returns true. What is ecc_enabled? It is set to a function called umc_ecc_enabled in this code. And pvt->ops is set to umc_ops when the processor family is >= 0x17. Ryzen 7000 (Zen 4) is family 0x19. Going by just the name, umc_ecc_enabled sounds like it would be querying the UMC. So let’s look at what it does. It looks like it’s checking that umc_cap_hi’s UMC_ECC_ENABLED bit is set. And what is UMC_ECC_ENABLED? It’s bit 30! So it looks like the EDAC messages are only shown if the UMC reports that ECC is enabled. This means that, at least on AMD processors, the Linux kernel message EDAC MC0: Giving out device to module amd64_edac is a reliable indicator that ECC is enabled. Conclusion ECC RAM is great, and you can easily get it working on Ryzen 7000 desktop CPUs, at least with ASRock motherboards. I learned a ton of low-level processor interface details along the way. Acknowledgements Thanks again to Robert for teaching me about a lot of the details here! While ECC RAM is probably overkill for most desktop users and I don’t have it in my gaming PC, I’ve seen enough random bit flips on servers to know that I would like to have ECC RAM in the computer I depend on for my livelihood. ↩︎ The internet is replete with complaints about slow Zen 4 boot times—these is in part due to DDR5 link training, which is a very slow process. With my system, link training almost three minutes for just 64 GB of RAM. Thankfully, at least on Ryzen 7000 desktops, it only needs to be done once after replacing RAM or changing timings. The UEFI caches the results of link training and reuses those values on subsequent boots. ↩︎ There’s some nuance here: some information like the memory speed does come from the memory controller. The ECC information, however, comes from the UEFI. ↩︎ READ OTHER POSTS Dealing with tempfile cleaners → © Rain 2020-present. Licensed under CC BY 4.0 unless marked otherwise. Theme based on terminal by panr.",
    "commentLink": "https://news.ycombinator.com/item?id=37826842",
    "commentBody": "ECC RAM on AMD Ryzen 7000 Desktop CPUsHacker NewspastloginECC RAM on AMD Ryzen 7000 Desktop CPUs (sunshowers.io) 307 points by mmastrac 16 hours ago| hidepastfavorite164 comments c0l0 8 hours agoMaybe slightly OT, since this concerns AMD older AM4 platform with a Zen3 APU core, but working ECC support looks like this and is definitely present on my system: $ sudo ras-mc-ctl --errorstail -n5 14 2023-08-20 20:16:41 +0200 error: Corrected error, no action required., CPU 2, bank Unified Memory Controller (bank=17), mcg mcgstatus=0, mci CECC, memory_channel=0,csrow=0, mcgcap=0x0000011c, status=0x9c2040000000011b, addr=0x36e701dc0, misc=0xd01a000101000000, walltime=0x64e31c78, cpuid=0x00a50f00, bank=0x00000011 15 2023-08-23 17:17:49 +0200 error: Corrected error, no action required., CPU 2, bank Unified Memory Controller (bank=17), mcg mcgstatus=0, mci CECC, memory_channel=0,csrow=0, mcgcap=0x0000011c, status=0x9c2040000000011b, addr=0x36e701dc0, misc=0xd01a000101000000, walltime=0x64ea5188, cpuid=0x00a50f00, bank=0x00000011 16 2023-09-03 16:52:15 +0200 error: Corrected error, no action required., CPU 2, bank Unified Memory Controller (bank=17), mcg mcgstatus=0, mci CECC, memory_channel=0,csrow=0, mcgcap=0x0000011c, status=0x9c2040000000011b, addr=0x36e701dc0, misc=0xd01a000101000000, walltime=0x64f4d227, cpuid=0x00a50f00, bank=0x00000011 17 2023-09-15 21:37:59 +0200 error: Corrected error, no action required., CPU 2, bank Unified Memory Controller (bank=17), mcg mcgstatus=0, mci CECC, memory_channel=0,csrow=0, mcgcap=0x0000011c, status=0x9c2040000000011b, addr=0x36e701dc0, misc=0xd01a000101000000, walltime=0x65071ed7, cpuid=0x00a50f00, bank=0x00000011This is with an ASRock B550M-ITX&#x2F;ac and a AMD Ryzen 5 PRO 5650G. It used to work the same with a Ryzen 5 3600 (using a dedicated GPU for video output) before I upgraded the CPU.To detect and log ECC activity on modern GNU&#x2F;Linux, you will want to have the \"rasdaemon\" service active. I will decode MCE (and other hardware-related) errors and persist them to the database that is shown being queried above. reply jacquesm 7 hours agoparentThe frequency of these errors should be enough to cause you to distrust any kind of information output by a computer without ECC.Edit: thinking about this a bit longer: that frequency is actually so high that you may well have a broken module in there. Note how it is the same module and the same address every time. reply whizzter 6 hours agorootparentSeems like a semi-stuck bit, it&#x27;d definitely cause issues w&#x2F;o ECC but seems to chug along with the circuits doing their job. Best would probably be to add an memory-range exclusion to the kernel at boot to avoid that single area since the sticks seems good otherwise. reply Modified3019 3 hours agorootparentI completely forgot you could do that. reply nvarsj 6 hours agorootparentprevIme ram is either bad or good. I’ve had ecc errors like this and I always ask the DC to replace the ram. After that, 0 errors forever. Same reason why I’m confident a 24 hour memcheck is sufficient for non ECC ram. reply simcop2387 3 hours agorootparentGenerqlly the same here, but I have had sticks fail after some time in use. I had to rma the ram in my frame.work laptop after it failed. No reason or clue why but it happened after 6 minths or so. No issues with the rma though and it went fine with no issues since. ecc if it was supported there might have given me a heads up about it and avoided needing me to restore from backups when the fs corrupted. reply c0l0 5 hours agorootparentprevI am fully aware the module is not 100% working, i.e., it is faulty at a specific physical address. That&#x27;s OK for my personal desktop though, unless the condition worsens, and UCEs (which will panic my kernel) follow. reply justinclift 3 hours agorootparentAny chance it&#x27;s something that&#x27;s being affected by temperature?Along the lines of \"computer gets toasty doing work, ecc errors start happening\"?Stuff like that could just mean the memory sticks need pushing in a bit more. reply code_biologist 7 hours agorootparentprevIt&#x27;d be cute to log what processes are using that memory at time of error. Fun to speculate about whether a kernel bit flip is better or worse than ones in a web browser, photo editor, spreadsheet, network storage client... reply jacquesm 7 hours agorootparentYou could test that empirically by setting up a box with the express intent to crash it and then using a chaos monkey like mechanism where you start injecting single bit faults into memory at random addresses. Wonder how long the box would be up before you start noticing something is broken. It would be funny if you accidentally killed the chaos monkey first! Best not use that box for banking... reply asmor 3 hours agoparentprevAPUs are specifically excluded from supporting ECC, except on the PRO SKU.https:&#x2F;&#x2F;www.asus.com&#x2F;global&#x2F;support&#x2F;FAQ&#x2F;1045186&#x2F; reply just_testing 40 minutes agoparentprevWhich memory sticks do you use? reply mlsu 13 hours agoprevI am in need of a processor upgrade, but am really interested in an ECC RAM setup. I read this thread of 2 people arguing on &#x2F;r&#x2F;AMD about whether or not the AMD processors and&#x2F;or their motherboards actually support ECC or not. And had no clue if they were right. [1] So this is topical for me![1] https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;Amd&#x2F;comments&#x2F;lzxqod&#x2F;list_of_am4_mot...So this definitively settles it, that the AMD+ASRock combo is truly ECC RAM? reply adrian_b 9 hours agoparentWhen buying the motherboard, you must check if it declares ECC support.This is normally specified in the \"Memory\" section of the specifications, in something like \"ECC & Non-ECC, Unbuffered Memory\".Beware of mentions of \"On-die ECC\", which is present in Non-ECC memories and which is irrelevant.You also have to buy ECC DDR5 UDIMMs and you must be careful to not buy by accident ECC DDR5 RDIMMs, which are incompatible with AM5 motherboards. The ECC DDR5 UDIMMs have a width of either 80 bits or 72 bits. The width does not matter, as long as it is not the 64-bit width of Non-ECC DDR5 UDIMMs. (For some vendors it is cheaper to use identical x8 chips in ECC and Non-ECC modules, despite wasting some capacity, which results in an 80-bit width; there is a myth that DDR5 ECC DIMMs must have a width of 80 bits, the myth is wrong, because the standard includes 36-bit channels, which result in a 72-bit width for a dual-channel DIMM; for instance Micron makes 72-bit DDR5 ECC UDIMMs)The last time when I have checked, ASUS had the most AM5 motherboards with ECC support. I like most the PRIME X670E-PRO WIFI because it has the best PCIe expandability beyond the slot occupied by the GPU.However there are many other cheaper MBs, when less connectivity is enough. reply 0xcde4c3db 3 hours agorootparent> This is normally specified in the \"Memory\" section of the specifications, in something like \"ECC & Non-ECC, Unbuffered Memory\".I&#x27;ve seen allegations that for some vendors, text like this on their non-server&#x2F;workstation boards turns out to mean that ECC modules will work in the board, but without the actual ECC function. reply adrian_b 2 hours agorootparentWhile there might have existed such vendors, nobody provides more information than that written above in their MB specifications, so it is difficult to know for sure which is the case, before buying a MB.The only way to gain more confidence is if the downloadable MB manual has an exhaustive description of the BIOS options.If in the BIOS options there is one for enabling ECC and perhaps additional related options, e.g. for configuring scrubbing, only then there is complete certainty about ECC support in the MB.However most recent MB manuals no longer have a complete BIOS description, so they may be not helpful.At least with the ASRock or ASUS AM4 or AM5 MBs that I have used, whenever \"ECC & Non-ECC, Unbuffered Memory\" was specified, the MB really had ECC support. reply formerly_proven 2 hours agorootparentSometimes the OS is unaware of ECC support on the hardware as well, e.g. Linux doesn&#x27;t&#x2F;didn&#x27;t enable the Intel edac driver on i3&#x27;s running on server chipsets using ECC memory, despite the CPU actually utilizing ECC in that scenario (they simply forgot to add them to the whitelist). So edac-util went \"No ECC MCs found!\", even though the platform worked. reply wil421 4 hours agorootparentprevAbout on-die ECC, as you said avoid it like the plague. Real ECC memory has an extra chip on the stick to support ECC. reply boris 10 hours agoparentprevThere are several plausible levels of \"support\" where ECC is concerned:0. Not supported at all (i.e., if you plug ECC RAM, your system won&#x27;t boot).1. ECC RAM can be plugged but the ECC functionality is not used (i.e., there is no relevant traces&#x2F;circuitry&#x2F;etc).2. ECC functionality is present (i.e., the circuitry is there) but it was not validated by the motherboard manufacturer to be functioning correctly (i.e., detecting&#x2F;correcting errors).3. ECC functionality is present and was validated by the motherboard manufacturer. This is the level one would expect from the server-grade boards from a reputable manufacturer like Supermicro.In case of the AMD processors, when you see \"ECC supported\", it&#x27;s anyone&#x27;s guess which level it is. This is in contrast with Intel, where if it says CPU&#x2F;chipset supports ECC, then you know it really does. I bet Intel won&#x27;t allow a motherboards manufacturer to sell a board with chipset like W680 without validated ECC support. reply theevilsharpie 9 hours agorootparentRyzen consumer CPUs use the same memory controller as their EPYC counterparts, and have full ECC support if the rest of the platform (i.e., motherboard, DIMMs) also supports ECC.What separates Ryzen from its professional-grade counterparts is that ECC support is an optional part of the consumer Ryzen platform spec, which means that it&#x27;s up to the motherboard vendor to enable support for it. Some motherboards don&#x27;t have any support at all, some have ECC support as an explicitly-advertised feature, and many have ECC support but it&#x27;s not explicitly advertised (simply listed as a footnote in the manual).That&#x27;s different from the way Intel does it, where Intel has explicit control over what the platform&#x27;s feature are, and uses that control to aggressively segment their markets. Intel&#x27;s approach makes easier to reason about ECC support as a buyer, but you pay for it with the lack of flexibility compared to AMD&#x27;s platform (and you literally pay more for ECC). reply LtdJorge 9 hours agorootparentYes, this is the correct explanation. Intel basically forbids ECC on consumer HW. reply ClumsyPilot 7 hours agorootparentThey use safety and correctness for market segmentation. Kinda evil reply sitkack 5 hours agorootparentNot kinda, def evil. reply MayeulC 8 hours agorootparentprevIIRC AMD doesn&#x27;t validate the ECC functionality on their ryzen chips? So you could theoretically end up with a defective ECC circuitry if unlucky. I think that was the case for the first generations, it may also have changed or I may be misremembering. reply theevilsharpie 8 hours agorootparent> IIRC AMD doesn&#x27;t validate the ECC functionality on their ryzen chips? So you could theoretically end up with a defective ECC circuitry if unlucky.This is not the case.Ryzen, Threadripper, and EPYC use a unified memory controller that has fully validated&#x2F;qualified&#x2F;supported ECC capability. The only difference between the memory controllers in these CPUs is the number of them (Threadripper and EPYC will have multiple memory controller to support the extra memory channels).When AMD claims that ECC on Ryzen isn&#x27;t validated, they&#x27;re talking about the platform as a whole, not the CPU specifically. ECC support on consumer CPUs depends on the motherboard supporting it. Unlike on Threadripper and EPYC (and also unlike Intel&#x27;s approach), ECC is not a guaranteed feature of the Ryzen platform, so people who want that functionality need to explicitly looks for motherboards that have it (in the same way that you&#x27;d need to explicitly verify PCIe bifurcation support).However, if the motherboard supports it, ECC on Ryzen is a fully supported, validated, you-can-RMA-if-it-doesn&#x27;t-work feature. reply adrian_b 8 hours agorootparentprevThat was in the past (true for Zen 1 and Zen 2 Ryzen). It is no longer true (after Intel enabled ECC in some desktop SKUs, starting with Alder Lake, AMD plussed by validating ECC in all desktop and mobile Ryzens).Now all Zen 3 and Zen 4 CPUs, both desktop and laptop, have explicit ECC support, which means that ECC must be validated by AMD in all of them.If any current AMD CPU happened to have defective ECC, that would be a completely defective CPU, which must be replaced by the vendor.Despite the fact that all laptop Ryzen 6000 and Ryzen 7000 CPUs support ECC, I have not seen yet any AMD laptop or SFF computer with ECC support. On the other hand it is much easier to find AM5 MBs with ECC support than Intel W680 MBs. reply mananaysiempre 2 hours agorootparentThe AMD website says the non-PRO 7x40 laptop Ryzens have no ECC support[1], and the Framework folks have said that AMD told them there’s no ECC on non-PRO 7x40 laptop Ryzens[2]. If plugged in, ECC modules will work, but without the error-correction functions.(Edited to reflect the current state of the website, as it used to say ECC support was present[3].)[1] e.g. https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;product&#x2F;13186[2] https:&#x2F;&#x2F;community.frame.work&#x2F;t&#x2F;responded-amd-batch-1-guild&#x2F;2...[3] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230513075641&#x2F;https:&#x2F;&#x2F;www.amd.c... (here “FP7r2” is the version for use with interchangeable DDR5 modules rather than with soldered LPDDR5) reply formerly_proven 6 hours agorootparentprevAMD Ryzen APUs don&#x27;t support ECC unless they&#x27;re the OEM-only PRO variant.(Edit: These are way more attractive for home server use because they consume a lot less power than the Ryzen CPUs when idle) reply adrian_b 5 hours agorootparentAll mobile Ryzen 6000 and Ryzen 7000 APUs (Zen 3 or Zen 4) support ECC, unlike in the earlier generations, where ECC was restricted to PRO variants. Unfortunately, none of the small computers that use them supports ECC on the MB.It is expected that AMD will launch a desktop Zen 4 APU in the near future. If that happens, it remains to be seen whether ECC will remain enabled in it, like in the current laptop packages, but there seems to be no reason to disable it. reply cassianoleal 5 hours agorootparentprevI was looking for this before I posted.If anyone is looking for one of these standalone, outside of a full build, I bought a Ryzen 7 PRO 4750G about a year or 2 ago from AliExpress. It&#x27;s been running a homeserver 24x7 since then and I never had any issues with it. YMMV of course. reply boris 9 hours agorootparentprev> lack of flexibility compared to AMD&#x27;s platformYou mean flexibility to claim ECC support but not doing any validation to make sure it actually works? Does any AMD motherboard manufacturer actualy states that \"ECC is supported and has been validated\"? I think the muddy waters that AMD has created would warrant such an explicit statement. reply theevilsharpie 8 hours agorootparent> You mean flexibility to claim ECC support but not doing any validation to make sure it actually works?The actual ECC functionality is part of the memory controller, which is entirely AMD&#x27;s domain. The ECC functionality of the memory controller is fully validated.Whether or not ECC support is present on the rest of the platform is the responsibility of the system builder. However, if the platform isn&#x27;t fully ECC-capable (e.g., you&#x27;re using non-ECC DIMMs, the motherboard doesn&#x27;t have the necessary electrical traces, ECC support is disabled in the UEFI, etc.), this will result in the memory controller disabling ECC support, which is visible to the operating system and is something that you -- the end user -- can verify.> Does any AMD motherboard manufacturer actualy states that \"ECC is supported and has been validated\"?Yes. ECC support will be listed in the motherboard&#x27;s spec sheet and manual. There also motherboards marketed for professional use where ECC support is explicitly advertised in the vendor&#x27;s marketing.> I think the muddy waters that AMD has created would warrant such an explicit statement.AMD&#x27;s official statement regarding ECC support on Ryzen is that it&#x27;s supported if the motherboard also supports it. I&#x27;m not sure how they can be any clearer without making ECC a mandatory feature of the platform. reply sidewndr46 1 hour agorootparentprevGiven this, why would anyone buy an AMD CPU if they need ECC? reply yetanotherloss 9 hours agoparentprevCan&#x27;t speak to asrock but asus x570 boards definitely really do ECC, I have a known bad ECC DIMM and it&#x27;s possible to use it to create correctable and uncorrectable conditions in short order.Hard to imagine asrock wouldn&#x27;t run the lines given all the other components are there, but I guess it&#x27;s conceivably possible. If the kernel says it has ECC, it&#x27;s right. If not, return the board as defective and use a different vendor. reply justinclift 3 hours agoparentprevIf it helps, the ASRock B550M Pro4 supports ECC. At least when paired with a Ryzen 5600X and 4x 16GB (Kingston KSM26ED8&#x2F;16HD @3200MHz) memory modules.It&#x27;s what I&#x27;ve been using for 15+ months as my main development desktop.This is how they show up in the system (Linux) from dmidecode: Handle 0x000F, DMI type 16, 23 bytes Physical Memory Array Location: System Board Or Motherboard Use: System Memory Error Correction Type: Multi-bit ECC Maximum Capacity: 128 GB Error Information Handle: 0x000E Number Of Devices: 4 Handle 0x001A, DMI type 17, 92 bytes (this section is repeated 4 times though, once per DIMM stick) Memory Device Array Handle: 0x000F Error Information Handle: 0x0019 Total Width: 72 bits Data Width: 64 bits Size: 16384 MB Form Factor: DIMM Set: None Locator: DIMM 1 Bank Locator: P0 CHANNEL A Type: DDR4 Type Detail: Synchronous Unbuffered (Unregistered) Speed: 3200 MT&#x2F;s Manufacturer: Kingston Serial Number: [snipped] Asset Tag: Not Specified Part Number: 9965745-028.A00G Rank: 2 Configured Memory Speed: 3200 MT&#x2F;s Minimum Voltage: 1.2 V Maximum Voltage: 1.2 V Configured Voltage: 1.2 V Memory Technology: DRAM Memory Operating Mode Capability: Volatile memory Firmware Version: Unknown Module Manufacturer ID: Bank 2, Hex 0x98 Module Product ID: Unknown Memory Subsystem Controller Manufacturer ID: Unknown Memory Subsystem Controller Product ID: Unknown Non-Volatile Size: None Volatile Size: 16 GB Cache Size: None Logical Size: None reply islandnut 8 hours agoparentprevUsing ASRock X570 PG 4S + Ryzen 5 2600 + Kingston 32GB 2666 ECC(cpu&#x2F;mem support list for this mobo says the ECC works in this config). Dmidecode still reports 128bit data width instead of 72 however it also reports multi-bit correction instead of single-bit so ... ;). I&#x27;m kind of used to 72bit on Intel boards with UDIMM for example Supermicro+Xeon that I have. I think that a combination of memory controller plus mobo reporting has an effect on that info instead of actual hardware support - but still EDAC works, registers proper driver and I get the warnings once in a while from EDAC&#x2F;RAS that a correctable error has been indeed corrected. Now if I should question whether it actually corrects something then I should also question the Supermicro+Xeon config - I don&#x27;t have any means to check that - however if it&#x27;s not working then I should see that on the ZFS dataset every month or so during scrubbing and I don&#x27;t see anything there. So for me it is settled. reply CTDOCodebases 6 hours agoparentprevA motherboard can accept ECC RAM and function but not correct single bit errors or halt on multibit errors a you would expect.Some motherboards list ECC RAM support as a feature and have ECC RAM on their QVL for memory. Be warned ECC UDIMMS are expensive.For checking if ECC RAM is working in linux use the dmidecode command.For monitoring ECC errors use rasdaemon.Asrock isn&#x27;t the only brand that reliably supports ECC memory. See below.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;homelab&#x2F;comments&#x2F;15zuj70&#x2F;ecc_udimm_... reply bick_nyers 13 hours agoparentprevI use ECC on my X570 and B550 ASRock boards, they have allowed unbuffered ECC for a while.Kind of a shame they don&#x27;t have a mini-itx&#x2F;matx X670E board (only ASUS does). reply SteveNuts 11 hours agorootparentSupermicro has an interesting AM5 motherboard which I&#x27;m planning to start building a workstation aroundhttps:&#x2F;&#x2F;www.supermicro.com&#x2F;en&#x2F;products&#x2F;motherboard&#x2F;h13sae-mf reply vardump 6 hours agorootparentI guess that 8&#x2F;8 split PCIe could also be used for 100 Gbps networking? I suppose 100 Gbit card requires up to 200 Gbit bandwidth. reply loxias 10 hours agorootparentprevBeautiful board! Shame it has to cost $550. I wonder how large of a heatsink I&#x27;d need to make it fanless. :) reply bick_nyers 10 hours agorootparentprevOooh, nice find. Now to find some 5200MHz (or more) Unbuffered ECC dimms... reply kvemkon 8 hours agorootparentJust be sure to think in advance about the maximal total amount of memory you&#x27;d need, since 5200 MHz is officially supported only for 2 modules (3600 MHz for 4). Discussed a week ago (also ECC issues were mentioned): https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37717567. reply bick_nyers 1 hour agorootparentHopefully won&#x27;t be the case for Threadripper which allegedly is due on the 19th reply dvasdekis 10 hours agorootparentprevThis is all I could find: https:&#x2F;&#x2F;www.mouser.com&#x2F;ProductDetail&#x2F;Kingston&#x2F;KSM56E46BD8KM-.... reply sunshowers 9 hours agorootparentprevThe v-color RAM I linked to in the post is available at up to 5600MHz (that&#x27;s what I got): https:&#x2F;&#x2F;v-color.net&#x2F;products&#x2F;ddr5-ecc-udimm-servermemory?var... reply nicman23 9 hours agoparentprevyes asrock is cheap, good vrms and somewhat good bios. but most of all, they exposed all the amd cbs etc options and do not lock them reply ChuckMcM 12 hours agoprevAn excellent read. I have ECC RAM on my Threadripper board. One of the things that ops at Blekko found was that you needed to tell Intel boards (NOTE vendor change!) to actually REPORT correctable errors. The default was machine-check if there was an unrecoverable error, otherwise just go with the flow. With ~ 1600 192GB systems we would see correctable errors about once a week as I recall. I don&#x27;t recall a single unrecoverable error in 6 years so that was pretty good. Greg will surely correct me if I missed one :-). reply toast0 11 hours agoparentYour luck was better than mine, but at least our systems reported correctable errors without us having to ask. We had a roughly similar amount of machines, probably about similar ram on average (many with less, and some with much more) We definitely had unrecoverable errors from time to time; maybe one or two a year, enough to have a policy: give it a shot to see if it was a one off, if it doesn&#x27;t fail again shortly after it&#x27;s probably fine; if it does fail again shortly after, swap the ram. Nicer server boards even have a led to tell you which ram module to replace.For correctable errors, we wouldn&#x27;t swap unless the error counts got pretty big; some systems went for a long time with one or two errors a day, which is fine. Others went zero errors for a long time, then a couple days at a small number, and then big numbers. There was one system that managed to get thousands per hour and the system was unusable because handling machine check exceptions was too expensive; unfortunately the reporting interval was one hour, so we didn&#x27;t realize why the system was unusable until the next report. reply ChuckMcM 11 hours agorootparentWell to be fair if we started regularly getting UCE&#x27;s on a stick of memory we did preemptively replace it. (where regularly was more frequently than one a week) reply toast0 10 hours agorootparentYeah, I&#x27;d guess a good number of the systems where we got one UCE, we got another one within a day after reboot. If so, off to repair. If not, it was pretty rare for that machine to cause trouble again; seemed worth the risk to check if repair was needed.The correctables were trickier to judge, because system halt on UCE is easy to recover from and easy to diagnose (system is down, check console, see UCE message); system slow as heck because of constant machine check exceptions is hard to diagnose and a slow system can disrupt a distributed system a lot more than a dead system. reply ChuckMcM 10 hours agorootparentGreg Lindhal had created a really fascinating system that surfaced anomalies like that to ops so that the systems could be fixed. He had a cute name for them like &#x27;fractures&#x27; or something (where it was a non-fatal failure but it was impacting overall performance). Things the system would catch were switch ports going bad, DIMMs going bad, and file system corruption outside of the set of released tools. Disks failure was fairly common and got caught, drive reformatted, and resumed quickly.By tracking the rate of disk FS errors for a particular drive we could pick up the \"you need to replace this drive\" signal as well. reply toast0 10 hours agorootparentWe mostly relied on a couple of easy metrics to signal trouble and then debug from there. Total size of all the Erlang message queues above a threshold was usually an indication of trouble; replication delays of more than a couple seconds too. CPU %, swap % were also signs of trouble.Tracking down almost working networking without access to the switch metrics was kind of fun, ish. :P replyRoark66 9 hours agoprevI&#x27;m currently on Ryzen 3700X and asus tuf gaming x570 MB. I&#x27;d love more single core performance and more nvme&#x2F;disk speed. Also I have a dual GPU setup, 2 M2 nvme, and 6 sata occupied.I&#x27;m considering upgrading end of the year. I briefly considered thread ripper (for it&#x27;s pcie lanes) until I found there is still no zen4 thread ripper and the price is likely yo be eye-watering.So the choice is, upgrade to Ryzen 5900x and keep the rest of the system, or spend a lot more and upgrade to a AM5 ryzen plus a new mobo(I considered Intel too, until I found it tops at 20 pcie lanes).I&#x27;ve always been buying mostly gigabyte and asus mobos, but I got burned more than once by them so I might go with another manufacturer this time.What do you think? Is it worth upgrading to AM5 for just single core and disk performance? What about Intel? Considering I&#x27;d love more pcie lanes for a 10gb adapter perhaps(so I can move some of these spinning disks out) Intel is probably not a good choice.I&#x27;m happy enough with the multi-core performance of ryzen 3700x. If I got a new MB I&#x27;d definitely want at least two nvmes in a mirror(for speed) - perhaps more and sata ports for my 6 spinning disks. reply t0mas88 9 hours agoparentFor your mirrored drives idea: I&#x27;ve had two nvme drives in mirror for a while but there are a lot of caveats to getting maximum performance. Not sure how it is on the AMD side but most Intel boards for example would have one m2 slot connected to the CPU and the other three via the chipset. Which makes them share a common bottleneck (also with your 10gb ethernet card)For me it was in the end much faster to get a new board with pcie 5.0 support and a large enough single SSD. Total IOPS and throughput both turned out higher than my previous RAID 0 array. reply justinclift 7 hours agorootparentWith my personal desktop (2x 1TB NVMe drives), they&#x27;re mirrored with ZFS for data integrity. Depending on what Roark66 has them mirrored for (speed vs data integrity, etc), the alternative single-drive approach might not be workable. reply t0mas88 4 hours agorootparentWell he wrote that it&#x27;s for speed, so that would be raid0> If I got a new MB I&#x27;d definitely want at least two nvmes in a mirror(for speed) reply justinclift 4 hours agorootparentraid0 isn&#x27;t really a mirror though.raid1 is a mirror, and can have speed benefits over just a single drive (able to read from multiple drives in parallel).But yeah, you might be right. When talking casually, things like \"mirror\", \"raid\" etc can be a bit fuzzily applied. :) reply wesapien 1 hour agorootparentYou&#x27;re right. The primary use of mirroring on raid 1 is for redundancy. Raid 0 is striping and more associated with performance. reply andrewstuart2 9 hours agorootparentprevI&#x27;ve got a 5950x and two NVME drives. The setup is the same as you describe. One has dedicated bandwidth and the other shares via the chipset. I just use them separately rather than trying to RAID them since the speed is fast enough for just about everything I need. reply t0mas88 4 hours agorootparentIndeed, that&#x27;s what I ended up doing with the other drivers. Use them separately for different data types. reply orthoxerox 7 hours agoparentprevWhat kinds of workloads do you run that you are capped by nvme speed? reply Roark66 3 hours agorootparentLoading ML models into GPU memory. reply nicman23 9 hours agoparentprevif you need more go 5950x for double the cores with only 4&#x2F;3 of the price or 3d cache cpus for that factorio UPS. 5900x is not that of an upgrade reply Crabstove 9 hours agoparentprevI have 5900X and I wish I’ve waited for 5800X3D instead. reply Havoc 8 hours agorootparentWhat’s the rationale for that? Gaming? reply beebeepka 1 hour agorootparentVery likely. I jumped from 3700x and the difference is staggering. My 6800xt came alive and stutters are a thing of the past.I kind of want an OLED but they don&#x27;t come cheap, vertical resolution is the same, and they are not amazing for coding. Maybe in time for a Zen 5 based 3d cache chip. reply justinclift 8 hours agoprevAs a data point, Hetzner has offered Ryzen 7000 CPU&#x27;s with ECC ram for months:https:&#x2F;&#x2F;www.hetzner.com&#x2F;dedicated-rootserver&#x2F;matrix-axThe AX52 has optional ECC ram as an upgrade, while the AX102 comes with ECC by default.It&#x27;d be surprising if they&#x27;d been offering ECC that didn&#x27;t really work. reply maccard 5 hours agoprevI have a genuine question - in practice on a workstation&#x2F;developer computer, what sort of protection does ECC ram give me?I&#x27;ve got two daily driver machines - a 3970x threadripper with 96GB ram, and an M1 Macbook Pro - neither of which have ECC ram.I&#x27;ve been using them both for over 2 years, and not once in that period (that I&#x27;m aware of) have I found myself with a problem due to faulty RAM, but I do regularly find myself wishing both were faster.What practical benefit would I get in exchange for the performance hit of ECC memory? reply theevilsharpie 4 hours agoparent> what sort of protection does ECC ram give me?The ability to detect (and possibly correct) physical memory errors.> I&#x27;ve been using them both for over 2 years, and not once in that period (that I&#x27;m aware of) have I found myself with a problem due to faulty RAMThe \"that I&#x27;m aware of\" part is the key issue. ECC provides visibility into the health of the physical memory that you otherwise wouldn&#x27;t have.> What practical benefit would I get in exchange for the performance hit of ECC memory?Side-band ECC (which is what you&#x27;d use on desktops&#x2F;workstations&#x2F;servers) doesn&#x27;t have a performance hit, as the overhead of ECC is fully neutralized by the additional bandwidth and capacity of an ECC DIMM. reply maccard 3 hours agorootparent> The ability to detect (and possibly correct) physical memory errors.This is a great example of theoretical benefits (note I&#x27;m not saying that those theoretical benefits are real, I&#x27;m asking how they practically benefit me).> The \"that I&#x27;m aware of\" part is the key issue.Ok so tell me what it looks like. _That&#x27;s_ what I want to know.> into the health of the physical memory that you otherwise wouldn&#x27;t have.And does what, on my windows workstation or my linux workstation?> Side-band ECC (which is what you&#x27;d use on desktops&#x2F;workstations&#x2F;servers) doesn&#x27;t have a performance hit, as the overhead of ECC is fully neutralized by the additional bandwidth and capacity of an ECC DIMM.That statement doesn&#x27;t hold water. If it takes extra bandwidth and capacity to provide ECC, I can use the extra bandwidth as memory instead of error correction, no? (Or I could if the non-ecc DIMM utilised that range). Either way, it&#x27;s an extra x bits for ECC that _could_ be used for storage. reply frankreyes 4 hours agoparentprevIt depends on your workload.Some industries require to be able to reproduce exact bit by bit data.Anything that requires absolute bit certainty, for example digital signatures, encryption, or financial information, will require ECC.If you don&#x27;t care if your files eventually don&#x27;t match a sha256 checksum, you&#x27;ll be fine. for example source code, it doesn&#x27;t matter because in the worst case, your code won&#x27;t compile because variable names got flipped.And even then, if you&#x27;re using Git for source code control, you&#x27;re already using hash signatures to detect data corruption, as well as a very large redundancy and replication. Git is, in a philosophical way, ECC by software. reply maccard 3 hours agorootparent> It depends on your workload. > Some industries require to be able to reproduce exact bit by bit data. > Anything that requires absolute bit certainty, for example digital signatures, encryption, or financial information, will require ECC.Totally, and I get that. We&#x27;ve got people in this thread who are saying that non-ECC ram shouldn&#x27;t be trusted [0], or that it should be standard [1]. I get the use cases, but why do I want that on my workstation.> your code won&#x27;t compile because variable names got flipped.I have _never_ seen or even heard of this or anything vaguely resembling this happening. Are there any writeups of this anywhere at all?[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37829796[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37828865 reply tpurves 2 hours agoparentprevBit flips in memory can affect instruction code, not just data. This will manifest as random bluescreen crashes or visual artifacts in the case of video memory. Similar to errors&#x2F;crashes from overclocking a little too high, but occurring occasionally on a normally stable system. reply orangepurple 3 hours agoparentprevWhen your RAM starts to go bad it can severely screw up writes to your filesystem without you noticing for a long time. reply neolefty 2 hours agoparentprevAnecdotally, on a desktop machine with something like 64GB RAM, when I switched from non-ECC to ECC (and 128GB RAM), the number of unexplained crashes seemed to drop from one every couple of weeks to one every 6 months or so. Could have been from a software upgrade though, probably Ubuntu 18 to Ubuntu 20.Now I&#x27;m on an M1 MBP with 32GB RAM, and I get unexplained crashes roughly every 3-4 months, but I&#x27;ve been chalking it up to MacOS. Behavior also seems to degrade after a month or two of uptime. Hmm, maybe it&#x27;s time for Apple to go ECC ... reply maccard 1 hour agorootparent> Anecdotally, on a desktop machine with something like 64GB RAM, when I switched from non-ECC to ECC (and 128GB RAM), the number of unexplained crashes seemed to drop from one every couple of weeks to one every 6 months or so. Could have been from a software upgrade though, probably Ubuntu 18 to Ubuntu 20.Thanks. This is a great anecdote&#x2F;example that is much more what I&#x27;m interested in. I don&#x27;t see the same level of system instability on my machine, but it&#x27;s a good example. Appreciate it.> Behavior also seems to degrade after a month or two of uptime.Ah, here&#x27;s another thing. I do tend to reboot daily&#x2F;weekly which may help reply foresto 11 hours agoprevSome (maybe all?) ASUS AM5 motherboards have official ECC support. It appears in both the board manual and the BIOS manual for the model I just checked. Note that one of the relevant BIOS settings is Auto by default, which (counterintuitively) leaves it disabled, so you&#x27;ll want to change that.ECC reporting for these processors appeared in Linux 6.5, so Debian Stable users will have to either wait for it to appear in Backports or stray from the beaten path.https:&#x2F;&#x2F;www.phoronix.com&#x2F;news&#x2F;AMD-EDAC-Ryzen-7000-Series reply bpye 10 hours agoparent> Note that one of the relevant BIOS settings is Auto by default, which (counterintuitively) leaves it disabled, so you&#x27;ll want to change that.I really dislike Auto settings in the BIOS. It wouldn&#x27;t be so bad if there was a way to see the effective value, but 9 times out of 10 - it&#x27;s no obvious. reply foresto 10 hours agorootparentI don&#x27;t mind auto settings themselves, but I agree about the opaque ones. In this case, the effective value is stated in the field&#x27;s help message, but it&#x27;s still easy to miss. reply snvzz 13 hours agoprevIf only if legislators could get their shit together and mandate ECC.It is unnerving most computing is done in fragile non-ecc systems.A very messed up form of artificial market segmentation. reply bubblethink 9 hours agoparent>legislatorsHaven&#x27;t you seen those congressional hearings with Zuck and others where congresspeople ask about how to use their phone ? How do you expect them to legislate about ECC ? reply declan_roberts 10 hours agoparentprevFragile non-ecc systems?Something that works absolutely fine 99.9999% of the time is not fragile. reply cwaffles 10 hours agorootparentProbability of a bit error increases as memory increases. Opens a large can of worms if control flow breaks. reply josephg 10 hours agorootparentYep. 99.9999% correct would mean 8 bit flips per megabyte of data stored in ram. The error rates are (thankfully) much lower than that (otherwise your computer wouldn’t boot). But random bit flips can cause utter havoc if they happen at the wrong time or place. If you download software from the internet, bit flips can introduce weird bugs to your software, only on your computer. (Including in the OS - including your filesystem or drivers). They can corrupt writes to your hard drive, and as a result corrupt your drive or files. Bit flips can quietly change the DNS request your browser sends to cause terrifying security problems. Or edit forms before you send them. There was even a case of a voting machine in Germany accidentally inventing 4096 votes due to a bit flip.ECC is a really good idea. It’s only expensive right now because it’s a “premium feature”. If it were a standard part of all ram sticks, it’d be cheap and we’d all benefit. reply littlecranky67 8 hours agorootparentNot argueing against ECC, but some of your scenarios seem to be outdated due to crypto. I.e software you download from the internet is often signed and hashes are validated (Linux package managers, macOS developer certs). Same for DNS requests (dnssec) etc. Yes, there is still wiggle room for bitflips to cause problems, but less so than in the past. reply mcesch 7 hours agorootparentDNSSEC is around the 4~5% mark in .com and .net. reply littlecranky67 6 hours agorootparentTrue - my bad of referring to DNSsec; there are other ways you can use encryption for DNS resolving (by using an external DNS server that encrypts using TLS or simply by using DNS-over-HTTPs). This way you get 100% encryption of your DNS traffic (and thus tamper checks that would detect bitflips). Again, not arguing against ECC, there are valid points to want it - I just see less and less reasons in the consumer market. reply josephg 3 hours agorootparentEncryption and signing don&#x27;t protect against memory corruption.For example, I download software from the internet then hash it. The hash matches. Before the bytes are written to disk locally, a bit flips in RAM. The corrupted data is written to disk and used.Likewise, dnssec doesn&#x27;t protect you against DNS bitsquatting attacks[1] because the domain name can be changed before the DNS request is made. So the DNS response your computer makes for a-azon.com might be totally valid and signed. It can come through DoH or whatever. The problem is that your browser thought it was the response for amazon.com and chrome send a bitsquatter your amazon cookies. (Oops).[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9WcHsT97suU reply littlecranky67 1 hour agorootparentWell aware of all of that, but it decreases the chances if corruption (ie no corruption during download). reply iopq 5 hours agorootparentprevnews.ycombinator.com not included in this 4% either replyClumsyPilot 7 hours agorootparentprevThat&#x27;s just made up statistics - average computer gets multiple errors a day.This was fine when consumer computers were for games and porn. Now they store birth certificates, submit information to the tax man, documents to court, sometimes deal with matters of life and death reply Scramblejams 14 hours agoprevI don’t quite have the courage to physically short pins, nor the patience to slowly overclock my RAM, waiting multiple minutes for DDR5 link training each time. So instead, I’m content with knowing that the memory controller is reporting that ECC is enabled.How about hitting the RAM with a warm stream of air from a hair dryer? I&#x27;ve seen that technique used in the past to generate errors. reply Tuna-Fish 14 hours agoparentMore sensibly, you can do some memory overclocking live on a running system, with no link training. It&#x27;s not advisable for actual use, but you can use it to find the limits of your memory, or to generate errors. reply HankB99 11 hours agoparentprevWould rowhammer testing reveal whether or not a system has ECC RAM? It reveals errors on my I7-4770K (not overclocked) system whereas an ancient Supermicro board (X10 era) seems to run the rowhammer test indefinitely w&#x2F;out detecting errors. I suppose this won&#x27;t work if newer systems have been designed not to be susceptible to rowhammer attacks.Incidentally the RAM on a Raspberry Pi 4B (and CM4) is feported to use ECC RAM, but this is not the same as discussed here. It&#x27;s on die ECC and the purpose is to improve yield of the chips. ECC errors are corrected and not reported via H&#x2F;W. ECC errors that cannot be corrected (I suppose) are just read out as incorrect data. I wonder if modern RAM sticks use chips with on-die ECC. reply ThePowerOfFuet 11 hours agorootparent> I wonder if modern RAM sticks use chips with on-die ECC.DDR5 does, AFAIK, but it is not a replacement for running it 72 bits wide like previous off-die ECC systems. reply KirillPanov 13 hours agoparentprevYou should be able to use a propane barbecue lighter at short distance; those things generate stupid amounts of EMI.https:&#x2F;&#x2F;hackaday.com&#x2F;2022&#x2F;01&#x2F;29&#x2F;blast-chips-with-this-bbq-li...https:&#x2F;&#x2F;hackaday.com&#x2F;tag&#x2F;emfi&#x2F; reply edrxty 11 hours agorootparentI&#x27;d be careful with EMI&#x2F;EMP based testing, if it&#x27;s latching up one line or flipping one bit, it&#x27;s probably also doing it to a ton of lines&#x2F;bits. I&#x27;m guessing here but based off my experience with such things, I&#x27;d expect it to be more likely to latch up whole busses and generally just crash the system than trigger anything ECC could report unless you had a very repeatable setup you could ramp up in a very controlled fashion.The mode of action here is you&#x27;re producing a very wide band pulse but it&#x27;s most strongly couple to the PCB traces long before anything within the chip itself. Guessing again but when people are using this to hack chips, they&#x27;re probably just causing voltage swings on the power traces that are effectively voltage glitching the chip. The problem is you&#x27;re over volting the part rather than under volting it which may cause permanent damage. reply bilbyx 8 hours agoparentprevHow about just bringing your cell phone close to the DIMMs to trigger errors? That would be easy to do. reply willis936 14 hours agoparentprevI feel like potentially reflowing BGAs on a high speed I&#x2F;O PCBA you want to run continuously for a decade is riskier than simply shorting a pair of diode-protected pins.Link training can be disabled in the BIOS, which would make searching for borderline bandwidth settings a quick operation. The results would not be very repeatable, but that&#x27;s not important. reply mlyle 14 hours agorootparent> I feel like potentially reflowing BGAs on a high speed I&#x2F;O PCBA yIf you&#x27;re trying to get chips up to something less than 100C, but instead get stuff underneath it with significant thermal mass up to above 200C, you&#x27;re really messing up.Hair dryers tend to emit like 65C-70C air on their \"high heat\" setting (as opposed to hot air guns used for heat-shrink and reflow soldering). reply 15155 1 hour agorootparentprevSAC305 solder won&#x27;t reflow until >230C vapor phase. Will a hair dryer get a chip to these temps, ever? reply latchkey 13 hours agoparentprevBoot the OS off ram and then do something that uses a lot of ram. If the machine crashes randomly or you have a corrupted \"disk\", chances are it is an ECC error. reply fomine3 13 hours agoparentprevOr buy a radioactive material on eBay? reply voxadam 9 hours agorootparentThoriated tungsten welding electrodes might be an option. reply benhoff 1 hour agoprevThis is a bit off topic, but I&#x27;m running Home Assistant on a system that doesn&#x27;t have any ECC.I&#x27;ll reboot it occasionally. Every once in awhile it will exhibit odd behavior that seems to resolve on reboot.Is it worth getting something that has ECC? I think I&#x27;m running like a Sandy Bridge i7 for reference. reply semi 55 minutes agoparentit&#x27;s not really possible to say if ecc would prevent the issue you&#x27;re describing.. but that&#x27;s why imo it is worth having ecc--so you don&#x27;t have to worry as much about if the weird behavior you see is due to random memory errors.On the more immediately practical side.. if this is happening frequently enough then running memtest86 or GSAT google stressful application test and see if it can pick up any errors.You also might be able to improve things with a bios upgrade, or by lowering the clock speed of the ram. reply tiffanyh 14 hours agoprev> ”Unfortunately, when the AMD Ryzen 7000 ‘Raphael’ CPUs were launched along with the brand new Socket AM5, all mention of ECC support was gone.”Had no idea that 7000s series doesn’t official state support of ECC. reply theevilsharpie 9 hours agoparent> Had no idea that 7000s series doesn’t official state support of ECC.You&#x27;ve misinterpreted the author.All currently-available Ryzen 7000 series CPUs have official ECC support, but it requires motherboard support as well.[1]This conditional ECC support has been the case for all past AMD consumer CPUs going back to the original Athlon 64, but the Ryzen 7000 series is the first time I can recall that this support has been explicitly listed on AMD&#x27;s marketing materials.What the author is saying is that mention of ECC support had disappeared from ASRock&#x27;s motherboard documentation. This was a notable change for ASRock, as they had explicitly mentioned ECC support on their previous Ryzen motherboards.[1] Example from the Ryzen 5 7600 spec page: https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;product&#x2F;12756#:~:text=ECC%20Support,R...) reply sunshowers 14 hours agoparentprevAfter publishing this post, I was alerted to the fact that there are some AM5 motherboards that do officially support ECC.ASRock&#x27;s Rack line supports it, for example: https:&#x2F;&#x2F;www.asrockrack.com&#x2F;general&#x2F;productdetail.asp?Model=1...This ASUS motherboard also claims to support ECC: https:&#x2F;&#x2F;www.asus.com&#x2F;us&#x2F;motherboards-components&#x2F;motherboards...Neither of those were out at the time I originally got my AM5 motherboard (which was right as they came out -- the performance numbers were so good I couldn&#x27;t help but spring on one early.) reply sysGlenn 13 hours agorootparentThe Asrock Racks, 1U4LW-B650&#x2F;2L2T, 10g ports appear to be supported by VMWare ESXI 8: https:&#x2F;&#x2F;www.vmware.com&#x2F;resources&#x2F;compatibility&#x2F;detail.php?de...I would be interested in hearing someones experience with getting this board running as a type 1 ESXI hypervisor. reply scheme271 10 hours agoparentprevIt was really iffy and not clearly mentioned until this year. Also, it&#x27;s confused with on-chip ECC which all DDR5 uses. DDR5 needs on chip ECC to correct errors that&#x27;ll occur in normal operation but that won&#x27;t provide ECC for transfers across the memory bus to the CPU. reply TacticalCoder 6 hours agoprev> The most foolproof way to test whether ECC is working is to introduce an error somehow. > > ApplesOfEpicness did so by shorting a data and ground pin on their motherboard.Epic! Some people, really...> I don’t quite have the courage to physically short pins, nor the patience to slowly overclock my RAM, waiting multiple minutes for DDR5 link training each timeIt&#x27;s not clear to me: when is the DDR5 re-trained? I assembled my Ryzen 7000 desktop PC myself and I don&#x27;t remember ever having to wait minutes for it to boot, not even the first time. It&#x27;s a bit slower at boot I&#x27;d say than non-DDR5 PCs I had in the past but it&#x27;s mere seconds, not minutes.And last but not least: DDR5 specs for ECC vs non-ECC, which price difference and speed difference are to be expected? reply wongarsu 4 hours agoparent> which price difference and speed difference are to be expectedECC RAM uses 1&#x2F;8th more memory chips, so as a rule of thumb it costs 1&#x2F;8th more.They can have very different dynamics on the used market though, because servers tend to be upgraded to larger modules over time, but there aren&#x27;t many buyers for smaller modules. Not a big factor for DDR5 because it&#x27;s too new, but for DDR4 you can get some great deals for 8GB and 16GB modules. reply demurgos 8 hours agoprevI&#x27;ve been actually researching this a lot recently as I&#x27;m in the process of buying parts for a desktop build and want ECC support.> Unfortunately, when the AMD Ryzen 7000 “Raphael” CPUs were launched along with the brand new Socket AM5, all mention of ECC support was gone.1. This was effectively a big point of concern for me. Previous ASRock Taichi motherboards officially advertised full ECC support, but not the latest X670E for AM5 model. Older version of the X670E Taichi page mentioned ECC support (\"Supports DDR5 ECC&#x2F;non-ECC, un-buffered memory up to 6600+(OC)\") [0], and this Level1Tech review [1] had a segment on ECC support (they fully tested it). The segment was around the 10min mark, but it looks like the video was swapped to remove it during the last 30 days (the original video was 17min41sec long, the current one is only 16min32sec). So I assumed that ECC was supported, but it&#x27;s a bit concerning that there&#x27;s no official mention. The article reassures me.2. Finding ECC memory for desktop computers is hard. For the X670E Taichi, you need DDR5 unregistered DIMM. The best solution I have to find ECC memory is to check QVL lists for similar server motherboards, for example this ASRock Rack [2] or this Gigabyte Motherboard [3]. I decided to go with two 32GiB Kingston sticks [4] for my own build.[0]: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20221002103925&#x2F;https:&#x2F;&#x2F;www.asroc...[1]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PhrqEV-VAjE[2]: https:&#x2F;&#x2F;www.asrockrack.com&#x2F;general&#x2F;productdetail.asp?Model=1...[3]: https:&#x2F;&#x2F;download.gigabyte.com&#x2F;FileList&#x2F;QVL&#x2F;server_mb_qvl_MC1...[4]: https:&#x2F;&#x2F;www.kingston.com&#x2F;en&#x2F;memory&#x2F;server-premier&#x2F;ddr5-4800m... reply harshreality 10 hours agoprevThere&#x27;s a rumor that older AGESA[1] versions had a bug that prevented the chipset from recognizing and utilizing ECC ram properly even though the chipsets should support it. Check any motherboard in question for a firmware update which includes at least AGESA 1.0.0.5 patch C.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;truenas&#x2F;comments&#x2F;10lqofy&#x2F;[1] Part of the firmware on AMD systems, that brings up core system components. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AGESA reply sunshowers 9 hours agoparentBased on the ASRock forum thread, this sounds right. Before installing the ECC RAM I updated to AGESA 1.0.0.7b. reply jadbox 14 hours agoprevI am just immensely impressed by this story. A+ hardware and software investigation work. reply tonoto 1 hour agoparentYes, a great article! It was no bigger surprise to see that the article was written by an Oxide employee - it has been a joyful signature that they&#x27;ve managed to attract curious people with an engineering approach to investigate problems and look up how the things work. I&#x27;m probably biased, but it seem like a dream company to me. reply sunshowers 14 hours agoparentprevThank you for the kind words! reply PeterStuer 10 hours agorootparentThough I have no intention of switching to ECC on my Ryzen system, I found this writeup both very clear and a great compelling educational read. Thank you for creating it. reply breakwaterlabs 1 hour agoprevThis is both a little off-topic and a little out of my expertise, but shouldn&#x27;t the file descriptors in the query function be closed? reply YetAnotherNick 12 hours agoprev> ApplesOfEpicness did so by shorting a data and ground pin on their motherboard.This doesn&#x27;t seem to be the proof that ECC is working. Error detection on things like this is different than bit flip correction. reply marginalia_nu 4 hours agoprevI feel the need for ECC is a bit overstated, probably confused by listening too much to people in the server space. In servers, ECC is critical because servers simply have more RAM than PCs do. You can easily find systems with 32 sticks of RAM. If you roll 32 dice, odds of a rare freak error is a lot bigger than if you roll 2. It&#x27;s the same reason why you probably don&#x27;t need RAID on a computer with one or two disks. Stick 48 disks in a machine however, and you&#x27;re a fool to go without it (or a plan at least). It&#x27;s why you don&#x27;t need an automatic fire suppression system in or homelab, because the odds of a fire in one or a few PSUs is fairly small, but stick a few thousands in a room and suddenly it&#x27;s a very real problem.That, and most memory problems in PCs tend to be from dodgy overclocking or just bad sticks rather than cosmic rays. ECC won&#x27;t really save you from that. reply Vogtinator 4 hours agoparentCounterpoint: Without ECC, you simply don&#x27;t notice how many flips happened and that they were the cause of some strange behaviour. reply marginalia_nu 3 hours agorootparentMost of them simply don&#x27;t matter though, and are inconsequential along other system instabilities.It&#x27;s just neurotic to worry about issues when you couldn&#x27;t tell they existed without being informed of them. reply ilyt 1 hour agorootparentMost issues with car don&#x27;t matter for driving, till it catches on fire or crashes due to catastrophic failure. Why ever go to mechanic ? reply marginalia_nu 1 hour agorootparentMost car crashes just aren&#x27;t due to mechanical failure. reply ilyt 1 hour agoparentprev> It&#x27;s the same reason why you probably don&#x27;t need RAID on a computer with one or two disksNo, it is not \"the same reason\"Disks have ECC, even consumer hard drives have checksummed blocks, that&#x27;s how you get media errors detected. RAM does not. Well, technically with DDR5 it has internal one but it does not give any feedback to the machine so you might not know your RAM has any problems.> It&#x27;s why you don&#x27;t need an automatic fire suppression system in or homelabBut you want smoke sensors. ECC is the smoke sensor too> That, and most memory problems in PCs tend to be from dodgy overclocking or just bad sticks rather than cosmic rays. ECC won&#x27;t really save you from that.But it will tell you the problemVery ignorant take reply marginalia_nu 1 hour agorootparent> Disks have ECC, even consumer hard drives have checksummed blocks, that&#x27;s how you get media errors detected. RAM does not. Well, technically with DDR5 it has internal one but it does not give any feedback to the machine so you might not know your RAM has any problems.Sure, and disks have random errors even with error correction. Adding hamming codes just makes errors less likely and easier to detect, but they aren&#x27;t fool proof, in ram or on disk or anywhere else. The protection offered is a bit questionable because they rely on the very sketchy assumption that errors are statistically independent events, which is rarely how storage errors work.> But it will tell you the problem > Very ignorant takeHardware isn&#x27;t perfect. No matter how much error correction you pile onto it, you will still have errors and some cases will still be undetectable. It&#x27;s a matter of pushing the rate of errors into an acceptable range, as a pure cost-benefit tradeoff, statistics through and through. reply Modified3019 3 hours agoparentprev>dodgy overclockingError detection and correction is actually ideal when overclocking. It&#x27;ll not only save you, it&#x27;ll let you know you need to back off a bit, because the handful of errors that may happen once a month despite passing days of tests will show up in the system logs instead of staying silent and causing problems. I speak from experience as I overclocked ECC memory in a first gen threadripper system, playing around with overclocking as a hobby for a bit. ECC memory was fantastic to work with.However the dodgy or outright lack of CPU&#x2F;Motherboard support results in trying to market that feature to gamers&#x2F;overclockers having too much friction. Much like what went on with intel&#x27;s confusing proprietary optane&#x2F;flash combo M.2 drives that needed certain motherboards in order to fully access both parts of the drive.And with bad sticks, instead of hard to explain crashes, you&#x27;ll end up with system logs filled with corrected&#x2F;detected errors and maby crashes if it&#x27;s really bad. Then you just RMA the sticks like normal. So honestly that&#x27;s a win too, because that&#x27;s the whole point of detecting and correcting errors. It&#x27;s in every other part of the system already, continuing to leave this capability out of memory is an oversight that needs to be.. corrected.I just don&#x27;t really get the strange resistance people have to ECC, it&#x27;s not some sacred cow. It&#x27;s just good sense. reply brucethemoose2 11 hours agoprevOh, I just happened to grab a B650E-ITX!...But are there any ECC sticks with \"known\" good Hynix ICs? I got lucky with a pair of sticks that can do DDR5 6000 CL30 at 1.3V (and maybe better), and I wouldn&#x27;t want to sacrifice a ton of RAM performance for ECC. reply sunshowers 9 hours agoparentThe v-color RAM I linked to in the post is Hynix: https:&#x2F;&#x2F;v-color.net&#x2F;products&#x2F;ddr5-ecc-udimm-servermemory?var...I haven&#x27;t tried overclocking it. reply brucethemoose2 8 hours agorootparentThat is A-Die! It should overclock like crazy.You should do it and post it. Ryzen 7000 likes OC&#x27;d RAM, and overclocked ECC ram is kind of a desktop hardware myth&#x2F;legend because its so rare and oxymoronic. Not sure if you&#x27;ve done it before, but DDR5 overclocking is quite a rabbit hole, and there are some \"easy\" tutorials out there like this: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dlYxmRcdLVwTest the stock primary timings with the modded subtimings at 6000 first, then jump straight to cl34 for the primary timings and reduce the voltage&#x2F;primary timings from there.I would grab these myself, but the kit is too rich for my blood at the moment. reply Arnavion 11 hours agoprevI used ECC with a ThreadRipper 2920x on an Asrock motherboard, but for a new Ryzen 7950x build I went back to regular RAM. The problem with ECC with the TR was that only Unbuffered DIMMs work, not Registered DIMMS, and the 7950x is the same. Unbuffered ECC is slower or costlier (or both) than the equivalent non-ECC or Registered, enough that it just wasn&#x27;t worth it in a new build.Ryzen has the additional disadvantage vs TR of only being able to run RAM fast if you limit yourself to two sticks. My TR build used 4x16GiB but for my 7950x build I had to get 2x32GiB to be able to run them at 6000MHz. reply nirvdrum 10 hours agoparentI currently run a 3700X with 64 GB ECC. I&#x27;ve been interested in a jump to an AM5 series, but have found the matter of ECC compatibility frustrating to research, particularly because DDR5 has limited ECC built in and that confuses the discussion.I&#x27;m curious what your use case is. I mostly use mine for software development (including VMs) and some family media processing. I like the peace of mind that ECC brings, but I have no way to really know if RAM speed is performance factor. reply Arnavion 10 hours agorootparentPersonal Linux machine mostly used for watching video, code compiling, and some light gaming. The 7950x definitely compiles my stuff much faster than the TR 2920x did, but I don&#x27;t know how much of that is because of the RAM speed (6000MHz vs 4800MHz, faster timings) and how much because the CPU clocks higher (~5.4GHz vs ~4.2GHz). reply Arnavion 17 minutes agorootparent(Made a typo. The RAM speed in my 2920x build was 2666MHz, not 4800MHz, of course.) reply vetinari 5 hours agoparentprev> Ryzen has the additional disadvantage vs TR of only being able to run RAM fast if you limit yourself to two sticks.TR has it similar, just doubled; you are able to run 4 sticks faster than 8. On my TR2920X+X399 (probably the same config as yours, Asrock Taichi) I&#x27;m able to run any four of them at 3066 MHz and all of them only at 2933 MHz. reply asmor 9 hours agoprevThe ASRock Rack B650D4U advertises ECC support on AM5.It&#x27;s a bit pricy, but you also get IPMI. reply tripdout 11 hours agoprevLooking to get an ASRock B650 Pro RS to go with a 7700X, hopefully ECC will be supported. reply aportnoy 12 hours agoprev> But the lack of ECC was a huge bummer at the time of purchasing my system.Why?.. reply dharmab 11 hours agoparentEver had to troubleshoot bit flips on a non-ECC system? One friend felt like he was going crazy as over the course of two months his system degraded from occasional random errors to random crashes, blue screens and finally to no POST. Another time, a coworker had to stare at raw bytestreams in Wireshark for hours to find a consistently flipped bit. reply aportnoy 11 hours agorootparentDon&#x27;t overclock your memory. reply dharmab 11 hours agorootparentAll of these were with stock, non XMP clocks. reply aportnoy 11 hours agorootparentWell then… test your memory :) reply toast0 10 hours agorootparentHow often do you test your memory? The nice thing about ECC is it&#x27;s always testing your memory, and (if it&#x27;s set up properly!) you&#x27;ll get notified when it begins to fail. Without ECC, your memory may begin to fail, and you&#x27;ll have to deal with the consequences between when it starts to fail and when you detect it.(Of course, I don&#x27;t run ECC on my personal systems, but at least I&#x27;m wandering knowingly into the abyss) reply nirvdrum 10 hours agorootparentprevTesting your memory detects if you have bad RAM, which ECC isn&#x27;t going to help with anyway. Perfectly fine memory will experience random bit flips from environmental factors. Your PC components and UPS also degrade over time and can cause random bit flips. ECC is there to catch problems as they happen and ideally take corrective action before bad data propagates reply ceeam 11 hours agorootparentprev> Ever had to troubleshoot but flips on a non-ECC system?No.> One friend felt like he was going crazyTell him about memtest86. reply aportnoy 11 hours agorootparentWow I came back to post this exact reply. I set my system to a slightly high frequency, ran memtest overnight with errors.Set it back down to a supported frequency, ran a full memtest suite again with no errors.Never had any issues since. reply theevilsharpie 9 hours agorootparent> Wow I came back to post this exact reply. I set my system to a slightly high frequency, ran memtest overnight with errors. > > Set it back down to a supported frequency, ran a full memtest suite again with no errors.Cool. You tested your memory at some point in the past.How do you know it&#x27;s still working properly and hasn&#x27;t flipped any bits?You don&#x27;t. Because you have no practical way of testing the integrity of the data without running an intrusive tool like memtest86 that basically monopolizes the use of the computer.Being able to detect these types of memory errors at a hardware level while the processor is doing other things is the fundamental capability that ECC gives you that you otherwise wouldn&#x27;t have, no matter how thoroughly you run memtest86. reply nirvdrum 10 hours agorootparentprevYou likely wouldn&#x27;t know if you had random bit flips. It&#x27;d manifest as silent data corruption. You might be okay with that. Others aren&#x27;t.It&#x27;s not a matter of overclocking. Bit flips are a fact of life running with 32+ GB RAM. Leaving your machine on 24&#x2F;7 (even if in sleep) stacks the odds against you. replymixmastamyk 12 hours agoprevRecently decided not to buy the AMD laptop from framework because they didn&#x27;t bother to implement ECC. Started me thinking that I don&#x27;t really need a new laptop, have an old one... so why continue to suffer from compromised parts at my desk?Unfortunately AMD has been going the wrong way with this. Oddly enough, Intel has quietly added a few cheaper models with ECC support.Unlike the author I don&#x27;t have time for building a new PC and a bunch of maybes. I found this machine that&#x27;s pretty cheap:https:&#x2F;&#x2F;www.dell.com&#x2F;en-us&#x2F;shop&#x2F;desktop-computers&#x2F;precision-...This one has a CPU option with a TDP of 65 W. What do y&#x27;all think? reply undersuit 10 hours agoparentI think you&#x27;re being a bit harsh to AMD on this, you still can run ECC on their consumer CPUs, you just need to research the motherboard because any motherboard&#x2F;chipset combo could have ECC support.That Dell has the Intel W680 chipset that is responsible for giving any Intel CPU ECC, just more pointless market segmentation by Intel. I don&#x27;t know if I would give Intel a glowing review for that, you can also buy an OEM system with an Ryzen Pro processor if you want that kind of ECC guarantee.You&#x27;re not going to find Intel offerings with ECC solutions for light laptops either right now. reply mixmastamyk 10 hours agorootparent> Just need to do a bunch of research and trial and errorOr just buy one?> buy an OEM systemWho sells certified ECC systems with AMD at similar prices? I did look but didn’t find much already assembled. reply undersuit 1 hour agorootparent>Who sells certified ECC systems with AMD at similar prices?I don&#x27;t think you can blame AMD for the OEMs choices. Lenovo does compete in a way. You have to buy a GPU on their Threadripper workstations because of no iGPU for the computer to fall back on like the Dell&#x27;s Intel iGPU. Also your Dell comes with 1 non-ECC 8GB DIMM standard, you have to pay $247 to upgrade to an ECC DIMM. Lenovos Threadrippers come with the ECC standard and can even run registered DIMMs.But yeah it is a $2500k Threadripper workstation with no GPU compared to a $1300 I5 workstation with no GPU.If you want to build an ECC AMD system some manufacturers want your money: https:&#x2F;&#x2F;www.supermicro.com&#x2F;en&#x2F;products&#x2F;motherboard&#x2F;h13sae-mfFrankly \"shopping\" OEM sites makes me crazy and it&#x27;s why I build my own. reply nrp 12 hours agoparentprevIt’s not a question of whether we want it or not. You’ll have to take it up with AMD on enablement of ECC support on non-PRO U-series mobile processors. reply kingsleyopara 11 hours agorootparentThanks for clarifying. That said, if you did want it, couldn’t you just offer a PRO series option e.g. AMD Ryzen 7 PRO 7840U? reply mixmastamyk 10 hours agorootparentprevDo we not deserve pro parts? Just a bunch of amateurs over here at HN? ;-)I suspect the group that wants to physically maintain their laptop but doesn’t care about data integrity isn’t too large. reply speed_spread 11 hours agoparentprevI haven&#x27;t looked but I suspect not many laptops support ECC, if any. That&#x27;s not a good reason to skip AMD.The Dell may support ECC, but as any workstation it&#x27;s pricier than consumer grade desktop with equivalent performance. If you need it, you need it but usually individuals don&#x27;t pay for that, their employers do. reply Modified3019 3 hours agorootparentThere are some xeon thinkpads that have full fat ECC capability, however you need to be exceptionally rigorous in making sure that&#x27;s what you are getting. Only some of the laptop xeon models support ECC, and it&#x27;s not as simply as \"higher cpu model number better\", it&#x27;s a fucked up matrix that intel loves to do.I believe that there might be issues with it not being enabled properly if you buy the machine with a minimum of non-ecc memory intending to switch it out, because lenovo does something fucky if you don&#x27;t get ECC from the get go. I could be misremembering that last bit, it&#x27;s been a couple of years since I looked at ECC capable workstation laptops.But yeah, when framework comes out with an ECC workstation laptop is when I&#x27;ll finally consider getting a new laptop. reply mixmastamyk 10 hours agorootparentprevIt’s a thousand and change, cheaper than a similarly specc’d laptop.And never been given the option. reply renewiltord 14 hours agoprevI think we have AsrockRack motherboards with Ryzen 7950x and ECC RAM. Works well. reply Modified3019 13 hours agoprev [–] See also:https:&#x2F;&#x2F;forum.level1techs.com&#x2F;t&#x2F;ecc-capable-verified-motherb...>\"I have ECC working on ASUS ProArt X670E-Creator with AMD Ryzen 9 7950X. But, you have to explicitly turn ECC on in the bios. If left on ‘Auto’, it will be off. I use four sticks of Supermicro (Hynix) 32GB 288-Pin DDR5 4800 (PC5-38400) Server Memory (MEM-DR532MD-EU48).\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;truenas&#x2F;comments&#x2F;10lqofy&#x2F;ecc_suppor... replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article investigates the lack of built-in support for ECC (Error Correcting Code) RAM in AMD (Advanced Micro Devices) Ryzen 7000 desktop CPUs (Central Processing Units).",
      "The author confirms that ECC RAM is operable on an ASRock motherboard with an updated UEFI (Unified Extensible Firmware Interface), based on a user's claim and their replication of the process.",
      "The article furnishes instructions for checking if ECC is enabled on a Linux system using the ryzen_smu driver, underscoring the benefits of ECC RAM for dependability and the involvement of the Linux kernel in reporting ECC status."
    ],
    "commentSummary": [
      "The piece focuses on the presence and performance of ECC (Error-Correcting Code) RAM on AMD Ryzen CPUs, noting experiences on specific motherboards and stressing its importance for reliable computing.",
      "It addresses varying levels of ECC support across different hardware platforms and the advantages and practical consequences of using ECC DIMM (Dual In-line Memory Module).",
      "While some argue its importance for data integrity and error detection and correction, others question its relevance and possible downsides, signaling diverse opinions on the need and benefits of ECC."
    ],
    "points": 307,
    "commentCount": 164,
    "retryCount": 0,
    "time": 1696894770
  },
  {
    "id": 37822774,
    "title": "Medieval staircases were not built going clockwise for the defender's advantage",
    "originLink": "https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/",
    "originBody": "Skip to content Fake History Hunter Medieval staircases were NOT built going clockwise for the defender’s advantage Posted on October 9, 2023 by The Fake History Hunter This story has been making the rdounds on the internet with a claim that you’ve probably been told during visits to castles, but, there’s no evidence for it whatsoever. In short the idea is that it’s easier for a right-handed soldier or knight to fight in a spiral staircase that is built going clockwise when they were defending the castle as they had space to swing their weapon from above while the attacker coming from below would find this more difficult.kn Like many myths that stick, the story at first makes sense. So when we hear it from a guide during a castle tour, from our history teacher, or even on television documentaries, why would we doubt it? But if you think about it a bit longer and start looking for evidence, you soon realise something is a bit iffy here. For starters, there is no primary evidence, whatsoever, that the people who built, lived and fought in these castles built staircases in that way for that reason. During the Middle Ages, nobody wrote down that you should build staircases like this and why. If it had been common knowledge among castle builders, then why are there still quite a lot (about 30%) of castles with counter-clockwise staircases? Why 70% of them were built clockwise is up for debate, of course. Some castles, like Clifford’s tower, had both and it seems this may have been for traffic going in different ways and thus having both types might have simply improved flow-through. And going downstairs is often trickier than going upstairs and it might help to have somewhere to place your right hand when descending, it also gives your right foot more space on the steps if the stairs go clockwise Or maybe it was just custom, what builders were used to, maybe it was easier for them to built stairs that went clockwise as right handed stone masons? Or maybe it just depended on where there was space for a staircase and how it would connect to the rest of the building, a simple, logical architectural functional reason. Until we find some medieval records explaining the castle builder’s choice to built stairs one way or another we just can’t say for sure what they were thinking. But 30% is a big enough number to suggest that there was not an overwhelming consensus that stairs going one way or another was better. And no, before you start, there’s no evidence of the Kerrs being left handed, that’s probably an 19th century (yes, them again) myth. The Tower of London, one of the most important castles in England, where royalty live(d) has counter-clockwise stairs! If medieval people thought this would give the defenders not an advantage, surely they would have fixed it, especially in this castle! Both these staircases are at Clifford’s Tower in York, two in the same building! So the defenders didn’t mind if they weren’t at an advantage when the enemy took the right stairs? Another reason why we know this story is a myth is that it also doesn’t make a lot of sense when you study medieval combat involving castles. Castle builders knew that it didn’t really make a huge difference which way the stairs go, they’re not suitable for fighting at all, neither party has a lot of space to wield those long, pointy, sharp weapons but even with daggers or short swords the situation is just very impractical. The person below you has the advantage of jabbing at your legs and feet while they can protect their head with their helmet and shield. Of course one of the few options you’d have to win would be by pushing your enemy back down the stairs and then with whoever is left with you, to retake the entire castle. Frankly, if you find yourself in this cornered position the castle is probably already lost. Sure, you can still hold out for some time, being above your enemy is a good strategic position, but only if you also have enough water & food to last. Which becomes more unlikely the further you’re pushed back as a well and your food storage are usually not somewhere high up in the castle but in stead at the lowest point, where the enemy already is. Again, when you get to the point that people are rushing up the stairs, you’re in the end-phase. But still, if you continue to fight a better way to stop your enemy than encountering them halfway down the steps would be to block the stairs by throwing heavy furniture and everything else you can find down it while you then wait at the top of the stairs where you have more space to fight and where your enemy really is at a disadvantage as they’re still on the stairs below you. Either way now would be a good time to start considering surrender, a glorious death in combat or jumping out the window. For attackers it’s also not a very tempting scenario. If you’ve already breached all the outer walls and defeated all the soldiers there and have reached so far into the castle that you’re at the foot of stairs, you’re very close to victory and who would want to risk their life crawling up some stairs where the defenders are waiting for you? Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win. In many cases simply realising the enemy was going to sit outside and wait was enough reason to surrender. Siege, from the Peterborough Psalter, early 14th century, via the KBR Museum, Belgium. Yes those defenders are all women. So in conclusion: there’s no evidence for this claim and it also doesn’t make a lot of sense. This, like SO MANY myths about the middle ages can very likely be credited to the Victorians, well technically an Edwardian, but still, same generation. One Sir Theodore Andrea Cook with a fancy moustache has a theory and for over a century everyone just blindly believes it. Yes, that seems to be the oldest source we have for anyone thinking the direction of spiral staircases helps defenders in castles. Until we find evidence for medieval people believing that one type of stairs was better than another, we can say that the old idea that favours the clockwise version for tactical reasons is a myth. As far as I know we’re yet to find ANY medieval source that writes about why spiral staircases should go one way or another. For more research & the opinions of historians, archaeologists & other experts check the sources below. Also, stairs were used to go up and down floors, they were not dimly lit or built to be uneven on purpose as you wouldn’t want servants, soldiers but also the lords and ladies themselves falling down them all the time. “Oh no Lord Dave has fallen down the stairs and broken his neck because we have no lights and dodgy steps in the tower just in case there’s a siege even though we haven’t had one in generations….” And if you’re trained in medieval combat and have access to some castle stairs, please do some experimenting, try if you can fight there and make a video of it, I’ll share it here! I’ve been trained in sword fighting but also with a short dagger but sadly never got a chance to try this on some medieval stairs myself. Do be careful & responsible though, I won’t take responsibility for you damaging yourself or worse, the castle Sources: Fake History, 101 things that never happened, by J.H.Teeuwisse ‘The Rise of the Anti-clockwise Newel Stairs’, research by the Castle Studies Group (pdf link) Medievalists.net Triskele Heritage Tales of times forgotten Newcastle Castle r/AskHistorians If you like my work, please consider supporting me on Patreon; Disclaimer; Picture(s) found online, used for (re-)educational purposes only. I do not own the copyrights to these images, I only share them here for educational purposes to try and make sure the real story behind it becomes known and people will stop spreading false information. If the copyright owner objects to the sharing here, kindly contact me and I shall alter the article. If you’re interested in using any of the images here get in touch with the copyright owners mentioned in the article. Feel free to contact me with questions. Share this: TwitterFacebook Loading... Related I’ve written a book! September 8, 2023 In \"My book\" Make Future Archaeologists Happy Day December 3, 2022 Liked by 3 people NOT an 16th century house in France November 17, 2021 In \"NOT an 16th century house in France\" Posted in Uncategorized Tagged castles, clockwise, stairs Post navigation I’ve written a book! Leave a Reply Twitter YouTube Facebook TikTok Instagram Like my work and want to support me? Join my Patreon! Buy me a drink & a stroopwafel by clicking here :) Search for: Recent Posts Medieval staircases were NOT built going clockwise for the defender’s advantage I’ve written a book! NOT medieval women poisoning their husbands List of medieval towns/villages/cities with sewer systems List of medieval towns/villages/cities with water supply systems The curious claims about James VI & I’s bathing habits NOT an antique Vampire hunting kit NOT Doctor Rebecca Lee Crumpler Not an Art Nouveau house in Bucharest NOT brothel candles NOT 1940s WASP pilot Shirley Slade Make Future Archaeologists Happy Day Reviews & recommended threads NOT Queen Elizabeth II throwing coins at the poor NOT a 3 year old chimney sweep NOT a Rolls Royce used to clean streets in India NOT the real Pharaoh Ramesses II & Seti I How to hunt fake history. NOT WWII spy shoes. NOT the world’s first camera NOT an abandoned Scottish Medieval village The curious claims about Elizabeth I’s bathing habits My Patreon Supporters Coca-Cola did not create Santa NOT an 16th century house in France Not a French colonial administrator being carried NOT a monastery’s ’Anti-Gluttony door’ NOT Marlene Dietrich being detained for wearing trousers NOT world’s first movie theatre NOT the world’s first video game NOT the world’s first computer virus NOT world’s first robot NOT world’s first Miss World BBC HistoryExtra article NOT Wojtek the WW2 bear soldier Blog at WordPress.com. Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37822774",
    "commentBody": "Medieval staircases were not built going clockwise for the defender&#x27;s advantageHacker NewspastloginMedieval staircases were not built going clockwise for the defender&#x27;s advantage (fakehistoryhunter.net) 288 points by BerislavLopac 22 hours ago| hidepastfavorite275 comments stult 16 hours ago> Of course the only way to win would be by pushing your enemy back down the stairs and then with whoever is left above you, retake the entire castle.> Yeah, that’s unlikely to work out.> Frankly, if you find yourself in this position the castle is probably already lost.This argument directly contradicts the instructions of Vegetius, whose De Re Militari was *the* definitive military manual of the Middle Ages. Specifically, in book 4, he writes,> Innumerable instances are to be met with where the enemy were entirely cut in pieces, even after they had penetrated the body of the place: this certainly will happen, if the besieged continue in possession of the ramparts, towers, and highest parts of the city... The sole resource after a place is forced, either by day or night, is however to secure the ramparts, towers, and all the highest places, and to dispute every inch of ground with the enemy as they advance through the streets.It&#x27;s hard to overstate how important Vegetius was to Medieval strategists, who treated his work practically as gospel and would generally try to follow its recommendations to the letter. So I seriously doubt any medieval strategist would have viewed the only conduit to the critical and decisive high ground positions as tactically irrelevant. reply mbreese 13 hours agoparentThis seems to discuss roads and cities… not stairs in a tower. If the direction of the stairs was so important, why isn’t that mentioned?Either is was very obvious to the authors (so not included), or not thought to be an important factor. reply atoav 7 hours agorootparentAs someone who grew up around medival european castles, the reason is that righthanders with weapons going upstairs will have a harder time using their weapons than righthanders defending the stairs downstairs.When you are inside such a narrow stairway this fact becomes very obvious. reply mbreese 29 minutes agorootparentI understand that this is the prevailing wisdom. But that’s exactly what the article is arguing against. reply Tao3300 15 hours agoparentprevVegetius, pray tell what the scrying glass saith of yon fortification level? reply bigstrat2003 9 hours agorootparentVerily, coz, it saith the level be over four hundred and fifty score! reply Grimblewald 15 hours agoparentprevStill doesn&#x27;t say anything about twisting direction of the staircase. reply atoav 7 hours agorootparentIf you use a handweapon (sword, axe, knife, hammer, etc.) you need space to perfom a swing with any meaningful amount of energy.Medival stairways were built this way because people going upstairs won&#x27;t have the space to swing if they are righthanders. Meanwhile people going downstairs have a good amount of space to do precisely that.The assumption of course is that you as the defender are the one fleeing upstairs, while the attacker is trying to get to you.Source: grew up around medival european castles and have been on a few tours. When you are inside such a stairway this becomes very obvious. reply mintplant 7 hours agorootparentThis is all addressed in the linked article. Even the bit about the tours. reply zeteo 14 hours agorootparentprevMaybe they&#x27;re easier to build that way if you&#x27;re right handed? reply pvdoom 8 hours agoparentprevAgreed, there are a number of accounts that do describe this happening as well reply zeteo 14 hours agoparentprevYes, it seems more likely they would do something like roll down a large boulder rather than push the enemy down the stairs. Having been up a few of these staircases recently, the prospect of something heavy coming down from above sounds absolutely terrifying. reply angled 9 hours agorootparentWhat are the optimal parameters for the size, mass, and velocity of the stone, and the material, height, and thickness of the walls, to meet the objectives without the stone damaging the walls? For more than one stone? How do you get them up? reply firtoz 7 hours agorootparentObviously you build the castle around the stoneOnce you use it to crush all enemies, you rebuild the castle around the new position of the stone reply c420 6 hours agorootparentAssuming you&#x27;re using African stones and not European stones to maintain air-speed velocity. Though African stones are non migratory. reply helsinkiandrew 7 hours agorootparentprevI think a long, sturdy spear to penetrate and&#x2F;or push down the enemy would be equally effective and reusable reply timthelion 13 hours agoprevThere is a pretty significant flaw in this article in that it assumes castles mostly defended against war. When you read history books, and actually visit real castles, you learn the main threats were insurection, rebellion, and disease. Most royalty who were killed were killed by people within the castle walls, so the argument &#x27;well you&#x27;d just give up&#x27; simply doesn&#x27;t apply. You don&#x27;t &#x27;just give up&#x27; if your brother is trying to kill you or there is a peasant rebellian. Neither of those situations typically involve unbreakable seiges.... The idea that castles are not built for internal defence goes against a tremendous amount of archeological evidence. They are choke full of trap doors, weird side rooms, and hiding spots. reply PumpkinSpice 13 hours agoparentThe relative scarcity of castle sieges doesn&#x27;t mean they weren&#x27;t a major concern. It&#x27;s quite likely that castles served as an effective \"siege deterrent\". That is, sieges weren&#x27;t common specifically because the likelihood of success was low. reply timthelion 12 hours agorootparentMy point was to criticise this paragraph: \" For attackers it’s also not a very tempting scenario. If you’ve already breached all the outer walls and defeated all the soldiers there, who would want to risk their life crawling up some stairs where the defenders are waiting for you? Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win. In many cases simply realising the enemy was going to sit outside and wait was enough to surrender.\"The author seems to be claiming that beyond the outer walls castles don&#x27;t have defensive elements as they are pointless once the walls have been breached. This claim is false. reply tnecniv 10 hours agorootparentI’m not going to claim I’m a medieval military tactician, but if you have some amount of resources stockpiled and friendly armies in the field, why surrender immediately? Your forces or allied forces could pin the siege force against your walls possibly giving you an advantageous position. Perhaps stockpiling supplies that didn’t go bad was difficult back then or militaries didn’t consistent of more than one army so if there was a siege that meant your main force was already defeated?I do remember that the first phase of the Punic Wars was basically Sparta chasing all the Athenians inside the city where they brought in supplies by boat and waited the Spartans out, rinse and repeat for a decade. Obviously that’s a different period and the Athenians suffered a horrible outbreak of some sort of plague possibly due to the overcrowding. reply defrost 10 hours agorootparent> where they brought in supplies by boat and waited the Spartans outThat comes down to the location and type of castle, nothing to do with period.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Caernarfon_Castlehas town walls, water on three sides, multiple independant keeps separated by curtain walls, etc. Once attackers \"gained entry\" they were faced with being in an enclosed space, surrounded by high archers, and tasked with as much work again to advance further ... only to be faced with the same again.It was damn near impossible to siege as restocking from the sea and|or river was almost always an option at the time.It was also a castle with decades of resources and cash thrown its way, other castles of the same period didn&#x27;t fare nearly as well.A great many of the Irish castles of the Ulster plantation and onwards fell to undermining - Irish sappers dug tunnels and propped the undersides of the walls .. only to later burn out all the props and collapse the walls.There were only so many castles that had water access, multiple layered defences and granite foundations all about that resisted tunnelling. reply meigwilym 7 hours agorootparentNice to see my home town - and its castle - on HN.Fred Dibnah included it in his programme on castles and how they were built. He also goes over its defensive and offensive features in detail.Here it is on YT:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=64tCM9zXTE4#t=345 reply heja2009 8 hours agorootparentprevAthens-Sparta would be the Peloponnesian War, Punic wars were between Rome and Carthage. Sorry for the nitpick. reply civilitty 12 hours agorootparentprevThe whole article is awful.> Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win. In many cases simply realising the enemy was going to sit outside and wait was enough to surrender.This part for example is just straight up false. While many more sieges were won by surrender than successful assault, sieges were very violent and full of fighting. Sallies and even open field combat between groups of warriors wanting to make a name for themselves were a daily occurrence. The vast majority of cities and castles under siege had plentiful water supplies and could hold up to a years supply of food under rationing, especially if they had any time to prepare for the siege (which they almost always did because moving big armies is hard to do discretely). That preparation also stripped the surrounding area of forage for the armies, giving them hard time limits on how long they could siege before morale cratered. The attackers were just as likely to starve unless they had a constant supply line which the defenders constantly tried to disrupt.In order to overcome that disadvantage the sieging army had to really do a lot of damage and scare the besieged into surrender. Constant volleys from siege equipment into and over the walls, attempted escalades, towers and projectiles, and soldiers with pickaxes batter the walls. At the siege of Lisbon in 1147, two shifts of 100 men each shot thousands of stones a day using two trebuchets.Major assaults would even be planned out in the open to drive fear into the defenders and try to get them to surrender before a large wave of violence.Source: see the Soldiers’ Lives Through History - The Middle Ages chapter 4: Sieges. Lots of primary sources like the St Omer Chronicle in the notes. reply sfink 16 hours agoprevHow wide are these stairs, typically? Because I&#x27;ve been in a staircase built by hand out of stone (and yes, I was given this exact explanation for why it was built clockwise, despite it being in Carmel, California, which is not exactly a hotspot for medieval sieges). And a lot of what people are talking about here is laughably irrelevant if the stairs were as steep and narrow as that one was.It was tight. I didn&#x27;t have much trouble climbing it, but I&#x27;m not sure I could have navigated it at all wearing armor. Falling down the stairs was not an issue because you&#x27;d just fall against the curved wall. Passing by other people? Hahaha. Maybe if you were trying to play Medieval Twister.The defender advantage argument was viscerally satisfying, because you could so easily imagine how impossible it would be to do anything with the inward hand. Which is probably mostly evidence for why the myth persists, whether it is true or false. Though that itself could have applied to the builders or customers of times past. You can build them one way or the other, and here&#x27;s a satisfying explanation for one even if it pertains to a situation that never happens, so... why not go with clockwise?Then again, if I were to speculate, I would wonder why the fixation on sieges? If the defensibility argument were true, couldn&#x27;t it apply to other situations like an attack by the populace or staff? The lord&#x27;s personal guard might still appreciate the edge.I can&#x27;t help but think that carrying beer, torches, or chamber pots ought to be a bigger part of the justification, though. reply Aeolun 15 hours agoparent> I&#x27;m not sure I could have navigated it at all wearing armorThat’s another myth. Wearing a reasonable form of plate mail is sort of heavy, but doesn’t really restrict your movement as much as people seem to think. reply bradknowles 14 hours agorootparentI&#x27;ve worn really good armor in SCA heavy combat. I&#x27;ve also been up some impossibly narrow curved staircases where I am certain I could not have made it while wearing armor -- I could barely squeeze through without armor. The top flights of stairs at Köln Cathedral are pretty tight, and the whole 55 flights of stairs is nothing to laugh at.Now, the difference is that I&#x27;m probably bigger than your average footman or knight who might have been trying to go up those stairs. But they definitely wouldn&#x27;t be passing anyone on the stairs, and they definitely would have had trouble hacking on someone who was above them on the staircase.The one key fact that puts the idea to rest is all the staircases I&#x27;ve seen that spiral clockwise in one part of the building, and counter-clockwise in the other. Everything else being equal, both sets of stairs could be used to go either up or down, and you could choose which set to use. At Köln Cathedral, they tell you which ones are for up and which ones are for down, but if you&#x27;re an invading attacker, you don&#x27;t pay attention to the rules of the house you&#x27;re invading. reply codedokode 3 hours agorootparent> The one key fact that puts the idea to rest is all the staircases I&#x27;ve seen that spiral clockwise in one part of the building, and counter-clockwise in the other.Smart! One staircase to defend from attackers coming up from the ground and another to defend from attackers coming from the roof. reply bombcar 12 hours agorootparentprevA cathedral is more likely to have architectural questions answered by aesthetic design than by defensive design. And if some decent percentage of the 30% of the \"wrong way\" staircases are paired like such, it would put even more evidence that there really was something about right-hand staircases. reply ffgjgf1 8 hours agorootparent> it would put even more evidence that there really was something about right-hand staircases.Probably there was. It might have also had nothing to do with making it easier to defend the staircase during combat. Maybe they just found that carry stuff up if the stairs go clockwise is easier. Maybe counterclockwise works better for those climbing down. But in most places you don’t really have enough space for two staircases so you just chose which (up&#x2F;down) is more important to you reply Beached 8 hours agorootparentprevplate armor makes you wider. weight and movement don&#x27;t matter if you are too wide to walk up the stairs. I too have been jn these stairs, and wearing a t-shirt as a 5&#x27;8\" male, I have about 2 to 4 inches of clearance. I would imagine a fully armored person taking up that small amount of empty space easily. reply firecall 14 hours agoparentprevYou also have a range advantage coming up.Your arm and the end of your sword can more easily reach the feet and lower legs of something above you.Whereas coming down the stairs, you have a harder time getting your sword to reach someone coming up because your range is reduced due to the height of your body. reply hoseja 6 hours agoparentprevMedieval people, even soldiers, had generally smaller statures in medieval times. reply gretch 21 hours agoprevMy own no-basis 30 second gun theory - what if they are all the same way because one guy who was really good at making them passed the knowledge down that way. Then everyone else followed from that one teaching and never bothered flipping it. It wasn’t better, it just won the coin flip reply mmanfrin 21 hours agoparentYou can go a step further and (maybe, I acknowledge this is a stretch) apply some evolutionary pressure in that it gave defensive advantages they didn&#x27;t think about and so the people whose castles this guy&#x2F;his students built retained their wealth and built more castles from the same building style. reply slim 20 hours agorootparentalso, when the number of stairs built that way reaches critical mass, any stair built otherwise will feel awkward reply derekp7 18 hours agorootparentI recall an interview with someone doing a late night talk show, that they tried putting the guest on the right side of the host but that didn&#x27;t sit to well with audiences because they were used to seeing the guest on the left side. No reason for it other than that is what the first popular late show did, so everything else followed. reply usrusr 19 hours agorootparentprevThat&#x27;s what I find most fascinating about the claimed 70&#x2F;30 distribution, I&#x27;d either expect something very close to even or far more lopsided.Perhaps a closer look at the numbers would show a very clear default direction plus a strong priority for symmetry where applicable? reply edgarvaldes 19 hours agorootparentWhat if the 30 percent are more close in region or time? reply vjk800 9 hours agorootparentprevI like this, and the comment you replied to. I think most of the things we have are the way they are because of reasons like these, not because someone rationally planned them. reply AlecSchueler 17 hours agorootparentprevI thought the current thinking was that no battle would ever come down to fighting on the stairway. If someone has already made it through all of your castle&#x27;s defences to even be on the stairs, then the battle is over. reply dexwiz 17 hours agorootparentAnd if you were defining a stairway, a spear is much better than a sword. Stand at the top, poke down. reply ffgjgf1 8 hours agorootparentAnd if you’re at the bottom you could just start a fire instead of risking your life by try to climb up reply thaumasiotes 13 hours agorootparentprevWouldn&#x27;t a spear be much better than a sword for any defensive position?The problem with a phalanx is that it&#x27;s hard to turn, not that attacking from short range is somehow better than attacking from long range. reply dexwiz 10 hours agorootparentWho said anything about a phalanx? You can have a spear and a makeshift barricade at the top of the stairs. reply thaumasiotes 7 hours agorootparent> Who said anything about a phalanx?I did. It&#x27;s right there in my comment.I&#x27;m supporting the idea that a spear is superior in any defensive position by pointing out that the problem with an offensive block of spears is the need to move, which doesn&#x27;t apply to defense. reply autokad 17 hours agorootparentprevthis comes off as video game logic. &#x27;well I lost, may as well hit the reset button&#x27;.Except when you are going to die, even if the extra odds seems pointless, you do it. much like WW2 tankers putting sand bags on their tank. reply Tao3300 15 hours agorootparentIt&#x27;s not a reset button. There&#x27;s a surrender button and a rout button. If you haven&#x27;t starved to death you get to pick one. reply Aeolun 15 hours agorootparentI’m pretty certain that when you’re at the top of the tower you cannot press the rout button. reply ffgjgf1 8 hours agorootparentprev> Except when you are going to dieThat’s why you surrender after you realize the situation is hopeless (which is hopefully long before anyone starts climbing up the stairs).Even if you’re willing to fight to the death&#x2F;don’t have a choice which was pretty rare and are just stuck at the top what incentives do the attackers have to risk their lives by rushing up the stairs when they can just start a fire at the bottom and&#x2F;or wait you out? reply rolph 15 hours agorootparentpreva hefty spherical boulder, works wonders for clearing a staircase. reply ffgjgf1 8 hours agorootparentprev> evolutionary pressureWouldn’t you need the relevant event to not be extremely rare for that to matter?I mean a sieges were once in a several decades or even once in 100-200 years events on average. Actual direct assaults with combat occurring on the stairs were significantly less frequent than that. The defender being able to turn the tide at that point? Even less. reply dbrueck 20 hours agorootparentprev> You can go a step furtherI see what you did there. reply nonethewiser 13 hours agorootparentprevSurvivorship bias reply fanf2 20 hours agoparentprevBut they aren’t all the same, they are 1&#x2F;3 : 2&#x2F;3 reply lawlessone 20 hours agorootparentMaybe that&#x27;s the ratio of left and right handedness in medieval staircase builders. i joke. reply teaearlgraycold 20 hours agoparentprevMy own guess - there’s already a bias towards right handedness. I assume that is related. I don’t know how these staircases were built but it may be that it’s slightly easier to build these staircases for right-handed people. And then maybe 30% of builders were left handed or some minority of the time the architect wanted to prioritize symmetry with another tower. reply rdtsc 20 hours agoprevFighting is fun to talk about but most of the time people didn&#x27;t fight on the stairs, they, unsurprisingly, simply climbed up and down on them. So, maybe it&#x27;s more comfortable to walk up the stairs that way? People are mostly right footed (60% as per [1]), so perhaps there is something about having the stronger right foot where the stairs are narrower when going up.[1] https:&#x2F;&#x2F;www.psychologytoday.com&#x2F;us&#x2F;blog&#x2F;the-asymmetric-brain... reply hutzlibu 20 hours agoparentAh, but going down is more tricky than up, so you want the strong foot on the slim side rather in this case. reply wizofaus 20 hours agorootparentI have to admit I had that thought - if I needed to get down a narrow staircase in a hurry, I&#x27;d prefer if it were anti-clockwise. But apparently another competing theory is that clockwise staircases allow people to put their right hand against the wall for balance&#x2F;safety... implying if they had anything to carry (including a lamp!) they&#x27;d prefer to do so in their left hand, which isn&#x27;t too convincing either. But in fact on further consideration, the fact that if you have something largish to carry, you&#x27;d probably want it on the wider side, and would be more likely you&#x27;d carry it in your right hand, might have something going for it...though I&#x27;m not sure why that would be obviously more so going down than going up (and logically I&#x27;d expect more things would be carried up from the ground floor than v&#x2F;v, particularly shortly after building the castle. From the upper floor you can discard used&#x2F;broken objects by tossing them over the side!). reply javcasas 18 hours agorootparentI don&#x27;t think going down was a priority. When you are under attack, you want your archers to rush up to the walls, with some extra fighters for good measure, and you don&#x27;t want them to go down until the enemy has decided to leave. At that point, the speed of your archers going down doesn&#x27;t matter much. reply wizofaus 4 hours agorootparentHmm...most archers would be right handed and used to holding&#x2F;carrying their bows in their left hand (during battle at least), which I assume would indeed be easier ascending a clockwise staircase...wonder how you&#x27;d test that theory! reply usrusr 19 hours agorootparentprevI wonder what the etiquette for oncoming traffic was, those spiral staircases with a central spine aren&#x27;t really walkable anywhere but at the outer wall.Whoever has to step to the spine side would probably want a hand on the spine, palm making contact from the uphill side no matter wether facing up or down. So for someone uphill, the spine contact would be made with the outside hand (arm crossing in front), for someone downhill with the inside hand. On a clockwise staircase, this would leave the right hand comfortably idle for candle, tool or whatever the person deferring to (presumably higher ranking?) oncoming traffic on the wall side is carrying. reply qup 18 hours agorootparentprevMaybe the castle with both was doing an A&#x2F;B test reply jackconsidine 21 hours agoprev> Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win.Currently reading Plutarch. Twice already he&#x27;s mentioned sieges where the attackers waited for the besieged to run out of water. The grueling wait is compressed in history. reply marginalia_nu 21 hours agoparentMy favorite siege weirdness is circum- and contravallation. Caesar&#x27;s seige of Alesia perhaps being one of the better examples. The man built a wall around the already walled fortification of Alesia... then built a wall behind him to keep the besieging army safe from Vercingetorix&#x27; allies.That&#x27;s a wall around a wall around a wall. Like a frickin&#x27; onion. reply jamiek88 18 hours agorootparentMy favorite siege story is Alexander being taunted by islanders who thought themselves immune to being under siege and attacked.They slowly stopped laughing as they realized the Macedonians were filling in the shore front to make a kilometer long 200m wide causeway to march across.It did not end well for the island City of Tyre and its inhabitants. reply lloeki 8 hours agorootparentI jumped to read a bit about it, expecting from your comment a swift victory, but it&#x27;s much more involved than that, the sequence of attack strategies and counterattacks are quite suspenseful.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Siege_of_Tyre_(332_BC)#The_sie... reply catlover76 20 hours agorootparentprevLike an ogre, one might say reply Tao3300 15 hours agorootparentprevMy answer to the tiktok trend: \"Roman Empire? Not much. Mostly I think about the late Republic.\" reply Animats 17 hours agoparentprev> Twice already he&#x27;s mentioned sieges where the attackers waited for the besieged to run out of water. The grueling wait is compressed in history.That&#x27;s happening now in Gaza. Israel has cut off water. reply fsckboy 17 hours agoprevthis title&#x2F;headline is ambiguous as to what it means.claim: \"Medieval staircases were built going clockwise for the defender&#x27;s advantage\"counterclaim: \"no they were not; medieval staircases were not built going clockwise for the defender&#x27;s advantage\"... it was for a different reason, or even, they weren&#x27;t even built that way.clarifying original claim: \"Medieval staircases were not built going clockwise for the defender&#x27;s advantage, they were built counterclockwise.\"confused? me too. and the site is called \"fakehistory...\"?The title should be, \"Exploring whether medieval staircases were built with chirality to benefit right handed defenders.\" reply mtoner23 16 hours agoparentIt&#x27;s a catchy title that is doing well on this website I don&#x27;t think your confusion on the title matters much at all reply ska123 12 hours agoparentprevHow do you manage to confuse yourself with something so simple? ;) reply crazygringo 21 hours agoprevWhat about evidence for a simpler theory, such as they were built in the direction that made most sense from where the doors would wind up?Like if you go through the bottom&#x2F;top door, it&#x27;s more natural to walk straight forwards and then curve, rather than walk in, turn 90°, and then walk upwards.Obviously this wouldn&#x27;t matter if the door were located facing precisely the middle of the spiral, but it certainly does if it more naturally opens on one side of the spiral. reply pzs 21 hours agoparentDoors can be built to open in four ways: inwards or outwards, hinge on the left or right. (Sorry if the language is wrong, non-native speaker here.) Considering that I am not sure I can follow why the door would make one direction more natural than the other. Maybe because there were more right-handed people than left-handed which made one setup more natural than the other? reply crazygringo 18 hours agorootparentSorry, I don&#x27;t mean the direction of the door but the position of the door itself in the wall.I can&#x27;t draw anything here, but imagine the staircase is the width of two doors. So the door could be on either side (closer to either edge).If the door is on the left, you want the staircase to curve upwards to the right. And vice-versa. reply bluGill 19 hours agorootparentprevOften the room itself gives you reason to prefer one direction or another. If the door is in a corner you want the open door to be against the wall (unless you don&#x27;t - I can&#x27;t think of why, but...). If there are other doors on the same wall you need to consider them - sometimes hinges all the same for symmetry; sometimes opposite so the the doors don&#x27;t bang into each other (when they are right next to each other. reply adrianmonk 16 hours agorootparent> If the door is in a corner you want the open door to be against the wall (unless you don&#x27;t - I can&#x27;t think of why, but...).There could be a window there but not in the alternative location. reply gowld 21 hours agorootparentprev> hinge on the left or right.Not \"left\" or \"right\", which is different on roomside and stairside, but inside or outside of the spiral. reply Xylakant 20 hours agorootparentLeft and right are usually (at least here in Germany) defined relative to “standing on the side the door will open towards and facing the door”. reply w-ll 21 hours agorootparentprevWouldn&#x27;t the doors likely be on the wall of the spiral. A door in the spiral stairs seems very awkward. reply EVa5I7bHFq9mnYK 19 hours agoprevI think people found out that more falls happened while descending than while ascending, so it was more important to have right hand holding the rails at the outer wall when descending. Thus counter-clockwise direction while going down and clockwise when going up. reply meigwilym 4 hours agoparentAre you sure there were rails? reply TheRealPomax 21 hours agoprevBut did staircases going into basements go clockwise? reply sethammons 20 hours agoparentThere we go; now something to falsify against. If the left or right is a defensive choice, we should see the reverse handedness defending attackers going down. Great point. reply lwn 21 hours agoprevI&#x27;ve visited a castle in Germany once, where they had special short swords for defending the staircases. The staircases in that castle were too small to wield a regular sword. reply Freak_NL 21 hours agoparentThat sounds eerily similar to the myth from the linked article. Although there is a chance that some enterprising blacksmith came up with a clever marketing scheme for those to convince the nobility that they really needed such a set of short swords.&#x27;Just in case pillagers come up the stairs, and I&#x27;ll throw in a Zweihänder for half the price too, in case your attacker steps out of reach of your regular sword!&#x27;. reply akozak 21 hours agorootparentI love this. Naive feudal lords as the historical equivalent to high net worth preppers. reply eproxus 19 hours agorootparentWhat could be more prepping than building a whole stone castle? It’s the historical equivalent of a bunker for most part of modern (and ancient) history reply smsm42 18 hours agorootparentBuilding castles to cover captured terrain was pretty common (unless of course there already was one around, in which case you besiege and take it, if you can). Of course, building a stone ond rakes time, so they&#x27;d build a temp one first, and then, ic theh manage to keep the territory, update it. So if it&#x27;s prepping, it&#x27;s a very common and prudenf version of it. reply mkoubaa 13 hours agorootparentI wonder how many castles were built like codebases. Start with a little MVP and accumulate stuff over time that eventually gets refactored and eventually seems well thought out reply bombcar 12 hours agorootparentApparently many of them, insofar as they started small and became large encrusted monoliths over time. replysmokel 20 hours agorootparentprevEhm. The article does not actually give any evidence, so this argument is becoming rather absurd. reply quotz 12 hours agorootparentprevZweihander means two handed swords quite literally, so in this case i guess it would be einhander haha reply russdill 21 hours agoparentprevWas there period documentation? Or a just so story about short swords? reply usrusr 19 hours agoprevLong article without even the tiniest hint of evidence to support the claim that the easier to defend theory wasn&#x27;t the reason why apparently there is a considerable imbalance in staircase direction.The reality is that most of the time most castles were not involved in violence at all (outside of rough methods of keeping order I guess). Even if staircase fighting never ever happened, the imagination of heroically fending off invaders who made it that far in person could have easily been a clever pose, a tool of the trade for architects to give the impression of really knowing all the tricks. Claiming better defensibility would have made an even bigger impression on the future inhabitant than on tourists hundreds of years later. Because, assuming that the article is not wrong in this, the customer has just as little experience fighting in a staircase as the tourist hordes.Medieval snake-oil, claiming that it never happened should require better evidence than \"you really would not want to ever let invaders get that far\".If it&#x27;s a 30&#x2F;70 distribution chances are that almost half of those 70 are just as random or motivated by more pressing concerns than the \"wrong direction\" 30, and of the remaining 40 that make up the imbalance, a certain amount will be habitual copies of conscious decisions for the snake-oil winding.Yeah, whenever a tour guide brings up the defensive advantage story, chances are that this particular staircase wasn&#x27;t really designed as defense-optimized but random&#x2F;some other reason&#x2F;habitual. But unless someone proposes a better explanation for the imbalance (I don&#x27;t know, some pseudoreligious thing perhaps? Some echo from whatever way Romans preferred? Oncoming traffic etiquette, like climbing side steps toward the steep side, taking a break grabbing the stair&#x27;s spine while the descending side slides past at the outer wall, and they&#x27;d both rather have their dominant hand wall-side?), it&#x27;s a rather bold claim to call it a victorian era fabrication. reply JdeBP 16 hours agoparentYou have the burden of proof the wrong way around.The earliest occurrence of this hypothesis was propounded by Theodore Andrea Cook in 1903. That was not the Victorian Era, but was later. Cook was not a historian, but a sports writer and art critic. The book was _Spirals in Nature and Art_. And this hypothesis is a half-paragraph aside, with words like \"would\" and \"probable\", given with zero supporting evidence, and clearly one (as xe wrote \"I think\") that Cook originated.The burden of proof is to prove that that is true, not to blithely assume that it is true and demand that there be evidence to prove it false.Especially since Theodore Andrea Cook held that \"right-handed spirals are more common in staircases\". By \"right-handed spiral\", Cook actually meant anti-clockwise staircases (as can be seen from figure 29 in the book). Not even Cook believed the premise that has given rise to this 120-year-old myth. Cook wrote that anti-clockwise staircases were \"more common\" despite the fact that clockwise ones would have been better for this reason, a reason that xe invented from whole cloth without any support from how helical staircases even featured in any siege of any castle in history.120 years of uncritical out of context repetition and augmentation later, here we are; with people demanding that the burden of proof lies with those who challenge something that was never proven in the first place, not expertly held, and not even held true by its own originator. reply User23 12 hours agorootparentIs there some reason you&#x27;re misgendering Theodore Andrea Cook? He&#x27;s obviously masculine. Perhaps you&#x27;re not aware that Andrea, like Shannon, Leslie, and many others, is also a masculine name? reply ordu 15 hours agoparentprevI hear about this imbalance for the first time, and reading about it for half an hour left an impression that no one tried hard to prove anything.The very first thing that begs to be done is to plot this imbalance on a time axis to see was it kept constant over time, or maybe people made clockwise stairs at first and switched to counter-clockwise later.But it is not the only possible correlation you can measure before assessing the hypothesis space. Does direction of a stair correlates with geography? With a number of times a castle changed his owner? With a size of a castle? ...I&#x27;m pretty sure you can get some idea of it all by studying historical sources. But I see no evidence someone bothered to do it. All I see people speculate a lot.In this situation, I believe the most reasonable will be to file the question as having no answer and to forget it as having no importance. reply usrusr 4 hours agorootparentAll those mythbuster sources seem to deliberately exaggerate a defensibility preference from a minor bias into a universal rule and then feel smug naming some counterexamples that would disprove a universal rule. But it was them who elevated a preference bias into a supposedly universal rule. Not even that supposedly first mention (beware! Universal claim, impossible to prove that it was never written before!) goes that far, at least not according to the retelling of the mythbusters. reply p1esk 18 hours agoparentprevthe customer has just as little experience fighting in a staircase as the tourist hordesYou’re talking about a customer who most likely received a rigorous sword fight training, and probably participated in numerous knight tourneys. And spent his life living in castles, walking up and down those stairs. And who most likely knew someone who had personally engaged in castle offense or defense (the world was a lot smaller back then). Somehow I think this customer would know a thing or two about defending castles.You could be right about the sales tactics, but comparing a medieval castle owner and a 21st century tourist is a bit much. reply usrusr 15 hours agorootparentThat&#x27;s the part where I was taking the claim of the article at face value, the claim that nobody would have ever considered the stairwell a possible site for violence to happen. reply autokad 16 hours agoparentprevas I mentioned above, the idea that &#x27;well if they got that far you already lost&#x27; comes off as video game logic. You don&#x27;t have a reset button or save point to go back to, you die. So even if it gives you ridiculously thin odds, or even if those added odds are just perceived ... You do it. Much like the ww2 tankers who put sand bags on their tanks.Do you see those tankers saying &#x27;well, if we took a shell there, we already lost&#x27; reply JdeBP 13 hours agorootparentThat&#x27;s because the writer of the article at hand is poor. For a better exposition of the argument, have James Wright, archaeologist.https:&#x2F;&#x2F;triskeleheritage.triskelepublishing.com&#x2F;mediaeval-my...To paraphrase: We know how sieges ended and castles fell. We have written histories to consult. None of them ended with swordfights on staircases like Errol Flynn movies. reply civilitty 18 hours agoparentprevI recommend Bret Devereaux&#x27;s series on medieval fortifications, specifically the manpower problem [1]:> While sapping (tunneling under and collapsing fortifications) remained in use, apart from filling in ditches, the mole-and-ramp style assaults of the ancient world are far less common, precisely because most armies (due to the aforementioned fragmentation combined with the increasing importance in warfare of a fairly small mounted elite) lacked both the organizational capacity and the raw numbers to do them.Overall, medieval armies just didn&#x27;t have the resources to siege for as long and as intensely as the Romans and other ancient armies did. Until the early modern period and gunpowder artillery, defenders in castles had a much bigger advantage over attackers so often attackers just didn&#x27;t bother. They were more common than actual pitched battles though and most ended through surrender rather than successful assault.The book Devereaux mentions Soldiers’ Lives Through History: The Middle Ages is a great resource for further reading - there&#x27;s a whole chapter on sieges. It starts out describing how much worse the life for siegers often was compared to the besieged.[1] https:&#x2F;&#x2F;acoup.blog&#x2F;2021&#x2F;12&#x2F;10&#x2F;collections-fortification-part... reply dustedcodes 7 hours agoprev> If it had been common knowledge among castle builders, then why are there still quite a lot (about 30%) of castles with counter-clockwise staircases?For the same reason why there are still a lot of tower blocks being built with combustible cladding or why we still find many houses not being built earth quake proof in prone countries: idiots and bunglers.> The Tower of London, one of the most important castles in England, where royalty live(d) has counter-clockwise stairs!That&#x27;s a bad example. It was built in 1066 (the first part) by Norse people who occupied England and not the English. I wouldn&#x27;t be surprised if the workmanship of building stone castles hugely differed between those two peoples at that time.> If you’ve already breached all the outer walls and defeated all the soldiers there and have reached so far into the castle that you’re at the foot of stairs, you’re very close to victory and who would want to risk their life crawling up some stairs where the defenders are waiting for you?That assumes that every castle was huge and wars were fought between hundreds of soldiers. Sure when you have 200 soldiers inside your castle having defeated everyone except a handful of people up the tower then this would be pointless, but that is not what happened in reality. It&#x27;s a Hollywood imagination of the battles fought. Many castles were tiny and the army was in the dozens, not hundreds. Raiders and other small groups of enemies would come in a couple dozens and not in hundreds. All of a sudden those stairs make A LOT of sense. reply reedf1 6 hours agoparentTechnically Norman not Norse. Granted the distinction is pretty pedantic. reply Garvi 5 hours agoprev> Of course the only way to win would be by pushing yfour enemy back down the stairs and then with whoever is left above you, retake the entire castle.I see we&#x27;re dealing with a castle siege expert over here. As I have visited many castles in Europe (I also live in bicycle driving distance of at least 5 medieval castles) and have heard this explanation many times, I was wondering about the authors counter arguments. Unfortunately there weren&#x27;t any. I cannot tell for sure since part of the article is missing after \"Of course if the enemy \". Now I will never now this another obvious fact.Reminds me of moon landing denier arguments: \"Of course we didn&#x27;t land on the moon. Duh! It doesn&#x27;t make any sense AT ALL. Pfff!\" reply karaterobot 20 hours agoprevTo be clear, this article does not attempt to explain why 70% of stairs were built clockwise, which seems salient. And the strongest arguments against the myth are that fighting on a staircase is bad no matter what (granted), and that certain, specific, famous staircases (like those in the Tower of London) were built counter-clockwise. To me, that&#x27;s not a slam dunk case against the myth, it could be explained by there not being a centralized Castle Staircase Building Code across all Europe, over the course of 1000 years, which was not a misunderstanding I had anyway. I am unconvinced for now! reply marcellus23 20 hours agoparentI think the slam dunk against the myth is simply that there&#x27;s no evidence for it at all. If you have no primary sources or archaeological evidence, and the only \"source\" is tour guides, then there&#x27;s no reason to believe it.It might be true or it might not, but talking about it as if it&#x27;s definitely true is simply wrong. reply jjk166 19 hours agorootparentThere&#x27;s no evidence for an alternative either. We simply don&#x27;t have surviving documents that talk about the logic of why staircases were built that way, which is hardly surprising given that even nowadays when books are dramatically cheaper to produce, architects don&#x27;t tend to write down the logic they use when designing the details of functional structures.The combat explanation fits the evidence as well as anything else. Perhaps it&#x27;s not proven to be true, but it&#x27;s certainly not proven to be false. reply marcellus23 18 hours agorootparentI don&#x27;t see anything in your comment that contradicts what I said:> It might be true or it might not, but talking about it as if it&#x27;s definitely true is simply wrong. reply afterburner 20 hours agoparentprevThe article is from the point of view of a responsible historian.There is no evidence of the myth being true. There are no sources in history suggesting it.It might be true. But there is no evidence that it is.Proving it false is another matter. reply karaterobot 20 hours agorootparentI don&#x27;t know about that. They seemed to be definitively saying the staircases were not built to aid defenders, but didn&#x27;t have strong evidence for that. If they&#x27;d said \"there is no positive evidence that...\" or \"we have no reason to believe that...\" then I&#x27;d agree with you, but what they wrote was:> Medieval staircases were NOT built going clockwise for the defender’s advantageand> it’s not true.Which seem like confident statements with no affirmative evidence to support them.In fairness, their conclusion is more measured:> So in conclusion: there’s no evidence for this claim and it also doesn’t make a lot of sense.But that&#x27;s not the headline they went with. reply ImPostingOnHN 19 hours agorootparentby default, it is untrue until sufficient evidence arises that it is truesee also: Russell&#x27;s teapot[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Russell%27s_teapot reply ncallaway 18 hours agorootparentOkay, so let me them make the claim: \"It is false that staircases were built clockwise to advantage the defender\".Then, since we agree that the claim has no evidence to support it, we assume it is false.Therefore, we conclude, \"it is true that staircases were built clockwise to advantage the defender\".I agree that the burden of proof lies upon the person that makes the claim. But that doesn&#x27;t mean we assume the opposite of the claim must be true until they do. It means we assume ignorance.So, a more correct statement would be: \"In the absence of evidence of why the staircases were constructed, we do not know why they were constructed\".To say the absence of evidence proves the opposite of the claim is wrong. reply ImPostingOnHN 17 hours agorootparentthe actual (and also initial) claim here is that the myth is true, the author is simply pointing out that there is insufficient evidence to support the myth, and thus we fall back on the null hypothesis, aka the default: that there does not yet exist sufficient evidence to conclude the myth is anything other than false.> But that doesn&#x27;t mean we assume the opposite of the claim must be true until they do. It means we assume ignorance.Regardless of the wording, the gist is the same: we &#x2F;don&#x27;t&#x2F; assume ignorance, we treat the claim, like Russell&#x27;s teapot [0], or any other unsupported claim, as false until such evidence arises, since there are an infinite number of unfalsifiable premises, and we neither want to, nor do, in practice, treat them all as maybe true, maybe not, forever.tl;dr: As Russell&#x27;s teapot [0] demonstrates, yes, there is a default, and that is that a thing is false unless sufficient evidence exists to believe otherwise. No, we don&#x27;t treat all unfalsified (and unfalsifiable) hypotheses as unknown and assume ignorance.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Russell%27s_teapot reply calderknight 13 hours agorootparentYou have cited that Wikipedia page five times. But it doesn&#x27;t say anything about there being such a default view. reply ImPostingOnHN 2 hours agorootparentIt actually does, that&#x27;s why I cited it so many times! :)In 1958, Russell elaborated on the analogy:> \"...nobody can prove that there is not between the Earth and Mars a china teapot revolving in an elliptical orbit, but nobody thinks this sufficiently likely to be taken into account in practice...\"[0]Replace &#x27;teapot revolving in orbit&#x27; with &#x27;truth to the staircase fighting myth&#x27; – hopefully you now see why it&#x27;s ridiculous to entertain all hypotheses as equally likely without evidence.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Russell%27s_teapot reply karaterobot 17 hours agorootparentprevMy comment was that I was not convinced of the argument the article made, not that I was convinced the opposite was true. reply ImPostingOnHN 17 hours agorootparentThe article doesn&#x27;t make any arguments, it simply examines the arguments made by others, and points out that those arguments aren&#x27;t convincing enough to conclude the myth is true (and thus we fall back to the default: that the myth is false) reply usrusr 14 hours agorootparentMuch of the article just describes that fighting in a stairwell would be dangerous and inconvenient (what fighting is not?), completely ignoring the question wether one winding might be more or less so. reply calderknight 19 hours agorootparentprevIf there&#x27;s no evidence about a situation, there&#x27;s no evidence for any theory about the situation. There&#x27;s no evidence for the proposition A. There&#x27;s no evidence for the proposition not A. By your reasoning we have to believe that both these propositions are untrue: A and not A. This seems totally insane. reply ImPostingOnHN 18 hours agorootparentAs Russell&#x27;s teapot [0] demonstrates, that is not the case. A thing, whether the existence of a teapot floating in space, or an old architecture myth, is by default untrue until sufficient evidence arises showing it is true. This article is simply pointing out that such evidence doesn&#x27;t exist in the staircase attacker theory.We do not believe that maybe it is true this teapot exists, maybe not, simply because the initial hypothesis (that it is true in the first place) hasn&#x27;t yet been falsified. If that were the case, I could make up a thousand improbable myths, and say they&#x27;re all maybe true, maybe not, and we would have to treat them all as equally plausible until someone wastes their time trying to disprove all thousand, and then I could make up a thousand more.That is why the burden of proof of truth lies with the person asserting the truth of a teapot&#x2F;staircase beliefTo add to your A vs. not-A problem, you are close to identifying the resolution, too: For an analogue in statistics, A = \"this staircase explanation has sufficient evidence to say it is true\", not-A = \"this staircase explanation does not have sufficient evidence to conclude it is true\". Not-A here is example of what is called the null hypothesis in statistics. The null hypothesis is the default.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Russell%27s_teapot reply calderknight 17 hours agorootparentThe point of Russell&#x27;s argument is that we should not believe in the Christian god&#x2F;the teapot. Not that we should believe that those things do not exist.It&#x27;s an argument against believing without evidence, not for believing without evidence. reply ImPostingOnHN 16 hours agorootparentthe point of Russell&#x27;s teapot is that even though the teapot (like this myth) is neither proven nor disproven, we should, and do, treat it unproven, because that is the default state until sufficient evidence arisesIt&#x27;s an argument against entertaining theories that have no evidence, against ignorant agnosticism towards any arbitrary theory replybluGill 19 hours agorootparentprevEven if you can prove it true in some specific castle that doesn&#x27;t not mean it is true for all. Maybe other castles just copied the one where it was - often type of thing is done in architecture without realizing why, and so one castle built for fighting on stairs was copied in others without the other features that make fighting on stairs possible. (Or maybe the first was built for fighting on stairs, but after it was built practice proved it was still a bad idea - lots of variations on this idea). reply empath-nirvana 20 hours agoparentprev> To be clear, this article does not attempt to explain why 70% of stairs were built clockwiseI wonder if it&#x27;s easier for right handed masons to build a staircase in a particular chirality. What percentage of modern staircases are built in a particular direction? reply onlyrealcuzzo 20 hours agoparentprevI&#x27;d imagine they were built in a direction without a ton of thought, and it&#x27;s not really surprising to me that if you basically flip a coin - 70% of them landed one way.If the staircase happens to be on one side of the building, it would be better to orient it one way - based on how the windows would work - for example.If the staircase is against another busy entryway - it might be better to have the stairs go one way or the other, etc reply wizofaus 20 hours agorootparentIf there are several thousand such towers in Europe, then chance of 70% of them all being clockwise due to use of coin flips seems unimaginably small. More likely the first one happened to built that way and most others copied that until someone wondered if you couldn&#x27;t go the other way instead. Or maybe it is connected to handedness in some other way (easier to draw the design? To lay the stone work? Traditions around who should pass who and how if somebody going up encounters somebody coming down? Who knows...) reply Aerroon 19 hours agorootparentI think it would be more likely that the staircase fit better going one direction than the other. Eg taking the most used path to the staircase and going straight onto the stairs vs having to do a 90 degree turn before you can step on the stairs. reply notahacker 19 hours agorootparentIt seems unlikely that random chance would lead to a 70&#x2F;30 ratio for \"best fit\" either, so that just seems to be moving the phenomenon that needs explanation to layouts around stairwells, which certainly weren&#x27;t standardised in the medieval era.The ratio of staircases in Norman castles was more like 20:1 which is a ratio even more in need of a non-chance explanation; the greater numbers of anticlockwise staircases came later, when coincidentally or otherwise individual towers were less important to the overall defensive scheme reply idiotsecant 20 hours agorootparentprevI am not a medieval stonemason but these were lifelong craftsmen and I doubt they did it without a lot of thought. They did it with one specific thought it their mind I suspect, it was the way that they were most familiar with doing it so it was the fastest &#x2F; easier &#x2F; cheapest way to do it! The same reason any modern craftsman does quite a lot of things. reply jethro_tell 20 hours agorootparentI&#x27;d like to see that 70% distribution mapped out against corner adjacency. As in, if I have a square room [ ] and I put a stairway on the right wall in the bottom corner there, there is a good chance I&#x27;m going to go counter clockwise, but if I put it on the right top, I&#x27;ll go clockwise. I feel like the general flow of a room needs to be mapped out on this as well to get the full context. reply JumpCrisscross 20 hours agorootparentprev> these were lifelong craftsmen and I doubt they did it without a lot of thoughtThere are so many things that could bias this result. Maybe it&#x27;s easier to craft in one direction. Perhaps, north of the equator, castles tended to be constructed in certain orientations, with the windowless stairwells tending towards one side versus another. Altogether, there is no reason to prefer the myth over any of those hypotheses--they each have no evidence. reply kdmccormick 20 hours agorootparentprevFlipping a coin 1000 times and getting >=700 heads has a ~1&#x2F;10^24 probability.There&#x27;s got to be a reason, even if it was as simple as \"it was arbitrarily chosen and then became standard practice.\" reply bluGill 19 hours agorootparentBut just that in some direction maters for some reason (layout of the castle forced a direction and thus this works out to random chance?), and the rest was just what the mason felt like building (default to right handed?). You can come up with your own story about why direction would matter, and why for the rest there would&#x2F;would not be a bias in direction. Then play with how random each one is to get the 70&#x2F;30 percentage split. reply canadianfella 20 hours agorootparentprevIf it was up to a coin flip, it wouldn’t be 70 percent. reply whall6 20 hours agoparentprevI think all the article is arguing is not to just accept that explanation as fact. There is no conclusive evidence that this is the reason stairs were built this way. reply bsder 16 hours agoparentprevIt&#x27;s almost certainly because staircases were 1) hazardous as hell, 2) going down is way more dangerous than going up, 3) clockwise puts the dominant hand&#x2F;foot on the side with the biggest width when descending.There was an article here on HN a while ago talking about how the stupidly designed staircases were responsible for the Victorian trope of \"falling down a staircase to your death.\"--the ones for servants were especially poorly designed. reply MarketingJason 20 hours agoprevWhat if it was still about the weapons - but more about them being sheathed? A right hander will usually have a sword sheathed on their left hip sticking out and down. Maybe it was a safety measure to have the tip not hanging over the inner part of the stairwell as someone was going up where someone behind them could get poked versus more along the outer wall? reply ofslidingfeet 19 hours agoprevSaying it definitively didn&#x27;t factor in is at least as stupid as saying it definitively did. reply jjk166 18 hours agoprevGoing through the cited sources, I&#x27;m more convinced the defender&#x27;s advantage theory is right than before I started.First the claim that stairs would not be optimized for combat because fighting on stairs was undesirable holds no weight. Castles were designed with many layers of defense - it was entirely expected that large sections of a castle would be lost and the defenders would continue to hold out in other sections, bitterly holding chokepoints. From murder holes to machicolations, every inch of castles were optimized defense. Even if in practice defenders would prefer not to fight on a stairway, if all else were equal (and it&#x27;s hard to think of something more arbitrary than which way the stones are flipped), why wouldn&#x27;t they go with the option that potentially could be helpful instead of potentially aiding an attacker?Next, the argument that \"not all castles had clockwise staircases\" seems to be an own-goal. During the time periods when having to defend a castle was likely, staircases were overwhelmingly clockwise. It is only in the late middle ages when defense became much less of a priority that anticlockwise stair cases start gaining popularity, and the later it gets the more common anticlockwise stairs become. If there were some non-military utilitarian reason for the choice, such as making it easier for someone to steady themselves or carry lanterns, presumably that need would remain. If the choice were non-utilitarian from the beginning, why the initial disparity? No doubt the designers of these buildings had multiple competing concerns, including aesthetics and convenience, but clearly the balance shifted. Examples of anticlockwise stairways were common in structures not intended for defense in earlier structures, which means the shift was not technological and further makes non-military utilitarian requirements unlikely.Obviously it would be nice if we had more surviving sources from the time period, but it&#x27;s hard to imagine any other theory fitting the data so well. reply pagekicker 20 hours agoprevThis article is not very good, notably, it is almost all guessing, no evidence.An explanation that I would have found plausible: building stairs clockwise is cheaper somehow. reply JdeBP 17 hours agoparentThe irony is that you would have found the original proposition of the hypothesis, by Theodore Andrea Cook in 1903, to be exactly the same thing. Cook presented zero evidence, clearly was originating the hypothesis, and made it up from whole cloth.Xe was a sports writer and art critic, not a historian, moreover.It&#x27;s a half-paragraph aside in a book entitled _Spirals in Nature and Art_, using words like \"would\" and \"probable\". And after 120 years of uncritical repetition and amplification, here we are. reply VikingCoder 12 hours agoprevSounds like you&#x27;d have to be sinister to attack up a medieval staircase. reply some_random 20 hours agoprevI&#x27;m not actually convinced, there&#x27;s been a disconnect between the theory of war and the reality for as long as there&#x27;s been war. Just because you&#x27;d never actually want to fight on a staircase doesn&#x27;t mean that money and thought didn&#x27;t go into defending a staircase from its middle. How many militaries today still issue bayonets to foot soldiers and handguns to rear line officers? reply samus 20 hours agoparentA modern bayonet is basically a combat knife, not a single-use item. Even though it has become rare, it is occasionally deployed.Officers simply retain their handguns when they get promoted into rear line positions; no special accommodation is required. reply bombcar 12 hours agorootparentAnd we&#x27;ve just seen examples on the news where rear officers might have been better equipped had they had their handguns on them. reply jack_riminton 19 hours agoprevIt has no mention of the masons, who had strict codes and rules of thumb and where all the knowledge was passed down in oral form through apprenticeships and quite a lot of secrecy (hence the Freemasons). I&#x27;m not sure it proves or disproves the main point, but it&#x27;s a glaring omission that if investigated could explain it reply mtreis86 17 hours agoprevPeople are dominantly right handed, so right hand on the wall.You need more space under your foot while descending, you only use the ball of your foot while going up.The stairs are thicker on the outside, so if that is on the right as you descend, the staircase will be counter clockwise. reply gooseus 20 hours agoprevI&#x27;m gonna guess it correlates with the handedness of the builder.As a right-handed person, when I&#x27;ve built spiral towers in games they have been clockwise because when building from the bottom up, clockwise just seems \"right\". reply mkoubaa 13 hours agoprevThe more I read about medieval history the less I buy the narrative that it was a time of widespread ignorance and backwardness reply jeremiahbuckley 12 hours agoparentI find myself very interested in trying to figure out the story of medieval progress. Because I learned it was all fallen and ruined as a kid, and now I don’t believe it. But, I don’t have a grasp of the timescales of progress involved.My working theory is that progress was really slow until the written word, incremental improvements but still slow until the printing press, and pretty quick thereafter (until computers, and then the wheels came off). But…I would love to read a history from someone who actually studied it, and said “look at the pace of discovery from 1000BC-200AD, 200AD-1200AD, 1200-1600, etc.” reply pbj1968 15 hours agoprevIn the UK, it’s possible to rent small castles. I’ve never felt more secure in my life. The stairs on the staircase were huge and would have slowed down anyone, particularly people of the average height at the time. You really contemplated whether or not you needed that thing when you faced those stairs. reply Levitating 20 hours agoprevThis reminds me of the many articles stating that pirates didn&#x27;t wear eye-patches to cover up an injury but that they used them for for their eyes to adjust to the dark when entering a ships hold. Even though there&#x27;s more evidence that eye injuries were probably just common across pirates.Applying Okkam&#x27;s razor I&#x27;d conclude that most medieval staircases were probably build clockwise simply because most staircases were already built clockwise. reply codedokode 19 hours agoprevSuch staircases are pretty scary to climb even without a knight attacking you because there is nothing to hold, the steps are not flat and it is easy to fall down.Also, such straicases are used not only in medieval castles. A modern Russian 19th century cathedral also has a staircase of such type. Probably, because cathedrals must be built using traditional architecture? reply EVa5I7bHFq9mnYK 18 hours agoparentThat cathedral you are talking about, has two spiral staircases, one counter-clockwise and the other clockwise. reply wizofaus 20 hours agoprevWere staircases built around the same time but in non-strategic&#x2F;non-fortified buildings (private manors etc.) notably different? Or were spiral staircases only built in circular towers that existed primarily for defence? Presumably the narrowness was largely due to the difficulty of being a strong enough tower with a wider radius. reply legitster 20 hours agoprevThis explanation has always seemed a bit daft to me.> If it had been common knowledge among castle builders, then why are there still quite a lot (about 30%) of castles with counter-clockwise staircases?AKA it&#x27;s almost surely just a builder&#x27;s preference probably stemming from their handedness. reply xyzelement 21 hours agoprevEven if defensibility was not the primary design concern, I am sure it factored in as an obvious consideration to accommodate when possible - eg if you could make it go any which way, you might as well make it go the way that gives you a better chance in the most likely scenario. reply chmod600 19 hours agoprevConsidering that the construction costs are identical, there needn&#x27;t be a very strong reason to do it one way vs the other. Any reason would be enough, which might include some remote possibility of a battle advantage. reply a-dub 21 hours agoprevif i were to guess it probably has more to do with left hand side driving semantics which as i understand comes from a prevalence of right-handedness and a norm of posturing the right hand for weapon use.so, maybe they just adopted the rules of the road, and the legends that come from it. reply civilitty 20 hours agoprevThe source mentioned in TFA is much better, with more photos and original content: https:&#x2F;&#x2F;talesoftimesforgotten.com&#x2F;2019&#x2F;12&#x2F;18&#x2F;no-medieval-sta... reply JP44 21 hours agoprevCould it be them optimising their floorplan? Direction of the spiral is based on e.g. the largest possible entry or smallest obstruction(in terms of construction and visually for the rest of the room&#x2F;castle? reply Hoasi 21 hours agoprevInconclusive.What if they built right-handed defenders AND left-handed defenders towers? reply the_af 21 hours agoparentOh, but what if the attackers divided themselves in left-handed and right-handed attack groups, and chose the stairs to attack accordingly?This is getting silly :P reply seabass-labrax 17 hours agorootparentYou&#x27;re right, but now I&#x27;m disappointed that this didn&#x27;t make it into Monty Python and the Holy Grail! reply NoMoreNicksLeft 21 hours agorootparentprevI think these staircases evolved to make it impossible for rapey male ducks to impregnate the castles. Ancient sources agree with my theory, so it must be true. reply the_af 2 hours agorootparentIn support of your theory: no medieval castle ever laid duck eggs that hatched....(An earlier version of my comment ended with \"... ever laid duck eggs.\", evidencing both my deep ignorance of medieval warfare and the biology of egg laying!) reply digging 21 hours agoparentprevThe article states that they likely built neither because nobody wants to be fighting for their life 1:1 on a dank staircase with poor visibility. It&#x27;s actually the much more logical option. Even if attackers are in the stairwell, why wouldn&#x27;t you retreat to the top where you can accumulate real advantages? reply alastairp 20 hours agoprevAnother anecdotal description of old staircases that I&#x27;ve heard of before is from Burgos castle in Spain, where (it&#x27;s said) that the stairs to the bottom of the well change direction half way down to prevent you from getting too dizzy [1]> Se accede al interior por unas escaleras de caracol. Para evitar el mareo, los 4 primeros tramos se hacen en el sentido de las agujas del reloj y los dos últimos tramos en sentido contrario.[1] https:&#x2F;&#x2F;rutasparatodaslasedades.blogspot.com&#x2F;2019&#x2F;07&#x2F;el-cast... reply jameshart 20 hours agoprevSimilar article discussed previously: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29274875 reply hermitcrab 17 hours agoprevThe victorians created a lot of persistent myths:-vikings with horns on their helmets-highlanders all wearing tartan-knights in plate armour not being able to get up if they fell over? reply fsckboy 17 hours agoparentyes, Vikings with horns on their helmetshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Veks%C3%B8_Helmets (from scandinavia, but a couple thousand years before the Vikings https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nordic_Bronze_Age ) reply hermitcrab 7 hours agorootparentInteresting. But not really the animal horn helmets beloved of the victorians and, as you say, not contemporary with the vikings. reply aristofun 20 hours agoprevThis is what strikes me more than the topic:> The person below you has the advantage of jabbing at your legsWeren&#x27;t virtually all fighters in those times men? reply dplavery92 18 hours agoparentFrom the captioned art in the article: \"Siege, from the Peterborough Psalter, early 14th century, via the KBR Museum, Belgium. Yes, those defenders are all women.\" reply goodpoint 19 hours agoparentprevNo. reply aristofun 19 hours agorootparentoh really, how much evidence do you have about women storming the castles all the way through inside? reply JdeBP 17 hours agorootparentHow much evidence do you have that \"storming the castles\" was how sieges ended at all? Errol Flynn movies are not reality.To quote James Wright, who is an archaeologist:> we know a fair bit about how sieges were ended, and it was never the desperate violent rout on the staircases that is so beloved of Hollywood films.https:&#x2F;&#x2F;triskeleheritage.triskelepublishing.com&#x2F;mediaeval-my... reply hnarn 20 hours agoparentprevSo what? reply howenterprisey 20 hours agoparentprevCan you expand on that? reply aristofun 20 hours agorootparentwhy use (abuse) the word \"person\" then? reply beej71 19 hours agorootparentBecause if you say the \"man\" it implies that women fighters would not have the same advantage, when clearly they would.As since men are people, I&#x27;d argue it&#x27;s not an abuse of language. reply aristofun 19 hours agorootparentagain — in those times women did not fight to get advantage in the first place why not use this to be more precise in the language? reply throwbadubadu 19 hours agorootparentMajority, but not all were men? But why care about that at all and consider it the most striking thing about the article? Even rethinking it 3 times I&#x27;m not sure what you find preciser in this, or how it is not completely irrelevant? reply beej71 16 hours agorootparentprevYou sound pretty sure that women would never be among the attackers, but that seems like a risky bet to me. There are historical accounts of Viking attackers who were women, for example. replyguhcampos 12 hours agoprevFun Fact: the author cites their own book as their main source. reply oh_sigh 21 hours agoprevI wonder if modern spiral staircases but also show the 70&#x2F;30 R&#x2F;L bias as well? reply cushpush 21 hours agoprevReally fun question! Let&#x27;s investigate chirality in all its manifestations, natural and humanmade. reply JdeBP 20 hours agoparentTheodore Andrea Cook did, writing _Spirals in Nature and Art_ in 1903 and _The Curves of Life_ in 1914. Unfortunately, we are here fighting the fallout 120 years later, as xe is the source of this very myth. reply antisthenes 20 hours agoprevUsually if the siege got to the point where attackers were IN YOUR TOWERs, then the next logical step would have been to either surrender or collapse the tower on the attackers to win a tactical victory.I am willing to bet $10000, that the number of sieges won or lost due to a staircase fight between knights is 0.Also I wonder what led to this hypothesis being created in the first place? That&#x27;s a much more interesting question to me. Was it some eccentric historian just inventing it? reply majikandy 20 hours agoprev70&#x2F;30 split sounds like there is a reason even if there isn’t primary evidence to backup the exact reason. Logically attack&#x2F;defence sounds like it works and I was certainly able to imagine that on my first tour of a fort when I was young. reply 221qqwe 19 hours agoparentOr maybe medieval people thought that it&#x27;s easier to climb&#x2F;carry stuff up if the stairs go clockwise (or some other mundane reasons)? Maybe architects just designed it that way because that&#x27;s just how everyone builds castle staircases? Seems much more plausible to me (or at least as plausible..)> I was certainly able to imagine that on my first tour of a fort when I was young.Most people visiting medieval castles probably significantly overestimate the frequency of hand to hand combat that might had taken place there (almost never as far as we know). reply notahacker 20 hours agoparentprevThe scholarly source he links to (which actually agrees with him) notes in passing that for Norman castles, the split wasn&#x27;t 70&#x2F;30, it was more like 95&#x2F;5.... reply bee_rider 20 hours agoparentprevI wonder what the split is nowadays. For example I lived in an apartment that had a counter-clockwise stairway, I’m not sure what the landlord’s handed was was, but I don’t think he designed it around defending against left handed sword-armed attackers. reply OrvalWintermute 18 hours agoprev> Castle builders knew that it didn’t really make a huge difference which way the stairs go, they’re not suitable for fighting at all, neither party has a lot of space to wield those long, pointy, sharp weapons.This is written by someone without experience in hand to hand combat as many weapons were blunt (like a mace or club) and a rondel dagger in an unarmored spot is far more difficult to parry than a sword. Speaking of which, a rondel dagger was specifically intended for grappling situations. Thrusting weapons were in many cases preferred for tight quarters combat although there are slashing weapons specifically designed for tight quarters combat as well. Sword variants like longer greatswords specifically designed vs. halbred or pike formations were not ideal for close quarters, but there were several short sword typesEven in more ancient times, weapons such as the Sica, from which we get the word sicario, were well known as a tool used in gladiatorial combat, and in the Judean wars. Additionally, the gladius wielded with the large shield, the scutum, was only an 18 inch short sword. Short because it was ideal for close quarters fighting via a thrust against other heavy infantry. reply deafpolygon 10 hours agoprevThe simplest explanation is probably that, it was just simply done that way. There&#x27;s no documented explanation why 70% of the staircases are clockwise. There&#x27;s a myriad of things that we do in this world that don&#x27;t have a basis for explanation, other than \"it&#x27;s just simply done that way\". reply im3w1l 21 hours agoprevSomething I would like to know: Do chirality statistics differ between castles and other buildings from the same era? reply sixothree 21 hours agoprevClockwise upward staircases do actually have one advantage (in certain locales). Going upwards your forward travel distance is less than going downwards. This is assuming people generally walk on the right hand side. It just feels easier to traverse stairs as close to the inside as possible. reply Someone 20 hours agoparent> It just feels easier to traverse stairs as close to the inside as possible.I would expect that depends on the design of the spiral staircase.In a spiral staircase, you want to go up about 3 meters in a 360° turn because you need a bit over 2m of headroom and some space for the stair itself.That means that, 1m away from the center of the staircase, the slope will be about 50%. The ideal staircase has more or less “step width + twice the step height = 63cm” [1], so that would give a good step width of 31cm and a step height of 16cm.However, 2m away from the center, that same stair would have a slope of about 25%, and the ideal step would be 41cm wide and 11cm high or thereabouts.3m from the center you’d have a 16% slope, and the ideal step would be 45 cm wide, 8cm high, etc.Now, in ‘standard’ designs [2], step height can’t change with distance to the center, so the designer has to pick one, and thus has control over the distance from the center where it’s easiest to step.[1] https:&#x2F;&#x2F;www.practicalarchitecture.com&#x2F;blog&#x2F;the-geometry-of-a.... Of course, that’s a heuristic, and the ideal will be different for different persons, but what’s important is that simply scaling up a staircase in order to get wider steps is not a good idea.[2] very wide stairs can and sometimes do have steps that are sloping upwards. I don’t think these are non-standard, but can’t think of a better word now. reply Scarblac 19 hours agorootparentI don&#x27;t think spiral staircases generally get even 1m wide, it&#x27;s not trivial for two people going in opposite directions to pass each other. You walk on the middle of the step as there isn&#x27;t much room to the left or right to go to. reply JackFr 20 hours agoparentprevActually more dangerous traveling downward on the inside, where a small misstep will have you miss 2-3 treads, as opposed to the outside where the same misstep won’t have you miss any. reply m463 20 hours agoparentprevI bet there is one way to climb that is easier than the other.Being right-footed, I can do cross-over turns while ice-skating in one direction MUCH easier than the other.However, not sure whether that translates to clockwise or counter-clockwise stairs being easier without trying it.maybe it would be counter-clockwise? Right foot travels further? reply kmoser 15 hours agorootparentI like this theory. Since most people are right-handed, and the right leg does more work than the left when walking up a counter-clockwise spiral staircase, it makes sense that spiral staircases would be designed counter-clockwise. reply afterburner 20 hours agoparentprevI don&#x27;t think there was so much traffic on these stairs that you ended up forced to one side the whole way.The forward distance travelled is also trivial in terms of effort compared to the height displacement upward. Most people can walk for 10 minutes without breaking a sweat, but way fewer would feel fine walking up stairs for 10 minutes.Not to mention, you can simply have a convention that the downward walker on a spiral staircase favour whichever side is best. reply watwut 20 hours agoparentprevWe walk on the right side, because of cars. reply renewiltord 21 hours agoprevA lot of these historic stories are someone&#x27;s fancy. In Turkey, they&#x27;ll make up all these stories about wine flasks in Cappadocia that have this hole in the middle. Supposedly the sun must fall through the hole to bless it or something and I can&#x27;t find any reference to that anywhere. But I wasn&#x27;t able to find a historian of Turkey and that region to say it definitely was ahistorical. reply redwall_hp 21 hours agoprevI&#x27;ll do one better: they weren&#x27;t built clockwise, as clocks were not available. They were built reverse-widdershins or sunwise.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Widdershins reply INTPenis 21 hours agoparentI love the word sunwise. In Swedish it&#x27;s \"medsols\" and \"motsols\", sunwise and counter-sunwise respectively.And speaking of, let&#x27;s start another myth. Swedes always dance around the christmas tree or maypole sunwise because it&#x27;s an ancient dance to evoke the sun after months of darkness. reply kwhitefoot 20 hours agorootparentI thought the pole and dance in Sweden was at midsummer. In England it&#x27;s on Mayday. reply INTPenis 20 hours agorootparentI call it a maypole to relate to foreigners. What would you call the pole? It&#x27;s actually called a midsommarstång, which means midsummerspole... reply headstorm 21 hours agoparentprevDeosil is the counterpart which means reverse-widdershins or sunwise, mentioned in your link. reply kwyjibo1230 21 hours agoparentprevWow, so Widdershins is not just a made-up word from Terry Pratchett&#x27;s Discworld series! reply Tagbert 21 hours agorootparentIt seems it goes back a little further than that.> probably from Middle Low German weddersinnes, literally \"against the way\"https:&#x2F;&#x2F;www.etymonline.com&#x2F;word&#x2F;widdershins#etymonline_v_799...Basically, this is NOT the way. reply redwall_hp 21 hours agorootparentprevI&#x27;ll admit that Discworld is the first place I heard it. It&#x27;s a perfect example of the sort of idiom authors should think about though, rather than using overly modern terms. reply zczc 9 hours agoparentprevAnd clock face mimics the sundial, therefore clockwise is sunwise reply gowld 21 hours agoparentprev&#x27;Tis but thy name that is my enemy;Thou art thyself, though not \"clockwise\".What&#x27;s \"clockwise\"? It is nor hand, nor pen-dulum, nor face, nor any other partBelonging to a clock. O, be some other name!What&#x27;s in a name? That which we call a roseBy any other name would smell as sweet;So \"Widdershins\" would, were it not \"Widdershins\" call&#x27;d,Retain that dear perfection which he owesWithout that title. Widdershins, doff thy name,And for that name which is no part of theeTake all my turns. reply JdeBP 21 hours agoprevIt&#x27;s amusing that the Hacker News reaction so far is to advance alternative hypotheses as to why helical staircases have a predominant chirality, without first establishing, as one should do if one were rigorous, that there is a need for an explanation in the first place, and that this is not, as is suggested in other articles (including one hyperlinked by the headlined one here), just a statistical fluke without significance that doesn&#x27;t need explanation.To put things in modern parlance: A meme, invented from whole cloth by Daily Telegraph writer Theodore Andrea Cook 120 years ago because he liked fencing, was still going strong on Twitter in 2022; and people are still falling prey to believing its assumptions.One has to appreciate the additional irony of the Twitter account actually being named \"history in memes\". reply the_af 21 hours agoparentAgreed! I like that there has to be an explanation. \"Just because\" or \"it&#x27;s the same either way\" aren&#x27;t acceptable. I suppose the internet loves to solve a puzzle (a sentiment I understand and share!). reply YuccaGloriosa 22 hours agoprevI often notice comments made regarding ancient or historical locations and civilisations, when discussed by a historian in a documentary, often seem to be opinions based on pretty flimsy evidence. In some cases no evidence at all, just things could be likely maybe possibly. Relying on the fact that there&#x27;s no written evidence for or against any claim. reply groestl 20 hours agoparentAlong these lines, a well established rule in Archaeology: \"Was man nicht erklären kann, sieht man gleich als kultisch an\" (what cannot be explained, is immediately perceived as religious) reply pc86 20 hours agorootparent\"That is either an incense dispenser, or a ceremonial ... sarcophagus.\"\"My German is pre-industrial, and mostly religious.\" reply duxup 21 hours agoparentprevI love me some history information, documentaries, and etc. But yeah I get strongly allergic to stuff where suddenly I wonder \"Wait did you just logic that out in your head? Like there&#x27;s no basis for that other than you observing how the thing &#x2F; situation is?\"I&#x27;m sure it has been an issue forever but online especially it seems painful how much of that information there is. reply alexpotato 21 hours agorootparentMy favorite version of the logic it out:\"People asked me if this tribe was originally from this area or if they migrated here.I always say: clearly they were from here. The weather is so bad around these parts, who would choose to move here from somewhere else?\"- German historian reply bobthepanda 21 hours agoparentprevEven if there is written evidence, nearly all past written information is also difficult to verify, and writers in the past were not necessarily unbiased or above lying and distortion. reply wnissen 21 hours agoparentprevYes, it would take not just a real historian, but someone who had done research, to answer this question. Having been up and down a few of those, it certainly seems more than just plausible to me, even taking into account the numerous recorded sieges. On the other hand it is also true that spears and shields play a much greater role than swords. Hard to imagine wielding a full-sized shield, let alone a spear, in one of those staircases, though! reply Analemma_ 21 hours agorootparentI think the bigger point from the article is that by the time people are fighting hand-to-hand in the tower stairwells, the defenders have already well and truly lost: comeback from such a state was probably impossible (and if the walls were breached the defenders would almost certainly have surrendered rather than fought to the last man). So it wouldn&#x27;t have really made sense to design things for this possibility. reply ramblenode 21 hours agorootparentThat&#x27;s not a good counter-explanation.A castle staircase takes a lot of time and effort to build. Choosing to build the staircase in one direction or the other has negligible cost. If there is even a slight or possible advantage to one direction then it would make sense to build it that way.Defense in depth. reply prewett 20 hours agorootparentAny defenders defending a tower are obviously above the ground floor, which is where access to food and water is. So why bother fighting up the stairway, when you can just block all the downstairs exits? The castle&#x27;s defenses are the walls; if attackers are in a position to go up the stairs then the castle&#x27;s defenses have failed, and the only defense left is the manpower of the defenders. So instead of being \"besieged\" up their towers, the only realistic strategy the defenders have is to come down from the towers and join the melee. Or just surrender, because the attackers have an army and the castles only had dozens of defenders (if that). What tactical situation do you have in mind where the success of the attack depends on success in a staircase battle? reply ramblenode 20 hours agorootparentDefense in depth isn&#x27;s about justifying in advance how every measure will win the battle; it&#x27;s about giving yourself as many small, incremental advantages as possible so that the odds steadily tick up in your favor. Battles are famously difficult to predict so every advantage is sought, and even small advantages can have multiplier effects. reply wongarsu 20 hours agorootparentprevEvery day the attackers besiege you is one they have to defend against potential counterattacks from your allies. And even if your castle falls you might buy your empire time to raise a bigger army and rally more allies in order to win the next bigger war. Delaying enemies could be an important function of castles. reply Tao3300 20 hours agorootparentprevIt&#x27;s a really good explanation. Castle sieges were big events, so historically we know the outcomes. Nearly 100% of the time, the garrison has already surrendered if it&#x27;s this bad. Medieval sieges come in three major flavors: ones where you sneak in, ones where you bombard the fortification, and ones where you don&#x27;t let anything in or out and you wait until they give up. reply ramblenode 20 hours agorootparentIf you examine a military you will find volumes of plans for incredibly unlikely situations. Once you have addressed all the likely and significant threats, you don&#x27;t just stop planning--at least not any good military.Saying that castle sieges didn&#x27;t tend to involve stairway fights doesn&#x27;t imply that stairways wouldn&#x27;t have had defensive measures built in. That is post-hoc rationalization. reply 221qqwe 20 hours agorootparent> That is post-hoc rationalization.You&#x27;re asking to a disprove a purely(?) speculative claim, though. reply the_af 21 hours agorootparentprev> If there is even a slight or possible advantage to one direction then it would make sense to build it that wayIf it&#x27;s true that the battle at this point is lost for the defenders -- and known history indicates this is so -- then why would the builders choose directions based on this extremely unlikely scenario, instead of on just about any other consideration (aesthetic, practical, or even random)? reply lazide 20 hours agorootparentWhy does the USMC issue bayonets still? reply qwytw 20 hours agorootparentBecause it&#x27;s a multi-purpose utility knife that can also optionally be mounted on a rifle?Having a knife might be useful in various situations even outside combat as far as I know. reply the_af 20 hours agorootparentprevI&#x27;ve honestly no idea.I&#x27;ll take a stab at guessing (mind you, this is blind guessing, happy to be corrected!): the USMC still issue bayonets because of both tradition, which is important to the military, and also because they are actually useful in close quarters battle, which still occurs on occasion, such as in urban warfare and house-to-house combat clearing, etc. The likelihood of having to use a bayonet&#x2F;knife in modern CQB is probably significantly higher than the likelihood of medieval defenders recovering from an enemy army that has stormed their castle. reply CydeWeys 20 hours agorootparentprevAn interstate takes a lot of time and effort to build. And yet which side you drive on doesn&#x27;t matter; it simply needs to be consistent with all the other roads you&#x27;re connected to. There are plenty of countries that, through historical happenstance, drive on the opposite side of the road, and it&#x27;s fine.So in other words, just because the staircases take a lot of time and effort to build, simply means that having the staircase itself is important, not necessarily that its chirality is important. It has to have a chirality but it may well not matter which one, just like roads. reply ramblenode 20 hours agorootparentYour example misses the point.If there were evidence that driving on the right side or left side of the road slightly reduces car accidents and a country with previously no roads or cars began planning to automotize the country, then, all things considered, it would make sense to have people drive in the lane with a slightly reduced fatality rate.If there are two choices where one presents a slight advantage but no additional cost then a rational actor will go with that choice. reply qwytw 19 hours agorootparentThe event has to occur relatively frequently for that slight advantage to become statistically noticeable. Direct assaults on castles with hand-to-hand combat occurring in stairwells were extremely rare as far as we know. reply notahacker 20 hours agorootparentprevYeah.For perspective, Norman keeps were often built with a large internal cross wall, so even if troops made it through the stair door and swarmed into the room they&#x27;d still have to fight their way into the other half of the floor. By the stage these expensive and space consuming walls were defensively relevant, defenders would have already lost outer walls, viable long-term food and water supplies and much of the garrison defending it... and any real chance of holding out. But an invading army would still lose more men storming it; so it functioned as a deterrent.I&#x27;ve heard this \"it&#x27;s a myth\" argument before, but 70% of staircases is quite a large proportion of staircases spiralling in a particular direction which would offer the defender a marginal advantage to be pure coincidence. Particularly when the ratio of clockwise to anticlockwise staircases in Norman castles was about 20:1; it was later generations of castle of builders who added many more anticlockwise stairwells, in an era when individual tower defence was less importance, and builders may have simply forgotten or come to doubt arguments about the defensive advantages of clockwise spirals (the blog&#x27;s arguments for why spiral staircase defence is rubbish work here of course!). Contemporary cathedrals which were not at all defensible tended to build clockwise and anticlockwise spiral staircases as matching pairs, so it wasn&#x27;t like there was some other sort of massive aversion to stairs in a particular direction. reply gowld 21 hours agorootparentprevWhere&#x27;s the contemporary research to determine which direction has advantage? reply Cass 20 hours agorootparentprevThat&#x27;s a bizarre line of thought to me. If you build an expensive structure for fortification, you don&#x27;t usually get to the interior design and then go \"Oh fuck it, this extra safety measure wouldn&#x27;t cost anything, but if they&#x27;ve got this far we might as well surrender, so let&#x27;s not bother.\"Going by that logic, the president&#x27;s bunker under the pentagon would&#x27;ve been built without a lock. After all, people don&#x27;t usually have to physically drag a country&#x27;s leader out of their locked bunker, right? By the time anyone&#x27;s knocking on that door, usually the war is lost and the country has surrendered.And yet, if you&#x27;re designing for defense, why NOT take such a cheap and easy countermeasure as putting a lock on the door or choosing the more defensible way to spiral your staircase? You might want to buy a few more minutes to negotiate in a desperate situation; you might want at least the option of taking that futile last stand; you might be facing not an invading army but a single lunatic with a sword who snuck past the outer guards. reply whiw 19 hours agorootparentprevI imagine that it would be more difficult to gain entry to an upper floor (at the top of a narrow staircase so single-file attackers) and a sturdy door with a couple of guards outside, than it would be to gain entry to rooms on the same level. Perhaps the women were tucked away on the upper floors, in relative safety. reply jvanderbot 21 hours agorootparentprevThis comment is a perfect example of GGP&#x27;s problem with historical analysis.As is the nearly-exactly comment in TFA:> Frankly, if you find yourself in this position the castle is probably already lost.It&#x27;s conjecture all the way down. reply qwytw 19 hours agorootparent> It&#x27;s conjectureJust like the entire staircase argument?Except that we actually know that:> Frankly, if you find yourself in this position the castle is probably already lost.Was true in almost all cases. reply Tao3300 21 hours agorootparentprevFighting on the stairs would be kinda silly. Better to wait outside the doorway so that after your attackers are done running up the stairs with armor and weapons, you and your pals are waiting there at the choke point to layeth the smacketh down. The only real benefit to fighting on the stairs is that you still effectively impede progress if you&#x27;re dead. reply the_af 21 hours agorootparentExactly, fighting on the stairs is pointless.If you are the attacking army, just wait it out. You&#x27;ve won the siege, and any defenders up the stairs will have to either come down or starve to death. Why risk attacking up the stairs? reply vidanay 21 hours agorootparentIf you&#x27;re at the bottom of the stairs, stuff the stairs full of firewood (tables, chairs, dressers, etc) and light it. reply CydeWeys 20 hours agorootparentYeah, just burn&#x2F;smoke out the defenders. If you&#x27;re already in the bottom of the building it&#x27;s over, just a matter of time when. You can also take the castle apart and cause it to collapse. reply dylan604 21 hours agorootparentprevwhat happens if you&#x27;re running down the stairs and come upon the attackers on the way down? reply the_af 21 hours agorootparentDie? Surrender? If attackers have stormed the castle and are running up the stairs all is presumably lost anyway? reply dylan604 21 hours agorootparentIf Errol Flynn could do it, then surely, everyone can do it reply the_af 21 hours agorootparentIt&#x27;s safe to assume if Errol is on your side, you&#x27;ve won. reply dylan604 20 hours agorootparentBut this goes against if you&#x27;re down to defending in the stairwells, you&#x27;ve already lost. reply the_af 20 hours agorootparentLet me fix it: if you are going down but you do not have Errol in your ranks, you&#x27;ve lost? replycatlover76 20 hours agoparentprevA lot like evolutionary psychology; it seems like a reasonable explanation or story and is supported by at least some circumstantial evidence, so it must have been the way things were reply kibwen 21 hours agoparentprevAccording to the OP, there is written evidence for it, from the Victorian era, which was 400 years after cannons made castles obsolete. It&#x27;s hard to fault modern historians too much if they&#x27;re simply trusting the old records to be accurate. Or as we say in computer science: garbage in, garbage out. reply pmichaud 21 hours agorootparent> It&#x27;s hard to fault modern historians too much if they&#x27;re simply trusting the old records to be accurate.Basically the entire job of a historian is to determine the credibility of old sources, so they can interpret all the data and come to the most accurate conclusion about what happened. reply 221qqwe 19 hours agorootparent> credibility of old sourcesUnsubstantiated conjecture by Victorian historians shouldn&#x27;t really be treated as a \"source\" in the first place by actual historians. reply gwern 21 hours agorootparentprevIf you click through, you can see there&#x27;s no &#x27;evidence&#x27; there. He simply offhandedly, in a sentence or two, makes the same speculation about fighting, with no sources, and the whole discussion of staircases in general is based on only 2 named examples. Chesterton&#x27;s fence is satisfied: he knew no more than we did. reply JdeBP 17 hours agorootparentprevA few points.Theodore Andrea Cook wasn&#x27;t a historian. Xe was a writer for t",
    "originSummary": [
      "The assertion that medieval staircases were primarily clockwise for defense purposes is a myth with no supporting evidence from medieval sources.",
      "This misconception could have stemmed from a theory introduced by Sir Theodore Andrea Cook in the 19th century, but it doesn't align with an understanding of medieval combat and the practicality of fighting on spiral staircases.",
      "The direction of these staircases was probably influenced by factors like architectural functionality, customs, and space availability, rather than strategic considerations."
    ],
    "commentSummary": [
      "The dialogue revolves around the controversial subject of the clockwise direction of medieval castle staircases, with some supporting it as a strategic defensive move while others contradicting it.",
      "Determining factors like accommodating right-handed fighters and space constraints may have influenced the staircase direction, but more research is necessary for a comprehensive understanding.",
      "The conversation extends to areas such as siege tactics, castle architecture, and historical events. However, there is a discernible lack of incontrovertible evidence and diverse perspectives to support one or another viewpoint."
    ],
    "points": 288,
    "commentCount": 275,
    "retryCount": 0,
    "time": 1696872054
  },
  {
    "id": 37829926,
    "title": "Fair coins tend to land on the same side they started",
    "originLink": "https://arxiv.org/abs/2310.04153",
    "originBody": "Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate > math > arXiv:2310.04153 HelpAdvanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search Mathematics > History and Overview [Submitted on 6 Oct 2023] Fair coins tend to land on the same side they started: Evidence from 350,757 Flips František Bartoš, Alexandra Sarafoglou, Henrik R. Godmann, Amir Sahrani, David Klein Leunk, Pierre Y. Gui, David Voss, Kaleem Ullah, Malte J. Zoubek, Franziska Nippold, Frederik Aust, Felipe F. Vieira, Chris-Gabriel Islam, Anton J. Zoubek, Sara Shabani, Jonas Petter, Ingeborg B. Roos, Adam Finnemann, Aaron B. Lob, Madlen F. Hoffstadt, Jason Nak, Jill de Ron, Koen Derks, Karoline Huth, Sjoerd Terpstra, Thomas Bastelica5, Magda Matetovici, Vincent L. Ott, Andreea S. Zetea, Katharina Karnbach, Michelle C. Donzallaz, Arne John, Roy M. Moore, Franziska Assion, Riet van Bork, Theresa E. Leidinger, Xiaochang Zhao, Adrian Karami Motaghi, Ting Pang, Hannah Armstrong, Tianqi Peng, Mara Bialas, Joyce Y.-C. Pang, Bohan Fu, Shujun Yang, Xiaoyi Lin, Dana Sleiffer, Miklos Bognar, Balazs Aczel, Eric-Jan Wagenmakers Many people have flipped coins but few have stopped to ponder the statistical and physical intricacies of the process. In a preregistered study we collected 350,757 coin flips to test the counterintuitive prediction from a physics model of human coin tossing developed by Persi Diaconis. The model asserts that when people flip an ordinary coin, it tends to land on the same side it started -- Diaconis estimated the probability of a same-side outcome to be about 51%. Our data lend strong support to this precise prediction: the coins landed on the same side more often than not, , 95% credible interval (CI) [ , ], . Furthermore, the data revealed considerable between-people variation in the degree of this same-side bias. Our data also confirmed the generic prediction that when people flip an ordinary coin -- with the initial side-up randomly determined -- it is equally likely to land heads or tails: , 95% CI [ , ], . Furthermore, this lack of heads-tails bias does not appear to vary across coins. Our data therefore provide strong evidence that when some (but not all) people flip a fair coin, it tends to land on the same side it started. Our data provide compelling statistical support for Diaconis' physics model of coin tossing. Subjects: History and Overview (math.HO); Data Analysis, Statistics and Probability (physics.data-an); Other Statistics (stat.OT) Cite as: arXiv:2310.04153 [math.HO](or arXiv:2310.04153v1 [math.HO] for this version) https://doi.org/10.48550/arXiv.2310.04153 Focus to learn more Submission history From: František Bartoš [view email] [v1] Fri, 6 Oct 2023 11:00:15 UTC (138 KB) Access Paper: Download PDF PostScript Other Formats Current browse context: math.HOnewrecent2310 Change to browse by: math physics physics.data-an stat stat.OT References & Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Demos Related Papers About arXivLabs Which authors of this paper are endorsers?Disable MathJax (What is MathJax?) About Help Contact Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack",
    "commentLink": "https://news.ycombinator.com/item?id=37829926",
    "commentBody": "Fair coins tend to land on the same side they startedHacker NewspastloginFair coins tend to land on the same side they started (arxiv.org) 285 points by fbartos 6 hours ago| hidepastfavorite177 comments jbandela1 5 hours agoVon Neumann described a very elegant way to get fair results from a biased coin.1. Flip the coin twice2. If you get the same result both times, goto 13. Now that you have different results for your pair of flips, use the first element of the pair of flips as your result.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_coin#Fair_results_from_a_... reply ChocMontePy 4 hours agoparentIf anyone wants to test it, someone wrote a short code that simulates doing that 100,000 times:https:&#x2F;&#x2F;www.techiedelight.com&#x2F;generate-fair-results-biased-c...The coin is biased to come up TAILS 80% of the time, but using Von Neumann&#x27;s method in the program I got HEADS 50.035%, TAILS 49.965%. reply 098799 3 hours agorootparentWhy would you test it?Probability of two heads: p*pProbability of two tails: (1-p)*(1-p)Probability of head followed by tails: p*(1-p)Probability of tails followed by heads: (1-p)*pIt&#x27;s not difficult to notice that if you remove the first two, the last two form a 50&#x2F;50 distribution reply cantrevealname 2 hours agorootparent> Why would you test it?I recall conversations on Usenet decades ago about the Monty Hall problem[1] in which people gave elementary proofs that probabilities don&#x27;t change by opening a door. Even from mathematicians and statisticians. People were very insistent that the analytical solution was simple and obvious and that switching doors didn&#x27;t change anything.The only thing that changed some people&#x27;s minds was a program that simulated the Monty Hall problem. This was needed to get people to reconsider their proof when the claim was highly counterintuitive.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Monty_Hall_problem reply bscphil 3 minutes agorootparentI think the great advantage of \"simulation\", for the programming-literate, is not that you can simulate your way to a correct answer, but that the process of creating a simulation is likely to show you the error in your reasoning.As a young teenager, I encountered the Monty Hall problem for the first time, and I didn&#x27;t believe that the \"analytical\" answer was correct. I decided to simulate it by programming. In the 20 minutes it took me to write a simulation, I went from complete incomprehension to a full understanding of why I got the results I got. Programming a simulation of the problem forces you to write out the algorithmic significance of \"Monty reveals one of the goats\". reply I_Am_Nous 2 hours agorootparentprevThe Monty Hall Problem is a fun one because you can try to approach it from a purely analytical perspective and get one answer, while incorporating the whole situation (especially the fact that the final probability is not natural as they force the final decision into far fewer doors than originally present) and testing you can find a different answer entirely.I suppose this is an interesting corollary with discoveries made by deep theoretical mathematics. While something may seem possible because \"the math checks out\" it could be only theoretically possible as it relies on some unnatural value to \"be\" possible in the first place.Testing is where hopeful theories are smashed by reality until all that remains is the verifiable truth. Truly, why wouldn&#x27;t we test? reply pmontra 1 hour agorootparentThat&#x27;s how it went when I was solving problems at the Statistics course at university. I modeled the problem perfectly, got the wrong result. Changed assumptions, got the wrong result. Checked the solution, its reasoning didn&#x27;t make much sense anyway. Run a simulation, got an approximate result close to the correct solution. reply naniwaduni 1 hour agorootparentprevFundamentally, the trouble with the Monty Hall problem isn&#x27;t that analysis comes to the wrong answer, it&#x27;s that people often come to the wrong model when reasoning about it informally.It&#x27;s not any harder to do the \"correct\" analysis than to write up a simulation. It&#x27;s mostly just easier to convince yourself that the simulation matches the problem description when it reaches the unintuitive result. reply 4star3star 37 minutes agorootparentprevThe way the problem makes sense to me is this.Doors: Goat Goat CarYou pick a door. Monty shows you a Goat. You switch or stay.Monty will never show you the Car before offering a switch. He always shows you a Goat. It doesn&#x27;t matter which Goat he shows you - it&#x27;s just \"not the Car\".If your first choice is a Goat, switching will win you the Car. If your first choice is a Car, switching will win you a Goat. You have a 2&#x2F;3 chance of picking a Goat, so, effectively, you want to pick a Goat so that you switch to the Car. reply tacitusarc 8 minutes agorootparentFor sufficiently analytical folks that works, but for lay people it tends to still be confusing.The best way I’ve heard it explained to help people get it through intuition is by changing the number of doors and goats. Say there are 100 doors, and they all have goats except one, which has a car. You pick door 1. Monty then proceeds to open doors 2 through 48, skips door 49, and then opens the remaining doors. After all that, he stops and asks you, would you like to switch? reply thaumasiotes 3 minutes agorootparentThere&#x27;s a better way to think about it.1. You pick a door.2. You get the offer \"Do you want to keep that door, or choose both [all] of the other doors? In either case, you&#x27;ll keep anything that isn&#x27;t a goat.\"3. Nobody opens any doors.Should you keep your one door, or switch to the two doors? jackfoxy 34 minutes agorootparentprevThe Monty Hall problem is a fun one to code up, and yeah, there are otherwise smart people who refuse to believe it.I coded it up in F# https:&#x2F;&#x2F;github.com&#x2F;jackfoxy&#x2F;LetsMakeADeal to convince one of the founders of a start-up I worked for. He just grunted and walked away. Pretty sure he still doesn&#x27;t want to hear about Bayes&#x27; Theorem. reply dfxm12 1 hour agorootparentprevThe Monty Hall problem is especially unintuitive if you&#x27;ve ever watched Let&#x27;s Make a Deal, since the problem set up is oh so close to, but not exactly, the set up of the Big Deal in the show. It&#x27;s too easy to conflate the rules of the show with the math problem, which will lead to confusion.I think seeing the results of a simulation also elucidates the set up of the math problem vs reading a proof. reply chankstein38 1 hour agorootparentprevThis was how I built an intuition into the Monty Hall problem as well! Wrote a little app that simulated it a decade or so ago when I was discussing with friends! reply CuriouslyC 1 hour agorootparentprevYou can demonstrate the Monty Hall problem solution analytically with Bayesian statistics using prior probabilities, no need to go all the way to Monte Carlo methods. reply TOMDM 1 hour agorootparentAs a proof the math is entirely sufficient, but for those who may struggle with it the simulation is persuasive. reply selimthegrim 1 hour agorootparentprevThis was how I convinced someone (RIP) by really stressing every element in the definition of Bayes’ theorem and probability space. reply bob88jg 3 hours agorootparentprevWhy would you not - analytical solutions are the rare occurrences might as well approach everything with simulation... reply kqr 3 hours agorootparentWhile I agree we should leave the correct answer to simulation, analytical approximations are often surprisingly close and have the benefit of being intuition-building. reply CuriouslyC 1 hour agorootparentprevYou learn a lot more from generating an analytical solution than a simulation, so it&#x27;s usually worth at least taking a stab at it analytically before jumping to monte carlo methods. reply taway_6PplYu5 3 hours agorootparentprev(preface with \"in today&#x27;s world\") reply nofinator 49 minutes agorootparentprevIronically, this reminds me of a story (folk tale?) about Von Neumann himself.A colleague told him about the Two Trains Problem (https:&#x2F;&#x2F;mathworld.wolfram.com&#x2F;TwoTrainsPuzzle.html), and Von Neumann replied with the correct answer. When his colleague said, \"Ah! You figured out he trick!\", Von Neumann replied, \"What trick? I just summed up the distances in my head!\" reply sidkshatriya 3 hours agorootparentprevThe thing about math is that you can do things in multiple ways.Theory is useful but so is experiment. reply gorjusborg 2 hours agorootparentprev> Probability of two heads: pp > Probability of two tails: (1-p)(1-p) > Probability of head followed by tails: p(1-p) > Probability of tails followed by heads: (1-p)p > > It&#x27;s not difficult to notice that if you remove the first two, the last two form a 50&#x2F;50 distributionVery nice way to illustrate why throwing out the duplicate sequences gets back to a 50&#x2F;50 distribution. reply voidfunc 3 hours agorootparentprevSome of us suck at math. reply williamstein 2 hours agorootparentMath is often much more fun and compelling for some people when you both theoretically prove something works and then also convince yourself of the same thing via a numerical experiment. I’m pretty good at math proofs (pure math PhD, wrote some books and papers), but I still love to do numerical experiments. It’s fun, and you also set yourself up to be able to easily ask different questions that may be very hard to answer theoretically. reply foobarian 2 hours agorootparentFor me it&#x27;s a case of, \"see, what I do is powerful after all!\" after a 5 minute analytical proof matches 3 hours of simulation work. :-) reply HideousKojima 2 hours agorootparentprevAlso certain unintuitive things in math&#x2F;statistics (like the Monty Hall problem) because a lot clearer when you write up a quick simulation. reply User23 2 hours agorootparentprevSome of you might have just suffered from poor math education. I don&#x27;t believe anyone capable of learning to program competently lacks the cognitive horsepower to do math competently with more or less equivalent ease. Many do however lack the training. reply BurningFrog 44 minutes agorootparentprevYou&#x27;re of course right, but maybe 1% of the population understands that, while 100% understands the practical test. reply jszymborski 39 minutes agorootparentprevSome folks have more faith in their ability to derive proofs than write simulations and vice-versa. reply toxik 3 hours agorootparentprevI think about it this wayp(th) = p(t) p(h)p(ht) = p(h) p(t)Hence p(th) = p(ht) regardless of coin imbalance as long as both events actually will happen. QED. reply someone7x 2 hours agorootparentprev> Why would you test itIs this a wrong way to get a right answer? reply skrebbel 1 hour agorootparentprev> It&#x27;s not difficult to notice thatLook I found the mathematician reply chaorace 1 hour agorootparentprevWow. As usual, Von Neumann makes it look easy reply dfxm12 1 hour agorootparentprevYou should change your name to ChocMonteCarloPy :) reply mewpmewp2 5 hours agoparentprevThat&#x27;s amazing, but I guess it won&#x27;t help when the person can choose the bias?Because according to the study the person can choose the bias by choosing which side start up.So if the person wants tails based on what you&#x27;ve said, they should always1. Do the first throw starting tails up.2. If the first one is tails, then they now want to start second one heads up.3. If the first one is heads, they will want to try and get heads again to dismiss the results. So they will do heads up.So assuming for example that they have an ability to control bias 75% vs 25%.Then there would be 75% chance of getting first as tails. After that 75% chance of getting heads.So they will have 56.25% chance of getting it right the first 2 rounds.The worst case for them would be if they get heads first (25% chance), and then are unable to get heads again. Which would be another 25% chance so 6.25% odds to lose with the first round.So 56.25% chance of winning the first round of 2, or 6.25% losing and 37.5% of having to try again.And I think the odds would converge at somewhere around 90% to 10%. I didn&#x27;t do full calculations here, but overall it seems this strategy would increase the bias even more. reply kqr 5 hours agorootparent> That&#x27;s amazing, but I guess it won&#x27;t help when the person can choose the bias?Alice writes on a piece of paper whether to use the result from the first or the second coin, Bob flips the coins however he likes, then once there are two different sides of the coins up, Alice turns over the paper and reveals to Bob which coin contains the result.Though I guess that unnecessarily complicates the procedure – maybe Alice can just write \"heads\" or \"tails\" on a note and then Bob flips without having seen the note. It essentially replaces the second coin with Alice&#x27;s mind which hopefully doesn&#x27;t suffer from the same known bias. reply sebzim4500 4 hours agorootparentIf you&#x27;re going to go that way you can skip the coin flip entirely. Just get both of them to write heads or tails on a note and then compare. This technique is used in some crypto projects, except instead of writing on a note you share cryptographic commitments. reply mewpmewp2 3 hours agorootparentBut they need to remove the possibility of a psychological guessing game. E.g. Bob could&#x27;ve researched before hand that people are 55% likely to pick heads if they can pick by themselves. reply arijun 3 hours agorootparentThat doesn’t remove the possibility of a psychological guessing game, just makes it more convoluted. If Bob knows Alice will pick first, he can still bias the results. reply CuriouslyC 1 hour agorootparentInconceivable! reply kibwen 4 hours agorootparentprevAt this point you can just play odds and evens: one person picks odd, the other picks even, they both hold up either one or two fingers behind their back, reveal them at the same time, then sum the result. This prevents the randomness from being in any one actor&#x27;s control. If you&#x27;re worried that your brain&#x27;s RNG can be gamed, then put an odd-denominated coin in one hand and an even-denominated coin in another, and mix them up so that even you don&#x27;t know which hand has which. reply mewpmewp2 3 hours agorootparentWe still need a study then to confirm that when people try to mix the coins in their hands like that, it would be random enough. And that would take another year... reply mewpmewp2 5 hours agorootparentprevSuppose Alice needs to take the coin first to herself, to use the aforementioned strategy without intentionally introducing bias, and then using result of that, which would determine whether the first or the second result from Bob would be used. Because otherwise Bob may be able to make psychological \"guesses\". reply amluto 2 hours agorootparentprevThere are nice protocols like this that don’t require anyone to visibly flip a coin. See, for example:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Commitment_scheme reply wesleychen 5 hours agorootparentprevYou can solve this easily by always flipping with the same side (doesn’t matter which) facing up for all flips. reply havnagiggle 5 hours agorootparentThere is skill to coin flipping. You&#x27;d need to blind the flipper, either physically blindfold or make it so they don&#x27;t know which result is the positive outcome ahead of time. reply bee_rider 1 hour agorootparentOr ask the competitors to flip the coin in a manner they doesn’t allow for skill, like put it in a Yahtzee cup and toss from there. reply mewpmewp2 5 hours agorootparentprevUnless they can also introduce bias using strength&#x2F;technique of the throw. reply asimpletune 1 hour agorootparentprevBut wasn&#x27;t the bias in the paper something like 50.5% vs 49.5%? reply Retric 4 hours agorootparentprevThe final calculation is easy 56.25&#x2F;(56.25 + 6.25) = 90%, unless the persons skills change between rounds or something. reply mewpmewp2 3 hours agorootparentYeah, thought so as well, interesting how easily those numbers worked out, but then again it&#x27;s because 75&#x2F;25=3 and 3x3 = 9 so the final difference must be 9x between the probabilities or 100 &#x2F; (9 + 1).I was still lucky with the numbers as for example with 80% vs 20% it would&#x27;ve been 4x4=16 and so 1 to 16 comes to 100 &#x2F; 17. reply thaumasiotes 1 minute agoparentprevThat only works if the result of the coin is independent of whatever it showed on the prior flip.(You might say \"of course it is!\", but if that&#x27;s your approach to the problem, you should be aware that biased coins don&#x27;t exist...) reply k7sune 12 minutes agoparentprevHow come when the results are the same you have to go to 1 and flip twice again? Can you just toss another one and use the last two results? reply ctenb 3 hours agoparentprevThat&#x27;s really cool. The key insight is that \"The reason this process produces a fair result is that the probability of getting heads and then tails must be the same as the probability of getting tails and then heads, as the coin is not changing its bias between flips and the two flips are independent.\" So you have to make sure you always start with the same side up. reply aidenn0 37 minutes agoparentprevThat is only guaranteed to work if subsequent tosses are independent of each other. TFA suggests that they are not.[edit]If you always start with the same side of the coin face-up, then the tosses will be independent of each other, but if you e.g. always flip it once or always keep it the same before the next toss, then they are not. reply elijaht 33 minutes agorootparentTFA does not suggest that. Even if a coin is biased towards the side it started on, this wouldn’t carry over from one flip to the next.It would be important to start the flip on the same side, but that’s doesn’t make the second flip dependent on the first reply dentalperson 5 hours agoparentprevI love the math&#x2F;stats history around gambling-related things, thanks for mentioning this. This method assumes the flipper can&#x27;t introduce bias. ET Jaynes in his book Probability Theory also mentions that it is easy to learn to flip a fair coin in such a way that the result can be predetermined. I searched a tiny bit for this but couldn&#x27;t find what he was referring to though. reply ryanar 4 hours agorootparentLots of practice, use your thumb to hit the edge of the coin to give you more control, aim for a specific spot so you use the same amount of force and control the amount of times it flips. You can also use a surface that absorbs more so the coin is less likely to flip after hitting it. reply aspenmayer 4 hours agorootparentprevI’ve heard that, with many hours of practice, dedicated amateurs and many famous magicians are able to do this kind of thing. I wouldn’t call it sleight of hand, but it is similar, although it may fall under that category broadly. I’m not a domain expert but I was taught some simple coin tricks as a child by my artist mom’s artist friend who ran the local frame shop. I never tried or thought to try to favor the coin flip or introduce bias, but it’s definitely a skill that can be acquired. reply kqr 2 hours agorootparentI remember at one point in my childhood learning a trick where it looks like you&#x27;re flipping the coin, but you&#x27;re really only causing it to rotate and wobble, meaning it&#x27;s guaranteed to land on whatever side faced up as you tossed it. I don&#x27;t remember how I did it though, and a few minutes of trying to recreate the effect has failed. reply 1980phipsi 3 hours agoparentprevYou can load a dice, but you can&#x27;t bias a coin: http:&#x2F;&#x2F;www.stat.columbia.edu&#x2F;~gelman&#x2F;research&#x2F;published&#x2F;dice... reply vikingerik 1 hour agoparentprevAlso interestingly, this extends beyond a two-sided coin, to any number of possible results, like a die with N sides.To get a fair result from a biased dN: Roll it N times. If you don&#x27;t get all N distinct results, restart. If you do, then the first of those is your final result. reply nullc 10 minutes agoparentprevThe VN debiaser is very simple but it&#x27;s not very efficient-- it loses a lot of your randomness.Under the same IID assumption you can take N flips that returned M heads and map them to the N choose M possible ways that could have happened. The result will (under IID assumption, even in the presence of bias) be a uniform number on the range [0..N choose M). The ctz(N choose M) trailing bits can be used directly (as they will be uniform) but the rest would have to be converted to binary via something like an arithmetic coder or rejection sampling.The result is muuch more efficient.Less directly, VN debiasers can also be stacked. Each debiaser outputs three streams: the normal one, one that says if the normal one output anything, and one that says if it got HH or TT. Then run VN debiasers on those. Though it takes a fairly large tree to extract most of the entropy. reply dataflow 3 hours agoparentprevI&#x27;m confused, how does this help? If coins are biased to land same-side up, then don&#x27;t I always have an advantage by guessing whatever side is up before the first throw? reply kqr 2 hours agorootparentI see what you&#x27;re getting at, and it&#x27;s subtle! To simplify the discussion, let&#x27;s assume we always start out with heads up.You&#x27;re right that the first coin is more likely to end up heads. But so is the second coin, and if both occur, that would invalidate the pair of tosses. Now, imagine you guessed tails despite the coin starting on heads. If the first toss lands tails, the second coin is still more likely to land heads, which keeps the pair valid.In other words, whatever you gain by guessing the side that&#x27;s up on the first coin, you lose on account of the second coin having that same higher probability of invalidating the pair.----Using extreme numbers, in case that makes it more clear: imagine a coin that has a 99 % probability of ending up with the same side we start with, and – for simplicity of exposition – we always start with heads facing up before the toss.If you guess heads, and the first coin lands heads, then there is a 1 % chance that you win, namely that when the second coin lands tails.If you guess tails, and the first coin lands tails, then there is a 99 % chance that you win, namely that when the second coin lands heads.The two outcomes of the first coin (99 % and 1 % respectively) perfectly balance out the two valid outcomes of the second coin. reply dataflow 2 hours agorootparentAh fascinating! Thank you! reply jpeterson 3 hours agorootparentprevThe probability of [HEADS, TAILS] is always the same as the probability of [TAILS, HEADS], no matter how the coin is weighted. reply dataflow 3 hours agorootparentI get that but I don&#x27;t see how it answers my question? reply arrowsmith 1 hour agorootparentYou&#x27;re flipping pairs of coins until you get either \"HT\" or \"TT\". So the only two possibilities are:1. keep flipping until you get HT (and so you choose &#x27;heads&#x27;) 2. keep flipping until you get TH (and so you choose &#x27;tails&#x27;)Since HT and TH are equally likely, results 1 and 2 are equally likely, i.e. there&#x27;s a 50% chance of choosing heads, 50% change of choosing tails. reply arkitaip 5 hours agoparentprevI absolutely love that even with a corrupted system you can use properties of the system to ensure just outcomes. reply sph 5 hours agorootparentThis works only if the bias is constant&#x2F;independent of the result of the previous flip. reply mnw21cam 2 hours agorootparentprevhttps:&#x2F;&#x2F;www.giantitp.com&#x2F;comics&#x2F;oots0327.html reply wslh 2 hours agoparentprevWith all due respect to Von Neumann, intuitively I would change it to use the information in the two coins: one for (X, Y) and another for (Y, X). Not the first. reply Schiphol 1 hour agorootparentYes, and as the second coin carries no information (because we are focusing now on sets of two different consecutive outcomes) both your and JvN&#x27;s protocols are equivalent. reply m3kw9 3 hours agoparentprevFlip till I get the side I wanted reply bryanrasmussen 4 hours agoparentprevok but if the coin tends to land as starting then1. starting from heads2. flip heads3. flip heads4. starting from heads5. flip heads6. flip tailstake 5 = heads?heads should still be more likely to occur than tails under this scenario, although, Zeno-like, with decreasing likelihood approaching zero over time?on edit: of course Von Neumann&#x27;s process has more restrictions, leading closer to fairness. reply raphael_kimmig 3 hours agorootparentIf you always start with heads the method works out. The key is that the first and the second toss need to be independent so that HT and TH have the same probability. If you influence the second toss based on the first one it no longer works. reply fbartos 6 hours agoprevAbout a year ago, we embarked on a quest to answer one of the most intriguing questions:If you flip a fair coin and catch it in hand, what&#x27;s the probability it lands on the same side it started?Today, we are finally ready to share the results. Thanks to my friends, collaborators, and even strangers from the internet, we collected flippin 350,757 coin flips. We ran several \"Coin Tossing Marathons\" (e.g., https:&#x2F;&#x2F;youtu.be&#x2F;3xNg51mv-fk?si=o2E3hKa-ReXodOmc) and spent countless hours flipping coins.In short, we found overwhelming evidence for a \"same-side\" bias predicted by Diaconis, Holmes, and Montgomery 2007: If you start heads-up, the coin is more likely to land heads-up and vice versa. How large is the bias? In our sample, the mean estimate is 50.8%, CI [50.6%, 50.9%].We also found considerable variance in the same-side bias between our 48 tossers. The bias varied with a standard deviation of 1.6%, CI [1.2%, 2.0%], in our sample. The variation could be explained by a different degree of \"wobbliness\" between our tossers.If you bet a dollar on the outcome of a coin toss 1000 times, knowing the starting position of the coin toss would earn you 19$ on average. This is more than the casino advantage for 6-deck blackjack against an optimal player (5$) but less than that for single-zero roulette (27$).The manuscript is at arXiv: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.04153 And the open data, code, and video recordings at OSF: https:&#x2F;&#x2F;osf.io&#x2F;pxu6r&#x2F;.Diaconis, P., Holmes, S., & Montgomery, R. (2007). Dynamical bias in the coin toss. SIAM Review, 49(2), 211-235. https:&#x2F;&#x2F;doi.org&#x2F;10.1137&#x2F;S0036144504446436 reply noobermin 5 hours agoparent>If you bet a dollar on the outcome of a coin toss 1000 times, knowing the starting position of the coin toss would earn you 19$ on average. This is more than the casino advantage for 6-deck blackjack against an optimal player (5$) but less than that for single-zero roulette (27$).This sounds like the plot of a western where a man travels from town to town and gleans a little cash from the local waterhole a little every time. I did the math though, in order to get just the $19, assuming you played a modest 20 times a day, it&#x27;d take 10 weeks (not including weekends), and by that point people would definitely figure out your trick. In order to make any profit quickly, you&#x27;d have to distribute the strategy, after which your secret would explicitly be out there. Even assuming perfectly honest colleagues, having that many parallel people using the same strategy in the open means that before you turn any real profit, people will find out. It&#x27;s a fun idea to fantasize about though.Anyway, cheers on the paper! Pretty cool result that you guys put the effort in in implementing. reply kqr 5 hours agorootparentThe upshot is that as long as you only stake $1 at a time, you&#x27;re unlikely to lose more than $50.On the other hand, &#x2F;if&#x2F; you do, you&#x27;ll have to play for 6000 more flips until you can be fairly certain that you&#x27;re even again.What&#x27;s worse is if, after having lost $50, you&#x27;re down to your last $50, there&#x27;s almost a 1&#x2F;5 chance you&#x27;ll blow all of it trying to recover if you wager $1 each time.If you grow wise and start Kelly betting you&#x27;ll get back to your starting $100 on average in 5000 flips, though. If you can take out a loan of $500 first, you can Kelly bet your way to even much faster, in an expected 700 flips. Whether this is worth the interest on the loan depends on how quickly you can find challengers to bet with. reply mewpmewp2 5 hours agorootparentMake a deal with all the banks or systems that can print money that would allow you to take an infinite loan from them. Then just double the bet every time you lose.If they can print money, why not infinitely as you will always pay it back anyway, so you don&#x27;t have to worry about introducing inflation. There will always be a point when you can just burn the money that you temporarily introduced. reply kqr 4 hours agorootparent...from where does the money come that you pay back? Even if you have an unlimited stake, your winnings will be constrained by the counterparty eventually. reply mewpmewp2 3 hours agorootparentRight, I forgot, you also need someone willing to take those bets. So I think what you should do is make bets against multiple casinos&#x2F;institutions where you can develop an algorithm that will find you an optimal method of betting for reasonable 50&#x2F;50 results, if it makes easier to think. So for example at some point you might want to go to a casino and put the max bet on a single number in roulette, but do it enough times that you would have 50% odds of winning.Once that is exhausted, you would have to become more creative, like trying powerball enough times, but I&#x27;m not sure how good the odds are there vs the reward. Maybe that wouldn&#x27;t ever work.Actually, I forgot. You can just play with highly leveraged options. It&#x27;s not infinite yet, but come back to me until you&#x27;ve multiplied enough times that even options are not enough.Forget everything I said before, just play with options and automated algorithm to buy more. And post here once you can&#x27;t buy any higher cost options, and we&#x27;ll figure something out together. reply andrewinardeer 4 hours agorootparentprevThe Federal Reserve. They can print money arbitrarily. replynomilk 3 hours agoparentprevIt becomes clear why there&#x27;s a same-side bias when watching the video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3xNg51mv-fkThese are fairly gentle coin tosses; barely going a foot into the air!When I think of a coin toss, I think high and spinning fast (like the ones before sports games, where the coin goes into the air and lands on the ground, usually rolls a short way, and is collected on whatever side it landed). I would guess the 50.8% same-side bias would be much closer to 50% if the coins were tossed this way in the experiment. reply fbartos 3 hours agorootparentThere was indeed a lot of variation in the height of the tosses. I however disagree with the conclussion: two of my friends at the video had the most different height of tosses (one tossed thrice as hight as the other one), yet both of them had exactly the same bias (0.505). The amount of spin is unfortunatelly very misleading from the 30fps videos--the coins often seem like not spinning at all but that&#x27;s just a result of the poor video quality. reply glandium 3 hours agorootparentprevWith a 1 foot to 2 feet toss, landing in the hand, I can get the same side as the starting side more than 90% of the time, without even trying. I wouldn&#x27;t trust such a toss to be fair. Landing on the floor would change the game. reply alkonaut 1 hour agoparentprev> This is more than the casino advantage for 6-deck blackjack against an optimal player (5$)I have seen that figure (roughly 0.5% edge) but that has to depend on how deep the shoe is dealt? I remember playing only the last hands with dealers playing down to between 1.0 and 0.5 decks left. That meant you could play hands where you knew almost all remaining cards were suited. I guess the average edge assumes constant bet and doesn&#x27;t include betting strategies based on counting at all? (And those strategies obviously wouldn&#x27;t work in any real casino because it&#x27;s \"frowned upon\"). reply Semaphor 5 hours agoparentprev> but less than that for single-zero roulette (27$).This reminds me of the casino I was at with a fair roulette. Betting Black&#x2F;Red and getting a zero meant all bets stayed for the next spin ;)My winning strategy was to always bet the opposite color of a friend of mine. reply fouronnes3 6 hours agoparentprevWhat is the physical explanation for this bias? reply bradrn 5 hours agorootparentIt’s in the paper:> The standard model of coin flipping was extended by Persi Diaconis [12] who proposed that when people flip a ordinary coin, they introduce a small degree of ‘precession’ or wobble—a change in the direction of the axis of rotation throughout the coin’s trajectory. According to the Diaconis model, precession causes the coin to spend more time in the air with the initial side facing up. Consequently, the coin has a higher chance of landing on the same side as it started (i.e., ‘same-side bias’).[12] Diaconis P, Holmes S, Montgomery R. Dynamical bias in the coin toss. SIAM Review 2007; 49(2): 211–235. reply Philip-J-Fry 5 hours agorootparentprevAfter reading this the first thought I had was how do you stop people flipping the same way? Like, give me a baton and I could throw it at varying heights and control which side I caught it on. In theory the same applies to coin flipping. You can get quite consistent with your positioning and power.You could probably control for it by making people alternate which side was face up before the flip.That&#x27;s my intuition anyway. reply aspenmayer 4 hours agorootparentYour comment reminded me of two-up.> Two-up is a traditional Australian gambling game, involving a designated \"spinner\" throwing two coins, usually Australian pennies, into the air. Players bet on whether the coins will both fall with heads (obverse) up, both with tails (reverse) up, or with a head and one a tail (known as \"Ewan\"). The game is traditionally played in pubs and clubs throughout Australia on Anzac Day, in part to mark a shared experience with diggers (soldiers).https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Two-up reply pirates 3 hours agorootparentTwo-up sounds pretty fun. Your comment in turn made me think of Chō-han, which is somewhat similar but involves rolling dice instead of flipping coins. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Ch%C5%8D-han reply rstarast 5 hours agorootparentprevI would guess it&#x27;s rather mathematical. Each coinflip has some number of half-flips. Now analyze the distribution of that number. If this distribution were to start at its maximum with 0 half-flips and decay as it increases, summing over the even values (same side up) clearly gives more than summing over the odd values. Now the distribution isn&#x27;t going to be like that, but I expect that it&#x27;s generally \"front-loaded\" in a way that causes a similar effect. reply mewpmewp2 4 hours agorootparentYeah, and seeing that the bias occurs only in some people, perhaps it occurs in people who do as little rotation as possible. Not sure if this study has a graph including amount of rotations occurred in general. E.g. you could take all coin flips where 0-5 rotations occurred and compare them to 6-11 rotations. reply gala8y 5 hours agoparentprevThis was my intuition in childhood. If you choose tails to be yours and start with tails then catch it, it is most likely to be tails. I came up with this observation myself. Weird. reply kqr 5 hours agorootparentYeah, I think you were just lucky that your superstition happened to be true.Trying not to be disrespectful but I don&#x27;t believe you intuited a 50.8 % bias. So nothing weird going on at all. reply gala8y 5 hours agorootparentI know it&#x27;s not on par with any real stats, but still... I just had this strong conviction that worked this way. The really interesting stuff is why it is so. I would think along lines of brain timing tossing and catching, eye-brain-timing rather than gravity and coin itself. Added: Yeah, now I remember actually manipulating timing of catch to achieve this.> Trying not to be disrespectfulNo worries, it is just me using high context communication style, where I assume that you know that I know this and I just share what was my experience in childhood (it was not like a single thought). reply JKCalhoun 3 hours agoparentprevFair coin, unfair flip. reply kzrdude 6 hours agoparentprevFun that you&#x27;re showing your own work. Since this is your work, it could have Show HN in the title; I guess. reply gala8y 5 hours agorootparentNo, not really.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;showhn.html reply input_sh 4 hours agorootparentprevIf there isn&#x27;t a product one can try, it&#x27;s not a Show HN material. reply kzrdude 3 hours agorootparentI see, it&#x27;s a bit more narrow than I knew reply cantrevealname 13 minutes agoprevI&#x27;m still looking for an intuitive or ELI5 explanation of the mechanism for this bias.The original paper says:The standard model of coin flipping was extended by Persi Diaconis who proposed that when people flip a ordinary coin, they introduce a small degree of precession’ or wobble—a change in the direction of the axis of rotation throughout the coin’s trajectory. According to the Diaconis model, precession causes the coin to spend more time in the air with the initial side facing up. Consequently, the coin has a higher chance of landing on the same side as it started.Another coin toss experiment[1] site says this:The basic reason is that, instead of rotating around a horizontal axis as one might imagine, a typical tossed coin is rotating around a tilted axis which is precessing in 3-space, and this entails a certain degree of \"memory\" of the initial parameters.The Diaconis paper[2] has the definitive explanation but it&#x27;s hardly intuitive. I got a feel for why it is, but I can&#x27;t do an ELI5. The best I&#x27;m able to write is this: A human being is likely to introduce some precession in the coin toss. If there is precession, then the angular momentum vector is going to spend more time in the heads direction if starting from heads, and that accounts for the bias.What I think would work well for an ELI5 is an animation of a coin toss showing the angular momentum vector sweeping out a region during its flight, and showing it spends slightly more time pointing toward heads.[1] https:&#x2F;&#x2F;www.stat.berkeley.edu&#x2F;~aldous&#x2F;Real-World&#x2F;coin_tosses...[2] http:&#x2F;&#x2F;epubs.siam.org&#x2F;doi&#x2F;10.1137&#x2F;S0036144504446436 reply helsinkiandrew 3 hours agoprevI think you can argue that the experiment wasn&#x27;t representative of &#x27;normal&#x27; coin flips.On average, each flipper in that experiment flipped a coin over 7000 times, after that amount many people will have learned to flip in a comfortable way with less variance between physical action and force they use. I&#x27;d imagine that in that case the coin would more likely land with the same orientation.I don&#x27;t think this would be true if someone flipped without practice. reply SamBam 3 hours agoparentI think this is a great point. One flipper 7000 times is quite different than 7000 flippers one time, if the aim is to see whether there is an underlying bias. reply fbartos 2 hours agoparentprevI personally did 20,100 flips and I can assure you I have no clue how to control the flip. I centrally got much better at flipping and catching the coin in hand without dropping it---which takes some practice on its own.(I know that there are techniques for adding the wobble to the toss, but I didn&#x27;t study them and I have no clue how to do them. I think it is safe to say you don&#x27;t discover them intuitevelly.) reply misja111 3 hours agoparentprevI bet that with enough practice, you can learn to toss the coin so that you get a much bigger than 51% chance of landing it on the same side. reply sjducb 2 hours agoprevHow do I bias a coin flip?Based on the paper it looks like 55% chance that it will land on the same side it started is possible. This was the most extreme subject.The bias is caused by procession so I want my flip to process as much as possible. Maybe I offset my finger as far away from the center of the coin as possible. Also putting as much force into it as possible is probably a good idea.Finally I have to catch it in a way that the top side is facing up when I reveal it.Any thoughts? reply ss1996 6 hours agoprevThank you for this. I&#x27;ll make sure to request a best of 350,757 next time I&#x27;m deciding anything by coin toss. reply LadyCailin 3 hours agoparentIt’s 50.8% bias, so you only need to do best of 1015! reply kqr 2 hours agorootparent...to accomplish what? Wouldn&#x27;t 1015 flips only give you a 70 % probability of winning? reply a_c 4 hours agoprevI always tell people that result of coin flip is highly start state dependent. Imagine a sequence of H(ead), T(ail), H, T, H, T, ... if the sequence starts with H first, in no way can the number of T exceed that of H, but the number of H might be 1 greater that that of T. I never tested my self, but I hypothesize that the propability will be more skewed if the number of revolutions is less, i.e. having a shorter Head-Tail sequence.Edit: The sequence was meant to represent the sequence of head and tail facing up during the rotation. A sequence of [H, T] denotes one full rotation, starting with head. [T, H, T, H] denotes two full rotation, starting with a tail, ends with a head. I didn&#x27;t mean the result of a flip. So the result of a flip is the final element of the sequence. reply Adverblessly 1 hour agoparentIf I were to dig through my comment history I would find I have already responded to this exact sort of comment before, so let me regurgitate :)If the coin is resting on your hand waiting to be flipped, it is currently mid-way through being on side up. This is because the switch between being e.g. heads up to tails up is done when the coin is vertical. If it isn&#x27;t a clear explanation, try imagining catching the coin and \"flattening\" it at different angles, while 50% of angles will match either side, at the moment the coin is flipped, it is already half-way through the angles representing the current side.This means that the correct sequence you describe it not THTHTH but rather THHTTHHTTHH. Taken at even intervals, both sides will appear the same number of times. Taken at odd intervals, at half of the intervals there are more Ts and the other half have more Hs. reply roflmaostc 4 hours agoparentprevOf course that is true, if you wait not significantly long enough.Imagine the situation that you flip the coin (starting at H) and you grab it in air immediately. Of course, you will get H as result.But let&#x27;s say, the time to stop the coin can be a relatively long time T. Then, I think the probability is some kind of sum. Let&#x27;s choose \\Delta T= 10ms as time discretization:P(H) = 1 &#x2F; T * (10ms-0ms) + (30ms-20ms) + (50ms-40ms) + ... = 1&#x2F;T \\sum_{i=0}{floor(T &#x2F; (2 * \\Delta T))} \\Delta TP(T) = 1 &#x2F; T ((20ms-10ms) + (40ms-30ms) + (60ms-50ms) + ... = 1&#x2F;T \\sum_{i=0}{floor(T &#x2F; (2 * \\Delta T)) - 1} \\Delta TFor T -> \\infty P(H) and P(T) getting more similar.But, in practice you wouldn&#x27;t wait equally distributed in time but more like a Gaussian distributed time period. Hence, each term of the sum would get weighted differently. And the variance and the offset of the Gaussian distribution can shift the probability in favor of H or T. It&#x27;s really dependent of the concrete parameters. If you grab always after 35ms, then you&#x27;ll always get T for example. reply cabirum 4 hours agoparentprevCan you toss a coin without it flipping at least once (changing state)? I find it quite unlikely to happen, so if the starting state was H, your sequence will be THTH... reply a_c 4 hours agorootparentI can&#x27;t quite define what counts as start of sequence. Maybe a sequence should always have at least one element, and toss straight up is allowed. But if some flipping is mandatory, then the start of sequence would mean the other side of the coin. All I could deduce before this paper is the probabilty of coin flip is skewed. reply havnagiggle 5 hours agoprevI&#x27;ve always caught the coin and flipped it onto the back of my hand to display the result. So I guess I have an opposite-side bias. reply quietbritishjim 1 hour agoparentThat&#x27;s the usual way of doing it. reply mihaic 5 hours agoprevInterestint, my intuition was inverse to the result: landing on the opposite side takes an odd number of flips and on the same side it would be an even number of flips.Since for every number of flips either the number of odds is the same as the number of evens, or higher by 1, the chances of getting an odd number of flips is higher. There seems to be more at work here, and only testing validates a model! reply omneity 2 hours agoprevThis got me thinking, is it physically feasible to slightly bias the coin against the starting side to get closer to fairness? reply alexmolas 3 hours agoprevI would like to see how TianqiP flips the coin. This user have a ratio of 0.601 [0.582, 0.619] heads, which is a lot. This is the type of skill that can get you a couple of bucks if played strategically. reply jcoder 42 minutes agoparentOr perhaps their coin was biased reply magicalhippo 2 hours agoprevThis reminds me of the opening scene of Rosencrantz & Guildenstern Are Dead[1]. Didn&#x27;t get to see the play, but loved the movie.[1]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gOwLEVQGbrM reply hurtuvac78 5 hours agoprevThis is incredibly puzzling.Is there a minimum number of rotations per coin flip to consider it valid?If looks like the bias was not evenly distributed across people. How did you protect your experiment from skilled bad actors who could influence the data with a few bad&#x2F;skilled flips? Did strangers on the internet fare any differently than in-person attempts from trusted people? reply fbartos 4 hours agoparentWe told people that the coin has to flip at least once (which would bias it for the opposite site). Whenever instructing people, I tried to explaining that the coin flip should look like you were trying to determine an outcome of a bet. You can find the complete experimental protocol here: https:&#x2F;&#x2F;osf.io&#x2F;hkv8pAlso, I wish I had (any) budget to hire proffesional skilled tossers haha. reply cantrevealname 1 hour agorootparentI assumed that the 1% bias was entirely due to coins that did not undergo any rotation at all. However, reading that you told people that the coin has to flip at least once, I think I assumed wrongly. It sounds like the bias is due to coins that have undergone an integral number of 360-degree rotations (not zero rotations). But what exactly is the physical mechanism causing this bias? It&#x27;s easy to understand why zero rotations would introduce a bias, but I can&#x27;t easily picture a reason for a bias toward an integral number of 360-degree rotations. Is there a simple and intuitive way you can explain the physical reason? reply fbartos 1 hour agorootparentIt&#x27;s not about the number of rotations at all. I doubt that you can control it at all even after dozens of hours coin flipping (I did more than 20h and I can&#x27;t eveb guess how many rotations the coin made) Diaconis, Holmes, and Montgomery (2007) proposed a physical model of coin flipping that introduces the bias as a result of wobblines (i.e., off-axis rotation in the flips).Diaconis, P., Holmes, S., & Montgomery, R. (2007). Dynamical bias in the coin toss. SIAM Review, 49(2), 211-235. https:&#x2F;&#x2F;doi.org&#x2F;10.1137&#x2F;S0036144504446436 reply morelisp 5 hours agoparentprevWhy do you think this is puzzling? This bias has been analytically and dynamically predicted for years. reply hurtuvac78 5 hours agorootparentBecause I find it counter-intuitive. And because I am not aware of scientific development in this field.@bradrn on this thread kindly extracted the description of the proposed physical model from inside the paper, it is helpful: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37830265 reply harimau777 4 hours agoprevSupposedly dice tend to role higher if you roll them starting with the largest side up. I use that when I&#x27;m creating my character in D&D and it seems to work. reply derbOac 1 hour agoprevPlaying games with my family, I&#x27;ve often wondered if there&#x27;s something similar with dice. reply brettwall 5 hours agoprevBased my back-testing of stock market, I found a similar conclusion: if a stock rise yesterday, then today the probability of raise > the probability of fall. P(raise) is about 50.1%, P(fall) is about 49.9%. Vice versa. Having this theory means you can&#x27;t rely on a single bet, you have to bets many many times to make profit from stock market. Even though I knew that, I am still working as a developer, I wish one day I have enough money to start stock career. reply hmate9 5 hours agoparentYou have to take into account how much it rises and how much it falls too. It might be you win more often but when you lose you lose more. reply sjamaan 5 hours agoparentprev> Having this theory means you can&#x27;t rely on a single bet, you have to bets many many times to make profit from stock market.If you take into account trading costs, you&#x27;ll probably lose money this way even if the theory is correct. reply mewpmewp2 5 hours agoparentprevAlert: It&#x27;s not going to be as simple as this to make money even with large numbers. So don&#x27;t fret about not having the money and missing some golden opportunity.There are enough actors out there trying to develop complex algorithms to find an edge, and so there wouldn&#x27;t be any simple edges like this left anywhere as they would be arbitraged away.If there is a simple pattern, it is noticed and traded until the pattern disappears. reply saalweachter 5 hours agorootparentAlso, if you do find an edge, you need to be prepared for what happens when everyone else discovers your arbitrage opportunity, and&#x2F;or you tap out the potential of it.A number of failed finance companies have the story: find a legitimate arbitrage opportunity; take on a billion dollars in investment to exploit the opportunity; make bank; other people discover your arbitrage opportunity and jump on; stop making bank; try riskier and riskier investment opportunities to keep it going; engage in outright fraud to keep it going; go bankrupt and&#x2F;or to jail. reply mewpmewp2 3 hours agorootparentStock market is such a slippery addiction slope. With casino a reasonable person would know, the odds are stacked against themselves, but with Stock Market, there&#x27;s no guarantee and it&#x27;s really easy to convince yourself that you have an edge, and sometimes it works for a while, and then it doesn&#x27;t, but you are already used to that feeling of reward, and as you said you will start to engage in riskier and riskier opportunities to get that feeling back. reply kqr 5 hours agorootparentprevHas hmate9 pointed out, a simple pattern like the one described can persist indefinitely – but the risk of exploiting it is priced in already. reply mewpmewp2 4 hours agorootparentYeah, you could find a pattern that wins 99% of the time to yield 1% of what you risk, but you don&#x27;t consider that there&#x27;s always 1% odds of losing it all and it&#x27;s priced in, it just hasn&#x27;t happened to happen yet, but systems with more precise data have accounted for it.E.g. something like selling 0dte options sufficiently out of money might seem like a free money hack, but once something unexpected happens you are down to just \"who could have possibly foreseen that event to occur, my decision making was solid.\". reply Karellen 4 hours agoparentprev> you have to bets many many times to make profit from stock marketYou also have to take into account transaction fees and broker spread. (If you get a great deal on one of these, check the other very carefully!) I&#x27;d be quite surprised if the edge on your system is enough to cover those. reply drexlspivey 4 hours agoparentprevSurely the armies of quants would have found this most trivial edge and exploited it if that was the case? reply fowlie 2 hours agoprevVery interesting! Is there reason to believe that the outcome would be different if the experiment was re-run but replacing the humans with coin-flipping machines? reply kortex 2 hours agoparentFolks have made flipping machines than can achieve near perfect reliability. Same guy mentioned in the paper.https:&#x2F;&#x2F;www.npr.org&#x2F;2004&#x2F;02&#x2F;24&#x2F;1697475&#x2F;the-not-so-random-coi... reply dmarchand90 5 hours agoprevExcellent ig nobel prize contender here reply rax0m 3 hours agoprevI watched one of the 12-hour coin tossing marathons.They were sitting with their laptops and pressed a button for every result.I wonder if human error can explain (at least part of) the deviation from 50&#x2F;50:* locations of the buttons they pressed on the laptops (they only pressed once per toss before enter, meaning the button represented same-side or other-side)* remembering what the coin started out as may be harder (or easier, but probably harder) when the result is other-side* other??Need to repeat this amount of tosses but with a higher degree of supervision to be sure of the result. reply fbartos 1 hour agoparentThat&#x27;s actually not completelly accurate. The study protocol (https:&#x2F;&#x2F;osf.io&#x2F;hkv8p) describes the procedure in greater detail.People were pressing one button for heads and another button for heads (which we deemend less error prone and less likely to be subcontiously influenced). The trick was that the next coin flip started the same side-up as the previous landed. Therefore there was no need to record the start (and we randomized the starting position of every 100th flip)We also did some auditing of the video recordings (trying to decode the outcomes from the videos) and they showed quite consistent degree of bias as the original responses. reply cabirum 4 hours agoprev50 authors in a paper about flipping coins? reply bunderbunder 2 hours agoparentMake me sit around flipping coins 10,000 times and recording the results, and you damn well better at least put my name on the paper. reply slingnow 40 minutes agorootparentThen I guess we should include every study participant as an author across all disciplines. 200 participant study in psychology? 200 authors on the paper. reply bunderbunder 10 minutes agorootparentNot necessarily? The difference is that the people flipping the coins are not just experimental subjects, they&#x27;re actually implementing the experimental protocol.The kinds of participants you&#x27;re talking about are not just left off the paper out of lack of interest. It&#x27;s often the ethically preferable option. They often have a vested interest in remaining unnamed for privacy reasons, and derive no tangible benefit from being listed as authors.A big author list isn&#x27;t totally unheard of. The paper where they announced the discovery of the Higgs boson had an author list that spanned 8 densely-packaged pages. reply netrus 1 hour agoparentprevBy flipping thousands of coins for this paper, I am sure their participation exceeds that of many 5-author-papers. reply jb1991 4 hours agoparentprevSounds fair to me. Better than if it was only 49, or 51. reply shusaku 3 hours agoparentprevI guess that’s one way to prevent p-hacking: you can’t exclude&#x2F;include someone’s flips without them getting mad! reply boomboomsubban 4 hours agoparentprevBlind guess, it&#x27;s cheaper and easier to recruit volunteers to flip a coin 7000 times if you promise them credit on the paper. reply fbartos 4 hours agorootparentYou are absolutely right :) reply m3kw9 3 hours agoprevWhat about if they were flipped by computer random functions reply iamflimflam1 5 hours agoprevI would have expected some variance between different currencies and denominations - but maybe that would need a lot more data. reply morelisp 5 hours agoparentIf you read the original Diaconis, Holmes, and Montgomery paper you&#x27;ll see why it shouldn&#x27;t depend on this.There&#x27;s also the classic Gelman & Nolan https:&#x2F;&#x2F;www.tandfonline.com&#x2F;doi&#x2F;abs&#x2F;10.1198&#x2F;000313002605 \"You Can Load a Die, But You Can&#x27;t Bias a Coin\", in case you&#x27;re imagining more complex dynamical behavior. reply 1f60c 5 hours agoprevHow is that possible when both outcomes have a probability of exactly 50%? reply nottorp 5 hours agoparentAn ideal coin flipped by an unbiased super person would have that 50% probability. A real coin flipped by a real human no, as the study shows.Let&#x27;s consider a spherical cow... reply kqr 2 hours agorootparentWait, didn&#x27;t Ed Thorp argue for the exact opposite – if you have a super-person that can guarantee lack of bias, then you also have absolute Newtonian predictability on virtue of the mechanical perfectitude. The randomness must come from somewhere, and it comes from imperfections which also incidentally introduce bias. reply tgv 4 hours agorootparentprevIt&#x27;s simpler: an ideal coin flip is simply assumed to be uniformly distributed, on the basis of there being two possible outcomes and no influence. Where the bias in reality comes from, doesn&#x27;t matter.This also happens to be the great divide between frequentists and Bayesians. reply kqr 2 hours agorootparentEven simpler than that, actually. There&#x27;s no requirement for any distribution at all. (And I would argue strongly against a uniform prior, but that is a separate discussion.)What&#x27;s necessary to guess 50 % on the first toss is simply (a) complete ignorance about the bias, whatever it is, and (b) the hypothesis that the bias is just as likely to be negative as positive (i.e. a symmetric prior.) reply saalweachter 5 hours agoparentprevHow did you determine that both outcomes have a probability of exactly 50%? reply defrost 4 hours agorootparentBut not running any large scale empirical studies and by ignoring any coins that landed on their edge. reply shawabawa3 5 hours agoparentprevbecause they don&#x27;t have a probability of exactly 50% reply cesaref 5 hours agoprevI think the sporting approach of letting the coin drop to the ground rather than catching it is the answer to avoid bias in coin tossing. reply fbartos 4 hours agoparentNot neccessarily because spinning and bouncing coins are often much more biased then flipped coins. (Unequal weight distribution on the side can bias a spinned coin while it doesn not bias a flipped coin. There are a couple of studies on it too.) reply shapefrog 5 hours agoprev [–] Can someone who has access to a precision robot and controlled environment please check; if one applies the same force on the coin in flipping, with it landing on a (soft) surface at the same height it - will it land the same side every time. reply tiagod 4 hours agoparentYour comment sniped me into thinking of some over-engineered systems to measure this with the human factor included. Some sort of RFID coin balanced on all axis with an IMU chip that measures the force applied to the force (through acceleration) and the mode and number of rotations of the coin. Maybe a computer vision solution would also work reply morelisp 5 hours agoparentprev [–] You could read the Diaconis paper? reply shapefrog 5 hours agorootparent [–] It is paywalled so I can not.However, I was unaware that they already conducted said experiment. I am now left confused as to why they would not mention such in the abstract, and refer only to natural experiments and second order measurements.I shall aquire the paper and learn why. reply tgv 4 hours agorootparent [–] Using Google Scholar (1), you can find PDF versions of the paper(1) https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cluster=16877003867074896... replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A research project gathered data from 350,757 coin flips to verify a physics model of human coin tossing.",
      "The findings demonstrate that when an individual flips a regular coin, it usually lands on the same side it began.",
      "The experiment further validated that when a fair coin is flipped with the initial side up randomly determined, there's an equal chance of the coin landing on heads or tails."
    ],
    "commentSummary": [
      "The discussion delves into a bias observed in coin flipping, its contributing factors like hand movements, and various strategies to achieve faire results.",
      "Simulations to understand probabilities, the use of coin pairs, and other techniques are proposed to minimize this bias. The use of computer-generated random functions for fairness is also suggested.",
      "A study revealing a bias towards the starting side of the coin is cited, with reminders on its implications for other experiments and how empirical studies can help gain better insights."
    ],
    "points": 283,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1696928805
  },
  {
    "id": 37826357,
    "title": "DSLinux – Linux for the Nintendo DS",
    "originLink": "https://www.dslinux.org/",
    "originBody": "____ ___ _ __ \\ / __|| ||_|||| |_| _ ____ _ _ _ _|| \\_ \\|| || _ \\||\\ \\/ /|_|__| || || ||| || |_| |/ \\ |____/ |___/ |_||_||_| |_| \\__,_|\\_/\\_/ For further information check: http://www.dslinux.org/ NintendoDS login: _The DSLinux project has ported the Linux operating system to the Nintendo DS and Nintendo DS Lite. Newer models such as DSi and 3DS might work in DS-compatibility mode. Apart from real hardware, DSLinux also runs on some NDS emulators, like desmume. DSLinux is functional, has excellent documentation, and brings a wealth of useful Linux programs to the DS. See the FAQ to get started. There are no active developers at the moment. New contributors are welcome to pick up the ball and make use of resources provided here. There is plenty of documentation for new developers in the wiki. DSLinux wiki IRC channel #dslinux on Blitzed (please be patient while waiting for replies) Nickname: The DSLinux forums are gone and won't be reactivated dslinux-devel mailing list dslinux-commit mailing list DSLinux SVN repository DSLinux builds (also here) DSLinux on Wikipedia $Id: index.html,v a47c28a21d79 2015/03/24 20:20:27 dslinux $",
    "commentLink": "https://news.ycombinator.com/item?id=37826357",
    "commentBody": "DSLinux – Linux for the Nintendo DSHacker NewspastloginDSLinux – Linux for the Nintendo DS (dslinux.org) 278 points by AntiRush 17 hours ago| hidepastfavorite65 comments erik 16 hours agoI made a few small contributions to this a long time ago. Nice to see that the website is still up!Probably the most interesting feature of this project was how it handled memory. The DS only has 4mb of ram. And there is no MMU, so swap isn&#x27;t an option. But the gameboy cartridge port has 32mb of address space mapped to the bus. And there are homebrew&#x2F;piracy cartridges that fill that space with 32mb of ram. Which is great, except that the DS can only write to the cartridge port on 16-bit aligned addresses. And almost all software will assume that 8-bit aligned writes will work. To make use of the expansion memory the developers ended up creating a patched GCC that would convert any writes to unaligned locations to an appropriate read, 16-bit write, and set of shift operations. reply MenhirMike 15 hours agoparent> And there are homebrew&#x2F;piracy cartridges that fill that space with 32mb of ram.There&#x27;s even an official one, the Opera Web Browser came with a second cartridge for the \"GBA\" slot to add 8 MB of RAM and a MMU: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nintendo_DS_Browser#Memory_Exp...(I&#x27;ve long lost the Opera DS cartridge, but the memory expansion is still in my DS Lite as a slot cover) reply monocasa 10 hours agorootparentHuh, does it really have an MMU? I don&#x27;t remember that when I coded for it back in the day, and wiki seems to be the only one saying that (uncited). It also doesn&#x27;t make a lot of sense to be at that point in the system as it&#x27;s so far away from the main bus matrix.But perhaps my memory is going bad and my Google Fu is worse.Edit: gbatek doesn&#x27;t document an MMU in those cards either. https:&#x2F;&#x2F;problemkaputt.de&#x2F;gbatek.htm#dscartexpansionram reply erik 9 hours agorootparentI think wikipedia is wrong. I don’t see how it would make sense to have a mmu in the ram expansion card. reply MenhirMike 8 hours agorootparentprevI have no idea, just quoted Wikipedia. It looks like there is only a single chip in that module, so it would make sense for that only being a RAM chip. Can&#x27;t edit the post anymore though. reply erik 9 hours agorootparentprevWe were pretty proud that we had a graphical browser running under DSLinux a good 6 months before Nintendo released the Opera cart. reply Operyl 11 hours agorootparentprevHaha! I always wondered as a kid why that was a requirement. The number of times I had to use the Opera browser to get around my restrictive mother, sigh. reply erik 16 hours agoparentprevAnother quirk: It was pretty common to load your homebrew software from a cartridge in the gameboy port. The cartridges would have some combination of ram and flash based storage or CF Card, and you could tell the cartridge to expose the storage or the ram as they were behind some sort of banking scheme. This meant that the storage system was mapped directly to the bus. So to save on ram, programs were run \"in place\", executing directly from the storage rather than being copied to ram first. reply joshumax 8 hours agoparentprevI very fondly remember this project when I was growing up too, and I credit it with sparking my interest in kernel development.When trying to port some industrial control software to DSLinux, I ran into some bugs around how the SLOB allocator behaved under memory pressure. One of my patches landed upstream, even though SLOB is deprecated now. Still, as a kid starting out in the embedded space, it opened my eyes to the joys of hacking around with homebrew.Fun fact: a modded DS still powers a large part of my local observatory&#x27;s equipment. reply dormento 2 hours agorootparent> Fun fact: a modded DS still powers a large part of my local observatory&#x27;s equipment.I&#x27;m interested! I&#x27;d like to read more about that. reply mikhael28 17 hours agoprevI recently did a deep dive into DS homebrew. Some cool stuff - a Yugioh calculator, mp3 player, port of Doom. In particular, I just love the hardware of the DS Lite or the DsI - it feels great in 2023, and the symmetrical screens are amazing when holding in vertical mode reading an ebook or playing Hotel Dusk. It also has one of the best pieces of software ever for learning Chinese, ‘My Chinese Coach’ - there are additionally two more (at least) homebrew software packages that focus on Chinese, such as DS Zhongwhen.DS is very underrated - so many great games, and it’s an emulation dream. All without being too powerful, and having ‘realistic’ graphics that just drain battery life. reply Hydraulix989 15 hours agoparentI was the one who ported DOOM to DS back in high school; we were all in the same DS homebrew IRC channel together. A lot of my now-closest friends worked on the other projects (including the author of DS Linux) -- incidentally we all ended up working for various tech companies in Silicon Valley and ended up reuniting in real life decades later. reply pixelatedindex 14 hours agorootparentThat&#x27;s an awesome anecdote, thank you for your amazing contributions! reply tmountain 14 hours agorootparentprevGreat story, thanks for sharing! reply rrc2soft 3 hours agoparentprevDS Zhongwen, that&#x27;s a name I didn&#x27;t heard in a long time! I am its author :-). I also made other stuff, like Knytt Stories DS. Making homebrew for the Nintendo DS was a great experience, as the limitations (and possibilities) of the hardware gave enough space for both creativity and engineering challenges. reply BaculumMeumEst 16 hours agoparentprevThe most surprising thing to me about DS and Switch homebrew was how approachable they are. For some reason I always imagined building things on them would be wizardry, but it&#x27;s really not. reply Gigachad 16 hours agorootparentI had a dive in to it. The docs and info is pretty accessible, the problem comes from the fact that the hardware itself is inherently pretty confusing. Having to understand all these memory banks and graphics modes, etc.Was a lot of fun though. It&#x27;s super cool how easy it is to just download libnds, compile the demos and get them running with a $9 flash cart. reply noirscape 8 hours agoparentprevThere&#x27;s also an entire visual novel engine called VNDS[0], with quite a few ports made for it. Afaict most \"classic\" VNs have ports available for it.Also if you have a 3DS, check out the TwilightMenu project. It&#x27;s a DSiMenu clone that can load homebrew titles and the like from the SD card (as well as flashcards).[0]: https:&#x2F;&#x2F;github.com&#x2F;BASLQC&#x2F;vnds reply mikhael28 16 hours agoparentprevFor the record, there are dozens of pieces of homebrew software worth mentioning. reply jimmaswell 16 hours agorootparentLemminds DS is my favorite.http:&#x2F;&#x2F;www.mrdictionary.net&#x2F;lemmings&#x2F; reply aquova 14 hours agoparentprevIs there a good source to find DS homebrew&#x2F;docs on developing for the system? reply ant6n 14 hours agorootparentYes.https:&#x2F;&#x2F;problemkaputt.de&#x2F;gbatek.htm reply priteau 8 hours agoprevWhat a nice surprise to see this on the HN front page! I was involved with DSLinux for several years. I maintained nightly-ish builds that I hosted on my website. I don&#x27;t think I ever contributed any code, as my C and system programming skills were still rudimentary at the time, but I did a fair amount of testing and helping people in the community.I sold my Nintendo DS since then, but I still have somewhere the Supercard that I would use to store and boot Linux, which looks like this: https:&#x2F;&#x2F;wiki.gbatemp.net&#x2F;wiki&#x2F;File:SuperCard_CF_V2.jpgMost of credit for the amazing work that made this possible goes to a few individuals, in particular Malcolm Parsons (pepsiman), Stefan Sperling (who later became an OpenBSD developer), and Amadeus: http:&#x2F;&#x2F;dslinux.org&#x2F;wiki&#x2F;ContactingDevelopers.html reply true_blue 17 hours agoprevThe Wikipedia article listed on the website was deleted as \"non-notable\". Here&#x27;s an archive of it though: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20170708075915&#x2F;https:&#x2F;&#x2F;en.wikipe... reply lynguist 9 hours agoparentInterestingly this one is still up: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;IPodLinuxWhich is the equivalent project (also on μCLinux) on an iPod. reply carstenhag 2 hours agorootparentI remember ...taking my sister&#x27;s iPod something to install this and then to connect it to my PS3 in order to jailbreak it. My sister was not happy of course, I am not sure whether I was able to reset the iPod to its original state or not. reply eggsome 9 hours agorootparentprevI interviewed the creator of μCLinux recently here:https:&#x2F;&#x2F;riscvnews.com&#x2F;posts&#x2F;j-core-interview&#x2F; reply crooked-v 16 hours agoparentprevnext [10 more] I don&#x27;t believe in Hell, but if I did I would suspect it would have a special place for Wikipedia deletionists, somewhere near the people who never return their shopping carts. reply PaulHoule 16 hours agorootparentI think Wikipedia deletionists would love to open up a circle of hell just for video games and related topics because it seems quite hard for a book to be considered notable on Wikipedia but hard for a game not to be. For instance only half of this author&#x27;s bookshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jill_Leporeare considered notable enough to have Wikipedia pages (and notably not the excellent https:&#x2F;&#x2F;www.amazon.com&#x2F;If-Then-Simulmatics-Corporation-Inven... but maybe that is just my opinion as a computer nerd who works in the public opinion field... If you notice I try not to say things like \"most people think that\" because I don&#x27;t want to be caught with my facts wrong.) but truly obscure games likehttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Code_of_Princessseem to not have to fight for notability at all. (Personally I kinda like that one, but I&#x27;m a serious weeb and even I&#x27;ll admit that it is terribly balanced and too grindy) reply LeoPanthera 15 hours agorootparentYou should join the group with the very long name.https:&#x2F;&#x2F;meta.wikimedia.org&#x2F;wiki&#x2F;Association_of_Wikipedians_W... reply MenhirMike 15 hours agorootparentprevIt&#x27;s a problem that came up ~~a few years~~more than a decade ago with Kate Middleton&#x27;s Wedding Dress which was deemed \"not significant\" initially, whereas every niche Linux distro has a page, which simply shows the demographics of the folks in charge of moderating Wikipedia: https:&#x2F;&#x2F;slate.com&#x2F;technology&#x2F;2012&#x2F;07&#x2F;kate-middleton-s-weddin...I get the idea of \"Let&#x27;s keep Wikipedia for relevant things instead of a graveyard of everyone that wants to self-promote their meaningless project\", but there is absolutely a real problem here.Code of Princess is relevant because it&#x27;s published by Atlus, but by that measure, any of Jill Lepore should be relevant enough. That said: Do you know if the books without pages were removed for non-relevance, or if it&#x27;s simply a matter of \"No one has created a proper Wikipedia Article for it yet?\" reply PaulHoule 15 hours agorootparentI think the strangest one is this gamehttps:&#x2F;&#x2F;krunker.io&#x2F;which has some stories in newspapers claiming it has serious player numbers but the people who make it have tried several times to make their own page for it which have been taken down because it was self-promotion. I’d imagine someone else could still make one but nobody has.Myself I’d rather deal with nicer people so I try to slip real Ukiyo-e prints into Danbooru and also correct historical inaccuracies in the bio(s) of people that FGO characters were based on. reply gaganyaan 12 hours agorootparentprevI don&#x27;t think it&#x27;s weird at all for there to be a Wikipedia page for every official release for a popular gaming system, even if the release itself is somewhat obscure. On the other hand, it makes sense that some author&#x27;s books would only be found as a subitem on the author&#x27;s page. I couldn&#x27;t tell you offhand what the exact delineation there is, though. reply pests 7 hours agorootparentHow does it make sense? Can you put it into words? Because that does not make sense to me. reply jacquesm 16 hours agorootparentprevGiven the price of bits these days a single bit flag with &#x27;non notable&#x27; would suffice and then they could keep these and allow people to see &#x27;full&#x27; or &#x27;just notable&#x27;. That should satisfy all parties. Of course there is then also the cost of the bits of the articles themselves but that too would be manageable. reply sithadmin 16 hours agorootparentThe problem with this idea is that it will just be abused for SEO spam junk, and you&#x27;ll have to default to hiding all content with the &#x27;non notable&#x27; bit from discovery by default lest the entire ecosystem get dragged down by the pollution. At this point, you might as well delete the content entirely, because it&#x27;s just taking up space and not contributing to the experience for the vast majority of users. reply jacquesm 15 hours agorootparentI think there is a pretty easy to distinguish difference between &#x27;SEO spam junk&#x27; and &#x27;non notable&#x27; but if you&#x27;re worried about that you could always have &#x27;non notable&#x27; default to all outbound links to be &#x27;nofollow&#x27;. For every problem there is a solution, if you want to solve it. I&#x27;ve seen and heard just about every excuse possible why particular things should be &#x27;non notable&#x27; but not a single one that has stood up to scrutiny, it always seems to in the end boil down to &#x27;because we say so&#x27;. Which is a pity because ultimately &#x27;notability&#x27; is as much in the eye of the beholder as it is something objective and what is non-notable to one large group may well be notable to another. And if that first group is over-represented amongst the wikipedians then that&#x27;s the end of that, no matter how important something really is. replynamuol 13 hours agoprevBack in high school, I used to go “war driving” on my bike around my neighborhood with DS Linux running on an M3 cart. Almost forgot this existed; thanks for sharing, this was a fun memory to dig up. I still have my DS and my M3 cart but the SD card with my old build on it is long gone. reply monocasa 16 hours agoprevInterestingly, based on some of the same uCLinux work as another story on the HN home page right now:789 KB Linux Without MMU on RISC-Vhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37822082 reply mintplant 6 hours agoprevThis was my gateway into Linux! I&#x27;m grateful to whoever decided to bundle the BSDgames [0] and Frotz [1] packages, for sparking a lifelong love of text adventure games and interactive fiction. Imagine my surprise as a little kid poking around the bin directory, typing \"advent\" into the prompt expecting a simple advent calendar application, and instead getting dropped into a whole other world [2]...[0] https:&#x2F;&#x2F;wiki.linuxquestions.org&#x2F;wiki&#x2F;BSD_games[1] https:&#x2F;&#x2F;davidgriffith.gitlab.io&#x2F;frotz&#x2F;[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Colossal_Cave_Adventure reply Wowfunhappy 4 hours agoparentYou played text adventures by typing on a DS touch screen keyboard with a stylus?! reply anthk 5 hours agoparentprevSame as you, but first I played IF games under Winfrotz&#x2F;ZX Spectrum. Later, I ran Linux with advent&#x2F;battlestar and such under Frotz for Unix (among trek) and I was hooked. reply thosakwe 15 hours agoprevI remember being 11 or so and installing this homebrew onto my DS...I had NO IDEA what Linux was at the time, but DSLinux helped me deepen my interest in computer science.So, thanks to the creators, and everyone who contributed code. reply widforss 8 hours agoprevI could never run DSLinux, I was in eighth grade and couldn&#x27;t afford the RAM pack (just used a pirate card for games). But I printed out all of the documentation at the school library and read it until I pretty much new it by heart, and that became my introduction to Linux.I can&#x27;t remember if this was before or after I managed to inadvertently install (!?) Knoppix on my sister&#x27;s school laptop, but my passion for Linux was there well before I had the means to run it myself. reply heywoodlh 12 hours agoprevAs a heavy Linux user myself, I was wondering what kind of functionality you would gain from running Linux on a DS (aside from the obvious learning experience and “because you can”). I found the FAQ[0] answers this nicely.Basically, it boils down to anything you can do on the command line within the resource constraints of the DS.Would love to hear any DSLinux users who would be willing to share stories about cool functionality they were able to achieve.[0] https:&#x2F;&#x2F;www.dslinux.org&#x2F;wiki&#x2F;DSLinuxFAQ.html reply askiiart 16 hours agoprevI remember looking into this a couple months back because I wanted to SSH into my server from my DSi, just for the lolz.I wasn&#x27;t too invested in it, so when the wifi didn&#x27;t \"just work\" I gave up, but I&#x27;d still love to get SSH working on that some day. reply snvzz 15 hours agoparent>DSiDid DSLinux team ever manage to get it to work on the DSi?I still have my DSi and it still works, but I remember DSLinux didn&#x27;t work with it. reply joshumax 7 hours agorootparentYes, it works, but there are some issues.The first one being that the SoC configuration runs in DS-compatibility mode which does not expose all of the available RAM in the DSi, and nds-bootstrap won&#x27;t properly redirect I&#x2F;O requests to the external SD card, which means you either need to embed the rootfs in the NDS ROM which won&#x27;t persist changes, or use a flash cart and run the DLDI build instead. reply snowram 5 hours agorootparentActually, someone made a working DSi mode WiFi driver some months ago. It is even used in a DSi compatible fork of ftpd. Very handy when transferring files on the SD card of a hacked DSi since it has WPA2 support unlike DS mode which is stuck with WEP.https:&#x2F;&#x2F;github.com&#x2F;devkitPro&#x2F;dswifi&#x2F;issues&#x2F;4#issuecomment-89...https:&#x2F;&#x2F;github.com&#x2F;shinyquagsire23&#x2F;dsiwifihttps:&#x2F;&#x2F;github.com&#x2F;mtheall&#x2F;ftpd&#x2F;compare&#x2F;master...shinyquagsi... reply chungy 11 hours agorootparentprevIt should work fine in the DS backwards compatibility mode, but a native DSi port might be slightly nicer. The DSi has 16MB of system RAM.Following that, the Old 3DS had 128MB and New 3DS had 256MB of RAM. reply erik 15 hours agoparentprevI believe most wifi routers have 802.11b support turned off by default these days. Otherwise, ssh should be doable! reply haunter 8 hours agoprevTried it on my New 3DS XL. There is a single .NDS build so starts perfectly with TwilightMenu++ http:&#x2F;&#x2F;dslinux.org&#x2F;builds&#x2F;dslinux.ndsThe problem is the touch keyboard is unusuable. Most likely because of the NDS v 3DS screen resolution difference, it&#x27;s impossible to type on it. Took me a couple of minutes to type \"root\" but never managed to hit Enter :D reply 5- 15 hours agoprevalso of note is a port of the inferno operating system to the ds, which makes for a rather nice platform.https:&#x2F;&#x2F;www.gamebrew.org&#x2F;wiki&#x2F;Inferno_DS reply circuit10 9 hours agoparentFor some reason Vodaphone wants me to confirm I’m over 18 to view this site reply prmoustache 8 hours agorootparentWhat has vodaphone to do with that website? Do they provide you a lying DNS and send you to their proxy servers?I suggest using DoH and uncensored DNS servers. Oh and cancel that shitty provider. reply circuit10 7 hours agorootparentIt’s meant to block “adult content” but it seems to count things to do with hacking as adult content with no obvious way to report a false positiveSee https:&#x2F;&#x2F;daniel.haxx.se&#x2F;blog&#x2F;2022&#x2F;05&#x2F;02&#x2F;considered-18&#x2F; (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31248250) reply CiaranMcNulty 6 hours agoprevI&#x27;ve a few DSi in a drawer somewhere... My first question was whether I can turn them into a k8s cluster reply RecycledEle 13 hours agoprevI love the idea of Linux on a Nintendo DS, but the name will cause confusion with this: http:&#x2F;&#x2F;www.damnsmalllinux.org&#x2F; reply luismedel 4 hours agoparentIn fact, I read it as if SDLinux (the original and only one) was ported to Nintendo DS :-) reply tylergetsay 11 hours agoprevEvery once and a while I get the urge to run this again and host a webpage from it.. sucks this device lacked a lot of IO and the wifi stack is so weird reply ndesaulniers 16 hours agoprevI did a stream about this on twitch. Someone uploaded it to YouTube. Trying to find itAha: https:&#x2F;&#x2F;youtu.be&#x2F;mTo8yb6q4Lw?si=LAchs9gVSHRONxn2 reply smoldesu 17 hours agoprev [–] It&#x27;s not exactly the modern equivalent, but owners of a modded Nintendo Switch can dual-boot with a few different Linux images: https:&#x2F;&#x2F;wiki.switchroot.org&#x2F;Since it&#x27;s based on the official (albeit outdated) Tegra drivers, you can run a surprising amount of stuff on it. I got SkiFree working in Box86 and called it a day. reply monocasa 16 hours agoparent [–] Additionally, the switch is a hop, skip, and a jump away from being the same hardware as a Tegra Shield that the L4T images initially targeted. Like even down to the same exact model of DRAM chips which should have been more of a commodity and a reflection of the manufacturer&#x27;s vendor relationships.It&#x27;s as close to an officially supported Linux distro for Nintendo hardware as we&#x27;ve ever gotten. reply an-unknown 15 hours agorootparent [–] > It&#x27;s as close to an officially supported Linux distro for Nintendo hardware as we&#x27;ve ever gotten.To be fair, Linux on the Wii was also quite good: I remember running Debian 5 Lenny on my Wii many years ago, and it seemed to be \"just\" a different kernel with drivers for the Wii hardware but with the normal userspace &#x2F; repos. With an USB mouse and keyboard this was even somewhat usable, even with X11 and some lightweight window manager. Of course RAM was quite limited with only 80MB in total, but still. It definitely wasn&#x27;t as hacky or limited as DSLinux. reply monocasa 13 hours agorootparent [–] It wasn&#x27;t supported by those who designed most of the circuit board though. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The DSLinux project has achieved a milestone of porting the Linux operating system to the Nintendo DS and DS Lite, and it's compatible with certain NDS emulators.",
      "While there are no contemporary active developers, new contributors are being invited to join, with abundant documentation available on the project's wiki for guidance.",
      "Despite inactive DSLinux forums, mailing lists and an SVN (Subversion) repository are there for further communication and online version control of code and resources."
    ],
    "commentSummary": [
      "DSLinux is a unique project aimed at enabling Linux to operate on the Nintendo DS handheld console, overcoming the device's memory limitations by utilizing homebrew cartridges with increased RAM capacity.",
      "The project necessitated innovation, as illustrated by the developers' creation of a patched compiler to effectively write to the cartridge port.",
      "The initiative has sparked interest and debate within the homebrew community, where enthusiasts share their experiences of running Linux on diverse devices and contemplate DSLinux's wider implications and potential applications."
    ],
    "points": 278,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1696891294
  },
  {
    "id": 37823160,
    "title": "Video streaming at scale with Kubernetes and RabbitMQ",
    "originLink": "https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb",
    "originBody": "Write Sign up Sign In ARCHITECTURE DEEP DIVE Video Streaming at Scale with Kubernetes and RabbitMQ Deep dive into the problems video streaming sites face and how they can architect their infrastructure to manage the load. Alexandre Olive · Follow 7 min read · 1 day ago 105 3 Photo by Marques Kaspbrak on Unsplash S treaming. That’s a word we hear a lot nowadays. Most of us use Netflix or YouTube daily. So much it has become part of everyone’s life, maybe too much for our own sake. But people rarely stop and wonder: how does it even work? From my developer’s point of view, it’s pure madness. There’s so much data to store and pass through the network, people worldwide should be able to access it without lag or issues, and it needs to work on all devices. I will not pretend I know how those apps work internally. They probably use concepts I never dreamed of to optimize every inch possible. But don’t leave just yet; there’s still a reason I’m writing this article. I want to use my direct experience working as a technical lead on a streaming solution at Skeepers to explain how we manage to produce high-quality videos and stream those videos directly onto our client’s website, just like you would watch a video on YouTube. I will discuss technical subjects like Kubernetes, RabbitMQ, and load balancers. A basic knowledge of those topics is necessary to follow the article. To clarify, I’m talking about streaming as watching a video online that is not a live stream. A regular video on YouTube is still called video streaming. The video’s life: from upload to playback I will take you on a journey from when a user uploads a video on our site to when you play it on your device and the challenges that come with it. Photo by Jakob Owens on Unsplash First step: Video upload Alright, the first step is when the video is uploaded. We have yet to determine what format, codec, or even which resolution the video will be. First, it will be normalized, which means we will transform all the videos in the same format (first mp4), stabilize the video, and harmonize the sound to mitigate shaking or loud sounds. We then break the video into multiple small chunks; the resulting format will be an adaptive bitrate streaming format called MPEG-Dash or HLS. You can read more about Adaptative bitrate streaming here. An Introduction to the Difficult World of Video Processing Dive into the video processing world and discover what problems mainstream platforms like YouTube or Netflix face when… alexandreolive.medium.com This task is time-consuming, so the user cannot just wait for the API’s response synchronously. It needs to be asynchronous. Custom-made schema representing the simplified architecture. You can see the asynchronous implementation using RabbitMQ on this schema. When a user uploads a new video, it first gets uploaded to a cloud storage. We use Google Cloud Storage, but it could be any storage. Once the upload finishes, we create a processing task in the database and send the task ID to the queue. The user screens update with a message that says the processing is ongoing and please wait a few minutes. A NodeJS worker is constantly polling the queue, waiting for new tasks like a good soldier. When a new one is available, it gets the processing task information from the database. It uses FFmpeg under the hood to do the required job (normalization or adaptative bitrate streaming format creation, for example), store the resulting files in storage, and update the task’s status in the database. You’re probably thinking: “Hang on, there’s Kubernetes in your article title but not in the schema”, or “It’s not scalable as is. If there are a lot of videos, it will crash.” I’m getting there! The schema I presented was just an introduction. I am gradually introducing each concept. There are indeed a couple of issues here. If there is only one API and one worker, it will quickly overload. Primarily since FFmpeg requires a lot of resources. Let’s spice it up! Custom-made schema representing the more complex architecture with Kubernetes. Alright, we introduced Kubernetes in the mix. The NodeJS API handling user calls will receive many HTTP calls with user files. So, instead of having one API instance, it’s now a variable number of Kubernetes pods. We have set it up to auto-scale in a way that if the RAM or CPU of the pods reaches a specific limit (70% of their capacity), it will launch a new pod for this same API. There is no “Kubernetes node“ reference to simplify the schema, but it can also scale across nodes. If the number of pods (actually the required capacity of the pods) reaches the capacity limit for the current node, it will auto-scale a new node and start launching new pods inside that node. The load balancer in front of the API will share the HTTP calls randomly between all the existing pods to split the load. The worker polling the RabbitMQ is also auto-scaling, but it’s not on resources; it is scaling on the number of messages waiting in the queue. The more messages await, the faster we need to process them, so launching new workers is the way to go. It’s much better, but we want to save costs when possible, so let me introduce preemptible nodes! Preemptible VMs are Compute Engine VM instances that are priced lower than standard VMs and provide no guarantee of availability — Google Cloud documentation. Custom-made schema representing the more complex architecture with Kubernetes and preemptible nodes. We want our user to have the best experience, but it’s perfectly fine for us if they don’t have access to the best video quality in adaptative bitrate streaming format right as they upload their content. It can take a few minutes for a preemptible node to be available, but they are cheaper than a normal node. In this new schema, we transformed our NodeJS worker with FFmpeg to what we call internally a “spawner”. It still polls the RabbitMQ queue, but instead of processing the video itself, it will launch a new Kubernetes pod in a preemptible node, and this new pod will do the processing. This way is cheaper. We switched all our resource-intensive tasks in a preemptible node, so we don’t need to scale our spawner as much in a normal-priced node. Google Cloud can kill preemptible nodes if a normal node needs the resources. We must ensure a failed task goes back to the queue and starts again by another node later. Terminated when Compute Engine requires the resources to run standard VMs — Google cloud documentation This new setup with preemptible nodes brings more overhead in the implementation but a significant cost improvement. We reached a point where we could scale horizontally indefinitely. Second step: Video playback Alright, at this point in the process, we uploaded and transformed our user video to stream it on our site. A video could be hundreds of megabytes split into thousands of chunks. The video HTML tag does not support adaptative bitrate streaming formats like HLS or MPEG-Dash by default, so we must use a custom player. The two most used players to handle streaming are HLS.js and Skaka Player. They both use Media Source Extension to be able to handle this format. I won’t go into more detail about players and MSE as it’s not the goal of this article; you can read more by clicking on the link I provided. To prevent loading the video files from the cloud storage each time someone tries to play the video, and therefore pay a lot of money to the cloud provider, we use a Content Delivery Network (CDN). Custom schema showing the process of using a CDN The user lands on the site to stream the video. All calls to retrieve the video go through our CDN provider, Cloudflare. A CDN will cache the content at the edges, which means if the content you are requesting is not present in their cache, it will demand it to the URL you provided. The “edge” part means that depending on where you are in the world, it will store it in a server close to you (regionally) so that if a user in your region asks for the same content, he gets it blazingly fast. If a user from another side of the world asks for the same content, it will do the same process and store it close to that user. Each video chunk is a separate file, so the waiting time for the unlucky user who has to create the cache is still relatively low. Not thousands of megabytes to download at once. I skipped some essential parts of our architecture like micro-services, WebSockets, Redis pub/sub, or webhooks to keep the focus on Kubernetes’ auto-scaling capabilities in combination with RabbitMQ asynchronous queues. I’ll probably write another article about “communication” in our architecture soon. YouTube probably has an implementation that differs significantly from ours, but it’s already a good look into what a complex system with Kubernetes might look like. I would love to be a little mouse and peek at YouTube’s complete architecture to see how far we are from them. I might want to contact Ratatouille’s movie creator to do so; it’s a real story right? Sign up to discover human stories that deepen your understanding of the world. Free Distraction-free reading. No ads. Organize your knowledge with lists and highlights. Tell your story. Find your audience. Sign up for free Membership Access the best member-only stories. Support independent authors. Listen to audio narrations. Read offline. Join the Partner Program and earn for your writing. Try for $5/month Kubernetes Architecture Rabbitmq Development Streaming 105 3 Written by Alexandre Olive 24 Followers Senior Lead Developer 🤓Globetrotter 🌍Fitness and self-improvement Enthusiast 💪 Love to learn and write about new subjects all the time! Follow More from Alexandre Olive Alexandre Olive Meditation Is Not Only for Monks. Embark on a journey of discovering meditation through the eyes of a regular guy with zero prior experience. Scientific facts and personal… 8 min read · Sep 24 34 1 Alexandre Olive An Introduction to the Difficult World of Video Processing Dive into the video processing world and discover what problems mainstream platforms like YouTube or Netflix face when a user uploads a… 9 min read · Oct 3 20 1 Alexandre Olive in skeepers StencilJS: A Deep dive into the inner workings of output targets 8 min read · Aug 29 14 Alexandre Olive in skeepers Unlocking Cross-Framework Power: StencilJS Configuration Demystified Stencil’s primary goal is to provide an easy way to build component libraries available in all the main frameworks available today… 12 min read · Sep 4 12 See all from Alexandre Olive Recommended from Medium Marcos Pereira Júnior Using NGINX as API Gateway Hi everyone! 8 min read · May 31 521 9 Asttle in AWS Tip AWS API Gateway Build, Manage and Deploy APIs 3 min read · Sep 11 19 Lists Stories to Help You Grow as a Software Developer 19 stories · 444 saves It's never too late or early to start something 15 stories · 156 saves Modern Marketing 34 stories · 175 saves Medium Publications Accepting Story Submissions 154 stories · 802 saves Seetharamugn When to use RabbitMQ or Apache Kafka In this article, my mission is to share insights based on the research, I had over the years and to try to convey my thoughts about why we… 4 min read · Apr 20 104 Sounak De in DevOps.dev Java Spring Events: A Developer’s Secret Weapon- Part 1 5 min read · Oct 2 14 Praneesha Chandrasiri in Ballerina Swan Lake Tech Blog Invoke an Azure Function via a Cosmos DB Trigger Using Ballerina This article was written using Ballerina 2201.7.0 (Swan Lake Update 7) and is about using a Cosmos DB connection to invoke an Azure… 7 min read · Sep 7 1 Hardik Shakya Winning the Agora Chat Applications Game: The Ultimate Guide to Building an Authentication Server… In today’s interconnected world, chat applications have become an integral part of our lives. Whether it’s staying connected with friends… 4 min read · Oct 1 605 See more recommendations Help Status Writers Blog Careers Privacy Terms About Text to speech Teams",
    "commentLink": "https://news.ycombinator.com/item?id=37823160",
    "commentBody": "Video streaming at scale with Kubernetes and RabbitMQHacker NewspastloginVideo streaming at scale with Kubernetes and RabbitMQ (alexandreolive.medium.com) 263 points by thunderbong 22 hours ago| hidepastfavorite83 comments schott12521 21 hours agoI thoroughly appreciated this article as I&#x27;ve been building a short-form video content streaming service and the performance hasn&#x27;t been what I expected.Granted, I knew that my service needs to be able to scale at different bottlenecks, but a lot of \"build your own video service!\" tutorials start with:- Build a backend, return a video file- Build a frontend, embed the videoAnd that leaves a lot to be desired in terms of performance. I think the actual steps should be:- Build a backend that consists of: - Video Ingestion service - Video Upload &#x2F; Processing Service that saves the video into chunks - Build a streaming service that returns video chunks- Build a frontend that consists of: - Build or use a video streaming library that can play video chunks as a streamEdit: From the author&#x27;s links, I found this website which is very informative: https:&#x2F;&#x2F;howvideo.works&#x2F; reply mmcclure 19 hours agoparentI helped work on howvideo.works, fun to see it helping people! The world of video is, I&#x27;d argue, one of those technical spaces that is extremely iceberg-y. You can get decently far enough using S3 + the HTML5 video tag, which I think creates a perception among some that video is just images but a little bigger, but that couldn&#x27;t be further from the truth. You can really pick just about any step along the video pipeline from production to playback and go as deep for as many years as you&#x27;d like.This is both a semi-shameless plug and probably a few levels deeper than what you&#x27;re looking for, but I organize a conference for video developers called Demuxed. The YouTube channel[1] has 8 years worth of conference videos about streaming video (and the 9th year is happening in a couple of weeks). The bullet points you mentioned are definitely covered across a few talks, but it&#x27;s certainly not in any kind of \"how to\" format.[1]: https:&#x2F;&#x2F;youtube.com&#x2F;demuxed reply alexandreolive 18 hours agorootparentI&#x27;m the writer of the article; I LOVE howvideo.works. It helped me quite a lot when I started working on video processing. I&#x27;m still a beginner and always fall back to it when I&#x27;m unsure about something fundamental. Thanks for your work. I&#x27;ll take a look at your YouTube channel. reply alexandreolive 18 hours agoparentprevI&#x27;m the writer of the article; thanks for your lovely comment. I skipped many essential parts of the architecture in the article to keep it concise. The following articles will be about the technical implementation of what I discussed in this one. reply wouldbecouldbe 8 hours agoparentprevI&#x27;ve been using commercial streaming services for in app (cloudflare, bunny, vimeo), and found performance & bandwith use terrible. The HLS protocol for iOS doesnt work wel for 5-10 second clips, since it needs 1-4 seconds. Now using compress mp4 with progressive loading. Way better. reply ddorian43 8 hours agorootparent> and found performance & bandwith use terribleCan you explain exactly what you mean? reply Uehreka 18 hours agoparentprevSomething like this? https:&#x2F;&#x2F;github.com&#x2F;streamlinevideo&#x2F;streamline reply andrewstuart 21 hours agoparentprev>> I&#x27;ve been building a short-form video content streaming serviceWhat does it do? reply schott12521 20 hours agorootparentRight now I&#x27;m basically trying to just re-create the TikTok &#x2F; Youtube Shorts &#x2F; Instagram Reels experience of infinitely scrolling videos.Mostly just building for fun though. reply John23832 18 hours agoparentprevI built a similar project, and had great results with cloudflare stream. reply littlestymaar 10 hours agoparentprev> Video Upload &#x2F; Processing Service that saves the video into chunksAt this point you also need to chose what streaming protocol you want to use. You have mostly two choices, HLS if you want to get things done quick, or MPEG-DASH if you want more control (but you&#x27;d need a separate HLS pipeline for iOS anyway…)> Build or use a video streaming library that can play video chunks as a streamAs someone who&#x27;s worked on a web streaming player, I&#x27;d strongly recommend not to build one but to use an existing one (or, in short: use HLS.js) reply com2kid 20 hours agoprevThis is nice if you only have to deliver in one format, but as soon as you want to show up on TVs you are stuck delivering in a lot of formats, and life gets complicated quickly.Throw subtitles in multiple languages, and different audio tracks, into the mix, and all of a sudden streaming video becomes a nightmare.Finally, if you are dealing with copyrighted materials, you have to be aware as to what country your user is physically residing in while accessing the videos, as you likely don&#x27;t have a license to stream all your videos in every country all at once.Throw this all into a blender and what is needed is a very fancy asset catalog management system, and that part right there ends up being annoyingly complicated. reply dbrueck 20 hours agoparentOh, this is just the tip of the iceberg. Many parts of on-demand video streaming are largely commoditized at this point. Add in support for linear (live) streaming and ad insertion and things start to get really interesting. :) reply chunkymilk 12 hours agorootparentMy background is in linear (title VI and OTT) and ad-insertion. A big chunk of my job is explaining to folks that just because you solved VOD that doesn&#x27;t mean you&#x27;ve solved linear. It&#x27;s almost best to think of them as two distinct problems. reply jackcviers3 12 hours agorootparentprevArticle made me nostalgic.My very first job was writing streaming media services for radio. Integrating the ad services over events embedded into the stream identifying content was a pretty nifty solution. You send the metadata to your ad server, it selects the ads based on your user and media metadata, you swap out the player&#x27;s media url to play the ad(s), and keep the stream going in the background. When the commercial break is up, you kill the ad stream and swap the media stream player back in. Presto changeo, seamless ads in 2007.You also track media playback through the stream embedded events.The hard part back then was live video&#x2F;audio encoding. These cards lived at the stations, and streamed to our cdn. Geocoding for American service bases in foreign countries was interesting too, the streaming rights for stuff limits the countries you can stream in.Monitoring the live encoders was an interesting problem - I setup an event-based solution so I could capture the audio waveform and analyze the frequency buckets on dozens of streams at once. Could tell if a stream was silent pretty quickly, and alert the station engineer via email.Back then, a lot of this stuff wasn&#x27;t off the shelf like it was today. Even on the frontend,working with Flash, window&#x27;s media player sdk, and the QuickTime sdk and integrating it with Javascript was challenging. And the backends were all in php and Java 1.4, and mysql, and a whole lot of memcache.Was a really great experience for a new professional programmer to write all that. reply timc3 10 hours agorootparentIn 2007 and i would argue before that, live media encoding for streams was pretty much a solved problem but it was often very expensive, and out of reach of radio stations and the information wasn&#x27;t readily accessible so you could potentially end up giving Microsoft or Real networks lots of money.I was working on streaming in the late 90s - that was real wild west, had to write solutions myself, and it felt very duck taped together. Luckily it was an offshoot of a largish ISP so we had bandwidth and a lot of servers. incoming streams often used bonded ISDN lines. reply grzes 20 hours agoparentprev\"fancy asset catalog management system\" - was thinking about building such solution lately - do you know any open-source solutions of this kind? reply timc3 10 hours agorootparentI’ve built or been involved in building 4 closed source media asset management systems ( including my current place of work and one I cofounded) and you can get relatively far in the first month.But the devil is in the details and most people that attempt it don’t even get the database models right on the first or second time, they underestimate the complexity particularly when it comes to video and struggle when the use cases widen. Document asset management systems are way easier but usually don’t understand media as in depth as a media asset management system. reply dvliman 19 hours agoprevI built a similar video pipeline, not on Kubernetes but using EC2 instances for those hungry FFMPEG encoder.The system differ in that it was not user generated video content. It was coming from the cameras in our fitness studio.Here is the article if anyone intereste to read about: https:&#x2F;&#x2F;dev.to&#x2F;dvliman&#x2F;building-a-live-streaming-app-in-cloj... reply devgoth 18 hours agoparentawesome article! curious -- why clojure? reply dvliman 18 hours agorootparentNo specific reason. It could have been built in any language. It was just the language we were using and enjoyed at that time. reply robinduckett 18 hours agorootparentprevBecause CS Degree reply thomasjudge 18 hours agoprevOP mentions that \"I would love to be a little mouse and peek at YouTube’s complete architecture to see how far we are from them.\" You can occasionally find posts -often linked here- from another player in streaming video which you might have heard of, discussing technical architecture. For example, this might be a little lower level that you may be interested in as it relates to kernel optimizations to jack bit throughput rates, but I dig this sort of thing -https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=36qZYL5RlgY reply c7DJTLrn 15 hours agoparentI&#x27;ve heard somewhere that YouTube has their own transcoding hardware. reply EricBurnett 14 hours agorootparentIndeed. https:&#x2F;&#x2F;blog.youtube&#x2F;inside-youtube&#x2F;new-era-video-infrastruc... , https:&#x2F;&#x2F;research.google&#x2F;pubs&#x2F;pub50300&#x2F; . (Search the paper title and you should be able to find the pdf itself elsewhere).I&#x27;m not actually sure on balance how much transcode gets done in hardware vs software, since it&#x27;s also very amenable to using batch compute that&#x27;s otherwise idle. I&#x27;ll guess that most or all live transcoding - streams, on-the-fly transcode into formats not pregenerated - are done in hardware, and transcoding new formats for the back catalog are probably done on a mixture of mechanisms where and when capacity is available. (Source: Googler, not on YouTube though.) reply mannyv 19 hours agoprevFuck K8. You literally don&#x27;t need it. Maybe he needs it because he&#x27;s building on google cloud.AWS is easier, but you can do it with anything. The basic steps are:1. Upload the file somewhere 2. Transcode it 3. Put the parts somewhere 4. Serve the partsYou should really transcode everything into HLS. It&#x27;s 2023, and everything that matters supports it. If you want 4k you can use HLS or the other thing (which I keep forgetting the acronym for).If you want to get fancy you can do rendition audio, which not everything supports. Rendition audio means sharing one audio stream amongst N number of video streams.You can use FFMPEG to transcode, but I&#x27;d suggest using AWS MediaConvert. It&#x27;s cheap, fast, and probably does everything you want. Using FFmpeg directly works, but why bother. You will get an option wrong and screw everything up. You don&#x27;t want your video to not work on some random device that 50k people are using in some country you didn&#x27;t think about.He&#x27;s using RabbitMQ but you should use SQS, because SQS can trigger lambdas...which means no polling required. But use whatever queue you want.You can kick the process off by attaching a Lambda to S3, which will start the process when the file is uploaded.You can kick your \"availability activation\" off by attaching a Lambda to the S3 output bucket.Background: I help run a streaming service and built the backend pipeline.This omits the entire \"metadata management and analytics\" side as well. That&#x27;s left as an exercise for the user. reply mikeryan 16 hours agoparentI would like to know what the costs come out to per minute of video encoded and how many outputs they&#x27;re getting in order to compare this to something like Media Convert (AWS), Google Transcode or something dedicated like Mux.For reference Google Transcoder is about $0.13 per minute of encoding (at four resolutions). Mux is at $0.032 &#x2F; min, AWS Media Convert $0.0188.I should note I know Mux&#x27;s pricing well, use them a lot, happily. It gets a bit confusing with Google and Media Convert because I&#x27;m not sure how these costs map to the resulting bitrate renditions that get created and I&#x27;ve not got the time for a deeper dive to get a more straight apples to apples comparison (ignore scale discounts)[1] https:&#x2F;&#x2F;cloud.google.com&#x2F;transcoder&#x2F;pricing[2] https:&#x2F;&#x2F;www.mux.com&#x2F;pricing&#x2F;video[3] https:&#x2F;&#x2F;aws.amazon.com&#x2F;mediaconvert&#x2F;pricing&#x2F; reply hckr1292 12 hours agorootparentFull disclosure, I currently work at Mux on the video product. Previously though, I worked at an education startup with user generated video content. Like many others commenting on this thread, I built a simple queuing system using RabbitMQ and celery, transcoding on EC2 with ffmpeg. While we might have saved some money by doing this in house, we almost certainly discouraged users from uploading content because the entire video needed to transcoded before it could be viewed. For use cases like the breaking news or high traffic user generated content, you really want to minimize wait time, and that requires some kind of special sauce. At Mux, we encode content just in time for very fast publish times. It’s very challenging to do this on your own. reply mrd3v0 7 hours agoparentprevDepending on proprietary software such as cloud offerings for something as essential to its requirements such as encoding is not sustainable, and will create technical debt as your software&#x2F;company will rely on the profitable success of the cloud service. reply jiggawatts 18 hours agoparentprevThis post is somewhat unfairly voted down.Cloud services like S3 and Azure Storage were invented specifically for hosting images and video. That’s their origin story, their foundation, their very reason for being.Similarly, cloud functions &#x2F; lambda were invented for background processing of blobs. The first demos were always of resizing images!Building out this infrastructure yourself is a little insane. Unless you’re Netflix, don’t bother. Just dump your videos into blobs.It’s like driving to your cousin’s place, but step one is building your own highway because you couldn’t be bothered to check the map to see if one already existed.PS: Netflix serves video from BSD running directly on bare metal because at that scale efficiency matters! If efficiency doesn’t matter that much, use blobs. Kubernetes is going to be even worse. reply dilyevsky 13 hours agorootparentI actually worked on system just like OP is describing and we ran everything ourselves including DBs (on k8s) so I can offer some perspective. For egress heavy services such as video minimizing outrageous cloud egress fees is key. Having an ability to tell your cloud account manager you can easily run multi-cloud or on-prem makes it a lot easier to negotiate sane rates.Ultimately you’re competing with the likes of Twitch (IVS), youtube and cloudflare on price and they ALL run their own compute so at certain size you will have to run your own hardware to stay competitive especially now that zirp is in rear view mirror.See Dropbox as another example of this but in documents&#x2F;storage space reply TheFragenTaken 8 hours agoparentprevRecently got burnt by Microsoft deprecating Azure Media Services, so I can understand if the author doesn&#x27;t want to use a cloud offering for encoding. reply c7DJTLrn 15 hours agoparentprevIf I&#x27;m understanding correctly you&#x27;re suggesting using Lambda for processing. Is that a good idea? Lambda is actually expensive for heavy workloads. reply goeiedaggoeie 3 hours agorootparentIf your video is short enough to encode in the lambda limit it is worth considering that https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;media&#x2F;processing-user-generated... mediaconvert is expensive, generally AWS video stack is expensive (MediaConvert, Elemental, Media Connect) reply pyrophane 15 hours agorootparentprevI believe the Lambda would just trigger a MediaConvert process, so it would actually be doing very little. reply c7DJTLrn 14 hours agorootparentAh, got it, thanks. reply jonnycoder 19 hours agoparentprevWhat would you recommend using as an alternative to being locked into AWS? reply whalesalad 14 hours agoparentprevserverless on aws is underrated if your workload can fit on it. i have an app that hasn&#x27;t received a single ounce of maintenance in like 3 years that still \"just works\", collects revenue from stripe, does all the business logic on lambdas, generates downloadable print-friendly pdf&#x27;s on lambdas, etc. the supporting tech is dynamo + triggers for lambda, s3 and related triggers for lambda. but it would be hard for a non-expert aws user to fathom this sort of architecture, so i don&#x27;t fault others for falling down the nih rabbit hole. reply irksomehails 2 hours agorootparentHey, just curios, can you link your app. reply _joel 16 hours agoparentprevNot one mention of MPEG-DASH reply bmurphy1976 13 hours agorootparentYou need to use MPEG DASH if you are contractually obligated to use DRM. You can create an M3U8 and an MPEG DASH manifest that share the same encrypted segment files. reply mikeryan 16 hours agorootparentprevI believe thats what \"or the other thing (which I keep forgetting the acronym for).\" was referring to. reply _joel 8 hours agorootparentWell it&#x27;s an international standard, no biggie. reply FaisalMahmoud 18 hours agoprevFor general video streaming, Mux.com has greatly decreased my development time. Getting playback working is straightforward. And for advanced use cases, like real time editing and preview in a web browser, it works as expected and doesn’t get in the way. reply totallyunknown 20 hours agoprevWhile the article provides guidance on utilizing standard software and services to construct a basic video upload platform, it lacks deeper insights into advanced scaling techniques. reply jspizziri 16 hours agoprevWe’ve built a similar pipeline architecture for our product. One key thing I’ll mention is that we’re using Shaka-streamer which is a python wrapper around Shaka-packager (which in turn is a wrapper around ffmpeg). We queue our transcode jobs into a redis queue, and use k8s to scale the transcode workers based on queue volume. Lastly, as a few folks have mentioned, we have an experimental on-prem transcoding cluster with consumer grade HW that is pretty cheap.If you’re interested in working on transcoding I’d highly recommend taking a look at Shaka-packager&#x2F;streamer. reply dilyevsky 13 hours agoprevI used to work on system like this and even built the logic to use preemptible pool effectively just like OP. If I had to design it from scratch today I would use Temporal for job scheduling - their durable compute concept is perfect fit for this and we had a lot of trouble maturing the equivalent scheduling system trying to keep up with rapidly growing scale reply sonof0dn 7 hours agoprevGreat article. The other day in my local dev group I gave a talk about something similar but much less sophisticated. reply adityapatadia 12 hours agoprevShameless plug here. In case someone does not want to build any of this and still stream video, you can check https:&#x2F;&#x2F;www.gumlet.com reply andrewstuart 21 hours agoprevMust be expensive to run on Google Cloud.Also looks pretty complex.The stabilization step presumably does a video encode …. that’s extremely expensive in terms of time, compute and money I wonder why it’s necessary. reply alexandreolive 19 hours agoparentHello, I&#x27;m the writer of the article. Our solution gets videos from random people who present products we sent them. We get dodgy videos filmed on bad devices, and the process of contacting the user and getting him to re-upload another video in better quality is time-consuming for our team. We&#x27;d rather spend a little bit more in computing to try and save time overall. I hope this answers your question. reply klaussilveira 21 hours agoparentprevI wonder if it wouldn&#x27;t be cheaper to run an on-prem farm of BestBuy-grade \"gamer PC\" for smaller scale networks like that. reply dilyevsky 12 hours agorootparentTwitch used to use cheap cores with Intel quicksync and maybe still does reply andrewstuart 20 hours agorootparentprevSlap one of these puppies in….AMD Alveo MA35D Media Acceleratorhttps:&#x2F;&#x2F;www.xilinx.com&#x2F;applications&#x2F;data-center&#x2F;video-imagin... reply goeiedaggoeie 19 hours agorootparentIve used xilinx a fair bit for encoding. once you get past the pain of compiling your tooling for it it does speed up VOD encode significantly. reply dilyevsky 12 hours agorootparentHow’s the quality? I heard it was so-so and i think you can’t close your own presets reply latchkey 21 hours agoparentprevNot necessarily. GCP, when used correctly, can be super cheap. You also don&#x27;t know the contractual deals they have with GCP. reply tehlike 21 hours agoparentprevI was thinking the same. CF on the front would improve on it but still.Hetzner or other bare metal providers would probably be a better idea. reply hotnfresh 19 hours agorootparentCF meaning Cloudflare? If you’re serving video through them, then you’re in “enterprise plan” territory. You can’t do that on the free or “self-serve” paid plans. $5k+&#x2F;m depending on bandwidth needs (and if you just need a cdn to push bits, CF won’t be competitive on price—their enterprise prices are tailored for companies that want all sorts of managed services and private networking stuff) reply mikeryan 14 hours agorootparentUm. Cloudflare stream starts at $5 per month and you don’t pay for encoding only storage and bandwidth. You can serve a decent video library for $500 per month.https:&#x2F;&#x2F;www.cloudflare.com&#x2F;products&#x2F;cloudflare-stream&#x2F; reply hotnfresh 13 hours agorootparentAh, must’ve changed up their billing structure to provide more add-ons for the self-serve plans since last time I was dealing them them. That’s good. replyandrewstuart 21 hours agoprevI have to ask, why bother with Kubernetes and all the associated config and pain? Why not just start a new spot instance? I can’t see any reason for Kubernetes in this architecture even though it’s the title of the post.Also personally I wouldn’t use rabbitmq … it’s pretty heavyweight… there’s lots of lightweight queues out there. Overall this architecture looks like it could be simplified.Also, the post doesn’t mention if the video encoding uses GPU hardware acceleration. Makes a big difference especially if using spot instances …. ffmpeg in CPU is extremely computationally expensive.Presumably all input videos need reencoding to convert them to HLS. reply alexandreolive 19 hours agoparentHello, I&#x27;m the writer of the article. We are using Kubernetes for our whole architecture, consisting of around 40 microservices and cron jobs. I just wanted in this article to give an example of asynchronous architecture using Kubernetes and RabbitMQ.We are using RabbitMQ because it&#x27;s my company target solution. There might better so lighter solution that would fit us but having just one for every solution is easier to maintain.Great comment about GPU hardware acceleration for encoding, I&#x27;m going to look this up. reply andrewstuart 18 hours agorootparentSo Kubernetes is only in this architecture because other systems use it and its required by the parent company but not needed.That&#x27;s pretty important context. reply alexandreolive 18 hours agorootparentThat&#x27;s not what I said; sorry if that was not clear. The parent company requires RabbitMQ, we are using Kubernetes because managing 40 microservices without it would be hell. In the article, I only showed 1 user-facing API, but it&#x27;s actually multiple services, I just did not want to complicate it too much. replymihaitodor 20 hours agoparentprevI believe loads of auxiliary microservices have been omitted for brevity. Of course, those also don’t require Kubernetes, but maybe they have some standardised deployment system which keeps things manageable. Don’t forget about Observability and whatnot. reply pyrophane 17 hours agoparentprevWhy do you say RabbitMQ is heavyweight? What queues do you consider more lightweight and what would be your go-to in a situation like this? reply KronisLV 8 hours agorootparentThey might be thinking of something like ZeroMQ, which is pretty well liked: https:&#x2F;&#x2F;zeromq.org&#x2F;That said, I wouldn&#x27;t call RabbitMQ that heavyweight myself, at least when compared to something like Apache Kafka. reply malux85 20 hours agoparentprevThis is what I was wondering, in the article it looks like kubernetes is just used to launch the node containers - why is the database and rabbitmq outside of kubernetes? This architecture looks like it’s been cobbled together by a junior reply sass_muffin 15 hours agorootparentIt is actually the opposite, it is currently considered a good practice to run stateful workloads outside of kubernetes and stateless workloads inside of kubernetes. reply KronisLV 8 hours agorootparent> It is actually the opposite, it is currently considered a good practice to run stateful workloads outside of kubernetes and stateless workloads inside of kubernetes.Is that still true?I wouldn&#x27;t call the parent comment charitable enough, because there definitely can be some reasons for running stateful workloads even outside of containers altogether (familiarity included), but at the same time it feels like a lot of effort has been invested into making that a non-issue.For example, how many database Operators are now available for Kubernetes: https:&#x2F;&#x2F;operatorhub.io&#x2F;?category=Database&capabilityLevel=%5...Honestly, as long as you have storage and config setup correctly, it&#x27;s not like you even need an Operator, that&#x27;s for more advanced setups. I&#x27;ve been running databases in containers (even without Kubernetes) for years, haven&#x27;t had that many issues at small&#x2F;medium scale. reply baq 19 hours agorootparentprevThere some of us who still perform four extra steps before putting any DB in k8s and we have good reasons. reply robertlagrant 19 hours agorootparentprevKubernetes loves stateless services. Zero wrong with moving RabbitMQ or a database outside of it. reply malux85 19 hours agorootparentExcept kubernetes has a whole storage provisioning system that gives you redundancy and automatic failover, if you’re going to the trouble of running kubernetes why not just run your whole infra on it?I run https:&#x2F;&#x2F;atomictessellator.com solo, using kubernetes, and my database, Minio object store, application servers, quantum workers, everything is all on kubernetes, it’s self healing and much simpler to run all the infrastructure the same.Recently I had a node failure while I was sleeping and the whole system healed itself while I slept, the monitoring system didn’t even alarm me because the small blip of increased latency while the pods rebalanced wasn’t above the alert threshold so it didn’t even wake me up.What happens in the article infra when the rabbitmq or database nodes fail? The whole system goes offline, which seems very silly setup when you have kubernetes sitting right there, who’s primary function is to handle all of this. reply codenesium 13 hours agorootparentRabbit and most databases have their own failover strategy. Putting it all on k8s is fine for a toy app but idk why anyone would deploy a real system like that. reply malux85 9 hours agorootparentOK, I can only speak to my personal projects and 20+ years experience at work.We run all of our stateful and stateless workloads on 10+ kubernetes clusters at work in multiple datacenters in multiple continents, and we serve 500 million users a month with it.I wrote the first BORG version of DFP backend systems at Google, where we served billions of users billions of ads a day, and we used stateful infrastructure management on some of the first container runtime systems that inspired k8s during it&#x27;s development.Using rabbit and \"most databases\" native fallover strategy is fine for toy projects, but when you&#x27;re operating at this scale, you need automated infrastructure provisioning and all of the automated tooling around it. reply robertlagrant 6 hours agorootparentThere are layers to this. At the simplest level, you only have K8s people (and aren&#x27;t willing to use cloud services). So you install the RabbitMQ Helm chart, hope for the best, and fix any issues that come up.Then you get a bit worried that the Postgres Helm chart, while good, doesn&#x27;t do what you want. So you update to use a dedicated clustered Postgres, using some Postgres clustering tech.Finally, you&#x27;re at so much scale you can throw giant wads of advertising cash at the problem, and you can use anything you like and it&#x27;ll work. You just need to choose the best thing for your particular problem. reply robertlagrant 17 hours agorootparentprevWhat happens when your storage detaches from your k8s cluster? Your services start 503ing, hopefully, because you didn&#x27;t design your system thinking that k8s == 100% uptime. reply malux85 17 hours agorootparentAnybody can invent random problems ad nauseam - that doesn’t prove anything.I’m not claiming that it’s totally bullet proof, I never said that - I’m saying that if you had a kubernetes cluster anyway why not benefit from its abilities? Especially when the alternative is single node, single points of failure, which is clearly inferior.The \"what if the storage detaches\" argument could easily apply to the single node VMs too, in which case the outcome would be a total system failure.We are discussing the contrast between the articles architecture and running everything on K8s ... and I&#x27;m saying that running everything on K8s is clearly better reply robertlagrant 6 hours agorootparent> Anybody can invent random problems ad nauseamI agree; I was replying to this invented problem:> What happens in the article infra when the rabbitmq or database nodes fail?It makes sense if you read the reply as a reply. reply jrockway 15 hours agorootparentprevYeah, what happens when someone in AWS clicks \"delete database\" accidentally? It&#x27;s the same thing that happens when K8s blows up in some weird way. You restore from your backup. (Fun fact: deleting the instance deletes the backups!) reply robertlagrant 6 hours agorootparentAgain, I was replying to:> What happens in the article infra when the rabbitmq or database nodes fail? replyakbansa 11 hours agoprev [–] I am sure it&#x27;s difficult for someone to build and scale video infrastructure. A few companies are doing it for you; plug in the APIs, and you&#x27;re done.Gumlet (https:&#x2F;&#x2F;www.gumlet.com): Per-title encoding (Netflix&#x27;s approach) to optimize and transcode your videos to boost engagement rates. Moreover, securing your videos is easy with digital rights management solutions paired with Widevine and Fairplay. Made for developers, by developers.Mux: Developer-friendly video infrastructure for your on-demand & live video needs.I love Gumlet because of their pricing and support. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article tackles the difficulties encountered in video streaming and details how to structure infrastructure to manage the load effectively.",
      "Key topics discussed include Kubernetes, RabbitMQ, and load balancers, with a particular focus on video upload, processing, and playback. Concepts such as Kubernetes auto-scaling and cost-saving with preemptible nodes are also addressed.",
      "The author wraps up by stressing the importance of a Content Delivery Network (CDN) to enhance video playback and caching."
    ],
    "commentSummary": [
      "The article touches upon the intricacies of video streaming, including managing myriad formats and languages, copyright constraints, and the complexities of ad placement and linear streaming.",
      "The discussion involves the use of pre-existing solutions or open-source asset catalog management tools, suggests on-prem hardware for video encoding over locking into AWS, and explores potential use of Kubernetes in a company's framework.",
      "Video optimization and security solutions such as Gumlet and Mux are mentioned during the dialogue, even though no in-depth exploration of advanced scaling approaches or MPEG-DASH is provided in the principal text."
    ],
    "points": 263,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1696873892
  },
  {
    "id": 37823377,
    "title": "Bare-metal Rust in Android",
    "originLink": "https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html",
    "originBody": "Security Blog The latest news and insights from Google on security and safety on the Internet Bare-metal Rust in Android October 9, 2023 Posted by Andrew Walbran, Android Rust Team Last year we wrote about how moving native code in Android from C++ to Rust has resulted in fewer security vulnerabilities. Most of the components we mentioned then were system services in userspace (running under Linux), but these are not the only components typically written in memory-unsafe languages. Many security-critical components of an Android system run in a “bare-metal” environment, outside of the Linux kernel, and these are historically written in C. As part of our efforts to harden firmware on Android devices, we are increasingly using Rust in these bare-metal environments too. To that end, we have rewritten the Android Virtualization Framework’s protected VM (pVM) firmware in Rust to provide a memory safe foundation for the pVM root of trust. This firmware performs a similar function to a bootloader, and was initially built on top of U-Boot, a widely used open source bootloader. However, U-Boot was not designed with security in a hostile environment in mind, and there have been numerous security vulnerabilities found in it due to out of bounds memory access, integer underflow and memory corruption. Its VirtIO drivers in particular had a number of missing or problematic bounds checks. We fixed the specific issues we found in U-Boot, but by leveraging Rust we can avoid these sorts of memory-safety vulnerabilities in future. The new Rust pVM firmware was released in Android 14. As part of this effort, we contributed back to the Rust community by using and contributing to existing crates where possible, and publishing a number of new crates as well. For example, for VirtIO in pVM firmware we’ve spent time fixing bugs and soundness issues in the existing virtio-drivers crate, as well as adding new functionality, and are now helping maintain this crate. We’ve published crates for making PSCI and other Arm SMCCC calls, and for managing page tables. These are just a start; we plan to release more Rust crates to support bare-metal programming on a range of platforms. These crates are also being used outside of Android, such as in Project Oak and the bare-metal section of our Comprehensive Rust course. Training engineers Many engineers have been positively surprised by how productive and pleasant Rust is to work with, providing nice high-level features even in low-level environments. The engineers working on these projects come from a range of backgrounds. Our comprehensive Rust course has helped experienced and novice programmers quickly come up to speed. Anecdotally the Rust type system (including the borrow checker and lifetimes) helps avoid making mistakes that are easily made in C or C++, such as leaking pointers to stack-allocated values out of scope. One of our bare-metal Rust course attendees had this to say: \"types can be built that bring in all of Rust's niceties and safeties and yet still compile down to extremely efficient code like writes of constants to memory-mapped IO.\" 97% of attendees that completed a survey agreed the course was worth their time. Advantages and challenges Device drivers are often written in an object-oriented fashion for flexibility, even in C. Rust traits, which can be seen as a form of compile-time polymorphism, provide a useful high-level abstraction for this. In many cases this can be resolved entirely at compile time, with no runtime overhead of dynamic dispatch via vtables or structs of function pointers. There have been some challenges. Safe Rust’s type system is designed with an implicit assumption that the only memory the program needs to care about is allocated by the program (be it on the stack, the heap, or statically), and only used by the program. Bare-metal programs often have to deal with MMIO and shared memory, which break this assumption. This tends to require a lot of unsafe code and raw pointers, with limited tools for encapsulation. There is some disagreement in the Rust community about the soundness of references to MMIO space, and the facilities for working with raw pointers in stable Rust are currently somewhat limited. The stabilisation of offset_of, slice_ptr_get, slice_ptr_len, and other nightly features will improve this, but it is still challenging to encapsulate cleanly. Better syntax for accessing struct fields and array indices via raw pointers without creating references would also be helpful. The concurrency introduced by interrupt and exception handlers can also be awkward, as they often need to access shared mutable state but can’t rely on being able to take locks. Better abstractions for critical sections will help somewhat, but there are some exceptions that can’t practically be disabled, such as page faults used to implement copy-on-write or other on-demand page mapping strategies. Another issue we’ve had is that some unsafe operations, such as manipulating the page table, can’t be encapsulated cleanly as they have safety implications for the whole program. Usually in Rust we are able to encapsulate unsafe operations (operations which may cause undefined behaviour in some circumstances, because they have contracts which the compiler can’t check) in safe wrappers where we ensure the necessary preconditions so that it is not possible for any caller to cause undefined behaviour. However, mapping or unmapping pages in one part of the program can make other parts of the program invalid, so we haven’t found a way to provide a fully general safe interface to this. It should be noted that the same concerns apply to a program written in C, where the programmer always has to reason about the safety of the whole program. Some people adopting Rust for bare-metal use cases have raised concerns about binary size. We have seen this in some cases; for example our Rust pVM firmware binary is around 460 kB compared to 220 kB for the earlier C version. However, this is not a fair comparison as we also added more functionality which allowed us to remove other components from the boot chain, so the overall size of all VM boot chain components was comparable. We also weren’t particularly optimizing for binary size in this case; speed and correctness were more important. In cases where binary size is critical, compiling with size optimization, being careful about dependencies, and avoiding Rust’s string formatting machinery in release builds usually allows comparable results to C. Architectural support is another concern. Rust is generally well supported on the Arm and RISC-V cores that we see most often, but support for more esoteric architectures (for example, the Qualcomm Hexagon DSP included in many Qualcomm SoCs used in Android phones) can be lacking compared to C. The future of bare-metal Rust Overall, despite these challenges and limitations, we’ve still found Rust to be a significant improvement over C (or C++), both in terms of safety and productivity, in all the bare-metal use cases where we’ve tried it so far. We plan to use it wherever practical. As well as the work in the Android Virtualization Framework, the team working on Trusty (the open-source Trusted Execution Environment used on Pixel phones, among others) have been hard at work adding support for Trusted Applications written in Rust. For example, the reference KeyMint Trusted Application implementation is now in Rust. And there’s more to come in future Android devices, as we continue to use Rust to improve security of the devices you trust. Labels: android , android security , rust No comments : Post a Comment    Labels   Archive  Feed Follow @google Follow Give us feedback in our Product Forums. Google Privacy Terms",
    "commentLink": "https://news.ycombinator.com/item?id=37823377",
    "commentBody": "Bare-metal Rust in AndroidHacker NewspastloginBare-metal Rust in Android (googleblog.com) 261 points by iamd3vil 21 hours ago| hidepastfavorite110 comments kajaktum 16 hours agoI don&#x27;t get mailing lists. See this https:&#x2F;&#x2F;lists.denx.de&#x2F;pipermail&#x2F;u-boot&#x2F;2022-March&#x2F;478466.htm...So where is the patch? reply 5- 15 hours agoparentthe git-send-email format for a patch series is the cover letter (the one you are looking at) and then one message per commit (subsequent emails in the thread).mailman is not the best interface for reading these; people would normally use their mail client, or specialised tools like patchwork.e.g. this series on patchwork: https:&#x2F;&#x2F;patchwork.ozlabs.org&#x2F;project&#x2F;uboot&#x2F;cover&#x2F;20220320114...(click &#x27;expand&#x27; in the &#x27;series&#x27; line) reply hackernudes 15 hours agoparentprev00&#x2F;12 is the description. The rest of them are 01, 02, etc...It all works great if you are actually subscribed to the mailing list. The kernel \"lore\" site has a better interface to the mailing lists and can download stuff as mbox files - https:&#x2F;&#x2F;lore.kernel.org&#x2F;all&#x2F;20220329165900.1139885-1-ascull@...There is also a service called \"patchwork\" that collects these patches in a web page format reply theusus 21 hours agoprevI found adoption of Rust being slow, but it has started to grow. reply outworlder 16 hours agoparentIt&#x27;s incredibly fast compared to most programming languages. reply trealira 14 hours agorootparentI wasn&#x27;t around for it, but didn&#x27;t C grow fast during the 70s and 80s?And didn&#x27;t Java and JavaScript also spread pretty fast? Of course, Java was explicitly promoted and advertised by Sun, and JavaScript played off of Java&#x27;s popularity and later became a web standard. reply kibwen 14 hours agorootparentC was definitely a player in the 70s and 80s (when it (and Unix) still had a lot of healthy competition), but it didn&#x27;t attain its current veneer of ubiquity until approximately the early 90s (after being standardized in 1989). Javascript was derided as a joke until 2009 brought ECMAScript 5 and Node.js. Java&#x27;s rise was relatively fast, but Java also had the benefit of the most concerted corporate ad campaign in the history of programming languages (how many programming languages have you seen advertised on TV? https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=FpirOZe1Cgk ) reply pjmlp 6 hours agorootparentRegarding Java, it also helped that big Smalltalk players like IBM, decided to fully pivot into Java, and many Oracle haters might not realise that alongside IBM, they were the first ones to have alternative JVMs and were together with Sun in the Network Computer effort.Smalltalk had a .NET like role in OS&#x2F;2, one of the reasons SOM even supported metaclasses, just imagine the alternative universe. reply samus 8 hours agorootparentprevJavaScript was a web standard right from the beginning. Its popularity grew together with the web itself by virtue of being the only programming language that could be counted on to be available on websites.Flash and Java both required plugins, didn&#x27;t integrate well with the rest of the website, were quite heavyweight, and frequently got bad publicity due to security bugs.Of course, browsers themselves also had them aplenty, but at the end of the day one can&#x27;t use the internet without one :) reply p4ul 14 hours agorootparentprevThis is exactly right! I believe C&#x27;s popularity grew so quickly because of its correlation with the popularity of Unix and its descendants. And yes, Sun pushing Java very hard certainly grew its adoption.JavaScript is a really interesting case; initially, I don&#x27;t think it was really taken very seriously. It was mostly tolerated because of its privileged status as part of the web platform. But since so much has moved from desktop application to the browser, that privileged status has proven all the more valuable! reply tialaramex 13 hours agorootparent> with the popularity of Unix and its descendantsand with that the Internet. In 1990 UK higher education sites had \"high speed\" (megabit sometimes!) networking but they used X.25 \"Coloured Book\" protocols. There were a handful of well developed applications for services such as email, but experimenting with novel software on X.25 was difficult. In 1991 JANET (the people providing these network services to Universities, then and now) began JIPS, an experiment to try out Internet protocols.Enthusiasm for JIPS was enormous. You could buy or, since you have an electronics department and an essentially inexhaustible supply of nerds, build, a Unix computer, and just like, write your own BSD sockets software. I hear a guy over a CERN has invented a World Wide Web we should check out... In less than a year JIPS ceased to be an \"experiment\" and by the time I arrived at a University a few years later X.25 was deprecated and few people cared that it was still technically available somewhere. reply pjmlp 9 hours agorootparentprevNot at all, it was only relevant to UNIX users. reply kramerger 8 hours agorootparentprevI think Java was much faster.Rust is 8 years old and is still not fully stable (you need nightly for a lot of projects). Projects are planning and adding support but not many are actually using it yet.Java was the hotest thing on the job market after only 3-4 years. reply kaba0 6 hours agorootparentYour reasoning is not quite correct (rust’s nightly has no relevance here), but you are right in that Java seen an unprecedented growth, and probably no other language will ever demonstrate anything like that due to the “market” being so saturated since. Even if it would be the silver bullet language. reply az09mugen 18 hours agoprevI may have wrong assumptions, but I find it funny they didn&#x27;t use Golang. Is it not capable of doing the same thing ? Anyway, happy to see rust being adopted for that usage. reply izacus 17 hours agoparentNo, Go isn&#x27;t appropriate for these things. Use the best tool for the job reply digdugdirk 17 hours agorootparentCan you please explain why Go isn&#x27;t appropriate here? reply okanat 15 hours agorootparentNot just garbage collection but also the way hardware work is done with languages that allow you to write one-to-one memory representations in order to be able to drive raw interfaces of hardware. A GC language almost always comes with a reference based type system that hides the very interfaces you&#x27;d like to access (fast) and adds deserialization overhead which has visible performance and battery life effects.The other reason is C interoperation. All of the common systems rely on C. C is not just a programming language. Since 80s everybody designs systems on top of C. We ended up with OSes written in C that ship their tightly integrated C compiler that outputs binaries optimized for C&#x27;s memory layout and primitives that the very same OS runs on silicon that&#x27;s optimized to run C fast. C unfortunately became the meta-language of the low level APIs.Go&#x27;s interoperability with C is out of hell. Its green-thread scheduler doesn&#x27;t play well with C. The foreign function interface is defined in the comments (!) of a source file and making CGo work on custom cross toolchains is full of hard to solve compiler errors.Rust can operate at the same level as C easily and it has all the low level primitives. C interoperability is a core language function that&#x27;s part of the syntax and standard library. It solves many gotchas of C without compromising speed. reply pjmlp 9 hours agorootparent> Since 80s everybody designs systems on top of C.More like since the 1990&#x27;s, as outside UNIX during the 1980&#x27;s no one cared about C, and mostly thanks to the GNU Manifesto and FOSS uptake that took the steam out of C++ adoption being pushed by Apple, IBM and Microsoft.There is firmware in production written in Go,https:&#x2F;&#x2F;www.withsecure.com&#x2F;en&#x2F;solutions&#x2F;innovative-security-... reply defrost 9 hours agorootparentI did a lot of cross platform development work from 1982 onwards and 1987 was very much the year of C for IntelDOS machines - they were cheap (comparitively), widely available and Borlands Turbo C was a fully integrated IDE that was affordable (and|or pirated) with some outstanding manuals.Between that and their ASM for low level work, C took off in a big way and Pascal sharply dwindled in popularity (although it still hung on for a long time, even up to the present).https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Borland_Turbo_CThere were better more expensive tools, but that was the product that planted a flag for widespread C development. reply pjmlp 9 hours agorootparentIn Europe, in a MS-DOS world without cross-platform considerations, it took until Windows 3.x release, and Watcom C++ with its DOS extender for folks to really care about C and C++.In fact, we used Turbo C 2.0 to prepare our code samples to deploy them into a single Xenix computer shared across the whole school, and that was it, nothing else. reply defrost 7 hours agorootparentWatcom was a much much better compiler and was welcomed with open arms to be sure - I still have a copy of the last release and use it on occassions.If we&#x27;re waxing historic here, my first C compiler (of my own and not a university VAXPDP version) was the CainHendrix Small C compiler (released 1980) which I handcopied in 1982 and extended over the next year or three as I read the Dragon books and other works .. bit of a side exercise while doing an engineering degree and working on a sheep shearing robot.Thank-you Dr. Dobb&#x27;s Journal of Computer Calisthenics & Orthodontiahttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Small-C reply hactually 15 hours agorootparentprevI disagree - working with CGo is really easy and predictable in behaviour.Cross compilation for Go is no more difficult than cross compiling Rust + .so &#x2F; .a files reply sangnoir 17 hours agorootparentprevBinary size, for one. The blog mentions a binary file grew from 220kb (C) to over 400kb (Rust).I also doubt a garbage-collected language work very well for drivers that require precise timing (MMIO) and&#x2F;or control over memory allocation. reply pjmlp 1 hour agorootparentIt worked rather well for Xerox PARC, TI, Genera and others, had they not mismanaged their products, or fighting against workstations being built with a free beer OS. reply izacus 17 hours agorootparentprevThe non-JVM code used in mentioned context will run in environments where yet another GC fighting the JVM GC isn&#x27;t desired or have to be a shared library talking to existing JVM code. While you can use Go to build libraries with C calling convention, it&#x27;s not the most supported use case and it shows in ergonomics. This also includes standard Go types and standard library which don&#x27;t fit nicely into a model where code needs to talk a lot with JVM world.It&#x27;s possible... But it feels like screwing screws with a knife. It&#x27;s doable, but noone from the language designers, stl designers and library developers are really thinking about that use case.Rust on the other hand fits very well into the model where it needs to be just a piece of a bigger whole - it&#x27;s been built that way (\"system\" programming language) and it doesn&#x27;t come with GC that will fight with JVM or Binder lifetimes, compatible type system and plenty of libraries that help develop libraries on an embedded platform. When building the language, Rust designers consider this as one of the main use cases of the language and it shows with how much less hassle it is to work with.The fact that it easily fits into existing C&#x2F;C++ codebases helps too. reply pix128 17 hours agorootparentprevGo is garage collected reply kaba0 6 hours agoparentprevGo is not a low-level language. They already have Java which sits at the exact same level. reply sureglymop 2 hours agorootparentThey have kotlin which can even compile to native binaries that run without a VM. reply kaba0 2 hours agorootparentThat can only compile a very limited subset of normal code.But no need for that, Android already does AOT. reply jiripospisil 21 hours agoprevIs there similar effort from Apple? reply pjmlp 19 hours agoparentApparently people keep forgetting Swift exists.\"CppNow 2023:Introducing a Memory-Safe Successor Language in Large C++ Code Bases\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lgivCGdmFrw reply adastra22 17 hours agorootparentSwift is a different class than rust though. reply pjmlp 10 hours agorootparentNot for Apple,> Swift was designed from the outset to be safer than C-based languages, and eliminates entire classes of unsafe code.-- https:&#x2F;&#x2F;www.swift.org&#x2F;about&#x2F;> Swift is a successor to the C, C++, and Objective-C languages-- https:&#x2F;&#x2F;developer.apple.com&#x2F;swift&#x2F; reply diogenes4 13 hours agorootparentprevSorry, what does swift have to do with this? reply pjmlp 10 hours agorootparentSwift is Apple&#x27;s answer to replacing C derived languages, they don&#x27;t need Rust.> Swift is a successor to the C, C++, and Objective-C languages -- https:&#x2F;&#x2F;developer.apple.com&#x2F;swift&#x2F;They also mention plans for kernel and firmware targets on that talk. reply monocasa 21 hours agoparentprevI don&#x27;t believe Apple has embraced Rust the same way Google has. Particularly their firmware is still very based on C. reply dagmx 21 hours agorootparentSpecifically a dialect called Firebloom (supposedly anyway)https:&#x2F;&#x2F;saaramar.github.io&#x2F;iBoot_firebloom&#x2F; reply mrpippy 21 hours agorootparentPossible related to the ‘-fbounds-safety’ feature they’ve proposed for Clanghttps:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;rfc-enforcing-bounds-safety-in-... reply jonpalmisc 20 hours agorootparentFirebloom == `-fbounds-safety` reply jonpalmisc 20 hours agorootparentprevFirebloom is more of a custom compiler&#x2F;toolchain than a dialect of C—apart from annotations to relate pointer+length parameters, etc., it is still just C. reply jd3 18 hours agorootparentReminds me of this blurb from djb&#x27;s qmail security guarantee [0]:> I&#x27;ve mostly given up on the standard C library. Many of its facilities, particularly stdio, seem designed to encourage bugs. A big chunk of qmail is stolen from a basic C library that I&#x27;ve been developing for several years for a variety of applications. The stralloc concept and getln() make it very easy to avoid buffer overruns, memory leaks, and artificial line length limits.[0]: http:&#x2F;&#x2F;cr.yp.to&#x2F;qmail&#x2F;guarantee.html reply jonpalmisc 20 hours agorootparentprevThe other commenter mentioning Firebloom is correct that some firmware (iBoot family) has been using C w&#x2F; Firebloom extensions for a while. Parts of SEPOS also use Swift, which would make more sense as a non-C language than Rust, from Apple&#x27;s perspective at least. reply candiddevmike 21 hours agoparentprevWhat benefit would Apple get from this? They want you all in on an ecosystem they control.EDIT: Thought OP was talking about writing iOS apps using Rust. reply steveklabnik 20 hours agorootparentApple does use Rust, though from job postings, we can infer it&#x27;s more like network services than firmware.Regardless though, I don&#x27;t see how the implementation language of your firmware is locking you into a specific ecosystem, so this criticism seems misguided to me. reply 1f60c 20 hours agoprevIdeally, Android wouldn’t have any security vulnerabilities, but that’s not realistic. Rust won’t prevent every bug (and it’s even possible to cause segmentation faults in an ostensibly safe language like Python), but “better” is still a huge leap forward. reply kupopuffs 17 hours agoparentjust.... no more buffers overflown reply vitiral 16 hours agorootparentOr dead pointers used, or race conditions reply tialaramex 12 hours agorootparentNope. Race conditions are an ordinary fact about our universe, Rust has those. (Safe) Rust doesn&#x27;t have data races which are much stranger.Race conditions are just an ordinary effect where several actors are doing things and you need to be careful to ensure that they&#x27;re co-ordinated properly if that&#x27;s important. If Alice and Bob both conclude there&#x27;s no milk, both then go to the store and buy milk, now there is too much milk.Data races are because it&#x27;s not possible to deliver what you intuitively expect from a computer which is capable of multiple notionally simultaneous operations. They have no analogue in our real world experience, which is why they&#x27;re baffling for real programmers on non-trivial software. The world stops making sense.Most programming languages which allow parallel computation have data races. In C and C++ they&#x27;re just Undefined Behaviour. Game over. In Go they&#x27;re sometimes not Undefined Behaviour if your race only touches very simple things like integers. In Java, interestingly, they&#x27;re always defined behaviour but it doesn&#x27;t help very much because the behaviour is extremely hard to reason about. Still, your program does do at least something sane even if your head hurts when you think about it. In safe Rust this never happens. reply kaba0 6 hours agorootparentJust to add: OCaml also recently introduced a new memory model which promises that data races can only corrupt a bounded part of the program (basically, even stronger guarantees than Java does). It comes with some runtime overhead, but quite interesting development, you might find worthwhile to check out. reply jon_richards 12 hours agorootparentprevSpeaking of race conditions, I recently looked into the current state of “make sure something is in the db and then retrieve it”. Absolutely bonkers that “on conflict do select” still doesn’t exist. replySuaveSteve 20 hours agoprevThe Doom of programming languages? Rust must be run everywhere with no irony. reply outworlder 16 hours agoparentPeople want to replace C, which runs anywhere. Rust must also be able to. reply lormayna 9 hours agorootparentRust is a replacement for C++; if you look for a C replacement you should look on Zig reply pjmlp 7 hours agorootparentPity that it is as good as C in producing UAF exploits, and doesn&#x27;t have any story for binary libraries. reply pjmlp 9 hours agorootparentprevC doesn&#x27;t run in 8 bit and DSP computers that well, dialects of it do though. reply kramerger 7 hours agorootparentAnd Rust does better?? reply pjmlp 7 hours agorootparentThe point being that C doesn&#x27;t really run anywhere. reply asrael_io 19 hours agoparentprevYeah but does Doom run on rust-analyzer? reply gpm 17 hours agorootparentRust analzyer type checks rust and type checking is turing complete... it&#x27;s only a matter of time. reply ireallywantthat 21 hours agoprev [–] Ok, now enable us to let create Android Applications entirely in Rust (including the GUI). Let&#x27;s get rid of Kotlin&#x2F;Java monopoly in Android App development. Shall we? reply rohandhruva 20 hours agoparentTell me you&#x27;ve never done any Android development, without telling me...This is such a low-effort \"take\" without any effort to justify _why_ you&#x27;d want something like this. There&#x27;s a high amount of impedance mismatch trying to write GUIs in a non-GC language like Rust which _has_ to run on what&#x27;s essentially a Java VM (ART).At least with a language like Go, it somewhat makes sense, and has been attempted: https:&#x2F;&#x2F;gioui.org&#x2F;All this Java&#x2F;Kotlin bashing is getting really old, especially for a forum like this one. reply ireallywantthat 20 hours agorootparentI didn&#x27;t bash Java&#x2F;Kotlin. In fact, I have written few android apps in Kotlin, Java and I also have fiddled with Jetpack compose, JNI and NDK (I have also played with mpv&#x27;s Opengl&#x2F;Vulkan&#x27;s rendering on Android if that matters to you). I don&#x27;t want to share the projects of mine because i don&#x27;t want to reveal my identity.> https:&#x2F;&#x2F;gioui.org&#x2F;I know that tailscale&#x27;s android application is written in it but i don&#x27;t think gioui is great for android apps.> Tell me you&#x27;ve never done any Android development, without telling me...All this Java&#x2F;Kotlin bashing is getting really old, especially for a forum like this one.Ok, this one hurts. Why are you attacking me instead of defending your stance. All are allowed to have opinions and I am allowed to have one(It&#x27;s sad to explain this to someone on forum like this one). I dream of Linux-desktop kinda situation where you can program in any language you want, where you are not hindered by any platform&#x2F;framework, where you have complete freedom and where you don&#x27;t want to be bothered&#x2F;(vendor locked-in) by Bigcorps(looking at you Google services framework).> write GUIs in a non-GC language like Rust which _has_ to run on what&#x27;s essentially a Java VM (ART).Haha, non-GC languages power the GUIs on Android fyi. Jetpack compose is powered by Skia. Chromium is powered by Skia. Skia is C++.Please do your own research before commenting low-effort replies. reply rohandhruva 15 hours agorootparent> Haha, non-GC languages power the GUIs on Android fyi. Jetpack compose is powered by Skia. Chromium is powered by Skia. Skia is C++.Skia is not something you use to write apps: it&#x27;s a graphics engine, essentially something you use to draw polygons on the screen.> Why are you attacking me instead of defending your stance. All are allowed to have opinions and I am allowed to have oneI apologize if any of this sounded like an attack. I was trying to be funny with that meme-like sentence formation, but I don&#x27;t profess to disparage anyone&#x27;s skills or opinions.> I dream of Linux-desktop kinda situation where you can program in any language you want, where you are not hindered by any platform&#x2F;framework, where you have complete freedomLinux desktop is certainly not the dream world you describe. Practically, you _have_ to pick a toolkit: one of GTK &#x2F; KDE &#x2F; Qt &#x2F; electron &#x2F; etc. Maybe it helps to think of Android&#x27;s toolkit (Views or Compose) as one of those. reply ireallywantthat 8 hours agorootparent> Skia is not something you use to write apps: it&#x27;s a graphics engine, essentially something you use to draw polygons on the screen.So, AOSP team can obviously create Rust framework ontop of Skia(or tinyskia,femtovg,etc.), make Android APIs available in Rust, Create proper widget framework and let us create Android Applications written entirely in Rust.> Linux desktop is certainly not the dream world you describe. Practically, you _have_ to pick a toolkit: one of GTK &#x2F; KDE &#x2F; Qt &#x2F; electron &#x2F; etc. Maybe it helps to think of Android&#x27;s toolkit (Views or Compose) as one of those.I know what I am talking about. This is exactly the freedom that I was talking about. I am able to choose any framework&#x2F;toolkit I want. If i don&#x27;t want any framework, that&#x27;s fine too. You don&#x27;t have that freedom in Android. Everything has to be routed via Java ecosystem that AOSP constructed. reply pjmlp 9 hours agorootparentprevCalm down with that \"Haha\", all those native libraries powering Android are behind JNI walls, and even NDK code is obliged to make use of JNI to call into them.Please do your own research on how AOSP is actually implemented. reply ireallywantthat 8 hours agorootparentCalmed down.> behind JNI walls, and even NDK code is obliged to make use of JNI to call into them.What i originally told was \"enable us to let create Android Applications entirely in Rust (including the GUI)\" . Surely Google and AOSP projects can remove the restrictions that you mentioned and provide us alternative to Kotlin&#x2F;Java ecosystem which is what i really want and hope them to do. Smartphones powered by Android are capable computers and freedom for App development is appreciated.Please don&#x27;t mention once again that \"X is not implemented in AOSP. Y is required to make use of JNI calls into them\". You know that this is superficial barrier and can be overcome&#x2F;corrected if they wanted to. reply pjmlp 8 hours agorootparentIf you want freedom for app development buy a Pinephone or Librem 5 device.Android Brillo demise already proved that isn&#x27;t what Google cares about. reply jeroenhd 18 hours agorootparentprevThere&#x27;s a reason Chrome is mostly written in C++. Android&#x27;s JVM system is a collection of Java wrappers around C++ libraries. There&#x27;s some overhead in that translation layer, and it&#x27;s unfortunate that you can&#x27;t skip it. Even Google&#x27;s own Flutter uses a C++ engine to run Dart applications.Kotlin (and Java) is fast enough for many applications, but even with the recent advancements in ART, does have overhead compared to pure native code. I can&#x27;t think of a reason why the API interaction overhead would pose a problem, but if Google themselves can find use cases for almost JVM-less apps, I&#x27;m sure there are reasons to give a Rust version a try. reply izacus 17 hours agorootparent> Android&#x27;s JVM system is a collection of Java wrappers around C++ libraries.This isn&#x27;t even remotely true and it&#x27;s obvious if you&#x27;d ever looked closely at Android. This take is as bizarre as saying that whole web&#x2F;JS&#x2F;React ecosystem is \"just\" wrappers on top of Skia. reply kaba0 6 hours agorootparentprevAt the same time, GUIs really don’t work nicely&#x2F;as idiomatically without a GC. Most Rust GUIs do immediate mode only, which is a much more easier problem, and you won’t have to “argue” with the borrow checker constantly. But it would drain the battery of a phone in an hour (it would be the equivalent of running a proper 3D game as your notes app or whatever). reply rohandhruva 15 hours agorootparentprev> There&#x27;s a reason Chrome is mostly written in C++.And for that same reason, you don&#x27;t see many apps do the same thing. Any time Chrome needs to request a permission (access files, location, etc), it _has_ to use the system-provided Java APIs.> Even Google&#x27;s own Flutter uses a C++ engine to run Dart applications.As do most games, so you can essentially think of Flutter as a game engine that renders apps.> Android&#x27;s JVM system is a collection of Java wrappers around C++ libraries.As others have mentioned, this is very much not the case. reply ireallywantthat 8 hours agorootparent> it _has_ to use the system-provided Java APIs.My original comment was against this. Why should this be the case? reply diogenes4 13 hours agorootparentprev> There&#x27;s a reason Chrome is mostly written in C++Yea, security is not a concern. Apparently. reply tempaccount420 4 hours agorootparentThey didn&#x27;t have Rust around when they started. reply ForkMeOnTinder 19 hours agorootparentprev> At least with a language like Go, it somewhat makes sense, and has been attempted: https:&#x2F;&#x2F;gioui.org&#x2F;Gio UI is an immediate-mode UI, and immediate-mode UIs map very nicely to Rust. egui is quite expressive and easy to use. https:&#x2F;&#x2F;www.egui.rs&#x2F;If you had pointed at something like GTK, then yes, there is a big impedance mismatch there. reply voxl 20 hours agorootparentprevWhat does a GC have anything to do with it? You can reference count all the pointers if you want, you can expose JVM pointers in Rust where Rust doesn&#x27;t manage the heap memory. There are plenty of easy solutions to work with the JVM reply ncruces 18 hours agorootparentIf you&#x27;re willing to work with the JVM (i.e. through JNI), there&#x27;s really nothing stopping you.You can 100% make entire apps using nothing but C, C++, or whatever, as long as you&#x27;re willing to interface with the JVM that&#x27;s created for you to access Android APIs.But the Android API is a JVM API. There&#x27;s no getting around that. At this point, it&#x27;s another OS (i.e. not Android) if it doesn&#x27;t have Java in it. reply pjmlp 9 hours agorootparentActually there was such OS, Android Brillo and the OEM market said no, hence why it got replaced with Android Things, which re-introduced Java again. reply diogenes4 13 hours agorootparentprev> There&#x27;s a high amount of impedance mismatch trying to write GUIs in a non-GC language like RustSorry, what does the idea of a user interface have to do with garbage collection? They seem entirely unrelated at first blush, and it&#x27;s not difficult to find GUI code written in rust. reply kaba0 6 hours agorootparentImmediate mode vs retained mode. It is not a hard requirement, but the borrow checker definitely makes the latter more complex. reply grishka 20 hours agoparentprevYou can technically create an Android app without any Java code. There are native APIs for graphics and input. However, as these are intended for games, you get a window into which you can draw... something. With OpenGL, for example. You don&#x27;t get access to Android&#x27;s regular UI framework. You will also have to go through the Java layer to do many things you might want to do — like requesting permissions or launching other apps&#x27; activities.Here&#x27;s all the APIs you get: https:&#x2F;&#x2F;developer.android.com&#x2F;ndk&#x2F;reference?hl=en reply izacus 17 hours agorootparentThat&#x27;s not really what&#x27;s going on. Those \"native\" APIs you mention in most cases just call back to Java APIs under the hood. For better or worse, most of what Android is is written in Java. There&#x27;s no hidden \"C++\" layer of Android to access. reply kllrnohj 13 hours agorootparent> Those \"native\" APIs you mention in most cases just call back to Java APIs under the hoodSome do, but most don&#x27;t. reply okanat 15 hours agorootparentprevIn theory it is possible to write raw Binder calls to various Android services, skipping JNI in many places. However, it is basically rewriting the entire OS API and structure from scratch. reply defer 14 hours agorootparentYou can generate binder wrappers from aidl, that would work. This is fairly common when doing platform work (for those like me who work on the operating system rather than on apps).However, this would be a terrible idea because usually the android api is stable at the Java wrappers (I.e. ActivityManager), not at the aidl level, which would make this very fragile for app development across a multitude of devices and platform versions. reply izacus 9 hours agorootparentprevSure, and some NDK APIs do exactly that. But you&#x27;re still just using IPC to call into services written in Java, just using a different approach. reply nologic01 19 hours agorootparentprevYou can also \"outsource\" the Java based interaction with Android to somebody else, Qt style? https:&#x2F;&#x2F;doc.qt.io&#x2F;qt-6&#x2F;android-getting-started.html reply flohofwoe 19 hours agorootparentprevYou can call into any Android Java API from native code using JNI. It&#x27;s not exactly convenient, but you are not limited to the C APIs exposed by the NDK. reply grishka 18 hours agorootparentMany Android APIs expect you to extend classes and implement interfaces for things like callbacks. You can&#x27;t do that with JNI alone, you will have to have a .dex of your own anyway. reply azemetre 20 hours agoparentprevIsn&#x27;t this what Tauri wants to achieve? At least it&#x27;s on the roadmap I mean.https:&#x2F;&#x2F;tauri.app&#x2F;Does anyone have any experience creating production apps with Tauri? Seems like a sane alternative to Electron, especially if they can target all major platforms and keep the promise of smaller footprints. reply flohofwoe 19 hours agorootparentThe traditional alternative to Electron on mobile platforms is Capacitor (which uses the system webview, so in that sense it&#x27;s closer to Tauri):https:&#x2F;&#x2F;capacitorjs.com&#x2F;(fka Apache Cordova, fka PhoneGap) reply asrael_io 20 hours agorootparentprevNot quite production, but I was on a paid contract on a PoC. I would say back at 1.0, mobile was pretty painful and signing of any binary dependencies was up to you. It looks like they addressed signing in 1.5 and I haven&#x27;t picked it back up to check out the mobile experience. reply Thorrez 13 hours agoparentprevWhile not a bad idea, it doesn&#x27;t have the urgency of C->Rust because Java is already memory safe. reply adastra22 16 hours agoparentprevYou can though? I maintain a rust-only app. reply Vt71fcAqt7 20 hours agoparentprevYou can already. The ndk allows any language to be compiled to android. For rust seehttps:&#x2F;&#x2F;github.com&#x2F;rust-mobile&#x2F;ndkWhich has the tools to do this. reply wredue 21 hours agoparentprevWhat would rust achieve aside from just enabling another, entirely distinct from the existing workflow, language?Haven’t android apps been compiled to native code since like 2012? (I actually don’t know, I left android a while ago and stopped caring what they do) reply cogman10 20 hours agorootparentI don&#x27;t think it&#x27;s a good idea, mainly because android is multiplatform and rust, by it&#x27;s nature, is only available for what it&#x27;s built for. Unless you are giving google your rust code to compile, your app will be limited on it&#x27;s reach.All that said.Rust doesn&#x27;t have a GC so it&#x27;d (likely) have a lower memory consumption and could possibly be lighter on the CPU.Native compilation helps mainly with startup time and memory consumption. It&#x27;s not exactly great for runtime performance as it takes away some key optimizations.Another benefit of rust assuming you are distributing binaries is you&#x27;ll be able to use the latest version of Rust rather than being pinned to older versions of the SDK with partial support based on the whims of google. reply flohofwoe 19 hours agorootparent> Unless you are giving google your rust code to compile, your app will be limited on it&#x27;s reach.Android has supported native code in apps for a long time via the Android NDK, mainly to enable game development. The Android team seems to hate the NDK, but the alternative is to have no games on the platform, so they can&#x27;t simply kill it.> ...[native] ... It&#x27;s not exactly great for runtime performance as it takes away some key optimizations.In theory a JIT might produce better runtime performance than AOT compiled code, but in practice that usually turns out as wishful thinking. reply pjmlp 19 hours agorootparentThankfully ART not only uses JIT, it also has an AOT compiler with PGO data shared across all devices in the ecosystem via the Play Store.In practice, people should learn how Android actually works. reply flohofwoe 4 hours agorootparentThis just seems to prove my point that AOT is usually better than JIT? reply pjmlp 1 hour agorootparentNot really, because not only it uses PGO, which most people using AOT languages never bother to learn, it only AOT compiles the code paths that JIT validated as being used, instead of the whole application.JIT + AOT with PGO data shared across all Android devices on the planet, gets the best of both worlds. reply galangalalgol 20 hours agorootparentprevVM warmup isn&#x27;t consistently a thing, in fact for over a decade there has been plenty of observation of the reverse, that runtime optimization often slows performance. Systems languages (c&#x2F;c++&#x2F;rust) consistently outperform warmed up managed languages. And that is ok, it doesn&#x27;t mean we shouldn&#x27;t have managed languages, but they are slower. reply pjmlp 19 hours agorootparentManaged languages also exist in AOT with PGO data. reply shopvaccer 20 hours agorootparentprev>mainly because android is multiplatform and rust, by it&#x27;s nature, is only available for what it&#x27;s built forAndroid is one platform: android. I thought rust worked across multiple operating systems.>Rust doesn&#x27;t have a GC so it&#x27;d (likely) have a lower memory consumption and could possibly be lighter on the CPU.So what? I have never used G.C.>Native compilation helps mainly with startup time and memory consumption. It&#x27;s not exactly great for runtime performance as it takes away some key optimizations.That is fair I supposeI think the main benefit of rust&#x2F;c++&#x2F;ndk on android is that I can just port desktop programs and I don&#x27;t have to learn android&#x27;s java&#x2F;kotlin and sdk. reply wiseowise 19 hours agorootparent> Android is one platform: android. I thought rust worked across multiple operating systems.Operating systems, not architectures. You&#x27;d have to cross-compile your application 4 times if you want to support all arms and x86s.> I think the main benefit of rust&#x2F;c++&#x2F;ndk on android is that I can just port desktop programs and I don&#x27;t have to learn android&#x27;s java&#x2F;kotlin and sdk.It&#x27;s not \"just\" port desktop programs. Android doesn&#x27;t even use glibc. reply rstat1 20 hours agorootparentprevNot having to use Java or any of its weird derivatives. reply smith7018 20 hours agorootparentI implore you to try Kotlin; it’s a fantastic language and is a wonder to code in reply TheDesolate0 19 hours agorootparentI implore you to try Rust.Kotlin is just Java with extra steps. reply wiseowise 19 hours agoparentprev [–] Why? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google's Android Rust Team has rewritten the firmware for the Android Virtualization Framework in Rust to enhance security and safety on Android devices, effectively mitigating vulnerabilities often linked with memory-unsafe languages such as C.",
      "The team actively contributed to the Rust community by fixing bugs, enhancing existing crates, and creating new ones, while revealing ongoing challenges with shared memory, raw pointers, and lack of tools for encapsulation and abstractions for critical sections.",
      "Despite Rust resulting in a larger binary size as compared to C, through careful optimization and avoiding unnecessary dependencies, it can provide comparable results; however, specific architectural support still remains limited."
    ],
    "commentSummary": [
      "The discourse focuses on applying the Rust programming language in Android development, commenting on its aptness for low-level programming and compatibility with C.",
      "Rust's potential in app development is discussed due to its capabilities in eliminating data races. However, it's compared and contrasted with other languages such as C and Java.",
      "The conversation also includes the limitations and challenges of using Rust, such as its compatibility issues with Android's UI framework and memory consumption, reach, and runtime performance trade-offs."
    ],
    "points": 260,
    "commentCount": 110,
    "retryCount": 0,
    "time": 1696875200
  },
  {
    "id": 37821821,
    "title": "DNS record \"hn.algolia.com\" was gone",
    "originLink": "https://www.nslookup.io/domains/hn.algolia.com/dns-records/",
    "originBody": "DNS for developers module 3 just dropped — 10 lessons on operational DNS ✨ Domain name Find DNS records LearningBrowser extensionAPI DNS records for hn.algolia.com Cloudflare Google DNS OpenDNS Authoritative Local DNS The Cloudflare DNS server responded with these DNS records. Cloudflare will serve these records for as long as the time to live (TTL) has not expired. After this period, Cloudflare will update its cache by querying one of the authoritative name servers. A recordsIPv4 address Revalidate in104.16.46.55 4m 36s104.16.45.55 4m 36s AAAA records No AAAA records found. CNAME record No CNAME record found. TXT records No TXT records found. NS records No NS records found. The name servers for this domain are inherited from one of its ancestor domains. Try its parent domain: algolia.com. MX records No mail servers found. Other records Additional record type No SOA records found. Look up DNS records for another domain name With DNS lookup, you can find the DNS record for any domain name or subdomain. When you enter the domain, it will show all the DNS records that are configured for that domain. Domain name Find DNS records © 2023 DNS tools Reverse IP lookup DNS checker Website to IP lookup CNAME lookup TXT lookup Learning center DNS record types Browser extension Blog About Contact Advertise Privacy policy Terms and conditions Status Do Not Sell My Personal Information",
    "commentLink": "https://news.ycombinator.com/item?id=37821821",
    "commentBody": "DNS record \"hn.algolia.com\" was goneHacker NewspastloginDNS record \"hn.algolia.com\" was gone (nslookup.io) 260 points by gslin 1 day ago| hidepastfavorite97 comments chuckmeyer 23 hours agoDNS is reverted and should be back up based on your local TTLs&#x2F;caching.Sorry about that, everyone! reply chuckmeyer 23 hours agoprevAlgolian here -- We were rolling out a new version of the HN search but accidentally swapped over the DNS before we were ready.I&#x27;ve got a group of folks over here working to restore the search. Sorry for the downtime, but it&#x27;s nice to know the search is useful to so many! reply __rito__ 22 hours agoparent> \"it&#x27;s nice to know the search is useful to so many!\"Well, this is basically how I do all my reading (books) now. See: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37761636I also search here before I start learning something new. Resources recommended on HN are almost always great! reply chhabraamit 22 hours agorootparenttell me more about your searching process here reply eigenvalue 23 hours agoparentprevOne of the best features of the site. Thanks for your service. reply NKosmatos 23 hours agoparentprevThanks for providing the search functionality. I always use it before submitting something, in case someone else has already posted it recently.@dang It would be great if this duplicate search functionality was embedded in the HN submission form ;-) reply lolinder 23 hours agorootparentIt actually is, for exact URL matches: if you try to submit a URL that has a recent exact match, it will just redirect you to that submission instead of creating a new one. reply nubinetwork 19 hours agorootparentExcept when it doesn&#x27;t and people submit the same link several times a week reply ehsankia 22 hours agorootparentprevDoes it do any URL cleaning, removing fragments, maybe normalizing shortlinks? reply lolinder 22 hours agorootparentNo idea, I haven&#x27;t ever intentionally tried to break it, I&#x27;ve just noticed it redirect me sometimes. I always clean my own links before attempting to submit. reply atonse 22 hours agoparentprevIt is very useful, I use it at least once a week.I even use it for more organic product research. “What have people on HN said about _____ over the years?” reply caprock 23 hours agoparentprevOut of curiosity, what functionality is forthcoming with the new version? reply chuckmeyer 23 hours agorootparentIt&#x27;s mostly a tech-stack update, but it resolves some longstanding edge cases in the search UI as well. I&#x27;ll try to get a changelog when we have it up and running. reply rolph 22 hours agorootparentthanks for the answer, there are some here that seem to have problems with questions, about why, the update.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37822329https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37822423https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37822897https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37823190 reply swores 21 hours agorootparentI would guess it&#x27;s not that people have \"problems with questions\", but are downvoting you for one or both of a) using multiple comments to ask the same question, and b) coming across as using a badgering tone, sounding entitled and complaining when you&#x27;re talking to people who provide a free service to you, and acting like they owe you a comment reply rather than waiting for the change log they&#x27;ve said will be released when they&#x27;re ready. reply rolph 21 hours agorootparentthanks for the answer. there seem to be assumptions>>coming across as using a badgering tone, sounding entitled and complaining when you&#x27;re talking to people who provide a free service to you Algolian hereIs that just a way to identify you are affiliated with it or do you guys actually call yourselves algolians inside the company? Nonetheless, good work on the update and fixing it. reply Rumel57 21 hours agorootparentYes we call ourselves Algolians within the company. reply teruakohatu 23 hours agoparentprev> it&#x27;s nice to know the search is useful to so many!I use it every few days. It&#x27;s exceptionally useful. Thank you for providing it. reply pgt 23 hours agoparentprevI use it all the time :) reply pierat 22 hours agoparentprevIt&#x27;s ALWAYS dns :D reply rolph 23 hours agoparentprevwhat does algolia search do now that it didnt do before; what does it no longer do; and how does this version change influence UX on HN ?How does this stand to benefit algolia ?i for one, was having no problems with the search, what made this nessecary ? reply JdeBP 22 hours agorootparentYou are erroneously assuming that the update was for reasons visible to end users like you.I am sure that Hacker News commenters are a vast mine of \"Well, one day we were updating to the new machine to finally get rid of the one with the knackered RAID controller …\" type anecdotes illustrating not only the other reasons that upgrades happen but also what can occur when they are performed. reply rolph 22 hours agorootparent>>You are erroneously assuming that the update was for reasons visible to end users like you., and the blog post author immediately added a large box on top of the blog post:They have now deleted the blog post entirely, citing being on HN as the reason: reply JdeBP 23 hours agorootparentJamie Zawinski is another; whose WWW site, if redirected from Hacker News, returned an obscene image at one point. reply rolph 22 hours agorootparentprevthere are a lot of groups, and individuals, that attempt to cause chaos and disenchantment with sites that differ from thier worldview, even going as far as stalking individual users with malignant actions. reply mardifoufs 23 hours agorootparentprevMostly white sf techbros lol. Pretty ironic reply zoover2020 23 hours agoparentprev [–] Curious, so giving in to the bait: why is this exactly? reply pcbro141 23 hours agorootparentGoing to assume some YC affiliated person has been declared &#x27;problematic&#x27;&#x2F;&#x27;cancelled&#x27; on Twitter, and parent commenter thinks it&#x27;s a bigger deal than it is in reality. reply sp332 23 hours agorootparentprev [–] Gary Tan has been getting into politics lately. https:&#x2F;&#x2F;sfstandard.com&#x2F;2023&#x2F;09&#x2F;27&#x2F;garry-tan-y-combinator-dec... reply waihtis 23 hours agorootparent [–] Indeed, according to some leftists Garry Tan is now a white supremacist (???) replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DNS for Developers module 3 offers 10 lessons on operational DNS, teaching how to find DNS records and understand authoritative and local DNS servers.",
      "The provided DNS records for hn.algolia.com include A records with IPv4 addresses, but no AAAA, CNAME, TXT, NS, or MX records are found.",
      "DNS lookup tools recommended in the module include reverse IP lookup, DNS checker, website to IP lookup, CNAME lookup, and TXT lookup. The module also provides additional resources like a learning center, a blog, and contact information."
    ],
    "commentSummary": [
      "The DNS record for \"hn.algolia.com\" was unintentionally removed, leading to downtime for Hacker News' search function.",
      "Algolia's team is rectifying the issue and has apologized for any inconvenience caused.",
      "The update that led to this situation was meant to tackle tech-stack and UI issues, and although some users questioned its necessity, it was clarified that the reasons may not be readily apparent to end users."
    ],
    "points": 260,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1696867551
  },
  {
    "id": 37821994,
    "title": "Make your own pyramid salt crystals",
    "originLink": "https://crystalverse.com/pyramid-salt-crystals/",
    "originBody": "Skip to content Search CRYSTALVERSE Crystal Growing HOME ABOUT BLOG CONTACT ME How to Easily Make Your Own Pyramid Salt Crystals HOUSEHOLD MATERIALS, RECOMMENDED, SODIUM SALTS / SEPTEMBER 9, 2022 by CHASE / 28 COMMENTS Here’s how you can transform regular table salt into gorgeous pyramid salt crystals at home. Regular salt looks like a fine white powder. Sure, it tastes good, but it’s not very interesting to look at. But what if I told you that you could transform the salt sitting in your kitchen into a work of art? What if I told you that within a few hours, you could turn white, powdery salt into premium salt crystals shaped like pyramids, flowers and Eiffel towers? Plus, you don’t need to be good at art. You don’t need to carve those pyramids yourself. Just sit beside the stove, and watch as pyramid salt crystals grow from a dish of salt water right before your eyes. Let me show you how to do just that. To my knowledge, it’s the only such guide on the Internet. First, let’s answer a question. What is pyramid salt? Pyramid salt crystals are made of the same stuff as regular salt. But these crystals look different because they formed in a different way. In nature, these elusive crystals grow on the surface of quiet, undisturbed pools of salt water that evaporate under the hot sun. Pyramid salt is more expensive than regular salt, because they taste saltier. Pyramid salt is hollow, and gram for gram, it dissolves in your mouth faster than regular salt. So the saltiness comes at your taste buds all at once. Plus, they also look awesome. Now, it’s easy to make regular salt crystals at home. Just leave a dish of salt water to evaporate, and you’ll get white powdery salt inside after a few hours. However, it’s much harder to make pyramid salt. True, you can buy them online. Maldon Sea Salt, for instance, contains crunchy pyramidal salt crystals. They are made by evaporating sea water in large heated pans, mimicking nature. But that kind of salt is produced industrially, with special equipment and mineral rich seawater. I’ve always wondered whether you could grow pyramids at home using a hot plate, a glass dish and some regular table salt. It took over 100 experiments and some sleepless nights, but here are the results. How to make pyramid salt crystals This guide will consist of the following parts: Materials Preparing the salt solution Growing the pyramid salt crystals Harvesting the pyramid salt crystals Storing the pyramid salt crystals Tasting the pyramid salt crystals 8 types of pyramid salt crystals Some more information Summary Materials To make pyramid salt crystals, you’ll need: A bag of salt Alum powder A stove/hot plate A heat resistant glass dish A pair of tweezers A thermometer (optional) I have tried table salt, sea salt, and Himalayan rock salt, and they all work. Sea salt seems to give better results. I’ve used both tap and deionized water. Both are fine. Also, in this experiment, we’ll be heating some very concentrated salt water. This solution will damage metallic objects, so you can’t use a stainless steel pot. Instead, I suggest using a heat resistant glass dish. The exact type doesn’t matter. You can use a Pyrex dish or an enameled cast iron pot, which won’t get corroded. I used a glass casserole. Preparing the salt solution Dissolve 165 g of salt in 500 mL of hot water. If you want to make a bigger batch, just use the same ratio (e.g. 330 g of salt per 1 L of water). Stir the solution gently until all of it dissolves. Depending on whether the salt is dirty, you can choose to filter it. I filtered mine. In my setup, I poured my filtered salt solution into a glass casserole sitting on top of a hot plate. A hot plate is fine. But don’t put the glass dish directly on the gas stove – the glass might break due to strong, uneven heating, even though it is technically heat resistant. Use a water bath instead. Growing the pyramid salt crystals Now, heat the solution to 60-70°C and keep it there throughout the growing process. When the solution warms up, convection currents start forming, causing the surface of the solution to swirl around. This is bad news, because when our pyramids form, they will also move around the surface of the solution. And they will bump into each other, stick together and fall to the bottom of the dish. The key is to add an ingredient called potassium alum. Alum calms the surface and helps the pyramids form. It is normally used in baking and pickling. You can find it at the grocery store, or buy it online. Add 0.5 g of alum per 500 mL of salt solution. No need to measure – just drop a few pea-sized pieces of alum/two pinches of alum powder into the solution and let it dissolve. Several minutes after the alum has dissolved, the surface of the solution should start to settle down. Check out this GIF: I placed a cork on the surface of the solution to visualize the movement on the surface. Before adding alum, the cork swirled around. After adding alum, the cork was completely motionless. Good. Now you just need to wait. It takes about 30 minutes for the salt solution to reach saturation, which is the point where salt crystals start to form. Eventually, small white squares will appear on the surface of the solution. Those are baby pyramid salt crystals. They’ll keep growing, and within 15 minutes they’ll look like this: The crystals are actually upside down pyramids, suspended on the surface of the solution due to surface tension. It’s the same principle that lets some insects walk on water. Here’s what they look like from the side: As the pyramid salt crystals get heavier, they sink lower into the solution. But evaporation on the surface causes the base of the pyramids to grow outwards, widening it and forming a staircase pattern in the process. Super cool. Here’s a time lapse of the growing process over 1 hour: As the pyramids get larger, they risk bumping into their neighbors. Usually, it isn’t a big problem – unless your solution is too hot. If you heat it beyond 80°C, the pyramids quickly join together to form a layer of crust. But even at 60°C, you shouldn’t leave them there, because they might get too heavy and fall to the bottom to the dish. So it’s time to harvest the pyramids. Harvesting the pyramid salt crystals Using a pair of tweezers, carefully remove the pyramid that you want, and place it on a piece of tissue paper. The paper will soak up excess salt solution. Before you remove the second pyramid, dip the tweezers in a cup of water. This step ensures that there are no powdery salt grains sticking to your tweezers – which will cause thousands of tiny crystals to form in the dish. Then, dry the tweezers with a tissue, and remove your second pyramid. Rinse and repeat. Instead of using tweezers, you can also use a sieve to scoop up those pyramids. Remember to dip the sieve in water after every run. Wash your tweezers after every run to prevent powdery salt grains from forming. You can keep doing this until the salt water starts to dry out. By this time, you should have quite a few pyramids. And that’s it! You’ve just made the fabled pyramid salt, also known as fleur de sel, flower of salt, at home. If you want to make more pyramids, just add some water to the dish and wait for all the salt to re-dissolve. Then repeat the process. This time, you don’t need to add alum. Re-dissolving the salt to make more pyramids. Storing the pyramid salt crystals Just store them like regular salt. If you live somewhere humid, the crystals will absorb moisture from the air and get slightly wet. This will cause part of the pyramid’s base to dissolve. It’s no big deal, but if you want to prevent this, store the pyramid salt crystals with a desiccant. Tasting the pyramid salt crystals What do you mean? Of course I’ve licked the pyramids. They taste a bit saltier than regular salt. And crunchier. You might also wonder if the alum added to the solution changes the taste of the salt, or if it’s unhealthy. First, we added an extremely small amount of alum to the salt solution. So the pyramids taste like pure salt. And since potassium alum is used in baking powder and considered safe by the FDA, it’s alright to bite a pyramid or two. However, I would discourage you from eating pyramid salt grown with this method regularly. I’m no dietician, and it’s best to look for an expert before adding something new to your diet. 8 types of pyramid salt crystals At the start, I promised you’d see all sorts of pyramid salt crystals, some narrow, others wide. I told tales of Mayan pyramids, flowers and Eiffel Towers. Below you will find pictures of 8 different types of pyramid salt crystals and how I grew them. 1. Regular pyramids Regular pyramids are the most common type of salt crystal. They form from a solution heated to 60-70°C at low to medium humidity. They look like the typical right pyramid, with a square base, and straight edges that meet at the top. The edges have small crystals on them. Remember, pyramids form upside down – hence, they grow from the top to the bottom. Since salt crystals get larger the longer they stay in the solution, the crystals near the top are bigger than the ones at the bottom. 2. Thick pyramids Now, regular pyramids are thin and fragile. But if they drop into the solution and are left there, more crystals will deposit on their surface, thickening the faces of the pyramid. Compare the regular pyramid, grown on the surface of the solution, vs the pyramid that fell to the bottom of the dish and left to thicken as more crystals formed on its surface. These “thick” pyramids might look less elegant, but they are also less fragile. 3. Two sided pyramids Once, I tried to pick up a pyramid with my tweezers, but by accident, it fell back into the solution. Instead of sinking, it continued to float – but with the tip of the pyramid facing up, and the base facing down. I let it grow for another 15 minutes, and the pyramid turned into this magnificent hourglass shaped crystal: 4. Narrow pyramids Pyramid growth is a balancing act between gravity and how fast the base of the pyramid can widen. Sometimes, the base of the pyramid grows very slowly, while gravity keeps pulling it downwards. As a result, we get narrow salt crystals that look less like pyramids and more like Eiffel towers, or chess pieces, if you will. Salty chess. When you capture a piece, you eat it. These narrow pyramids like to form when the temperature of the solution is below 60°C. My theory is that when the temperature is low, less evaporation occurs, and so less crystal growth occurs at the surface. Thus, the pyramids sink faster than they widen – hence the narrower shape. If you increase the temperature while these salt crystals are forming, the base will get wider, curving outwards. The resulting pyramids look like trumpets. 5. Big headed pyramids If you look closely at the pyramids, you’ll find that each pyramid has a “head” at its tip. Sometimes the head is small, sometimes it is big. Below are some big headed pyramids. The so-called “head” is actually a large salt cube. When it starts forming, it looks like a tiny square on the surface of the solution. Then, as the crystal gets heavier, it sinks a little into the solution. As it sinks, layers of salt crystals grow on the face of the cube facing the sky, forming a pyramid. But the other sides of the crystal cube (that are underwater) also keep growing. Eventually, they form the “head” of the pyramid. Sometimes, the head is tiny. Sometimes the head is much larger, and you can see interesting patterns on the hopper crystal. If you place the pyramids upside down, they look remarkably like flowers. You might be able to serve some ketchup in them. Despite having spent an unhealthy amount of time on this project at home, I confess that there was one secret that escaped me: how to control the size of the heads. At first, I thought it was due to different types of salt. So I tried comparing two types of salt – sea salt and rock salt. I found that the batch with sea salt gave big heads and rock salt gave small heads. I thought I had my answer. After a few days, out of curiosity, I ran the two experiments again, side by side. This time, it was the opposite – sea salt gave small heads and rock salt gave big heads. I was equal parts surprised and confused. And we haven’t even gotten to the scary part yet. After 15 minutes, the heads on the sea salt pyramids started growing bigger, until they were just as big as the heads of the rock salt pyramids! Such was my hunt for the reason behind different head sizes. I tried changing the temperature and the type of container. I tried using deionized water. I even tried adding impurities such as vinegar and baking soda to the solution. But my efforts were mostly frustrating and fruitless. It was full of contradictions. I was as salty as the saturated salt solution and my mood as sour as the vinegar I added to it. Top and side view of big headed pyramid salt crystals. My last hope was the effect of humidity. But I didn’t have a device to measure humidity. So I had to rely on a crude technique – obsessively checking the weather station reports. Based on the several experiments I did, there seemed to be some relationship: The lower the humidity, the smaller the pyramid head. My tests were not conclusive, as occasionally large heads still formed on hot sunny days. But generally, drier days yielded smaller heads. I’ll discuss this later. For now, let’s look at 3 other types of pyramids. They were grown from the exact same salt solution – in which I had added a teaspoon of Epsom salt. 6. Monster pyramids The first pyramid salt crystal that grew from this solution was an absolute beast. The humongous head was covered with all sorts of intricate formations that reminded me of bismuth crystals. After half an hour, I extracted this crystal with tweezers and dried it. Then, from the same solution, a different type of pyramid started forming: 7. Slanted pyramids At first, it looked like a regular, small-headed pyramid. Then, it tilted over to one side and continued growing, until it looked like this: 8. Ultra wide pyramids After removing the slanted crystal, more pyramids continued to form. These were regular symmetrical pyramids with small heads. But they were also very flat – the flattest I have ever seen: 3 different types of salt crystals forming from the same solution, barely an hour apart. I was reminded once again that the art of crystal growing is both mysterious and wonderful. Some more information Before writing this article, I have looked online for guides on how to grow pyramidal salt at home, and found nothing. But I did find a study published in the World Salt Symposium where researchers successfully grew pyramid salt from waste salt water in large, steel crystallizers. They claim that calcium ions in seawater help pyramids form by allowing more salt to dissolve in water. I tried adding various amounts of calcium chloride to my solutions, and it had no noticeable effect. They also claim that a pH of 4, and a temperature of 55-65°C was good for pyramid growth. My experiments agree. Since alum is mildly acidic, dissolving some alum in water would indeed yield a pH of around 4. But I have tried using other acids like vinegar and cream of tartar. Neither yielded pyramids. I suspect it has something to do with aluminum ions, because replacing potassium alum with aluminum sulfate worked. Finally, according to the authors, sulfate ions were bad for pyramid growth because they encouraged hopper cubes (we know them as “heads”) to form. After removing the sulfates, the researchers managed to grow nice regular pyramids. I knew that sulfates were not the only factor that affects head size, because in my experiments, the same solution could form both big and small heads. Nevertheless, I decided to try this hypothesis. I had no easy way to remove the sulfates, but I could add Epsom salt (magnesium sulfate) to my solutions. You have seen the results in the previous section. The same solution formed monster pyramids, slanted pyramids and ultra wide pyramids, 1 hour apart. Maybe magnesium sulfate indeed makes the heads bigger, but then, it must be quickly used up, causing subsequent pyramids to have very small heads. But it’s hardly conclusive. What do you think? How do you control head size? Whether you’re a science loving kid or a research chemist, I leave it to you. Summary That’s all for now. I have been trying to grow pyramid salt crystals for a very long time, and I’m glad to share what I’ve learnt with you. Hopefully you found the guide useful. Here’s a super short summary of what we’ve covered. To grow pyramid salt crystals, you’ll need: A bag of salt Alum powder A stove/hot plate A heat resistant glass dish A pair of tweezers A thermometer (optional) Dissolve 165 g salt per 500 mL of water. Heat the solution to 60°C. Add 0.5 g alum per 500 mL of solution. Wait for pyramids to form. Remove the pyramids with tweezers. Dry and store them with a desiccant. Enjoy your pyramid salt. *** Thank you for reading. Maybe you found a new hobby today. Maybe you’ll find a few hours of joy with your kids. Or maybe it simply put a small smile on your face. I grow crystals because it makes me happy, and I hope it made you happy too. If you want to start crystal growing, I also recommend making alum crystals. They are large, transparent and easy to grow. And if you enjoyed this guide, consider subscribing to my newsletter. Let’s keep in touch. I’ll share more crystal growing guides with you when they come out. As always, happy growing. About Chase I'm a university student who loves to grow crystals using chemistry while sharing my discoveries along the way. My other interests include mathematics, nature and Harry Potter. Reader Interactions Comments Muhammad Athar FEBRUARY 12, 2023 AT 12:39 AM Hello, Are all salts work for making Pyramids. I have tried a lot with different rock salts as we have a lot in our country,Pakistan. But these rock salts did’t worked as you mentioned. What is the reason behind this.? REPLY CHASE FEBRUARY 23, 2023 AT 1:52 PM I have tried rock salt before, and it worked for me. But different types of rock salts have different mineral contents. Can you tell me more about how it did not work? What did you observe? REPLY Joe FEBRUARY 1, 2023 AT 11:57 PM Hello! Awesome article. I was wondering if you knew a way to keep the pyramids normal when they’re on the bottom for a long time? I wanted to make some but would want to make a big batch and just forget about it (lol). Is there a way to let the crystals sit on the bottom of solution without getting bulky? I can’t imagine big business that sell flake salt take them out before they hit the bottom. Thanks for the reply REPLY CHASE FEBRUARY 3, 2023 AT 12:52 AM I don’t know of any such method. Businesses do indeed harvest their flaky salt by scooping them up from the surface and selling them as high quality flaky salt, while selling those at the bottom as regular salt. REPLY CORA A. HARRIS JANUARY 29, 2023 AT 9:48 PM Chase, these pyramid salt crystals you’ve grown are absolutely amazing! Just signed up for your newsletter too. Thanks for posting awesome stuff like this! – Cora REPLY CHASE JANUARY 30, 2023 AT 2:12 AM Hey Cora, super happy you liked it! Your work is awesome too. REPLY Francesc DECEMBER 13, 2022 AT 12:17 PM Hello from Kenya! I was wondering about your thoughts about using a heat-proof glass dish in the oven set to 65 degrees – would it be too dry? I thought perhaps a second dish of water on another shelf might help with the humidity. And do you think it makes a difference adding the alum before or after filtering? Thank you for your detailed and fun write up! REPLY CHASE DECEMBER 14, 2022 AT 12:54 AM I think it should be alright. Water will evaporate inside the oven anyway. When you add alum isn’t too important, but if the alum makes the solution cloudy because it is impure, then add it before filtering so that you can filter out the cloudiness. Good luck! REPLY Alana DECEMBER 7, 2022 AT 5:37 AM You posted an optimal temperature range of 55-65 , but how important is it to be held at a temp or can it fluctuate? I have a steady hold temp at 50 (which I found was too low and the cystals were smaller, but with my plate cycling with bursts of heat but managing to get my temp closer to 65-70c I had bigger flakes but they sank a bit faster and i ran into harvest issues missing windows lol…. REPLY CHASE DECEMBER 8, 2022 AT 12:17 AM The crystals grow too slowly below 50C, and they also appear narrower. The crystals are much wider and grow more chaotically at temperatures above 70C, to the point where they sometimes join into crust. 55-65C is not a hard rule, but generally I found it to be the right balance between those two conditions to get the best pyramid salt crystals. REPLY Alana DECEMBER 8, 2022 AT 2:50 AM Thanks for the reply! Would cycling temperature swings from 62-70 every 2-3 minutes make the pyramid structure so that they sink faster? I’m just not sure how much extra effort I should put into holding the temperature steady REPLY CHASE DECEMBER 8, 2022 AT 3:06 AM It should be fine. I’ve noticed no significant effect when the temperature fluctuates slightly. If you really want to keep the temperature stable, you can place the salt solution in a water bath and heat the water bath instead. Good luck! REPLY Fiona SEPTEMBER 29, 2022 AT 5:43 AM Thanks – interesting and well-written as always. Do you think it’s possible to grow a crystal with some sort of inclusion in a home setup (e.g. https://www.geologyin.com/2017/01/types-of-mineral-inclusions-with-photos.html)? Say, for these, could a higher-density liquid be dropped into the pyramid once it’s a decent size so it pools at the tip? REPLY Fermin SEPTEMBER 26, 2022 AT 8:10 AM Where did you find this trick of stabilizing the liquid surface by adding alum? It looks very susseful! REPLY CHASE SEPTEMBER 26, 2022 AT 9:01 AM I got the idea of adding alum after seeing that the research paper (mentioned in the article) successfully produced pyramids from salt solution containing several different types of ions, including aluminum. They didn’t mention that aluminum ions were beneficial in particular, but since I had some alum on hand, I decided to give it a try, and it worked! REPLY Chandler SEPTEMBER 11, 2022 AT 6:17 PM This is so cool! Inspiring how much time and effort went into this. I need to master this so I can be a wizard dad when I have kids. REPLY Caleb K SEPTEMBER 11, 2022 AT 5:52 PM I really enjoyed reading this! You have a an engaging writing style that maintained my interest throughout the article. I really like how you asked questions and encouraged your readers to engage and learn. REPLY CHASE SEPTEMBER 12, 2022 AT 12:59 AM Yay! I tried my best to make the article both interesting and informative. Glad you liked it. REPLY ANDREAS SEPTEMBER 11, 2022 AT 5:14 PM Thank you for making this detailed and funny guide. I will share this with my students. Last school year we grew some crystals from store bought kit and they love it so much. REPLY kamran SEPTEMBER 11, 2022 AT 5:09 PM wow, this was extremely interesting!) Thank you!!! REPLY 321 SEPTEMBER 12, 2022 AT 7:11 AM Loved it REPLY Aly SEPTEMBER 11, 2022 AT 5:09 PM Thank you for the article!!! Great piece and the pictures you added are so helpful. This was really a fun read. REPLY Huseyin SEPTEMBER 11, 2022 AT 5:07 PM Nice work REPLY RocketSlug SEPTEMBER 11, 2022 AT 4:54 PM Please reach out to Adam Ragusea! He had a great video on salt crystals and his own attempts at growing hopper crystals. I’m sure he’d be delighted to learn about your findings! https://youtu.be/FVEZuzEHwQk REPLY CHASE SEPTEMBER 12, 2022 AT 12:58 AM I’ve watched the video before! I will! Thanks for the suggestion. REPLY Peter OCTOBER 15, 2022 AT 3:05 AM I had the exact same thought. REPLY Teun SEPTEMBER 11, 2022 AT 4:17 PM Thanks so much for taking time to write this up. I will be growing some pyramids with my 7 year old son who loves science. Best regards, Teun (from the Netherlands). REPLY CHASE SEPTEMBER 11, 2022 AT 4:35 PM You’re welcome. Spend some quality time with your son, and all the best! REPLY Leave a Reply Your email address will not be published. Required fields are marked * Comment * Name * Email * Website Save my name, email, and website in this browser for the next time I comment. Please enter an answer in digits: two × 2 = CONTACT/CONSULTING TERMS AND CONDITIONS PRIVACY POLICY AFFILIATE DISCLOSURE COOKIE POLICY (US) Copyright © 2023 Crystalverse.com",
    "commentLink": "https://news.ycombinator.com/item?id=37821994",
    "commentBody": "Make your own pyramid salt crystalsHacker NewspastloginMake your own pyramid salt crystals (crystalverse.com) 248 points by klyrs 23 hours ago| hidepastfavorite27 comments steve_adams_86 14 hours agoThis website is what I want the internet to be. Information like this is such a treat, and I would have gone crazy for it as a kid (and I still do). I used to search high and low for books containing these kinds of guides, and it makes me happy to see it online. reply klyrs 14 hours agoparentI&#x27;ve got alum on order. My kid isn&#x27;t old enough to do this one unsupervised, but this is our plan for next weekend. reply TedDoesntTalk 7 hours agorootparentWhere can I get it? reply klyrs 1 hour agorootparentI found some food grade stuff, there&#x27;s probably a reseller near you. Apparently it&#x27;s used for pickling?https:&#x2F;&#x2F;www.mccormick.com&#x2F;spices-and-flavors&#x2F;herbs-and-spice... reply Kon-Peki 54 minutes agorootparentYes, for sure. At least in the US, it will be in the spice aisle at your local generic grocery store (Safeway, Kroger, Walmart, Meijer, etc), although keep in mind that it is a very small container - on a cost-per-weight basis you are going to get a much better deal somewhere else. reply gsinclair 6 hours agorootparentprevTry a shaving supplies website, I think. reply ranting-moth 5 hours agorootparentprevI got some years ago from ebay. reply Varriount 18 hours agoprevnext [–]> But I did find a study published in the World Salt Symposium where researchers successfully grew pyramid salt from waste salt water in large, steel crystallizers.Wow, I never knew that there was an entire symposium dedicated to salt.From https:&#x2F;&#x2F;www.bolton-menk.com&#x2F;salt-symposium&#x2F;: This event celebrates the optimization of salt use to improve community sustainability and protect vital freshwater systems and infrastructure. The Salt Symposium brings together leaders from diverse economic sectors to learn about the impacts of chloride and reduction methods. Professionals from across the world will share their expertise on current research initiatives including water softening, wastewater, fertilizer, snow and ice management, and more. reply orionex_sigma 5 hours agoparentHave you ever heard of the Royal society for putting things on top of other things? reply Ajay-p 17 hours agoparentprevAlso 484 pages of the pretty dense but readable, Salt by Mark Kurlansky reply cyclotron3k 13 hours agorootparentSeconded reply civilitty 14 hours agoparentprevAnother recent salt submission: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37786245 reply klyrs 11 hours agorootparentYep, that&#x27;s what tripped me down the rabbit hole I found this article in. reply BrainBacon 6 hours agoprevThe YouTube channel Alex (FrenchGuyCooking) made some nice flakey salt in this video: https:&#x2F;&#x2F;youtu.be&#x2F;eN6U58LzyHg It&#x27;s a similar process, but he uses coarse sea salt without any alum or other additives. The results are less uniform, but probably better for human consumption. reply hyperific 12 hours agoprev> The key is to add an ingredient called potassium alum. Alum calms the surface and helps the pyramids form.Does anyone know of scientific article where I can read more about this? I&#x27;ve never heard of alum&#x27;s water calming abilities. reply curiousgibbon 10 minutes agoparentAn excellent question, it seems way outside my high school chemistry knowledge that you could calm water with a tiny amount of anything, be it alum or otherwise. reply appplication 11 hours agoparentprevNot an expert, but probably in relation to this[1]:> In water, most of the particles are negative charged, to neutralize the charge a positive ion (cation) may be used as a coagulant. Potassium hydroxide contributes a mono-valent ion, K+. Calcium hydroxide gives a divalent ion, Ca2+. Aluminum coagulants give trivalent aluminum ions, Al3+. According to Schultz in 1882 and Hardy in 1900, higher the charge of cation, more effective is charge neutralization.This charge would be present at the surface[2] if not dealt with via the alum, and I imagine that could disrupt the crystallization process happening there.[1] https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s13201-018-0662-5 [2] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Surface_charge reply speakspokespok 5 hours agoprevThe article says ‘Add 0.5 g of alum per 500 mL of salt solution.’ but in the gif demonstrating the difference, it’s 0.5 g of alum per 100 mL of salt solution. reply njarboe 37 minutes agoparentA photo caption also says, \"No need to measure – just drop a few pea-sized pieces of alum&#x2F;two pinches of alum powder into the solution and let it dissolve.\", so the exact ratio is unimportant. reply gaudat 15 hours agoprevI thought these crystals are 3D printed at first judging by the layered look. reply omneity 13 hours agoparentResin 3D printing is kind of this at a finer resolution. reply datadrivenangel 16 hours agoprevHas anyone tried doing this with Bismuth?Bismuth crystals can also be grown at low temperature, so maybe they can be shape controlled as well. reply jamal-kumar 15 hours agoparentYeah of course, you can even make it from pepto bismol tablets from what I remember reading [1] [2][1] https:&#x2F;&#x2F;www.wikihow.com&#x2F;Make-Bismuth-Crystals[2] https:&#x2F;&#x2F;www.thoughtco.com&#x2F;bismuth-metal-pepto-bismol-antacid... reply s0rce 13 hours agoparentprevI think the surface of the melt will oxidize so you might need to cover it with inert gas but something like this might be possible. One issue is that the crystals might want to melt if they grow downwards into the molten liquid. I think the temperature gradients might be really important here. reply Terr_ 11 hours agorootparent> I think the temperature gradients might be really important here.Hm, I&#x27;m trying to think of ways to maintain an even gradient without unduly stirring up the liquid metal.Probably sealing the pot-o-bismuth inside another container, where the outer container&#x27;s fluid is being stirred and circulated to minimize external gradients. reply j7ake 9 hours agoprevThis is fantastic, bravo ! reply peter_d_sherman 13 hours agoprev [–] >\"6. Monster pyramidsThe first pyramid salt crystal that grew from this solution was an absolute beast. The humongous head was covered with all sorts of intricate formations that reminded me of bismuth crystals.\"That&#x27;s a very interesting observation!I&#x27;m wondering in all of Chemistry -- are there other possible crystal formations that look like Bismuth or specific Bismuth-looking pyramid salt crystals?Also, could we take molten Bismuth -- and somehow grow a pyramid shaped crystal out of it? If so how? If not, why not?Anyway, great article! replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article offers a detailed tutorial on creating pyramid salt crystals at home with table salt, illustrating the author's findings that adding alum to the salt solution yielded a purer salt taste.",
      "Variables like temperature, humidity, and impurities were found to influence the size and shape of the crystals, while magnesium sulfate may potentially affect crystal size.",
      "Although the experiments partially reflected a previously published study, the author documented these findings and promised more guides on crystal growth for subscribers."
    ],
    "commentSummary": [
      "The article explains the process of creating pyramid salt crystals, including where to source necessary ingredients.",
      "It delves into related subjects such as the application of alum in water.",
      "The article also explores the prospect of cultivating pyramid-shaped bismuth crystals."
    ],
    "points": 243,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1696868511
  },
  {
    "id": 37822927,
    "title": "Linux ate my RAM (2009)",
    "originLink": "https://www.linuxatemyram.com/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=37822927",
    "commentBody": "Linux ate my RAM (2009)Hacker NewspastloginLinux ate my RAM (2009) (linuxatemyram.com) 239 points by StrauXX 22 hours ago| hidepastfavorite180 comments gslin 19 hours agohttps:&#x2F;&#x2F;archive.ph&#x2F;WmJHf neonate 17 hours agoparenthttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230928045611&#x2F;https:&#x2F;&#x2F;www.linux... mjb 22 hours agoprevThere&#x27;s some really interesting little details here.Linux, by default, is making the very reasonable assumption that the marginal cost of converting empty physical memory into caches and buffers is very near zero. This is fundamentally reasonable, because the cost of converting empty memory into used memory isn&#x27;t really any cheaper than converting a clean cached page into used memory. It&#x27;s a little more subtle when you take accounting into account, or when you think about dirty pages (which need to be written back to clear memory), or think about caches, but the core assumption is a very reasonable one.Except for on some multi-tenant infrastructure. Here, \"empty\" pages don&#x27;t really exist. There&#x27;s mostly not an empty page of memory kicking around waiting (like there is on client devices). Instead, nearly all the memory on the box is allocated, but each individual guest kernel doesn&#x27;t know the full allocation. In this world, the assumption that the marginal cost of converting empty to full is zero is no longer true. There&#x27;s some real cost.Projects like DAMON https:&#x2F;&#x2F;sjp38.github.io&#x2F;post&#x2F;damon&#x2F; exist to handle this case, and similar cases where keeping empty memory rather than low-value cache is worse for the overall system. These kinds of systems aren&#x27;t super common, especially on the client side, but aren&#x27;t unusual in large-scale cloud services. reply mjb 21 hours agoparentThe other interesting detail here is the memory sizing problem. If I can consume all my RAM with caches and buffers, how much RAM do I need? The answer (as always) depends on what you&#x27;re optimizing for. For performance, bigger is better. For cost, energy, etc you&#x27;re going to want some way to calculate whether adding more RAM (and so having bigger caches) is worth the cost, heat, power, etc.Gray and Putzolu&#x27;s classic \"The 5 minute rule for trading memory for disc accesses\" (https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;38713.38755) from 1987 is probably one of the most important CS systems papers of all time. In it, they lay out a way of thinking about memory and cache sizing by comparing the cost of holding cache to the cost of access (this isn&#x27;t the first use of that line of thinking, but is a very influential statement of it). Back then, they found that storing 4kB in RAM for 5 minutes costs about the same as reading it back from storage. So if you&#x27;re going to access something again within 5 minutes you should keep it around. The constants have change a lot (RAM is way cheaper, IOs are way cheaper, block sizes are typically bigger) since then, but the logic and way of thinking are largely timeless.The 5 minute rule is a quantitative way of thinking about the size of the working set, an idea that dates back at least to 1968 and Denning&#x27;s \"The working set model for program behavior\" (https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;363095.363141).Back to marginal costs - the marginal cost of converting empty RAM to cache is zero in the minute, but only because the full cost has been borne up front when the machine is purchased. It&#x27;s not zero, just pre-paid. reply LeifCarrotson 19 hours agorootparentHuh, never heard of that before. An interesting paper!Running the numbers - assuming 4k record size instead of 1k, ignoring data size changes, ignoring cache, ignoring electricity and rack costs, selecting a $60 Samsung 980 with 4xPCIe and a $95 set of 2x16GB DDR5-6400 DIMMs...I get $0.003&#x2F;disk access&#x2F;second&#x2F;year and $0.0000113 for 4k of RAM, a ratio of 264.That is remarkably close to the original paper&#x27;s ratio of 400, even though their disks only got 15 random reads per second, not 20,000, and cost $15,000, and their memory cost $1000&#x2F;MB not $0.002&#x2F;MB.I&#x27;m not sure the \"Spend 10 bytes of memory to save 1 instruction per second\" works equally well, especially given that processors are now multi-core pipelined complex beasts, but working naively, you could multiply price, frequency, and core count to calculate ~$0.01&#x2F;MIP (instead of $50k). $0.01 is about the cost of 3 MB of RAM. Dividing both by a million you should spend 3 bytes, not 10 bytes, to save 1 instruction per second. reply justsomehnguy 16 hours agorootparent> $60 Samsung 980If this is a Hetzner machine then yes, but enterprise SSDs costs more, especially from enterprise vendors. But this only drives the storage cost up.More so, if you tend to send some big amount of data every 5 minutes and you are somewhat constrained by memory (32 &#x2F; 1000 x 100 = 3.2%) then it would be easier to just read it from the storage again. If you are not constrained by storage bandwidth, of course.And by the way, the latest gaming consoles (at least PlayStation?) is designed around this concept - they trade having big amount of RAM (which in case of PS5 is shared between GPU and the OS) to just loading assets from the storage extremely fast &#x27;just in time&#x27;. Which works fine for games. reply GTP 21 hours agorootparentprev> Back to marginal costs - the marginal cost of converting empty RAM to cache is zero in the minute, but only because the full cost has been borne up front when the machine is purchased. It&#x27;s not zero, just pre-paid. .Or, in other words, you get to fully use what you paid for. reply teruakohatu 20 hours agorootparentI think the OPs point was that people tend to buy more RAM than they actually need because they have no idea how much RAM they actually need, because it&#x27;s always used, and so err on the side of caution reply Arrath 16 hours agorootparentWell you don&#x27;t have to call me out for running 64gb of ram in my home desktop like that. reply dist-epoch 21 hours agoparentprev> but each individual guest kernel doesn&#x27;t know the full allocationI was under the impression that at least in some virtual machine types the guest kernel is collaborating with the host kernel through vm drivers to avoid this problem. reply mjb 21 hours agorootparentWell, yeah. But (DAMON and friends aside), Linux doesn&#x27;t handle that non-zero marginal memory cost well today. reply jsight 22 hours agoprevI once worked at a government job and took my computer into the IT department for an issue. I can&#x27;t remember anything about the original issue.But I do vividly remember the help desk trying to figure out one last issue. Some process was consuming all my resources.They never could figure out why \"System Idle Process\" kept doing that. reply sweetjuly 20 hours agoparentA few years ago a similar issue cropped up on macOS where when the device was extremely hot (at least on intel), you&#x27;ll see kernel_task seemingly using a ton of CPU time. What was actually happening is that the kernel was scheduling an idle thread which just put the CPU to sleep in an effort to lower the temperature beyond what it could achieve with fans and DVFS. reply justsomehnguy 15 hours agoparentprevBack in the day I was asked why it consumes 2 seconds of CPU Time each second.I couldn&#x27;t answer that at time. Took a bit more years and understanding until I remembered that situation and it was obvious for me. reply lynguist 8 hours agorootparentWhat’s the answer? One second user time and one second kernel time? Or something completely different? reply roelschroeven 5 hours agorootparentIt was a dual processor system. The computer I&#x27;m using right now has 8 logical processors, and that statistic is incremented by 8 seconds per second: 1 second per logical processor. reply thebruce87m 7 hours agorootparentprev2 cores? reply kevin_nisbet 21 hours agoprevWhen I worked in telco we used to run into this a lot.We&#x27;d demand standard alarms for things like memory leaks &#x2F; out of memory conditions &#x2F; high than normal memory usage, as to get 99.999% uptime we want to be paged when problems like this would occur. Except a bunch of platform did the extremely naive implementation and included recoverable memory in their alarm conditions. So inevitably someone would log in and grep the logs or copy some files to the system, and hit the alarm conditions.And there were some vendors who really didn&#x27;t want to fix it, they would argue that recoverable memory is in use, so it should really be part of that alarm condition. reply drewg123 21 hours agoprevI used to run a Linux workstation in the late 00&#x27;s (sorry FreeBSD folks, I know, the shame...), and I ran a closed source PVR application on it.The memory access pattern was pretty much pessimal for my use of the box as a workstation. I&#x27;d use it from 7am -> 8&#x2F;9pm every day, then when I&#x27;d walk away from the keyboard, I&#x27;d watch HD recordings (which could be 7GB or more per hour). Those would get cached in memory, and eventually my workstation stuff (emacs, xterms, firefox, thunderbird) would start to get paged out. In the mornings, it was painful to start using each application, as it waited forever to page in from a spinning disk.I eventually wrote an LD_PRELOAD for the DVR software that overloaded open, and added O_DIRECT (to tell the kernel not to cache the data). This totally solved my problem, and didn&#x27;t impact my DVR usage at all. reply toast0 17 hours agoparent> I used to run a Linux workstation in the late 00&#x27;s (sorry FreeBSD folks, I know, the shame...), and I ran a closed source PVR application on it.It&#x27;s ok, no shame. But as I understand it, FreeBSD would prefer to throw out (clean) disk cache pages under memory pressure until somewhere around FreeBSD 11 +&#x2F;- 1, where there were a few changes that combined to make things like you described likely to happen. Heavy I&#x2F;O overnight might still have been enough, and I&#x27;m not going to test run an old OS version to check ;)I can&#x27;t find the changes quickly, but IIRC, older FreeBSD didn&#x27;t mark anonymous pages as inactive unless there was heavy memory pressure; when there was mild memory pressure, it would go through the page queue(s) and free clean disk pages and skip other page; only taking action on a second pass if the first pass didn&#x27;t clean enough. This usually meant your program pages would stay in memory, but when you hit memory pressure, there would be a big pause to mark a lot of pages inactive, often too many pages, which would then get faulted back to active...Current FreeBSD marks pages inactive on a more consistent basis, which is nice because when there is memory pressure, chancws are there&#x27;s already classified pages. But it can lead to anonymous pages getting swapped out in favor of disk pages as you described; it&#x27;s all tunable, of course, but it was a kind of weird transition for me. After upgrading the OS, some of my heavy i&#x2F;o machines saw rising swap usage running the same software as before; took a while to figure that out. reply tonyarkles 12 hours agorootparentRan into an issue like this on relatively modern embedded Linux platform. It was a driver bug and it’s been fixed, but here’s the scenario:- heavy disk access because we were writing real-time images to an SSD at about 500MB&#x2F;s- our application was steady-state about 4GB of RAM and we had 32GB available on the platform- the serial port that we received data from was, under the hood, using DMAIn certain cases, Linux would completely run out of free pages (28GB of it being used for cache on files we were never going to read again). These were all available pages but just occupied at the exact moment. The serial driver would request a page for DMA when it received an interrupt and being inside an interrupt context would request that page with NOBLOCK. That meant that kmalloc would return NULL instead of giving a page, since it would need to evict one of the cache pages before one was available. The serial driver would then blow up and never retry the DMA transaction.Fun to debug that one! reply toast0 11 hours agorootparentDMA pages are fun. Some devices have special needs for DMA buffers, so maybe you&#x27;ve got something ancient that can only use memory under 32-bit, or maybe you have something really ancient that can only use memory under 16 MB; or maybe the disk controller is fine for regular disk access, but administrative commands need to use a limited range. I didn&#x27;t really finish debugging that one, I got close enough and said well --- we can just measure SMART status a lot less frequently on boxes with that controller and called it a day. :) reply avgcorrection 20 hours agoprevTrust me. If Linux really eats your RAM to the point of reaching an OOM state you will know.(This was of course because of having too many apps relative to my RAM. Not because of disk caching.)The OOM behavior is not pleasant for a desktop system. reply cycomanic 16 hours agoparentAnd this (the OOM behaviour instead of the paging behaviour on linux) is something that can (and should) be criticised. Every time I encountered a situation where I was running out of memory (usually due to some out of control process) the system would become completely unusable. All interactivity is gone, so it was impossible to kill the out of control process (which was typically misconfigured program i started). If the OOM killer started to take action it would almost never kill the process that was gobling up memory like crazy but instead any of the other apps that are necessary to intervene (like e.g. the terminal or the WM). It always seemed incredibly stupid to me.I remember some time back there was discussion about improving the OOM killer, but I don&#x27;t know what came out of it. reply Timber-6539 12 hours agorootparentThis may or may not preserve your desktop and other important applications in an OOM situation. https:&#x2F;&#x2F;github.com&#x2F;hakavlad&#x2F;prelockdI&#x27;ve heard some good results with it and the applications locked in memory is configurable. reply mnd999 18 hours agoparentprevReally broken and stupid would be how I would describe it. Typically is just hangs hard with the disk at 100% and if you’re really patient you might be able to get a shell and kill some things over the course of the next 10 minutes. reply ValdikSS 11 hours agorootparentIt has been fixed by MGLRU patchset since kernel 6.1. Do: cat > &#x2F;etc&#x2F;tmpfiles.d&#x2F;mglru-min-ttl.confthere has been ongoing work to improve this. Including improved pressure detection,Are you referring to the &#x2F;proc&#x2F;pressure interface?https:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;linux&#x2F;kernel&#x2F;git&#x2F;torvalds&#x2F;lin... reply the8472 3 hours agorootparentYes, the pressure information is used by userspace OOM killers but afaik also internally to detect whether progress has been made on reclaiming memory and it&#x27;s supposed to be better than the previous progress heuristic. reply stefan_ 19 hours agoparentprevIts interesting how much stuff we have in Linux now to make OOM decisions (even userland daemons) yet on every modern distribution it still ends up killing your desktop environment instead of the fricking C++ compiler jobs that caused the problem in the first place. reply justsomehnguy 15 hours agorootparentnext [–]Out of memory: kill process 12345 Killed process 12345 (sshd)is the funniest and ugliest message to see on the iLO&#x2F;VM console. reply berkes 19 hours agoparentprevI&#x27;ve never encountered this with \"many apps\" starting to OOM, but many times with one process OOMing. That one will simply crash and everything else continues to run unharmed. reply mbakke 18 hours agorootparentWhat distribution are you using?IME, if a process grows out of control, Linux won&#x27;t notice until the whole system is thrashing, at which point it&#x27;s too late and it tries killing random things like browser tabs way before the offending process.In rare cases Linux might recover, but only because I hammered C-c the right place 30 minutes ago. In most cases a hard reboot is required (I left it overnight once, fans spinning at max, hoping the kernel would eventually accept my plea for help, but she had other priorities). reply jltsiren 17 hours agorootparentI guess OOM is more problematic on low-memory systems or when you have more than a nominal amount of swap.If you have enough memory that the desktop environment, browsers, and other processes that should keep running only use a small fraction of it, the OOM killer can pick a reasonable target reliably. A process that tries to allocate too much memory gets killed, and everything is robust and deterministic. I sometimes trigger OOM several times in an hour, for example when trying to find reasonable computational parameters for something. reply mnw21cam 17 hours agorootparentOn the contrary, it&#x27;s worse on systems with lots of memory, because those are the systems that are trying to do more.About 8 years ago I got a work machine with 384GB of RAM, and I installed early_oom on it to make the OOM killer work a whole load earlier, otherwise the system would just become completely unresponsive for hours if one of my students&#x2F;colleagues accidentally ran something that would make it run out of RAM. reply temac 16 hours agorootparentLinux provably got better because i&#x27;ve got a 200GB multi user machine where oom kills (on a stock debian 12) are largely uneventful. reply Sakos 17 hours agorootparentprevHow much memory do you think is reasonable? I&#x27;ve had it happen to me with 16GB and even 32GB, where I never ever have this issue on Windows (unless for some reason I&#x27;m on a 2GB RAM system for God knows why). I wish people would stop defending pathological behavior that&#x27;s broken for standard desktop use. What&#x27;s wrong with wanting things to improve? reply jltsiren 17 hours agorootparentNobody was defending anything. I just told that I don&#x27;t remember having any issues with the Linux OOM killer, and guessed a potential reason.I haven&#x27;t really used any Windows version later than 2000 for anything except gaming, so I don&#x27;t know how things work there these days. I mostly use macOS and Linux, and I&#x27;ve had far more trouble with pathological memory management behavior in macOS. Basically, macOS lets individual processes allocate and use far more memory than is physically available. When I&#x27;m running something with unpredictable memory requirements, I have to babysit the computer and kill the process manually if necessary, or the system may become slow and poorly responsive. reply berkes 8 hours agorootparentprevUbuntu.I&#x27;m guessing you are referring to \"swapping\", though?If it&#x27;s just one user process, it&#x27;ll be killed by the OOM killer¹. That application will just be gone: poof. And for the rest you&#x27;ll probably not notice anything, not even a hiccup in your Bluetooth headphones.If it&#x27;s many services, or services that are excempt from that killer, your system might start swapping. Which, indeed, leads to the case you describe.¹https:&#x2F;&#x2F;unix.stackexchange.com&#x2F;questions&#x2F;153585&#x2F;how-does-the... reply julienpalard 22 hours agoprevMy advice in the situation when someone wants to \"free RAM\": \"You bought it, better use it.\"It always felt strange that people buy lots of RAM but want it to be kept unused... reply jabroni_salad 21 hours agoparentBack when I played WoW I would occasionally run into issues with windows trying to put the game into memory compression, as opposed to basically any other process. It turned the game into a powerpoint.You could either get freaky with process explorer, or just keep some overhead so the system wouldn&#x27;t try to do that. When I asked my guildies, they told me the &#x27;default&#x27; for gaming is 16GB now, I was on 8 at the time.Pretty much every gamer will at some point tab out to process manager to see wtf the computer is trying to do and exactly zero of them will think to themselves \"I&#x27;m so glad there is no wasted memory!\" reply spookie 20 hours agorootparentFor the 3rd paragraph, specifically: That&#x27;s a fault with Windows not being clear enough with what is actually being in use, and what may be used and already there for a myriad of reasons.(edit: specified my intent on the reply) reply jstarfish 21 hours agoparentprevIt&#x27;s there for when you need to do something requiring that much memory.Your approach is like buying a giant house, becoming a hoarder, and trying to throw a party. reply OrderlyTiamat 9 hours agorootparent> Your approach is like buying a giant house, becoming a hoarder, and trying to throw a party.exactly, excepting that the items they&#x27;re hoarding are occasionally very useful for making their day to day activities go faster. And the hoarder has the superpower that in the blink of an eye they can discard everything that&#x27;s hoarded to make room for the party.Wait it isn&#x27;t quite like a normal hoarder at all come to think of it! reply outworlder 22 hours agoparentprevThe issue is that they think they are reaching their system&#x27;s capacity. reply sznio 8 hours agoparentprevI just got a 64GB machine. It rarely sees much use, but I did go over 32GB a few times.Could&#x27;ve done away with less but I still have PTSD from all my applications crashing after I started Teams on my 16GB machine. On another note: Upgrading from i5-2500k to R7-5800X doesn&#x27;t make Teams faster in any way. reply freedomben 22 hours agoparentprevWell, usually you want to free it so you can use it for something else without hitting swap. At least that&#x27;s my use case reply lstodd 21 hours agorootparentThe whole point is that pagecache does not cause any swap hits.Oh my god, it&#x27;s 2023 and we&#x27;re still discussing this idea from 1970s.Is that so hard to grasp? No, stuff gets evicted from the cache long before you hit the swap, which is by the way measured by page swap-out&#x2F;in rate and not by how much swap space is used, which is by itself a totally useless metric. reply Dylan16807 19 hours agorootparent> stuff gets evicted from the cache long before you hit the swapNo...?I&#x27;m looking at a machine right now that has 3.7GB not swapped out and 1.2GB swapped out. Meanwhile the page cache has 26GB in it.Swapping can happen regardless of how big your page cache is. And how much you want swap to be used depends on use case. Sometimes you want to tune it up or down. In general the system will be good about dropping cache first, but it&#x27;s not a guarantee.> measured by page swap-out&#x2F;in rate and not by how much swap space is usedEh? I mean, the data got there somewhere. The rate was nonzero at some point despite a huge page cache.And usually when you want to specifically talk about the swap-out&#x2F;in rate being too high, the term is \"thrashing\". reply fsckboy 15 hours agorootparentcached disk pages are not going to be swapped out, they&#x27;re just freed (because these pages are already \"out\" in the same place swapland is)if your cached disk pages keep getting hit and are \"recent\", they&#x27;re going to stay in, and your old untouched working pages are going to be swapped out, to make room either for new working pages because you&#x27;ve just loaded new programs or data, or to make room for more disk pages to be cached because your page cache accesses are \"busier\" than some of your working pages.you will swap out pages to make room for disk cache, but your cached disk pages will never be swapped out, they are just tossed (of course, after any dirty pages are written) reply throwaway092323 17 hours agoparentprevJust because it&#x27;s there, doesn&#x27;t mean I want the same programs to use more. reply flashback2199 22 hours agoprevRAM isn&#x27;t user friendly in Linux. Ubuntu Desktop is the most popular distro by far by Google Trends, but it doesn&#x27;t even come with RAM compression set up out of the box, so as soon as you run out of memory the UI totally locks up until the task killer kills a process, which always takes minutes in my experience. Pop OS does come with RAM compression set up, which is Ubuntu based, but then you&#x27;re stuck on xorg instead of Wayland right now, because they decided to make their own DE from scratch in Rust for some strange reason, which isn&#x27;t available yet. You can set up RAM compression yourself, but when macOS and Windows both have it standard, coming to Linux as a newbie so you install Ubuntu Desktop and your whole system locks up as soon as you run out of physical RAM, it&#x27;s really odd and unexpected. I&#x27;m not even sure who would want to run a desktop distro without RAM compression. reply outworlder 21 hours agoparentRAM compression is not magic.It does allow you to save RAM and might prevent you from hitting swap for a while longer, but it won&#x27;t save you if your working set is just too large and&#x2F;or difficult to compress. Apps like web browsers with multiple tabs open might be easier to compress, a game with multiple different assets that are already in a variety of compressed formats, less so.The Linux Kernel also has a bunch of optimizations (Kernel same-page merging, for example, among others) that do not require compression(although you could argue that same-page merging _is_ a form of compression).The system is not supposed to &#x27;lock up&#x27; when you run out of physical RAM. If it does, something is wrong. It might become slower as pages are flushed to disk but it shouldn&#x27;t be terrible unless you are really constrained and thrashing. If the Kernel still can&#x27;t allocate memory, you should expect the OOMKiller to start removing processes. It should not just &#x27;lock up&#x27;. Something is wrong.> which always takes minutes in my experienceIt should not take minutes. Should happen really quickly once thresholds are reached and allocations are attempted. What is probably happening is that the system has not run out of memory just yet but it is very close and is busy thrashing the swap. If this is happening frequently you may need to adjust your settings (vm.overcommit, vm.admin_reserve_kbytes, etc). Or even deploy something like EarlyOOM (https:&#x2F;&#x2F;github.com&#x2F;rfjakob&#x2F;earlyoom). Or you might just need more RAM, honestly.I have always found Linux to behave far more gracefully than Windows (OSX is debatable) in low memory conditions, and relatively easy to tune. Windows is a swapping psycho and there&#x27;s little you can do. OSX mostly does the right thing, until it doesn&#x27;t. reply jowea 20 hours agorootparent> The system is not supposed to &#x27;lock up&#x27; when you run out of physical RAM. If it does, something is wrong. It might become slower as pages are flushed to disk but it shouldn&#x27;t be terrible unless you are really constrained and thrashing. If the Kernel still can&#x27;t allocate memory, you should expect the OOMKiller to start removing processes. It should not just &#x27;lock up&#x27;. Something is wrong.I don&#x27;t why but locking up is my usual experience for Desktop Linux for many years and distros, and I remember seeing at least one article explaining why. The only real solution is calling the OOMKiller early either with a daemon or SysRq.> It should not take minutes. Should happen really quickly once thresholds are reached and allocations are attempted. What is probably happening is that the system has not run out of memory just yet but it is very close and is busy thrashing the swap. If this is happening frequently you may need to adjust your settings (vm.overcommit, vm.admin_reserve_kbytes, etc). Or even deploy something like EarlyOOM (https:&#x2F;&#x2F;github.com&#x2F;rfjakob&#x2F;earlyoom). Or you might just need more RAM, honestly.Yeah. Exactly. But as the thread says, why aren&#x27;t those things set up automatically? reply schemescape 19 hours agorootparentAs an additional data point, my usual OOM experience on Linux is also a completely frozen system until I get frustrated enough to power cycle the machine.Has anyone transitioned from this being their observed behavior to something more tolerable? What did you change to avoid this problem? reply cycomanic 16 hours agorootparentSame here, for me this has been the most annoying issue when running Linux (much less now as I have much more RAM so I don&#x27;t encounter the issue). reply sznio 8 hours agorootparentprev>The system is not supposed to &#x27;lock up&#x27; when you run out of physical RAM. If it does, something is wrong.I&#x27;ve never seen a Linux system not lock up on OOM. At work or at home the instant it starts swapping you might as well restart. Of course it has to kill the SSH daemon rather than the process using 98% of the memory.>I have always found Linux to behave far more gracefully than WindowsWindows just gets sluggish for a few seconds. You can even still move the cursor when that happens! reply MrDrMcCoy 21 hours agorootparentprevSame page merging only works for KVM, as that&#x27;s the only case that enables it without intervention that nothing else supports. It&#x27;s MADVISE for everything non-KVM, and no applications are compiled with support for telling the kernel \"hey, it&#x27;s OK to dedupe me\". The only way to get KSM to work with userspace applications is to use LD_PRELOAD to inject the necessary bits (https:&#x2F;&#x2F;github.com&#x2F;unbrice&#x2F;ksm_preload) or to use a custom kernel that has a patch and extra daemon to globally enable KSM for everything (https:&#x2F;&#x2F;codeberg.org&#x2F;pf-kernel&#x2F;uksmd).I really wish this was a standard, configurable sysctl. There are many container environments (and heck, even browsers) that would benefit from this, and I cannot see any real downside. reply mhitza 19 hours agorootparentprevOOMKiller jumps into action pretty late. I&#x27;m on Fedora, thus running the systemd-oomd service, but even with this new service the system will lock up for a minute or two before the greedy process is killed.I think with modern browsers, on memory constrained systems (think 4GB of RAM) this is easier to encounter than in the past. As someone who programs in Haskell from time to time I think I&#x27;m more familiar with Linux OOM behavior than most.If someone wants to experience this easily with Haskell just run the following in ghci foldl (+) 1 [1..] reply flashback2199 21 hours agorootparentprevDidn&#x27;t say it was magic. System slows down more as you use more RAM compression, so you have time to respond and close some apps. Without it I find I often am working at a thousand miles an hour, not noticing anything amiss, and then suddenly, brick wall, out of memory and I can&#x27;t do anything at all. reply astrange 14 hours agorootparentprev> Apps like web browsers with multiple tabs open might be easier to compressUnfortunately harder than it looks; if you compress the JS heap the garbage collector may decompress it again when scanning for references. reply ihattendorf 22 hours agoparentprevI don&#x27;t see how RAM compression helps address the machine locking up when it&#x27;ll still lock up when the compressed RAM is used up. It just buys you a little more time.Also, Fedora has had zram enabled by default for a few years now along with systemd-oomd (which can sometimes be too aggressive at killing processes in its default configuration, but is configurable). reply mxmlnkn 21 hours agorootparentsystemd-oomd is also default since Ubuntu 22.04. I remember it vividly because it effectively kept killing X when RAM filled up instead of sanely killing the process that last filled up the RAM, which is either gcc or firefox in my case. Absolutely user-unfriendly default configuration. I removed it and reinstalled earlyoom, which I have been using for years with a suitable configuration. I can only concur, RAM behavior isn&#x27;t user-friendly on Ubuntu. reply pxtail 20 hours agorootparentThank you for mentioning earlyoom - I&#x27;ll install and try it because current behavior of total, complete lockup without ability to do anything besides reset with the hardware button infuriates me unbelievably. I really don&#x27;t comprehend how something like this is possible and default behavior in 2023 in OS marketed as &#x27;desktop&#x27; and &#x27;casual&#x2F;user friendly&#x27; reply mhitza 19 hours agorootparentprevHad the same experience in the past with systemd-oomd, nowadays it does a better job at killing greedy processes than the entire user slice&#x2F;scope. reply konstantinua00 21 hours agorootparentprevI second the earlyoom recomendationit&#x27;s a lifesaver reply khimaros 20 hours agorootparentpersonally, i run my systems without swap, and kernel OOM behavior has been adequate. reply flashback2199 21 hours agorootparentprevBecause it slows down as you use more RAM compression, so you have time to respond and close some apps. Without it you are working at a thousand miles an hour and then suddenly, brick wall. reply bityard 20 hours agorootparentAh yes, the old, \"you should enable swap so that when your RAM fills up, you know about it when the disk starts thrashing and all I&#x2F;O grinds to a near-halt.\"I mean, swap is useful, but that&#x27;s not what it&#x27;s for. Same is true for compressed RAM. If you want an alert for low available RAM, it seems like it would be better to write a script for that. reply flashback2199 18 hours agorootparent> disk starts thrashing and all I&#x2F;O grinds to a near-haltNope, neither of those things happen when zram starts compressing ram. Nothing grinds to a near halt until the compressed RAM space is used up, it just slows down a little bit. Btw, compressed RAM via zram isnt swap, it&#x27;s available as actual ram. It also increases the total amount of ram available. I don&#x27;t think I need to make arguments in favor of ram compression since Windows and macOS both have ram compression by default. reply Karellen 21 hours agorootparentprev> Because it slows down as you use more RAM compression,Wait, are you claiming RAM compression uses an adaptive compression factor that compresses more as memory pressure grows?Are you sure that&#x27;s how it works? reply flashback2199 21 hours agorootparentIn the case of zram, it reserves a portion of the physical RAM, and when the remaining physical RAM portion runs out, it begins compressing ram into the reserved portion. So the system slows down a bit as this compression starts happening. Nothing really adaptive about it to my knowledge but the result to the user is a noticeable slow down when there is high ram usage, which is a heads-up to me to close some stuff. Without it the system just locks up as soon as physical RAM is exhausted, without any warning, since it&#x27;s fast up until that moment. Hope this makes sense. I&#x27;m not an expert on zram or other Linux RAM compression packages, so can&#x27;t really answer questions about it beyond that. reply IshKebab 21 hours agorootparentprevYeah you&#x27;d think it would make no difference but in my experience it does help a little. Don&#x27;t ask me why.But yeah even with zram my laptop still hard reboots 80% of the time when it runs out of RAM. No idea how people expect the Linux Desktop to ever be popular when it can&#x27;t even get a basic thing like not randomly rebooting your computer right. reply yjftsjthsd-h 22 hours agoparentprevI&#x27;m pretty sure what you&#x27;re calling RAM compression is swapping to zram, in which case the answer is that Some people prefer to not swap at all because that will still make things janky in comparison to just killing things when you&#x27;re out of memory. (I would endorse earlyoom for that) reply vlovich123 21 hours agorootparentI’ve heard this position multiple times, and yet every single benchmark I’ve seen repeated by teams of engineers in multiple contexts fails to replicate this fear. Zswap really is something that should just always be enabled. reply dmacvicar 19 hours agorootparentFor me it solved most of these lockups when using heavy ram apps (Electron, Firefox + Teams, etc) and keeps the system responsive. I am happy with it and plan to keep it enabled. I have no data to validate except that I don&#x27;t remember having to SysRq key + F some app for a long time. reply yjftsjthsd-h 21 hours agorootparentprevHow would you benchmark that? reply vlovich123 20 hours agorootparentFor example, at Oculus they ran both performance benchmarks in a lab and collected feedback data from field telemetry. Now of course, it’s always possible some performance counter was overlooked &#x2F; the degradation requires a specific workload to show, but the lack of ability to show any evidence of a difference implies that you probably are unlikely to see it given that the detractors were very vocal and engineering at big corps tends to be more stasis driven.I saw this also repeated at Apple (not Zswap since not Linux, but similar idea of compressing pages) and Android. reply MrDrMcCoy 21 hours agorootparentprevIn addition to swap on zram, there&#x27;s also zswap. zswap is not quite as good as swap on zram, but almost certainly is better suited to systems that you want to have be able to hibernate. reply flashback2199 21 hours agorootparentprevMy point was that as a new user the default experience is unfriendly and saying that I have to understand the nuance between different ram related packages in order to talk about it is just proving my point. reply yjftsjthsd-h 20 hours agorootparentI&#x27;m not saying that a new user should need to understand the nuance, I&#x27;m questioning whether your understanding of the underlying problem is accurate. I do agree that it&#x27;s a poor experience for the system to freeze up under excess memory pressure, I just think the correct fix is less swap combined with earlyoom. reply flashback2199 12 hours agorootparentGah I am so tired of explaining this in this thread: As the system begins running out of memory, it starts using more of the zram. The zram is compressed which uses CPU and slows the system down enough to notice it during which time I notice and begin closing apps. The alternative, without zram, is it&#x27;s super fast right until I run out of memory then bam my whole system locks up. Zram also effectively makes the total available ram larger because zram swap is actually useable whereas swap to disk is so slow the system basically locks up when you start depending on it as if it were ram. Just try it dammit! It takes a few mins to set up and open enough stuff to see the effects. reply olddustytrail 21 hours agoparentprevAs the other comment says (but kind of hides) install earlyoom and point the config at whatever you reckon is the main culprit. It only needs done once and you can forget about it.Edit: I should add, this is advice for desktops. If it&#x27;s a server either resize or fix your service. reply __turbobrew__ 21 hours agoprev> Disk cache can always be given back to applications immediatelyThis is not true, there is a cost to freeing the cache pages and allocating them to the other program. I have seen some very regressive performance patterns around pages getting thrashed back and forth between programs and the page cache, especially in containers which are memory limited. You throw memory maps into the mix and things can get really bad really fast. reply mnw21cam 17 hours agoparentThat&#x27;s why Linux does keep a certain amount of RAM actually-free, so that it can hand over some pages immediately. If the amount of actually-free RAM goes below a certain amount, then it will pre-emptively evict a load of cache pages. reply blueflow 20 hours agoparentprevCan you elaborate further? reply loktarogar 21 hours agoprevThis feels like a UX problem. If this is a normal and expected part of linux operation, it should be called out in the {T,G}UI. reply bityard 21 hours agoparent1. You can&#x27;t change `free` output, you&#x27;ll break SO many scripts.2. Most things which report memory usage in a user-friendly way _already_ do this in an obvious way. (Htop shows disk cache in a bar graph, but doesn&#x27;t add it to the \"used\" counter.)3. Should UX always compensate for some fraction of users&#x27; misunderstanding of how their OS kernel works? Or would it be better for them to ask the question and then be educated by the answer? reply loktarogar 20 hours agorootparent> Or would it be better for them to ask the question and then be educated by the answer?Good UX makes the question \"why is linux using my unused RAM for disk caching\" (a non pressing question) instead of \"why is linux eating up all my RAM\" (panic, stressful question) reply gruez 21 hours agoparentprevIt is. Windows does the same thing, but it&#x27;s a non-issue because task manager makes it look like cached memory is free memory. reply the8472 20 hours agoparentprevBut it does. https:&#x2F;&#x2F;files.catbox.moe&#x2F;l9je82.png orange is the part used by caches reply loktarogar 17 hours agorootparentI&#x27;m not a linux user, so not an observation of experience. Just the existence of this website suggests to me that however it is being done right now could be made clearer somehow. reply nightfly 21 hours agoparentprevhtop shows this reply skazazes 22 hours agoprevIs this the reason Windows Task Manager seems to show Vmmem (WSL2) as gobbling up well more RAM then WSL seems to indicate is in use?I have more then enough RAM on my office workstation to just accept this, but on my personal gaming computer that moonlights as a dev machine, I run into issues and have to kill WSL from time to time. reply praash 22 hours agoparentThat&#x27;s just one part of the issue - even after forcefully dropping Linux&#x27;s caches, WSL has been unable to reclaim the memory back reliably. There has been a recent update that claims to finally fix this.You might find this package helpful: https:&#x2F;&#x2F;github.com&#x2F;arkane-systems&#x2F;wsl-drop-cache reply Dylan16807 19 hours agorootparentIt&#x27;s also really annoying that \"drop caches\" seems to be the only interface here. No way to simply limit it. reply sp332 22 hours agoparentprevI think there is some conflict between the disk cache running inside WSL and the memory management outside. I tried turning up memory pressure in WSL but it didn&#x27;t help. This does work but I have to run it manually from time to time: # sync; echo 3 > &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches reply chabad360 22 hours agoparentprevNo, that&#x27;s because WSL (until v2&#x2F;very recently) didn&#x27;t properly release memory back to windows. This actually would cause docker to effectively leak memory really quickly. reply Zetobal 21 hours agoparentprevThe worst offense of wsl2 is writing files to ram before copying it to the native filesystem unusable with lots of data. reply therealmarv 21 hours agoprevWindows and Mac use compressed RAM for many many years as standard.Yet on many Linux desktop you have to activate it (namely ZRAM). It solves the problem that a e.g. browser eats all your memory. It&#x27;s much quicker than Swap and yet mostly unknown by many people who are running a Linux desktop. As mentioned by another user it&#x27;s still not standard on Ubuntu desktop and I don&#x27;t understand why. reply viraptor 21 hours agoparent> It solves the problem that a e.g. browser eats all your memory.It doesn&#x27;t solve that. You get a little bit more headroom, but that&#x27;s it. Not much ram is considered compressible anyway. On my Mac I&#x27;m barely reaching 10% of compressed memory anyway, so it doesn&#x27;t make that much difference. reply noisem4ker 21 hours agorootparentCurrent RAM usage from my Windows 10 dev machine, as reported by Task Manager:> In use: 18028 MB> In use, compressed: 2718 MB> Compressed memory stores an estimated 9013 MB of data, saving the system 6294 MB of memory.That&#x27;s not a small amount. reply therealmarv 1 hour agorootparentprevyes, it&#x27;s not the ultimate solution but if your machine behaves in 98% of cases snappy and does not slow down vs. let&#x27;s say only 70% of cases then that&#x27;s a huge usability difference. Sometimes you just need a little headroom on top and not more. As some user point out it really depends on the workload and data etc. Browsers are a good example because in my experience browser cache can be compressed quite good. reply jowea 20 hours agorootparentprevMy experience is that zram saves quite a bit. I have another old laptop with 4GB where it&#x27;s essential. Maybe it differs by program type? NAME ALGORITHM DISKSIZE DATA COMPR TOTAL STREAMS MOUNTPOINT &#x2F;dev&#x2F;zram0 lzo-rle 15,6G 1,9G 248,6M 418M 16 [SWAP] reply viraptor 19 hours agorootparentYup, it will depend on your workload a lot. Worth testing of course! reply ltbarcly3 19 hours agorootparentprev> Not much ram is considered compressible anyway.What are you basing this on? Things in RAM are often very very compressible, usually between 3:1 and 4:1. reply viraptor 17 hours agorootparentDepends on what things are in your ram. Code&#x2F;configuration&#x2F;simple data structures compress nicely. Images&#x2F;videos&#x2F;ML-models don&#x27;t. reply ltbarcly3 16 hours agorootparent> Depends on what things are in your ram.No offense, but you are being a very precise in defense but very broad in your (in general incorrect) claim.The representation of an image sitting in memory will be a bitmap array, and for sure that will compress quite well. Video data as well but any decompressed frames are so transient I agree they won&#x27;t benefit. ML-models don&#x27;t compress well, but training data certainly does.If you put aside mapping already compressed or non-compressable data into memory, all the rest of the things ram is used for can be compressed. Day to day you will have a lot of memory allocated that can be compressed. Most memory in use right now on most computers is compressible. reply dmacvicar 20 hours agoparentprevOne can also use zswap: https:&#x2F;&#x2F;docs.kernel.org&#x2F;admin-guide&#x2F;mm&#x2F;zswap.html https:&#x2F;&#x2F;wiki.archlinux.org&#x2F;title&#x2F;Zswapwhich I find easier to setup. Just enable it and it manages itself. You can still keep swap on disk, but it will act as a buffer in between, trading CPU cycles for potentially reduced swap I&#x2F;O.I think Arch has it enabled by default, but I am not sure about that. I had to enable it manually on Tumbleweed because my rolling install is years old. reply bandrami 17 hours agorootparentFedora does that on some (but not all) disk&#x2F;ram size combos. IIRC the installer won&#x27;t put swap on nvme unless you tell it to explicitly, and will always set up the smaller of 4g or half of physical memory as zram. reply bee_rider 21 hours agoparentprevCompressing data has a cost, right? Modern systems have a ridiculous amount of memory, if you are bumping into that limitation, it seems like something odd is happening.If your web browser is using all your ram, it is probably misconfigured, maybe the ad-blocker has accidentally been turned off or something? reply undersuit 19 hours agorootparentI run a Linux system with 2GB of RAM... and Intel integrated graphics, it&#x27;s storage is not exceptionally fast flash. The more pages I can keep compressed in RAM, the less the CPU has to spend waiting on the storage, especially if we&#x27;re talking about the swap partition. After letting that computer run a long time I can tell whats been swapped to disk versus just compressed to zswap. reply colinsane 19 hours agorootparentprev> Modern systems have a ridiculous amount of memorywell it depends on your definition of modern, i suppose. i run Linux on a smartphone, which is about the most modern use of Linux i can think of, and hitting that 3-4 GB RAM limit is all too easy with anything touching the web, adblocker or not.zram isn&#x27;t exactly a trump card in that kind of environment, but it certainly makes the experience of saturating the RAM a lot nicer (\"hm, this application&#x27;s about half as responsive as it usually is. checks ram. oh, better close some apps&#x2F;tabs i don&#x27;t need.\" -- versus the default of the system locking for a full minute until the OOMkiller finishes reaping everything under the sun). reply bee_rider 13 hours agorootparentHow strange, I guess we must use different websites or something. reply spookie 21 hours agoparentprevThere are distributions that enable it by default, Fedora comes to mind. reply HippoBaro 19 hours agoprevI think the information there is valuable because questions about memory usage in Linux keep coming up. The answer: \"don&#x27;t worry about it,\" is probably a good starting point. The page claims things that are just really misleading, though.> There are no downsides, except for confusing newbies.False. Populating the page cache involves lots of memory copies. It pays off if what&#x27;s written is read back many times; otherwise, it&#x27;s a net loss. It also costs cycles and memory to keep track of all these pages and maintain usage statistics so we know what page should be kept and which can be discarded. Unfortunately, Linux makes quantifying that cost hard, so it is not well understood.> You can&#x27;t disable disk caching. The only reason anyone ever wants to disable disk caching is because they think it takes memory away from their applications, which it doesn&#x27;t!People do want that, and they do turn it off. It&#x27;s probably the number one thing database people do because they want domain-specific caching in userland and use O_DIRECT to bypass the kernel caches altogether. If you don&#x27;t, you end up caching things twice, which is efficient&#x2F;redundant. reply lnyng 15 hours agoprevWe published this paper \"TMO: Transparent Memory Offloading in Datacenters\" last year which covers some Linux memory management mechanisms that may be quite useful for providing reasonable estimations to application memory usage.We observed that the real memory footprint for applications depends on many factors: file access pattern, disk IO speed (especially if swap is enabled), ssd vs hdd, application latency sensitivity, etc. Instead of coming up with some overly complicated heuristic, we use the Linux kernel provided memory.pressure [0] metric via cgroup v2. It measures the amount of time spent waiting for memory (page fault etc). Then by slowly reclaiming memory from the application until its memory pressure hits some target (say 0.1%), we can claim that the steady state usage is the actual memory footprint.This may not be useful for PC but could be very useful for data center to track memory regression, and also to harvest disk swap without concerning too much about the cliff effect when the host runs out of memory and suddenly kernel pushes everything to swap space.[0] https:&#x2F;&#x2F;facebookmicrosites.github.io&#x2F;cgroup2&#x2F;docs&#x2F;pressure-m... reply bminor13 21 hours agoprevDoes anyone happen to have expertise&#x2F;pointers on how ZFS&#x27; ARC interacts with Linux disk caching currently when using ZFS-on-Linux? It seems like the ARC space shows up as \"used\" despite being in a similar category of \"made available if needed\" - is that correct?Is data in the ARC double-cached by Linux&#x27;s disk caching mentioned in the post? If so, is it possible to disable this double-caching somehow? reply MrDrMcCoy 21 hours agoparentZFS ARC unfortunately does not integrate with the kernel file cache, so they step on each other a lot. ZFS does watch available system RAM and try to dynamically reduce its usage as memory pressure increases, but I&#x27;ve found its responsiveness for this to be far too slow. This combined with how ARC appears to just be an opaque block of RAM that cannot be reclaimed, I usually just set a hard limit on how big the ARC is allowed to get in the module load arguments and be done with it (at least for systems that are doing more than just storage). reply drewg123 20 hours agorootparentIs ARC really non-reclaimable on Linux?At least on FreeBSD, there is a kmem_cache_reap() that is called from the core kernel VM system&#x27;s low memory handlers.Looking at the linux code in openzfs, it looks like there is an \"spl_kmem_cache_reap_now()\" function. Maybe the problem is the kernel dev&#x27;s anti-ZFS stance, and it can&#x27;t be hooked into the right place (eg, the kernel&#x27;s VM low memory handling code)? reply MrDrMcCoy 18 hours agorootparentIt&#x27;s reclaimable, but opaque. The ARC just looks like used RAM rather than file cache, which throws off various means of accounting. reply nubinetwork 9 hours agorootparentprevecho 3 > &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches(Bear in mind that 3 is the most aggressive but other than exporting the pool, it&#x27;s the only way to dump the cache, especially if you boot off ZFS) reply nubinetwork 9 hours agoparentprevARC is completely separate from FS caches... if the kernel needs memory, it will tell ZFS to prune the ARC, however it&#x27;s not exactly instantaneous.Newer versions of htop also now have counters for ARC usage (compressed or uncompressed)... but it still shows up as used rather than cache. reply neurostimulant 21 hours agoprev> If your applications want more memory, they just take back a chunk that the disk cache borrowed. Disk cache can always be given back to applications immediately! You are not low on ram!I&#x27;m running RKE2 on my desktop and it&#x27;ll start killing pods due to low memory pressure, even though the memory was only used for disk caching. I wonder if there is any way to make it stop doing that and instead only start killing pods if it&#x27;s due to \"real\" low memory pressure. reply blueflow 20 hours agoparentThink about it: A processes executable code comes from a file. You will need the size of the executable available as disk cache or the program execution will cause heavy thrashing and I&#x2F;O. So some part of it is \"real\" memory pressure. reply neurostimulant 18 hours agorootparentI also run an nfs server in the same machine, so after a period of heavy nfs use, most of the ram were eaten by the disk cache and rke2&#x2F;kubernetes start having memory pressure taint. After a fresh restart with all pods running, the memory usage is below 10%, so I doubt the disk cache was full with executable files cache. reply okwhateverdude 20 hours agoparentprevAssuming Linux, oddly enough I came across this exact behavior[0] while researching resource management for an on-prem k8s cluster. Take a look at that thread for more info, but TL;DR, you need to actually finesse page cache constraints if you want avoid the behavior. You actually can have really fine grained control over page cache via cgroups v2[1][2] and systemd[3].[0]: https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;issues&#x2F;43916[1]: https:&#x2F;&#x2F;docs.kernel.org&#x2F;admin-guide&#x2F;cgroup-v2.html#memory-in...[2]: https:&#x2F;&#x2F;biriukov.dev&#x2F;docs&#x2F;page-cache&#x2F;6-cgroup-v2-and-page-ca...[3]: https:&#x2F;&#x2F;www.freedesktop.org&#x2F;software&#x2F;systemd&#x2F;man&#x2F;systemd.res... reply neurostimulant 17 hours agorootparentThank you for the pointers. That&#x27;s a lot of things to learn since I never look into cgroup before. I&#x27;ll see if there is something better there than my current \"fix\" (periodically run `echo 1 > &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches`). reply GuB-42 19 hours agoprevI remember that being the case for early versions of Android, people were surprised all their RAM was used, and of course, we could find apps that \"freed\" the RAM, generally making things worse.And the response was similar: all that \"used\" RAM can be reclaimed at any time should an app need some, but in the meantime, the system (which is Linux) might as well use it.I think they \"fixed\" it in later versions. I don&#x27;t know how, but I suspect they just changed the UI to stop people from complaining and downloading counterproductive apps.As usual in these situations, unless you really know what you are doing, let the system do its job, some of the best engineers with good knowledge of the internals have worked on it, you won&#x27;t do better by looking at a single number and downloading random apps. For RAM in particular, because of the way virtual memory works, it is hard to get an idea of what is happening. There are caches, shared memory, mapped files, in-app allocators, etc... reply burnte 21 hours agoprevUnused RAM is wasted RAM. Why people want to see GOBS of empty RAM boggles my mind. reply filchermcurr 19 hours agoparentI think the disconnect is not understanding how the RAM is used. If the average user looks and sees all of their RAM in use, they&#x27;re going to think that there&#x27;s no more room for the applications that they want to launch. They don&#x27;t understand that what&#x27;s cached will just get out of the way when the memory is actually needed. So they want to see free RAM, because that means it&#x27;s free for their game or millions of tabs. reply lxe 21 hours agoprevThis made me chase red herrings when debugging oom issues in production. Wish free would just remove the &#x27;free&#x27; column and replaced it with &#x27;available&#x27;. reply tetha 20 hours agoparentThis is what we did in pretty much all of our monitoring some time ago. We ripped out most memory graphs except for \"Total Memory\" and \"Available Memory\" as well as memory pressure from the PSI metrics. And we placed alerts on available memory growing low, as well as pages being swapped in. Newer kernel opportunistically swap-out idle pages, but that&#x27;s fine as long as you never see the path from disk to memory (swap-in).This has increased the quality of our memory monitoring by a lot. reply mkhnews 22 hours agoprev>> If applications want more memory, they just take it back from the disk cache. Q: If there is no swap configured, will a malloc() then take away clean page-cache pages ? Or does that happen only on page-in ? reply dfox 21 hours agoparentIn general, no and it will happen when there is something actually written to the page (which will cause a page fault and the kernel will have to somehow materialize the page). This works the same way regardless of how &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;overcommit_memory is configured, the setting only affects how kernel tracks how much memory it is going to need in the future. (Obviously if we talk about malloc() this is a slight over-simplification as most malloc() implementations will write some kind of book-keeping structure and thus dirty some of the allocated pages)Whether swap is available is more or less irrelevant for this behavior. The only thing that swap changes is that kernel is then able to “clean” dirty anonymous pages by writing them out to swap. reply AnotherGoodName 21 hours agoparentprevmalloc will take away from the disk cache.Fwiw without swap there isn&#x27;t really any paging in or out (yes mmapped files technically still can but they are basically a special cased type of swap) so your question is hard to parse in this context. The disk cache is all about using unallocated memory and an allocation will reduce it. Paging is irrelevant here.Btw you should always enable swap. Without it you force all unused but allocated memory to live on physical RAM. Why would you want to do this? There&#x27;s absolutely no benchmarks that show better performance with no swap. In fact it&#x27;s almost always the opposite. Add some swap. Enjoy the performance boost!https:&#x2F;&#x2F;haydenjames.io&#x2F;linux-performance-almost-always-add-s... reply dfox 21 hours agorootparentI would say that for any modern unix implementation mmaped pages are quite significant, as all the read-only copies of libc code, other shared libraries and various mmaped data files (iconv tables, locales, terminfo, gettext catalogs…) are not exactly small. reply robinsonb5 20 hours agorootparentWhich is why disabling swap in the hopes of preventing the system grinding to a halt on out-of-memory doesn&#x27;t work, and actually makes things worse. reply thiag0 3 hours agoprevIs the website down? I was reading and suddenly started to get timeout. reply mkhnews 20 hours agoprevAnother question is about containers and memory limits. Does the page-cache count against my container memory limit ? And if so, then when I hit that limit from doing many reads, does the page-cache start taking from itself without OOM killer getting involved ? reply defer 19 hours agoparentI also want to know this, but in reverse.I build older android (the OS) versions inside docker containers because they have dependencies on older glibc versions.This is a memory-heavy multi-threaded process and the OOM killer will kill build threads, making my build fail. However, there is plenty of available (but not free) memory in the docker host, but apparently not available in the container. If I drop caches on the host periodically, the build generally succeeds. reply mkhnews 19 hours agorootparentAnd perhaps k8s is a specific category to consider here. I&#x27;ve read and thought I&#x27;ve experienced where &#x27;active&#x27; (as opposed to in-active) page-cache does count towards k8s mem limit. reply otterley 19 hours agoparentprev1. Pages cached by applications are charged to its container for the purpose of memory resource limits.2. IME the kernel takes the container&#x27;s memory limit into account when determining whether to allocate a page for cache. Caching, by itself, won&#x27;t cause the container to exceed a memory limit. reply jenadine 21 hours agoprevHow old is this website? It&#x27;s from a time when a typical computer only had 1.5 G of ram. reply I_Am_Nous 20 hours agoparentThe domain appears to have been registered 25 Apr 2009, and I remember seeing this quite a while ago. That would make sense for 1.5 G of RAM being typical. Glad it&#x27;s still around :) reply Pathogen-David 20 hours agoparentprevOldest copy on the Wayback Machine is from May 2009 https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20090513043445&#x2F;https:&#x2F;&#x2F;www.linux... reply Tao3300 22 hours agoprevI pity the fool who don&#x27;t eat RAM. reply meepmorp 21 hours agoparentIt’s the first thing that popped into my head. reply msla 21 hours agoparentprevI guess people around here are Too Young.This is a reference to a legitimate piece of Internet history:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ate_my_balls> \"Ate my balls\" is one of the earliest examples of an internet meme. It was widely shared in the late 1990s when adherents created web pages to depict a particular celebrity, fictional character, or other subject&#x27;s zeal for eating testicles. Often, the site would consist of a humorous fictitious story or comic featuring edited photos about the titular individual; the photo editing was often crude and featured the character next to comic-book style speech in a thought balloon.> The fad was started in 1996 by Nehal Patel, a student at University of Illinois at Urbana-Champaign with a \"Mr. T Ate My Balls\" web page. reply simonblack 16 hours agoprevWhy all the fuss??When you can download as much RAM as you want, any time you want.https:&#x2F;&#x2F;downloadmoreram.com&#x2F; reply 404mm 17 hours agoprevYou can always just download more RAM. https:&#x2F;&#x2F;www.downloadmoreram.com reply fuzztester 14 hours agoprevWindows ate my hard disk (every year). reply wingworks 20 hours agoprevhtop shows this (it&#x27;s the orange&#x2F;yellow bar in RAM) reply withinboredom 16 hours agoparentI recommend btop these days (https:&#x2F;&#x2F;github.com&#x2F;aristocratos&#x2F;btop) reply wingworks 14 hours agorootparentI just tried btop, it has crazy colours (nothing like screenshots) on my Mac Terminal app (Misterioso theme). reply Karunamon 20 hours agoprevOkay, if unused memory is wasted and there are truly no consequences for the \"free\" column reading zero, then why on a busy system do I get UI chugging and otherwise poor (bordering on unusable) performance under this condition that is immediately resolved by forcing the caches to drop and freeing multiple gigabytes?Whatever conceivable speedup there is from 12 GB of file cache as opposed to 11 is obliterated multiple times over from the time lost by having to do this dance, or worse, recovering after the oom killer wipes out my X session or browser. reply AnotherGoodName 19 hours agoparent>recovering after the oom killer wipes out my X session or browser.Perhaps you can share more details of what you&#x27;re doing to force the cache to drop and what the side effects are exactly because an OOM can&#x27;t be caused by the file cache since the total free memory available to applications remains the same. The whole point of the file cache is to use otherwise unallocated memory and give it up the moment it&#x27;s needed. There should not be an OOM from this short of an OS bug or an over allocated virtualized system. reply Karunamon 19 hours agorootparentnext [–]echo 3 > &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_cachesLast time I ran into this was a couple of years ago on a stock Arch system. (Disabilities forced me back to Windows). Every time, the largest memory consumer was the web browser. Also every time, the system became nearly unresponsive due to swap thrashing (kswapd at the top of the CPU usage list, most of which was I&#x2F;O wait).Last time I complained about this problem, someone suggested installing zram which did stop it from happening. However, this does not change the fact that there is some pathological failure case that contradicts the central thesis (not to mention, smug tone) of this website and makes searching for solutions to the problem infuriating. reply PhilipRoman 18 hours agoparentprevI find that task priorities in general are not strict enough under Linux. Try running a cpu heavy but very low priority task in background and it still manages to measurably affect the latency of the more important process. And this is just the CPU, not to mention disk utilization and network usage.I was too lazy to find a proper solution, so I just used mlockall after allocating a massive heap and pin the process to a core that is reserved only for this specific purpose.I think cgroups has very flexible tools for reserving system wide resources, but haven&#x27;t had the time to test it yet. reply mavhc 20 hours agoprevMy Linux ram problems are 1: Ubuntu default install, ends up with xwayland using 5GB ram. 2: when running out of ram it seems to default to crashing back to the logon screen reply Scarbutt 20 hours agoprevIt&#x27;s weird that their &#x27;used&#x27; column is accounting for &#x27;buff&#x2F;cache&#x27;&#x27;man free&#x27; states used Used or unavailable memory (calculated as total - available) reply zaptrem 21 hours agoprev [–] > Disk caching makes the system much faster and more responsive! There are no downsides, except for confusing newbies. It does not take memory away from applications in any way, ever!No downsides except for massive data loss when the system suddenly loses power&#x2F;a drive crashes and the massive theft of memory from host OSes (e.g., when using Windows Subsystem for Linux). reply nightfly 21 hours agoparent [–] There is no data loss from disk caching. reply zaptrem 20 hours agorootparent [–] Does disk caching not include write caching? reply ormax3 19 hours agorootparentthe cache being talked about is for recently&#x2F;frequently accesses things, not stuff pending write reply nightfly 20 hours agorootparentprev [–] Not in the context we&#x27;re talking about reply hifromwork 17 hours agorootparent [–] Are you sure? Dirty pages have to reside somewhere, so they are actually stuck in RAM until successfully written RAM. Linux will lie with straight face that dd to my 8gb pendrive finished successfully in a few seconds, so there may be non-trivial amounts of RAM involved here.I don&#x27;t know enough of Linux internals to know if the writeback cache and read cache are the same object in the kernel, but they feel similar.Of course the real response is that without write cache (effectively adding fsync to every write) any modern linux system will grind to absolute halt and doing anything would be a challenge. So contray to GP&#x27;s post, it&#x27;s not reasonable to complain about it&#x27;s existence. reply withinboredom 16 hours agorootparent [–] It&#x27;s written asap to disk unless you configure it otherwise. The disk (or flash disk, in your case) has its own ram before actually flushing to physical storage (fsync, unless it lies, in which case there is probably an article about it here cough macs cough). So the kernel isn&#x27;t lying to you, but your disk probably is. reply Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion revolves around memory usage and management in Linux systems, with user frustrations pointing to system lockups owing to low memory, and questionable behaviour of the Out of Memory (OOM) killer.",
      "Possible solutions/tools like DAMON, RAM compression, and ZRAM are scrutinized to enhance system performance and prevent lockups.",
      "The effect of disk caching on system performance is debated, showing the complexities and trade-offs inherent in Linux memory management."
    ],
    "points": 239,
    "commentCount": 180,
    "retryCount": 0,
    "time": 1696872690
  },
  {
    "id": 37826775,
    "title": "Stop EU Chat Control",
    "originLink": "https://stopchatcontrol.eu/",
    "originBody": "Skip to content Home Arguments Testimonials Contact MEPs Share Post Petition English LET’S STOP THE CHAT CONTROL TOGETHER! In order to put pressure on the policy makers we need to come together and contact all of our European friends and our national members of the European Parliament to convince them that the chat control contradicts our fundamental rights. With the help of GPT-3 we will support you in your political opposition. Contact your local MEP Inform your European friends OUR ARGUMENTS Ursula von der Leyen and the European Commission 🇪🇺 launch an attack on our civil rights with chat control.🚩🚩🚩 With the chat control, the European Commission wants to prevent the spread of child abuse depictions and grooming. You can find out why chat control is unfortunately the wrong tool here: If the chat control detects suspicious content 🚨 – it will be forwarded to an authority. The two problems here: 1⃣ Completely normal photos, such as holiday pictures 🏞 are considered suspicious. The chat control therefore produces too many false results and overloads the authorities. This will lead to fewer investigation successes. 2⃣ So our private family photos or the chats and pictures from your sexting yesterday 🍑🍆 also end up on an official table. So we can throw privacy in the bin 🚮 The chat control is not in line with the Charter of Fundamental Rights⛔ The digital secrecy of letters is thus going into the digital wastebasket 🚮 The chat control would read and screen all our WhatsApp messages, emails, photos and videos on our cell phone in real time 🔦 Minors are prohibited from accessing apps where there is a risk that adults could write to children illegally. So basically all common social media apps. Look for a leisure activity without an app 🙃 WhatsApp, Snapchat etc. are forced to check the age of their users with chat control. The apps will have to do this with a photo and proof of passport. So you can forget about being anonymous on a dating app 🙅🙅♂ The EU Data Protection Board, the European Parliament’s Research Service and the EU Council’s Legal Service say they are warning of chat controls. Ursula von der Leyen is not interested in these opinions 🤡 🚩 The chat control destroys the encryption infrastructure 🔐 Because it must always be possible to read the encrypted messages unencrypted. That’s the only way to check what’s inside. This means full monitoring of all news, including journalists, lawyers and political opponents in exile. Child protection can also be improved without chat control. Instead, investments must be made in equipping and training the judiciary, the police, Europol and in cooperation between the authorities 💶⚖ EU member states already have sufficient powers to monitor criminal suspects on a case-by-case basis and to secure evidence 🚔 A general surveillance of our digital communication is more reminiscent of China than European values 👁 TESTIMONIALS “Commission President Von der Leyen’s planned chat control is a Big Brother agency that would monitor EU citizens’ private communications. We must prevent this massive state surveillance.” Moritz Körner Member of the European Parliament “Chat control is dangerous for us as it threatens our privacy and freedom of expression. Through the monitoring and censorship of our online communication, we are restricted in our freedom to form opinions. It also opens the door to abuse and manipulation by governments and authoritarian organizations. It is important that we defend our rights to privacy and freedom of expression in order to maintain an open and democratic society.” Franziska Brandmann Federal Chair of the Young Liberals Germany NOW IT’S YOUR TURN! Send your local member of the European Parliament an e-mail with the drafting help of GPT-3! All you need to do is to choose your country of origin: Austria Belgium Bulgaria Croatia Cyprus Czech Denmark Estonia Finland France Germany Greece Hungary Ireland Italy Latvia Lithuania Luxembourg Malta Netherlands Poland Portugal Romania Slovakia Slovenia Spain Sweden Generate Please note that the drafts generated by Large Language Models can still contain errors. Read the draft carefully and eventually correct mistakes prior to sending your e-Mail! CONTACT YOUR EUROPEAN FRIENDS Chances are high that most of your European friends have never heard of chat control. So let them know about the danger and what you think about the chat control proposal. MESSENGER SERVICES Hey, the European Commission launched an attack on our civil rights with chat control. But we can still stop the proposal. Let us contact all our friends and also the members of the European Parliament to make sure that they vote against it. This Website I found will help you do that using A.I.: www.Stop-Chat-Control.eu Check it out! Copy Send via WhatsApp Send via Telegram TWITTER & FACEBOOK The European Commission launched an attack on our civil rights with chat control. I contacted my local MEP to tell him that I oppose the proposal. You can do so too! This Website I found will help you write an e-mail to an MEP using A.I.: www.Stop-Chat-Control.eu #StopChatControl Copy Share on Twitter Share on Facebook INSTAGRAM CREATE YOUR OWN POST Stop Chat Control Slides (EN) Download all SIGN OUR PETITION! Using petitions we can put further pressure onto the lawmakers. Support us by signing our petition today! Sign now! Legal NoticePrivacy Policy",
    "commentLink": "https://news.ycombinator.com/item?id=37826775",
    "commentBody": "Stop EU Chat ControlHacker NewspastloginStop EU Chat Control (stopchatcontrol.eu) 185 points by porsager 16 hours ago| hidepastfavorite114 comments marcus_holmes 13 hours agoA bit less than 25 years ago, I was IT director at a small tech company. The MD approached me and asked about how we stop people looking at pr0n on the company&#x27;s internet.I looked into it, and worked out how much we&#x27;d need to restrict and monitor everyone&#x27;s internet activity. And then realised that this wasn&#x27;t a tech problem at all. If someone is looking at pr0n instead of doing their job, then that&#x27;s a line management problem. Exactly the same as if they were reading a copy of Playboy at their desk.Preventing child abuse is, similarly, not a tech problem. It&#x27;s a human problem. The internet did not cause this problem, and if we monitor every single byte sent over a wire, the problem will still remain. reply arp242 12 hours agoparentYou can apply this argument against pretty much anything: theft, murder, sexual assault, general twatery, etc. because in the end almost every crime or other undesirable behaviour is a \"human problem\".Almost no one would disagree that removing all instances of CSAM from the internet would be a good thing, whether it&#x27;s a \"human problem\" or not. That&#x27;s not really the issue. Things like \"how much we&#x27;d need to restrict and monitor everyone&#x27;s internet activity\" is the problem: it&#x27;s all very complex and probably not worth the cost. reply AnthonyMouse 11 hours agorootparent> You can apply this argument against pretty much anything: theft, murder, sexual assault, general twatery, etc. because in the end almost every crime or other undesirable behaviour is a \"human problem\".Exactly?None of them are tech problems, they all predate the tech and so do the solutions. The police do ordinary policework, arrest the criminals and they&#x27;re convicted of their crimes.Mass surveillance is a dangerous power grab regardless of the purported rationale. reply arp242 8 hours agorootparentThe argument is \"it&#x27;s not worth the trade-off, because the downsides are [X]\".This is a profoundly different argument than \"we should never under any circumstances use any technology to prevent anything because &#x27;it&#x27;s not a tech a tech problem&#x27; and&#x2F;or &#x27;it predates tech&#x27;\".Merely \"X predates Y\" is a worthless argument that can be applied to almost everything (accidents predate cars, murder predates guns, war predates ICBMs, etc. etc.) reply AnthonyMouse 23 minutes agorootparentThe distinction is between the police using technology and the population being subjected to it involuntarily.Fingerprints are a technology. If your fingerprints are on the murder weapon the police can use that as evidence that their suspect is the murderer. That&#x27;s not the same thing as requiring everyone to be fingerprinted ahead of time. reply watwut 8 hours agorootparentprevWe use quite a lot of tech to mitigate the theft and murder problem. Including stuff like having lamps on the streets in the night.> The police do ordinary policework, arrest the criminals and they&#x27;re convicted of their crimes.Only around 54% of murders are solved by police. Other crimes have lower clearance rates. reply AnthonyMouse 18 minutes agorootparent> We use quite a lot of tech to mitigate the theft and murder problem. Including stuff like having lamps on the streets in the night.These are not required by law, or if they are they shouldn&#x27;t be.> Only around 54% of murders are solved by police.This is quite sufficient to provide an effective deterrent. If someone is willing to take a 54% chance of a murder conviction then you weren&#x27;t going to deter them with a 59% chance of one. reply snowpid 7 hours agorootparentprevwhich country? which source? reply watwut 2 hours agorootparentI googled it for United States. reply deely3 11 hours agorootparentprevUsually you will not be thrown in a jail for having images of arm, or theft, or murder in some folder.Ha, we officially buy videos of murders and theft from big companies and even see these videos on a big screen in groups. reply eterps 9 hours agorootparentprev> Almost no one would disagree that removing all instances of CSAM from the internet would be a good thing, whether it&#x27;s a \"human problem\" or not. That&#x27;s not really the issue.Would removing all instances of CSAM from the internet be a good thing if it would lead to an increase in CSA? After all the human problem still exists after removing CSAM. reply arp242 8 hours agorootparent> Would removing all instances of CSAM from the internet be a good thing if it would lead to an increase in CSA?Yes.Even if CSAM would reduce actual abuse (which is a big \"IF\", last time I looked researched leaned weakly towards that it increased abuse), the argument is essentially a variant of the trolley problem: \"we&#x27;ll let one kid be abused to make the CSAM to save n others\". I&#x27;m not comfterable with that, especially since alternatives such as cartoons, AI-generated, or just old-fashioned photoshop exist (but whether that&#x27;s a good thing is debatable, and is rather off-topic here). reply eterps 8 hours agorootparent> AI-generated, or just old-fashioned photoshop existAren&#x27;t those considered CSAM as well? At least as far as the EU Chat Control proposal is concerned?BTW, you raise an interesting point about the argument being a variant of the trolley problem. reply arp242 7 hours agorootparentI don&#x27;t know what the EU chat law thinks of that, I&#x27;d have to read the law[1], but no child was abused so it&#x27;s not CSAM under a \"common sense\" definition.[1]: The definition that the law uses is in Directive 2011&#x2F;93. In a very quick check it probably would be considered CSAM, but I&#x27;d have to read the entire thing to be sure: https:&#x2F;&#x2F;eur-lex.europa.eu&#x2F;legal-content&#x2F;EN&#x2F;TXT&#x2F;HTML&#x2F;?uri=CEL... reply squigz 8 hours agorootparentprevPerhaps I&#x27;m misunderstanding something, but are you saying that if the research said conclusively that banning CSAM absolutely leads to an increase in actual sexual assaults against children, it would still be a good idea to ban CSAM? replyrenegat0x0 2 hours agoparentprevWhen you try to remove a bug from code, sometimes you make the bug to be more nuanced and hidden from plain sight.I am not sure if you can remove crimes with surveillance. Maybe people will just hide deeper. The government will receive &#x27;new powers&#x27;, but crimes will not be solved.But maybe after all that is the end goal. To win the \"Crypto wars\". Not to solve crimes.How many cases where solved because of Patriot Act? reply npteljes 6 hours agoparentprevBreak-ins are also not a technological problem, but even a simple lock helps - a lock that can trivially be picked. Setting up the perimeter, a technological thing, sends the psychological message that there&#x27;s a barrier, the insides are for people with access only. It doesn&#x27;t prevent break-ins, but the frequency is reduced significantly. reply phowat 12 hours agoparentprevWhy not just write \"porn\" ? Is there some sort of filter here on hn I&#x27;m not aware of ? reply jstarfish 11 minutes agorootparent\"Child pornography\" is very specifically-defined in terms of strictly-photorealistic content.Notice that the topic discussed here is chat control. What does this have to do with photorealistic content?The \"CSAM\" moniker is a broad net that drags other forms of media into scope. Sharing a fictional story about raping a child isn&#x27;t child pornography (there&#x27;s no victim)...but it is CSAM.Same with manga&#x2F;comics, sharing elaborate fantasies, AI images and any other fictional products. As CSAM, all of it becomes fair game for indictment. reply marcus_holmes 9 hours agorootparentprevNot so much these days. But back in the day one of the crude efforts to control access to porn on the internet was filtering for the word \"porn\", which lead to a standard mis-spelling of it as \"pr0n\". Which became so ingrained that I now spell it that way by default.I was mostly referencing that rather than trying to avoid an actual filter now. reply abdusco 7 hours agorootparentAny filter worth its salt would also include \"pr0n\" along with \"porn\" reply lozf 4 hours agorootparentJust write \"pom\" and pretend it&#x27;s a keming issue ;) reply KirillPanov 12 hours agorootparentprevYes, quite a few in fact. That&#x27;s why you&#x27;ll see a lot of intentional mis-spellings like \"virtual signaling\". reply barrysteve 38 minutes agoparentprevComputer security used as an adult babysitting tool, is ripe for abuse. reply DavideNL 10 hours agoprev[offtopic]\"You do not have access to stopchatcontrol.eu. The site owner may have set restrictions that prevent you from accessing the site.\" \"\"Sigh... perhaps we should start \"stopCloudflareAccessControl.eu\".[&#x2F;offtopic] reply derelicta 9 hours agoprevCasual reminder there are talks to extend the reach of the chat control, now plenty of reactionary politicians wish it could also target regular criminal offenses, like drug dealing, or drag shows. reply rand846633 9 hours agoparentCopyright infringement will follow soon.. reply frizlab 12 hours agoprevIn French the autogenerated text is a (bad) joke. As an argument as to why the chat control law should not pass it’s saying chats are pets and are a part of the family! Because yes, chat means cat in French…I stopped reading after that and increased my already great distaste for LLM and co.It’s sad because we actually must stop chat control. It’s a terrible idea. (Like most EU regulations nowadays.) reply ThePowerOfFuet 7 hours agoparentWhat autogenerated French text? The only two languages offered seem to be English and German. reply T-A 6 hours agorootparentScroll down to \"Send your local member of the European Parliament an e-mail with the drafting help of GPT-3!\" reply xvector 13 hours agoprevThe EU is a total clusterfuck when it comes to tech regulation. Maybe the only good thing out of the EU is GDPR, everything else has been a massive overreach doing more harm than good. reply makeitdouble 13 hours agoparentThey&#x27;d have less success and support if the EU wasn&#x27;t the only entity doing something about antitrust and market abuse. This kind of massive initiative becomes realistic because they&#x27;ve been battling for ages against the tech giants and know they can take the heat. reply AnthonyMouse 11 hours agorootparentAre they though? They make a lot of noise about it but meanwhile who have they broken up? You can&#x27;t even replace the OS your phone came with in most cases, Safari&#x2F;Chrome derivatives are 95% of the browser market, app stores are still charging 30% with no meaningful competition and excluding apps that compete with their own, Qualcomm et al don&#x27;t publish what&#x27;s necessary to produce indepedent firmware for the zillion devices that use their chips and whose OEMs went out of business or otherwise stopped updating them.Sound and fury is nothing. Actually fix some of these. reply makeitdouble 4 hours agorootparentYou&#x27;re asking these questions as if others have shown strides in all these domains and they&#x27;re table stakes.Apple got asked why they take 30% by the US gov, answered that they just like money, and never got asked anything again. The only gov that could do squat on that front is China. Netherlands and Korea barely got some small exceptions.Same way Google&#x27;s only trial that went anywhere regarding Google Services binding happened in EU, and the only country that got away with a vibrant android ecosystem is China (to my knowledge...does India do too?)I&#x27;ll poopoo Eu&#x27;s efforts when another entity actually splits Google away, and I&#x27;ll be really happy to do so, trust me. reply AnthonyMouse 1 hour agorootparentYou&#x27;re using \"at least they do something about antitrust\" as an excuse for all their poorly thought out rules that increase compliance burdens and actually make competing in those markets harder. You can&#x27;t then say \"well the US isn&#x27;t doing it\" -- the US isn&#x27;t imposing the higher compliance costs either. reply scarface_74 10 hours agorootparentprevPlease tell me where this fairy tale comes from that either Apple or Google are excluding apps that compete with its own? reply AnthonyMouse 9 hours agorootparentApple, for iOS? You have to use their browser engine, you can&#x27;t install anything like a JVM or the .NET runtime that competes with their APIs, you can&#x27;t replace the Apple libraries that other apps use even if you were willing to implement the same interface, you have to use their App Store app to install other apps, you can&#x27;t produce kernel drivers for third party hardware, pretty much all of the software they include with the device you&#x27;re proscribed from replacing with a competing offering from someone else.Google uses different methods (e.g. until fairly recently third party app stores couldn&#x27;t auto-update the apps they installed, now many apps require attestation that fails if you don&#x27;t run Google&#x27;s code), but somehow or other the vast majority of Android phones still end up with Google Play and Google services. reply scarface_74 4 hours agorootparentAll that and you still haven’t shown where “you can’t install an app that competes with their own”Microsoft and Google both have cross platform frameworks for iOS and Android. reply AnthonyMouse 41 minutes agorootparentBrowsers with their own browser engines and bytecode runtimes are apps. These are the exact things Microsoft got in trouble for in the 90s -- because they enable competition.A translation layer between a generic API and Apple&#x27;s isn&#x27;t the same thing. It can&#x27;t add things Apple&#x27;s doesn&#x27;t already have. For example, how do you run CUDA or OpenCL code on Apple&#x27;s devices? Can a cross-platform framework provide a payments implementation so your cross-platform app can use a cross-platform payments system for in-app purchases? No, because they make you use theirs and apps that compete with theirs aren&#x27;t allowed.Visual Studio Code is clearly an app. Apple doesn&#x27;t allow it on iOS. Apple makes a competing app -- for which they want you to buy a Mac.You can&#x27;t just use a definition of \"app\" that means \"whatever is in their app store\" and then claim that whatever they don&#x27;t allow in their app store isn&#x27;t an app. reply scarface_74 1 minute agorootparentA bytceode runtime is not an “application”.Apple never stopped VSCode from being on iOS. There are plenty of IDEs for the iPad built by third parties.No one would ever call a virtual machine an “application”.Are you making up things now? You don’t run CUDA on any non Nvidia hardware.But yes, you are free to port OpenCL to iOS if you want to.> Can a cross-platform framework provide a payments implementation so your cross-platform app can use a cross-platform payments system for in-app purchasesA “payment API” is not an “application”. Yes the cross platform frameworks do expose the underlying API.And you can have a cross platform app that forces you to subscribe outside of the App Store - Spotify, Netflix, Microsoft, etc all do that.> No because they make you use theirs and apps that compete with theirs aren&#x27;t allowed.Are you saying that their no competitors on iOS to AppleTV, Apple Music, Apple Podcasts, Apple Books, the iWork suite?TrickyRick 12 hours agoparentprevMandated USB-C was good, swappable batteries that&#x27;s coming in a few years as well. GDPR was mostly useless and the only real consequence is more cookie banners that people accept as a knee jerk reaction and a lot of money that went to lawyers and \"consultants\" which helped smaller businesses get \"GDPR ready\".Chat control is not really tech regulation though, even if it affects tech the proposal is written by people who have no idea what the fuck they are doing. Ylva Johansson (The MEP responsible for it) has even said straight out she has no idea if or how this should be complied with but \"They will figure it out\" (They being tech companies). With people like that deciding our laws of course you end up with shit like this. reply lazycouchpotato 12 hours agorootparent> GDPR was mostly uselessI would disagree with that. I like being able to download a copy of all my data from all these big websites. Since I no longer use Twitter&#x2F;X, it&#x27;s nice to have a copy of everything I have posted there. reply AnthonyMouse 11 hours agorootparentThey had that before the GDPR. reply Martinussen 4 hours agorootparentAs someone that worked in an EEA tech company when the GDPR was actually being implemented, it absolutely did a ton for improving how much focus there was on privacy and PII security. That has seemed to be true for the places I&#x27;ve worked since too, from what I&#x27;ve heard. Most companies still have no good process for data deletion or export, and I am fairly convinced it would be even more dire if people hadn&#x27;t started preparing for the GDPR years ahead. reply Moldoteck 8 hours agorootparentprevYes, but now with gdpr it&#x27;s enforceable, what if twit decides to stop providing that data? reply AnthonyMouse 34 minutes agorootparent> Yes, but now with gdpr it&#x27;s enforceable, what if twit decides to stop providing that data?Why would you want a law with high compliance costs to solve a problem that was already solved? It makes no sense to impose the costs unless the thing it purports to solve actually presents as a problem. reply cccbbbaaa 8 hours agorootparentprevIt was enforceable before too, thanks to the Data Protection Directive from 1995. GDPR is an harmonization of the various national transcriptions of the DPD, plus higher fines, a better cooperation mechanism, and data portability (which is a bit useless but it&#x27;s nice to have). Cookie banners also predate GDPR (it was the ePrivacy directive). reply isodev 10 hours agorootparentprev> GDPR was mostly uselessNot at all, I think it achieved exactly what it was designed to do. The part where we blindly accept cookie banners without holding companies accountable for doing so much tracking (or put them in place without questioning if they&#x27;re needed) is totally on us.GDPR did give us the tools and the means, we just don&#x27;t take full advantage of them. reply xvector 12 hours agorootparentprevMandated USB-C disincentives ever improving on the connector. The EU attempted to enforce a similar mandate for micro-USB back in the day - can you imagine if they succeeded? Fortunately, we got Lightning and USB-C thereafter, but improvement is always possible.Product design doesn&#x27;t need to be written into law. reply dzikimarian 10 hours agorootparent>Mandated USB-C disincentives ever improving on the connector.Please stop repeating that argument, it&#x27;s not true. There&#x27;s periodic review proces built in into this legislation.>attempted to enforce a similar mandate for micro-USB back in the day - can you imagine if they succeeded?That would be great. Probably Apple would transition to the USB-C a few years ago with everyone instead current nonsense. reply ssbash 2 hours agorootparentUSB C was created due to Apple donating the reversible connector technology they created for lightning.If micro usb was enforced, USB C in its current form wouldn’t exist. reply Aerroon 2 hours agorootparentprevI guess power cords and power plugs landed on perfect designs. It&#x27;s weird how there are so many different \"perfect\" power plugs though.A periodic review process won&#x27;t matter. Somebody has to actually research, design and create an alternative. Why would they spend resources on that if their competitors can just decide that they&#x27;re not allowed to use it? reply scarface_74 10 hours agorootparentprevYes just imagine how long that’s going to take… reply dzikimarian 9 hours agorootparentAgain commonly repeated FUD.Lightning originated when there was a talk about mandating micro-USB and finally died, after 11 years, when USB-C was mandated. If not for that legislation it would still be alive.It&#x27;s actually faster that way. reply mardifoufs 2 hours agorootparentNot remotely the same for micro usb. It wasn&#x27;t the same law.Now it will be a chicken and egg problem. No one will want to put a new connector in phones, because they&#x27;d need usb c too anyways. So no new standard will emerge with wide enough industry support. If the micro usb \"mandate\" was as binding and restrictive as this one, we would not have had usb c. reply scarface_74 3 hours agorootparentprevI keep forgetting how dynamic the EU tech industry is and the great companies that have come out of it because of the wisdom of European legislation. replymaxhille 10 hours agoparentprevMobile Roaming is awesome though reply royal_ts 13 hours agoparentprevEuropean Accessibility Act for 2025 is also great reply Xelbair 8 hours agoparentprevEven GDPR turned out to lack teeth and be easily circumvented. Fines are sky high, but i see abuse daily, and no regulatory body cares. reply YetAnotherNick 13 hours agoparentprev> Maybe the only good thing out of the EU is GDPRHow is GDPR any good? All I saw is addition of misleading popups in the sites without any actual improvement to privacy. Has any big tech reduced data collection after GDPR? reply dexwiz 13 hours agorootparentIn my experience there are much more stringent control over logging. Tokenization is the default for anything related to PII or customer data. Log retention rarely goes over 30 days. Data residency is now in the conversation when talking about storage. Maybe smaller companies can fly under the radar, but any larger companies with auditing and compliance controls take it seriously. reply myaccountonhn 5 hours agorootparentprevYou can legally request to have all data they have on you deleted from their website. That&#x27;s fantastic. reply makeitdouble 13 hours agorootparentprev> Has any big tech reduced data collection after GDPR?Any big tech still operating in the EU did. A lot. reply TrickyRick 12 hours agorootparentConsidering they keep racking up fines I seriously doubt it. It&#x27;s become like banking regulation, fines are just a cost of doing business and you just have to factor in the percent chance of getting caught times average size of fine vs revenue.See https:&#x2F;&#x2F;www.enforcementtracker.com reply makeitdouble 12 hours agorootparentBut banking regulation still has an effect on any entity that can&#x27;t afford to be continuously fighting lawsuits and paying fines.And actual changes happens on many of these cases. An entity getting fined three of four times for different offenses doesn&#x27;t mean they never fix any of the issues.An easy example could be Google, who&#x27;ve been a target of so many of these complaints, and made many adjustment, up to building separate data centers with separate management rules to deal with the EU situation. reply xvector 12 hours agorootparentprevThese regulations are so overwrought, complex, and even contradictory, that it is literally impossible to comply with them fully. Hence fines. reply YetAnotherNick 13 hours agorootparentprevAny example or source? All the big tech is still operating in EU and I don&#x27;t know of any reduction in data collection. reply howenterprisey 12 hours agorootparentAre you in a position where you would know firsthand whether big tech data collection is trending up or down, or if not, could you share the research you&#x27;ve done to reach your conclusion? It seems plausible to me that the fines and other penalties have forced changes in how some companies operate, based on the large fines (absolute value, not % of revenue...) that have made the news in the past five-ish years. reply AnthonyMouse 11 hours agorootparentTheir business model is sucking up all your data and using it to target ads. You can tell they&#x27;re still doing it because they&#x27;re not making any less money.No doubt it made them spend a lot of money on lawyers to figure out the best way to keep doing it, but what good is that? reply Moldoteck 8 hours agorootparentWelp, considering rumors that meta is going to introduce a fee for using their apps with opt out ads in eu, maybe they really feel the effects of the law reply AnthonyMouse 31 minutes agorootparentOr they found a loophole because they can just make the fee large enough that almost everyone opts in to the ads. reply YetAnotherNick 12 hours agorootparentprevWhat conclusion? As I said in my message, I don&#x27;t know of any reduction in data collected. I am turning to community who might have some example if there is any instance of that. reply makeitdouble 12 hours agorootparentprevThere has been sweeping changes in log management, data export to outside entities, reliance on third party providers to parse that data and come up with insights etc.Pre-GDPR, you&#x27;d open your logs to any random company promising to come up with something that could remotely help your marketing department. Nowadays, you&#x27;ll have to vet your partners and audit how your data is handled internally. It&#x27;s hard to come up with concrete examples when it&#x27;s basically every single company above a decent size, as they typically don&#x27;t want to work against the law.Same for the retention period, the very type of log that you&#x27;d open for internal harvesting (you could still be collecting the info, but keep it way more confidential to the point no one outside of your SRE team has access to the totality of it)It&#x27;s as if you were asking what changes the PSI and DSS compliance laws had on the card processing field. reply scarface_74 10 hours agoparentprevYou mean the thing that made web browser worse and entrenched the large players who are more easily able to conform to the 11 chapter 99 section monstrosity? reply 2Gkashmiri 14 hours agoprevThis is a joke, right?Edit: I am aware about EU DMA that has working on mls and interoperability but nothing about csam and breaking encryption or sharing with third parties....How will both exist together?Is chat control part of new legislation supposed to undermine DMa? reply Semaphor 13 hours ago[flagged]| parentnext [9 more] > Is chat control part of new legislation supposed to undermine DMa?Ursula von der Leyen has a long history of instrumenting children and CSAM to get more control. She did the same in Germany, she’s an utterly despicable person. reply barbazoo 12 hours agorootparentMy bet is she&#x27;s ignorant and&#x2F;or incompetent but not \"evil\" in the way you imply. reply Semaphor 12 hours agorootparentBack when she tried her censorship thing in Germany, people openly (this was all through the news and done by child abuse survivors, so it’s not as if she had no clue) showed her how easy it was to get CSAM removed, yet she refused to entertain even a \"best effort\" to get it deleted and kept saying it’s impossible to remove, only concentrating on building up a censorship infrastructure.That said, she has generally been pretty incompetent in every role, but keeps falling upwards. reply stephen_g 12 hours agorootparentprevEvil might be too strong a word, but when we have seen such a pattern of behaviour, I think we&#x27;re well past the point where we can assume ignorance and incompetence in the case of von der Leyen.(That&#x27;s not to say she&#x27;s not ignorant and incompetent in many ways, because she clearly is, but I&#x27;m talking about the root of these specific behaviours, which seems pretty clearly intentional at this point). reply AnthonyMouse 12 hours agorootparentprevIt isn&#x27;t rare in politics for a politician to be opportunistic rather than incompetent.If they tell you they want to invade your privacy over internet casinos and copyright infringement, you tell them to pound sand. If they claim it&#x27;s to arrest pedos then you tell them to pound sand and they accuse you of being a pedo. Then you have to accuse them of being a Nazi and reasoned debate is at a close and it becomes a popularity contest, which is the only way the people with no capacity for reasoned debate can win.That seems pretty evil. reply anonzzzies 12 hours agorootparentprevHanlon’s razor indeed. I believe that even some of the more historically famous evil political leaders started out that way. reply nceqs3 13 hours ago[flagged]| rootparentprevnext [3 more] Imagine thinking stopping the horrors of child sexual abuse makes you an evil person. Perhaps you are projecting. reply dang 12 hours agorootparentCould you please stop posting unsubstantive comments and flamebait? You&#x27;ve unfortunately been doing it repeatedly. It&#x27;s not what this site is for, and destroys what it is for.If you wouldn&#x27;t mind reviewing https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html and taking the intended spirit of the site more to heart, we&#x27;d be grateful.Edit: it looks like you&#x27;ve been breaking the site guidelines quite badly on a regular basis—for example:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37733548https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37718945 (Sept 2023)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37100652 (Aug 2023)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36975625 (Aug 2023)This kind of thing destroys what the site is for, so if it keeps up, we&#x27;re going to have to ban you. If you&#x27;d please stick to the guidelines from now on, that would be good. Among other things, that means no personal attacks, putdowns, or snark. reply Semaphor 13 hours agorootparentprevedit: Nevermind, saw what kind of comments you post, not engaging with trolls. reply codetrotter 14 hours agoparentprevOn whose part? EU? Or the protestors? If the latter, why? Because of the emojis? reply Affric 13 hours agorootparentIt’s like it’s repeating itself or using too many punctuation marks. Emoji are meant to be the informal and succinct. The emoji don’t make it briefer.With that said the message is very serious. And serious isn’t disjunct to formal.I think highlighting the difference between the people (real warm) and the bureaucracy (operated by people who are taught to turn off their empathy to serve the system) is worthwhile and has been proven effective in populist campaigns of late.All in all it’s interesting political communication. reply 2Gkashmiri 12 hours agorootparentWhat&#x27;s.... The proboe with emojis now? reply imchillyb 14 hours agoparentprevThis legislation is not a joke at all.> https:&#x2F;&#x2F;www.patrick-breyer.de&#x2F;en&#x2F;posts&#x2F;chat-control&#x2F;> Currently a regulation is in place allowing providers to scan communications voluntarily (so-called “Chat Control 1.0”). So far only some unencrypted US communications services such as GMail, Facebook&#x2F;Instagram Messenger, Skype, Snapchat, iCloud email and X-Box apply chat control voluntarily (more details here). As a result of the mandatory Chat Control 2.0 proposal, the Commission expects a 3.5-fold increase in scanning reports (by 354%).> https:&#x2F;&#x2F;eur-lex.europa.eu&#x2F;legal-content&#x2F;EN&#x2F;TXT&#x2F;?uri=COM%3A20... reply stavros 14 hours agoparentprevIt doesn&#x27;t look like a joke. reply brigandish 14 hours agoparentprevWhat makes you think that? reply polski-g 13 hours agoprev [–] It seems like most of these problems can be alleviated by two actions:1) don&#x27;t have servers in Europe2) don&#x27;t hire EuropeansIf Europe wants to regulate themselves into the stone age, they should be free to do it. reply makeitdouble 13 hours agoparentI don&#x27;t know how serious this take is or if it&#x27;s more emotional than not.This is probably the same reaction regulators have around the world, where they&#x27;d prefer to have their own walled garden where they apply their own rules and don&#x27;t need to talk to anyone else. Except when there&#x27;s lot of money down the line, then they&#x27;ll do an effort and make exceptions.That&#x27;s how many US services reacted to GDPR. That&#x27;s how many Japanese services reacted to VISA&#x2F;Mastercard ban on sexual content. That&#x27;s how China is reacting to many things. I think we&#x27;ll see more and more example of it down the line.On one side, balkanization can probably help to get more diversity and allow local content to thrive with less competition. On the other side, it&#x27;s basically reversing decades of cultural evolution that happened on the net, which I personally think sucks a lot. reply Analemma_ 13 hours agorootparent> the same reaction regulators have around the world, where they&#x27;d prefer to have their own walled garden where they apply their own rules and don&#x27;t need to talk to anyone elseI don&#x27;t like the trend of balkanization, but I have to say that this is kind of suffering from a lack of perspective. What you call \"their own walled garden\" a lot of people call \"national sovereignty\", especially people who dislike the fact that the \"unregulated\" internet was actually regulated by the United States for all intents and purposes, and so \"lack of regulation\" was equivalent to letting the US run a critical piece of their national infrastructure. It should be understandable that people kinda didn&#x27;t like that. reply makeitdouble 12 hours agorootparentYou&#x27;re right that it comes down to national sovereignty. I&#x27;ll show my bias: I don&#x27;t think a complete lack of sovereignty is viable nor desirable. Completely erasing cultures and local specificities won&#x27;t help, and I agree there is way too much US centralized critical infrastructure.But I prefered a kind of status quo where the big players are in a standstill and can&#x27;t make bold moves that could destabilize the whole board. Basically the state where the US couldn&#x27;t abuse too much their position in fear of the other entities calling it quit, and the other entities couldn&#x27;t completely close their borders in fear of losing too much as they retreat.In recent years we&#x27;ve seen more and more moral&#x2F;cultural rules getting applied to critical infra (payment, communications etc.), and I guess we&#x27;re not getting that standstill back anytime soon. That also means we&#x27;re back to black market style communication, as it was in the earlier decades, when we were looking for a common ground less constrained by national limitations. reply AnthonyMouse 12 hours agorootparent> In recent years we&#x27;ve seen more and more moral&#x2F;cultural rules getting applied to critical infra (payment, communications etc.), and I guess we&#x27;re not getting that standstill back anytime soon.This really depends on what the response to that is. People tolerated centralized chokepoints because they were neutral. That was why they historically feared doing otherwise -- it would give people an incentive to disintermediate them.So now people are going to try to disintermediate them. Question is how long it takes to happen. reply marcus_holmes 13 hours agoparentprevI don&#x27;t think that&#x27;s a valid proposition for most international businesses. Europe is too big a market for this. reply jdminhbg 12 hours agorootparentIt seems like it depends. If it&#x27;s just paying fines, like where the EU uses US tech companies as a piggy bank, you can easily compare your revenue to the cost and decide to stay. It&#x27;s not as much money as it would be otherwise, but with zero-marginal-cost products, it&#x27;s still worth it. On the other hand, where it would completely break your product, like in the case of installing backdoors into E2EE chat applications, it might not be worth it anymore. Google and Meta survive fine without China, for example. reply sol91949 12 hours agorootparentAnd then emerging companies and nations will fill the gap. This may benefit everyone except pre-existing hegemons, suffice to say it’s not in a monopolists interest to allow any other significant marketplace to be dominated by another. This is why we the strategy of isolating China rather than competing directly may backfire. Also why China protecting it’s own internal market is net beneficial for the world in aggregate, whilst perhaps not good for dominant powers (hence the geopolitical u-turn from China good to China bad) reply donatj 13 hours agorootparentprevTheir value is largely overstated. Most of continental Europe has very little actual disposable income.https:&#x2F;&#x2F;www.reddit.com&#x2F;media?url=https%3A%2F%2Fi.redd.it%2Fz... reply chmod775 11 hours agorootparentDisposable income is extremely pointless to compare if you want to figure out how much people will have left to pay for your product. Look at actual spending in whichever category you&#x27;re interested in.To illustrate, let&#x27;s subtract some spending categories from that disposable income which tech companies generally don&#x27;t compete for: Germans spend $13713 + $1604 on housing&#x2F;lodging vs $22624 for Americans, education $255 vs $1226, food $5706 vs $8289, health $1632 vs $5452.So comparatively Americans are already down $14681 of that disposable income, which definitely won&#x27;t be spent on whatever some American tech darling produces - food, housing, education, and health spending is generally considered more important than getting a Meta Quest headset. At the end of the day US&#x2F;Germany spend the same amount of money on entertainment&#x2F;recreation almost to the dollar. France is similar in that regard and together Germany and France are already a market of close to 150 million people.Numbers are from 2021 using the historic EUR&#x2F;USD exchange rates.The point is: drill down to some category and compare actual spending in it. You&#x27;ll be surprised how wildly some things vary even between countries that nominally have the same disposable income.US Data: https:&#x2F;&#x2F;www.bls.gov&#x2F;news.release&#x2F;cesan.nr0.htmGerman Data: https:&#x2F;&#x2F;www.destatis.de&#x2F;DE&#x2F;Themen&#x2F;Gesellschaft-Umwelt&#x2F;Einkom... reply AnnikaL 13 hours agorootparentprevWestern Europe seems to hover around $20,000 to $30,000 in disposable income, which seems like quite a bit. Certainly it&#x27;s more than Eastern Europe and Asia have, even if it&#x27;s less than parts of North America and Oceania. reply bee_rider 13 hours agorootparentprevIt looks like they have more disposable income that every country other than the United States. reply crossroadsguy 12 hours agoparentprevAnd alienate an entire continent, where, people are much more likely to fight against such shit and support you? reply janosdebugs 10 hours agoparentprev [–] 3) Don&#x27;t have paying customers in the EU.4) Get a good lawyer who is well versed in international jurisdiction issues to avoid getting dragged to an EU court anyway. Possibly operate from a non-extradition country. reply Moldoteck 8 hours agorootparentThere&#x27;s a reason cookie prompts aren&#x27;t just in eu, afaik(maybe wrong) the law will cover even eu citizens outside of eu so idk, even if you geoblock the eu you may still have problems) reply cccbbbaaa 7 hours agorootparentYou are wrong, cf. GDPR article 3. The Belgian DPA even ruled that GDPR is unenforceable if the controller is not located in EEA, does not serve anyone in EEA, and does not monitor EU individuals. https:&#x2F;&#x2F;gdprhub.eu&#x2F;index.php?title=APD&#x2F;GBA_(Belgium)_-_161&#x2F;2... reply cccbbbaaa 7 hours agorootparentprev [–] Stop with the FUD. GDPR is not enforceable if you respect 1-3. https:&#x2F;&#x2F;gdprhub.eu&#x2F;index.php?title=APD&#x2F;GBA_(Belgium)_-_161&#x2F;2... replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The initiative seeks to halt the European Commission's implementation of \"chat control,\" aimed at curbing child abuse and grooming, arguing it violates fundamental rights and privacy.",
      "The initiative claims chat control generates false results, strains authorities which might hinder investigation achievements, infringes on the Charter of Fundamental Rights, and damages encryption infrastructure.",
      "They propose other means for child protection, encourage reaching out to local MEPs to express disagreement, provide AI-generated email templates for effective communication, and promote signing a petition to apply more pressure on lawmakers."
    ],
    "commentSummary": [
      "The debate focuses on technology regulation and control within the EU, entailing topics such as surveillance technology effectiveness and limitations, and the influence of regulations on data collection and privacy.",
      "The post also mentions internet balkanization and the potential repercussions of cultural and moral norms being incorporated into critical infrastructure.",
      "The consensus is a need for better regulation and a more profound understanding of issues associated with technology."
    ],
    "points": 183,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1696894293
  },
  {
    "id": 37829551,
    "title": "Simulation Islands",
    "originLink": "https://box2d.org/posts/2023/10/simulation-islands/",
    "originBody": "About Documentation Posts Publications Oct 8, 2023 Simulation Islands Island management is a fundamental low level feature of physics engines and can have a big impact on solver design and performance. This was one of the first problems I decided to work on for Box2D version 3 (v3). Since I began working on v3 I've been comparing several algorithms for island management. My goal has been to make island building scale better with multiple CPU cores. Here are the three approaches I've considered: Depth-first search (DFS) Parallel union-find Persistent islands Let's dive in! What are islands? You can view a rigid body simulation as a graph where bodies are nodes and constraints are edges. Constraints consist of contacts (shapes touching) and joints (hinges, sliders, etc). From the graph point of view contacts and joints are the same. In graph theory islands are called connected components. In rigid body simulation static bodies are not part of the graph. For example, this image shows three islands. Islands Static bodies are not part of the island graph because they can be shared among multiple islands. They need to shared because in a video game lots of bodies will be touching the static ground. Without sharing the static bodies among multiple islands there will be far fewer islands. Islands then lose their value. Islands are not required for correctness. They are an optimization (as we shall see) and they only work well as an optimization if there are many islands. Static bodies can be shared because nothing in the simulation affects their position or velocity. Sharing static bodies among multiple islands requires a little bit of care in the algorithms, but this is straight forward and for simplicity I will not include such logic in my examples. In practice an island is a data structure that keeps track of a set of bodies and a set of constraints. This is the island data structure in Box2D v2.4: class b2Island { b2Body** bodies; b2Contact** contacts; b2Joint** joints; int bodyCount; int contactCount; int jointCount; }; The island uses arrays of pointers because the island does not own the bodies or constraints. An island is a subset of the simulation world. Users of Box2D don't interact with islands. They are an implementation detail of the solver. Box2D v2.4 does not retain islands across time steps, so there is no way to access them. Sleeping and waking Islands are very useful in game physics. The most important aspect is sleeping. Sleeping rigid bodies are removed from the solver and this drastically reduces their CPU load. The engine checks islands during simulation for low energy. If all bodies in an island have low energy for several time steps, then all the bodies in the island are flagged as sleeping and no longer added to the active simulation. The Box2D debug display shows sleeping bodies as gray. Sleeping must be done per island, not per body. I made this mistake early in my work on game physics. If you put a body to sleep but not the whole island then you will see shapes begin to overlap and joints begin to dislodge. Sleep has a flip side as well: waking. Bodies wake other sleeping bodies through constraints and this must propagate through all touching bodies immediately. Otherwise you get those nasty overlapping shapes and dislodged joints. Islands are just as important for waking as for sleeping. Parallel islands Islands work well for multicore simulation. Game worlds often have many separate islands of bodies. A ragdoll over here. A pile of debris over there. This relates to the concept of spatial coherence as described by Gino van den Bergen in his book Collision Detection in Interactive 3D Environments. Spatial conherence says that rigid bodies tend to spread out and we can take advantage of this to improve performance and lower memory usage. An island can be simulated indepedently from other islands. Therefore an island can be simulated on a thread and you can send multiple islands to multiple threads using a task system such as enkiTS. This scales very well with CPU core count as long as there are a sufficient number of islands. This is also cache efficient because the core is doing significant work on a subset of the simulation world. Parallel islands simulation is not a silver bullet. There may not be enough islands to span all the CPU cores. In some games there may be a large pile or tower of rigid bodies that are in a single island. This large single island can dominate performance even with multithreading. It can lead to a situation where many cores are sitting idle. I plan to discuss large islands in a future post. Large Island Depth-first search Box2D v2.4 uses depth-first search DFS to build islands from scratch every time step. Version 2.4 does not have multithreading support, so islands are only used for sleeping and waking. The SolveIslands function takes all the bodies and constraints of the simulation world and finds their simulation islands. Before finding the islands, it clears a mark (visitation flag) on every body and constraint. These marks ensure that a body or constraint is only added to a single island. The algorithm has a simulation island G that is reused for each island found. The island finder loops over all bodies and looks for awake dynamic bodies to be the seed for the island. Starting from the seed, connected bodies and constraints are added to G. Once all the connected bodies have been traversed the island G is simulated, updating the constraint forces and the body velocities and positions. Then the algorithm continues looking for the next seed body that hasn't already been simulated in the current time step. function SolveIslands(bodies, constraints) ClearMarks(bodies) ClearMarks(constraints) let G be an island for seed in bodies if seed not marked and seed is dynamic and seed is awake Clear(G) Mark(seed) let S be a stack S.Push(seed) while S not empty b = S.Pop() G.Add(b) for c in b.GetConstraints() if c not marked G.Add(c) Mark(c) other = OtherBody(c) if other not marked S.Push(other) G.Simulate() DFS has linear time complexity in the number of bodies. It can be made faster by only using awake bodies as seeds. This can be done by keeping an array of awake dynamic bodies. Traversal mark management can also be expensive. At the cost of more memory, each body and constraint can hold a time step counter. The DFS can then compare a body's time step counter with the current time step count of the physics world. Marking a body or constraint is done by setting the local time step counter equal to the world time step count. The DFS naturally wakes bodies. When a body is added to an island it is flagged as awake. A body can only be flagged as sleeping with another routine called IslandSleep. Part of island simulation is checking for sleeping. Every body has velocity and a sleep timer. If the velocity is greater than a velocity threshold then sleep timer is reset. Otherwise it is advanced by the time step. If the minimum sleep timer of all bodies in an island is greater than a time to sleep threshold then the entire island is marked as sleeping. function IslandSleep(islandBodies, timeStep) minSleepTime = MAX_FLOAT for b in islandBodies if b velocity > velocityThreshold b.sleepTime = 0 minSleepTime = 0 else b.sleepTime += timeStep minSleepTime = Min(minSleepTime, b.sleepTime) if minSleepTime > timeToSleep for b in islandBodies MarkSleeping(b) Then the next time step no collisions between sleeping bodies are updated and sleeping bodies are not added to simulation islands unless an awake body begins interacting with a sleeping body. This is a huge win for performance in large game worlds. Watch this video if you want more details on DFS: Union-find Union-find (UF) is a competitor to DFS for game physics island simulation. This algorithm is also called a Disjoint-set data structure. UF focuses on merging sets (islands). Each dynamic body starts alone in its own set. As constraints are added to the world the sets are merged. Within each set a single body is considered the root body and uniquely identifies the set. After all constraints have been added the union-find is complete. This video series explains union-find very well: https://youtube.com/playlist?list=PLDV1Zeh2NRsBI1C-mR6ZhHTyfoEJWlxvq&si=brluQ5CldgIXFMhv. If you are not familiar with union-find and/or path compression, please go watch this and come back. Like DFS, union-find (with path compression) has linear time complexity for building islands. Union-find can be a drop-in replacement for DFS. However, some additional care must be used to ensure that all touching bodies are woke up. The Amdahl problem DFS and UF are fast but they are not parallel algorithms. So when I began multithreading Box2D I started to get timing results like this: This is Amdahl's law in action. Multi-core scaling is limited by single-threaded processing. You will also notice a single-threaded broadphase section which I'll discuss in a future post. Parallel union-find At the GDC 2022, Jorrit Rouwe introduced a parallel union-find algorithm. The slides are here. You can also find an implementation in Jolt Physics. I implemented this algorithm in Box2D v3. In the process I learned a lot about using atomics and lock-free algorithms. If you want to learn more about atomics and the C/C++ memory model, I highly recommend this two-part video by Herb Sutter: The first challenge I faced was making the algorithm recursive so that it would wake entire islands in one time step. I needed to add some additional iteration to ensure that all touching bodies are woken up. After fumbling with atomics a bit, I got something working. However, I quickly ran into a problem and did a lot of head scratching trying to figure out the problem. Fortunately I still have plenty of hair. Parallel union-find uses atomic compare-and-swap (CAS) when merging islands. This means the order of constraints in the resulting islands is non-deterministic. The final order depends on which core happens to be faster at completing the CAS. This can change dramatically across time steps and repeated runs of the application. This is a serious problem for the solver used in game physics because the constraints are solved one at a time, sequentially. The results from each constraint propagate to the next constraint. This contraint solver algorithm is formally called the Gauss-Seidel method. The problem is magnified because Box2D uses warm starting for contacts, which gets confused when the contraint order varies each time step. You can read more about Gauss-Seidel and warm starting here. The constraints can be sorted after union-find and they can be sorted for each island independently. However, I could not find a faster way to do this than by using quicksort which is O(n log n). For large islands this added cost is significant, even when sorting a minimal index array. This video shows the effect of a parallel union-find and the resulting non-deterministic constraint order. The serial DFS and UF do not have this problem. They generate constraints in a deterministic order. The loss of determinism is due to multithreading and the use of atomic CAS. If you want to learn more about determinism and multithreading, I recommend this video: What's next? After implementing the parallel union-find I took a step back and reconsidered my options and tried to look at the big picture. First, I decided that I did not want to sacrifice determinism. As a programmer I value predictability in the software I write. Determinism affects my ability to debug and any Box2D user's ability to debug. I'm willing to give up performance for my software to be debuggable. Second, Amdahl says that the serial part of a program dominates scaling. However, having a very fast serial part might be okay. Not every algorithm needs to be parallel if it is fast enough. So maybe I can find something faster than DFS or serial UF. Third, Gino also describes temporal coherence in his book. Temporal coherence says the configuration of rigid bodies in a simulation does not change much across a single time step. How often do islands change? I suspect islands change slowly. Fourth, maybe the cost of islands can be spread out in other ways. For example, it is urgent that islands are merged within the current time step. This is necessary to wake islands immediately. On the other hand it is not urgent to put islands to sleep or to split islands when bodies stop interacting. Delayed sleep is a minor performance loss. Persistent islands The points above led to me investigate persistent islands. Persistent islands are retained across time steps. They need to support adding and removing bodies and contraints incrementally. When a dynamic body is created it also creates a new island: an island of a single body. Static bodies do not get islands. When a constraint between two dynamic bodies is created the two associated islands are merged. It may be the case that the bodies are already in the same island and this is an early out in the island merger. When a dynamic body is destroyed it is removed from its island. If that island is now empty then the island is also destroyed. When a constraint is destroyed then it is removed from the island. The island becomes a candidate for splitting. I need to merge persistent islands immediately. This is necessary to ensure that all bodies that should be awake are added to the active simulation. Persistent island splitting can be deferred. I can put a quota on island splitting. For example, one island per time step can split. Maybe I can choose to split the largest island first. Or maybe I can choose to split the island with the most constraints removed. Some heuristic can be used. I suspect any reasonable heuristic is fine. I modified the v2.4 island structure to support adding and removing bodies and constraints quickly using linked lists. This also makes it fast to merge islands. Linked lists are slow to traverse because of cache misses, but I suspect I will not need to traverse them often. I also added a flag maySplit to indicate that the island has had contacts or joints removed and it may be possible to split the island into two or more islands. struct b2Island {int index;int parentIsland;int headBody;int tailBody;int headContact;int tailContact;int headJoint;int tailJoint;bool maySplit; }; If I have an existing set of islands I can add an edge and this may lead to two islands merging. Island merging should be fast and it has to be deterministic. I decided to stick with serial union-find for merging islands. Here is the code for adding a contact constraint. Joints are similar. I abbreviated the code a bit and left out path compression. You can see the full version here. Notice that islands are flagged as awake when they are merged. void b2LinkContact(b2Island* islands, b2Body* bodyA, b2Body* bodyB, b2Contact* contact) {int islandIndexA = bodyA->islandIndex;int islandIndexB = bodyB->islandIndex;if (islandIndexA == islandIndexB){ // bodyA and bodyB are already in the same island b2AddContactToIsland(&islands[islandIndexA], contact); return;}// Find root of islandAb2Island* rootA = &islands[islandIndexA];b2WakeIsland(rootA); while (rootA->parentIsland != B2_NULL_INDEX) { rootA = &islands[rootA->parentIsland]; b2WakeIsland(rootA); }// Find root of islandBb2Island* rootB = &islands[islandIndexB];b2WakeIsland(rootB); while (rootB->parentIsland != B2_NULL_INDEX) { rootB = &islands[rootB->parentIsland]; b2WakeIsland(rootB); }// Make islandB a child of islandAif (rootA != rootB){ rootB->parentIsland = rootA->index;}b2AddContactToIsland(rootA, contact); } Removing a contact from an island involves linked list bookkeeping and flagging the island for spitting (maySplit). Union-find is not involved. Once all the new constraints have been added to all islands, there is a serial merge step. Here is an abbreviated version of the code. The full version is here. The function b2MergeIslandWithParent is just some boring bookkeeping code. Note that b2DestroyIsland invalidates the current island, so tread carefully. void b2MergeIslands(b2Island* islands, int count) {// Step 1: ensure every child island points directly to its root islandfor (int i = 0; i parentIsland != B2_NULL_INDEX) {rootIsland = &islands[rootIsland->parentIsland]; } if (rootIsland != island) {island->parentIsland = rootIsland->index; }}// Step 2: merge every awake island into its parentfor (int i = 0; i parentIsland != B2_NULL_INDEX) { b2MergeIslandWithParent(island); b2DestroyIsland(island); } } } These code snippets show that union-find builds multiple island trees then collapses each island tree into its root island. With persistence this process can occur incrementally as shapes come into contact. Island splitting I handle island splitting by taking an island and using all of its bodies as seeds for the DFS algorithm. This could be done with union-find as well. Any island finding algorithm will do. I'm not really splitting the island, I just building new islands from the original island. Because the island is guaranteed not to connect to other islands, the depth-first traversal is guaranteed to stay within the original island. This is critical to allow the original island to be split concurrently with other work. Here is the pseudo-code for island splitting. It is very similar to the DFS algorithm above. Instead of dealing with all the bodies and constraints in the entire simulation world, it is limited to the bodies and constraints of a single island. After a new island is built, it is added to the world as a new persistent islands. After the island is split the original island is destroyed. This is fine because nothing should refer to the original island at this point. function SplitIsland(world, island) bodies = GetIslandBodies(island) constraints = GetIslandConstraints(island) ClearMarks(bodies) ClearMarks(constraints) let G be an island for seed in bodies if seed not marked and seed is dynamic and seed is awake Clear(G) Mark(seed) let S be a stack S.Push(seed) while S not empty b = S.Pop() G.Add(b) for c in b.GetConstraints() if c not marked G.Add(c) Mark(c) other = OtherBody(c) if other not marked S.Push(other) world.AddIsland(G) world.DestroyIsland(island) The result of splitting the island is one or more new islands. It is a little sad if only one new island results, but it would be the correct result. Removing a constraint may or may not cause and island to split into two islands. Determining whether an island will split or not is similar to the work of doing the DFS, so I might as well optimistically attempt to split the island. Making persistent islands fast While working on parallel union-find I learned that the narrow-phase can drive island management. The narrow-phase is the simulation stage where contact points are computed between colliding shapes. The contact pairs that manage potentially colliding shapes are persisted across time steps. Each contact pair holds the current contact points. The number of contact points is 0, 1, or 2. If the number of contact points changes from zero to non-zero or vice-versa then there is an edge that should be added or removed from the island graph. Scalability requires the narrow-phase to be executed in parallel. This is a naturally parallel algorithm because the contact points between one shape pair are not affected by other shape pairs. This is the easiest part of a physics engine to spread across multiple cores. Like butter on bread. When a contact pair is updated there are three outcomes relevant to persistent islands: edge added edge removed unchanged The gambit is that most pairs fall in the third camp in a typical game scenario. This seems to be the case so far in my testing. Edge additions need to be processed right away, before the islands are solved. I handle this with serial union-find as described above. Edge removals are less urgent. The contact constraint needs to be removed right away, but the island doesn't need to be split. Removing and edge doesn't mean the island will split. There may be other edges holding the island together. However, the island might split. So I flag the island as potentially splitting. I can defer island splitting to later. For example, I can split an island after it has been solved, in the same task. This works because island A doesn't care if island B is split. Island A only cares if island B wants to merge with it. And merging is handled serially. How about determinism? Determinism is maintained if the edge additions and removals are processed in deterministic order. It turns out in Box2D that the order of contact pairs in the world is deterministic, so I just need to process the edge changes according to the order of the contact pairs. However, there can be a huge number of contact pairs and looping over all the pairs serially looking for changes is going to be very slow. There is one data structure that can have an large number of entries and still be fast to iterate across. The bit array! Modern CPUs help us do this quickly with bit scanning intrinsics. See this and this. The bit array can also work well with multithreading. Each narrow-phase worker can access a thread context that holds a local bit array. When the contact pair has an edge add or remove outcome, it flips a bit in the thread context bit array. Then after the narrow phase is complete, the main thread can bit-wise OR all the bit arrays together. This is quite fast using a bit array built on 64-bit words. And no atomics are needed. Putting this all together I have the program flow shown below. This example has three threads in the narrow phase. Each thread gets its own bit array which is initially all zeros. When a contact pair is processed it checks if the number of contact points went from 0 to non-zero or vice-versa. In either case it sets the thread's bit array at the index associated with the contact pair. After all contact pairs are processed the bits from each thread are combined into a global bit array using bit-wise OR. Then a loop iterates over the global bit array looking for set bits. If a set bit is found, the code looks up the contact pair and determines if an edge should be added or removed from the island graph and then does that work. These additions and removals are done serially in the main thread. This retains a deterministic constraint order. Persistent island program flow In practice the number of set bits is very small. Bit traversal is very fast, even for a large number of contact pairs. Results And performance? Performance is good. Gino was right! This image shows a typical timing result. The blue bars are the contact pairs and the yellow bars are the island constraint solvers. The gap in between is the serial island management. The gap also includes island solver preparation and task system overhead. Let's look at some benchmarks. The first test is 182 pyramids with a base of 10 boxes, so 55 bodies each and a total of 10010 bodies. These pyramids are not moving and so this test favors persistent islands. The tumbler test has 2000 boxes inside a hollow box that is constantly rotating on a revolute joint. This test should be difficult for persistent islands because constraints are constantly being added and removed. The darker boxes are colored that way because Box2D considers them fast enough to engage continuous collision checks. Here are the results for the two tests. Times are in milliseconds. The first time value is the average and the value in parentheses is the maximum. For DFS I'm using commit #32 of Box2D v3. For persistent islands I'm using commit #36. For persistent islands there can be many frames in a row where the island management has no work, making it tricky to benchmark. Persistent islands are strangly fast. I had to verify the code was working a few times. Indeed it is doing real work as I have tested island merging and splitting as well as sleeping and waking. Take the maximums with a grain of salt. They could be due to anything. I include them because the persistent island has a heavier load when the bodies are created and this is relevant to avoid frame rate dips. Test DFS Persistent pyramids 0.69 (0.98) 0.01 (0.45) tumbler 0.43 (0.87) 0.08 (0.43) Persistent islands are roughly an order of magnitude faster than DFS. What about splitting? The current implementation uses DFS to split at most one island per time step. My current heuristic is to split the largest island that has had one or more constraints removed. Island splitting isn't free but it is usually easy to hide the cost. I have experimented with putting the island splitting at the end of an island solve task. When there are many islands and multiple cores then this time is almost completely hidden and insignificant, amounting to a few microseconds on a single core. If there are a small number of large islands then the cost of splitting can be significant. Nevertheless, island splitting can be done in parallel with other work and this is a significant gain over the traditional serial DFS/UF. Summary I covered a lot of material in this post and there are a lot of references and auxilliary knowledge. Simulation islands touch a lot of systems, so it is challenging to fully understand islands without understanding how a physics engine is put together. Hopefully I've provided enough background knowledge so you can understand the scope of island mangement. If not, please let me know! These are the main takeaways I have learned or reinforced while working on islands: island management can become a bottleneck in multicore simulation determinism is important for game physics spatial and temporal coherence provide many opportunities for improving performance sometimes a fast serial algorithm may be better than a parallel algorithm bit arrays are awesome! What's next? At the end of this journey I have many tools to work with islands. This will help me as I explore other aspects of improving Box2D. There is more work to do on Box2D and more to write up. I plan to post more in the future on broad-phase improvements and dealing with large islands. Stay tuned! 4378 words 2023-10-07 17:00 -0700 © 2023 Erin Catto",
    "commentLink": "https://news.ycombinator.com/item?id=37829551",
    "commentBody": "Simulation IslandsHacker NewspastloginSimulation Islands (box2d.org) 182 points by AshleysBrain 8 hours ago| hidepastfavorite8 comments ghusbands 0 minutes agoWhy are the boxes always made of jelly in these physics simulations? Stacks&#x2F;walls of boxes in real life are never that jiggly. reply hesdeadjim 2 hours agoprevGiven how widespread the usage of Box2D has been over the last decade+, I truly hope the creator has seen some form of financial benefit from it. His work is awesome and has benefitted the gamedev community immensely.He mentions Jolt physics in this blog. That’s another example of “holy shit look at what one person can do”. I’ve found myself wishing I had Unity source so I could performantly inject that engine instead of being stuck with PhysX. reply foota 7 hours agoprevThis left me wondering if there might be a deterministic parallel algorithm for union find :)I did find this arxiv paper from April which claims to have one: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.09331My understanding is that they process batches of edges at a time. If they \"conflict\" (meaning they want to do different things to the data structure) then they&#x27;re processed in serial, otherwise all edges in the batch are handled sequentially. They provide a bound on how often edges should conflict, and use that to show the complexity. reply loa_in_ 7 hours agoprevSoftware engineering at it&#x27;s best. And surprisingly nicely written up.One of my favourite reads! Would read again. reply faldore 7 hours agoprevIt&#x27;s lovely to see active development on Box2D. Thank you for your efforts. reply picadores 2 hours agoprevAka causality limitations through propagationspeed -aka lightspeed. reply SeanAnderson 30 minutes agoparent:) This was the same conclusion I came to when I first started researching this in video game design. No idea if there&#x27;s actual merit to it, but the parallels are uncanny to be sure. reply mortallywounded 4 hours agoprev [–] I haven&#x27;t seen or heard of box2d in years.... awesome to see again :) replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This article underlines the significance of island management within physics engines, particularly focusing on Box2D.",
      "The post compares various methods and accentuates the advantages of using persistent islands.",
      "It also explores the issues in executing parallel algorithms and shares the author's intention to enhance Box2D, stressing the vitality of determinism and performance in physics simulations."
    ],
    "commentSummary": [
      "The conversation is centered around Box2D, a widely utilized physics simulation engine in the gaming development sphere.",
      "Some users appreciate the creator's hard work on Box2D and hope for financial gain for the creator, and Jolt physics is mentioned as another admirable independent project.",
      "There is also discussion on a deterministic parallel algorithm for union find and limitations of causality through propagation speed, emphasizing the active development and excitement about Box2D's resurgence."
    ],
    "points": 166,
    "commentCount": 6,
    "retryCount": 0,
    "time": 1696924558
  },
  {
    "id": 37823543,
    "title": "LLMs can't self-correct in reasoning tasks, DeepMind study finds",
    "originLink": "https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/",
    "originBody": "Home Blog Tips & Tricks What is Interviews Reviews About About TechTalks About Ben Dickson Write for TechTalks TechTalks HOME BLOG TIPS & TRICKS WHAT IS INTERVIEWS REVIEWS ABOUT Home Blog LLMs can’t self-correct in reasoning tasks, DeepMind study finds Blog LLMs can’t self-correct in reasoning tasks, DeepMind study finds By Ben Dickson - October 9, 2023 Facebook Twitter ReddIt Linkedin Image generated with Bing Image Creator This article is part of our coverage of the latest in AI research. Scientists are inventing various strategies to enhance the accuracy and reasoning abilities of large language models (LLM) such as retrieval augmentation and chain-of-thought reasoning. Among these, “self-correction”—a technique where an LLM refines its own responses—has gained significant traction, demonstrating efficacy across numerous applications. However, the mechanics behind its success remain elusive. A recent study conducted by Google DeepMind in collaboration with the University of Illinois at Urbana-Champaign reveals that LLMs often falter when self-correcting their responses without external feedback. In fact, the study suggests that self-correction can sometimes impair the performance of these models, challenging the prevailing understanding of this popular technique. What is self-correction? Self-correction is predicated on the idea that LLMs can assess the accuracy of their outputs and refine their responses. For instance, an LLM might initially fail a math problem but correct its answer after reviewing its own output and reasoning. Several studies have observed this process, also known as “self-critique,” “self-refine,” or “self-improve.” However, the effectiveness of self-correction is not universal across all tasks. The paper from DeepMind and University of Illinois reveals that the success of self-correction is largely contingent on the nature of the task at hand. In reasoning tasks, self-correction techniques typically succeed only when they can leverage external sources, such as human feedback, an external tool like a calculator or code executor, or a knowledge base. The researchers underscore the fact that high-quality feedback is not always accessible in many applications. This makes it crucial to understand the inherent capabilities of LLMs and to discern how much of the self-correction can be attributed to the model’s internal knowledge. They introduce the concept of “intrinsic self-correction,” which refers to a scenario where the model attempts to correct its initial responses based solely on its built-in capabilities, without any external feedback. Different LLM self-correction techniques (source: GitHub) Testing self-correction on reasoning tasks The researchers put self-correction to the test on several benchmarks that measure model performance in solving math word problems, answering multiple-choice questions, and tackling question-answering problems that require reasoning. They employed a three-step process for self-correction. First, they prompt the model for an answer. Next, they prompt it to review its previous response. Finally, they prompt it a third time to answer the original question based on its self-generated feedback. Their findings reveal that self-correction works effectively when the models have access to the ground-truth labels included in the benchmark datasets. This is because the algorithm can accurately determine when to halt the reasoning process and avoid changing the answer when it is already correct. As the researchers state, “These results use ground-truth labels to prevent the model from altering a correct answer to an incorrect one. However, determining how to prevent such mischanges is, in fact, the key to ensuring the success of self-correction.” However, this assumption does not reflect real-world scenarios, where access to the ground truth is not always available. If the ground truth were readily accessible, there would be no need to employ a machine learning model to predict it. The researchers demonstrate that when they remove the labels from the self-correction process, the performance of the models begins to decline significantly. Interestingly, the models often produce the correct answer initially, but switch to an incorrect response after self-correction. For instance, in GPT-3.5-Turbo (the model used in the free version of ChatGPT), the performance dropped by almost half on the CommonSenseQA question-answering dataset when self-correction was applied. GPT-4 also exhibited a performance drop, albeit by a smaller margin. In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer According to the researchers, if the model is well-aligned and paired with a thoughtfully designed initial prompt, “the initial response should already be optimal given the conditions of the prompt and the specific decoding algorithm.” In this case, introducing feedback can be viewed as adding an additional prompt, potentially skewing the model’s response away from the optimal prompt. “In an intrinsic self-correction setting, on the reasoning tasks, this supplementary prompt may not offer any extra advantage for answering the question. In fact, it might even bias the model away from producing an optimal response to the initial prompt, resulting in a decrease in performance,” the researchers write. Self-correction is also prevalent in multi-agent LLM applications. In these scenarios, multiple instances of an LLM, such as ChatGPT, are given different instructions to perform distinct roles in a multi-sided debate. For instance, one agent might be tasked with generating code, while another is instructed to review the code for errors. In these applications, self-correction is implemented by instructing agents to critique each other’s responses. However, the researchers found that this multi-agent critique does not lead to any form of improvement through debate. Instead, it results in a form of “self-consistency,” where the different agents generate multiple responses and then engage in a form of majority voting to select an answer. “Rather than labeling the multi-agent debate as a form of “debate” or “critique”, it is more appropriate to perceive it as a means to achieve “consistency” across multiple model generations,” the researchers write. Post-hoc vs pre-hoc prompting While self-correction may not enhance reasoning, the researchers found that it can be effective in tasks such as modifying the style of the LLM’s output or making the response safer. They refer to these tasks as “post-hoc prompting,” where the prompting is applied after the responses have been generated. They write, “Scenarios in which self-correction enhances model responses occur when it can provide valuable instruction or feedback that pre-hoc prompting cannot.” Another key finding of the paper is that the improvement attributed to self-correction in certain tasks may be due to an inadequately crafted initial instruction that is outperformed by a carefully constructed feedback prompt. In such cases, incorporating the feedback into the initial instruction, referred to as the “pre-hoc prompt,” can yield better results and reduce inference costs. The researchers state, “It is meaningless to employ a well-crafted post-hoc prompt to guide the model in ‘self-correcting’ a response generated through a poorly constructed pre-hoc prompt. For a fair comparison, equal effort should be invested in both pre-hoc and post-hoc prompting.” The researchers conclude by urging the community to approach the concept of self-correction with skepticism and to apply it judiciously. “It is imperative for researchers and practitioners to approach the concept of self-correction with a discerning perspective, acknowledging its potential and recognizing its boundaries,” the researchers write. “By doing so, we can better equip this technique to address the limitations of LLMs, steering their evolution towards enhanced accuracy and reliability.” Like this: Loading... TAGS AI research papers Artificial intelligence (AI) DeepMind large language models Facebook Twitter ReddIt Linkedin Previous article Turn your smartphone into a thermal camera with the Infiray P2 Pro Ben Dickson Ben is a software engineer and the founder of TechTalks. He writes about technology, business and politics. RELATED ARTICLESMORE FROM AUTHOR Can AI be a force for social good? This generative AI model can be a big deal for the gaming industry The promising alliance of generative and discriminative AI What to know about Amazon’s Alexa LLM How is AI impacting B2B marketing? The complete guide to LLM compression Leave a Reply This site uses Akismet to reduce spam. Learn how your comment data is processed. Recent Posts LLMs can’t self-correct in reasoning tasks, DeepMind study finds Turn your smartphone into a thermal camera with the Infiray P2 Pro Can AI be a force for social good? This generative AI model can be a big deal for the gaming industry The promising alliance of generative and discriminative AI Follow Us Twitter Facebook ABOUT US At TechTalks, we examine trends in technology, how they affect the way we live and do business, and the problems they solve. But we also discuss the evil side of technology, the darker implications of new tech and what we need to look out for. The idea is to be able to make the most out of the benefits provided by new tech trends and to minimize the trade-offs and costs. FOLLOW US © TechTalks, all rights reserved. This website uses cookies to improve your experience. We assume you're ok with this.Accept Reject Read More",
    "commentLink": "https://news.ycombinator.com/item?id=37823543",
    "commentBody": "LLMs can&#x27;t self-correct in reasoning tasks, DeepMind study findsHacker NewspastloginLLMs can&#x27;t self-correct in reasoning tasks, DeepMind study finds (bdtechtalks.com) 161 points by nyrikki 21 hours ago| hidepastfavorite326 comments bradley13 21 hours agoLLMs have no real understanding, so of course they cannot self-correct. They can&#x27;t even correct on command.I had an example just today: I wanted an example of a piece of code using framework X to do task Y. I didn&#x27;t realize that what I wanted is not possible.The LLM I was using gave me code that worked, but did not do what I wanted. I pointed this out, so I then got code that syntactically did what I wanted, but could never work. This went back and forth twice, before I gave up.The LLM was incapable of recognizing the falsity of its answers. It certainly wasn&#x27;t capable of suggesting a different approach that would work (and yes, there was one, I found after a bit more research). reply caturopath 20 hours agoparentI see remarks like this a lot, and I don&#x27;t know what to do with them.Talking about \"real understanding\" without fleshing out what we mean by the phrase doesn&#x27;t strike me as at all insightful in this context. In day-to-day use, the term is imprecise but usually easy enough to talk about, but I&#x27;d struggle to apply it to dogs, let alone to LLMs or AGIs or whatever.You say that _of course_ they cannot self-correct because of this. If Deepmind&#x27;s tests showed the opposite result, would you say that the system they were testing did have \"real understanding\"? It seems likely to me that future systems will demonstrate self-correction using Huang et al.&#x27;s methodology...will we think those systems are different in some way involving understanding?> The LLM I was using gave me code that worked, but did not do what I wanted. I pointed this out, so I then got code that syntactically did what I wanted, but could never work. This went back and forth twice, before I gave up.> The LLM was incapable of recognizing the falsity of its answers. It certainly wasn&#x27;t capable of suggesting a different approach that would work (and yes, there was one, I found after a bit more research).I really don&#x27;t know what to do about these sorts of anecdotes. Often with slightly different random values or temperature or phrasing, the same LLM will give different results for the same problem. I&#x27;ve repeatedly seen people make much more narrow claims about what LLMs get wrong or what their biases are, where simply regenerating will give a dramatically different answer.Your pain here sounds like something I see in humans all the time. If we trained a human harder never to ask follow-up questions, I imagine it would be even worse. There are clearly important differences between an LLM and a human being, but I don&#x27;t think it&#x27;s always easy to describe what they are in useful ways. reply klyrs 19 hours agorootparent> Often with slightly different random values or temperature or phrasing, the same LLM will give different results for the same problem.You&#x27;re fundamentally describing a stochastic parrot here, and not an intelligence. When you say that humans can also make the same mistake, you&#x27;re ignoring the fact that every human testing these systems and finding it lacking are also comparing their experience to a lifetime of interacting with human intelligence. Every anecdote of this sort is an example, typically based on repeatedly trying an assortment of prompts (eliminating two of your variables -- random values & varying prompts), on a large variety of tasks, which is curated down to a single example for the sake of brevity.To say that \"oh maybe it would have gotten the right answer if you got lucky or tried harder or twiddled a knob that you don&#x27;t have access to\" is simply nowhere near the extraordinary evidence that is required to prove the extraordinary claim of \"real understanding.\" The reason that you don&#x27;t know what to do about these anecdotes is that you lack the evidence to properly rebut them. You can only wave your hands at ill-defined properties and gaslight about the user holding it wrong. Perhaps you should ask your parrot buddy what to do.But if you were really serious about this, you wouldn&#x27;t be going after the strawfolk down in the comments, you&#x27;d rebut the paper itself. reply yawnxyz 19 hours agorootparentThis is super interesting because you’ll end up with different people with different opinions on “what is the best answer” if they all have different experiences.Most of us when using LLMs feel it should only produce the one correct answer; sometimes that’s the right way to think about it, but other times we might want an opinionated answer, when there is no true answer.So I think if we get better learning and self correcting machines, we also get more opinionated and sometimes incorrect machines. Kind of like people. And sometimes they’re stubborn or confidently incorrect, but that I think actually points to more intelligence (in people at least), since it points to people deciding based on their experiences. reply aarong11 15 hours agorootparentThere&#x27;s no such thing as \"one correct answer\" to most tasks in any language. In mathematics, maybe. If you&#x27;re asking it to recall a specific quote verbatim, yeah. But other than that there are many (infinite?) different ways you can paraphrase differently to get the same point across (at least in English). reply lossolo 15 hours agorootparentprev> This is super interesting because you’ll end up with different people with different opinions on “what is the best answer” if they all have different experiences.In context of grandparent comment it&#x27;s code, so while we can have different solutions to the same problem, we can verify if the solution is correct because it&#x27;s not an opinion on some subject. reply soco 8 hours agorootparentprevAnd I assume there&#x27;s no understanding of what \"real understanding\" means. In this so limited context \"real understanding\" looks like \"did what I wanted without me really explaining what I wanted\". Although in real life I seldom know from the start what I really want either and takes me a few iterations to clarify it even to myself - so \"real understanding\" seems to be something even I am missing (and I shouldn&#x27;t blame poor AI for lacking it). Or maybe I&#x27;m an AI myself just unaware of it? reply caturopath 13 hours agorootparentprev> Every anecdote of this sort is an example, typically based on repeatedly trying an assortment of prompts\"Data\" isn&#x27;t the plural of \"anecdote\" -- you can systematically test things, as the authors of the study the article reports did, or you can say \"I tried something and got result ~X, therefore LLMs cannot X\", which is my honest understanding of what I&#x27;ve heard people say repeatedly.> But if you were really serious about this, you wouldn&#x27;t be going after the strawfolk down in the comments, you&#x27;d rebut the paper itself.I don&#x27;t know the details of the paper, but I suspect it&#x27;s right. My actual problem was with someone explaining that the result was trivial and offering what I thought was a non-helpful explanation of why. reply graeme 19 hours agorootparentprevOne example. I asked ChatGPT to take 7 letters and find all the word combos.There were about 80 possible. It maxed out at 19 or so.Now clearly this is a hard task. Humans can’t do it well and none of the text corpus would offer training on this sort of thing.If I asked a human to do it they would say “here’s what I got, I don’t think that is all of them”ChatGPT would apologize when corrected and make a new, equally wrong list with full confidence.That’s how I interpret understanding. Self awareness and doubt.Oddly enough the code interpreter seems much stronger on this point. Now that I think about it I don’t think I was using it for the letter combo task. reply jiggawatts 18 hours agorootparentCurrent LLMs use an optimisation of processing data one word at a time. This makes them bad at solving puzzles involving individual letters or digits.This is a well known, well understood limitation that can be overcome (Facebook published a hierarchical model that can parse individual characters), but this technique isn’t used by ChatGPT.Whenever I see a criticism like this, it says more to me about the hubris of humans and the falsity of their assumed superior intelligence.You’re criticising the intelligence of a thing you don’t understand yourself!You didn’t “read the manual”. You didn’t go find out why the AI is failing. You just spouted an angry comment and gave up without gaining any understanding.PS: the “stupid AI” understands all of this. Just ask it to explain it to you: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7bc1c1cb-d888-4ccb-904a-79e9ae... reply fragmede 19 hours agorootparentprevChatGPT will happily tell you it doesn&#x27;t know anything after January 2022, and it&#x27;ll say \"jdnrirmd-gurlksjd\" is not a recognizable term, instead of trying to bullshit a definition of that, if that&#x27;s your bar for \"understanding\", reply jfim 19 hours agorootparentprevYou can see it in various tasks where the answer for a text generator would be incorrect, yet simple reasoning or understanding yields the correct answer. For example, the everything fits in the boat variant of the farmer across the river problem: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7d2de1c4-1cd6-4d7d-97e4-645830... reply godelski 19 hours agorootparentI love this example! I&#x27;ve been using a different one and GPT has been getting better at it (unconvinced they aren&#x27;t training on my reporting that it gets the wrong answer. Or that I&#x27;ve posted this question dozens of times here and some have gotten pretty high up. But it&#x27;s been a year now and we&#x27;re still in stochastic phase). The question I ask is variants of \"Which weighs more, a pound of feathers or a kilogram of bricks?\" Similar to yours it is just a slight variant on a standard logic puzzle.For those wondering why ask these questions, we&#x27;re testing for overfitting. Yes, you can overfit even if your training and validation curves don&#x27;t diverge. If the model fails these questions, they&#x27;ve clearly overfit. But the solution space is very large and complex, so overfitting in one regime doesn&#x27;t mean it didn&#x27;t underfit another.GPT 3.5: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;328cc39d-7fb3-4726-92a2-29437c...LLaMA 2 70B chat: https:&#x2F;&#x2F;hf.co&#x2F;chat&#x2F;r&#x2F;KX5H3P2Falcon 180B Chat: https:&#x2F;&#x2F;hf.co&#x2F;chat&#x2F;r&#x2F;V8XxdYhNone of these models can consistently get the answer right. GPT used to actually explain to me the difference between a pound and kilogram (correctly) and then use that answer to justify why they are the same. Such an answer is very clearly a demonstration of a lack of understanding as it isn&#x27;t even remotely self consistent.LLMs are powerful and amazing technologies. But we can also critique them. Hyping up models hinders the ability to improve them because every thing (LLMs, humans, governments, whatever) has limitations and is worthy of critique. But criticism isn&#x27;t saying something is garbage and too many people confuse this. reply spdustin 3 hours agorootparentI was pleased to see GPT-4, combined with my custom ChatGPT instructions, had no problem with this: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;726d5c7b-761f-462e-8a6a-61904a... reply jfim 18 hours agorootparentprevAgreed, there&#x27;s definitely a lot of value in LLMs even if they don&#x27;t really have an understanding of the world. reply godelski 16 hours agorootparentIt is quite interesting to me that people latch onto the world model so much as if it is highly significant or a lack of a world model invalidates LLMs. Personally I still believe they&#x27;re magical (in the proverbial sense) and amazing tools even though I also believe they are just complex stochastic machines that have very little understanding of the things they are doing. That just tells me how cool and amazing that statistics is. I honestly don&#x27;t know anyone that thinks LLMs are useless things, despite knowing a large number of people that are highly critical of them. But those are very different metrics. I don&#x27;t know why we can&#x27;t have nuance in things, why they need to either be a gift from god or a pile of shit. reply fragmede 19 hours agorootparentprevIt figures it out if you point out the difference much like a human would when faced with a riddle they didn&#x27;t get.https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;34df3eb0-c41c-4c5b-80d2-48f5d0...I&#x27;ll be honest, the only reason I knew to read your variation of the farmer-boat problem carefully is because you set me up for success - I knew it wasn&#x27;t going to be the original.Curiously, I haven&#x27;t been able to get it to one-shot the question, even by prefixing it with instructions. reply godelski 19 hours agorootparentExcept the problem here is that you spoiled the solution. It is quite difficult to provide hints that don&#x27;t spoil. Or rather, don&#x27;t provide hints but rather tell it that it is wrong.Here, I&#x27;ll demonstrate it. First I&#x27;ll prod it with vague responses about it just generally being wrong. Trying to leak no information to the model. We&#x27;ll try to slowly add a bit more and then use your followups. Notice that the model cannot escape the overfit regime without your strong hints. You told the model specifically what to consider. You told it that it is a trick question of a trick question. This is not how a human would handle the situation. To my followups they wouldn&#x27;t spit out the same answers. They&#x27;d actually likely followup with questions if they were confused. Which is a behavior I&#x27;ve never seen from an LLM: asking clarifying questions.https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;57ab9bca-326d-45cb-9257-7fb8c2... reply throwaway4233 19 hours agorootparentprevI do not think that answer would correctly solve the original riddle. The LLM blindly just gave an answer without raising the question of which pair of objects together would be a problem if left alone. reply jfim 18 hours agorootparentGood catch, it actually leaves the goat with the cabbage in the answer above. reply glitchcrab 10 hours agorootparentprevBut that isn&#x27;t a correct solution - it leaves the cabbage with the goat. reply all2 20 hours agorootparentprev> I see remarks like this a lot, and I don&#x27;t know what to do with them.There&#x27;s no \"reasoning loop\" built into LLMs yet. Keyword, yet. For now we&#x27;re left with single-shot answers from \"memory\" rather than a reasoning loop akin to what a human would do, which is read the docs, try some stuff out, discover that what you&#x27;re asking for is impossible, and then telling you that it isn&#x27;t possible. reply jaidhyani 20 hours agorootparentAlternatively, the prior on \"this is not possible\" is very low because RLHF & Friends have targeted metrics that, inadvertently or not, discourage that outcome. reply robertlagrant 19 hours agorootparentI think that&#x27;s the right answer - human trainers prefer an answer, even a made up one, to \"I don&#x27;t know\". reply Jensson 19 hours agorootparentDataset as well. In a forum if you don&#x27;t know the answer you simply don&#x27;t post. Only people who think they know will post an answer. In a dialogue you see a lot more \"I don&#x27;t know\" since there they are expected to respond, but there isn&#x27;t a lot of dialogue data to be found on the internet compared to open forum data. reply SAI_Peregrinus 17 hours agorootparentAmazon product Q&A has a lot of \"I don&#x27;t know\" answers. Unlike just about everywhere else on the internet. reply brandall10 17 hours agorootparentprevAny agent that uses a tool (ie. repl&#x2F;apis) essentially has a reasoning loop just like this. Microsoft Research recently got their Autogen framework up to point where the results are much better than AutoGPT&#x2F;BabyGPT and the like through more optimal tool use, showing the ability to do rather sophisticated research and problem solving.This new research focuses on responses just using its own corpus of knowledge. And this totally makes sense if that&#x27;s all you do without giving a hint to what is incorrect, if indeed anything is incorrect. It&#x27;s akin to asking a child after they produce an answer they feel sure about an \"are you sure?\", and then receiving another answer out of a state of confusion.The main takeaway for me is if you can somehow get better performance on followup queries from simply telling it to more carefully review its approach, that your initial prompt wasn&#x27;t as efficient as it could be. reply danielmarkbruce 19 hours agorootparentprevIt&#x27;s trivially easy to build a reasoning loop using the GPT-4 API. reply lawlessone 19 hours agorootparentHow? reply danielmarkbruce 19 hours agorootparentexample:Initial Prompt:\"Here is the schema for a database: CREATE TABLE persons ( id INTEGER PRIMARY KEY AUTOINCREMENT, first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INTEGER NOT NULL ); CREATE TABLE Y(blah blah blah)I&#x27;ll pose a question and I want you to: Respond with JSON which has two fields, Query and Error. Query: A SQL query to get the required information Error: An error message to pass back to the user if it&#x27;s not possible.Question: Show me all the people who are over 40. \"Response from prompt: {Query: \"Select years_old from persons where age > 40\", Error:\"\"}Now, in your \"agent\": Get that response, run it against your db, get the error message. Go back to the GPT-4 api with the initial prompt and response, and add \"this doesn&#x27;t work and gives the following error message. Correct your response and responde in JSON again.\"And so on. reply Art9681 17 hours agorootparentPeople who are having trouble getting good results from LLMs are still trying to figure them out. Most folks are using the product and not the model. Where it really shines is when you use the API and build a platform of workflows around it, starting with a real solid prompt template and working your way through various methods to achieve an outcome. There is no magic wand to get a full solution in one shot, but guiding the LLM towards that ultimate outcome is the type of thing a lot of nerds dont have the attention span for and instead move on to the next weekly JS framework to get their fix.Which is good for us who stick with the process. reply danielmarkbruce 16 hours agorootparentYup, agree. replyabm53 19 hours agorootparentprevThese models produce correct answers to many problems that require “reasoning” (for any sensible meaning of the word), that are not in their training set. reply a_wild_dandan 18 hours agorootparentIt’s also unclear that LLMs have no “reasoning loop”, or that a “loop” abstraction is necessary for all reasoning, or that eyeballing wrong answers is a sufficient metric to categorically dismiss “reasoning.\" A \"reasoning loop\" argument is especially odd when applied to LLMs...which explicitly have architectural loops, and their output generation is a literal loop.Folks, we don&#x27;t understand our own minds. You think we already understand a potential alien mind? With our n = 1 examples of generally intelligent mind architectures (ours)? Fat chance.Anyone confidently claiming sweeping, nebulous conclusions about these new models is likely revealing more about their biases than the model&#x27;s inner workings. We just don&#x27;t know much. Hot takes on ML are just anthropocentrism Rorschach tests. reply all2 16 hours agorootparent> A \"reasoning loop\" argument is especially odd when applied to LLMs...which explicitly have architectural loopsOh, I understood that the current crop of LLMs didn&#x27;t have a way to push data back into itself. I know so little about LM architecture at this point. I need to work my way through the freeAI course that&#x27;s out there. Maybe a tutorial or two on building one from scratch. reply all2 19 hours agorootparentprevThat just shows that parroting will solve a number of problems that require reasoning, that is \"reasoning\" as we think of it can be reduced to a statistical process.Kids parrot their parents before they understand the meaning of what they are doing or saying. Meaning arises from a much more complex process than seeing&#x2F;repeating. I think the same will be true with LLMs. True reasoning capabilities will be another revolution entirely.---This just occurred to me; LLM&#x27;s have a cargo cult level understanding of anything they&#x27;ve been trained on. Correct answers are actually statistical flukes -- purposeful because that&#x27;s how we trained the models -- but not actually significant in terms of reasoning. reply a_wild_dandan 18 hours agorootparentHow do we test this alleged distinction between \"true reasoning\" and statistical parroting? What experiments can we perform on SotA models to make this idea falsifiable?Commonplace hypotheses like these give me strong \"No True Scotsman\" vibes, but I&#x27;m often wrong. Let&#x27;s agree on a method, and I&#x27;ll test it. reply Art9681 17 hours agorootparentThere is none. No one understands what intelligence really means or self-awareness. Which is why they feel threatened by anything that challenges their self proclaimed uniquely human trait. The goal posts WILL move a lot more before this debate is settled. Inevitably the success rate and accuracy of LLM responses is going to get better and better, quite possibly to the point where it is indistinguishable from a human. But it wont matter, because some humans will redefine intelligence to be something else so their place at the top of the intelligence pyramid remains in place. reply all2 16 hours agorootparentprevYou can coax LLM&#x27;s into reasoning. I recall someone on here posting a link to prompts that instruct the LLM to reason through a request, and this improves its output significantly.I think what our models are missing is recursion on themselves. You and I can be self-referential, and we are capable of meta thought. We are also capable of \"internal dialogue\" where we speak and reason internally.The LLMs at present lack even state or memory. Arguably those aren&#x27;t necessary for \"reasoning\" capabilities.I wonder how far off \"stochastic parrot\" is from what we do naturally. I have an image in my head of how we think using associated words&#x2F;concepts&#x2F;pictures for learning and I can&#x27;t imagine it is too different from statistically associated concepts&#x2F;words.---This is sort of scatterbrained, and I apologize. I don&#x27;t have enough time to write a more concise response. reply kahnclusions 19 hours agorootparentprevThat doesn’t mean it does any “reasoning”. It generates a response text that looks like a response to the input text. The whole point is that it generates responses that aren’t in the training set. But the fact that the response is actually a correct one is just coincidence. reply a_wild_dandan 18 hours agorootparentSo when a model succeeds on a reasoning task it&#x27;s not positive evidence, but when it fails it&#x27;s negative evidence? The good ol&#x27; confirmation bias feedback loop! reply caturopath 13 hours agorootparentprevThe article is about work to add a loop somewhat to that effect reply layer8 20 hours agorootparentprevYou are right that “understanding” requires further explanation.In the anecdote above, however, it seems to be clear that the LLM didn’t realize a number of things, such as:– It might not have sufficient information to answer the question.– It’s just making a guess of what a correct answer might plausibly look like.– The fact that this is different from actual correctness.– That by asking questions back, it might actually be able to come up with a working answer, with the help of its collocutor.Even after being informed multiple times that it made an error, it doesn’t seem to realize any of the above. This apparent lack of self-reflection, of addressing and working with the conversational situation — i.e., what a human would typically do — is what people usually mean by LLMs lacking an understanding of what they output. reply godelski 19 hours agorootparentTo add to this list of things LLMs don&#x27;t understand:- Numbers (LLMs still can&#x27;t do math and the ones that \"can\" are very brute forced and don&#x27;t generalize)- Commutative properties (The (idk why anyone was surprised) \"reversal curse\": https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12288)- Associative properties- World models (i.e. can understand some basic physics and causality. Not mathematically, but the same way a child understands that letting go of something in their hand falls to the ground and not up)- How to say \"I don&#x27;t know\"- Any form of meaningful generalization (GPT 3.5 and most LLMs still have difficulties with \"Which weighs more, a pound of feathers or a kilogram of bricks\". GPT4 gets it, but I&#x27;m not convinced it isn&#x27;t because I&#x27;ve asked it that question too many times and they specifically trained on it.)And a whole load of things. With basically all these things being quite relevant to the collective interpretation of \"understanding.\" They aren&#x27;t hard to tease out either. You ever have a problem that isn&#x27;t easy to google because the search terms are too close to a different problem? The LLM will give you very similar results, even if you probe with corrections and specify that your problem is different. Like layer8, many many times I&#x27;ve corrected (many different) LLMs and cannot tease out the correct answer. Because the correct answer is too low likelihood and often the RLHF has decreased the distribution in that region to get to it. Because this is exactly what RLHF does, on purpose. reply og_kalu 19 hours agorootparent> Numbers (LLMs still can&#x27;t do math and the ones that \"can\" are very brute forced and don&#x27;t generalize)These seem to generalize.https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.09066https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.00304> Commutative properties (The (idk why anyone was surprised) \"reversal curse\": https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12288)This was a retrieval from training issue not an inference one. and make no mistake, people will fail these sort of answers too (perhaps not to the same extent). Very often someone will learn a fact in a certain why and fail to recall that when asked in a reverse or roundabout way.Communicative properties are not something that occur in the vast majority of text or language. It&#x27;s not \"generalization\" for training to treat it as such lol. Since they can answer such questions just fine during inference, It makes little sense to say an LLM doesn&#x27;t understand communicative properties.> How to say \"I don&#x27;t know\"There&#x27;s quite a lot of indication that the computation can distinguishing hallucinations. It just has no incentive to communicate this. Don&#x27;t blame the LLM here. Blame the very human data that doesn&#x27;t encourage this.GPT-4 logits calibration pre RLHF - https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;3gYel9rJust Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.14975Teaching Models to Express Their Uncertainty in Words - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.14334Language Models (Mostly) Know What They Know - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.05221I&#x27;m not trying to say that LLMs are perfect. and as long as people understand that saying an LLM doesn&#x27;t understand x doesn&#x27;t mean an LLM doesn&#x27;t understand anything at all, i&#x27;ll happily state weaknesses. reply godelski 16 hours agorootparent> These seem to generalize.I&#x27;m not convinced. Zhou et al explicitly is teaching the model to decompose the longer chain addition into a windowed problem. Which yeah, that is good and how we humans do this. But that is limited, see Figure 10. It is a pretty heavy prompt. Figure 3 is showing that the method is not very robust (aka, not generalizing). We see changing symbols really hurts performance, subtraction and multiplication are not great. But even a 90% accuracy is not suggesting great generalization when we&#x27;re talking about a pretty simple algorithm, especially one that is natural to computers. Chen et al is doing a better job, but their prompting still shows a lack of generalization and appears to be dependent on how much the model was originally tuned for mathematical tasks in the first place, with GPT having explicitly been tuned for this (if we are to believe OpenAI claims of working on making the model better at math). But this is convincingly a better method, just not convincingly generalized.I&#x27;ll note that an important aspect of generalization is not just extending to the OOD but also: not requiring fancy prompts at inference, working with arbitrary symbols in few shot exampling ( This was a retrieval from training issue not an inference one.Actually I disagree. We know (likely) why this happens -- because the autoregressive nature biases a model towards a specific sequence direction -- but that doesn&#x27;t mean it isn&#x27;t generalization issues. And I very much disagree that humans will fall prone to these same issues. You keep using this claim with very little evidence. An explicit example from that work is the LLM getting correct the answer to \"Who is Tom Cruise&#x27;s mother?\" (Mary Lee Pfeiffer) but not getting the correct answer to \"Who is Mary Lee Pfeiffer&#x27;s son?\" Humans naturally handle this difference trivially. The thing is that this specific knowledge is probably not known to most people so the latter question is more likely to confuse the person. But this is different.And we need to also recognize that humans are even explicitly evaluated this way. Learning history, in a textbook or lecture you&#x27;ll be presented information like \"On December 7, 1941 the Japanese attacked Pearl Harbor.\" But then on a test you&#x27;ll be asked \"What day did the Japanese attack Pearl Harbor?\" That&#x27;s specifically a reversal. When was X? Why is the day X important? These are explicit ways that people test other people, at a very early age, so I disagree that it is a highly common occurrence for people to fall prone to this. I&#x27;m sure you&#x27;ll find example, but I&#x27;m willing to bet that those examples have another factor (you also won&#x27;t be able to test the examples I gave on LLMs because they will have specifically seen both directions __because__ we do this kind of testing).> It just has no incentive to communicate this. Don&#x27;t blame the LLM here. Blame the very human data that doesn&#x27;t encourage this.You&#x27;re right that we can probably do a better job at training the models to respond this way. But they naturally don&#x27;t. But that is the clear demonstration of not understanding. I&#x27;d equally claim that a person doesn&#x27;t understand something if they rambled off bullshit and were trying to talk their way into a solution or post hoc explain why their wrong answer is correct. Either way, it doesn&#x27;t challenge the claim that it doesn&#x27;t demonstrate a lack of understanding. Especially when you see these ramblings not be self consistent.> LinksI&#x27;m not sure what you&#x27;re showing here. They&#x27;re kinda supporting my explicit point of RLHF messing with the distribution. I&#x27;ll add more that this is a crazy hard problem to even evaluate because what is being shown as metrics are extremely aggregated. Aggregation is the bane of evaluation but so is dimensionality.> I&#x27;m not trying to say that LLMs are perfect. and as long as people understand that saying an LLM doesn&#x27;t understand x doesn&#x27;t mean an LLM doesn&#x27;t understand anything at all, i&#x27;ll happily state weaknesses.Just to be clear, no one has claimed that an LLM has 0 understanding. Those of us critiquing the understanding claim are pretty well aligned with that the model has some understanding. Of course it does. That&#x27;s what a fitting function is. But we&#x27;re challenging the claim of understanding in the generalized context which is what you&#x27;ve been pointing towards. Things like an LLM having a world model. Things like an LLM understanding how addition works (compared to understanding how addition works for 2-6 digit numbers). These things are quite different and I&#x27;ve been trying to be very clear that I&#x27;m not claiming LLMs are a load of bullshit. I&#x27;ve explicitly stated as much in other comments, but the prior comment wasn&#x27;t as necessary given the context. (not that this statement should be necessary in the first place. It is only a result of over hype that people binarize critique. I really don&#x27;t want to see more of this religious nature around ML, it is harmful to our community) reply YeGoblynQueenne 20 hours agorootparentprev>> I&#x27;ve repeatedly seen people make much more narrow claims about what LLMs get wrong or what their biases are, where simply regenerating will give a dramatically different answer.It will, but what&#x27;s the point of a random answer generator? What&#x27;s useful is a system that gives correct answers, and can discriminate correct answers from incorrect answers. Otherwise, you can only know that an answer is correct when you already know it, and that&#x27;s not very useful at all. reply caturopath 13 hours agorootparentI think usefulness is a different question than capabilities. \"LLMs can&#x27;t do X\" is an interesting claim, and it takes some level of systematic work to make it. If the capability exists at all, this is interesting, even if it&#x27;s not useful. That being said, it doesn&#x27;t mean such an existing capability will not prove useful. If something is fallible, it might be above a threshold worth using, it might be improved by doing the same techniques that are already being used, or it might be improved by adding on some sort of system to filter or refine responses.> you can only know that an answer is correct when you already know it, and that&#x27;s not very useful at all.This statement makes sense on the surface, but I don&#x27;t think it&#x27;s true. All the time I get told things that I don&#x27;t know the answer to beforehand, but judge pretty well whether it&#x27;s right or not. reply LASR 19 hours agorootparentprevAssuming “correctness” as being a hard criterion will greatly limit your ability to get powerful and very useful output from LLMs.A person doing some knowledge work will fail on this criterion. But they still are employable and generally regarded as being useful. reply RandomLensman 20 hours agorootparentprevAn LLMs can explain a concept but is unable to apply said concept to a given problem - for me that shows a lack of \"real understanding\". reply somewhereoutth 17 hours agorootparentprevYou have it backwards - there might be some similarities between LLMs and humans. I don&#x27;t think any such almost certainly superficial similarity is meaningful in any way. reply godelski 19 hours agorootparentprevLet me give an example[0]> Before LLMs, we had a very crisp test for having, or not having a world model: The former could answer certain questions that the latter could not, as shown in #Bookofwhy. LLMs made it harder to test, for the latter could fake having a model by simply citing texts from authors who had world models, see https:&#x2F;&#x2F;ucla.in&#x2F;3L91Yvt The question before us is: Should we care? Or, can LLMs fake having a world model so well that it wouldn&#x27;t show up in performance? If not, we need a new mini-Turing test to distinguish having vs. not-having a world model.The thing here is that LLMs are trained on most of the internet. Some people are surprised by some results but don&#x27;t seem to know what kind of content is on the internet or in the training set (to be fair, we don&#x27;t know what all the training sets are). There&#x27;s lots of people that believe LLMs have world models (there have even been papers written about this!) but it&#x27;s actually pretty likely that the LLMs were trained on similar examples, and this also helps explain why it is easy to break the world model (it isn&#x27;t a world model if it is very brittle). We can see similar things with our tests like LSAT and GRE subject tests. Well guess what, there are whole subreddits and stack exchanges dedicated to these. Reddit is is most of these datasets and if you&#x27;re testing on training data you&#x27;re spoiled (there&#x27;s a lot of spoiling that happens these days, but like Judea said, does it matter?)The problem with hyping up LLMs&#x2F;ML&#x2F;AI up too much is that we can no longer discuss how to improve the system. If you are convinced that they have everything solved then there&#x27;s nothing to do. But no system is perfectly solved. Never confuse someone criticizing a tool with someone saying a tool is useless. I&#x27;m pretty critical of LLMs and am happy to talk about their limitations. That doesn&#x27;t mean I&#x27;m also not wildly impressed and use them frequently. There&#x27;s too much reaction to criticism as if people are throwing the thing in the dumpster rather than just discussing limitations.FWIW, I wouldn&#x27;t change my mind if DM&#x27;s test showed the opposite result. You can check my comment history. I&#x27;d probably dig in and rather comment why DM&#x27;s tests were bullshit. I&#x27;ve even made comments about how chain of thought is frequently a type of spoiling. The reason being not because I don&#x27;t think we can&#x27;t create AGI (I very much do), but because I have a deep experience with these models and ML in general and nothing in my experience and understanding leads me to even believe half the things people claim. You&#x27;ll see me make many comments ranting about the difficulties of metrics and how there&#x27;s this absurd evaluation that people do (not just in ML) of using a proxy test set and using some proxy metric and saying performance on it is enough to claim a model is better. It is a ridiculous notion.[0] https:&#x2F;&#x2F;twitter.com&#x2F;yudapearl&#x2F;status&#x2F;1710038543912104050 reply ekidd 20 hours agoparentprev> LLMs have no real understandingA large language model trained on Othello games will actually build a \"board representation\" inside its neural network: https:&#x2F;&#x2F;thegradient.pub&#x2F;othello&#x2F;. This was confirmed by editing the board representation inside the neural net, \"tricking\" it into \"believing\" the board was in a different state. At this point, the LLM started making legal moves based on the edited position. If the LLM is actually building a data structure describing the board state, then it&#x27;s hard to claim it&#x27;s just acting as a parrot.The raw version of GPT apparently achieves an Elo score of 1800 at chess: https:&#x2F;&#x2F;twitter.com&#x2F;GrantSlatton&#x2F;status&#x2F;1703913578036904431. This is worse than a good dedicated chess engine, but almost certainly better than I could do!And every day, I see Copilot occasionally perform non-trivial completions that require \"in-context learning\" of complicated things that exist only in my source code. Sure, it crashes and burns regularly, too, but I&#x27;ve seen a lot of cases where it could only have figured out the code it did by carefully combining information available in the file.So I believe that LLMs can actually achieve surprisingly large amounts of understanding, particularly ChatGPT 4 and (on a good day) CoPilot. But the frustrating thing is that they&#x27;re inconsistent, and the current RLHF process apparently impairs their ability to correctly estimate accuracy. When they make mistakes, they&#x27;re effectively \"blind\" to those mistakes, to a shocking degree. reply YeGoblynQueenne 19 hours agorootparent>> The raw version of GPT apparently achieves an Elo score of 1800 at chess: https:&#x2F;&#x2F;twitter.com&#x2F;GrantSlatton&#x2F;status&#x2F;1703913578036904431. This is worse than a good dedicated chess engine, but almost certainly better than I could do!Probably because it was trained to get better at it.https:&#x2F;&#x2F;twitter.com&#x2F;GrantSlatton&#x2F;status&#x2F;1706545268009931175There&#x27;s already been plenty of discussion on LLMs&#x27; ability to play chess and it makes sense that OpenAI would try to make their models better at it. reply kweingar 20 hours agorootparentprevI’d point out that the LLMs are still incapable of using these internal representations in novel ways. A human who has internalized the rules of chess can learn and play variants like duck chess easily. GPT-4, despite being somewhat proficient at chess, falls apart when asked to play duck chess, constantly making illegal or illogical moves. reply og_kalu 20 hours agorootparentUhh not really. I assure you, a LLM that can play chess will converge in training on duck chess much faster than one that wasn&#x27;t. reply emmender1 20 hours agorootparentLLMs are failing on tasks as simple as this. you can call it a trick question but what the hey.\"prove that there are no non negative numbers less than 3\"Claude puts out this elaborate BS - whats funny is the pretension.----This is trivial to prove by contradiction:Assume there exists a non-negative number n Understanding the physical or emotional world solely from human language is more like trying to use the Othello LLM&#x27;s state representation to establish the colour of the boardNobody truly understands the physical world. Don&#x27;t you think the birds that can feel the electromagnetic fields around the earth and use it to guide their travels would tell you your model was fundamentally incorrect ?Certainly, LLMs are more limited in their input data, but it&#x27;s not a fundamental difference. and adding more modalities is trivial. reply notahacker 16 hours agorootparent> The sense data your brain ingests does not map perfectly or even particularly closely to the real physical world we inhabit.I never argued otherwise, though being aware that there is a physical world that I can interact with helps! The point is that the only reason the LLM&#x27;s transformation of syntax approximated an Othello board was the unusually perfect correspondence between permutations, syntax and efficient storage that seldom exists. In other circumstances your LLM vectors are modelling language constructs, lies and other abstractions that only incidentally touch on world and brain state.The term \"understanding\" is generally used by humans to refer to how humans model reality[1] and need not imply completeness. But it also implies that a model isn&#x27;t extremely dissimilar to humans in what its parsed and how its parsed it. Or to slightly alter your example, if a bat argued that following the bat swarm well enough to locate the exit didn&#x27;t mean humans had achieved \"true echolocation\", I&#x27;d have to agree with them.I mean, a photograph and a pocket calculator are also representations of some aspect of the state of the world, sometimes even representing a particular subset of the world information in sufficient fidelity to allow humans to make much better predictions about it. But fewer people seem to wish to stan for the capacity of the calculator or the bitmap to have \"real understanding\" of the outputs they emit, even though fundamentally the LLM has much in common with them and far less in common with the human...[1]the potential for debate around such definitions underlines the paucity of language... reply DanHulton 19 hours agorootparentprevI think you underestimate humans. reply jaidhyani 20 hours agorootparentprevAs the other commenter said, this is incorrect. The input was a sequence of legal moves (not even \"real\" moves - most of the training data was synthetically generated with \"generate legal moves\" as the only constraint).Deducing board state from this is extremely non-trivial. reply sneak 21 hours agoparentprevThe reason this is notable is because people keep anthropomorphizing text generators into what they perceive as something a small way from AGI.Of course they have no understanding. They’re text generators.This persistent response to LLMs is bigger news, to me, than the fact that LLMs can’t think. reply nologic01 21 hours agorootparent> This persistent response to LLMs is bigger news, to me, than the fact that LLMs can’t think.I can testify that people will be manipulated by sleight of hand (the physical act) even after they have been alerted to it. Now transfer that weakness to a domain where most people have zero equipment and training to form a sound judgement.Its a big and complicated world and our brains are wonderful but limited. We have to rely on trust for the vast majority of information we digest.When organized coalitions of individuals subvert the channels of trust we stand exposed as idiots.The principal characteristic of the digital era is, alas, not harnessing this amazing technology for societal benefit but betraying trust and violating unspoken contracts - for profit. reply jppittma 20 hours agorootparentprevIt&#x27;s because up until a few years ago, everything that was capable of communicating at that level was a (non Artificial)GI. It&#x27;s a bit ..surreal? to see text and speech without intelligence and understanding behind it. reply tsunamifury 20 hours agorootparentWhat is intelligence. Honestly other than something we keep claiming only humans have. reply jppittma 16 hours agorootparentWhat is the feeling of sunshine on your face? What is love? I think intelligence, as a prerequisite requires consciousness. It&#x27;s the capability for the \"aha!\" moment where for a brief moment all if quiet, and the student and the concept are one. reply tsunamifury 15 hours agorootparentThis is ridiculous. Sorry. Intelligence is the ability to reason and communicate to another creature and for them to understand and cooperate or betray you.This can do that. reply Jensson 10 hours agorootparentA basic diplomacy AI is also intelligent according to your definition, so why do you think ChatGPT is different than what we had before then? reply __loam 19 hours agorootparentprevYou&#x27;re making this comment in a way that devalues human intelligence but I actually think not having a great understanding of our own cognition is indicative of something deeper going on physically in our heads that isn&#x27;t modeled by the extremely simple \"neurons\" in LLMs. I&#x27;ve seen several people here talk about \"the weights in our heads\" and I don&#x27;t think we have enough information about the brain to make that analogy. reply tsunamifury 15 hours agorootparentDid you know we also don’t know how LlMs work and neither do they… reply smokel 21 hours agorootparentprevIf you compare \"thinking\" to \"text generators\", don&#x27;t you need to understand what \"thinking\" actually is, before you can conclude that these are unequal? reply swatcoder 20 hours agorootparentNo more than I need to understand every dynamic of walking to know that my goldfish doesn’t do it.For a lot of us, LLM behavior and thinking are so plainly and obviously dissimilar that the endless comparisons look somewhere between naive or manipulative, depending on who’s making them. reply digging 20 hours agorootparent> For a lot of us, LLM behavior and thinking are so plainly and obviously dissimilarBut what&#x27;s obvious to you is not obvious to everyone.Even though you don&#x27;t have to mathematically prove a goldfish doesn&#x27;t walk for me to believe you, that&#x27;s because we can both agree on a very good definition of walking. If it came down to it, I am sure we could sit down with pen an paper and some textbooks and agree upon a physical definition as robust as any. We&#x27;re just skipping that step because it&#x27;s been done before by others.I am positive that we can&#x27;t agree on a robust definition of thinking, because the definition of thinking is beyond human understanding.We have to keep an open mind. I don&#x27;t believe it&#x27;s likely that any LLMs are experiencing anything we&#x27;d call thought, but without knowing how thought works, it would be foolish of me to say it&#x27;s impossible. The problem in AI discussions is not the positions people are taking but the certainty with which they are taking them. reply YeGoblynQueenne 19 hours agorootparent>> I am positive that we can&#x27;t agree on a robust definition of thinking, because the definition of thinking is beyond human understanding.In that case, shouldn&#x27;t the people who say LLMs can think do the hard work of explaining what \"thinking\" means and why they er think it&#x27;s done by LLMs?Surely the default position should be that LLMs don&#x27;t think because they don&#x27;t belong to the class of entities that we know can think. If that default assumption is wrong, well, then, someone has to do the hard work of rejecting it. But just claiming that we think they think because who knows what thinking is, is just an excuse to not do the work. reply digging 16 minutes agorootparentYou&#x27;ve totally missed the point if you&#x27;re still reaching to assume one position or the other.We can be sure humans think. Does a crow think? We don&#x27;t know. Does an LLM think? We don&#x27;t know.We can talk about more specific phenomena in contexts that demand it, if we have the data. But there is no way to say right now that an LLM does or does not think. All we can say is it seems unlikely. reply DanHulton 19 hours agorootparentprevI would take the opposite opinion - we have to maintain a _critical_ mind. Otherwise, we&#x27;re open to being taken advantage of by any smooth-talking charlatan (or LLM, but that&#x27;s largely the same thing) that comes along.Constantly moving the goal posts with this incessant \"but what IS intelligence, though?!?\" gets us nowhere. By your own argument we can never define intelligence, so we can never actually discuss it. LLMs consistently and constantly fall down on tasks that we would not expect a human to fail at, but you and people like you insist we cannot use this as evidence because you refuse to accept any defined terms.I mean, remain as hopeful and uncritical as you want. But you&#x27;re basically asking the rest of us \"Who are you gonna believe, me or your lyin&#x27; eyes?\" and that&#x27;s gonna go about as well for you as it typically does. reply digging 12 minutes agorootparentNo, I don&#x27;t see any of this as a response to my positions at all. I must not have expressed myself clearly enough.I&#x27;m not talking about getting scammed by SBF or whatever. I&#x27;m saying that there doesn&#x27;t exist a definition of \"thinking\" that we can use to include or exclude LLMs from the group \"beings that think\". It&#x27;s counterproductive to say they do or don&#x27;t and is a distraction from useful conversation.To say I&#x27;m not being critical when I clearly said I don&#x27;t think it&#x27;s likely that LLMs think feels disingenuous and, frankly, uncritical.> By your own argument we can never define intelligenceIn no way does that extend from my argument. Intelligence and thinking are separate phenomena, and I didn&#x27;t say \"never\". reply __loam 19 hours agorootparentprevThe AI camp has economic incentives to inflate what their systems can do. I&#x27;d bet we&#x27;d get a different reaction from neuroscientists. reply digging 10 minutes agorootparentI&#x27;m specifically referring to the inability of current neuroscience to explain what \"thinking\" is. reply stavros 20 hours agorootparentprevThe difference is that your goldfish doesn&#x27;t look like it&#x27;s walking. I&#x27;m sure my door doesn&#x27;t think. I&#x27;m not sure the LLM doesn&#x27;t. reply antisthenes 19 hours agorootparent> I&#x27;m not sure the LLM doesn&#x27;t.If you turn off the power to the computer hosting the LLM, you can also be sure it doesn&#x27;t think. reply ben_w 20 hours agorootparentprevIt may be \"plainly and obviously\" different for you, but for me? I seem to have two components to my thinking process, one of which has ideas without needing words, another of which turns those ideas into words and gets (for lack of a better description) \"annoyed\" if I try to skip the word-generation part.There&#x27;s no reason to presume we all think the same way; rather the opposite, given how many ways in which humans are already known to think unalike to each other. reply jddj 20 hours agorootparentprevJust to throw the other side&#x27;s perspective of the argument into the ring, the ones reducing the observed phenomena to obviously anything can seem emotional and defensive of some metaphysical person-ness. reply marcus0x62 21 hours agorootparentprevYeah. Now, imagine the hubris required to think we&#x27;ve invented something we functionally cannot define. reply usernomdeguerre 20 hours agorootparentIsn&#x27;t scientific advancement inventing things we can&#x27;t fully define? Each working atop the other to define more? reply astrange 20 hours agorootparentprevThat&#x27;s pretty easy to do. We don&#x27;t know how Tylenol works. reply semi-extrinsic 20 hours agorootparentYes we do, it&#x27;s a cyclooxygenase inhibitor. E.g. from the abstract of [1]:\"The mode of action of paracetamol has been uncertain, but it is now generally accepted that it inhibits COX-1 and COX-2 through metabolism by the peroxidase function of these isoenzymes.\"Furthermore, the active ingredient in Tylenol is a very simple molecule from a synthetic perspective, and it was developed while trying to overcome the toxicity of an even simpler molecule called acetanilide. Even though it was developed 150 years ago, there was a systematic understanding of organic chemistry and the interaction with the human body already at that time.[1] https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s10787-013-0172-x reply tpush 4 hours agorootparentI mean, there&#x27;s plenty of other meds whose exact precise functioning we don&#x27;t know, just what results and side effects it has. reply marcus0x62 3 hours agorootparentprevWhen tylenol was invented, did the inventors have to precisely specify the molecular interactions between the compound and the human body in the same way a programmer has to precisely specify a program?No? Maybe the analogy you are suggesting isn’t the most accurate. reply __loam 18 hours agorootparentprevHumans invent things they don&#x27;t fully understand basically always. reply ryanklee 21 hours agorootparentprevGenerally, people in HN don&#x27;t let that small detail get in the way of making strong assertions on these matters.These threads are always massive, embarrassing trainwrecks of naive takes on cognition and consciousness.It&#x27;s like HN just woke up and refuses to acknowledge the relevance of the extensive prior literature on these subjects. Instead, people seem mostly fine with making shit up.Embarrassing. reply sho_hn 20 hours agorootparent> Embarrassing.It&#x27;s fine. We&#x27;re social animals, we discuss topics even if we lack perfect expertise, at our present level of understanding. I&#x27;ve certainly had, for example, many opinions on programming that were later superseded by deeper understanding or evolving priorities.It&#x27;s just important to remember there&#x27;s probably a bigger and better expert out there, and stay humble and interested, and let yourself be corrected. reply ryanklee 20 hours agorootparentYes, true, however, what I find egregious in this case is the comparative lack of standards.Among the other technical and scientific topics often discussed here, there is a basic general expectation of grounded reference to existing research and bodies of knowledge. Deviations from this standard are usually met with corrections.With the topic of cognition and consciousness, this is not so (generally). The standard is to absolutely not reference existing research and to basically pretend it doesn&#x27;t exist.Instead, the vacuum of ignorance is filled with whatever comes to mind and threads engage in freeform speculation.This is also ironic since these topics are usually about how LLMs don&#x27;t understand and just fill the vacuum of its ignorance with whatever happens to be next on the statistical chain, regardless of veracity. reply sho_hn 20 hours agorootparentI think it&#x27;s because a lot of people presume the topic at hand to be relatively novel and not have a significant body of work behind it. At to some extent this is because they have been told this is the case - even by experts or their reporters.With physics, for example, people have an understanding that there&#x27;s a large existing body of work, and that physics has been remarkably successful at building on earlier knowledge for decades without having to debunk a lot of earlier results. It&#x27;s a familiar story.With AI, however, the popular narrative is that earlier approaches to the problem were all laughing stocks that went nowhere. There&#x27;s not a good sense for how old some the ideas that work now actually are, and how many of the older theoretical and thought frameworks are still perfectly valid, in particular at the interfaces toward other branches of science and engineering. There&#x27;s some more nuanced and balanced primers on the topic (e.g. the Wooldridge book), but an awful lot more writing on AI Winters and what not.This snowballs into a lack of awareness of the overlap between \"AI\" and, say, the body of knowledge in statistics.In other words: Sure, I agree - HN collectively is less knowledge on this than on some other topics (myself included!), and it&#x27;s worth taking stock of that, I suppose. reply YeGoblynQueenne 19 hours agorootparentprevHang on. I&#x27;ve watched these trainwrecks for a while. The people who usually don&#x27;t let details get in their way are the ones who claim that LLMs think even though these same people can&#x27;t explain what thinking means.The onus [1] should go the other way.____________[1] Today&#x27;s conversation-derailing trivium: \"onus\" means ass in Greek. As in donkey.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Onager reply smokel 19 hours agorootparentI&#x27;m happy to be on the agnostic front.A colleague at my first job was working on some software that wrapped around other software, and he dubbed it \"Burrito\". When his project turned out not to be as useful as expected, he was pleasantly surprised that he could also use the original meaning of the word burrito, being \"little donkey\" in Spanish [1].[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Burrito reply YeGoblynQueenne 19 hours agorootparent:) reply ryanklee 19 hours agorootparentprevIt happens on both sides in equal measure. reply robertlagrant 19 hours agorootparentprev> Generally, people in HNThese silly generalisations about HN are pointless. HN has a pretty diverse set of worldviews, approaches, and levels of expertise across a range of topics. There is zero point in lumping people into a single, or even a majority, behaviour. reply ryanklee 19 hours agorootparentYeah, disagree. I read most threads on these topics, and although I can&#x27;t characterize people that don&#x27;t post, I can certainly attest to the generality I&#x27;m pointing out. I haven&#x27;t seen any discussions that defy it. They may exist, but they are atypical.The idea that generalities can&#x27;t be true or useful is pretty insidious, since it prevents reasoning about groups. reply robertlagrant 18 hours agorootparent> The idea that generalities can&#x27;t be true or useful is pretty insidiousThis idea was not mentioned, whether or not you attest that it was. reply smokel 19 hours agorootparentprevIt is unfortunate that HN is not very well suited for long-running discussions. A topic mostly dies out after about a day or less. Early reactions seem to score more karma, and that probably spurs people into writing hasty replies. To most, it is not worth it to perform a couple of hours of research before writing up a good reply.This means we have to be lucky to have some expert with current knowledge join in. Given that most people here are billionaires with a passion for dynamic typing, and not philosophers of mind, I am actually fairly surprised at the reasonable level of discussion.Also, I doubt that referencing prior literature in the context of cognition and consciousness would be of much help. HN writes a lot of nonsense about it, but so have many professional philosophers. After sifting through all of that, one still has to add a lot of convincing arguments to advance an unpopular opinion.A friend once suggested to build forum software that would allow discussions to reach a certain level of trustworthiness or truth. After several lengthy discussions I still doubt that such a thing is feasible. But it might spark your interest? :) reply bondarchuk 6 hours agorootparentprevCan you name some prior work that you think should be required reading here? I honestly don&#x27;t think there&#x27;s much if anything in the philosophy of consciousness that would be worth it. But maybe in cognition, not very familiar with it. reply maxdoop 19 hours agorootparentprevAnd generally, people like yourself make opposite claims with equally no backing.What does it mean to understand something? To think? How is a human any different than predicting the next “thing” given a series of inputs? reply ryanklee 19 hours agorootparentI didn&#x27;t make any claim other than that threads on this topic systematically disregard existing knowledge and research. And also, that I don&#x27;t think it&#x27;s justified. reply RC_ITR 20 hours agorootparentprevNo. We know exactly what \"text generators\" do and we also know that is not what the brain does. That can be true even if you don&#x27;t fully understand what the brain does.An easy way to prove the two are different is &#x27;What is the equivalent to the endocrine system for an LLM and why doesn&#x27;t it get tired like a mind?&#x27;The logical problems that a lot of people run into are twofold:1) At a very basic level, we modeled these architectures on brains (and named them after our brains), so at a very very basic metaphorical level, you can say &#x27;these things are acting like our brains act.&#x27; This ignores the complexity of the brain.2) We like to think that inconveniences of our minds (like the need for sleep) are \"problems\" that we can engineer away, rather than intrinsic components of the process. People won&#x27;t like hearing this, but there&#x27;s no formal reason why &#x27;the need to sleep&#x27; is not a necessary criteria for &#x27;being conscious,&#x27; because as far as we know, the only conscious beings out there also sleep. It&#x27;s just human nature to assume we can engineer the &#x27;good&#x27; parts of a biological system while avoiding the &#x27;bad&#x27; while still essentially replicating the system, but that&#x27;s usually not the case.[0]https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC2525690&#x2F; reply nomel 20 hours agorootparent> What is the equivalent to the endocrine system for an LLMAre you suggesting that the brain is the only implementation that can “think”? Or that an endocrine system is required?The difference isn’t the interesting, or necessarily useful, part; the practical similarities of the output are. If we can make a system that appears to \"think\", I can’t understand how it can be so easily dismissed when we don’t know what’s going on in it or us. reply RC_ITR 18 hours agorootparentI do think nervous systems (the brain being the most complex example we know of) are the only things that do what we call thinking.What else does (please do not mention any deterministic counting machines like semiconductors - neurons are not deterministic and thought isn’t a deterministic set of calculations).I would argue that the difference in process is extremely important, as evidenced by how easily we are fooled by optical illusions.Just because we think two things appear the same does not mean they are, and understanding why they appear the same but are different relies on a study of the “how”To put your argument differently - “if we can make drawings that appear to be three dimensional to our eyes, why bother understanding the difference between 2-D and 3-D space?” reply nomel 15 hours agorootparent> please do not mention any deterministic counting machines like semiconductors - neurons are not deterministic and thought isn’t a deterministic set of calculationsI have to mention it, because it&#x27;s physics, and related to the current implementation of LLMs: random numbers are possible, and used to break determinism. Intel CPUs use thermal noise to generate random numbers [1]. With silicon, randomness is a free choice, not an impossibility. LLMs front ends, like anything from OpenAI, use random numbers to get non-deterministic output, which is also the input of the next word, and the context of the next response, resulting in output that&#x27;s not deterministic, with broad divergence [2]. Both systems are somewhat bound by the \"sensibility\"&#x2F;logic of the output though, of course.> as evidenced by how easily we are fooled by optical illusionsThis isn&#x27;t neccesarily unique to humans [3]. Do you have a specific illusion in mind? Many are related to active \"baselining\", and other time response things, that happens in our eyes, with others being an incorrect resolution of real ambiguity, from a two sensor system, that any sensor system will struggle with.> Just because we think two things appear the same does not mean they areI don&#x27;t think anyone is suggesting they&#x27;re the same, but I see many people suggesting, with seemingly undue confidence, that they&#x27;re completely unrelated, which would require an understanding of either system that we don&#x27;t have.> To put your argument differently - ...My argument is, if it&#x27;s 3d to your eyes, then that understanding, and relation, between 2d and 3d space already exists in the system, to some degree.[1] https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;developer&#x2F;articles&#x2F;g...[2] https:&#x2F;&#x2F;www.coltsteele.com&#x2F;tips&#x2F;understanding-openai-s-tempe...[3] https:&#x2F;&#x2F;blog.frontiersin.org&#x2F;2018&#x2F;04&#x2F;26&#x2F;artificial-intellige... reply RC_ITR 14 hours agorootparentI know that there are various strategies for picking pseudo random numbers, but what I mean by determinism is that as far as we can tell, the activation trigger for a neuron is highly dependent on outside signals like hormones. That means that a biological “dot product” will be different if you are tired vs. well rested.A dot product run on Intel CPUs are intended to always be the same no matter what. The heat signature stuff isn’t changing the way circuits do math.As to optical illusions, the point I was making was that “the way humans practically perceive something” is not a sufficient way to measure the similarness of two things, since our perceptions are so often tricked (LLMs are literally trained specifically to trick you into thinking you’re talking to sentience).I also don’t think they are completely unrelated at all. As I said I know we designed one to be like the other. It’s just by no means “the same.” AI may one day do convergent evolution toward how brains think, but it’s still important to recognize that’s convergent evolution. reply nomel 10 hours agorootparentI see all of this as implementation details of a single biological system that exhibits \"thought\", not a definition of \"thought\".> It’s just by no means “the same.”The implementation is not the same. Everyone agrees with that. The concept being compared is \"thought\", not \"implementation of thought\". Maybe I&#x27;m lost. replywarkdarrior 20 hours agorootparentprevThe endocrime system is a tool to manage&#x2F;regulate the operation of a physical object (the human body). LLMs do not have a body or other physical object to manage, so they do not need endocrime systems. reply RC_ITR 18 hours agorootparentThe endocrine system has a huge impact on your brain and thought process. reply maxdoop 19 hours agorootparentprevWe know exactly what an LLM does? How does that differ from a brain? reply RC_ITR 18 hours agorootparentOne does deterministic matrix math and the other doesn’t.It’s a common experience that candy tasted sweeter to you as a child, right?How does that work in a transformer? reply hackinthebochs 17 hours agorootparentprevIn this[1] piece I argue that LLMs do, in some cases, demonstrate understanding.[1] https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;naturalism&#x2F;comments&#x2F;1236vzf reply Fleusal 20 hours agorootparentprevLLMs definitely show signs of understanding, though they might not be the sharpest tools in the shed right now. reply nomel 20 hours agorootparentThere’s a very good chance that many of these people have never used something like GPT-4, at all, or outside of treating it like google. This has been the conclusion of every other claim like that, stated with such certainty, that I’ve seen in the wild. reply maxdoop 19 hours agorootparentprevAnd what would it look like is something were capable of truly “understanding”? reply camdenlock 21 hours agorootparentprevAren’t humans text generators too? What makes you think the processes are so categorically different? reply crdrost 20 hours agorootparentThis is one of those topics that Searle wants folks to think straight about.He&#x27;d say: You are conscious. You are also a computer. You are not, as far as we can tell, conscious by virtue of being a computer. They&#x27;re just two things that happen to be true about you but they are not linked in that super-direct way.Similarly, you can think. And you can generate text. But you are not, as far as we can tell, thinking by virtue of generating text. reply the_gipsy 20 hours agorootparentHow can we tell? All I hear in my head is some monologue, or hypothetical dialogues with or between other persons. Sounds a lot like predicting text. reply cj 20 hours agorootparentI think very few people think one word at a time, like a LLM.A lot of people think in concepts without words at all in many scenarios. E.g. when you cook an egg, do you reason (in words) with yourself to decide what temperature to set the dial on the stove? Or do you just do it “without really thinking”?Does your brain respond with annoying disclaimers when asking yourself medical questions? Does your brain refuse to entertain an idea if it’s questionable? reply jddj 20 hours agorootparentObserve your thought process while reading the following sentences.If you&#x27;re not with us you&#x27;re...If you scratch my back I&#x27;ll..A bird in the hand is worth...What is a bird in the hand worth? How did you know that? reply danShumway 20 hours agorootparentI&#x27;m not sure what this is intended to demonstrate.Your response to \"not all problems are solved through generating text\" is \"but what if the problem is specifically to generate text?\" Sure? Yes, if you ask me to complete a sentence, I complete a sentence. That doesn&#x27;t indicate that human brains are reducible to text generators.If anything, what&#x27;s interesting about your example is that it might actually in some ways demonstrate the opposite of your point. How many instances are there of people memorizing text or song lyrics and singing along with an artist dozens of times, and only later sitting down and thinking about what the words actually mean? For humans, it&#x27;s well understood that memorization and repetition of a text is not necessarily the same thing as understanding the concepts within that text.I feel confident I could find you some kids that know that \"a bird in the hand is worth two in the bush\" that have never actually thought about what that phrase is intending to convey. reply jddj 19 hours agorootparentI didn&#x27;t ask you to complete a sentence, though. Just to read them. Then I asked a question.I think you&#x27;ve made my point quite well. reply danShumway 18 hours agorootparentI&#x27;m going to be completely honest, I still don&#x27;t know what your point is.That humans are capable of memorizing text? Is that a thing anyone was debating? reply jddj 18 hours agorootparentDrawing a line around the bits that aren&#x27;t language generation unfairly ignores the massive apparatus that seems to be specialised (oftentimes overly so) at language generation.Sure there&#x27;s other stuff going on, but a lot of it is language and a lot of that subset seems to be quite closely approximated by these larger LLMs, warts and all. reply danShumway 18 hours agorootparentHold on a sec, think about what you&#x27;re saying. The ability of a larger system to imitate a smaller system in some situations means they&#x27;re they&#x27;re mostly the same? Since when?If I told you that an LLM was basically a Markov chain because there are situations where the Markov chain and LLM produce similar output and where you could reasonably argue that it&#x27;s possible the LLM is working the same way that the Markov chain is working -- you would (correctly) say I was oversimplifying what&#x27;s going on in GPT. It would be a terrible comparison to make. Similarly, if you say that human reasoning is the result of an LLM, and what you&#x27;re actually saying is that in a subset of situations humans produce output that could theoretically be working the same way as an LLM, I&#x27;m gonna say you&#x27;re oversimplifying how human brains work.Very clearly, there is more going on in a human brain than language, evidenced by the fact that our brains are larger than our language centers and we can literally measure which parts of the human brain experience the most activity when we&#x27;re tackling different tasks.> Sure there&#x27;s other stuff going on, but a lot of it is language and a lot of that subset seems to be quite closely approximated by these larger LLMs, warts and allIf you define your tests and scenarios to specifically encompass only the situations in which similar outputs are produced, then sure. But that&#x27;s not a very strong argument for you to make. It&#x27;s like saying chickens are basically the same as fish since both of them lay eggs. The phrase \"sure there&#x27;s other stuff\" is doing a lot of work there, because \"there&#x27;s other stuff\" is what we&#x27;re all saying when we say that LLMs aren&#x27;t just primitive humans -- LLMs are different from humans in the sense that when we reason, there&#x27;s other stuff going on and the entire process is not reducible to only language generation.----Of course, absent from this conversation is the fact that the way our language center develops is different from how LLMs are trained and even in the parallels you&#x27;re drawing, LLMs demonstrate different strengths and weaknesses from humans -- humans demonstrate reasoning capabilities faster than proficiency with language&#x2F;text, LLMs demonstrate proficiency with text faster than they demonstrate reasoning capabilities. Even in situations where both LLMs and humans predict text, it&#x27;s likely that we&#x27;re using different strategies to do so given our differing capabilities.Look I am not even making a claim about whether GPT can reason. Defining intelligence through a purely human lens would be unimaginative and needlessly narrow. Whether GPT actually reasons or just appears to is a different conversation. I haven&#x27;t touched that conversation, all that I&#x27;m saying is, it&#x27;s very obvious that whatever GPT is doing, it is different from how human brains work. reply jddj 9 hours agorootparentI can agree with all of that.I was pushing back against something that might not have been there initially: an unwillingness to accommodate the idea that a fairly significant part of our intelligence is actually stored in our language and that it can seem subjectively (perhaps excluding those with no internal monologue) that we recall that knowledge in a manner which is close enough to the one we have managed to replicate in the larger LLMs.This part of our function could well be a lazy optimization that in reality sits on top of our reasoning capabilities to save energy, but the point of the trite task with the bird in the hand was just to demonstrate that it seems to play a fairly significant role. I&#x27;m out of my depth entirely with respect to the actual form and function of the brain as per the state of research today.I&#x27;m willing to admit though that when I replied to you I was probably really replying to a lot of other commenters, many of whom had stronger objections to the idea that LLMs are now knocking on the door of intelligence at least to the point where we feel the need to redefine it. replycolonCapitalDee 20 hours agorootparentprev> A lot of people think in concepts without words at all in many scenarios.Many scenarios, not all scenarios. reply danShumway 20 hours agorootparentprevThere is debate over whether or not every person has an internal monologue, and a nontrivial number of people self-report that they don&#x27;t experience conscious dialogs while they think: https:&#x2F;&#x2F;www.verywellmind.com&#x2F;does-everyone-have-an-inner-mon...It&#x27;s certainly possible that they&#x27;re wrong, but my suspicion is that at the very least the form their internal monologue is taking is not one of consciously simulating hypothetical conversations in their head.Additionally, we know that human decisions can in some situations be influenced by stimuli that take effect before the brain has even consciously registered that a decision needs to be made. It seems pretty safe to say that those stimuli are not being processed using a language model. reply nomel 20 hours agorootparent> It seems pretty safe to say that those stimuli are not being processed using a language model.Could you expand on that? I don’t see how it follows. If there is unconscious output, why wouldn’t it suggest there’s something analogous to a “unthinking” language model stuck behind our conscious, self reflective, bits? How does unconscious output prove that it’s not something similar to a language model?Or, are you speaking on a technicality, saying it’s not a literal language model? I think the idea is something similar and, obviously, multi modal, not a literal LLM&#x2F;text predictor implementation like runs on GPUs. reply eichin 18 hours agorootparentIsn&#x27;t this the essence of teddy-bear&#x2F;rubber-duck debugging? You&#x27;re forcing yourself to run your abstract concepts through the narrow channel of language and instantiating it in a way you haven&#x27;t previously done (because if you had, you&#x27;d have solved the problem already and wouldn&#x27;t need to be talking it through.) (I&#x27;m very specifically talking about the case where you explain and noone else contributes&#x2F;responds, and you come up with the answer solely through trying to explain&#x2F;speak it.) reply danShumway 19 hours agorootparentprevShort answer, the responses are happening too fast for that stimuli to be going through the language centers of our brain. In order to say that the processing of that stimuli is like a language model, we would need to widen our definition of a language model to encompass basically any communication between neurons happening within the brain.----So on one hand, you could call that a technicality, on the other hand I would say that if we reduce \"like an LLM\" to mean \"responds to a stimuli by generating a response\", at that point \"like an LLM\" is so broad as to be meaningless. Sure, we can define \"humans use a language model\" as \"human brains generate signals to other parts of the human brain in response to stimuli\" -- but that&#x27;s not really a useful thing to say when we&#x27;re comparing human reasoning to GPT-4.If we&#x27;re talking so broadly about reasoning, then it would be just as accurate to say that human brains are like Markov chains. After all, Markov chains interpret inputs and transform them into other signals that they send to other parts of the chain. But if I told you that GPT-4 was just a Markov chain you would (rightfully) disagree with me on that and you would (rightfully) say that I was oversimplifying what&#x27;s going on within GPT-4&#x27;s model.Typically, when people say that human beings are text generators, they&#x27;re talking in the context of GPT-4; they&#x27;re trying to claim that GPT-4&#x27;s behavior is analogous to human behavior. Whether or not GPT-4 can reason under any definition of reasoning (direct analogy to human thought should not be the only way we think about reasoning), the way GPT works and the way that it&#x27;s trained and taught is extremely alien to how human brains work and how humans learn. Broadening the definition doesn&#x27;t change the fact that LLMs and human brains are very different in practical ways that influence their observable behaviors.----I don&#x27;t think people are consciously trying to do this, but the debate over whether humans are LLMs often ends up feeling like an attempt to simultaneously broaden and narrow a definition at the same time. What people seem to want to do is to describe LLMs extremely broadly but then assume that conclusions they draw from that broad definition are necessarily applicable to a very narrow definition of an LLM (specifically, GPT and similar models). But once we define an LLM broadly enough to encompass the entirety of human reasoning, we have also broadened the category enough to encompass a lot of processes that no one would call reasoning. What doesn&#x27;t transform inputs into other forms and pass them along to another object? An AC&#x2F;DC electrical converter does that, but that doesn&#x27;t mean it can think.It&#x27;s like claiming, \"computers are made of carbon and so are humans, so computers are basically the same as humans.\" Well, wait a second -- the category as you&#x27;ve defined it is so broad that objects within that category can no longer be assumed to share other attributes with each other. reply nomel 15 hours agorootparent> to be going through the language centers of our brain.> \"like an LLM\" is so broad as to be meaningless.I don&#x27;t think this is a fair interpretation, in the context of this comment chain. To me, a charitable interpretation is that \"like an LLM\" means no feedback loop, no refinement, just input to output, like an LLM.I point my brain at problems, using my conscious intent, and I see answers. I don&#x27;t really consider myself consciously involved in those answers, and I do have to check them, and sometimes iterate, with that iteration almost always involving some solidification of the answers&#x2F;concepts by externalizing them in writing, drawing, etc. Point at solidification, get response, repeat. The \"me\" in my head is the one talking, pointing, receiving, checking, and mixing. The \"here&#x27;s your answer\" intuition that I experience is the \"like an LLM thing\". My understanding of my own thought process follows the historic interpretation: the pre-frontal cortex is a new attachment, and probably the one that is the active participant, and planner, that is \"me\". The fast, but unrefined, input->output system being the rest of it, and is probably closer to the experience of a monkeys day to day activities. reply danShumway 12 hours agorootparent> \"like an LLM\" means no feedback loop, no refinement, just input to output, like an LLM.But that&#x27;s not what an LLM is, an LLM is a large language model. The distinguishing characteristics between an LLM and other AIs are not whether or not an LLM has a feedback loop. Lots of AI categories (arguably the majority of AIs) generate output from a single set of inputs as a single \"operation\" (ignoring the fact that most neural networks including LLMs internally have multiple layers and do in fact have multiple transformation steps, but whatever, we can treat that as one step for the purposes of conversation).If anything, LLMs are the exception here in that they very often do have a feedback loop during normal usage; they are most commonly used in a conversational context where they generate the next \"chunk\" of a conversation after being fed back their previous answers alongside the followup responses of the person working with them. Arguably the feedback loop of an LLM is that as a conversation progresses, its future output is based on its previous output, which very literally becomes its new input after being marked up and extended by a human being. That is notably more feedback than many other AIs get.Doubly so if you&#x27;re trying to argue that an LLM can encompass a multi-modal setup, because suddenly refinement and feedback between multiple models is a core part of the final product.So I&#x27;m not sure I agree that an LLM fits into that category in the first place, but even assuming it does, if your definition of an LLM is is just that it takes an input and turns it into an output as a single step without help... that is just such a broad category, I would guess the majority of AIs fall into that category. It&#x27;s not what makes LLMs special; most predictive neural networks take a single set of inputs and generate a single set of outputs without intermediary human input. What makes LLMs interesting as a category is the training and structure and quirks of how they work, what makes them interesting is the differences between LLMs and other AI techniques.To jump back to the Markov chain again, Markov chains do not have a feedback loop or refinement step: they take an input and map it to an output as a single step. Are Markov chains LLMs? Is any data transformer that operates in a single step an LLM? That is a really broad definition to use.----And we run into the same problems, because if you&#x27;re arguing that a human brain is like an LLM and what you&#x27;re really saying is, \"it&#x27;s kind of like an AI in general\" -- well, that doesn&#x27;t really say anything about whether a human brain is specifically similar to a system like GPT. There are lots of different ways to build a neural network, LLMs are one strategy.When you say this:> The \"here&#x27;s your answer\" intuition that I experience is the \"like an LLM thing\".What this sentence is actually saying is that you experience conclusions and knowledge where you don&#x27;t know the source or where the process of your brain generating a decision or information happens unconsciously. The sentence is just saying that there are unconscious parts of your brain where you are not an active participant in the thinking process and it feels like the a spontaneous transformation from input to output.But does that really strike you as a strong indicator that your brain is like an LLM, or does that sound more like a general description of almost any black-box system where the mechanisms are hidden and you can only examine the inputs and outputs? To say that there are parts of our thinking process that we&#x27;re not able to consciously observe or examine is really just saying that parts of our thinking process resemble a black-box oracle. It&#x27;s not making a strong claim about GPT. reply the_gipsy 19 hours agorootparentprevInternal monologue can only be self-reported, and I kind of feel like telling someone that says they are ill that it&#x27;s just all in their head, but... I don&#x27;t think that any functioning human could possibly have no internal monologue, just lack of introspection. reply pineaux 20 hours agorootparentprevI dont think in words at all. That is why -quite often- I know what i want to tell but the correct word just doesnt pop up in my head. I can then explain the concept and other people can help me find the word in question. Even while writing this little response, this happened. You see in the first sentence: I know there is a nice word that could be used instead of \"doesn&#x27;t pop up\" it resembles the word \"evades\"? You know when something just keeps out of your grasp, that word... my mind does a little movie and my \"mouthbrain\" tries to find the nice words for it. That is how I perceive it to be. I dont know how other people perceive this. I imagine they have little words popping up or something. But I dont understand how that kind of thinking could be used to think and reason. How can relationships between concepts be intuitively understood if one does not have a mental picture? reply the_gipsy 19 hours agorootparentDo \"relationships between concepts\" have any meaning, for us humans, if we can&#x27;t express them? reply cj 19 hours agorootparentHumans can express them.But we rarely do, outside of (maybe) therapy. reply bondarchuk 20 hours agorootparentprevBut Searle also believes obviously wrong things like the Chinese room argument. reply fragmede 19 hours agorootparentIf it were so obviously wrong, there wouldn&#x27;t be so much debate over it. reply danShumway 20 hours agorootparentprevInfants demonstrate reasoning capabilities before they learn language skills. Human reasoning is not derivative of language generation, and it&#x27;s certainly not derivative of text generation (illiterate humans are still capable of reasoning). Humans demonstrate reasoning even in the absence of language skills.LLMs approach learning differently -- whatever reasoning they do possess is an emergent property that arises as they get better and better at language generation. In other words, unlike humans, LLMs learn to \"speak\" before they exhibit behaviors that look like logical reasoning. Humans do the opposite. reply jppittma 20 hours agorootparentMy blind speculation would be that this property is likely to disappear as more and more text is written by non-thinking agents. Most text on the internet prior to 2022 was written by an agent capable of thinking. That may not be true going forward. reply init2null 20 hours agorootparentI&#x27;ve been wondering the same thing. It&#x27;s possible that older pre-LLM data sources may become indispensable for training.It would be both amusing and disturbing to see older Usenet, Slashdot, and Reddit conversations turned into rare and valuable resources. reply grumbel 20 hours agorootparentprevOne big difference is that LLMs don&#x27;t do loops, new words are produced in a fixed amount of steps. They can&#x27;t go \"give me a minute\", think for a bit in the background and come back with an answer. That&#x27;s why you can often get better answers when you force them to go through the individual steps, as that allows them to use the prompt history as working memory.That said, this all seems like a &#x27;fallacy of composition&#x27;. Humans are not LLMs, so much should be obvious, but at the same time concluding that they are completely different just feels wrong. The mistakes LLMs make feel very similar to what humans do when they don&#x27;t have the time to deeply think about a problem and just give you the best guess that pops into their head. Humans will have other systems on top that allow them deeper reasoning, but the language generation really doesn&#x27;t feel all that different from what LLMs do.That aside, humans interact with the world, they get instant feedback on what of their predictions is right or wrong. LLMs are stuck with just static training data that might simply not be enough to develop higher level reasoning skills. reply wouldbecouldbe 21 hours agorootparentprevMachines of meaning probably, text generation is more a side effect or maybe a feature, but not the core of our reasoning let alone being. reply skepticATX 21 hours agorootparentprevImagine solving a tough math problem. Are you generating text, or doing something else entirely? reply mike00632 20 hours agorootparentI just asked Chat GPT 3.5 the following: \"Please give an exponential equation that has integer solutions which is difficult to solve.\", and the response is: \"Certainly, here&#x27;s an exponential equation that can be challenging to solve for integer solutions:2^x+3^y=7^zThis equation involves three variables, x, y, and z, and requires finding integer values for these variables that satisfy the equation. This type of equation is known as a Diophantine equation, and solving it can be quite challenging, especially for larger values of x, y, and z.\" reply crdrost 20 hours agorootparentThat&#x27;s quite the nerd snipe.I mean, it&#x27;s definitely not a Diophantin",
    "originSummary": [
      "A recent study by Google DeepMind and the University of Illinois challenged the current understanding of self-correction in large language models (LLMs), revealing they often struggle to refine their answers without external feedback.",
      "The study suggests self-correction in LLMs is more effective when they can utilize external sources like human feedback or a knowledge base; without such, their performance significantly drops.",
      "The research also stresses the significance of well-designed initial prompts for LLMs and the cautious application of self-correction to enhance their accuracy and reliability, especially in tasks like altering the LLM's stylistic output or ensuring safer responses."
    ],
    "commentSummary": [
      "The discussions focus on the limitations of Language Models (LLMs) in emulating human intelligence, questioning whether they truly understand or reason.",
      "The importance of defining terminologies to avoid LLMs hype is stressed, emphasizing the gap between human cognition and artificial intelligence.",
      "The call for further research and clearer understanding underpins the concept, implying the complexity of AI systems and the notable differences from human cognition."
    ],
    "points": 161,
    "commentCount": 319,
    "retryCount": 0,
    "time": 1696876111
  }
]
