[
    {
        "id": 36069847,
        "timestamp": 1685017362,
        "title": "Everything you always wanted to know about mathematics (2013) [pdf]",
        "url": "https://www.math.cmu.edu/~jmackey/151_128/bws_book.pdf",
        "hn_url": "http://news.ycombinator.com/item?id=36069847",
        "content": "",
        "summary": "",
        "hn_title": "Everything you always wanted to know about mathematics (2013) [pdf]",
        "original_title": "Everything you always wanted to know about mathematics (2013) [pdf]",
        "score": 751,
        "hn_content": "The post discusses a math textbook used in a first-semester course for CS and math undergrads at Carnegie Mellon University. The book, available on the provided link, includes an introduction to each chapter to contextualize the topic, making it conversational in tone. Several related books are also mentioned in the comments section, with links provided. Additionally, several people recommend courses or textbooks for those wishing to learn math, ranging from high school to university-level, and some are skeptical about their effectiveness. Lastly, a book on computer systems, Computer Systems: A Programmer's Perspective, is highly recommended by a few commenters, who suggest it as a must-have for those learning to program.A list of resources for individuals interested in studying mathematics; includes books, websites, and online courses, such as 'No Bullshit Guide to Math and Physics' and Kahn Academy's math curriculum; individuals recommend various sources based on their experience and interests; some individuals suggest ways to approach studying mathematics, such as connecting it to solving interesting problems or revising material on a schedule.A recent thread on Hacker News discussed the best way to create high-quality physical copies of electronic books. The thread mentions various services that provide high-quality printing options. The thread is notable for its diverse array of recommendations and suggestions. Some commenters mentioned using software with PDF reflow functionality, while others recommended tablets specifically designed for e-reading. Overall, the thread is a valuable resource for those interested in creating physical copies of their favorite eBooks or other digital media.",
        "hn_summary": "- 'Everything you always wanted to know about mathematics' is a math textbook used in a first-semester course for CS and math undergrads at Carnegie Mellon University.\n- The book includes an introduction to each chapter to make it more conversational in tone.\n- Commenters recommend various resources for studying math, including books, websites, and online courses, as well as offering tips for approaching the subject."
    },
    {
        "id": 36075886,
        "timestamp": 1685047105,
        "title": "Whistleblower drops 100 GB of Tesla secrets to German news site",
        "url": "https://jalopnik.com/whistleblower-drops-100-gigabytes-of-tesla-secrets-to-g-1850476542",
        "hn_url": "http://news.ycombinator.com/item?id=36075886",
        "content": "THE A.V. CLUBDEADSPINGIZMODOJALOPNIKJEZEBELKOTAKUQUARTZTHE ROOTTHE TAKEOUTTHE ONIONTHE INVENTORYThe Cult of Cars, Racing and Everything That Moves You.HOMELATESTREVIEWSUNPAVEDBUYINGTECHCULTURETRUCKSWe may earn a commission from links on this pageNEWSWhistleblower Drops 100 Gigabytes Of Tesla Secrets To German News Site: ReportThe files contain over 1,000 accident reports involving phantom braking or unintended acceleration--mostly in the U.S. and Germany.ByErin MarquisPublishedYesterdayComments (21)AlertsA \u2018Tesla Street\u2019 sign stands near a plot of land at the Tesla Inc. Gigafactory construction site in Gruenheide, Germany, on Wednesday, Sept. 2, 2020.Photo: Krisztian Bocsi/Bloomberg (Getty Images)A German news outlet sifted through over 23,000 of Tesla\u2019s internal files and found a disturbing trend of brushing off customers complaining about dangerous Autopilot glitches while covering the company\u2019s ass.The publication Handelsblatt got its hands on the data through an unnamed informant. Handelsblatt confirmed the data\u2019s authenticity with Fraunhofer Institute for Secure Information Technology, which found no evidence of doctoring or fabrication in the files. Tesla attempted to stop the publication from using this data in its reporting and even threatened legal action against Handelsblatt. The publication, however, decided this was one of the extraordinary circumstances when reporting on such a data breach would be legal under European Union law.It posted \u201cMy autopilot almost killed me\u201d: Tesla files cast doubt on Elon Musk\u2019s promises on Thursday. The story is both in German and behind a paywall, but the English translation is of excellent quality. Here\u2019s a bit of the meat of it:The Tesla files contain more than 2,400 self-acceleration complaints and more than 1,500 braking function problems, including 139 cases of unintentional emergency braking and 383 reported phantom stops resulting from false collision warnings. The number of crashes is more than 1000. A table of incidents involving driver assistance systems where customers have expressed safety concerns has more than 3000 entries.The oldest complaints available to the Handelsblatt date from 2015, the most recent from March 2022. During this period, Tesla delivered around 2.6 million vehicles with the autopilot software. Most of the incidents took place in the US , but there are also complaints from Europe and Asia in the documents - including many from German Tesla drivers.The Handelsblatt contacted dozens of customers from several countries. All confirmed the information from the Tesla files. In discussions, they gave insights into their experiences with the autopilot. Some disclosed their communication with the US automaker, others showed Handelsblatt reporters videos of the accident.Customers from the U.S. and Europe told Handelsblatt Tesla wasn\u2019t too interested in assisting with their issues, but seemed more intent on covering for the company. It turns out, this was explicit policy at Tesla:How did the company deal with complaints? The Tesla files also provide information about this. The files show that employees have precise guidelines for communicating with customers. The top priority is obviously: offer as little attack surface as possible.For each incident there are bullet points for the \u201ctechnical review\u201d. The employees who enter this review into the system regularly make it clear that the report is \u201cfor internal use only\u201d. Each entry also contains a note in bold type that information, if at all, may only be passed on \u201cVERBALLY to the customer\u201d.\u201cDo not copy and paste the report below into an email, text message, or leave it in a voicemail to the customer,\u201d it said. Vehicle data should also not be released without permission. If, despite the advice, \u201can involvement of a lawyer cannot be prevented\u201d, this must be recorded.Customers that Handelsblatt spoke to have the impression that Tesla employees avoid written communication. \u201cThey never sent emails, everything was always verbal,\u201d says the doctor from California, whose Tesla said it accelerated on its own in the fall of 2021 and crashed into two concrete pillars.Throughout the report, there is a refrain familiar to anyone who covers Tesla: \u201cTesla did not answer questions about the allegations from customers.\u201d Some told Handelsblatt they either sold their Teslas or tried to give them back to the company, saying they couldn\u2019t in good conscience let anyone else drive the car.Elon Musk and Tesla had a hell of a 2022, and this year is shaping up to be no different. It was revealed a 2016 video of a self-driving Tesla was likely a hoax made with Musk\u2019s approval and participation. Multiple lawsuits from everyone from shareholders to surviving family members of crash victims, are about to have their day in court. The National Highway Traffic Safety Administration and Department of Justice are closing in.The report goes into breathtaking detail of just about every hurdle Tesla is facing right now, and you can read the whole report in German and English here.Show all 21 commentsContinue reading",
        "summary": "- A whistleblower leaked over 23,000 internal files from Tesla to a German news outlet, revealing a pattern of dangerous Autopilot glitches allegedly ignored by the company.\n- The files contain more than 2,400 self-acceleration complaints and over 1,500 braking function problems, including phantom braking or unintended acceleration, with over 1,000 accident reports filed--mostly in the U.S. and Germany.\n- Handelsblatt confirmed the authenticity of the data with the Fraunhofer Institute for Secure Information Technology, which found no evidence of doctoring or fabrication. Tesla tried to block the story but Handelsblatt published it, citing the urgent matter of public interest under European Union law.",
        "hn_title": "Whistleblower drops 100 GB of Tesla secrets to German news site",
        "original_title": "Whistleblower drops 100 GB of Tesla secrets to German news site",
        "score": 495,
        "hn_content": "A whistleblower has leaked 100 GB of confidential Tesla documents to a German news site.\n\nSome internal documents suggest Tesla's self-driving software has systematic failure modes, which could harm their reputation in the future.\n\nInvestors disagree with Tesla CEO Elon Musk's claim that self-driving cars will quintuple in value, but some praise his success formula of overhype, delays, and eventual achievement.\n\nTesla's head start in the electric car industry is a significant advantage, but other manufacturers are catching up and producing electric trucks.\n\nDespite Tesla's outstanding accomplishments, Musk's behavior shows him to be capricious and callous.\n\nTesla's share of the overall automotive market is growing, but their share of the EV car market is shrinking, which could be a bad sign.No clear central topic or story. A range of comments on various topics such as Tesla, Elon Musk, Starlink, self-driving cars, and the valuation of companies. Some comments are critical of Musk and his companies, while others defend him. Some discussions are about the feasibility and impact of self-driving cars, while others are about stock valuation and investment strategies. There is some mention of the role of public and private investment in technological innovation.The value of a car does not increase with increased usage, as cars need to be serviced and replaced independently of usage. Driving in harsh environments with heavy salt damage can also significantly decrease the value of a car. The idea of self-driving cars increasing the value of a car is difficult to determine and largely dependent on the specific market. Ride-sharing companies may be able to benefit from self-driving cars, but personal car owners may not see the same benefit. Tesla's current self-driving technology has received some criticism, and their approach without LIDAR sensors has been a point of contention. LIDAR can be expensive and is not a historically standard feature in cars.Leaks from Tesla reveal more than 2,400 self-acceleration issues, 1,500 problems with braking function, and over 1,000 accidents involving Tesla vehicles. Some are concerned about Tesla\u2019s self-driving technology, as it lacks LiDAR and radar, and its performance is inferior to Waymo and Cruise. However, some argue that Tesla has already shown the world how to make commercial electric vehicles viable. Although Tesla reports fewer safety issues than its peers, detractors say the number of incidents should still be taken seriously. Concerns about Tesla\u2019s reliability and safety have led some to argue that the company\u2019s cars should be auditable by independent experts and controllable by the end-user. Despite criticisms, Tesla\u2019s safety record remains solid.- Public transport should prioritize fully autonomous, small electric trains combined with exercise and movement\n- Ebikes may generate tire dust, but bikes weigh less than automobiles and generate less dust\n- Bicycles are a mainstream public transport solution in cities like Copenhagen and Amsterdam\n- Most people want high-tech features in their cars, which is why even ICE vehicles have them\n- The flashy bells and whistles on electric cars compensate for their lagging range compared to gasoline cars\n- While suburban sprawl is entirely car-focused, people need cars to get outside cities\n- One can buy a used car and convert it to EV, but it's a very manual task and cannot be scaled easily\n- Whistleblower information tends to weaken the maker's ability to deny knowledge of a product's defects.A discussion about liability claims for defective firearms raises questions about the safety of self-driving cars. Some argue that Tesla's Full Self-Driving (FSD) technology is superior to bad human drivers, but some are skeptical, citing videos of FSD failing in ordinary situations. The issue of liability is raised, with some suggesting that Tesla should be legally responsible if their technology causes harm. Others argue that statistical evidence of safety should be used to judge Tesla's products, as it is for other manufacturers. However, there are concerns about the quality of the statistics and possible biases. Overall, the discussion highlights ongoing debates about the safety, regulation, and liability of self-driving cars.Tesla cars are experiencing a rise in insurance costs due to the high cost of replacement parts. However, despite this, Tesla owners are not causing many collisions. Some critics argue that Tesla's behavior toward customers is flagrantly customer-hostile to the point of probable illegality, with an official policy to deprive customers of information. The concept of FOSS self-driving cars has been discussed, but it is challenging to achieve as the safety verification process needs to be thorough and costly. The automaker's production of dangerous products has been compared to those of other automakers in the past. \n\nKey points: \n- Tesla cars have expensive replacement parts leading to a rise in insurance costs \n- Critics argue Tesla behaves in a customer-hostile way, depriving customers of information \n- FOSS self-driving cars are challenging to achieve due to costly safety verification \n- Comparisons have been made between Tesla's actions and those of other automakers in the past.",
        "hn_summary": "- A whistleblower has leaked 100 GB of confidential Tesla documents revealing potential systematic failures in the company's self-driving software.\n- Tesla CEO Elon Musk's claim that self-driving cars will quintuple in value is disputed by investors, but some praise his success formula of overhype, delays, and eventual achievement.\n- Tesla's share of the overall automotive market is growing, but their share of the EV car market is shrinking, which could be a bad sign. Additionally, Tesla cars have expensive replacement parts leading to a rise in insurance costs, and critics argue Tesla behaves in a customer-hostile way, depriving customers of information."
    },
    {
        "id": 36072268,
        "timestamp": 1685029640,
        "title": "AI Canon",
        "url": "https://a16z.com/2023/05/25/ai-canon/",
        "hn_url": "http://news.ycombinator.com/item?id=36072268",
        "content": "The Tech Times has curated a list of resources known as the AI Canon that covers the most important parts of the modern AI wave. The AI Canon includes a gentle introduction and foundational learning material, deep dive resources, practical guides to building with LLMs, market analysis, and a list of landmark research results. Key papers include \"Attention is All You Need,\" which introduced transformer models and generative AI, and \"Language models are few-shot learners,\" which describes GPT-3 and the decoder-only architecture of modern LLMs. The AI Canon also includes a reference list of landmark research results covering large language models, including Google's LaMDA and OpenAI's GPT-4.- Stanford's model (2023) shows the efficacy of instruction tuning in small open-source models.\n- Deep reinforcement learning from human preferences (2017) proves beneficial in gaming and robotics contexts for Language and Learning models (LLMs).\n- Developed by Facebook, RAG (2020) and RETRO developed by DeepMind (2021) prove to be highly successful in improving LLM accuracy through information retrieval.\n- Microsoft's LoRA model (2021) is an efficient alternative for training LLMs on new data.\n- Constitutional AI (2022) proposes the concept of autonomous and harmless AI assistants with the supervision of other AIs.\n- Various platforms including Stanford's FlashAttention (2022), Hungry hungry hippos (2022), and ControlNet (2023) enhance LLMs' abilities to learn and forecast.\n- AI Generative agents, Reflexion, Toolformer, and Auto-GPT (all 2023) from researchers at Google, Northeastern University, and Meta seek to improve LLMs' skills through self-reflection, autonomous experimentation, and problem-solving.\n- Various researches from Google, OpenAI, UC-Berkeley, and DeepMind (2020-2023) aim to develop highly efficient and successful techniques for generating code, videos, images, and audio.\n- Work from DeepMind (2020), and Med-PaLM (2022) aims to enhance the medical field through better protein structure prediction, and language model capable of answering USMLE style questions.",
        "summary": "- The AI Canon is a collection of resources that cover the most important parts of modern AI.\n- It includes foundational learning material, practical guides, market analysis, and landmark research results.\n- Key papers cover transformer models, generative AI, and modern LLMs, including GPT-3.\n- Landmark research results include Google's LaMDA and OpenAI's GPT-4, among others.\n- Various models, including Stanford's and Facebook's, aim to improve LLM accuracy through information retrieval.\n- Constitutional AI proposes the idea of autonomous and harmless AI assistants, and various platforms enhance LLMs' forecasting abilities.\n- Generative agents from Google, Northeastern University, and Meta seek to improve LLMs' skills.\n- Research aims to develop techniques for generating code, videos, images, and audio.\n- Work from DeepMind and Med-PaLM aims to enhance the medical field through protein structure prediction and language models capable of answering USMLE style questions.",
        "hn_title": "AI Canon",
        "original_title": "AI Canon",
        "score": 471,
        "hn_content": "Hacker News readers discuss generative AI and articles from venture capital firm a16z on the topic. The discussion diverges into criticism of a16z's investment practices, as well as opinions on affordable housing and celebrity privacy. Some readers offer additional resources on generative AI, including textbooksThe discussion covers a range of topics related to VC investment strategies and skepticism towards particular firms. A16z's investment thesis is noted as being centered around finding the next bagholder for their investments, which is not unusual for VC firms. However, there are criticisms about a lack of focus on adding value to businesses and instead inflating hype. The discussion also includes comments about crypto and AI resources, with one user expressing skepticism towards the former and another noting that the latter is a useful list of links. There are mentions of A16z's reputation and past investments, including the Adam Neumann saga. Overall, the discussion provides insight into various factors at play within the VC world and how investors are perceived.Readers on Hacker News are expressing their negative sentiments towards venture capital firm a16z and its partners, especially co-founder Marc Andreessen. Many commenters cite a16z's poor investments, excessive hype, questionable behavior, and obnoxious behavior as reasons for their disapproval. They also criticize the firm's forays into cryptocurrency, NFTs, and Web3, which they view as scams that bilked everyday people. However, some readers suggest that a16z is not alone in their dislike among venture capitalists, and that competitors like SoftBank and Sequoia Capital have also faced similar criticisms.Venture capital firm, Andreessen Horowitz (a16z), has released an \"AI Canon,\" a list of the 50 best resources, both academic and commercial, for understanding artificial intelligence (AI). Among the resource list are distinct areas of AI, including natural language processing (NLP), computer vision, and robotics, and topics such as self-driving cars, quantum computing and the ethics of AI. The list also includes blogs and media outlets that cover AI, while software and platforms that rely on AI to operate are also included. Critics have called into question whether the inclusion of certain resources is truly indicative of the best resources and whether the term \"Canon\" is accurate.Venture capital firm Andreessen Horowitz's crypto fund returned almost five times for early investors. The firm sold a portion of its tokens before the bear market began in May, guaranteeing success for early investors. A16Z invests in private tech firms as a way to accumulate wealth via insider trading. The AI Canon, a collection of AI resources, has been published by A16Z, and some argue it leaves out landmark AI results before 2017. A list of articles compiled by A16Z contains important information for those interested in AI and tech. Some might find these resources useful, such as the comic explainer of stable diffusion.",
        "hn_summary": "- Venture capital firm a16z has released an \"AI Canon,\" a list of the 50 best resources for understanding AI that covers distinct areas of AI and software and platforms that rely on AI to operate.\n- Hacker News readers criticize a16z's investment practices and past performance, with some expressing disapproval of its involvement in cryptocurrency, NFTs, and Web3.\n- Some readers offer additional resources on generative AI, including textbooks, while others discuss skepticism towards crypto and praise the AI Canon as a useful list of links."
    },
    {
        "id": 36068850,
        "timestamp": 1685009198,
        "title": "How to Finetune GPT-Like Large Language Models on a Custom Dataset",
        "url": "https://lightning.ai/pages/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/",
        "hn_url": "http://news.ycombinator.com/item?id=36068850",
        "content": "How To Finetune GPT Like Large Language Models on a Custom DatasetPosted on May 19, 2023 by Aniket Maurya - Blog, TutorialsTakeawaysLearn how to fine-tune large language models (LLMs) on a custom dataset. We will be using Lit-Parrot, a nanoGPT based implementation of the GPT-NeoXmodel that supports \u2013 StableLM, Pythia, and RedPajama-INCITE model weights.The AI community\u2019s effort has led to the development of many high-quality open-source LLMs, including but not limited to Open LLaMA, StableLM, and Pythia. You can fine-tune these models on a custom instruction dataset to adapt to your specific task, such as training a chatbot to answer financial questions.Lightning AI recently launched Lit-Parrot, the second LLM implementation in the Lit-* series. The goal of these Lit-* series is to provide the AI/ML community with a clean, solid, and optimized implementation of large language models with pretraining and fine-tuning support using LoRA and Adapter.We will guide you through the process step by step, from installation to model download and data preparation to fine-tuning. If you have already completed a step or are confident about it, feel free to skip it.Installing Lit-ParrotThe Lit-Parrot repository is available in the Lightning AI Github organization here. To get started, clone the repository and install its dependencies.git clone <https://github.com/Lightning-AI/lit-parrot>cd lit-parrotCopyWe are using FlashAttention, a fast and memory-efficient implementation of attention, which is only available in PyTorch Nightly 2.1 at the moment of writing this article.# for cudapip install --index-url <https://download.pytorch.org/whl/nightly/cu118> --pre 'torch>=2.1.0dev'# for cpupip install --index-url <https://download.pytorch.org/whl/nightly/cpu> --pre 'torch>=2.1.0dev'CopyFinally, install the dependencies using pip install -r requirements.txt .Downloading the model weightsIn order to use the model or fine-tune it we need a pre-trained weight. Thanks to the effort of open source teams, we have a bunch of open source weights that we can use for commercial purposes. Lit-Parrot being a GPT NeoX implementationsupports StableLM, Pythia, and RedPajama-INCITE weights. We use the RedPajama-INCITE 3B parameter weights in this tutorial. You can find the instructions to download other weights in this howto section.# download the model weightspython scripts/download.py --repo_id togethercomputer/RedPajama-INCITE-Base-3B-v1# convert the weights to Lit-Parrot formatpython scripts/convert_hf_checkpoint.py --checkpoint_dir checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1CopyYou will see, gpt_neox layers being mapped to the Lit-Parrot layers in the terminal. After this step, you can find the downloaded weights in the checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1 folder.Prepare the datasetIn this tutorial, we will use the Dolly 2.0 instruction dataset by Databricks for fine-tuning. Finetuning involves two main steps- first, we process the dataset in the Lit-Parrot format and then we run the fine-tuning script on the processed dataset.Instruction datasets typically have three keys: instruction, input (optional context for the given instruction), and the expected response from the LLM. Below is a sample example of instruction data:[  {    \"instruction\": \"Arrange the given numbers in ascending order.\",    \"input\": \"2, 4, 0, 8, 3\",    \"output\": \"0, 2, 3, 4, 8\"  },  ...]CopyThe dolly 2.0 dataset comes in JSON Lines format, which is plainly speaking a text file with rows of JSON data. It is a convenient format when processing one record at a time. The Dolly dataset contains the following keys \u2013{ \"instruction\": \"When did Virgin Australia start operating?\", \"context\": \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", \"response\": \"Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.\", \"category\": \"closed_qa\"}CopyWe need to rename context to input and response to output and we are all set to process our data.with open(file_path, \"r\") as file:  data = file.readlines()  data = [json.loads(line) for line in data]for item in data:  item[\"input\"] = item.pop(\"context\")  item[\"output\"] = item.pop(\"response\")CopyWe can modify the existing Alpaca script for our data preparation. This script downloads data from tloen\u2019s Alpaca-lora project and saves the processed data. It includes a prepare function that loads the raw instructiondataset, creates prompts, and tokenizes them using the model tokenizer provided in the checkpoint_dir. The tokenized data is split into training and test sets based on the test_split_size provided and saved to the destination_path.To modify the Alpaca script, open it from here and edit the prepare function. This is how our final function would look after mapping the keys appropriately.DATA_FILE = \"https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\"DATA_FILE_NAME = \"dolly_data_cleaned_archive.json\"def prepare(  destination_path: Path = Path(\"data/dolly\"),  checkpoint_dir: Path = Path(\"checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1\"),  test_split_size: int = 2000,  max_seq_length: int = 256,  seed: int = 42,  mask_inputs: bool = False, # as in alpaca-lora  data_file_name: str = DATA_FILE_NAME,) -> None:  \"\"\"Prepare the Dolly dataset for instruction tuning.  The output is a training and validation dataset saved as `train.pt` and `val.pt`,  which stores the preprocessed and tokenized prompts and labels.  \"\"\"  destination_path.mkdir(parents=True, exist_ok=True)  file_path = destination_path / data_file_name  download(file_path)  tokenizer = Tokenizer(checkpoint_dir / \"tokenizer.json\", checkpoint_dir / \"tokenizer_config.json\")  with open(file_path, \"r\") as file:    data = file.readlines()    data = [json.loads(line) for line in data]  for item in data:    item[\"input\"] = item.pop(\"context\")    item[\"output\"] = item.pop(\"response\")  # Partition the dataset into train and test  train_split_size = len(data) - test_split_size  train_set, test_set = random_split(    data, lengths=(train_split_size, test_split_size), generator=torch.Generator().manual_seed(seed)  )  train_set, test_set = list(train_set), list(test_set)  print(f\"train has {len(train_set):,} samples\")  print(f\"val has {len(test_set):,} samples\")  print(\"Processing train split ...\")  train_set = [prepare_sample(sample, tokenizer, max_seq_length, mask_inputs) for sample in tqdm(train_set)]  torch.save(train_set, file_path.parent / \"train.pt\")  print(\"Processing test split ...\")  test_set = [prepare_sample(sample, tokenizer, max_seq_length, mask_inputs) for sample in tqdm(test_set)]  torch.save(test_set, file_path.parent / \"test.pt\")CopyFinally, let\u2019s run the script by providing the data path and the model checkpoint directory.python scripts/prepare_yourscript.py \\  --destination_path data/dolly \\   --checkpoint_dir checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1CopyFinetuning the RedPajama-INCITE modelOnce you have completed all the above steps, it is straightforward to start fine-tuning. You need to run thefinetune_adapter.py script by providing your data path.python finetune_adapter.py \\  --data_dir data/dolly \\  --checkpoint_dir checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1CopyYou can update the default number of GPUs, micro-batch size, and all the other hyperparameters in the fine-tuning scripthere.You can play with your fine-tuned model using the generate_adapter.py script by trying different promptsand turning the model temperature.python generate_adapter.py \\  --adapter_path out/adapter/alpaca/iter-015999.pth \\  --checkpoint_dir checkpoints/togethercomputer/RedPajama-INCITE-Base-3B-v1 \\  --prompt \"who is the author of Game of thrones?\"CopyWe would love to hear what you have built with Lit-Parrot. Do share us your favorite prompt and response on Twitter or in the Discord community!Related ContentAccelerating Large Language Models with Mixed-Precision TechniquesUnderstanding Parameter-Efficient Finetuning of Large Language Models: From Prefix Tuning to LLaMA-Adapters",
        "summary": "- Learn how to fine-tune large language models (LLMs) on a custom dataset using Lit-Parrot, a nanoGPT based implementation of the GPT-NeoX model that supports StableLM, Pythia, and RedPajama-INCITE model weights.\n- With the aid of Lit-Parrot, you can fine-tune the available high-quality open-source LLMs such as Open LLaMA, StableLM, and Pythia on a specific instruction dataset, such as training a chatbot to answer financial questions.\n- Lightning AI released Lit-Parrot to provide the AI/ML community with a clean, solid, and optimized implementation of large language models with pre-training and fine-tuning support using LoRA and Adapter, and this article guides the reader through the process of installing, downloading model weights, processing the dataset, and finetuning the model using the finetune_adapter.py and generate_adapter.py scripts.",
        "hn_title": "How to Finetune GPT-Like Large Language Models on a Custom Dataset",
        "original_title": "How to Finetune GPT-Like Large Language Models on a Custom Dataset",
        "score": 461,
        "hn_content": "The discussion on Hacker News centers around the use of GPT-4 and other large language models for training custom datasets. There are debates about vendor lock-in, fair use of copyrighted material, and whether the generated content is copyrightable. Some commenters argue that OpenAI's TOS prohibits using their services for developing competing models, while others suggest finding loopholes in their policies. Some suggest that the development of new models is inevitable, and that the industry should focus on the greater good of AI tools over individual businesses. OpenLLaMA is suggested as a potential alternative to GPT for developing custom datasets.Experts discuss the benefits of fine-tuning AI language models (LLMs) for specific tasks, such as text completion or code generation. Fine-tuning involves modifying pre-existing LLMs to perform better on a particular task by training the model on new data. Fine-tuning is seen as a cost-effective and efficient way to improve LLM performance on narrow-use cases. While using vector databases and embeddings can provide context to LLMs, they are not as effective in tasks like information retrieval and search engines, which require a broader understanding of text. The use of fine-tuning, in combination with vector databases, could potentially enhance LLMs' ability to provide users with accurate and relevant information. However, fine-tuning models also carries the risk of contamination and overfitting.- Fine-tuning is a way to improve the output of a pre-trained language model for specific use cases.\n- It involves training the model with a smaller, specific dataset to make it more useful for that application.\n- Fine-tuning generally requires less data and compute than training a large language model from scratch.\n- LLMs and GPT3 can be fine-tuned with demonstration data that looks like a prompt input and output.\n- Adapter is a fine-tuning strategy that adds a learnable layer to the transformer block.\n- EasyLM is a popular tool for fine-tuning models.\n- Fine-tuning with LoRa designs can offer faster training times due to fewer parameters.",
        "hn_summary": "- Fine-tuning is a cost-effective and efficient way to improve LLM performance on narrow-use cases.\n- Using vector databases and embeddings can provide context, but fine-tuning can enhance LLMs' ability to provide accurate and relevant information.\n- However, fine-tuning models come with risks of contamination and overfitting."
    },
    {
        "id": 36077360,
        "timestamp": 1685054608,
        "title": "Firefox displayed a pop-up ad for Mozilla VPN over an unrelated page",
        "url": "https://bugzilla.mozilla.org/show_bug.cgi?id=1835158",
        "hn_url": "http://news.ycombinator.com/item?id=36077360",
        "content": "BugzillaBrowseAdvanced SearchNew AccountLog InForgot PasswordCopy Summary\u25beView \u25beClosed Bug 1835158 Opened 10 hours ago Closed 8 hours agoFirefox displayed a pop-up ad for Mozilla VPN over an unrelated pageCategoriesProduct: Firefox \u25beComponent: Messaging System \u25beVersion: Firefox 113Type: defectPriority:Not set Severity: --TrackingStatus: RESOLVED WORKSFORMEPeople (Reporter: zak.wilson, Unassigned)References ( URL )Details (Keywords: parity-chrome, ux-interruption)AttachmentsScreenshot_20230525_224308.png10 hours ago Zak Wilson268.97 KB, image/pngDetailsWider image of the phenomenon10 hours ago lordpidey763.91 KB, image/pngDetailsBottom \u2193 Tags \u25beTimeline \u25beZak Wilson ReporterDescription \u2022 10 hours agoAttached image Screenshot_20230525_224308.png \u2014 DetailsUser Agent: Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/113.0Steps to reproduce:Browsed an unrelated page (in this case, a the Syncthing admin UI generated from a server running on my own PC)Actual results:A pop-up ad for Mozilla VPN appeared on top of the page, and disabled the rest of the Firefox UI until closed. It is shown in the attached screenshot.Expected results:The browser should not have displayed an advertisement.DarkspiritUpdated \u2022 10 hours agoComponent: Untriaged \u2192 Messaging SystemKeywords: parity-chrome, ux-interruptionlordpideyComment 1 \u2022 10 hours agoAttached image Wider image of the phenomenon \u2014 DetailsA view of the entire browser window during the incident.jscher2000Comment 2 \u2022 9 hours agoSuddenly, there are numerous reports of this on r/Firefox. Seems related to bug 1834728 but I don't understand the message routing so it's difficult to have anyone reconstruct the trail.https://firefox-source-docs.mozilla.org/browser/components/newtab/content-src/asrouter/docs/index.htmlmjbUpdated \u2022 8 hours agoStatus: UNCONFIRMED \u2192 RESOLVEDClosed: 8 hours agoResolution: --- \u2192 WORKSFORMEEd Lee :MardakUpdated \u2022 8 hours agoSee Also: \u2192 1835175, 1834728Ed Lee :MardakUpdated \u2022 8 hours agoURL: https://support.mozilla.org/en-US/que...Shane Hughes [:aminomancer]Updated \u2022 7 hours agoDuplicate of this bug: 1835182Ed Lee :MardakUpdated \u2022 6 hours agoURL: https://support.mozilla.org/en-US/que... \u2192 https://support.mozilla.org/questions...See Also: \u2192 https://support.mozilla.org/questions/1414266#answer-1582507You need to log in before you can comment on or make changes to this bug.Top \u2191",
        "summary": "- Firefox displayed a pop-up ad for Mozilla VPN on top of an unrelated page, disabling the rest of the Firefox UI until closed.\n- Multiple users have reported similar incidents, possibly related to bug 1834728.\n- Mozilla has acknowledged the issue and provided a workaround on their support page.",
        "hn_title": "Firefox displayed a pop-up ad for Mozilla VPN over an unrelated page",
        "original_title": "Firefox displayed a pop-up ad for Mozilla VPN over an unrelated page",
        "score": 381,
        "hn_content": "Firefox displayed a pop-up ad for Mozilla VPN over an unrelated page. Comments on Hacker News debate whether Mozilla has lost its way with a focus on politics and feel-good initiatives instead of making a great web browser with privacy features. Suggestions for improvement include making Firefox faster, lighter, more privacy-focused, and focused on fixing the web by removing ads, paywalls, ad tracking, and other annoyances. One commenter suggests Mozilla should make the plugin ecosystem so good that people flock to help them. The blog post cited presents Mozilla's \"messaging system,\" \"Vision,\" and that Firefox must be an \"opinionated user agent that keeps folks safe, informed, and effective while browsing the Web.\"Mozilla Firefox's recent language changes and design choices have received criticism for being vapid and meaningless, with suggestions that the brand's focus on political messaging is at odds with its goal of being a user-oriented browser. Some believe that this focus has resulted in a devolution of the browser's capabilities to provide an enjoyable user experience. However, others argue that the changes appeal to a different market and may be effective for marketing purposes. There are concerns that these choices may push away developer usage, which could have long-term effects on Firefox's growth. Additionally, some users are unhappy with Mozilla's lack of privacy settings and ad-blockers in iOS Firefox.Mozilla faced backlash for displaying full-page pop-up ads on Firefox that violated user consent when implemented. This event led Firefox users to consider alternative browsers such as Brave, LibreWolf and Mullvad. Mozilla has received criticisms for recent changes that affect the browsing experience such as: ad-filled new tab pages, new mouse gestures that are worse, VPN, and other unrelated products instead of Firefox development. Users expect Firefox to uphold higher standards than Google\u00a0and share their humanistic values over conversion numbers. Mozilla's defense is that they need ads to pay for the developers, but users contend that donating directly to Firefox development is a better option. Firefox users are unwilling to switch to paid Firefox and contend that removing activism projects and donating for Firefox development directly can significantly help.- Mozilla released a pop-up ad asking users to subscribe to their VPN service on Firefox\n- Users express anger and frustration at the intrusive nature of the advert and Mozilla's direction\n- Some suggest alternative browsers or Firefox forks, like LibreWolf\n- Discussion around funding Firefox's development, with some suggesting Mozilla implement a subscription model\n- Some criticize Mozilla's leadership and priorities, such as investing in VR and AI, instead of focusing on the core browser experience\n- Mozilla issues a statement acknowledging the negative impact of the ad experience and committing to putting people first in their online experience.Mozilla is facing backlash from users after a pop-up ad for their VPN appeared while browsing. Some users see this as an example of Mozilla prioritizing ads over users, questioning the necessity of such promotions and the ethics of advertisements in general. The post highlights a growing concern among Firefox users who prefer a stripped-down browser free of ads and pop-ups, with some suggesting that Mozilla should offer a premium, ad-free version of the software. While some users complain about the intrusion of pop-up ads, others argue that it is possible to do ads in a way that puts people first, and that treating the customer ahead of employees or prioritizing ads over unrelated content defines user hostility.Users express frustration over Mozilla Firefox's recent move to display advertisements on the browser's new tab page. Some users even reported seeing advertisements while on other websites. Many users are disappointed with the direction Mozilla is taking the browser, including the addition of bloatware, analytics tracking, and ads, which they believe are hostile to the user experience. Some users have instead switched to alternative browsers like Safari, Brave, Vivaldi, and LibreWolf. There is a call for Mozilla to be more transparent and respectful of user privacy. Despite criticisms, some users continue to support Mozilla Firefox and are looking for ways to disable ads and other intrusive features.",
        "hn_summary": "- Mozilla faced backlash for displaying a pop-up ad for their VPN while browsing, which violated user consent\n- Users express dissatisfaction with Mozilla's direction, including its focus on ads and other unrelated products instead of improving Firefox's core browser experience\n- Some users suggest alternatives like LibreWolf, while others call for Mozilla to be more transparent and respectful of user privacy."
    },
    {
        "id": 36074845,
        "timestamp": 1685042175,
        "title": "War Is a Racket (1935)",
        "url": "https://archive.org/details/WarIsARacket",
        "hn_url": "http://news.ycombinator.com/item?id=36074845",
        "content": "Skip to main contentSearch icon An illustration of a magnifying glass.UPLOAD ICON AN ILLUSTRATION OF A HORIZONTAL LINE OVER AN UP POINTING ARROW. UPLOADUSER ICON AN ILLUSTRATION OF A PERSON'S HEAD AND CHEST. SIGN UP | LOG INBOOKSVIDEOAUDIOSOFTWAREIMAGESABOUT BLOG PROJECTS HELP DONATE DONATE ICON AN ILLUSTRATION OF A HEART SHAPE CONTACT JOBS VOLUNTEER PEOPLEWar Is A RacketBookreader Item PreviewLoading viewerClose iconA line drawing of an XFavoriteShareFlagtextsWar Is A Racketby Major General Smedley ButlerPublication date 1935Topics anti-warPublisher Round table press, inc.Collection folkscanomy_politics; folkscanomy; additional_collectionsContributor dudeman5685Language EnglishFamous booklet by the ex high ranking MarineAddeddate 2007-08-15 18:23:33Identifier WarIsARacketIdentifier-ark ark:/13960/t3qv3fk1cOcr ABBYY FineReader 8.0Pages 14Ppi 300Year 1935plus-circleAdd ReviewcommentReviewsReviewer: Fazal Rahman, Ph.D. -favoritefavoritefavoritefavoritefavorite- August 4, 2014Subject: Unique among the high ranking military officers of the US and the worldI do not know of any other high ranking military officer of the US or the world, who has spoken or written such most important truths and facts about the nature and causes of war. General Butler wrote these in simple and direct language that everyone can understand. His honesty; care for society, humanity, and justice for all; and profound insights; are self-evident in his writing. Moreover, it is even much more relevant now than when it was written in 1935.136,165 Views48 Favorites1 ReviewDOWNLOAD OPTIONSdownload1 fileABBYY GZdownloaddownload1 fileDAISYdownloadFor print-disabled usersdownload1 fileEPUBdownloaddownload1 fileFULL TEXTdownloaddownload1 fileITEM TILEdownloaddownload1 fileKINDLEdownloaddownload1 filePDFdownloaddownload1 fileSINGLE PAGE PROCESSED JP2 ZIPdownloaddownload12 Filesdownload5 OriginalSHOW ALLIN COLLECTIONSFolkscanomy Politics: Political Systems, Government and Democratic OrganizationFolkscanomy: A Library of BooksAdditional CollectionsUploaded bydudeman5685on August 15, 2007Terms of Service (last updated 12/31/2014)",
        "summary": "- 'War Is a Racket' is a famous booklet by Major General Smedley Butler, an ex-high-ranking Marine.\n- Butler speaks about the nature and causes of war in simple language.\n- The booklet is relevant now, even though it was written in 1935.",
        "hn_title": "War Is a Racket (1935)",
        "original_title": "War Is a Racket (1935)",
        "score": 354,
        "hn_content": "A post of a 1935 text titled War Is a Racket sparks a discussion on the benefits and drawbacks of US military dominance and the role and influence of the military-industrial complex, including the need for greater control over it. The post also touches on the differences between the Korean and Vietnam Wars and the importance of global multipolarity and the promotion of justice rather than imperialism. The discussion includes various viewpoints on the matter, including the efficiency and potentially negative aspects of the US military and the need for better allocation of resources and addressing inefficiencies.The post consists of a heated conversation about US foreign policy and international relations, with a focus on the Russian invasion of Ukraine. Some commenters argue that American hegemony is necessary for peace, while others point out problems with US actions in the past. The conversation touches on various historical events, including espionage cases, wars in Europe, and colonialism. There is no new or exciting information presented in the post, but readers interested in international politics and history may find the discussion engaging.No meaningful content, as the text only contains a series of comments on various political and historical topics.The comments section discusses the validity of the two-party system and the actual differences between Democrats and Republicans. The conversation suggests that party affiliation is more like belonging to a sports team than representing any particular political beliefs. The comments also note that the left-right political dichotomy is a recent development consolidated under Reagan. Finally, the thread includes comments about people who flipped from Sanders to Trump in the 2016 election, with some suggesting that they did so in significant numbers, while others dispute this claim.The comments in the post are a debate about leftist ideologies and their alignment with the Democratic and Republican parties in the US, specifically related to their stance on war policies. The anti-war sentiment has existed for many of the wars and is not specific to either of the parties. The discussion also touches on gun rights and unions as means of achieving justice. The use of force is necessary to defend human rights when the law fails to protect people. The F-35 fighter jets are powerful, but guns and trucks are more effective and cheaper to establish control. Gun regulation is also necessary to ensure responsible use, and pro gun rights and regulation can coexist.The comment thread discusses the sensibility of anti-war beliefs, the potential paradox of tolerance, and the blurry line between anti-imperialist war versus anti-war. The conversation also touches on specific conflicts like Afghanistan, Iraq, Ukraine, and Covid, with opinions varying widely on the effectiveness and morality of intervening in these situations. There is some criticism of political figures on both sides for their handling of these conflicts, with some arguing that the intervention was necessary while others criticize it as a waste of resources. The conversation highlights the complexity of war and foreign policy and the difficulty in finding a one-size-fits-all solution.The comment section discusses various topics such as the management of COVID-19, the Iraq War, and the military-industrial complex. Some commenters argue that COVID-19 was won and that the concern was always hospital capacity. Others question the war in Iraq and the actions of political leaders. There are debates about the military-industrial complex, with some preferring to name wars after the beneficiaries of the conflict. The comment section reflects a range of opinions on political and social issues but ultimately serves as an example of how discussions can spiral into tangential topics.The discussion on the article centers around the existence of the military-industrial complex, where there are profiteers in times of war. The commenters provide examples of US imperialism and foreign invasions, with emphasis on the exploitation of nations through modern imperialism. The conversation includes sarcasm and an ironic comment about corporate involvement in wars.",
        "hn_summary": "- The comments discuss the benefits and drawbacks of US military dominance and the role of military-industrial complex, with various viewpoints on efficiency and better allocation of resources. \n- The conversation also touches on specific conflicts like Afghanistan, Iraq, and Ukraine, with opinions varying widely on the effectiveness and morality of intervention. \n- The comment section reflects a range of opinions on political and social issues and serves as an example of how discussions can spiral into tangential topics."
    },
    {
        "id": 36075801,
        "timestamp": 1685046713,
        "title": "Colorado repealed law limiting municipal internet",
        "url": "https://coloradosun.com/2023/05/24/municipal-internet-sb-152-repealed-colorado/",
        "hn_url": "http://news.ycombinator.com/item?id=36075801",
        "content": "Colorado has repealed a 2005 state law that required every local government to ask voters for permission to build advanced broadband internet service and limited local government options for exploring internet service for its community. The law had been promoted by the cable industry as a way to prevent wasting taxpayer money on infrastructure projects like municipal internet. As of November 2022, 122 Colorado towns and about 40 counties had opted out. The Colorado Municipal League estimates a cost for a ballot measure between $5,000 and $40,000 depending on the size of the municipality. The repeal removes the need for a referendum and modernizes the language. The change also means Colorado will be eligible for federal broadband funds.Pueblo, Colorado is working to provide adequate broadband to all households, and expanding options for the Pueblo West community. The city only put broadband expansion on the ballot after realizing they hadn't opted out of Senate Bill 152, which could be construed as the city getting into the internet business. Highline and Comcast are both investing in broadband expansion in Pueblo West, with construction underway and service anticipated by this fall. The expansion is a result of the growing community's need for better broadband options and competition between providers.",
        "summary": "- Colorado has repealed a law that limited municipal internet and required voters' permission to build advanced broadband internet service in their communities, making it easier for local governments to explore broadband options.\n- The law had been promoted by the cable industry as a way to prevent wasting taxpayer money on infrastructure projects like municipal internet, but it had become an obstacle for many Colorado towns and counties.\n- The repeal removes the need for a referendum and enables Colorado to be eligible for federal broadband funds, while some Colorado cities such as Pueblo are working on providing better broadband options to their residents.",
        "hn_title": "Colorado repealed law limiting municipal internet",
        "original_title": "Colorado repealed law limiting municipal internet",
        "score": 275,
        "hn_content": "Colorado has repealed the law that limits municipal internet, citing cable industry interests in preventing taxpayer money from being wasted on infrastructure projects as the motivation behind the law. A resident in Fort Collins has shared their positive experience with city fiber internet, which provides gigabit symmetric service with no caps for $70 per month or 10 gig for $200 per month. Municipal internet has been successful in cities like Longmont and Chattanooga, providing reliable, affordable, and unconstrained internet access to residents. In some areas, private companies offer similar services, although competition is necessary to drive consumer costs down. Symmetric fiber internet, especially in areas where work from home has become the norm, is becoming increasingly essential.Colorado is a red/blue state that is also a tech hub and provides most of the water for the entire southwest. It has been solidly blue for 8+ years, with Biden winning the state by over 55% of the vote and having two Democratic senators. However, the state still has a local political split with dense urban areas voting heavily liberal and rural areas voting conservative. Municipal broadband is being discussed, with some expressing skepticism of local governments running last mile networks and potential issues with government surveillance. The competition situation for broadband in the US is generally considered to be lacking.",
        "hn_summary": "- Colorado repealed a law limiting municipal internet, citing the cable industry's interests in preventing taxpayer money from being wasted on infrastructure projects as the motivation behind the law.\n- Municipal internet has been successful in cities like Longmont and Chattanooga, providing reliable, affordable, and unconstrained internet access to residents.\n- Symmetric fiber internet, especially in areas where work from home has become the norm, is becoming increasingly essential."
    },
    {
        "id": 36070090,
        "timestamp": 1685019022,
        "title": "Show HN: Visual intuitive explanations of LLM concepts (LLM University)",
        "url": "https://llm.university",
        "hn_url": "http://news.ycombinator.com/item?id=36070090",
        "content": "",
        "summary": "- LLM University has created visual and intuitive explanations of LLM concepts.\n- The platform allows users to access different modules from a dashboard.\n- The explanations are designed to simplify complex legal concepts and make them easier to understand.",
        "hn_title": "Show HN: Visual intuitive explanations of LLM concepts (LLM University)",
        "original_title": "Show HN: Visual intuitive explanations of LLM concepts (LLM University)",
        "score": 267,
        "hn_content": "LLM University has published visual, intuitive explanations, and original content for free to introduce people to large language models. The course includes text articles, video explanations, and code examples/notebooks. It covers various topics, starting from introducing large language models to text generation. The course is not limited to the structure of a typical university course, with focus on the application of LLMs rather than their theory or training. Cohere, LLM University, has further plans to add content to the course and is available to answer questions in a dedicated Discord channel. Users are welcomed to suggest more concepts of their interest, which they may consider in their subsequent content. The landing page of LLM University is the course overview, which provides information about the different modules. However, some of the users have raised concerns about the accessibility of the material. Also, researchers have been working on LLMs' interpretability, and there are several explainability papers available that can help understand these models.Readers have left positive feedback on a tech-related material post by Jay Alammar, commenting on how informative and helpful the content is. Some nitpicks have been noted, such as obscuring buttons. One reader expressed interest in having chapter indicators and links to jump directly to a specific news in the audio. Jay Alammar praises a reader's visual explanations for machine learning whilst expressing hope they can do more in the future. The post does not contain any meaningful information.",
        "hn_summary": "- LLM University has published a free course on large language models with visual and intuitive explanations, code examples, and video content.\n- The course emphasizes the application of LLMs rather than their theory or training and welcomes suggestions for future content.\n- Some users have raised concerns about the accessibility of the material, and there are papers available on LLM interpretability. Positive feedback has been received on related tech content by Jay Alammar."
    },
    {
        "id": 36068896,
        "timestamp": 1685009760,
        "title": "Deno 1.34: Deno compile supports NPM packages",
        "url": "https://deno.com/blog/v1.34",
        "hn_url": "http://news.ycombinator.com/item?id=36068896",
        "content": "Deno 1.34: deno compile supports npm packagesMay 26, 2023Andy Jiang, Bartek Iwa\u0144czuk, David SherretProduct UpdateAs we continue our development journey towards Deno 2, this minor release is primarily focused on boosting compatibility with npm and Node.js, enhancing the overall quality of life and developer experience, and establishing the foundation for future performance enhancements.The most significant updates in this release include three highly anticipated features:deno compile supports npm packagesGlob support in deno.json and CLI flagsTLS certificates with IP addressesBesides the aforementioned features, there are many other improvements and bug fixes worth mentioning:Configuration file improvementsLanguage server improvementsDeno API changesImprovements to npm and Node compatibilityV8 11.5 and TypeScript 5.0.4deno compile supports npm packagesEver since v1.6, deno compile has allowed you to compile your project into a single binary executable. This development has proven to be substantial for a multitude of reasons, as it enables developers to:distribute and execute binaries on all major platforms without needing to install Deno or dependenciesinclude assets inside executable for more portabilitysimplify deployment with a single binaryachieve faster startup timeSince then, we've continued to make deno compile more useful, by adding support for web workers and dynamic imports, and today, by supporting npm packages.Here's an example creating a single binary executable with cowsay:$ cat main.tsimport { say } from \"npm:cowsay@1.5.0\";console.log(say({ text: \"Hello from Deno!\" }));$ deno compile --allow-read main.ts$ ./main __________________< Hello from Deno! > ------------------    \\  ^__^     \\ (oo)\\_______      (__)\\    )\\/\\        ||----w |        ||   ||cowsay is a simple example, but you can use deno compile with much more complex projects. Let's try vite:$ deno compile --allow-read --allow-write --allow-env --allow-net npm:vite$ ./vite \u279c Local:  http://localhost:5173/ \u279c Network: use --host to expose \u279c press h to show helpOr maybe eslint?$ deno compile --allow-read --allow-write --allow-env --allow-net npm:eslint$ cat .eslintrc.jsmodule.exports = {  \"env\": {    \"es2021\": true,    \"node\": true  },  \"extends\": \"eslint:recommended\",  \"overrides\": [  ],  \"parserOptions\": {    \"ecmaVersion\": \"latest\",    \"sourceType\": \"module\"  },  \"rules\": {  }}$ cat foo.jsfunction foo() {}$ ./eslint/dev/foo.js 1:10 error 'foo' is defined but never used no-unused-vars\u2716 1 problem (1 error, 0 warnings)The difference between using deno compile to create an eslint binary and npm install -g eslint is that Deno packages eslint with all of its dependencies and configurations alongside the actual deno executable. This means that the produced executable ensures its dependencies will not be changed by accident and continue working the same way without interference from other dependencies on your system. Additionally, our testing suggests the binaries from deno compile tend to start up faster than executing the same program with dependencies cached locally.There's more work to improve deno compile, including minimizing total binary size, which we intend to address in upcoming releases.Do you specific feedback on deno compile? Let us know.Glob support in deno.json and CLI flagsGlobs are now supported in the configuration file deno.json, deno task, and CLI arguments for specifying files. The glob syntax is cross platform, so you can confidently use it on Windows, macOS, and Linux.In deno.json, you can use * to match any number of characters in a path, ? to match a single character, and ** to match any number of directories:{ \"fmt\": {  \"include\": [\"data/example?.txt\"],  \"exclude\": [\"testdata/**/*.ts\"] }}You can also use glob patterns as CLI arguments. Here's the above example, but using deno fmt:$ deno fmt --exclude=\"testdata/**/*.ts\" \"data/example?.txt\"\u26a0\ufe0f Notice that we put the glob in quotes to prevent the shell from expanding it.With deno task, in addition to the glob syntax above, you can also use square brackets to match a range of characters:{ \"task\": {  \"files\": \"echo **/*.ts\",  \"data\": \"echo data[0-9].txt\" }}TLS certificates with IP addressesOne of the most wanted features is finally here. You can now use TLS certificates that contain IP addresses.Quoting rustls team:This is useful for things like Kubernetes pods, which often use IP addresses instead of domain names, and for DNS over HTTPS/TLS which needs an IP address for the server to avoid circular dependency on name resolution.With Deno v1.34 any API that uses TLS will work with IP addresses. For example:const resp = await fetch(\"https://1.1.1.1\");console.log(await resp.text());Configuration file improvementsExclude files or folders for all sub commandsPreviously, if you wanted Deno to ignore a file or folder for every sub command, you would have to specify it repetitively:{ \"fmt\": {  \"exclude\": [\"target/\"] }, \"lint\": {  \"exclude\": [\"target/\"] }, \"test\": {  \"exclude\": [\"target/\"] }, \"bench\": {  \"exclude\": [\"target/\"] }}Starting in this release, you can use a top level exclude property:{ \"exclude\": [\"target/\"]}Thank you to @scarf005 for implementing this feature.nodeModulesDir propertyA nodeModulesDir property can now be specified in the deno.json file for explicitly enabling or disabling Deno's use of the node_modules directory.{ \"nodeModulesDir\": true}If you are using Deno with a package.json and node_modules directory, it is recommended to enable this setting as it will provide a better experience. For example, with it enabled, Deno's language server will use the local node_modules directory for caching and resolving packages.Language server improvementsDeno 1.33 introduced document preloading in the language server, which pre-loads modules in the workspace on initialize so Deno knows about them and their contents.In some cases, the default 1000 file system entry limit was either too little or too much, so it's now configurable by setting the deno.documentPreloadLimit property.{ \"deno.enable\": true, \"deno.documentPreloadLimit\": 2000}Additionally, the language server's internal TypeScript isolate's default max memory limit was increased to 3GB to match TypeScript in VS Code's default. Lastly, this limit can be configured in the VSCode extension via deno.maxTsServerMemory:{ \"deno.enable\": true, \"deno.maxTsServerMemory\": 3072}Deno API changesDeno.serve()Last month, we hinted that we planned to stabilize the Deno.serve() API. After much deliberation, however, we decided to postpone the stabilization by another month in order to make this API more forward compatible.The signature of Deno.serve() has been changed to return an instance of Deno.Server instead of Promise<void>. Deno.Server has a finished property that's a Promise, which resolves when the server shuts down (using an AbortSignal). This gives more flexibility in controlling the server programmatically.const ac = new AbortController();const server = Deno.serve( { signal: ac.signal }, (_req) => new Response(\"Hello world\"),);setTimeout(() => { ac.abort();}, 1000);await server.finished;console.log(\"Server has shut down\");Additionally, Deno.Server has ref() and unref() methods. You can use these methods to control whether the server should keep the process alive or not.Deno.createHttpClient()This unstable API now exposes a few more options that allow greater control over the created client:const client = Deno.createHttpClient({ // Set maximum number of idle connections in the connection pool per host to 10. poolMaxIdlePerHost: 10, // Set a timeout for idle connection being kept alive to 10s. You can disable // timeout all together by passing `false`. poolIdleTimeout: 10_000, // Configure if the client can use HTTP1. http1: false, // Configure if the client can use HTTP2. http2: true,});const resp = await fetch(\"...\", { client });Deno.FileInfoThe Deno.FileInfo interface now includes the following new fields:Deno.FileInfo.isBlockDeviceDeno.FileInfo.isCharDeviceDeno.FileInfo.isFifoDeno.FileInfo.isSocketThe fields are available on Linux and macOS. On Windows, they are always null.Thank you to Hirotaka Tagawa for the contribution.Improvements to npm and Node compatibilityThere are a couple other notable improvements to npm support:deno vendor handles npm specifiers and will no longer error when they are encountered.deno task runs pre and post scripts if present when executing a script from a package.json file similar to npm. Thanks to Marvin Hagemeister for implementing this feature.We also polyfilled a few more built-in Node.js APIs:crypto.createDiffieHellmancrypto.createDiffieHellmanGrouphttp.Server.unrefModule.runMainperformance.markResourceTimingprocess.releaseworker_threadsAdditionally, the following N-API symbols now work properly:napi_async_initnapi_async_destroynapi_add_finalizerV8 11.5 and TypeScript 5.0.4Finally, Deno v1.34 ships with V8 11.5 and TypeScript 5.0.4.Take a look at Deno KV, our globally distributed database for Deno Deploy, now in beta",
        "summary": "- Deno 1.34 release focuses on improving compatibility with npm and Node.js, enhancing overall quality of life and developer experience, and establishing the foundation for future performance improvements.\n- Major features include support for deno compile with npm packages, glob support in deno task and CLI flags, and TLS certificates with IP addresses.\n- Other improvements include configuration file improvements, language server improvements, Deno API changes, improvements to npm and Node.js compatibility, and updates to V8 and TypeScript.",
        "hn_title": "Deno 1.34: Deno compile supports NPM packages",
        "original_title": "Deno 1.34: Deno compile supports NPM packages",
        "score": 267,
        "hn_content": "Deno 1.34 now supports NPM packages, which has caused some discussion among developers about the direction and focus of the project. There are concerns that the move towards NPM compatibility is detracting from Deno's original vision and could lead to a loss of focus. However, others argue that NPM compatibility is essential for wider adoption and that it will not necessarily harm the pure Deno projects. Stakeholders emphasize the importance of practicality and pragmatism in software development, which may involve trade-offs and compromises. Ultimately, the decision to support NPM packages was made to address user frustration, attract new adopters, and make the platform more versatile and applicable in different contexts.Deno, a secure runtime for JavaScript and TypeScript, recently added support for NPM, which some argue compromises its security-oriented design. While NPM support certainly enhances Deno's usability, many users appreciate the simplicity and security of working with just the native package manager. Some users argue that Deno's integration with Node is risky and insufficient, and they look forward to migrating from NPM to Deno's native packages. Others see the integration with Node's ecosystem as a step towards a more unified JavaScript community. Deno's built-in tooling, such as formatting and testing, alongside its strict permissions, are cited as reasons to use it instead of Node. Some users appreciate the ability to package Deno applications into single binaries, though the tooling for serving static files needs improvement.Developers discuss the benefits of using Deno, a secure JavaScript/TypeScript runtime. \nDeno eliminates the need for build steps and comes with all the necessary tools, such as test runner and linter, for a smooth developer experience. \nHowever, some argue that the trend of constantly switching to new technologies comes with tech debt and requires significant sacrifices.",
        "hn_summary": "- Deno 1.34 now supports NPM packages, leading to discussions about the project's direction and focus.\n- Concerns that NPM compatibility detracts from Deno's original vision, while others argue it's essential for wider adoption without necessarily harming pure Deno projects.\n- Stakeholders stress the importance of practicality and pragmatism in software development, which may involve trade-offs and compromises."
    },
    {
        "id": 36070426,
        "timestamp": 1685021207,
        "title": "Implementing a distributed key-value store on top of implementing Raft in Go",
        "url": "https://notes.eatonphil.com/2023-05-25-raft.html",
        "hn_url": "http://news.ycombinator.com/item?id=36070426",
        "content": "A beginner-friendly post describes implementing a distributed key-value store on top of implementing Raft in Gogoraft with an explanation of how the Raft protocol works. The post contains around 1k lines of Go and took around 7 months of sporadic studying to come to an understanding of the basics. The implementation consists of two key components of Raft: leader election and log replication. The algorithm is described, including reconfiguration and snapshotting. The post includes modeling with state machines and key-value stores. Additionally, the post covers how to build the HTTP endpoints used for interacting with the Raft cluster, and implementation of Raft server. The post is created for educational purposes only, not intended to be used in production.",
        "summary": "- A post explaining how to implement a distributed key-value store on top of implementing Raft in Go.\n- The post covers two key components of Raft: leader election and log replication, and also describes reconfiguration and snapshotting.\n- The post includes modeling with state machines and HTTP endpoint building, created for educational purposes only.",
        "hn_title": "Implementing a distributed key-value store on top of implementing Raft in Go",
        "original_title": "Implementing a distributed key-value store on top of implementing Raft in Go",
        "score": 255,
        "hn_content": "A Hacker News post discussing the implementation of distributed key-value store on top of Raft implementation in Go, has gained significant traction. The post has been praised for its coverage of advanced concepts, above and beyond what is usually covered on the internet. Readers admire the author's work, a seven-month-long project, and his willingness to share it with the community. Several readers also discuss their experiences interviewing senior developers, noting that they often struggle to articulate knowledge and expertise. Many feel that technical interviews fail to filter out the best candidates since the questions asked are often too simple or not relevant. Some readers suggest finding quality engineers by looking at their blogs to gauge their level of expertise, rather than relying solely on technical interviews.Developers discuss their experiences working with distributed databases and building their own Raft implementation from scratch. Some suggest alternative methods to achieve scalability in a key-value store. Others recommend resources for learning about distributed systems, including the MIT 6.824 course and implementations like etcd and TIKV. Experts share insights on using the encoding/gob library for serialization and discuss the challenges of implementing Raft correctly. Finally, some developers express their admiration for the author's clear and informative write-up.",
        "hn_summary": "- The article is praised for its coverage of advanced concepts and long-term project dedication\n- Technical interviews are criticized for being too simple or irrelevant in finding quality engineers\n- Developers discuss experiences with distributed databases and building Raft implementations, suggesting alternative scalability methods and learning resources."
    }
]