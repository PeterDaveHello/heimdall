[
  {
    "id": 37612127,
    "title": "Valve is a wonderful upstream contributor to Linux and the open-source community",
    "originLink": "https://www.phoronix.com/news/Valve-Upstream-Everything-OSS",
    "originBody": "ARTICLES & REVIEWS NEWS ARCHIVE FORUMS PREMIUM CONTACT CATEGORIES Valve Is A Wonderful Upstream Contributor To Linux & The Open-Source Community Written by Michael Larabel in Valve on 22 September 2023 at 06:18 AM EDT. 51 Comments This shouldn't come as any surprise to any longtime Phoronix readers and dedicated open-source/Linux enthusiasts, but Valve with their work on the Steam Deck and SteamOS have been lifting the open-source ecosystem as a whole. A talk this week at the Linux Foundation Europe's Open-Source Summit highlighted some of the great and ongoing contributions by Valve and their partners. Alberto Garcia of the open-source consulting firm Igalia, which continues to collaborate with Valve on some of these Linux ecosystem improvements, talked at length around how SteamOS is contributing to the Linux ecosystem. SteamOS is built atop Arch Linux with a GNU user-space and systemd, the desktop mode features KDE Plasma to which Valve has funded some improvements there, Valve's Steam Play / Proton that leverages Wine has been immensely valuable to Linux gamers and enthusiasts along with related open-source projects like DXVK / VKD3D-Proton, and then there's also they work they are doing around AMD color management / HDR. Igalia engineers have been involved with Valve on the AMD color management work as well as other areas like enabling new Linux kernel features for enabling better Steam Play support. The elephant in the room meanwhile is the countless improvements Valve engineers have made to the the Mesa OpenGL and Vulkan drivers as well as to the kernel graphics driver components. Not just to the AMD graphics drivers for benefiting the Steam Deck's hardware but also to Zink OpenGL-on-Vulkan and then other common infrastructure. But in this area of the Linux graphics driver support, Valve's contributions and those of their partners have been incredibly beneficial to the Linux desktop ecosystem even outside gaming. There has also been other efforts Valve has been involved in such on expanding case insensitive file-system support on Linux, various other kernel features, their Gamescope Wayland compositor, immutable software updates, and Flatpak. Igalia says it's part of Valve's policy to \"upstream everything\" they are working on. So for those questioning Valve's contributions to the Linux and open-source ecosystems or for helping to convince any friends/colleagues about Valve's open-source software work, check out Alberto Garcia's OSS EU 2023 presentation for the more comprehensive look at all of the great Valve / SteamOS upstream contributions. 51 Comments Related News SteamOS 3.5 Rolls Out In Preview On The Steam Deck With Many New Features VKD3D-Proton 2.10 Released With More Performance Improvements, Game/Driver Workarounds DXVK-NVAPI 0.6.4 Implements HDR Support Via DXVK DXVK 2.3 Brings Presentation Improvements, More Game Fixes, \"hideNvidiaGpu\" Option Steam Survey Results For August Show A Linux Dip After A Very Exciting July Steam On Linux Usage Spikes To Nearly 2% In July, Larger Marketshare Than Apple macOS About The Author Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com. Popular News This Week The Maintainer Of The NVIDIA Open-Source \"Nouveau\" Linux Kernel Driver Resigns Valve Is A Wonderful Upstream Contributor To Linux & The Open-Source Community GCC Preparing To Introduce \"-fhardened\" Security Hardening Option Intel To Further Collaborate With Red Hat, Canonical & SUSE For Intel-Optimized Linux Distros Ubuntu 23.04 & 22.04.3 Installs Haven't Been Following Their Own Security Best Practices SteamOS 3.5 Rolls Out In Preview On The Steam Deck With Many New Features Microsoft Releases A Big Update To Windows Subsystem For Linux, New Experimental Options Linux 6.5 Now Powering Ubuntu 23.10 Latest Linux News KDE Plasma 6 Seeing Many Bug Fixes -- Including For The Plasma Wayland Session VKD3D 1.9 Released With HLSL Compiler Improvements, Ability To Inspect DXBC Blobs AMDVLK 2023.Q3.2 Released With Quadbuffer Stereo, Quake 2 RTX Optimizations Valve Is A Wonderful Upstream Contributor To Linux & The Open-Source Community Compute Runtime 23.30.26918.9 Released For Intel's Open-Source GPU Compute Stack Ubuntu 23.10 Beta Released - Powered By Linux 6.5, GNOME 45 & Other Updates Reminder: The 2023 Phoronix Premium Oktoberfest/Autumn Special PuzzleFS Continues Striving To Be The Best File-System For Containers CentOS Starts An Integration SIG To Help Products/Services Built On RHEL / CentOS Stream GNOME 45 Released With New Apps, New Activities Indicator Show Your Support, Go Premium Phoronix Premium allows ad-free access to the site, multi-page articles on a single page, and other features while supporting this site's continued operations. Latest Featured Articles Linux 6.5 With AMD P-State EPP Default Brings Performance & Power Efficiency Benefits For Ryzen Servers Linux 6.6 Looks To Be Very Lucrative For AMD Server Performance Intel oneAPI Initiative Evolves Into The Unified Acceleration \"UXL\" Foundation SteamOS 3.5 Delivering Some Decent Performance Gains For The Steam Deck AMD Launches The EPYC 8004 \"Siena\" 4th Gen EPYC Processors Support Phoronix The mission at Phoronix since 2004 has centered around enriching the Linux hardware experience. In addition to supporting our site through advertisements, you can help by subscribing to Phoronix Premium. You can also contribute to Phoronix through a PayPal tip or tip via Stripe. Phoronix Media Contact Michael Larabel OpenBenchmarking.org Phoronix Premium Support Phoronix While Having Ad-Free Browsing, Single-Page Article Viewing Share Facebook Twitter Legal Disclaimer, Privacy Policy, CookiesContact Copyright © 2004 - 2023 by Phoronix Media. All trademarks used are properties of their respective owners. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=37612127",
    "commentBody": "Valve is a wonderful upstream contributor to Linux and the open-source communityHacker NewspastloginValve is a wonderful upstream contributor to Linux and the open-source community (phoronix.com) 866 points by WithinReason 20 hours ago| hidepastfavorite338 comments gabereiser 20 hours agoValve is a darling. Not simply because of steam (though, that enables them) but because from HL1, they truly cared about making good games, providing gamers a platform for good, working on problems outside their wheelhouse (Linux, VR, etc) for the betterment of gamers.Seriously. Yeah give them flak for steam’s store policies and such but Valve has always cared about gamers. They just don’t have the means to do it all (maybe they do?). I’m a fan. Not for HL1 or 2, not for Portal or TF2, not for CS, but for their never ending support on making sure “gaming” can be enjoyed by all. reply deelowe 20 hours agoparentSteam got so much flak when it first came out because it supported DRM, facilitated the death of physical media, and was generally kind of clunky and buggy. However, looking back, I&#x27;m thankful. I think Gabe did truly care about gamers&#x2F;gaming and was worried about Microsoft&#x27;s growing interest in gaming. I think he knew that that the transition to digital distribution was inevitable and made it his mission to get a platform out there before Microsoft did, because they would ultimately create something that was not gamer friendly.Perhaps this is all wishful thinking, but history has proven that Valve was perhaps the best steward we could have asked for in supporting the transition to online distribution. If we look at the alternatives be it Microsoft, Epic, or even GOG, no one has done it better. And, when tested, Valve continues to show they strive to do the right thing. For example look at returns. I never thought we&#x27;d see a no questions asked return policy for digital games and yet, with steam, it&#x27;s a fairly simple process. On top of this, when the policy doesn&#x27;t work (e.g. games which are broken outside of the return window), Valve again does the right thing and creates exceptions. reply doctorpangloss 18 hours agorootparentSteam continues to be the best platform because it shares per-game and per-user cross-game transactional data with everyone. It&#x27;s kind of hard to explain why this is so important, but it is unique to Steam, compared to all pay-to-play and subscription media as far as I know.Whereas things like DRM and returns and even royalties differ amongst platforms, and none of those have the same hegemony as Steam does; and the compulsory platforms, like the App Store and Google Play, developers complain bitterly about them in a way I&#x27;ve never heard regarding Steam, which they participate in voluntarily. reply gabereiser 16 hours agorootparentValve will never say “You know what, we are going to go this direction, market be damned. Follow us if you want to be cool” and proceed to introduce a new graphics API. Don’t get me wrong, we needed one, but the current state of graphics “drivers” sucks. Here comes Valve: “Hey bro, I heard graphics apis suck and are bifurcated by platform, here’s a wrapper that wraps them all into an API you probably already use.” (Initial version of their DX9->OpenGL bridge).Years later, Valve again: “You know, we just kept going on that thing we told you about, here’s a full fledged x86 win32 compatibility layer for anything posix. We had to patch the kernel but they were receptive.” Who does this? No one. Not a single company does this. They all have ulterior motives. Patch Linux for some hardware they are introducing for sale or patching it for some platform to get your PII data. Valve is the only company that is patching to make things better for the sake of making “the ecosystem” better. Apple: “We have the best products” yet those products aren’t helping the compute ecosystem. Microsoft: “We have AI” yet those products are still being worked out and is under active litigation from pretty much every creative out there. Valve: “We just want to play, make sense of players, to make better play experiences, to make better games, and not write more code than we have to. Our business is games, not code”. reply kaba0 3 hours agorootparentThere is no good company, they are all just profit-maximizing paperclip machines - they just put different weights behind the public opinion on them. E.g. Nike will put up a BLM logo not because they care, but because based on their calculations, it brings in more money. Some oil or logistics company won’t, because the average Joe doesn’t even know about them, and another company looking to minimize costs in general don’t decide on their partners based on that.In Valve’s case, it pays them to have this “good guy” look - some other stores try different strategies, but overall we really should never put personalities behind companies. They all are lawnmowers. reply sumuyuda 2 hours agorootparentValve operates quite differently from publicly traded companies that must see infinite growth to appease the investors. reply xtracto 2 hours agorootparentprevPeople need to understand this I buy several ETFs. I dont give a crap about the companies each etf is composed of. And I care less about how good or bad the company is with their environment, society or whatnot.The only thing I care about my set of ETFs is how profitable they are. If one of them stops giving me profits, I&#x27;ll sell it, contributing to de downward trend of the etf and its underlying stocks.Social, environmental or other aspects do not play in capitalism. reply DanielHB 13 hours agorootparentprevI might get some flak for this, but Meta is pretty big contributor to open source projects. The amount of bugs and features that they work on that are not used in their own products is quite staggering. Their open source projects are very embracing of the community.Google on the other hand... reply gabereiser 10 hours agorootparentMeta is doing things for Meta. Yes, it helps the greater ecosystem but they have problems no one else has outside of Google and Amazon and a few foreign players. Presto, React, etc are things they needed and decided to open source. Valve needed something at went TO the source. There’s a huge difference. The few tools Meta has released for Linux were things that were important to them at that scale. btrfs, etc. While one could argue Valve did it for Valve, the sheer impact it has on small to medium sized studios is undeniable. Not having to rewrite your engine and just compile with a -lproton is wizardry. SteamOS forced graphics card manufacturers to start including drivers. GNU community being what it is, they reverse engineered it and upgraded Mesa. I’d love to see Facebook include something like making Oculus open source. React isn’t a fair comparison either because it’s a singular path architecture. There’s really only one way, the React way. If they wanted to be serious about improving the web, they would have brought the legacy along and made jsx a web standard for browsers to support natively.Google, isn’t the same Google. Eric Schmidt is from my area of the world but advertising poisoned the company (one would argue, gave it a monetary value). Like Napster, Google was designed with good intentions in the beginning. That’s why it beat Excite, Webcrawler, Yahoo, Bing, AskJeeves, etc was because its usefulness at searching AND ranking.All the FAANGs contribute to open source. That’s not what I’m getting at. I’m saying Valve does it not just for them but for everyone. With the only hope that Gabe can get HL3 running on a CoreBoot Linux Handheld because console royalties suck. reply blibble 19 hours agorootparentprevsteam was terrible when it came outhowever it was still miles better than \"Games for Windows Live\", which was so bad I don&#x27;t even try replaying the games that still require it reply mpixel 19 hours agorootparentJust to clarify, Steam came out in 2003 and GFWL in 2007.Initial Steam was a horrible horrible experience, it also didn&#x27;t have a store, and it was mainly just something you had for Counter Strike. Now, CS was MASSIVE, it still is, but that was enough to get a whole lot of people experience Steam.It didn&#x27;t help the internet connection back then was, to put it mildly, shit for most people, so a constantly disconnecting program wasn&#x27;t a shocking outcome in hindsight, remember, this is 2003-2004.It also felt unnecessary, you bought the game off Steam, Steam didn&#x27;t let you buy anything and then anything not-made-by-valve, so why couldn&#x27;t you just play CS directly, why did you have to install an additional app on your limited hardware?And then things have changed. It&#x27;s my go-to shop, and their contributions to the Linux ecosystem is much welcome. There&#x27;s self interest, since operating a shop on Windows comes with inherent risks, but I don&#x27;t see the same interest in other parties, so I&#x27;ll take it over anything else today. reply Qwertious 18 hours agorootparent>It also felt unnecessary, you bought the game off Steam, Steam didn&#x27;t let you buy anything and then anything not-made-by-valve, so why couldn&#x27;t you just play CS directly, why did you have to install an additional app on your limited hardware?My understanding was they were solving the update problem:Back in the day, every CS update broke the community - not everyone updated at the same time, and if you update then you can only join a server that&#x27;s updated. Most people don&#x27;t update immediately, and servers want to only update when most users have updated, so as a result the servers don&#x27;t update. But now users don&#x27;t want to update because their favourite server hasn&#x27;t updated yet.This happens every time the CS devs ship a bugfix.Solution: force updates. Servers now have no reason not to update. The community stays unified, updates aren&#x27;t inherently socially painful. That&#x27;s what Steam accomplished for CS. reply sylens 18 hours agorootparentAnd downloading patches often meant waiting in a queue at places like FilePlanet for an hour or two, then downloading it at a snails pace reply yomlica8 17 hours agorootparentAnd then manually applying them. If the game was old enough you might need to apply multiple patches, something you&#x27;d have to figure out. I definitely had mixed feelings about Steam at first, and my internet connection at the time was such I&#x27;d hoard some larger patches and didn&#x27;t like the idea of re-downloading them on reinstall but there is no doubt now that where Valve was going with this was the future. reply Arrath 7 hours agorootparentprevI absolutely do not miss \"download button roulette\" on cnet or whatever site it was where it you had the joy of playing \"which of these 3 banners saying &#x27;DOWNLOAD NOW&#x27; is actually the download button and not a sketchy ad that will ruin your day\" reply dpkonofa 9 hours agorootparentprevOh god! Fileplanet. That also reminds me of \"Download managers\". They were literally apps that would search for the same file from multiple places so that it could try to part the download up and then combine the file at the end. It was like BitTorrent before BitTorrent. reply theLiminator 17 hours agorootparentprevHaha I totally forgot about that aspect of the Internet reply deelowe 14 hours agorootparentYep. That&#x27;s essentially why \"the cloud\" became a thing. reply dpkonofa 9 hours agorootparentprevThis was it 100%. I lived through this and that was exactly why Steam continued to be used in our LAN groups. Even for LAN parties, it made it super easy for everyone to make sure they were on the same version of everything. Extending that to online play is the reason it persisted to this day. reply phone8675309 18 hours agorootparentprevAt the expense of Valve exerting more control over what CS version that server admins and players run reply ta1243 19 hours agorootparentprevIt&#x27;s odd seeing Counterstrike because I haven&#x27;t really done gaming (and certainly not FPS) since Counterstrike was a free mod to Half Life.Wikipedia tells me that \"window\" of time was a year or two reply bravetraveler 18 hours agorootparentOne nice thing about Steam (back then, maybe still now?) was after the mod status left.One copy of the Half Life box set (with Blue Shift, Opposing Forces, etc) could basically become as many copies as the whole thing.I turned that one box set into several Steam accounts for my friends&#x2F;I to share. Each &#x27;mod&#x27; (turned game) basically granted a new Half Life license and cloned the derivatives reply semi 15 hours agorootparentThere was also a separate release of counterstrike called condition zero that included a single player campaign and a tweaked version of counterstrike multiplayer.That was not included as part of that bundle.. but if you used the dedicated server tool to download the czero mod and copied it to your halflife folder you could play both the single player and multiplayer version on steam reply gabereiser 10 hours agorootparentThis was how my brother played it. He was too dumb to know the difference because the box art literally looked like CS’s splash screen. CS != CZ but nevertheless, a steam account was a steam account, and technically CZ was HL so he downloaded CS off FilePlanet and was getting destroyed by me and my friends for weeks until he learned the strafe-run hack. reply gabereiser 16 hours agorootparentprevI still have my 6 (7?) digit ID from those days as my steamID. It got rolled into a larger one but still kept the old digits. Pretty cool of them. reply dpkonofa 9 hours agorootparentYou get a special badge now too. I waited a month or 2 from release to install Steam because I only cared about Half-Life 2 and that was the first game from Valve that required Steam. You didn&#x27;t even get a CD in the box, just a Steam redemption code. reply internet101010 19 hours agorootparentprevIt&#x27;s crazy that it came out before the bulk of its professional players were born. It is truly a timeless game. reply gabereiser 16 hours agorootparentprevIt wasn’t just CS, Team Fortress had a huge player base. Natural-Selection as well. There were like 7 or 8 mods for HL1 that were “on-par” with the quality of HL1, which says something about Hammer Editor and the toolkit they had at the time. GTkRadiant is great but Hammer Editor (formerly WorldCraft) was excellent.The popularity of the mods, CS included, is what drove Steam to become the store that it is. reply Arrath 7 hours agorootparentI still maintain that GldSrc was the golden age of game modding.We are, admittedly, in a pretty sweet spot right now with games running the genre gamut from Rimworld to Minecraft to Cities: Skylines to Starsector to the Bethesda RPGs having vibrant mod scenes but man, I have serious nostalgia for CS, NS, and DoD, oh and Tribes. reply gabereiser 6 hours agorootparentTribes! The OG of “yeah, we’re gonna open source this”. Torque Engine was awesome. reply physicles 8 hours agorootparentprevIt did feel unnecessary at the time, but I was obsessed with all things half-life so I was there mashing the refresh button the night when it launched. The launch itself was kind of a shit show, but IIRC it didn’t take more than a few months for everyone to realize that it was massively improved compared to the old ways of distribution. reply philipov 18 hours agorootparentprevDo you remember before Steam won, there was also Stardock. They&#x27;re still around now because they make Galactic Civilizations, but back in the day, they were also one of the early innovators in having their own store launcher for distributing their and others&#x27; games. reply NikolaNovak 18 hours agorootparentI still use stardock fences on my windows pc.I also... Fondly?... Recall the time everybody was excited to have Xmas or star trek themes desktop with windowblinds.... Funny how not just fashion changes, but even need for fashion - virtually nobody customizes their windows desktop anymore :) reply Kuraj 12 hours agorootparentprevIt&#x27;s kinda funny that there&#x27;s a company out there that does both game publishing and popular desktop utilities reply pdntspa 17 hours agorootparentprevI remember that. It was a really good store, the first of its kind IIRC. Every so often I think about what happened to the games I owned on there? reply gabereiser 16 hours agorootparentprevOh child, Stardock was originally a windows shell… Dressing to be modded like your Winamp skins. reply phone8675309 18 hours agorootparentprevThis is giving me a flashback to the time when I was still on dialup (the off-campus dorm I lived at had a shitty shared cable connection that was often slower or less reliable than dialup) and spent about three days downloading Half Life 2 on launch.It wasn&#x27;t until a few weeks later that I realized I could take my laptop to campus, download it over their incredibly fast WiFi, and then transfer the files to my desktop that had a decent GPU. reply pradn 19 hours agorootparentprevIt seems like any product named \"X for Y\" is terrible enterprise-y drivel. It means the project is part of some umbrella corp, which ofc means they can&#x27;t possibly actually care about anything by profit, move slow, and are un-responsive. reply beebeepka 17 hours agorootparentI have heard nothing but good things about skype for business! reply stonogo 16 hours agorootparentHearing nothing was a pretty widespread feature of that product! reply gabereiser 10 hours agorootparentsuppose no news is good news, I think I see the mouth moving but the picture froze. reply Insanity 19 hours agorootparentprevI remember using Steam for the games library and using Xfire for the ingame chat features. At some point steam because the only survivor there. reply HeckFeck 19 hours agorootparentXfire is something that died a sad death. Used it to chat with many people I met playing Star Wars Galaxies and Empire at War - think it was actually bundled with that one.The profile pages and screenshot uploads were fun too.Another online community lost to the sands of time, alas. reply Arrath 7 hours agorootparentDon&#x27;t forget GameSpy. Many, many rounds of multiplayer C&C: Renegade played through that back in the day. reply elesiuta 19 hours agorootparentprev> \"Games for Windows Live\", which was so bad I don&#x27;t even try replaying the games that still require itIf it&#x27;s even still possible to install&#x2F;activate them. Whenever any of them became available on Steam I would rebuy them there just for the convenience. reply the_biot 15 hours agorootparentprevThe Steam client was always, and is still, a gigantic pile of shit. The massive CPU usage when idle, the crazy game start delays, it&#x27;s all plain and obvious to anyone who installs it.But for some reason people will insist on ignoring those problems, or instead compare it to some earlier experience with standalone games or some Microsoft pile of garbage, and will defend Steam in places like this.Valve&#x27;s Steam service is super nice for consumers (though developers get squeezed terribly), but the client is just horrible. reply dpkonofa 9 hours agorootparentI disagree wholeheartedly here. The Steam client has its problems but it&#x27;s not shit. I use Big Picture mode exclusively on my gaming PC that&#x27;s hooked up to my TV and I never have problems with Steam unless some other garbage launcher (I&#x27;m looking at you, Ubisoft) crashes and doesn&#x27;t return focus. That&#x27;s it. Other than that, all my games stay updated, the client updates on restart, and I never have to mess with it. I&#x27;m not sure what more you can ask for. reply gabereiser 10 hours agorootparentprevWait, how do developers get squeezed? As a developer I need to know if I’m standing in quicksand.Having access to so many gamers, at once, without me having to setup a storefront, and pci compliance, and credit card data, is actually good for me. If you live in part of the world where there isn’t a tax treaty with the United States, that’s not exactly Valves fault. Blame your government for the squeeze. reply vunderba 10 hours agorootparentprevWhen I ran Windows 7, I was pretty fastidious about cpu consumption, and never observed Steam consuming more than 1-2 CPU percent on average assuming it was collapsed to the system tray and wasn&#x27;t downloading game updates in the background.I don&#x27;t think there&#x27;s any grand conspiracy like you make it out to be, perhaps you&#x27;ve had an outlier experience. reply Kuraj 12 hours agorootparentprevI wonder if it&#x27;s going to become even more web based but it has also accomplished things like a sorta unified desktop&#x2F;web&#x2F;mobile experience and the steam deck. So there&#x27;s that. reply deelowe 14 hours agorootparentprevOdd. I have no issues with the client and it&#x27;s miles better than any other client out there. reply waymon 19 hours agorootparentprev> steam was terrible when it came outDo people really think this? I remember applying updates to CS before steam and it was awful. Steam streamlined that and gave us a much needed friends list. I never ever thought steam the application was a bad. reply blibble 19 hours agorootparentthe friends list didn&#x27;t work for 5 or so years and neither did the download limiter (not a big deal these days, but on dialup... yeah)the UI was exceptionally slow and it took forever to do anythingthis wasn&#x27;t a meme for no reason: https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;bpGpe0o reply jonatron 18 hours agorootparentI spent ages looking for that meme recently, thanks! reply waymon 19 hours agorootparentprevha, im just forgetful. thank you. reply wredue 17 hours agorootparentprevInternet and DRM back then were absolutely shit. So a company coming along and embracing DRM in a consumer friendly way during a time where DRM was rightfully a major topic of contention put a lot of negativity out there.Few people then knew that it was way ahead of its time, and even fewer knew how much of a fight valve would be putting up against capitalist regimes trying to kill gaming. reply dcdc123 19 hours agorootparentprevSteam came out almost 5 years before GFWL. reply dspillett 19 hours agorootparentGiving GFWL less excuse for being as bad as it was. They&#x27;d witnessed Steam&#x27;s early problems, yet repeated them (and added more besides). reply blibble 19 hours agorootparentprevprobably about the same time they managed to get the Friends service to work reply grumbel 18 hours agorootparentprev> I never thought we&#x27;d see a no questions asked return policy for digital games and yet, with steam, it&#x27;s a fairly simple process.That was however not Valve&#x27;s idea, but only came in response to EA Origin offering a return policy in 2013, Valve follow up in 2015 with their own.One of the very rare cases where the competition was a little ahead for once. reply pbhjpbhj 17 hours agorootparentUK Consumer Rights Act gives you two weeks for no fuss return of items bought remotely. IME, Steam do not adhere to the law here. reply solardev 17 hours agorootparentDigital items too? reply angus-prune 16 hours agorootparentNo, GP is incorrect. Digital goods are treated differently under the act. reply subtra3t 16 hours agorootparentfull form of GP? reply fknorangesite 16 hours agorootparentGrandparent [comment]. replyTAForObvReasons 17 hours agorootparentprevValve&#x27;s 2 hour refund option came in direct response to a 2014 lawsuit from the Australian Competition and Consumer Commission[1].Rod Sims, head of ACCC at the time, asserted that Valve&#x27;s original no-refund stance broke Australian law.> Under Australian Consumer Law, everybody who buys a product or a service has a right to a refund if the product doesn’t work. They have a right to a refund, or a repair. Those rights are enshrined in Australian Law, and our allegation is that Valve sought to remove those consumer rights which is a breach of Australian Consumer Law[1] https:&#x2F;&#x2F;gizmodo.com.au&#x2F;2014&#x2F;08&#x2F;accc-commissioner-heres-why-w... reply lolinder 19 hours agorootparentprev> I never thought we&#x27;d see a no questions asked return policy for digital games and yet, with steam, it&#x27;s a fairly simple process.In general their policy very good, but it&#x27;s not quite no questions asked—they&#x27;re pretty strict about the 2 hour playtime limit, which is quite a short time to decide if a game will actually be fun. In many types of games by the time you get through the tutorial and have access to all the game mechanics you&#x27;re already past the two hour mark, and they also can&#x27;t tell the difference between actual play time and time in the menu while you&#x27;re doing something else.EDIT: To be clear, I&#x27;m not saying it&#x27;s a bad policy, there are obviously reasons for this. But it&#x27;s not truly no questions asked. reply dspillett 19 hours agorootparentIIRC, the refund window used to be longer, but was abused.It still is abused for short indie games, with people buying them with the intention of speed-running through and refunding.The refund policy is intended more for “crashed repeatedly”, “far too slow despite my machine matching the stated specs”, and “simply wouldn&#x27;t run”, type problems, rather than not liking the game. There isn&#x27;t much a service like Steam can do about that, that won&#x27;t be abused, other than offer demos (enough for you to try out those core mechanics) which is really down to the game creators and out of their power. Other than that you just have to not be first in line, and wait for reviews from sources you trust. reply lolinder 19 hours agorootparentRight, I get that. I&#x27;ve added a note to my comment above clarifying that I&#x27;m not critiquing the policy, just trying to clarify that \"no questions asked\" isn&#x27;t a good characterization of it. It&#x27;s a very good return policy for the industry and medium Steam operates in, but it has hard limits that are worth being aware of. reply jstarfish 14 hours agorootparentprevI wish more devs offered shareware&#x2F;demo releases. Not doing so was unthinkable in the hardware hell of the 90s.Too much shovelware on Steam these days, and the user has to pay retail price to even try it. reply ragestorm 19 hours agorootparentprevThe frequency of the returns probably plays a part. Anecdotally, I&#x27;ve returned a couple of games over the 2h limit and they have refunded, no questions asked. reply lolinder 19 hours agorootparentMy only experience with hitting the limit was also the only time I&#x27;ve ever tried to return a game. I&#x27;m sure it mostly depends on the service rep handling your claim and how many bogus returns they&#x27;ve seen so far that day. reply dspillett 19 hours agorootparentprevWas that 2 hours since purchase, or 2 hours play time?The current limits are 14 days since-purchase as long as you&#x27;ve played the game for less than 2 hours. reply pseg134 19 hours agorootparentprevIt is quite literally no questions asked. It isn’t meant to be a demo system which is what you seem to want. reply lolinder 19 hours agorootparentNo, there&#x27;s a single question asked: how long have you had the game open on your computer?Costco has a no-questions-asked return policy, and demo-ing your purchase is absolutely part of the expectation for how people will use said policy. Steam even explicitly includes \"it wasn&#x27;t fun\" as a valid return option, as long as you reached that conclusion quickly enough.To be clear, I&#x27;m not saying the policy is wrong, it&#x27;s clearly designed to prevent abuse, I&#x27;m just saying that it&#x27;s not no-questions-asked. reply tempest_ 18 hours agorootparentprevYeah I always considered something used to make sure the game will run correctly on my system and I feel like 2 hours is generous enough for that use case. I suppose it doesn&#x27;t preclude game breaking bugs later in the experience but nothing is perfect.Valve is there to facilitate the sale of the game, not guarantee the game is good. reply semi 17 hours agorootparentprevFor some context on the early days of steam, I remember the Friends network having reliability issues presumably due to scaling as everyone adopted steam.But by reliability issues I don&#x27;t mean it occasionally failed. It did, but that was early on. I assume they just killed the backend and never pushed a client update to remove it because I remember what was at least months if not a full year of the friends UI just saying it failed to connect to the Friends network.The actual matchmaking never had any real issues that I remember, but the login servers definitely did, and deleting clientregistry.blob and restarting steam was just a routine thing you did to get steam working again.None of this is really that surprising though, steam was originally a tool just for beta testers, while the live game used WON for matchmaking. WON was shutting down and Valve had to rush steams public release. reply PH95VuimJjqBqy 16 hours agorootparentprevIt got flak when it came out because it was released at the same time as HL2 and steam was the _only_ way to get HL2. If you wanted HL2 then you were installing steam, even if you weren&#x27;t interested in it. reply gabereiser 16 hours agorootparentSteam came out before that. You missed the HL1 mod era. reply PH95VuimJjqBqy 15 hours agorootparentI was around before HL1 existed, I didn&#x27;t miss anything.I wasn&#x27;t trying to imply they were released on literally the same day, of course steam was out before HL2, but HL2 is what drove its popularity because people were forced to install steam to get access to HL2.And most people resented them for it. At that time, store purchases was still the common way to get at PC games. reply dpkonofa 9 hours agorootparentI&#x27;m in this crowd. I initially resented them but now love Steam and HL2 was what got me to install it. I have a 7-digit steam ID but my account is still 20 years old (it might be 19, I&#x27;m not sure). reply Am4TIfIsER0ppos 14 hours agorootparentprevI resent them now for the same reason but on another game: Civ 5. I even bought that one in a box from a store. reply PH95VuimJjqBqy 14 hours agorootparentand still had to install steam? ouch, yeah, that would irritate the crap out of me too. reply Am4TIfIsER0ppos 11 hours agorootparentYes. DVD was pointless. Online steam was required. Worse still it happened to be down that day. The worst possible first impression. reply gabereiser 8 hours agorootparentUltima Online launch day had a similar feel. Servers melted under the load of 1500 (maybe 2,000). After a weekend of reading the booklet and studying the map, I was able to login. Only to find that cave on the map I wanted to explore was between me and a dozen Ogres and Ratmen. Good times.Steam was the first “online required” for offline play I think. Others like EA and Ubisoft followed shortly after but didn’t have their own stores until many many years later. replyhave_faith 19 hours agorootparentprev> was generally kind of clunky and buggySteam is by far the jankiest program I have installed on my machine. It&#x27;s TSAB (time to seeing a bug, I just made it up) is measured in seconds, not minutes or hours. I know they&#x27;re raking in money for being what is mostly a very large FTP server (I kid...), but please spend some of it on the basic experience. reply happymellon 19 hours agorootparentStrange, Steam is quite stable for me. On both my SteamDeck, my couch PC on the main TV, and my laptop.A lot more stable than Tim Sweeneys ego. reply pdimitar 18 hours agorootparentprevI have only seen one Steam bug once in the last 6 years and that was a game that restarted its download from scratch, followed by the client crashing. Never happened again, never saw another bug either.Used it on hard drives, SATA SSDs and NVMe SSDs. reply ElectricalUnion 18 hours agorootparentprevOf all the \"app store\" type programs that I have to interact with, Steam is somehow the least painful one.And I deal with a bunch of them; Gnome Software, Microsoft Store, Epic Games Store, Google Play Store, (Samsung) Galaxy Store, F-droid, not counting some dedicated pseudo-stores aberrations like JetBrains Toolbox and Wargaming.net Game Center... Those are all much smaller (ok, Google Play Store is probably the largest), almost featureless in comparison, yet they are slow as molasses and buggy as hell. reply subtra3t 16 hours agorootparentMaybe its just my bad system (integrated graphics, 4 GB ram, i3 8th gen processor) but Steam actually performs far worse than MS store, Gnome Store, and the Google Play Store (though thats on my phone and not my laptop). reply jstarfish 14 hours agorootparentYour system is either old or a Chromebook heh. Same problem here.Try disabling the options that preload and refresh all the store&#x2F;community \"stuff\" behind the scenes. Maybe auto-updates too. replylsaferite 19 hours agoparentprevMy personal Steam customer support &#x27;win&#x27; was several years back when I decided to start building a game library for my son. I had purchased Conan and Elite Dangerous while they were on deep discount and gifted them to my son&#x27;s account. At the time I was unaware that gifts can expire and be refunded. So, at some point the gifts expired and they refunded the purchases, but the game were no longer on that deep discount. I was fairly upset and contacted customer support. The initial customer support agent was unhelpful and I sent a follow-up contact to Gabe that expressed my discontent. I explained that they&#x27;d managed to alienate a user that had been on the platform since 2005 and who had a massive library of purchased games at that point. I told them I would no longer be using the platform and would not be using it for my kids either. This email elicited a response from one of the Steam devs and they agreed that my initial interaction was not what they wanted the experience to be. He sent me copies of the games that have been refunded and he sent me to codes for \"all present and future Valve titles\" for me and my son to be able to play together. In the end he turned it around fully and only increased my appreciation for the company and platform. reply eropple 19 hours agorootparentYeah, Steam has always some really impressively dedicated help when somebody escalates. It&#x27;s probably harder to access now, but I remember one time in college when TF2 came out of beta and performance was awful. Steam Support didn&#x27;t have anything, so I sent an email to GabeN; he put me in touch with a senior Source dev who had me press some debug buttons and hop in a game with a bunch of Valve folks (I was pretty good but this was definitely an exception to \"game devs are worse that their games than players\", I got my ticket punched worse than when I was playing in competitive leagues). A few weeks later there was a patch that significantly improved perf on my particular flavor of hardware. reply callalex 18 hours agorootparentprevI’m glad everything worked out for you in the end, but it seems like the Steam policy here is pretty reasonable, and you come across as unreasonable. reply lsaferite 17 hours agorootparentI know I shouldn&#x27;t engage, but your comment irks me.This is the email I sent, make of it what you will:Mr. Newell,I figured I would email you as a sort of spiritual goodbye to my fandom of Steam.I have been a customer for as long as I can remember. I&#x27;m pretty sure it&#x27;s longer than the 15 years my profile lists as I had a profile that I lost access to before this one. For this entire time I&#x27;ve been a staunch supporter and advocate of Steam. I&#x27;ve slowly built my collection over the years and would always prefer to buy via Steam vs.another platform or even direct. I would always recount my many positive experiences with the Steam platform when discussions online turned negative. Overall I was a very happy customer and advocate.My son is now 10 and I had finally decided to start a game library for him. We are a multi-PC family and we frequently want to game together or just want to all play games at the same time, even if they are different ones. As the Steam sharing feature means we cannot all play different games I decided I&#x27;d just buy him some of the games he asked for or that we could play together. The last two of those purchases is what triggered my loss of faith in Steam. And to be honest, it was such a trivial thing to trigger it in the end. I purchased a copy of Elite Dangerous: Commander Deluxe Edition and a copy of Conan Exiles - Complete Edition. They were both on sale for a good amount off, 75% for ED and 40% for CE. As I seem unable to just purchase a game and hold it as a later gift to someone and instead I have to specify the recipient right away I went ahead and sent it to my son&#x27;s email address. That address is simply a group that goes to myself and my wife until he&#x27;s a little older. Apparently I missed the fact that I needed to go and accept the gift or the gift would be REFUNDED. Eventually the gifts were both refunded and I had missed it until the second gift was refunded. I immediately reached out to support to help un-refund the purchases. They said that they were unable to help me.That is really where the story ends I&#x27;d say. Nothing dramatic, but I told them they&#x27;d lost a customer for giving me my money back. Pretty ironic really.I keep getting emails about deals on items on my wishlist and I keep realizing that I meant what I&#x27;d said. You guys lost a customer. I&#x27;ve gone so far as to start buying games I already own on Steam on GOG instead now. I won&#x27;t walk away from my Steam library and I&#x27;m not saying I&#x27;ll never spend more money on Steam. But I&#x27;ll never do it as a first choice and I&#x27;ll never do it as a happy customer.I just wanted to write to you on the off chance that you might read this so perhaps you can do something for the future to not lose another loyal customer over such a trivial thing.And this was the response:Hello Mr. [X],My name is [Y] and I am a developer on Steam. Thank you for taking the time to email us and bring this issue to our attention.I have reviewed your help request and I am contacting you to apologize for the responses that you received. Your request was not handled appropriately and we will use it as well as your feedback to improve how we handle cases like yours in the future.We would like to add free copies of the games that were automatically refunded to your son&#x27;s account. From your email, it sounded like you were hoping to delay giving him these games until he is a little older. So, I have added giftable copies of Elite Dangerous: Commander Deluxe Edition and Conan Exiles - Complete Edition to your account&#x27;s inventory. You can access your inventory through the dropdown menus near the top of the Steam Client and gift them to his account at any time.We also think it is great that you are starting a game library for him and we would like to contribute some games from Valve as well. I am including two CD keys which you can register on both of your accounts so that you can play the included games together. These keys include all present and future Valve titles:[CODE1][CODE2]Thank you again for bringing this to our attention. Please let me know if I can help with anything else. reply subtra3t 16 hours agorootparentI have nothing to add except that this is such a wonderful interaction between two polite people. On the internet, too! reply yett 1 hour agorootparentprevWow that&#x27;s pretty cool. So you get access to all new Valve games on day 1 for free? reply bobsmooth 14 hours agorootparentprev>but I told them they&#x27;d lost a customer for giving me my money back.That sounds unreasonable. reply dpkonofa 9 hours agorootparentHow so? If the customer doesn&#x27;t want their money back and didn&#x27;t intend to get their money back, that seems completely reasonable. There&#x27;s no reason someone should expect that a purchase they made got removed without their consent regardless of whether or not a refund was issued. reply oynqr 19 hours agorootparentprevYou \"own\" Half Life 3 in some timeline. reply lsaferite 16 hours agorootparentprevAs a small follow-up to this that exemplifies the continuing good interactions:I posted the email exchange I had below another comment. In that exchange you&#x27;ll notice that the dev said they&#x27;d added the games under my inventory to gift to my son at a later date (when he was older). That came about 2 years later when he was 12. The problem was, when I tried to use the gifts from my inventory they both failed for unspecified reasons. I reached out to the initial dev again, hoping he was still there. He was and he helped resolve the issue right away.I know some people have had bad customer service with Steam or have other complaints, some valid and others not so much. In the end, I&#x27;m a pretty satisfied Steam customer and will generally speak well of them when the situation arises (like today). reply rollcat 17 hours agorootparentprevThese kinds of cases can be rare enough that finding them is absolutely worth that cost, in terms of fixing a rare but annoying bug, helping customer retention, \"word on the street\", etc.I don&#x27;t do customer support very often, but when I do, it&#x27;s my default response. reply lsaferite 17 hours agorootparentTalking about customer service, the best I&#x27;ve _ever_ experienced has been with Sweetwater, on online music store. I seriously rave about them to anyone that will listen. Someone should do a case study on their CS program. reply dpkonofa 9 hours agorootparentThis is great to know. For some reason, I got the impression that Sweetwater was a terrible company but I can&#x27;t, for the life of me, remember if that&#x27;s based on a personal purchase I made from them (and I made several) or if it was based on someone else&#x27;s experience that was related to me. It&#x27;s just something that I had stored away in my memory as a \"Well, I&#x27;m never buying from them again\". reply MegaDeKay 19 hours agoparentprevThat their games aren&#x27;t filled with Pay To Win microtransactions and Day 1 DLC is yet another reason to love Valve. If someone wants to spend a few bucks to buy a hat in TF2, that&#x27;s fine by me. reply lapetitejort 19 hours agorootparentConversely, CSGO and DOTA 2 has facilitated real money gambling among the youth on third party sites for years. Valve has attempted to crack down on gambling sites, however it&#x27;s still possible for a fourteen year old to insert credit card details and lose real money gambling for virtual skins. reply ysavir 19 hours agorootparentAnd Artifact has card packs that are effectively loot boxes, and a whole marketplace to facilitate selling&#x2F;buying them. I don&#x27;t know how much&#x2F;if they made any cut from the marketplace, but it&#x27;s certainly a form of \"play to win\". reply dietr1ch 17 hours agorootparentprevWhich could easily be fixed if Valve decided to put a hard-cap by selling skins for a fixed price, even if they were only for sale a couple weeks a year.They&#x27;d also pocket all that money, but I guess they don&#x27;t want people who spent more than said cap to get their skins. But people who are spending 100+ on skins should know they are playing the NFT game. reply waveBidder 17 hours agorootparentprevthis is nothing compared to Robloxhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_gXlauRB1EQ reply gabereiser 8 hours agorootparentMan complaining about a monetization platform by making a video on a monetization platform. reply babypuncher 19 hours agorootparentprevThey should kill their RNG skin distribution and open a normal cash shop like everyone else. I find this cosmetic market where people pay hundreds or even thousands for items they want skeevy as hell. It&#x27;s a big black mark on Valve&#x27;s otherwise exceptional reputation. reply robertlagrant 19 hours agorootparentWhy do people spend this much? Are they being tricked or something? reply enragedcacti 18 hours agorootparent1) People really like skins2) Unlike basically every other game with paid skins, Valve games let you sell them to other players on an open market for Steam credit.Valve takes 5% of each market transaction and many skins hold their value quite well so using a $200 knife for years and years could only end up costing $10 (+ opportunity cost) or so assuming the market stays flat and you will eventually buy $200 of games in the future.The real losers in the system are the people with gambling addictions opening cases and hoping to get something really good for less than market price. Cases are free drops but cost $2.50 to open and the average market value of what you win is usually less than (value of the case)+$2.50. Because the cases can be sold there&#x27;s no limit to the amount of gambling one person can do.https:&#x2F;&#x2F;csroi.com&#x2F; reply skeaker 18 hours agorootparent>Valve takes 5% of each market transaction... on their own community market platform. Valve supports third party stores that don&#x27;t have a Valve cut, and they freely provide the ability for users to trade items for items with no fees to allow third party stores to work. These systems kick off a whole third angle of businesses being propped up around the exchange of these items and of people doing speculative trades on certain items. reply babypuncher 17 hours agorootparentprevThe market where Valve takes a cut of all cosmetics sold also incentivises them to maintain an extreme level of artificial scarcity for the most desirable cosmetics in the game.To me this is infinitely worse than just having a skin shop and&#x2F;or battlepass. reply dcow 17 hours agorootparentI bet valve makes more off the hundreds of thousands of $2 transactions than the occasional $100 or $1000 transaction. I mean think about it... reply michaelt 18 hours agorootparentprevIt&#x27;s difficult to come up with an informed opinion on this sort of thing because it&#x27;s nigh-impossible to talk to the people involved. I certainly don&#x27;t know anyone who spends thousands of dollars on TF2 hats.One possibility is that they&#x27;re gambling addicts in countries where gambling is heavily restricted, and buying \"loot boxes\" containing random items is the closest they can get to playing a casino slot machine.Or perhaps they think of themselves as clever investors in collectables, which they hope to sell on at a profit later on. You and I might think they&#x27;re buying the equivalent of tulips or beanie babies - but they think their purchases are more like fine wines or rare postage stamps.Perhaps the big spenders actually only spend big five bucks at a time, and they&#x27;re merely poor at managing their personal finances - spending five bucks a day for five years, unaware of how it&#x27;s adding up.Or it could be money laundering - perhaps there&#x27;s some criminal scheme where bank transfers are heavily monitored by the cops, but transfers of rare TF2 hats aren&#x27;t.Perhaps the big money transactions are actually fake, aiming to pump up prices or make people spending mere hundreds of dollars feel better about it because at least they&#x27;re not spending thousands.Yet another option is that they&#x27;re super-successful billionaires, and a thousand bucks is nothing to them, not even worth bending down to pick up if they saw it in the street.People who make games with microtransactions for a living probably find it a lot easier to sleep at night if they think all their whales are billionaires. reply dcow 17 hours agorootparentOr, maybe they just value the skins? Maybe they want to contribute financially to a game they really like in the hopes of keeping it healthy? I do know people that buy every new cosmetic that&#x27;s released and they enjoy doing it. They aren&#x27;t even millionaires. So what? reply Zpalmtree 17 hours agorootparentprevThe people I know who have thousands of dollars in TF2 hats, have played the game for thousands of hours and so want to show off a little bit with cool looking items while doing so.They have a fair amount of disposable income, but certainly aren&#x27;t billionaires. reply usea 17 hours agorootparentprevYes. They sell items via loot boxes where you don&#x27;t know what you&#x27;re buying until you&#x27;ve already opened it. It&#x27;s gambling. Distributing purchases this way is well known to increase spending and hurt people. It&#x27;s why they do it. reply dcow 17 hours agorootparentThe stock market is also gambling. Plenty of informed consenting adults visit casinos all the time. What&#x27;s the \"responsible adult\" way to spend your discretionary entertainment budget these days? NFTs? Disney+? Binge drinking at cocktail bars after work? High yield savings accounts? I mean seriously I&#x27;m not pro psychologically damage people with manipulative feedback spirals. But let&#x27;s not ignore the fact that 1) owning a cool cosmetic and looking good stomping noobs is fun, and 2) that people are willing to pay purely for entertainment. reply usea 16 hours agorootparentI&#x27;m not passing judgment on the victims of this practice. We should be regulating it, instead of allowing companies to abuse people. reply Mustachio 18 hours agorootparentprevAs someone who played a lot of CSGO as a 15-16 year old back in 2015, it&#x27;s all psychological. Why does anyone become addicted to gambling? The thrill releases enormous amounts of dopamine. Satisfy this over and over, and the threshold for the same euphoria becomes higher and higher. That&#x27;s how yo end up with people, and particularly teens and young adults spending massive amounts of money for &#x27;some pixels&#x27;. I think I sank about 1.5k into it in total over the years. When Belgium decided to ban such loot boxes I was happy to see the addiction forcibly ended. They just need to repeat it for predatory battlepasses and the likes. reply dcow 17 hours agorootparentprevBecause they value the content. Might not be your style, but participating in battle passes and cosmetic drops is enjoyable for many people. What else should they be spending their discretionary income on? Stonks? reply callalex 18 hours agorootparentprevYes, Valve is relying on gambling mechanics to entice people, the same way a casino does. reply gabereiser 8 hours agorootparentprevIt’s slot machines with a different UI reply skyyler 19 hours agorootparentprevWhen it was TF2 and not CSGO, there was a lot of money laundering.Not sure if that&#x27;s still happening. reply babypuncher 17 hours agorootparentprevDepends on how you define tricked. The whole practice relies heavily on FOMO driven by artificial scarcity. It&#x27;s all psychological manipulation, that many of us are susceptible to even if we think we aren&#x27;t.I bring it up because games like Overwatch 2 get regularly shit on for introducing things like a battle pass and paid skin shop. Those rely on FOMO as well, but not nearly to the same extent. There are no gambling mechanics, and there is no Blizzard-sanctioned auction house where the most desirable items sell for thousands of dollars. The most desirable cosmetics in the game can be had for 10 dollars plus spending some time playing the game.As a player, it also just feels really shitty that customizing my character the way I want is reliant entirely on blind luck through gambling mechanics or spending obscene amounts of money.So if Blizzard is gonna take heat for this (and they do deserve at least some of it), then Valve absolutely should get raked over the coals for their far worse system. reply dcow 17 hours agorootparentPokemon as an entire game relies on artificial scarcity and psychological manipulation. It&#x27;s just a fixed cost up front for the game (and arguably not even strictly so these days with Pokemon Go). Same with any game ever that has loot and drop tables. Allowing people to pay more money to get more drops is the only thing that&#x27;s really changed. And honestly it seems the feedback depends entirely on how \"sleazy\" the game studio&#x27;s street reputation is. Dota2 cosmetics are considered tasteful while Genshin Impact is \"gacha\". But heh even Genshin gets a pass because it&#x27;s such a good game and not one of those mobile penguin island simulators (which even get a good rap in many circles for being cute and fun to play).My new thesis is: if \"winning\" is \"looking cool by getting good loot\", then allowing people to pay for drops is effectively pay to win. I think this nuance is often skipped over in the conversation about whether some new game&#x27;s micro-transaction framework is sleazy or not. replymiki123211 19 hours agoparentprev> but for their never ending support on making sure “gaming” can be enjoyed by all.Oh how I wish that was true. Steam&#x27;s accessibility story is an utter and inexcusable piece of garbage. Using Steam with a screen reader is a constant struggle, to the point where people had to write guides [1] on how to go about this. It got a bit better recently, at least on Windows, Mac still sucks. There are plenty of Steam games that a blind person can play, sometimes natively[2][3], sometimes through special accessibility mods[4][5][6]. Not to mention the Steamdeck, which has no accessibility support at all, despite the fact that Linux screen readers do exist[7], and consoles like PS5 and Xbox implement their own[8][9]. Valve really doesn&#x27;t care.[1] (outdated) https:&#x2F;&#x2F;www.mail-archive.com&#x2F;audiogames-reflector@sabahattin... [2] https:&#x2F;&#x2F;blind.shadows1428.com&#x2F; [3] https:&#x2F;&#x2F;mortalkombatgamessupport.wbgames.com&#x2F;hc&#x2F;en-us&#x2F;articl... [4] https:&#x2F;&#x2F;github.com&#x2F;bradjrenshaw&#x2F;say-the-spire [5] https:&#x2F;&#x2F;www.nexusmods.com&#x2F;stardewvalley&#x2F;mods&#x2F;16205 [6] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yQC6TJkBElY [7] https:&#x2F;&#x2F;www.a11yproject.com&#x2F;posts&#x2F;getting-started-with-orca&#x2F; [8] https:&#x2F;&#x2F;support.xbox.com&#x2F;en-US&#x2F;help&#x2F;account-profile&#x2F;accessib.... [9] https:&#x2F;&#x2F;www.playstation.com&#x2F;en-us&#x2F;support&#x2F;hardware&#x2F;ps5-acces... reply idontknoworcare 17 hours agorootparentTheir policy is for you to get a Gameboy clip on magnification panel. Ebay has them. reply danShumway 15 hours agorootparentI don&#x27;t think that would help blind users.In before Steam has moved off of web interfaces (I haven&#x27;t checked in a couple of years so they might be doing something different now particularly with big picture mode), but I&#x27;m frustrated that we all started building interfaces for native platforms in HTML&#x2F;Javascript and it didn&#x27;t lead to embracing any of the accessibility features that those same interfaces would get by default inside of a web browser.To be fair, my understanding is that Linux screenreader support is pretty bad, but it does seem like if a developer is going to the trouble to build the majority of their interface in a semantic XML-like pure-text format, there should probably also be an option to read that text out loud. reply miki123211 15 hours agorootparentPart of Steam is indeed HTML, and that is the accessible part. They&#x27;re rewriting more and more of their UI in that technology, and that&#x27;s definitely a good accessibility move. reply Fluorescence 18 hours agoparentprevI want to see what happens when Gabe retires. If Steam goes public, starts hiring EA management and begins to squeeze the sponge ala Unity, we will regret not challenging Steam&#x27;s supremacy earlier. reply amatecha 17 hours agorootparentYeah, it&#x27;s already bad enough you can no longer play games through Steam that were made for the respective OS, e.g. Windows XP, and soon Windows 7... like, I bought games on steam nearly 20 years ago, and the games I bought at that time were designed to run on the systems of that time (and many haven&#x27;t been updated since). I expect to still be able to play those games on my old computers... but I literally can&#x27;t (unless I pirate them), because Valve decided old computers just don&#x27;t matter and you might as well throw those in the trash, I guess? Cool.Take your favorite game today. In ~20 years, you&#x27;ll be lucky if you can even play it at all.I guess luckily the backup insurance we have is Linux... but that&#x27;s also a matter of how far back of a Linux install you could log into Steam with. I guess we&#x27;ll see. :) reply dpkonofa 8 hours agorootparentCan&#x27;t you just play these in a VM? reply amatecha 7 hours agorootparentWhat OS would I be running in the VM? I still can&#x27;t run Steam on the old OS, and thus can&#x27;t install&#x2F;run the respective game I&#x27;d want to play :( Actually, now that I think about it, I bet a pretty noteworthy % of my Steam library is literally not playable on any OS supported officially by Steam... reply dpkonofa 2 hours agorootparentI&#x27;m pretty sure you have a few options - you can download an old version of Steam and just not update, you can download the games for offline use and then copy them to the VM, you can just download a crack for that game since any game old enough to not be usable on a new OS wouldn&#x27;t have DRM, or you can pirate them (as you said). :) reply gabereiser 12 hours agorootparentprevGabe will find a way to AI himself to be Valve’s CEO in perpetuity. reply fullspectrumdev 18 hours agoparentprevYears ago I lost access to my steam account that I had since HL2 came out.I was able to get back in by emailing Valve support the account name, and photos of the box and serial key HL2 came in.I was genuinely impressed - up to that point I had absolutely despised Steam as DRM shovelware that almost never worked right due to constantly downloading updates over my shitty internet connection. reply aceazzameen 18 hours agoparentprevIt helps that they aren&#x27;t beholden to shareholders and the \"value\" of showing unlimited growth. You&#x27;ll never see enshitification there. They&#x27;re a group of creators who want to create. Sometimes they slip up, but it&#x27;s no more than anyone else would. reply xinayder 12 hours agoparentprevDon&#x27;t forget that:- they did a massive fuck up with Artifact, thinking they could pull out MTG&#x27;s monetization model for an online game (where you didn&#x27;t even receive card as rewards for levelling up, you actually had to spend money to enjoy playing the game)- they released Underlords and killed it right away, the battle pass is still the first one and the game hasn&#x27;t received any balancing patch in 3 yearsUnderlords could be a real good competitor to TFT. and Artifact would be nice to compete against Hearthstone&#x27;s cash grab. Thankfully they actually listened to our feedback and put a nail on the coffin for Artifact. reply dpkonofa 9 hours agoparentprevIt makes me sad to think about what will happen when the guiding lights at Valve grow dim and have to be replaced. I hope that they can continue this culture that you&#x27;re describing. Their games are my favorites, the Steam Deck is incredible, Steam itself is wonderful, and Valve&#x27;s VR platform is the only one that I&#x27;ve ever really enjoyed enough to tell non-tech people about it.Long live Valve. Long live the cabal. reply gumballindie 10 hours agoparentprevFunny how tech companies that are still owned or run by the technical people that founded them are awesome, while those where business bros take over turn to … dust. A lesson to be learned by us, the market, when we spend money. I prefer spending on those still “true” to their core - steam being one of them. I am literarily using linux daily part thanks to them (I still play games sometimes). reply kart23 14 hours agoparentprevwat. enabling kids to gamble with csgo skins and then only doing something about it when it got exposed in the media? the amount of money and stress that minors were going through with the entire csgo gambling racket was insane. they caused real harm imo, and they didn’t even make a change prohibiting it until this year.https:&#x2F;&#x2F;kotaku.com&#x2F;valve-steam-gambling-csgo-skins-ban-18504...they don’t care about gamers wellbeing when the alternative is a money printer.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Skin_gambling reply meesles 19 hours agoparentprevI whole-heartedly agree. They seem good for the right reasons.That said, I&#x27;m scared about the inevitable creep of capitalism. What happens when Gabe retires? Or some legal&#x2F;financial event changes things?I have no reason to doubt them, but history gives me reasons to be cautious with my optimism. We&#x27;ve seen similar parallels with beloved tech companies in the past. reply babypuncher 19 hours agoparentprevDevelopers don&#x27;t get much sympathy from users over Valve&#x27;s store policies precisely because Valve cares so much about the users.Epic makes a big deal about digital storefronts only needing a 12% cut to turn a profit, but Epic isn&#x27;t turning around and investing that money into things that make the platform better for everyone like Valve does (Steam Input, Proton, Workshop just to name a few things). reply johnnyanmac 18 hours agorootparent> Epic isn&#x27;t turning around and investing that money into things that make the platform better for everyone like Valve doesEpic invests in devs. Valve invests in users. I guess the difference in focus is why you&#x27;ll see such different reactions to Valve vs. Epic online vs when talking to actual devs. reply skeaker 18 hours agorootparent>Epic invests in devs.Is this true? I know they pay up front to have exclusivity for some games, but I don&#x27;t know if I would consider that \"investing in devs\" in the same way that Valve \"invests in users.\" Valve puts money into platforms and tools that users enjoy (things like forums, hosting mods, user reviews, community pages) as their investment. Does Epic do something similar for devs? The only thing I can think of is using funds to polish Unreal Engine, but that would only invest in devs that use Unreal which is not really applicable to most devs. reply johnnyanmac 17 hours agorootparent>Valve puts money into platforms and tools that users enjoy (things like forums, hosting mods, user reviews, community pages) as their investment. Does Epic do something similar for devs?Sure,- They invest in Unreal Engine and all the adjacent tech available, some of which can be used without Unreal Engine (Epic Online services). Of course, tech like Metahuman and Quixel want to draw people into UE but if you are already using UE it&#x27;s a strong consideration.- Similar to Unity, they have an asset store which enables some devs to make money selling tools&#x2F;assets to other devs- Lastly they do directly fund various games and tools. The forced exlusivity didn&#x27;t put a good taste in consumers mouths but I&#x27;m mostly talking about Epic Megagrants. No strings attached, they can just throw money at good devs and most notably they invested into Godot and blender (again, no strings attached. True grants just to make open source tooling better).most of their stuff is skewed towards Unreal Engine, but I don&#x27;t see it as any different from Valve being skewed towards Steam. The difference is that consumers want to buy games while devs want to make money. So while there&#x27;s a stronger business angle to every Epic solution, it fits with what a dev would want to do. reply skeaker 17 hours agorootparentAll good points, I had totally forgotten about their asset store as well. Thanks! reply danShumway 19 hours agorootparentprev>into things that make the platform better for everyoneCorrection, for Steam users, not for everyone.Steam Input and Workshop are completely proprietary services that do not work outside of Steam. Steam Input configs are difficult (not impossible, but unnecessarily complicated) to access&#x2F;share across services, meaning that even if you do use Steam, if you bought a game outside of Steam and are importing it, you&#x27;re probably going to be rebuilding the Steam Input config from scratch. Steam Workshop is also inaccessible to games purchased outside of Steam even if you import those games into Steam. And not only has Valve not built a way to link imported games to a Workshop and not provided mechanisms for games to make use of Workshop outside of Steam as an independent service, the company has actually clamped down on efforts to circumvent that DRM and shut down community projects.Both Steam Workshop and Steam Input are very clearly designed to be vendor lock-in. To gamers who only use Steam and nothing else, it feels like Valve is making it better for everyone, but it&#x27;s a lot more like the Apple ecosystem -- Valve is leaving behind anyone who buys games outside of Steam and almost explicitly punishing users who get games from other storefronts. The company offers a lot of services that can&#x27;t be debundled from Steam -- you can&#x27;t as a developer pay Valve to make use of Workshop outside of Steam. And so a lot of these \"universal\" benefits are really only benefits for people who buy games exclusively on Steam.That&#x27;s not to say Valve doesn&#x27;t do great work elsewhere. Proton is genuinely good for the ecosystem, even though Valve still ties it heavily into Steam and combines it with Steam-specific features like shader caches that are inaccessible outside of Steam. I think the Steam Deck is a wonderful device hampered only somewhat by the fact that it&#x27;s so reliant on Steam Input which is entirely proprietary. But it&#x27;s still miles above other consoles and I&#x27;m genuinely grateful that Valve built it and even more grateful that they based it on Linux. It&#x27;s repairable, it&#x27;s far more open than other consoles. Valve might \"punish\" users for installing 3rd-party software on it but at least installing that software is allowed.Valve is neither perfect nor evil. People get enamored with Valve because our standards for companies have fallen so unbelievably far, to the point where just allowing people to install 3rd-party software and responsibly contributing back to an ecosystem that Valve is heavily reliant on feels like being granted an unexpected gift. We&#x27;re used to companies abusing consumers even when there&#x27;s no reason to do so. And so Valve saying \"yeah, it makes more sense to us contribute upstream and it makes sense not to treat our customers like crap\" is a refreshing difference.But Valve is still a company and is still willing to prioritize its own hold on the PC marketplace over consumer and developer rights; it has plenty of vendor lock-in and plenty of proprietary services and systems that are designed to make it so that you as an end-user can buy the exact same game on two platforms and run both versions on the same device, and one of them will literally perform worse, will be harder to configure, and won&#x27;t have mod support. reply skeaker 17 hours agorootparentRegarding Steam input, can&#x27;t you add any program as a \"non-steam game\" and apply custom inputs with it? I haven&#x27;t used it much myself, but as far as I know there isn&#x27;t any sort of lockout on what you&#x27;re able to apply it to.And regarding the workshop, I would be lying if I said that I never bought a game on Steam only for the convenience of using the workshop for said game... But then I have also paid Nexus for their mods because by default they cap downloads at 1 mb&#x2F;s. I am also aware of tools that let you download workshop mods for games you don&#x27;t own. It&#x27;s certainly less convenient to have to manually download them and drag-and-drop them into your mod manager or mods folder or whatever, but they hardly make it impossible, so it&#x27;s not like the mods are actually locked in to the platform. reply danShumway 17 hours agorootparent> can&#x27;t you add any program as a \"non-steam game\" and apply custom inputs with it?I mentioned this -- you can only do so if you use Steam as the launcher, Steam Input is tied to using the overall Steam client. Additionally, you&#x27;ll have to make that config by scratch, Steam&#x27;s community sharing for configs is much more limited for non-Steam games. This seems like a small complaint but if you&#x27;re buying new games you don&#x27;t know what the optimal config is, so the Steam Input experience for non-Steam games is that you load up the game and as you play it you constantly adjust the config until you find an setup that works, as opposed to Steam games where you just download the highest rated community config and go from there.On top of that, there are Steam Input features that flat-out don&#x27;t work for 3rd-party games; specifically input glyphs within the game. Steam offers an API for developers to define \"action sets\" that among other features will make sure that instructions within the game use the correct keybindings and pictures. 3rd-party game are (as far as I can tell) completely locked out of that service.----> I am also aware of tools that let you download workshop mods for games you don&#x27;t own [...] but they hardly make it impossible, so it&#x27;s not like the mods are actually locked in to the platform.I mentioned this as well, Steam has actually gone after and shut down community projects that allow you to do this. It&#x27;s much harder than it used to be and for some games it&#x27;s outright impossible.Steam Workshop is literally DRM as far as I&#x27;m concerned; there are plenty of games that are completely inaccessible. Even if that wasn&#x27;t the case, the inability for 3rd-party games to be linked to Steam Workshop profiles by users is vendor lock-in. The vast majority of gamers didn&#x27;t have the technical skills to route around Steam&#x27;s restrictions even before Steam started shutting down community projects and putting ownership checks in front of downloads.----What would be far more market-friendly and what would actually benefit everyone would be for Valve to debundle those services from Steam -- I&#x27;m not saying every developer should be able to use Steam Workshop for free, but Steam Workshop should not be tied to Steam. It should just be \"Valve Workshop\".There are a lot of games that are Steam exclusive specifically because there are Steam APIs that they can&#x27;t take advantage of on other storefronts. And it&#x27;s very common for games to come to other platforms outright missing features (particularly online content) because developers don&#x27;t even have a choice to pay to utilize those features outside of Steam.I think modding and input configuration are the two most obvious examples of this, but if you&#x27;ve ever bought a game on GoG and then found out after the fact that it&#x27;s missing an entire game mode, Steam is (in my experience) probably the reason for that. reply subtra3t 16 hours agorootparent> Steam Workshop is literally DRM as far as I&#x27;m concerned; there are plenty of games that are completely inaccessibleI think that the Steam Workshop would be at least partially fine IF they allowed all Workshop items to be downloaded without a steam account. And even if a game developer enables this option, steam randomly disables it occasionally and the game developer has to re enable it all over again (this happened with Terraria).Furthermore, its really, really hard to download Workshop items for a lot of games. Short of buying the game (a good $30-70 down the drain), your only options are to:- Download through steamcmd. this only works if the game has explicitly enabled the anonymous download thing I talked about earlier. steamcmd (like the name suggests) also has a CLI which a lot of gamers can&#x27;t&#x2F;won&#x27;t navigate.- Go through external services. These external services often charge you if you download Workshop items for popular games or if you download Workshop items that are new.- As a player playing through steam to download the item and then send it to you. In the Terraria discord server you&#x27;ll find plenty of these people (I&#x27;m one of them!). This also doesn&#x27;t work for games without an active playerbase. reply danShumway 15 hours agorootparentI think you&#x27;ve phrased the problem better than I did.> As(k) a player playing through steam to download the item and then send it to you.If anything this might be my biggest critique of Valve&#x27;s handling of the situation. Even with the DRM on top of Workshop mods, community mirroring of locked-down games would be possible to do in a way that was convenient for end-users outside of Steam... if Valve didn&#x27;t occasionally just straight-up send cease-and-desist letters to those services.It wouldn&#x27;t cover every game, it would still be a problem, there would still be legal and ethical questions about distributing mods without modder consent, but it would be a lot better than the current situation. Right now if a game has those restrictions turned on (which Valve seems to specifically encourage) you kind of have to go underground or interact with shady services or ask players directly, and so coordination between communities becomes very difficult.I can&#x27;t read Valve&#x27;s mind, but I lose a lot of sympathy for them when they&#x27;re both not supplying any option for users to get access to mods without rebuying the game on Steam and stopping anyone else from trying to solve the problem Steam created for them -- at that point it&#x27;s very hard for me to avoid thinking that Valve is being deliberately anticompetitive.I&#x27;d still have criticism of a less locked-down system, but it would be easier for me to assume Valve just doesn&#x27;t see it as worth the effort to support rather than thinking that they seem to be taking a lot of active steps to make the situation worse than it needs to be. reply skeaker 17 hours agorootparentprevThanks for clarifying, in particular about the workshop. I think you&#x27;re right that the service could definitely stand to be decoupled from Steam. While that might be easier said than done (you would still have to implement Valve&#x27;s downloading&#x2F;update checking to match the quality of the Steam client to make it as seamless), it would definitely be huge for modding. I mentioned Nexus in my post to get at the idea that modding for a lot of games is far from an ideal system and you pretty much have to pay to get around that in most cases, but an independent Steam workshop page that developers pay to opt into would be a good approach to that. Now I want them to do it...The input thing does seem like a niche complaint, sorry to say. I don&#x27;t think I&#x27;ve ever encountered that, and I think even if I did it wouldn&#x27;t stop me from playing the game, I would just bind the controls myself. I guess this could be decoupled as well, but I don&#x27;t think the reason that it isn&#x27;t is necessarily lock-in; I would bet that there just aren&#x27;t enough people that care about it, so to Valve it would be wasted effort. But now I&#x27;m assuming intent so what do I know, really. reply danShumway 15 hours agorootparentThat&#x27;s fair, the input stuff is annoying but it doesn&#x27;t get in the way of actually being able to play the game or get content -- stuff like modding and multiplayer&#x2F;online storage is arguably a much bigger issue than needing to build your own controller mapping. I just think it would be really low-hanging fruit.SDL is currently working on an Action Set equivalent, and I think their plan is to just use configuration files on disk for the most part. So in the same way that ProtonDB is mostly community maintained and outside of Steam and you can look up a game&#x27;s settings and apply them to a 3rd-party game, what I think would be the easiest improvement would be allowing arbitrary search for community-supplied configs and moving that to be an independent URL that Steam hits that just downloads an encapsulated config file that Steam reads.There is some way to do share non-Steam configs, if you link a 3rd-party game in Steam you will sometimes in community configs and then see a subset of the normal configs? I have no idea how that subset is calculated or if users need to do something to enable it though, the entire interface around sharing Steam Input configs even for games purchased from Steam is a little bit of a mess, or at least it is on Steam Deck.I feel like I&#x27;m settling by saying this because I&#x27;d also like straight-up input binding outside of Steam, but even ignoring stuff like action sets, 3rd-party clients -- just being able to load a community config by typing a game name into a search box instead of needing to build my own would get rid of a lot of my problems, particularly for control schemes like flick stick that require me to take measurements of mouse&#x2F;gyro sensitivity.----> but an independent Steam workshop page that developers pay to opt into would be a good approach to thatMy current plan for my own games I&#x27;m working on is to leverage git for modding support -- I&#x27;m not going to build a studio-specific mod hosting service or partner with a company, I similarly don&#x27;t really like ModDB that much and don&#x27;t think they&#x27;re great community players. So instead I&#x27;m going bundle a small git client with the final game and use that to download&#x2F;update mods and handle stuff like versioning, readmes, etc...That doesn&#x27;t help with discoverability or ratings, but my thought process is that a lot of games (Terraria, Celeste, Hollow Knight, etc..) are organized around Github&#x2F;Gitlab&#x2F;Codeberg already for the primary modding engines, so at least if people are using that they can get issue trackers and embedded wikis, there&#x27;s a standard way to download, it encourages releasing the mod source, you can look at activity to see whether or not a mod is active, you can have beta branches, you can check for updates without re-downloading everything, you can have a canonical source URL without wondering if a mod is only updated on Workshop&#x2F;ModDB&#x2F;whatever.At least for the moment I don&#x27;t plan to enable Steam Workshop for any of the games I&#x27;m working on, I think git will give me most of the same features minus a search function and user ratings. To be fair, search and user ratings are pretty important though, so :shrug: I&#x27;ll see how that goes. reply gabereiser 8 hours agorootparentprevFirst off, Steam Workshop. The way Workshop works is it requires deep integration into the asset management of the game. This deep integration often requires custom build of the game to support it. Stitching packages of assets isn’t something a small team wants to tackle. Workshop will do that for you. The reason you can’t just drop in any game and have it “workshop ready” is because Workshop needs to know how to deliver assets to your game. It’s needs developers to do some legwork to register that stuff. You aren’t downloading zip files like it’s FTP. You’re downloading signed asset packages in the engines own format. If you’re using Unity or Unreal that has multiple asset package management capabilities this is trivial. If you’re running SDL2 or your own Vulkan renderer, you’ve got a bunch of work to do parsing and stitching assets bundles and layered ordering loading of asset files. reply danShumway 6 hours agorootparentMod packages have been a thing long before Steam Workshop existed and long before Unity&#x2F;Unreal. Steam didn&#x27;t invent modding.And if mod support for non-Steam games was as technically challenging as you suppose, Valve wouldn&#x27;t need to be sending cease and desist letters to community projects that redistributed mod files. Valve wouldn&#x27;t need to be verifying purchases before allowing users to download files.The fact that Valve is putting additional technical and even legal barriers in front of mod redistribution means that it&#x27;s not just that the mods wouldn&#x27;t work without a special Steam build. The reality is that many of the mods would work, and that is precisely what Valve is trying to prevent. Tools that allowed for loading mods from Steam Workshop weren&#x27;t shut down because they didn&#x27;t work, they were shut down because they did work.----There&#x27;s a somewhat weird deference here to technical issues, but it&#x27;s not clear whether you&#x27;re claiming that developers are solving those issues or Valve is.Saying that Workshop needs to deliver assets in the \"engine&#x27;s own format\" is really just another way of saying \"different games need to be modded differently.\" But that has always been the case and yet before Steam Workshop modding files were distributed and installed manually. Similarly, asset patching and replacement for games has always been a thing. And mods worked.To the extent that mods today are drag-and-drop, they are drag and drop because the developers put in the work. Valve is not going into engine source code, decompiling everything, and then figuring out how to get the mod to work. They&#x27;re providing APIs and mechanisms for developers to tell Steam Workshop how to modify the game files.So unsurprisingly, the majority of mods that work in Steam work outside of Steam because once the developer puts in the work to build a modding system that&#x27;s compatible with the assets and files that Steam workshop downloads and once those assets are patched for a version of the game, then developers are shipping that same version of the game on multiple platforms (unless they&#x27;re using proprietary Steam APIs, in which case it&#x27;s probably a Steam-exclusive game anyway).Whatever APIs Steam is providing for Steam Workshop, there is no reason those APIs need to be restricted to Steam. A debundled service could provide the same stitching and the same APIs on-demand for games outside of Steam.----Now, if you wanted to defend some of Valve&#x27;s other anticompetitive behavior, such as precompiling shader caches, that would be much easier for you to do, since shader caches are not only game-version specific, they are also often platform-specific, and there&#x27;s very little way for Valve to provide those assets without knowing exactly what version of the game is installed where. It&#x27;s not like Valve can compute a single set of shaders and then just give them to everyone, they&#x27;re dependent on the actual install.But mods aren&#x27;t in that position. Developers are putting in the work to support modding, games have to opt-into this system anyway so it&#x27;s not like 3rd-party installs can&#x27;t report to Steam Workshop what version they are, it&#x27;s not like games who are adding modding support can&#x27;t upload resource files to a debundled Workshop to be modified. And the end result of that process would work for games outside of Steam, as evidenced by the fact that in the instances where you can download mods from Steam Workshop and get access to the files, they tend to work in versions of the game from alternate storefronts.This is another way of re-saying -- if this was actually a technical issue, Valve would not need to put barriers in place keeping people from downloading mods outside of Steam. If it&#x27;s so impossible for Valve to support mods outside of Steam, then fine, they don&#x27;t have to do anything. Just get rid of the extra barriers they&#x27;ve constructed and let communities solve the problem for them without interference. But Valve isn&#x27;t willing to do that. The reason Steam Workshop has such poor support outside of Steam isn&#x27;t because it&#x27;s an impossible technical problem, it&#x27;s because Valve is taking active steps to prevent people from accessing those mods. Valve could do literally nothing to support Workshop access outside of Steam and the situation would be better than it is today. reply babypuncher 17 hours agorootparentprevSteam Input and Steam Play both work fine with games bought elsewhere, you just have to add them as non-Steam games to your library.Though even if they didn&#x27;t, I can&#x27;t see how these features being exclusive to Steam \"punishes\" users for buying games elsewhere. The most probable alternative scenario is that these features wouldn&#x27;t exist at all.The biggest alternative to Steam Workshop is Nexus Mods, which is ironically far less friendly to mod developers. reply danShumway 17 hours agorootparent> Steam Input and Steam Play both work fine with games bought elsewhere, you just have to add them as non-Steam games to your library.I&#x27;ve talked about this in a sibling comment more, but as far as I can tell, no they really don&#x27;t. Valve does ownership checks for a nontrivial number of games before downloading workshop mods. And I&#x27;m not sure where you&#x27;re getting the idea that 3rd-party games can be linked to the workshop, I am not aware of any mechanism to do that. I&#x27;d definitely be using it if it existed :)Steam Input partially works with 3rd-party games but won&#x27;t work with things like glyphs and seems to (in my experience) have very limited support for searching for existing configs.> The most probable alternative scenario is that these features wouldn&#x27;t exist at all.I strongly disagree with this, and I think if we slip into thinking in this way, you can excuse almost any abusive behavior. It&#x27;s just as plausible to say that without Epic&#x27;s exclusive sponsorship a number of indie games also wouldn&#x27;t exist -- and in fact many developers have outright said that Epic is the reason their games were able to be funded at all.But I&#x27;m not going to give Epic bonus points for doing timed exclusives, it&#x27;s still abusive behavior. And similarly I&#x27;m not going to give Valve bonus points for building services that are arbitrarily tied to a specific storefront. There is no reason Steam Workshop and Steam Input couldn&#x27;t be debundled from Steam.We&#x27;re on here praising Valve for upstreaming code to Wine through Proton. If Wine wasn&#x27;t already Open Source and Valve had built it from scratch, I don&#x27;t believe they would have Open Sourced it. What I&#x27;m asking for (particularly with systems like Steam Input which could be standardized outside of Steam and which are heavily reliant on clientside APIs that run entirely locally) is for Valve to not conditionally engage with Open Source communities only when they have to or are they working with codebases that are already Open Source.\"We wouldn&#x27;t build this if we weren&#x27;t able to use it for lock-in\" is how companies get away with a lot of consumer-abusive behavior. And I just don&#x27;t buy it -- if anything, the opposite is more likely true; we might have standardized on more Open mod platforms and might have gotten true platform-agnostic controlling binding support within libraries like SDL much sooner if Steam Input didn&#x27;t exist and games&#x2F;gamers weren&#x27;t able to just ignore the problem and stick with Steam&#x27;s solution. reply ffgjgf1 19 hours agorootparentprevJust like Apple? I do agree with you overall but 30% is still excessive reply happymellon 19 hours agorootparentBetter than Apple.Apple don&#x27;t reinvest in creating open standards, and don&#x27;t invest in improving user experience for everyone.Their investments are generally to increase lock-in. reply subtra3t 16 hours agoparentprevThey had the means to implement a good refund policy for Steam (evidenced by the fact that they have a good refund policiy now) but they didn&#x27;t implement it until they were legally forced to. reply c-hendricks 18 hours agoparentprevSteam Input alone gets them a lot of respect from me. reply waihtis 16 hours agoparentprevWell said. Many Valve products have been absolute artisanal masterpieces. Very rare today. reply 2OEH8eoCRo0 19 hours agoparentprevOther than DRM, what&#x27;s not to like about Steam policies? reply alexb_ 19 hours agorootparentThey&#x27;ve caught a TON of criticism for Counterstrike cases, which is where they make an absolute crapload of money. I don&#x27;t think it&#x27;s a big deal, but others do. reply belltaco 19 hours agorootparentprevTaking 30% of indie developers revenues while being a near monopoly, so indie devs have to be on Steam. Something like Epic&#x27;s 12% would be a fair cut given storage and bandwidth costs have gone down over the years. Being able to keep an additional 18% of their game&#x27;s revenue would be huge for developers. Some may call it rent-seeking. reply ric2b 18 hours agorootparentThey&#x27;re a monopoly in the same way that Amazon is: they&#x27;re not, there are plenty of popular alternatives and publishers aren&#x27;t locked from selling wherever else they want.They&#x27;re just the biggest player and the 30% cut is worth it for all the additional sales. reply belltaco 16 hours agorootparent>there are plenty of popular alternativesLike what? GoG? And what else? reply xcdzvyn 16 hours agorootparentEpic Games comes to mind. Or just buy the game from the developers. reply 2OEH8eoCRo0 18 hours agorootparentprevAh, that&#x27;s a fair criticism. reply no_time 15 hours agorootparentprevErosion of the concept of ownership. I can lose access to the content I have paid full price for through no fault of my own. Just because they&#x27;ve decided to no longer support the platform I&#x27;ve never stopped using. Also not being able to resell the product I supposedly \"own\".To be fair, none of these things were pioneered by Valve, but more of a general change in what society accepts as the new normal.Even though I can remove SteamStub DRM with an automatic tool to solve these issues, It still irks me how there isn&#x27;t a regulatory solution to these problems reply sangnoir 19 hours agorootparentprevI don&#x27;t know if this is accurate, but IIRC, if you&#x27;re banned, you lose access to even the single-player games in your collection. reply Ekaros 19 hours agorootparentI don&#x27;t think that happens. You might lose access to features and multiplayer, but not the games you own.At worst, you cannot buy more games or gifts or trade your items. But you can still download the single player games you already have.EDIT: Generally it seems account suspension is possible, but that usually means they noticed something illegal or extremely suspicious activity. reply Quikinterp 19 hours agorootparentprevThat sounds odd, because how does your steam account even get banned? If you cheat in a game and get banned, your steam account isn&#x27;t banned reply lvass 18 hours agorootparentAFAIK most horror stories are from people who move between countries, particularly from one with \"cheaper\" prices like Argentina to one with more expensive ones. Not sure if the account itself gets banned but the games previously bought do get locked out. reply mjh2539 15 hours agorootparentprevBack in the day playing on VAC servers and attempting to use exploits would get your whole account banned. reply ant6n 19 hours agoparentprevBut when will Half Life 3 be released. reply johnnyanmac 18 hours agoparentprevThey haven&#x27;t really cared about games since Portal 2. Counterstrike simply enabled them to benefit from their own marketplace, which spread to other games. And we don&#x27;t need to Talk about Artefact. Alyx was really good but inherently niche given its focus on VR (which made sense, because they had a hardware investment in VR).They have billions so they can do both games and services if they want to. But it sounds like there was a lot of brain drain from the game designer perspective as Valve&#x27;s priorities shifted. Why risk something as unstable as a game if you can focus on steady income from others making games? reply danShumway 15 hours agorootparent> Alyx was really good but inherently niche given its focus on VRI&#x27;m being pretty critical of Valve on here in other places, but I would say that taking the time to make an excellent game even though a platform is niche and even though that game is essentially just a hardware advertisement and even though that advertisement isn&#x27;t likely to move that platform to be non-niche to me shows a strong commitment to good game design.Alyx didn&#x27;t really need to exist I don&#x27;t think. I don&#x27;t think it moved the needle on making VR any less niche. I don&#x27;t see it as a good economic move. And yet it&#x27;s arguably one of the best shooters on VR.I do think they&#x27;re a lot less interested in game development than they used to be, I do have criticisms of some of their monetization schemes, but whenever they do get interested in games enough to actually make something, they seem to do a pretty good job of it. Even with Artefact, I&#x27;m not sure if the game was bad as much as just part of a crowded market and burdened with Valve&#x27;s (admittedly awful) monetization philosophies for games as a service. reply coffeebeqn 17 hours agorootparentprevAs much as I like half life games, there are a handful of studios capable of creating interesting sci-fi shooters but no other company can really have things like Steam Deck, Proton, etc. as some of their core products reply johnnyanmac 17 hours agorootparent>no other company can really have things like Steam Deck, Proton, etc. as some of their core productswell of course not. These aren&#x27;t product that directly make money. Maybe a small chinese startup can do it, but they would still prefer to ship with Windows.I only really played Portal so I have no real fond memories of TF&#x2F;CS&#x2F;HL. But I&#x27;m just saying that Valve definitely has the money to invest in games if they really wanted to. reply entuno 20 hours agoprevI don&#x27;t have a Steam Deck, and I&#x27;ve never used SteamOS. But it&#x27;s been incredible over the last few years how much better the support for games (both old and new ) on Linux has become, to the point where it seems more likely than not that a game will be playable.It&#x27;s been great to see that Valve have been pushing so many of their improvements upstream rather than trying to keep them to themselves - long may it continue. reply coldpie 19 hours agoparent> It&#x27;s been great to see that Valve have been pushing so many of their improvements upstream rather than trying to keep them to themselves - long may it continue.Yes, the Linux team at Valve really understands how open source incentives align with their own. Since they & their contractors upstream almost everything they do, they don&#x27;t have to maintain a diff, or even build most of the software they ship (they just use Arch packages for most stuff, as mentioned in the article). Unlike many proprietary companies who try to keep as much as possible in-house, Valve understands you get higher quality software with a lot less work overall when you work with and are friendly to upstream projects, even if it means a bit more work and negotiation up front.I was the creator & lead dev on Proton for its first 5 years (2016-2021), and from day 1 Valve understood that most of the work we did for them would be going upstream[1]. It wasn&#x27;t even a conversation point in the early meetings. They&#x27;ve taken the same approach with every other OSS project they&#x27;ve worked with, and it shows in the great results & community relations. Valve is a great open source citizen.[1] E.g. https:&#x2F;&#x2F;www.codeweavers.com&#x2F;blog&#x2F;aeikum&#x2F;2019&#x2F;3&#x2F;27&#x2F;how-proton... reply ncallaway 19 hours agorootparent> I was the creator & lead dev on Proton for its first 5 years (2016-2021),Wow, than k you. I know it takes a village, and it’s always a team effort, but still thank you. My windows PC is gathering dust now. I only use my Linux laptop and steam deck now. If a game doesn’t run on Linux, I just won’t play it anymore.That’s a huge change, and I really appreciate it.Thanks to everyone who contributed. reply coldpie 19 hours agorootparentThanks, it was quite a ride! Definitely a team effort, not only developers, but also a fantastic QA team that puts a ton of work into polishing every single release. Also don&#x27;t forget that Proton was built on top of 20 years of hard work on Wine before Valve even entered the picture.I know I&#x27;m not the only (ex-)Wine&#x2F;Proton dev who posts here on HN :) reply yomlica8 16 hours agorootparentIt bothers me a bit when I see the narrative on here that the introduction of the Steam Deck changed everything for linux gaming, but really it is a culmination of steady ongoing work that didn&#x27;t even start with Valve. I&#x27;ve been primary linux gaming since probably about 2014. When Steam machines fizzled out Valve just quietly brushed it off and continued investing in the general concept. reply entuno 14 hours agorootparentThere was a huge amount of work by WINE (and others), but it really was a huge leap in how accessible Linux gaming was to people.Going back a few years, my experience was that you had to do some research to see if a game was likely to work, install it through wine, and then usually faff around with a load of winetricks&#x2F;configurations&#x2F;packages&#x2F;etc to get a game that mostly worked (often with some weird bugs, performance issues, etc).Now there&#x27;s a whole library of games that you can just right click -> install and they work perfectly well on Linux. And of course that wouldn&#x27;t have been possible without the years of work building up to it - but it was a massive improvement when Valve threw their weight behind it and built it directly into the Steam client. reply xethos 15 hours agorootparentprev> When Steam machines fizzled out Valve just quietly brushed it off and continued investing in the general concept.I remember being really disappointed when they did - I assumed gaming on Linux would be following the same path, because what the fuck kind of company breaks down a wall by repeatedly bashing their forehead into it?Steam machines did not do well, and instead of Valve saying \"Maybe this is a money pit we should abandon\", they just shoveled money into it until it was mostly full. replyACS_Solver 17 hours agorootparentprevThank you for your, and your team&#x27;s, work on Proton! It&#x27;s one of the biggest software leaps I&#x27;ve experienced. I&#x27;d been using Wine to launch games on Linux for more than ten years and across all those years, it remained inconvenient and success rates remained fairly low despite some definite improvement. Then with the first Proton release, most of the games I wanted to play... just worked. These days my default expectation has changed to games working well on Linux unless they have stuff like kernel-mode DRM (such as Denuvo) and I refuse to buy games using that anyway. reply danparsonson 19 hours agorootparentprevSide note: thank you for your contributions to Linux gaming - Proton helped me finally shed Windows as a base OS and I couldn&#x27;t be happier about it. reply solardev 19 hours agorootparentprevDo you think Mac gamers would ever see similar love, like Game Porting Toolkit integrated into Steam? reply coldpie 19 hours agorootparentI don&#x27;t know anything about Valve&#x27;s future plans, and I don&#x27;t know anything at all about that toolkit (it was announced after I stopped working on Wine). My gut feeling is it&#x27;s unlikely. There was a lot of incentive to target Linux with this tech, even though it&#x27;s a smaller market than macOS, because you can control the whole stack and do cool stuff like SteamOS, which is what allowed the Deck to happen. On macOS, all you can do is sell stuff to end-users, where you also have to compete with the Apple store, which is owned by Apple, who also make the OS. Apple has also shown they&#x27;re a bad partner for game companies (nuking 32-bit support; crummy OpenGL support; no Vulkan suppo",
    "originSummary": [
      "Valve is contributing significantly to the Linux and open-source community via their work on the Steam Deck and SteamOS, collaborating with open-source consultancy Igalia on various improvements in the Linux ecosystem.",
      "They've made contributions to Mesa OpenGL and Vulkan drivers, kernel graphics driver components, and have been involved in expanding support for case insensitive file-systems, the development of the Gamescope Wayland compositor.",
      "Their support extends to immutable software updates and Flatpak. This magnitude of contributions has had a positive influence on the Linux desktop ecosystem beyond just the gaming sector."
    ],
    "commentSummary": [
      "Valve, creator of the Steam platform, is lauded for its contributions to the open-source community and its endeavors to enhance the gaming experience, despite facing initial criticism.",
      "There is a spectrum of opinions regarding Steam's refund policy and its role in real money gambling, along with concerns about the platform's compatibility with older games.",
      "The recent launch of Steam Deck has boosted gaming accessibility on Linux, though it's anticipated that Mac users may not reap the same benefits due to constraints within the macOS ecosystem."
    ],
    "points": 866,
    "commentCount": 338,
    "retryCount": 0,
    "time": 1695391044
  },
  {
    "id": 37613054,
    "title": "Paisa – Open-Source Personal Finance Manager",
    "originLink": "https://paisa.fyi/",
    "originBody": "I have been using plaintext accounting for some time and had a duct-taped together reporting system. Paisa is my latest attempt at making it usable for others.I am interested in knowing what people normally want to understand about their financesPS: Please avoid editing the demo data. Download and run locally if you want to edit.",
    "commentLink": "https://news.ycombinator.com/item?id=37613054",
    "commentBody": "Paisa – Open-Source Personal Finance ManagerHacker NewspastloginPaisa – Open-Source Personal Finance Manager (paisa.fyi) 549 points by ananthakumaran 19 hours ago| hidepastfavorite218 comments I have been using plaintext accounting for some time and had a duct-taped together reporting system. Paisa is my latest attempt at making it usable for others.I am interested in knowing what people normally want to understand about their financesPS: Please avoid editing the demo data. Download and run locally if you want to edit. 8589934591 21 minutes agoI&#x27;m a longtime user of gnucash and this is a great product to convince me to move to ledger&#x2F;hledger.Question for author - Is it mostly a reporting tool or does it work similar to h&#x2F;ledger where I can input my transactions from paisa?Question for HN users - have you found ledger to be easier to use compared to gnucash? My challenges have been my lack or ease of understanding on how to input transactions in ledger and also getting good reports comparable to gnucash. It&#x27;s highly likely I&#x27;m unaware of how to use the tool properly but I am not sure where to learn this. reply pasc1878 58 minutes agoprevUnfortunately I can&#x27;t see your web site as it does not work without sending cookies to Google. Please implement the site with only needed cookies.NB this means that your site cannot be used in Europe, reply bbor 0 minutes agoparentIf you have time, could you clarify how you can tell that? I just opened it in Europe and the blurb seems to pass “these cookies are for internal self-improvement of the product only” (see below). Is your problem that google is managing the analytics so could be spying, or that the stated use isn’t essential? We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they&#x27;re searching for. With your consent, you&#x27;re helping us to make our documentation better. reply robcohen 18 hours agoprevThis looks awesome. I love that it&#x27;s built on ledger. I have been wanting to move away from Simplifi Money for some time for obvious reasons (owned by Intuit). It seems that the real moat is pulling the data in a consistent and correct way. Yes, you COULD try to find every single export option for every bank, but I think Plaid is really the only service that pulls this data somewhat correctly, due to the U.S. not having a PSD2 equivalent in our laws.So the question is, would it make sense to have a Plaid plugin for this? Obviously because they are a 3rd party, it negates some of the benefits, but I simply cannot use this system manually because I have so many accounts. Maybe one workaround is to pull from Tiller (which uses plaid), then export a csv&#x2F;excel.Any chance there&#x27;s a good plan in place to get automated data imports working, even if we need a 3rd party to do it? reply avirut 12 hours agoparentOne option I&#x27;d recommend for anyone working towards this is to use the SimpleFIN Bridge [0], which is basically an API wrapper around MX (a Plaid competitor) designed for personal use by the same people that make Budgeting with Buckets. Data security is definitely an issue, but I value having my transactions automatically imported more than I&#x27;m concerned about the risk of SimpleFIN being breached.I&#x27;ve personally used SimpleFIN to provide automatic imports in my own personal, kind-of selfhostable personal finance tool [1].[0] https:&#x2F;&#x2F;beta-bridge.simplefin.org&#x2F;[1] https:&#x2F;&#x2F;github.com&#x2F;avirut&#x2F;bursar reply itissid 18 hours agoparentprevMint already uses Plaid, but I the transaction information it gets is too low in information to categorize anything reasonably. For example my Amazon Grocery transaction happen on my amazon Chase Credit card(gives me 5% discount).But connecting to Chase.com using plaid pulls in transaction statement is still information poor. The obvious consequence of this is that budget information is not correctly reflected in Mint(that info is actually in my Amazon.com silo). The only way to fix this rn is sadly manually.As a tangent, I do feel though that LLM agents that can one day act on individuals behalf, reading info and making this manual job far more easier in absence of any govt regulations. reply avarun 18 hours agorootparentMint does not use Plaid. Intuit has their own service for integrating with bank APIs and&#x2F;or screen-scraping that they use across all their products. reply marwis 8 hours agorootparentThey used plaid as a fallback for some banks reply parkerhiggins 5 hours agorootparentprevCopilot Money achieve Amazon SKU description automatically by AuthN into your Amazon account and transaction matching.They do this lack of info lift and then recommend category splits. reply ananthakumaran 17 hours agoparentprevI can try to improve import functionality, but Plaid etc is quite hard. I can&#x27;t even figure out their pricing model from their page. So, as a free app I don&#x27;t think it can support Plaid. reply phoenixy1 17 hours agorootparent[I work at Plaid] The pricing model is here: https:&#x2F;&#x2F;plaid.com&#x2F;docs&#x2F;account&#x2F;billing&#x2F; but @jpeeler is right that for a free app like this aimed at an audience of engineers you could also set it up for your users to BYO Plaid API keys. reply rendaw 2 hours agorootparentHow much would it generally cost for a user? I couldn&#x27;t figure it out from the pricing page. reply robcohen 14 hours agorootparentprevThis is the precise option I was thinking might be possible. Is it even reasonable for an individual developer to use their own API keys for something like this? I assume because you suggested it, it is. Any limitations that are impractical for personal use? reply debaserab2 14 hours agorootparentI&#x27;m in the middle of going down this path right now. It kind of works, except for certain banking institutions require more rigor than just getting accepted into the developer platform.The steps, as far as I can tell, look something like this:1) Sign up for Plaid developer account2) Request developer access (without it you can only play with sandbox data)3) Request production access4) Submit application information including a name, website URL, and logo5) Add a legal company entity name and address to my plaid account6) Sign an MSA contract (no idea what its about)7) Fill out a security questionnaire.I&#x27;m at step 3 currently but I&#x27;m not sure how much further I&#x27;m realistically going to get. I&#x27;m not sure I could reasonably fill the rest without stretching the truth quite a bit and it seems to get deep into legal territory that I&#x27;m not sure I&#x27;m comfortable with.There&#x27;s also apparently different API behaviors depending on the bank: https:&#x2F;&#x2F;plaid.com&#x2F;docs&#x2F;link&#x2F;oauth&#x2F;#institution-specific-beha...I don&#x27;t have a lot of hope that this is going to pan out. I&#x27;m considering just scraping Chase with a headless puppeteer script instead.It&#x27;s possible that this may be simpler for other banks though, I&#x27;ve only tried Chase since that&#x27;s my primary bank. reply phoenixy1 13 hours agorootparent[I work at Plaid]I will say that while annoying (especially for Chase, which has the most paperwork-type requirements for developers) this process should be totally doable for solo developers. You can put your own name as the legal entity name if you don&#x27;t have a company. The Master Services Agreement (MSA) sounds scary but is just the contract between you and Plaid -- the legalese laying out what you&#x27;re paying for, what Plaid is providing, and the rights and obligations of both parties. And when it comes to the security questionnaire, fill it out as accurately as you can, but you don&#x27;t need to stress over it -- Plaid doesn&#x27;t expect a solo hobbyist to have the same security measures as, like, a publicly traded company. reply akerl_ 12 hours agorootparentCan confirm: I did this as a solo user of a personal API integration with Chase via Plaid. I answered honestly given the scope of what I was doing: for example, IIRC there was a question about whether all employees are background checked, and another about how we deal with terminated employee access. As the only user&#x2F;employee&#x2F;human, I could confidently say I background check all my employees and that if they’re terminated, their access will be promptly revoked :D reply debaserab2 13 hours agorootparentprevThanks for the info -- this is really good to know. I&#x27;ll keep pressing on as far as I can! replyjpeeler 17 hours agorootparentprevYou just need to have each person create their own Plaid account (which is probably the way you want it anyway). The free tier supports 100 institutions.Last time I looked at this, I thought it was stated that the free&#x2F;sandbox tier is not guaranteed to have the same SLA as the production environment. But I can&#x27;t find this in the documentation anywhere. reply phoenixy1 17 hours agorootparent[I work at Plaid] I don&#x27;t know if we explicitly write down in the docs that the free Development tier isn&#x27;t guaranteed to have the same SLA as the production environment, but if you&#x27;re not paying Plaid there is no SLA (I mean, the usual recourse for an SLA breach is a rebate, but you can&#x27;t give a rebate to someone who isn&#x27;t paying you in the first place). That said, in practice the differences between the free and paid tiers for a personal finance app are not really such that someone doing a hobbyist app for personal use would notice them. reply debaserab2 13 hours agorootparentCorrect me if I&#x27;m wrong but some of the banks don&#x27;t work in developer mode at all (at least, it doesn&#x27;t seem to work with Chase). reply phoenixy1 9 hours agorootparentAll banks work in the free Development environment, but for banks on OAuth, including Chase, you need to go through the Production approval vetting as a pre-requisite. Once you&#x27;ve been approved for Production (and if applicable for the given bank, gotten your security questionnaire approved as well -- I think Chase requires this) you can then access those banks in Development for free. replysalmaanp 14 hours agorootparentprevI would use this if there was an easy way to integrate it with plaid. (login once and keep data synced). This would be comparable to personal capital at that level. reply dingdong33 6 hours agoparentprevReason are not obvious to me. Could you elaborate? reply hackernewds 13 hours agoparentprevWhat is PSD2 and why is it important? Is it the basis for something like UPI in India? reply sailorganymede 13 hours agorootparentPayment Services Directive 2 and it’s basically legal stuff we gotta comply with to do payments. Can’t speak for India but it’s v much something in the UK reply malermeister 15 hours agoparentprevI know this is only vaguely related, but as a European that&#x27;s been looking for an open source budgeting solution, how does PSD2 help? reply robcohen 14 hours agorootparentMy understanding of PSD2 is that it requires banking transactions to be \"machine-readable\" whatever that means. So there&#x27;s an actual legal requirement for making data accessible outside of the browser. reply ghosty141 12 hours agorootparentThe problem I faced when I looked at data export was that none of the banks had any apis. You always had to go through 3rd party commercial apis. Maybe there are ways bur I didnt find them reply jtha 11 hours agorootparentIf you&#x27;re talking about European banks they all have APIs. But only licensed companies can use them directly. Those companies are called AISPs within the PSD2 framework, sometimes referred to as aggregators. Some of them have ways for individuals to access their own accounts at banks via the AISP APIs. But there are limitations, one major one being that PSD2 doesn&#x27;t cover credit card data or anything other than deposit accounts. [I&#x27;m a product manager at a bank] reply dylmye 7 hours agorootparentprevyou should check out Actual budget as well - works perfectly for me in the same situation. replyscubakid 18 hours agoprevIt&#x27;s interesting how many tools can analyze where your money has been going, but few go deep on the planning + forecasting side.Have you thought about building out the \"retirement\" module more? If you need any inspiration, I&#x27;ve been working on a personal finance simulator [1] for the past two and a half years as a side project.Really great job with the docs on this, and I love that you include a demo environment!I imagine that eventually we&#x27;ll see an app that pulls budgeting, tracking, and planning all together in a fully seamless way. Whoever manages that will probably be a force to be reckoned with.[1]: https:&#x2F;&#x2F;projectionlab.com reply ananthakumaran 17 hours agoparentI have seen projectionlab before and agree with you. There are few tools on the forecast side. Most of them stop at budgeting. I do have plans to make retirement page generic (aka Goals&#x2F;Target), but I am yet to figure out the details.In an ideal world, double entry accounting would be your database and there would be lot of tools that use that and focuses on a specific niche. But we are far from that and everyone wants to create their own data island. reply sanat 7 hours agorootparentThis is a nice interface that you could emulate for some of the goals&#x2F;target level details. I quite like the simplistic UI.It&#x27;s a lead magnet for an Indian PMS service.https:&#x2F;&#x2F;plan.capitalmindwealth.com&#x2F; reply Brajeshwar 19 hours agoprevNostalgia. I led a small team in 2009 and built Paisa.com - a financial&#x2F;investment Startup. I still have the initial mockup designs I did in a hotel room in Delhi&#x2F;Gurgaon to pitch to NDTV. reply 19f191ty 11 hours agoparentI remember that! I really liked it. What happened to it? And what are you upto these days? reply Brajeshwar 4 hours agorootparentIt is a long story, but here is the short from my perspective. I left after a year and made the mistake of spending two years building an audio-video dating app. Poor men’s FaceTime-ish tech, but the business failed. However, I sold&#x2F;transferred the tech to an investor.When we released its beta, early users were happy with the new-age design and one of the best user experiences in a web app for India. Later, I heard MoneyControl sued Paisa.com (I’d consider that a success).The Paisa team went on to become Helpshift.com. One of the founders became an investor, and another is now the co-founder of teamohana.com. Another key member started his own Startup, later acquired by GoJek.And a lot of stories in between. It all started in 2007-2008 when I started in a spare attic in my erstwhile boss’s office and assembled a small but brilliant team. I retained that Startup’s domain for a long time and sold it this year. I need to write about all of this one day. A few publications have written strange stories about it, and I’ve not been interested enough.Now, I’m doing things with Satellite and stuff for Climate and the like. reply jaipilot747 18 hours agoprevThis is incredible!Great job building this and also writing the documentation that explains concepts as well as how they are implemented.I can&#x27;t believe how many comments here are dismissive. If you are happy using a paid solution to manage your finances and don&#x27;t want to get into the weeds yourself, you are probably not the target audience for this.One suggestion would be to make the country-specific pieces like tax calculations module so others can contribute their own. reply redact207 17 minutes agoparentI&#x27;ve been looking for a personal finance app for a long time. I don&#x27;t want a Saas that charges me monthly and can shutdown at anytime. Most other homebrewed apps are incomplete or abandoned. Of all things I ended up paying for an Excel sheet to track it all - https:&#x2F;&#x2F;cspersonalfinance.io&#x2F;This tracks all my cashflows, investments, net worth etc, and since it&#x27;s in excel there&#x27;s no risk of it disappearing after 10 years reply ananthakumaran 18 hours agoparentprev> One suggestion would be to make the country-specific pieces like tax calculations module so others can contribute their own.This is something I have been thinking about, I need to figure out the base abstraction. Even the current implementation (which is basically written for my personal use cases) has too many conditions&#x2F;grandfathering etc, I suspect it might not be accurate. reply kelnos 4 hours agoprevWow, this is fantastic! I&#x27;ve been using GNUCash for some simpler tasks, like tracking income and expenses for a rental property, not for all of my personal finance. But GNUCash is... kinda clunky, and I&#x27;m not sure of the best way to share the data, as my partner would appreciate having access to it too.I love that this has a web interface, but still seems to have a fairly simple data model based on `ledger` and plain text files.I see some other posts about data import from banks, and that&#x27;s always been the thing keeping me from doing this for all of my personal finance. I just don&#x27;t think I&#x27;d be able to keep up if I had to manually log into bank, brokerage, and credit card accounts, download my data for each one (assuming they even allow a CSV-style download), and import into GNUCash (or whatever).I&#x27;m curious about the Plaid option (and really cool a Plaid employee is posting here), but I&#x27;ve always been wary of them. It looks like they have some sort of OAuth-like process for one of my financial institutions, but the others are all \"give Plaid your credentials and we promise to keep them safe\". Not really comfortable with that. Everyone gets hacked eventually. Regardless, I&#x27;m not too keen on giving Plaid literally all of my financial data; just doesn&#x27;t seem like a great idea.But it seems like there&#x27;s really no alternative, at least in the US. I wish the government would mandate that all of these institutions implement a standardized API, and that they give regular people (not just big companies) access to their own data through it. Sigh... reply dvdkon 2 hours agoprevI was looking for some software that I could use to make sense of my bank transactions from imported statements, and sadly found that none of the FLOSS options I tried could import the counterparty&#x27;s bank account number.I have to ask, do people mostly enter transactions manually into their personal finance software? Or do they just go by names for imported transactions? This means that I can&#x27;t meaningfully import transactions between my multiple accounts. Do others just fix them up manually? reply danielvaughn 10 hours agoprevTools where you control the underlying data in plain text are severely underrated. I love this. reply ibdf 17 hours agoprevHow are people automating the data import? I can&#x27;t imagine someone entering everything by hand. Lots of places don&#x27;t even provide an export file you can work with... most of them offer a PDF.It seems like most financial places rely on Plaid for the data integration, but that&#x27;s a paid service I don&#x27;t think Open-Source or free personal finance apps would use. reply rmuratov 26 minutes agoparentI use hledger and I enter everything by hand.I used to dread it too. But actually, in normal life, the volume of daily transactions is not that large. Besides, filling out a journal disciplines you. And VS Code does autocomplete for accounts and payees. reply freddie_mercury 5 hours agoparentprevI enter everything manually. I live in SE Asia where there&#x27;s no other option, really. For some of my banks there&#x27;s not even a CSV&#x2F;Excel download option, just a PDF \"balance statement\".I (mostly) don&#x27;t find it too onerous. But it is very much Inbox Zero. If you keep on top of it then it isn&#x27;t much additional effort. While I&#x27;m waiting for the cashier to make change or print a receipt or while I&#x27;m walking out of the shop I can enter the transaction. But if I let a few days of them build up it becomes a more annoying 5-10 minute effort.Also you need to do manual entry for anything you pay with cash anyway.But the manual approach starts to fail in a family unless all involved are on-board with the data entry. (Which is almost never the case in my experience.) In practice that means all of my wife&#x27;s expenses are a bit of a black hole. reply bogwog 12 hours agoparentprevSome years ago I built a custom tool similar to this which downloaded financial data from my Chase bank account and converted it to beancount (another text-based accounting tool).Chase charged like $10&#x2F;mo or something like that for using OFX to download your bank statements (which is pretty ridiculous considering what it is). Eventually I abandoned it because none of the other bank accounts I needed to track offered OFX or anything similar that I could find, and just gave up. reply BeetleB 14 hours agoparentprevMost banks&#x2F;CC have some sort of export - be it in CSV, OFX, Quicken, etc. Then you import it using your financial story.The real pain is in the categorization (was this Groceries, Supplies, Dining, Medical Expense)?I use KMyMoney which usually picks the same category as the last transaction from the same place. Saves some of the work, but it&#x27;s still painful. I then wrote a script to export from KMyMoney to ledger format. reply alchemist1e9 7 hours agorootparentReckon works well enough for me.https:&#x2F;&#x2F;github.com&#x2F;cantino&#x2F;reckon reply astral303 11 hours agorootparentprevCategorization seems like low-hanging fruit given the age of AI we are in today. reply BeetleB 7 hours agorootparent> Categorization seems like low-hanging fruit given the age of AI we are in today.AI can assist, but that&#x27;s it. When I go to a Kroger&#x27;s store, I may buy food. Or I buy supplies. Or medicine. Or gifts. Or something else. And almost always a combination of these. We are already at 5 categories, without mentioning others. All my CC will report is a transaction at Kroger&#x27;s. How is an AI supposed to guess how much I spent on each? reply all2 2 hours agorootparentTake a picture of the receipt and a picture of your groceries, pipe them to appropriate models? reply ska 10 hours agorootparentprevYou think so? They have such inconsistent reporting, and the data is the exactly hard kind to aggregate massive sets of. reply eredengrin 17 hours agoparentprevAs far as standard checking&#x2F;savings&#x2F;credit card accounts go, I haven&#x27;t had one that didn&#x27;t have a csv export option yet. Some of them are very buried and much harder to find and use than I wish, but they are there at least with the banks I use. reply bdcravens 7 hours agoparentprevYou can sign up for a developer account and have up to 100 accounts that you access. reply Gualdrapo 18 hours agoprevToday I learned \"paisa\" is a subunit of the Indian rupee - here we call \"paisa\" to all things related to a specific region of Colombia (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Paisa_(region)) reply qingcharles 9 hours agoparentI think paisa literally translates as \"country man.\" In jail every older Latino is automatically a \"paisa\" and it is seen by many as a derogatory term. reply codegeek 18 hours agoparentprevThe word \"Paisa\" is also used generally for \"money\" depending on the context. But specifically, 100 Paisas = 1 INR (Rupee). reply cultofmetatron 18 hours agoparentprevits also a term used to refer to women with a certain \"look\" from medellin. my ex was an example. \"paisa as an areppa\" is a pretty common term there. reply theviajerock 12 hours agorootparentWhat? Yeah, that&#x27;s a say, but \"Paisas\" are all the people from Antioquia (Medellin is the capital), Quindio and Risaralda. All of us are Paisas. That say could be referenced to any person from there, because of the look or way to talk or just because we were born there. reply sdfghswe 17 hours agorootparentprevTell us, what does it mean? \"as an areppa\" suggests flat and round...? reply criloz2 17 hours agorootparentIt&#x27;s the same as saying \"American as a burger\", arepa is just a traditional food in Colombia, a bread made of corn reply sdfghswe 17 hours agorootparentOk but I was wondering if you&#x27;d describe the \"look\". reply cultofmetatron 12 hours agorootparentthis should help https:&#x2F;&#x2F;www.tiktok.com&#x2F;discover&#x2F;Paisa-girls reply cultofmetatron 12 hours agorootparentprevto be honest, I don&#x27;t actually know but I&#x27;ve heard it from multiple people when I was in Medellin in reference to girls. none of them were \"flat and round.\" I think it just refers to them being from the same area. \"american as apple pie\" reply MenhirMike 17 hours agoprevHas anyone compared this to YNAB4? (Not the cloud-only subscription-only YNAB, but the good one that was killed off in 2019)It&#x27;s by far the best household bookkeeping tool I&#x27;ve ever used, but it won&#x27;t ever get updates again (running it in a VM just so I can make sure I will always be able to run it), and it would be nice to have something that can track stocks and maybe even foreign currency - but for now, I would be happy with something that can just replace YNAB4.The lack of Quicken OFX Import is a bummer :( But if the CSV import is good, it would still work. (As much of a pain as OFX is to implement for developers, especially since there&#x27;s at least two major versions, it is pretty widely supported by US banks to download my transaction history)Will probably give it a spin on the weekend, since the demo actually looks promising! reply nirvdrum 6 hours agoparentI&#x27;ve been pretty happy with financier.io as a replacement. I pay the $12 a year for hosting, but I think you can get by running a CouchDB server somewhere. The author basically stopped working on it so its future may be in question, but he open-sourced the code. It&#x27;s just an Angular application.I may have been using YNAB wrong, but I had allowed budget categories to go negative and gradually fill them back in. Financier imported all of that data with 100% fidelity. YNAB5 couldn&#x27;t do that and it&#x27;s one of the key reasons I didn&#x27;t upgrade. I wasn&#x27;t keen on losing my historical budgeting data and starting all over (YNAB&#x27;s official recommendation). reply Dennip 9 hours agoparentprevhttps:&#x2F;&#x2F;actualbudget.org&#x2F; Actual has OFX support! Really great tool reply MenhirMike 5 hours agorootparentOh wow, this does look REALLY good, at least the demo does! Going to give it a spin. reply JTyQZSnP3cQGa8B 17 hours agoparentprevI use YNAB 4 every day on macOS thanks to patches available online for the Adobe Air framework (from 32 to 64 bits). What OS are you using? reply MenhirMike 17 hours agorootparentI use Windows, though I did download the 64-Bit macOS patch just in case I ever need it. Mostly just playing it safe in case there are future incompatibilities because they&#x27;ll have to pry YNAB4 from my cold, dead hands - unless I find an actual alternative :D reply cec 8 hours agorootparentprevIs a MacOS build of YNAB 4 still available? reply MenhirMike 6 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;banesto&#x2F;YNAB4-64bit&#x2F; reply ska 10 hours agoparentprevHave you tried gnucash? It does currencies, stock, properly (even journaling), etc., OFX import. reply ananthakumaran 17 hours agoparentprevOFX is unheard of in my country. I would look into it if someone could open a issue and attach a few sample OFX files. reply MenhirMike 17 hours agorootparentYeah, it&#x27;s an American thing mostly, I think (it originates from Quicken). I know that Germany used to have another standard, HBCI (which is now FinTS?) and I&#x27;m not sure what other countries do.OFX is a huge PITA to implement, I&#x27;ve tried it and realized I would want to get paid to put up with it :) I&#x27;ll try the CSV import, if it works then there&#x27;s no need to overcomplicate stuff.The Demo looks really good by the way, and props for actually having one! reply bakul 13 hours agorootparentprevPerhaps you can just use https:&#x2F;&#x2F;github.com&#x2F;aclindsa&#x2F;ofxgo - it seems to be a pretty good Go package (just eyeballing it, haven&#x27;t use it). reply BOOSTERHIDROGEN 2 hours agoprevI’m using beancount with fava as UI, any experience why you choose based on Ledger vs Beancount ? Thanks reply ananthakumaran 2 hours agoparentNothing specific, I was even looking at adding support for beancount then realized it&#x27;s much more strict and doesn&#x27;t support some features like periodic transactions (which I use for budgeting) reply asdajksah2123 18 hours agoprevHere&#x27;s something that always trips me up when I look into non professional software for double entry accounting (or more accurately, instructions around them).It&#x27;s been a long time, so I may be getting it wrong, but I do have some introductory information of accounting. And according to that, in a transaction such as salary received, the accounting would look something like:Income: Salary - CreditAssets: Checking - Debit.The Golden rule&#x2F;s that apply here (Debit the receiver, credit the giver)However, looking at the tutorial, the example given is:2022&#x2F;01&#x2F;01 SalaryIncome:Salary:Acme (Debit Account)Assets:Checking (Credit Account)This is the opposite of what I expect, however, I see this all the time when looking at tutorials&#x2F;information written by SW devs.What am I missing or is everyone else just getting it wrong? reply PopAlongKid 17 hours agoparent\"Debits and credits are nothing more than “increases” and “decreases” to accounts.\" Don&#x27;t try to apply logic; it is just a convention: debits to the left, credits to the right.In particular, the first example above is correct. An asset account is increased by debits; a credit increases a revenue account.Salary received:Income: Salary - CreditAssets: Checking - Debit. reply gunnaraasen 11 hours agoparentprevMost tutorials for financial services are written for bank account users.People refer to their bank account colloquially as a \"debit account\" and \"credit account\" because those are the types of accounts offered to them by a bank. From the bank&#x27;s perspective, a consumer debit account is (correctly) considered a \"debit\" since any money deposited into the account by the account owner is an asset for the bank. reply hliyan 8 hours agorootparentActually shouldn&#x27;t any money deposited into the bank be a liability for the bank? reply elbasti 16 hours agoparentprevThe gnuCash documentation has it as you describe: debits checking and credits salary.https:&#x2F;&#x2F;stuff.mit.edu&#x2F;afs&#x2F;sipb&#x2F;project&#x2F;gnucash&#x2F;1.6.4&#x2F;arch&#x2F;i3... reply thuruv 18 hours agoparentprevThats correct with DE accounting. However I always assumed, the logic followed here is that the money has been \"debited from\" the INCOME account and \"CREDITED to\" Assets&#x2F;Checkings. reply asadjb 11 hours agorootparentMy somewhat limited understanding of this is that from your perspective, an increase in your asset&#x2F;cash account would be a debit.A big confusion for me initially was that my banks always talked about crediting my account whenever money was deposited&#x2F;added to my account.I finally understood it when I realized that from the banks perspective, an increase in my account is an increase in their liability towards me; they now owe me more money. Which is why they call it crediting my account.So now I think of it like this: an increase in an asset is always a debit, an increase in liability is always a credit. reply john2x 13 hours agorootparentprevDebit from employer&#x27;s account, credited to your bank. reply mcshicks 18 hours agoprevThis looks really cool I&#x27;ve used beancount&#x2F;fava for tax planning, but of course I had to code up my own tax models. In the US tax table change every year (by a predictable formula) and some forms of income are weird, like I bonds are exempt from federal tax, but are taxed by state income tax. It seems unlikely that you could support all the cases, but is there a straightforward way to plug in your own model? I did see in tax.go you had long term, short term, but couldn&#x27;t quite find the income tax tables, like long term capital gains has different rates depending upon filing status and amount. reply ananthakumaran 18 hours agoparentI have replied at another thread, but there is no plugin support as of now. My country changes the rules every year and add grandfathering, xyz rules etc. I think, I have to figure out a DSL or some other way to make it general. This is something I am interested, but haven&#x27;t figured out how to solve it yet. reply tmikaeld 18 hours agoprevThis is great!If you could add multi-language support, then I&#x27;m sure my family will use it :)> I am interested in knowing what people normally want to understand about their financesFor my family use cases - seeing upcoming expenses and how much is left in the account on the specific dates in a calendar time-flow view, this way we can see how and when things are spent and if new entries are added we can plan for how much is left at a specific target date (like a trip). I&#x27;ve seen nothing like this, so would be extremely useful. reply ananthakumaran 15 hours agoparentI don&#x27;t know what you mean by multi-language support. But calendar view on Budget page is something I can think about. I will soon add a calendar view to Recurring page. reply jaipilot747 18 hours agoparentprevHaven&#x27;t used it but it sounds like this feature would work?https:&#x2F;&#x2F;paisa.fyi&#x2F;reference&#x2F;budget&#x2F; reply Fire-Dragon-DoL 6 hours agoprevI love the idea, but to me one of the key things is being able to record expenses manually from the phone, in the same account my wife uses. I&#x27;m stuck with ynab for this requirement reply thelazyoxymoron 6 hours agoparentGive Actual Budget a try: https:&#x2F;&#x2F;actualbudget.org&#x2F; reply hawk01 4 hours agoprevAmazing I stumbled across Paisa a while back on plaintextaccounting subreddit and has come a long way since reply edoceo 18 hours agoprevI want to know where my money goes. I like to look at stacked-area (or column) charts of the categories of spending. To make this work I have some software I made ~20 years ago that does double-entry book-keeping. At the end of the month, I import statements from financial service providers (eg: Wells Fargo, Chase, PayPal, Stripe, etc). Lots of stuff is repeat purchases (eg: Shell Gas) and my software automatically categorises. Some transactions I have to categorise manually. Each category &#x2F; vendor becomes an expense-account and my banks and CCs exist as assets and liabilities.Once the import and reconciliation is done I pull up a my column chart that shows where the money went -- and can compare over time -- see a full year of movement. I&#x27;ve been through various charting libraries with it and most recently moved to ECharts[0] -- so I&#x27;m planning to expand with Treemap and Sankey style visuals.The import process, which I do monthly takes maybe an hour. I&#x27;m importing from like 5 bank accounts, 3 payment processors, 4 CC providers. The part that takes the longest is signing into their slow sites, navigating past pop-up&#x2F;interstitial, getting to their download page and waiting for it to download. Loads of these sites (WF, Chase) have been \"modernised\" and have some real bullshit UI&#x2F;UX going on -- lags, no keyboard, elements jump around, forms can&#x27;t remember state, ctrl+click won&#x27;t open in a new page cause that damned link isn&#x27;t actually a link but some nested monster of DIVs with 19 event listeners on each one -- and somehow still all wrong.I think the most-best feature would be to have some tool automatically get all my transactions from all these providers into one common format. Gimmee some JSON with like 10 commonly-named fields for the normal stuff and then 52 other BS fields that each provider likes to add (see a PayPal CSV for example). Does that exist and I just don&#x27;t know?[0] https:&#x2F;&#x2F;echarts.apache.org&#x2F; reply alchemist1e9 7 hours agoparentI’m in a similar boat and this comment has an interesting link.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37613525 reply bbkane 14 hours agoparentprevI don&#x27;t know about a service that does this, but you might be able to script the website logins with https:&#x2F;&#x2F;playwright.dev&#x2F; reply bakul 18 hours agoprevLooks good! Paisa Vasool! Especially as it is free :-)You don’t have to, of course, but do you plan to open source it? That way others can contribute to it too.How tightly is it bound to ledger? How hard would it be to adapt it to other plaintext accounting programs like beancount? reply dkjaudyeqooe 18 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;ananthakumaran&#x2F;paisa reply bakul 18 hours agorootparentVery good! Thanks! reply mahoro 18 hours agoprevThis is awesome! I like how it&#x27;s built and I looks like it&#x27;s open for integrations of any kind.I&#x27;m also too impatient to manually enter all transactions but import from PDF statement form a bank looks like a doable task. The only transactions that would be required to enter manually is cash&#x2F;crypto&#x2F;etc but for them there are no other choice.Contrats with the the release Anantha and I hope your project will gain attention it deserves! reply ananthakumaran 17 hours agoparentFeel free to open an issue if you can&#x27;t get PDF import working. This is something I am interested in improving. I have tested with few PDFs and they are hit&#x2F;miss based on how the data is encoded. reply GingerMidas 18 hours agoprevAwesome! I&#x27;ve been using Beancount&#x2F;Fava for over 2 years now and this looks really slick.One thing off the bat I noticed, it doesn&#x27;t look like custom Tags are supported? I use tags all the time in beancount, say to filter for a trip #trip-europe-2022 which would break down my cash flow and balances (and the rest of the fava UI) for a subset of transactions. reply ananthakumaran 18 hours agoparent> One thing off the bat I noticed, it doesn&#x27;t look like custom Tags are supported?Not as of now, Tags are used only for recurring transactions as of now. I first need to figure out how to bring the filter into the UI. Everything now works based on Account names only. reply GingerMidas 18 hours agorootparentMakes sense - great work so far! This is easily the best looking PTA app I&#x27;ve seen. reply charles_f 18 hours agoprevThis looks very similar to Beancount, which has been around for a while and has quite the community and extensions.How does this differentiate? reply ananthakumaran 18 hours agoparentIt is quite similar to Beancount Fava. I want to focus and improve some of the things like app distribution (desktop&#x2F;single cli binary) and the UI (reporting) and make it accessible for more users. reply arun-mani-j 17 hours agoprevIt&#x27;s nice and has a lot of quite advanced features.If you want a simple app to track lent and borrows among friends and circle then try Debitum. But it&#x27;s for Android only..https:&#x2F;&#x2F;github.com&#x2F;marmo&#x2F;debitum reply trippyrooster 14 hours agoprevI have a tool to easily convert bank csv&#x27;s to ledger format https:&#x2F;&#x2F;github.com&#x2F;muralisc&#x2F;bank2ledger-cli reply wreck 17 hours agoprev@ananthakumaran, can this be installed via Docker and ran in the browser like your demo[1]?[1]: https:&#x2F;&#x2F;demo.paisa.fyi&#x2F; reply ananthakumaran 17 hours agoparentYes, check the installation page https:&#x2F;&#x2F;paisa.fyi&#x2F;getting-started&#x2F;installation&#x2F; reply cryptozeus 4 hours agoprevGreat work but not useful unless there is integration with 3rd party via plaid reply mr-karan 19 hours agoprevLove this project! I&#x27;ve been trying out Paisa off late and it&#x27;s been great at just de-cluttering my investments in various assets (which are spread all over). reply lijok 14 hours agoprevThis looks great.Semi-related to this: does anyone know of any double entry ledgers backed by actual databases like dynamo? reply ffpip 17 hours agoprevLove the app, will try it for a few days. Thanks for making it. Hopefully I can contribute after trying it for a few days! reply esosac 16 hours agoprevhaving using hledger for a little more than a year, this is all my reporting dreams came true. thank you so much reply eviks 17 hours agoprevIs there any good non-web non-plaintext (which is unsuitable for rich data despite its initial allure) alternative? reply aidenn0 4 hours agoparentgnucash? reply thrway9925235 16 hours agoprevI must admit as a Western-denomination consumer I was thrown off by the display of the monetary convention such as this --> 1,25,80,568 then realized it must be in Lakh and the author coming from this convention. The difference in perception is interesting. reply danscan 18 hours agoprevThrilled to see something like this building on Ledger (a great tool by itself). Will definitely check it out! reply miroljub 18 hours agoparentI like the fact that the author supports both ledger and hledger. reply anjel 9 hours agoprevAny plans for a Linux version? reply ananthakumaran 9 hours agoparentCli is already available for linux (which provides the same functionality, just that you have to use the web browser instead of desktop window)For desktop app I plan to add support soon. The delay is because there are too many variations (appimage&#x2F;flatpak&#x2F;deb&#x2F;snap) and I need to figure out which one to support etc. I use linux myself (NixOS). reply grudg3 8 hours agorootparentany plans to get this into nixpkgs? reply ananthakumaran 8 hours agorootparentThe project comes with a flake.nix file, you can try that (you would still need to build it manually, I use the flake only to bring the dev environment, not to build the final package). I don&#x27;t plan to submit to nixpkg myself or any other package managers. I will only focus on binary builds that&#x27;s downloadable from release page. I don&#x27;t have any experience with maintaining distro level packages, and I don&#x27;t think I can figure out the details and keep it maintained. I will leave it to the community to figure that out. reply aidenn0 4 hours agorootparentI had to modify the flake.nix to get \"npm run build\" to work replysdfghswe 18 hours agoprevWhat is the difference between this and GnuCash?GnuCash also allows you to generate reports from double-entry accounting. reply VinLucero 18 hours agoprevLove the clean interface example into ledger-cli! reply flandish 14 hours agoprevI use “pocketsmith” because I like the look ahead calendar view. Does this offer that? I could not see it in the demo. reply SanjayMehta 9 hours agoprevIt has a CLI? And it’s on macOS? I’m sold. reply jonathankoren 17 hours agoprevI got turned off with the cookie popup. There&#x27;s literally no reason why you need any of that. You want to know which pages people are visiting? Mine your htaccess logs. reply ananthakumaran 16 hours agoparentUnfortunately this is hosted on github pages and I can&#x27;t get usage information without using 3rd party analytics. reply dvdkon 2 hours agorootparentJust so you know, opt-out cookie banners are illegal in the EU. If you want to only measure visits, there are alternatives to Google Analytics that don&#x27;t even require a notice, since they don&#x27;t record personal information (Plausible is one, but there are many others). reply jonathankoren 14 hours agorootparentprevWell then, I guess the two solutions are obvious. reply bbkane 14 hours agorootparentI think he&#x27;s happy with the solution he found... reply cultofmetatron 18 hours agoprevwow, now I can say I like my personal finance manager the way I like my women. reply waynesonfire 17 hours agoprevi won&#x27;t use any finance manager that doesn&#x27;t employ the envelop method, like ynab.looking at the demo for 10 seconds it looks like a web based gnu cash. reply BeetleB 14 hours agoparentThis is based on ledger, which actually does allow envelope based budgeting via virtual accounts. No idea if Paisa handles virtual accounts well. reply ananthakumaran 13 hours agorootparentPaisa supports budgeting and the model is inspired by YNAB. It doesn&#x27;t use virtual account, but uses periodic transaction which is simpler from data entry perspective, but achieves the same thing reply BeetleB 13 hours agorootparentNot trying to be argumentative, but every time I&#x27;ve heard someone claim they do envelope budgeting in ledger without virtual accounts, I&#x27;ve always found a flaw in their approach.[1] So let me give you the standard scenario:I have two checking accounts, and a credit card. I budget $300&#x2F;mo on groceries. Sometimes I buy groceries with my credit card, and sometimes using money from either of those two checking accounts.Last month I spent $200. This month I&#x27;ll spend $350. I should see that I have $50 left in the envelope. At the same time, I should see an accurate amount of money in my actual checking accounts&#x2F;credit card (i.e. despite doing automatic transactions).How do you do this with periodic transactions, and without a virtual account?[1] Same goes for Beancount. The author was adamant one could do it without virtual accounts, but never showed a way to do it. reply ananthakumaran 8 hours agorootparent> Not trying to be argumentative, but every time I&#x27;ve heard someone claim they do envelope budgeting in ledger without virtual accounts, I&#x27;ve always found a flaw in their approach.[1] So let me give you the standard scenario:I fully understand. I spent some time looking into the details and if you do it via ledger command line, this is probably the only way to do Envelope method.Now, Paisa is a bit different, I can process the info before presenting it to the user. The fundamental data that we require is1) what is the actual spend 2) what is the budget.Periodic transaction is a type of transaction which is completely ignored by ledger unless you try to forecast. So this fits my use case perfectly. When I export transactions from ledger, I will know whether it&#x27;s forecast&#x2F;normal transaction. Forecast is ignored everywhere, so your checking account balance will show actual balance everywhere. But if you go to budget page, it will take the forecast transaction into consideration. It will show what is the current balance, month end balance if the forecasted spends are done etc.Again, the fundamental difference is, Paisa can process the output of ledger and it can get away with asking the user to provide the bare minimum data (actual, forecast in this case) reply 2Gkashmiri 2 hours agorootparentprevdouble entry accounting would solve this problem by aka \"contra\" entries most of the time.one thing would be to have a petty cash \"virtual account\" that pulls money in from your checking account(s), credit cards and pay off groceries from there. that would not be helpful when auditing actual payments because you did actually pay directly from a certain bank and not the pool but this should be simpler for personal use. reply AlanYx 15 hours agoparentprevYou can easily do the envelope method in ledger (aka. ledger-cli if you&#x27;re searching for it), which is the back end for Paisa. reply freitzkriesler2 19 hours agoprevI honestly just use excel but that&#x27;s because I use it as a book of record for receipts as well. Since you&#x27;re looking for open source alternatives, OpenOffice would fill that need. reply girishso 16 hours agoparentI tried Excel few years back, it’s only easy when all you are tracking is income and expenses. But when you buy some stocks or MFs, the amount is debited from Bank but it’s not really an “expense”. And good luck tracking fund flows between your own accounts.I’ve finally settled on hledger for now. There’s some issues, mainly the reports are generated by calendar year, there’s no support for Financial Year reports (Apr-1 till Mar-31 in India). reply 2Gkashmiri 1 hour agorootparenthave you tried something like gnukhata? it should work out for you i suppose reply freitzkriesler2 7 hours agorootparentprevWhoever down voted me can suck a fat bag of d1cks.The trick with making excel work is treating your finances like a company with assets and liabilities. Build out your balance sheets, list it out, and compute it. reply lionkor 18 hours agoprevSlightly off topic but how do people use these? Depending on where&#x2F;what I pay, I pay with an assortment of credit cards, bank account, debit cards, paypal, etc.Do people who use this kind of software manually enter every transaction they do every day, or something? reply maherbeg 18 hours agoparentIf you use hledger, you can actually write a csv importer directly in the tool: https:&#x2F;&#x2F;hledger.org&#x2F;import-csv.htmlI wrote my own idempotent parser before this existed but would give this a try first reply GingerMidas 18 hours agoparentprev> Do people who use this kind of software manually enter every transaction they do every day, or something?Yes, exactly that. You can do automatic imports of your bank statements but that&#x27;s arguably more hassle.It takes 10 minutes at the end of my day to record all my transactions and it gives me a complete understanding of where my money is going. reply teeray 18 hours agorootparent> It takes 10 minutes at the end of my day to record all my transactionsI’d love to be able to do this, but realistically (for me), I’d need something that works reliably on my worst days. If I’m out late, on vacation for a few days, dealing with some on-call thing all night, etc., I don’t want to be beholden to a 10-minute per day commitment that accumulates linearly. Discipline can only get me so far in the face of chaos—automation can take me the rest of the way there. reply cortesoft 18 hours agorootparentprevThis would be a lot harder if you have a spouse and want to track your family finances. It would require both people working together to keep it up to date, and finding that time is tough with kids.For all the concerns and problems over tools like Mint, having all 10-20 accounts we have automatically sync their data into the system makes it so much easier to manage. reply helij 15 hours agorootparentWe don&#x27;t find it hard. We sit down one or two times during the week in the evening and I enter all our transactions into KMyMoney. It takes 5-10 minutes to do once you get the hang of it. This is across 5-10 accounts. You might have a little more work to do with 10-20 accounts.On Paisa (ledger). I like it! But...KMyMoney has such a nice interface for recurring&#x2F;future payments and reports (that I can edit to suit our needs) that I&#x27;m struggling to see the point of ledger behind gui for our use case. It does look nice though. reply brewdad 18 hours agorootparentprevI do the bank import once a week. I set aside an hour on my calendar to update all of my spending accounts. It usually takes more like 15-20 minutes unless I find something unexpected.For longer term accounts like my 401k, IRAs, and brokerage accounts, I track money going in our out but only update the gains&#x2F;losses every 6 months or annually on Dec 31st. reply n6242 18 hours agorootparentprevI only do it every few days but pretty much the same. I find it&#x27;s too easy to lose track of how much I&#x27;ve been spending, so by doing it manually I always notice before it becomes a problem. It also helps me save because I notice right away if I get charged for a subscription I&#x27;m not using and I can cancel it. reply BeetleB 14 hours agorootparentprev10 minutes a day is a lot! That&#x27;s 300 minutes a month. I do it about once a month and I probably do 2-3 hours. reply plibither8 18 hours agoparentprevNot to be that guy that tries to force LLMs into everything, but after automatically importing bank transactions, LLMs like GPT are very powerful in extracting information from the ill-formed, non-standard, transaction description, and subsequently classifying it. You can help train it by manually identifying and classifying the first few, and let it do the rest of the job. I&#x27;ve tried it out myself and works well for me! reply MenhirMike 17 hours agorootparentHow would LLMs really help though if all you get is usually an order number? I mean, it can probably figure out that an order from McDonalds is food related (though does it get categorized as \"Everyday Lunch\" or \"Going out with Friends\" or \"Work Events\"?) and Geico will probably be some sort of Insurance - but that would just be a large database of common payees, no real need for any AI. That said, if you&#x27;re importing years worth of data, it would be a great starting point to get ballpark estimates of where your money goes, so that has value.And then there&#x27;s e.g., \"Amazon Transaction AB2314ACWERF\" which could be a new Fridge (\"Household Appliances\"), a 3D Printer (\"Hobby Expenses\"), a video game (\"Entertainment Expenses\"), or a giant double-headed adult massager (\"Fax Machine Maintenance\") - but the bank statement wouldn&#x27;t have enough information. reply plibither8 16 hours agorootparentYep, that&#x27;s one of its deficiencies! For me, something like GPT helps in triaging and \"cleaning up\" bulk of the transactions, with little micro-categorization left to be manually done. reply palidanx 17 hours agorootparentprevI played around with this quite a bit with chat gpt 4 with confirmation instructions, and after a bit of time it starts going haywire. I played around with just creating in a simple csv format, transactions date, name, category (asking it to categorize it), and amount. After a couple runs it started going haywire and hallucinating with transactions I never created.I created an internal rails clone of financier.io and just created a spreadsheet web area i could copy&#x2F;paste mass transactions in so i could add a batch at a time ( I suppose I could upload a csv also, but the problem is every bank has different formats) reply ananthakumaran 16 hours agorootparentprevI have tried this and it works very well. I just copy paste my investments data from website and put it as a comment and usually copilot will figure out how to format it as a ledger transaction based on the previous transactions.I am not sure if it will work with bulk import though. It&#x27;s easy to spot mistakes with single entry, hard to do when you have lot of them reply boredtofears 17 hours agorootparentprevWhat software have you used that does this?So far every time I&#x27;ve relied on automatic categorization for this sort of thing it fails horribly. I don&#x27;t think I&#x27;ve used anything that&#x27;s GPT based though. reply plibither8 16 hours agorootparent> What software have you used that does this?I wrote my own script that uses the GPT API. For automating bank transcation downloads, it&#x27;s just a cronjob that runs ever X hours and scrapes the information from the banking website. reply boredtofears 15 hours agorootparentWould you be willing to share the prompts you use? reply figmert 18 hours agoparentprevI&#x27;ve kind of been thinking that there needs to be an open source version of Yodlee&#x2F;Plaid. I keep picking up some project like Paisa and then realise that I have to figure out how to import things automatically. I don&#x27;t really have the patience to do it manually.But for a few months now I&#x27;ve been thinking an OSS service that does this might be great for such OSS projects. Maybe I&#x27;ll eventually start it. reply boredtofears 17 hours agorootparentI think the problem is that you need to establish a business relationship with the giant banking systems to get them to give you access and unless you have contacts or a way into that world this is very hard to do. I don&#x27;t know how you&#x27;d pull it off in an OSS project. reply hackpelican 18 hours agoparentprevI used to host an instance of Firefly III, which has a perfectly usable mobile web interface.This way, I would log every transaction immediately rather than wait until I get home. reply jcpst 18 hours agoparentprevAt least with ledger cli, the format for a transaction is simple enough that a just make a script that reads the CSV that I can export from my bank’s website.But to your point, it’s still a lot of customization and manual work, I never keep up with it for more than a month or two reply MenhirMike 17 hours agoparentprevMost banks (at least in the US) allow a data export, usually in Quicken&#x2F;OFX or CSV format. I download the transactions from my accounts once a week or so and import it into the tool. (PayPal gets charged to my credit card, so it shows up on the credit card import, no need to track PayPal separately)I currently use YNAB4, and I&#x27;ve assigned categories to Payees, so when it sees a transaction to e.g., my local Pub, it knows to categorize it as Food. For stuff like Amazon or eBay, I need to manually categorize each transaction, but that takes a minute or two. reply poisonborz 18 hours agoparentprevYes, I do this for over 15 years every day. You can easily train yourself, it never \"breaks\" and takes only a few seconds. reply wingerlang 18 hours agoparentprevI download my bank&#x2F;cc statements once every few months and run them through some homemade cleanup scripts, then I could technically plug it into a tool like this. reply jonathankoren 17 hours agorootparentI also have some clean up scripts, but the worst part is I have to manually select the tables to extract in the PDF using Tabula. There&#x27;s still some serious manual reconciliation between credit card and bank statements. I feel good doing it, but it&#x27;s a slog.Technically, I might be able to get something similar by using some website to download everything, but honestly I don&#x27;t trust them. I don&#x27;t want all of my banking, investment, and spending information consolidated in one place for some tech bro douche bag to sell off to some richer fucks and then lose it to some hackers.https:&#x2F;&#x2F;tabula.technology reply ananthakumaran 16 hours agorootparentPaisa supports PDF import (very rough implementation), but the problem is actually simpler compared to what tabula is trying to solve. I just need a 2 dimensional array and then the template can easily filter out non financial data by checking if specific column is Date. I have tried it personally on a few PDFs, it worked well except one which had a two column layout. reply Zaheer 18 hours agoparentprevThe paid accounting tools usually will have integration with your banks via Plaid or similar reply progx 18 hours agoparentprevI do this since ~20 years with a simple Calc-Table. Easy overview and simple to search. reply fstrazzante 17 hours agoparentprevSplitwise user here reply boredtofears 18 hours agoparentprevI&#x27;ve been attempting to build a little hobby budgetting app the past couple weeks that could automatically sync from my bank since none of the OSS options seem to be able to this and require manual logging.I thought this would be fairly straightforward but it&#x27;s been anything but that - what few open formats there were for this thing are all being sun-setted and most US based banks seem to only allow API access of any kind to established companies. The only real option is to go through Plaid which still seems to require initiating a business relationship with them to get through all the red tape.For whatever reason, if your in the US, real time syncing of this sort of thing just isn&#x27;t an option at the personal level.Only other solution I can think of at this point is to manually scrape with a puppeteer script. reply eredengrin 17 hours agorootparentThere is a middle ground I think - all my banks&#x2F;credit cards (7 or 8 accounts spread across 4-5 providers) offer csv downloads of transactions. I haven&#x27;t tried to automate downloading the csv, but once the csv exists locally automation becomes straightforward. But yes, for real-time automated gathering of the data, this wouldn&#x27;t be appropriate I imagine. reply velcrovan 19 hours agoprevI am probably the target audience for this kind of thing, but I’m having trouble seeing myself slog through hundreds of household transactions every month (or putting in the time to automate transaction imports from my credit union and credit cards). I’m happy to huck money at YNAB to do all this for me, on top of which they give me an app that my wife and I can both use to check the budget and enter transactions on our phones. Reconciling the accounts and budgeting for the next month becomes maybe a half-hour exercise. Whereas with Paisa I see nothing but entire weekends lost in service of the machine. reply abdullahkhalids 18 hours agoparentGnuCash can import directly from your bank [1]. There are also some mobile apps [2], but they are not super well integrated with the desktop application - I think you have to manually export and import every time.[1] https:&#x2F;&#x2F;www.gnucash.org&#x2F;docs&#x2F;v5&#x2F;C&#x2F;gnucash-manual&#x2F;tools-on-li...[2] https:&#x2F;&#x2F;wiki.gnucash.org&#x2F;wiki&#x2F;GnuCash_and_Mobile_Devices reply piperswe 18 hours agorootparentIt can import directly from some banks maybe, but certainly not my bank. I haven&#x27;t had any success importing to GnuCash from _any_ bank I do business with. reply mcjiggerlog 12 hours agorootparentEvery bank I&#x27;ve ever used has had functionality to do csv exports (or xlsx, for which I have a one-liner to convert to csv), which can trivially be imported into gnucash.At least in the UK&#x2F;EU, it seems to be a common feature. reply piperswe 11 hours agorootparentThat&#x27;s true, I mean the automatic direct import though. reply abdullahkhalids 8 hours agorootparentI wonder if there is a nice local browser automation tool one can use to do the download of the csv files directly from the bank. reply abdullahkhalids 17 hours agorootparentprevThere is also the plaid api to gnucash [1], which should work with a lot more banks. Personally, I have not used any of these. My banks allow csv downloads, which works well enough for me. I wouldn&#x27;t give my data to a 3rd party in any case.[1] https:&#x2F;&#x2F;github.com&#x2F;ebridges&#x2F;plaid2qif reply BeetleB 14 hours agorootparentprevI used to have this problem, but then I found most banks offer free export to some file format - even those that charge for SW integration. You just have to dig around the site to find the feature. reply yonrg 13 hours agorootparentprevTo be precise, the wonderful aqbanking is doing the job for gnucash. I do not see why paisa could not use aqbanking as well reply ananthakumaran 19 hours agoparentprevThere is import option available on Paisa, but I agree, it won&#x27;t match YNAB level experience. reply chrbr 18 hours agoparentprevYeah, I&#x27;m in the same boat. I&#x27;ve used YNAB for almost a decade now, but wish it were more powerful for things like investment tracking. I tried last month to get into the ledger systems (beancount, specifically), but it&#x27;s a huge additional time sink. And implementing YNAB-style envelope-based budgeting on top of them is always a bit of a hack. Went back to YNAB quickly. reply waynesonfire 17 hours agorootparent> wish it were more powerful for things like investment tracking.Community needs an open-source version of YNAB, not another gnu cash clone.Plaid solves the transaction import problem, the hardest part, unfortunately at the expense of privacy. reply rambambram 13 hours agoprevAfter building and using my own bookkeeping solution for my small business, one of the main takeaways for me before and after I built it was that bookkeeping software is only useful once you know the bookkeeping rules. Whatever software solution you use - whether that&#x27;s some webapp, an Excel sheet, or some homegrown solution - you always need to know these rules. Even the simple rules for a small business take some time and understanding to get a grip on. I haven&#x27;t seen bookkeeping software that is plug-and-play, so without knowing these rules as a user, if that&#x27;s even possible!?Knowing this for my own situation made me decide to opt for a homegrown software solution, because I had to learn these rules anyway. I felt more capable in my programming language of choice than in Excel, and I didn&#x27;t want to pay for a SaaS solution, let alone learn another interface. reply hedgehog0 12 hours agoparentAny any suggestions or recommendations for learning these rules? Either for future business or current personal finance management? reply rambambram 2 hours agorootparentStart reading up on &#x27;double entry&#x27; bookkeeping. Soon enough you will read about certain constructs and try these as a tutorial on your own financial situation. That&#x27;s how I did it. Because of the &#x27;double entry&#x27; you can find out soon enough when you&#x27;re making mistakes, and then &#x27;bugfixing&#x27; these mistakes makes you learn quick enough. Well, this is how I did it. reply codethief 13 hours agoprevThat cookie banner is straight from hell. Took me a solid minute to realize how to disable tracking. Ugghh. reply sbehere 18 hours agoprevI think it helps if personal finance managers explicitly describe at least the following:1. What automation, if any, exists for entering transactions? This is the most laborious&#x2F;cumbersome part of personal finance. Some tools use financial data aggregators (plaid, yodlee etc.) that involves sharing login credentials with a third party, sometimes disabling 2FA, or other steps that are anti-security or anti-privacy. It sucks that in the USA at least, there is practically no way for customers to fetch their bank data via an open API. Until recently, many financial institutions supported OFX, but that is being phased out.2. How is categorization of transactions accomplished? Ideally, I want autocategorization based on my own previously categorized transactions, since the bulk of my transactions are repeats at the same merchants.3. What sort of reporting, dashboarding, and potentially sharing capabilities exist? Ideally, I want to share some reports with my partnerA while ago, I created my own homegrown system to automate my personal finances[1]. It is capable of doing all of the above, without sharing data with a 3rd party. Unfortunately, the automated transaction retrieval mostly does not work because financial institutions are dropping support for OFX.[1]: https:&#x2F;&#x2F;sagar.se&#x2F;blog&#x2F;where-is-the-money&#x2F; reply ananthakumaran 17 hours agoparent> 1. What automation, if any, exists for entering transactions? This is the most laborious&#x2F;cumbersome part of personal finance. Some tools use financial data aggregators (plaid, yodlee etc.) that involves sharing login credentials with a third party, sometimes disabling 2FA, or other steps that are anti-security or anti-privacy. It sucks that in the USA at least, there is practically no way for customers to fetch their bank data via an open API. Until recently, many financial institutions supported OFX, but that is being phased out.It has import support (can be templated using handlebars), no automated fetch though> 2. How is categorization of transactions accomplished? Ideally, I want autocategorization based on my own previously categorized transactions, since the bulk of my transactions are repeats at the same merchants.It has a very crude tf-idf based categorization. I do have plans to improve it.> 3. What sort of reporting, dashboarding, and potentially sharing capabilities exist? Ideally, I want to share some reports with my partnerYou can checkout the https:&#x2F;&#x2F;demo.paisa.fyi It&#x27;s just a web app that works over http, so you can run it on a machine and share them access. You have to figure out the authorization part, I do plan to add some password based auth soon. reply garyrob 17 hours agorootparent> It has a very crude tf-idf based categorization. I do have plans to improve it.You could use the same algorithm that was used for spam filtering in my Linux Journal article from back in 2003[1]. I have thought about making a plugin to do it with MoneyDance but haven&#x27;t gotten around to it. But I think it would be quite easy for you to integrate into Paisa if you are looking to do that sort of thing. I have actually made some improvements to the algorithm since then; let me know if you&#x27;re interested...[1] https:&#x2F;&#x2F;www.linuxjournal.com&#x2F;article&#x2F;6467 reply mgkimsal 17 hours agoparentprev> How is categorization of transactions accomplished? Ideally, I want autocategorization based on my own previously categorized transactions, since the bulk of my transactions are repeats at the same merchants.One of my aggregators categorizes any alcohol purchases (purchases from a state &#x27;ABC&#x27; store) as &#x27;home improvement&#x27;. While technically the house looks better when I&#x27;m drunk, I still thinks it&#x27;s a mistake, and I submitted feedback to them. 2 years ago. No change. reply Telemakhos 17 hours agorootparentWould you rather your aggregator sell your alcoholism data to your health insurance company, or your joy of maintenance and taking good care of your property to your home insurance company? reply mgkimsal 17 hours agorootparentWhy not both? I would not be surprised to find the banks already sell that data to other entities anyway (directly or indirectly). I end up buying perhaps $100 of hooch per year; unsure I personally care if anyone knows, but yes, for some it might be an issue. reply halotrope 18 hours agoprevThis looks great! We&#x27;ve been building a wealth tracker with https:&#x2F;&#x2F;markets.sh and were a bit flabbergasted when people started \"abusing\" our automatically syncing Yodlee connection to hook up all of their checking and credit card accounts (technically we market only for brokerages and investment accounts). We have a free and simple API and plain CSV download which in itself seems to be a real pain point for people.Apparently, just being able to pull your financial data into open-source tools and excel could be a product since Yodlee and other aggregators are often too expensive and technical to set up for individuals.I think we need to force all financial companies to have a modern API and OAuth available for everyone via legislation. reply lukebennett 17 hours agoparent> I think we need to force all financial companies to have a modern API and OAuth available for everyone via legislation.That already exists[0] in the UK[0] https:&#x2F;&#x2F;www.openbanking.org.uk&#x2F; reply domh 17 hours agorootparentIt&#x27;s been a little while since I&#x27;ve looked into the Open Banking API stuff - how easy is it to use this API as a consumer? Or do I have to create a business and apply for a license in order to use it? reply jon-wood 17 hours agorootparentOpen Banking is in some ways misnamed - you can&#x27;t as an end-user just do OAuth and get a data feed out of your account, you&#x27;ll have to go via a third party who&#x27;ve jumped through all the hoops. reply domh 17 hours agorootparentGot it! That&#x27;s what I thought (feared). I wonder if there are ever plans to open it up to general use, or if it would be easy as an end user to jump said hoops.I wonder if there are any open source third parties? reply buzer 17 hours agorootparentI don&#x27;t know about open source ones, but I did find Enable Banking (https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;eupersonalfinance&#x2F;comments&#x2F;k4ny3j&#x2F;f...) offering free access to your own accounts. I don&#x27;t know if \"offer\" still stands, the FAQ is not very explicit on it (it only talks about testing, https:&#x2F;&#x2F;enablebanking.com&#x2F;docs&#x2F;faq&#x2F;#can-i-test-the-api-befor... & https:&#x2F;&#x2F;enablebanking.com&#x2F;docs&#x2F;api&#x2F;linked-accounts&#x2F;).I tried it, but I couldn&#x27;t get things working sandbox environment so I ended up giving up and just do manual exports. reply halotrope 17 hours agorootparentprevEurope has a shot too but what i’ve found is that the API’s are often so clunky and bad that they might as well not exist reply lelo_tp 16 hours agoparentprevyep. That&#x27;s exactly what&#x27;s happening in Brazil - https:&#x2F;&#x2F;www.bcb.gov.br&#x2F;en&#x2F;financialstability&#x2F;open_financesimilar to how the central bank forced every major bank to adopt PIX (our instant payment system), they&#x27;re doing the same with open banking.Sure, it&#x27;s not exactly \"open\" for end users. But now, as a company, I can build a personal finance app without asking for my end users bank account password. This is so much better UX-wise. reply asveikau 17 hours agoprevI wondered about the name. I guess I&#x27;m unfamiliar with a bunch of South Asian references, apparently it is Hindi and related to currency: https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;%E0%A4%AA%E0%A5%88%E0%A4%B8%E...I was perplexed a bit because paisa (like paisano, countryman) is also a word I hear a lot among Latin American immigrants in the US, seems like one of those things that can be taken offensively but I mostly seem to hear it as a term of endearment. reply makingstuffs 17 hours agoparentYeah it means money in Hindi reply iFire 11 hours agoprevLICENSE AGPL3https:&#x2F;&#x2F;github.com&#x2F;ananthakumaran&#x2F;paisa&#x2F;blob&#x2F;master&#x2F;COPYINGI won&#x27;t use this because I can&#x27;t ensure all my systems can be agpl3. Like bank systems I don&#x27;t control. reply mattigames 10 hours agoparentThis is false, interacting with public APIs that are not under your control is allowed under AGPL3, the only thing you may have to do is release any code you may add to connect with those APIs. Source https:&#x2F;&#x2F;opensource.stackexchange.com&#x2F;questions&#x2F;8201&#x2F;if-i-use... reply iFire 8 hours agorootparentI refuse, would rather release on my own terms like Apache 2 or MIT or any other license. reply mekster 18 hours agoprev [–] What&#x27;s with the thousand separator being placed on every 2 digits except for the last 3 digits?How do you even do that, unless you manually regex it?If that&#x27;s the case, already looks weird on technical decisions.There&#x27;s never a decent open source self finance management app somehow.It&#x27;s either bloated or just doesn&#x27;t look easy on the eyes for simple day to day use. reply jaipilot747 18 hours agoparentThat&#x27;s how they are delimited in India and the author is probably from there.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Indian_numbering_system reply ananthakumaran 18 hours agoparentprevThe author is from India (myself) and this is how numbers are formatted there. Locale can be configured via configuration page, so it&#x27;s just a matter of changing it to `en-US` if you want thousand separator. reply sdfghswe 17 hours agorootparentBoom headshot reply lelo_tp 15 hours agoparentprev [–] lol, this is such an aggressive reaction. People won&#x27;t always live where you live. Be kind to others, don&#x27;t assume there&#x27;s something wrong until you gather the full context. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The developer has been utilizing plaintext accounting and has designed a reporting system named Paisa for public use.",
      "The developer is looking for feedback regarding what people typically want to know about their personal finances.",
      "There's request to refrain from editing demo data, and to download and run it locally where necessary."
    ],
    "commentSummary": [
      "The discussion focuses on personal finance management tools and methods, including the integration with Plaid for automated data imports, but with concerns about data security and a demand for standardized APIs from financial institutions.",
      "The conversation also explores other topics such as tax models, alternative software, transaction categorization challenges, and user praises for a project called Paisa, along with debates on the availability of Linux versions.",
      "It underscores the challenges and potential solutions for efficient personal finance management and highlights the importance of grasping bookkeeping rules and the difficulties of using open banking APIs."
    ],
    "points": 549,
    "commentCount": 217,
    "retryCount": 0,
    "time": 1695395312
  },
  {
    "id": 37614816,
    "title": "0-days exploited by commercial surveillance vendor in Egypt",
    "originLink": "https://blog.google/threat-analysis-group/0-days-exploited-by-commercial-surveillance-vendor-in-egypt/",
    "originBody": "This site uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. Learn more OK, got it Updates from Threat Analysis Group (TAG) THREAT ANALYSIS GROUP 0-days exploited by commercial surveillance vendor in Egypt Sep 22, 2023 2 min read M Maddie Stone Threat Analysis Group Share Last week Google’s Threat Analysis Group (TAG), in partnership with The Citizen Lab, discovered an in-the-wild 0-day exploit chain for iPhones. Developed by the commercial surveillance vendor, Intellexa, this exploit chain is used to install its Predator spyware surreptitiously onto a device. In response, yesterday, Apple patched the bugs in iOS 16.7 and iOS 17.0.1 as CVE-2023-41991, CVE-2023-41992, CVE-2023-41993. This quick patching from Apple helps to better protect users and we encourage all iOS users to install them as soon as possible. Exploit delivery via man-in-the-middle (MITM) The Intellexa exploit chain was delivered via a “man-in-the-middle” (MITM) attack, where an attacker is in between the target and the website they’re trying to reach. If the target is going to a website using ‘http’, then the attacker can intercept the traffic and send fake data back to the target to force them to a different website. Visiting a website using ‘https’ means that the traffic is encrypted, and it is easily verifiable that the received data came from the intended website using their certificate. That is not the case when using ‘http’. In the case of this campaign, if the target went to any ‘http’ site, the attackers injected traffic to silently redirect them to an Intellexa site, c.betly[.]me. If the user was the expected targeted user, the site would then redirect the target to the exploit server, sec-flare[.]com. While there’s a spotlight on “0-click” vulnerabilities (bugs that don’t require user interaction) this MITM delivery also didn’t require the user to open any documents, click a specific link, or answer any phone calls. iOS Exploit Chain As soon as the attacker redirected the target to their exploit server, the exploit chain began to execute. For iOS, this chain included three vulnerabilities: CVE-2023-41993: Initial remote code execution (RCE) in Safari CVE-2023-41991: PAC bypass CVE-2023-41992: Local privilege escalation (LPE) in the XNU Kernel The chain then ran a small binary to decide whether or not to install the full Predator implant. However, TAG was unable to capture the full Predator implant. We plan to publish a technical deep dive on these exploits in line with the Google vulnerability disclosure policy. Android Exploit Chain The attacker also had an exploit chain to install Predator on Android devices in Egypt. TAG observed these exploits delivered in two different ways: the MITM injection and via one-time links sent directly to the target. We were only able to obtain the initial renderer remote code execution vulnerability for Chrome, which was exploiting CVE-2023-4762. This bug had already been separately reported to the Chrome Vulnerability Rewards Program by a security researcher and was patched on September 5th. We assess that Intellexa was also previously using this vulnerability as a 0-day. Chrome's work to protect against MITM For years, Chrome has worked toward universal HTTPS adoption across the web. Additionally Chrome has an “HTTPS-First Mode” that can reduce the likelihood of exploits being delivered via MITM network injection. \"HTTPS-First Mode\" will attempt to load all pages over HTTPS, and show a large warning before falling back to sending an HTTP request. This setting is currently on by default for users enrolled in the Advanced Protection Program who are also signed into Chrome. We encourage all users to enable “HTTPS-First Mode” to better protect themselves from MITM attacks. Conclusion This campaign is yet another example of the abuses caused by the proliferation of commercial surveillance vendors and their serious risk to the safety of online users. TAG will continue to take action against, and publish research about, the commercial spyware industry, as well as work across the public and private sectors to push this work forward. We would like to acknowledge and thank The Citizen Lab for their collaboration and partnership in the capturing and analysis of these exploits, and Apple for deploying a timely patch for the safety of online users. POSTED IN: Threat Analysis Group Related stories THREAT ANALYSIS GROUP TAG Bulletin: Q3 2023 This bulletin includes coordinated influence operation campaigns terminated on our platforms in Q3 2023. It was last updated on September 8, 2023. By Shane Huntley Sep 08, 2023 THREAT ANALYSIS GROUP Active North Korean campaign targeting security researchers Threat Analysis Group shares findings on a new campaign by North Korean actors targeting security researchers. By Clement Lecigne Maddie Stone Sep 07, 2023 THREAT ANALYSIS GROUP TAG Bulletin: Q2 2023 Threat Analysis Group shares their Q2 2023 bulletin. By Shane Huntley Jul 31, 2023 THREAT ANALYSIS GROUP The ups and downs of 0-days The goal of this report is to analyze the exploits from the year as a whole, looking for trends, gaps, lessons learned, and successes. By Maddie Stone Jul 27, 2023 THREAT ANALYSIS GROUP TAG Bulletin: Q1 2023 Threat Analysis Group shares their Q1 2023 bulletin. By Shane Huntley May 01, 2023 THREAT ANALYSIS GROUP Ukraine remains Russia’s biggest cyber focus in 2023 Google's Threat Analysis Group shares first quarter cyber updates on the threat landscape from the war in Ukraine. By Billy Leonard Apr 19, 2023 Privacy Terms About Google Google Products Help Deutsch English English (Africa) English (Australia) English (Canada) English (India) English (MENA) Español (Latinoamérica) Français (Canada) Français (France) Italiano Português (Brasil) اللغة العربية (MENA)",
    "commentLink": "https://news.ycombinator.com/item?id=37614816",
    "commentBody": "0-days exploited by commercial surveillance vendor in EgyptHacker Newspastlogin0-days exploited by commercial surveillance vendor in Egypt (blog.google) 471 points by mikece 17 hours ago| hidepastfavorite214 comments Macha 16 hours agoIt&#x27;s good to get some more info, but it is a little disconcerting that they only mention patching Chrome. What was the sandbox escape on Android? Even if you had code execution inside the Chrome process on Android, that shouldn&#x27;t be enough to enable persistence, so clearly there&#x27;s another vulnerability.Also in this case the attack vector was MITM of http and one time links as it was a targeted campaign, but it feels there&#x27;s nothing preventing someone putting this in an ad campaign or sms&#x2F;discord&#x2F;matrix&#x2F;whatever spam and spraying it everywhere to build a botnet or steal user credentials or whatever. reply toasterblender 14 hours agoparent> What was the sandbox escape on Android? Even if you had code execution inside the Chrome process on Android, that shouldn&#x27;t be enough to enable persistence, so clearly there&#x27;s another vulnerability.This is such a crucial point. Forced to read between the lines of the blog post (because the above information is missing), it sounds like there are currently unpatched issues in Android revolving around this? reply fullspectrumdev 12 hours agorootparentLikely yes, they were unable to capture the following stages so they don’t know what was exploited after gaining initial execution within the chrome sandbox.Likely there’s a chrome sandbox escape and a kernel exploit remaining “unknown and unpatched”. reply vdfs 12 hours agorootparent> Likely there’s a chrome sandbox escape and a kernel exploit remaining “unknown and unpatched”.There is certainly many of those that we don&#x27;t know about, if this was done in Egypt, imagine what a 3 letters agency have reply conradev 4 hours agorootparentEvery government with money has exploits for every device imaginable.The going price was $1m for a full exploit chain on iPhone a while ago, and I’m sure it’s gone up, but I’m also sure it is minuscule compared to the amount of money governments have.Everyone should assume this is fact, and not imagine some secret spy world. If you ever become interesting enough to hack, you will be, and there is little recourse (currently) reply CobrastanJorji 4 hours agorootparentKinda surprising that Apple wouldn&#x27;t be the highest bidder for a full exploit chain. They&#x27;ve been known to give out $100,000 bug bounties, but you&#x27;d think one million would be a pretty good deal for closing a vulnerability vs having it sold to companies that professionally surveil people. reply apienx 3 hours agorootparentOne million dollars is what some states pay _per target_.Every major black hat group operates with the blessing of some state. It’s about more than just money. Actual exploits are probably traded for “favours” (e.g. votes in international bodies, collaboration on thorny dossiers, extraditions, etc.). The infiltration of electronic communication is a major aspect in determining a state’s level of “soft power” and - in a software-run world - its weight only increases. reply taway1237 1 hour agorootparent>Every major black hat group operates with the blessing of some state.Citation needed. As far as I know that&#x27;s true. Yes, some groups cooperate with the state (true in Russia after the escalation of the war in Ukraine, for example). But that&#x27;s certainly not true for everyone - not every group has uses as an APT unit, most are just common criminals. reply bboygravity 2 hours agorootparentprevI&#x27;d go a step further and state: everybody is interesting enough to fully automatically hack.I have 0 doubt that literally everybody is being scraped by 1 or more governments and&#x2F;or companies.Because if they can, why not? reply computerfriend 2 hours agorootparentBecause every time you do it, you run the risk of discovery. This can be expensive (you burn your exploit) and politically embarrassing. reply conradev 1 hour agorootparentprevThe answer to “why not” is this blog post. Lots of people are likely very unhappy that their expensive exploit has been patched. This is what The Citizen Lab does! reply staplers 11 hours agorootparentprevWouldn&#x27;t be a stretch to assume this is forced by 3 letter agencies and it&#x27;s details leaked for sale on an exclusive dark web.Think of all the insidious corruption we find out about via declassification 50 years later. It&#x27;s not like human nature has changed. reply wyldfire 11 hours agorootparentprevIs it possible that it was detected but without a sandbox escape? would it still be described as \"an exploit\" if so? reply saagarjha 10 hours agorootparentYes. reply vardump 9 hours agorootparentprevCan be multiple vendor specific exploits. reply throwawaaarrgh 11 hours agorootparentprevI mean there are always unpatched issues in everything... There&#x27;s nothing you can do, whether you know about it or not. You have to just assume you&#x27;re always actively being exploited at some level reply fredgrott 11 hours agorootparentprevRead it again, no sandbox attack on Android MITM and one time link attack only . reply saagarjha 10 hours agorootparentThat’s all they were able to gather. reply fullspectrumdev 12 hours agoparentprevThey state that they were unable to capture the follow-on stages of the Android chain, they only got the initial execution component.Which means there’s missing a sandbox escape and privilege elevation bug.Also yes while delivery here was apparently ISP level MiTM using lawful intercept capabilities, there’s no reason the exploit couldn’t be delivered as a 1click via a phishing link. reply nfriedly 10 hours agoparentprevThere are millions of android devices out there that have been abandoned by their manufacturers, so they might be omitting those details because the flaw hasn&#x27;t yet been patched (and likely never will be.) reply 0x38B 3 hours agorootparentRide public transport in Eastern Europe and you&#x27;ll see Androids running versions as old as 4; such devices are cheap, and ubiquitous phone repair shops will fix or replace components, such as batteries, speakers, and more. If the situation in Egypt is similar among less-affluent users, then there are many Android phones just waiting to be exploited. reply Macha 9 hours agorootparentprevEven with Google&#x27;s own flagship device, the latest security patches date from August while this announcement is much newer, so it seems unlikely _any_ Android devices have been patched. reply kramerger 3 hours agorootparentI belive you are mistaken.Firat of all, some part of Android is updated via the store. So the Chrome vulnerability and system libraries were probably updated without you noticing.Also, this started in May. Before it went public both Apple and Google had already patched some vulnerabilities. Latest round was in August&#x2F;September. reply bobviolier 3 hours agorootparentprevI got a September security update for my Pixel 5, I think 2 days ago. reply flangola7 3 hours agorootparentprevUpdates occur all the time, what do mean there&#x27;s none since August? reply kramerger 13 hours agoparentprevThe article is mainly about the iphone exploit chain: Safari exploit -> PAC bypass -> kernel exploit.Android version was pretty similar but I think needed two more exploits to bypass Linux kernel mitigations.PZ has a good technical writeup. reply Macha 12 hours agorootparentThe only Project Zero write up recently about android sandbox escapes appears to be on a different, ALSA based and Samsung specific vulnerability. reply 3abiton 13 hours agorootparentprevWho is PZ? reply popey456963 13 hours agorootparentGoogle&#x27;s Project Zero. reply waihtis 16 hours agoparentprevIm not well versed in mobile environments. Presumedly breaking out of the Chrome sandbox would land you within the underlying OS. Can you not build persistence there without abusing further vulns? reply Macha 16 hours agorootparentThere&#x27;s nested sandboxes for browsers in mobile environments. There&#x27;s the inner layer which the web content is running in, but then the browser itself is sandboxed so it can&#x27;t do things like access OS APIs it doesn&#x27;t have permission for, install apps that run in the background, etc. This is why the iOS example needed 3 exploits chained. The fact that a similar example worked on Android, which also has app sandboxing, implies there should be an exploit chain but we&#x27;ve only been told of the first. reply codedokode 13 hours agorootparentBut browsers, especially Chrome, have lots of permissions (including geolocation, accessing SD card, accessing user&#x27;s personal data, camera and microphone etc.). You don&#x27;t need to do anything if you can run under browser&#x27;s privileges. reply roblabla 13 hours agorootparentNone of the mentioned privileges should net you a persistence though, so there&#x27;s clearly still another vulnerability. reply codedokode 2 hours agorootparentBut smartphones are rarely rebooted so maybe you don&#x27;t need persistence that much? reply tux3 57 minutes agorootparentYou still want priv escalation if you&#x27;re trying to spy on someone. The content process can&#x27;t see anything you&#x27;re doing in other apps, and the browser can only access a very restricted view of the storageLiving in memory or living off the land is generally a good idea, but you still want a chain of exploits anyways reply djbusby 8 hours agorootparentprevAbove says access to SD card. I think that means write ability. Which means persistence. reply tux3 59 minutes agorootparentAndroid has clamped down hard on access to the SD card. Chrome certainly doesn&#x27;t have the special All Files Access, and on my device it doesn&#x27;t even have Photos or Music, since I never use those permissions with Chrome, and Android regularly turns off permissions that haven&#x27;t been used recently reply astrange 7 hours agorootparentprevPersistence means you can write to something that&#x27;ll cause your malware to run again after reboot, but external storage isn&#x27;t enough to do that without another exploit in the boot path, right? reply insanitybit 15 hours agorootparentprevThere&#x27;s also SELinux on Android. reply tester756 14 hours agorootparentprevthat sounds like terrible jokesandbox in sandbox in sandbox in sandbox in sandbox in sandbox in sandboxand stuff still manages to escape reply taway1237 1 hour agorootparentDefence in depth. Now you need a working chain of 3 exploits instead of one. It&#x27;s about raising the bar, perfect security is impossible. reply appplication 14 hours agorootparentprevThat’s the thing about sand. It’s course and rough and irritating and it gets everywhere. reply hollander 13 hours agorootparentBut there is always time for a glass of good wine! reply djbusby 8 hours agorootparentprevThe Buffalo buffalo buffalo... thinghttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Buffalo_buffalo_Buffalo_buff... reply waihtis 16 hours agorootparentprevGotcha, thank you. reply fullspectrumdev 12 hours agorootparentprevOn Android, you usually need three exploits.1. Chrome code execution (gain foothold inside Chrome process).2. Sandbox escape (gain code execution outside the Chrome sandbox, with the privileges of the Chrome process, which aren’t very useful except to stage another exploit).3. Local privilege escalation, usually a kernel bug or similar, to elevate to root where you can break the process “sandbox” and establish persistence. reply adm_ 14 hours agoprevRelated recent episode of Darknet Diaries about the Predator spyware: https:&#x2F;&#x2F;darknetdiaries.com&#x2F;episode&#x2F;137&#x2F;. reply hedora 16 hours agoprevThough HTTPS is better than nothing, and this attack relies on HTTP to inject the initial payload, state sponsored attackers in some countries can likely just subvert CA or CDN infrastructure instead. reply astrange 11 hours agoparentYou probably can&#x27;t forge a certificate like that without all the browsers noticing and dropping your CA; there&#x27;s protections against it. reply kadoban 10 hours agorootparentIf you&#x27;re a nation you can just force the CAs that are in your jurisdiction to do whatever you want, or sneak in in various ways so they won&#x27;t know.If you use the MITM judiciously, it&#x27;s very likely that nobody will notice, or that those that notice can be compelled not to say anything. reply oefrha 9 hours agorootparentCT means a CA can’t do whatever they want. Your comment is handwavy, do you have any details on the “various ways” you’re talking about? reply corbezzoli 7 hours agorootparentI think it’s true that they can do “whatever they want”, but only once, because they’ll lose the right once found. The issue is the time between breach and punishment. reply oefrha 4 hours agorootparentAs long as a domain has the CAA record specifying which CAs are allowed to issue certificates for it (I believe CAA checking is now mandatory in the baseline requirements for CAs), coupled with CT, a misissurance by a malicious CA should be immediately detectable.Of course then the question is how quickly browsers can roll out an update&#x2F;config to distrust all future certs from said CA. reply kadoban 8 hours agorootparentprevPhysically, or by compromising employees or business owners in whatever legal or illegal means, depending on the country.Sounds from other comments like my knowledge is out of date though, and browsers have real protections against the obvious ways that used to be possible, which is great news. reply gpvos 4 hours agorootparentprevCT = Certificate Transparency, https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Certificate_Transparency reply astrange 9 hours agorootparentprevThe browser will notice that it&#x27;s being given a cert that isn&#x27;t in the CA transparency log + other hardcoded known certs for top sites and will phone home about it. reply kadoban 9 hours agorootparentWhat browsers actually do that? And do all CAs support it?Besides, if you have enough access to the CA, you can just get whatever cert is in the transparency log, though that&#x27;s almost certainly harder for most nations and CAs. reply astrange 8 hours agorootparent> What browsers actually do that?Chrome, Safari, Firefox.> And do all CAs support it?Yes, the browsers made them.> Besides, if you have enough access to the CA, you can just get whatever cert is in the transparency logNo, the CA doesn&#x27;t have the private key of certs. reply kadoban 8 hours agorootparentThat&#x27;s great! I guess my knowledge is out of date, happy to be wrong about that.> No, the CA doesn&#x27;t have the private key of certs.Woops, yeah good point. reply trifurcate 9 hours agorootparentprev> you can just get whatever cert is in the transparency logThat would require compromising the certificate requester. reply notabee 7 hours agorootparentA lot of certificate management services for enterprise customers \"helpfully\" store the private key files. How many cloud or SaaS vendors automatically handle the private keys as well instead of them being generated and staying securely only on the systems using them? So there are still points of centralization to attack, potentially. reply astrange 7 hours agorootparentYes, state actors have been known to steal things like codesigning keys. Microsoft had that happen recently where someone with persistence on a dev machine sniffed them out of crash logs(!).But it requires a lot more steps. replypipo234 15 hours agoparentprevOr get someone to click on a spoofed domain, certified by our beloved LetsEncrypt! Apparently al that is needed is an HTTP 302&#x2F;307 redirect response (or html redirect payload, maybe even DNS?) pointing the client toward c.betly[.]me reply glaucon 15 hours agorootparentI&#x27;m interested at your suggestion that Digicert et al are doing some sort of \"keeping the streets safe\" checking. I have zero experience of using them but I thought all they were doing was confirming the applicant represented some entity that matched the domain name. If I manage to get a company registered called G00gle, buy a corresponding domain and then send them my $500 are you suggesting they&#x27;re going to refuse to issue a certificate?My impression was the CA&#x27;s made the likes of Standard and Poor look rigorous, but I&#x27;m happy to learn more from actual experience of them rejecting such an application. reply pipo234 14 hours agorootparentYou are absolutely right, that (for plain, domain attestation) paid CAs are exactly as trustworthy as LetsEncrypt, and often much less (remember the Diginotar debacle, for example). \"Keeping the streets safe\" is not their responsibility, except in a very limited sense. The $500 extended validation was mostly paper work and snake oil.My point wasn&#x27;t to discredit LetsEncrypt, but to point out that Google&#x27;s claim to mitigate the MITM attack vector with https-first wasn&#x27;t a very strong argument. I mean, yes, sure: if you can&#x27;t intercept or downgrade to HTTP the MITM doesn&#x27;t work. But all the HTTP seems to do was redirect to a malicious payload. But you can also do a redirect in HTTPS.So if you can spoof someone to go to https:&#x2F;&#x2F;g00gle.com&#x2F; it should be just as easy to launch the attack chain from there. reply malaya_zemlya 10 hours agorootparentprevAs far as I can tell, the verification that DigiCert performs is 1. the company exists in various Business listings 2. the phone number listed in whois has a human behind it and the human confirms the phone number belogs to the company.Source: Have to be that human from time to time reply nerdbert 9 hours agorootparentOnly if you pay $$$$ for OV&#x2F;EV.If you get the normal DV cert they don&#x27;t provide any more verification than Letsencrypt.And since browsers have moved away from indicating OV&#x2F;EV certs to end users, not many organizations are paying for those anymore. reply Tijdreiziger 8 hours agorootparentCan confirm as someone who has to renew a non-Let’s Encrypt cert every year (for reasons). The CA sends an automated email to the email address listed in WHOIS, you click a link in the email, and they issue the certificate. No human interaction necessary. reply ComputerGuru 7 hours agorootparentEV certs have a slightly more rigorous approach. They’ll call the registered agent for the business as registered&#x2F;licensed with the state, not the phone number from whois or an email to webmaster@ reply Tijdreiziger 5 hours agorootparentYes, I’m just talking about regular DV certificates (the same type you’d get if you just used Let’s Encrypt). replyvngzs 14 hours agorootparentprevI don&#x27;t see GP claiming CAs should be checking reputability for domain issuance certificates. But the thread originator mentioned subverting CAs! Something to remember about even the most advanced attackers is that they value the continued effectiveness of their tactics, tools and procedures. Even nation-states in possession of CA subversion abilities won&#x27;t burn their malicious CA on someone if they can conduct the attack with a legitimately-issued certificate, and they won&#x27;t bother with a legitimately-issued cert if they can conduct the attack without even involving a CA. reply glaucon 13 hours agorootparentI was referring to this comment https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37615985 reply malaya_zemlya 9 hours agorootparentprevCoincidentally, the ACME DNS verification process that LetsEncrypt uses is vulnerable to the QUANTUM attack. If NSA injects a fake DNS response in the right spot, and have the their response arrive before the official response, they can get the domain verified.OTOH, Certificate Transparency Logs will give the game away, so there&#x27;s that. reply jrockway 6 hours agorootparentDoesn&#x27;t Let&#x27;s Encrypt check the DNS record from multiple widely-distributed endpoints to avoid this attack? reply insanitybit 15 hours agorootparentprevHuge difference between being tricked into clicking a link vs just browsing the web and getting owned. reply Macha 14 minutes agorootparentThe vector is an image file. Put your image in a display ad, now you don&#x27;t need the user to click anything reply aidos 15 hours agorootparentprevIs there? reply insanitybit 15 hours agorootparentYes. The move from 0 to 1 click exploits (thanks to putting Flash&#x2F;Java behind a click) in the early 2000s marked a massive negative shift in attacker capabilities and ultimately destroyed multiple (black market) exploit dev businesses. reply fullspectrumdev 13 hours agorootparent“Click to play” bypasses became incredibly valuable as an enabler for Flash&#x2F;Java exploits, for a while. They were also few and far between, and if memory serves me, unreliable as fuck. reply pipo234 14 hours agorootparentprevIt definitely matters. Just think about what sort of how much Dr. Evil would pay for an exploit that relies on user action versus one that doesn&#x27;t.https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln-metrics&#x2F;cvss&#x2F;v3-calculator reply autoexec 14 hours agorootparentprevI can probably avoid bring tricked into clicking a link, I&#x27;ve avoided many many attempts to trick me in the past. I probably can&#x27;t avoid browsing the internet though. reply jefftk 15 hours agorootparentprev> certified by our beloved LetsEncryptAre you saying that CAs should be refusing to issue certs for potentially spoofed domains? reply pipo234 15 hours agorootparent...or Digicert, Globalsign, the Hongkong post office, whichever CA is in your truststore.I just mentioned LetsEncrypt because it&#x27;s free and exceptionally easy to use. I&#x27;m not implying in any way they aren&#x27;t providing a great service, it&#x27;s just that that service also gets misused because it&#x27;s cheap and easy. reply xcdzvyn 14 hours agorootparentIt really sounds that way, FYI. I interpreted it as a dig at LetsEncrypt in particular. reply pipo234 14 hours agorootparentPlease accept my apologies :-) replyComputerGuru 7 hours agoparentprevNote that it only took&#x2F;takes one http visit (to any site) to compromise the device. reply crumpled 1 hour agoprevThe Citizen Lab post linked from this article has the details of the MITM attack. It&#x27;s almost not even an attack, the network is designed to do content injection on demand. reply toasterblender 14 hours agoprevHere is what I do not understand:Spyware firms and 0-day vendors both have staff dedicating to finding 0-days. Why do Google and Apple not simply poach these staff?I am sure Google and Apple can offer very competitive salaries, so why do they not do so? Is it because the cost of basically poaching all of the skilled 0-day hunters is deemed to be greater than the cost of just issuing patches? reply OneLessThing 12 hours agoparentI am this person. I work as a researcher finding 0-days.From the employee perspective: Wages are equal. Big Tech work is less interesting (build big bug finding machines that find have high quantity of bugs) and report the bugs that sit into some bug tracker only to maybe be fixed in 3 months. Offensive security work is more interesting. It requires intimate knowledge of the systems you research, since you only need a handful and the shallow ones get found by Big Tech. You must go deep. Additionally offensive security requires the know-how to go from vulnerability to code execution. Exploitation is not an easy task. I can&#x27;t explain why engineers work for companies that I deem immoral, but that&#x27;s probably because they don&#x27;t feel the same way as I do.From the employer perspective: How much does the rate of X vulnerabilities per year cost me? If our code has bugs but is still considered the securest code on the market, it may not benefit the company to increase the security budget. If the company expands the security budget then which division is getting cut because of it, and what is the net result to the company health?If you want to fix the vulnerabilities you need to make the price of finding and exploiting them higher than the people buying them can afford. And you must keep the price higher as advances in offensive security work to lower the price of finding and exploiting them. Since defensive companies don&#x27;t primarily make money from preventing bugs and offensive companies do primarily make money by finding bugs, there is a mismatch. The ultimate vulnerability in a company, or any entity, is finite resources. reply saagarjha 10 hours agorootparentI mean wages might be equal (are they, though? Big tech pays a lot as you go up) on average but there’s a lot of difference in how they pay out. Big tech usually provides compensation bands where your salary is pretty stable. Vulnerability research frequently has your compensation hinge on your performance to a much larger extent. reply theragra 2 hours agorootparentprevWould amount of critical vulnerabilities be lower if we sacrifice some performance? 10-20%? reply eviks 5 hours agorootparentprevYou don&#x27;t need to cut any division, profits can also change reply kramerger 14 hours agoparentprevGoogle has one of the best teams money and prestige can buy:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Project_ZeroThey also have excellent collaboration with independent researchers across the world. But given how much software is written everyday, they can still miss some issues. reply toasterblender 14 hours agorootparentProject Zero is amazing, but they 1) seem like a very small team, and 2) their mandate is far too broad (essentially to search for 0-days in anything, versus a specific system). What I am talking about is more like Apple having a dedicated team of 10 vulnerability researchers all looking into iOS 0-days fulltime. reply throwaway38475 14 hours agorootparentThey all do that. I&#x27;ve been in Offensive Security for 10+ years with several spent at FAANGS, and not only do they all have large security teams doing internal testing, they hire multiple contractors like Trail-of-Bits to audit every important service continuously throughout the year.Apple has way more than 10 full time researchers looking at iOS all day, trust me :). They also have a really generous bug bounty. There is always bugs though. reply kramerger 14 hours agorootparent> Apple has way more than 10 full time researchers looking at iOS all day.Yes> They also have a really generous bug bounty.Hell no reply tholdem 13 hours agorootparentAgree. Not long ago, Apple used to sue people reporting vulnerabilities to them. Imagine punishing people doing free work for you. Not a good look. reply 77pt77 13 hours agorootparentGetting punished is the default.If you refer come across anything, keep your mouth shut. reply lima 14 hours agorootparentprevNot only is it not generous (relatively speaking), but actually getting paid can be extremely annoying.Used to be even worse. replytetrep 14 hours agoparentprevI think this is similar to looking at the budget of the US government and asking why they don&#x27;t simply pay off all the potential criminals such that most crime in the US is then mitigated. reply callalex 12 hours agorootparentThat’s not equivalent at all. Paying off criminals creates an incentive for there to be more criminals. Paying more security researchers does not incentivize people writing buggy C code to write even buggier C code. reply cuu508 4 hours agorootparentRaising compensation creates an incentive for there to be more bug hunters. reply flangola7 3 hours agorootparentWhich is good reply entuno 14 hours agoparentprevSome of them wouldn&#x27;t want to work for Google and Apple in the first place, regardless of the salary.But while they could try and poach them today, tomorrow there will be a whole load of new people working for those companies, and it&#x27;ll just be a never-ending cycle. reply toasterblender 14 hours agorootparent> But while they could try and poach them today, tomorrow there will be a whole load of new people working for those companies, and it&#x27;ll just be a never-ending cycle.The number of people who successfully find 0-click 0-days for iOS&#x2F;Android is very small. It&#x27;s not a vastly replenishable resource. reply hattmall 14 hours agorootparentIt&#x27;s a small group but a wide pool. It&#x27;s not like the same person finds 10 0days. And until they do find their one exploit most of them have pretty much no credentials at all. So how do you avoid hiring 10,000 up and comers that never actually come up? reply toasterblender 14 hours agorootparentThe same that it works in any other industry. By hiring those with proven track records, the best of the best. The goal is obviously not to hire 100% of the potential 0-day hunters, but by launching a concentrated poaching effort, to make a sufficient dent. reply astrange 7 hours agorootparentIf you inject a lot of money into the industry I think it&#x27;ll result in more people learning how to do it.Though, the reason governments found the best exploits for the longest time wasn&#x27;t by hiring geniuses, but by giving people long periods of time and freedom to do kinds of research nobody else was motivated to do. reply throwaway38475 14 hours agorootparentprevPeople have said Apple can buy companies like NSO for less than they probably spend on SEIMs in a year. But as soon as they do that there will be another startup doing the same thing.The company (GreyShift) that broke the secure enclave had ex-apple security engineers working for them. reply entuno 13 hours agorootparentprevThey could certainly go out and try and hire some of the best iOS vuln researches. But if they hire the top 10 out there, then #11 gets a massive payrise to go and work for one of the spyware companies.And if Apple is paying huge amounts of money and getting into bidding wars with all the other companies out there for vuln researches, that&#x27;ll attract a load more people to start hunting. reply cco 14 hours agorootparentprev> Some of them wouldn&#x27;t want to work for Google and Apple in the first place, regardless of the salary.For moral reasons do you mean? I would be surprised to learn there are a lot of people that are open to selling 0 day exploits to \"bad actors\" (granted that this term is doing a lot of heavy lifting here), but wouldn&#x27;t want to work for Google or Apple.> ...it&#x27;ll just be a never-ending cycleI think the idea is you pay them so well that they can work for a handful of years and remove any cash incentive reason for them to continue selling 0 days to bad actors. reply eastbound 14 hours agorootparent> “bad actors\", but wouldn&#x27;t want to work for Google or Apple- Everyone who doesn’t like US hegemony. Which happens about everywhere but US, in varied proportion, but even in Europe, and even worse in Middle-East,- Everyone who doesn’t like monopolies. Capitalism of competition (as opposed to state capitalism, when the state borrows a trillion per semester, ahem) requires that monopolies be broken down to avoid distortion of competition. Helping bad actors can be, under their viewpoint, less bad than the damage done to a billion consumers consumers at a time. Plus monopolies impose a monoculture of occidentalism, with certain values that a firm in Egypt might consider worse than sponsoring bad actors. reply toasterblender 14 hours agorootparentIf the number of skilled 0-day hunters who will work for a paycheck is > 0, then yours is a moot point, since a poaching program would still make an impact even if there are some people who work for spyware companies who would not work for FAANG.I think you will also find that morals for many people are inversely proportional to the offered salary. An 0-day developer being compensated $130k may well abandon their particular morals if offered a $240k salary instead. reply crtified 13 hours agoparentprevIt&#x27;s a good idea, but in some ways, akin to the challenge that would be presented by attempting a similar-veined \"why doesn&#x27;t the world&#x27;s richest country just hire all the world&#x27;s best military generals, leaving zero for any other country?\".The reasons why it&#x27;s not possible are myriad, but boil down to the fact that the world and humanity are very big things, and one entity can&#x27;t possibly get them all, or even most of them. There&#x27;s too much diverse heterogenuity built into everything. Including many worldviews and loyalties that go beyond money. reply alephnerd 14 hours agoparentprev> Why do Google and Apple not simply poach these staffThey do. Plenty of white hat teams hire 8200 vets, but sometimes they&#x27;d rather make their own company instead of being a cog within an amaphorous foreign corporation. reply FirmwareBurner 14 hours agorootparentThis. IIRC some famous security researcher responsible for iOS jail-breaks was poached by Apple only to leave after 3 months.Successful and skilled security people with a proven track record, don&#x27;t have the paciente of putting up with the charade such large orgs require. reply stepupmakeup 6 hours agorootparentPlenty of jailbreak developers have been poached by Apple. Whether they&#x27;re still at their A-game still is questionable, I follow one on Twitter and there&#x27;s regular tweets about depression, suicide, debt and other gloomy topics. reply reqo 14 hours agorootparentprevGeorge Hotz replytoxik 14 hours agoparentprevI think it’s many factors.1. They do to some extent.2. Which researchers are you going to hire? Lemon market, whoever wants to be hired is more likely a lemon.3. Freelancing grayhat stuff is very rock n roll.4. I bet some they try to hire and then the square and inflexible large corpo hiring process is just absolutely unfit for hiring such a person. reply fullspectrumdev 14 hours agorootparent> Which researchers are you going to hire? Lemon market, whoever wants to be hired is more likely a lemon.Not really. Most people in that space who have a “day job” are almost always open to being hired for better TC&#x2F;benefits&#x2F;more interesting problems.Points 3 & 4 are largely correct.It’s very rock and roll, but a very unstable income and most of the brokerages are comically untrustworthy. Also you may develop a conscience and find it hard to sleep at night.Point 4… usually the people who can find such bugs reliably don’t work well in large corps past the short term. The unexplained gaps in a CV also aren’t conducive to getting past HR easily. reply permo-w 14 hours agoparentprevwho&#x27;s to say they&#x27;re not doing this? there are a lot of security companies and researchers in the world thoughor alternatively: as lovely as the hacker -> employee fairytale sounds, a certain % of the \"I would never work for Google&#x2F;Apple\" types would come in with the sole purpose of installing backdoors from the inside reply fullspectrumdev 12 hours agorootparentA lot of the really good hackers won’t pass HR screening, or be able to cope with corporate bullshit beyond a year.So there’s also that. reply rehitman 13 hours agoparentprevThere is also a chance at play here. Many people are trying to find a hole, some are more lucky than the other. Google has a great team, so they get lucky more, that is why these things are not too common, but at some point a bad guy gets lucky too, even though he is not the smartest in the room. reply eviks 5 hours agoparentprevWhy would you need to poach all of them, just enough to find bugs fasterThough poaching all is simply impossible, by raising prices you&#x27;ll incentivize more people to become vulnerability researches, so more will always be available to the spyware firms reply icelancer 14 hours agoparentprevMoney is just one input for why people choose to work at certain places. reply callalex 12 hours agoparentprevBecause that would eat into profit margins, and at the end of the day very very few paying customers actually make their purchasing decisions based on security. On top of that almost nobody is really knowledgeable enough to make an informed decision in the first place. So the money doesn’t get spent. reply jklinger410 14 hours agoparentprevThey probably don&#x27;t want to hire criminals to work at their companies. reply ziftface 14 hours agorootparentAlready very well-paid criminals for that matter reply jrvarela56 14 hours agoparentprevIsn&#x27;t this akin to asking why Google and Apple end up acquiring companies at very high prices if they could just hire the founders and have them build the products in-house? reply toxik 14 hours agorootparentGoogle absolutely “poach” promising startup devs tbh. reply toasterblender 14 hours agorootparentprevPoaching founders is an entirely different kettle of fish than just poaching line employees. reply jrvarela56 12 hours agorootparentOh, I thought finding these vulns was a highly open-ended endeavor with variable payouts. reply fullspectrumdev 11 hours agorootparentIt depends. Some companies that buy exploits have public “price lists” for acquisitions.100k+ for a Safari on iOS code exec, another 200k for the Safari sandbox escape, then another 500k+ for the kernel exploit?A full chain is real money. Especially when they resell this ability for 1-2M+ per user. reply saagarjha 14 hours agoparentprevPoach them to do what? There’s not much use to Apple or Google to have an implant developer around, and just having them do nothing is likely to be frustrating if the corporate lifestyle wasn’t enough already. reply toasterblender 14 hours agorootparent> Poach them to do what?Poach them to discover 0-days in their software, as I said. reply saagarjha 14 hours agorootparentThat’s not what implant developers do. reply tagawa 11 hours agoparentprevIt’s not just money that motivates. reply fortran77 10 hours agoparentprevI want to fight terrorism. I’ll work for a company finding ways to get data from bad actors’ phones before I’d work for Google or Apple, at any price. reply trollian 13 hours agoparentprevThese exploits are weapons. Look at what governments pay for weapons. That&#x27;s hard to compete with. reply eviks 5 hours agorootparentHow much do they pay for weapons at the level of an individual weapon designer&#x2F;manufacturer&#x27;s employee?? reply fh9302 14 hours agoprevThe article doesn&#x27;t mention it but Lockdown Mode on iOS blocked this exploit chain. reply boothemoo 13 hours agoprevThis vulnerability was most probably used by the Egyptian authorities to hack the mobile phone of the presidential candidate Ahmed El Tantawy who is competing with the current president Abdel Fatah El Sisi over presidency.https:&#x2F;&#x2F;x.com&#x2F;jsrailton&#x2F;status&#x2F;1705271600868692416?s=46&t=Kq... reply cotillion 16 hours agoprevOuch.Apparently Firefox has \"Https First\" also but requires the pref dom.security.https_first to be set.\"HTTPS-Only Mode\" is obviously best if you can do that. reply rany_ 15 hours agoparentYou&#x27;d still need to resist the urge to not press \"allow me anyway\" and to be honest, even I&#x27;d click it knowing the risk (I just want to visit the damn site!). This doesn&#x27;t solve anything unless the prompt is extremely suspicious (like the prompt showing for Google.com or some other site I know supports HTTPS). reply rany_ 14 hours agorootparentReplying to myself but also, they could easily trick you into clicking some link and exploiting you that way. HTTP isn&#x27;t the issue here, it&#x27;s just being exploited so they don&#x27;t have to get you to click some link.In all likelihood they&#x27;d do that if the less direct&#x2F;obvious method of transmission didn&#x27;t work. reply arkj 14 hours agoprevGoogle search to intellexa results in an http site which got redirected. I am now installing the update. reply qingcharles 9 hours agoprevI can&#x27;t help but think Google cheekily outed the domains the vendor was using as a way to target some vigilante justice upon them. reply aborsy 14 hours agoprevI’m not an expert, but would’t a VPN (commercial or to a server with known exit IP) prevent such attacks? It will kick out the MITM.Also I wonder if the lock down mode could block it. reply fullspectrumdev 13 hours agoparentYes and also yes.These attacks when launched by government entities pretty much always rely on placing a box at the ISP that does the targeted interception&#x2F;MiTM against a subset of subscribers.So using a VPN would ensure your traffic is tunnelled “beyond” their reach.Lockdown mode also would have prevented the iOS exploit chain, apparently. reply sylware 1 hour agoprevOfc, the \"services\" have enough CA certificates private keys to legitimate any \"man-in-the-middle\" attack for any browsers. Worst case scenario they have root-kits they can easily inject on user systems in order to intercept some trafic before encryption. They have probably a significantly sized \"library\" at their disposal to work from, depending on the \"targets\", and it could even be kind of automated (up to a certain point) with proper finger-printing of user system&#x2F;components.Presuming the other way around would be unreasonable. reply account-5 13 hours agoprevI&#x27;ve a question. This 0-day is a 0-click that didn&#x27;t require any document download or anything. Simply visiting a http site would do it. What if you have JavaScript disabled be default. Would this exploit still work? reply saagarjha 10 hours agoparentNeeding to visit a website makes it a 1-click attack, unless you can do passive redirection. reply bananapub 13 hours agoparentprevit&#x27;s http interception so no, I doubt javascript matters at all reply lucb1e 12 hours agorootparentWithout knowing more, that&#x27;s a bit of an assumption. The vulnerability could be in image decoding, in which case antag is enough and no scripting is needed, but it could also very well require doing something funky with JavaScript. reply swordbeta 12 hours agoprevIs the commit containing the fix for the v8 bug 1473247 CVE-2023-4762 available anywhere? reply 1letterunixname 8 hours agoprevIf I were a government security regulator or intelligence agency, I would monitor bank accounts associated with Zerodium and similar 0day and payload marketplaces and offensive sec tools to issue a secret, internal threat forecast that marks the beginning potential of increasing, directed, high-value attacks. Probably already exists in various forms, but taking it semi-public to sensitive industries might be useful. reply saagarjha 6 hours agoparentThis is basically “can the government prosecute money laundering and tax evasion”. reply AtNightWeCode 15 hours agoprevI don&#x27;t get it. If it is over http then you can play around with anything in a proxy. You have no TLS tunnel so it is not encrypted. It is by design. reply vngzs 15 hours agoparentThat&#x27;s just the delivery method, not the exploit. reply d3w4s9 15 hours agoparentprevYes it is not encrypted and the response returned from server can be modified to anything and ask for password etc, but that is far from an exploit that runs native code. reply alephnerd 16 hours agoprevSlighty related, but Senator Bob Menendez was just indicted for taking bribes from people connected with the Egyptian military [0]. Gotta say, the Egyptian intelligence services are definitely punching above their weight by regional power standards.[0] - https:&#x2F;&#x2F;www.politico.com&#x2F;news&#x2F;2023&#x2F;09&#x2F;22&#x2F;egypt-guns-money-me... reply Ozzie_osman 14 hours agoparentFrom the Google disclosure I can&#x27;t tell what Egypt has to do with this though. Intellexa is a Greek firm founded by an ex-IDF (aka Israeli) guy. In general, while Egypt has definitely been caught using tech like this, it rarely has the sophistication to develop it itself. reply lainga 16 hours agoparentprevHey, they nearly destroyed the Ottoman Empire in the 1840s... reply WarOnPrivacy 14 hours agoparentprev> Senator Bob Menendez was just indicted for taking bribes from people connected with the Egyptian militaryAt a federal level law&#x2F;power is continually traded for cash&#x2F;favors. Heck, DoJ itself gets deployed in response to lobbyist demands (eg:copyright enforcement).From what I see this case was egregious and involved a non-favored foreign state. Maybe that&#x27;s the bar at which DoJ begins to care about political ethics. reply alephnerd 14 hours agorootparent> law&#x2F;power is continually traded for cash&#x2F;favorsI worked on the Hill and that&#x27;s not how it works. Yes, lobbying happens, but the what Menendez is indicted for goes well beyond anything a lobbyist would do legally. On top of that, foreign lobbyists need to formally register with the DoJ, which obviously didn&#x27;t happen, but that&#x27;s just the icing on the cake. reply WarOnPrivacy 13 hours agorootparent>> law&#x2F;power is continually traded for cash&#x2F;favors> I worked on the Hill and that&#x27;s not how it works.Your are asserting that law&#x2F;power is not continually traded for cash&#x2F;favors. That&#x27;s a pretty clear assertion and I appreciate it.To follow, you would also assert that this chain doesn&#x27;t exist in any meaningful way:Major campaign donations are used by legislator -> Legislator benefiting from funds is critical to creation of law&#x2F;regulation or to enactment of federal action taken that is favorable to donor -> Influential&#x2F;lucrative, positions that benefit the legislator (or their interest) are made available to the legislator (during&#x2F;after the elected term) by the donor.recap: You are asserting that what I describe above is not occurring on an ongoing basis, correct? reply astrange 11 hours agorootparentYes, that doesn&#x27;t happen.If a legislator agrees with you, you want to keep them in the legislature, not retiring into industry.Also, campaign donations are capped at like $5000 and most of what people think is corruption is them recklessly misreading the donation reports.Similarly, it&#x27;s Bernie and similar people who get the most donations these days because of ActBlue, and it doesn&#x27;t help them win elections, because voters actually like the legislators you think are owned by corporations and actually vote for them. reply WarOnPrivacy 10 hours agorootparent> Yes, that doesn&#x27;t happen.I invested 15 seconds into a search query.Former Members Dick Armey. Tom Daschle. Tom Foley. Trent Lott.Once, these politicos ranked among Congress&#x27; most powerful members. Today, they share another distinction: They&#x27;re lobbyists (or \"senior advisors\" performing very similar work). And they&#x27;re hardly alone. Dozens of former members of Congress now receive handsome compensation from corporations and special interests as they attempt to influence the very federal government in which they used to serve.ref: https:&#x2F;&#x2F;www.opensecrets.org&#x2F;revolving&#x2F;top.php?display=ZThis is an incomplete list of just one body of lawmakers who went to work for just one industry. It&#x27;s a very limited reference to the much, much larger whole.>If a legislator agrees with you, you want to keep themAlthough I included people tied to legislators (and their interests) you opted to limit your response to just legislators and even that seemed more platitude than substance.> Also, campaign donations are capped at like $5000So what? This falsely implies no donor can get more than $5k into any one campaign fund. Tossing it out there as primarily defining detail seems disingenuous. It omits non-cash contributions. It omits donations to traditional PACs, Super PACs, 527s, political parties, 501(c)4,5 & 6.It omits all the possible avenues of getting money to candidates that someone with a CapHill political background almost certainly knows.It does dovetail nicely with an alternate narrative about revolving doors not existing, however. reply astrange 9 hours agorootparent> This is an incomplete list of just one body of lawmakers who went to work for just one industry. It&#x27;s a very limited reference to the much, much larger whole.Those people are a combination of 1. really old and 2. lost an election. You can&#x27;t keep people around forever, even if you might want to. (It also implies they&#x27;re effective as lobbyists, which I don&#x27;t think is necessarily true.)> This falsely implies no donor can get more than $5k into any one campaign fund.Those other things aren&#x27;t the campaign fund, they&#x27;re largely separate funds running separate campaigns and not controlled by the candidate. So they can&#x27;t be used to directly pay the candidate.Also, as I said, 1. money doesn&#x27;t actually win elections and 2. if it did, it&#x27;s Bernie and fellow non-corporate-Dem candidates who&#x27;d actually be winning, because small donor fundraising is more effective than this stuff is.There are some straight up bribery scandals, but I think Bob Menendez is an exception that proves the rule and is going to lose his office based on his literal piles of gold bars bribery.It is, however, actually the case with SCOTUS judges that they straight up take bribes and nobody can stop them. replypakyr 14 hours agorootparentprev> involved a non-favored foreign stateEgypt is not &#x27;non-favored&#x27;. The US has very close ties with Egypt&#x27;s dictatorial regime[0], despite its awful domestic human rights record[1].[0]https:&#x2F;&#x2F;thehill.com&#x2F;blogs&#x2F;congress-blog&#x2F;foreign-policy&#x2F;58552...[1]https:&#x2F;&#x2F;www.amnesty.org&#x2F;en&#x2F;latest&#x2F;news&#x2F;2022&#x2F;09&#x2F;egypt-human-r... reply WarOnPrivacy 13 hours agorootparent> Egypt is not &#x27;non-favored&#x27;.The WTO sets the MFN list and Egypt isn&#x27;t on it so strictly speaking you aren&#x27;t correct.Besides incurring WTO favor, the US also bestows it&#x27;s own preferential treatments to those same nations. Egypt has long received many of those preferences so you&#x27;re right in the ways that are most relevant.That said, I wouldn&#x27;t place Egypt on US&#x27;s BFFs! Top partners in crime list - the one that includes 5&#x2F;8 eyes nations and Israel. reply KoftaBob 15 hours agoparentprevProbably part of the long running (now peaceful) rivalry they have with Israel. reply alephnerd 13 hours agorootparentYep! Totally forgot about that! reply shmatt 16 hours agoprevAnother company founded by ex-Israeli intelligence.The funny thing about exploits is, once hundreds of employees or soldiers have access to the exploit, they don&#x27;t need to physically copy the code. They just need to understand how it works, to then open 10 other companies that use the same exploit, or sell it to 20 other companies on the dark web.Although the IDF is great at stopping people from copying files outside of their networks, it can&#x27;t stop people from remembering what they did during their service reply alephnerd 16 hours agoparentFor every 1 zero day, there are around 10-20 others that haven&#x27;t been publicized. You can make plenty of money by trying to find a niche and concentrating on that (eg. android exploitation, iOS exploitation, Windows exploitation, APAC buyers, US Defense buyers, Middle Eastern buyers, EU buyers, etc). reply Veserv 16 hours agoprevJust your regular reminder that for the only security certification that Apple advertises on their website for iOS [1][2] Apple only achieved the lowest possible level of security assurance, EAL1. A level only fit for products where [3]: \"some confidence in the correct operation is required, but the threats to security are not viewed as serious\" which does not even require \"demonstrating resistance to penetration attackers with a basic attack potential\" [4]. This is four entire levels lower than \"demonstrating resistance to penetration attackers with a moderate attack potential\" [5].Apple has never once, over multiple decades of failed attempts, demonstrated \"resistance to penetration attackers with a moderate attack potential\" for any of their products. To be fair, neither has Microsoft, Google, Amazon, Cisco, Crowdstrike, etc. It should be no surprise that the companies, processes, and people who lack the ability, knowledge, and experience to make systems resistant to moderate attackers despite nearly unlimited resources are regularly defeated by moderate attacks like commercial surveillance companies. They certify that they absolutely, 100% can not.[1] https:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;certifications&#x2F;ios-security-...[2] https:&#x2F;&#x2F;support.apple.com&#x2F;library&#x2F;APPLE&#x2F;APPLECARE_ALLGEOS&#x2F;CE...[3] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 14[4] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 16[5] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 20 reply dang 12 hours agoparentPlease don&#x27;t post \"regular reminder\" style comments - they&#x27;re too generic, and generic discussion is consistently less interesting. Good threads require being unpredictable. The best way to get that is to respond to specific new information in an article.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply alephnerd 15 hours agoparentprev> neither has Microsoft, Google, Amazon, Cisco, Crowdstrike, etc. It should be no surprise that the companies, processes, and people who lack the ability, knowledge, and experience to make systems resistant to moderate attackersCompanies create a separate SKU for products that meet higher levels of security assurance for Common Criteria. I know for a fact that the companies you listed offer SKUs that meet higher EA levels (EAL4+) for Common Criteria. You just gotta pay more and purchase via the relevant Systems Integrators.A consumer product line like the Apple iPhone isn&#x27;t targeting DoD buyers. That&#x27;s always been Blackberry Ltd&#x27;s bread and butter reply Veserv 15 hours agorootparentI said, \"resistance to penetration attackers with a moderate attack potential\". EAL5 is the first level at which you must demonstrate that as can be seen in my 5th link [1] which bolds the diffs from the previous level.None of those companies has ever once certified a product to that level as far as I am aware. The failure is so complete that it is generally viewed as impossible to fix the structural defects in products that failed a EAL5 certification without a total rewrite. It used to say that in the standard somewhere, but the standard revisions have moved it so I can not quote it directly.[1] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 20 reply alephnerd 15 hours agorootparentGoing EAL5 and above doesn&#x27;t make sense from a cost to security ratio UNLESS the customer is open to paying more for that level of verification.Certain agencies and bureaus within the DoD do ask for this and pay for it, but most are good enough with EAL4.Most attacks can be resolved by following the bare minimum recommendations of the MITRE ATTACK framework (marketing buzzwords aside).Least Priviliged Access, Entitelement Management, Identity Enforcement, etc are all much easier wins and concepts that haven&#x27;t been tackled yet.Companies will provide EAL5+ if the opportunity is large enough, but it won&#x27;t be publicized. Iykyk. If not, chat with your SI. reply Veserv 14 hours agorootparentNo. The US government briefly had procurement requirements for high security deployments.They were forced to relax them because Microsoft could not make bids that met the minimum requirements for DoD and high security projects and that made their Senators mad. They relaxed them to EAL4+ because that was the most that Microsoft could do.They since relaxed them further to EAL2 because that is all the most large AV and cybersecurity appliance vendors could achieve. They justified it under the \"swiss cheese\" model where if you stack multiple EAL2 then you get EAL4 overall, which is insane. The government has since relaxed them even further since none of the companies want to do any certification since none of them can achieve a decisive edge over the others that they can write into the requirements thus disqualifying their competition, so certification is just a zero-sum game. reply kramerger 14 hours agorootparentEAL5 is mainly about having a semi- formal description and for 6-7 you also need formal verification.Outside some very limited cases, we don&#x27;t have the tools to go there yet. EAL4+ is what people should aim for. reply Veserv 14 hours agorootparentEAL4+ is useless against the prevailing threat actors as can be seen time and time again. There is no point at aiming for inadequate; even if you get there you still get nothing.EAL6-7 certifications are basically the only known, existing certifications that have any evidence supporting that they are adequate to defend against the known and expected threats. As far as I am aware, there are no other certifications even able to distinguish products that can viably protect against organized crime and commercial spyware companies. Existing products max out every other certification and we know for a fact those products are ineffective against these threat actors. Therefore, we can conclude that those certifications are useless for identifying actual high security products adequate for the prevailing threat landscape.Sure, if we had some other certification that could certify at that level and was more direct, that would be nice. But we do not, the only ones that we know to work and that products have been certified against are Common Criteria EAL6-7 (and maybe EAL5). We can either choose certifications that are cheap and do not work, or ones that work. Then, from the ones that work, we can maybe relax the requirements carefully to identify useful intermediate levels, or identify if some of the requirements are excessive and unnecessary for achieving the desired level of assurance.However, the key takeaway from this is not whether we can certify products to EAL5 and higher or whether those certifications work or the cost-benefit of that certification process. The key takeaway is that EAL4 is certainly inadequate. Any product in commercial use targeting that level or lower is doomed to be useless against the threat actors who we know will attack it. reply kramerger 13 hours agorootparent> EAL4+ is useless against the prevailing threat actorsHold on a second. Assurance level is about, well, level of assurance the developers can provide. It is in most cases just paperwork.CC has a different mechanism to define attacker capability & resources (cant recall what it&#x27;s called) and set the security goals accordingly reply Veserv 13 hours agorootparentThe AVA_VAN (vulnerability analysis) Security Assurance Requirement (SAR). AVA_VAN.4 requires “resistance to penetration attackers with a moderate attack potential”. AVA_VAN.4 is only required for EAL5 and higher.You could individually incorporate a higher AVA_VAN into a lower EAL as a augmentation, but few do that. You also do not get any of the other conformance assurances that a higher EAL gives you. There is a reason we use EAL as a whole instead of just quoting the AVA_VAN at each other.Though maybe you are talking about the Security Functional Requirements (SFR) which define the security properties of your system? That is somewhat orthogonal. You have properties and assurance you conform to the properties. Conformance more closely maps to “level of security” as seen in the AVA_VAN SAR. However, the properties are just as important for the usage of the final product because you might be proving you absolutely certainly do nothing useful. reply insanitybit 13 hours agorootparentprevI feel like you&#x27;re arguing that these certifications are useless and uncorrelated with security but then you&#x27;re trying to say that Apple and others are bad for not having them. reply Veserv 13 hours agorootparentLow certification levels certify low levels of security. High certification levels certify high levels of security.EAL4 is known to be too low against modern threats that will attack commercial users. We know this from experience where EAL4 systems are routinely defeated. Higher certification levels, such as the SKPP at EAL6&#x2F;7, are known to be able to resist against much harder threats such as state actors like the NSA (defeating a NSA penetration test was a explicit requirement tested in the SKPP by the NSA themselves).Low certification levels, like EAL4 and lower, that are the limit of the abilities of companies such as Apple and Microsoft are known to be useless against commercial threats. They are uncorrelated with protection against commercial threats because they are inadequate in much the same way that having a piece of paper in front of you is uncorrelated with surviving a gunshot. Systems that can only be certified to EAL4 and lower are certifiably useless. reply insanitybit 11 hours agorootparent> Low certification levels certify low levels of security. High certification levels certify high levels of security.I guess I don&#x27;t know enough to say but I just doubt that, knowing what I know about other certifications. I expect that they&#x27;re perhaps lightly correlated with security. reply Veserv 11 hours agorootparentYou said that I was arguing the certification is useless. I was arguing that certifying to low levels is useless. Those are not even close to the same argument.For example, a squat test is a reasonable measure of leg strength. Only squatting 20 kg means your leg strength is extremely weak. The test procedure is fine, getting results like that is not. If that is all you can do, that is quite problematic.As to the certification itself, it is pretty good. Easily hacked products like iOS, Linux, and Windows are consistently unable to certify as moderately secure. That is vastly different than basically every other certification where products like Windows pass with flying colors even though we all know that is nonsense.So, at the very least, low certification levels like EAL4 provide high confidence of lackluster security. You can withhold judgement of high assurance levels corresponding to high security if you like, but low assurance levels corresponding to low security is pretty clearly established. reply insanitybit 15 hours agoparentprevI mean, it occurs to me that maybe all of these companies aren&#x27;t doing this for a reason - because common criteria and compliance are often stupid and don&#x27;t represent real security. Perhaps these policies are the exception? But I&#x27;ve managed SOC2 for example and I can definitely say that there are plenty of ways to get your SOC2 without giving a shit about actual security. reply Veserv 14 hours agorootparentThey failed. Repeatedly. For decades. They spent billions trying. The failed so much that the standard writers determined the only logical conclusion is that it must be practically impossible to retrofit a system that failed EAL5 certification to achieve EAL5 or higher certification without a complete rewrite and redesign. It says so right there in the standard [1]: \"EAL4 is the highest level at which it is likely to be economically feasible to retrofit to an existing product line\". That was added due to the decades of experience where everybody who ever tried to do that failed no matter how much time or money they spent.We also have plenty of evidence that it does matter, they just can not do it. Here is Google touting their Common Criteria certification for the Titan M2 security chip hardware which is EAL4 + AVA_VAN.5 (resistance against penetration attackers with a high attack potential) [2]. Note that this is only the hardware (software was not certified; a critical severity vulnerability was actually disclosed in the software allowing complete takeover if I remember correctly) and only cherry picks AVA_VAN.5 so is still only EAL4, not a holistic EAL6 certification. Getting that certification was a deliberate effort and cost. If they literally did not care about the Common Criteria then they would just certify to the checkbox level like everybody else. It is because they could certify it to a higher level than most other can achieve that they chose to do it because then they could tout their unique advantage.Basically everybody gets a certification and basically everybody displays their certification on their page. There is something to be said about them opting for a EAL1 over a EAL4. It is basically assumed that any serious vendor could probably get a EAL4 with some effort. So, there is no differential advantage to displaying a EAL4 since everybody could get it. It is just a zero-sum game to pay for certification if everybody knows nobody has a true advantage. However, if you can achieve EAL5 or higher, then you do have a unique advantage because basically nobody else can do it. The fact that none of the major vendors attempts EAL5, shows that they can not do it.[1] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 18[2] https:&#x2F;&#x2F;security.googleblog.com&#x2F;2022&#x2F;10&#x2F;google-pixel-7-and-p... reply manuelabeledo 15 hours agoparentprev> Apple has never once, over multiple decades of failed attempts, demonstrated \"resistance to penetration attackers with a moderate attack potential\" for any of their products. To be fair, neither has Microsoft, Google, Amazon, Cisco, Crowdstrike, etc.So, OK I guess?It&#x27;s worth noting that CC evaluation does not score the actual practical security of a device or system, but the level of testing it was submitted to, which is consistent with pretty much every single governmental certification out there. reply Veserv 13 hours agorootparentSure it does, it is just that EAL4+, the highest level any of them can reach, does not certify \"resistance to penetration attackers with a moderate attack potential\". Guess what, commercial hackers have \"moderate attack potential\".You are complaining that the 40 cm high jump test does not score actual jumping ability. You are right, it is a low bar that they should all be able to pass. You can not use the 40 cm high jump test to distinguish them. What you need to do is use the 100 cm high jump test. Some can pass it, but none of the large commercial vendors can. Sure, it would be nice if we had more gradations like the 60 cm and 80 cm tests, but we do not really know how to do that, so the best we can do is the 100 cm test. reply manuelabeledo 13 hours agorootparentI&#x27;m not really complaining, though. I&#x27;m just saying that security certifications are more about compliance than actual proof that a system cannot be easily compromised. In other words, they are more about legal requirements than guarantees.It is also misleading to assert that a device or a system are less secure because they haven&#x27;t been certified. Vendors submit requests to validate against specific levels or certifications, and it is not the goal of the certification authority to determine \"how high\" they score. reply Veserv 13 hours agorootparentThey can not certify against useful assurance levels. They have tried repeatedly for decades and spent huge gobs of money. It is not a choice, they are incapable of it.I am judging them by their maximum ability ever demonstrated under the most favorable circumstances and they still can certify resistance against moderate attackers. They have never developed systems that can protect against the prevailing threat landscape and they can not develop such systems. Their best is not good enough. reply manuelabeledo 11 hours agorootparent> They have tried repeatedly for decades and spent huge gobs of money. It is not a choice, they are incapable of it.First of all, I don&#x27;t think that&#x27;s true, and if it is, I would like to see proof of Apple submitting their products for evaluation.Second, you are judging an entire industry. This is not about Apple shortcomings, there isn&#x27;t a single vendor doing what you say needs to be done.Regardless, and this is more a personal opinion than a hard fact, most certifications out there are BS. PCI-DSS is basically a checklist of best practices, CC goes from common sense stuff to essentially impossible to achieve unless designed for the specific purpose, etc. Yes, all these helped create a very healthy - and profitable - industry where consultants have thrived on Powerpoints and PDFs, without really creating any tangible value. replykramerger 14 hours agoparentprevIsn&#x27;t EAL1 what you get for just showing up?Basically, here is the product. Here are some design documents. We don&#x27;t have anything more. Can we get our EAL1 please? reply Veserv 14 hours agorootparentYup. Want to have a laugh? Here is the Apple iOS certification report [1].On PDF page 26 (document page 21) they describe the rigorous AVA_VAN.1 vulnerability analysis certification process they faced. The evaluation team basically typed in: \"ios vulnerabilities\" into Google and then typed in \"ios iphone\" into the NVD and verified that all of the search results were fixed. AVA_VAN.1 certification please.To explain why, AVA_VAN.1 does not require a independent security analysis, it only requires a survey of the public domain for known vulnerabilities [2]. You need AVA_VAN.2 (which is only required in EAL2 and EAL3) before they actually attempt to look at for vulnerabilities themselves.[1] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;epfiles&#x2F;st_vid112...[2] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;files&#x2F;ccfiles&#x2F;CC2022PAR... Page 154 reply tptacek 8 hours agoparentprevCommon Criteria EALs have nothing whatsoever to do with practical security. I&#x27;d be surprised to hear anybody on this site who has managed a CCTL security review for a product saying anything positive about the program.A fun exercise: find a list of commercial mainstream products with \"high\" EAL audits, and then look at their vulnerability histories. reply Veserv 8 hours agorootparentSince it is fun can you link some of these EAL5 or higher products with sordid vulnerability histories? reply tptacek 8 hours agorootparentThe archetypical EAL5 product is a smartcard or cryptographic coprocessor (same thing, different package). They&#x27;re certifiable because they don&#x27;t do much.But if you&#x27;d like an example from the EAL4 list: start with FortiOS. reply Veserv 7 hours agorootparentEAL4 and under is junk (with respect to security). I already said that. The standards committee has also always maintained that there is no meaningful security at EAL4. Earlier drafts of the standards said EAL4 is only meant to protect against “casual and inadvertent attacks”.The general crappiness of EAL4 goes all the way back to the Orange Book where EAL4 maps approximately to Level C2 (contemporaneous projects got certified to those levels simultaneously). That level was intentionally meant for toys before they put on their big person pants and release a grown up product with actual security [1]. It is a mystery why anybody thinks EAL4 and security belong in the same sentence.[1] https:&#x2F;&#x2F;www.stevelipner.org&#x2F;links&#x2F;resources&#x2F;The%20Birth%20an... reply tptacek 6 hours agorootparentIf you&#x27;re saying \"EAL4 and below is junk\" (I&#x27;d say EAL* is junk, but whatever), all you&#x27;re really saying is that minimal-function cryptographic coprocessors are safer than operating systems and applications. Well, yeah, sure. I don&#x27;t think you needed the farce of Common Criteria to tell you that, though.But upthread, you knocked Apple for not achieving an adequate assurance level. As you can see now, and from your own last comment, that doesn&#x27;t make any sense. It&#x27;s possible (though deeply silly) that there&#x27;s some iPhone configuration that could \"achieve\" EAL4, but you yourself don&#x27;t believe that has any meaning. I don&#x27;t either.I don&#x27;t think EAL5 or EAL6 do, either, except that if you tell me your product is EAL5, I&#x27;ll assume it&#x27;s a small fixed-function device. reply Veserv 6 hours agorootparentNo. The Separation Kernel Protection Profile (SKPP) defines a model for a operating system kernel at EAL6+. So all I am really saying is that safe operating systems are safer than non-safe operating systems. You could also look backwards to the TCSEC and the comparable certified Level A1 systems for other operating systems designed for actual high security work.You keep calling it a farce, but you keep pointing at EAL4 and lower systems. Yes, those levels are farces, that was the whole point. Those are the levels for the certification of toys where documentation and paperwork is all that is needed, not proper design.Complaining about the Common Criteria in the context of EAL4 and lower systems is like complaining about tissue paper manufacturers putting their tissue paper through bulletproof vest testing and certifying that it does not stop bullets. Yes, that is pretty stupid, farcical, and probably a waste of time. But no, the test is not stupid. It can test actual bulletproof vests, you just keep seeing stupid waste of time tests proving a useless fact that everybody already knows, the EAL4 quality system sucks and has no place in a serious security organization. reply tptacek 5 hours agorootparentThis is like comparing the L4-based SEPOS to macOS. They share the name \"operating system\", but they are not the same thing. reply pvg 3 hours agorootparentI can&#x27;t help but pick a couple of general points from area standards-arguer man.One is &#x27;problems of standardization in high-development-velocity fields&#x27;:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=3577837The other is \"this is worse in security engineering broadly and outright catastrophic in cryptography engineering specifically\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25451351There&#x27;s probably better&#x2F;longer, I just looked at the first page of \"standards\" search. The points are strong, like messageboard-argument-winning bear, though. replywepple 14 hours agoparentprevThere is a near zero chance that being EAL4 or higher certified would’ve prevented these attacks.CC might be better than PCI-DSS, but not by much. reply vuln 15 hours agoparentprevDo you by any chance have this data on Google, Samsung, Huawei, LG, and other cell phone manufacturers? I’ve never looked into these certifications and I wouldn’t know where to start looking. Do the above companies publish the results like Apple? reply selectodude 15 hours agorootparenthttps:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;products&#x2F;index.cfm?Generally only components are EAL certified. For example, the iPhone is not on there, but the security protecting access to Apple Pay on the iPhone 13 with A15 Bionic running iOS 15.4.1 (19E258) is EAL2+. reply alephnerd 15 hours agorootparentprevYou as a private consumer wouldn&#x27;t be able to buy one of these EAL4+ products without a relationship with a defense and security oriented reseller. reply Veserv 15 hours agorootparentprevSure. The Common Criteria for Information Technology Security Evaluation [1] is the foremost internationally recognized standard (ISO 15408) for software security that most large companies certify against for at least some of their product portfolio. I believe there are US government procurement requirements to that effect, so many systems will have certifications of some form.For many companies you just search: \"{Product} Common Criteria\" and they will usually have a page for it on their website somewhere.You can also go directly to the certified products page: https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;products&#x2F;For smartphones you can see them there under \"Mobility\".Unfortunately, it is fairly hard to parse if you are not familiar with the terminology. The general structure of Common Criteria certifications is Security Functional Requirements (SFR) which are basically the specification of what the product is supposed to do and the Security Assurance Requirements (SAR) which are basically how you certify the SFRs are met (and what level of assurance you can have that the SFRs are met). SARs can be bundled into Evaluation Assurance Levels (EAL) which define collections that reasonably map to levels of confidence. You can add SARs beyond the current EAL which is how you get a EAL level with a +, but it is important to keep in mind that just cherry picking certain SARs does not necessarily give you a holistic assurance improvement.SARs and SFRs can be further pre-bundled into Protection Profiles (PP) which basically exist to provide pre-defined requirements and testing methodologies instead of doing it one-off every time. Some Protection Profiles support variable EAL&#x2F;SAR levels, but these days people generally just certify against a Protection Profile with a fixed SAR bundle. This is what PP Compliant means. If you want to see what they certified against, you would need to look at the Protection Profile itself.For smartphones, the standard Protection Profile for the phone itself is Mobile Device Fundamentals. If you look at the SAR bundle there you will see that they correspond to EAL1 + a small number of EAL2, resulting in a overall level of EAL1+. As they are in-between EAL1 and EAL2 I just classified it as EAL1 for my earlier post. If you peruse further you will see that basically every Protection Profile that companies certify to as PP Compliant are basically the same EAL1+ or thereabouts. So, if you see PP Compliant, it probably means EAL1+ or so.Hope that helps.[1] https:&#x2F;&#x2F;www.commoncriteriaportal.org&#x2F;cc&#x2F; reply bingobongodude 12 hours agoprevI am pretty sure I was hit with this. I had some REALLY weird redirects coming from text msgs. NOT from Egypt. Maybe paranoid. Offline &#x2F; on new Linux devices for now. reply saagarjha 10 hours agoparentText messages with links that do weird redirects aren’t too unusual. What makes you think you were a target? reply mtu9001 14 hours agoprev [–] Some men just want to watch the world burn. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google's Threat Analysis Group and The Citizen Lab have discovered a 0-day exploit chain for iPhones, developed by the surveillance vendor Intellexa, used to install the 'Predator' spyware via a man-in-the-middle (MITM) attack.",
      "Apple has rectified this problem by patching the vulnerabilities in iOS 16.7 and iOS 17.0.1, which emphasizes the risks posed by commercial surveillance vendors.",
      "Google proposes users to enable \"HTTPS-First Mode\" as a protection measure against MITM attacks, underscoring Google's ongoing efforts against these threats in the spyware industry."
    ],
    "commentSummary": [
      "The article discusses broad cybersecurity subjects including, exploit of software weaknesses by an Egyptian surveillance vendor, the difficulties in remedying vulnerabilities, and the need for skilled security professionals.",
      "It delves into the effect of security certificates and the role of VPNs in shielding against government surveillance.",
      "It also mentions corruption allegations and the impact of these vulnerabilities on a presidential candidate's phone, indicating the far-reaching consequences of cybersecurity issues."
    ],
    "points": 470,
    "commentCount": 214,
    "retryCount": 0,
    "time": 1695403282
  },
  {
    "id": 37612420,
    "title": "GitHub Actions could be so much better",
    "originLink": "https://blog.yossarian.net/2023/09/22/GitHub-Actions-could-be-so-much-better",
    "originBody": "ENOSUCHBLOG Programming, philosophy, pedaling. Home Tags Series Favorites Archive Main Site GitHub Actions could be so much better Sep 22, 2023 Tags: programming, rant, workflow I love GitHub Actions: I’ve been a daily user of it since 2019 for both professional and hobbyist projects, and have found it invaluable to both my overall productivity and peace of mind. I’m just old enough to have used Travis CI et al. professionally before moving to GitHub Actions, and I do not look back with joy1. By and large, GitHub Actions continues to delight me and grow new features that I appreciate: reusable workflows, OpenID connect, job summaries, integrations into GitHub Mobile, and so forth. At the same time, GitHub Actions is a regular source of profound frustration and time loss2 in my development processes. This post lists some of those frustrations, and how I think GitHub could selfishly3 improve on them (or even fix them outright)4. Debugging like I’m 15 again Here’s a pretty typical session of me trying to set up a release workflow on GitHub Actions: In this particular case, it took me 4 separate commits (and 4 failed releases) to debug the various small errors I made: not using ${{ ... }}5 where I needed to, forgetting a needs: relationship, &c. Here’s another (this time of a PR-creating workflow), from a few weeks later: I am not the world’s most incredible programmer; like many (most?), I program intuitively and follow the error messages until they stop happening. GitHub Actions is not responsible for catching every possible error I could make, and ensuring that every workflow I write will run successfully on the first try. At the same time, the current debugging cycle in GitHub Actions is ridiculous: even the smallest change on the most trivial workflow is a 30+ second process of tabbing out of my development environment (context switch #1), digging through my browser for the right tab (context switch #2), clicking through the infernal nest of actions summaries, statuses, &c. (context switch #3), and impatiently refreshing a buffered console log to figure out which error I need to fix next (context switch #4). Rinse and repeat. Fixing this Give us an interactive debugging shell, or (at least) let us re-run workflows with small changes without having to go through a git add; git commit; git push cycle6. Give us a repository setting to reject commits with obviously invalid workflows (things like syntax that can’t possibly work, or references to jobs/steps that don’t exist). It’s infuriating when I git push a workflow that silently fails because of invalid YAML; especially when I then merge that workflow’s branch under the mistaken impression that the workflow is passing, rather than not running at all. Security woes Speaking from experience: it’s shockingly easy to wreck yourself with GitHub Actions. Way easier than it should be. Here is just a small handful of the ways in which I have personally written potentially vulnerable workflows over the past few years: Using the ${{ ... }} expansion syntax in a shell or other context where a (potentially malicious) user controls the expansion’s contents. The following, for example, would allow a user to inject code that could then exfiltrate $MY_IMPORTANT_SECRET: 1 2 3 4 5 - name: do something serious run:something-serious \"${{ inputs.frob }}\" env: MY_IMPORTANT_SECRET: ${{ secrets.MY_IMPORTANT_SECRET }} Some among you will observe that a ✨good✨ programmer would simply know not to do this, and that a bad programmer would eventually learn their (painful) lesson. This might be an acceptable position for a niche piece of software to hold; it is not an acceptable position for the CI/CD platform that, to a first approximation, hosts the entire open source ecosystem. Using pull_request_target. As far as I can tell, it’s practically impossible to use this event safely in a non-trivial workflow7. This event appears to exist for an extremely narrow intended use case, i.e. labeling or commenting on PRs that come from forks. I don’t understand why GitHub Actions chooses to expose such a (relatively) simple operation through as massive of a foot-gun as pull_request_target. Over-scoping my workflow and job-level permissions. The default access set for Actions’ ordinary GITHUB_TOKEN is very permissive: the only thing it doesn’t provide access to are the workflow’s OpenID Connect token. This consistently bites me in two different ways: I consistently forget to down-scope the default token, especially when working with repositories under my personal account (rather than under an org, where the default scope can be reduced across all repositories). I consistently over-scope my tokens because I don’t know exactly how much access my workflow will need. This is further complicated by the messy ways in which GitHub’s permission model gets shoehorned into a single permissions dimension of read/write/none: why does id-token: write grant me the ability to read the workflow’s OpenID Connect token? Why do some GET operations on security advisories require write, while others only require read? There are also a few things that I haven’t done8, but are scary enough that I think they’re worth mentioning. For example, can you see what’s wrong with this workflow step? 1 2 steps: - uses: actions/checkout@c7d749a2d57b4b375d1ebcd17cfbfb60c676f18e Despite all appearances, SHA ref c7d749a2d57b4b375d1ebcd17cfbfb60c676f18e is not a commit on the actions/checkout repository! It’s actually a commit on a fork in actions/checkout’s network which, thanks to GitHub’s use of alternates, appears to belong to the parent repository. Chainguard has an excellent post on this9, but to summarize: SHA references from forks are visually indistinguishable from SHA references in the intended target repository. The only way to tell the two apart is to manually inspect each reference and confirm that it appears on the expected repository, and not one of its forks. GitHub’s own REST API makes no distinction between SHA references in a repository graph — /repos/{user}/{repo}/commits/{ref} returns a JSON response that only references {user}/{repo}, even if {ref} is only on a fork. Because GitHub fails to distinguish between fork and non-fork SHA references, forks can bypass security settings on GitHub Actions that would otherwise restrict actions to only “trusted” sources (such as GitHub themselves or the repository’s own organization). GitHub’s response to this (so far) has been to add a little bit of additional language to their documentation, rather than to forbid misleading SHA references outright. Fixing this Give us push-time rejection of obviously insecure workflows. In other words: let us toggle10 a “paranoid workflow security” mode that, when enabled, causes git push to fail with an explanation of what I’m doing wrong. Essentially the same thing as the debugging request above, but for security! Give us runtime checks on our workflows, analogous to runtime instrumentation like AddressSanitizer in the world of compiled languages. There are so many things that could be turned into hard failures for security wins without breaking 99.9% of legitimate users, like failing any attempt to use actions/checkout on a pull_request_target with a ref that isn’t from the targeted repository. Maybe just deprecate and remove pull_request_target entirely. GitHub’s own Security Lab has been aware of how dangerous this event is for years; maybe it’s time to get rid of it entirely. Allow us to set a more restrictive default token scope on our personal repositories, similar to how organizations and enterprises can restrict their default GITHUB_TOKEN scopes across all repositories at once. By default, reject any SHA-pinned action for which the SHA only appears on a fork and not the referenced repository. It’s hard to imagine a legitimate reason to ever need to do this! Real types would be nice When writing a custom GitHub Action, you can specify the actions inputs using a mapping under the inputs: key. For example, the following defines a frobulation-level input with a description (used for tooltips in many IDEs) and a default value: 1 2 3 4 inputs: frobulation-level: description: \"the level to frobulate at\" default: \"1\" Notably, this syntax does not allow for type enforcement; the following does not work: 1 2 3 4 5 6 7 inputs: frobulation-level: description: \"the level to frobulate to\" default: 1 # NOTE: this SHOULD cause a workflow failure if the input # isn't a valid number, but doesn't type: number This absence is strange, but what makes it bizarre is that GitHub is inconsistent about where types can appear in actions and workflows: workflow_call supports type with boolean, number, or string workflow_dispatch supports type with boolean, choice, number, or string Action inputs: no types at all Unfortunately, this is only the first level: even inputs that do support typing doesn’t support compounded data structures, like lists or objects. For example, neither of the following works: 1 2 3 4 5 6 7 8 - uses: example/example with: # INVALID: can't use arrays as inputs paths: [foo, bar, baz] # INVALID: can't use objects as inputs headers: foo: bar baz: quux …which means that action writers end up requiring users to do silly things like these: 1 2 3 4 5 6 7 - uses: example/example with: # SILLY: action does ad-hoc CSV-ish parsing paths: foo,bar,baz # SILLY: action forcefully flattens a natural hierarchy header-foo: bar header-baz: quux This is bad for maintainability, and bad for security: maintainability because actions must carefully manage a single flat namespace of inputs (with no types!), and security because both action writer and workflow writer are forced into ad-hoc, unspecified languages for complex inputs. Fixing this Let action and workflow writers use type: everywhere, and let us use choice everywhere — not just in workflow_dispatch! Give us stricter type-checking. Where action and workflow types can be inferred statically, detect errors and reject incorrectly typed workflow changes at push time, rather than waiting for the workflow to inevitably fail. Give us type: object and type: array types. These won’t be perfect to start with (thanks to potentially heterogeneous interior types), but they’ll be a significant improvement over the status quo. Implementation-wise, forward these as JSON-serialized strings or something similar11 where appropriate (such as in auto-created INPUT_{WHATEVER} environment variables). (More) official actions would be nice The third-party ecosystem on GitHub Actions is great: there are a lot of high-quality, easy-to-use actions being maintained by open source contributors. I maintain a handful of them! Beneath the surface of these excellent third-party actions is a substrate of official, GitHub-maintained actions. These actions primarily address three classes of fundamental CI/CD activities: Core git operations: actions/checkout Core GitHub operations and repository housekeeping: actions/{upload,download}-artifact, actions/cache, actions/stale General (but essential) configuration: actions/setup-python, actions/setup-node These classes are somewhat distinct from “higher-level” workflows (like the kind I write): because of their centrality and universal demand, they benefit from singular, high-quality, officially maintained implementations. And so, the question: why are there so few of them? Here is just a smattering of the official actions that don’t exist: Programmatically adding a pull request to a merge queue. GitHub has the machinery to support this: gh pr merge already exists. It just isn’t exposed as an action; users are (presumably) expected to piece it together themselves. Even worse, there are actions that did exist but were deprecated (generally for unclear reasons12): actions/create-release: unmaintained as of March 2021. Users encouraged to switch to various community maintained workflows, most notably13 softprops/action-gh-release. actions/upload-release-asset: marked as unmaintained at the same time as actions/create-release. actions/setup-ruby: unmaintained as of February 2021. Users encouraged to switch to ruby/setup-ruby. I’m sympathetic to the individual maintainers here and, in each case, the transition to a “recommended” third-party action was relatively painless. Still, the overall impression given here is unmistakable: that GitHub does not see official actions for its own platform features (or key ecosystem users, like Ruby) as priorities, and would rather have the community develop and choose unofficial favorites. This is not unreasonable on a strategic level (it induces third-party development in their ecosystem), but has a deleterious effect on trust in the platform. I’d like to be able to write workflows and know that they’ll run (with minimal changes) 5 years from now, and not worry that GitHub has abandoned core pieces underneath me! Apart from imparting a general feeling of shabbiness, this compounds with GitHub Action’s poor security story (per above): not providing official high-quality actions for their own API surfaces means that users will continue to make exploitable security mistakes in their workflows. Nobody wins14. Fixing this Give us more official actions. As a very rough rule of thumb: if a thing directly ties different pieces of GitHub infrastructure together and currently needs to be done manually (with REST API calls, gh invocations, or whatever else), it probably deserves a full official action! Give us more pseudo-official actions. Work with the biggest third-party actions15 to form a community-actions (or whatever) org, with the expectation that actions homed under that org have been reviewed (at some point) by GitHub, are forced to adhere to best practices for repository security, receive semantically versioned updates, &c &c. Wrap-up This is a long and meandering post, and many parts are in conflict: security and stability (in the form of more official actions that break less often), for example, are in eternal conflict with each other. I’m just one user, and I don’t expect my interests or frustrations to be overriding ones. Still, I hope that the problems (and potential fixes) above aren’t unique to me, and that there are engineers at GitHub who (again, selfishly!) share these concerns and would like to see them fixed. In a large part because, at GitHub’s size, I worry much less about private equity enshittifying it. ↩ Just enough for it to really hurt, against the backdrop of GitHub Actions’ overall productivity benefits. ↩ In the sense that these things would be in GitHub’s own self-interest, making GHA even more appealing to developers, further cement its dominance in the CI/CD space, &c. They should do these things for their own sake! ↩ After finishing this post, I discovered that GitHub has a public roadmap for Actions features. Maybe some of my grievances are already known and listed here; it’s a big roadmap! ↩ Completely unrelated to this post: writing ${{ ... }} is remarkably painful in a Liquid-rendered Jekyll blog. ↩ Yes, I know this fundamentally breaks the GitHub Actions data model; I didn’t say it would be easy! ↩ In the sense that “using pull_request_target safely” means being confident that you never accidentally run anything from the pull request that just triggered your workflow. ↩ And I think haven’t been done to me. ↩ Which I stole the actions/checkout example from, since I was too lazy to make my own. ↩ Even better, make it the default, and require people to click through a “destructive action” modal similar to the ones for other dangerous user or repository setting changes. ↩ JSON is a semi-obvious choice here, since GitHub Actions already has a fromJSON(...) function and maps cleanly from YAML. ↩ The primary stated reason is time, leading to the revelation that these critical actions were side projects. That isn’t these engineers’ fault; they seem to have been making the best out of a bad situation! But it’s incredible to see GitHub, organizationally, squander so much value and community goodwill here. ↩ In my opinion. It seems to have the most users and most activity, although it’s bonkers that I’m evaluating something as critical as this based on those kind of weak proxy signals. ↩ Except for the pentesting industrial complex. ↩ Off the top of my head: actions like ruby/setup-ruby, shivammathur/setup-php, and peaceiris/actions-gh-pages (among others) have hundreds of thousands of active users, and form a critical part of the Actions ecosystem. They should be treated as such! ↩ Previously",
    "commentLink": "https://news.ycombinator.com/item?id=37612420",
    "commentBody": "GitHub Actions could be so much betterHacker NewspastloginGitHub Actions could be so much better (yossarian.net) 382 points by woodruffw 20 hours ago| hidepastfavorite207 comments MoreQARespect 19 hours agoThere are two types of github actions workflows you can build.1) Program with github actions. Google \"how can I send an email with github actions?\" and then plug in some marketplace tool to do it. Your workflows grow to 500-1000 lines and start having all sorts of nonsense like conditionals and the YAML becomes disgusting and hard to understand. Github actions becomes a nightmare and you&#x27;ve invited vendor lock in.2) Configure with github actions. Always ask yourself \"can I push this YAML complexity into a script?\" and do it if you can. Send an email? Yes, that can go in a script. Your workflow ends up being about 50-60 lines as a result and very rarely needs to be changed once you&#x27;ve set up. Github actions is suddenly fine and you rarely have to do that stupid push-debug-commit loop because you can debug the script locally.Every time I join a new team I tell them that 1 is the way to madness and 2 is the sensible approach and they always tepidly agree with me and yet about half of the time they still do 1.The thing is, the lack of debugging tools provided by Microsoft is also really not much of a problem if you do 2, vendor lock in is lower if you do 2, debugging is easier if you do 2 but still nobody does 2. reply woodruffw 18 hours agoparentThis is a great perspective, and one I agree with -- many of the woes associated with GitHub Actions can be eliminated by treating it just as a task substrate, and not trying to program in YAML.At the same time, I&#x27;ve found that it often isn&#x27;t sufficient to push everything into a proper programming language: I do sometimes (even frequently) need to use vendor-specific functionality in GHA, mark dependencies between jobs, invoke REST APIs that are already well abstracted as actions, etc. Re-implementing those things in a programming language of my choice is possible, but doesn&#x27;t break the vendor dependency and is (IME) still brittle.Essentially: the vendor lock-in value proposition for GHA is very, very strong. Convincing people that they should take option (2) means making a stronger value proposition, which is pretty hard! reply MoreQARespect 18 hours agorootparentNo, you&#x27;re right it&#x27;s not necessarily a good idea to be anal about this rule. E.g. If an action is simple to use and already built I use it - I won&#x27;t necessarily try to reimplement e.g. upload artifacts step in code.Another thing I noticed is that if you do 1 sophisticated features like build caching and parallelization often becomes completely impractical whereas if you default to 2 you can probably do it with only a moderate amount of commit-push-debug. reply flohofwoe 2 hours agorootparentprevI use yaml and gh actions to prepare the environment, define jobs and their dependencies and for git operations, everything else goes into scripts. reply MenhirMike 18 hours agoparentprevOption 2 also makes it easier for developers to run their builds locally, so you&#x27;re essentially using the same build chain for local debugging than you do for your Test&#x2F;Staging&#x2F;Prod environments, instead of maintaining two different build processes.It&#x27;s not just true for GHA, but for any build server really: The build server should be a script runner that adds history, artifact management, and permissions&#x2F;auditing, but should delegate the actual build process to the repository it&#x27;s building. reply hk1337 15 hours agorootparentLocally or if for some reason you need to move off of Github and have to use Jenkins or some other CI tool. reply dmtryshmtv 17 hours agoparentprevGood perspective. Unfortunately (1) is unavoidable when you&#x27;re trying to automate GH itself (role assignments, tagging, etc.). But at this point, I would rather handle a lot of that manually than deal with GHA&#x27;s awful debug loop.FWIW, there&#x27;s nektos&#x2F;act[^1], which aims to duplicate GHA behavior locally, but I haven&#x27;t tried it yet.[^1]: https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply dlisboa 17 hours agorootparent> Unfortunately (1) is unavoidable when you&#x27;re trying to automate GH itself (role assignments, tagging, etc.)Can&#x27;t you just use the Github API for that? The script would be triggered by the YAML, but all logic is inside the script.But `act` is cool, I&#x27;ve used it for local debugging. Thing is its output is impossibly verbose, and they don&#x27;t aim to support everything an action does (which is fine if you stick to (2)). reply plorkyeran 16 hours agorootparentYeah, I&#x27;ve done quite a bit of Github scripting via octokit and it&#x27;s pretty simple. Using GHA&#x27;s built-in functionality might turn a five line script into a one-liner, but I think being able to run the script directly is well worth the tradeoff.The main thing that you can&#x27;t decouple from GHA is pushing and pulling intermediate artifacts, which for some build pipelines is going to be a pretty big chunk of the logic. reply toolslive 2 hours agoparentprev> still nobody does 2.They don&#x27;t seem to grasp how bad their setup is, and consequently are willing to understand awful programming conditions. Even punch cards were better as these people had the advantage of working with a real programming language with defined behaviour. \"when exactly is this string interpolation step executed? in the anchor or when referenced? (well, it depends)\". No it&#x27;s black box tinkering (you might as well be prompt engineering)the C in IaC is supposed to stand for code. Well, if you&#x27;re supposed to code something you need to - be able to assert correctness before you commit, - be able to step through the codeIf the setup they give you doesn&#x27;t even have these minimal requirements you&#x27;re going to be in trouble regardless of how brilliant an engineer you are.(sorry for the rant) reply EddTheSDET 16 hours agoparentprevHow DO you debug your actions? I spend so long in the commit-action-debug-change loop it’s absurd. I agree with your point re: 2 wholeheartedly though, it makes debugging scripts so much easier too. CI should be runnable locally and GitHub actions, while supported with some tooling, still isn’t very easy to work with like that. reply MoreQARespect 14 hours agorootparentUsing the same commit-push-debug loop you do. It just isnt painful if I do 2. reply davidmurdoch 10 hours agorootparentprevMy GH Actions debugging usually devolves into `git commit -m \"wtfqwehsjsidbfjdi\"` reply no_wizard 9 hours agorootparentyou could always do git commit -m \"\" --allow-empty reply _nhynes 9 hours agorootparentnext [–]git commit --amend --no-edit && git push -f reply totetsu 5 hours agorootparentprevgit commit -m \"--allow-empty\" reply diarrhea 4 hours agorootparentprevYou can even allow empty messages. reply all2 9 hours agorootparentprevThere are ways to run GHA locally. I&#x27;ve tried out one or two of the tools. [0]- [0] https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply EddTheSDET 5 hours agorootparentI tried Act at one point but couldn&#x27;t get it to run the whole pipeline correctly, it might have improved since though so I&#x27;ll try it out again soon reply somehnguy 15 hours agorootparentprevAct works pretty well to debug actions locally. It isn&#x27;t perfect, but I find it handles about 90% of the write-test-repeat loop and therefore saves my teammates from dozens of tiny test PRs. reply EddTheSDET 5 hours agorootparent> saves my teammates from dozens of tiny test PRsMay have misread this but you know you can push to one branch and then run the action against it? Would reduce PRs if you&#x27;re doing that to then check the action in master. You have to add a workflow_dispatch to the action: https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;actions&#x2F;using-workflows&#x2F;manually-... reply mook 4 hours agorootparentAnd if you&#x27;re working on workflows that need to be in PRs, you can make a PR from your fork _to_ your fork. reply edgyquant 16 hours agorootparentprevI too wish I could find a nicer way than this to debug. reply flohofwoe 2 hours agoparentprevThat&#x27;s true for all CI services, do as little as possible in yaml, mostly just use it to start your own scripts, for the scripts use something like python or deno to cover Linux, Mac and Windows environments with the same code. reply jahnu 17 hours agoparentprevThe main reason I aim for (2) is that I want to be able to drive my build locally if and when GitHub is down, and I want to be able to migrate away easily if I ever need to.I think of it like this:I write scripts (as portable as possible) to be able to build&#x2F;test&#x2F;sign&#x2F;deploy&#x2F;etc They should work locally always.GitHub is for automating me setting up the environments where I can run those scripts and then actually running them. reply konschubert 3 hours agoparentprevWhen GitHub actions came out, I felt bad about myself because I had no desire to learn their new programming language of breaking everything down into multiple small GitHub actions.I think you explained quite well what I couldn&#x27;t put my finger on last time: Building every simple workflow out of a pile of 3rd party apps creates a lot of unnecessary complexity.Since then, I have used GitHub actions for a few projects, but mostly stayed away from re-using and combining actions (except for the obvious use cases of \"check out this branch\"). reply flohofwoe 2 hours agorootparentGithub Actions basically only became usable once they started copying features from Gitlab CI. Before that it was an incomprehensible mess.Compared to Gitlab CI, GH Actions still feels like a toy unfortuantely. reply rayhu007 16 hours agoparentprevTotally get what you&#x27;re saying. I once switched our workflow to trigger on PRs to make testing easier. Now, I&#x27;m all about using scripts — they&#x27;re just simpler to test and fix.I recommend making these scripts cross-platform for flexibility. Use matrix: and env: to handle it. Go for Perl, JavaScript, or Python over OS shells and put file tasks in scripts to dodge path issues.I&#x27;ve tried boxing these scripts into steps, but unless they&#x27;re super generic for everyone, it doesn&#x27;t seem worth it. reply pplonski86 4 hours agoparentprevYAML is perfect for simple scenarios. But users produces with it really complex use cases.Is it possible to write Python package that based on YAML specification produces Python API? User will code in Python and YAML will be the output.I was working on YAML syntax for creating UI. I converted it to Python API and Im happy. For exmple, dynamic widgets in YAML were hard, in Python they are strightforward. reply kelnos 9 hours agoparentprevI try to do (2), but I still run into annoyances. Like I&#x27;ll write a script to do some part of my release process. But then I start a new project, and realize I need that script, so I copy it into the new repo. Then I fix a bug in that script, or ad some new functionality, and I need to go and update the script in the other repo too.Maybe this means I should encapsulate this into an action, and check it in somewhere else. But I don&#x27;t really feel like that; an action is a lot of overhead for a 20-line bash script. Not to mention that erases the lack of lock-in that the script alone gives me.I guess I could check the script into a separate utility repo, and pull it into my other repos via git submodules? That&#x27;s probably the least-bad solution. I&#x27;d still have to update the submodule refs when I make changes, but that&#x27;s better than copy-pasting the scripts everywhere. reply riquito 17 hours agoparentprevI agree overall, but you oversimplify the issue a bit.> can I push this YAML complexity into a script?- what language is the script written in?- will developers use the same language for all those scripts?- does it need dependencies?- where are we going to host scripts used by multiple github actions?- if we ended up putting those scripts in repositories, how do we update the actions once we release new version of the scripts?- how do you track those versions?- how much does it cost to write a separate script and maintain it versus locking us in with an external github action?These are just the first questions that pop in my mind, but there is more. And some answers may not be that difficult, yet is still something to think about.And I agree with the core idea (move logic outside pipeline configuration), but I can understand the tepid reaction you may get. Is not free and you compromise on some things reply tomtheelder 16 hours agorootparentI think they framed it accurately and you are instead over complicating. Language for scripts is a decision that virtually every team ends up making regardless. The other questions are basically all irrelevant since the scripts and actions are both stored in repo, and therefore released together and versioned together.I think the point about maintenance cost is valid, but the thesis of the comment that you are responding to is that the prebuilt actions are a complexity trap. reply plorkyeran 16 hours agorootparentprevI think you are still envisioning a fundamentally incorrect approach. Build scripts for a project are part of that project, not some external thing. The scripts are stored in the repository, and pulled from the branch being built. Dependencies for your build scripts aren&#x27;t any different from any other build-time dependencies for your project. reply c-hendricks 17 hours agorootparentprevThis is a whole lot of overthinking for something like #!&#x2F;usr&#x2F;bin&#x2F;env bash set -ex aws send-email ... reply umvi 17 hours agorootparentprevDefault to bash. If the task is too complex for bash, then use python or node. Most of these scripts aren&#x27;t going to change very often once stable. reply wry_discontent 14 hours agorootparentDefault to babashka. reply peteradio 15 hours agorootparentprevIf build scripts or configuration is shared it might be one of the only times a git submodule is actually useful. reply pjc50 18 hours agoparentprevI&#x27;ve reached the same conclusion with Jenkins. It also helps if you ever have to port between CI systems.A CI \"special\" language is almost by definition something that can&#x27;t be run locally, which is really inconvenient for debugging. reply progmetaldev 12 hours agoparentprevYour advice is sane and I can tell speaks from experience. Unfortunately, now that Github Actions are being exposed through Visual Studio, I fear that we are going to see an explosion of number 1, just because the process is going to be more disconnected from Github itself (no documentation or Github UI visible while working within Visual Studio). reply lambda_garden 17 hours agoparentprevOption 1 is required if you want to have steps on different runners, add approval processes, etc.I always opt for option 2 where possible though. reply wbond 17 hours agoparentprevI have a few open source projects that have lasted for 10+ years, and I can’t agree more with approach #2.Ideally you want your scripting to handle of the weird gotchas of different versions of host OSes, etc. Granted my work is cross-platform so it is compounded.So far I’ve found relying on extensive custom tooling has allowed me to handle transitions from local, to Travis, to AppVeyor, to CircleCI and now also GitHub Actions.You really want your CI config to specify the host platform and possibly set some env vars. Then it should invoke a single CI wrapper script. Ideally this can also be run locally. reply MuffinFlavored 9 hours agoparentprev> our workflow ends up being about 50-60 lines as a result and very rarely needs to be changed once you&#x27;ve set up.As in, use GitHub Actions as a YAML wrapper around bash&#x2F;zsh&#x2F;sh scripts? reply flohofwoe 42 minutes agorootparentIt can be any scripting language, Python or Typescript via Deno are good choices because they have batteries-included cross-platform standard libs and are trivial to setup.Python is actually preinstalled on Github CI runners. reply jjice 16 hours agoparentprevAbsolutely agreed. Well said and I&#x27;ll be stealing this explanation going forward. Hell, just local running with simplicity and ability to test is a massive win of #2, aside from just not dealing with complex YAML. reply hk1337 15 hours agoparentprev1 is to build utilities for 2, IMO. It shouldn&#x27;t have repository specific information inside and should be easily useable in other workflows. reply chubot 14 hours agoparentprevExactly, I showed here how we just write plain shell scripts. It gives you \"PHP-like productivity\", iterating 50 times a minute. Not one iteration every 5 minutes or 50 minutes.https:&#x2F;&#x2F;lobste.rs&#x2F;s&#x2F;veoan6&#x2F;github_actions_could_be_so_much_b...Also, seamlessly interleaving shell and declarative JSON-like data -- without YAML -- is a main point of http:&#x2F;&#x2F;www.oilshell.org, and HayHay Ain&#x27;t YAML - https:&#x2F;&#x2F;www.oilshell.org&#x2F;release&#x2F;0.18.0&#x2F;doc&#x2F;hay.html reply xeromal 16 hours agoparentprevGithub actions calling make commands is my bread and butter. reply intelVISA 17 hours agoparentprevTurns out the real SaaS is Scripts as a Service. reply withinboredom 11 hours agoparentprevI appreciate this perspective, however, after spending 6mo on a project that went (2) all the way, never again. CI&#x2F;CD SHOULD NOT be using the same scripts you build with locally. Now, we have a commit that every dev must apply to the makefile to build locally, and if you accidentally push it, CI&#x2F;CD will blow up (requiring an interactive rebase before every push). However, you can’t build locally without that commit.I won’t go into the details on why it’s this way (build chain madness). It’s stupid and necessary. reply Tainnor 11 hours agorootparentThis comment is hard to address without understanding the details of your project, but I will at least say that it doesn&#x27;t mirror my experience.Generally, I would use the same tools (e.g. .&#x2F;gradlew build or docker build) to build stuff locally as on CI, and config params are typically enough to distinguish what needs to be different.My CI scripts still tend up to be more complicated than I&#x27;d like to (due to things like caching, artifacts, code insights, triggers, etc.), but the main build logic at least is extracted. reply SAI_Peregrinus 6 hours agorootparentAgreed. I want my builds reproducible. The CI binaries should be bit-for-bit identical to the locally-built ones. reply tao_at_garden 19 hours agoprevThe git commit, push, wait loop is terrible UX. Users deserve portable pipelines that run anywhere, including their local machines. I understand Act [1] goes some way to solving this headache but it&#x27;s by and large not a true representation.There are many pipelines you can&#x27;t run locally, because they&#x27;re production, for example, but there&#x27;s no reason why we can&#x27;t capture these workflows to run them locally at less-critical stages of development. Garden offers portable pipelines and then adds caching across your entire web of dependencies. Some of our customers see 80% or higher reductions in run times plus devs get that immediate feedback on what tests are failing or passing without pushing to git first using our Garden Workflows.We&#x27;re OSS. [2][1] https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act[2] https:&#x2F;&#x2F;docs.garden.io reply candiddevmike 18 hours agoparentIf folks just had actions target make or bash scripts instead of turning actions into bash scripts none of this would be an issue. Your CI&#x2F;CD and your devs should all use the same targets&#x2F;commands like `make release`. reply taeric 18 hours agorootparentI&#x27;m actually confused and scared on how often this isn&#x27;t the case? What are people doing in their actions that isn&#x27;t easily doable locally? reply ghayes 18 hours agorootparentA huge portion of my actions are for things like caching or publishing artifacts, which are unique to actions itself. reply taeric 18 hours agorootparentI&#x27;d assume you would be able to publish and deploy locally before setting up actions. Such that those are likely targets in your build system?Caching, I can mostly understand as unique there. Though, I think I&#x27;m living with whatever the default stuff in actions is. Slow for builds that don&#x27;t happen often, of course, but not so slow that I care. reply Tainnor 11 hours agorootparentUnfortunately, my team has some builds that take ~25 min without caching and maybe 2 min with caching.I&#x27;m still not entirely sure why it&#x27;s the case, but the connection to the package registry is incredibly slow, so downloading all dependencies takes forever. reply taeric 10 hours agorootparentI&#x27;m fortunate that worrying about 25 minute builds just doesn&#x27;t matter. The long pole on all builds is still the code review that goes with it, such that I just don&#x27;t care about getting that time too low here.That is, I am assuming that a CI build is not on the immediate dev loop, such that the person pushing it doesn&#x27;t have to wait for the build before they prepare a review on it. reply duped 16 hours agorootparentprevWhy should caching in the cloud be any different than caching locally? reply baq 16 hours agorootparentThere isn’t any locally in GHA after the runner exits reply baq 18 hours agorootparentprevIt&#x27;s the cloud. Runners are ephemeral (pretend, but still) with no persistent storage. This makes you either rebuild everything in every release stage (bad) or put artifacts in s3 or whatever (also bad) - this is especially painful for intermediate artifacts like dependency bundle caches etc.As much as I like make it just doesn&#x27;t work with the typical cloud stateless by default configs. If it works for you, your project is small enough and try to keep it this way. reply taeric 18 hours agorootparentRebuilding at every stage shouldn&#x27;t be too bad, with pinned dependencies. I can see problems with it, of course. That said, using a private code publishing location seems the correct path? That isn&#x27;t too difficult to setup, is it?That said, I&#x27;m still not clear on what difficulties folks are worried about. I&#x27;m also not clear I care on the mess of commits getting things working. The initial commits of getting anything working are almost always a mess. Such that worrying about that seems excessive. reply ZeWaka 18 hours agorootparentprev> with no persistent storageThere&#x27;s https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;cache though? reply dcow 17 hours agorootparentThey&#x27;re saying that unless you use actions, you don&#x27;t get the cohesive cache and artifacts support. That replicating that in the cloud or locally is a PITA. Thus people are using the GH actions vendor specific tooling in that way. reply plonk 15 hours agorootparentprevJust run the GitHub cache action on your build directory and then run make inside it? reply ramraj07 18 hours agorootparentprevAll the linting checks and end to end tests I don’t want to bother setting up locally for every repo I touch. reply taeric 18 hours agorootparentAren&#x27;t these just other targets in whatever build system you are using, though? reply thiht 3 hours agorootparentprevWell… yeah?My GitHub actions workflow consist of calls to make lint, make test, make build, etc. Everything is useable in local.There’s just some specificities when it comes to boot the dependencies (I use a compose file in local and GitHub action services in CI, I have caching in CI, etc.) but all the flows use make.This is not a technical problem, you’re just doing it wrong if you don’t have a Makefile or equivalent. reply globular-toast 2 hours agorootparentprevThis is how it should be done. It was trivial to port my company&#x27;s CI from Jenkins to Gitlab because we did this.Confusion arises when developers don&#x27;t realise they are using something in their local environment, though. It could be some build output that is gitignored, or some system interpreter like Python (especially needing a particular version of Python).Luckily with something like Gitlab CI it&#x27;s easi to run stuff locally in the same container as it will be run in CI. reply andrewstuart2 19 hours agoparentprevYeah, it seems like we lost a lot of the \"CI shouldn&#x27;t be a snowflake\" when we started creating teams that specialize in \"DevOps\" and \"DevOps tools.\" Once something becomes a career, I think you&#x27;ve hit the turning point of \"this thing is going to become too complicated.\" I see the same thing with capital-A Agile and all the career scrum masters needing something to do with their time. reply baggachipz 19 hours agoparentprevAct&#x27;s incompleteness has had me barking up the wrong tree many times. At this point I&#x27;ve temporarily abandoned using it in favor of the old cycle. I&#x27;m hoping it gets better in time! reply frodowtf 14 hours agorootparentI don&#x27;t get why GitHub doesn&#x27;t adopt it and make it a standard. Especially the lack of caches is annoying. reply sakopov 12 hours agoparentprevWe need Terraform for build pipelines and God help you if you use Bitbucket lol reply joshstrange 18 hours agoprevI couldn&#x27;t agree more with the pain of debugging a GH Actions run. The &#x2F;only&#x2F; tool you have is the ability to re-run with debug on. That&#x27;s it. I have so many \"trash\" commits trying to fix or debug a pipeline and so much of it&#x27;s just throwing stuff at the wall to see if it sticks.Very basic things, like having reusable logic, is needlessly complex or poorly documented. Once I figured out how to do it it was fairly easy but GitHub&#x27;s docs were terrible for this. They made it seem like I had to publish an action to get any reusability or put it in a different repo. Turns out you can create new yaml files with reusable logic but make sure you put them in the root of the workflows folder or they won&#x27;t work, go figure.It&#x27;s just incredibly painful to work on GH Actions but once you have them working they are such a joy. I really wish there was some kind of local runner or way to test your actions before committing and pushing. reply giobox 18 hours agoparent> I have so many \"trash\" commits trying to fix or debug a pipeline and so much of it&#x27;s just throwing stuff at the wall to see if it sticks.One tool is to use draft PRs for this - you can run changes to your action YAML from the draft PR. When you are happy just squash the commits as you see fit on a \"real\" PR to merge the changes in without the mess.I&#x27;ve found draft PRs for debugging&#x2F;developing GH action logic to be pretty reasonable. reply lambda_garden 17 hours agorootparentSince some action depend on the branch &#x2F; tag you are on this is not always possible. reply secret-noun 15 hours agorootparentIndeed. I have sometimes made release workflows, hardcoded to the main branch.You don&#x27;t want to experiment too much on main because it dirties your commit history with 20 \"Fix typo\"-esque commits.Or, if you try to emulate the main branch with a fake main branch (so you can squash it later), you&#x27;re still going to have some test commits when do the find-replace back to main.Neither are great. reply mook 3 hours agorootparentSometimes forking and using the main branch on the fork (or tags and releases) can help. And if you&#x27;re on a team, nobody else needs to be aware of the noise that is you throwing trivial changes at the wall.It gets painful if there are things you&#x27;ve only got on the main repo (e.g. custom runners, credentials, etc.) though. reply hahn-kev 17 hours agoparentprevCheck this out. It doesn&#x27;t do everything but it&#x27;s decent https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply andix 18 hours agoparentprevIf I&#x27;m fixing CI I always put it on a feature branch and do a squash merge once I&#x27;m done. Because it&#x27;s never just one quick fix, it&#x27;s always 3-10 commits. reply kitallis 16 hours agorootparent> If I&#x27;m fixing CI I always put it on a feature branch and do a squash merge once I&#x27;m done. Because it&#x27;s never just one quick fix, it&#x27;s always 3-10 commits.The problem is GA also does not allow you to commit a new workflow in a branch. It must first exist on your primary branch and then you may tweak it in another. reply vladaionescu 16 hours agoparentprevThis is the main reason we built Earthly: run your builds locally, and get consistency with the CI. reply pid-1 17 hours agoparentprevIf only competitors could do better...https:&#x2F;&#x2F;gitlab.com&#x2F;gitlab-org&#x2F;gitlab-runner&#x2F;-&#x2F;issues&#x2F;2797 reply hv42 13 hours agorootparentyeah... https:&#x2F;&#x2F;github.com&#x2F;firecow&#x2F;gitlab-ci-local is a good workaround but should be built-in. How do developers at GitLab&#x2F;Github debug their workflows? reply TeeMassive 18 hours agoparentprevI&#x27;ve tried running the GitHub runner image (or maybe an imitation) and it was really painful to setup and to get some things working. I just let it go after 2 days.And it&#x27;s not just Github. The others big CI platform are not really better in terms of workflow and integration.Now I just script everything to the maximum. reply solatic 14 hours agoprevGitHub Actions is a horrible CI&#x2F;CD system. You cannot run steps in parallel on the same VM; container-based workloads are a second-class citizen. The first problem means that setting up local credentials and other environment dependencies cannot be parallelized (I&#x27;m looking at you, google-github-actions&#x2F;setup-gcloud, with your 1m+ runtime... grrr), the second makes it quite difficult to put a Dockerfile in a repository to represent setup of the CI environment, and have both (a) the CI rebuild the container images when the image would change, pausing workflows depending on that image until the image is rebuilt, (b) not attempting to rebuild the image when its contents did not change, and immediately running workflows inside that image, including all dependencies already installed.No, in GitHub Actions, you will attempt to repopulate from cache on every single run. Of course, sometimes the cache isn&#x27;t found, particularly because there&#x27;s a 5 GB cache size limit (which cannot be enlarged, not even for payment) which cycles out FIFO. So if you go over the 5 GB cache, you might as well not have one.I deeply miss Concourse. Too bad Pivotal dismantled the team and it barely gets even maintenance work. Parallel tasks. Custom pipeline triggers. SSH into the CI environment to debug. Run one-off tasks in CI without needing to set up a pipeline. Transfer directory contents from one job to another without needing to create artifacts (which cost money to store if you&#x27;re not careful about how long they should stick around for).GitHub Actions is a bastardized toy CI&#x2F;CD system that only got popular because GitHub make it as simple as uploading a file to .github&#x2F;workflows in any repository - no additional signup, no in-house ops required, everything you could want is just there. So let&#x27;s be very clear about what GitHub Actions is good and what it&#x27;s bad at - it&#x27;s good at getting people to sign up, but it&#x27;s not nearly powerful enough to be the \"best\" system once you start to outgrow the early features. reply couchand 12 hours agoparent> Of course, sometimes the cache isn&#x27;t found, particularly because there&#x27;s a 5 GB cache size limit (which cannot be enlarged, not even for payment) which cycles out FIFO. So if you go over the 5 GB cache, you might as well not have one.Looks like I can move on that \"build caching mysteriously broken\" issue now. Thanks for the heads up! reply Huggernaut 5 hours agoparentprevLess Pivotal and more VMWare post acquisition dismantling I&#x27;d say. There was a lot of love internally for Concourse (I left before the acquisition though).SSH debugging and one off tasks absolutely dreamy. reply toastal 2 hours agorootparentEven SourceHut’s Spartan CI supports SSH debugging reply speed_spread 5 hours agoparentprevConcourse rocks. I didn&#x27;t know the team had been dismantled, this sucks. Zito&#x27;s communication style was the best. reply Huggernaut 5 hours agorootparentVito is at dagger.io now so hopefully we can expect some good stuff in the CI space there. reply solatic 1 hour agorootparentSadly, Dagger doesn&#x27;t get it either. It&#x27;s so focused on portability between the underlying infrastructure providers, on not being the underlying infrastructure provider, and therefore it doesn&#x27;t solve the real problem, which is the underlying infrastructure provider.(a) Consider Dagger&#x27;s integration with GitHub Actions: https:&#x2F;&#x2F;docs.dagger.io&#x2F;cookbook#github-actions where you anyway need to run setup-node, npm ci, etc. just to start the Dagger pipeline. So Dagger isn&#x27;t saving you from the having to deal with GitHub Actions&#x27; caching layer and always-blank starting point - it&#x27;s unavoidable. Well, if I can&#x27;t avoid it, why should I use Dagger in the first place - why not embrace it?(b) Consider a usecase where I want to parallelize the computation onto a number of machines dynamically chosen at run-time. Maybe I want to allow a test suite to run on an increasing number of machines without needing to periodically manually increase the number of machines in a configuration file, or maybe I&#x27;m using Terraform workspaces where I want to run terraform apply for each workspace on a different VM to let the number of workspaces scale horizontally. This is fundamentally impossible with something like Dagger (also impossible in GitHub Actions) because it would require Dagger to communicate with the infrastructure provider to tell it to scale up compute to handle the parallel jobs, and then scale down once those jobs finish.This was achievable with Concourse by having Concourse pipelines generate other Concourse pipelines, and running the underlying Concourse workers as an autoscaling Kubernetes statefulset&#x2F;deployment, combined with other Kubernetes implements like cluster autoscaler. reply txtsd 6 hours agoparentprevTry the sourcehut build server reply solatic 1 hour agorootparentIt&#x27;s a public alpha and clearly targeted for small hobbyists &#x2F; FOSS work as a result. I&#x27;m looking for something where the creator has more confidence in its reliability... reply pxeger1 16 hours agoprevI would like to give a strong recommendation for https:&#x2F;&#x2F;pre-commit.ci (no relation, just a happy user).The idea is that you write hooks (or use pre-existing ones) that check (and fix, where possible) your code before you commit, and then once you&#x27;ve pushed, the CI will check again, including automatically committing fixes if necessary.Anyway, it works brilliantly - unbelievably fast thanks to good automatic caching, and using the exact same setup on your local development machine to in CI negates a lot of these debugging problems. It&#x27;s free for open source.It only does checks, not things like automatic releases, but it does those them well. reply globular-toast 1 hour agoparentThis combined with tox is great for Python projects in particular. Tox automates creating virtualenvs for the right Python versions you want to test with then running your tests in them. It can also run static checks by issuing `skip_install = True` because you want to test the source code itself. You just need to run this in a Python container that has tox installed as a globally available tool and all versions of Python available in it (like https:&#x2F;&#x2F;github.com&#x2F;georgek&#x2F;docker-python-multiversionBecause GitHub fails to distinguish between fork and non-fork SHA references, forks can bypass security settings on GitHub Actions that would otherwise restrict actions to only “trusted” sources (such as GitHub themselves or the repository’s own organization).How is this not resolved?Easily bypassing security controls is a major security issue.Yes, you need to convince someone to use your SHA, but social engineering is usually the easy part. reply kaikoenig 17 hours agoprevBeen through that git commit; git push; repeat cycle too much as well until i discovered https:&#x2F;&#x2F;github.com&#x2F;mxschmitt&#x2F;action-tmate which gives a shell in between steps, which does not help with all problems but sure it&#x27;s makes it less painful at times. reply justinclift 17 hours agoparentThanks, that looks super useful. :) reply giobox 18 hours agoprevMy personal wish is for the ability to attach HTML reports the the action runs without having to use the current actions&#x2F;upload-artifact etc.Particularly for test builds, I very often just want to quickly view the output HTML report. The current approaches I am familiar with are the aforementioned upload-artifact, or using GH pages, but GH pages is not great when you have multiple different reporting output for the same repo, or you wanna quickly view historical reporting rather than latest.I&#x27;d love a simple \"attach-report\" action that just put a link to an HTML report on the job summary, and clicking on it renders the html.Other automated CI&#x2F;CD style systems have much richer support out of the box for dealing with HTML report capturing and viewing. reply dmart 17 hours agoparentGranted, it&#x27;s not HTML, but you can append Markdown output directly to $GITHUB_STEP_SUMMARY without dealing with artifact uploads etc. reply giobox 17 hours agorootparentThanks, I&#x27;m aware of this option too, but if you say have an HTML report with the results of 200 tests, no one has time to write some logic to parse the results to a markdown summary frankly. Just give me the link!Similar too if the reporting captures video&#x2F;screenshots of a given bug - the original report UI is far easier to deal with. Many test frameworks already natively put out an HTML report UI etc, it&#x27;s just harder to get to than it should be with GH actions today. reply pests 14 hours agorootparent> an HTML report with the results of 200 tests, no one has time to write some logic to parse the results to a markdown summary frankly.Not sure how GHA treats it, but markdown is a subset of HTML so by default all HTML pages are valid Markdown documents. No conversion required. reply Aeolun 10 hours agorootparentThey just don’t show half of the stuff inside correctly. replyNezteb 16 hours agoprevThis is why I want projects like Earthly to succeed: https:&#x2F;&#x2F;github.com&#x2F;earthly&#x2F;earthlyI want to be able to run my all of CI workflows on my local machine.I agree with other commenters that most of what CI does should be abstracted out into scripts or other non-CI tools. Unfortunately it&#x27;s not easy to do that for large pre-existing CI setups, especially if a different team is the one maintaining your CI workflows. reply dboreham 2 hours agoprevI think most developers don&#x27;t need to or don&#x27;t have the time to dive deeply into their build systems, but having had to do so as part of a project to migrate to Gitea (which turned into a larger project to enhance&#x2F;fix its act-based github actions clone), my take is:1. Github actions embodies the wrong abstractions. I&#x27;m not 100% sure what the right ones would be but it feels all wrong.2. It has the feel of an unfinished&#x2F;undocumented project. Someone&#x27;s project to get a promotion perhaps that they handed off to interns after securing said promotion. A product that forces me to expend brain cycles reverse engineering it&#x27;s behavior just makes me want to design it out of my life. I may as well develop my own thing : at least I&#x27;ll understand that.3. A build system that can only be run in a proprietary SaaS environment is a terrible idea. I mean, great idea for locking in customers I suppose. reply rurp 18 hours agoprevIt&#x27;s hard for me to articulate exactly why but I really dislike the information layout in GH Actions. Compared to other CI&#x2F;CD tools, it&#x27;s harder to debug problems or get a sense of the state of a pipeline. Part of the problem is the number of clicks it takes to look at various step logs. Some of the controls are unintuitive, but maybe that&#x27;s just me. reply whalesalad 18 hours agoparentThis could be said for a lot of GitHub. The fact that you need to open a disclosure menu to edit a PR is wild. reply mock-possum 18 hours agorootparentTheir comment system just doesn’t feel right compared to Bitbucket’s either - I think it’s the distinction between comments that are part of a review, versus comments that are ‘just’ comments reply simse 19 hours agoprevA linter can catch some obvious errors: https:&#x2F;&#x2F;github.com&#x2F;rhysd&#x2F;actionlint. But yes, I agree, it&#x27;s not a fun debugging experience. reply woodruffw 18 hours agoparentYep, actionlint is great! I&#x27;ve used it successfully both to lint my own workflows, and to lint third-party workflows for (basic) security issues.Unfortunately, it can&#x27;t lint actions themselves, only workflows that call actions[1]. This is a substantial deficiency, especially for users (like me) who write and maintain a decent number of actions.[1]: https:&#x2F;&#x2F;github.com&#x2F;rhysd&#x2F;actionlint&#x2F;issues&#x2F;46 reply bastardoperator 18 hours agoparentprevact would also be helpful here in terms of debugging and development of Actions workflows.https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply ris 16 hours agoprevThe single thing that I most detest about GitHub Actions is how they, by design, completely miss the point of containers. Having \"actions\" that are just \"install language foo\" is barely better than just publishing shell scripts or even the days of Travis.As a result, few GitHub workflows benefit from the immutability or reproducibility guarantees that can be provided by containers, and most workflows I interact with spend more than half their time running ridiculous installer scripts. reply brabel 15 hours agoparentAre you unaware that GH Actions can run jobs in containers??https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;actions&#x2F;using-jobs&#x2F;running-jobs-i... reply icecap12 7 hours agoprev> And so, the question: why are there so few of them? Here is just a smattering of the official actions that don’t exist[...]This part of the article half triggered me and half made me laugh. I was recently on a GitHub webinar to listen to the pitch for CoPilot, but of course they also talked about Actions and GHAS. Anyway, during the overview of Actions, the presenters made a comment about how Actions was \"backed by the community.\" It felt to me like a glaring admission that the product isn&#x27;t mature. But in true Microsoft fashion, they charge you like it is. reply vladaionescu 16 hours agoprevFounder of Earthly here - besides the build debugging difficulty, I would add that modern CI&#x2F;CD repeats a lot of steps: downloading, installing and configuring dependencies, making things much slower than they should be.We built Earthly [1] to tackle these two problems specifically. We&#x27;re open-source (10k stars).[1]: https:&#x2F;&#x2F;earthly.dev reply krzema12 5 hours agoprevI created https:&#x2F;&#x2F;github.com&#x2F;typesafegithub&#x2F;github-workflows-kt and https:&#x2F;&#x2F;github.com&#x2F;typesafegithub&#x2F;github-actions-typing to address some of the mentioned issues. Some problems remain unsolved because it&#x27;s just a Kotlin DSL that generates the YAML, but it does catch some issues early. Related blog post: https:&#x2F;&#x2F;dev.to&#x2F;jmfayard&#x2F;github-actions-a-new-hope-in-yaml-wa... reply chrissoundz 17 hours agoprevStruggling with this today, and numerous other days. It&#x27;s so bad. Stop trying to build an operating system out of YAML. I&#x27;ll always use and recommend Gitlab from now on.And what the earth is an \"actions\" anyway? How on earth is simple bash functions not just as suitable here? Instead you have some weird YAML scripting language. It&#x27;s so bad. Why. Somebody please tell me. I&#x27;m losing my mind. It is a good reflection of the rest of the world though and why the worlds infrastructure is crumbling in many places. reply giobox 17 hours agoparentExecuting bash statements&#x2F;scripts&#x2F;functions is the thing I struggle least with in GH actions personally, it&#x27;s remarkably easy to execute shell steps. If you really want your entire build to be a shellscript the action executes, you can do just that with very little YAML. reply Aeolun 10 hours agorootparentExcept it doesn’t execute quite like in bash, and every single command is it’s own little island.So exporting an environment variable doesn’t work for example. reply he0001 18 hours agoprevWe recently converted from Jenkins to GitHub Actions (complete rewrite) build pipeline. Jenkins had its issues and warts, but holy Beelzebub what a monster GitHub Actions is. It pure downright evil and creates all sort of headaches. Opaque, zero clues on what broke. Glacial slow even if you throw the biggest instance at it. It’s all enterprise and 1000s of repositories big company.I’m spending more time finding bugs in the build pipeline than the time I spend doing other things. And it’s all GitHub actions fault. I hate it with a passion. reply andix 18 hours agoprevI&#x27;m really not sure if we are using CI correctly. Sometime i think all those CI Templates should be replaced by just one executable that does everything, like a modern alternative to Makefiles (and there are a lot of build tools).So the CI pipeline would only call the build tool, like \".&#x2F;build containers push-to-registry release:1.0.0 run-tests\"Those scripts can be tested and debugged everywhere. Also migrating to a different CI platform would be really easy. reply gravlaks 14 hours agoparenthttps:&#x2F;&#x2F;dagger.io&#x2F;may be an alternative. You can run it in GitHub actions somehow as well. reply pixl97 17 hours agoparentprevHow does that integrate in with every else&#x27;s tooling? At least in enterprise there are a ton of things like \"SCA, SBOM, Compliance report, etc\" that tie in with plugins and such.Also, why would a large commercial CI want to have their environment too open? reply andix 16 hours agorootparentThey don’t want to have their environments too open, that’s why we are at this point.Those enterprise tools i know (like sonarqube for example) are mostly cli tools in their core. Can be integrated everywhere. reply WirelessGigabit 17 hours agoparentprevWhile this is totally possible you lose a lot of the things that make GitHub Actions nice. Nice logs, annotations, individual steps that went wrong. Being able to see the status at a glance. Seeing 10 steps where 1 fails and 13 pass is nice. reply andix 16 hours agorootparentAll those things the custom build tool would need to handle. It needs more or less the same functionality as GitHub actions and the marketplace. It would also need to integrate with different CI platforms to some extent for reporting and user interactions. reply riv991 19 hours agoprevThe feature I&#x27;d love is history.I&#x27;d like to know if my builds are getting slower over time. I&#x27;d be able to detect flaky tests automatically.It seems basic, but I know third-party solutions exist for this. It&#x27;s out of the box in Circle CI and Buildkite and feels like it should be here. reply atomicfiredoll 16 hours agoparentI was with a team that moved from Jenkins to Actions. Jenkins has a lot of issues, but if you knew what you were doing, at least it was easy to see the history and at a glance know the project pipelines were green&#x2F;healthy. It was super useful for seeing where flake was in tests or observing changes to coverage over time.After the team migrating to actions swept though, we ran without this basic stuff for years because nobody had the time to figure out what 3rd party tool to use, money to pay for it, or capacity to re-implement the functionality. It made dealing with test failures or flake that crept in awful. reply remram 13 hours agoprevCan I trigger a workflow from a different workflow yet? That seems very basic, and last time I looked I had to create a token that gives read&#x2F;write access to every repo in every organization to do this. And then it didn&#x27;t work because the docs for the trigger API is apparently wrong. reply Aeolun 10 hours agoparentAs long as they’re in the same repository, yeah. reply remram 9 hours agorootparentDifferent repo same org reply lijok 15 hours agoprevPeople really need to stop writing scripts in yaml. Not to be dismissive but the issues outlined in this article, aside from that security footgun, are non-issues as soon as you start using github actions only for what it should be used - to invoke your scripts in parallel in response to an event. We&#x27;ve banned all but actions&#x2F;checkout in our org and have a very healthy dev experience as a result. People are naturally guided towards writing scripts that they can run locally instead of for github actions specifically.Some real issues with github actions:1. MacOS runners have ridiculously inconsistent IO performance causing 200x slowdown in some cases2. Getting charged to the nearest minute is asinine and punishes highly parallelised (fast) workloads3. GitHub OIDC endpoints constantly timing out reply fijiaarone 7 hours agoparentYaml is the worst possible programming language, beating out even ant’s xml abomination.Unfortunately most of the work of GitHub actions is configuring the runners and setup data, which requires you to use lots of yaml to invoke unvetted public repositories (actions) written in JavaScript to do what is easier done as shell scripts, and then use shell scripts to workaround the limitations of actions.State is impossible, data is even more impossible, and caching is completely broken. And if you use your own runners, GitHub actions don’t even clean up their own garbage. I suspect it’s the same on public runners, but just statistically less likely to affect you, but a potential security vulnerability.I’ve been working 2 things:1. A front end that crafts GHA workflow yamls from a sane configuration with common tasks baked in.2. An event and reporting system so you can see what is happening during a workflow — not after — without having to scroll through GitHub’s hideous log output in html or download and unzip the full log. reply suhlig 2 hours agoprevConcourse has it right: You can ssh into a failed container, and debug in the exact environment where the failure occurred.I don’t understand why people settle for less. reply plonk 14 hours agoprevThe best approach is to develop completely local build scripts and add a few options to plug GitHub Actions&#x27; exclusive features into them. Make a build script that can take a cache folder&#x27;s path as argument. Make it take a test report output path as another argument. etc.So your GHA workflow is: set up secrets (AWS and co.), set up Python, download cache to path X if possible, run the build in X and send reports to Y, publish reports in Y. And put as much work as possible inside the build script. We have a whole Python project for that.This is truly painless after the first development effort. reply nthState 19 hours agoprevMost of my problems would vanish if there was an official way to run workflows locally, something like:shell: run_workflow name=MyJob in=MyWorkflow.yml params={} reply avtar 18 hours agoparentI guess you have to ask yourself what&#x27;s in MyWorkflow.yml that can&#x27;t be in a script and run locally? reply mason55 15 hours agorootparentWell, that&#x27;s why the word \"official\" is in there. Obviously you could mock up the entire github actions scaffolding locally and have it inject environment variables and support all the actions and everything, but keeping that up to date will be a nightmare if you&#x27;re doing it on your own.Obviously you could put the whole CI&#x2F;CD into a bash script and not use any features or functionality provided by github actions but there are plenty of nice things that it does and it would be a shame to not use any of them. reply avtar 14 hours agorootparentI didn&#x27;t mention it in my reply but I was referring to the complaint in the article that the author wants to be able to debug locally without having to push changes to GitHub first. The top comment by MoreQARespect and others highlight the benefits of scripting as much as possible so that processes like builds and cutting releases can be run and tested locally.> Obviously you could mock up the entire github actions scaffolding locallyNot sure if anyone&#x27;s advocating for implementing GA entirely. You can at least automate project-specific bits as much as possible using scripts, and then have the CI environment use the same automation. That allows for more local debugging than overusing GA. reply bob1029 14 hours agoprevMy experience with GitHub Actions is mostly managed by way of certain Azure Portal interactions these days.When I create a new Function app, it gives me the opportunity to enable GitHub integration. The experience for this is flawless, IMO. You provide your GH credentials, select the org&#x2F;repo&#x2F;branch, and then it will create the workflow file for you and push it automatically. It will also update the secrets in your repository settings to match what Azure expects on its end for deployment.By the time you get to look at your GitHub repo, the action is already running and will 100% complete successfully if you followed a standard&#x2F;default project structure. The automatically-generated workflow files aren&#x27;t perfect, but they&#x27;re so close that it becomes trivial to tweak for additional build args or project arrangements. Just getting the secrets & related boilerplate configured makes the difference between me doing it right now vs maybe never. The consequence of always having proper CI&#x2F;CD from day zero, even for the most trivial projects, seems profound to me.There exist some really happy paths now wrt GH actions, but you gotta be willing to get pretty hammered on the Microsoft koolaid to explore them. reply elischleifer 13 hours agoprevAnother tool that tackles GitHub Action debugging head on: https:&#x2F;&#x2F;www.ci-debugger.io&#x2F;Wrap your GH Actions in a debugger breakpoint and connect into the live broken GH Action to inspect the machine, re-run commands etc..At it&#x27;s heart - realtime debugging for GitHub actions. reply atomicnature 18 hours agoprevThis is a real problem. I think the problem stems from the unasserted assumption that declarative YAML is not really coding&#x2F;debugging. The root problem is the assumption that infrastructure specifications are second-class citizens when it comes to managing a software ecosystem. Due to this, one rarely sees any sort of strong tooling support for creating, updating, debugging and extending various infrastructure activities. The unpleasant truth is that we live in the dark primitive days of infrastructure management. reply theideaofcoffee 19 hours agoprevAs someone who has recently sunk a considerable amount of time in modernizing some pipelines, workflows, what have you, I feel this deep in my bones. The commit-test-fail-recommit test loop is painful and something I’ve experienced all too well. Trying to work around product limitations brought about by whoever concocted the system on GitHub’s side to save customers from themselves and declared it good is painful. Trying to debug simple issues is painful. I’m glad I’m not alone. reply varsketiz 14 hours agoprevIt&#x27;s not really context switching. Author is debugging github actions, thats the context in which a few window changes seem minor. Context switching would be to get dragged to meeting, or getting asked by a colleague to explain how to set up github actions for their project. reply jusonchan81 17 hours agoprevWe moved our CI to this orchestrator called Netflix Conductor. It’s highly customized internally with workers capable of running different kind of tasks etc. But since we did this, CI has been a wonderful experience. Things run smoothly and history can be tracked and easy to build variants by modifying or creating new workflows. We aim to open source this extension soon. reply becurious 15 hours agoprevYou’d think they could at least train GitHub Copilot to test run the workflow and point out immediate issues.We have to add an action to kill duplicate runs on triggers.The caching is marginal, at least on Windows runners because it takes forever to expand the tar ball. Not even sure from their docs &#x2F; issues on the cache action if they did finally move it to use GNU tar.Having some way to get an interactive shell on fail would be a big step up for debugging issues. Otherwise we are back to print debugging in the actions or uploading artifacts at each step so we can inspect them. reply gchamonlive 17 hours agoprevI am thinking about porting my ci&#x2F;cd pipelines from Jenkins to GitHub actions to leverage autoscaling self-hosted runners, which I don&#x27;t think there is an exact equivalent for Jenkins nodes, at least not one that is already implemented where I work.The pipelines though, are all configured using ansible. Applying the same principle I did to Jenkins, using it strictly for execution automation, logs, permission and the likes, and leaving the heavy lifting to a more trusty tool, I think I can avoid both major vendor lock-in and idiosyncrasies and nonsenses from the language.It boggles my mind how unrefined the GitHub actions flow is. It doesn&#x27;t offer a good experience by a long shot. reply kathlam 15 hours agoprevIt&#x27;s clear we&#x27;ve all wrestled with GitHub actions and Jenkins in some shape or form. Debugging them can feel like being in an escape room, without any clues.I work at Trunk.io and we have a tool called CI Debugger. It helps you understand your workflows. Instead of getting lost in logfiles and commits, you can pinpoint where things are bogging down or going haywire. It can give you a clearer picture of what&#x27;s happening under the hood. Like having a heat map for the CI&#x2F;CD processes. reply ctoth 17 hours agoprevOne thing that actually makes this slightly less horrible is the Gh tool. You can use gh run watch to tail your logs in the terminal and at least don&#x27;t have to click through a million things just to see output. reply rane 17 hours agoparentI wrote a command-line tool that streamlines retrieving test results from GitHub Actions even further. Essentially parses jest&#x2F;tsc&#x2F;eslint errors in GHA jobs&#x27; logs for the current&#x27;s branch PR. https:&#x2F;&#x2F;github.com&#x2F;raine&#x2F;ghtool reply fijiaarone 6 hours agoparentprevDo you know a way to stream the gh run watch output? reply bysja 13 hours agoprevGithub Actions has been a pleasant introduction to CI&#x2F;CD for me. I used to build locally and then git push and&#x2F;or rsync everything directly to a VPS (Digitalocean Droplets in my case). But for collaboration, this workflow breaks down. Then, using Github as the \"origin\" repository becomes compelling, and Github Actions fit very nicely with that workflow. reply lenkite 9 hours agoprevI wish Github Actions were Lua instead of YAML. One could use a restricted environment populated with predefined functions, a restricted set of modules and all the advantages of syntax checking and language help. reply lpapez 3 hours agoparentCongratulations, you just reinvented Jenkins but using Lua instead of Groovy. reply watermelon0 17 hours agoprevMy number one complaint is that they still don&#x27;t have managed ARM runners. Considering how overpriced runners are (compared to cloud instances), I&#x27;m sure they would make a ton of money here.My choices here are either to use a different CI solution (but I quite like Actions, and they are better integrated in the Github UI than alternatives), or to use custom self-hosted autoscaling runners (but there doesn&#x27;t appear to be a good solution available at the moment, and I definitely don&#x27;t want to managed infra for CI.) reply xjia 13 hours agoparentCheck out https:&#x2F;&#x2F;dime.run&#x2F; they manage workers for you reply Aeolun 10 hours agoprevMy biggest pain point is not being able to do proper ternary statements in workflows. And passing arrays to called workflows. My ‘runs-on’ statements need more than one label!You can fake it by passing a stringified JSON object, but that’s bizarre. reply bingemaker 15 hours agoprevThe current state of GA is much better than Jenkins. I don&#x27;t like yaml, but this is still better than mucking around Jenkins configs. Fin reply kitallis 16 hours agoprevOne of my biggest gripes with Actions is that it doesn&#x27;t allow you to trigger workflows for a specific SHA. Only the branch HEAD.This is pretty much possible in all other CIs. reply tra3 10 hours agoparentYou can pass a sha into your workflow and then check it out. reply ivanjermakov 10 hours agoprevI feel this pain. So much that now, when I need to set up new GitHub actions pipeline, I always create a new branch to push there until it&#x27;s working. And then squash merge as a single commit. reply cwales95 18 hours agoprevThis is my normal CI&#x2F;CD workflow -- even for GitLab. Debugging why CI&#x2F;CD doesn&#x27;t work is one of the worst headaches you can imagine. reply artursapek 17 hours agoprevGitLab’s CI is so much better than GH it’s not even funny reply globular-toast 3 hours agoprevA tight feedback loop is everything. I will not use tools that require long waits between tests. I want to edit, test, wait a matter of seconds to see the results.Seeing people push hundreds of commits to their CI pipeline trying to fix it by trial and error makes me cringe. I do not understand how some people accept such a workflow without thinking it could be better.When I was planning the CI set up at my job I made sure it could all be run locally and hammered this point home to developers. CI isn&#x27;t magic, it&#x27;s just some other computer running your shit.We use Gitlab CI which runs your script in a container. It&#x27;s trivial to run the container locally with docker to test exactly what will happen in CI (although you do have to make a fresh clone of your repo for the mount, I thought about scripting this but in practice it was never needed that much).GitHub Actions seems much harder to test locally. There seems to be some projects to do it but they are too heavy for me to want to install. For this reason alone I don&#x27;t like Actions. reply ZeWaka 18 hours agoprevre: `pull_request_target` and fork PRs - You can get around the !Even More Fun! limitations this has (GITHUB_TOKEN being read-only) by having a workflow called by another workflow.For example, I wrote a set of workflows[1] to automatically apply a label after 2 &#x27;review approvals&#x27;.First, a &#x27;dummy&#x27; workflow triggering off PRs (in that context) that uploads an artifact: the PR numberSecond, the &#x27;real&#x27; workflow that runs in the context of the actual repository, set to be `on: workflow_run: workflows: - Final Review Labeler` - this pulls in the artifact, runs a GraphQL query, and applies the label if applicable.[1]: https:&#x2F;&#x2F;github.com&#x2F;goonstation&#x2F;goonstation&#x2F;blob&#x2F;master&#x2F;.gith... reply kevmo314 16 hours agoprevI wish individual actions could be specified as Dockerfiles instead of yaml files. That would address a lot of issues that I&#x27;ve run into around build environments being slightly different than locally.Yes, I can wrap it with a simple docker action. It would be cool if that were automatic. reply jurassic 16 hours agoprevMost of my frustrations with GHA arise when doing something useful conflicts with someone’s idea of security. For example, branch protection rules intended to stop devs from yoloing commits blocking me from pushing a version bump commit during a release workflow. reply Aeolun 10 hours agoparentThe lack of exceptions for actions is bizarre. And then they build repository rules or whatever, and made the same mistake again! You can at least exclude github apps now, but then you need to run all your repo actions with an app installtion key :&#x2F; reply da39a3ee 2 hours agoprevThe VSCode extension is quite good and solves some of the problems mentioned concerning detecting errors without needing to go through the commit-push-run cycle. reply sitzkrieg 18 hours agoprevone thing to be aware of, if you use windows, and submodules in a repo, ci will fail to clone over 50% of the time (with internal retries) with early eof errorsit&#x27;s apparently a fixed problem in upstream openssl beta that isnt bundled yet, but i think a custom runner would be better too (but not an option at my org)still, some days it gets in a rut and quickly fails for 10+ runs all billed at full rate. the entire eng group is severely annoyed by it because we cross test all oses on each commit so its becoming an expensive problem. basically 3x the billing on windows ci reply natbennett 17 hours agoprevFor validating YAML I love CUE. It takes some work to define the schema — would def be nice if GitHub provided that.I found Nektos act pretty usable for local testing when I was doing a lot of GA work. reply eviks 17 hours agoprevVery good points, especially re. the security footguns reply Pxtl 19 hours agoprevI mean GH Actions is basically a re-brand of Microsoft&#x27;s \"Azure Pipelines\". As somebody who used all previous incarnations of TFS&#x2F;VSTS&#x2F;AzDO build and release pipelines: they are not good at this. This is not a team with a record of success. That Azure Pipelines is moderately usable only happened because they failed literally every other approach they tried.There was a project to allow you to run the pipelines locally so you could do the edit-run-debug loop on your own private environment without committing. It was, of course, canned.https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;azure-pipelines-agent&#x2F;pull&#x2F;2687...However, there are tools to improve QOL. For example:https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=ms-azure...A vscode extension that&#x27;s syntax-aware.Now, I&#x27;ll be a bit controversial: if they&#x27;d used XML instead of YAML, you could have an xmlns declaration up-top that would give you validation in most decent code editors without user intervention. XML is awful, but it has a lot of useful features that we gave up when we threw the baby out with the bathwater. reply woodruffw 18 hours agoparent> I mean GH Actions is basically a re-brand of Microsoft&#x27;s \"Azure Pipelines\". As somebody who used all previous incarnations of TFS&#x2F;VSTS&#x2F;AzDO build and release pipelines: they are not good at this. This is not a team with a record of success. That Azure Pipelines is moderately usable only happened because they failed literally every other approach they tried.I was under the impression (which might be wrong!) that GHA was an independent project within GitHub that was well underway before the acquisition. Are you saying that GHA was rebuilt on top of AzP, that it&#x27;s just a relabeling of AzP, or something else?(I have no particular dog in it being one way or the other, but I&#x27;m curious about the history here.) reply Pxtl 18 hours agorootparentThey share a lot of code. My understanding is that it was an MS project first, but I might have that backwards.> GitHub Workflows execute on runners. The runner code is essentially a fork of the Azure Pipelines code, so it&#x27;s very similar. It&#x27;s also cross-platform and you can also use hosted or self-hosted runners.https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;dotnet&#x2F;architecture&#x2F;devops... reply woodruffw 18 hours agorootparentThanks for the link -- I knew that GHA workflow runs ran on Azure, but I didn&#x27;t know the workflow runner itself was a fork of Azure&#x27;s runner&#x2F;instrumentor. That&#x27;s interesting context! reply evntdrvn 18 hours agorootparentif you look at the source of the GHA runner, you can see where they regex-replace all references to Azure Pipelines with GitHub Actions lol reply evntdrvn 18 hours agorootparentprevthe original GHA implementation was shitcanned reply fijiaarone 6 hours agorootparentIs that a nice way of saying we are still stuck with the original GHA implementation reply ZeWaka 18 hours agoparentprev> GH Actions is basically a re-brand of Microsoft&#x27;s \"Azure Pipelines\"Probably even moreso than most people think - a large portion of the AzDo team got moved over after the acquisition to work on GitHub Actions&#x2F;Projects. reply jahsome 10 hours agoparentprevYou had me up til that last paragraph.Call me crazy but xml just hurts my eyes. I&#x27;ll always take a nicely formatted yaml doc with all the pains that come with it over the horrors of angle brackets and camel case. reply Pxtl 3 hours agorootparentXML syntax is bad, but yaml doesn&#x27;t have a proper blessed batteries-included built-in schema language afaik. A well formed XML with an xmlns will have validation and autocomplete in a good editor thanks to this. JSON can do it too. Never seen it done with yaml.It&#x27;s a pretty big frustration in a language that is so slow to test -- commit push run wait find the error oh I made a typo. Better code-time validation fixes this but the tooling for that in yaml is weak. reply nafizh 19 hours agoprevWhat&#x27;s the technology behind the blog? It&#x27;s clean, minimal and beautiful. reply woodruffw 18 hours agoparentIt&#x27;s a Jekyll site. I originally built it off of a popular theme (back in 2014 or so), but these days the theme is just a custom thing that I&#x27;ve cobbled together.(So, in a sense, there&#x27;s no real technology \"behind\" it. It&#x27;s just Markdown with a little HTML templating, with Jekyll as the SSG.) reply nafizh 17 hours agorootparentThanks for the reply. Is the code available by any chance? reply woodruffw 16 hours agorootparentUnfortunately not -- it used to be in a public repo, but I also track drafts and other things now that I don&#x27;t want to be public until they&#x27;re ready.I&#x27;ll see if I can clean it up into a public repository, but no guarantees :-) reply fooker 15 hours agorootparentprevRight click -> view page source. reply junke 18 hours agoparentprevJekyll reply ulizzle 16 hours agoprevMore official or blessed packages for sure. I agree with that. reply darepublic 19 hours agoprevI don&#x27;t see how you love something that makes you jump through these hoops:> In this particular case, it took me 4 separate commits (and 4 failed releases) to debug the various small errors I made: not using ${{ ... }}5 where I needed to, forgetting a needs: relationship, &c reply garciasn 19 hours agoparentWe use Github Actions and we just don&#x27;t have any issues with it outside the first time we set it up for each repo. Then we make 100s of commits a week and it does its thing and our work goes live a few seconds later. That&#x27;s why I love it.Could things be better? Of course; that&#x27;s how software is--and this should resonate with most folks on this site. But just because some product isn&#x27;t infallible doesn&#x27;t mean we can&#x27;t love it too. reply moralestapia 19 hours agorootparent>Then we make 100s of commits a week and it does its thing and our work goes live a few seconds later.Wow, computers doing what they&#x27;re supposed to do. Pretty impressive ...The UX on GH actions is crap, other CI&#x2F;CD solutions give you way more control and tooling. GH really needs to step up their game on this one. reply garciasn 18 hours agorootparentI am not sure why you’re being so snarky, but I did address that it could be better.The thing for us is that we’re already paying for GitHub and Actions are included. I know, for a fact, GH is&#x2F;was working with stakeholders using their software to get feedback on what could be better. So they are trying!I’m not here being a fanboy by any means; I’m just saying it does what I need it to do and I’m an active user who is pleased with the service provided.YMMV. reply neuromanser 14 hours agorootparentprev> we just don&#x27;t have any issues with it outside the first time we set it up for each repoBut that&#x27;s exactly what a lot of commenters complain about. reply vegardx 19 hours agoparentprevThere&#x27;s tools like Act[0] that tries to solve this, but this has been an issue with CI systems since they were invented.[0] https:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply 5e92cb50239222b 19 hours agorootparentAlso reused by gitea for their CI runner. I was quite impressed by that feat, pretty neat.https:&#x2F;&#x2F;gitea.com&#x2F;gitea&#x2F;act_runner reply layer8 19 hours agoparentprevYeah, I wouldn’t want to use any automation that you can’t also easily and quickly test locally. reply bdcravens 16 hours agorootparentAct can do most of it locallyhttps:&#x2F;&#x2F;github.com&#x2F;nektos&#x2F;act reply Pxtl 19 hours agorootparentprevFun fact: Microsoft had a plan to provide that!They canned it.https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;azure-pipelines-agent&#x2F;pull&#x2F;2687... reply hanniabu 19 hours agoparentprevIsn&#x27;t that just programming? That&#x27;s not much different than saying you forgot a bracket and had to make another commit to make it work. Granted, it would be nice if they had some linter. reply 5e92cb50239222b 19 hours agorootparentGenerally programming these days does not require you to submit build jobs or jump through other hoops to catch trivial mistakes. Although it depends on what you do, embedded developers and game programmers writing for consoles might disagree.It really feels like a throwback to the punch card era.I too don&#x27;t enjoy writing CI scripts (despite knowing Linux administration and shell scripting quite well), it always takes an inordinate amount of time, but it also saves much more over the long term. reply matthewaveryusa 19 hours agorootparentprevThis is a usecase where chatgpt works great! I usually pass this kind of ops DSL in gpt and it will find my mistakes. Github actions and graphanaQL code, oof, they just click for me. reply chc 19 hours agorootparentI&#x27;m not gonna post my employer&#x27;s proprietary code into ChatGPT. reply matthewaveryusa 18 hours agorootparentDon&#x27;t fixate on the details, fixate on the larger point. your specific situation of having code self-hosted and an employer that cares deeply about their proprietary code is a detail beside the point. LLMs shine at fixing up DSLs that you&#x27;re unfamiliar with. chatgpt to llm is kleenex to facial tissue. replysyndicatedjelly 18 hours agoprev [–] gitlab-runner allows you to run scripts locally for GitLab, but even that is lacking (any env secrets stored in GitLab? Script is going to fail).I really, really wish there was a way to clone the GitHub Actions or GitLab runner environment, spin up a runner locally and test. That would shave off 95% of the wait time replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author raises concerns about GitHub Actions, emphasizing issues with debugging, possible security vulnerabilities, and the need for enhancement in workflows validation.",
      "They propose several improvements including interactive debugging, stricter workflow validation, and better specification of types, along with a call for more official GitHub-maintained actions.",
      "The author also criticizes the lack of community emphasis by GitHub and expresses concerns about potential security exploits within the GitHub Actions ecosystem."
    ],
    "commentSummary": [
      "The discourse revolves around users' frustrations and criticisms of GitHub Actions, a tool used for Continuous Integration and Continuous Deployment (CI/CD) workflows.",
      "Users express difficulties with debugging, limited functionality, and integration problems. Some suggest using alternate tools and workarounds to address these concerns.",
      "The community highlights the need for improvements in CI platforms, better support for HTML reports, and a preference for running workflows locally."
    ],
    "points": 382,
    "commentCount": 207,
    "retryCount": 0,
    "time": 1695392482
  },
  {
    "id": 37610899,
    "title": "Ways to capture changes in Postgres",
    "originLink": "https://blog.sequin.io/all-the-ways-to-capture-changes-in-postgres/",
    "originBody": "Docs Pricing Integrations Blog Login Start free Back to posts All the ways to capture changes in Postgres Anthony Accomazzo • Sep 19, 2023 • 9 min read We're Sequin and we let developers build on their API data using their Postgres database. We sync data from third-party APIs like Salesforce and HubSpot to Postgres so you can select with SQL or an ORM. And when you mutate tables with insert, update, and delete, we write those changes back to the API. Setup takes just two minutes. Working with data at rest is where Postgres shines. But what about when you need data in motion? What about when you need to trigger a workflow based on changes to a table? Or you need to stream the data in Postgres to another data store, system, or service in real-time? Fortunately, Postgres comes with a lot of options to make this happen. In this post, I’ll lay them all out. I’ll also give you an idea of which are easy to do, which are more robust, and how to make the right choice for you. Listen/Notify Perhaps the simplest approach is to use Postgres' interprocess communication feature, Listen/Notify. Listen/Notify is an implementation of the publish-subscribe pattern. With Listen/Notify, a Postgres session (or connection) can \"listen\" to a particular channel for notifications. Activity in the database or other sessions can \"notify\" that channel. Whenever a notification is sent to a channel, all sessions listening to that channel receive the notification instantly. You can see Listen/Notify for yourself by opening two psql sessions. In session 1, you can setup your listener: > listen my_channel; LISTEN And in session 2, you can publish to that channel with a message: > notify my_channel, 'hey there!'; NOTIFY > notify my_channel, 'is this thing on?'; NOTIFY While the listener process received the message right away, psql won't print the message automatically. To get it to print out the messages it's received so far, you just need to run any query. For example, you can just send an empty query like this: > listen my_channel; LISTEN > ; Asynchronous notification \"my_channel\" with payload \"hey there!\" received from server process with PID 80019. Asynchronous notification \"my_channel\" with payload \"is this thing on?\" received from server process with PID 80019. (Naturally, this isn't how the Postgres client library in your preferred programming language will work. Libraries will deliver messages to your subscriber immediately without requiring a query.) To use Listen/Notify to capture changes, you can set up a trigger. For example, here's an after trigger that sends along the payload of the record that changed as JSON via Notify: create or replace function notify_trigger() returns trigger as $$ declare payload json; begin payload := json_build_object('table', TG_TABLE_NAME, 'id', NEW.id, 'action', TG_OP); perform pg_notify('table_changes', payload::text); return new; end; $$ language plpgsql; create trigger my_trigger after insert or update or delete on my_table for each row execute function notify_trigger(); Downsides Listen/Notify is simple and powerful, but has some notable downsides. First, as a pub-sub mechanism, it has \"at most once\" delivery semantics. Notifications are transient; a listener needs to be listening to a channel when notifications are published. When a listener subscribes to a channel, it will only receive notifications from that moment forward. This also means that if there are network issues that cause a listening session to disconnect even briefly, it won't receive the notification. Second, the payload size limit is 8000 bytes. If the message exceeds this size, the notify command will fail. [1] As such, Listen/Notify is solid for basic change detection needs, but you'll probably find it does not serve more sophisticated needs well. However, it can complement other strategies (like \"poll the table\") nicely. Poll the table The simplest robust way to capture changes is to poll the table directly. Here, you need each table to have an updated_at column or similar that updates whenever the row updates. (You can use a trigger for this.) A combination of updated_at and id serve as your cursor. In this setup, your application logic that polls the table handles storing and maintaining the cursor. In addition to polling the table, you can use a Notify subscription to inform your application that a record has been inserted or modified. Postgres' notifications are ephemeral, so this should only serve as an optimization on top of polling. Downsides This approach has two downsides. The first is that you can't detect when a row is deleted. There's no way to \"see\" the missing row in the table. One remediation is to have a Postgres trigger fire on deletes, and store the id (and whatever other columns you want) in a separate table: e.g. deleted_contacts. Then, your application can poll that table to discover deletes instead. The second downside is that you don't get diffs. You know this record was updated since you last polled the table, but you don't know what was updated on the record. Maybe deletes aren't a big deal for your use case or you don't care about diffs. If so, polling the table is a reasonable and simple solution for tracking changes. Replication (WAL) Postgres supports streaming replication to other Postgres databases. In streaming replication, Postgres sends the WAL stream over a network connection from the primary to a replica. The standby servers pull these WAL records and replay them to keep their database in sync with the primary database. Streaming replication was built for streaming changes to other Postgres servers. But you can use it to capture changes for your application too. You first create a replication slot, like this: select * from pg_create_logical_replication_slot('', ''); output_plugin is a parameter which specifies which plugin Postgres should use to decode WAL changes. Postgres comes with a few built-in plugins. pgoutput is the default. It formats the output in the binary expected by client servers. test_decoding is a simple output plugin that provides human-readable output of the changes to the WAL. The most popular output plugin not built-in to Postgres is wal2json. It does what it says on the tin. JSON will be a lot easier for you to consume from an application than Postgres' binary format. After creating your replication slot, you can start it and consume from it. Working with replication slots uses a different part of the Postgres protocol than standard queries. But many client libraries have functions that help you work with replication slots. For example, this is how you consume WAL messages in the psycopg2 library: cursor.start_replication(slot_name='your_slot_name', decode=True) cursor.consume_stream(lambda msg: acknowledge_to_server(cursor, msg)) def acknowledge_to_server(cursor, msg): # Process the message (msg) here # ... # Acknowledge the message cursor.send_feedback(flush_lsn=msg.wal_end) Note that the client is responsible for ack'ing WAL messages that it has received. So the replication slot behaves like event buses such as SQS. Instead of consuming from the WAL directly, you can use tools like Debezium to do this for you. Debezium will consume the WAL from Postgres and stream those changes to a variety of sinks, including Kafka or NATS. Downsides Using Postgres' replication facilities to capture changes is a robust solution. The biggest downside is complexity. Replication slots and the replication protocol are less familiar to most developers than the \"standard\" parts (i.e. tables and queries). Along with this complexity is a decrease in clarity. If something with replication breaks or if there's a lag or things aren't working as expected, it can be a bit trickier to debug than the other solutions outlined here. Another aspect worth mentioning is that replication slots may require tweaking postgresql.conf. For example, you may need to tweak parameters like max_wal_senders and max_replication_slots. So you'll need total access to the database to implement this solution. Capture changes in an audit table In this approach, you set up a separate table for logging changes, e.g. changelog. That table contains column related to the record's modification, such as: action: Was this an insert, update, or delete? old: A jsonb of the record before the mutation. Blank for inserts. values: A jsonb of the change fields. Blank for deletes. inserted_at: Time the change occurred. To set this up, you need to create a trigger function that inserts into this table every time a change occurs. Then, you need to create triggers on all the tables you care about to invoke that trigger function. Here's an example of what that trigger function might look like: create or replace function changelog_trigger() returns trigger as $$ declare action text; table_name text; transaction_id bigint; timestamp timestamp; old_data jsonb; new_data jsonb; begin action := lower(TG_OP::text); table_name := TG_TABLE_NAME::text; transaction_id := txid_current(); timestamp := current_timestamp; if TG_OP = 'DELETE' then old_data := to_jsonb(OLD.*); elseif TG_OP = 'INSERT' then new_data := to_jsonb(NEW.*); elseif TG_OP = 'UPDATE' then old_data := to_jsonb(OLD.*); new_data := to_jsonb(NEW.*); end if; insert into changelog (action, table_name, transaction_id, timestamp, old_data, new_data) values (action, table_name, transaction_id, timestamp, old_data, new_data); return null; end; $$ language plpgsql; After setting up a way to capture changes, you need to figure out how to consume them. There's a lot of different ways you can do this. One way is to treat the changelog as a queue. Your application workers can pull changes from this table. You'll probably want to ensure that changes are processed ~exactly once. You can use the for update skip locked feature in Postgres to do this. For example, your workers can open a transaction and grab a chunk of changelog entries: begin; select * from changelog order by timestamp limit 100 for update skip locked; Now, other workers running that query will not receive this \"locked\" block of rows. After your worker processes the records, it can delete them: delete from changelog where id in (list_of_processed_record_ids); commit; Downsides This approach is similar to using a replication slot, but more manual. The trigger function and table design I've outlined might work to start. But you'd likely need to make tweaks before deploying at scale in production. [2] The advantage over replication slots is that it's all \"standard\" Postgres. Instead of an opaque replication slot, you have an easy to query Postgres table. And you don't need access to postgresql.conf to make this work. Foreign data wrappers Foreign data wrappers (FDWs) are a Postgres feature that allow you to both read from and write to external data sources from your Postgres database. The most notable and widely supported extension built on FDWs is postgres_fdw. With postgres_fdw, you can connect two Postgres databases and create something like a view in one Postgres database that references a table in another Postgres database. Under the hood, you're turning one Postgres database into a client and the other into a server. When you make queries against foreign tables, the client database sends the queries to the server database via Postgres' wire protocol. Using FDWs to capture changes is an unusual strategy. I wouldn't recommend it outside very specific situations. One situation where FDWs could make sense is if you're capturing changes in one Postgres database in order to write them to another Postgres database. Perhaps you use one database for accounting and another for your application. You can skip the intermediary change capture steps and use postgres_fdw to go from database to database. Here's an example trigger that ensures the status for a given account (identified by email) is in-sync across two databases. This assumes the foreign table has already been declared as foreign_app_database: create or replace function cancel_subscription() returns trigger as $$ declare account_status text; begin if (new.status = 'cancelled' or new.status = 'suspended') then account_status := 'cancelled'; update foreign_app_database.account set status = account_status where email = new.email; end if; return new; end; $$ language plpgsql; In addition to postgres_fdw, you can create and load your own foreign data wrappers into your Postgres database. That means you could create a foreign data wrapper that posts changes to an internal API. Unlike the other change detection strategies in this list, because you'd write to the API inside your commit, your API would have the ability to reject the change and roll back the commit. Downsides Foreign data wrappers are a fun and powerful Postgres feature. But they'll rarely be your best option for capturing changes. You're probably not trying to replicate changes from one Postgres database to another. And while writing your own foreign data wrapper from scratch has gotten easier, writing your own FDW is probably the biggest lift in this list for capturing changes. Conclusion There are lots of options for capturing changes in Postgres. Depending on your use case, some options are clearly better than others. In sum: Listen/Notify is great for non-critical event capture, prototyping, or optimizing polling. Polling for changes is a fine, straightforward solution for simple use cases. Replication is probably your best bet for a robust solution. If that’s too difficult or opaque, then perhaps the audit table is a good middle-ground. Finally, foreign data wrappers solve a need you’re unlikely to have. We examined all of these options for our own change capture requirements, and unfortunately none of them met our complex (and niche) needs. So, we ended up needing to build a Postgres proxy 😅 You can read more about that here. Note the payload size includes the channel name, which like all Postgres identifiers can be up to 64 bytes in size. ↩︎ One example issue that comes to mind: should there be a timeout for how long workers can have changes checked out? ↩︎ Product Pricing Changelog Status Company Careers Blog Developer Docs Airtable guide Stripe guide Playbooks Retool AWS Lambda Metabase PowerBI More... © Sequin Labs, Inc. 2022 Terms of Service Privacy Policy Security Data Processing All systems nominal",
    "commentLink": "https://news.ycombinator.com/item?id=37610899",
    "commentBody": "Ways to capture changes in PostgresHacker NewspastloginWays to capture changes in Postgres (sequin.io) 288 points by chuckhend 22 hours ago| hidepastfavorite80 comments slotrans 19 hours agoUsing triggers + history tables (aka audit tables) is the right answer 98% of the time. Just do it. If you&#x27;re not already doing it, start today. It is a proven technique, in use for _over 30 years_.Here&#x27;s a quick rundown of how to do it generically https:&#x2F;&#x2F;gist.github.com&#x2F;slotrans&#x2F;353952c4f383596e6fe8777db5d... (trades off space efficiency for \"being easy\").It&#x27;s great if you can store immutable data. Really, really great. But you _probably_ have a ton of mutable data in your database and you are _probably_ forgetting a ton of it every day. Stop forgetting things! Use history tables.cf. https:&#x2F;&#x2F;github.com&#x2F;matthiasn&#x2F;talk-transcripts&#x2F;blob&#x2F;master&#x2F;Hi...Do not use Papertrail or similar application-space history tracking libraries&#x2F;techniques. They are slow, error-prone, and incapable of capturing any DB changes that bypass your app stack (which you probably have, and should). Worth remembering that _any_ attempt to capture an \"updated\" timestamp from your app is fundamentally incorrect, because each of your webheads has its own clock. Use the database clock! It&#x27;s the only one that&#x27;s correct! reply smilliken 17 hours agoparent> each of your webheads has its own clock. Use the database clock!Yes, for consistency you should use the database clock by embedding the calls to `now()` or similar in the query instead of generating it on the client.But it&#x27;s not sufficient to use these timestamps for synchronization. The problem is that these timestamps are generated at the start of the transaction, not the end of the transaction when it commits. So if you poll a table and filter for recent timestamps, you&#x27;ll miss some from transactions that are committing out of order. You can add a fudge factor like querying back an extra few minutes and removing the duplicates, but some transactions will take longer than a few minutes. There&#x27;s no upper bound to how long a transaction can take in postgresql, and there&#x27;s a lot of waste in querying too far back. This approach doesn&#x27;t work if you care about correctness or efficiency. reply sbuttgereit 11 hours agorootparentThere is a way in PostgreSQL to get actual wall clock time of the database server: `clock_timestamp()` regardless of transaction start time.There&#x27;s also `statement_timestamp()` per the docs: \"returns the start time of the current statement (more specifically, the time of receipt of the latest command message from the client).\"https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;functions-datetime.h...This isn&#x27;t to say any of these methods are the best (or even good) in all cases. Time is tricky, especially if you&#x27;re trying to do any sort of sequencing. reply jgraettinger1 16 hours agoparentprevEstuary (https:&#x2F;&#x2F;estuary.dev ; I&#x27;m CTO) gives you a real time data lake&#x27;d change log of all the changes happening in your database in your cloud storage -- complete with log sequence number, database time, and even before&#x2F;after states if you use REPLICA IDENTITY FULL -- with no extra setup in your production DB.By default, if you then go on to materialize your collections somewhere else (like Snowflake), you get synchronized tables that follow your source DB as they update.But! You can also transform or materialize the complete history of your tables for auditing purposes from that same underlying data-lake, without going back to your source DB for another capture &#x2F; WAL reader. reply jvz 9 hours agorootparentI&#x27;m evaluating Flow for CDC. Do you support logical decoding messages from `pg_logical_emit_message`? This would allow us to add audit metadata[^1].[^1]: https:&#x2F;&#x2F;www.infoq.com&#x2F;articles&#x2F;wonders-of-postgres-logical-d... reply jgraettinger1 7 hours agorootparentNo. But this is neat, and at a glance it looks straight forward to add. Happy to discuss further! reply slotrans 7 hours agorootparentprevThat sure sounds cool but I can&#x27;t tell from your website that it does any of that. Even giving up on the marketing copy and going straight to the docs... I can&#x27;t follow them. reply jgraettinger1 6 hours agorootparentHi fellow Dark Tower friend.Yes, marketing and docs are not our strongest suits and we need to do better. To be fair, though, we&#x27;re also trying not to scare off less technical users who see a bullet list like above and think \"well this is clearly not for me\". It&#x27;s a hard balance reply DenisM 14 hours agorootparentprevAre you using debezium to capture changes? reply jgraettinger1 7 hours agorootparentNo. We implemented our own [1] for a few reasons:* Scaling well to multi-TB DBs without pinning the write-ahead log (potentially filling your DB&#x27;s disk) while the backfill is happening. Instead, our connector constantly reads the WAL and works well in setups like Supabase that have very restrictive WAL sizes (1GB iirc).* Incremental fault-tolerant backfills that can be stopped and resumed at will.* Flowing TOAST columns through seamlessly to your materialized destination, without requiring that you resort to REPLICA IDENTITY FULL.* Being able to offer \"precise\" captures which are logically consistent in terms of the sequence of create&#x2F;update&#x2F;delete events.The last one becomes really interesting when paired with REPLICA IDENTITY FULL because you can feed the resulting before&#x2F;after states into an incremental computation (perhaps differential dataflow) for streaming updates of a query.Our work is based off of the Netflix DBLog paper, which we took and ran with.[1] https:&#x2F;&#x2F;github.com&#x2F;estuary&#x2F;connectors&#x2F;tree&#x2F;main&#x2F;source-postg... reply simonw 10 hours agoparentprevThanks for that example. I got Code Interpreter to port it to SQLite and demonstrate it working here: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;b5113cb1-10df-4a38-adde-5ec0e7...I have my own SQLite implementation of a similar pattern (but using columns rather than JSON) which I describe here: https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Apr&#x2F;15&#x2F;sqlite-history&#x2F; reply dllthomas 18 hours agoparentprevI found that referencing session variables from triggers lets me add additional information (eg. a comment on why the change is being made) to the history. I&#x27;ve only done it in a small personal project, but it&#x27;s worked well there so far. reply cpursley 19 hours agoparentprevI agree and this is a good approach - and how we power the activity feed in our app. But it doesn’t solve the issue of “pushing the changes” out. Of course, you can always listen to the audit table WAL changes - best of both worlds. reply krashidov 14 hours agoparentprevIf you have a GDPR request to delete everything for a user, do you go through the audit table and delete everything related to that user? reply slotrans 7 hours agorootparentUnfortunately yes. reply PaulMest 20 hours agoprevI enjoyed this blog. I think it provides a great succinct overview of various approaches native to Postgres.For the \"capture changes in an audit table\" section, I&#x27;ve had good experiences at a previous company with the Temporal Tables pattern. Unlike other major RDBMS vendors, it&#x27;s not built into Postgres itself, but there&#x27;s a simple pattern [1] you can leverage with a SQL function.This allows you to see a table&#x27;s state as of a specific point in time. Some sample use cases:- \"What was this user&#x27;s configuration on Aug 12?\"- \"How many records were unprocessed at 11:55pm last night?\"- \"Show me the diff on feature flags between now and a week ago\"[1]: https:&#x2F;&#x2F;github.com&#x2F;nearform&#x2F;temporal_tables reply allan_s 20 hours agoprevIf you go the \"audit table\" path, just use \"pgaudit\" , it&#x27;s a battle-tested extension, that is even available on RDS if you use AWShttps:&#x2F;&#x2F;github.com&#x2F;pgaudit&#x2F;pgaudit&#x2F;blob&#x2F;master&#x2F;README.mdhttps:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonRDS&#x2F;latest&#x2F;UserGuide&#x2F;Appen... reply schlowmo 20 hours agoparentThere is also the temporal_tables extension [0], which was already discussed in HN. [1][0] https:&#x2F;&#x2F;github.com&#x2F;arkhipov&#x2F;temporal_tables [1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26748096 reply lhnz 21 hours agoprevI once consulted at a company with a very large monolithic SQL Server. It actually wasn&#x27;t Postgres but let&#x27;s pretend it was.It had been around for decades and over time it had ended up being used for all sorts of things within the company. In fact, it was more or less true that every application and business process within the whole company stored its data within this database.A key issue we had was that because this database had many different applications that queried it, and there were a huge number of processes and procedures that inserted or updated data within it, sometimes queries would break due to upstream insert&#x2F;update processes being amended or new ones added that broke application-level invariants -- or when a normal process operated differently when there was bad data.It was very difficult to work out what had happened because often everything that you looked at was written a decade before you and the employees had long since left the company.Would it be possible to capture changes from a Postgres database in some kind of DAG in order that you could find out things like:- What processes are inserting, updating or deleting data and historically how are they behaving? For example, do they operate differently ever?- How are different applications&#x27; querying this data? Are there any statistics about their queries which are generally true? Historically how are these statistics changing?I don&#x27;t know if there is prior art here, or what kind of approach might allow a tool like this to be made?(I&#x27;ve thought of making something like this before but I think this is an area in which you&#x27;d want to be a core Postgres engineer to make good choices.) reply agentultra 20 hours agoparentLogical replication, in Postgres, contains all of the information about the change statement (insert&#x2F;update&#x2F;delete) in order to logically recreate the same state in another database.You won&#x27;t get client-level providence data with each change...However you could hack around that. The logical replication stream can also include informational messages from the \"pg_logical_emit_message\" function to insert your own metadata from clients. It might be possible to configure your clients to emit their identifier at the beginning of each transaction. reply cpursley 21 hours agoparentprevI’m not sure how to handle queries, but for inserts&#x2F;updates I have a column that tracks the event source (last updated by). Maybe this is an anti-pattern - I’d love a more robust solution. reply drsopp 20 hours agoparentprevI had the following idea recently: Go through all scripts&#x2F;programs that send queries to the db and append a comment to the queey containing a unique id for that query that links it to the script&#x2F;program. The query log hopefully shows the comment with the id so you can trace the origin. reply NortySpock 14 hours agoparentprevFor the \"I just need to emit and visualize a DAG\" problem, at one point I wrote a python script that would filter for the relevant data, emit line-by-line mermaidJS-flavored markdown, and then shove that into an HTML file that imported the MermaidJS library.The MermaidJS solves for the DAG and visualizes it, and your browser has enough context to let you CTRL-F for any interesting phrases you put in the label. reply brightball 20 hours agoparentprevYou get a lot just by making sure each application has its own user access. reply rjbwork 20 hours agorootparentThis seems like the right approach to me.An approach I&#x27;ve taken is temporal tables w&#x2F; Application and UpdatedBy fields. That gives you a permanent record of every change, what application did it, and what user performed the action, at what time, and then lets you query the database as if you were querying it at that point in time. You can add triggers to fail CRUD if those fields are not updated if you want to get really paranoid.There&#x27;s a lot of overhead to this in terms of storage, so it&#x27;s not suitable for high-throughput or cost-constrained transactional systems, but it&#x27;s something for the toolbox. reply aidos 20 hours agorootparentprevEven if it doesn&#x27;t you can start by adding the application name to the connection string and you could probably do something gnarly with triggers to write that in a table and get it pushed in the logical replication. reply evntdrvn 18 hours agorootparentyeah, for SQL Server the connection string has an ApplicationName property for this purpose, it&#x27;s pretty useful :) reply cpursley 20 hours agorootparentprevThis is an interesting idea reply camgunz 16 hours agoparentprevI think it&#x27;s users + pgAudit. reply hobs 21 hours agoparentprevTechnically log replication has everything done by everything, and if you are careful with triggers you can also track everything as well, using a DDL&#x2F;DML capture table(DCL too if you&#x27;re worried!).These approaches work on basically every type of SQL solution that uses WAL&#x2F;triggers.For your specific question I have a trigger approach many times in SQL Server but it has a tendency to slow things down if you are logging every query so designing an insertion mechanism that doesn&#x27;t bog down production isn&#x27;t perfect, and you might want to perform some sampling. reply rpier001 21 hours agoprevRelax, don&#x27;t do it. When you want this, you&#x27;re turning the relations in postgres into a contract. No service gets to persist internal state. If you&#x27;re _really_ committed to domain driven design it could work... but you&#x27;d be better off with a light (but real) event driven system. reply slotrans 19 hours agoparentThe relations in the database _are_ a contract whether you like it or not.Event-driven anything is 1000x more complex. reply postgressomethi 21 hours agoprevPolling an updated_at column is not robust in its most simple form, as transactions are not guaranteed to commit in that order. reply _acco 21 hours agoparentAuthor here. Good point. For those that are curious, parent is referring to the following situation:1. Transaction A starts, its before trigger fires, Row 1 has its updated_at timestamp set to 2023-09-22 12:00:01.2. Transaction B starts a moment later, its before trigger fires, Row 2 has its updated_at timestamp set to 2023-09-22 12:00:02.3. Transaction B commits successfully.4. Polling query runs, sees Row 2 as the latest change, and updates its cursor to 2023-09-22 12:00:02.5. Transaction A then commits successfully.A simple way to avoid this issue is to not poll close to real-time, as the order is eventually consistent.Perhaps a more robust suggestion would be to use a sequence? Imagine a new column, `updated_at_idx`, that incremented every time a row was changed. reply postgressomethi 21 hours agorootparentSequences kind of have the same issue, because you don&#x27;t know if a gap is because of a rollback or an uncommitted transaction. Though with some logic you can do a pretty good job at this with sequences. And then you&#x27;re not in the realm of \"simple\" anymore, at all. reply _acco 21 hours agorootparentAny ideas for a simple polling implementation that&#x27;s more robust? reply qazxcvbnm 19 hours agorootparentI&#x27;ve had pretty much the exact same problem and what I went for in my low-volume case was to simply add advisory locks such that I can guarantee the transaction start times provide correct ordering. reply oconnore 14 hours agorootparentprevSet the trigger to add the primary key + change time to a separate table, then scan&#x2F;truncate that table to poll changes. reply farsa 19 hours agorootparentprevIt&#x27;s not exactly simple as it involves some postgres specific knowledge, but you can make it reliable when working with transaction ids (see https:&#x2F;&#x2F;event-driven.io&#x2F;en&#x2F;ordering_in_postgres_outbox&#x2F;). reply physicles 8 hours agoparentprevFor polling, instead of updated_at, I use a _txid column that gets set by a trigger to the current transaction ID. Then, when polling, use txid_current() to see which transactions have committed and which haven’t. It’s a little dicey and super easy to hit fencepost errors, but it’s been running smoothly in production for a few years. reply iknownothow 20 hours agoparentprevWoah, that&#x27;s news to me. Is that true even if triggers are used to update a column? CREATE OR REPLACE FUNCTION update_updated_at_function() RETURNS TRIGGER AS $$ BEGIN NEW.updated_at = now(); RETURN NEW; END; $$ language &#x27;plpgsql&#x27;; CREATE TRIGGER update_updated_at_trigger BEFORE INSERT OR UPDATE ON \"my_schema\".\"my_table\" FOR EACH ROW EXECUTE PROCEDURE update_updated_at_function(); END $$;Is it possible for two rows to have `updated_at` timestamps that are different from the transaction commit order even if the above function and trigger are used? It&#x27;s alright if `updated_at` and the commit timestamp are not the same, but the `updated_at` must represent commit order accurate to the millisecond&#x2F;microsecond. reply smilliken 17 hours agorootparentTo confirm your fear, you can&#x27;t use the updated_at timestamp as a proxy for commit order. The commits happen in a different order, and can be arbitrarily far apart, like hours or days depending on how long your transactions can last. reply singron 20 hours agorootparentprevnow() is the timestamp the transaction began at. There is no function to return the commit timestamp because you have to write the value before you commit. reply cpursley 21 hours agoprevOutstanding writeup.If you&#x27;re an Elixir & Postgres user, I have a little library for listening to WAL changes using a similar approach:https:&#x2F;&#x2F;github.com&#x2F;cpursley&#x2F;walex reply cultofmetatron 17 hours agoparentthis looks great. my startup is elixir based and I&#x27;ve been looking for something like this. reply physicles 8 hours agoprevThere’s a huge footgun with replication that the article didn’t mention, and it’s the reason why I don’t use it.Postgres is VERY committed to making sure a replication slot’s consumer doesn’t miss any data. This means that if a consumer stops consuming data from the slot, Postgres will helpfully store all that missed data… right up until the disk fills up and the database falls over. Had this happen during prototyping with two different SaaS DBs, and the only way to get it back up was to file a support ticket. (I can’t remember if metrics warned that the disk was about to fill up or not). Basically, if your replication slot consumer stops reading, that should trigger some kind of alert.The other reason I don’t use it: the code path to get the initial snapshot of a table is totally different from the code path to read changes. Initializing the read from the replication slot so you never miss any changes is nontrivial.It’s too bad, because replication is obviously the least hacky solution for change capture.I use polling, but storing the txid instead of updated_at. reply klysm 5 hours agoparentOne trick to deal with the first problem is sending logical decoding messages to yourself. That keeps the retained WAL low. Another potentially useful thing is temporary replication slots which clean themselves up on connection loss. I use those when I don’t need all of the changes. There is also configuration for setting the maximum WAL that’s retained so you don’t murder the server. reply _acco 7 hours agoparentprevI&#x27;ve run into this footgun before! It&#x27;s very subtle – you de-provision a consumer, and that feels like it should have no impact on the primary. But it creates a ticking time bomb.Mind expanding on how you use txid instead of updated_at? reply physicles 5 hours agorootparentSee my other comment over here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37610899#37619993 reply jhh 21 hours agoprevAll of those are kind of bad, polling being the most practical, imho.Would be great if Postgres innovated in this area. reply gen220 21 hours agoparentThere’s been attempts to revise the SQL standard to accommodate various types of temporality as a “first party” feature.I think that we won’t see traction at the RDBMS “kernel space” until it’s in the SQL standard. There are many valid and complex options to choose from, and there are successful solutions in user space that aren’t overly burdened, performance-wise, from being in user space.FWIW, the “audit table” approach is the approach that people who study this field gravitate towards. Mainly because it maintains consistent ACIDity in the database, and maintains Postgres as the single point of failure (a trade off vs introducing a proxy&#x2F;polling job). reply hughw 21 hours agoparentprevIs one second polling interval practical? reply benjaminwootton 20 hours agoprevI think there is a big gap in this space in the data world - having query results incrementally pushed to me rather than me asking the data store for them.I do a lot of work in real-time and streaming analytics. We can do stream processing and maybe some work in the datastore with a materialised view. However, once data has hit your database or data lake you are then effectively back to polling for changes further downstream.If I want to respond to some situation occuring in my data or update things on a screen without a page refresh then there isn&#x27;t really a clean solution. Even the solutions in this article feel hacky rather than first class citizens.Say I want to have a report updating in real time without a page refresh. The go-to approach seems to be to load your data from the database, then stream changes to your GUI through Kafka and a websocket, but then you end up running the weird Lambda architecture with some analytics going through code and some through your database.There is innovation in this space. KSQL and Kafka Streams can emit changes. Materialize has subscriptions. Clickhouse has live views etc. A lot of these features are new or in preview though and not quite right. Having tried them all, I think they leave far too much work on the part of the developer. I would like a library with the option of [select * from orders with suscribe] and just get a change feed.I think this is a really important space which hasn&#x27;t had enough attention. reply ris 16 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;pipelinedb&#x2F;pipelinedb reply synthmeat 20 hours agoparentprevMongoDB has had ChangeStreams for a long time now. reply benjaminwootton 19 hours agorootparentIs this a stream of changes to a query?I know the NoSQL world had some progress in this space. RethinkDB was going in this direction around a decade ago if I recall. I would really like this from a modern relational database or data warehouse though. Polling sucks. reply synthmeat 19 hours agorootparentYou can read more about it here https:&#x2F;&#x2F;www.mongodb.com&#x2F;docs&#x2F;manual&#x2F;changeStreams&#x2F;My feeling is that database needs to be built with replication in mind from the get-go to have something like this work well. reply irrational 19 hours agoprevThe main thing everyone always wants to know is whom to blame. Who added this store? Who changed the name of this store? Who deleted this store? The last one is particularly tricky - keeping audits of deleted things. Do you just soft delete everything? reply klysm 5 hours agoparentSoft delete is really hard to do well IMO, especially if it’s user facing. There have been some long threads on HN before about that. reply netcraft 20 hours agoprevWhat I would love is a turnkey service I could set up with logical replication and a straightforward configuration that can listen for any changes on certain tables (ideally with optional filters) that will take those changes and put them in a queue &#x2F; ESB &#x2F; whatever. If youre designing a new application from scratch and you have only one place that certain logical changes happen you can do this from the start. But in any system not designed that way from the start, the database is the place where all things go. Using that as your event source allows everything to keep on working like they always have but allow you to now notify new processes when something changes. reply cpursley 20 hours agoparentIf you&#x27;re using Elixir, check out https:&#x2F;&#x2F;github.com&#x2F;cpursley&#x2F;walexI&#x27;ve actually been thinking about turning this idea into a product where you can just point it at your postgres database and select the tables you want to listen to (with filters, like you describe). And have that forwarded to a webhook (with possibility of other protocols like websockets).I&#x27;d love to hear folks thoughts on that (and if it would be something people would pay for). And if anyone might want to partner up on this. reply chasers 17 hours agorootparentYo :D This is what Supabase Realtime does!https:&#x2F;&#x2F;github.com&#x2F;supabase&#x2F;realtimeSpin up a Supabase database and then subscribe to changes with WebSockets.You can play with it here once you have a db: https:&#x2F;&#x2F;realtime.supabase.com&#x2F;inspector&#x2F;new reply cpursley 17 hours agorootparentYeah, Supabase is awesome. In fact, WalEx originally started out as stolen code from realtime so I could do stuff right in Elixir (biz logic). reply evntdrvn 18 hours agorootparentprevWhat advantages does this have compared to Debezium? reply cpursley 18 hours agorootparentYou wouldn&#x27;t have to host it yourself (not everyone knows how or wants to run a heavy Java app).Add your database string, a couple extra migrations, your webhook endpoint - and you&#x27;re off to the races.Target customer would be low-code space (think admin dashboards on postgres, webhook integration tools). reply alibero 20 hours agoparentprevI used to work at Yelp, which had something that I think it similar to what you are describing called Data Pipeline (https:&#x2F;&#x2F;engineeringblog.yelp.com&#x2F;2019&#x2F;12&#x2F;cassandra-source-co...).I remember it being pretty simple (like, run one or two bash commands) to get a source table streamed into a kafka topic, or get a kafka topic streamed into a sink datastore (S3, mysql, cassandra, redshift, etc). Kafka topics can also be filtered&#x2F;transformed pretty easily.E.g. in https:&#x2F;&#x2F;engineeringblog.yelp.com&#x2F;2021&#x2F;04&#x2F;powering-messaging-... they run `datapipe datalake add-connection --namespace main --source message_enabledness`, which results in the `message_enabledness` table being streamed into a (daily?) parquet snapshot in S3, registered in AWS Glue.It is open source but it&#x27;s more of the \"look at how we did this\" open source VS the \"it would be easy to stick this into your infra and use it\" kind of open source :( reply bzzzt 19 hours agoparentprevSomething like Debezium? https:&#x2F;&#x2F;debezium.io reply joelhaasnoot 20 hours agoparentprev- https:&#x2F;&#x2F;hevodata.com&#x2F;- https:&#x2F;&#x2F;airbyte.com&#x2F;- https:&#x2F;&#x2F;www.stitchdata.com&#x2F;Unfortunately none of them are perfect as your data scales, each have up and downsides... reply ed_blackburn 17 hours agoprevIf you need to get data out as a feed and you need something robust, you almost always evolve until you land on the WAL option. The only problem with WAL is that many of us are (rightly) moving towards managed cloud sql instances such as AWS Aurora and then your options narrow. It&#x27;s a fair trade off, but for all the amaze of Supabase, Neon Cockroach et al a PG WAL to AWS native bus &#x2F; stream with filtering solution is sorely needed. Apologies if this already exists and I&#x27;ve missed it :) reply ruslan_talpa 17 hours agoparentIt exists [0] but does not seem to be that interesting to users[0] https:&#x2F;&#x2F;github.com&#x2F;subzerocloud&#x2F;pg-event-proxy-example reply brap 21 hours agoprevUnrelated to the article, but I gotta say I just learned about Sequin from this link, and it seems very cool! But, I can&#x27;t think of a use-case for it. Can you please explain the value-add? reply _acco 20 hours agoparentHey there, author here. We help our customers build their integrations faster&#x2F;easier by syncing API data with Postgres tables.Because your API data is in Postgres, you can query it exactly how you like. You&#x27;re not limited by the API&#x27;s supported query params, batch sizes, or rate limits. You can use SQL or your ORM.This also means you don&#x27;t need to learn all the API&#x27;s quirks. And every API we support has the same interface. (Which will become more valuable as we add more APIs!)So, the value is less code and simpler code. reply brap 19 hours agorootparentInteresting, thanks. Do you manage the DB yourself or do you sync it to customers&#x27; existing DBs? Does this play nicely with pg_graphq? reply _acco 17 hours agorootparentWe offer a demo Postgres instance for getting up and running. You can move the sync to your db when you&#x27;re ready for production. Therefore, should be compatible with extensions like `pg_graphql` (can&#x27;t think of customers using that extension, but we have quite a few using Hasura).Any other questions, feel free to email: anthony@[domain] reply ht85 20 hours agoprevUnless it has been updated, another caveat of LISTEN &#x2F; NOTIFY is that it becomes slower and slower the more NOTIFY you use within a transaction.If I remember correctly, the reason is that postgres attempts to de-duplicate messages using a naive quadratic algorithm, causing horrible slowdowns for large query with a FOR EACH ROW trigger.The way we mitigated that is by creating a temporary table and write the notification payloads. An AFTER * trigger reads distinct rows, groups the data and sends the messages. reply cpursley 20 hours agoparentThere’s also an 8000 character limit which is why we went to the WAL approach. reply maxbond 18 hours agoprevThis episode of the Postgres.FM podcast may also be of interest (it&#x27;s about implementing queues in Postgres).https:&#x2F;&#x2F;postgres.fm&#x2F;episodes&#x2F;queues-in-postgres reply maxbond 18 hours agoprevI didn&#x27;t see what imho is a significant LISTEN&#x2F;NOTIFY caveat, which is that it is sticky to a session. As such, it requires a dedicated connection - eg, it isn&#x27;t compatible with pgBouncer in transaction mode. reply jwsteigerwalt 20 hours agoprev [–] Listen&#x2F;Notify Is an underrated tool. reply klysm 5 hours agoparent [–] Not sure I agree, it’s got some really annoying footguns and limitations. I’ve found much more success with logical replication. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article analyzes different methods for tracking changes in a Postgres database: Listen/Notify, direct table polling, replication, and using an audit table.",
      "Each approach is scrutinized for its advantages and complexities to provide valuable insight.",
      "The article endorses replication as the most potent technique, with leveraging an audit table recommended as a preferred alternative."
    ],
    "commentSummary": [
      "The discussion focuses on optimal methods for monitoring and recording changes in a Postgres database, with recommendations such as using triggers, history tables, and relying on the database clock for precision.",
      "Extensions like \"pgaudit\" or \"temporal_tables,\" logical replication, and trigger functions have been suggested; however, concerns over performance and storage requirements persist, highlighting a demand for improved and reliable change tracking methods in database systems.",
      "Tools like Debezium are recognized while addressing the constraints in using LISTEN/NOTIFY feature in PostgreSQL."
    ],
    "points": 288,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1695384402
  },
  {
    "id": 37612968,
    "title": "Working remotely can more than halve an office employee’s carbon footprint",
    "originLink": "https://www.scientificamerican.com/article/working-remotely-can-more-than-halve-an-office-employees-carbon-footprint/",
    "originBody": "Scientific American Temporarily Unavailable We have detected some suspicious traffic, please try again later. Scientific American is part of Springer Nature, which owns or has commercial relations with thousands of scientific publications (many of them can be found at www.springernature.com/us). Scientific American maintains a strict policy of editorial independence in reporting developments in science to our readers. All Rights Reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=37612968",
    "commentBody": "Working remotely can more than halve an office employee’s carbon footprintHacker NewspastloginWorking remotely can more than halve an office employee’s carbon footprint (scientificamerican.com) 274 points by rustoo 19 hours ago| hidepastfavorite220 comments ipnon 18 hours agoRemote work seems like one of many missed “Jetsons opportunities.”[a] Why wouldn’t we, given the ability, work from our own comfy homes instead of rolling into a crowded, stuffy office everyday? Why isn’t this practice that workers clearly love, and are willing to leave companies to keep, seen as a great step in the progress of labor? We should be counting our blessings instead of counting beans, that such a way of working is even possible today.[a] A Jetsons opportunity is any missed prediction of the future from the past, usually in a form like “where’s my flying car?” reply Balladeer 17 hours agoparentI understand and even expect the lack of empathy from RTO executives, but the lack of empathy on the part of the &#x27;remote work for everyone, always&#x27; camp saddens me.I&#x27;ve worked primarily remote since 2016; but I have the option of going to an office a few miles away when I want to. My wife, forced to work from home, finds the entire experience to be socially isolating and misery inducing.> work from our own comfy homes instead of rolling into a crowded, stuffy office everyday?This one-sidedness is a strawman. Not everyone&#x27;s home is comfy or has space for working; some people made housing decisions based on one person leaving the home for most of every day (e.g. choosing a smaller apartment closer to city). Not every office is crowded and stuffy; some are quite pleasant. Not every worker gets their social needs met outside of work, and forcing them home ends up isolating them from the primary source of social interaction in their world, with all of the mental health and well-being issues that entails.Personally, think that \"more remote work\" is the way to go, but the issue is more nuanced than \"why are people resisting this obviously beneficial change?\" reply paulryanrogers 17 hours agorootparentWork is not voluntary, there are no alternatives. Unlike other social opportunities in ones free time. So folks who can&#x27;t get their needs met from remote work can still remote work and find fulfillment elsewhere.Folks forced into an office cannot choose to opt out of all work. Changing jobs is a bigger lift than picking up some social hobby or activities after work.I agree hybrid can be nice, yet executives are too often demanding RTO compliance. That&#x27;s why there is so much breathless enthusiasm for remote work, and angst against attempts to both-sides the issues. reply Gud 16 hours agorootparentBut some people need to be around other people more or less all the time to be happy. For them finding fulfillment off hours is not going to cut it.Personally, I would probably be happiest with a remote office situation. reply temende 15 hours agorootparent> But some people need to be around other people more or less all the time to be happy.That&#x27;s fine, but no one is obligated to spend time with them. They need to be more convincing or charismatic then to get people to spend more time with them. \"If you don&#x27;t endure a commute to spend time with me, I won&#x27;t be happy\" won&#x27;t cut it. reply pfannkuchen 14 hours agorootparentThis view is too zoomed in. The human organism generally expects other humans to be around. Solitude in nature is a death sentence for humans, so our organism provides inbuilt incentives to avoid solitude. We can’t turn this instinct off, except to partially anesthetize it via fake social interaction like television, podcasts, etc. The anesthesia works better or worse for different people.Some people have convinced themselves that they don’t like social interaction, but this is probably due to a trained negative association caused by repeated past negative experiences. It seems very unlikely that some humans simply lack the social instinct congenitally.Society is currently set up in a way that social urges are largely satisfied by work. Is that a good setup? No, it definitely isn’t. Is deleting it without a proven replacement a good idea? Also no. reply temende 14 hours agorootparentMy point is that there are many other, more fulfilling ways to get human company than forcing your co-workers to commute to the office everyday. Besides, for the many people who live with a family&#x2F;kids&#x2F;partner, WFH lets them spend even more time with them. The solution for people whose only source of social interaction is the office is to develop a social life outside of the office, not to force everyone else into RTO. reply paulryanrogers 14 hours agorootparentprevRemote advocates by and large aren&#x27;t arguing for abolition of offices. Only a choice.And remote work can also be done from co-working spaces. Or with occasional all-hands IRL. reply tmpX7dMeXU 10 hours agorootparentThis is simply a non-starter. I have not witnessed a single work environment where long-term remote workers don’t effectively become second-class citizens against in-person workers on the same team, in a way that materially harms productivity. reply thorncorona 14 hours agorootparentprevHow cold this world is to cut out communal spaces and force us to spend 40h&#x2F;w in solitude. reply temende 14 hours agorootparentNot everyone is a single tech employee who lives alone. Some (in fact, many) people have a social life outside the office where not going to an office doesn&#x27;t result in eternal solitude. reply thorncorona 11 hours agorootparentdo i need to add the &#x2F;s reply blooalien 5 hours agorootparent> \"do i need to add the &#x2F;s\"Sadly, probably yes. This is the \"age of outrage\" after all. reply shrimp_emoji 12 hours agorootparentprevI don&#x27;t believe you. reply bugglebeetle 14 hours agorootparentprevHow cold the world is to make the primary form of communal spaces be working in the rigid hierarchy, abuse, and discomfort of the modern American workplace. reply tmpX7dMeXU 10 hours agorootparentI don’t live in America. How cold the world is that you lot resign yourselves to the expectation that you’ll resent your coworkers and employer. reply bugglebeetle 10 hours agorootparentI recommend the 1999 American film “Office Space” or the 2003 British television series “The Office” if you somehow think this is a novel sentiment. Or “Bartelby the Scrivener” by Herman Melville from 1856. replypaulryanrogers 14 hours agorootparentprevPerhaps that&#x27;s a niche for co-working spaces? Or mid-level management which can get an _optional_ office for others so inclined? reply RestlessMind 15 hours agorootparentprev> So folks who can&#x27;t get their needs met from remote work can still remote work and find fulfillment elsewhere.How? If my remote work makes my employer schedule 2 hrs of extra zoom meetings and the workday is now 8-6 instead of 9-5, how can I find fulfillment elsewhere? In that scenario, office seems better because I get to hang out with other people between 9-5. Remote is much worse if one likes to socialize. reply bart_spoon 15 hours agorootparentIf your employer is increasing the workday to 8-6 due to Zoom calls then you are in the minority and that is an issue with your employer, not remote work. reply tarsinge 16 hours agorootparentprev> but the lack of empathy on the part of the &#x27;remote work for everyone, always&#x27; camp saddens me.You are making the straw man here. People are mostly asking for a right to work remotely if they want to, that&#x27;s all. And the status quo until very recently was (and still is) the opposite: not allowing remote work for people who want it, without any empathy for their needs. Try not to read it as an attack on the office, but more as millions of people asking for not being forced to commute and go to the office for a miserable experience. reply UtopiaPunk 14 hours agorootparentprevI generally think that we, as a society, should prioritize happiness and human flourishing. Work-from-home has been great for me, but I understand why others wouldn&#x27;t enjoy it.Workers should have a strong say in how they spend their 40+ hours a week, but we have a society where petty tyrants get to control their workers&#x27; lives. It should be easier to form worker-owner cooperatives and to organize strong unions, and generally promote more democracy in the workplace. And we should, as a society, de-emphasize work a bit. With all the automation we have, most people should be able to work a 32-hour work week and society would clip along just fine. Meanwhile, people would have more time to devote to the rest of living a life (pursuing art, socializing with friends&#x2F;family, volunteering in social projects, studying an interesting subject, etc).That&#x27;s all to say, we are all individuals with different wants and needs, and we spend a lot of time at our jobs. We should restructure society to make us all happier and more fulfilled. reply bugglebeetle 14 hours agorootparent> Workers should have a strong say in how they spend their 40+ hours a week, but we have a society where petty tyrants get to control their workers&#x27; lives.To be fair, this is especially egregious in the United States, where urban design is incredibly hostile and workers have long commutes because of distortionary policies to boost car sales and maximize returns on real estate speculation. Likewise, workers have so few protections and paid leave relative to other developed countries.I probably wouldn’t care about going into the office in a nice, walkable European city, where I didn’t live in constant fear of being fired, be unable to take sick days, or be constantly forced to work over 40 hours, rarely take vacations, etc. But if you’re going to design society around maximizing my misery to make as much money as possible for someone else, I’m sure as hell not going to want to go into work if I can do my job from my couch with my dog beside me. reply smileysteve 15 hours agorootparentprev> My wife, forced to work from homeYour wife is not \"forced\" to work from home. She is forced to find her own work accommodations. At the extremes of requiring a dedicated IP address and fiber connection, it&#x27;s still an option to rent an office space individually. At the less extreme: an individual membership at a coworking space, likely a public library, or a coffee shop. Similarly, whether at home, at a office, or at a coworking space she is not forced to be socially isolated or miserable. reply UtopiaPunk 14 hours agorootparentThere are also, frankly, a lot more jobs out there where 100% remote isn&#x27;t even an option. Maybe they should consider changing jobs? 100% WFH is a dream for a lot of people, so let someone else have that spot reply LeifCarrotson 16 hours agorootparentprevIt&#x27;s always more nuanced, but headlines don&#x27;t have room for that.If you advocate for \"mostly remote work, with hybrid scheduling and hot desking as needed\", some unempathetic execs and clueless middle micromanagers are inevitably going to try to turn that into a privilege to be allowed to work from home once a month. You have to open the negotiation by demanding full remote, so there&#x27;s room for concessions allowing a few satellite campuses and occasional all-hands meetings. reply RestlessMind 15 hours agorootparent> unempathetic execs and clueless middle micromanagersWhat about clueless employees who think remote is great for their needs but is actually counterproductive to what the company needs? reply orwin 25 minutes agorootparentThe employee only have to care about their work and paycheck. Is they were paid to accommodate company needs, CEO wouldn&#x27;t be paid 500 times the media pay and C-suite wouldn&#x27;t be paid 100 times what I earn. reply sam0x17 5 hours agorootparentprevThere is more to life than work and it should never be your entire or even most of your social life. Being socially isolated as a result of not having to go to work is a pretty good sign that your entire existence revolves around your work. Go outside, make friends, have a social life outside of work. It doesn&#x27;t and shouldn&#x27;t have to rule your world.On the flipside, it&#x27;s pretty sick that we&#x27;ve normalized getting all of one&#x27;s social fulfillment from wage slaving rather than genuine social experiences that don&#x27;t involve exploitation of our labor. reply dfxm12 16 hours agorootparentprevthe &#x27;remote work for everyone, always&#x27; campLMAO, and you&#x27;re the one complaining about strawmen? Give me a break. reply layer8 17 hours agoparentprevI have a nice office at work, where I have less distractions than at home. Face to face meetings allow for better discussions and whiteboarding than video conferencing. I can commute by bike on nice route, thus getting regular exercise and fresh air. I can better compartmentalize work from leisure. I don’t have to spend my whole day within the same walls. I get to see other people and have random encounters with interesting technical and non-technical discussions at work.So it depends on circumstances and preferences. Both modes should be possible. reply randomdata 16 hours agorootparent> Both modes should be possible.I am not sure there is more than one mode. Remote work isn&#x27;t about working from home, it about working from wherever you want. That necessarily includes working from an office, if that is what you want. reply layer8 16 hours agorootparentThat’s an interesting definition of “remote”. Remote-work companies usually don’t have offices. If remote work became the new norm, employees would be forced to arrange for a working space on their own, removing the choice. reply randomdata 16 hours agorootparentI agree that remote is interestingly defined. Remote normally refers to somewhere away from where the population is found or away from where one is usually located. Home is where the population is found – where one is usually located. The office is what is remote.It is bizarre that the companies without offices – with workers most likely to work from home – are the ones given the \"remote\" moniker. Technically, it is the companies with offices that are most likely to have remote workers. reply atomicnumber3 18 hours agoparentprev>We should be counting our blessings instead of counting beansIn America, we generally treat exclusively counting the beans as a literal capital-V Virtue. And there are hordes of lumpenproletariat who will vehemently defend it when any thought is paid to not exploiting workers to the maximal extent possible where there is even the slightest hint of perceived additional beans to be acquired. reply Aerroon 17 hours agoparentprevI think a lot of people are less productive when they work from home. It&#x27;s easier to switch into \"work mode\" when there&#x27;s a specific physical location where you only work.A separate room as a home office probably has the same benefit though. reply munk-a 17 hours agorootparentThat&#x27;s a fair hypothesis and intuition... that has not been apparent for the majority of people. Some folks really do benefit from an office setting and I think we should support those people by having such a setting still available... but I&#x27;m going to keep dancing to thumping techno in my bathrobe as it makes me far more productive reply thegrim33 17 hours agorootparentThe very fact that companies are doing everything they can to bring people back into the office refutes your comment. Do you really think if people were as&#x2F;more productive at home that companies would throw that increase in productivity away? It&#x27;s so funny that half the comments on the topic are about how evil and money hungry companies are, but at the same time they&#x27;re supposedly choosing to throw away free money? It&#x27;s nonsensical. Just another political echo chamber social war. reply munk-a 17 hours agorootparentBasically yes - I think that a fair number of companies would throw away that increase in productivity purely for a sense of control. Companies do dumb stuff all the time and I&#x27;ve personally worked under an \"asses-in-chairs\" style owner who assumed that if you went for a walk to get a coffee with a coworker while having a technical discussion your productivity was 0. A lot of people are dumb and there are no secret smart people at the tops of companies making smart decisions - companies are ruled by majority and the majority is usually quite easily influenced by marketing campaigns (i.e. the ones launched by commercial real estate holders who are currently losing money hand over fist). And, just for reference, companies are also evil primarily because they&#x27;re dumb and petty and there is a constant struggle for fiefdoms within the budget.I think a fair number of people struggle with imposter&#x27;s syndrome because they imagine that somewhere above them there&#x27;s someone that is really really smart and has a plan - no such person exists, we&#x27;re all just trying our best... and that \"all\" is all-inclusive - the person you remember who got D&#x27;s in middle school is probably a middle manager somewhere. reply RestlessMind 15 hours agorootparent> I think that a fair number of companies would throw away that increase in productivity purely for a sense of control.Citation needed. This seems like a really bogus claim which assumes decision makers don&#x27;t know what&#x27;s best for themselves. reply munk-a 15 hours agorootparentThe asses-in-chairs owner I mentioned briefly had us discount time we spent on coffee breaks or on walks from our daily hours... exercise tends to encourage brain activity and for me specifically (I have ADHD) it has an extremely strong effect. Things slowed down for a while before senior management stepped in and said \"Enjoy your coffee breaks and walks on the company time - be healthy!\"This is absolutely an anecdote - but I&#x27;m not certain how else to source data around this. reply 26fingies 17 hours agorootparentprevYou have to remember that companies are run by people and people have incentives that are not always aligned with the company.For example if you are a very wealthy person who runs a large company you need to put that money somewhere and that somewhere may be real estate. In fact it may be real estate in a city such as San Francisco. Prior to covid and work from home that was a very good place to keep your money, but today it’s a lot less good. Companies themselves may have significant real estate investments as well. There are more inputs to this than productivity (and real estate for that matter but it was the first example that came to mind) reply SamoyedFurFluff 16 hours agorootparentprevI personally think yes, upper management will prioritize nonsensical behaviors that incentivize their own self aggregation over the betterment of the company. This is sort of mindset is also behind shit like “don’t hire women, I might be tempted to sexually assault them” rhetoric. reply chasd00 16 hours agorootparentprev> Do you really think if people were as&#x2F;more productive at home that companies would throw that increase in productivity away?I think the main reason is all those expensive office towers are now sitting empty and no one wants to buy them. I bet 75% of RTO is sunk cost fallacy trying to make use of all that leased empty space. reply j4yav 17 hours agorootparentprevI guess you&#x27;ve been lucky to never have a bad manager? I can think of plenty of times in my career that corporate leadership was short-sighted. From terrible managers who think their job is to ensure butts are in seats, to turf battles that make the company worse off, and so much more. Awful behavior, but nothing that provides being money-hungry and sociopathic at the same time. reply bit_logic 14 hours agorootparentprevWe don&#x27;t need to guess at this, companies like Amazon already admitted there&#x27;s no data to support RTO:https:&#x2F;&#x2F;www.businessinsider.com&#x2F;amazon-andy-jassy-no-data-re...https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;08&#x2F;03&#x2F;amazon-svp-mike-hopkins-offic... reply kcplate 10 hours agorootparentI say this out here whenever this comes up…but if we are truly being honest there really is no hard data out there to support that WFH benefits the organization. All of the arguments and anecdotes I hear are specific to the individual. If you can’t support your argument with data against the people who get to make the decisions where you work, you can’t really blame them for going back to a historical work environment that made them successful in the first place.I always caveat this idea with the fact that I love WFH and do not want to RTO, but I can’t make an argument why it’s better for my organization. reply pandaman 11 hours agorootparentprevDon&#x27;t know about Amazon, for all I know about their disfunction they could be actually running the company without any performance statistics. But, say, Goldman definitely has these statistic since they pay bonuses based on them and it is pretty aggressive in RTO. I imagine Amazon has statistics too but they just don&#x27;t want to publish them, afraid (rightfully so, IMHO) of what that will do to their stock price. reply TigeriusKirk 17 hours agorootparentprev>t. Do you really think if people were as&#x2F;more productive at home that companies would throw that increase in productivity away?Yes, I do.Also, I don&#x27;t think the vast majority of office-based companies have any idea what their actual productivity levels are. reply bart_spoon 14 hours agorootparentprevThere was recently some research showing that people working for only 4 days a week instead of 5 were equally&#x2F;more productive, and yet you don’t see companies rushing to implement a 4 day work week.Your assumption is flawed on a number of levels, first and foremost due to the fact that it is based on the faulty premise that companies will always make optimal decisions based on perfect data, when the reality is:- in most cases the data on whether remote work is more or less productive is murky at best, non-existent at worst. For ever study showing and increase&#x2F;decease in productivity there is a study showing the opposite. Most companies struggle to even define and measure productivity in the first place, outside the context of remote work. - productivity isn’t the sole axis of decision making. Some companies prioritize excellent benefits to retain talent in the belief the benefits of a happy talented workforce will outweigh the costs of providing it. Other companies are much less generous, happy to churn through less competitive employees to keep costs down. Similar disagreements on remote work exist, which is why there are many companies with no plans to mandate in office work - what company leadership prioritizes is not necessarily what is best for the business. I’m not sure how anyone, after 40 years of Jack Welch-style executives destroying long-term business value for short-term profits, would fail to recognize this. Company leadership will do what is in company leadership’s best interest, whether that’s cutting long-term profits for short term share price increases that are tied to personal compensation, exorbitant spending for unnecessary company amenities like private transportation, or dictating the workforce comes back into the office because they prefer to work that way. Note when outspoken critics of remote work like Elon Musk, personally, almost exclusively work remote. reply belter 14 hours agorootparentprevProductive in the Office? You are surely joking? reply pc86 17 hours agorootparentprevI do the exact same amount of work now that I did in an office, except now I can just watch a video on YouTube or an old episode of Veep or something if I want to take a break, rather than looking at my phone for a few minutes wondering if someone is going to tap me on the shoulder.I literally saw a coworker sleeping in his cubicle, and had I not woken him up he probably would have gotten fired that day when our boss walked in maybe 90 seconds later. Offices are not the meccas of productivity the RTO crowd would like us to believe. reply bravetraveler 17 hours agorootparent> Offices are not the meccas of productivity the RTO crowd would like us to believe.Indeed - just today I joked with my manager that being forced on-site has perks; aimlessly wandering&#x2F;engaging people looks like productive work.You can run a gambit with this; nobody expects you to be able to really prove Useful Conversations happened. reply breischl 16 hours agorootparent>aimlessly wandering&#x2F;engaging people looks like productive work.Indeed, even though it might actually be _negative_ work, if one of those people would have otherwise been productive. Which was one of my major gripes with being in the office. reply bravetraveler 16 hours agorootparentThat negative work is so true. Like you, that&#x27;s my main complaint.I&#x27;m a local celebrity due to putting out all the Big Fires - so now, whenever people see me on-site as a trapped&#x2F;captive audience, I hear about every hint of smoke.Thankfully our mandates are currently more... suggestions, giving credit to the \"layoffs but not really\" story IMO.It&#x27;s annoying to even re-negotiate. I&#x27;ve been remote for years, pre-pandemic, only appearing when required. reply pawelduda 16 hours agorootparentprevYou have a separate room at home and that&#x27;s where you switch to work mode. Some people don&#x27;t even need that, just an environment free of interruptions. No need to overthink it, both home and office are a \"physical location\" reply RestlessMind 15 hours agorootparent> You have a separate room at home and that&#x27;s where you switch to work mode.Ironic to see this comment in a discussion about carbon footprints of remote work. Separate rooms do not come from free - they also have a high carbon cost in terms of bigger house, more heating&#x2F;cooling, most likely suburban setting which has its own carbon costs etc. reply sottol 15 hours agorootparentBut does that room come at a higher carbon cost than commuting to the office (45mins each way(!) afair on average in the US) and having an office building that&#x27;s entirely empty at night. That building needs maintenance, gardening, cleaning, ... reply thefz 15 hours agorootparentThe gas engine in a car surely comes with a stellar carbon cost compared to heating another room in the house. reply pawelduda 14 hours agorootparentThen maybe work from home but in your car is the answer reply lotsoweiners 13 hours agorootparentprevYeah but I already have the room and it is being cooled&#x2F;heated whether I’m there or not. Driving 25 miles each way to the office on the other hand is something that I stopped doing completely once my work started letting me WFH full time. reply pawelduda 14 hours agorootparentprevSo having a small room at home dedicated for work is bad? I don&#x27;t really get it. How is office different, cooling&#x2F;heating isn&#x27;t needed there? reply thefz 15 hours agorootparentprev> I think a lot of people are less productive when they work from home. It&#x27;s easier to switch into \"work mode\" when there&#x27;s a specific physical location where you only work.I switched from a clearly defined (imposed) lunch break with multiple intra day whole floor coffee breaks to working straight 10 hours with a break when I can slip into the kitchen and I feel I am both more productive and happy when working from home.The point is not on the clock hourly days of work but rather being treated like an adult and trusted. reply ar_lan 17 hours agorootparentprevI&#x27;m really, really curious about this data, because I can only extrapolate from personal anecdata.I&#x27;ve personally measured this for myself and WFH is overwhelmingly more productive for me, measured via sheer output. I think part of this is because I&#x27;m naturally just working... longer? It&#x27;s a mind shift, but this was generally my stance when I was in office too, which is:1. When I&#x27;m in office, those are my working hours. Unless there was a very critical crunch period, I did not work at home at all. It was a very strong boundary.2. I was very diligent about keeping my office hours - partially because of traffic. So I&#x27;d put in my 8 hours, often skipping lunch, and go straight home. 7am-3pm every day.3. When you&#x27;re in the office, people really love impromptu meetings. So a good chunk of the day is used talking to people. Sometimes this is productive, but often it just means the project you are working on gets 1-2 less hours that day than it would otherwise.--Contrast this with WFH:1. My commute was 1 hour both ways (Bay Area), which is now gone. I usually work in the range of 7am - 5pm now. I take a break for lunch and to go for a run. Ultimately, I end up working 8.5-9 hours now (a .5-1 hour increase in duration), but I&#x27;m actively healthier because I can take a break + exercise.2. Because my desk is always setup, I end up doing more sporadic tasks - especially when it comes to long, async build processes, I&#x27;m more inclined to quickly debug something and run a pipeline again. Before I just left my laptop in my bag, and couldn&#x27;t (wouldn&#x27;t) be bothered to pick it up.3. Sporadic meetings are non-existent. Slack is async, so I just check it a few times a day. I can control my time much better meaning actual focus on a task is possible - which is nearly impossible in an office environment.Not to mention just the overall quality of life improvements from being able to eat lunch with my wife and daughter, be able to take appointments and slightly shift my calendar, be flexible in where I am (we can actually visit family not on weekends now!). Also I save about $5k&#x2F;year by not driving all the damn time. Also, my company could save money by just not leasing their office anymore...I&#x27;m happier, healthier, more energetic, and thus ultimately more productive remote. In office work sets stronger barriers, sure, but returning to the office will mean that&#x27;s where I leave my work too. To satiate someone&#x27;s requirement for social interaction through coworkers is bizarre to me.--Anyway - that&#x27;s my personal view. I&#x27;m curious what actual macro data shows. Perhaps I&#x27;m one in a million - but I doubt it. reply mattw2121 18 hours agoparentprevExcept, didn&#x27;t the intro to the Jetsons have George headed to the office every day? reply nedrylandJP 18 hours agorootparentYes, and when he got there he put his feet up and closed his eyes.https:&#x2F;&#x2F;youtu.be&#x2F;0JQbeCAlF6s?t=61 reply drekk 17 hours agorootparentprevWhat does it say about our culture that futuristic media envisioned flying cars and robotic servants but not an altered labor arrangement? reply trgn 17 hours agorootparentModernism. Infatuation with the transformative power of technology. It transfers responsibilities of political participation (what it means to be a citizen) to a mechanistic, consumptive process (what it means to be a consumer). Could not exist without mass manufacturing (without which technology cannot fulfill its telos) or mass media (without which humans would not submit to this ideology). reply MattPalmer1086 16 hours agorootparentprevI&#x27;m not sure it says anything about our culture specifically. It speaks to all cultures.The future is always going to be what we have now, but sexier in some way. So replace cars with flying ones, and replace work we do with robotic servants.The really interesting science fiction doesn&#x27;t do a linear extrapolation, it looks at how we might really change. But that&#x27;s not what we get from a kid&#x27;s cartoon. reply j4yav 16 hours agorootparentprevAnd, while we are at it, what&#x27;s up with the Flintstones and dinosaurs and humans living side by side. If that isn&#x27;t commentary on the sorry state of academic culture I don&#x27;t know what else is. reply joquarky 7 hours agorootparentFlintstones is based in the future, not the past ;-)Also, do cassowaries count as dinosaurs? reply 0cf8612b2e1e 17 hours agorootparentprevIt was a kid’s show. I doubt it was meant to be a cutting commentary on social structures. reply fknorangesite 16 hours agorootparentprevYes, that&#x27;s what they&#x27;re saying: that the Jetsons completely missed this prediction. reply robertlagrant 18 hours agoparentprev> Why isn’t this practice that workers clearly love, and are willing to leave companies to keep, seen as a great step in the progress of labor?It&#x27;s better to think of people as individuals, and not as \"labor\" or \"not-labor\". I think remote working is great for this, much better than top-down mandates on cars and congestion zones, although those swell the tax coffers nicely, but I don&#x27;t think it&#x27;s a great victory. Lots of people (particularly those who do actual physical labour, such as builders and shopkeepers) have to go to a workplace. It&#x27;s not a victory for them, because lumping people into tribes means category errors abound. reply lotsofpulp 17 hours agorootparentWhy is it not a victory for them? Less congestion on the roads, higher prices for their labor since WFH work is more attractive. reply ghaff 17 hours agorootparentFor the shopkeepers and others who provided services for the office workers… fewer jobs. reply lotsofpulp 17 hours agorootparentIf society wants to make jobs, there is tons of trash to pickup. And infrastructure to maintain&#x2F;build. reply ghaff 16 hours agorootparentOh I’m not saying people should go back into an office because of the retail and restaurant workers. It’s just this isn’t good for those workers as an upstream comment seemed to suggest. reply pc86 17 hours agorootparentprevGood luck getting people to drop the \"labor\"&#x2F;\"not labor\" schtick when you literally have people here using Marxist language to describe working from home vs. commuting into an office like it&#x27;s the 1800s. reply kibwen 16 hours agoparentprev> one of many missed “Jetsons opportunities.”This isn&#x27;t a missed opportunity, it&#x27;s just an opportunity. Large-scale remote work wasn&#x27;t feasible prior to the advent of the web and the personal home computer in the 90s, and realistically wouldn&#x27;t have happened prior to the mass penetration of the internet and the computerization of everything circa 2005&#x2F;2010. It just so happened that the covid pandemic occurred at approximately the exact moment in human history where mass remote work was even an option (and obviously is still limited to people in knowledge sectors). reply dublinben 7 hours agorootparentFor most of recorded history, people also worked from wherever they lived, largely in agriculture. The protoindustrialization that emerged in the 16th century saw rural residents performing many new industrial tasks beyond subsistence farming. During slow parts of the season they earned extra money by spinning wool or weaving and washing cloth.The urbanization driven by the Industrial Revolution of the 18th century didn’t tip the balance to a majority of the US population living in cities until 1920. Other countries were even further behind.Work From Not Home is the actual historical anomaly here. Information technology allowing people to perform their 21st Century, postindustrial knowledge work at home is just reversion to the mean. reply ianburrell 16 hours agoparentprevOne issue is that lots of people don&#x27;t have the work space at home. It takes a lot of privilege to have an extra room for office. Lots of people managed to work from other places in house during pandemic because they had to.Coworking spaces are one solution. But many disappeared during the pandemic. Also, somebody needs to pay for them. I bet we&#x27;ll see a lot more of them using the empty commercial space. But they will work best near residential areas. reply maximinus_thrax 16 hours agoparentprev> Why wouldn’t we, given the ability, work from our own comfy homes instead of rolling into a crowded, stuffy office everyday?Because a considerable part of our economy apparently relies on people getting out of the house, (mostly) driving somewhere, buying their lunch (and other stuff) and temporarily occupying some landlord&#x27;s building. reply screye 16 hours agoparentprevIt&#x27;s especially annoying when your job only needs 3-5 meetings every week. If a task can be fully explained in a ticket, and the architectural design has already been done by someone higher up, then why do you need to see the foot soldiers working. Either the work gets done or it doesn&#x27;t.I understand 1 day in the office, but 3-5 days&#x2F;week is madness. Doubly so in places where the commute is upwards of 1 hour in each direction. M reply srackey 17 hours agoparentprevBecause it just doesn’t seem to work (in aggregate, it may work for you, but not the firm, and not the firm over an indefinite time span). reply Centigonal 17 hours agorootparentThe research on this is very mixed, and in many cases has found that remote workers are more productive than their office-bound counterparts. Anecdotally, I&#x27;ve found some organizations work great fully remotely, while others require in-person presence at least some of the time.https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41562-021-01196-4https:&#x2F;&#x2F;bfi.uchicago.edu&#x2F;insight&#x2F;research-summary&#x2F;time-savin....https:&#x2F;&#x2F;academic.oup.com&#x2F;qje&#x2F;article-abstract&#x2F;130&#x2F;1&#x2F;165&#x2F;2337...https:&#x2F;&#x2F;www.nber.org&#x2F;papers&#x2F;w31515 reply feedsmgmt 17 hours agoparentprevThere are people who make a lot of money from the consumption of gas and tires and oil. Also the manufacturing and selling of automobiles. Those people make a lot of financial contributions to politicians and sometimes become politicians themselves. reply _jal 17 hours agoparentprevMy company went fully remote. Moved the office out of SF proper to avoid the Twitter Tax and downsized it, now it can only hold about half the locals, and most days nobody goes in.At the same time, we started hiring without geographic concern. The mandate became get the best folks you can, we don&#x27;t care where they are[1].It has worked out well for us. We&#x27;ve gone heavily international, and grown our customer base and expanded markets at a slightly faster faster pace than we were before going remote. (I don&#x27;t think going remote did that - more capital and people did. But it didn&#x27;t hurt.)And maybe we&#x27;re just selecting for folks who like remote work now, but I don&#x27;t know of anyone who wants to go back to the old days.[1] With some exceptions, some managers want people in the same timezone, some roles are inherently place-bound, etc. reply foobarian 17 hours agorootparentMaybe a part of the problem is that the two work patterns are suitable for much different personalities, but when switching from all-in-office to remote, the mix of personalities leads to lower aggregate productivity. E.g. someone who needs a periodic tap on the shoulder (nothing wrong with that, I&#x27;ve known plenty of people like this) might do very poorly in a much more loose environment. Of course it could be argued that this is a badly executed remote switch, which could be worked on, but still - I&#x27;d guess that when starting out hiring for full remote, you preselect a group that works well in that environment. reply Maultasche 17 hours agorootparentprevMy company had a similar experience. They were a smaller Bay Area company only hiring locally, then went remote and expanded their candidate search. They were able to get a much better selection of candidates after they started hiring remotely.Any kind of return to office is now impossible. Their (now much smaller office) can only hold about 5% of the employees, and the vast majority of employees are now scattered throughout the United States. Not even the founders or any of the executives live near the office anymore; they&#x27;re all scattered geographically as well.I was hired as part of the wave of remote hiring, and it seems to me based on the stories I hear from those that worked there in the pre-remote times that the switch to remote hiring really worked out well for them. reply dfxm12 16 hours agoparentprevHistory shows the employer -> employee relationship is about exerting control over the employee, not making the employee happy. reply uoaei 16 hours agorootparentOne might call the relationship dialectical, and the most effective analysis of its dynamics rooted in materialism. reply bugglebeetle 17 hours agoparentprevBecause real estate speculation is more important to Capital owners. reply mikhailfranco 19 hours agoprevIs there a carbon credit for that?If not, there should be a tax on employers for RTO, in the cause of realizing externalities. reply toomuchtodo 19 hours agoparentPublic companies will be required to report their carbon emissions as part of new SEC rules. Perhaps this could be reported to the SEC if they don&#x27;t report these emissions? Sounds like securities fraud to me if they don&#x27;t (hat tip to Matt Levine&#x27;s \"Everything is securities fraud\" series).Buy some shares, get some standing, spin up the legal apparatus. Not legal advice.https:&#x2F;&#x2F;www.sec.gov&#x2F;news&#x2F;press-release&#x2F;2022-46> The proposed rules also would require a registrant to disclose information about its direct greenhouse gas (GHG) emissions (Scope 1) and indirect emissions from purchased electricity or other forms of energy (Scope 2). In addition, a registrant would be required to disclose GHG emissions from upstream and downstream activities in its value chain (Scope 3), if material or if the registrant has set a GHG emissions target or goal that includes Scope 3 emissions. These proposals for GHG emissions disclosures would provide investors with decision-useful information to assess a registrant’s exposure to, and management of, climate-related risks, and in particular transition risks. The proposed rules would provide a safe harbor for liability from Scope 3 emissions disclosure and an exemption from the Scope 3 emissions disclosure requirement for smaller reporting companies. The proposed disclosures are similar to those that many companies already provide based on broadly accepted disclosure frameworks, such as the Task Force on Climate-Related Financial Disclosures and the Greenhouse Gas Protocol. reply dehrmann 18 hours agoparentprevCredits should be for actually removing carbon. Credits for this devolve really quickly into giving people credits because they bought a sedan instead of a truck. Tax emissions, credit removal. Less tax is its own reward. reply usefulcat 17 hours agoparentprevIt would be far, far more direct to just have a carbon tax. reply vikingerik 17 hours agorootparentYou realize the effect would be to drive businesses out to foreign jurisdictions that don&#x27;t have that carbon tax. reply function_seven 17 hours agorootparentTariffs on goods that originate from countries that don&#x27;t properly account for this externality.If a country doesn&#x27;t want to collect it from their domestic producers, we&#x27;ll handle it on our end. Companies offshoring production to avoid the carbon tax will be a no-op. reply p0nce 16 hours agorootparentprevSame with VAT really. Yet some business just stay there. reply nicoburns 17 hours agoparentprevThe tax is typically on fuel, which employees pay for. In theory this ought to filter through to employers who may well end up having to pay more for in-office employees to cover the extra costs. Whether that plays out in practice I&#x27;m not sure. reply syndicatedjelly 19 hours agoparentprevThere never was a tax to begin with, in fact there is the opposite (tax credits) in a lot of America if a business decides to open up a shiny new $200 million concrete jungle and forces employees to commute in. reply barney54 19 hours agorootparentTax credits for what exactly? reply syndicatedjelly 18 hours agorootparentFor bringing business to the community. People will move to live close to the office, the company itself pays taxes in the future to the township, more traffic = more opportunities for small business. It&#x27;s generally seen as healthy for an economy, but the huge downside is the environmental externalities are completely ignored.Depending on the community, they may be required to do an environmental study which does...many things that I&#x27;m not familiar with. All I know is a lot of new buildings in my area come with lots of green space and solar panels over parking lots. And probably other green things. reply xur17 18 hours agorootparentOne of my favorite examples: my Dad worked at a F100 company, and they moved a large group of employees to a new office building. That office building was taxed in a special \"opportunity zone\" that gave the employer tax credits while the employees got stuck with a new higher local income tax. reply toomuchtodo 18 hours agorootparentFundamentally, the problem is that the worker should be given incentives to bring their income to an area. This allows a community to diversify economically, vs handouts to large corporations who will continually wield their business contributions against a jurisdiction to continue to obtain substantial tax breaks or other economic concessions, and when they finally leave, they do substantial harm to the community.As a community, you then cater to workers to draw and keep them there (not maliciously, simply providing high quality of life like a community should), and they will continue to contribute to the community by way of their spending from income (on taxes and consumption) for their productive lifespan. reply robertlagrant 17 hours agorootparent> Fundamentally, the problem is that the worker should be given incentives to bring their income to an areaThis can be done naturally, if local government intervention is low, so there&#x27;s more money for local businesses to spend, or unnaturally, if local government intervention is high, so local businesses have less decision power, and the local government spends that money on infrastructure for companies coming in who pay less tax. reply d3w4s9 18 hours agorootparentprevI understand how it works but it just seems a zero sum game. When someone moves from city A to city B, it&#x27;s more tax for city B but less for A, and it often happens in one direction than the other. Same for companies. Reminds me of the silly and meaningless \"border war\" between Missouri and Kansas. reply Izkata 18 hours agorootparentTypically cities A and B fall under different local governments (states or counties or whatever), making it not zero sum for the government of city B to attract the business. reply syndicatedjelly 15 hours agorootparentprev> I understand how it works but it just seems a zero sum game.Not necessarily, most companies are growing and building new offices in addition to existing ones. replyEumenes 18 hours agoparentprevCompanies should be taxed MORE for having people work in an office? reply toomuchtodo 18 hours agorootparentYes. They are causing negative externalities without exposure to the costs. Why would we collectively not force them to internalize the costs of their requirements? Pay up.Tangentially, it is sort of fun to potentially wield capitalist economic mechanisms against poor human decisions powered by hierarchical social power structures causing detriment to physical systems. Not all hacks require code (although, one could consider statute and executive branch rule making a form of code processed by the legal system I suppose). reply Eumenes 15 hours agorootparentI don&#x27;t think a tax like this would have the intention you think. It would likely increase outsourcing, massively benefit large corporations who can afford to absorb the fees (and have better accountants&#x2F;lawyers compared to startups), destroy the tax base of cities (after the companies flee to business friendly states), shut down tons of small business that rely on commuters&#x2F;workers (like restaurants, bars, cleaning staff, etc). Believe it or not, many people like to see their co-workers daily and don&#x27;t view going to an office as a crime against humanity. This forum skews heavily towards the opposite view obviously. reply toomuchtodo 15 hours agorootparentEither pay for the climate damage you cause or don&#x27;t cause it. If tariffs are needed to avoid using outsourcing to evade the spirit of the law, implement them. No freeloading, no papering over unsustainable systems. If city tax bases crumble, so be it. If small businesses fail, that is what one would expect in a dynamic, constantly changing economic system when the system changes.> Believe it or not, many people like to see their co-workers daily and don&#x27;t view going to an office as a crime against humanity. This forum skews heavily towards the opposite view obviously.I take no issue, just pay your fully loaded costs to have this experience. My work is an income, not my social life, so I cannot relate. Now if your argument instead is, \"My in office work life is a core component of myself but I also don&#x27;t want to pay for the externalities living this experience causes because I didn&#x27;t have to previously,\" I do not have much sympathy.https:&#x2F;&#x2F;www.gallup.com&#x2F;workplace&#x2F;397751&#x2F;returning-office-cur... (\"Approximately 56% of full-time employees in the U.S. -- more than 70 million workers -- say their job can be done working remotely from home.\")https:&#x2F;&#x2F;www.mckinsey.com&#x2F;industries&#x2F;real-estate&#x2F;our-insights... (\"Another of the survey’s revelations: when people have the chance to work flexibly, 87 percent of them take it.\") reply Eumenes 14 hours agorootparentMeh, I think the jury is still out on the effectiveness of carbon credits&#x2F;offsets. Its a new system and there&#x27;s no way in telling if it will have its intended impact. Levying taxes and enacting policy is an inherently political game, and these solutions impact people TODAY. Most people would prefer to keep their quality of life high today, vs mitigating some potential risk 100s of years from now when they won&#x27;t even be alive. reply robertlagrant 18 hours agorootparentprevThey pay them by paying their employees, who pay for transport. reply lowmagnet 17 hours agorootparent…but not the pollution, road maintenance due to extra wear, fuel economy stagnation, etc.That is what gp was referring to: externalities, which you don&#x27;t directly pay for reply sahila 16 hours agorootparentGas tax and car registrations cover a fair amount of what you&#x27;re talking about. reply smileysteve 15 hours agorootparentI&#x27;ve got some bad news for you about the gas tax for repairs; at least on US Interstate highways.> (2021) The transit and highway accounts are projected to have a shortfall of $207B over the next 10 yearshttps:&#x2F;&#x2F;www.pgpf.org&#x2F;blog&#x2F;2021&#x2F;03&#x2F;its-been-28-years-since-we...> The American Society of Civil Engineers, which gives U.S. infrastructure a C-minus, is calling on the government and private sector to increase spending on roads and bridges by at least $2.5 trillion within a decade.https:&#x2F;&#x2F;www.pbs.org&#x2F;newshour&#x2F;politics&#x2F;the-gas-taxs-tortured-... replyFredPret 16 hours agorootparentprevWork at office: hundreds&#x2F;thousands of multi-ton SUV&#x27;s try to get to the same place at 9am and 5pm; parents are absent from their children and each other half the day; real estate values near offices spike insanely; if people commute by bus&#x2F;train they have to sacrifice even more hours, and also, share space with crazies and you still have to move a massive amount of physical stuff around.Work from home: some electrons & photons move.Which one costs society more? reply realusername 18 hours agorootparentprevWhy not? They pollute more because of this decision (assuming we&#x27;re talking about a desk job of course) reply misja111 17 hours agoprevThe title is misleading. For who didn&#x27;t read the article (and judging by the reactions, that is most people here), this is what the study that the article refers to really found:- the way how most people currently work remotely is -more- carbon intensive than commuting to the office- working remotely -can- halve the carbon footprint, if employees take drastic measures to reduce their footprint at home. Such as using solar panels etc.- still, offices could do the same, and employees could also choose more carbon friendly ways to commute to the office and then the balance would swing the other way again reply BadCookie 14 hours agoparentThe article seems to be implying that remote workers drive more because they live in more rural places, and some also take “several short trips” throughout the day that add up to more driving than their commute would have been. But why are they taking lots of short trips? To do errands that they would otherwise have done on the weekends? I don’t have any intuition about this. reply subhero 17 hours agoprevYeah, and at least halve the cost for the employer by rolling off office space, supplies, heating, insurance, etc. to the employee. And the decrease of the carbon footprint works “only if they take the necessary measures at home.” I am so done with virtue signalling that puts the responsibilty on the individual instead of holding corporations and policy makers accountable as the main systemic culprits. reply Centigonal 17 hours agoparent> I am so done with virtue signalling that puts the responsibilty on the individual instead of holding corporations and policy makers accountable as the main systemic culprits.I agree with you on this point, but staying in one place instead of commuting to and from work every day really does reduce the carbon footprint of most drivers. For people who take transit or bike to work, this may be a moot point. reply subhero 17 hours agorootparentCommuting,as a neccessity, is also for the policy makers to fix imo, after they have put billions (trillions?) into road infrastructure. Channel it to public&#x2F;mass transport if you are serious about decreasing carbon footprint of individuals in that aspect. reply Centigonal 16 hours agorootparentI agree with that. Plenty of European and East Asian cities have massive commuter load with a way smaller per-commuter energy footprint than in the USA. reply liquidgecka 17 hours agorootparentprevYou still have to build an office building you wouldn&#x27;t need, run the AC and heater, clean it, etc. reply irrational 17 hours agoprevI work for a Fortune 500 company. One of the things a higher up said in discussing getting people back into the office is they need us spending money of food and driving. Food I can kind of understand. We have a ton of food options on campus that are ran by a third party company. I would guess that my company has a contract with them that we will spend $x and if the employees are not spending at least $x, then the company has to make up the difference.But the driving comment didn&#x27;t make any sense to us. Is our company getting some sort of kickback from the gasoline stations, car mechanics, or tire shops? Wouldn&#x27;t the city rather have us not driving to save wear and tear on the roads?Any my company gives so much lip service to sustainability and the environment. What could be better for the environment than nobody driving into work? reply monatron 17 hours agoparentI used to work for a Fortune 500 company and in my case it was obvious that businesses in and around our campus suffered significantly with more people not coming to the office. My guess is the company had tax incentives in place with the city&#x2F;state on the condition that their being there was a boost for the local economy. People not coming to work and spending money jeopardized those incentives. reply lowmagnet 17 hours agorootparentThe sunk cost fallacy in full effect, except in some of the big companies that involves actual investment in real estate they want to recoup somehow.I don&#x27;t know how long it&#x27;ll take, but I expect less offices built, and less office floor area being leased in the long term. reply cjbgkagh 17 hours agoparentprevMaybe they need you to spend more of your money so you have to keep working to make more money.One of the problems with paying people more is that they often quit to enjoy the money they’ve made. reply polishdude20 17 hours agoparentprevYou can also think of it this way, if you&#x27;re not spending money, you&#x27;re saving it and thus, the company can&#x27;t hold you hostage in the future because you \"need the money\". reply irrational 16 hours agorootparentJokes on them. I bring my lunch everyday and ride my bike to work. I&#x27;m getting exercise and they are losing the time I could have been working if I had stayed home. reply lowmagnet 17 hours agoparentprevHaving reliable public transportation with good headways for those who still need to commute to work, getting even more cars off of the roads.It&#x27;s the same with people who are paranoid of 15 minute cities as a concept. I don&#x27;t know whose ends they&#x27;re useful idiots for, but someone is rioting them. reply oneepic 17 hours agoparentprevMaybe they want to get the most use out of their parking garage? If they have one. reply irrational 17 hours agorootparentThere are four parking garages and more surface parking lots than I could possibly count. I think it has more to do with the millions of square feet of office space on campus. But, they should just admit that rather than giving BS excuses. reply woranl 17 hours agoprevI don’t think companies can rightfully claim carbon neutral if they don’t account for the GHG emissions from their forced “working in the office” policy. They should be taxed heavily at the very least. reply lotsofpulp 17 hours agoparentMuch simpler to just tax things that cause GHG emissions like fossil fuels directly. reply woranl 17 hours agorootparentIn this case, taxing fossil fuel directly won’t reduce emissions. The increased cost to fossil fuel will simply be passed to the consumers. It just adds cost to the affected employees and makes them accountable for bad corporate policies to make a choice between livelihood and climate. The root of the problem is not addressed. The deep pocket should be accountable. It is the unnecessary emissions forced onto the working class that should be discouraged. reply lotsofpulp 17 hours agorootparentUnless everyone has unlimited money, then increasing the price of a good decreases the amount of it that is purchased. The higher the price, the less is sold, even for things with low elasticity of demand.Gas at $5&#x2F;gallon? SUVs are not a problem, and commuting 1.5 hours in individual cars is a thing. Gas at $30&#x2F;gallon, and you will see people demand more high density communities with walking&#x2F;bicycling&#x2F;public transit infrastructure. reply woranl 16 hours agorootparentWhat actually happened is the costs and wages are all jacked up and we ended up with inflation. There is no meaningful GHG emissions reduction overall. reply lotsofpulp 16 hours agorootparentBecause the price is not high enough to curb consumption. reply woranl 15 hours agorootparentTax the companies that deliberately and unnecessarily decided to go against climate policies. Let them feel the direct economic impact for their action. If we are to shield these initiators from the consequence through a series of convoluted economic maneuvers, then nothing will get changed and it’s just business as usual. reply lotsofpulp 15 hours agorootparentTaxing businesses for employees&#x27; GHG emissions is far more convoluted than simply taxing the things causing GHG emissions at the point of sale.You would need to figure out which employee is driving which kind of car with which kind of emissions systems, then keep records of all of that, and then hire people to audit it, and then prosecute corruption.All unnecessary.The direct impact will easily be felt by businesses who unnecessarily require commuting because they will become less competitive. They have to pay their employees more than their competitors to pay for the commute, hence the prices for their products&#x2F;service are higher than a competitor who does not require commuting. Obviously, this does not manifest at $5&#x2F;gallon. It needs to be something that hurts, like $30&#x2F;gallon, and not just at the fuel pump, but at the refinery&#x2F;extraction level so everything that causes GHG emissions gets hit.It is simple, easy to audit, fewer entities to audit, fewer chances for corruption, and easier to prosecute if need be. reply woranl 12 hours agorootparentI beg to differ. Impact will not be easily felt by businesses if it relies on trickle down consequences. In a capitalistic society, employers and employees don’t share the equal power dynamics. replymunk-a 17 hours agorootparentprevThe problem is that employees don&#x27;t have a limited spectrum of employer choice in the modern world and a good chunk of those employers mandate a commute. If the employer is forcing the choice on employees they should be the one to pay the tax - rather than the employee. reply lotsofpulp 17 hours agorootparentEmployers do not force people to work for them, and they also do not have an unlimited choice of employees. Certain commute lengths make sense at certain payrates at certain commute costs. If the commute costs change, then the other two variables have to change too, and the employer will have to pay more to incentivize people further away to work for them.And if living closer to work costs more, then the employer is going to have to pay more to have their employees afford to live closer. reply munk-a 17 hours agorootparentThe choice of who to hire and who to work for is limited on both sides... but in this case it&#x27;s the employer who is making the mandate that people should commute into the office - the employer should bear the cost of that mandate. reply lotsofpulp 17 hours agorootparentShould the employer also pay for the costs of clothes and water to bathe oneself since they mandate being presentable?Should the employer pay for someone to commute 4 hours? How about a 2 hour flight everyday? This is all arbitrary, but it is much simpler to just let the market sort it out.Employer offers $x for employee to be in y place at time z. Employee figures out if $x is enough to incentivize them to be there at the time, and otherwise asks for more money or seeks other employment.If employer does not find sufficient employees at $x, then they have to increase. reply munk-a 15 hours agorootparentOutside of things considered mandatory for normal life - yes, I think so. I absolutely loathe companies that make you purchase a company uniform (if they want a consistent employee appearance the company should pay for that benefit) and when it comes to bathing yourself that&#x27;s a general social expectation so I don&#x27;t believe it&#x27;s valid to try and offload on a company - but if you are required to use certain high grade soaps (i.e. some expensive brand of hypoallergenic soap since you work at a health-care provider) or the like then I think the company should provide it.In terms of commutes I think you&#x27;re thinking too much with programmer brain - when it comes to laws of society we have the reasonable person&#x2F;common sense standard. Companies should reimburse a reasonable commute to the office - if you&#x27;re thirty minutes by car then gas reimbursement is reasonable... but if you choose to make that commute in a helicopter the costs of operating that helicopter are not reasonable. reply lotsofpulp 13 hours agorootparentI would bet most people consider showing up to a regular place of work mandatory for “normal” life. I cannot even think of an example where it is not the expectation.And why is an environment damaging car considered be reasonable instead of a 30min bicycle? Or a Prius instead of an F250? What about variances? Road closures? Dropping kids off on the way? All unnecessary complications and arbitrary classifications.The goal is to reduce carbon emissions, not subsidize individuals’ living preferences. reply dublinben 6 hours agorootparentprevThe IRS currently sets a cap on employer commute benefits of $300 a month, which probably needs to be adjusted for inflation a bit, but generally establishes a reasonable standard. replyMenhirMike 13 hours agoprevYeah, but it makes downtown city centers deserted, and politicians can&#x27;t have that, so their make your CEO make you get your ass back into the office. reply tmnvix 16 hours agoprevPeople seriously underestimate how significant driving is to their environmental footprint.Rough calculation is 14,000kg&#x2F;y of CO2 per capita in the US. Of which 4,000kg would be from driving (at average yearly distance of 20,000km in average new ICE vehicle).Recycling, and other initiatives are nice but don&#x27;t come close. WFH is a huge help. reply plaidfuji 14 hours agoprevMan, I started reading the headline and was worried it would end with “can more than halve an office employee’s lifespan”, hahaI’m sure it’s great for the planet, but I’ve been working remotely for about 4 years and my body is not thanking me for it in any way whatsoever. reply brazzledazzle 11 hours agoparentIf the only exercise you were getting before really was what you got from the walking you did at work why not incorporate walks around your neighborhood into your day? reply gumballindie 9 hours agoprevYeah i’d rather spend the money saved by not commuting on solar panels and a nice little well, a massive internet pipe and a nice little house with a garden. Guaranteed my productivity will be through the roof, and i will also save on emissions. Win win. reply RestlessMind 15 hours agoprevEveryone pretty much agrees that effective remote work needs a dedicated setup. Which means having an extra room. That means remote work is going to increase real estate footprint. The carbon savings on commute will instead be used up for propping up suburban lifestyle.If one is living in a dense city and going to use wework instead, then we still need wework office buildings and commute will still be involved. So I don&#x27;t see real carbon savings with a switch to remote. reply brazzledazzle 11 hours agoparentWho is everyone and what does dedicated setup mean when they say it? You say it has to be an entire room but for me and most folks I work with outside of management that&#x27;s a desk somewhere in their house like their room, family room or living room. reply Spivak 15 hours agoparentprev> effective remote work needs a dedicated setup.I have 900 sq ft apartment, when I switched to wfh I went to Ikea, put two desks in my one bedroom one for my partner one for, and it&#x27;s doubled as our office for years now.Yes you need a dedicated space but do you know what spaces typically have lots of extra room and involve activities that basically never overlap with work -- your bedroom. And this is with the fact that I work on call and get called into work during weird hours, I sit at my kitchen island with headphones. reply swader999 16 hours agoprevEveryone knows this yet there&#x27;s not one head of state encouraging companies that can to relax on the RTO push.Makes me think we aren&#x27;t in a climate emergency. reply nightski 15 hours agoprevIt&#x27;s amusing seeing people justify working from an office but the same people turning around and telling others to not eat meat or other restrictions on their life style.Either it&#x27;s all in or it&#x27;s not, and for most people it&#x27;s not. reply postalrat 11 hours agoprevNot if it takes 3 remote workers to do the work of 1 in office worker. reply gumballindie 9 hours agoparentGossip and smalltalk arent work. reply engineer_22 18 hours agoprevThe ultimate moral high ground. reply gsibble 18 hours agoprevAnd yet they don&#x27;t care. reply mannyv 17 hours agoprevFiring everyone can reduce an office&#x27;s carbon footprint to 0. Just sayin&#x27; reply Nischalj10 17 hours agoprevand more than halve collaboration. thanks reply brazzledazzle 11 hours agoparentWhen the death, strife and pain climate change is bringing becomes impossible to ignore at least we&#x27;ll be able to say we were able to increase collaboration and shareholder value. reply pelasaco 18 hours agoprevWorking Remotely Can More Than Halve an Office Employee&#x27;s Productivity (but don&#x27;t have to)https:&#x2F;&#x2F;www.businessinsider.com&#x2F;wfh-work-from-home-decreases... reply hnta2023 17 hours agoparent\"The study observed groups of data-entry workers in India working from home and from the office.\" reply throwbadubadu 17 hours agoparentprevAnd it can also double it.. this study, just to quote one bit> observed data-entry workers in Chennai, India, across two groups — those working from the office and those working from homeDon&#x27;t want to go into all the details that had been discussed when the study was posted first - yes you also said \"can\".But to start, certainly not the representative office employee that&#x27;s discussed here. reply SubiculumCode 18 hours agoprevDriving less is good. I hate my commute anyway. However, I did wonder whether having everyone&#x27;s houses being actively heated&#x2F;cooled because you are at home versus the business office would result in more net carbon. reply standardUser 17 hours agoparentI would just ask that anyone who makes such a calculation consider that, in the SF offices I used to work in, they heated the fucking garages. They literally heated the massive, multi-level car garages that were, for the vast majority of the time, completely unoccupied by human beings. In San Francisco.That&#x27;s not the mention the sprawling lobbies, long hallways, unused conference rooms and so on. reply jrace 18 hours agoparentprevPersonally,my homes heat and ac use us u changed whether or not I am home. There has been minimal savings (from my own small sample size) to reducing either while I am away, as when I would return the system would have to work longer to restore the desired temps.So my situation it actually is a net benefit to work from home. reply ghaff 18 hours agorootparentI think that’s typical. I can drop my thermostat about 7 degrees F in the winter if I’m not home. Just have a window unit AC which I rarely use and don’t even put in some years.But I’m probably about 40 miles RT to go into my closer office which I have basically not done for years. Sometimes go into the urban one to meet with customer which is about 2x the distance and 3x the time.For most people commuting costs dwarf the costs of being home for the day—unless they move to a bigger and more expensive place. reply theandrewbailey 18 hours agorootparent> 7 degrees FTypo? Pipes freeze and burst at that temperature. reply ghaff 17 hours agorootparentDrop by not to. To about 55 degrees. reply ejvincent 17 hours agorootparentprevIf you have a modern heat pump system, it&#x27;s often more energy efficient to keep it at a steady temp. They become more efficient the less they have to work. This means if you&#x27;re changing the temp while at work, there&#x27;s a spike when you return where it has to work harder. The efficiency loss there is often worse than what was saved by changing the temps while you were away. reply brennaw1 18 hours agorootparentprevSame, most people keep their home in a narrow temperate range, especially if you have pets at home. reply ryukafalz 18 hours agoparentprevDepends on how much you blast the AC&#x2F;heating while you&#x27;re home I suppose, and whether or not you have pets and so need to keep your house somewhat heated&#x2F;cooled all the time anyway.The office I used to work at had the thermostat set far lower in the summer than I ever would at home. reply LazyMans 18 hours agoparentprevThis is pretty easy to figure out by looking at grid energy use. I think a lot of producers make that public info. Not sure there was much impact. reply lotsoweiners 18 hours agoparentprevI keep my house the same temp whether I’m home or not. I figured most people probably do the same. reply jimbob45 18 hours agoparentprevThe commute is what killed me. Doing what is essentially unpaid work to get to&#x2F;from work seems pretty unfair when you’re losing potentially an hour each day doing it.I have to imagine companies would quit this RTO nonsense if they were forced to pay hourly rates for commutes. reply lotsofpulp 17 hours agorootparent>Doing what is essentially unpaid work to get to&#x2F;from work seems pretty unfair when you’re losing potentially an hour each day doing it.I do not agree with this framing. People have agency to choose where they live and what tradeoffs they want to make in their life. No reason someone willing to live in a certain location should subsidize someone wanting to live further away. reply brazzledazzle 11 hours agorootparentSo you have agency in theory but not in practice? I don&#x27;t know many coworkers who can afford to live anywhere near our office aside from management and people far along on the technical promotion path. Every state, city and area is different but I can&#x27;t imagine these circumstances are rare. Homes without commutes tend to have a much higher price or rental cost than those further away. If 80% of your workers have to commute to get to your office what agency do they really have? The agency to live in a van parked a few blocks away? reply ericjmorey 17 hours agorootparentprevSuburban sprawl is highly subsidized in the USA. Having agency doesn&#x27;t negate the environment your surrounded by. reply lotsofpulp 17 hours agorootparentYes, and forcing business to pay people the further away they live further subsidizes the sprawl. reply SubiculumCode 15 hours agorootparentIt also happens that living in an apartment in the middle of a city is depressing to many people, who wish for green spaces, gardening, and a bit of s p a c e. So I just disagree that suburbia is hell, and high-rise living is next to godliness.I would live in a world where I was near wilderness, working remotely, but occasionally commuting to work through ultra high speed transport. reply tjpnz 17 hours agorootparentprevTell that to the person cleaning your offices. reply lotsofpulp 17 hours agorootparentThe person cleaning the office being too poor to live near the office is a separate issue, solved with wealth redistribution and more high density housing. reply jimbob45 17 hours agorootparentjust fundamentally restructure your government and undertake decades-long construction projects!That doesn&#x27;t help the people in the 20-year interim before those changes are made. God forbid wealth redistribution doesn&#x27;t actually solve the problem. reply lotsofpulp 16 hours agorootparentYes, I know it is politically intractable, hence all of these problems are unsolvable. But technically, it is feasible, just requires a lot of reduced expectations from people who are anticipating living a certain lifestyle. replySubiculumCode 18 hours agorootparentprev1.5 hours driving a day * 5 days a week = not going to the gym ever. reply Jcampuzano2 18 hours agorootparentI&#x27;m a pretty big gym rat, so I went even when i did go to the office.All that to say that having the freedom to go in the middle of the day&#x2F;lunchtime and also having more energy for it was one of the single biggest benefits I enjoy from remote work as someone who lives alone.I can also go for short walks around my neighborhood for small breaks without feeling like I&#x27;ll be judged for not being at my desk&#x2F;making smalltalk with people who don&#x27;t wanna be active. Normally those breaks would just be sitting around the coffee maker, or people standing at desks.Remote work opens up so much for human health in my opinion. I do understand some jobs can&#x27;t be done from home, but in my opinion that should be reason to compensate them even more. reply Winse 18 hours agoprevnext [2 more] [flagged] yieldcrv 18 hours agoparent\"I&#x27;m going to move the goal posts of this thing I don&#x27;t like until it reaches a ESG argument, despite all the things I like having a bigger ESG argument, but you&#x27;re strawmanning if you point that out\" reply 8f2ab37a-ed6c 18 hours agoprevAnd it&#x27;s great for DEI as well, truly a moral free lunch https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;forbesbooksauthors&#x2F;2023&#x2F;01&#x2F;10&#x2F;r... reply Pannoniae 16 hours agoparentDEI is an income-suppressing initiative, as shown by \"In fact, if your office is in a major hub like New York or Hong Kong, the distant designer may be even more appealing because of lower salary expectations.\".That&#x27;s not a positive. reply sahila 16 hours agorootparentFeels like that&#x27;s a matter of perspective, the distant designer and non-Americans may like working for this company and significantly increasing their wages. reply piuantiderp 17 hours agoprevThe (often) unsaid truth about carbon footprint is that dead people produce no carbon. The lineage of the movement can be directly traced to Neomalthusian and eugenicists. reply groucho 17 hours agoparentYou could say this about any pov that discourages any behavior: \"Dead people don&#x27;t murder, and so the movement to stop murder can be traced directly to Neomalthusian and eugenicists.\"It&#x27;s obnoxious to exaggerate the perspective of people you disagree with, just to make them seem less reasonable. Those who want people to decrease their carbon footprint don&#x27;t want you dead, they just want people to decrease their carbon footprint. reply Null-Set 17 hours agoparentprevNo, dead people produce about 13 kg of carbon. reply voisin 18 hours agoprevThe title is misleading as it ignores the qualifier that the employees have to take certain steps at home to achieve this. Some examples:> You and his team found that this isn’t the case. In fact, remote workers often drive more often than their in-office counterparts by taking several short car trips throughout the day.> The researchers also found that working from home can prompt people to use more energy over the course of a workday on things such as air-conditioning and a dishwasher. And remote workers are more likely to move out of big, centralized cities, where lifestyles are generally less carbon-intensive than in suburban or rural areas. reply sideshowb 17 hours agoparentThese issues are key. Thanks for raising them.In some recent transport modelling work we decided there wasn&#x27;t yet enough evidence about wfh, specifically because people may move further from the office. If this study fills some gaps, it&#x27;s good work....edit: ok so it doesn&#x27;t address causality. Alas. We need a study following a cohort for a few years after wfh became available, vs another cohort denied wfh. reply sideshowb 4 hours agorootparentDown votes are being used reddit style, I see. I&#x27;d love to know what the disagreement is exactly? reply semerda 18 hours agoprev [–] Yet somehow the C02 PPM kept on climbing during Covid era when many worked from home. https:&#x2F;&#x2F;gml.noaa.gov&#x2F;ccgg&#x2F;trends&#x2F; reply fredoliveira 18 hours agoparentDoes it surprise you that despite many working from home, the world in general kept on trucking along? Of course CO2 PPM kept rising. Where people work isn&#x27;t the only cause of carbon emissions. reply enragedcacti 18 hours agoparentprevYou could read the article that you had to scroll past to look at the chart.Can we see a change in the CO2 record because of COVID-19?: https:&#x2F;&#x2F;gml.noaa.gov&#x2F;ccgg&#x2F;covid2.html reply arrowsmith 18 hours agoparentprev [–] So? reply olddustytrail 15 hours agorootparent [–] So lockdown was a liberal hoax! It never actually happened and there never really were any restrictions. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Scientific American's website is temporarily unavailable due to abnormal traffic.",
      "Scientific American is a subsidiary of Springer Nature, a company associated with many scientific publications.",
      "The publication claims editorial independence in reporting scientific developments."
    ],
    "commentSummary": [
      "The dialogue centers on the effects of remote work on carbon emissions, societal well-being, productivity, and the boss-worker relationship.",
      "Differing viewpoints are highlighted, underscoring the environmental advantages of remote work and juxtaposing them with potential challenges such as social seclusion and diminished productivity.",
      "The need for government intervention, tax incentives, and democratic instruction in workplaces to tackle these outcomes is also noted."
    ],
    "points": 273,
    "commentCount": 220,
    "retryCount": 0,
    "time": 1695394954
  },
  {
    "id": 37612975,
    "title": "Java 21: The Nice, the Meh, and the Momentous",
    "originLink": "https://horstmann.com/unblog/2023-09-19/index.html",
    "originBody": "Java 21: The Nice, The Meh, and the ... Momentous When Java 17 was released in 2021 as a “long term support” version, I wrote an article dissecting its features and came to the conclusion that it had a few nice features, but none that were compelling reasons to upgrade. Except one: tens of thousands of bug fixes. Java 21 was released today, as another “long term support” release. How does it rate on the momentousness scale? Read on for an unbiased opinion. The Momentousness Ratings Every six months, there is a new Java release. Ever so often (currently, every two years), Oracle labels a release as “long term support”, and Java users wonder whether they should upgrade. In theory, other JDK distributors could offer “long term support” for other releases, but it seems everyone is following Oracle's lead. Should you upgrade? Here are the major features of Java 21. I omit preview and incubator features (which you are surely not going to use in production), JVM internals, highly specialized features such as this one, and deprecations. Feature Example Momentousness rating Why care? Pattern matching for switchEmployee e = . . .; String description = switch (e) { case Executive exec when exec.getTitle().length() >= 20 -> \"An executive with an impressive title\"; case Executive __ -> \"An executive\"; case Manager m -> { m.setBonus(10000); yield \"A manager who just got a bonus\"; } default -> \"A lowly employee with a salary of \" + e.getSalary(); };Nice It's better than chains of if/else/else with instanceof. Do you do that often? The JDK source has over 5 million LOC with about a thousand instanceof preceded by else. Record PatternsString description = switch (p) { case Point(var x, var y) when x == 0 && y == 0 -> \"origin\"; case Point(var x, var __) when x == 0 -> \"on x-axis\"; case Point(var __, var y) when y == 0 -> \"on y-axis\"; default -> \"not on either axis\"; };Nice How many records are in your codebase? (The Java 21 API has two.) Sequenced CollectionsList words = ...; String lastWord = words.getLast(); for (String word : words.reversed()) System.out.println(word);Nice Good to have, but you wouldn't upgrade for that. Virtual threadstry { var response = client.send(request, HttpResponse.BodyHandlers.ofString()); for (URL url : getImageURLs(response.body())) { saveImage(getImage(url)); } } catch (...) { ... }Momentous No more async gobbledygook! client.sendAsync(request, HttpResponse.BodyHandlers.ofString()) .thenApply(HttpResponse::body) .thenApply(this::getImageURLs) .thenCompose(this::getImages) .thenAccept(this::saveImages) .exceptionally(this::ohNoes); Miscellaneous new methods\"Hello, World!\".splitWithDelimiters (\"\\\\pP\\\\s*\", -1) // [\"Hello\", \", \", \"World\", \"!\", \"\"]Meh Good that the API keeps evolving in small ways, but the changes are pretty minor. Over 10,000 bug fixes Bug JDK-8054022 HttpURLConnection timeouts with Expect: 100-Continue and no chunking Count me in! Unless you are sure that none of them might impact you, shouldn't you upgrade? Let's look at these features in more detail. Virtual Threads Virtual threads are a big deal. Similar to generics, lambda expressions, and modules, they solve a major problem for which the language has otherwise no good alternative. If you have the problem that they are designed to solve, you will have a powerful motivation to upgrade. Here is the problem. If you write applications that process many more concurrent requests than available platform threads, you currently have two unappealing choices: Use a synchronous programming style and accept that throughput is limited by the number of platform threads Use an asynchronous or “reactive” programming style What is wrong with an asynchronous programming style? You have to structure your program as chunks of callbacks. You need library support for sequencing, branches, loops, and exception handling, instead of using the features that are built into Java. Debugging is more challenging since the debugger cannot show you a complete execution history when it stops at a breakpoint. Not convinced? Make one of your junior programmers read through the documentation of Project Reactor and then assign a simple task, such as loading a web page and then loading all images in it. Of course, virtual threads are not appropriate for all concurrent programming. They only work for tasks that spend most of their time waiting for network I/O. This is the situation in many business applications where much of the request processing consists of calls to the database and external services. Interestingly, there is very little to learn in order to use virtual threads. You just use them like regular threads. In most scenarios, you simply configure your application framework to invoke your business logic on virtual threads, and watch throughput increase. One idiom is worth learning. To run multiple tasks in parallel, use a local instance of ExecutorService: try (var service = Executors.newVirtualThreadPerTaskExecutor()) { Future f1 = service.submit(callable1); Future f2 = service.submit(callable2); result = combine(f1.get(), f2.get()); } Obtaining the result with get is a blocking call, but so what, blocking is cheap with virtual threads. Structured Concurrency, a preview feature in Java 21, simplifies error handling and makes it easier to harvest the results of multiple concurrent requests. There are a few caveats: In the past, a thread pool didn't just throttle the incoming requests but also the concurrent resources that your app consumed. If you now accept many more incoming requests, you may need other ways to manage resource consumption. One resource that deserves particular attention is thread locals. With many more threads than before, do you really want many more thread locals? Or are there more appropriate mechanisms to achieve whatever you wanted to achieve with thread locals? Your framework provider needs to think this through, and if you actively use thread locals, so should you. A lighter-weight alternative is in preview. Virtual threads do not yet work well with blocking calls inside synchronized methods or blocks. The remedy is to rewrite the offending code with java.util.concurrent locks. Be sure that the providers of your framework, database driver, and so on, update their code to work well with virtual threads. Quite a few already did. Pattern Matching Many functional languages have some form of pattern matching that makes it convenient to work with “algebraic data types”, which in Java are implemented with sealed hierarchies and record classes. Java has chosen to extend the syntax for instanceof and switch for pattern matching, in order to leverage existing programmer knowledge. These extensions have been in preview until Java 20 and are now in their final form. Are you using sealed hierarchies and records in your code base? Then pattern matching is appealing. Here is an example, a simple JSON hierarchy: sealed interface JSONValue permits JSONArray, JSONObject, JSONPrimitive {} final class JSONArray extends ArrayList implements JSONValue {} final class JSONObject extends HashMap implements JSONValue {} sealed interface JSONPrimitive extends JSONValue permits JSONNumber, JSONString, JSONBoolean, JSONNull {} final record JSONNumber(double value) implements JSONPrimitive {} final record JSONString(String value) implements JSONPrimitive {} enum JSONBoolean implements JSONPrimitive { FALSE, TRUE; } enum JSONNull implements JSONPrimitive { INSTANCE; } Now you can process JSON values like this: JSONPrimitive p = . . .; double value = switch (p) { case JSONString(var v) when v.matches(\"-?(0|[1-9]\\\\d*)(\\\\.\\\\d+)?([eE][+-]?\\\\d+)?\") -> Double.parseDouble(v); case JSONString __ -> Double.NaN; case JSONNumber(var v) -> v; case JSONBoolean.TRUE -> 1; case JSONBoolean.FALSE, JSONNull.INSTANCE -> 0; } Note the following: This is a switch expression that yields a value The compiler checks that the switch is exhaustive The pattern JSONString(var v) binds the variable v to the component of the record The when clause restricts a match to a Boolean condition With JEP 445, you will be able to use case JSONString _, with a single underscore, to indicate that you do not need the variable binding. But that is still a preview feature. Since Java 14, you can have multiple constants in a single case All this is certainly nicer than the instanceof and casting that one might do right now with Jackson. But you might want to hold off switching to a new JSON hierarchy until Java gives us value classes. In general, pattern matching is more useful in contexts that are designed for pattern matching. Today's use cases are perhaps not all that compelling, but it is an investment in the future. Sequenced Collections When you have a Collection, how do you get the first element? With a List, it's list.get(0), but in general, you'd call collection.iterator().next(). Except with a stack or queue it is peek, with a deque getFirst, and the SortedSet interface has first. And what about the last element? And how do you visit the elements in reverse order? Deque and NavigableSet have a handy descendingIterator. For lists, you iterate backwards, starting from the last element. JEP 431 cleans up this situation with a SequencedCollection interface. It has these methods: E getFirst(); E getLast(); void addFirst(E); void addLast(E); E removeFirst(); E removeLast(); SequencedCollection reversed(); The first six methods are the same as in the Deque interface, which is now a subinterface. There is also a SequencedSet, where reversed yiels a set, and a SequencedMap, with methods to get and put the first and last entry, and with sequenced views for the keys, values, and entries. This figure, by Stuart Marks, shows the change in the collections hierarchy. TL;DR Reverse iteration over a list, deque, tree set, or tree map is now more uniform. Getting the first and laste element too. That's nice. Obviously not momentous. Should You Upgrade? When Java 17 was released, I opined that none of its features were momentous enough to warrant upgrading, and one was downright ugly. Still, upgrading was a no-brainer: tens of thousands of bug fixes. Of course you should upgrade again to Java 21. Because, lots of bug fixes. And this time there is a truly momentous feature: virtual threads. If you are contemplating the use of reactive programming, or you are already unhappily doing so, you definitely want to check them out. Also Nice Oracle now has an online “playground” for testing Java snippets. Check it out! Comments powered by Talkyard. More Entries RSS Feed",
    "commentLink": "https://news.ycombinator.com/item?id=37612975",
    "commentBody": "Java 21: The Nice, the Meh, and the MomentousHacker NewspastloginJava 21: The Nice, the Meh, and the Momentous (horstmann.com) 252 points by pwpwp 19 hours ago| hidepastfavorite133 comments adra 18 hours agoVirtual threads are going to be great, but they&#x27;re still limited (still starved the pool when used with &#x27;synchronized&#x27; blocks), and they aren&#x27;t the structured concurrency power houses like kotlin coroutines, but its an invaluable tool that will only continue to accelerate as the ecosystem moves to adopt them.Expect a lot of libraries to start release versions that are java 21 baseline because of this feature alone. We&#x27;re in for a little bit of dependency hell for the short while. Thankfully, devs have been exposed to a mostly final loom for a year, so my hope is that at least the big projects are well on their way to quick adoptions.Unlike the 8->11 migration which largely brought pain, the 8->21 release brings with it a ton of value that i think will encourage most shops to actually pull the trigger and finally abandon 8. reply pron 17 hours agoparentStructured concurrency in JDK 21 is not only a powerful and flexible library feature, but one that is built deep into the runtime in a way that allows observability into the relationships among threads: https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;453 reply cogman10 13 hours agorootparentIt&#x27;s somewhat unfortunate that structured concurrency ended up being a preview feature in 21. I agree that it&#x27;s a great addition but man it&#x27;d be nice if it made the LTS.As it stands, probably won&#x27;t be heavily used until Java 25. reply pron 9 hours agorootparentOrganisations that care about new features need to reconsider their stance on using Preview features and even more importantly sticking to versions for which the sales org offers an LTS service. The whole concept of LTS is designed for companies that are so uninterested in new features (often because their software is no longer heavily maintained) that they&#x27;re willing to pay money not to receive them. There are a lot of such projects around, and the fact that non-legacy projects choose old versions and an LTS service shows that the ecosystem still hasn&#x27;t adapted to the new release model. reply thfuran 1 hour agorootparentThat seems like a bad faith interpretation. Upgrading has both costs and risks. Even upgrades within the same major version can break things. LTS is about paying for stability, not a lack of features. reply pron 48 minutes agorootparentWell, yes, but in the past the versions that now get a new integer number (feature releases) were mandatory for everyone and there was no LTS at all. There were some differences, but not as big as many think. The biggest one was the psychological aspect of the name (7u4 or 8u20, which were not patch releases but big feature releases).So why did we create the LTS service? 1. Because the new feature releases, while no more risky than the old ones (like 7u4 and 8u20), do require a little more work that companies don&#x27;t want to put into legacy applications, and 2. Many companies indeed are willing to pay for more stability for their legacy apps.So while it is absolutely true that some projects want better stability, this level of stability is new. Companies that religiously stick to old versions now didn&#x27;t do that in the past. The simplest explanation is that the new release model isn&#x27;t yet understood, not that thousands of companies changed their risk strategy. reply logicchains 14 hours agorootparentprevDo you know if clojure will be adopting these virtual threads, or still using the macro-based approach? reply bcrosby95 10 hours agorootparentIt depends upon what you mean here.You could always set the backing thread pools for core.async and agents in Clojure. That gives you the ability to use virtual threads right now.But in order to avoid thread pinning, there will need to be some code changes to convert some uses of synchronized to ReentrantLock. How fast that happens will depend upon the given library maintainer. Here&#x27;s an issue for making some of these changes in Clojure&#x27;s core library: https:&#x2F;&#x2F;clojure.atlassian.net&#x2F;browse&#x2F;CLJ-2771I&#x27;ve tested Clojure&#x27;s agents with the new virtual threads for my targeted use case they&#x27;re significantly faster than before - I can spin up tens of thousands of mostly idle agents and reach performance close enough to core.async for me. reply Quekid5 12 hours agorootparentprevCongrats to you and the team on this huge milestone!Really looking forward to taking advantage of these things (transparently and automatically!) in ZIO&#x2F;Scala... which I think shows the true power of the JVM-as-platform approach you&#x27;re taking! reply brabel 16 hours agoparentprev> Expect a lot of libraries to start release versions that are java 21 baseline because of this feature alone.Java has had multi-version jars since 11 I think... that allows library authors to ship code that benefits from new features in newer versions of the JDK while still supporting older ones as well. Hopefully library authors can leverage that, though I&#x27;m aware something like Virtual Threads may be very difficult to design around for older versions. reply tadfisher 6 hours agorootparentmrjars are a terrible idea, because libraries are very rarely a single jar, and require dependencies. Often that dependency set is different depending on the runtime version because of backports of newer Java APIs. So either you don&#x27;t care and make your consumers use proguard to remove the unnecessary backports, or you create a Maven package with variants for each runtime version, which 99% of your downstream will end up using anyway. reply skwirl 17 hours agoparentprevDo you have to baseline on Java 21 if you want to add support for virtual threads? Couldn&#x27;t you continue using heavyweight threads on older versions of Java? My understanding is that both use the same Thread abstraction. reply adra 16 hours agorootparentFrom an API perpective, you can always use reflection to cheat past the option to create virtual threads in pre-21 (without previews) java bytecode, but you need to do more to your code than just flip the switch to support virtual threads.A virtual thread thread pool by definition is unbound. If you&#x27;re binding data to a thread (eg. Thread locals, you now have a seemingly unbound list of threads that is now effectively a memory leak). I bumped into that one a few months ago with Netty that has a per thread cache for some things (thankfully you can turn off that cache). It was creating a significantly large waste of RAM that slowed down the application alone.The other big one is as I mentioned the synchronized limitation. If you assume naively that anything can run in a virtual thread without worries, you&#x27;re opening yourself up to deadlocks or at least significantly low performance code if you&#x27;re relying on libraries&#x2F;code that are synchronized using java monitors.There may be more examples of gotchas, but these two are the most notable examples I have right now. reply Quekid5 14 hours agorootparentprevI believe, e.g. ZIO 2.next is doing something like this, dynamically deciding whether running something async or just doing the blocking thing depending on the availability of VThreads... but of course that&#x27;s Scala, so YMMV.Without a way to trampoline computation (or transform code appropriately) it&#x27;s probably impractical to do anything like that.(And of course, still many caveats as the sibling post points out.) reply larperdoodle 17 hours agoparentprevWhy haven&#x27;t places updated already? It&#x27;s not that much work to update. Where I work we always go to the new LTS version as soon as it&#x27;s supported by gradle.Doesn&#x27;t cross anyone&#x27;s mind to _not_ upgrade. reply jfengel 16 hours agorootparentThe bigger the project, the more painful the upgrade. Package systems are convenient to avoid reinventing the wheel, until you have to upgrade any piece of it. Then you&#x27;re stuck trying to figure out which versions of each package go together.If Package A won&#x27;t run on JDK 17 your entire project is stuck on JDK 11. If Package B is upgraded but has conflicts with Package A, you have to dig through old versions until you find one that works -- and you don&#x27;t get upgrades.The more games somebody has played with reflection, undocumented features, deprecations, etc. the more likely you are to have a conflict. And since package managers encourage you to depend on somebody else&#x27;s code, you end up depending on everybody else&#x27;s code.The smaller and greener the project is the more likely it is you can just pull the latest versions and be happy about it. A project that was written when Java 8 was current, and continued to develop, is going to be a nightmare. reply Macha 16 hours agorootparent\"Oh look, I need to upgrade mockito and Spring. Oh, now I upgraded Spring I need to update the spring JPA plugin. Oh now I upgraded that I need to upgrade Hibernate. Oh now I need to upgrade the library built on it that that team over there maintains. Oh, they&#x27;re not interested.\" etc. etc. reply ivan_gammel 4 hours agorootparentWhen using Spring Boot you usually update just one version and everything else is updated via BOM. There should be a really good reason to have fine-grained control over every single dependency. reply Macha 54 minutes agorootparentNot every app using Spring is using Spring boot reply dingi 2 hours agorootparentprevTrue, Spring upgrades can be a pain in the ass. There is a trick to make it less painful though. Use maven BOM for version management. As with any framework upgrade, it doesn&#x27;t make the process entirely painless. But very much less painful. reply dionian 11 hours agorootparentprevHaving a lot of experience with that stack... it is why i migrated to scala long ago reply paulddraper 6 hours agorootparentTho Scala makes the upgrade problem even worse:) reply brnt 5 hours agorootparentprevJava isn&#x27;t forward compatible? reply Brystephor 17 hours agorootparentprev1) dependencies need to be upgraded. for example, not all versions of Gradle support all Java versions. So you need to upgrade Gradle to upgrade Java.2) other things are deemed to have higher priority.3) people are satisfied with existing features and don&#x27;t want to spend energy to upgrade to something that doesn&#x27;t provide immediate value.4) folks aren&#x27;t educated on what the benefit of switching would be so why would it be prioritized? This is a case of \"they don&#x27;t know what they don&#x27;t know\".I work on a team using Java 8 daily. It&#x27;s fine. It&#x27;s got things I wish it didn&#x27;t (no null in switch statements for example) but I don&#x27;t care about that so much that I&#x27;m going to go through the pain of upgrading 7-9 services in the mono repo, their dependencies, and then test them all to be on a new version of Java. reply belfthrow 8 hours agorootparent1) is garbage. Since grade 6 you can run on 22 ea with no issues. Use toolchains, as they say on their docs.2) no shit. What business user is every in their mind prioritising upgrading their language version? It&#x27;s not up to them to push the upgrade. It&#x27;s yours.3) of course they are. People don&#x27;t desire what they don&#x27;t want. Invest in people who are actually interested in improvement of their software.4)the java team have been pushing heavily via twitter &#x2F; youtube &#x2F; infoq &#x2F; hacker news &#x2F; other open jdk providers all the new features for every single java version during their 6 months release cycles. If your devs &#x2F; your team don&#x27;t know about it, then maybe again youre not encouraging people to want to improve on what they have, or take interest in the tech they work in.I mean that is fine, do I give a shit what java version in using for my take home salary? No...but I enjoy using the newest, most interesting and useful tools. And you best believe those people are more attractive to other companies and you working on some 15 year old java 8 tech. reply krzyk 17 hours agorootparentprevGradle&#x2F;groovy is a liability for any jdk upgrades (similarly like lombok, but it usually supports new JDK at release, not before).We ditched spock because of groovy, and never looked back. Now at jdk 21, previously at 20. reply brabel 16 hours agorootparentThat&#x27;s pretty disingenuous. Groovy has always run on newer JDK versions before they even get released.One year ago, Gpars already supported Virtual Threads: https:&#x2F;&#x2F;groovy.apache.org&#x2F;blog&#x2F;gpars-meets-virtual-threadsAs a heavy user of Groovy&#x2F;Spock, though, I agree that upgrading Groovy itself can be challenging, unfortunately. Really depends though on how many edgy Groovy features you relied on :). reply krzyk 14 hours agorootparentNot always for sure. We started JDK upgrades with 9 and went +1 every half year and Groovy was lacking with one of 10, 11, 12 or 13. It got so tiring that we had to let it go. Fortunately our tests were mostly JUnit 5, so it wasn&#x27;t much of work.We only used it for Spock AFAIR. reply brabel 4 hours agorootparentIf you&#x27;re upgrading every minor Java version, then yeah, I agree Groovy and most other dependencies that may not work on Java version changes off the bat (Lambok, probably Spring and other heavy frameworks like Micronaut and Quarkus, build tools like Gradle... many more) are going to slow you down. You end up with a very simple project if you remove all of that, which is actually a good thing if you can afford doing it. reply krzyk 3 hours agorootparentThose are not minor versions, that&#x27;s quite natural path and is supported by every lib we used, except groovy. And this is the encouraged path for JDK upgrades, people are lazy, but not us :)Spring supports new JDK release (\"minor version\" like you called them, those between 11 and 17 and 21) before release. The only exception was with JDK 13, there was about 2 week slip there.Lombok (I don&#x27;t like it) supports every such version at release (not before unfortunately).Other libs didn&#x27;t even error out (we keep them at newest versions possible, aside from Jakarta madness).So from the major libs&#x2F;frameworks, the only thing that slowed us down was groovy. reply NovaX 9 hours agorootparentprevKotlin, not Groovy, has been the culprit for slower Gradle support. I believe there was some split module pain in Groovy wrt Java 9, but it has been very smooth since then. The Kotlin compiler on the other hand is not very forgiving.This is a moot point because your the build execution and the project compile&#x2F;run can be on different JDKs. It is a tiny amount of configuration to decouple them, e.g. to use an EA build. reply defatigable 17 hours agorootparentprevThis is a niche case, but I spent months trying to upgrade one of our services from one LTS version to the next (I forget which). We encountered a weird bug where services running on the latest JRE would mysteriously corrupt fields when deserializing thrift messages, but only after running for a little while.After an enormously unpleasant debugging cycle, we realized that the JIT compiler was incorrectly eliminating a call to System::arrayCopy, which meant that some fields were left uninitialized. But only when JIT compiled, non-optimized code ran fine.This left us with three possible upgrade paths:* Upgrade thrift to a newer version and hope that JIT compilation works well on it. But this is a nightmare since A) thrift is no longer supported, and B) new versions of thrift are not backwards compatible so you have to bump a lot of dependent libraries and update code for a bunch of API changes (in a LARGE number of services in our monorepo...). With no guarantee that the new version would fix the problem.* File a bug report and wait for a minor version fix to address the issue.* Skip this LTS release and hope the JIT bug is fixed in the next one.* Disable JIT compilation for the offending functions and hope the performance hit is negligible.I ultimately left the company before the fix was made, but I think we were leaning towards the last option (hopefully filing a bug report, too...).There&#x27;s no way this is the normal reason companies don&#x27;t bump JRE versions as soon as they come out, but it&#x27;s happened at least once. :-)In general there&#x27;s probably some decent (if misguided) bias towards \"things are working fine on the current version, why risk some unexpected issues if we upgrade?\" reply Freaky 10 hours agorootparentI encountered a weird bug with deserializing JSON in a JRuby app during an OpenJDK upgrade - it would sporadically throw a parse error for no apparent reason. I was upgrading to OpenJDK 15, but another user experienced the same regression with an LTS upgrade from 8 to 11.The end result of my own investigation led to this quite satisfying thread on hotspot-compiler-dev, in which an engineer starts with my minimal reproduction of the problem and posts a workaround within 24 hours: https:&#x2F;&#x2F;mail.openjdk.org&#x2F;pipermail&#x2F;hotspot-compiler-dev&#x2F;2021...There&#x27;s also a tip there: try a fastdebug build and see if you can convert it into an assertion failure you can look up. reply dihrbtk 15 hours agorootparentprevdid you work for a very large rideshare company by any chance? reply dingi 23 minutes agorootparentprevOn topic of upgrades, here are a couple of tricks I&#x27;ve learned throughout the years which make the upgrade process easier.1. Use Maven 2. Use BOMs to manage related dependencies 3. No lombok reply kevan 7 hours agorootparentprevFor an example, my team owns a dozen services and they have hundreds of direct and transient dependencies. Of those, maybe a dozen or two to need work to support the new version but that&#x27;s a dozen different teams that have to put the work on their roadmap and prioritize it. When the entitlement is &#x27;devs want to use shiny feature X with hard to quantify productivity benefit&#x27; it&#x27;s difficult to prioritize. When there&#x27;s an efficiency benefit then things move fast because a 10% efficiency improvement means 10% lower server costs and that&#x27;s easy math. reply coldtea 9 hours agorootparentprevOther workplaces have more long term supported systems, with more complex requirements, and more SLAs and guarantees to fulfil. reply yCombLinks 17 hours agorootparentprevThe services I work on pump the entire business revenue from start to finish. A few nice to haves for devs aren&#x27;t any where close in the risk calculation if something breaks reply jabradoodle 11 hours agorootparentSounds like code that&#x27;s worth learning how to test. reply yCombLinks 9 hours agorootparentI know right. Unfortunately with jdk upgrades only e2e tests have much value, and those are much more expensive reply tantamounta 17 hours agoparentprevWith the API being nearly the same, I keep just thinking that Virtual Threads are basically identical to Platform Threads except that they use far less memory (so you can have lots more of them).Are there any other actual differences? Better Peformance? reply pron 17 hours agorootparentThe relationship between throughput, latency, and concurrency in servers is expressed via Little&#x27;s theorem. If your server is written in the thread-per-request style -- the only style for which the platform offers built-in language, VM, and tooling support -- then the most important factor affecting maximum throughput is the number of threads you can have (until, of course, the hardware is fully utilised). Being able to support many threads is the most effective improvement to server throughput you can offer.See: Why User-Mode Threads Are Good for Performance https:&#x2F;&#x2F;youtu.be&#x2F;07V08SB1l8c reply tantamounta 15 hours agorootparentThanks for the video. I feel like there&#x27;s a bit of conflation between the terms \"performance(latency)\" and \"throughput\", but I see the point. I&#x27;d be interested to see that latency graph (Time marker 15:38) between platform and virtual threads in the case where the server doesn&#x27;t manufacture a 100ms delay (say, in the case of a caching reverse-proxy).Also - millions of Java programmers thank you for not going to async&#x2F;await. What an evil source-code virus (among other things that is).I tried to watch it at 1.25x speed as I normally do, but you already talk at 1.25x speed, so no need ! reply pron 15 hours agorootparentTo understand what happens when the server doesn&#x27;t perform IO, apply Little&#x27;s formula to the CPU only. Clearly, the maximum concurrency would be equal to the number of cores, which means that in that situation there would be no benefit to more threads than cores. What you would see in the graph would be that the server fails once L is equal to the number of cores. The average ratio between IO and CPU time as portions of the average duration would give you an upper limit on how much more throughput you gain by having more threads. That&#x27;s what I explain at 11:34.Also, both throughput and latency are performance metrics. reply Svenskunganka 12 hours agorootparentprevI watched the video and thoroughly enjoyed it, thank you for sharing it! I have a question that is perhaps not entirely related to the video, but it touches the topic of context switches. I&#x27;ve read this post [1] by Chris Hegarty, which explains that when calling the traditionally blocking network I&#x2F;O APIs in the Java stdlib from a virtual thread, it uses asynchronous&#x2F;poll-based kernel syscalls (IOCP, kqueue, epoll on Windows, Mac and Linux respectively) which I assume is to avoid blocking the carrier threads. That post was written in 2021, does it still hold true today in Java 21?Reading that, it also makes me wonder what happens for disk I&#x2F;O? Many other runtimes, both \"green thread\" ones like Golang and asynchronous like libuv&#x2F;tokio, use a blocking thread pool (static or elastic) to offload these kernel syscalls to because, from what I&#x27;ve read, those syscalls are not easily made non-blocking like e.g epoll is. Does Java Virtual Threads do the same, or does disk I&#x2F;O block the carrier threads? For curiosity, does Java file APIs use io_uring on Linux if it is available? It is a fairly recently added kernel API for achieving truly non-blocking I&#x2F;O, including disk I&#x2F;O. It doesn&#x27;t seem to bring much over epoll in terms of performance, but has been a boon for disk I&#x2F;O and in general can reduce context switches with the kernel by reducing the amount of syscalls needed.[1]: https:&#x2F;&#x2F;inside.java&#x2F;2021&#x2F;05&#x2F;10&#x2F;networking-io-with-virtual-th... reply pron 10 hours agorootparent> That post was written in 2021, does it still hold true today in Java 21?Yes.> Does Java Virtual Threads do the same, or does disk I&#x2F;O block the carrier threads? For curiosity, does Java file APIs use io_uring on Linux if it is available?We&#x27;re working on using io_uring where available, especially for filesystem IO. For now, filesystem IO blocks OS threads but we temporarily compensate by increasing the size of the scheduler&#x27;s worker thread pool. reply jlokier 4 hours agorootparentIn late 2021 I compared OS threads to io_uring for filesystem I&#x2F;O at random-access reads from fast, NVMe SSDs.That measurement told me that it&#x27;s not necessary to use io_uring for disk I&#x2F;O performance for some workloads.It found no improvement in performance from io_uring, compared with a dynamic thread pool which tries to maintain enough I&#x2F;O-blocked threads to keep the various kernel and device queues busy enough.This was a little surprising, because the read-syscall overhead when using threads was measurable. preadv2() was surprisingly much slower than pread(), so I used the latter. I used CLONE_IO and very small stacks for the I&#x2F;O threads (less than a page; about 1kiB IIRC), but the performance was pretty good using only pthreads without those thread optimisations. Probably I had a good thread pool and queue logic, as it surprised me that the result was much faster than \"fio\" banchmark results had led me to expect.In principle, io_uring should be a little more robust to different scenarios with competing processes, compared with blocking I&#x2F;O threads, because it has access to kernel scheduling in a way that userspace does not. I also expect io_uring to get a little faster with time, compared with the kernel I tested on.However, on Linux, OS threads* have been the fastest way to do filesystem and block-device I&#x2F;O for a long time. (* except for CLONE_IO not being set by default, but that flag is ignored in most configurations in current kernels), reply statquontrarian 7 hours agorootparentprevThat is an absolutely amazing video. From a brief, intuitive, and well-diagrammed explanation of non-trivial concepts of queuing theory, to practical examples, to connecting it all to real-world use cases and value, and all within a surprisingly short period of time, it is one of the most impressive technical videos I&#x27;ve ever seen. Thank you. reply Mawr 9 hours agorootparentprev\"With the currency being the same, I keep thinking a salary of $50k&#x2F;year is the same as that of $500k&#x2F;year. Are there any other actual differences?\"Just as with performance improvements [1][2][3][4], the actual impact on the user experience is non-linear and often hard to predict. In the case of virtual threads, you go from needing to consciously work around a limited amount of available threads to spawning one per request and moving on.[1]: https:&#x2F;&#x2F;youtu.be&#x2F;4XpnKHJAok8?t=3026[2]: \"These tests are fast enough that I can hit enter (my test-running keystroke) and have a response before I have time to think. It means that the flow of my thoughts never breaks.\" - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7676948[3]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37277885[4]: \"Go’s execution tracer has suffered from high overhead since its inception in 2014. Historically this has forced potential users to worry about up to 20% of CPU overhead when turning it on. Due to this, it&#x27;s mostly been used in test environments or tricky situations rather than gaining adoption as a continuous profiling signal in production.\" - https:&#x2F;&#x2F;blog.felixge.de&#x2F;waiting-for-go1-21-execution-tracing... reply noelwelsh 17 hours agorootparentprevThe context switch time is much smaller, so yes, better performance. reply krzyk 17 hours agoparentprevYou forgot about 8->17 which ads really nice language features, records alone are greatest feature after lambdas.And 21 brings patterns in switch and records. reply ivanjermakov 14 minutes agoprevI love pattern matching, but without a proper support for variant types it won&#x27;t be as useful as it could.I&#x27;m aware of `permits` clause, but it&#x27;s not good enough. reply ecshafer 19 hours agoprevJava getting better pattern matching is a great change. Id really like more of the functional features to make it into Java.I would love if Java pattern matching could at least get to the level of ruby pattern matching. Ruby pattern matching will allow you to deconstruct arrays and hashes to get pretty complicated patterns, which is really powerful. Right now it seems like Java might have that with a lambda in the pattern, but its not going to be as elegant as ruby where:case {name: &#x27;John&#x27;, friends: [{name: &#x27;Jane&#x27;}, {name: &#x27;Rajesh&#x27;}]} in name:, friends: [{name: first_friend}, *] \"matched: #{first_friend}\" else \"not matched\" end #=> \"matched: Jane\"But the big change here is virtual threads which should be a game changer. reply brightball 18 hours agoparentSimple solution: JRuby.Virtual threads are going to make Ruby fibers work properly for JRuby so that’s going to be huge as well.Charles Nutter gave an update in August. 45 minute mark he talks about virtual threads.https:&#x2F;&#x2F;youtu.be&#x2F;pzm6I4liJlg?si=vKVICrola4OmJIal reply munificent 17 hours agoparentprevWe recently added pattern matching to Dart [1], so I&#x27;m always keen to see how it compares to similar features in other languages. In case it&#x27;s interesting, here&#x27;s that Ruby example ported to Dart: print(switch ({&#x27;name&#x27;: &#x27;John&#x27;, &#x27;friends&#x27;: [{&#x27;name&#x27;: &#x27;Jane&#x27;}, {&#x27;name&#x27;: &#x27;Rajesh&#x27;}]}) { {&#x27;friends&#x27;: [{&#x27;name&#x27;: var firstFriend}, ...]} => \"matched: $firstFriend\", _ => \"not matched\" });Pretty similar! The main differences are that Dart doesn&#x27;t have symbols, so the keys are string literals instead. Also, variable bindings in patterns are explicit (using \"var\") here to disambiguate them from named constant patterns.[1]: https:&#x2F;&#x2F;medium.com&#x2F;dartlang&#x2F;announcing-dart-3-53f065a10635 reply brabel 16 hours agorootparent> We recently added pattern matching to Dart [1]I&#x27;ve been using that and I love it, in general... but can I ask you why do we need to name a variable in a pattern like this: switch (p) { Person(name: var name) => ... }That&#x27;s the only thing that feels a bit annoying as you have to rename the variable... In Java, this would be something like: Person(var name) -> ...EDIT: I guess it&#x27;s to support `Person(name: &#x27;literal&#x27;)` matches.> Dart doesn&#x27;t have symbolsThat&#x27;s weird, as I actually use sometimes `#sym` (which has type `Symbol`)?? print((#sym).runtimeType);This prints `Symbol` :)I know you know Dart in and out, but could you explain why this is not actually a symbol in the way Ruby symbols are? reply munificent 9 hours agorootparentWe require \"var\" before variable patterns because we also allow named constants in patterns (which match if the value is equal to the constant&#x27;s value): const pi = 3.14; &#x2F;&#x2F; Close enough. switch (value) { (pi, var pi) => ... }This case matches a record whose first field is equal to 3.14 and binds the second field to a new variable named \"pi\". Of course, in practice, you wouldn&#x27;t actually shadow a constant like this, but we didn&#x27;t want pattern syntax to require name resolution to be unambiguous, so in contexts where a constant pattern is allowed, we require you to write \"var\", \"final\", or a type to indicate when you want to declare a variable.Swift&#x27;s pattern syntax works pretty much the same way.> > Dart doesn&#x27;t have symbols> That&#x27;s weird, as I actually use sometimes `#sym` (which has type `Symbol`)??Oh, right. I always forget about those. Yes, technically we have symbols, but they are virtually unused and are a mostly pointless wart on the language. It&#x27;s not idiomatic to use them like it is in Ruby. reply brabel 4 hours agorootparentI don&#x27;t find symbols to be pointless. They are useful as \"interned strings\" and that&#x27;s exactly what I need sometimes. I could use `const myThing = \"my thing\";` for that purpose (but with symbols I don&#x27;t need to declare it anywhere, just use it... for better or worse!), I suppose, but before `const` existed, I believe symbols were the only way to do that? reply unregistereddev 19 hours agoparentprevPattern matching is a neat tool to keep in the toolbox. When it&#x27;s the right tool for the job, it is really cool and is a lot cleaner than a bunch of conditional checks. However, I rarely reach for it. Maybe my use cases are unusual? I am genuinely curious how often other developers find pattern matching to be the best tool for the job. reply hibikir 15 hours agorootparentPattern matching is what makes sum types ergonomic enough to be used. Many a Java design doesn&#x27;t use said interface-based sum types because it&#x27;s so cumbersome to use them. But whena language has pattern matching, then suddenly designing with sum types in mind is done a lot, and therefore you see examples of good pattern matching everywhere.When I teach Scala, a very high percentage of the teaching time is ultimately down to re-introducing how to design business domains, because seasoned devs just reach for large classes with a million optional fields, which not only can represent valid systems states, but thousands of invalid ones. reply weatherlight 18 hours agorootparentprevIn languages that have strong support for pattern matching, whether it be on values or types, I find myself reaching for it instead of conditionals. It&#x27;s all about the explicitness for me. You have to list out all the cases you care about, so there&#x27;s no room for ambiguity. Plus, the compiler will usually warn you if you&#x27;ve missed a case, which is like a built-in bug catcher. It&#x27;s also great for working with immutable data, less state to worry about. And let&#x27;s talk about readability; the code basically documents itself because you can see the shape of the data right in front of you. You can even destructure data on the fly, pulling out exactly what you need. If you&#x27;re using a statically-typed language, pattern matching adds an extra layer of type safety. And, not to forget, it nudges you toward a more functional style of coding, which I find leads to cleaner, more modular code. So yeah, I reach for pattern matching quite a bit; it often feels like the right tool for the job. reply Jtsummers 18 hours agorootparentprevWhen available, I pretty much always use pattern matching. It tends to shorten code while not reducing clarity (often increasing it) which means fewer opportunities for errors to creep in. Statically typed languages that can detect incomplete case handling also reduces the chances for some errors (as long as you don&#x27;t make a catch-all case) but also helps when you change something so that a new case is needed. It also tends to shift the code to the left, reducing the indentation. So shorter, clearer, less unnecessary indentation. Generally a positive. reply bcrosby95 18 hours agorootparentprevIt probably depends on the language you&#x27;re using. Pattern matching is awesome in Erlang and Elixir. In most other languages it ranges from \"nice\" to \"bleh\". reply nayuki 18 hours agorootparentPattern matching is awesome in Rust. It carries the stellar legacy of Haskell. reply grumpyprole 14 hours agorootparentprevOne example for you: anytime you needed to use the \"Visitor pattern\" to do a transformation from one representation to another - you don&#x27;t need it now. Sealed classes and pattern matching will be more succinct and easier to reason about. reply ecshafer 16 hours agorootparentprevI think that you can replace almost any If else with pattern matching. Pattern matching makes type checks easier, which if you are really heavily using types through your program, makes pattern matching even better. reply frou_dh 18 hours agoparentprevI really like that Ruby throws NoMatchingPatternError if none of the patterns match. It&#x27;s a bit like the much-acclaimed exhaustive pattern matching in static languages (though at runtime rather than compile-time, obviously) and better than just silently falling off the end, which IIRC is what Python&#x27;s pattern matching does. reply rusk 17 hours agorootparentIn Python you can terminate a for loop with else, which will be run whenever the loop runs to the end without breaking reply frou_dh 1 hour agorootparentThat&#x27;s not particularly relevant to the nice pattern matching property I mentioned. If you need to manually write supplementary code to get the exhaustiveness safety then that&#x27;s back into the realm of bog-standard defensive programming.Here&#x27;s what I mean. The Ruby will throw NoMatchingPatternError and the Python will silently do nothing. x = [10, \"figs\"] case x in [n, \"apples\"] :foo in [n, \"oranges\"] :bar end # --- x = [10, \"figs\"] match x: case [n, \"apples\"]: ... case [n, \"oranges\"]: ... reply specialist 15 hours agorootparentprevNeat. Will check it out.I recently spotted a (new to me) foreach &#x2F; else construct in a templating language (sorry, forget which one); else is invoked if the list is empty. Nice sugar for common outputs like \"no items found\".I appreciate modest syntactic sugar.For instance, my #1 sugar wish is for Java&#x27;s foreach is to do nothing when the list reference is null. Versus tossing a NPE.Eliminates an unnecessary null check and makes the world a little bit more null-safe. reply rusk 4 hours agorootparent> else is invoked if the list is empty.for &#x2F; else should do that too … replyPaulHoule 17 hours agoprev(1) It&#x27;s a bit of a bad smell (which he points out) that records aren&#x27;t being used much at all in the Java stdlib, I wrote something that built out stubs for the 17 and 18 stdlibs and that stood out like a sore thumb. I do like using records though.(2) I&#x27;ve looked at other ways to extend the collections API and related things, seehttps:&#x2F;&#x2F;github.com&#x2F;paulhoule&#x2F;pidoveand I think the sequenced collections could have been done better.(3) Virtual Threads are kinda cool but overrated. Real Threads in Java are already one of the wonders of the web and perform really well for most applications. The cases where Virtual Threads are really a win will be unusual but probably important for somebody. It&#x27;s a good thing it sticks to the threads API as well as it did because I know in the next five years I&#x27;m going to find some case where somebody used Virtual Threads because they thought it was cool and I&#x27;ll have to switch to Real Threads but won&#x27;t have a hard time doing so. reply twic 15 hours agoparentI think the biggest impact of virtual threads is that the ecosystem will abandon asynchronous APIs. No more futures, callbacks, servers where you have to make sure not to block the thread, reactive frameworks, etc. Just nice simple imperative blocking code. Nima is the first example i&#x27;ve seen:https:&#x2F;&#x2F;helidon.io&#x2F;nimaWe&#x27;ve had two production bugs in the last two weeks caused by handlers blocking the server thread in apps using an async web framework, which would simply not have happened with a synchronous server. reply jayd16 14 hours agorootparentYou&#x27;ll still have the structured concurrency calls but that&#x27;s much better than pure callback hell. reply winrid 9 hours agorootparentprevThey won&#x27;t abandon async callback based code.VT have too much memory overhead to be equivalent. reply winrid 6 hours agorootparent* for high performance stuffyou can still wrap the medium speed&#x2F;slower stuff in virtual threads. reply za3faran 6 hours agorootparentDo you have a citation for that? Genuinely curious. reply winrid 5 hours agorootparentThe stack for the VT requires a heap allocation [0], which ok, not huge deal for most scenarios, but something to consider. Reactive programming will avoid that. For example, for a service that doesn&#x27;t do much IO (like an in memory pubsub thing or CDN) you would still want to use reactive programming if you care about performance, since likely the code will be simple anyway.[0] https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;444 reply kaba0 4 hours agorootparentBullshit - reactive frameworks allocate a shit ton of helper classes. replypapercrane 16 hours agoparentprevI suspect if we had records from the start they&#x27;d be all over the stdlib, but because of backwards compatibility they&#x27;ll likely only be considered for new APIs. reply zmmmmm 12 hours agoparentprevI think virtual threads are huge.The problem with regular threads is (a) multi-kb memory stack per thread and (b) consuming a file handle.Either of those severely limits the scalability of the most \"natural\" parallelism constructs in Java (perhaps generally). Whole classes of application can now just be built \"naturally\" where previously there were whole libraries to support it (actors, rxJava, etc etc).It make take a while for people to change their habits, but this could be quite pervasive in how it changes programming in general in all JVM languages. reply fulafel 3 hours agorootparentYou could easily have a million threads if you use multi-kb stacks. Million times multi-kb means multi-gb, that&#x27;s still 3-4 orders of magnitude less than big memory servers&#x2F;VMs. (and 1 order of magnitude less than a normal laptop)What do you mean by using a file handle, is this a Windows platform thing? On *ix, threads don&#x27;t use up file descriptors (but you can still have a million fd&#x27;s at least on linux for other stuff if you want). reply thfuran 1 hour agorootparentBut \"multi-kb\" in this context probably actually means about 1MB. reply fulafel 1 hour agorootparentWhat do you base this on? The stacks and kernel bookkeeping shouldn&#x27;t use nearly this much at least on linux. Keep in mind that thread stacks have are lazily allocated virtual memory so won&#x27;t use as much physical memory as the thread stack size setting shows.If these threads are handling TCP connections and L7 protocol processing on top, you&#x27;re going to have nontrivial both kernel and userspace memory usage per connection too that may dwarf the thread overhead.Here&#x27;s a linux kernel dev (Ingo Molnar) benchmarking Linux in 2002 and starting just shy of 400k threads in 4 GB: https:&#x2F;&#x2F;lkml.iu.edu&#x2F;hypermail&#x2F;linux&#x2F;kernel&#x2F;0209.2&#x2F;1153.html - though on a 32 bit systems lots of objects things are 50% the size compared to current 64 bit. But still gives you a ballpark. reply riku_iki 10 hours agorootparentprev> Either of those severely limits the scalabilityyou can avoid both issues by using 20yo executorservice. reply pron 8 hours agorootparentIf the code is simple, blocking code, then the number of threads required in the pool is the average total duration of a request times the fanout times the request rate. That number can easily reach many thousands and more. reply riku_iki 8 hours agorootparentyes, you shouldn&#x27;t add blocking code into executorservice.. reply pron 45 minutes agorootparentThen you either don&#x27;t get the same scalability that virtual threads give you or you get it but with asynchronous code that requires not just more work but can&#x27;t enjoy the same observability&#x2F;debuggability on the Java platform. reply kaba0 2 hours agorootparentprevWtf, where on Earth do you put blocking code then? Firing off some long-running task in a background thread through executors is bog-standard usecase. replyyankput 14 hours agoparentprevVirtual threads are strictly better than normal threads, no? I am thinking of any reason to still use traditional threads. Is there any downside? reply papercrane 14 hours agorootparentCurrently virtual threads aren&#x27;t a good match if you have a CPU heavy workload. The scheduler isn&#x27;t fair and if your code doesn&#x27;t enter into any blocking code it won&#x27;t be unmounted from the carrier thread. reply YeBanKo 9 hours agorootparentWhy would you use virtual threads for CPU heavy loads? reply kelnos 7 hours agorootparentYou wouldn&#x27;t. The GP was illustrating a situation where virtual threads are not a good substitute for native threads. reply yankput 12 hours agorootparentprevAhh. It makes sense. But it’s much better fit for file io&#x2F;sockets&#x2F;db. reply aggregat 3 hours agoprevWe have 2.1 million LOC in Java and we&#x27;re moving to Java 21 (from 17) in two weeks when we branch for release.We have a hundreds of third party dependencies across the code base, a lot of the big ones (Hibernate, Spring, a lot of Apache). We write a big web application and maintain a big legacy desktop application in Swing.We run a dedicated nightly CI job that is on the latest Java release to get early warning for any incompatibilities. After the painful migration from 8 to 9 so many years ago it has been smooth sailing.In all those version upgrades over all those years and dozens of on premise installations with big customers we have never had a regression or a problem that was caused by the runtime itself. reply Vicinity9635 15 hours agoprevThe examples having to word wrap in a tiny text box look even more absurd and unreadable when the page is only using 1&#x2F;3rd of the screen.What is with this awful formatting? https:&#x2F;&#x2F;i.imgur.com&#x2F;nQmt7Qo.png reply marginalia_nu 18 hours agoprev> Miscellaneous new methods -- mehDunno, several of these are tangible QoL boosts:Math.clamp(), List.reversed(), List.addFirst(), List.addLast(), Character.isEmoji() reply winrid 9 hours agoparentSo I can reverse a list without using \"streams\" now? Thank heavens reply bcrosby95 18 hours agoparentprev> List.reversed(), List.addFirst(), List.addLast()These fall under sequenced collections, not \"miscellaneous new methods\". reply marginalia_nu 18 hours agorootparentI guess? I found them under the API diff linked as \"miscellaneous new features\". reply hinkley 15 hours agoprevWhat&#x27;s the Scala community think about this development? I would think this would affect them quite a lot.Google is not helping. reply rr808 8 hours agoparentScala community always thinks they&#x27;re the best tool. The size of the community is at best static though, Kotlin and re-energized Java took away most of the reasons for using it. I know in my company the teams that went the Scala route complain of huge compile times and really struggle to find people, I think we&#x27;ll probably port back to Java. reply discodachshund 13 hours agoparentprevThe Typelevel folks on Discord are of the opinion it&#x27;s not of much interest to them reply hinkley 11 hours agorootparentI wonder if that&#x27;s \"not interesting\" or \"we already fixed this another way\" reply dionian 11 hours agoparentprevIt&#x27;s great, but irrelevant since Scala is already so far ahead. I will start to care if i am ever forced to do java again. I love how much better Java is getting! Most of these things we have had in scala for a long time already, and much better versions. reply Someone1234 18 hours agoprevIf you&#x27;re viewing that website on a desktop, I strongly suggest removing max-width: 90ch from the body css. Instead of 50% white space, it goes full width and makes the table substantially more readable (particularly the code samples). reply munk-a 17 hours agoparentHilariously enough I was initially confused by this comment because the webpage rendered so readably for me - the base CSS is actually quite reasonable and because I have JS disabled by default the page never re-rendered into the thinner mode. reply Someone1234 17 hours agorootparentIt may be my specific setup. But on a 1440p display, 125% OS scale, I&#x27;m seeing more white left&#x2F;right than actual content in the middle. It is also wrapping the code making it difficult to read.Completely readable at 100% width though. reply pacoverdi 3 hours agoparentprevI viewed it on Firefox for Android and I immediately had to jump to reader mode for the same reason.But I tend to use reader mode on most sites anyway because it&#x27;s an easy way to get rid of banners (cookies, subscription etc.) reply anonymousDan 13 hours agoprevCan anyone explain this comment: \"In the past, a thread pool didn&#x27;t just throttle the incoming requests but also the concurrent resources that your app consumed. If you now accept many more incoming requests, you may need other ways to manage resource consumption.\" reply yCombLinks 12 hours agoparentYeah, if your server maxed out at 256 system threads you didn&#x27;t have to worry about the fact that 1024 simultaneous calls would crash your DB. But now you&#x27;re not limited by system threads reply YeBanKo 8 hours agorootparentYou can still use connection pool + platform threads. Or executor with virtual threads and semaphores or blocking queues. It’s mostly a concern for someone who implements a connection pool, for most devs it’s gonna be the same config option of max connection, that you need to pay attention to.Any modern web app already has multiple instances of the app querying a db, so you have to keep a tally of total connection number either way. reply sylware 48 minutes agoprevI am looking for assembly implemented JVMs (x86_64&#x2F;risc-v&#x2F;etc), that to remove SDK pressure and give stable auditability of machine code.Do those exist? reply mrkeen 18 hours agoprevIn the code example for virtual threads, I have no idea what will happen in parallel.How do I reason about the order in which the calls change the state of the world? reply Jtsummers 17 hours agoparentThat&#x27;s all sequential code, it would be run inside a single \"virtual thread\". Note that the async code on the right is also sequential, just structured through an async API. reply Svenskunganka 13 hours agorootparentFrom my perspective they&#x27;re not entirely equivalent. The async variant seems to be batching getImages and saveImages, while the sync variant gets and saves each image individually, sequentially. reply Jtsummers 13 hours agorootparentThey aren&#x27;t perfectly equivalent because the virtual thread example uses a loop instead of the following (dropping the try&#x2F;catch): &#x2F;&#x2F; client.sendAsync(request, HttpResponse.BodyHandlers.ofString()) var response = client.send(request, HttpResponse.BodyHandlers.ofString()); &#x2F;&#x2F; .thenApply(HttpResponse::body) var body = response.body(); &#x2F;&#x2F; .thenApply(this::getImageURLs) var urls = getImageURLs(body); &#x2F;&#x2F; .thenCompose(this::getImages) var images = getImages(urls); &#x2F;&#x2F; .thenAccept(this::saveImages) saveImages(images);And if it had been written this way it would have been clearer that they are, in fact, equivalent. But generally people don&#x27;t write like this, they use looping constructs.Regardless, the important bit is that the parallel&#x2F;concurrent bit of the async one is that it is cast off into an async system. The following execution steps are, well, steps. Each executed in sequence. Just like the body of the virtual thread example would be executed, but without the cumbersome noise of thenApply and thenCompose and such. reply logicchains 14 hours agoprevDoes anyone know if Java virtual threads will also have channels and a select concept, like in Go? reply shaunxcode 4 hours agoparentJust spit balling but you should be able to use clojure core async channels and the blocking put&#x2F;take&#x2F;alts functions. Would probably take a small amount of work to expose those things to Java in an idiomatic way but should be doable. Please take all of that with a giant grain of salt though! reply kaba0 5 hours agoparentprevJava already has many more concurrent and parallel data structures, so while it likely won’t have a keyword, it can definitely do it already. reply aardvark179 13 hours agoparentprevI think at some point yes. We certainly discussed it but it’s one of those things that takes time to really get right and performant. reply billfruit 17 hours agoprevDoes it add stdint style names for integer types, unsigned integer types etc? reply layer8 17 hours agoparentThe size of the integer types are already fixed by the JVM specification (int is always 32 bits, etc.), and there are no unsigned integer types in Java except for char (a 16-bit unsigned integer type). Furthermore, Java does not support alias names for types. Hence it’s unclear what your question is aiming at. reply szatkus 16 hours agoparentprevAFAIK Java 8 added a few methods that helps you handle integers as if they were unsigned, like `toUnsignedString`. I think it&#x27;s enough for any exotic cases. reply waynesonfire 17 hours agoprev> Over 10,000 bug fixesMost of which were likely introduced during new feature development in recent releases. To suggest that this on its own somehow manifests a more stable jdk compared to some ancient, battle tested version of the jdk is debatable.I find it rather concerning that so many bugs exist to begin with. Why are these not caught sooner?Has the whole world gone crazy? Am I the only one around here who gives a shit about quality? Mark it zero! reply specialist 15 hours agoparentRandomly looking at bugs fixed the last 10 weeks, it seems like a healthy mix of old and new bugs.https:&#x2F;&#x2F;bugs.openjdk.org&#x2F;browse&#x2F;JDK-8316305?filter=-7&jql=pr...Being allergic to JIRA, my JIRA-fu is weak, so there&#x27;s probably an easier&#x2F;faster way to report bugs fixed in v21.Any way.> Am I the only one around here who gives a shit about quality?Ages ago, I was a QA&#x2F;Test manager. So I appreciate your sentiment. But it seems to me that Oracle&#x27;s being a FANTASTIC shepherd of Java. Definitely a huge upgrade, at the very least. reply rr808 8 hours agoparentprevJava has been around for nearly 30 years, I&#x27;d hope the core libraries had very few bugs by now. reply doodpants 15 hours agoparentprevYou might be the only person in the world who writes bug-free code on the first try. reply baq 18 hours agoprevnext [–]> \"Hello, World!\".splitWithDelimiters > (\"\\\\pP\\\\s\\*\", -1) > &#x2F;&#x2F; [\"Hello\", \", \", \"World\", \"!\", \"\"]> MehMy brain just melted. reply hinkley 15 hours agoparentI&#x27;d have a lot of uses for that. But also worry about it enabling more stringly-typed code. reply hoistbypetard 11 hours agoprev [–] It sounds like it has some neat new features. But I&#x27;ll never know because I&#x27;m never again going to use another Oracle thing. There&#x27;s not a thing they could make that&#x27;s good enough for me to agree to one of their EULAs and install it. Their behavior in that area is just staggeringly bad. reply matt_heimer 10 hours agoparentThen use Java without agreeing to an Oracle EULA. You can get a GPLv2 open source build from https:&#x2F;&#x2F;jdk.java.net&#x2F;21&#x2F;If you don&#x27;t trust the Oracle based open source builds then just wait a bit for Microsoft, Redhat, and others to release their version 21 OpenJDK builds that will be found under https:&#x2F;&#x2F;adoptium.net&#x2F;marketplace&#x2F; reply kaba0 4 hours agoparentprev [–] Not this bullshit again. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Java 21 has been launched as the \"long term support\" version, bringing improvements like pattern matching for switch statements, record patterns, sequenced collections, and virtual threads.",
      "Notable are the virtual threads, which address concurrent request handling, and pattern matching that eases working with sealed hierarchies and records.",
      "The release promises a substantial maintenance boost with over 10,000 bug fixes, making it an advantageous upgrade."
    ],
    "commentSummary": [
      "The text comprises diverse discussions concerning features like virtual threads in Java and pattern matching in programming languages.",
      "The discourse also touches on the subject of software package and dependency upgrade; detailing the merits, limitations, and particular challenges associated with these functionalities.",
      "However, the text summary lacks clarity and coherence in providing a straightforward understanding of the discussed topics."
    ],
    "points": 252,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1695394977
  },
  {
    "id": 37614793,
    "title": "An open letter to our community",
    "originLink": "https://blog.unity.com/news/open-letter-on-runtime-fee",
    "originBody": "Search Unity Products Solutions Learning Support & Services Community Dev tools See plans & pricing Unity Blog NewsEngine & platformGamesIndustryDevBlog An open letter to our community By Marc Whitten September 22, 2023 in News3 min. read Topics covered Company announcement Editor Unity Enterprise Unity Personal Unity Pro Share To our community: I’m Marc Whitten, and I lead Unity Create which includes the Unity engine and editor teams. I want to start with this: I am sorry. We should have spoken with more of you and we should have incorporated more of your feedback before announcing our new Runtime Fee policy. Our goal with this policy is to ensure we can continue to support you today and tomorrow, and keep deeply investing in our game engine. You are what makes Unity great, and we know we need to listen, and work hard to earn your trust. We have heard your concerns, and we are making changes in the policy we announced to address them. Our Unity Personal plan will remain free and there will be no Runtime Fee for games built on Unity Personal. We will be increasing the cap from $100,000 to $200,000 and we will remove the requirement to use the Made with Unity splash screen. No game with less than $1 million in trailing 12-month revenue will be subject to the fee. For those creators on Unity Pro and Unity Enterprise, we are also making changes based on your feedback. The Runtime Fee policy will only apply beginning with the next LTS version of Unity shipping in 2024 and beyond. Your games that are currently shipped and the projects you are currently working on will not be included – unless you choose to upgrade them to this new version of Unity. We will make sure that you can stay on the terms applicable for the version of Unity editor you are using – as long as you keep using that version. For games that are subject to the runtime fee, we are giving you a choice of either a 2.5% revenue share or the calculated amount based on the number of new people engaging with your game each month. Both of these numbers are self-reported from data you already have available. You will always be billed the lesser amount. We want to continue to build the best engine for creators. We truly love this industry and you are the reason why. I’d like to invite you to join me for a live fireside chat hosted by Jason Weimann today at 4:00 pm ET/1:00 pm PT, where I will do my best to answer your questions. In the meantime, here are some more details.* Thank you for caring as deeply as you do, and thank you for giving us hard feedback. Marc Whitten *We are working to localize translations of this web page. By Marc Whitten September 22, 2023 in News3 min. read Topics covered Company announcement Editor Unity Enterprise Unity Personal Unity Pro Related Posts Unity plan pricing and packaging updates By Unity Technologies In January 2024, Unity will introduce a new Unity Runtime Fee based on game installs. Prior to this, Unity subscription plans will add cloud-based asset storage, Unity DevOps tools, and AI at runtime at no additional cost. in News9 min. read Where might AI take gamedev next? By Luc Barthelet AI brings the promise of making real-time creation accessible to more people, and simplifying some development tasks to let you focus on being creative while helping you to achieve more with less. in Games8 min. read Unity 2023.3 coming April 2024 with updates for graphics and performance By Ralph Hauwert Find out how Unity is changing its engine development methodologies to provide you with the most stable builds. in Engine & platform9 min. read The power of Unity Wētā Tools for artists, workflows By Alice Gardner Unity Wētā Tools bring together award-winning solutions from Wētā Digital, Ziva, SpeedTree, and Unity for character, environment, and compositing. Discover how this product suite can transform creativity. in News5 min. read Navigation News Engine & platform Games Industry DevBlog Language English 中文 Deutsch Español 日本語 Русский Français 한국어 Português More Reading lists RSS feeds Social Purchase Products Subscription Asset Store Resellers Education Students Educators Certification Learn Center of Excellence Download Get Unity Download Archive Beta Program Unity Labs Labs Publications Resources Learn platform Community Documentation Unity QA FAQ Services Status Case Studies Made with Unity Unity Our Company Brand Newsletter Blog Events Careers Help Press Partners Investors Affiliates Security Social Impact Inclusion & Diversity Copyright © 2023 Unity Technologies Legal Privacy Policy Cookies Do Not Sell My Personal Information Your Privacy Choices (Cookie Settings) \"Unity\", Unity logos, and other Unity trademarks are trademarks or registered trademarks of Unity Technologies or its affiliates in the U.S. and elsewhere (more info here). Other names or brands are trademarks of their respective owners. This website uses cookies to enhance user experience and to analyze performance and traffic on our website. We also share information about your use of our site with our social media, advertising and analytics partners. Cookie Settings Reject All Accept Cookies",
    "commentLink": "https://news.ycombinator.com/item?id=37614793",
    "commentBody": "An open letter to our communityHacker NewspastloginAn open letter to our community (unity.com) 234 points by gmjosack 17 hours ago| hidepastfavorite195 comments cmcaleer 17 hours agoI think it might be too little too late. I do wonder if this was always the plan with classic door-in-the-face technique, but I can&#x27;t imagine they would have anticipated the absolute magnitude of backlash. Their product certainly isn&#x27;t as special as they clearly think it is, and the fact that they attempted to unilaterally change the contract in as egregious as way as they did is unacceptable and not behaviour I would want from a vendor I&#x27;m reliant on. Anecdotally, I&#x27;m seeing a lot of game devs being surprised at relative ease of migration in some instances, though I imagine there are megaprojects which will have a much worse time.Crow had to be eaten but it looks like they&#x27;re only tasting the feathers. reply dpkonofa 17 hours agoparentThis is it, in a nutshell. People don&#x27;t want the apology. They want to know that a decision like this doesn&#x27;t have a chance of happening because the people in charge know it&#x27;s a bad idea before it leaves the door. No one wants to be stuck in a cycle of getting fucked and then boycotting to get what they want, especially for something that their livelihood depends on. They want a product made by people they trust who are making decisions in the best interest of the users&#x2F;creators and not only decisions that are in the best interest of the company. reply hn_throwaway_99 16 hours agorootparentIt&#x27;s amazing to me how very smart people in corporations can convince themselves (and I mean, like really believe it) that the shit sandwich they are serving up is actually filet mignon. It&#x27;s the whole \"it&#x27;s very hard for someone to understand something when their paycheck depends on not understanding it\" issue. I&#x27;ve seen it a few times in person, where I&#x27;m like \"How the f are we convincing ourselves of this?\"2 recommendations:1. This is where a \"neuro-diverse\" person or two can really be an asset. The social dynamic in corporations often leads to people eventually shaking their heads in agreement, even if they have big underlying concerns. Those of us somewhere on the spectrum are less likely to understand those social dynamics in the first place and be more willing to call out BS.2. Good corporate leaders have trusted outside council that they can run ideas by to get brutally honest feedback. reply coldpie 16 hours agorootparentI haven&#x27;t seen any evidence that anyone smart was involved in this decision. There&#x27;s been some hints that the actual smart people (devs, customer support folks) were screaming bloody murder that it was a terrible idea, but the execs pushed it through anyway. This is yet another entry in the enormous list of evidence that becoming the head of a company does not require any intelligence. Quite the opposite, apparently. reply hn_throwaway_99 12 hours agorootparentDon&#x27;t mean to defend the execs that made this decision too much, but I think saying \"they&#x27;re all just idiots\" is probably not what really happened.Basically, execs (especially public company execs) have the responsibility for growing revenue and earnings. Ideally they do that by just making better products, but some times you do need to \"thread the needle\" by charging more for your products while not pissing off customers too much.I&#x27;m sure the devs and customer support folks were screaming bloody murder, but they are also not responsible for satisfying public markets, so it&#x27;s easier to say those things without having to worry about revenue growth.So point being, I&#x27;m sure execs thought there would be some blowback, but they probably felt it would be \"manageable\", and like others have said, they overestimated the irreplaceability of Unity. So its important at the exec level to have someone who can whisper in your ear, someone who does understand the requirement for growing revenue, that can honestly say \"you&#x27;ve managed to convince yourself of this bullshit.\" reply jenkstom 15 hours agorootparentprevThere are so many things left unsaid, but implied, in this post. I love it. reply m463 14 hours agorootparentprevI wonder what the reality really is? Does this stuff all blow over?Thinking back to recent controversies:- reddit with third party apps- the D&D open gaming license- redhat and centos- etc... reply dpkonofa 10 hours agorootparentI think it does, to an extent. Reddit is still alive, for example. It&#x27;s just nowhere near the community and content it used to be and, in my mind, it won&#x27;t ever be that way again. Reddit&#x27;s biggest benefit was that most of the moderators were people who were really, really into very niche topics. The big subs were all moderated by the same 10 people so they devolved into meme depositories and made up stories that stoked emotions. Now that the principled mods have left and those niche subreddits are being taken over by people who care more about the memes than the topic at hand, it&#x27;s falling apart. reply badRNG 7 hours agorootparentReddit, like Twitter, isn&#x27;t going anywhere. It&#x27;s just a worse value for the end user, and in Reddit&#x27;s case the business is potentially better off for it, users be damned. reply dpkonofa 2 hours agorootparentI disagree. Twitter is already dying, albeit slowly. Reddit will suffer the same fate. The entire reason Reddit grew the way it did was because it had content that other sites didn&#x27;t have and the reason it had that content was because of the niche subreddits modded by people who were extremely passionate about niche stuff. Reddit won&#x27;t grow anymore because the content being fed to it now is just content stolen from other sites and it&#x27;s not any easier to access or better for being on Reddit. It&#x27;s a worse value for the end user because the value was in the people that have now all left. reply drpossum 15 hours agorootparentprevMaybe, judging by their actions, they&#x27;re not actually that smart. reply the_snooze 16 hours agorootparentprevExactly. If your project or organization is dependent on some external product or platform, that thing had better be boring and predictable. Busy people don&#x27;t have the time or the patience to be jerked around by external surprises.Walk-back or not, Unity is demonstrably not boring and predictable anymore. That&#x27;s done. reply sounds 16 hours agorootparentOh they didn&#x27;t walk it back. It&#x27;s now one of two ways for them to get a percent of your revenue - that did change.(It also was only going to kick in once your revenue hit a certain point.)The CEO John R. didn&#x27;t chime in here, and that would have meant him being accountable for this decision and its effect on Unity. His mask slipped here. reply brucethemoose2 16 hours agorootparentThey did walk back charging per download&#x2F;install.There was no way they couldn&#x27;t. Its literally not practical. reply 3836293648 15 hours agorootparentThey only walked back it applying retroactively. Now it&#x27;s from the next LTS release.It applying to free games was walked back immediately and isn&#x27;t news reply Applejinx 16 hours agorootparentprevYou misunderstand, I think.ACCOUNTABILITY would not be practical.Them charging for whatever they can make up and claim to be true, is neither walked back or not walked back. It&#x27;s waiting to happen again, in whatever way they dream up. You&#x27;re assuming they wouldn&#x27;t simply make stuff up and that there would be a chain of accountability, so the process would make sense.Such things are for making money, not sense. You have not seen the last of them. reply coldpie 15 hours agorootparentprevSorry, where did they walk it back? The letter linked in this thread still refers to the \"runtime fee\". reply brucethemoose2 15 hours agorootparenthttps:&#x2F;&#x2F;www.axios.com&#x2F;2023&#x2F;09&#x2F;13&#x2F;unity-runtime-fee-policy-ma...> After initially telling Axios earlier Tuesday that a player installing a game, deleting it and installing it again would result in multiple fees, Unity&#x27;sWhitten told Axios that the company would actually only charge for an initial installation. (A spokesperson told Axios that Unity had \"regrouped\" to discuss the issue.) reply dpkonofa 9 hours agorootparentThat&#x27;s not walking back. That&#x27;s taking a step back. The runtime fees still exist. reply usea 15 hours agorootparentprevIf you&#x27;re working on strategy at Unity in good faith right now, I think you announce like they did rather than having the CEO take accountability. Because I think the CEO apology strategy depends on the CEO&#x27;s ability to convince people he&#x27;s sincere and contrite. That&#x27;s a tall order under these circumstances. reply hintymad 12 hours agorootparentprevIs Unity&#x27;s CEO a product guy? It appears that the CEO does not give a shit to the product, or details of pricing policy in this particular case. If so, I could never understand how a tech company would get someone who wouldn&#x27;t pay attention to such details. reply dredmorbius 15 hours agorootparentprevI don&#x27;t have a horse in the Unity issue, though I&#x27;ve been following it loosely. I can speak to my own response to another organisation.I&#x27;d written off Reddit personally around five-six years ago. This despite having a fairly long-lived bloggy subreddit (and a small smattering of others) on the site, which I still use as a reference (despite having taken it private).It wasn&#x27;t specifically on account of the specific technical decisions they&#x27;d made, or the site changes (or lack of site changes) resulting, but the fact that those decisions were being made. That is, as with other business organisations I&#x27;ve encountered over the years, Reddit had repeatedly proven themselves antithetical to my own interests and values.I suspect that&#x27;s the issue Unity&#x27;s going through here, and that though the final endgame may take some time in coming, it could well doom the company.One business strategy that seems to have been increasingly widely adopted over the past decade or two, or perhaps I&#x27;m only simply far more cognisant of it and recognise it where it occurs, is the \"walk right up to the creepy line\" approach (as Eric Schmidt put it: ), or moving products or services right to the pain or tolerance threshold.In the short term this can work. It can even be successful over a longer term, in cases. But there are two inherent problems with the concept:1. The threshold, whether it&#x27;s pain, tolerance, creepiness, or whatever, can change, and often startlingly suddenly. At which point the organisation is caught high and dry.2. The long-term erosion of trust and affection for the firm and its products effectively primes a trigger of latent demand for any viable alternative which appears. An example that comes to mind is the exclusive launch of Apple&#x27;s iPhone in the US by AT&T. On the day that Verizon began officially supporting the iPhone on their own network, people were cramming Verizon stores and phone lines trying to make the switch. (A cow-orker at the time was one of those people.) They were absolutely fed up with AT&T&#x27;s service and behaviour. See:and , discussed at the time:and .I&#x27;ve seen IBM, Microsoft, and Google subject to similar shifts, some more pronounced than others, over the years.Leaving a considerable goodwill moat around offerings is an alternative. I&#x27;m too far outside the consumer mainstream to know what business, products, services, and&#x2F;or brands exemplify this, though I suspect Costco and Trader Joe&#x27;s might be among these. reply SleekEagle 14 hours agorootparent> moving products or services right to the pain or tolerance thresholdWhen did we start talking about the airline industry?But seriously, the reason it works for the airline industry is because there is literally no other alternative, unlike in this case. reply dpkonofa 9 hours agorootparentThis is a great take because I suspect that the airline industry is exactly the reason why all these companies are now in the \"death by a thousand cuts\" stage of their strategies. Literally no one prefers the airlines today and the experience of flying to the same degree (and especially not more) than they did a decade ago or more. Everything about the experience, from the boarding to the seating to the food, is objectively worse than it was before and yet people still need to fly. reply dredmorbius 13 hours agorootparentprevCommercial office real estate is another example that comes to mind.TINA. Until suddenly, with COVID-19, there was an alternative.And the real estate market is now (slowly) imploding. reply krapp 16 hours agorootparentprev>No one wants to be stuck in a cycle of getting fucked and then boycotting to get what they want, especially for something that their livelihood depends on.A lot of devs and studios are, they know they are, Unity knows they are, and there&#x27;s little anyone can afford to do about it. I suspect most of the crowd that ostensibly abandoned Unity will return because they&#x27;ve already sunk too much time and energy into the platform, and that&#x27;s the path of least resistance. They will tolerate whatever deal Unity gives them because they can&#x27;t afford to do otherwise. Even if they liked the alternatives, the only reasonable business decision is to return to Unity and pretend this never happened.Unfortunately this probably means much of the interest in Godot and other open source alternatives this debacle created is about to evaporate. Inertia is a harsh mistress. reply cowsup 17 hours agoparentprevUnity lost a lot of goodwill among developers, and it took over a week for them to admit fault. I seriously doubt they planned all along to present a temporary horrible plan, to make their “real” plan easier to swallow.If this were a 48- or 72-hour turnaround, maybe. But Unity lost a lot of goodwill amongst developers and there are some they may never get back as a result. reply intelVISA 16 hours agorootparentDevelopers aren&#x27;t the ones choosing Unity most of the time... reply drpossum 16 hours agorootparentIf you&#x27;re working in a development environment where management is drawing hard lines at choosing your tooling you should find a place that&#x27;s going to succeed. reply djbusby 15 hours agorootparentSometimes the tooling is in place before you arrive. reply drpossum 14 hours agorootparentThat&#x27;s right and you have a choice to accept that job. If the tooling takes you by surprise you either didn&#x27;t do your due diligence with a new employer or you were lied to. reply Macha 16 hours agorootparentprevIt feels like any game developer or publisher big enough to be dictating engines top down probably has their own engine? reply johnfernow 14 hours agorootparentFor a lot of studios, even very large ones, that&#x27;s not the case anymore, and even those that have their own engines don&#x27;t use them for everything. Nintendo has several engines, but Pokémon Go is made in Unity, as was Mario Kart Tour and Pokémon Brilliant Diamond and Pokémon Shining Pearl. miHoYo has over 5000 employees but they still use Unity for Genshin Impact and some of their other games. Blizzard surely had the money to make their own engine for Hearthstone, but they chose Unity.This is even more pronounced for Unreal, where Final Fantasy VII Remake, Valorant, Apex Legends Mobile, Star Wars Jedi Fallen Order and Survivor, Octopath Traveler, and tons of other wildly profitable games are made in it. CD Projekt Red is making the next Witcher game in Unreal as well. Square Enix has a ton of money and thousands of employees, as does Riot Games, EA, and plenty of other huge companies. Nearly all of these companies have developed their own engines in the past, but Unity and Unreal are just really hard to beat: not only can they offer great performance and stability, as well as easy multiplatform support (can publish on Windows, PlayStation, Switch, Xbox, iOS, Android, etc.), but it also can make development easier since new employees likely already are familiar with the engine, versus if you build your own it can take months for new employees to be productive and contribute much of anything to the project.Often times they&#x27;ll still make changes to the engine&#x27;s source code (miHoyo didn&#x27;t just download the latest Unity LTS from the website or Unity Hub), but that&#x27;s still considerably less work than building your own engine from scratch, and in many cases even that&#x27;s not necessary. reply bigstrat2003 1 hour agorootparentOn the topic of Square Enix, what&#x27;s bizarre to me is that FF7R is the odd one out among recent games. FF15 and FF16 were on two different internally developed engines! I wonder if the reason FF7R used UE is because it was originally being developed outside, before Square was unhappy with how development was going and brought it back in house. reply imtringued 2 hours agorootparentprevDo you really think that a 10 person indie shop is going to have every single person choose their own favorite engine? reply Macha 19 minutes agorootparentNo, but I&#x27;d expect the person choosing the engine for the 10 person indie shop to be a developer. reply msk-lywenn 16 hours agorootparentprevHuh? Who then? reply cmrdporcupine 16 hours agorootparentprevBut they were at one point. I&#x27;m not in gamedev but I do recall people being enthused about it some years ago.When you lose that audience and enthusiasm among the people who influence next year&#x27;s technical decisions, eventually you enter the dustbin of history. reply morrbo 16 hours agoparentprevI simply don&#x27;t trust publicly traded companies these days. I genuinely can&#x27;t think of an example where a private company in the tech space has become better since going public. I don&#x27;t like to MBA bash, but it large tech companies genuinely seem filled with people who don&#x27;t even like tech (let alone love it) and are just happy to squeeze everything and everyone at any opportunity. I&#x27;m genuinely concerned and waiting for the enshittification of the next round of companies - people like cloudflare - then I guess I&#x27;ll just give up on anything mainstream and remain an indy Dev doing indy things for fun reply hn_throwaway_99 4 hours agorootparentI definitely agree with this sentiment. And it&#x27;s not just publicly traded companies - I like the saying \"private equity kills everything it touches\" because whenever PE buys a a company I have never seen it turn to anything but a shit pile eventually.At some point with all companies the finance people take over. But well-loved products and companies are never created by finance people - they&#x27;re created by people with a passion for something. reply blastro 14 hours agorootparentprevI got a new pair of lululemon pants this week and they&#x27;re terrible quality compared to year&#x27;s past. I remember their CEO saying they were trying to double their stock price this year. Know I know how. reply PaulKeeble 16 hours agoparentprevYou don&#x27;t build buildings on sinking sand regardless of whether for now it appears not to be sinking. Once the footing has proved unstable its best to build elsewhere. reply gumballindie 16 hours agoparentprevCat’s out of the bag. I gave godot a try and it’s absolutely amazing! It felt great working with open source tools - i could finally read the source when i needed to understand something. Indeed it lacks some features but it is an amazing engine. Unity and their ceo has proven to be untrustworthy. I am getting the sense that open source engines will eat their market share. reply Applejinx 16 hours agorootparentI&#x27;m curious to see how quickly it gains a performant 3D layer now that people capable of getting performance out of Unity are looking at it.It was interesting seeing some people bounce off it on the grounds of woeful inefficiency. I don&#x27;t remember the person, but one Unity refugee traced the path of a raycast and Godot more or less needed to treat it as a dynamically typed generic thing, going through a huge rigamarole to get a result.It&#x27;s possible to hack in more direct access for those who can make sense of it. I don&#x27;t think there&#x27;s a thing going on in Godot&#x27;s 3d engine that some of these Unity refugees can&#x27;t understand. They&#x27;re running into arbitrary obstacles based on Godot&#x27;s attitude towards what&#x27;s clean and elegant code. These obstacles could go away really quickly under the right conditions… reply gumballindie 14 hours agorootparent> it gains a performant 3D layerIt already is pretty darn performant - but without the many convenience features unity and unreal have. Also it does lack means to modify vertex buffers directly on the GPU - a feature I liked in Unity (https:&#x2F;&#x2F;docs.unity3d.com&#x2F;ScriptReference&#x2F;Mesh.GetVertexBuffe...). However, I think godot shouldn&#x27;t try and implement everything - the project should focus on getting core functionality performant and flexible enough.Everything else - managing massive world, etc, should be done by 3rd parties and monetised. I hope the game dev world wont take the web dev world path where code is in oversupply and there are little options to monetise.Unity&#x27;s asset store allowed many people to gain freedom by selling assets. I think godot should follow the same path. But indeed for that the engine needs even more low level access exposed in a nice manner. reply ajvs 1 hour agorootparent> I hope the game dev world wont take the web dev world path where code is in oversupply and there are little options to monetise.Very beneficial for the consumer however. Right now the bar to create a good videogame is rather high, and this leads to the current hellscape where so many videogames are plagued with lootboxes, season passes and other microtransactions to make up for the multiple years in dev time required with many employees.If the tooling gets better to the point that it takes less time and less devs to create good games that don&#x27;t require the insane levels of monetisation, then this trend is more likely to be reversed. reply imtringued 1 hour agorootparentprev>It&#x27;s possible to hack in more direct access for those who can make sense of it.>These obstacles could go away really quickly under the right conditions…I&#x27;m not sure why you feel the need to paraphrase this so much but the GDextension API is a thing and it is more efficient but it hasn&#x27;t been implemented for C#. The blog poster extrapolated from the C# bindings that there are unfixable flaws in the engine when in reality the C# bindings aren&#x27;t up to date yet. reply krapp 15 hours agorootparentprev>I don&#x27;t remember the person, but one Unity refugee traced the path of a raycast and Godot more or less needed to treat it as a dynamically typed generic thing, going through a huge rigamarole to get a result.There was a whole HN thread about it[0], and the response[1].[0]https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37561762[1]https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37598985 reply DonHopkins 9 hours agorootparentprevUnity also has a C# wrapper layer around C++ objects. Most of the performant stuff is written in C++, and the C# source code they provide as reference is just a wrapper around it.For example, the Cloth bindings with annotations like [NativeHeader(\"Modules&#x2F;Cloth&#x2F;Cloth.h\")] and [NativeClass(\"Unity::Cloth\")]:https:&#x2F;&#x2F;github.com&#x2F;Unity-Technologies&#x2F;UnityCsReference&#x2F;blob&#x2F;... reply raincole 16 hours agoparentprevUnity definitely hurt itself in confusion.My anecdoate is that many people in this industry don&#x27;t even know the existance of Godot. Yeah, I mean Godot, not Love2D or LibGDX. People can work in video games but are completly unaware of Godot.Now they ALL know it. reply EA-3167 17 hours agoparentprevI think the bottom line damage is that no one is going to develop new games on Unity if they have any other choice. Even if Unity walks this back 100%, why would a dev trust them not to pull this again in the future? Maybe some large projects will stop looking at migration in the short-term, but any new work is going to start happening elsewhere for sure. reply sangnoir 16 hours agorootparent> Even if Unity walks this back 100%, why would a dev trust them not to pull this again in the future?This is why I stopped paying JetBrains, despite them 100% walking back their idiotic licensing change proposal many years ago. I love(d) the products, but could no longer trust the decision-makers. reply PaulKeeble 16 hours agorootparentThey went back to the monthly billing with no option for buying a version permenantly. I think you can still fix your version for a while without upgrades but they will force an upgrade at some point now. The original issue I complained about has returned. reply maccard 16 hours agorootparentI don&#x27;t know of them for ing an upgrade. If you subscribe for 12 months you get perpetual access to the version that was available when you subscribed, so you can buy a version for 12 monthly subscriptions. There&#x27;s nothing wrong with that IMO reply Macha 16 hours agorootparentprevJetbrains?Seems the same model it was when they moved to subscriptions:https:&#x2F;&#x2F;sales.jetbrains.com&#x2F;hc&#x2F;en-gb&#x2F;articles&#x2F;206544479-Subs...https:&#x2F;&#x2F;sales.jetbrains.com&#x2F;hc&#x2F;en-gb&#x2F;articles&#x2F;207240845-What... reply sangnoir 16 hours agorootparent> Jetbrains?Yes!> Seems the same model it was when they moved to subscriptionsIndeed, but there was a period of brain-dead decision making in 2015 where they announced a very different direction and back-tracked 2 weeks later.They announced plans for an evergreen subscription model, but the flip side was that they&#x27;d brick your IDE (with no fallback) the moment your subscription lapsed[1]. The only reason the subscription model seems unchanged from their initial one was because of the outrage their controversial change generated.I found this unconscionable - they backtracked (faster than Unity to their credit, but still)1. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10170089 reply Macha 16 hours agorootparentYes, that was years ago, the \"move to subscriptions\" that the since in my post referred to. The parent poster was claiming they&#x27;d backtracked since on getting the perpetual fallback license, which doesn&#x27;t seem true. reply sangnoir 15 hours agorootparentGot it - I mixed up the reply levels replyvsareto 16 hours agoparentprevI think their product is technically special -- as with all of the commercial game engines -- but they were not in the market position they thought they were, which is what led to them to thinking this was a good idea.Very much an unforced error on their part. reply HellDunkel 16 hours agoparentprevShow some respect and let the CEO go. reply peteforde 14 hours agoprevIt&#x27;s really telling to me that we&#x27;ve heard not a peep from co-founder and CTO Joachim Ante.Oh wait, apparently he is no longer CTO as of May 2023.Well, what was his last official statement?https:&#x2F;&#x2F;blog.unity.com&#x2F;community&#x2F;updated-terms-of-service-an...\"When you make a game with Unity, you own the content and you should have the right to put it wherever you want. Our TOS didn&#x27;t reflect this principle - something that is not in line with who we are.We charge a flat fee per-seat -- not a royalty on all of your revenue. Building Unity takes a lot of resources, and we believe that partnerships make better services for developers and augment our business model -- as opposed to charging developers to pay for Unity’s development through revenue share.When you obtain a version of Unity, and don’t upgrade your project, we think you should be able to stick to that version of the TOS.\"Well, that all sounds pretty good to me! Perhaps its time for Joe to pull a Steve Jobs style comeback. reply AndrewKemendo 7 hours agoparentHe was perfecting the “rest and vest” while I was there. reply johnnyanmac 3 hours agorootparentClearly worked at a different part of Unity. Joe was very involved on the DOTS side while I was there. Arguably a bit too involved at times.But I&#x27;d take that 1000x over what other c execs were doing at other places I worked at. reply gmjosack 17 hours agoprevThis is basically everything policy wise they needed to do to quell the storm. This is honestly what should have just been announced originally. So much reputational damage just to arrive at a reasonable model weeks later.I&#x27;m happy for all the Unity developers out there that are breathing a sigh of relief. Hopefully they can ship their ongoing projects but I&#x27;d be hesitant about a continued long term relationship with Unity after this.This isn&#x27;t the first Unity backlash and I&#x27;d be surprised if it&#x27;s the last. reply misnome 16 hours agoparentHow does this help anything when they have already demonstrated their willingness to alter terms and retrospectively add fees or alter licensing conditions. They already walked back changes once before saying “Okay you can keep the terms you agreed on your version” and went back on that promise for this clusterfuck.They burned the trust bridge and nothing they _ever_ do or can say will bring that trust back. reply ASalazarMX 16 hours agorootparentCompared to how other companies behave, Reddit for example, it&#x27;s a good signal to their customers that they&#x27;ve come to their senses and reached a reasonable compromise. Also, a second mistake like this would be devastating, so hopefully Unity will handle changes better from now on. reply soerxpso 12 hours agorootparentI&#x27;m not so sure. Although the opportunity hasn&#x27;t really even come up, one thing that Reddit has never done is make an agreement along the lines of, \"You can use X version of this software under this license forever,\" in their own ToS, and then suddenly go back on it and declare that, actually, everyone they had that agreement with is now subject to arbitrary new rules. While Reddit has done some sketchy and user-hostile things in the past, it&#x27;s an entirely different category.It&#x27;s a can of worms that cannot be closed. Even the apology-promises they&#x27;re making right now are subject to random change, because they&#x27;ve made clear that they don&#x27;t see their own ToS as binding for them. The article says, \"We will make sure that you can stay on the terms applicable for the version of Unity editor you are using – as long as you keep using that version,\" and we&#x27;re supposed to be reassured by that, but they&#x27;ve already said that exact thing before and shown that it was meaningless. What&#x27;s to stop them from deciding next week that they changed their minds on their commitments again? They may have learned that they can&#x27;t make such grand changes all at once without a boycott, but they could think that they can still roll out the same types of changes piecemeal over the next few years (and they might be right). What&#x27;s to stop them from finding new ways to skirt around these commitments in the future (for example: adding some sort of planned obsolescence to future LTS versions to ensure that, even though you are technically allowed to use them under an old ToS, actually doing so would be completely untenable)?Personally, I wouldn&#x27;t trust anything this company says unless I have a legally binding contract with them, with clear damages defined if they break it (this may be the case for some larger studios, and that&#x27;s fine for them). They can say anything they want in a PR release. reply tremon 15 hours agorootparentpreva second mistake like this would be devastatingAccording to the GP, this already was their second mistake like this. I&#x27;m not in game development and I&#x27;m not aware of the first, but maybe someone else can explain what&#x2F;when their first \"mistake\" was. reply dpkonofa 17 hours agoparentprevEver since the mobile ad-first approach that&#x27;s been a result of their buyout&#x2F;merger&#x2F;whatever it was, I think most Unity developers are bouncing. No one in their right might would leave their potential income in the hands of these sycophants. reply brucethemoose2 16 hours agorootparent> most Unity developersMost non mobile Unity developers?Unity has cultivated this reputation as a provider for artsy indies and small studios, and now some larger AAs, but I think they want to be a provider for mobile casinos. That&#x27;s where all the money is, and they are less likely to balk at more fees. reply dpkonofa 10 hours agorootparentNo, most Unity developers. Unity the company definitely wants into that market but, unfortunately for them, that&#x27;s not the majority of their customers. reply drpossum 16 hours agoparentprevAnyone breathing a sigh of relief on this isn&#x27;t paying attention reply 0cf8612b2e1e 16 hours agorootparentIf you have a game that has been X months&#x2F;years in development, porting to a different platform was not a realistic option. Those people are mega relieved they can get the current project out the door. Greenfield development should do a significant amount of consideration before starting a Unity project. reply drpossum 16 hours agorootparentAgreed and good point. reply gmjosack 16 hours agorootparentprevoh it&#x27;s a very temporary sigh. finish up what&#x27;s in the pipeline and get the hell out of there. reply ulucs 16 hours agoparentprevJust gotta pray they don&#x27;t alter the deal any further, or use another option. reply hnarn 15 hours agoparentprev> I&#x27;m happy for all the Unity developers out there that are breathing a sigh of relief.That’s not really how trust works. If I was a Unity developer, I’d still be migrating, just not in total panic mode. reply tombert 16 hours agoprevIf they are willing to retroactively change the TOS once, why wouldn&#x27;t they do it again once the smoke has settled?I don&#x27;t make games, I have nothing at stake in this fight, but this just feels like PR damage control and to be completely honest, I don&#x27;t think most software engineers are so absolutely dependent on (proper noun) Unity to risk this company doing shady stuff again, and I suspect this entire ordeal will work as great marketing for engines like Unreal.A part of me thinks that the CEO (and all the other executive morons who decided to make the installation fee) was sitting there thinking \"what are they going to do? Move to Godot?\", but if that was their line of thinking, and if they seriously did not think they were competing with Unreal, then I really do not see what business they have being multimillionaires in charge of any kind of decision-making process. reply gumballindie 16 hours agoparent> A part of me thinks that the CEO (and all the other executive morons who decided to make the installation fee) was sitting there thinking \"what are they going to do? Move to Godot?\"Their CEO gives me the impression of a rich but unsophisticated mba type who can only deliver revenue growth by raising prices. I doubt he even thought about captive customers and lack of what he might have thought alternative engines, let along open source and free.He’s the type that thinks open source is maybe a toy.I knew he was a stink when i read that he ordered unity employees back to offices. He thought he can order customers a new fee. He confirmed my suspicion. A shame that we as a society and industry allow these zeroes to end up leading tech companies. reply DonHopkins 10 hours agorootparentI know John Riccitiello from when I worked at Maxis&#x2F;EA on The Sims last century, and when he was involved with investing in Will Wright&#x27;s Stupid Fun Club, and later when he was involved as CEO of EA in open sourcing SimCity for the One Laptop Per Child. We (including Eben Moglen, Free Software Foundation general counsel) explained to him why EA should open source the original SimCity source code under GPL-3, and what open source software and GPL-3 mean, and he approved the deal, and I gave him credit and positive feedback and sincerely thanked him. And we earned EA a lot of good publicity during a time when they were considered one of the worst companies in the world.EA Donates Original City-Building Game, SimCity, to &#x27;&#x27;One Laptop per Child&#x27;&#x27; Initiative:https:&#x2F;&#x2F;ir.ea.com&#x2F;press-releases&#x2F;press-release-details&#x2F;2007&#x2F;...OLCP EA Contract:https:&#x2F;&#x2F;donhopkins.com&#x2F;home&#x2F;olpc-ea-contract.pdfAnd I&#x27;ve given him credit for doing that here:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23251414When Unity joined the Blender development fund as a Patron member while Riccitiello was CEO of Unity, I also gave him positive feedback and sincerely thanked him again, telling him how important Blender is to Unity game developers, and how important it is for them to work well together.Unity Joins the Blender Development Fund as a Patron Member:https:&#x2F;&#x2F;www.blender.org&#x2F;press&#x2F;unity-joins-the-blender-develo...I recommended he watch Ton Roosendaal&#x27;s excellent \"Money doesn&#x27;t interest me\" interview, in which he does not hold back on his feelings about Autodesk:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qJEWOTZnFegAnd also this video of Ton getting hit by a ceiling tile during a talk. (Presumably perpetrated by Autodesk!)https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eJwG-qt-sgkThen when Joe Biden endorsed Unity three times in his inaugural address, I asked Riccitiello how much Unity paid for that product placement, but he wouldn&#x27;t tell me:>\"With Unity we can do great things, important things!\">\"For without Unity, there is no peace, only bitterness and fury.\">\"And Unity is the path forward.\">-Joe Biden&#x27;s inaugural address.Then after Unity recently announced they&#x27;re pulling the rug out from under their developers, I posted to Riccitiello&#x27;s Facebook page a screen snapshot of the github star ranking table showing that Godot suddenly had a 535.6% increase in stars, and sincerely thanked him again, writing \"Thank you for your substantial contribution to open source gaming engines, at the expense of your own company!\"So I&#x27;m pretty sure he&#x27;s aware of open source software, but I don&#x27;t think he actually meant to benefit the Godot project so much at the expense of Unity.The Godot folks, who have greatly benefited from this fiasco through no fault of their own, immediately condemned the death threat that somebody (who turned out to be a Unity employee) posted, which caused Unity to cancel an event and close their office.https:&#x2F;&#x2F;twitter.com&#x2F;godotengine&#x2F;status&#x2F;1702413121086705951>Godot Engine @godotengine>We extend our sincere solidarity and support to the Unity workers. The recent reactions have left us profoundly disappointed. Threats of violence should have no place in the gamedev community.The truth behind the Unity \"Death Threats\":https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;gamedev&#x2F;comments&#x2F;16j21jg&#x2F;the_truth_...>Update: San Francisco police told Polygon that officers responded to Unity’s San Francisco office “regarding a threats incident.” A “reporting party” told police that “an employee made a threat towards his employer using social media.” The employee that made the threat works in an office outside of California, according to the police statement.Reddit thread from 8 years ago, with recent posts:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;Unity3D&#x2F;comments&#x2F;3cxogb&#x2F;til_unity_c...TIL Unity CEO John Riccitiello was former CEO of EA. He saved EA from declining profits by sellings games EA made online (Origin) rather than physical packages and raising game quality. Also, he&#x27;s barely known for being CEO at Unity Technologies.>drakfyre 8 yr. ago>I am honestly really pleased the hate has died down. Riccitiello is a pretty damn good CEO and Unity&#x27;s former CEO (though a SUPER COOL dude) really didn&#x27;t have the practice nor want to be a CEO of such a rapidly expanding company.>rvc3m8 8 days ago>now, that didn&#x27;t age well, did it? ;)>drakfyre 7 days ago>No, no it did not, not at all... reply gumballindie 9 hours agorootparentInteresting. What i fail to understand though is how on earth he could have approved or thought that this may be a good move. I find it hilariously childish. But glad it ignited the idea of open source in game development - hope the industry figures out how to also monetise it. reply PoignardAzur 2 hours agorootparentprevThis is such a weird post. Why the Biden mention? reply DonHopkins 1 hour agorootparentBecause Biden endorsed Unity so many times in his inaugural address. It was a such refreshing departure and contrast from Trump&#x27;s obsession with Unreal lies and propoganda.The 41 most Unreal Donald Trump quotes of 2018:https:&#x2F;&#x2F;edition.cnn.com&#x2F;2018&#x2F;12&#x2F;20&#x2F;politics&#x2F;trump-lines-of-t...JANUARY 20, 2021: A National Day of Unityhttps:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;presidential-action...President Joe Biden 2021 Inaugural Address:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UlbyOeMCL0gInaugural Address by President Joseph R. Biden, Jr.:https:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;speeches-remarks&#x2F;20...To overcome these challenges – to restore the soul and to secure the future of America – requires more than words.It requires that most elusive of things in a democracy:Unity.Unity.With Unity we can do great things. Important things.I know speaking of Unity can sound to some like a foolish fantasy.History, faith, and reason show the way, the way of Unity.For without Unity, there is no peace, only bitterness and fury.This is our historic moment of crisis and challenge, and Unity is the path forward.And together, we shall write an American story of hope, not fear.Of Unity, not division. reply jimbob45 16 hours agoparentprev\"What are they going to do? Move to Godot?\"I&#x27;m a casual observer in this space. Is Unreal not a viable alternative? reply tombert 15 hours agorootparentThat&#x27;s my point, I think it is! The fact that the Unity executives didn&#x27;t consider that people will jump ship to Unreal baffles me. reply rhtgrg 16 hours agoparentprev> If they are willing to retroactively change the TOS once, why wouldn&#x27;t they do it again once the smoke has settled?I haven&#x27;t seen any evidence they did that, it&#x27;s mostly been FUD from Godot supporters. The initial communication was messy, but where are actual TOS changes that are being touted so loudly?https:&#x2F;&#x2F;unity.com&#x2F;legal&#x2F;terms-of-servicehttps:&#x2F;&#x2F;unity.com&#x2F;legal&#x2F;terms-of-service-legacy reply tombert 16 hours agorootparentI have no skin in this game, but I read this article: https:&#x2F;&#x2F;gameworldobserver.com&#x2F;2023&#x2F;09&#x2F;14&#x2F;unity-license-terms...ETA:You updated your post with the TOS, but from what I read the concern was that the new TOS said it applied to any new distribution of the Unity Runtime, without specifying versions and the like. reply rhtgrg 16 hours agorootparentI have never seen a Unity TOS that specified versions as seen in the screenshot of the link you shared. Where did they get that screenshot from? They need to share their source. For all we know this is a change from 2020 (latest version referred to in their screenshot).In which case I think you will agree that is plenty of notice and most likely unrelated to be maliciously related to what&#x27;s being announced now. They&#x27;ve even walked back the applicability to old versions as seen in GP. reply wolrah 15 hours agorootparent> I have never seen a Unity TOS that specified versions as seen in the screenshot of the link you shared.You mean this screenshot, right? https:&#x2F;&#x2F;gameworldobserver.com&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;09&#x2F;uni...Right here: https:&#x2F;&#x2F;unity.com&#x2F;legal&#x2F;terms-of-service&#x2F;software-legacyScroll down about 80% of the page to section 8. reply tombert 16 hours agorootparentprevWell Unity is being accused of some dishonesty with updating things and not disclosing it [1]. If that&#x27;s true, then it&#x27;s possible that it&#x27;s been somewhat purged to make themselves look better.That said, that&#x27;s a big \"if\", I&#x27;m just regurgitating what I read in news articles.[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37615183 reply rhtgrg 16 hours agorootparentJan &#x27;22 TOS does not have such a clause either (from archive.org):https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220716041837&#x2F;https:&#x2F;&#x2F;unity.com...At this point I&#x27;m pretty sure this is a dishonest attempt to dig up a 2020 change (if this clause even ever existed, which I&#x27;ve seen zero proof of) and correlate it to a 2023 announcement as if these things were done in tandem.Downvote me all you want. I don&#x27;t think Godot et al will survive with these scummy tactics. reply tombert 16 hours agorootparentI seriously doubt this is some conspiracy from the Godot team, even if it&#x27;s dishonest. I think people are probably drawing some correlations as a response to an announcement that they don&#x27;t like, and then saying \"Godot doesn&#x27;t have this bullshit because it&#x27;s open source\". I don&#x27;t think the Godot team is engaging in \"scummy tactics\" explicitly.ETA:Also, if you&#x27;re going to edit your responses after you post them, I recommend using the `delay` feature in your HN settings, or adding an addendum section like I&#x27;m doing here, as it&#x27;s a little unfair to people responding to you to make undisclosed changes so it looks like people responding to you aren&#x27;t responding to all your points. I&#x27;m not saying you&#x27;re being dishonest, I&#x27;m just saying that it feels a little unfair to responders. reply rhtgrg 15 hours agorootparentThanks, I&#x27;ll use the delay feature. I accept that this has nothing to do with Godot.I did find the TOS in question, as expected, it&#x27;s very old (from 2019):https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201111183311&#x2F;https:&#x2F;&#x2F;github.co...So people saying \"who&#x27;s to say they won&#x27;t do this again,\" if four years isn&#x27;t enough for you to catch up, I don&#x27;t know what to tell you.Edit: They have also brought the repo back, which was likely another unrelated change:https:&#x2F;&#x2F;github.com&#x2F;Unity-Technologies&#x2F;TermsOfService reply danShumway 8 hours agorootparentprevThe Jan 22 TOS you link to includes this section:> Notwithstanding this Section 1.4, any modification of the Unity Software Additional Terms is subject to Section 8 of the Unity Software Additional Terms.If you click on the \"Unity Software Additional Terms\" link within that clause, it will take you to the July 2022 snapshot of those terms in the Internet Archive (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220716082334&#x2F;https:&#x2F;&#x2F;unity.com...). Section 8 reads:> Unity may update these Unity Software Additional Terms at any time for any reason and without notice (the “Updated Terms”) and those Updated Terms will apply to the most recent current-year version of the Unity Software, provided that, if the Updated Terms adversely impact your rights, you may elect to continue to use any current-year versions of the Unity Software (e.g., 2018.x and 2018.y and any Long Term Supported (LTS) versions for that current-year release) according to the terms that applied just prior to the Updated Terms (the “Prior Terms”). [etc...]As of March 2023, those terms were still present in the TOS (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230303043022&#x2F;https:&#x2F;&#x2F;unity.com...), moved to section 6 (Modifications to these Software Terms and Long-Term Supported versions).The terms disappear in the May 2023 snapshot (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230528084511&#x2F;https:&#x2F;&#x2F;unity.com...), which states that the last update to the TOS was April 3rd, 2023, which is fully consistent with all of the reporting about this change.Not only is there no conspiracy from Godot, the reporting is correct. The TOS was modified between March&#x2F;May of 2023 to remove the reported clause and the Internet Archive proves it. replydanShumway 8 hours agorootparentprevI commented similarly below, but see the March 2023 snapshot at https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230303043022&#x2F;https:&#x2F;&#x2F;unity.com... Section 6 (Modifications to these Software Terms and Long-Term Supported versions).If you go to the next snapshot (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230413210637&#x2F;https:&#x2F;&#x2F;unity.com...), Section 6 will be missing and you&#x27;ll see the following header at the top of the TOS:> Last updated: April 3, 2023> What’s changed: We have posted an update to our Unity Editor Software Terms to, among other things, provide for our Industry Offering. We’ve also updated other sections, including those relating to data collection and modification of terms.Interestingly, their linked FAQ (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230605071610&#x2F;https:&#x2F;&#x2F;unity.com...) provides no mention of the fact that they&#x27;ve removed the clause. I can&#x27;t know what was going through Unity executives&#x27; heads when that FAQ was written, but they apparently didn&#x27;t think it important to draw attention or specifically notify users about that revocation of their rights. reply imtringued 1 hour agorootparentprevWhy would \"Godot supporters\" care about what Unity is doing? It&#x27;s not like they are on payroll and more users means more bug reports and feature requests for the maintainers without necessarily gaining more capacity to implement them. An open source project doesn&#x27;t need an exodus of users from another project, it needs to get parity with its competitors and then quietly take over the market with little resistance. reply MikeBVaughn 16 hours agoprev\"We should have spoken with more of you and we should have incorporated more of your feedback before announcing our new Runtime Fee policy. Our goal with this policy is to ensure we can continue to support you today and tomorrow, and keep deeply investing in our game engine.\"It is hard to think of a diplomatic response to this specific framing. Of course the first substantive paragraph was this. It&#x27;s inevitable, and I&#x27;m convinced it&#x27;s encoded into some fundamental physical constant.If a company actually, once, for-real avoided this specific sort of mealy-mouthed, boilerplate-indirect-corporatese semi-apology, I would seriously consider using their product solely on that merit alone. I&#x27;m fairly certain I&#x27;m not the only one who feels that way, and it&#x27;s sort of amazing that nobody appears to have figured that out.Surely someone in some sort of corporate PR position at some company is reading this. Think about it. Seriously think about it.---Edit: this isn&#x27;t a personal criticism of the author either, I&#x27;m pretty darn sure that this the post was vetted and revised by at least one layer of PR and legal. The issue is an intractably systemic one that is not rectifiable by any individual. Outside of maybe the C-suite, I&#x27;m skeptical the that it makes any sort of sense to attribute blame to any individual for this type of corporate apology. reply avalys 16 hours agoparentI’m curious, what would you recommend they should have said instead? reply PoignardAzur 14 hours agorootparentNot GP, but for a while I have thought that PR shitstorms should be treated like security breaches and outages.So you do a blameless post-mortem where you outline what went wrong, your five whys, and what steps you are taking to make sure it doesn&#x27;t happen again.The Rust leadership did it right during the RustConf scandal. Key figures resigned (from leadership, not from their respective teams), changes in procedure were announced, process transitions were accelerated, etc.Here Unity is just saying \"here&#x27;s somsome decisions we&#x27;re lightly amending, sorry you got upset\". reply risingsubmarine 17 hours agoprevA definite improvement but the CEO needs to go. It&#x27;s the only way to begin restoring long term trust. Developers & publishers are extremely wary of unstable business partners. reply jstarfish 16 hours agoparentYeah. An apology isn&#x27;t enough in this case-- words clearly mean nothing to them.We were always told C-level compensation is as absurd as it is because they&#x27;re expected to fall on their sword for fucking up. Keeping your position after defrauding customers is not a sign of good faith, it&#x27;s just another [social] contract broken. reply johnnyanmac 8 hours agorootparent>We were always told C-level compensation is as absurd as it is because they&#x27;re expected to fall on their sword for fucking up.We were? I thought it was as simple as \"big leader + big company = big money\". Made sense in the days where those leaders rose the company off the ground. Not so much when it&#x27;s just some MBA that comes in or a friend of some other rich guy that simply wants to increase stock numbers. reply tombert 16 hours agorootparentprevYeah, I really do not understand why these executives get such huge salaries. They get all the credit when something goes well (see: Elon Musk, Steve Jobs, Bill Gates, Mark Zuckerberg, probably a dozen other CEOs in big tech), but when their decisions lead to a drop in revenue they get to fire 12,000 people, get to keep their exorbitant salaries and&#x2F;or stock options, and just blame everyone else for the problem, or blame a \"bad market\".I really do not understand what it is that they actually do, outside of being an extremely overpriced and lazy spokesperson. reply rybosworld 16 hours agorootparentAt that level it&#x27;s often just a big club that you don&#x27;t get to be a part of because you don&#x27;t have the right connections.Many CEO&#x27;s (and execs in general) are not extraordinary people in any sense of the word.I think people underestimate just how often a business leader gets to where they are because of nepotism. Many of the biggest companies in the world operate like a royal dynasty, with children inheriting the leading roles from parents.When you consider that decision making is often inherited, rather than earned, these displays of incompetence make much more sense. reply tombert 15 hours agorootparentIt wouldn&#x27;t bother me so much if not for the fact that they get lauded as geniuses for every innovation coming out of their companies.I&#x27;ve seen dozens of people on LinkedIn claiming that Elon Musk invented self-landing rockets, and they get mad at me when respond with \"no he fucking didn&#x27;t! He hired people to figure that stuff out\".So I think \"Fine, I guess you could make some kind of transitive argument that he hired the right people so he&#x27;s responsible for the self-landing rocket\", but in the same breath they will claim he&#x27;s not responsible for any of the failures involved with his handling Twitter.Well which is it? Is this executive some genius pulling all the strings of the company and should be given credit for all the innovations? Or are they just idiots like the rest of us and like to take credit for when things go well? reply PoignardAzur 2 hours agorootparentElon Musk is kind of a special case, and shouldn&#x27;t used as a representative example of the class \"CEOs\".Most CEOs don&#x27;t micromanage to the level Musk does, most CEOs wouldn&#x27;t have ran SpaceX the way Musk did, competent engineers or not. If all it took was hiring the right people, Blue Origin would have left them in the dust.(That said, yes, he should definitely be considered responsible for the failures with Twitter) reply coldpie 15 hours agorootparentprev> Yeah, I really do not understand why these executives get such huge salaries.Because they can. What do you have to fight back with? All you can do is bargain individually, and they&#x27;ll laugh at that. reply Jochim 16 hours agorootparentprev> I really do not understand what it is that they actually doTheir main purpose is to occupy the same social circles as other executives and board members. reply aeyes 17 hours agoparentprevI&#x27;m surprised that this letter isn&#x27;t written by the CEO, maybe the board is already in the process of axing the guy. reply eitally 16 hours agorootparentI&#x27;d be more surprised if the board hadn&#x27;t been included in the review process for the previous change. reply Waterluvian 16 hours agorootparentBoards are often presented pre-packaged answers via CEOs with slide decks. They are rarely given the flat truth about reality. Good boardmembers know this and how know to smell and cut through bullshit. Sales gonna sell. reply peteforde 16 hours agoparentprevThe fact that it wasn&#x27;t written by the CEO is the strongest indication that Riccitello might be out. reply Scalene2 15 hours agoprevIf you as a gamer or developer are unhappy with this outcome or are unhappy that this happened at all.Have a reminder that Godot (an open source MIT License) game engine could use your support, Godot offers a way to address this long term instead of relying on a contract with an untrustworthy company:Use:Homepage with download links for Latest and LTS versions for Android, Linux, macOS, Windows, and Web (you can build for iOS but cannot write on it).https:&#x2F;&#x2F;godotengine.org&#x2F;Code&#x2F;document&#x2F;contribute:https:&#x2F;&#x2F;docs.godotengine.org&#x2F;en&#x2F;stable&#x2F;contributing&#x2F;ways_to_...Donate&#x2F;fund: https:&#x2F;&#x2F;fund.godotengine.org&#x2F;IMO there is nothing Unity can realistically do to regain trust, when a corporation shows you what their goals are and how they plan to reach them; believe it. reply bangonkeyboard 16 hours agoprevUnity is not trustworthy. This was not the first time they&#x27;ve changed terms unilaterally, and will not be the last.This letter should be seen as a rickety runway extension: finalize any Unity projects you already have in development, but make sure you move to another engine in the immediate future. reply johnnyanmac 8 hours agoparentwell, this at least saves Silksong. That&#x27;s all I can ask for at this point.But if they are considering a 3rd Hollow Knight it&#x27;d be the biggest W if they chose an open-source engine (and hopefully not take 7 years, but TBH I&#x27;d take my time too if I made hollow knight money). reply rybosworld 17 hours agoprevThis is better than what they announced originally but it doesn&#x27;t cure the breach of trust.I have no doubt that as long John R. and Tomar B. continue to run the show, that the company will behave unethically again in the future. reply rybosworld 17 hours agoparentAlso, there are still hints of them trying to play this off as a misunderstanding rather than what it really was: a predatory pricing scheme and an attempt to retroactively change ToS.\"When we first introduced the Runtime Fee policy, we used the term “installs” which the community found to be unclear so we’re using the term \"initial engagement\" as the unit of measure.\"The community did not find this unclear. The original pricing scheme was very straightforward about developers being charged multiple times for a user that reinstalls a game, or install it across multiple devices.This is Unity trying to rewrite history so they don&#x27;t seem like the bad guys. reply flutas 17 hours agorootparent> This is Unity trying to rewrite history so they don&#x27;t seem like the bad guys.Yup, even going so far as to rewrite the FAQ and pretend they never said the initial answer, it only being noted as \"(Updated, Sept 14)\"[0]For full context, the original Q&#x2F;A was> Q: If a user reinstalls&#x2F;redownloads a game &#x2F; changes their hardware, will that count as multiple installs?> A: Yes. The creator will need to pay for all future installs. The reason is that Unity doesn’t receive end-player information, just aggregate data.and has since been edited to> Q: If a user reinstalls&#x2F;redownloads a game, will that count as multiple installs?> A: We are not going to charge a fee for reinstalls. The spirit of this program is and has always been to charge for the first install and we have no desire to charge for the same person doing ongoing installs.> (Updated, Sep 14)> Q: Do installs of the same game by the same user across multiple devices count as different installs?> A: Yes - we treat different devices as different installs.> (Updated, Sep 14)[0]: https:&#x2F;&#x2F;forum.unity.com&#x2F;threads&#x2F;unity-plan-pricing-and-packa... reply rybosworld 17 hours agorootparentIt&#x27;s sort of surprising that they would try to act as if the plan was never to charge for multiple installs.By lying about the situation so transparently, it&#x27;s clear to me that this is nothing more than damage control, and that the loss of trust does not deserve to be earned back. reply shoemakersteve 16 hours agorootparentHonestly. They want to earn back people&#x27;s trust, so they figure the best way to do that is with good ol&#x27; gaslighting. Thing is, it&#x27;ll probably work. At least to some extent. The irony is actually kind of funny. reply DonHopkins 16 hours agorootparentprevHere&#x27;s where a professional NFT shilling tech influencer tried to carry the water for Unity by parroting their gaslighting that developers were bitchy little children who \"misunderstood\" the announcement, and the NFT shill&#x27;s followers chimed in with how stupid and childish and demanding game developers are.https:&#x2F;&#x2F;www.facebook.com&#x2F;robert.tercek&#x2F;posts&#x2F;pfbid0RPPNvecme...Including un-ironic replies like this one commenting \"some insight into what the gamer peasants are talking about\" and quoting one game developer&#x27;s factual reaction, to which the NFT shill replied by calling it \"unhinged conspiratorial speculating that poisons the whole atmosphere\".https:&#x2F;&#x2F;www.facebook.com&#x2F;robert.tercek&#x2F;posts&#x2F;pfbid0RPPNvecme...I took the NFT shill to task on that, with quotes and links and receipts. I pointed out that he and Unity were the ones \"poisoning the whole atmosphere\" by gaslighting, calling developers \"confused\" when they actually understood all too well, and if anyone was \"poisoning the whole atmosphere\" first and foremost, it was John Riccitiello literally and publically calling game developers \"some of the biggest fucking idiots\".https:&#x2F;&#x2F;www.pocketgamer.biz&#x2F;interview&#x2F;79190&#x2F;unity-ironsource...Twice the NFT shill snarkily blamed game developers for the death threat. First he baselessly accused game developers of \"often\" making death threats, then he gleefully berated game developers for not condemning it (which they actually did, but he didn&#x27;t bother to notice), demanding they condemn it without actually condemning it himself, when it was actually a Unity employee who made the death threat, not a game developer:\"Game developers often find colorful ways of making their disappointment known.\"https:&#x2F;&#x2F;www.facebook.com&#x2F;robert.tercek&#x2F;posts&#x2F;pfbid0RPPNvecme...\"I notice that none of game developers who shared their righteous indignation last week had the courage to speak up and condemn the cowards who phoned in death threats to Unity offices. Keep it classy, game developers.\"https:&#x2F;&#x2F;www.facebook.com&#x2F;robert.tercek&#x2F;posts&#x2F;pfbid0RPPNvecme...>Here are the Godot folks, who have greatly benefited from this fiasco through no fault of their own, condemning the bomb threat, and proving you wrong. No, Robert Tercek, you are wrong when you blame game developers for the bomb threat with no evidence, when the police say it was a Unity employee, and when you falsely claim that game developers \"OFTEN find colorful ways of making their disappointment known\" like making bomb threats.>Godot Engine @godotengine>We extend our sincere solidarity and support to the Unity workers. The recent reactions have left us profoundly disappointed. Threats of violence should have no place in the gamedev community.https:&#x2F;&#x2F;twitter.com&#x2F;godotengine&#x2F;status&#x2F;1702413121086705951The truth behind the Unity \"Death Threats\":https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;gamedev&#x2F;comments&#x2F;16j21jg&#x2F;the_truth_...>Update: San Francisco police told Polygon that officers responded to Unity’s San Francisco office “regarding a threats incident.” A “reporting party” told police that “an employee made a threat towards his employer using social media.” The employee that made the threat works in an office outside of California, according to the police statement.The PacMan Fever &#x2F; NFT Shilling thread:https:&#x2F;&#x2F;www.facebook.com&#x2F;robert.tercek&#x2F;posts&#x2F;pfbid0RPPNvecme... reply gmerc 16 hours agoprevOh, it’s community now, not “prospective bagholders” and “pigs for slaughter”.Next they are gonna push a narrative of greedy mid level managers over hiring and building fiefdoms like everyone else. The Metagame for the C level is zero risk and zero accountabilityThey can fuck right off and fire the CEOManagement knew this was going to be controversial including internally so they hid it from employees who could have told them just how bad the idea was and how many edge cases they had to consider.Management needs to be fired. reply Macha 16 hours agoprevSo, if this had been what they launched with out the window, I don&#x27;t think they would have had the same uproar. I don&#x27;t think this is a door-in-face technique planned retreat (compared to the \"leaked\" proposal earlier this week which basically just started the install count at 0 and increased a revenue threshold, but still maintained it applied to existing games developed under the current deal).I don&#x27;t think this is enough that I would consider Unity for a new project (compared to my niggling doubts on my projects using Godot and Bevy in the past that maybe I should just bite the bullet and learn the \"grown up\" engine, until this announcement). That would require something a bit more iron clad renouncing their claim to be able to change the deal like this.I don&#x27;t know if Unity considers it a success that they&#x27;ve moved from their customers being in a \"port everything now\" rush to \"Well I wouldn&#x27;t take that deal, and a lot of customers will now not be upgrading Unity or developing their next titles in Unity\".But I guess as a consumer this moves my position to \"someone should sue them for a declaratory judgement that making this retroactive is not legal\" to \"Well, guess I&#x27;m not investing in learning Unity\". reply alexb_ 17 hours agoprevPeople are going to continue to complain, but I honestly think this is a pretty good walk back. It addresses all of the more legitimate things people were upset about:- $1,000,000 income floor for a trailing 12 months- Doesn&#x27;t apply to old versions- Billed a lesser amount of 2.5% revenue if available, so low-cost indie games don&#x27;t get destroyedNot to mention, removing the requirement to have \"Made with Unity\" on the free version? Surprised they would change this - it wasn&#x27;t really a problem for most people, and afaik getting rid of the \"Made with Unity\" was one of the main reasons people would buy the non-free versions of Unity.I think this is probably the best they could have done for indie devs. As it turns out, pushback works. They did destroy a lot of trust with developers with this move though. Going to be hard to get any of that back. reply pixl97 17 hours agoparent>People are going to continue to complain, but I honestly think this is a pretty good walk back.If you come up to someone, point a gun at their head, and scream you&#x27;re going to murder them it&#x27;s very likely there is no walking back even if you put the gun away and then state more reasonable demands. Everyone knows you have a gun in your back pocket and you&#x27;re insane enough to use it. reply alexb_ 17 hours agorootparentI agree - like I said at the end of my comment, the trust being broken is why the original pricing plan was such a disaster, and it&#x27;s going to take a lot to build that back up. reply PaulKeeble 16 hours agorootparentIts going to take firing the people responsible, which means the CEO has to go. reply gmjosack 17 hours agoparentprevI&#x27;m in a lot of gamedev communities and I&#x27;m not seeing any complaints. Everyone agrees this is fine. I believe if they announced this initially people probably would have complained but nothing close to the backlash there was. Most people just don&#x27;t trust Unity after this. This is after all the second time we&#x27;re getting a promise not to change the terms on an existing engine version as a result of backlash. How long until the third? reply JohnMakin 17 hours agoparentprev> - Doesn&#x27;t apply to old versionsIt&#x27;s not beyond the realm of reasonable belief to assume they can or will roll out some breaking change eventually that forces upgrades. reply LanceH 17 hours agorootparentOr shift other (possibly not yet existent) assets between versions.The goodwill has been burned and now everything needs to be contractually spelled out.Or, for a good number of people, they can bail out to Godot for 2D or Unreal for 3D or consoles. reply raincole 16 hours agorootparentprevThe old version of Unity can be used offline. Truly offline. How are they going to force you to upgrade? Hakc into your PC? reply JohnMakin 15 hours agorootparentthis is a pretty naive comment. reply raincole 14 hours agorootparentExcept our stuido has been using Unity 2020 for 3 years :) reply dangerwill 17 hours agorootparentprevThat isn&#x27;t really a thing they can do for already shipped games, unless your game has an online component with dedicated servers and you need to update unity on the server side for a security fix. Most games don&#x27;t upgrade their engine post launch, unless they are a live service game intended to get constant, significant updates for a long time. reply drpossum 17 hours agoprevI like how the CEO can&#x27;t be bothered for this, though. Shows real leadership reply peteforde 16 hours agoparentThat the CEO didn&#x27;t write this is a major indicator that he has or will be fired. reply drpossum 15 hours agorootparentWhat are they doing? Biding their time? reply peteforde 14 hours agorootparentThere&#x27;s a term for this: dead man walking.This is all pure speculation based on what I would do if I was on Unity&#x27;s board. I&#x27;m confident that his contract has all sorts of gotchas and landmines, so there is probably a ton of expensive lawyering happening right now on both sides. reply Rapzid 12 hours agorootparentprevMaybe they are begging Acton and Ante to come back from \"sabbatical\" (or whatever their official statuses are). reply koromak 15 hours agorootparentprevFiguring out how to cut up the pie most likely reply DiabloD3 16 hours agoprevA lot of the game developers I know are either dropping Unity projects right in the middle of development to switch engines, or they&#x27;re working on their last Unity project and abandon the engine forever.You&#x27;re only going to see major(-ly incompetent) studios from now on using it (ie, big enough to pressure Unity into complying to their licensing requirements, ie, Microsoft or Nintnedo kind of big). reply glimshe 15 hours agoprevTheir executives make millions. They make millions because they are supposed to have unique insights and skills that the rest of us don&#x27;t have. These insights are supposed to exactly avoid this situation where they probably killed the company with an absolutely irresponsible plan (from a business perspective). I think this is a historical blunder in the the industry and will be studied in business schools in the future.There is no amount of walkback that will work here. The only possible way out, if any is even possible, would be a summary dismissal of their entire leadership team due to gross incompetence. These people don&#x27;t deserve even minimum wage, much less the millions they make. A junior business manager out of school wouldn&#x27;t have made such irresponsible, company-killing move. These are some of the worst executives in gaming history, to be honest. reply markhaslam 17 hours agoprevThis seems very reasonable actually?Being able to choose 2.5% revenue share (half of Unreal) does not sound bad to me. And very glad they removed the retroactivity of the new fees. reply drpossum 17 hours agoparentIt may be reasonable and this is nothing but an attempt to stop the bleeding. There is no reason to trust them or their leadership again. The fact the CEO wasn&#x27;t booted immediately shows they still want that style of leadership. The fact the CEO is not the one making this statement shows the fact Unity not interested to hold him accountable. They did this last year making dumb statements about monetization and then pulled this out this year. They deserve no trust and anyone that continues business with them gets what they deserve. reply markhaslam 15 hours agorootparentFair points. Not sure if it will ever be possible to get back the trust they destroyed. reply gs17 14 hours agoparentprevIf they had opened with this it would have been amazing, but this being 3-4 revisions in with nothing locking them to this going forward, it&#x27;s not that good a look. reply skilled 17 hours agoprevI didn’t follow this very much but did they basically tried to enforce this on people out of the blue? If so, that must sting like crazy to have to walk it back with the addition of losing trust and goodwill of your users, not to mention those that went on to different engines.How high up does this rank in “the dumbest decisions you can make” chart? reply olgeni 1 hour agoprevThe tone of this post is exactly the same as a company would use after a very public incident of harassment or discrimination. So, they probably realized it was not the smartest thing to do. reply wildermuthn 14 hours agoprevSome meta-commentary about executive leadership: the skills required to gain such a position are orthogonal to the skills required to exceed at such a position. Clarifying Questions:1) What type of person gets hired as CEO?2) What type of person excels as CEO?3) What type of person seems most suited to being a CEO while actually being least suited?Possible Answers:1) the salesmen, the connected, the take-crediting, the attractive, the eloquent, the politically savvy, the ambitious, the tactical2) the decisive, the persevering, the give-crediting, the communicative, the empathetic, the trustworthy, the humble, the strategic3) When confidence is unwarrantedBoth types of people have high confidence, but only one type has a good reason to be confident. Both types are effective in making plans and executing upon them, but where the first type’s plan’s focus on personal success, the second type’s plans focus on mutual success.Is there a good way to distinguish between the two? Yes, but subtly — have their former direct reports gone on to success outside of the candidate’s current sphere of influence? The first type will drag along the people they can trust to support their personal ambitions, elevating them in the process. The second type will elevate their direct reports without grasping on to them as life preservers in choppy political seas.Being a good CEO is a very difficult job, and should be rewarded. It is the most important job anyone can have at a company. It is also the hardest to fill with the right person, given the hordes of ill-suited confidence men seeking their own stardom. reply INTPenis 16 hours agoprevTrust is a fickle thing. Why would a new game creator use Unity with the fear of suddenly having the rug pulled from under your with another ToS change? Doesn&#x27;t he realize this? reply spl757 16 hours agoprevDone bun can&#x27;t be undone. Just another example of the enshittification that&#x27;s rampant. reply VohuMana 16 hours agoprevToo little too late, at least for me. I have been slowly working on some game ideas I want to make, in this process I have been checking out different game engines to see which one meets my needs best. With these changes I have removed Unity from my list of engines I am considering using. Granted I am just one dev and definitely don&#x27;t represent the community as a whole so who knows maybe I am in the minority here. reply opyate 15 hours agoprevTangential: what other downloadable software makes (or, tries to make) money with \"revenue share\"?I&#x27;m aware of these not-downloadable-but-is-digital services&#x2F;stores&#x2F;platforms that do:- app stores (Apple takes 30%, Google takes 30%)- content (YouTube keeps 45%, Twitch takes a cut)- e-commerce (Etsy 5% transaction fee; eBay takes a %)- music&#x2F;podcast (Spotify; SoundCloud)- e-learning (Udemy; Teachable)- gaming (Steam takes 30%; Epic takes %12)- rental (AirBNB service fees; Turo commission on each car rental)- freelancing (Upwork&#x27;s sliding fee; Fiverr takes 20%)But Unity is DOWNLOADABLE software, not a platform&#x2F;app-store&#x2F;SaaS. So, why revenue share? Surely most devs just make free-standing&#x2F;downloadable games that don&#x27;t tie into any platform-y features?AFAIK, even Unity Enterprise [0] is just source code, support, 3-year LTS bug fixes, and the only real thing that&#x27;s platform-y is the build server, which seems to cost extra anyway.0. https:&#x2F;&#x2F;unity.com&#x2F;products&#x2F;unity-enterprise reply aschearer 15 hours agoparentFor starters, their number one competitor Unreal. reply FateOfNations 13 hours agoparentprevIt&#x27;s best to think about more like a royalty. reply opyate 2 hours agorootparentWell, in that case, I&#x27;m glad it&#x27;s not common across software, e.g. imagine authors having to pay MS Word or Scrivener a cut for every book sold, or musicians for every song made with Logic Pro or Ableton.What makes games so special? reply endisneigh 16 hours agoprevIt’s interesting how some complain companies don’t listen to them, and others say that it doesn’t matter if changes are made after (rightful) complaints.I have absolutely no stake in this and I’m sure these aren’t the same people, but it is interesting.From reading the original proposal and this new one, they should’ve gone first with this one. I’m sure unity developers will hesitatingly continue their work. reply Macha 16 hours agoparent\"Unity decides to change the deal in a way that costs us money for our already developed game\" was not something on anyone&#x27;s threat model. Until last year, Unity&#x27;s TOS even included provisions that would have unambiguously prevented such a move. Maybe some considered \"Unity changes the deal in the future and we need to learn a new engine for project n+1 and get stuck on an old version of Unity on our current project\" as a threat. But now that Unity has put the first one in people&#x27;s minds, Unity has to put people at ease about that to get to square one, not just cancel the current attempt. reply njovin 16 hours agoparentprev> It’s interesting how some complain companies don’t listen to them, and others say that it doesn’t matter if changes are made after (rightful) complaintsIn this case I think those can (rightfully and reasonably) be the same people. If a company rolls out a pricing&#x2F;licensing change that is so detrimental to the developers that it seems like no reasonable developer would have thought it was a good idea, then it looks like the company rolled it out either without talking to their developers or without taking their feedback into account, both of which are equally bad.In cases like this where the business acted so egregiously, the damage is done and trust might not be restorable long-term without C-level heads rolling. reply PaulKeeble 16 hours agoparentprevIf they had gone with this one to begin with they would have lost some customers but no where near as many. What they did makes them clearly an unstable business partner that is willing to break the law to rip you off. Walking it back changes the deal but it doesn&#x27;t change the type of business they are. reply cco 15 hours agoparentprev> It’s interesting how some complain companies don’t listen to them, and others say that it doesn’t matter if changes are made after (rightful) complaints.That&#x27;s because many folks recognize that the fundamental problem is not the proposal, it is the mechanism by which that proposal was crafted, refined, and finally approved that is rotten.Walking back the proposal is fine in the near term, but without drastic change to the fundamentals of the company and its leadership, you&#x27;ll just end up in the same situation in the future, it is just a matter of when. reply squeaky-clean 16 hours agoparentprevJust because they listened once when their profits were seriously on the line, doesn&#x27;t mean they listen generally.If you file for divorce, and in reaction they buy you flowers and other gifts, it doesn&#x27;t mean they&#x27;re suddenly fixed and have always been a good partner.It&#x27;s also very likely they got some legal letters from Pokémon Go or other similarly large Unity based games, and they still don&#x27;t care about what the online community has to say. reply generationP 17 hours agoprev[EDIT: False; see comments.]From a viewpoint of \"will it be compatible with a DRM-free release that doesn&#x27;t phone home\" (i.e., playing by GOG rules), this doesn&#x27;t seem to solve the problem at all. What is in it for them? Why per install and not per sale? reply Macha 16 hours agoparentIt says that they&#x27;re trusting developer provided numbers, and they&#x27;ve basically moved from literal installs to basically a user count metric provided by the developer, so it seems there is no need for it to be DRMed or phone home. reply generationP 16 hours agorootparentAh, I didn&#x27;t spot that they no longer require counting installs. But you&#x27;re right; this is probably what \"the number of new people\" means. And the \"2.5% revenue share\" variant means no hurdles for freeware. So a real improvement indeed. Thanks for the corrections! reply gs17 15 hours agorootparentAnd freeware can get rid of the Made with Unity splash screen now, so it&#x27;s honestly a big step up from where we were before. I&#x27;d still rather switch to Godot, but at least I can walk away from Unity calmly instead of running away screaming. reply peteforde 12 hours agoprevYouTube Unity dev channel CodeMonkey just did an excellent summary of the revised TOS changes.https:&#x2F;&#x2F;youtu.be&#x2F;m4OzqgTa_hk?si=xiuNmYNVEgNoZ-Dj&t=455I have linked to his interactive exploration of their fee calculator, which should set many \"what if\" scenarios to rest.Nobody can really say anything educated about the long-term impact on trust, but I suspect that if they can Riccitello things will return to something of a baseline and nobody will be talking about it in a year.I trully cannot fathom Riccitello&#x27;s tenure remaining viable on the other side of this. He is a dead man walking, corporately speaking.I&#x27;m reminded of a favorite allegory which seems perfect for today:New CEO walks into her office just as the old CEO is leaving. Old CEO says congrats and good luck; I left you three sealed envelopes which you should open in times of crisis.Things go well until they don&#x27;t. First letter says \"blame your predecessor\".This fixes things until the next crisis. Second letter says \"blame the technology\".Nothing could go wrong, until it does. Third letter says \"write three letters\". reply rybosworld 16 hours agoprevThese words are an improvement of the situation but nothing here can be considered legally binding.For all intents and purposes, this is meaningless until they update the old ToS to prevent this from happening again. reply bangonkeyboard 16 hours agoparent> For all intents and purposes, this is meaningless until they update the old ToS to prevent this from happening again.Unity did just that the last time this happened, in 2019: https:&#x2F;&#x2F;blog.unity.com&#x2F;community&#x2F;updated-terms-of-service-an...They silently deleted the then-added clause allowing you to use the ToS you agreed to before this most recent attempt. reply whartung 16 hours agoparentprevI may be misremembering but this is what happened with recent the Open Gaming License fiasco.As I recall, they inevitably changed the current one with a clause saying “we explicitly can’t pull the rug out from folks anymore with this license”. Simply ensuring that while they can create new licenses for new content, that can’t mess with creators who adopted the previous one. reply Rapzid 12 hours agoprevPeople woke up to the fact that Unity Technologies is a dirty Ad company. That toothpaste isn&#x27;t going back in the tube. reply aschearer 16 hours agoprevWhat a bizarre self-own to just end up at \"2.5% of revenue when you earn one-million or more in a year.\" reply omgmajk 16 hours agoprevHeads has to roll in the c-level space for them to Ever get the trust back. This walk-back is reasonable but they will still lose a majority of their customers. I am glad that people late in their projects can still ship and see a profit and hopefully move on to another engine. reply pushcx 17 hours agoprevDoes anyone have the text of this? For me the page appears momentarily, then is replaced with a blank white screen reading \"An unexpected error has occurred.\" The archive.org copy is also broken. (Most likely some kind of analytics or ad erroring because of a browser privacy setting.) reply cmcaleer 17 hours agoparentTo our community:I’m Marc Whitten, and I lead Unity Create which includes the Unity engine and editor teams.I want to start with simply this: I am sorry.We should have spoken with more of you and we should have incorporated more of your feedback before announcing our new Runtime Fee policy. Our goal with this policy is to ensure we can continue to support you today and tomorrow, and keep deeply investing in our game engine.You are what makes Unity great, and we know we need to listen, and work hard to earn your trust. We have heard your concerns, and we are making changes in the policy we announced to address them.Our Unity Personal plan will remain free and there will be no Runtime Fee for games built on Unity Personal. We will be increasing the cap from $100,000 to $200,000 and we will remove the requirement to use the Made with Unity splash screen.No game with less than $1 million in trailing 12-month revenue will be subject to the fee.For those creators on Unity Pro and Unity Enterprise, we are also making changes based on your feedback.The Runtime Fee policy will only apply beginning with the next LTS version of Unity shipping in 2024 and beyond. Your games that are currently shipped and the projects you are currently working on will not be included – unless you choose to upgrade them to this new version of Unity.We will make sure that you can stay on the terms applicable for the version of Unity editor you are using – as long as you keep using that version.For games that are subject to the runtime fee, we are giving you a choice of either a 2.5% revenue share or the calculated amount based on the number of new people engaging with your game each month. Both of these numbers are self-reported from data you already have available. You will always be billed the lesser amount.We want to continue to build the best engine for creators. We truly love this industry and you are the reason why.I’d like to invite you to join me for a live fireside chat hosted by Jason Weimann today at 4:00 pm ET&#x2F;1:00 pm PT, where I will do my best to answer your questions. In the meantime, here are some more details.*Thank you for caring as deeply as you do, and thank you for giving us hard feedback.Marc Whitten reply purplecats 17 hours agoprevask for something you know will cause backlash (an anchor point) then recede to what you actually want reply hysan 15 hours agoprevDropping this on a Friday with a fireside chat happening in the afternoon on the same day leaves a bad impression. A blog post announcement is ok, but my reading of this is that there is no guarantee that they will not attempt a retroactive change again (ex: their TOS change and removal). This is a step in the right direction, but feels there’s still a long gap to bridge if they want to earn back trust. reply drra 16 hours agoprevUnity attempt at cash grab is nothing new but since it backfired they are using their sweetest words to walk it back. This is happening all the time in ecosystems where businesses are built completely relying on a single vendor or platform. The difference is hardly anybody hears or cares about it.You are not doing good job if your company or business model can be killed by anyone else than you or your customers. reply egypturnash 14 hours agoprev\"I’d like to invite you to join me for a live fireside chat hosted by Jason Weimann today at 4:00 pm ET&#x2F;1:00 pm PT, where I will do my best to answer your questions.\"Awaiting countless variants of \"who the hell thought this price change sounded like a good idea, and are they fired yet\". reply jenkstom 15 hours agoprevWhy can&#x27;t we just come out and say that the agent &#x2F; capital model is consumer antagonistic and work on fixing it? This is just a symptom, the cause needs to be addressed by the legislature. reply throw7 16 hours agoprevWhy is this not being given by the dude that made the initial pronouncement? I&#x27;m not affected by unity, but if I was I&#x27;d think long and hard about being fooled twice. reply rybosworld 16 hours agoprevOriginal pricing scheme was the brainchild of John R and Tomar B. As far as I am concerned, this announcement changes nothing with those two still present. reply yellow_lead 16 hours agoprevDid they wait so long to release it on a Friday? reply xyst 16 hours agoprevgot to love the Meta-esque “I am sorry” opener. At least they made changes to the program though.I feel Unity violated trust of community. No going back. Today it’s a claw back. Tomorrow (future) it’s back to f’ing over the community once the heat wears off. Or a new CEO is appointed. reply jhaehl 16 hours agoprevWhile a good portion of developers will still be switching engines and staying there, as an AR developer, there isn&#x27;t really anywhere else for me to go aside from developing with WebXR. Because of this, I am glad to see these changes. reply roblabla 16 hours agoparentWhat prevents you from using Unreal Engine? It has AR, and it seems fairly mature, though I&#x27;ve never tried it. Is it technical limitation&#x2F;pricing? reply peteforde 16 hours agorootparentApple won&#x27;t even release an Unreal SDK for Vision Pro, since they are still fighting over Fortnite.Unity has a major lock on the VR&#x2F;AR&#x2F;MR space. reply jhaehl 13 hours agorootparentprevApple&#x27;s Vision Pro support as well as Niantic&#x27;s Lightship ARDK are currently only available via Unity. In general, many of the tools for new AR platforms and devices are developed for Unity first. With all of this backlash that might change in the future, but for the time being the overwhelming majority of AR support goes into Unity. reply momojo 16 hours agoprevI&#x27;m out of the loop but used to use Unity as a hobbyist. What&#x27;s been going on? The letter and comments hint at an out-of-the-blue policy change? Who was affected? reply omgmajk 16 hours agoparentI skimmed this but it seems like a fine explanation: https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;9&#x2F;12&#x2F;23870547&#x2F;unit-price-chang...Basically policy changes that were absolutely abysmal and pretty much killed the entire Unity engine for most people. Now walk-back but trust is broken forever. reply 29athrowaway 16 hours agoprevToo late. They issued an ultimatum and proved they can change their time at any time for any reason.That got people thinking that it&#x27;s an unacceptable risk and they are working on mitigations. reply sdfghswe 16 hours agoprevIt takes 20 years to build your reputation and only 5 minutes to ruin it. reply lijok 15 hours agoprevStill not listening are they reply an5 15 hours agoprev [–] Salut replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Unity, the game development platform, has revised its new Runtime Fee policy, following backlash from the community; The company has issued an open letter of apology.",
      "Significant changes include an increased revenue cap from $100k to $200k for the Unity Personal plan, fee exemption for games earning less than $1million, and policy application only for Unity Pro and Enterprise users from the 2024 LTS version onwards.",
      "Unity offers payment options of a fixed 2.5% revenue share or new player-based calculated amount, billing the lesser figure. Unity invites creator queries and concerns through a live chat session."
    ],
    "commentSummary": [
      "Unity, a widely-used game development platform, is facing criticism for recent changes in its pricing policy, leading to a debate among its user community.",
      "Users are not only demanding assurances to prevent similar decisions in the future, but they are also unsure of Unity's ability to bounce back from this controversy.",
      "There are worries that Unity might continue making such changes without accountability, sparking a conversation about the significance of customer trust and the potential for damaging the company's reputation."
    ],
    "points": 234,
    "commentCount": 194,
    "retryCount": 0,
    "time": 1695403212
  },
  {
    "id": 37610447,
    "title": "Signal: The Pqxdh Key Agreement Protocol",
    "originLink": "https://signal.org/docs/specifications/pqxdh/",
    "originBody": "Get Signal Help Blog Developers Careers Donate The PQXDH Key Agreement Protocol Revision 1, 2023-05-24 [PDF] Ehren Kret, Rolfe Schmidt Table of Contents 1. Introduction 2. Preliminaries 2.1. PQXDH parameters 2.2. Cryptographic notation 2.3. Roles 2.4. Elliptic Curve Keys 2.5. Post-Quantum Key Encapsulation Keys 3. The PQXDH protocol 3.1. Overview 3.2. Publishing keys 3.3. Sending the initial message 3.4. Receiving the initial message 4. Security considerations 4.1. Authentication 4.2. Protocol replay 4.3. Replay and key reuse 4.4. Deniability 4.5. Signatures 4.6. Key compromise 4.7. Passive quantum adversaries 4.8. Active quantum adversaries 4.9. Server trust 4.10. Identity binding 4.11. Risks of weak randomness sources 5. IPR 6. Acknowledgements 7. References 1. Introduction This document describes the “PQXDH” (or “Post-Quantum Extended Diffie-Hellman”) key agreement protocol. PQXDH establishes a shared secret key between two parties who mutually authenticate each other based on public keys. PQXDH provides post-quantum forward secrecy and a form of cryptographic deniability but still relies on the hardness of the discrete log problem for mutual authentication in this revision of the protocol. PQXDH is designed for asynchronous settings where one user (“Bob”) is offline but has published some information to a server. Another user (“Alice”) wants to use that information to send encrypted data to Bob, and also establish a shared secret key for future communication. 2. Preliminaries 2.1. PQXDH parameters An application using PQXDH must decide on several parameters: Name Definition curve A Montgomery curve for which XEdDSA [1] is specified, at present this is one of curve25519 or curve448 hash A 256 or 512-bit hash function (e.g. SHA-256 or SHA-512) info An ASCII string identifying the application with a minimum length of 8 bytes pqkem A post-quantum key encapsulation mechanism (e.g. Crystals-Kyber-1024 [2]) EncodeEC A function that encodes a curve public key into a byte sequence DecodeEC A function that decodes a byte sequence into a curve public key and is the inverse of EncodeEC EncodeKEM A function that encodes a pqkem public key into a byte sequence DecodeKEM A function that decodes a byte sequence into a pqkem public key and is the inverse of EncodeKEM For example, an application could choose curve as curve25519, hash as SHA-512, info as “MyProtocol”, and pqkem as CRYSTALS-KYBER-1024. The recommended implementation of EncodeEC consists of a single-byte constant representation of curve followed by little-endian encoding of the u-coordinate as specified in [3]. The single-byte representation of curve is defined by the implementer. Similarly the recommended implementation of DecodeEC reads the first byte to determine the parameter curve. If the first byte does not represent a recognized curve, the function fails. Otherwise it applies the little-endian decoding of the u-coordinate for curve as specified in [3]. The recommended implementation of EncodeKEM consists of a single-byte constant representation of pqkem followed by the encoding of PQKPK specified by pqkem. The single-byte representation of pqkem is defined by the implementer. Similarly the recommended implementation of DecodeKEM reads the first byte to determine the parameter pqkem. If the first byte does not represent a recognized key encapsulation mechanism, the function fails. Otherwise it applies the decoding specified by the selected key encapsulation mechanism. 2.2. Cryptographic notation Throughout this document, all public keys have a corresponding private key, but to simplify descriptions we will identify key pairs by the public key and assume that the corresponding private key can be accessed by the key owner. This document will use the following notation: The concatenation of byte sequences X and Y is X || Y. DH(PK1, PK2) represents a byte sequence which is the shared secret output from an Elliptic Curve Diffie-Hellman function involving the key pairs represented by public keys PK1 and PK2. The Elliptic Curve Diffie-Hellman function will be either the X25519 or X448 function from [3], depending on the curve parameter. Sig(PK, M, Z) represents the byte sequence that is a curve XEdDSA signature on the byte sequence M which was created by signing M with PK’s corresponding private key and using 64 bytes of randomness Z. This signature verifies with public key PK. The signing and verification functions for XEdDSA are specified in [1]. KDF(KM) represents 32 bytes of output from the HKDF algorithm [4] using hash with inputs: HKDF input key material = F || KM, where KM is an input byte sequence containing secret key material, and F is a byte sequence containing 32 0xFF bytes if curve is curve25519, and 57 0xFF bytes if curve is curve448. As in in XEdDSA [1], F ensures that the first bits of the HKDF input key material are never a valid encoding of a scalar or elliptic curve point. HKDF salt = A zero-filled byte sequence with length equal to the hash output length, in bytes. HKDF info = The concatenation of string representations of the 4 PQXDH parameters info, curve, hash, and pqkem into a single string separated with ‘_’ such as “MyProtocol_CURVE25519_SHA-512_CRYSTALS-KYBER-1024”. The string representations of the PQXDH parameters are defined by the implementer. (CT, SS) = PQKEM-ENC(PK) represents a tuple of the byte sequence that is the KEM ciphertext, CT, output by the algorithm pqkem together with the shared secret byte sequence SS encapsulated by the ciphertext using the public key PK. PQKEM-DEC(PK, CT) represents the shared secret byte sequence SS decapsulated from a pqkem ciphertext using the private key counterpart of the public key PK used to encapsulate the ciphertext CT. 2.3. Roles The PQXDH protocol involves three parties: Alice, Bob, and a server. Alice wants to send Bob some initial data using encryption, and also establish a shared secret key which may be used for bidirectional communication. Bob wants to allow parties like Alice to establish a shared key with him and send encrypted data. However, Bob might be offline when Alice attempts to do this. To enable this, Bob has a relationship with some server. The server can store messages from Alice to Bob which Bob can later retrieve. The server also lets Bob publish some data which the server will provide to parties like Alice. The amount of trust placed in the server is discussed in Section 4.9. In some systems the server role might be divided between multiple entities, but for simplicity we assume a single server that provides the above functions for Alice and Bob. 2.4. Elliptic Curve Keys PQXDH uses the following elliptic curve public keys: Name Definition IKA Alice’s identity key IKB Bob’s identity key EKA Alice’s ephemeral key SPKB Bob’s signed prekey (OPKB1, OPKB2, …) Bob’s set of one-time prekeys The elliptic curve public keys used within a PQXDH protocol run must either all be in curve25519 form, or they must all be in curve448 form, depending on the curve parameter [3]. Each party has a long-term identity elliptic curve public key (IKA for Alice, IKB for Bob). Bob also has a signed prekey SPKB, which he changes periodically and signs each time with IKB, and a set of one-time prekeys (OPKB1, OPKB2, …), which are each used in a single PQXDH protocol run. (“Prekeys” are so named because they are essentially protocol messages which Bob publishes to the server prior to Alice beginning the protocol run.) These keys will be uploaded to the server as described in Section 3.2. During each protocol run, Alice generates a new ephemeral key pair with public key EKA. 2.5. Post-Quantum Key Encapsulation Keys PQXDH uses the following post-quantum key encapsulation public keys: Name Definition PQSPKB Bob’s signed last-resort pqkem prekey (PQOPKB1, PQOPKB2, …) Bob’s set of signed one-time pqkem prekeys The pqkem public keys used within a PQXDH protocol run must all use the same pqkem parameter. Bob has a signed last-resort post-quantum prekey PQSPKB, which he changes periodically and signs each time with IKB, and a set of signed one-time prekeys (PQOPKB1, PQOPKB2, …) which are also signed with IKB and each used in a single PQXDH protocol run. These keys will be uploaded to the server as described in Section 3.2. The name “last-resort” refers to the fact that the last-resort prekey is only used when one-time pqkem prekeys are not available. This can happen when the number of prekey bundles downloaded for Bob exceeds the number of one-time pqkem prekeys Bob has uploaded (see Section 3 for details about the role of the server). 3. The PQXDH protocol 3.1. Overview PQXDH has three phases: Bob publishes his elliptic curve identity key, elliptic curve prekeys, and pqkem prekeys to a server. Alice fetches a “prekey bundle” from the server, and uses it to send an initial message to Bob. Bob receives and processes Alice’s initial message. The following sections explain these phases. 3.2. Publishing keys Bob generates a sequence of 64-byte random values ZSPK, ZPQSPK, Z1, Z2, … and publishes a set of keys to the server containing: Bob’s curve identity key IKB Bob’s signed curve prekey SPKB Bob’s signature on the curve prekey Sig(IKB, EncodeEC(SPKB), ZSPK) Bob’s signed last-resort pqkem prekey PQSPKB Bob’s signature on the pqkem prekey Sig(IKB, EncodeKEM(PQSPKB), ZPQSPK) A set of Bob’s one-time curve prekeys (OPKB1, OPKB2, OPKB3, …) A set of Bob’s signed one-time pqkem prekeys (PQOPKB1, PQOPKB2, PQOPKB3, …) The set of Bob’s signatures on the signed one-time pqkem prekeys (Sig(IKB, EncodeKEM(PQOPKB1), Z1), Sig(IKB, EncodeKEM(PQOPKB2), Z2), Sig(IKB, EncodeKEM(PQOPKB3), Z3), …) Bob only needs to upload his identity key to the server once. However, Bob may upload new one-time prekeys at other times (e.g. when the server informs Bob that the server’s store of one-time prekeys is getting low). For both the signed curve prekey and the signed last-resort pqkem prekey, Bob will upload a new prekey along with its signature using IKB at some interval (e.g. once a week or once a month). The new signed prekey and its signatures will replace the previous values. After uploading a new pair of signed curve and signed last-resort pqkem prekeys, Bob may keep the private key corresponding to the previous pair around for some period of time to handle messages using it that may have been delayed in transit. Eventually, Bob should delete this private key for forward secrecy (one-time prekey private keys will be deleted as Bob receives messages using them; see Section 3.4). 3.3. Sending the initial message To perform a PQXDH key agreement with Bob, Alice contacts the server and fetches a “prekey bundle” containing the following values: Bob’s curve identity key IKB Bob’s signed curve prekey SPKB Bob’s signature on the curve prekey Sig(IKB, EncodeEC(SPKB), ZSPK) One of either Bob’s signed one-time pqkem prekey PQOPKBn or Bob’s last-resort signed pqkem prekey PQSPKB if no signed one-time pqkem prekey remains. Call this key PQPKB. Bob’s signature on the pqkem prekey Sig(IKB, EncodeKEM(PQPKB), ZPQPK) (Optionally) Bob’s one-time curve prekey OPKBn The server should provide one of Bob’s curve one-time prekeys if one exists and then delete it. If all of Bob’s curve one-time prekeys on the server have been deleted, the bundle will not contain a one-time curve prekey element. The server should prefer to provide one of Bob’s pqkem one-time signed prekeys PQOPKBn if one exists and then delete it. If all of Bob’s pqkem one-time signed prekeys on the server have been deleted, the bundle will instead contain Bob’s pqkem last-resort signed prekey PQSPKB. Alice verifies the signatures on the prekeys. If any signature check fails, Alice aborts the protocol. Otherwise, if all signature checks pass, Alice then generates an ephemeral curve key pair with public key EKA. Alice additionally generates a pqkem encapsulated shared secret: (CT, SS) = PQKEM-ENC(PQPKB) shared secret SS ciphertext CT If the bundle does not contain a curve one-time prekey, she calculates: DH1 = DH(IKA, SPKB) DH2 = DH(EKA, IKB) DH3 = DH(EKA, SPKB) SK = KDF(DH1 || DH2 || DH3 || SS) If the bundle does contain a curve one-time prekey, the calculation is modified to include an additional DH: DH4 = DH(EKA, OPKB) SK = KDF(DH1 || DH2 || DH3 || DH4 || SS) After calculating SK, Alice deletes her ephemeral private key, the DH outputs, the shared secret SS, and the ciphertext CT. Alice then calculates an “associated data” byte sequence AD that contains identity information for both parties: AD = EncodeEC(IKA) || EncodeEC(IKB) Alice may optionally append additional information to AD, such as Alice and Bob’s usernames, certificates, or other identifying information. Alice then sends Bob an initial message containing: Alice’s identity key IKA Alice’s ephemeral key EKA The pqkem ciphertext CT encapsulating SS for PQPKB Identifiers stating which of Bob’s prekeys Alice used An initial ciphertext encrypted with some AEAD encryption scheme [5] using AD as associated data and using an encryption key which is either SK or the output from some cryptographic PRF keyed by SK. The initial ciphertext is typically the first message in some post-PQXDH communication protocol. In other words, this ciphertext typically has two roles, serving as the first message within some post-PQXDH protocol, and as part of Alice’s PQXDH initial message. The initial message must be encoded in an unambiguous format to avoid confusion of the message items by the recipient. After sending this, Alice may continue using SK or keys derived from SK within the post-PQXDH protocol for communication with Bob, subject to the security considerations discussed in Section 4. 3.4. Receiving the initial message Upon receiving Alice’s initial message, Bob retrieves Alice’s identity key and ephemeral key from the message. Bob also loads his identity private key and the private key(s) corresponding to the signed prekeys and one-time prekeys Alice used. Using these keys, Bob calculates PQKEM-DEC(PQPKB, CT) as the shared secret SS and repeats the DH and KDF calculations from the previous section to derive SK, and then deletes the DH values and SS values. Bob then constructs the AD byte sequence using IKA and IKB as described in the previous section. Finally, Bob attempts to decrypt the initial ciphertext using SK and AD. If the initial ciphertext fails to decrypt, then Bob aborts the protocol and deletes SK. If the initial ciphertext decrypts successfully, the protocol is complete for Bob. For forward secrecy, Bob deletes the ciphertext and any one-time prekey private key that was used. Bob may then continue using SK or keys derived from SK within the post-PQXDH protocol for communication with Alice subject to the security considerations discussed in Section 4. 4. Security considerations The security of the composition of X3DH [6] with the Double Ratchet [7] was formally studied in [8] and proven secure under the Gap Diffie-Hellman assumption (GDH)[9]. PQXDH composed with the Double Ratchet retains this security against an adversary without access to a quantum computer, but strengthens the security of the initial handshake to require the solution of both GDH and Module-LWE [10]. The remainder of this section discusses an incomplete list of further security considerations. 4.1. Authentication Before or after a PQXDH key agreement, the parties may compare their identity public keys IKA and IKB through some authenticated channel. For example, they may compare public key fingerprints manually, or by scanning a QR code. Methods for doing this are outside the scope of this document. Authentication in PQXDH is not quantum-secure. In the presence of an active quantum adversary, the parties receive no cryptographic guarantees as to who they are communicating with. Post-quantum secure deniable mutual authentication is an open research problem which we hope to address with a future revision of this protocol. If authentication is not performed, the parties receive no cryptographic guarantee as to who they are communicating with. 4.2. Protocol replay If Alice’s initial message doesn’t use a one-time prekey, it may be replayed to Bob and he will accept it. This could cause Bob to think Alice had sent him the same message (or messages) repeatedly. To mitigate this, a post-PQXDH protocol may wish to quickly negotiate a new encryption key for Alice based on fresh random input from Bob. This is the typical behavior of Diffie-Hellman-based ratcheting protocols [7]. Bob could attempt other mitigations, such as maintaining a blacklist of observed messages, or replacing old signed prekeys more rapidly. Analyzing these mitigations is beyond the scope of this document. 4.3. Replay and key reuse Another consequence of the replays discussed in the previous section is that a successfully replayed initial message would cause Bob to derive the same SK in different protocol runs. For this reason, any post-PQXDH protocol that uses SK to derive encryption keys MUST take measures to prevent catastrophic key reuse. For example, Bob could use a DH-based ratcheting protocol to combine SK with a freshly generated DH output to get a randomized encryption key [7]. 4.4. Deniability Informally, cryptographic deniability means that a protocol neither gives its participants a publishable cryptographic proof of the contents of their communication nor proof of the fact that they communicated. PQXDH, like X3DH, aims to provide both Alice and Bob deniablilty that they communicated with each other in a context where a “judge” who may have access to one or more party’s secret keys is presented with a transcript allegedly created by communication between Alice and Bob. We focus on offline deniability because if either party is collaborating with a third party during protocol execution, they will be able to provide proof of their communication to such a third party. This limitation on “online” deniability appears to be intrinsic to the asynchronous setting [11]. PQXDH has some forms of cryptographic deniability. Motivated by the goals of X3DH, Brendel et al. [12] introduce a notion of 1-out-of-2 deniability for semi-honest parties and a “big brother” judge with access to all parties’ secret keys. Since either Alice or Bob can create a fake transcript using only their own secret keys, PQXDH has this deniability property. Vatandas, et al. [13] prove that X3DH is deniable in a different sense subject to certain “Knowledge of Diffie-Hellman Assumptions”. PQXDH is deniable in this sense for Alice, subject to the same assumptions, and we conjecture that it is deniable for Bob subject to an additional Plaintext Awareness (PA) assumption for pqkem. We note that Kyber uses a variant of the Fujisaki-Okamoto transform with implicit rejection [14] and is therefore not PA as is. However, in PQXDH, an AEAD ciphertext encrypted with the session key is always sent along with the Kyber ciphertext. This should offer the same guarantees as PA. We encourage the community to investigate the precise deniability properties of PQXDH. These assertions all pertain to deniability in the classical setting. As discussed in [15] we expect that for future revisions of this protocol (that provide post-quantum mutual authentication) assertions about deniability against semi-honest quantum advsersaries will hold. Deniability in the face of malicious quantum adversaries requires further research. 4.5. Signatures It might be tempting to omit the prekey signature after observing that mutual authentication and forward secrecy are achieved by the DH calculations. However, this would allow a “weak forward secrecy” attack: A malicious server could provide Alice a prekey bundle with forged prekeys, and later compromise Bob’s IKB to calculate SK. Alternatively, it might be tempting to replace the DH-based mutual authentication (i.e. DH1 and DH2) with signatures from the identity keys. However, this reduces deniability, increases the size of initial messages, and increases the damage done if ephemeral or prekey private keys are compromised, or if the signature scheme is broken. 4.6. Key compromise Compromise of a party’s private keys has a disastrous effect on security, though the use of ephemeral keys and prekeys provides some mitigation. Compromise of a party’s identity private key allows impersonation of that party to others. Compromise of a party’s prekey private keys may affect the security of older or newer SK values, depending on many considerations. A full analysis of all possible compromise scenarios is outside the scope of this document, however a partial analysis of some plausible scenarios is below: If either an elliptic curve one-time prekey (OPKB) or a post-quantum key encapsulation one-time prekey (PQOPKB) are used for a protocol run and deleted as specified, then a compromise of Bob’s identity key and prekey private keys at some future time will not compromise the older SK. If one-time prekeys were not used for a protocol run, then a compromise of the private keys for IKB, SPKB, and PQSPKB from that protocol run would compromise the SK that was calculated earlier. Frequent replacement of signed prekeys mitigates this, as does using a post-PQXDH ratcheting protocol which rapidly replaces SK with new keys to provide fresh forward secrecy [7]. Compromise of prekey private keys may enable attacks that extend into the future, such as passive calculation of SK values, and impersonation of arbitrary other parties to the compromised party (“key-compromise impersonation”). These attacks are possible until the compromised party replaces his compromised prekeys on the server (in the case of passive attack); or deletes his compromised signed prekey’s private key (in the case of key-compromise impersonation). 4.7. Passive quantum adversaries PQXDH is designed to prevent “harvest now, decrypt later” attacks by adversaries with access to a quantum computer capable of computing discrete logarithms in curve. If an attacker has recorded the public information and the message from Alice to Bob, even access to a quantum computer will not compromise SK. If a post-quantum key encapsulation one-time prekey (PQOPKB) is used for a protocol run and deleted as specified then compromise after deletion and access to a quantum computer at some future time will not compromise the older SK. If post-quantum one-time prekeys were not used for a protocol run, then access to a quantum computer and a compromise of the private key for PQSPKB from that protocol run would compromise the SK that was calculated earlier. Frequent replacement of signed prekeys mitigates this, as does using a post-PQXDH ratcheting protocol which rapidly replaces SK with new keys to provide fresh forward secrecy [7]. 4.8. Active quantum adversaries PQXDH is not designed to provide protection against active quantum attackers. An active attacker with access to a quantum computer capable of computing discrete logarithms in curve can compute DH(PK1, PK2) and Sig(PK, M, Z) for all elliptic curve keys PK1, PK2, and PK. This allows an attacker to impersonate Alice by using the quantum computer to compute the secret key corresponding to PKA then continuing with the protocol. A malicious server with access to such a quantum computer could impersonate Bob by generating new key pairs PQSPK’B and PQOPK’B, computing the secret key corresponding to PKB, then using PKB to sign the newly generated post-quantum KEM keys and delivering these attacker-generated keys in place of Bob’s post-quantum KEM key when Alice requests a prekey bundle. It is tempting to consider adding a post-quantum identity key that Bob could use to sign the post-quantum prekeys. This would prevent the malicious server attack described above and provide Alice a cryptographic guarantee that she is communicating with Bob, but it does not provide mutual authentication. Bob does not have any cryptographic guarantee about who he is communicating with. The post-quantum KEM and signature schemes being standardized by NIST [16] do not provide a mechanism for post-quantum deniable mutual authentication, although this can be achieved through the use of a post-quantum ring signature or designated verifier signature [12], [15]. We urge the community to work toward standardization of these or other mechanisms that will allow deniable mutual authentication. 4.9. Server trust A malicious server could cause communication between Alice and Bob to fail (e.g. by refusing to deliver messages). If Alice and Bob authenticate each other as in Section 4.1, then the only additional attack available to the server is to refuse to hand out one-time prekeys, causing forward secrecy for SK to depend on the signed prekey’s lifetime (as analyzed in Section 4.6). This reduction in initial forward secrecy could also happen if one party maliciously drains another party’s one-time prekeys, so the server should attempt to prevent this (e.g. with rate limits on fetching prekey bundles). 4.10. Identity binding Authentication as in Section 4.1 does not necessarily prevent an “identity misbinding” or “unknown key share” attack. This results when an attacker (“Charlie”) falsely presents Bob’s identity key fingerprint to Alice as his (Charlie’s) own, and then either forwards Alice’s initial message to Bob, or falsely presents Bob’s contact information as his own. The effect of this is that Alice thinks she is sending an initial message to Charlie when she is actually sending it to Bob. To make this more difficult the parties can include more identifying information into AD, or hash more identifying information into the fingerprint, such as usernames, phone numbers, real names, or other identifying information. Charlie would be forced to lie about these additional values, which might be difficult. However, there is no way to reliably prevent Charlie from lying about additional values, and including more identity information into the protocol often brings trade-offs in terms of privacy, flexibility, and user interface. A detailed analysis of these trade-offs is beyond the scope of this document. 4.11. Risks of weak randomness sources In addition to concerns about the generation of the keys themselves, the security of the PQKEM shared secret relies on the random source available to Alice’s machine at the time of running the PQKEM-ENC operation. This leads to a situation similar to what we face with a Diffie-Hellman exchange. For both Diffie-Hellman and Kyber, if Alice has weak entropy then the resulting shared secret will have low entropy when conditioned on Bob’s public key. Thus both the classical and post-quantum security of SK depend on the strength of Alice’s random source. Kyber hashes Bob’s public key with Alice’s random bits to generate the shared secret, making Bob’s key contributory, as it is with a Diffie-Hellman key exchange. This does not reduce the dependence on Alice’s entropy source, as described above, but it does limit Alice’s ability to control the post-quantum shared secret. Not all KEMs make Bob’s key contributory and this is a property to consider when selecting pqkem. 5. IPR This document is hereby placed in the public domain. 6. Acknowledgements The PQXDH protocol was developed by Ehren Kret and Rolfe Schmidt as an extension of the X3DH protocol [6] by Moxie Marlinspike and Trevor Perrin. Thanks to Trevor Perrin for discussions on the design of this protocol. Thanks to Bas Westerbaan, Chris Peikert, Daniel Collins, Deirdre Connolly, John Schanck, Jon Millican, Jordan Rose, Karthik Bhargavan, Loïs Huguenin-Dumittan, Peter Schwabe, Rune Fiedler, Shuichi Katsumata, Sofía Celi, and Yo’av Rieck for helpful discussions and editorial feedback. Thanks to the Kyber team [17] for their work on the Kyber key encapsulation mechanism. 7. References [1] T. Perrin, “The XEdDSA and VXEdDSA Signature Schemes,” 2016. https://signal.org/docs/specifications/xeddsa/ [2] “Module-lattice-based key-encapsulation mechanism standard.” https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.203.ipd.pdf [3] A. Langley, M. Hamburg, and S. Turner, “Elliptic Curves for Security.” Internet Engineering Task Force; RFC 7748 (Informational); IETF, Jan-2016. http://www.ietf.org/rfc/rfc7748.txt [4] H. Krawczyk and P. Eronen, “HMAC-based Extract-and-Expand Key Derivation Function (HKDF).” Internet Engineering Task Force; RFC 5869 (Informational); IETF, May-2010. http://www.ietf.org/rfc/rfc5869.txt [5] P. Rogaway, “Authenticated-encryption with Associated-data,” in Proceedings of the 9th ACM Conference on Computer and Communications Security, 2002. http://web.cs.ucdavis.edu/~rogaway/papers/ad.pdf [6] M. Marlinspike and T. Perrin, “The X3DH Key Agreement Protocol,” 2016. https://signal.org/docs/specifications/x3dh/ [7] T. Perrin and M. Marlinspike, “The Double Ratchet Algorithm,” 2016. https://signal.org/docs/specifications/doubleratchet/ [8] K. Cohn-Gordon, C. Cremers, B. Dowling, L. Garratt, and D. Stebila, “A formal security analysis of the signal messaging protocol,” J. Cryptol., vol. 33, no. 4, 2020. https://doi.org/10.1007/s00145-020-09360-1 [9] T. Okamoto and D. Pointcheval, “The gap-problems: A new class of problems for the security of cryptographic schemes,” in Proceedings of the 4th international workshop on practice and theory in public key cryptography: Public key cryptography, 2001. [10] A. Langlois and D. Stehlé, “Worst-case to average-case reductions for module lattices,” Des. Codes Cryptography, vol. 75, no. 3, Jun. 2015. https://doi.org/10.1007/s10623-014-9938-4 [11] N. Unger and I. Goldberg, “Deniable Key Exchanges for Secure Messaging,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015. https://cypherpunks.ca/~iang/pubs/dake-ccs15.pdf [12] J. Brendel, R. Fiedler, F. Günther, C. Janson, and D. Stebila, “Post-quantum asynchronous deniable key exchange and the signal handshake,” in Public-key cryptography - PKC 2022 - 25th IACR international conference on practice and theory of public-key cryptography, virtual event, march 8-11, 2022, proceedings, part II, 2022, vol. 13178. https://doi.org/10.1007/978-3-030-97131-1_1 [13] N. Vatandas, R. Gennaro, B. Ithurburn, and H. Krawczyk, “On the cryptographic deniability of the signal protocol,” in Applied cryptography and network security - 18th international conference, ACNS 2020, rome, italy, october 19-22, 2020, proceedings, part II, 2020, vol. 12147. https://doi.org/10.1007/978-3-030-57878-7_10 [14] D. Hofheinz, K. Hövelmanns, and E. Kiltz, “A modular analysis of the fujisaki-okamoto transformation,” in Theory of cryptography - 15th international conference, TCC 2017, baltimore, MD, USA, november 12-15, 2017, proceedings, part I, 2017, vol. 10677. https://doi.org/10.1007/978-3-319-70500-2_12 [15] K. Hashimoto, S. Katsumata, K. Kwiatkowski, and T. Prest, “An efficient and generic construction for signal’s handshake (X3DH): Post-quantum, state leakage secure, and deniable,” J. Cryptol., vol. 35, no. 3, 2022. https://doi.org/10.1007/s00145-022-09427-1 [16] NIST, “Post-quantum cryptography.” https://csrc.nist.gov/Projects/post-quantum-cryptography [17] “Kyber key encapsulation mechanism.” https://pq-crystals.org/kyber/ Want to get involved with Signal? We're hiring! © 2013–2023 Signal, a 501c3 nonprofit. Signal is a registered trademark in the United States and other countries. For media inquiries, contact press@signal.org Organization Donate Careers Blog Terms & Privacy Policy Download Android iPhone & iPad Windows Mac Linux Social GitHub Twitter Instagram Help Support Center Community",
    "commentLink": "https://news.ycombinator.com/item?id=37610447",
    "commentBody": "Signal: The Pqxdh Key Agreement ProtocolHacker NewspastloginSignal: The Pqxdh Key Agreement Protocol (signal.org) 225 points by thunderbong 23 hours ago| hidepastfavorite67 comments niel 23 hours agoPrevious discussion about the blog post announcement, including speculation about timelines: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37571919 reply ignoramous 23 hours agoprevCloudflare did a (phenomenal) series on pq safe (public key) cryptography; here are some posts:- NIST pq candidates: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;towards-post-quantum-cryptograph...- Kyber in TLS: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;post-quantum-for-all&#x2F;- Other candidates for TLS: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;the-tls-post-quantum-experiment&#x2F;- For cert sigs (as opposed to kex): https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;sizing-up-post-quantum-signature...If you squint enough, what Signal&#x27;s doing is similar to Kyber in TLS, which takes us back to KEM (like with RSA-OAEP in TLS v1.2 removed from v1.3) for key exchange (kex) with ECDH, in a pq safe way of course. reply drcongo 22 hours agoparentThat&#x27;s really useful, thanks. I barely understood a word of the OP. reply couchand 22 hours agorootparentThe link is a specification of the protocol, not a tutorial. It is intended to unambiguously state the operations, and requires significant background knowledge to be able to read correctly. reply drcongo 22 hours agorootparentI know, that&#x27;s why I thanked this poster for adding some links that are easier to understand. reply ylk 21 hours agorootparentSignal also created an easier to understand blog post in case you haven’t seen it, yet: https:&#x2F;&#x2F;signal.org&#x2F;blog&#x2F;pqxdh&#x2F; reply ignoramous 21 hours agorootparentprevI guess if you&#x27;re not already familiar with the Signal protocol specs, the current documentation might feel a little incomplete.TLDR is, SS (shared secret) derived rom Kyber is mixed in to make the handshake, which outputs SessionKey (SK), pq safe. Note though, offline authentication (of identities) itself isn&#x27;t pq safe (the authors plan to address this in the near future, however). &#x2F;&#x2F; CipherText (CT) and SharedSecret (SS) as outputs from Kyber (CT, SS) = Kyber(PostQuantumOneTimePublicPreKeyBob) &#x2F;&#x2F; DH1, DH2, DH3, and optionally DH4 are Diffie-Hellman-Merkel outputs SecretKey = HKDF-Signal(DH1 || DH2 || DH3 || *SS*) &#x2F;&#x2F; or StrongSecretKey = HKDF-Signal(DH1 || DH2 || DH3 || DH4 || *SS*)From Signal&#x27;s PQ-XDH spec (section 4.11):> Kyber hashes Bob&#x27;s public (pre)key with Alice&#x27;s random bits to generate the shared secret, making Bob&#x27;s key contributory, as it is with a Diffie-Hellman key exchange. This does not reduce the dependence on Alice&#x27;s entropy source but it does limit Alice&#x27;s ability to control the post-quantum shared secret (SS). Not all KEMs make Bob&#x27;s key contributory and this is a property to consider when selecting pqkem.The pqkem (Kyber) happens 2 phases (1a & 1b below): ---------- Alice: xx. recv(publickey) 0a. msg\"In short: constructions that concatenate secrets are vulnerable when the underlying hash function is not collision-resistant\"That&#x27;s quite a condition. reply beders 18 hours agoprevIf an attacker needs your specific signal messages, they wouldn&#x27;t bother with trying to break encryption as the messages you type and receive are right there in plain text on your device.(The software that captures your input and the software that writes to your display driver are typically not under your control)As for large scale surveillance: Definitely an improvement that makes it much more expensive for attackers. reply ignoramous 16 hours agoparent> If an attacker needs your specific signal messages, they wouldn&#x27;t bother with trying to break encryption as the messages you type and receive are right there in plain text on your device.Good thing then that the Signal Protocol is repudiable? https:&#x2F;&#x2F;signal.org&#x2F;docs&#x2F;specifications&#x2F;pqxdh&#x2F;#deniability reply handsclean 10 hours agorootparentThey definitely can and do scrape Signal logs and use them in court. The protocol doesn’t help them prove the validity of the log, but they don’t need it to: it’s already not plausible to claim that you and your contact falsified your logs, something few people know how to do, in sync, in order to frame yourselves. I think Signal’s approach to deniability is just not making it even more hopeless, while the real protection against future compromise of a currently trusted contact or your own device lies in a different strategy that does work, ephemerality. reply baby 22 hours agoprevthat&#x27;s interesting, I&#x27;m wondering how it compares with the way I drafted it a while back (https:&#x2F;&#x2F;gist.github.com&#x2F;mimoo&#x2F;356fd8c32216307d4f4f8b79659637... & https:&#x2F;&#x2F;gist.github.com&#x2F;mimoo&#x2F;4e90d030b4e927be29459f0ef92e62...) reply piuvas 23 hours agoprevloving it!!! reply RunSet 21 hours agoprevStill:• relies on a centralized authentication server• bans third party clients• requires a phone number to create an account despite no longer supporting SMS• marketing \"Perfect Forward Secrecy\" AKA \"Forward Secrecy\"[0].I favor Session Private Messenger[1] because it is decentralized and allows third party clients, but Signal enthusiasts warn me that the Session client may, hypothetically, at some future date, integrate a cryptocurrency, as the Signal client already does[2].[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Forward_secrecy[1] https:&#x2F;&#x2F;getsession.org[2] https:&#x2F;&#x2F;www.stephendiehl.com&#x2F;blog&#x2F;signal.html reply lxgr 17 hours agoparentI feel like at this point, we can consider Signal the Mozilla of messaging: They deliver a desperately needed high-quality, open-source alternative to an oligopoly of sometimes secure but always closed-source competitors, yet we hold them to much higher standards than any of these.Yes, Signal is (intentionally, i.e. as a stated design goal!) not federated, and I&#x27;m not super happy about it.Yes, it includes a cryptocurrency nobody asked for, and I&#x27;m definitely not happy about that.Yes, they&#x27;ve dared to dabble with trusted computing, and Intel SGX at that! (Although only in a purely-additive way, which I find really hard to disagree with, personally.)But they have done so much for giving users a reasonable chance at evading the warrant-less wiretapping that is dragnet data collection.Signal has pushed WhatsApp to become end-to-end encrypted by default, and that might have very well set the most important precedent for encryption-by-default in the recent past (see the UK&#x27;s current legislation, and the EU&#x27;s attempts of doing the same).They&#x27;re continuously pushing the envelope and are collaborating with academic cryptgraphic researchers on pq-safety, which will trickle down into all non-Signal users of the Signal protocol before too long (which includes WhatsApp and Facebook Messenger, making up for multiple billion daily users).Yes, we should continue to hold them to a high standard, but I&#x27;d love if we could sometimes also keep things in perspective. reply autoexec 11 hours agorootparentThey also refuse to update their privacy policy, which lies when they say that signal is designed to \"never collect and store any sensitive information\". They&#x27;re collecting and forever storing a list of all your contacts in the cloud, along with your name, phone number, and photo.Considering too their very sketchy communication about that data collection and the confusion it&#x27;s caused, I suspect that lie to be a canary warning people away from Signal.If it isn&#x27;t, and they&#x27;re just misleading people about the risks of using their service while also advertising it to vulnerable people like activists and whistleblowers, I guess they failed to live up to my \"high standard\" of having ethics. In either case, all I can do is recommend that people stay the hell away from Signal.If you want a Mozilla of secure messaging, try Jitsi or Jami reply spoiler 15 hours agorootparentprevI might be out of the loop a little bit, but wasn&#x27;t Telegram the first that offered E2E encryption[1] for the \"general public\" (at least it was very popular in Europe)? So, I feel attributing WhatsApp etc implementing E2E because of Signal is overselling it a bit.[1] I know there was some controversy because someone (Signal, maybe?) accused them of using a custom encryption scheme that was poorly designed. I didn&#x27;t follow that drama very closely, but given Telegram is still around and there hasn&#x27;t been any outrageous news claiming its encryption getting cracked, I assume it was a mistaken claim. reply lxgr 13 hours agorootparentNo, Telegram was neither the first to offer end-to-end encryption (Signal started out as TextSecure in 2010), nor do they make end-to-end encryption the default.Defaults matter.> given Telegram is still around and there hasn&#x27;t been any outrageous news claiming its encryption getting cracked, I assume it was a mistaken claim.“Innocent until proven guilty” is for criminal systems, not security analysis.And the controversy you are referring to, regarding unusual (to put it mildly) design choices in their E2E protocol is indeed very concerning, but the fact that Telegram by default is not end-to-end encrypted and stores all chat history server-side in a way that is accessible to its operators is undisputed. reply spoiler 10 hours agorootparentOh, you&#x27;re right about it not being the default. I could&#x27;ve sworn it was the default way back when, but I might be misremembering. Also wasn&#x27;t aware Signal rebranded.> “Innocent until proven guilty” is for criminal systems, not security analysis.Sorry if this sounds ignorant; I&#x27;m not a cryptanalyst&#x2F;security researcher. Isn&#x27;t this kind of the norm in the industry?A few examples come to mind like hashing algorithms or encryption methods becoming obsolete over the years.Was that due to the innocent-until-guilty mindset, or because computational power just overtook those standards? reply nullc 10 hours agorootparentprev> includes a cryptocurrency nobody asked for, and I&#x27;m definitely not happy about that.They created a centralized SGX based \"cryptocurrency\" and some not-publicly-identified person with a phenomenal amount of this entirely premined cryptocurency used the signal integration as a pump to steal a billion dollars from FTX&#x27;s customers.This isn&#x27;t even equivalent to Mozilla integrating something widely used like Bitcoin at all... and Mozilla hasn&#x27;t done that.Even if you&#x27;re utilitarian-consequentialist enough to see enabling&#x2F;participating in a scam as a justifiable means to fund charitable efforts (like SBF) then you should still see that an encrypted messager with remote update ability really shouldn&#x27;t be putting itself in a potentially exploitable position. \"Ship this backdoor to these targets, or you get prosecuted for your cryptocurrency stunts\".The \"Don&#x27;t Break the Law When You&#x27;re Breaking The Law\" adage doesn&#x27;t just apply to doing crimes, it also applies when you&#x27;re doing stuff that powerful entities wished were crimes.> (Although only in a purely-additive way,I don&#x27;t agree. Signal now uploads your contacts and other privacy relevant data to their servers, protected by nothing other than a trivial-to-bruteforce pin and SGX. They used varrious dark patterns to prevent any opt-out from the functionality. Their excuse for the acceptability of protection by trivially weak pins is SGX.If they were streaming all session keys to the Chinese government protected by ROT13 would we say that it&#x27;s okay that rot13&#x27;s dubiousness is okay because its purely additive? No. Signal depends on SGX is a material way, and compromises user confidentiality with it even for users that have no interest in the marginal functionality provided by backing up that data to their servers.The grandparent poster also missed many other problems with signal. For example, they actively block users from protecting themselves from rogue updates by timebombing every version. They undermined the ability for users to validate identities via other channels by making the comparison fingerprint process functionally pairwise unique (something which originally worked in signal). They&#x27;ve at various times made it extremely difficult to tell when a MITM has replaced your counterparty, e.g. by reencrypting and automatically resending when messages when the key changes (though I&#x27;m not sure if they backed off on that) and by noting a key change with a small grey message which the other side can scroll off by sending multiple times.All that said I think signals weaknesses are kind of moot now in any case, because it no longer acts as an SMS app on android anymore it will likely fade out as more and more people fail to discover that the people they&#x27;re communicating with have it installed. Signal is dead but it&#x27;ll take a decade for the body to cool off. reply sneak 21 hours agoparentprevSignal does not ban third party clients. I use a private fork of Signal Desktop every day and it works fine.I know several others who operate Signal bots using API clients (in Java, IIRC).They don&#x27;t like it, but the ToS doesn&#x27;t prohibit it.We would consider it ridiculous if Google updated their ToS to say you must use Chrome to access google.com. I consider HTTP APIs of which I am a legitimate user to be the same; I will use whatever client I wish. reply kuschku 20 hours agorootparentWell, they threatened LibreSignal with legal action, both for accessing their service and for using the Signal name, demanding that any third party client runs their own entire separate server network. Sounds pretty much like a ban. reply sneak 20 hours agorootparentThat&#x27;s a trademark (or perhaps trade dress) issue because it had \"Signal\" in the name.They (the forkers) were stupid to induce brand confusion like that.Signal is GPL free software; you can fork it and release it with any API URLs you like in the source or binary. It is perfectly legal to fork Signal and remove the user-hostile expiration timer, the image scaling enshittifier that happens on upload, and leave the signal.org API URLs completely unchanged. You just can&#x27;t call it Signal (or LibreSignal, or BetterSignal, or ExtraSignal, or whatever) when distributing it.The API ToS is what applies to end users who connect to the API. It says nothing about what software you are allowed to use to do so.Signal would prefer to pretend that they get to choose what tools their users get to use to consume their service. Unfortunately for them (but good for us), they don&#x27;t. It&#x27;s the web and such a restriction would be insane.Don&#x27;t confuse software and services. They aren&#x27;t the same. reply Evidlo 18 hours agorootparentThis is so wrong. Signal is absolutely against third-party clients. Here&#x27;s a quote from Moxie himself: I understand that federation and defined protocols that third parties can develop clients for are great and important ideas, but unfortunately they no longer have a place in the modern world. Even less of a place for an organization the size of ours. Everyone outside the FOSS community seems to know it, but it took actually building the service for me to come to the same understanding, so I don&#x27;t expect you to believe me. [0]0: https:&#x2F;&#x2F;github.com&#x2F;libresignal&#x2F;libresignal&#x2F;issues&#x2F;37I push back when anyone recommends Signal because it is fundamentally not an open network. reply exitheone 17 hours agorootparentThis is not saying anything about being open. This is talking about federation and stable protocols.Both absolutly do hamper fast evolution of a product because they require a LOT of coordination and consensus, both of which are incredibly expensive and time consuming.With a non-federated and unstable protocol, they are free to update and deprecated whatever they like and on a fast timescale. That is impossible with a federated stable protocol.This has nothing to do with FOSS.XMPP is a good example of a protocol that got fragmented to death by many many different and incompatible extensions, ultimately making it too fragmented and too slow to adopt to new requirements. reply wkat4242 10 hours agorootparentXMPP is fragmented yes but matrix works great. XMPP just made things too modular. reply wkat4242 10 hours agorootparentprevSame here, and I think matrix is doing an amazing job at proving that federation is not a barrier to innovation.Third party clients really should be fully allowed too (even though they&#x27;re not actually being banned so technically they&#x27;re being condoned) reply greyface- 17 hours agorootparentprevMoxie isn&#x27;t CEO anymore. Has Meredith made any statements on third party clients since taking the reins? reply kuschku 19 hours agorootparentprev> Signal would prefer to pretend that they get to choose what tools their users get to use to consume their service. Unfortunately for them (but good for us), they don&#x27;t. It&#x27;s the web and such a restriction would be insane.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Computer_Fraud_and_Abuse_ActSadly, they do get to choose what is considered \"authorised\" use of their service :( replynebulous1 20 hours agoparentprev> • relies on a centralized authentication serverThe reality is that most of Signal&#x27;s popularity stems from them using phone numbers for initial authentication. Obviously there are people who can work without phone number, but the general population cannot. Or perhaps more correctly, will not. They&#x27;ll just continue using a system that does. reply xoa 18 hours agorootparent>Obviously there are people who can work without phone number, but the general population cannot.I think you&#x27;re wrong in multiple ways. First, you are asserting a false dichotomy. Using phone numbers as one option for authentication in absolutely no way requires using them exclusively. To take a fairly large scale example, Apple&#x27;s iMessage does not require any phone number. People can transparently use it with their phone numbers easily, but it will also work fine and always has with any email-based Apple ID. No telephone is required at all.Second and more foundationally, we can objectively observe given the popularity of a range of online accounts using email or just user names (Facebook, Google, etc) that the general population is perfectly capable of working without a phone number. The UX might require more effort, and onboarding in some countries might be easier of course with phone numbers. reply wkat4242 10 hours agorootparentprevThe general population is doing just fine with emails, Twitter handles or Instagram names without a phone number. reply jacoblambda 19 hours agoparentprev> but Signal enthusiasts warn me that the Session client may, hypothetically, at some future date, integrate a cryptocurrencySession actually already does. It&#x27;s just not exposed to the user because the OPTF foots the bill for it. But theoretically if the OPFT was to completely fold and Oxen & Session were to keep chugging along, you&#x27;d need to pay some minuscule per message fee for the service you are getting from the network.The OPTF intends on footing the bill for basic messaging as long as they continue to exist but they probably will need to add some degree of user facing fees for video chat, etc in the long run if it ever seriously takes off. reply tcfhgj 21 hours agoparentprev> • marketing \"Perfect Forward Secrecy\" AKA \"Forward Secrecy\"[0].what do you mean by that? reply bawolff 19 hours agorootparentIndeed this is a bizarre criticism.Why wouldn&#x27;t signal market a crypto property that is especially important in the context of a messenger app? reply nullc 10 hours agorootparentBecause lay users misunderstand \"Perfect forward secrecy\" as \"perfect security\". It&#x27;s actively misleading when included in marketing material targeted at a lay audience.OTOH it&#x27;s also probably read by most as meaningless hyperbole, so the actual damage from being misleading is probably minimal. reply bawolff 10 hours agorootparentI also hate the name, but its not like signal was the one who came up with the term. I somewhat think most marketing discussions of cryptography are highly misleading, although i suppose its reasonable to want signal to be better. reply ComodoHacker 16 hours agoparentprevPlease can we refrain from arguments like \"this is from the same people I don&#x27;t like because ...\"? reply popol12 21 hours agoprevAnd yet I still can&#x27;t back up or transfer my message history out of my iPhone&#x2F;to Android. Priorities. reply sneak 20 hours agoparentI don&#x27;t think this is a very common use case.When I switched to Signal, I stopped preserving my message history. I now have 4 week expirations on all chats by default. reply JoshTriplett 20 hours agorootparent> I don&#x27;t think this is a very common use case.It&#x27;s the use case that prevents me from recommending Signal to anyone I know.Some people may not value that data, and may choose to deliberately throw it away; that&#x27;s their choice. But it shouldn&#x27;t get lost because of a lost or broken phone. reply taway1237 19 hours agorootparentI value ma data, that&#x27;s why I don&#x27;t keep important information in random chats. But I digress. If you care about losing your history, the proper solution is backing it up, right? Signal does support that. reply sneak 19 hours agorootparentIt does not, at least not on iOS. reply sneak 20 hours agorootparentprevYou can restore from Android to Android, and from iOS to iOS.I don&#x27;t think it&#x27;s very often that people switch phone platforms, given the enormous switching costs engineered by Apple and Google to avoid competition on merit. reply adastra22 20 hours agorootparentMessage history isn’t saved in backups. Restoring your phone does not preserve message history. reply sneak 19 hours agorootparentWe are talking about restoring chat history in-app from one phone to another phone. The Signal app allows you to transfer its state (which you correctly note is not stored in backups) from Signal running on one phone to Signal running on a second phone on the same LAN.The serialization (I guess) is different on iOS and Android so it only works between phones running the same OS.A lost or broken phone does indeed render the chat history toast, however. replyexfil 21 hours agoprev [–] \"Don&#x27;t roll your own crypto...\" reply josephg 20 hours agoparentThis is coming from Signal, who are more than qualified to do this kind of work. You shouldn&#x27;t roll your own crypto. But crypto experts can do what they want. reply inp 20 hours agorootparentYes, and moreover, they just add a shared secret in the computation of the initial root key, it cannot be worse in this case. reply flangola7 18 hours agorootparentIs that good or bad? reply 7v3x3n3sem9vv 17 hours agorootparentit&#x27;s good. think of it like adding a different kind of lock that requires a different key (method) to open up first. at worst it&#x27;s no less secure than before. If it works as intended it&#x27;s a huge disincentive for anyone collecting encrypted data with the hopes that a quantum computer may break encryption the \"old\" method in the future. reply zx8080 18 hours agorootparentprevWhat could go wrong reply HumanOstrich 19 hours agoparentprevIf this is always true, then where does crypto come from? reply lxgr 17 hours agorootparentJust like the efficient market hypothesis presents a paradox of who actually makes the market, \"don&#x27;t roll your own crypto\" keeps this question unanswered :) reply omginternets 19 hours agorootparentprevI believe a stork installs the crypto package for your favorite language. reply lxgr 17 hours agoparentprev [–] Not sure if you&#x27;re joking, but \"your own\" usually means \"in isolation of both academic and applied cryptography\" – and Signal has some of the world&#x27;s finest of both working on their protocol, as evidenced by the multiple quoted academic papers. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The document details PQXDH, a key agreement protocol for public key authentication, providing post-quantum forward secrecy, deniability, and designed for asynchronous settings.",
      "It describes the protocol's phases, the roles of involved parties, and incorporates both elliptic curve and post-quantum keys with focus on post-quantum deniable mutual authentication.",
      "It also outlines security implications, addressing threats such as communication failure, and identity misbinding attacks while emphasizing on strong randomness and the importance of contributory properties during post-quantum key encapsulation mechanism selection."
    ],
    "commentSummary": [
      "The newly released Pqxdh Key Agreement Protocol by Signal is a central topic of discussion, with users debating its privacy features and potential security vulnerabilities.",
      "Some users are recommending alternative secure messaging apps, indicating a mixed perception of Signal's latest protocol.",
      "Criticisms of Signal include its dependence on a centralized server and marketing strategies, yet the main focus remains on the security and privacy features of Signal and its counterparts."
    ],
    "points": 225,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1695380570
  },
  {
    "id": 37613747,
    "title": "I'm all-in on server-side SQLite (2022)",
    "originLink": "https://fly.io/blog/all-in-on-sqlite-litestream/",
    "originBody": "Articles Blog Phoenix Files Laravel Bytes Ruby Dispatch Django Beats JavaScript Journal Docs Community Status Pricing Sign In Get Started RSS Feed READING TIME • 15 MIN SHARE THIS POST ON TWITTER SHARE THIS POST ON HACKER NEWS SHARE THIS POST ON REDDIT I'm All-In on Server-Side SQLite Author Name Ben Johnson Twitter @benbjohnson I’m Ben Johnson. I wrote BoltDB, an embedded database that is the backend for systems like etcd. Now I work at Fly.io, on Litestream. Litestream is an open-source project that makes SQLite tenable for full-stack applications through the power of ✨replication✨. If you can set up a SQLite database, you can get Litestream working in less than 10 minutes. The conventional wisdom of full-stack applications is the n-tier architecture, which is now so common that it’s easy to forget it even has a name. It’s what you’re doing when you run an “application server” like Rails, Django, or Remix alongside a “database server” like Postgres. According to the conventional wisdom, SQLite has a place in this architecture: as a place to run unit tests. The conventional wisdom could use some updating. I think that for many applications – production applications, with large numbers of users and high availability requirements – SQLite has a better place, in the center of the stack, as the core of your data and persistence layer. It’s a big claim. It may not hold for your application. But you should consider it, and I’m here to tell you why. A Brief History Of Application Databases 50 years is not a long time. In that time, we’ve seen a staggering amount of change in how our software manages data. In the beginning of our story, back in the ‘70s, there were Codd’s rules, defining what we now call “relational databases”, also known today as “databases”. You know them, even if you don’t: all data lives in tables; tables have columns, and rows are addressable with keys; C.R.U.D.; schemas; a textual language to convey these concepts. The language, of course, is SQL, which prompted a Cambrian explosion of SQL databases, from Oracle to DB2 to Postgres to MySQL, throughout the '80s and '90s. It hasn’t all been good. The 2000s got us XML databases. But our industry atoned by building some great columnar databases during the same time. By the 2010s, we saw dozens of large-scale, open-source distributed database projects come to market. Now anyone can spin up a cluster and query terabytes of data. As databases evolved, so too did the strategies we use to plug them in to our applications. Almost since Codd, we’ve divided those apps into tiers. First came the database tier. Later, with memcached and Redis, we got the caching tier. We’ve got background job tiers and we’ve got routing tiers and distribution tiers. The tutorials pretend that there are 3 tiers, but we all know it’s called “n-tier” because nobody can predict how many tiers we’re going to end up with. You know where we’re going with this. Our scientists were so preoccupied with whether or not they could, and so on. See, over these same five decades, we’ve also seen CPUs, memory, & disks become hundreds of times faster and cheaper. A term that practically defines database innovation in the 2010s is “big data”. But hardware improvements have made that concept slippery in the 2020s. Managing a 1 GB database in 1996? A big deal. In 2022? Run it on your laptop, or a t3.micro. When we think about new database architectures, we’re hypnotized by scaling limits. If it can’t handle petabytes, or at least terabytes, it’s not in the conversation. But most applications will never see a terabyte of data, even if they’re successful. We’re using jackhammers to drive finish nails. The Sweet Release of SQLite There’s a database that bucks a lot of these trends. It’s one of the most popular SQL databases in the world, so standardized it’s an official archival format of the Library of Congress, it’s renowned for its reliability and its unfathomably encompassing test suite, and its performance is so good that citing its metrics on a message board invariably starts an argument about whether it should be disqualified. I probably don’t have to name it for you, but, for the one person in the back with their hand raised, I’m talking about SQLite. SQLite is an embedded database. It doesn’t live in a conventional architectural tier; it’s just a library, linked into your application server’s process. It’s the standard bearer of the “single process application”: the server that runs on its own, without relying on nine other sidecar servers to function. I got interested in these kinds of applications because I build databases. I wrote BoltDB, which is a popular embedded K/V store in the Go ecosystem. BoltDB is reliable and, as you’d expect from an in-process database, it performs like a nitro-burning funny car. But BoltDB has limitations: its schema is defined in Go code, and so it’s hard to migrate databases. You have to build your own tooling for it; there isn’t even a REPL. If you’re careful, using this kind of database can get you a lot of performance. But for general-purpose use, you don’t want to run your database off the open headers like a funny car. I thought about the kind of work I’d have to do to make BoltDB viable for more applications, and the conclusion I quickly reached was: that’s what SQLite is for. SQLite, as you are no doubt already typing into the message board comment, is not without its own limitations. The biggest of them is that a single-process application has a single point of failure: if you lose the server, you’ve lost the database. That’s not a flaw in SQLite; it’s just inherent to the design. Enter Litestream There are two big reasons everyone doesn’t default to SQLite. The first is resilience to storage failures, and the second is concurrency at scale. Litestream has something to say about both concerns. How Litestream works is that it takes control of SQLite’s WAL-mode journaling. In WAL mode, write operations append to a log file stored alongside SQLite’s main database file. Readers check both the WAL file and the main database to satisfy queries. Normally, SQLite automatically checkpoints pages from the WAL back to the main database. Litestream steps in the middle of this: we open an indefinite read transaction that prevents automatic checkpoints. We then capture WAL updates ourselves, replicate them, and trigger the checkpointing ourselves. The most important thing you should understand about Litestream is that it’s just SQLite. Your application uses standard SQLite, with whatever your standard SQLite libraries are. We’re not parsing your queries or proxying your transactions, or even adding a new library dependency. We’re just taking advantage of the journaling and concurrency features SQLite already has, in a tool that runs alongside your application. For the most part, your code can be oblivious to Litestream’s existence. Or, think of it this way: you can build a Remix application backed by Litestream-replicated SQLite, and, while it’s running, crack open the database using the standard sqlite3 REPL and make some changes. It’ll just work. You can read more about how this works here. It sounds complicated, but it’s incredibly simple in practice, and if you play with it you’ll see that it “just works”. You run the Litestream binary on the server your database lives on in “replicate” mode: litestream replicate fruits.db s3://my-bukkit:9000/fruits.db And then you can “restore” it to another location: litestream restore -o fruits-replica.db s3://my-bukkit:9000/fruits.db Now commit a change to your database; if you restore again then you’ll see the change on your new copy. We’ll replicate almost anywhere: to S3, or Minio; to Azure, or Backblaze B2, or Digital Ocean or Google Cloud, or an SFTP server. The ordinary way people use Litestream today is to replicate their SQLite database to S3 (it’s remarkably cheap for most SQLite databases to live-replicate to S3). That, by itself, is a huge operational win: your database is as resilient as you ask it to be, and easily moved, migrated, or mucked with. But you can do more than that with Litestream. The upcoming release of Litestream will let you live-replicate SQLite directly between databases, which means you can set up a write-leader database with distributed read replicas. Read replicas can catch writes and redirect them to the leader; most applications are read-heavy, and this setup gives those applications a globally scalable database. Litestream SQLite, Postgres, CockroachDB, or any other database They all work on Fly.io; we do built-in persistent storage and private networking for painless clustering, so it’s easy to try new stuff out. Try Fly → You Should Take This Option More Seriously One of my first jobs in tech in the early 2000s was as an Oracle Database Administrator (DBA) for an Oracle9i database. I remember spending hours poring over books and documentation to learn the ins and outs of the Oracle database. And there were a lot. The administration guide was almost a thousand pages—and that was just one of over a hundred documentation guides. Learning what knobs to turn to optimize queries or to improve writes could make a big difference back then. We had disk drives that could only read tens of megabytes per second so utilizing a better index could change a 5-minute query into a 30 second query. But database optimization has become less important for typical applications. If you have a 1 GB database, an NVMe disk can slurp the whole thing into memory in under a second. As much as I love tuning SQL queries, it’s becoming a dying art for most application developers. Even poorly tuned queries can execute in under a second for ordinary databases. Modern Postgres is a miracle. I’ve learned a ton by reading its code over the years. It includes a slew of features like a genetic query optimizer, row-level security policies, and a half dozen different types of indexes. If you need those features, you need them. But most of you probably don’t. And if you don’t need the Postgres features, they’re a liability. For example, even if you don’t use multiple user accounts, you’ll still need to configure and debug host-based authentication. You have to firewall off your Postgres server. And more features mean more documentation, which makes it difficult to understand the software you’re running. The documentation for Postgres 14 is nearly 3,000 pages. SQLite has a subset of the Postgres feature set. But that subset is 99.9% of what I typically need. Great SQL support, windowing, CTEs, full-text search, JSON. And when it lacks a feature, the data is already next to my application. So there’s little overhead to pull it in and process it in my code. Meanwhile, the complicated problems I really need to solve aren’t really addressed by core database functions. Instead, I want to optimize for just two things: latency & developer experience. So one reason to take SQLite seriously is that it’s operationally much simpler. You spend your time writing application code, not designing intricate database tiers. But then there’s the other problem. The light is too damn slow We’re beginning to hit theoretical limits. In a vacuum, light travels about 186 miles in 1 millisecond. That’s the distance from Philadelphia to New York City and back. Add in layers of network switches, firewalls, and application protocols and the latency increases further. The per-query latency overhead for a Postgres query within a single AWS region can be up to a millisecond. That’s not Postgres being slow—it’s you hitting the limits of how fast data can travel. Now, handle an HTTP request in a modern application. A dozen database queries and you’ve burned over 10ms before business logic or rendering. There’s a magic number for application latency: responses in 100ms or less feel instantaneous. Snappy applications make happy users. 100ms seems like a lot, but it’s easy to carelessly chew it up. The 100ms threshold is so important that people pre-render their pages and post them on CDNs just to reduce latency. We’d rather just move our data close to our application. How much closer? Really close. SQLite isn’t just on the same machine as your application, but actually built into your application process. When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds. That’s micro, with a μ. A 50-100x improvement over an intra-region Postgres query. But wait, there’s more. We’ve effectively eliminated per-query latency. Our application is fast, but it’s also simpler. We can break up larger queries into many smaller, more manageable queries, and spend the time we’ve been using to hunt down corner-casey N+1 patterns building new features. Minimizing latency isn’t just for production either. Running integration tests with a traditional client/server database easily grows to take minutes locally and the pain continues once you push to CI. Reducing the feedback loop from code change to test completion doesn’t just save time but also preserves our focus while developing. A one-line change to SQLite will let you run it in-memory so you can run integration tests in seconds or less. Small, Fast, Reliable, Globally Distributed: Choose Any Four Litestream is distributed and replicated and, most importantly, still easy to get your head around. Seriously, go try it. There’s just not much to know. My claim is this: by building reliable, easy-to-use replication for SQLite, we make it attractive for all kinds of full-stack applications to run entirely on SQLite. It was reasonable to overlook this option 170 years ago, when the Rails Blog Tutorial was first written. But SQLite today can keep up with the write load of most applications, and replicas can scale reads out to as many instances as you choose to load-balance across. Litestream has limitations. I built it for single-node applications, so it won’t work well on ephemeral, serverless platforms or when using rolling deployments. It needs to restore all changes sequentially which can make database restores take minutes to complete. We’re rolling out live replication, but the separate-process model restricts us to course-grained control over replication guarantees. We can do better. For the past year, what I’ve been doing is nailing down the core of Litestream and keeping a focus on correctness. I’m happy with where we’ve landed. It started as a simple, streaming back up tool but it’s slowly evolving into a reliable, distributed database. Now it’s time to make it faster and more seamless, which is my whole job at Fly.io. There are improvements coming to Litestream — improvements that aren’t at all tied to Fly.io! — that I’m psyched to share. Litestream has a new home at Fly.io, but it is and always will be an open-source project. My plan for the next several years is to keep making it more useful, no matter where your application runs, and see just how far we can take the SQLite model of how databases can work. LAST UPDATED • MAY 9, 2022 Share this post on Twitter Share this post on Hacker News Share this post on Reddit Next post ↑ Logbook - 2022-05-13 Previous post ↓ Logbook - 2022-05-05 COMPANY About Pricing Jobs ARTICLES Blog Phoenix Files Laravel Bytes Ruby Dispatch Django Beats JavaScript Journal RESOURCES Docs Support Status CONTACT GitHub Twitter Community LEGAL Security Privacy policy Terms of service Copyright © 2023 Fly.io",
    "commentLink": "https://news.ycombinator.com/item?id=37613747",
    "commentBody": "I&#x27;m all-in on server-side SQLite (2022)Hacker NewspastloginI&#x27;m all-in on server-side SQLite (2022) (fly.io) 203 points by rrampage 18 hours ago| hidepastfavorite152 comments erulabs 17 hours agoI hope fly is able to make it. I’m rooting for them - however - I’m starting to wonder if the SQLite push isn’t more “this is fun and interesting to build” and less “customers want this”.Don’t get me wrong - this is neat - but I’d never suggest anyone to actually use this outside of a fun experiment. The problem with existing SQL dbs isn’t really the architecture - its the awful queries that do in memory sorting or make temporary tables for no reason or read-after-write, etc, not network latency. SQLite won’t fix your current production problems.If it turns out they’re building this for customers throwing cash at them, awesome. I just somehow doubt it. I think Planetscale has the better approach: a drop in replacement for MySQL&#x2F;RDS with a smarter query planner. As a production engineer that’s what I want to pay for! reply mattgreenrocks 16 hours agoparentI’m excited about SQLite for web apps if only because it is one less moving piece in my stack, which focuses on prototyping and finding product market fit.If I start hitting hundreds of writes per sec, then, thats either awesome or I wrote some horrible code. reply erulabs 15 hours agorootparentThis is exactly where I think SQLite shines! Unfortunately, I don&#x27;t get to do much green-fielding in my career. reply oooyay 15 hours agoparentprevI recently implemented SQLite for a metadata application at work. My constraints in design were pretty concise; the application will only ever need to scale vertically, my data persistence story is a matter of speed and accessibility over longevity, I have plenty of options for scaling disk IO, and my read performance is much more paramount than write performance.The outcome is that my persistence later is not adding $200&#x2F;m immediate service overhead cost and my deployment was easy to manage, which is a strong promise made to the rest of the team. I think there&#x27;s a place for SQLite, but just like any tool you need to know that your design constraints match the constraints of the tool. reply jjtheblunt 17 hours agoparentprevI think you&#x27;re skipping the replicated read only use case, which is our use case, and it&#x27;s super handy there. but i understand this is a restricted scenario where little could really go wrong, and it could be done other ways. reply sodapopcan 17 hours agoparentprevLots of smaller businesses could do fine with this if they don&#x27;t have a write-heavy workload. Like an ecomm shop, for instance. reply hinkley 15 hours agorootparentLots of small businesses invent write heavy workloads and don&#x27;t realize how many thousands of dollars they are spending a month on being nosey. reply nitwit005 14 hours agorootparentprevIf you&#x27;re a smaller e-commerce business, your whole site can probably be cached aside from auth, checkout, and order history. reply sodapopcan 12 hours agorootparentI can say with authority that this is true! We used to store our whole massive catalog in Varnish. reply endisneigh 17 hours agorootparentprevAny self respecting e-commerce site would want fault tolerance and strong consistency even with potential network partitions, so definitely not SQLite as described in article reply sodapopcan 17 hours agorootparentThey aren&#x27;t necessarily going to have all this. Lots of smaller ecom shops can run on a single server per region. If you&#x27;re a North American company selling a few hundred t-shirts per day in NA and EU, it could probably be fine, no? I&#x27;ll admit I&#x27;m not speaking from experience. Rather, I have experience in everything I just said only I was using pg, not sqlite. But I&#x27;ve been very interested in sqlite recently. reply endisneigh 16 hours agorootparentIt’s not about the size. Issues result in lost sales which means lost revenue. You would want fault tolerance regardless of how big you are. reply bootsmann 16 hours agorootparentThere is a cost to fault tolerance as well, if you lose $100 per month due to fault tolerance thats worth about 30 developer minutes. Do you really get good fault tolerance for 30m of monthly work? reply erulabs 15 hours agorootparentYou do with RDS and&#x2F;or other hosted database services, hence their popularity. reply sodapopcan 15 hours agorootparentprevThat&#x27;s something for me to look into. Like what would it would look like in each? I&#x27;ve never been the dba-type in past jobs. I&#x27;m relatively well-versed in SQL but not administration. reply emodendroket 17 hours agorootparentprevWhy even build your own e-commerce Web site at all in that case? It’s undifferentiated work. reply bcrosby95 16 hours agorootparentI don&#x27;t know about nowadays.8 years ago we built our own ecommerce site + warehouse app (inventory tracking, fulfillment, receiving) for a few hundred orders per day. The goal was to be able to better see profit margins by product, track where the money was going&#x2F;coming from in detail, along with cleaning up the inventory management part of the operation.The warehouse people loved the change because it really streamlined the fulfillment process and it basically reduced their errors to zero. Owners loved it because of the all the cost&#x2F;price tracking. It took about 6 months of work by 2 devs.Before this they were on woocommerce. It was slow as shit. We looked at shopify but the integrations with 3rd party warehouse stuff was bad. The other solutions we looked at were overly complicated swiss army knives. reply sodapopcan 16 hours agorootparentThis is very close to my experience as well. Unfortunately, it was in reverse for me :( We had a custom solution and people were happy. A new tech lead came in and didn&#x27;t like that the custom solution was PHP that still had some legacy spaghetti in it, so we switched to an off the shelf solution. It was very painful. People were unhappy. reply pmarreck 8 hours agorootparent> that still had some legacy spaghetti in itI&#x27;m going to take a wild ass guess here that you are wildly understating the \"bit of legacy spaghetti\" reply evantbyrne 16 hours agorootparentprevAs with anything, the typical business can use something off-the-shelf, but a certain percentage are doing things differently enough that custom development becomes practical. I had to custom build the billing system for Beaker Studio to properly meter customers. Even Stripe&#x27;s metering API wasn&#x27;t flexible enough to handle per-hour metering. reply emodendroket 16 hours agorootparentI find it hard to imagine a reason a shop selling 100 tee shirts in a day would need any custom functionality since this is basically the exact use case all these OOB e-commerce tools are built for. reply sodapopcan 16 hours agorootparentI&#x27;ve worked for such a place. Off-the-shelf solutions are trying to be everything to everyone and you can end up customizing the crap out of them to the point where it can become more onerous than just building your own. The place I worked was also print-on-demand service and had hundreds of thousands of SKUs as well as allowed customers to make custom products and we also hosted some peoples&#x27; shops. Shoehorning that into a custom solution was painful.I work at a very similar place now that uses Shopify. Managing that many SKUs on Shopify is crazy painful.The thing is is that custom ecom solutions really aren&#x27;t that hard. The off-the-shelf ones are complex because, as stated above, they are trying to be everything to everybody. reply MyneOutside 15 hours agorootparentprevIn our B2B space there are tons of custom business rules. For example, you place orders per manufacturer and each manufacturer has its own minimum and reorder amounts and reqs on an order, promotions, business rules, etc. This is for business that have been around 25-30 years.We did an evaluation on several out of the box ecommerce solutions and none of them were able to meet the requirements that absolutely had to be there. Shopify flat out said no, they can&#x27;t help us, etc. reply sarchertech 15 hours agorootparentprevOne of the first commercial projects I worked on nearly 20 years ago was a tshirt shop. And the precious company I worked for was a comparatively huge logistics startup.I’m fairly confident I could spend a month or so writing a custom solution for a shop selling and shipping a few hundred tshirts a day that would save them enough money to break even on the software in a few years (compared to off the shelf solutions).If I was starting my own tshirt company, I’d definitely do it. reply evantbyrne 16 hours agorootparentprevYeah, you&#x27;re probably right about that. Main thing that would likely be custom would be the design. reply parineum 16 hours agorootparentprev> the typical business can use something off-the-shelfI think we generally have this problem. It&#x27;s not the typical business that can use that stuff, it&#x27;s the average business. Unfortunately no business is the average business. reply geysersam 5 hours agorootparentprevWhy would they need strong consistency? What&#x27;s shown on the page the user sees is never strongly consistent with the db anyway. reply pmarreck 9 hours agorootparentprevhttps:&#x2F;&#x2F;rqlite.io&#x2F; at least looks like an interesting option, here reply lib-dev 17 hours agorootparentprevYeah it seems to make a lot of sense in ecomm. Product search and filtering on tables in the 1000s rather than the millions. reply laurencerowe 16 hours agoparentprev> The problem with existing SQL dbs isn’t really the architecture - its the awful queries that do in memory sorting or make temporary tables for no reason or read-after-write, etc, not network latency. SQLite won’t fix your current production problems.In my experience SQL databases are pretty poor at executing the kinds of deeply nested joins needed to return all of the data needed to render more complex UIs. It almost always ends up being faster to simply make nested selects in batches. So latency ends up mattering in these cases.You can work around this by denormalizing the data, but this often explodes your data size. reply ngrilly 15 hours agorootparentWhich is exactly where SQLite shines, but I guess that was your point: https:&#x2F;&#x2F;www.sqlite.org&#x2F;np1queryprob.html reply WuxiFingerHold 15 hours agoparentprevI can&#x27;t imagine many suitable production use cases too. Alternatives like Planetscale, Supabase or Neon are even easier to use and at the same time much more powerful. If latencies around 50 ms are too much for the specific use case, SQLite with Litestream could be a great solution. Otherwise I&#x27;d go with managed Postgres&#x2F;MySQL solutions. reply Xeoncross 17 hours agoparentprevReplace SQLite with Excel and read it again. reply eek2121 14 hours agoparentprevThe first iteration of my website used sqlite. I only switched away because the growing audience made me nervous. reply Varriount 17 hours agoparentprev> It&#x27;s the awful queries that do in memory sorting or make temporary tables for no reason or read-after-write, etc.Are there any viable alternatives though? I often wonder what an SQL-like language built from the ground up would look like. reply erulabs 15 hours agorootparentThe alternative is to write good queries! Alternatively, a better query planner that has a more liberal approach to \"I know what you want, not what you&#x27;re asking for\". A great article on this re: Planetscale&#x27;s approach is at https:&#x2F;&#x2F;vitess.io&#x2F;blog&#x2F;2021-11-02-why-write-new-planner&#x2F; reply teaearlgraycold 16 hours agoparentprevIf you want a read only database that’s too large to simply be a JSON file hosted on a CDN it makes sense. That’s kind of niche but not unheard of. reply maxmcd 18 hours agoprevBeen feeling a little miffed about this recently. Litestream is excellent but if you have multiple writers your db gets corrupted. Quite easy to do with rolling deploys.LifeFS was announced and is intended to help this. Now seems like (https:&#x2F;&#x2F;fly.io&#x2F;docs&#x2F;litefs&#x2F;getting-started-fly&#x2F;) it requires an HTTP proxy so that the application can guess about sqlite write&#x2F;read usage by reading the HTTP request method. This seems... to introduce a different (maybe better?) set of gotchas to navigate.There are now SQLite cloud offerings but you pay the network overhead and avoiding that was so much of the appeal of using SQLite.Are people successfully using SQLite in a work or production setting with a replication and consistency strategy that they like? I&#x27;ve had trouble getting a setup to the point where I can recommend it for use at my jarb. reply bob1029 17 hours agoparent> if you have multiple writersOur strategy is to not attempt replication at the level of SQLite. We use a single binary for our SaaS product which shares 1 SQLiteConnection instance for the lifetime of the whole ordeal. Remember - every single SQLite connection instance is a file system abstraction, not some in-memory&#x2F;networking clever optimized thing that Postgres or SQL Server is managing on your behalf. Every time you open a new connection to SQLite you are doing some pretty heavy-duty OS calls, relative to just reusing a prior connection. SQLite itself is typically built with serialization on by default, which deals with multiple threads on one connection. In my experience, this is the most stable & performant arrangement (with WAL, et. al. also enabled).Our backup solution is to snapshot the entire VM (or block storage device) that SQLite is running on. Replication is not a concern because our restore strategy is to just bring back a snapshot if required. Our customers are ultimately responsible for this and typically handle it with a few clicks through AWS, Azure or a quick email to their private cloud provider. RPO and RTO is entirely in their court and all parties prefer it this way - them being highly-regulated banks and us being a small startup operating at the edge of the abyss.To this day, we have not once had to support recovery of a SQLite database from snapshot due to corruption or other weirdness. We&#x27;ve been at it for half a decade now. reply benbjohnson 16 hours agoparentprevAuthor here. The single-node restriction for Litestream was one of the main reasons we started LiteFS. There isn&#x27;t a way to handle streaming backup from multiple nodes with Litestream & S3 as SQLite is a single-writer system and there aren&#x27;t any coordination primitives available with S3.I agree that many of the SQLite cloud offerings introduce the same network overhead. With LiteFS, the goal is to have the data on the application node so you can avoid the network latency for most requests. Writes still need to go to the primary so that&#x27;s unavoidable but read requests can be served directly from the replica. The LiteFS HTTP proxy was introduced as an easy way to have LiteFS manage consistency transparently so you can get read-your-writes consistency on replicas and strict serializability on the primary. That level of consistency works for a lot of applications but if you need stronger guarantees then there&#x27;s usually trade-offs to be made. reply capableweb 18 hours agoparentprevI&#x27;ve had success in a production capacity with using rqlite before. There are also a bunch of other alternatives that still seem to be actively maintained, although I&#x27;ve only used rqlite myself before:- https:&#x2F;&#x2F;github.com&#x2F;canonical&#x2F;dqlite- https:&#x2F;&#x2F;github.com&#x2F;rqlite&#x2F;rqlite- https:&#x2F;&#x2F;github.com&#x2F;Expensify&#x2F;Bedrock reply liveoneggs 18 hours agoparentprevDo you use https:&#x2F;&#x2F;www.sqlite.org&#x2F;cgi&#x2F;src&#x2F;doc&#x2F;begin-concurrent&#x2F;doc&#x2F;begi... ? reply morelisp 18 hours agoparentprev> Litestream is excellent but if you have multiple writers your db gets corrupted.Isn&#x27;t this not only well-documented, but (restricting to a single writer to avoid distributed systems issues while still making it easy to move that single writer around) sort of the whole point? reply jmull 17 hours agoprevI’m bullish on SQLite, and this is mostly a great article, but this kind of stuff is flat-out misleading:> When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds.As if postgres and others don’t have a way to run application logic at the database. I like the SQLite way of doing it — you pretty much freely choose your own host language — anything with a decent SQLite client will work. While in postgres, for example, you’ll probably end up with pgplsql (there are others, but there are constraints). So this isn’t about latency, as the whole section of the article suggests.There’s actually a relative weakness in SQLite here, since it doesn’t include a built-in protocol to support running application logic separate from the database. That’s also architecturally useful, and so you may have to find&#x2F;build a solution for this.Just adding replicas isn’t a general solution either, because each replica has an inherent cost: changes have to somehow get to every replica.E.g., systems can grow to have a lot of database clients. In traditional setups you begin to struggle with the number of connections. You might think with SQLite, “hey, no connections, to problems!” but now, instead of 1000 connections you’ve got 1000 replicas. That’s something you’re going to have to deal with… that’s 1000x write load, 1000x write bandwidth.Perhaps fly.io has a solution for this, but I suspect it’s going to cost you. reply JohnBooty 16 hours agoparentnext [–]As if postgres and others don’t have a way to run application logic at the database.I mean...This is probably the least popular possible thing you can possibly suggest as an engineer in 2023.Me? I actually think pushing app logic to the DB is a solid, underrated, and possibly even optimal solution for a lot of scenarios.But don&#x27;t tell anybody I said that. I might get beaten up.That&#x27;s probably why fly.io sort of glosses over it as a possibility. Almost nobody is even considering it as an option in 2023. reply vsareto 15 hours agorootparent>Me? I actually think pushing app logic to the DB is a solid, underrated, and possibly even optimal solution for a lot of scenarios.The languages for writing it are not as comfy as traditional programming languages, which affects how expressive and maintainable your code will be. The tools for debugging a regular language might also be better than debugging application logic in SQL. Having done some of this in T-SQL, it&#x27;s very tedious day-to-day compared to writing C#. reply JohnBooty 10 hours agorootparentFirst, to be clear - I&#x27;m not talking about moving the whole application layer to the DB. Sometimes, I think moving some of it can be a viable option.I did a fair bit of T-SQL back in the day. You&#x27;re right: it&#x27;s not fun.It&#x27;s okay for shuffling data around and doing SQL-y things in a slightly procedural way. Inserting rows, copying rows. For anything complex... well, it&#x27;s not made for that.But even SQL Server lets you call .NET CLR code now: https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;sql&#x2F;relational-databases&#x2F;s...And of course Postgres supports Python, etc etc etc. reply totallywrong 11 hours agorootparentprevI&#x27;ve never done it so I won&#x27;t comment, but Postgres supports Perl, Tcl, and Python besides SQL. reply pmarreck 8 hours agorootparentIf you peek outside the box, Postgres supports a lot more than those, now:https:&#x2F;&#x2F;wiki.postgresql.org&#x2F;wiki&#x2F;PL_Matrix reply marcosdumay 15 hours agorootparentprev> Having done some of this in T-SQLDon&#x27;t expect your experience with any other DBMS to give you an idea about how nice it is to program in Postgres.It&#x27;s still not as nice as creating some independent code. But Postgres is quite nice to program in. reply dangets 13 hours agorootparentGenuinely curious what your experiences of postgres programming you are fond of. Are you talking about functions & procedures in pgsql or are you using an extension to enable a different language?Do you have any interesting blog links? reply Micoloth 16 hours agorootparentprevHonest question.. Why?I’m always thinking that a db that can also run business logic would be the ultimate backend solution for crud apps.I know there are several options to do it, but I always assumed Postgres did not support it.What do people have against it? reply JohnBooty 14 hours agorootparentAfter several decades in the business, I have learned not to underestimate the massive power of trendiness.A lot of the argument against it is: SQL is stodgy and uncool, and I want to use Cool Language XYZ. And honestly, I don&#x27;t entirely blame people for that. If you want to work in this industry you need to do things the \"cool\" way or you&#x27;ll never even be considered for roles. Gotta keep that resume looking good.People also don&#x27;t appreciate how performant it can be. Depending on what you&#x27;re doing it can be orders of magnitude more performant to do things in-database versus shuffling things back and forth. (It can also be less performant...)There are definitely cons to that approach.One is scalability. It&#x27;s easier to scale your app layer horizontally than it is to scale your database server vertically. This isn&#x27;t necessarily an issue: a modern beefy server CPU with 64-128 cores and a TB or two of RAM is more than 99.9% of companies need, is really not that expensive, and is probably a lot cheaper than more complicated setups and extra devops headcount. But that&#x27;s not cool either.Two is the language&#x2F;skills mismatch. You&#x27;ve got an app layer in one language, a frontend in another, and now potentially a data storage layer written in a third. This is a valid concern, but also nobody seems to use it as an argument against Javascript frontends, so apparently sometimes it&#x27;s cool and sometimes it isn&#x27;t.Debugging stored procedures sort of sucks. That&#x27;s fair. (But also, nobody is saying to rewrite your entire app, or even most of it, in the DB layer)Common migration tools often don&#x27;t really have explicit support for stored procs and things like that, but AFAIK they do let you run arbitrary SQL DDL stuff, so I don&#x27;t think this is a hard barrier. reply simonw 15 hours agorootparentprevI think the main thing is that most people still aren&#x27;t working with a good migrations system to manage changes to their schema... which means logic held in database triggers and stored procedures quickly becomes a non-version-controlled not-properly-tested mess.Good migration systems exist, and people should use them!I held off on doing interesting things with triggers for more than a decade. In the past year I&#x27;ve started leaning into them much more heavily (actually using them in SQLite) because I have confidence that I can both write good tests for them and have good migrations automation in place for version-controlling my schema. reply marcosdumay 14 hours agorootparentprevPostgres has plugins for running the entire backend.People don&#x27;t like it for a lot of reasons. Making privilege escalation harder is a big one, but also, all the CPU (and memory) load on serializing that data is CPU that could be used managing the distributed processes problems that only the DBMS can solve.Personally, I think access management on those tools needs to improve a lot before they get usable. But also, the data-oriented languages have some issues, and the non data-oriented ones don&#x27;t gain much by running inside the database.IMO, we are missing a really good data-oriented language. But I don&#x27;t see any gain from running it inside the database. reply candiddevmike 16 hours agorootparentprevFew reasons:- Enforce application logic with constraints so you don&#x27;t have to duplicate it- Use triggers and get access to things like old and new without having to create a bunch of transactions- If you have multiple apps sharing a DB, you either keep your business logic consistent across them vs just doing it in the database- You can version your business logic with your schema reply xboxnolifes 15 hours agorootparentprevThe tooling around maintaining logic-in-db is worse than the tooling for logic-out-of-db. reply __jem 15 hours agorootparentprevFriction with modern devops practices is a big one. reply sodapopcan 14 hours agorootparentprevI run a bunch of business logic in the database but have no interest in writing my whole application as triggers or whathaveyou. It&#x27;s a bit of a middle ground, perhaps? reply JohnBooty 13 hours agorootparentHow did you decide which bits of business logic would live in the database as opposed to at the application layer(s)? no interest in writing my whole application as triggers or whathaveyou. It&#x27;s a bit of a middle ground, perhaps?Yeah, I think our position is often misunderstood as \"put everything in the database layer.\"That is definitely not how I think. I just think moving stuff to the database layer is one possible tool in the toolshed.One thing I like to use it for is when it&#x27;s a \"low level\" database concern, like generating an audit trail whenever a particular table is changed. To me, populating that audit trail is clearly a database concern and not an application concern. (And if there are heavy writes to that table, the performance difference may be large) reply sodapopcan 12 hours agorootparentAll aggregating and all math I do in the db. Stuff like taxes, royalties, any reporting stuff (that should probably be in a column store). It may seem like a no-brainer to do that but you&#x27;d be surprised. I worked at a fintech briefly and ALL the math was done in Elixir which surprised me. I also usually like to do permissions in SQL, ie, selecting a record based on a permission as opposed to grabbing the record then checking (I go back and forth on this). I do like to have everything that is going on represented in the application code, though, so I&#x27;ve never actually written a trigger in my life... I did write a stored procedure once for generating unique product codes... I never said I was a particularly good engineer, lol. But ya, even in the case of a cascading delete or something I still like to spell that out in application code so there are no surprises. Of course, I&#x27;ve never gotten to work on a team where everyone felt this way.Audit trails seems like an interesting case I have thought about before (I have been a part of building audit trails at the app level before). It&#x27;s something I&#x27;ve been curious about but never looked into. I think it depends on how detailed they have to be. Like, just creating a history of every table seems a little wasteful to me, but you&#x27;re probably talking more nuanced than that. I did talk to someone who worked somewhere where that was the strategy. reply JohnBooty 10 hours agorootparentI feel like audit trails are under-discussed and under-rated.Great for debugging (obviously, not as the sole debugging information, hopefully) and indispensible for covering your ass at times. If people screw up and put bad data in they frequently will blame the app and as a developer the burden of truth is often on you. Especially if the app has had bugs in the past... and what app hasn&#x27;t? Like, just creating a history of every table seems a little wasteful to me, but you&#x27;re probably talking more nuanced than thatYeah, doing it indiscriminately is wasteful to the extreme, no arguments! You would want to be judicious about the tables for which you employ it, the size of the data, frequency of updates, etc. In almost all cases you will surely want some kind of automated pruning ability. (Of course, this all applies at the app level as well, no difference here)What&#x27;s unique about triggers is that they have access to the \"old\" and \"new\" versions of a row. Implementation varies but generally it&#x27;s something like this Postgres example - note the special `OLD` and `NEW` tables. CREATE TRIGGER check_update BEFORE UPDATE ON accounts FOR EACH ROW WHEN (OLD.balance IS DISTINCT FROM NEW.balance) EXECUTE FUNCTION check_account_update();Now, that specific is obviously \"application\" or \"business\" logic and it can be debatable if that should go into the database. But audit trails are more of a pure data layer concern IMO. reply JohnBooty 10 hours agorootparentprevBTW, thank you for your reply and examples. reply jmull 12 hours agorootparentprev> How did you decide which bits of business logic would live in the database as opposed to at the application layer(s)?Not the previous poster but...I would think of it as an application layer that is running at the database.It would make the most sense for logic that is closely coupled to data access... exactly what that is depends on your app. Low-level access control policies... maybe you need to dig data out of a bunch of tables and turn it in to a hierarchy based on complicated user prefs also stored in the database... Or the opposite where you have complex data coming in that needs to be written to a bunch of tables, especially when there&#x27;s back and forth.I don&#x27;t think very many should try to put their whole app in there. Database compute tends to get expensive and complicated to scale, so stuffing things in there just because you can might run in to trouble. Not to mention (except for SQLite) the runtime environment is seriously constrained in all kinds of ways.The previous post mentions triggers but I don&#x27;t know what those have to do with this. The chance that triggers are right solution to any given problem is approximately 0% in my experience. reply sodapopcan 12 hours agorootparentI think this is essentially what I meant? In any event, I responded a little clearer but ya, shaping data and moving it around is a big thing I feel should be done in the DB. Having spent time in the rails world for several years, I worked with a lot of people who didn&#x27;t want to do ANYTHING at the DB level. Like, obviously they&#x27;d do joins and things ActiveRecord could do easily, but they&#x27;d be fine pulling in a bunch of rows and reducing them in Ruby. That drove me nuts. I&#x27;m not an optimization junky at all but I do not like that in the slightest. Not only is it wasteful and slower, in my experience it&#x27;s also more error prone. reply JohnBooty 10 hours agorootparentnext [–]pulling in a bunch of rows and reducing them in Ruby [...] Not only is it wasteful and slower, in my experience it&#x27;s also more error prone.Yeah. A lot of problems happen for one of two reasons. The application developers don&#x27;t wrap the whole thing in a transaction, and open themselves up to consistency problems. Or they do wrap a bunch of database round trips up in a transaction and open themselves up to contention issues, deadlocks, etc.In both cases, those problems generally never show up in local or test environments. Only in prod... under load. replypmarreck 8 hours agorootparentprevI completely avoided the need for maintaining an additional dependency (ElasticSearch) simply by taking advantage of fulltext search in Postgres. This did involve some writing of triggers and stored procedure code (which was generated by server-side code, but anyway), which is technically application logic.There are no perfect solutions in engineering, only tradeoffs. reply sodapopcan 17 hours agoparentprev> As if postgres and others don’t have a way to run application logic at the database.I think it&#x27;s reasonably fair of them not to specify this. The target audience of this article is people who are writing their applications in languages like Elixir, JS, Ruby, Python, and are not going to be interested in pushing all of their business logic to the db. reply TylerE 17 hours agoparentprevThat whole series of blog posts is an ad for fly.io. reply andrewstuart 17 hours agoprevI can’t see any valid reason not to use Postgres at the back end, unless you are in some sort of environment such as embedded or cloudflare workers that requires it. Or if you need a graph database there are better choices than Postgres.Postgres is good on multi core, incredibly feature rich, multi user, supported by everything, lightweight and has all the tools for production workload and management. All stuff that is important.Most important difference to me being SQLite I understand lacks flexibility in modifying table structures. reply kentonv 17 hours agoparentPostgres is great at what it does, but it is extremely inefficient for storing a small amount of data, e.g. kilobytes or a few megabytes. sqlite, on the other hand, scales nicely all the way down to a few kb.This matters for cloud in that it means with Postgres you cannot take a \"lots of small databases\" strategy, e.g. database per user or database per document. You pretty much have to group a lot of data into one big database.Many apps want to do that anyway! For them, Postgres makes sense. But in the growing world of global deployments and edge compute, the lots-of-small-databases approach is getting popular because it means you can store than data out on hundreds or thousands of edge locations, rather than a single central location. And many (not all) applications actually fit pretty well into a database-per-user or database-per-document model. Centralizing their storage only hurts performance for no benefit.As a bonus, if you are able to run sqlite compiled directly into your app, not making any kind of network connection, it can be much faster than Postgres, especially in \"N+1 select\" situations (which are well-known to be a problem with most SQL databases, but are not a problem when using local sqlite). Postgres does not support running as a library like this. reply fauigerzigerk 16 hours agorootparent>This matters for cloud in that it means with Postgres you cannot take a \"lots of small databases\" strategy, e.g. database per user or database per document. You pretty much have to group a lot of data into one big database.You&#x27;re right, it&#x27;s a very interesting strategy. Unfortunately, last time I looked Cloudflare&#x27;s D1 didn&#x27;t support this approach as there was no API to create a database at runtime from Worker code. Has that changed? reply candiddevmike 16 hours agorootparentprevNow your app is stateful, you need storage for it, a backup strategy, a free space monitoring strategy, a way to have the storage follow the app, etc. Depending on your situation, that could be harder than just getting a Postgres database. reply ngrilly 15 hours agorootparentI used to be in the stateless camp. But I think we pushed that argument too far. Stateless apps are not very useful. Most useful apps are stateful. What we are doing with promoting stateless services is just delegating the necessary stateful complexity to someone else, sweeping it under the carpet. By doing that, we are losing so many opportunities to do smarter and better things where the complexity really lies, which is where the state is. That’s why I really appreciate SQLite and other approaches like using KV embedded databases like RocksDB making a come back. That’s the job of the infrastructure providers, AWS, GCP, DO, and others, to provide the tools solving the problems you mentioned: block storage that is synchronously replicated across data centers (GCP does this), snapshots and backups on block storage, possibility to quickly reattach the block storage to a new computing node if the previous one died, etc. reply kentonv 15 hours agorootparentprevEdge compute platforms aim to take care of all that for you. reply bambax 17 hours agoparentprev> I can’t see any valid reason not to use Postgres at the back endFrom TFA:> if you don’t need the Postgres features, they’re a liability. For example, even if you don’t use multiple user accounts, you’ll still need to configure and debug host-based authentication. You have to firewall off your Postgres server. And more features mean more documentation, which makes it difficult to understand the software you’re running. The documentation for Postgres 14 is nearly 3,000 pages. reply voganmother42 16 hours agorootparentthem citing the (excellent) Postgres documentation page count is hilarious. There is a really useful comparison to be made re: features &#x2F; scope -- but approximating that and punishing a project for how comprehensive their docs are...feels like lines of code as a productivity measure but like 10x less accurate or useful lol reply benbjohnson 16 hours agorootparentAuthor here. My goal in the comparison was only in terms of scope, not that Postgres folks should be penalized for having good documentation. I think Postgres is great and it makes sense to use it when it&#x27;s called for. But I think it can be overkill for many projects. reply voganmother42 15 hours agorootparentMakes sense and I enjoyed the article.Estimating the complexity of using a project can be really...complex. I think about systems I have used which make it easy to use a minimal set of features and where I don&#x27;t have to reason about or be negatively impacted by aspects I do not benefit from, and other systems where things are less easily isolated and more challenging to reason about.I do think the Postgres docs in particular seek to be a reference in addition to an operating manual and I for one really enjoy them. I think the point is well made that Postgres can be too much (or too much right now) for many projects. reply andrewstuart 17 hours agorootparentprev>> you’ll still need to configure and debug host-based authentication.False>> you have to firewall off your serverWell yes. Are you saying SQLite servers don’t need a firewall?>> more features&#x2F;more documentation&#x2F;hard to understand your softwareFeatures lead to powerful software, documentation leads to understanding. reply bambax 16 hours agorootparent> Are you saying SQLite servers don’t need a firewallI&#x27;m not the author. But I can tell you there are no \"SQLite servers\". That&#x27;s kind of the whole point. reply sumtechguy 16 hours agoparentprevSQLite fills a need in the market that postgres does not. Local single process data storage and retrieval from that with some structure. Postgres and all of the DB&#x27;s like it kick in when you want more than one process involved. MS used to have Access that filled this need very nicely. Once you go multi user&#x2F;process you probably do not want sqlite you will want something that can do ACID on a multi user level. Once you go more than one process to store data you can make your installation a larger burden than you really need to deal with. On the other hand I can think of maybe one or two projects where sqllite fit very nicely for a data store. Most of the other cases I had involved a &#x27;real&#x27; db.For this case I guess they could try to bend sqlite to do this but the pain in doing so will probably not be worth the long term trouble than just using mysql or postgres or something like those. reply bajsejohannes 15 hours agoparentprev> I can’t see any valid reason not to use Postgres at the back endI&#x27;m using sqlite in production for a backend service. There are plenty of downsides, but to focus on the positives:- I can run all tests in a database in memory. It&#x27;s incredibly fast to \"spin up\" and I can use a separate database per test- Related, I find that I write more tests against the database instead of mocking a database, which cuts down on time writing tests.- I don&#x27;t need to start a database to run the backend- I can have snapshots of the databases in a single files for various scenariosAll in all, the development process feels a lot faster. When something takes a millisecond instead of seconds, you do things differently. reply dimgl 17 hours agoparentprev> any valid reasonWell, cost, right? Cost is a reason why someone may not want to use a traditional RDBMS. AWS RDS and GCP Cloud SQL aren&#x27;t exactly the cheapest solutions out there. reply andrewstuart 17 hours agorootparentPostgres is free. Put it on a computer. Cost is certainly not an argument against Postgres cause it can run on any back end that runs Linux. reply zaphar 17 hours agorootparentOut of not cheaper to run a postgres server than an embedded sqlite DB. There is more to the cost than just the software license. reply arcatech 14 hours agorootparentprevWho pays for the computer and bandwidth? reply srcreigh 15 hours agoparentprevPostgres doesn’t support b-trees for primary storage, so data can’t be automatically clustered, which reduces efficiency for joins by 50x. MySQL and SQLite don’t have this issue. reply adzm 15 hours agorootparentthis fact still blows me away reply benbjohnson 18 hours agoprevAuthor here. Cool to see the post make it up on HN again. I&#x27;m still as excited as ever about the SQLite space. So much great work going on from rqlite, cr-sqlite, & Turso, and we&#x27;re still plugging away on LiteFS. I&#x27;m happy to answer any questions about the post. reply otoolep 16 hours agoparentThanks Ben!rqlite[1] creator, happy to answer questions too.[1] https:&#x2F;&#x2F;www.rqlite.io reply rubenv 17 hours agoparentprevWhat&#x27;s the status on litestream? Does that have a future as well or is it LiteFS all the way? reply benbjohnson 16 hours agorootparentLitestream definitely has a future. Our goal is to keep it as a simple single-node disaster recovery tool though so it won&#x27;t see as much feature development as something like LiteFS. We&#x27;ve been focused a lot on LiteFS & LiteFS Cloud to get them in a good place but I&#x27;m looking forward to going back and updating Litestream more regularly. reply rubenv 5 hours agorootparentNot much feature development is perfectly fine if it works! Things don&#x27;t have to evolve.Planning to use litestream as a library to dynamically swap in&#x2F;out dozens of databases in a process. Looking at the code it&#x27;ll easily allow that (super clean, kudos!).So many thanks, it&#x27;s going to enable a lot of new things! reply jjtheblunt 18 hours agoparentprevIs there a recommendable way to feign a graph database within SQLite? (because read only replication would be fantastic on fly.io for us.) reply benbjohnson 16 hours agorootparentSQLite has very little per-query overhead (as opposed to a database connection over a network) so I would think you could traverse a graph using multiple small queries rather than using a graph query language. reply jjtheblunt 15 hours agorootparentyep that&#x27;s what i am doing reply blagie 18 hours agoprevI don&#x27;t need to be sold on the virtues of applications running on systems like SQLite. The nineties had a lot of servers which were very simple (and performant) compared to LAMP, and I like systems like that.What I would like is a good primer about the layers on top of SQLite. What does Litestream do for me? How does it compare to competitors? Why not just use SQLite directly? A more in-depth technical discussion would be nice. I&#x27;d also like to understand wrappers and ORMs for migration to other systems, should SQLite stop scaling. reply fiedzia 17 hours agoparent> Why not just use SQLite directly?SQLite does not provide replication, so there is no way to use it directly (other than copy whole file). If you mean it as \"Why not use it as a database\" than sure, you can use it directly, though the article states reasons for not doing so (resiliency and concurrency). Postgres is a lot better in those areas, and so is the tooling.>I&#x27;d also like to understand wrappers and ORMs for migration to other systems, should SQLite stop scaling1. It heavily depends on the orms. For example Django provides good abstraction layer and many things works with any database with no change needed, but many other don&#x27;t bother about that. However just because a query runs, doesn&#x27;t mean it will return the same results. Any non-trivial app will rely on numerous accidental details and you can&#x27;t switch db and expect everything will be fine. SQL is not really portable even in the parts it does cover, and there are many it doesn&#x27;t. reply blagie 15 hours agorootparentI&#x27;ve definitely build portable systems in Django, back in the day. The trick was to have decent test coverage and run over both (at the time) MySQL and SQLite.(And yes, I should have used postgres).I&#x27;ll mention: The internet, in the nineties, was powered by 486-grade computers, and things were perfectly performant to a pretty decent scale. If you can get rid of issues like network latency (from e.g. a database on a different machine than your main computer), and similar 2020-era bottlenecks, a lot of web apps can serve millions of users from a single machine. That&#x27;s doubly true with gigabytes of RAM and modern SSDs.With RAID and regular backups, it can even be pretty robust.It&#x27;s even easier to do now that you can write static client apps that just need to push and pull little bits of data to and from the server.That&#x27;s not an architecture that&#x27;s used often, but it keeps things very simple and can work quite well. reply matlin 18 hours agoprevIf you need multiple writers and can handle eventual correctness, you should really be using cr-sqlite[1]. It&#x27;ll allow you to have any number of workers&#x2F;clients that can write locally within the same process (so no network overhead) but still guarantee converge to the same state.[1] https:&#x2F;&#x2F;github.com&#x2F;vlcn-io&#x2F;cr-sqlite reply eternityforest 17 hours agoparentI don&#x27;t see any timestamps in the data. If two peers write to the same row, does it not use latest-wins logic? reply jeromegn 12 hours agorootparentThere’s a col_version column in a clock table used for last-write-wins. In case a tie, the “biggest” value wins. reply eternityforest 4 hours agorootparentOh nice. Looks like on closer inspection they&#x27;re using Lamport Clocks, which track causation, but if ignore time, although time is mentioned somewhere as a possibility in hybrid systems someday, if I&#x27;m understanding it?Looks like only a 2MB binary for the extension, so you could in theory just pack it with your app too.I&#x27;m particularly interested because it seems like(For very small databases) you could use SyncThing as the sync backend by just periodically dumping your data to files(And making a new one once the file got too big).I don&#x27;t know how you could ever garbage collect the old files aside from some kind of manual \"Delete everyone else&#x27;s stuff and output your own big merged log\" command, but it would be really cool to be able to make apps with P2P sync.It also seems like you could put them in an http server and use it like an RSS feed. Or even serve them via torrents. reply mediumsmart 4 hours agoprevMe too. It’s just a .db file on the server. The same as MySQL but this one is on the same server like the clients site or my site. Get it? It’s a file! How crazy is that. If you wanted to outsource the sqlite the same way you do the myposmongresdb databases with separate login, scale from zero to ipo and all the trimmings you would have to put it on another server or a service even. Then you can call it long distance and have a dedicated dbdudeuser like with a grown up database and you get networklattemacciato for free! Endless possibilities and constellations. reply endisneigh 18 hours agoprevUse Postgres. Or if you insist on this type of architecture use CouchDB. I shudder thinking about a SQLite schema migration across clients with potentially unknown versions.Seems like a disaster waiting to happen unless you have a bunch of logic centralized somewhere to keep track of last know schemas per user client database. And if you’re going to do all that, unless you desperately need low latency (in which case you could use a multi region database like cockroach), why not just centralize? reply simonw 15 hours agoparent\"unless you have a bunch of logic centralized somewhere to keep track of last know schemas per user client database\"I&#x27;ve been building exactly that here: https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;sqlite-migrate reply ak39 17 hours agoprevSQLite not supporting \"stored procedures\" is a deal-breaker for me. The idea for stored procs is not to \"put the process as close to the data\" but simply that we have a single place for language-agnostic encapsulation of data procedures. reply bob1029 17 hours agoparentSQLite supports the best version of \"stored procedures\", IMO:https:&#x2F;&#x2F;www.sqlite.org&#x2F;appfunc.html reply chungy 17 hours agoparentprevSQLite is an in-process database. If you need language-agnostic encapsulation of data procedures, SQLite is not for you. I would suggest you consider PostgreSQL. reply ketralnis 17 hours agoparentprevI don&#x27;t think I&#x27;ve ever needed language-agnostic procedures in a project where sqlite is also a fit. I like them both but at different times. I&#x27;d love to hear your use case though. Do you have microservices in different languages running on the same machine that share a db file? Or maybe a web + command line interface?Sqlite&#x27;s internals actually could support something like this: it has a bytecode engine https:&#x2F;&#x2F;www.sqlite.org&#x2F;opcode.html that&#x27;s more oriented around executing query plans and it&#x27;s missing some pieces (e.g. it has no stack, only registers) but much of the machinery is there to expand it to stored procedures reply chasil 15 hours agoparentprevThe language for triggers in SQLite appears to be a fragment of SQL&#x2F;PSM and Oracle PL&#x2F;SQL.Perhaps this will grow into a more thorough implementation. reply hahn-kev 17 hours agoparentprevBut man the maintenance and debug nightmare never seems worth it for that tradeoff. Not to mention vendor lockin reply pstuart 17 hours agoparentprevWhat language(s) would the stored procedures be, and how would that look in keeping with the ethos of the project?Their reasoning for not doing this is not unreasonable, but it certainly would be cool if such functionality existed. reply srameshc 18 hours agoprevI recently saw the launch post of Electric SQL which syncs to SQlite, I like the pattern on how keeping the data close to the frontend can solve many problems, if synced with the main DB. I hate to run another docker or manage service to manage this layer but if somehow a part of data from the database like Postgres can be synced using something simple like litestream and can be placed either on edge or client can be a solution to many of the problems. reply bradgessler 16 hours agoprevRelated: I wrote a piece last week on deploying Rails apps to production on Fly.io at https:&#x2F;&#x2F;fly.io&#x2F;ruby-dispatch&#x2F;sqlite-and-rails-in-production&#x2F;The work that’s made this possible is:1. Litestack https:&#x2F;&#x2F;github.com&#x2F;oldmoe&#x2F;litestack runs everything on Sqlite2. Fly.io’s work on the dockerfile-rails generator detecting Sqlite and Litestack in a Rails project, then setting up sane defaults for where that data is stored and persisted in production. This is all done behind the scenes with no intervention required from the person deploying.3. Servers are overall faster and more powerfulI hope more Rails hosts make it easier and safer to deploy Sqlite to production. It will lower costs and reduce complexity for folks deploying apps. reply greatNespresso 17 hours agoprevWhile different than the approach offered by Litestream, I am fairly excited by the direction of Cloudflare D1, making SQLite available at the edge without having to manage anything. Still in alpha but worth looking at if you&#x27;re looking for cheap cloud option. reply sigmonsays 13 hours agoprevI dont want this to be taken the wrong way but I read about fly.io and sqlite atleast once a week.Who is using this and why is it such a hot topic on HN? reply adamrezich 11 hours agoparentSQLite appeals to the hacker because it is simple on the surface, complex beneath the surface, easy-to-use, and does its job well. however, replacing a traditional MySQL or PostgreSQL database with it, takes a bit of work, because it&#x27;s not a drop-in replacement. so you see this push and pull between people of different strata advocating for SQLite, disparaging it in favor of PostreSQL, and some who try to engineer stuff around SQLite to make it a better fit for traditionally PostgreSQL-type situations.if you&#x27;ve never tried SQLite on your own and you&#x27;re comfortable with C, I&#x27;d recommend giving it a try, it&#x27;s pretty dang cool. reply sergioisidoro 17 hours agoprevA few years I made a decision to ship a SQLite database in an (internal) ruby on rails package. Why? Because there was a large set of (static) data that was required for the package to work, and it made no sense to make an API to query it from external sources (It wasn&#x27;t that big, something like 5-10Mb if I recall). At the time it felt like a super dirty hack, but time seems to have validated that decision :) reply meitham 17 hours agoprevI recently wrote a production system that uses SQLite as the main backend. SQLite is in memory in this case and its entire state gets rebuilt from Kafka on start. The DB receives about 2 updates a second, wrapped with rest api aiohttp and odata filters. It has been able to handle close to 9k requests&#x2F;second ands it’s a primary system in a financial institution. So yes SQLite is fully capable prod db. reply endisneigh 17 hours agoparentYou’re using SQLite and Kafka? Very ironic. reply meitham 17 hours agorootparentIn large organisations you often have no choice of the type of queue between your team and other teams. That being said there’s nothing wrong with Kafka and the ability to seek back to the earliest timestamp since midnight and being able to rebuild our state from that is a godsend feature, in comparison to other queues. This means we can make our application stateless or at least afford to lose the state and be able to build it quickly from Kafka. reply endisneigh 17 hours agorootparentKafka is just fine. I just thought it was funny that SQLite would be involved at all. reply morelisp 16 hours agorootparentprevKafka for consistency&#x2F;durability and local storage for speed&#x2F;structure is a common architecture, and a really good one any time you can tolerate async writes. reply jerrygenser 16 hours agoparentprevIf you don&#x27;t need SQL (relational data), but maybe have a schema per topic, I&#x27;ve used rocksdb as a cache for latest in tombstones topic. It has high write throughput for rebuilding state when playing forward a stream reply paulryanrogers 17 hours agoparentprevSo your source of truth is ... Kafka? reply nik736 17 hours agoprevWhy would I use SQLite over PostgreSQL for regular CRUD apps? reply simonw 14 hours agoparenthttps:&#x2F;&#x2F;www.sqlite.org&#x2F;np1queryprob.html is one of my favourite answers to that question. reply imhoguy 16 hours agoprevDid anybody try something like that: read&#x2F;write to SQLite database file on backend, but also allow the database file to be downloaded at any time by rich JS frontend for read-only querying. I just wonder if the file is going to be (eventually-) consistent and not corrupted. reply simonw 14 hours agoparentMy hunch is that if you want to do that the safe way would be to have a mechanism that creates a snapshot of the SQLite database for the client to download when they request it.One way to do that is with VACUUM INTO, e.g. how I use it in this TIL: https:&#x2F;&#x2F;til.simonwillison.net&#x2F;sqlite&#x2F;python-sqlite-memory-to...If your database is less than 100MB or so I imagine this would easily be fast enough that the performance overhead wouldn&#x27;t be worth worrying about. reply sneak 17 hours agoprev> We’re beginning to hit theoretical limits. In a vacuum, light travels about 186 miles in 1 millisecond. That’s the distance from Philadelphia to New York City and back. Add in layers of network switches, firewalls, and application protocols and the latency increases further.> The per-query latency overhead for a Postgres query within a single AWS region can be up to a millisecond. That’s not Postgres being slow—it’s you hitting the limits of how fast data can travel.No. An AWS region has a radius of less than a few dozen kilometers, more likely around 5km. Lightspeed doesn&#x27;t factor into it at those small distances. That millisecond is indeed Postgres being \"slow\" in these terms. (Most of it is the networking stack, as noted.)This basic error makes me question the validity of the document. I stopped reading here.I agree that \"networks are slow\" but this sort of false justification is not the way to sell it. Is this an attempt to make the author seem like he knows what he is doing because he knows the speed of light? reply SantaCruz11 17 hours agoparentIf he really understood what he&#x27;s talking about, he would at least say \"half the speed of lights\" because that&#x27;s the max speed a fiber cable will ever go. reply aaviator42 17 hours agoprevMy org&#x27;s apps heavily use this simple key-value interface built on sqlite: https:&#x2F;&#x2F;github.com&#x2F;aaviator42&#x2F;StorXHandles tens of thousands of requests a day very smoothly! :) reply declan_roberts 17 hours agoprevI really worry about split-brain with sqlite. These replication features just seem too immature for me.That being said I love sqlite and it should be the DEFAULT database with any application until something is demanded otherwise. reply k_vi 15 hours agoprevI&#x27;ve been using turso.tech for my current side project project and happy with it so far. iirc, their sqlite is deployed using fly.io too. reply Dwedit 13 hours agoprevIf you&#x27;re running a small message board where the whole database fits in under 32MB, SQLite makes perfect sense. reply ricardobeat 12 hours agoparentYou might be thinking of 32 bits (2GB)? Even that limit has been lifted and it can easily handle multi-GB databases. reply kijin 18 hours agoprev> When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds. That’s micro, with a μ. A 50-100x improvement over an intra-region Postgres query.Why compare the latency of a remote Postgres database with a local SQLite database? If your app is so simple and self-contained that it runs on a single EC2 instance using local files, nothing prevents you from installing Postgres on the same machine, whether inside a container or not.I have some simple apps on EC2 with MariaDB on localhost, and well-tuned queries rarely take more than 100-200 microseconds. That&#x27;s total query execution time, not just communication latency. RDS just sucks for this kind of use case. It&#x27;s not a useful comparison.> As much as I love tuning SQL queries, it’s becoming a dying art for most application developers. Even poorly tuned queries can execute in under a second for ordinary databases.Didn&#x27;t you just say that milliseconds matter? reply benbjohnson 16 hours agoparentAuthor here. The comparison was meant to be about how Postgres (or any client&#x2F;server RDBMS) is typically deployed. Yes, you can deploy Postgres on the same machine but I wouldn&#x27;t say it&#x27;s common. Maybe I could have expanded more on that point or simply referenced client&#x2F;server architecture rather than Postgres so it didn&#x27;t seem like a straw man argument. reply marcosdumay 14 hours agorootparentIf I had to guess, I&#x27;d say that single-machine (with cold backups) is the most common way to use Postgres with a web server. reply morelisp 17 hours agoparentprevBut why take on the operational overhead of a separate DB server (not to mention 200 more microseconds), plus the EC2 surcharge? I would rather run app+SQLite + dumb object storage, than app + MySQL + MySQL incremental backup and restore. reply kijin 17 hours agorootparentWhat separate DB server? I was talking about installing the RDBMS on localhost, right inside the server where your application runs. No other EC2 instance, no extra charges. Preferably connect to it over a Unix domain socket instead of TCP. That&#x27;s the only way to compare SQLite performance with an RDBMS in an apples-to-apples way.The point about operational overhead makes sense, though, and IMO it&#x27;s the only point in this unnecessarily long article that&#x27;s actually worth considering. I do have a couple of other apps running on SQLite, so I appreciate the simplicity. reply Dan42 16 hours agorootparentThank you for saying that, it save me the trouble of writing it.This apples-to-oranges comparison (strawman? motivated reasoning?) unfortunately makes me mistrust this entire article. reply morelisp 16 hours agorootparentprev> What separate DB server?It&#x27;s still normal to refer to e.g. \"database server\", \"application server\", etc. processes even when running on a single machine. Re. EC2, I&#x27;m referring to the surcharge of having a dedicated instance at all, vs. working at the container &#x2F; object storage level of abstraction. reply kijin 5 hours agorootparentSure, you can download an SQLite database from S3 and use it in your Lambda if your dataset is small enough and, more importantly, you either don&#x27;t do any writes or have access to a highly reliable solution that synchronizes writes across copies and persists them back to S3.Unfortunately, Litestream (which OP is promoting in TFA) needs to run as an independent process inside a VM and&#x2F;or container in order to sync your writes. It&#x27;s not very different from a traditional RDBMS in that regard. Even the title says \"server-side\" SQLite, not \"server-less\" SQLite. reply giantrobot 17 hours agorootparentprev> No other EC2 instance, no extra charges.Think Lambda (or equivalent) instead of EC2. reply giantrobot 17 hours agoparentprev> Why compare the latency of a remote Postgres database with a local SQLite database?The SQLite DB is just a flat file that can be packaged in a lambda or whatever cloud&#x27;s object store. It makes sense for fast access to read-heavy or read-only data. Even a shitty query can return rows in less than a millisecond where a remote DB that same amount of data is tens of milliseconds away. reply PKop 18 hours agoprev2022 reply tuukkah 18 hours agoparentLatest development on this line of work was a week ago: https:&#x2F;&#x2F;fly.io&#x2F;blog&#x2F;skip-the-api&#x2F;Discussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37497345 reply NoahKAndrews 18 hours agoparentprevThanks, I was thinking that the real-time replication features of Litestream had been dropped in favor of LiteFS. reply pmarreck 10 hours agoprev [–] How does Litestream compare to rqlite? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The piece highlights the advantages of employing SQLite as the main database for full-stack applications due to its simplicity and enhanced performance.",
      "Litestream, an open-source tool, is introduced, which strengthens SQLite's resilience and concurrency.",
      "The forthcoming update of Litestream will enable live-replication of SQLite databases, offering a globally scalable database solution especially for read-intensive applications."
    ],
    "commentSummary": [
      "The article talks about using server-side SQLite within web applications, discussing its strengths and weaknesses, and the varied responses towards its use in production environments.",
      "The discussion explores the pros and cons of running application logic in a database, using tools like triggers and stored procedures, and it gives a comparative analysis between SQLite and PostgreSQL as application backends.",
      "The limitations of SQLite in larger, distributed systems are discussed, as well as methods for replication and synchronization, the latency of data travel in computer networks and the performance variance among different database systems."
    ],
    "points": 202,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1695398561
  },
  {
    "id": 37614216,
    "title": "How to Roman Republic, Part IV: The Senate",
    "originLink": "https://acoup.blog/2023/09/22/collections-how-to-roman-republic-part-iv-the-senate/",
    "originBody": "Skip to content A Collection of Unmitigated Pedantry A look at history and popular culture Home Resources for Teachers Resources for World-Builders Book Recommendation List Guest Posts Contact About the Pedant Collections: How to Roman Republic, Part IV: The Senate Bret Devereaux Collections, How To Civic Governance September 22, 2023 24 Minutes This is the third section of the third part of our our planned five part series (I, II, IIIa, IIIb, IIIc) on the structure of the Roman Republic during the third and second centuries, the ‘Middle’ Republic.’ Over the last few posts we looked at the role of Roman magistrates who carried out a range of executive functions for the republic. This week, we’re looking at the Roman Senate, an institution so important that it is included alongside the people of Rome in the SPQR formulation that the Romans used to represent the republic, and yet also paradoxically it is an institution that lacks any kind of formal legal powers. Despite that lack of formal powers, the Senate of the Roman Republic largely directed the overall actions of the republic, coordinating its strategic policy (both military and diplomatic), setting priorities for legislation, handling Rome’s finances and assigning and directing the actions of the various magistrates. The Senate – not the Pontifex Maximus1 – was also the final authority for questions of religion. The paradox exists because the Senate’s power is almost entirely based in its auctoritas and the strong set of political norms and cultural assumptions which push Romans to defer to that auctoritas. And if you want to wield the auctoritas of the ACOUP Senate, you can support this project on Patreon at the patres et matres conscripti tier, to be able to submit questions and weigh in on what topics we should cover next (I promise the long-awaited Greek-and-Phoenician colonization treatment is coming!). As always, if you like this, please share it! If you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings, assuming there is still a Twitter by the time this post goes live. I am also on Bluesky (@bretdevereaux.bsky.social) and (less frequently) Mastodon (@bretdevereaux@historians.social). Email Address Subscribe! Membership We should start with who is in the Senate. Now what you will generally hear in survey courses is this neat summary: the Senate had 300 members (600 after Sulla) and included all Romans who had obtained the office of the quaestorship or higher and its members were selected by the censors. And for a basic summary, that actually serves pretty well, but thinking about it for a few minutes one quickly realizes that there must be quite a bit of uncertainty and complexity underneath those neat easy rules. And indeed, there is! First we can start with eligibility by holding office. We know that in the Sullan constitution, holding the quaestorship entitled one into entrance into the Senate. Lintott notes that the lex repetundarum of 123/4 lumped every office aedile-and-above together in a phrasing ‘anyone who has or shall have been in the Senate’ when setting eligibility for the juries for the repetundae courts (the aim being to exclude the magistrate class from judging itself on corruption charges), and so assumes that prior to Sulla, it was aediles and up (but not quaestors) who were entitled to be in the Senate.2 The problem immediately occurs: these higher offices don’t provide enough members to reach the frequently attested 300-Senator size of the Senate with any reasonable set of life expectancies. By contrast, if we assume that the quaestors were enrolled in the Senate, as we know them to have been post-Sulla (Cicero is a senator for sure in 73, having been quaestor in 75), we have 8 quaestors a year elected around age 30 each with roughly 30 years of life expectancy3 we get a much more reasonable 240, to which we might add some holders of senior priesthoods who didn’t go into politics and the ten sitting tribunes and perhaps a few reputable scions of important families selected by the censors to reach 300 without too much difficulty. The alternative is to assume the core membership of the Senate was aediles and up, which would provide only around 150 members, in which case the censors would have to supplement that number with important, reputable Romans. To which we may then ask: who might they choose? The obvious candidates would be…current and former quaestors and plebeian tribunes. And so we end up with a six-of-one, half-dozen of the other situation, where it is possible that quaestors were not automatically enrolled before Sulla, but were customarily chosen by the censors to ‘fill out’ the Senate. Notably, when Sulla wants to expand the Senate, he radically expands (to twenty) the number of quaestors, which in turn provides roughly enough Senators for his reported 600-person Senate. That leads us to the roll of the censors: if holding a sufficiently high office (be it the quaestorship or aedileship) entitles one to membership for life in the Senate, what on earth is the role of the censors in selecting the Senate’s membership? Here the answer is in the sources for us: we repeatedly see the formula that the meetings of the Senate were attended by two groups: the Senators themselves and “those who are permitted to state their opinion in the Senate.” Presumably the distinction here is between men designated as senators by the censors and men not yet so designated who nevertheless, by virtue of office-holding, have a right to speak in the Senate. It’s also plausible that men who were still iuniores might not yet be Senators (whose very name, after all, implies old age; Senator has at its root senex, “old man”) or perhaps men still under the potestas of a living father (who thus could hardly be one of the patres conscripti, a standard term for Senators) might be included in the latter group. In any case, the censors seem to have three rolls here. First, they confirm the membership in the Senate of individuals entitled to it by having held high office. Second, they can fill out an incomplete Senate with additional Roman aristocrats so that it reaches the appropriate size. Finally, they can remove a Senator for moral turpitude, though this is rare and it is clear that the conduct generally needed to be egregious. In this way, we get a Senate that is as our sources describe: roughly 300 members at any given time (brought to the right number every five years by the censors), consisting mostly of former office holders (with some add-ons) who have held offices at or above the quaestorship and whose membership has been approved by the censors, though office holders might enter the Senate – provisionally, as it were – immediately pending censorial confirmation at a later date. If it seems like I am giving short shrift to the ‘filling the rank’ add-ons the censors might provide, it is because – as we’ll see in a moment – Senate procedure combined with Roman cultural norms was likely to render them quite unimportant. The role of senior ex-magistrates in the Senate was to speak, the role of junior ex-magistrates (and certainly of any senator who had not held high office!) was to listen and indicate concurrence with a previously expressed opinion, as we’re going to see when we get to procedure. Meetings Meetings of the Senate were formal affairs, but unlike modern legislatures the Senate did not stay in session over long periods. Instead, it met in specific venues – they had to be inaugurated – when called by a magistrate with the power to do so. We may begin with place: the Senate had no single fixed meeting spot, though the curia in the Forum was the most common location, however the place the Senate met had to be religiously prepared via inauguration (the taking of the auspices by the augurs) and by sacrifices in order to make sure the gods approved of the proceedings and its results. Consequently, the Senate always met in a templum in the sense of a consecrated space, but also it tended to meet literally in temples, with meetings in the temples of Jupiter Optimus Maximus, the temple of Fides, the temple of Concord, and so on. Notably, two locations, the temple of Bellona and the temple of Apollo were also used and these sat outside the pomerium, enabling the Senate to meet with magistrates who, because of their active command of an army, could not cross the pomerium; they were also sometimes used to meet with foreign dignitaries the Senate did not wish to let into the city. Later added to this number of sites outside the pomerium was Pompey’s theater, which included a temple of Venus Victrix and a curia as part of the overall complex. Via Wikipedia, the interior of the curia Julia, the Senate’s primary meeting place. The curia Julia itself comes late, finished in 29 BC to replace the destroyed Curia Cornelia which in turn had replaced the older Curia Hostilia. Still, this gives us a sense of what a meeting place for the Senate might be like, rather less spacious than most movies would have it, with 300 senators it would have been quite crowded (and the curia Hostilia was no larger in terms of footprint). In order to meet, the Senate had to be called or more correctly ‘driven together’ (cogere, often translated adequately as ‘summoned,’ but as Lintott notes, it has an element of compulsion to it) by a magistrate. There were a few standard dates on which this would effectively always happen, particularly the first day of the consular year, but beyond that it was expected that magistrates in Rome could call the Senate at any time to discuss any issue on relatively short notice. There was initially no requirement that Senators live in the city of Rome, but it was clearly assumed. Early on in the second century, we get regulations requiring Senators to stay close to Rome unless they had an official reason to be elsewhere, though Senators might be permitted to leave if they needed to fulfill a vow. In the Late Republic it seems to have been common also for Senators to leave the city during the spring res prolatae, a sort of recess from public business (literally “the deferring of business”), but these informal breaks did not mean the Senate was truly ‘out of session’ and it could still be summoned by a magistrate. Via Wikipedia, two sestertii from the reign of Tiberius minted in 36/7 in Rome commemorating his restoration of the Temple of Concord, another traditional meeting place of the Senate. The large ‘SC’ on the reverse does in fact, stand for senatus consulto, because the weights and values of Roman bronze coinage was decreed by the Senate. Generally, meetings of the Senate began at dawn, though they could begin later, and they proceeded either until the business was concluded or to dusk. Because of the ritual preparations required, no meeting of the Senate could last more than a day, much like the assemblies, so if the business was not finished, a new meeting would need to be called and the process begun from scratch. While it seems that magistrates generally tried to avoid calling the Senate during festival days, dies nefandi (days unsuited for public business) and meetings of the popular assemblies, there was no requirement to do so and the Senate might be called for any day for most of the Republic, with laws restricting the Senate’s meeting days only coming midway through the first century. Beyond this, Senators were expected to show up and we hear of threats of fines or other censure for failure to show up, but it also seems like no meeting of the senate was ever very close to the full body and quorums for the Senate were fairly low, 100 or 150. For the Sullan Senate, notionally of 600 members, the highest attendances we know of, as noted by Lintott, are 415, 417 and 392. Of course some significant number of Senators will, at any time, have been active magistrates overseas, or serving as military tribunes, or as senatorial legati, but it seems clear that even beyond this attendance was not universal even if it was in theory supposed to be. Procedure Once the Senate met, it had a standard procedure which was followed. The Senate was fundamentally a deliberative body, unlike the assemblies which merely voted, and so most of the procedure focused on that deliberation and debate. And this makes sense, as the notional purpose of the Senate was as a large advisory council to the magistrates, in the same way that it had once been the advisory council to the kings. Generally, each meeting of the Senate had a set agenda item, presented by the convening magistrate, although for that traditional meeting at the start of the consular year it was common to convene the Senate de re publica infinite, “on the whole Republic.” By far the most common convening magistrate was the consul, but other magistrates could convene the Senate (notably the tribunes). The convening magistrate spoke first with an introductory speech, a relatio, with introduced the topic and often presented a proposed course of action on that topic. In some cases, that introduction might be a short one, but it could also be a long and involved speech or the introduction of an ambassador or the reading of dispatches. The Senate seems also at sometimes to have formed subcommittees and a magistrate might use an introduction to put the recommendations of a subcommittee, such as pre-drafted legislation, before the body. But it was just as common to open a debate on a broad topic. Once the convening magistrate was done introducing the issue, the opinions of each senator, in turn, were sought. The order was set by the censors, but it was based on offices held and seniority, so while the censors could shift (‘movere’) a senator down in the order, they were expected to have a good reason (typically conspicuous moral turpitude). The order began with the princeps senatus, traditionally the most senior ex-consul, though ‘most senior’ here often meant both in age and in influence, so while the princeps senatus was never young, it might not strictly be the oldest senator. After that, the former consuls (in Latin consulares, which enters English as ‘consulars’ to mean ‘men who have held the consulship’) spoke, with the most former (and thus likely oldest) going first. And then the Senate proceeded down in rank order to ex-praetors and so on all the way down. As you may well imagine, the figures who spoke first tended to set the terms of the debate and indeed the whole reason they spoke first is because they were understood to be preeminent in auctoritas. Each senator, as the order came to them was expected to present their opinion (sententia). The expression of their view could be as long or as short as they wished (filibusters were possible), but they had to answer. Senators were given broad latitude in their response, able to interrogate the magistrate or visiting ambassadors, respond to their fellows or wander entirely off of the origional relatio to another topic entirely They could also launch into long speeches which, again, might or might not actually pertain primarily to the topic at hand. Cato the Elder was famous for ending speeches on topics entirely unrelated to the matter with an exhortation that “Carthage must be destroyed,” while Cicero took the opportunity of a debate on some relatively minor matters of roads and mints to launch into his Seventh Philippic, a speech exhorting the Senate to move against Marcus Antonius. Still it was expected that at some point the response ought to speak to the matter at hand and so Cicero ends the Seventh Philippic with quibus de rebus refers, P. Servilio adsentior, “on the matters you refer [to the Senate], I agree with Publius Servilius.” Via Wikipedia, Cicero Denounces Catiline (1888), painting by Cesare Maccari. As noted, the Senate’s meeting place would not have been so spacious or rounded like this, but the painting does capture the movement of the pedarii, in this case abandoning Catiline as Cicero denounces him with the First Catilinarian. On the other hand, the minimum possible response a senator could give, and this must have been a very frequent response, was to agree with what some other senator earlier in the speaking order had said and we certainly get the sense that this was the most common thing for more junior senators to do. Indeed, we’re told that, while the more senior senators were speaking, more junior senators, termed pedarii (lit: ‘footmen’ but really ‘walkers’) by Cicero for reasons that will soon be obvious, would move in the hall to sit by the speaker with whom they agreed to show their support. Given the elimination-contest nature of the Roman office holding, the Senate must always have had far more of these junior senators than of senior consulars whose opinion would carry real weight, but their movement en masse to agree with one or another position would have carried its own auctoritas. Now, junior senators absolutely could hold forth on their own basis and we are told of occasions where they did so. Sallust presents the debate on the fate of Catiline’s conspirators in 63 as turning on the opinions of Marcus Porcius Cato (the younger) and Gaius Julius Caesar; Cato was almost certainly one of the most junior members of the Senate, being the quaestor urbanus that very year, while Caesar was more senior as a praetor-elect and Pontifex Maximus, but still hardly the most senior fellow in the room. But in practice, moments like these were probably relatively rare (Caesar and Cato both may have felt emboldened because of their current positions, though Cato especially, a powerful speaker, maintained outsized influence in the Senate despite never rising to the consulship). Roman culture strongly encouraged deference both to elders and social superiors and the senior consulars were both, while in turn the mechanics of Roman politics will have meant that junior senators would have been wise to attach themselves to powerful consulars in any event. At the end of this process of speaking, the presiding magistrate could put the issue to a vote. The magistrate in question set the terms of the vote, laying out a proposed senatus consultum (opinion of the Senate) and asking all senators who agreed to go to one side while everyone who disagreed go to the other. Multiple such motions could be voted in succession and the Senate might approve or disapprove of any set of them, but the order was up to the magistrate who might thus frame proposals tactically to achieve a given outcome. If the vote passed then the proposal – drafted into written form by the presiding magistrate, usually with the assistance of a few more junior senators – and issued as a formal decree of the Senate, called a senatus consultum. A few things could interrupt this stately order. The simplest was that senators could change their mind, based presumably on the arguments of others later in the speaking order; they seem to have been able to interrupt the order to announce that change, that they now agreed with so-and-so. Alternately, there might be calls for various kinds of floor motions, akin to points of order. The most common was consule! (‘consult!’), a call to signal that the magistrate needed to consult the senators (run through the speaking order) before proceeding to a vote on a given measure; you couldn’t just propose a vote and ram it through without debate. Alternately, senators might call out divide! (‘divide!’) to signal that certain motions being presented together needed to be split up, discussed and voted on separately. Also numera! (‘numbers!’ meaning ‘count!’) was the call to demand a quorum check. The Senate might even call for discussion to be opened on an issue, demanding a new relatio to discuss issues that had been raised – most often in the reading of dispatches or the reports of ambassadors, but sometimes from debates that broke out between senators. Consequently, while the presiding magistrate convened the Senate and in theory set the agenda, in practice the Senate was much less under their control than the voting assembly. The presiding magistrate, it must be noted, could not cut off debate, though he could simply refuse to put a motion to a vote at the end of it. In addition, just to gum up the process further, a senatus consultum could be veto’d by the consuls or the tribunes, though the opinion of the Senate was still registered, just merely as the senatus auctoritas rather than consultum, though this carried a lot less weight. A veto’d proposal could simply be brought another day, in the hope that it might escape veto subsequently and at least until the 130s, it seems to have been an accepted part of the mos maiorum that one did not maintain a veto indefinitely against either the popular will or the will of the Senate (much less both), so in the third and most of the second century, a veto was a delaying tactic rather than a decisive killing of a motion. As an aside before we move on to the Senate’s (lack of) formal powers and (abundant) traditional prerogatives, it seems worth noting how much emphasis this sort of system placed both on the speaking ability of senators and their personal auctoritas. Unlike as in many modern legislatures, the speeches here were not cosmetic and senators were not bound to a ‘party line’ in their votes. Consequently, powerful speakers or senators with formidable reputations, if they were present (and not, say, deployed in the provinces) could exert a lot of sway among the junior members of the senate who would make up the majority of votes when it came time to approve a senatus consultum. Powers and Prerogatives Now we have a senatus consultum, so we may ask what power it has and the answer is ‘none.’ But it is also ‘very much.’ And that brings us to the central paradox of the Senate. On the one hand, as I have my students chant in class, the Senate has no formal powers (in the Republic, before Sulla). It cannot legislate, it cannot adjudicate court cases, it cannot create or appoint magistrates, it cannot order armies or convene assemblies. All the Senate can do is issue opinions, which are not technically binding on anyone. This is particularly true when a senatus consultum comes into conflict with a decision of a popular assembly (a lex); at all points, the lex wins. But the advice of the Senate is almost always followed, especially in certain key areas of the Republic. Consequently while the Senate’s de iure powers basically don’t exist, its de facto powers under the mos maiorum are vast to the point that outside observers like Polybius conclude that the Senate is the most powerful part of the Roman state.4 As a result, in the period we can see most clearly from the fourth to the second century, the Senate almost always gets its way and exercises a customary control over key aspects of Roman governance, especially foreign policy, that is nearly complete. And while the Senate might not have any clearly defined legal authority to do any of this, governments are how they function and this is how the res publica functioned during the third and second centuries. Domestically, the auctoritas of the Senate was such that it was clearly hard to pass laws without obtaining the consilium (consultation, counsel) of the Senate and receiving a favorable senatus consultum. You can easily see the mix of pressures here: on the one hand, a politician pushing a law would be profoundly unwise to trample the Senate to do so, because at the end of his short one-year term he would go back to being just a senator and in any case reliant on the influence of other senators to win future high office or other honors. At the same time, Roman voters seem to have taken the consultum of the Senate pretty seriously, so if the Senate was strongly against a motion, they were likely to vote it down anyway. And that makes sense: the Senate is a body of the most successful, most prestigious, most respected Romans in a society where you are expected to the defer to the judgements of such men. The People were not always supine before the Senate by any means, but the auctoritas senatus meant a lot. That said, the Senate’s authority was unevenly spread. It seems fairly clear, especially by the fourth century, that the Senate felt it necessary to yield – if only slowly – on proposals where it faced widespread popular opposition. One may, of course, immediately contrast the Senate of the late-second and early-first century, which squanders its auctoritas trying to stop proposals of this sort. So when it came to domestic affairs, the power of the Senate was perhaps at a low ebb; it could offer its approval to laws or its disapproval, but carrying out the laws was up to the magistrates and the assemblies of the people had the final say in passing or not passing proposals. In foreign policy, the Senate was far more influential, to the point of dominance. One crucial task that is clearly regularized well before 218, when the survival of more of Livy lets us see it clearly, is the assignment of magistrates to specific jobs or provinciae. It is frankly unclear how strong the legal basis for these assignments was and in any event it doesn’t matter: what matters is that the Senate advised the magistrates and the magistrates always acted accordingly. Consequently, the Senate was the senior strategic directing organ of the Republic, coordinating strategy and indeed grand strategy over the whole of the Mediterranean through a system of provincial assignments, directives to the magistrates assigned and transfers of resources between Italy and those provinces (including province-to-province transfers) accomplished by assigned senatorial commissioners (called legati).5 What we see in Livy is a regular cycle where these assignments are decided on at the start of each consular year, along with the Senate ‘advising’ the magistrates and pro-magistrates on how many soldiers they should levy and where those troops ought to go (along with supplies, as mentioned); the Senates prerogative in this regard becomes so ironclad that it is by the career of Scipio Aemilianus treated as effectively a legal restriction, which can only be finessed by taking volunteers, but not by simply passing a law or ignoring the Senate. Connected to this was the Senate’s oversight over state finance. The finances of the res publica, you will recall, were overseen by quite junior officials, the quaestors. In practice what that seems to have really meant was that the larger financial picture was handled by the Senate, which ,set the annual tributum (Rome’s direct tax on citizens) and approved major expenditures from the treasury, the largest of which will have been to the armies, thus neatly tying up with the above paragraph. It is not hard to see why the Senate ends up running this aspect, both because it was one which required long-term vision, but also because the quaestors, as junior magistrates looking to move further up the cursus honorum, wouldn’t have have had any incentive or sufficient personal influence to defy the Senate’s auctoritas in any event. The Senate thus ‘advised’ the quaestors on what to do with Rome’s finances, and they did it. Once again, the question of if the Senate had the legal power to do this was rather beside the point: in any event the quaestors complied. Likewise, the Senate had a powerful role in foreign policy, though in the end only the comitia centuriata could make peace or declare wars. Foreign ambassadors had to report to the consuls, but the consuls role, in addition to hosting them, was primarily to introduce the ambassadors to speak to the Senate, and then it was the Senate which considered their positions. That makes a lot of sense, as the Senate is a continuing body: an agreement with a consul would only hold potentially for a year, but an agreement with the Senate has some permanence to it and it certainly seems like if the Senate suggested treaty ratification to the assembly, it passed. As noted previously, assemblies bucking the Senate on questions of war and peace was extremely rare; when it happened, concessions were made and eventually the People followed the advice of the Senate. Finally, the Senate was also the effective final authority on Roman religion. Quite a few students tend to assume this authority must rest with Rome’s most senior priest, the Pontifex Maximus, but it does not. Instead, Rome’s senior priests, like the College of Pontiffs advised the Senate on religious matters, but it was the Senate which decided. Thus it was the Senate which instituted the Ludi Apollinares (Livy 25.12), it was the Senate that directed that the worship of Cybele be brought to Italy as the Magna Mater (Livy 29.10), the Senate which ordered the suppression and later regulations (Livy 39.14 and we have the text of the senatus consultum) of the Bacchanalia. Via Wikipedia, a reproduction of the senatus consultum de Bacchanalibus, which regulated the the Bacchanalia in Italy, firmly asserting senatorial authority over it. Auctoritas Senatus All of these prerogatives are based on the Senate’s informal authority, its auctoritas, rather than any formal powers of compulsion (which it lacks). The extent of that auctoritas and the degree to which it was clearly felt by most Romans to be necessary to respect, can come as a bit of a surprise. But it is worth remembering the sort of society the Romans have and also the kind of organization the Senate is. On the one hand, Roman culture is one where deference to age and authority is expected and normalized, with the Romans being quite comfortable with open hierarchies among citizens. These sorts of cultural values were mot than just a dry sense that one needed to be polite to the elderly; the Romans felt the demands of honor and deference quite keenly.6 The Senate was in turn a collection of the 300 very highest status individuals, the men with the most auctoritas in a society that did not have many alternative structures of power or influence. Modern politicians have to compete with journalists, pundits, business moguls and media stars for influence; but to a substantial degree the nature of Roman society meant that nearly all of the most influential men in this period were in the Senate. These were the wealthiest men in Rome and also the most politically accomplished men in Rome and also the most visible and notable men in Rome. When they spoke collectively through a senatus consultum, the auctoritas of the thing was immense. At the same time, the Senate’s auctoritas also came from the accomplishments and in a sense the expertise of its members. Because it was a body of ex-magistrates, pretty much every Roman with senior leadership experience in either civil or military affairs was a member. It was at once a council of Rome’s most experienced political leaders and its most experienced generals, which also included its most experienced priests. And as the only deliberative part of the Roman political process, it provided those figures the opportunity to debate and discuss; it is thus perhaps unsurprising that it usually took quite a lot for the Roman People to come to the decision that the Senate was making a poor choice. Finally, the auctoritas of the Senate clearly rested substantially on its history, something that it seems to me the senators themselves did not fully understand. In the early third century, the Senate – in as much as we can see with our often less-than-ideal sources – both managed the closing stages of the Struggle of the Orders and the successful completion of the last two wars to dominate Italy (the Third Samnite War, 298-290 and the Pyrrhic War, 280-275) against formidable opponents. Then under the leadership of the Senate, Rome emerged victorious from a long and grueling first war against Carthage (264-241). It seems little surprise then that, when deciding how to manage the governance of their new overseas provinces (Sicily, then Corsica et Sardinia) the Romans leaned on the Senate. When the Second Punic War (218-201) came around, the Senate assumed a decisive role in strategic direction, especially after the initial setbacks. In short, the Senate’s auctoritas was also substantially rooted in the perception that its advice was generally wise, that it had been generally successful, particularly through the third century. That in turn explains substantially just how dominant the Senate is through much of the second century – its auctoritas, when we come to see it clearly – was at a high ebb. But of course that auctoritas was to a substantial degree dependent on future performance. We see pretty clearly that faith in the Senate wanes over the back half of the second century and its auctoritas with it. Setbacks in the Third Punic War (149-146) and the Numantine War (143-133) lead the assemblies to demand unconventional generals – in both cases, electing the legally-ineligable-at-the-time Scipio Aemilianus to the task, over the objections of the Senate. And the Senate’s stubborn failure to address perceived economic problems and the boiling crisis over the status of the socii also seems to have degraded its auctoritas. The great advantage of government by auctoritas rather than laws was that the Senate’s authority could flow wherever it was needed, enabling the Roman system to adapt to the shift from being one city in Italy to an Italian empire to a Mediterranean Empire smoothly. But such a government was also necessarily fragile in ways I am not sure the Romans ever quite realized, because if that auctoritas were squandered, there was no legal, compulsive authority for the Senate, which had become the central organ of Roman governance, to fall back on. Sulla’s effort to restore the power of the Senate by radically expanding it seems, here, particularly misguided, as if adding 300 more mediocrities could restore the respect of an institution after Marius and Sulla himself had gotten done killing nearly all of the men of experience, capability and consequence in the body. But all of this is getting rather too close to a narrative of the collapse of the Republic, which is a formidable topic in its own right. Next time, we’ll close out the main trunk of this series with a look at Rome’s courts (but expect addenda also covering provincial government and Rome’s Italian alliance system). Share this: TwitterFacebook I stress this point because this is a common mistake: assuming that the Pontifex Maximus as Rome’s highest priest was in some way the ‘boss’ of all of Rome’s other priests. He was not; he was the presiding officer of the college of Pontiffs and the manager of the calendar (this was a very significant role), but the Pontifex Maximus was not the head of some priestly heirarchy and his power over the other pontifices was limited. Moreover his power over other religious officials (the augures, haruspices, the quindecimviri sacris faciundis and so on) was very limited. Instead, these figures report to the Senate, though the Senate will generally defer to the judgement of the pontifices. With sitting tribunes able to attend meetings of the Senate, but not being granted lifelong membership. A touch higher than the 24 years a L3 Model West life table (what we generally use to simulate Roman populations) leads us to expect, but then these are elites who are likely to be well nourished and not in hazardous occupations, so they might live a bit longer. Though it must be noted that Polybius is mostly looking at Roman foreign policy, where the Senate is strongest. I should note much of this picture is owed to Michael Taylor, with whom I am collaborating on work on this very topic; I’ll be sure to hollar if/when that work appears in print, of course. For a sense of how keenly, see C. Barton, Roman Honor: the fire in the bones (2001). Like this: Loading... Tagged Ancient Auctoritas Customs Political Systems Roman Republic Rome Senate Published by Bret Devereaux View all posts by Bret Devereaux Published September 22, 2023 Post navigation Previous Post Collections: The Gap in the Armor of Baldur’s Gate and 5e 33 thoughts on “Collections: How to Roman Republic, Part IV: The Senate” Eric Scharf September 22, 2023 at 12:50 pm Was there a dress code? Loading... Reply Bret Devereaux September 22, 2023 at 12:54 pm Uh, yes, actually. Senators not holding a magistracy wore a tunic with the latus clavus (broad purple stripe) and the white toga virilis. Senators who held a curule magistracy instead wore the toga praetexta, which had a purple border and they wore a tunic with two purple stripes instead of one. Loading... Reply Jaojao September 22, 2023 at 3:23 pm I have tried to find sources for this, but had some problems. Do we know if equites also had two stripes or one? Loading... Reply lockeandlol September 22, 2023 at 3:53 pm GASP! another thing the painting got wrong! there’s no purple present! Loading... Reply Dillon Saxe September 22, 2023 at 10:50 pm Until whit gym shorts and a hoodie with a purple stripe were accepted for some senators in 50 BC, and the Republic fell shortly afterward. Lesson learned. Loading... Reply Adam September 22, 2023 at 12:58 pm Given the deliberative nature of the Senate as a body, and the unequal distribution of auctoritas, it strikes me as likely that even if there isn’t a formal convention of the Senate, a few of the more senior senators could get together and arrange how they were going to vote and speak such that when the issue of the day was formally convened by a magistrate, they were waiting and ready to go and all pus h their influence in whatever the desired direction was. Do we have any record of that? Also, owing to the necessary wealth and accomplishment to get in the senate, I assume almost all of these senators had networks of clients, probably very significant networks of clients. Did they ever use these client networks to try to get things done in the senate itself? (Say, arranging a demonstration by your clients hollering in favor of the proposal you just happened to be in favor of yourself). I could easily see one of the reasons and ways to get a lex approved in favor of the way the senate decided is by having the senators then go out to their various clients and ‘advising’ them how to vote in the upcoming assembly. Loading... Reply guy September 22, 2023 at 1:59 pm I have the feeling that the most useful clients for getting things done in the Senate are other people’s clients, because part of the system is that they represent their client’s interests in the Senate. The whole idea of the Senate having Auctoritas from being older and wiser would seem to encourage them to ignore the sort of popular appeals we’re used to unless things were at a breaking point. Loading... Reply John Firth September 22, 2023 at 1:15 pm The fifth entry marking the rough midpoint of a five-part series is a clever way of alerting the reader to some complex, legalistic discussion within. And, of course, said discussion is quite clear and enjoyable as always. Loading... Reply DerekL September 22, 2023 at 1:29 pm Curious, would the agenda have been known in advance? Days, weeks? Loading... Reply Raphael September 22, 2023 at 1:52 pm Minor correction: “This is the third section of the third part of our our planned five part series[…]” I think it’s actually the fourth part, or the first section of the fourth part. Loading... Reply Axioms September 22, 2023 at 1:55 pm This is gonna be fun to represent in game form. That NPC decision code, though, wow. Longer than War And Peace. Loading... Reply 60guilders September 22, 2023 at 2:54 pm So, what would have been considered “egregious moral turpitude”? What examples do we have of senators being removed for it? Loading... Reply Axioms September 22, 2023 at 3:31 pm https://discovery.ucl.ac.uk/id/eprint/1407932/1/Lee%20Christopher%20Moore_Thesis.pdf Here’s a thesis focused on the issue of Senatorial expulsion. It discusses both the ostensible and actual reasons for explusion by the censors. For example P. Cornelius Rufinius was expelled for the ostensible reason of owning over 10 librae of silver plate but in truth it was that the censor involved was his political opponent Gaius Fabricius Luscinus. Fabricius was notable in his “austerity and incorruptibility” so he probably really opposed the level of avarice Cornelius exhibited but he also hated his guts. Loading... Reply Jaojao September 22, 2023 at 3:38 pm It seems to me that senators were often removed for rather frivolous, or at least very culturally specific reasons. For instance one of Sulla’s ancestors was supposedly removed for owning too much silver tableware, and Cato the Elder is said to have expelled a man for kissing his wife in public. Of course the problem with saying this definitely on the issue is that the examples mentioned in the sources are often of censors being unusually strict Loading... Reply Patrick September 22, 2023 at 3:07 pm Was there any sense that the assemblies might be more likely to disagree with the pronouncements of a divided Senate? If it was a knife edge vote in the Senate did that make the assembly more willing to think “eh loads of important people don’t like it too”? Loading... Reply Jaojao September 22, 2023 at 3:31 pm It seems to me that celebrities of the day (gladiators and actors, I mean) did have a kind of influence senators wished for; we find legislation banning those of the senatorial class from partaking in these activities in the Empire, and we know some of them were part of Caesar’s exhibitions (Suetonius, Life of Caesar 39) Loading... Reply godfreyofboulogne September 22, 2023 at 3:31 pm “what on earth is the role of the censors in selecting the Senate’s membership?” A major role was enforcing the monetary qualification. After all, the principal job of the censors was to take the census, the quintenniel count of all Rome’s citizens, and (just as important) classifying them both by tribe and by wealth. To enter – and remain in – the Senate, one needed 600,000 sesterces (a knight’s census)- at least at this period; it would be raised to 1 million under T Gracchus. And it wasn’t just any money: a Senator had to have his money respectably invested in land (and the produce thereof, like wine and olive oil). Merchants and bankers were not eligible, no matter how rich. Of course, there were lots of dodges – just look at Crassus! – usually shell companies nominally run by clients or freedmen. But at least on paper the source of income mattered, and there were definitely some very wealthy tycoons who were content to remain equites and not meddle in politics. Loading... Reply hrotha September 22, 2023 at 4:11 pm You’re a relatively junior senator who has this brilliant idea about an item on the agenda that you think the Senate absolutely needs to hear. Do you give a speech yourself, even as a junior senator, even though you’re not Cato? Do you try to win over a more senior senator through informal talks so that he can give his own speech instead? Does the idea not even cross your mind because you know you’re a junior senator and junior senators know their place? Loading... Reply Roxana September 22, 2023 at 8:56 pm I think you’d probably try to interest a consular in your project, or you’d run for Tribune of the Plebs. Loading... Reply Devin September 23, 2023 at 6:20 am If you have an *idea,* rather than an argument (that is, not a line of reasoning to support a position that is likely to already have senior senators attached, but a genuinely different thing that could be done) you might want to broach it to the magistrate who has convened the Senate. After all, not only do you not want to be interrupting an up-or-down argument on the merits of a road from X to the ford at Y by suggesting building a bridge instead, but also the Senate isn’t going to be building the bridge even if the vote goes your way, so you might want to talk to the guy who would be and see if he’s interested or able. Clearly junior senators do give speeches, so if you have what you think is a strong or novel argument in support of a position already held by your seniors, you probably do give it yourself. You’re in the Senate, after all, you’re not a complete upstart. Loading... Reply chris September 22, 2023 at 4:21 pm I forgot to ask in the Cleopatra article. But I wanted to ask why you prefer Marcus Antonius over Mark Anthony while Pompey is still written as Pompey and not Pompeius. Loading... Reply Demarquis September 22, 2023 at 7:37 pm I can’t help wondering how well this would work in the modern day. A non elected body, with a minimum wealth requirement, made up primarily of former elected officials. There aren’t enough of those at the Federal level (in the US), but if you included former State Governors you could raise quite a number. Maybe senior Cabinet members as well. This is the only body allowed to deliberate, and sitting Presidents and this body can introduce legislation into the Assembly equivalent. They serve for life (or perhaps until they fail a health exam). Who would we use in place of the Censors (the Census Bureau seems inappropriate). Maybe the Supreme Court. Surprisingly workable. Loading... Reply CarlXII September 22, 2023 at 11:07 pm List I found was 274 former governors, in practice a bit less since that includes acting governors and criminally convicted and so on and people not in any condition to participate. Seems in fitting with original experience. Problem of course is just how it would come about. Such big change unlikely down the road. And at the start you only have 13 states and probably don’t want most former colonial governors, so pitifully small group. Ex-Cabinet members doesn’t work great given how flexible what a cabinet member is and even more so their tenure is. I suppose one initial cheat code might be to honorarily throw in the signers of the Declaration of Independence to tide you over. Actually looked into and not as bas as I feared. By my count in 1812, for instance, there would be 10 signers, Burr literally the only ex-P/VP beyond that, roughly 90 former governors. You see the fun thing I learned is that states early on loved year-long terms for governors…As well as 2-term limits… Obviously reasonable to expect states to cling to that approach longer, so by modern date might have a thousand former governors easily. But I don’t think this is realistically happening. One thing is it is very random based on state selection process. Not to mention how many a state has. Like DE would have 7 ex-governors and PA 1. And we know relative state balance of power was *huge* concern. Loading... Reply mindstalk0 September 23, 2023 at 3:00 am If you just go for inspiration rather than a direct analogy, an elected House might feed into an unelected Senate. People who’d had 5 House terms, or were elevated by their peers? Seems like Canada’s Senate wants to be a “body of accomplished people who can give advice” though I don’t think it has nearly the auctoritas to pull it off. Likewise the reformed House of Lords, with more “life-lords” than hereditary peers. Also, simply being wealthy doesn’t command the respect it allegedly did then. Many would see excess wealth as a detriment to being politically respected. Loading... Reply adamx September 23, 2023 at 4:11 am On the wealth side, the top 50 senator all have net worth over $10 million. There are a few with negative net worth but I assume this has something to do with financial dealings. Wealth is hardly an impediment to gaining office though the truly wealthy seem to more invest in controlling batches of senators or whole political parties (ala the Heritage foundation and Koch brothers). Not sure if respect is the currency that matters in the current US political system, especially with recent revelations about supreme court justices and “gifts.” Loading... Reply Dillon Saxe September 23, 2023 at 3:34 am None of the parts of Roman government has an exact equivalent in modern governments. The assemblies map onto part legislature, part general elections. The magistrates map onto parts of individual bureaucracies, and some state level offices like Attorney General or Comptroller in the U.S.. The Senate combines roles of bureaucracy and legislature. General purpose leaders like governors and presidents don’t have a Roman equivalent, and the Roman government doesn’t seem to have as big a civilian role as modern governments do (There is infrastructure and money management, but concentrated in a few guys much more than modern governments can be.) So a modern advisory body of previous officials has more competition, both in what can fill its role and in other power centers. Almost certainly would not be as powerful for that reason. It could still make sense, though politicians probably consult with each other somewhat often anyway. You’d basically have a formalized version of these sorts of informal networks. Loading... Reply Demarquis September 22, 2023 at 7:38 pm I can’t help wondering how well this would work in the modern day. A non elected body, with a minimum wealth requirement, made up primarily of former elected officials. There aren’t enough of those at the Federal level (in the US), but if you included former State Governors you could raise quite a number. Maybe senior Cabinet members as well. This is the only body allowed to deliberate, and sitting Presidents and this body can introduce legislation into the Assembly equivalent. They serve for life (or perhaps until they fail a health exam). Who would we use in place of the Censors (the Census Bureau seems inappropriate). Maybe the Supreme Court. Loading... Reply Yet Another Rob September 22, 2023 at 10:16 pm You have referred to the cursus honorius as an elimination contest several times. So how did you know and accept being eliminated? Was every election sudden death, ie lose one and your career was over? Or was there an accepted threshold where you just had to accept your career was done? Loading... Reply Mary Catelli September 22, 2023 at 10:49 pm Since getting an office the first year you are eligible was considered a particular feat, it must have been feasible to get it later. Loading... Reply Yet Another Rob September 22, 2023 at 11:21 pm Aye, but was it run, lose, run again, or wait until you were assured of winning, because losing was the kiss of death? I suspect it was the former, but it’s entirely possible there were unspoken rules and different conditions for a given office. Loading... Reply mindstalk0 September 23, 2023 at 1:58 am “I promise the long-awaited Greek-and-Phoenician colonization treatment is coming!” I look forward to it! I particularly hope you’ll shed some light on the prior inhabitants. As a child I just assumed the Greek colonists found empty land to move into, like farmers simply hadn’t saturated the coastal Mediterranean yet. This seems very unlikely to me now. Hoyos does mention Carthage paying a land tax to the prior locals, until it got powerful enough to stop and then reverse things Loading... Reply Jaojao September 23, 2023 at 6:35 am Me too, I’m very interested in that! There are mentions in the sources that some native populations became helot-like underclasses, for instance the Bithynians in Byzantium and a group called Cyllyrians in Syracuse, but I don’t know how common this was Loading... Reply mindstalk0 September 23, 2023 at 2:30 am “Sulla’s effort to restore the power of the Senate by radically expanding it seems, here, particularly misguided, as if adding 300 more mediocrities could restore the respect of an institution after Marius and Sulla himself had gotten done killing nearly all of the men of experience, capability and consequence in the body.” snerk! I note the WordPress UI seems different now. typos: three rolls here — roles which ,set — rogue comma were mot than — more than legally-ineligable- — ineligible Loading... Reply Leave a Reply Search for: Updates every Friday! You can support this project via Patreon, and by spreading the word! Recent Posts Collections: How to Roman Republic, Part IV: The Senate Collections: The Gap in the Armor of Baldur’s Gate and 5e Michael Taylor on The Development of the M1 Garand and its Implications Fireside Friday, September 1, 2023 Collections: How to Roman Republic, Part IIIc: Ten Tribunes, Two Censors and Twenty-Six Guys Collections: How to Roman Republic 101, Part IIIb: Imperium Questions? Requests? Have a topic you want me to post about? A question on a post? Do you want to scream incoherently into the endless void that is the internet? The best place to find me is on twitter @BretDevereaux Following me on Twitter is the best way to be informed of new posts as they appear. Tags Academia Ancient Armor Artillery Broader Mediterranean Cavalry Cities Cohesion Command Command Structures Content Warning Culture Customs Demography Doctrine Dune Early Modern Economic History Economy Empire Farming Field Fortifications Fireside Chat Food Fortifications Game of Thrones Gaming History Hollywood Tactics Horses Household Humanities Imperialism Infantry Iron Kingship Logistics Lord of the Rings Markets Medieval Middle Ages Military History Modern Oh no Operations Organic Economy Organization Paradox Paradox Development Studio Political History Political Systems Production Religion Roman Roman Empire Roman Republic Rome Science Fiction Siege Siege Warfare Slavery Social History Sparta States steppe nomads Strategy Tactics Technology Textiles Trade Ukraine Video Games War and Society Warfare Weapons Archives September 2023 (4) August 2023 (4) July 2023 (4) June 2023 (5) May 2023 (4) April 2023 (4) March 2023 (5) February 2023 (4) January 2023 (4) December 2022 (5) October 2022 (5) September 2022 (5) August 2022 (5) July 2022 (5) June 2022 (4) May 2022 (4) April 2022 (5) March 2022 (4) February 2022 (4) January 2022 (4) December 2021 (5) November 2021 (4) October 2021 (5) September 2021 (4) August 2021 (4) July 2021 (5) June 2021 (4) May 2021 (4) April 2021 (5) March 2021 (4) February 2021 (4) January 2021 (5) December 2020 (3) November 2020 (4) October 2020 (5) September 2020 (4) August 2020 (4) July 2020 (5) June 2020 (4) May 2020 (5) April 2020 (4) March 2020 (5) February 2020 (4) January 2020 (5) December 2019 (4) November 2019 (5) October 2019 (5) September 2019 (5) August 2019 (6) July 2019 (5) June 2019 (6) May 2019 (12) Powered by WordPress.com.",
    "commentLink": "https://news.ycombinator.com/item?id=37614216",
    "commentBody": "How to Roman Republic, Part IV: The SenateHacker NewspastloginHow to Roman Republic, Part IV: The Senate (acoup.blog) 192 points by Tomte 18 hours ago| hidepastfavorite103 comments eru 2 hours agoThe same blog&#x27;s posts on Sparta are also really worth reading: https:&#x2F;&#x2F;acoup.blog&#x2F;2022&#x2F;08&#x2F;19&#x2F;collections-this-isnt-sparta-r...The author also did a guest appearance on Drachinifel&#x27;s Youtube channel about the Punic war: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EVnXG0Yrfns reply jackconsidine 17 hours agoprevWhoa! I picked up The Fall of the Roman Republic by Plutarch this week and have been glued. Will definitely be reading this whole series reply swasheck 15 hours agoparentthe fall of the roman empire is such a fascinating, and surprisingly divisive, topic. enjoy the read and then pick up other works and it will feel like hearing the same story through a brand new lens. this may be part of the enduring curiosity with the roman republic and subsequent empire - it&#x27;s so complicated and nuanced that you cannot simply distill it down to a single factor. reply philipov 16 hours agoprevI hope he does a series like this on civic governance in Han China next! reply eru 2 hours agoparentYes. Though I&#x27;d be more interested in Song China, ever since reading The Gunpowder Age by Tonio Andrande.Btw, Tonio Andrande&#x27;s &#x27;How Taiwan Became Chinese&#x27; is available for free online at http:&#x2F;&#x2F;www.gutenberg-e.org&#x2F;andrade&#x2F;intro.html reply DylanSp 16 hours agoparentprevAs great as that would be, it&#x27;s well out of Devereaux&#x27;s area of specialization; I don&#x27;t think he&#x27;d feel like he could do that topic justice. If you look up his older series on farming, he notes in the introduction and in his addendum on rice farming that he&#x27;s not as familiar with Chinese history. reply red_admiral 14 hours agorootparentHe does guest posts though, so maybe there&#x27;s a chance? reply fladrif 16 hours agoparentprevUnfortunately he as a historian specializes in the Mediterranean, specifically Rome. reply swasheck 16 hours agoprevbret devereaux is a great follow on twitter, uh ... X, as well. his thoughts on the ukraine&#x2F;russia conflict are very interesting to me reply ethbr1 12 hours agoparentHis modern stuff is more... eh.E.g. I thought there were a lot of flaws in his early-war \"NATO can&#x27;t supply X, because Russia will threaten nukes\" positions, as he completed ignored the obvious opposite \"Russia can&#x27;t escalate, because NATO will threaten nukes\"110% love his Roman-period deep dives though.There&#x27;s probably a smarter quip than me out there to the effect of \"Great people share their brilliance on many matters, while the greatest speak on but a few.\" reply jltsiren 9 hours agorootparentWasn&#x27;t the standard model for how a nuclear war would start basically \"if you escalate, the reasonable expectation is that the other side will escalate as well\"? If you escalate despite the nukes on the other side, it would be risky to assume that the other side is unwilling to do the same.If you escalate, you signal your intent to start a nuclear war if the other side does not back down. But if you are willing to do that, you should assume that the other side is equally willing. Otherwise why would they waste money on nuclear weapons if they are not prepared to use them?Much of the cold war was basically figuring out what you are allowed to do in a proxy war, so that the other side still interprets your actions as a legitimate proxy war rather than escalation. reply eru 2 hours agorootparentWhile the Cold War was still raging, Thomas Schelling, of &#x27;Strategy of Conflict&#x27; fame, pointed out that while the war stays cold thanks to the &#x27;mutually assured destruction&#x27; consensus, it would be an optimal strategy in terms of bang-for-your-buck to pretend to have many more nukes than you actually have.Concretely, since no one ever wants to call your bluff and test your nuclear arsenal, it&#x27;s natural to expect that unless there are strong countervailing pressures, one can expect that many nukes will be badly maintained and turn out to be duds.Given what we learned about the state of the Russian armed forces since February 2022, it would not surprise me, if Russia barely had any working nuclear capabilities in practice.(However they would still be dangerous enough. Even a nuclear payload that doesn&#x27;t explode properly would still be a very dirty bomb.) reply xg15 27 minutes agorootparentWithout wanting to do any speculation how the current situation will ever end, but I always assumed that the first stage of nuclear escalation would be nuclear tests - to exactly call this kind of bluff of the other side and to signal that the own side would be actually capable of performing a nuclear strike.From what I know this was also what happened in the cold war - the nuclear threat back then was a lot more \"palpable\" than it is now, possibly because both blocks were already constantly launching nukes - they just weren&#x27;t launching nukes at each other:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Historical_nuclear_weapons_s... reply bobthepanda 12 hours agorootparentprevTo be fair, it took a while for people to figure out how much MAD was still in play, since before the invasion most punditry thought Russia was bluffing and would never try to invade Kyiv with tanks, so what else had they gotten wrong? reply ethbr1 12 hours agorootparentIf a shoe fits on one foot, it fits on the other too. Aka the \"M\".The \"Russia is a madman, but we&#x27;re not\" is... difficult to square logically and historically.Beneath all the political and PR charades, during the Cold War the Soviet Union was generally as terrified of the West pre-emptively nuking them as vice versus. reply galaxyofdoom 10 hours agorootparentPresently, it is not during the Cold War. The idea that Putin is terrified of nuclear annihilation is ridiculous. reply eru 2 hours agorootparentJust speculating: I&#x27;m fairly sure Putin knows that the West won&#x27;t do any nuclear first strikes.But if he tries anything even remotely nuclear, the West would just annihilate his empire. And the West wouldn&#x27;t even need to go nuclear.(Especially if the West got serious and opened the money floodgates. I suspect even in the current state of the Ukrainian war, if they offered any Russian defector 100k USD and a new identity under a EU passport, they could meld away the Russian army fairly quickly.)Russia would most likely also lose the tacit support of India and China, if the bear were to use nukes first. replypphysch 12 hours agoparentprevI was curious, so I looked. He&#x27;s out there boosting Timothy Snyder. Oof. I&#x27;ll pass. reply _whiteCaps_ 12 hours agorootparentCan you explain further? I see on his Wikipedia page:\"Since Russia&#x27;s 2022 invasion of Ukraine, and the bombing of its energy infrastructure, Snyder has spoken and written widely on the history of Ukraine and its worldwide importance for democracy, on the disastrous geopolitical effects of the invasion, and on the need for other nations and individuals to stand for the protection of territory belonging to that state.\"which seems reasonable to me. reply pphysch 11 hours agorootparentSnyder leans heavily on moralizing and evidence-free psychoanalysis to explain current events.It&#x27;s far too much \"trust me I&#x27;m an established intellectual\" and far too little evidence-based reasoning for me. To each their own. reply lying4fun 12 hours agorootparentprevI’m not familiar with Timothy’s persona&#x2F;work, why did that repel you? reply Symmetry 17 hours agoprevIt&#x27;s amazing this showed up on Hacker News before it showed up in my RSS reader. reply bee_rider 17 hours agoparentThis guy has absolutely nailed the nerdy-but-accessible vibe, no surprise his posts are recurring first-pagers. reply belval 13 hours agorootparentI wish we had a Bret Devereaux for more topics, but then I might never get things done. reply ethbr1 12 hours agorootparentIt seems like there&#x27;s a ridiculous amount of time to sink into a single blog post.So you&#x27;re probably looking at mostly historians to be able to do something like what Devereaux puts out. The closest I could think of would be: Derek Lowe Neil deGrasse Tyson (when not playing for camera) Adam Savage Nigel Braun (NileRed) Salman Khan Dianna Cowern (Physics Girl) Grant Sanderson (3Blue1Brown) reply monocasa 17 hours agoparentprevMakes you wonder how prevalent RSS->HN submission scripted automation is, or if it&#x27;s just the thundering herd of users. reply ulizzle 16 hours agoprevI think I’m almost out of this illness. Still sweating the fever but no migrainesIve been reading a lot because that’s about the only thing I can do so I read the original Gallic wars from Julius Cesar and its funny because he’s painted like a bad guy today for becoming a dictator but the Senate was at that point so corrupt and inefficient and everyone hated it so he wasn’t the only one trying to get rid of democracy. Julius Caesar had actually been involved in four attempted coups before he got it done. And he was popular with the public even after his death so that makes senseI’m sure a lot of here think of the Roman Empire almost obsessively. How bad is this turn toward extrémeme censorship and surveillance? At what point do people say to hell with it and bring back kingship? reply bigstrat2003 16 hours agoparentI recently read Rubicon by Tom Holland, and honestly I came away from that book feeling like it&#x27;s Sulla, not Caesar, who truly deserves the blame for the downfall of the Republic. Like yeah, Caesar crossed the Rubicon, but that seal was broken decades earlier by Sulla. If Caesar hadn&#x27;t done it, someone else would have because it was clear that there would be no real consequences as long as you could win the war. And then Sulla painted the town red with blood to get rid of his enemies. All the reforms in the world can&#x27;t undo that kind of damage to the social fabric, or so I would think. I am admittedly not the most knowledgeable about this topic, but it really does seem like Sulla should get the blame that Caesar does.Also, one thing that struck me about the Republic is that it worked right up until people stopped upholding the social norms that made it work. And while one might say the lesson is \"make your system of government work without social norms\", I wonder if such a thing is possible. Looking at the US government it seems damaged (not broken yet, at least) precisely because we have stopped upholding the social norms that made it work. This being despite the fact that the US constitution seems to be more robust than what the Romans had! It really makes me wonder if any form of government, no matter what, absolutely relies on social norms to work well (and breaks down when those norms do). reply seanw444 15 hours agorootparentThis is the conclusion I&#x27;ve come to. Societal decay causes nations with even the most solid foundations to topple. There&#x27;s really no way around it.A phrase to summarize the phenomenon is: \"Politics is downstream from culture.\"We focus too much on slapping bandaids on society through increasing bloat of government and adding more laws to the pile, when the real root of the problem is our culture is falling apart. No amount of laws is going to fix that.I parallel it to medications. You get one illness, so you get prescribed a medication. But then that medication causes an unusual reaction with your body, so you&#x27;re given another medication to fix that one. But that medication has adverse effects when taken in conjunction with the first one, so now you need to take another medication to fix that... and it continues until you have a daily ritual of popping 20 pills to solve a trivial health condition.The US is taking way too many medications, and not going on the proper diet to solve its health issues. That can be said both literally, and in the metaphorical sense. reply araes 14 hours agorootparentYou use the phrase Societal Decay. I think you can say it has many similarities to a corpse. Not to be gross, just you get a lot of the same terms.The country freezes in rigor mortis, and can no longer take actions.Politics or governance often feels like its experience brain death.You get bloat and deflating effects, bubbles that inflate and pop.You get a lot of social events that humans would describe as \"putrid\".You get flight or escape of those that can leave for a new host, others flee to the remaining healthy areas.You have external \"parasites\" &#x2F; enemies removing portions of the empire&#x2F;nation.The process usually results with breakup and collapse in prior body segments. reply Jensson 13 hours agorootparentHeart disease fits the best. Your heart is dying, it can&#x27;t pump blood properly. To compensate it tries to grow larger, it swells and you get a giant heart. At some point it collapses since the problem was that the heart was leaky or the arteries got clogged or the muscles has some issue etc, growing larger can compensate in the short term but eventually you die anyway.So it is similar to how a government that tries to grab more power and become larger is a red flag for corruption or inefficiency. The problem isn&#x27;t that it tries to grow, the problem is that it is corrupt and inefficient in the first place, the country is then dying no matter what.Countries can be replaced however, and small governments are easier to replace than large ones, so ideally should fix the government before it grows too large and powerful to easily be replaced. reply url00 15 hours agorootparentprevThis is very poignant. I have come to similar conclusions w.r.t societal systems only last as long as the social norms continue - the actual legal framework and structure is secondary to the larger cultural imperatives that brought it about in the first place.And as you say, history directly plays into the shift of possible actions by social elites&#x2F;leaders. Once change starts, change itself can become as social norm and seen as acceptable by society at large (at least to a point in a given time period). reply Exoristos 15 hours agorootparentprevPeople, historically, have often had successful lives with social norms but no government (as we think of it), but never with a government and no social norms. reply lainga 16 hours agorootparentprev\"Time was when men could (so to speak) of a given man, by nourishing and decorating him with fit appliances, to the due pitch, make themselves a King, almost as the Bees do ... How such Ideals do realise themselves; and grow, wondrously, from amid the incongruous ever-fluctuating chaos of the Actual ... How they grow; and, after long stormy growth, bloom out mature, supreme; then quickly (for the blossom is brief) fall into decay; sorrowfully dwindle; and crumble down, or rush down, noisily or noiselessly disappearing.\"(Carlyle&#x27;s history of the French Revolution) reply digging 16 hours agorootparentprevSulla often gets the opposite treatment because he retired from dictatorship, but it&#x27;s important to keep in mind exactly the problems you raise. Mass murder causes stress to a society, regardless of intent. reply henrikschroder 14 hours agorootparentprev> Rubicon by Tom HollandI&#x27;m currently listening my way through The Rest Is History, the podcast he does with Dominic Sandbrook. Very entertaning, highly recommended! reply 12907835202 14 hours agorootparentWorth starting from ep.1 or just diving in where it&#x27;s at now? reply henrikschroder 5 hours agorootparentEvery episode is pretty stand-alone and specific, so pick episodes with topics that interest you. reply Eumenes 15 hours agorootparentprevThe entire civil war and times surrounding Marius and Sulla would make an amazing movie. Its a real shocker that Hollywood hasn&#x27;t picked it up yet. Not that I trust Hollywood to make anything good anymore. I think Caesar gets alot of attention due to the way he was murdered. And it was the \"end\" of the Republic. You also have Marc Antony and Cleopatra in there, which is a good story. reply rawgabbit 15 hours agoparentprevMy understanding was that Caesar represented the populares who championed the poor like the Gracchi brothers. By Caesar&#x27;s time, the poor believed not only the Senate was beyond repair but were the primary reason for their poverty. Several attempted land reforms were blocked by the Senate who lived off their latifundium. https:&#x2F;&#x2F;www.britannica.com&#x2F;topic&#x2F;latifundiumThe populares welcomed Caesar and Augustus because they saw no other alternative. Sulla had effectively ended the office of the tribunes who represented the poor. From the essay below, A tribune couldn’t even guarantee his personal safety: the murder of the Gracchi brothers is the best example. This office itself was an outcome of the political compromise in the early Republic. Its seemingly supreme and sacrosanct power was based on the compromise, or to say, tolerance of the Senate. When the symbiotic relationship between the nobles and the commoners on the political stage of the early Republic collapsed after drastic economic changes, the compromise of the Senate automatically vanished, so it was only a matter of time to weaken the power of the tribunate. Thus, the Roman commoners must find new strength for their political struggles. https:&#x2F;&#x2F;www.atlantis-press.com&#x2F;article&#x2F;125967046.pdfIn other words, the people will rise up if they believe the political class no longer represents them and are actually opposed to them. I see a parallel between the enslaved Carthaginians working the latifundium and all the immigrants our politicians want to bring in to \"fix our economy.\" I believe this is playing with fire. reply kmeisthax 15 hours agorootparentThe question is not whether or not to bring in more immigrants. The agricultural industry already does so in large numbers, legality be damned, and the parallels to the latifundium are way stronger than, say, Facebook&#x2F;Meta wanting to hire more people from India.Ironically if we radically legalized immigration it&#x27;d make it harder for Big Ag to exploit migrant workers, since they&#x27;d have access to legal immigration and the protections therein. But that&#x27;s assuming Big Ag doesn&#x27;t do to that program what they did to the Bracero program back in the 70s. reply rootusrootus 16 hours agoparentprev> At what point do people say to hell with it and bring back kingship?That seems to be well in progress, though I don&#x27;t think anyone is actually using the term &#x27;king&#x27; yet. reply __MatrixMan__ 15 hours agorootparentI had a ton of time to kill in an airport recently, so for a little while I hung out at the end of the TSA line to let the confused passerby know that yes... this is the end of the line for peasants. Nobility goes over there. I think I did a much better job than the existing signage--branding sort of confuses the matter.Had a lot of fun conversations with other peasants about whether this is the kind of privilege that the french revolution was fought over. The nobility didn&#x27;t have as much time to stand around and water the seeds of revolution. Seemed fitting. reply lokar 15 hours agorootparentprevJudges are: “the president is not a king, and you are not the president “ reply AnimalMuppet 15 hours agorootparentYes, they&#x27;re using it in the negative.But Yarvin and the \"Dark Enlightenment\" people seem to be using it seriously (so far as I understand them). reply lokar 15 hours agorootparentBut that they thought it worth pointing out is telling reply jiofj 15 hours agoparentprev> At what point do people say to hell with it and bring back kingship?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Curtis_Yarvin reply golem14 13 hours agorootparentI propose to instead use the system proposed by G.K. Chesterton in \"The Napoleon of Notting Hill\". reply waihtis 16 hours agoparentprevWe’re super close to it given how many states have abandoned and spat on the contributing class in favour of egalitarianism. reply hef19898 15 hours agorootparentIn a Monarchy, or Oligarchy, not everyone who thinks they can make into the ruling class will manage to do so. reply riazrizvi 16 hours agoprevPoint to Charlie Munger, whom I was critical of a few days ago, how is so much written on how the Roman Republic worked, without talking about the most basic of incentive structures that drove its citizens to work like no others in the first place - The Law of Twelve Tables? It gave every citizen property rights that were protected by the State. The system was _the_ get rich game for the common man (after Alexander replaced ancient Greece&#x27;s Solonian Constitution with his Royal authority). Roman soldiers were citizens looking to make money, it was a so called army of merchants. Joining the empire was an attractive proposition because people saw an opportunity to break out of their own opportunity-poor regimes, so the model spread like wildfire, though obviously resisted by hereditary rulers who stood to lose their cozy positions. reply arrosenberg 16 hours agoparentAnd look! The problems started when the wealthy Senators started hoarding land in the aftermath of the Punic and Greek conquests. The Gracchi - land reform issues! Marius - land reform issues! Caesar - land reform issues!It&#x27;s as if history rhymes. reply riazrizvi 13 hours agorootparentRhymes indeed. Caesar rode a popular wave of resentment to a system that was increasingly gamed by the powerful few, and it ultimately lead to power being captured by an even more concentrated body, the office of an emperor, Augustus, Caesar’s heir.Isn’t this the exact thing we see in the USA where the economically disadvantaged seek solutions from the right whose policies aim to further concentrate wealth and opportunity? reply 1980phipsi 15 hours agorootparentprevSlavery certainly had an impact on that as well. reply snowpid 17 hours agoprevThis is the reason I think about the Roman Empire at least once a week! reply belval 17 hours agoparentThis has the be the funniest trend to come out of Tiktok. My SO point blank asked me how many times I thought about the roman empire and I replied \"I don&#x27;t know, once or twice a week\".Little does she know we get a post from acoup every week!Reference (for those out of the loop): https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;conormurray&#x2F;2023&#x2F;09&#x2F;18&#x2F;how-ofte... reply swasheck 16 hours agorootparentmy wife asked me and i said once per week. then she and my daughter cackled and asked me to repeat my answer and i knew i was about to become part of a trend so i refused. but isn&#x27;t it fascinating how truly interested in the roman republic and emopire we are? people are coming up with theories about why this is the case but i&#x27;m not sure any of them resonate with me. i was always more of a greece person until i visited italy 7 years ago and i was thoroughly smitten. reply henrikschroder 15 hours agorootparent> but isn&#x27;t it fascinating how truly interested in the roman republic and emopire we are?If you&#x27;re in the US, how can you not be? It&#x27;s everywhere! The fledgling US was desperately in need of authority and gravitas, so they essentially cosplayed as the inheritors of the ideals of Rome, and put that shit everywhere.Why does Washington DC look the way it does? Why are there pillars and obelisks and domes and white marble everywhere? Why is there Latin on the money? Why does every US courthouse look like a Roman temple, and why is there a Roman goddess on it?The trend is popular because it&#x27;s laughing at men for being \"nerdy\", but I think it&#x27;s sad how ignorant a lot of people in the US are for not knowing about or recognizing the absolutely enormous amounts of references to Rome that exists in modern US. reply mattmanser 14 hours agorootparentIt is not a US thing.Europeans also have Latin on our money too. Our alphabet is the Latin alphabet.They were still teaching primarily IN Latin at universities around the war of independence. Yes, you read that right, you spoke and read Latin as your primary learning language. The American universities copied the practice from their home countries.Until the 1960s in the UK you had to know Latin to learn Medicine or Law. It was still taught in many schools, and I think has been having a resurgence.I was taught Latin at school.The Americans didn&#x27;t cunningly adopt it to lend themselves legitimacy. It&#x27;s as simple as the European settlers brought it with them. It was the culture of European intellectuals. reply lo_zamoyski 14 hours agorootparentprev> Why does Washington DC look the way it does? Why are there pillars and obelisks and domes and white marble everywhere? Why is there Latin on the money? Why does every US courthouse look like a Roman temple, and why is there a Roman goddess on it?This is all true for much or most of Europe, the West, and Western-affiliated countries. (Also, the marble in Rome, and Greece from whom the Romans took much of these styles) was generally painted, so not quite the austere white of DC.) reply kjkjadksj 12 hours agorootparentprevWhat is sort of curious to think about is that all these monuments really shouldn’t be white. They should be painted many colors especially the friezes. There were never temples with big empty rooms with a white marble statue either. Done in proper roman tradition the Lincoln memorial would be this imposing giant, fully painted, with a pile of gold and other offerings right there in the room along with regular insence burning fronted by local patrons.Of course by the time europeans got into the rennaisance all these temples had been pilfered and regular repainting had ceased for centuries. So because of this huge misunderstanding, neoclassical architecture is always boring and beige despite us knowing better today. reply verve_rat 13 hours agorootparentprevBut everyone tries to wear the clothes of Rome. The Russians, the Ottomans, unified Germany all played Roman dress up.Edit: also Catholicism. reply Detrytus 13 hours agorootparentFor Catholicism it wasn&#x27;t a \"dress up\" - it was the official religion of Rome in the last couple centuries, and the Catholic Church was the only main institution of (Western) Roman Empire surviving its fall. reply seanw444 15 hours agorootparentprevMy answer to my girlfriend was that I think about ancient Greece more often. Rome less. Greece was ahead of its time in philosophy and science. So many household names. Rome has a lot of political analogs to today though, which is what I find interesting about it. reply Keyframe 14 hours agorootparentDifference being Rome was an entity with government, military, etc. with which we can draw a lot of parallels to today, whereas Greece was more of a loose interconnection of cities that shape shifted over time. Both extremely interesting, of course. reply jmkr 14 hours agorootparentprevI&#x27;ve never been asked this question, but I think I&#x27;d respond similarly. In fact, when I think of Rome, I think of Greece. They are nearly inseparable for me, but that&#x27;s probably because my understanding of history is the history of western philosophy. You start with the Socratics, then read about the neo-platonist in Rome. reply lo_zamoyski 14 hours agorootparentprev> Greece was ahead of its time in philosophy and scienceAnd some would say that, philosophically, while we have the potential benefit of hindsight and therefore the opportunity to exceed the Greeks (you just need to crack open the right books), our typical modern, academic philosophy, is in many ways, inferior to it. reply jmkr 14 hours agorootparentThis is a strange comment because not only is academic philosophy built from the Greek tradition, but it is formalized. Maybe one can say it stagnated for centuries but I find it difficult to say that the work in the 20th century is inferior.I wouldn&#x27;t say that about comparing Hilbert to Pythagoras, and this is not putting down history of knowledge. reply Jensson 13 hours agorootparentJust the awareness of the scientific method makes us far superior to the ancient Greeks. Many still doesn&#x27;t follow it, but basically no Greek followed it and it really shows in their works.For problems where the scientific method doesn&#x27;t help however we probably aren&#x27;t that much better than the ancient Greeks, maybe we are even inferior there. replyTeMPOraL 13 hours agorootparentprevMaybe with all that sudden interest, we&#x27;ll get some progress on the \"Rome Sweet Rome\" movie. For context, and going by my memory, circa 12 years ago somebody on Reddit asked who would win, a bunch of Marines or the army of the Roman Empire; in response, one redditor wrote a short story about Marines being thrown back through time into the Roman era - it became viral (for ~2011 levels of \"viral\"), and the author ended up making a movie deal with some producers. I&#x27;ve been waiting for over a decade now for said movie to happen... reply jffry 12 hours agorootparentIt was indeed August 2011: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rome,_Sweet_RomeIf it&#x27;s been in development hell that long, I don&#x27;t know how likely it is that it&#x27;ll ever see the light of day. reply Jensson 15 hours agorootparentprevWhy do people think that is funny?Edit: Why downvote a genuine question? How else would I learn why people find that funny? reply bcherry 15 hours agorootparentFor me, it&#x27;s because it&#x27;s true. I really do think about the roman empire all the time! and my wife couldn&#x27;t believe it.Most \"trends\" from TikTok are made up, stupid, fake, or highly exaggerated. This one is funny because it&#x27;s actually kinda true for a LOT of people, and has nothing to do with TikTok. reply Jensson 14 hours agorootparentIs it really that strange that people think about the Roman empire when things related to it are all around us? Even the white house is built to look Roman. Not to mention all the documentaries and games that touches on Roman stuff.If you ask men how often they think about different manufacturing processes you will probably get similar numbers, or even higher, for the same reason. reply acatnamedjoe 14 hours agorootparentI don&#x27;t think it&#x27;s funny because it&#x27;s \"strange\". It&#x27;s funny because it reminds people that they can have very different inner worlds to people they share their life with. reply Jensson 14 hours agorootparentBut people already know that? Everyone knows men and women think about very different things.But I guess it is similar to the old meme where a woman worries why the guy is so distant that day and if he doesn&#x27;t like her any longer, and the guy is just thinking hard about why his motorcycle isn&#x27;t starting.But that explains it: it is funny the first time you see it, but these differences aren&#x27;t funny when you already are aware of them. Everything is a first to people. So I don&#x27;t find it funny since I have seen similar things many times before and have grown tired of it, while others here finds it funny since it is new to them. reply wizerdrobe 14 hours agorootparentprevI find it interesting but for the diversity of “why”I have an Italian American friend who weirdly into the Roman Empire, kind of in a weeb kind of way but he’s a tatted up (Roman Republic full back piece!) Army veteran who would Kimura my ass if I he sees this.I have a friend just nerdy as shit and into history. He constantly talks about this podcast or that.I have an ex-roommate &#x2F; philosophy major, so it comes up a good bit.I have a friend into Stoicism. Oddly not a philosophy major.I have a friend rich in small arms, ammunition, and those rice ration buckets because we’re destined for a failure of the Republic as they had.I have a friend with the same belief, except he just wants to fiddle so I’m pretty sure I won’t bother raiding his house if either of them are correct. reply coffeefirst 13 hours agorootparentprevOne girl learning her dad and boyfriend are both history geeks who think about the Roman Empire all the time is not funny.Hundreds of thousands of women realizing that unbeknownst to them ALL the men in their lives secretly think about the Roman Empire all the time is hilarious.Of course, the more specific this phenomenon is, the funnier it is: all men think about history isn&#x27;t fun. All men are thinking about the Roman Empire is pretty funny. All men are thinking about Pliny the Elder and none of the women in their lives had any idea much funnier.This is classic benign violation https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Theories_of_humor#Benign_viola... The reason I think its a hit because it scales and its totally silly&#x2F;fun&#x2F;harmless, relatable beyond expectations, and a welcome distraction to the usual hellscape that is the internet in 2023.---So the next question is why is it happening, and I have two theories for this:1. History is stranger than fiction. There&#x27;s a lot of history geeks out there and there always have been. See stereotype about dads reading WWII books.2. The Roman Empire is a gateway drug to history for a lot of people. And why not? It&#x27;s a fascinating period full of whacky characters, and there&#x27;s been so many movies&#x2F;shows&#x2F;plays&#x2F;games about it that you probably already know enough to dive in and generally know to expect some togas and a dude shouting \"I&#x27;m Spartacus.\" reply Jensson 13 hours agorootparentThanks, that explains it even better! Basically many women all over the world realized this &#x27;weird&#x27; thing now together and that shared experience creates something magical. reply nullindividual 15 hours agorootparentprevOne might think that an individual who thinks about an empire that has been “dead” for nearly 1500 years is a bit strange. Why would anyone care about a dead empire, after all? The reason why it’s funny is because of how common people say they do think about the Roman empire (which for me is also quite often). It’s subverting expectations— you think no one thinks about the Empire— in reality, all of your family and neighbors do think about the Empire on a regular basis. reply Jensson 14 hours agorootparent> Why would anyone care about a dead empire, after all?Because it isn&#x27;t dead culturally.When you see a medieval castle you think about medieval things, when you see Roman architecture you think of Roman things, and since you see Roman architecture all the time in the news, like every time they show the white house etc, it makes sense your brain thinks about the Romans now and then. reply nullindividual 9 hours agorootparentThe question was rhetorical. And the article does go into detail about why people like Roman things-and-stuff. reply verve_rat 13 hours agorootparentprevSee also: the Pope and the Catholic Church. reply Rebelgecko 14 hours agorootparentprevI think people find it humorous because it&#x27;s an unexpected instance of sexual dimorphism. Like a \"Men are from Mars [not Ares]\" kind of thing. reply Jensson 14 hours agorootparentSince when is making fun of sexual dimorphism a thing? I thought we stopped doing that.Like, would it be funny if men asked women how often they think about celebrity relationships and drama? People just think about different things. reply lotsoweiners 14 hours agorootparentMaybe nerds on the internet stopped doing that but plenty of my coworkers and people I meet in everyday life aren’t competing for “woke” points. reply edgarvaldes 12 hours agorootparentprevThe other day I was in a party with my wife and my friends. In some moment, we (all men) were in a corner talking about comics, movies, sports. My wife was sitting nearby, and she could hear us for 30 minutes straight talking about the same topics. At the end of the party, she asked me how were my friends&#x27; kids, jobs and family. I had no clue. She laughed at me and said \"Typical men. We women always ask for the family, the school, the kids, the life of her friends, you boys talk for hours and know nothing new about your friends\".Is it typical? I don&#x27;t know. reply genewitch 16 hours agorootparentprevthanks for the reference. I mean i could have websearched around for a while, but i&#x27;ve been asking everyone that comments in my friends group, about this topic, and i&#x27;m getting \"it was a trend\" but not where or why it started.when 1&#x2F;8th of the planet knows about a trend and i&#x27;m out of the loop... reply jjulius 15 hours agorootparentI was completely out of the loop as well, until my wife shot me a completely out of the blue text this morning asking me if I thought I could help land a plane in an emergency, and how often I thought about the Roman Empire. After I begged for context, she told me about the trend, and then about three minutes later I happened upon this thread and this comment chain was at the top lol. reply martinclayton 16 hours agoparentprevOur release tool is called \"Roderick\", as-in the Monty Python \"Life of Brian\" sketch. TBH I don&#x27;t think about the Roman Empire much apart from that, I mean, what did they ever do for us? reply edgarvaldes 15 hours agoparentprevIt&#x27;s all about the Roman Empire and World War II. The other day, while I was taking my son to school, we were talking about the Maginot Line. He knows that story better than I do, even though my son is only 8 years old. But he likes history and yes, he has a nice illustrated book about Rome. reply Ian_Macharia 17 hours agoparentprev\"I&#x27;m thinking about it right now!\" reply OldHunter69X 13 hours agoparentprevOnly a Barbarian would think of Rome any less than that frequency. reply morelisp 15 hours agoparentprevWhy would I stop thinking about something that never ended? reply throwawaycities 16 hours agoparentprevThat is one of the great ironies of the meme…Most people self-identifying that they think about the Roman Empire don’t seem to know the difference between the Roman Republic & Roman Empire (much less the period of Kings)…it’s all just the Roman Empire. reply thom 16 hours agorootparentWell, the Roman Republic had an empire so you can see where it gets confusing. reply namaria 13 hours agorootparentIf you want to get technical, the Roman Republic controlled provinces and ally states. Emperor was the title of a victorious general, and a notion of a \"Roman Empire\" is an artifact of modern scholarship. reply thom 2 hours agorootparentI don’t think there’s much difference between our concept of empire and what Polybius called “ἀρχή” in his Histories (“dominion”, perhaps). He compares Rome to Persia and yes, some smaller states like Sparta, but it’s clearly in the context of acquiring and controlling large territories. That the Roman war machine had a particularly efficient and (for the most part) inclusive manner of absorbing territories doesn’t really change the nature of the resulting entity even if we use different words. reply snowpid 15 hours agorootparentprevI havent read the article. Im still stuck at work. also there was a senate during imperial time. reply gmaster1440 16 hours agoprev [5 more] [flagged] CydeWeys 16 hours agoparent [–] HN really needs to add \"No AI generated comments\" to the site rules. I&#x27;m not interested in reading AI summaries in comments here; I come for actual discussion by real people. reply gmaster1440 16 hours agorootparent [–] I don&#x27;t see how a short AI summary dissuades actual discussion by real people. If anything, it can lower the barrier to entry and encourage more people to comment and participate, especially for longform pieces. reply the_af 15 hours agorootparentPeople who want an AI summary can get it for themselves, I think there&#x27;s no need to \"spam\" that service here, unasked for. reply pvg 16 hours agorootparentprev [–] It&#x27;s just noise, you can read the moderation side of it here:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36252547 replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article is part of a series about the Roman Republic and delves into the influence and role of the Roman Senate.",
      "Although the Senate formally lacked legal powers, it exerted control over state finance, religion-related decisions, and foreign policy via its auctoritas (Latin for authority) and political norms.",
      "The article also explores the difficulties in integrating a comparable advisory organization within the modern US political framework."
    ],
    "commentSummary": [
      "The article delves into the Roman Republic with a focus on the Senate, sparking a conversation on societal decay, historical figures, and correlations between the Roman Empire and current issues.",
      "Participants highlighted the enduring influence of Rome, its effects on varying life facets, and the ubiquitous nature of Roman Empire-related thought today.",
      "Mention is made of viral internet stories and potential for a film adaptation of the topic, although an unrelated reference to YC (Y Combinator) Winter 2024 applications is also present."
    ],
    "points": 191,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1695400736
  },
  {
    "id": 37611457,
    "title": "Learn piano without sheet music",
    "originLink": "https://jacobdoescode.com/piano-tabs",
    "originBody": "I always found sheet music way too hard to read - and I literally spent a year at a company building a sheet music rendering engine. I wanted an app that would display music like the tutorials on YouTube, but not be focused on upselling lessons etc. like most current apps, and also would let me import my own filesThis works on MIDI files. If it’s a valid midi it probably plays.Since releasing, I did add a subscription for classical music - on a theory that most normal users don’t know what a midi file is. It changed about a month ago from an up front price to in app purchases and&#x2F;or a subscription - which has absolutely tanked revenue so far - but maybe it will pick upWould love to hear your thoughts and if you have any suggestions!",
    "commentLink": "https://news.ycombinator.com/item?id=37611457",
    "commentBody": "Learn piano without sheet musicHacker NewspastloginLearn piano without sheet music (jacobdoescode.com) 192 points by jacobp100 21 hours ago| hidepastfavorite233 comments I always found sheet music way too hard to read - and I literally spent a year at a company building a sheet music rendering engine. I wanted an app that would display music like the tutorials on YouTube, but not be focused on upselling lessons etc. like most current apps, and also would let me import my own filesThis works on MIDI files. If it’s a valid midi it probably plays.Since releasing, I did add a subscription for classical music - on a theory that most normal users don’t know what a midi file is. It changed about a month ago from an up front price to in app purchases and&#x2F;or a subscription - which has absolutely tanked revenue so far - but maybe it will pick upWould love to hear your thoughts and if you have any suggestions! kashunstva 15 hours agoI’m a professional pianist; so I’m not in your target audience. There may well be some system of notation that is superior to the standard that has developed in Western music; but nothing I’ve seen matches the expressive flexibility and compactness of the way music is now notated.Experienced players read music in a way that overcomes some of the limitations that form the assumptions that are behind these alternative notation systems. Instead of looking at a measure as a collection of individual notes that must be perceived, interpreted and executed in sequence, they take it in as a chunk. (I imagine reading code must be similar.) This is why the density of traditional notation isn’t intimidating - after a while it can be read as a whole.Whether a system like this could be a pedagogical bridge to formal notation remains to be seen. I’ve encountered such bridging systems before. I’m an admitted skeptic because my orientation to this is that if you want to learn a thing, just start learning the thing. The struggle, within limits, is known to enhance learning. reply _gabe_ 6 hours agoparent> Instead of looking at a measure as a collection of individual notes that must be perceived, interpreted and executed in sequence, they take it in as a chunk.I’m not professional, but I have been playing for awhile and can sight-read fairly easily. What you said here is 100% true, and I liken it to learning to read a language. Watch how kids learn to read, they have to look at each syllable and letter and sound out each word. Eventually, after enough practice, you don’t read individual letters, you read words. Then, you begin to observe the nuance of the grammatical structure.I feel like reading music notation has followed a similar trend for myself. I no longer read individual notes, I see chords and progressions. Just like stories tend to follow a plot line, and you can predict how the story may end, music follows a plot line, and you can predict the movement. This is also why certain styles of music is so interesting! We expect the plot to move in a direction and then are surprised by the twist. This video by 8 bit music theory gives a good overview of how that can be done[0].I especially love when I’m playing through a new piece and every part of the song just makes sense. Yiruma’s music in particular feels very natural for me, and it’s an absolute joy to play through the song and have it all flow together so well.Anyways, I think a lot of people just don’t give it enough time and give up a bit too early. It’s magical when you pass that point of reading individual notes and enter into the territory of really reading pieces. I still have so far to go, but music will always be a relaxing and fulfilling hobby.[0]: https:&#x2F;&#x2F;youtu.be&#x2F;gzK1CTxxRH0?si=H3aUQo83lVl-2BQK reply heleninboodler 12 hours agoparentprevI spent decades not understanding music theory and thinking of music as a sequence of notes, and I never understood why music notation and the layout of a piano were so bizarre. It just seemed like something that we were stuck with due to tradition and lack of innovation.Ever since I started learning something about music theory (just in the past couple years... I&#x27;m far from an expert), I&#x27;ve realized that both sheet music and the piano layout are both very clever in unexpected ways that, as you point out, make the music notation both expressive and more compact than a straight timeline of linear note values, because they lean on the fact that sections of music tend to skip very predictable parts of the range of notes. They tend to use them in particular patterns that make it useful to reduce your focus to a subset of the available range at any given moment. reply djtango 1 hour agorootparentYup the more I learn music the more I&#x27;m impressed by sheet notation and realise (as someone passionate about programming language theory and also linguistics) that something that can unseat sheet notation will be a huge undertaking.Granted it does have its edge cases. IIRC it&#x27;s not great at representing complex rhythm.But what sheet notation does great man does it do well at it. Like recently have been looking at quite a few different multi voice piano pieces and the fact that using convention you can differentiate between the lower and middles voices is pretty amazing.Eg in Clair de lune the runs that are played by both hands will share the same beam to denote it&#x27;s a single voice reply patmorgan23 11 hours agorootparentprevYeah, it even goes down to the physics of harmonics.There&#x27;s this absolutely wild video by Adam nealy about how polyrhythms are actually cords. (It&#x27;s very approachable if you know just a smidgeon of music theory). Highly recommend Adam&#x27;s channel if you&#x27;re interested in music&#x2F;music theory. https:&#x2F;&#x2F;youtu.be&#x2F;JiNKlhspdKg?si=J7eaB1xH4Eo27cC9 reply coldtea 10 hours agorootparent>about how polyrhythms are actually cordsMeant chords? I&#x27;m not buying it. The commonality is very stretched (notes are ratios, and chords are several ratios together). That&#x27;s like saying \"code is actually poetry, both are based on the arrangement of alphabet symbols groupped in small blocks\". More something for a TedX talk, than something practicing composers and musicians have in mind when using either.For starters, in chords the ratios are stacked vertically (multiple \"ratio\" notes played together at once), in polyrhythms horizontally. In chords it carries harmonic information, where polyrhythms can and are just as well be played with unpitched drums and percussion. And in general they serve different purposes. You can have chords playing without any polyrhythm in the rhythm side or play monophonic lines with polyrhythms. reply wheels 8 hours agorootparentI just watched the first half of the talk, and it&#x27;s pretty interesting. I don&#x27;t think Adam Neely is actually saying they&#x27;re the same; he&#x27;s saying it&#x27;s interesting to think about their similarity. And what you actually get out of the talk is that his point is that pitch is our perception of frequency over a certain limit, and that rhythm is our perception of frequency under that limit. They&#x27;re both perceptions of frequency and the ratios of those frequencies are the defining property of both chords and polyrhythms. reply frutiger 7 hours agorootparentI haven’t seen the video (and likely will not) but there is a similar “shower thought” that vision is also energy of a given range of frequency, just like hearing. reply tomtheelder 8 hours agorootparentprevI haven’t seen the video, but I assume what it’s getting at is that if you have like a simple 5 over 4 polyrhythm and you speed it up sufficiently you’ll start to perceive it as a major third.I kind of also think that’s a little meaningless since while tempo for a beat and pitch for a tone are both sort of frequencies we perceive them completely differently. reply gabereiser 10 hours agorootparentprevYou can also play chords polyrhythmically. Timpani is a great example. reply coldtea 9 hours agorootparentYou can, but it&#x27;s optional (and orthogonal). reply amelius 11 hours agorootparentprevHowever transposing music should not have a dramatic effect on notation. Melodies that sounds the same should look the same. reply TylerE 11 hours agorootparentStrong disagree. On many instruments there is a strong memory association between the place of the note on the staff and the physical movement to play that note, Wether it be a fingering, valve combination or lip tension or whatever. reply yayitswei 6 hours agorootparentprevI agree. Even though some (most?) instruments have different shapes for each scale, notation should transcend implementation and aim for the most general representation. See: isomorphic instruments.I&#x27;ll concede that traditional music notation is the most efficient way of representing classical music. reply pclmulqdq 11 hours agorootparentprevI&#x27;m not convinced, personally. Melodies that sound the same don&#x27;t really sound the same (hitting different registers on the same instrument), and they aren&#x27;t played the same (different fingerings), so why would they look the same in notation? reply klodolph 7 hours agorootparentprevWith sheet music, transposing music means moving it up or down the staff, and changing the key signature to match, and adjusting any accidentals. reply bluGill 7 hours agorootparentprevMusic theory gives good reasons for changing keys to have a significant effect on how the song sounds. Most pianos are tuned equal temperment so you don&#x27;t get that effect, but there is a good argument for other tunings that do. (You may or may not agree, but the argument is valid) reply unc0n 15 hours agoparentprevI&#x27;m an experienced musician and this really resonates with me. It&#x27;s possible to see a scale written out in the score and know exactly what that means in terms of how it&#x27;s supposed to sound, what fingering I should use, and whether there are any \"aberrant\" notes in there that I should watch out for. The same goes for many other common note patterns. Trying to decode something like this into something that makes sense to me musically is a huge additional burden that doesn&#x27;t exist. That said, having been through the journey of being able to sight read music myself and then trying to teach it to a number of people, I agree that reading a score in real time is one of the greatest hurdles to beginner and intermediate players alike, and probably a huge impediment to many people learning to play a variety of instruments.There is one particular instance in which getting away from traditional notation can help. I have absolute pitch, and I&#x27;ve played transposing (woodwind) instruments before. The mental link between specific finger positions and specific tones &#x2F; notes on the score, is one that causes me untold issues with transposing instruments. If I could just focus on the finger positions without the distraction of the score, that would help me. I don&#x27;t think this is a common problem though. reply tomcam 4 hours agorootparent> The mental link between specific finger positions and specific tones &#x2F; notes on the score, is one that causes me untold issues with transposing instruments.Yes! I quit tenor and alto sax in favor of C melody. And I learned euphonium before trumpet so I just can’t see a Bb but call it C. Not at speed anyway. reply Blackthorn 8 hours agorootparentprev> If I could just focus on the finger positions without the distraction of the score, that would help me.Isn&#x27;t this exactly what most guitar players do? Tablature is used instead of traditional staves. reply cratermoon 7 hours agorootparentClassical and jazz guitar are written in traditional notation. Classical notation has implied positions on the fretboard - first, fifth, seventh, etc. Tablature is useful, but it is not musical notation. Its expressiveness is so limited that many tablature sites add various symbols borrowed from standard. Indeed, go on almost any guitar forum on the net and you&#x27;ll find a beginner asking about some notation found on a tablature. There&#x27;s a great deal more to performing on the guitar than knowing where to put the fingers of the fretting hand. reply nescioquid 13 hours agorootparentprevI think there might be two different basic strategies that could help you out of this:1) just work on actually transposing whatever you&#x27;re reading by a fixed interval. If you get fluent in doing this, you&#x27;ll get past your \"page says f but it sounds d\" discomfort.2) practice reading C clefs (+ octave transposition). You play a C on a clarinet in B-flat, it sounds a B-flat. So, imagine instead of a treble clef, it were a tenor clef (but 8va higher) instead. That third-space treble-clef C is now a tenor-clef B (you have to add the accidentals).In either case, it is probably matter of just getting used to it, and that means spending time with it, so no truly \"easy\" answer for you. reply unc0n 9 hours agorootparentI&#x27;m actually quite good at transposing by any arbitrary interval (by ear), and can also play music both from sight reading and from ear. The problem is I have both an instinctive link between sounds and fingerings (or keys on a piano when I play that) and between the notes in the score and the keys they map to on the instrument. Alas I didn&#x27;t encounter c clefs until rather late in my musical training (they weren&#x27;t relevant for any of the instruments I played) and by that time I didn&#x27;t have a compelling reason to practice reading scores. I&#x27;m adulthood I more or less only play solo piano so transposition is a moot point. reply chimpansteve 11 hours agoparentprevAs a kid, I learnt violin and trombone to a very high orchestra level standard, and could read sheet music from a very early age. I then moved on in my late twenties to guitar, bass and keyboard in a rock band, and never looked at a piece of sheet music again in my life, and would have no idea how to translate musical notation to those instruments.I know people who cannot play a tune without sheet music. I know some of the most talented musicians on this earth who cannot read sheet music. There is no right and wrong to this. It&#x27;s what works for you.I do think some form of formal music theory training is an absolute cheat code when it comes to playing multiple instruments, or just jamming and playing by ear though reply tkgally 9 hours agorootparentI’m similar to you, and I agree with your points completely.I learned to play classical piano as a child and teenager and got reasonably good at it. But as my interests expanded to music that is normally not written down, I had less need to read music notation. Fifty years later, I still play the piano every day, but the only reading I do is occasionally looking at the chords and melody lines for jazz standards.The music theory I learned when young has been very helpful over the years, and it would have been more difficult for me to absorb it then without using standard music notation. But I no longer think about music in terms of notes on a stave; I have gradually developed my own mental representation of it.I still listen to classical music, and I do wish that I had acquired and maintained better sight-reading skills so that playing it would be a pleasure for me now rather than a chore. reply singingfish 6 hours agoparentprevMy former piano teacher tells me that these non-traditional systems enable people to learn specific stuff fluently and quickly but it engenders various habits that are difficult to unlearn, and limits people&#x27;s development.Personally I believe there&#x27;s no substitute to doing serious amounts of repetition of stuff that you&#x27;re trying to learn to get it fluent, and using your ears (and on the piano to a lesser extent eyes) to get it. Personally I&#x27;m happiest when I&#x27;m able to step away from the sheet music, but I also read to an intermediate level.It turned out what got me much more fluent with sheet music reading was copying out some scores that were a little bit of a stretch for me, at the time, due to having multiple performances of same music at short notice.For most music I play (I&#x27;m on sax in a couple of street bands) I much prefer to have internalised the music and be able to operate from memory based on knowing the key and some intuition of the harmonic structure. In fact if I know a tune too well the sheet music starts to throw me if I try reading and playing.Intuition is important. The fact that I already had good intuition on the sax, but that it was a struggle on the piano is what made me stop piano lessons because getting better at piano was eating in to my getting better at the sax time too much. reply djtango 2 hours agoparentprevHa when you described reading things in chunk I started wondering if you were a programmer.I found that once I learned coding I started to internalise and conceptualise things about music I didn&#x27;t before. The structure of music became so much more concrete and I also realised that not only are musical chunks (eg scale or arpeggio) an abstraction on paper but so too is the brain-muscle instruction to execute it. In some of the intermediate Beethoven and Chopin where it starts to get spicier you don&#x27;t have time to think note by note... reply vidarh 3 hours agoparentprevI&#x27;m a very mediocre pianist, and my take would be that I&#x27;m not looking for a bridge because I know I&#x27;ll never spend enough time to be good and I don&#x27;t care about getting good, but I enjoy sitting down and playing (butchering) some pieces now and again. So if I found something simpler that helped improve my playing with minimal effort that&#x27;d be good for me even if it actively hampered any effort to get good.I don&#x27;t know whether or not this is it - judging purely from the screenshots I think it&#x27;s too pared back and austere, e.g. making it harder (for me at least) to see expected duration of a note from length alone, but I love that people are trying. reply jacobp100 1 hour agorootparentI&#x27;d love suggestions if you have any! The note length is maybe not possible, just due to the fact most midi files don&#x27;t encode it very well reply whartung 11 hours agoparentprevFar from left field related. > Instead of looking at a measure as a collection of individual notes that must be perceived, interpreted and executed in sequence, they take it in as a chunk.This is how Morse code is done. Not as individual letters, but as the sound of the stream. You don’t listen for letters per se, just rhythms of the sounds and patterns of letter combinations and words. reply shadowfoxx 9 hours agoparentprevI&#x27;m someone who&#x27;s quite interested in learning to play music - took some classes in highschool (but my focus was the visual arts which is why I struggle to find time amongst my other hobbies, I&#x27;ll get there)I always wished that sheet music was rotated 90 degrees. The more I hear from musicians the more I think maybe that&#x27;s not good... but there is something to be said about, \"with experience you&#x27;ll just get it, it become natural\" especially with a system that&#x27;s been around for hundreds of years... reply klodolph 7 hours agorootparentThere are some musicians out there who rotate the sheet music 90 degrees. These people exist. But I don&#x27;t see a particular reason why one orientation should be much better than the other—maybe your eyes are better at following horizontally or vertically. The standard layout matches instruments like the flute, the 90 degree rotated version matches instruments like a piano. reply Madmallard 8 hours agorootparentprevhumans spent hundreds of years figuring out what the best option would be considering this isn&#x27;t something that required the technological revolution reply mdorazio 8 hours agorootparentBullshit. The world is absolutely packed with standards that are standards because of nothing to do with being \"the best\". Perfect example: the imperial measurement system. Another example: logographic writing systems. Another: qwerty keyboard layout. Etc. Just because a thing is accepted today doesn&#x27;t mean it&#x27;s the best. reply frutiger 7 hours agorootparentOverall a great point, but the world is not packed with the Imperial system, almost everyone uses Metric. reply snarkypixel 10 hours agoparentprevI think I&#x27;m closer to the target audience as I usually learn either by \"ear\" or by watching someone play the song. Actually, what I prefer is looking&#x2F;finding the chords first, and then I fill up the melody and everything in-between. So, an app like this is very helpful. My only feedback is I find the UI piano at the bottom of the screen hard to read without black keys reply dehrmann 6 hours agoparentprevSo it&#x27;s a bit like the qwerty keyboard? Sure, there are better layouts, but it&#x27;s good enough, and the benefits from switching aren&#x27;t worth it in exchange for universality? reply jrockway 13 hours agoparentprevLooking at the screenshots, I think this notation was chosen because it&#x27;s easy to generate from MIDI files. MIDI files just say what note is being played, when it starts, and when it stops. Sheet music is much richer than that (as you&#x27;ll note if you&#x27;ve ever used a tool to turn MIDI into sheet music), so anything that takes MIDI as an input is going to be terrible if it produces traditional notation as output. (I bet AI could help a lot here, though.) reply simonjgreen 12 hours agorootparentVery importantly, just to append, midi start note also contains velocity, and midi also contains and control changes. reply bluGill 6 hours agorootparentprevThe notation looks like what a player piano would have used, so predates midi by 100 years. reply RogerL 10 hours agoparentprevI want to expand on this. Not only do I agree with what you wrote, but this app is trading access to millions of available sources in a very well known writing system to one more or less unique to this app. That&#x27;s a terrible investment for anyone who wants to do more than learn 1-2 favored songs.If you need to sight read (and as rock&#x2F;pop&#x2F;jazz people point out, you don&#x27;t have to for many genres), then you need to sight read.There are so many other virtues to sheet music. Look at the cover image. I can see a few notes. I can see vastly more notes in sheet music. I can easily evaluate if the piece is playable, I can scan and look for broader patterns. I can see that a bass note is being held for 8 measures (and I may choose to repeat it at some point). I can look ahead quite a bit. I can understand the repeat structures - don&#x27;t gasp, but you don&#x27;t have to take repeats, or you can repeat more times than written, especially with 20th+ century music, where you are often expected to do things like choose your own ordering of measures or blocks of measures. There are fingerings. I can see if the composer is writing out finger pedaling explicitly (Couperin normally does, Bach normally doesn&#x27;t). I can see the pedal markings, general contours of dynamics. I can see the trills, etc., which are often just suggestions rather than hard requirements. I can see the meter, meter changes, keys, key changes, accidentals. I can see a big scary chord coming up and spend a bit more time looking at it while I play a few measures behind. I can see that Bach is repeating a phrase a 5th down, or inverting it, or reversing it. I can see the difference between passages meant to be played in time, and fioritura type writing.I haven&#x27;t used these piano roll systems so there are undoubtedly some things that are nice about it for an experienced player that I don&#x27;t know about, so that paragraph is one sided. But that one side is very important - I&#x27;d loathe to go without them, and can&#x27;t imagine I&#x27;d ever trade them for whatever advantage the piano roll might bring. After all, a player can take a sheet of paper Chopin wrote, produce that music at a more or less performance level. So it gives you about everything you need. I could imagine a current composer might find something more expressive about the piano roll (maybe expressing note durations not evenly subdivided by 2 or 3).I suspect there is something neurological happening that stops some people from sight reading well, just like some people struggle with text. I&#x27;ve read accounts of people trying for years, with seemingly good practice techniques, still struggling.So things like this, synthasia, etc., seem to have a niche. But in general, I suggest, think about someone proposing an app that instead of displaying printed text output it sonically. Great boon for certain situations or people! Undoubtedly someone is using one to read this very post. But a terrible replacement for reading in general.If a six year old was relying on screen readers because reading is too hard to learn, after testing for dyslexia and vision problems, you&#x27;d urge them to make the effort; the advantages of reading text vastly outweighs the 1st grade difficulties of learning to read (yes, that time span will differ by language and writing system, not the point). Literacy is empowering, and arguing that the auto mechanic down the street can&#x27;t read yet makes a good living is probably not a convincing argument to not teach a child to read.I learned to sight read at age 4-5 with a plastic brain (I recall my mother having to teach me the letters a-g, and how to write them, for example), so I may underestimate the difficulties of learning later in life. But if you are in a situation where some kind of notation is helpful (again, not all are), learn standard notation!edit: I thought of a counter-example. Say you play in a band. You can record your output to midi, and then share it with others. You can quantize midi and turn it into sheet music, but chances are you playing is not rhythmically exact. Sight reading that sort of thing is painful (notes carry 1&#x2F;16th note into the next measure, that sort of thing), and I imagine a piano roll would often be easier. reply keithalewis 7 hours agoparentprev> if you want to learn a thing, just start learning the thingThis. After you have learned things feel free to come up with something others might want to spend their time on learning. reply yieldcrv 14 hours agoparentprev> There may well be some system of notation that is superior to the standard that has developed in Western music; but nothing I’ve seen matches the expressive flexibility and compactness of the way music is now notated.I like Ableton&#x27;s Push system and associated sequencing software. I think it is superior.Its an LED grid and matrix, but primarily within that grid it highlights all the C notes for every octavefor someone that doesn&#x27;t have the discipline to already sense them, there is no need to ever gain or hone that sense anymoreits hard to describe, as the combination of hardware and software is quite comprehensive, but in comparison it really does seem like this just wasn&#x27;t revisited for the last 700 years. the matrix is for playing and reading. whereas these would be separate things in analog devices and things that simulate them. hm, lines blur with the term analog. I mean in comparison to traditional physical instruments. reply squeaky-clean 12 hours agorootparentI love me a matrix sequencer, but they don&#x27;t easily convey things like dynamics, or tempo changes, or key changes. It also requires a score for an 88 key piano be 88 rows tall. A 4 bar rest and 64 16th notes also all have the same length in the sequencer, which is some times helpful but often not helpful.The Ableton Push sequencer is also designed with using it in a scale-only mode in mind. It gets a fair bit uglier if you enable chromatic mode. reply Johnythree 7 hours agoprevAfter reading this thread, I&#x27;m amazed that no one has mentioned the work being done on alternative keyboards (and on alternative music notation).The main point is that the design of the piano has held beginners back for centuries, and likewise has hindered the development of music notation.Unfortunately the design of the piano keyboard requires that fingering change when you change key. The guitar doesn&#x27;t do this, neither does the button accordion.Whatever, a number of keyboards have been developed where the fingering does not change as you change key.Start here https:&#x2F;&#x2F;www.le-nouveau-clavier.fr&#x2F;english&#x2F;and https:&#x2F;&#x2F;musicnotation.org&#x2F;wiki&#x2F;instruments&#x2F;isomorphic-instru...Particularly the https:&#x2F;&#x2F;musicnotation.org&#x2F;wiki&#x2F;instruments&#x2F;wicki-hayden-note...But please start searching and reading on the following topics:Isomorphic Instruments, the Xenharmonic Keyboard, the Janko Keyboard, Linnstrument, Lumatone, Dodeka, Chromatone, Balanced keyboard.And for just a glimpse of an alternative music presentation:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=NQ7LkWCzKxI reply YeGoblynQueenne 37 minutes agoparent>> Start here https:&#x2F;&#x2F;www.le-nouveau-clavier.fr&#x2F;english&#x2F;That is an absolutely horrible idea. It might seem intuitive at first (\"Just alternate keys!\") but its impracticality becomes immediately apparent and is directly acknowledged in the site you linked:>> There’s just one drawback: the monotony of such an arrangement. How can we find our way on such a keyboard? Recently, the French musicologist Laurent Fichet remarked: “This system would certainly be much more rational than the keyboard of today, but one may wonder how players would locate the different notes with such a systematic and uniform layout.”The French version of the article then goes on to suggest many variations of ways to avoid being lost on a keyboard without any obvious pattern (the English version only lists one, briefly). Some include coloured keys.It is beyond obvious that the simple, intuitive solution proposed at the start produces a cavalcade of complications none of which has a simple solution.Not to mention: despite what the linked site suggests, learning how to position your fingers on the keyboard is the least of your problems when you learn the piano, just as learning to touch-type is the least of your problems when you learn how to code.I vote no. reply jerpint 1 hour agoparentprevThe symmetric keyboard seems “as obvious” as using tau instead of pi as a universal constant, but then again I don’t play piano reply 4gotunameagain 4 hours agoparentprevThe last link is very interesting, but it doesn&#x27;t look like a sheet music alternative, since it only gives you the chord progressions and not the constituent notes.Also, good luck printing it on paper without the animations :) reply zharknado 12 hours agoprevI want to try to articulate an idea I see represented elsewhere without dismissing the value of what’s being offered here.There are many comments to the effect that this is a crutch that will inhibit future learning. I agree with that assessment.I also agree that such a tradeoff is probably fine for many people, depending on their goals.I studied music composition in college and then worked in adult world language curriculum. Perhaps a useful analogy is the use of Romanization to teach world languages to native English speakers (romaji, pinyin, etc.)For languages like Chinese (Mandarin, Cantonese, etc.) where there is (virtually) no phonetic information in the writing system, it’s just too dang hard for a lot of people to make the leap to pronouncing characters as they are reas by natives. Pinyin or its equivalents are an “inauthentic” but valuable tool, but eventually you have to discard it to progress.With straightforward phonetic languages like Korean, it’s actually counterproductive to try to bridge people to familiar symbols, because there’s very few resources for the learner until they start mapping sounds to Hangul.That’d be my argument—-if you find you can’t easily make the leap to reading music and just want to get playing, sure, use this. But know that there’s a whole world of communication out there that you’ll be missing until you abandon this simplified representation and cross the full chasm. reply jhbadger 4 hours agoparentThis whole argument in favor of sheet music reminds me quite a lot of the defense of Chinese&#x2F;Japanese characters. Yes, there is a long glorious tradition of using them, but assuming that they are the optimal solution and that any exploration of better methods is wrongheaded seems unsupported. Korean used to be written in Chinese characters, as was Vietnamese, Korean developed its own superior phonetic replacement for the characters (Hangul) and Vietnamese is now written in the Roman alphabet (originally for the convenience of French colonizers but independent Vietnam shows no desire to go back to characters). reply openquery 16 hours agoprevI&#x27;ve been playing piano for a few years (no teacher, on and off) and have always been curious about the topic of sheet music. When you&#x27;re first learning it&#x27;s very painful. The notation isn&#x27;t that bad, sharps, flats, time signatures etc - that part is ok. What _is_ difficult is corresponding a position on the staff to a physical note on a keyboard, especially when you have a treble clef and a base clef.However over time it becomes easier and easier - and then you wonder is sheet music somehow optimal or is it &#x27;good enough&#x27; and has withstood the test of time (also accounting for the fact that there is an enormous corpus of existing sheet music).The question regarding this app (which looks awesome) is, is this format for reading music better than sheet music at the expert level (for professional musicians). And if not, how can we get that 10x improvement to make the switch from sheet music to something better. reply phlakaton 14 hours agoparentIt is not.I am, once again, asking people to understand that piano roll notation is no substitute for traditional notation when it comes to performance, among many other things. reply Aeolun 8 hours agoparentprev> and then you wonder is sheet music somehow optimal or is it &#x27;good enough&#x27; and has withstood the test of timeI suspect traditional sheet music is like the the qwerty keyboard.At this point it’s momentum is so large that it’s impossible to stop. reply klodolph 7 hours agorootparentSure, if traditional sheet music is the qwerty keyboard, then this new version is a 2x expanded keyboard, with separate keys for all the capital letters.I think there’s no denying that the particulars of the current system of musical notation is more or less an accident of history. But it’s also a local minimum—if you want to improve on it, you’re probably going to have to come up with radical changes. reply Aeolun 5 hours agorootparent> if you want to improve on it, you’re probably going to have to come up with radical changesYeah, that’s sort of related to my point. Like, Colemak and Dvorak are theoretically (and practically, with enough practice) better than qwerty, but they don’t need to just be better, they need to be so much better that people will throw all the investment in qwerty away.Sheet music feels the same. reply userbinator 5 hours agorootparentprev...and a traditional piano is like a keyboard with no markings on the keycaps. reply strunz 16 hours agoparentprevIt&#x27;s even more frustrating on guitar where the literal same note in the same octave appears all over the fretboard. You have to figure out all the notes nearby to figure out what position you should be in. Even with years of experience I find tabs faster reply b450 15 hours agorootparentThe flip side of this is that chord shapes (in terms of hand shape, not intervals) are constant on the guitar (assuming no open strings). Learning piano after guitar, I was intimidated by the fact that – for example – an Am and Bm had different shapes, whereas on the guitar it&#x27;s just the same shape transposed up the neck.Anyway, I&#x27;ve noticed some music youtubers can read and write midi notation just as fluidly as sheet music. Which can result in some fun shenanigans[^1][^1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=sy_0mMcj0Q8 reply kzrdude 13 hours agorootparentThere&#x27;s a lot of same shapes on the piano as well.And the differing shapes are a bit like how A major and C major have different shapes on the guitar isn&#x27;t it, for practical reasons you don&#x27;t use the same shape for those two. reply kzrdude 3 hours agorootparentWith the clarification that the same shape of the C major chord on the piano, when you move it up through the scale, the same shape produces all the diatonic three note chords of the scale, i.e C, Dm, Em, F, G, A, Bdim, C etc. reply warcher 13 hours agorootparentprevIt might be, but it also might not. If you&#x27;re just cowboy chording, sure, but if you&#x27;re playing chord melody you&#x27;ll find the chord you choose is highly contextual based on what you&#x27;re playing and where you&#x27;re going. An Am chord is a continuum of notes going up or down the neck A-C-E (G?) over and over-- wherever your hand sits, there&#x27;s an Am available to you. It just might sound better (or more interesting!) or play easier to grab one set of A-C-E versus another. reply rtsil 11 hours agorootparentI think the parent meant that those voicing are still the same when transposed all over the fretboard. E.g. the first inversion of a V7 has the same shape for all the notes horizontally. To go from A7 to B7, you just move two frets. And if you move vertically, the shape is slightly changed, but still recognizable enough.A guitar has to be the easiest instrument for transposition (or maybe it&#x27;s just the one I&#x27;m most comfortable with!). reply RogerL 10 hours agorootparentUntil you reach the B string. A shape that works on strings 4&#x2F;5&#x2F;6 does not work on 1&#x2F;2&#x2F;3. This is because G->B is 4 half steps, the rest of the strings are 5 half steps apart. So you need 2 forms for closed chords. reply rtsil 8 hours agorootparentThen you move that note a half-step. The rest is the same. And actually, if you use drop-2 voicing, there are 3 forms because of that half-step, but still the overall shape is pretty much the same. You really need to remember one shape, and then adjust it accordingly. reply wizofaus 14 hours agorootparentprevThere&#x27;s no standard Midi \"notation\" that&#x27;s human-readable&#x2F;writeable AFAIK - even written out in, e.g. hex, I would be flabbergasted if anyone could perform from a displayed Midi file. The YT video appears to show a piano-roll type display (common for DAWs etc.), nothing to do with midi (which doesn&#x27;t even have the concept of notes or note lengths at all). reply jacobp100 14 hours agoparentprevI think back when music notation was being actively iterated on, you had to convey all the information possible, because it’s not like you could share a recording. Things like guitar tabs - which typically erase timing information - only work because who ever reading them has already heard the song and know what it’s meant to sound like reply bumby 14 hours agorootparentAren&#x27;t guitar tabs typically combined with abbreviated notation to show the rhythm? No lettering of notes, but just an \"X\" associated with half-notes, quarter notes, etc? reply jacobp100 14 hours agorootparentSometimes. Guitar Pro had a text format that could output them - but it&#x27;s not frequently used. Bar lines are encoded pretty reliably, which is at least some timing information reply warcher 13 hours agorootparentprevThere&#x27;s always been a tendency towards shorthand-- medieval manuscripts elided certain parts of the harmony&#x2F;accompaniment because it&#x27;s just known to be there by the musicians of the day. Same for jazz lead sheets-- they give you the melody and a general sense of the harmony, with the understanding that specific voicings and reharmonizations will be left to the discretion of the performer in the moment. reply yongjik 9 hours agoparentprevIt&#x27;s really not, not even for professionals, but anyone playing at a decent hobby level. Consider, for example, Beethoven&#x27;s Sonata Pathétique (accessible to many amateurs), starting with Grave (very slowly) and changes to Allegro.Either you start with an impossibly long bar that covers the screen, where you can&#x27;t see how the phrase flows into the next notes, or you later get to a dozen identical ultra-short bars mashed on top of each other.And that&#x27;s just one problem. reply airstrike 16 hours agoparentprevThis reminds me of this excellent video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=b9IkpUYlOx8Can we get this guy to play the Super Mario World ending theme with the notation from TFA? reply openquery 9 hours agorootparentThe nyan cat improvisation is even better imo. reply RobertRoberts 15 hours agoparentprev> What _is_ difficult is corresponding a position on the staff to a physical note on a keyboard, especially when you have a treble clef and a base clef.This is my biggest issue. I played piano for years and still struggle with this. (though I never excelled, and started young)Any suggestions on a simple way to overcome this issue? reply wizofaus 14 hours agorootparentEven experienced pianists would have trouble sight reading music that uses an excess of ledger lines - i.e. we can&#x27;t accurately judge what note is intended just by estimating its vertical distance from the staff. But notes on the staff (or 3 or fewer ledger lines off) are rarely an issue - it&#x27;s really just familiarity (I struggle reading off unusual clefs too). Which is why I don&#x27;t think any sort of piano-roll based notation system is ever going to become the norm for performers, because it essentially does require accurately judging which key to hit, when to hit it and how long to hold it for just by its spatial position on the score. reply holri 16 hours agoprevThere has always been a very old method to learn music without sheet music. It is called playing by ear. It is incredible that we have a word for that. Because nobody is saying he is learning to talk by ear. Because talking and making music is an acoustic thing, and the natural thing is to use primarily your ear for that. The eye can be helpful, be it sheet music or a midi visualisation like this app. But an eye can not hear music. reply analog31 9 hours agoparentThere&#x27;s more to music than an \"acoustic thing\" because of processes such as composition, arrangement, rehearsal, and so forth. Whether those things are necessary or useful depends mostly on what genre you&#x27;re interested in playing.Some genres, like rock and folk music, involve little or no written material. There are certainly players who have never read music from a sheet. I attend a week-long folk music camp every summer, and there&#x27;s no sheet music. I perform jazz \"standards\" in small ensemble settings entirely by ear.But I also belong to a 19-piece jazz ensemble, that plays from sheet music. It&#x27;s really not practical to expect the players to figure out their parts by ear and perform them from memory. Requiring that would greatly reduce the scope of our repertoire, and the band&#x27;s ability to attract players. Sheet music literally expands the artistic palette of the composer, to the delight of both the performers and the audience.Sheet music allows students to study and work through a large amount of literature, quickly. My kids are both studying music in college, and the amount of material they&#x27;re exposed to every week is mind blowing, in lessons, class, rehearsals, and even getting together to play for fun.Having been a part time working musician for a few decades, I&#x27;ve also noticed that sheet music is a band management tool. My band would be incapable of performing if we couldn&#x27;t call in one or two substitutes per performance, some of whom are sight-reading on the bandstand. Same deal for a classical orchestra. In a smaller band that I play in, the bandleader is composing most of the material, and we scribble edits and rehearsal notes in our parts as we collaborate on refining each piece.Up through the 1960s or 70s, the instrumental parts for most popular music was recorded by professional musicians who were working from written material, even if they made sometimes dramatic changes to the songs. This was just the most efficient way to manage a studio date. The touring musicians could always learn the songs by ear later on. There are stories of bands, where the first few dates of each tour still sounded rough as the band was coming up to speed on material that had already been professionally recorded. reply holri 6 hours agorootparentI do not doubt the usefulness of written music, as I do not doubt the usefulness of written speech. But you have to walk before you run. Often people play music by eye before they can really hear. Written music is a useful tool, hearing is the essence of music. reply layer8 15 hours agoparentprevThe problem with this is remembering what you want to play, for pieces of any length and complexity. The comparison in that case is not talking, but reciting a long poem&#x2F;article&#x2F;novel. reply utexaspunk 14 hours agorootparentI mean, I can sing or whistle any song I can think of -surely thousands of tunes- without thinking about what I need to do with my lips. That same mechanism that connected tune in head to lips and mouth can also connect tune in head to fingers on piano with enough effort. reply bumby 13 hours agorootparentI think, maybe to the OPs point, that would require you to either 1) remember the tune perfectly to recreate it, 2) or to have a recording that you can continually reference. #1 is still unreliable and sheet music was created when #2 was unavailable.I&#x27;m personally envious of those who can play by ear but have found reading music to be easier to learn by comparison and more precise. reply holri 7 hours agorootparentI learn by sheet music and ear. Ear is by far more precise because of the severe limitation of musical notation. As Mahler said: The essence of music is not in the notation. reply Joeri 14 hours agorootparentprevI’ve been learning piano for over a year gradually learning more and more pieces like that, and I’m starting to notice a limit to memory. The basic melody is easy to remember as you point out, but piano music often has multiple things going on at once, and it gets harder to keep track of all that in your head. reply holri 6 hours agorootparentThe best piano players in the world play by memory whole concerts evenings with incredible complex and hard to remember music like JS Bach. They play hundreds such of gigs a year reliable with a very big repertoire. reply vixen99 4 hours agorootparentAnd of course, very often not only their own parts but to varying extents, those of their fellow musicians if they&#x27;re not playing a solo composition. reply holri 6 hours agorootparentprevYes the eye can be useful as I said, but it is not the primarily thing to use to learn music, like a lot of people and maybe app programmers think. I think a lot of bad music comes from not using your ears to full extent. reply tredre3 15 hours agoparentprevLearning by ear can be more fun and is easier to some. It is indeed a more natural process; hear something -> replicate it. But, unless you&#x27;re just playing alone or jamming with friends, not being able to read sheet music is a real hindrance when it comes to collaboration. reply wizofaus 14 hours agorootparentYou&#x27;d think, but I&#x27;d suggest the bulk of collaborative music making throughout human history was done without notated music. But it&#x27;s undoubtedly a massive timesaver if all the musicians going into a collaborative session know what they&#x27;re supposed to play ahead of time. I certainly can&#x27;t imagine it being possible to perform something like a Mahler symphony or Wagner opera without the vast majority of performers being competent readers of sheet music. reply Fervicus 15 hours agoparentprevIs this something you have learnt? If so, any suggestions how to go about learning music this way? reply analog31 9 hours agorootparentI learned by playing along to the radio. This was in the late 70s and early 80s, and I still remember a lot of the \"classic rock\" repertoire for this reason. It can help to have a teacher give you a head start on easy songs before diving in head-first, and also, learning your way around your instrument independently from ear training.You develop a reflexive connection between your ears and your hands, so the signals flow through your spinal cord and reptilian brain, while you&#x27;re thinking consciously about the higher levels of musical structure and what&#x27;s going on around you. reply wizofaus 13 hours agorootparentprevPractice. Trial & error. Playing along with the recording. I still do it regularly and it can often take a few goes to get all the chords just right, even with the relatively simple tonal&#x2F;rhythmic language of most pop music. reply vcg3rd 20 hours agoprevI can play piano, trumpet, and trombone, but hardly ever do anymore. I have been able to read sheet music since I was 8.If the whole concept of this confuses me, and it does, it may confuse people who are eager to learn and get playing (without doing endless scales) and don&#x27;t read sheet music.I have no idea what tabs means in this context, though I am vaguely familiar, I think, with it as a guitar term (which you or a commenter came from).Looking at the graphics on the site (I don&#x27;t use Apple) gives me no clue how the notes for each hand are displayed \"according to how they look on a keyboard.\"What am I missing? Will someone who uses Apple, can&#x27;t read sheet music, has never played any instrument and wants to learn how to play piano be able to figure it out within app tutorials? reply solardev 20 hours agoparentLooking at the screenshots, it reminds me of Guitar Hero &#x2F; ROCK Band on like ultra hard mode, maybe? reply colonCapitalDee 16 hours agoparentprevSee https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=e2YF34XlfzU reply karmakaze 19 hours agoparentprevThe layout is a rotated & mirrored version of that commonly used on DAWs (Digital Audio Workstations) so it certainly makes sense to professionals. reply wizofaus 14 hours agorootparentIt&#x27;s just a vertical piano roll (in fact that&#x27;s the typical orientation of physical piano rolls - DAWs typically rotate them 90 deg as we&#x27;re accustomed to the concept of time being the horizontal axis). reply singleshot_ 14 hours agoparentprevIf someone described to you how to play d above middle c on a trumpet by saying “1 & 3” that would be pretty close to guitar tablature. Instead of reading a score, they show you what frets to hit. reply ShamelessC 12 hours agoparentprev> I have been able to read sheet music since I was 8. If the whole concept of this confuses me, and it doesIt’s been my experience that most people who are fond of sheet music learned it at a very young age.Or perhaps I’m just stupid? I’ve tried several times to learn sheet music in my 20’s and it is brutally difficult. Guitar tabs? Easy. Chord charts? No problem. Sheet music? Go fuck yourself!What is it with the musicians in the comments here having _zero_ awareness? Sheet music is probably great! Sure, fine. But to claim that OP’s idea or even YouTube tutorials are outright not a good idea is laughable and tone deaf.Not everyone’s folks bought them a Steinway and piano lessons at age 5-13 (the age when humans can magically pick up on absurdly difficult concepts with relatively little effort). reply reikonomusha 4 hours agorootparentChildren have to put in the hours, maybe the same or slightly less than an adult does, to learn to read music. A 9 year old will need to practice reading and playing daily for at least 3 years before they can kinda sorta (sight-)read through beginner material with some facility. Most (middle-class with supportive parents) children who are learning to play an instrument benefit from having the time, space, and energy to do this as a part of their ordinary schooling routine. This is of course in contrast to many adults who have to attend to work, family, and other life things.I started learning to play music as an adult with zero training as a child, and in my observation, adults (such as myself) don&#x27;t actually have a problem learning sheet music, so long as they&#x27;re comfortable practicing reading for several years daily, just like a child would. I&#x27;m several years in with daily practice, and I can work my way through sight-reading early-intermediate classical repertoire, albeit slowly.Adults, at least those with the privilege of learning music, are usually already quite literate and perhaps even quite formally educated. Moreover, said adults also have a strong conception of music—their ears are good and attuned to their preferred styles of music. To many such adults then, it feels agonizing to start learning to read, and dedicate oneself to the pursuit at a child-level for many years. No doubt plasticity is a factor, but I genuinely think it&#x27;s grossly overstated. reply balfirevic 12 hours agorootparentprev> I’ve tried several times to learn sheet music in my 20’s and it is brutally difficult.What do you mean by \"learn it\"? Just being able to decode what notes are supposed to be played and how long they should last from sheet music, given no time limit? Or doing it in near real-time? reply Aeolun 8 hours agorootparentIs there any point to learning to do it not in real time? reply balfirevic 8 hours agorootparentWell, of course. I can only do it pretty slowly, and I can still learn songs, intros, licks etc. by finding sheet music online and spending time with it. Isn&#x27;t that pretty obvious? reply Aeolun 5 hours agorootparentIsn’t that essentially the same as memorizing the notes for the whole song?I dunno, I guess it’s useful, but if I were trying to learn to read sheet music it would be so that I could pick up and play. reply navane 10 minutes agorootparentI&#x27;m pretty fluent in reading sheet music. Still, for most songs the process is figuring out what notes to play in sub realtime, then slowly speeding up where both reading and fingering are limiting my speed. Then, as I \"know\" the whole song, looking at the sheet music helps my fingers remember which notes come next—together with muscle memory. And here sheet music notation shows its strength. At this point I don&#x27;t see individual notes, but groups of notes, both in time and in harmony, and because I see them as groups at once, my sight reading can keep up with the song. But that takes practice for each song. reply ShamelessC 11 hours agorootparentprevThe latter, obviously. reply beautron 6 hours agorootparentPianists call real-time reading \"sight-reading\", and it&#x27;s not what pianists usually focus on. Even the most skilled pianist is probably not going to sight-read a Bach fugue (or be satisfied with the result).The more common way to read music (at least in terms of the large and marvelous classical piano literature), is as part of a careful process of studying. You read to learn and understand the music, but the reading doesn&#x27;t need to be real-time (it normally isn&#x27;t, when learning a piece).Real-time sight-reading is its own special skill, which you can practice for its own sake. But it&#x27;s nowhere near as important as the non-real-time learning process mentioned above. I got pretty good at sight-reading when I worked as an accompanist, but I still hate it: It&#x27;s not how I like to learn a piece. (And the music I find most interesting [like Bach!] can&#x27;t even really be learned that way). replyduped 16 hours agoprevOne problem I see with your design is that there&#x27;s no way to deal with rubato, and presumably you can&#x27;t alter the tempo on the fly as you&#x27;re playing.The problem that sheet music solves is providing a static notation that can be read non-linearly for a dynamic piece of art that must be played linearly.There&#x27;s also no way to represent dynamics, as far as I can tell? The MIDI file won&#x27;t give you that information.Similarly unless you support MIDI 2 clip files (to my knowledge, no one does yet) you&#x27;re also missing the key signature information, which is kind of important (otherwise the notes have no meaning - you need to infer their function from context, which is ambiguous) reply jacobp100 16 hours agoparentMidi actually supports a lot of this. You can change the tempo on the fly, and each note has a velocity that&#x27;s effectively your dynamicYes - there&#x27;s no key signatures. It&#x27;s something I may add in the futureDon&#x27;t forget - most people who use this app don&#x27;t learn a lot of this stuff. They just want to play reply duped 15 hours agorootparentMIDI supports neither. It supports an encoded tempo change, there is no way for you to read a MIDI file back at the pace a player wishes to play using just the MIDI file. Velocity is not the same thing as dynamics, it represents the particular force applied to a key at a moment in time but cannot represent change in dynamics over time (or even leave room for interpretation).The thing is that if you want to play you need to learn some fundamentals first. A keyboard isn&#x27;t a just slab of buttons to push at particular times. reply Aeolun 7 hours agorootparent> A keyboard isn&#x27;t a just slab of buttons to push at particular times.Have you ever played any beginner songs? That’s literally what they are. reply reikonomusha 4 hours agorootparentMost good classical music teachers will instill, as early as possible, that piano isn&#x27;t just hitting buttons at particular times. Even music like Three Blind Mice or Mary Had A Little Lamb will be augmented with some instruction on how to play it musically, such as balance of the hands and some phrasing. Of course, at this level, one wouldn&#x27;t expect mastery of these ideas, but one would certainly be exposed to them. replymasukomi 20 hours agoprevon the one hand, yay. Tabs have made learning guitar stuff incredibly accessible, and dealing with the separate hands of the piano and separate clefs is a PITA. On the other hand... ugh. We&#x27;ve successfully churned out generations of musically illiterate musicians. We&#x27;ve also made it really hard to find the sheet music for a piece instead of the tabs, and the tabs are lacking in SO MUCH information. reply klodolph 7 hours agoparentI think the real problem is that people are going for free tabs, and the free tabs online are just kinda awful. They don&#x27;t just miss information, but they also contain outright errors.If you’re serious about learning a piece, so you can perform it, you’ll want to transcribe it yourself, buy some better tabs, or buy sheet music. Or do some combination of those things. It’s not a problems with tabs themselves, but the general low quality tabs you see in ASCII art from random websites.(For what it’s worth, I think it’s really easy to find sheet music for popular music. Sometimes too easy… I search for some pop song and get a couple dozen different arrangements for different instruments at different levels. The catch is that you have to pay a couple bucks.) reply duped 16 hours agoparentprevNotation is always lossy. And for what its worth, for the entirety of human civilization music has been an aural tradition passed down from teacher to student, and primarily learned by ear. The notation is just whatever is most convenient to people for taking notes at the time. reply vixen99 4 hours agorootparent> The notation is just whatever is most convenient to people for taking notes at the time.That &#x27;at the time&#x27; now seems to have extended to around 400 years (in Western classical tradition for instance, from pre-baroque). The evolution of another type of keyboard demonstrates that convenience is not necessarily the watchword.https:&#x2F;&#x2F;www.thoughtco.com&#x2F;history-of-the-computer-keyboard-1... reply avtar 20 hours agoparentprevThom Yorke, among probably other great musicians, couldn’t read sheet music. reply zengid 19 hours agorootparentBut Jonny Greenwood can.I completely agree with your point though, sheet music is an element from Western \"Music Theory\", and has nothing to do with being able to make music. It definitely does help if you want to have musicians trained in that Western cultural practice to play your music, but not everyone cares about that.Edit: my point about Mr Greenwood is that he is a huge part of the sound of Radiohead, as well as the other members. reply sebastiansm 16 hours agorootparentprevMaybe not, but he has an amazing ear and a vaste knowledge of music theory. reply Octabrain 20 hours agoprevIt&#x27;s great to have tools that make easier to learn how to play music, which btw, I feel music should have evolved naturally itself towards something with better high level abstraction (kinda like programming languages). However, my fear with this kind of approaches in music is that you might end up being a simple \"typewriter\". I mean, you play by pure mechanical memory instead of due to develop a logical understanding of what you are doing. This was the main reason I ditched yousician for guitar. I saw myself just doing a more complex \"guitar hero\" kind of thing and I don&#x27;t want that, I want music theory and understanding instead of moving blindly my hands following coloured dots on the screen. reply irrational 5 hours agoprev> It changed about a month ago from an up front price to in app purchases and&#x2F;or a subscription - which has absolutely tanked revenue so far - but maybe it will pick upThis doesn’t surprise me. I abhor all subscriptions. I’ll pay for things once, upfront, but I’d rather do without than have continuous payments. reply Gigachad 1 hour agoparentThese days I avoid upfront payments unless you come out ahead within a year. I don&#x27;t want to buy something that takes 5 years to be cheaper than the yearly payments. I have no idea if I&#x27;m going to want this thing for x years, most of the time I don&#x27;t end up getting good value from upfront payments. With subscriptions I can just cancel and move to the best option at the time. reply jacobp100 1 hour agoparentprevThe old offering is still available as an in app purchase (it only unlocks importing, but doesn&#x27;t expire) - but I think the conversion rates for IAPs are far, far lower reply wirrbel 3 hours agoprevHaving been trained to read sheet music, I definitely wouldn&#x27;t be your customer. The notation system is so smart, the closer you look at it, that I cannot imagine that it can be replaced with something just as good, especially for the more complex scores.Definitely some alternative solutions may be good for beginners, but I wonder how they would perform with the Kreisleriana. reply catapart 16 hours agoprevOh, awesome! I&#x27;m working on something similar, to put out as a PWA. Seems I had similar aspirations&#x2F;complaints that you did, but also didn&#x27;t have an apple device (that I wanted to use for the app).Yours is a very nice presentation! I like the annotations feature, and the comprehensiveness of the features, even for the stated goal of such simple functionality. A lot of people might leave out percussion loops, or be a bit more stingy with the free tracks.This may be a stupid question, but I&#x27;ll ask anyway: does it recognize Midi controller input? In my practice, I&#x27;ve found value in having the notes I play represented digitally, so that I can keep my eyes on the screen (and, let&#x27;s face it, Rock Band&#x2F;Guitar Hero is fun). But I didn&#x27;t see that specifically advertised anywhere, so I was curious! reply jacobp100 16 hours agoparentFunny - this actually started as a web app! https:&#x2F;&#x2F;github.com&#x2F;jacobp100&#x2F;pianoIt does not recognize midi input at the moment reply notorandit 14 hours agoprevLearning piano without reading scores (Bach, Mozart, Beethoven, Chopin...) is like learning C without bitwise operators and pointers... reply pascalxus 12 hours agoprevTwo fatal issues I discovered: - the apple store was so biased, even when I typed in \"piano tabs\", it couldn&#x27;t find your app in the top 10 results. I had to type in the name of the entire app: \"Piano Tabs: Learn & Practice\"Then I attempted to install it and got this: - \"This application requires iOS 15.0 or later\". This is a deal breaker on so many apps. I don&#x27;t trust apple enough to change my iOS version. Note: this happened on a pretty recent iphone 7+ reply jacobp100 1 hour agoparentYes - it&#x27;s so difficult to get up the pecking order in the App StoreUnfortunately I won&#x27;t be able to support older versions - iOS 15 already causes a lot of problems. That said, all devices that ran iOS 13 also run iOS 15 reply crazygringo 10 hours agoparentprevYou don&#x27;t trust what?I&#x27;m struggling to imagine why anyone would trust e.g. iOS 10 more then iOS 15.(And if it&#x27;s about not trusting new updates, iOS 15 has been out for 2 years now.) reply callalex 11 hours agoparentprevIf you don’t trust Apple to maintain your phone why even bother buying a phone from them in the first place? reply pascalxus 11 hours agorootparenti didn&#x27;t buy it. I got it as a hand me down. reply jacobp100 58 minutes agorootparentI&#x27;m not sure what OS you&#x27;re on, but iOS 13 was about the buggiest OS they ever released. If you&#x27;re on that, I&#x27;d highly recommend upgrading. iOS 14 was pretty solid - but I&#x27;d still recommend upgrading reply golergka 11 hours agoparentpreviPhone 7 was released 7 years ago. It&#x27;s definitely not recent, and I wouldn&#x27;t expect any app developer to support such an old device. reply junar 11 hours agorootparentIronically, OP can still upgrade their iPhone 7 to iOS 15. Apple claims that 94% of iPhones are on iOS 15 or later.[1] https:&#x2F;&#x2F;developer.apple.com&#x2F;support&#x2F;app-store&#x2F; reply jimmytucson 20 hours agoprevThis is really cool! Guitar was my first instrument, then I went on to learn bass, drums, and a bunch of others, but I never bothered to learn how to read music - or, really, sight read. The few songs I know on piano, I learned from an electronic piano that had a display with an image of the keyboard and the keys would change color to tell you which one to play. When I play Maple Leaf Rag for other musicians they&#x27;re often surprised to find out I can&#x27;t read music.So I can definitely see a market for this and will probably try learning another song on piano with it. That said, I do wish I had just learned to read music up front, as I learned my first instrument. I think it would have opened up doors for me, particularly for playing with other musicians (like an orchestra or a jazz band). But who knows how much longer that will be the case - tomorrow&#x27;s great musicians may learn on an app like this! reply foobarian 16 hours agoparentI learned a soprano instrument and was able to sight read the treble clef since forever. But try as I could I never could teach myself to be fluent with the bass clef. It just messes with my brain somehow. reply tnecniv 20 hours agoprevThis is kind of a tangent, but I’ve played instruments all my life and I never really understood how to use sheet music beyond the initial learning of a piece. I always see musicians actively referencing it while playing, but I’ve never been able to read it nearly quickly enough to do so. That also holds for guitar tabs, which I can read more quickly than sheet music (for guitar or piano). For anything remotely complicated, I need to memorize the piece so I can focus on what I need to do with my hands. A chord sheet I can follow while improvising even if I haven’t seen the progression before, but my playing definitely isn’t as good because the mental load of reading, listening, and playing is too much. It’s like having one too many processes open on your computer and the OS &#x2F; CPU can’t quite keep up reply powersnail 16 hours agoparentThe ability to read unfamiliar music while playing is called sight reading, and generally speaking it&#x27;s more of an exercise than a capability relevant to actual performance.During performance, sheet music is like a cheat sheet during exam, a reminder of something you already know. Most of the music is in your head and hand. The sheet music is just there to prevent a memory slip. Some orchestral music can be awfully repetitive, and having the page there helps you keep track of where you are. You are not supposed to devote lots of attention to the page itself, (unless you didn&#x27;t practice before the performance and decides to sightread on stage, which, you know, happens). reply pclmulqdq 13 hours agoparentprevI play a lot of piano and harpsichord at a very advanced level, and almost always use the sheet music. For me, it&#x27;s a memory aid and a sort of \"map\" to the piece. You can also write stuff on your score to have reminders. This takes cognitive load off when you are performing. The goal of music is to play the music, so why waste brain capacity on getting to perfect memory of a piece when you can instead spend that on making the piece more expressive?I will also say that learning to play without looking at your hands is a great skill to have, and also takes off some of the cognitive load. reply bibanez 17 hours agoparentprevHaving good memory is important. It seems to me you have a really good muscle memory and that has helped you play without looking at the score.I&#x27;ve played the piano since a very young age and the thing is, learning to play without looking at the keys (eg whilst reading) is actually a good skill to have. The argument goes that this way you can look at one hand without worrying about missing with the other while in a concert. I tend to agree.Also I scribble a lot in my sheet music because part of studying a piece is discovering things written in it (everything has a purpose, every staccato, forte, piano, etc.) reply bstpierre 9 hours agoparentprevI’m basically the opposite — really struggle to memorize music, and will almost always read while playing.Maybe because I was taught to read music for piano as a kid?The only exception was learning banjo (as an adult) because I basically learned it all from youtube and forced myself to memorize songs. But when I could play piano I only ever remembered a few bars from a couple of songs, everything else had to be written down. Even just playing chords on a uke! reply rwhyan 20 hours agoprevLooks cool design-wise, but who is this for?Although the upfront cost of learning sheet music is a few weeks of study, it quickly becomes worth it due to gains in speed of learning and sightreading skills.Maybe this can introduce people to piano and get them playing quickly, but it&#x27;ll ultimately stunt their development. reply ksenzee 15 hours agoparentFor people saying “but there are amazing musicians who don’t read music,” yes, of course there are. Literacy isn’t required for poets, either. There are rich oral traditions that weren’t written down for hundreds or thousands of years. But you cannot convince me that reading and writing are unimportant for poets and audiobook readers. You can do both jobs without reading or writing, but they’re a heck of a lot easier if you do.I think it also depends what instrument you play. It’s understandable that there are guitarists in this thread saying “eh, pianists don’t need sheet music, I do fine without it” but they are missing the fact that sheet music is way more useful for piano than it is for guitar. If someone truly does not want to learn to read music, they might consider taking up an instrument like guitar where you can get along without it. reply jacobp100 20 hours agoparentprevIf you already know and like sheet music, I don’t think this app will be for youI know at least one other person who didn’t bother learning sheet music. Maybe it’s because I came from guitar, where tabs aren’t particularly sight readable, so I just learn and remember the entire piece reply rwhyan 20 hours agorootparentYes, this app could serve as an introduction to piano, but ultimately relying on it will be detrimental to long-term growth.I think the app would b more useful if it helped teach sheet music (which can be frustrating for beginners) through this friendly UI. reply nogridbag 20 hours agoparentprevI learned piano when I was young, but I never practiced and basically repeated the same lesson over and over. We started taking our 5 year old for piano lessons and I was inspired and wanted to start practicing as well, but I found I couldn&#x27;t read any sheet music.I found a course on Udemy: Read Music FAST and Read Music FAST! Part 2. I highly recommend those. It basically took a week or two to get through them and I was able to jump into the author&#x27;s free Intermediate lesson. reply OfSanguineFire 20 hours agoparentprevIn the jazz world it is fairly common for pianists to be unable to read music. For example, Colin Vallon, one of the most successful jazz pianists of the new millennium, has admitted in a number of interviews that he never learned. reply rwhyan 20 hours agorootparentI wouldn&#x27;t call it \"fairly common.\"There are certainly outliers who play by ear or rely on improvisation, but musicians in all genres rely on sheet music to develop their craft. reply Rochus 14 hours agorootparentMany, many \"outliers\". reply Aeolun 7 hours agoparentprev> Maybe this can introduce people to piano and get them playing quicklyThat’s good enough for the people that would otherwise never play at all. reply tobr 20 hours agoparentprevThis is wrong. Played piano all my life, and never learned to read sheet music fast enough for it to be any use. This has not stunted my development. I play by ear and chords. reply ksenzee 15 hours agorootparentI play by ear and chords too, but being able to jot something down, or read something someone else has written down, is as useful to me in music as it is in English. Literacy is just plain practical. reply tobr 15 hours agorootparentPractical and useful, yes! Stunting development is something different. I do know how to read sheet music, but I’ve never practiced it to be fast enough to sight read. I’ve never felt that this has stunted my development - if it had, I probably would have picked up speed naturally. reply ksenzee 11 hours agorootparentSightreading is difficult enough that most pianists aren’t any good at it. Those who are get props and envy from other musicians. reply rwhyan 20 hours agorootparentprevI&#x27;m sure you can play piano, but I&#x27;m also willing to bet it has put a ceiling on the types of pieces you can learn.Have you tried learning a Chopin Ballade or Bach WTC fugue without sheet music? reply dbalatero 20 hours agorootparentGP might not want to play that kind of music. You can easily get away with no reading ability if you play in bands, pop groups, etc. (not that it&#x27;s not useful to read) reply tobr 19 hours agorootparentprevWho is it for, you asked. Do you think there might be a few beginner pianists who see value in being able to play other music than 300-year-old fugues? If an interest in developing musical abilities in a different direction constitutes a “ceiling” and “stunted development” for you, you have a very narrow view of what it means to play an instrument. reply rwhyan 18 hours agorootparentIt&#x27;s objectively a ceiling if you can&#x27;t work towards playing the most technically challenging music.It doesn&#x27;t have to be Bach. You will struggle to learn ANY advanced piano without sheet music.Sure it&#x27;s for \"beginners,\" but I&#x27;m saying it will inherently stunt their growth compared to putting in the work to learn sheet music. reply eitally 16 hours agorootparentThat&#x27;s not remotely true. if your objective is to play keys in a rock band, you really mostly just need chords and a little fill here and there.I completely agree with your fundamental point, but it&#x27;s a mistake to say someone needs to be able to be technically excellent in order not to feel like they&#x27;ve hit a ceiling in what they can do. reply tobr 16 hours agorootparentprevIt’s not an objective ceiling when we disagree on which way is up! You have a super-weird and specific idea of what it means to play piano. I really can’t think of a less inspiring goal than playing “advanced” or “technically challenging” music. If you like to do that, go nuts, but don’t assume that anything else is meaningless. reply rwhyan 16 hours agorootparentHow is that \"super-weird\" or \"specific\"? If anything, your idea of advanced pieces not being \"up\" is obscure.> I really can’t think of a less inspiring goal than playing “advanced” or “technically challenging” musicReally? You can&#x27;t understand how aiming to conquer a highly technical and musical piece is inspiring? It&#x27;s the same as tackling any other difficult goal.Music at a less technical level isn&#x27;t meaningless, but it&#x27;s an inherent limitation on your musicality if your repertoire is limited by technique.Technique facilitates greater musicality. Sheet music facilitates greater technique.Regardless, do as you please, but it&#x27;s like saying, \"I&#x27;ll never learn code, because I can build no-code products!\" reply tobr 15 hours agorootparent> You can&#x27;t understand how aiming to conquer a highly technical and musical piece is inspiring?You are putting words in my mouth - I am saying it’s not inspiring to me. I can understand that someone else might find it inspiring, sure! Like speedrunning a video game, some might find it an enjoyable challenge - but I think they can see that there are other reasons to play games. They wouldn’t say “who’s it for?” about a strategy guide because it’s not about speed.For what it’s worth, I disagree with almost all of your descriptions of what musicality consists of. It’s not about repertoire or technique. If you see what types of music most people enjoy listening to and playing, you can see that you have a niche point of view. Technically challenging music is not more enjoyable to play or hear. Sheet music is irrelevant to most types of music, both historically and today - music is fundamentally heard and felt, not written and read, nor conquered.I’ll leave this conversation now as it doesn’t appear to go anywhere meaningful. reply dbalatero 14 hours agorootparentYes, and, it&#x27;s a niche view even if you restrict things to America&#x2F;western music. From a global perspective it&#x27;s even more niche, limiting, and boxed in. replyabid786 20 hours agorootparentprevYou’re probably not very good at playing the piano. I’m not sure what you mean by far enough, but not being able to sight read a piece is not the same as being unable to read sheet music at all. reply bityard 20 hours agorootparentI&#x27;ve noticed that across my many hobbies, there are always people who insist that THEIR way of learning how to do a thing is the ONLY way to learn how to do a thing. This seems more prevalent in the music world, though. Especially if they had strict teacher. reply djaychela 13 hours agorootparentprevWes Montgomery couldn&#x27;t read music, but he was a pretty good guitarist [1][1] This is an understatement, by the way. reply tobr 20 hours agorootparentprev> You’re probably not very good at playing the piano.This is rude. What the heck do you base this on? reply dbalatero 20 hours agorootparentYeah it&#x27;s a moronic comment. I&#x27;m not even going to bother to compile a list of musicians that smoke everyone else without reading sheet music, but you can&#x27;t throw a rock without hitting one. reply pclmulqdq 13 hours agorootparentIn the professional music scene, you can go for an entire career without running into one. It is a relatively small set of outliers, and even then, there is a narrow set of genres (most of them Western and modern) where a professional player can get away with not reading or writing music.Even in the poster child of learning by ear, Jazz, something like 99% of session and pro players learn to read music. replyteo_mosce 20 hours agoparentprevYeah that&#x27;s true but I know for a fact that many of my friends would like to simply learn a few simple songs without really getting into the details of learning music! So this might be helpful for all those people like them! reply AntonyGarand 20 hours agoprevCongrats on the release, looks great!Reminds me of Synthesia[1], with a better UX but less features!How do you handle the displaying all notes on a portrait phone per your homepage screenshot? Especially on songs with a large gap between both hands, seems like it would be pretty cramped so a tablet might be the better option.[1] https:&#x2F;&#x2F;www.synthesiagame.com&#x2F; reply jacobp100 19 hours agoparentYes - it is heavily based on Synthesia. It has a few different priorities - it won&#x27;t play weird formats like MusicXML, but it has stuff like looping, a speed trainer (looping with an automatic tempo increment), transposition etc.Portrait on your phone is about the worse way to use the app, but it does technically work. You&#x27;ll have to scroll side to side to see all the notes. Landscape is better - you fit all the notes in - and if you tap the screen once, it&#x27;ll hide the header for a bit of extra space. But yes, an iPad or Mac is by far the best experience reply AntonyGarand 19 hours agorootparentThanks for your response!I was confused on the portrait as the phone is shown as-is on the homepage, I would advice making it landscape instead as it seems to be a more usable format reply jacobp100 19 hours agorootparentYes - that would make a lot of sense! I copied the layout from the TechniCalc page, and never gave it a second thought reply crtified 13 hours agoprevI applaud tools like this, which give alternative options for people to access the music world. Traditional sheet music is a very competent tool, but it&#x27;s also a very specific form of translation (of sound, to print). Certainly not the only one, and not even necessarily the best possible one.I am getting a little off-track here, and I&#x27;m probably doing my suggestion few favours by burying it here where few will ever see it, but on a similar track, I envisage music tuition being a huge potential application for augmented reality. The possibilities there are mindblowing. reply julienmarie 10 hours agoprevWas interested in the concept because weirdly i&#x27;m an ok average+ piano player but just suck at sheet reading. Just downloaded it on my M2 mac. It doesn&#x27;t work? Clicking on a track just show a picture of the track. Clicking on a composer just show a picture of the composer. Clicking on View All just show a page with View All written in the middle. reply jacobp100 57 minutes agoparentThat does not sound right. Don&#x27;t suppose you could record a video, then tap the &#x27;help&#x27; button and email me it? reply tornato7 20 hours agoprevI agree that sheet music could be improved. The worst part to me is simply that notes are identical symbols just shifted up or down ever so slightly. But based on the screenshots your app does the same thing, just side to side. I think it would be more helpful if each note had a color to it. reply jacobp100 19 hours agoparentYes - that is a problem with the format. There&#x27;s a few visual cues I add for this, like the black notes extending all the way up into the score, markers on every octave. You can also scroll the score like a normal scrollview, and it&#x27;ll highlight on the visual keyboard what&#x27;s currently played, and also play the notes if you scroll slow enough reply gcanyon 5 hours agoprevDoes anyone have recommendations for a learn-to-play-on-it keyboard? Not too expensive, but not a toy? reply reikonomusha 4 hours agoparentRoland FP-10 is en entry level \"not a toy\" keyboard. reply ksherlock 19 hours agoprevMaybe it&#x27;s just me, and I&#x27;m not particularly good at reading sheet music but -- for piano -- I find all the alternative even worse.At least this sort of display eliminates the \"akshually C𝄫 and A♯ are different\"-type cranks. reply conkeisterdoor 20 hours agoprevI recently started looking into cheap electric keyboards that I could use to teach myself piano, and this looks so awesome for learning. I would pay for this app, but unfortunately I don&#x27;t have any Apple devices. reply bityard 20 hours agoparentBe careful admitting this in public: you are going to get comments from people telling you that it is impossible to learn how to play piano on a cheap keyboard because it doesn&#x27;t have the same feel as a real piano, and lacks pedals. Fortunately, they are wrong up to a certain point. There is a difference playing the two, to be sure, but it&#x27;s like saying you can&#x27;t learn to drive in a car with an automatic transmission. reply conkeisterdoor 17 hours agorootparentHah that&#x27;s good to know, the comparison to learning to drive makes a lot of sense. Thanks for the tip reply nogridbag 20 hours agoparentprevI just did the same. I wanted to get something cheap-ish, but still feeling like a piano. Roland seems to the default choice, maybe with Yamaha being a close second.I wound up buying a Roland FP-30X, but I think the FP-10 feels basically the same. When we visit friends who went for cheaper options, their keyboards feel like toys. reply yepguy 16 hours agorootparentI just did the same, and I think those Rolands are basically the cheapest options that will actually serve you well over the medium to long term. reply jacobp100 20 hours agoparentprevSorry - yes it is Apple only. Their OSes have a tonne of audio stuff out the box which can be pricey to license from other places reply conkeisterdoor 20 hours agorootparentUnderstood and makes sense - best of luck with this, it really looks fantastic. reply jacobp100 20 hours agorootparentThank you! reply Cthulhu_ 20 hours agoprevDoes it support midi-in? I&#x27;ve got a small midi keyboard, being able to hook that up to this would be ideal.And if that&#x27;s in there, what about a mode - like typing instructors - where the page only advances if you hit the right keys? I think that would be an ideal way to learn the notes, followed by a mode like Guitar Hero where you have to hit the right notes at the right time.Finally, given that the app is aimed at teaching, I&#x27;d add a progression path, have the user start with simple music and gradually progress. Finding rights-free midi files and assessing difficulty might be difficult though. reply QVVRP4nYz 16 hours agoparentSynthesia works with midi(via USB) - at least the PC and Android versions do. reply buffington 12 hours agorootparentI use Synthesia on the iPad and it works great. reply jacobp100 20 hours agoparentprevNo MIDI in for the moment. It’d be nice to have, for sure!For learning - I agree - I wanted to have some kind of ‘difficulty’ heuristic for pieces, and recommend easy ones. I just haven’t been able to come up with anything yet. reply dbalatero 20 hours agorootparentYou can look up the royal grading the UK uses for classical pieces and use that.A single difficulty score is a bit difficult (hah) as a piece will have many technical dimensions to it, and ideally you&#x27;re comfortable with most of it but a few dimensions push you out of your comfort zone.I think these standard grade scores attempt to give some kind of loose ordering to when you might want to tackle the piece. reply jacobp100 19 hours agorootparentI&#x27;m actually from the UK. Is this the grade system people normally refer to - like they say they&#x27;re grade 8?I meant more an algorithm to determine the difficulty. Things like tempo and how much your fingers would need to move. But equally, I could probably just cherry pick some easier pieces far quicker reply awill 20 hours agoprevWhat&#x27;s the pricing model here? the AppStore lists a yearly subscription as $10, but then an additional IAP to import songs of $5? It&#x27;s confusing, and I never install apps when the pricing is unclear. Also, any plans for lifetime, as a lot of people simply don&#x27;t want yet another subscription. reply jacobp100 20 hours agoparentThe subscription unlocks everything while it’s activeThe ‘lifetime’ option is $5 but only unlocks importing your own files (not the 800 pieces in the catalog)Its a good point - I should clarify this pricing reply zengid 20 hours agoprevThis is really awesome, congrats on shipping. If you don&#x27;t mind me asking, what do sales look like on average for an app like this? I&#x27;m hoping to someday make a \"music education app\", but I&#x27;m skeptical if people would pay for it. Thank you! reply jacobp100 19 hours agoparentI don’t mind being candid about sales - I always found it really interesting reading about othersSo for 2022, this app was a $5 up front price, and made $200. I have a similar one for MP3 playback - also $5 up front - that made $900. Then you used to be able to buy both together for $8, which made $130A month ago I moved to in app purchases and subscriptions - and since then I’ve only managed to get one subscription and zero IAPs. The downloads have also been terrible - with about 5 a dayThe level of marketing before has been having a good store listing, and some effort into keywords, but no active marketing (self promotion or ads etc.)Focus now is on marketing. The nice thing about it being free to download is it’s easier to get interest from posts like these. That was much harder to do before reply zengid 19 hours agorootparentThanks for sharing! One thing I&#x27;ve thought about for marketing an app like this was to just sit down and do a Twitch stream or something and screen-share while using the app. I feel like if it looks cool enough you&#x27;ll get a few folks that want to check it out.. and hopefully it snowballs. You could record it and slice up clips for YouTube with the good parts..Good luck with marketing! reply zengid 19 hours agorootparentAnd another note.. Free-to-play apps with IAP could benefit from learning about how it works in the gaming industry. I highly recommend the Gamecraft podcast from the incredible VC Mitch Laskyhttps:&#x2F;&#x2F;www.gamecraftpod.com&#x2F; reply jacobp100 19 hours agorootparentThanks! I&#x27;ll give that a listen. I think I have a lot of learning to do here replyfilcuk 20 hours agoprevThat honestly looks amazing. Do you plan to release on Android by any chance? reply jacobp100 20 hours agoparentUnfortunately not! This is a SwiftUI app using a lot of Apple audio libraries - so it would be a complete rewrite to get it running on Android reply ics 20 hours agoprevThe pricing model is confusing at first and not very clear until you start trying to use the app (tried the macOS version for now). The App Store description does not mention the subscription and what features it unlocks, and in the app it doesn&#x27;t trigger until you try to play a song. If you dismiss the window, you actually have to go back to playing a song (and wait) to see it again as there isn&#x27;t a settings pane or other trigger just to see the subscription page. A few suggestions on that front: - Put the pricing either on a splash window after opening for the first time OR in a message tile on the library screen - Include certain (full) songs in the free version and give them a badge of some sort (\"free\", \"included\", etc.) - Put a badge in the toolbar indicating whether you are in a free or paid mode - Make it clear if a subscription is valid for iOS *and* macOS or if they are separate (2x the cost) (edit: downloaded on iOS and it&#x27;s not limiting anything so it must be a universal subscription. Put that early in the description for sure.)I put a piano in my apartment in 2020, the year the app appears to have been first released. Several people in my household were looking for something exactly like this to practice and never came across it, though we did get suckered into a few $10&#x2F;month or $75&#x2F;year subscriptions for other things that ended up barely getting used. If the pricing stays the same but is much clearer to people I believe you could get decent conversion from a little bit of targeted advertising.Besides that, the import dialog could be less spartan. It is not indicated in the app itself that it takes MIDI files only. Normal users may not know what a MIDI file is at first but you might be surprised at how many would learn and go seek those if given a tiny bit of guidance. Tons of non-technical people have learned to get their hands on playable guitar tabs the same way.As for the playing interface, I like it quite a bit. Plenty of people will comment about how anything getting in the way of becoming an expert in sight reading is somehow evil (hyperbole) but this is silly. I could easily recommend this app to friends who played Guitar Hero as kids and now want to play along to stuff on the piano or keyboard– hey, we all got older and maybe acquired more \"mature\" instruments with black and white keys. I used to read standard sheet music for chamber&#x2F;orchestra but it&#x27;s been years and frankly it&#x27;s the least important skill for the type of music that I play. However I do have a piano and once in a while want to play something without getting into a lesson on sheet music especially since what I used to read had far less range than a piano.App Store note: searching for \"piano tabs\" the app doesn&#x27;t show up even after a lot of scrolling. \"piano tabs learning & practice\" finds it as the top result. I am a fan of the plain name; it&#x27;s short and self-explanatory to the point that I imagine people do randomly search those terms without knowing about your app. That should be a good thing but in practice it seems the discoverability isn&#x27;t there which is worth looking into. reply ics 19 hours agoparentSome suggestions and features based on personal preference, so I&#x27;m putting in a separate comment. - Put an \"Import MIDI file\" button in the Imported Files section - Star or bookmark icon, pick one for favorites. Currently one is used on the library screen and a different one in the song view. - Sidebar for the different sections with hide&#x2F;show toggle, for example I don&#x27;t like to scroll through stacked Sections and don&#x27;t really care to see Recents at all - Options for thumbnail, tab display could be one but some variations would be interesting: - Color based on tempo - Dot-based graphic (primarily aesthetic, but recognizable at a glance) - Size S&#x2F;M&#x2F;L option which assigns per section - Tags for tracks, ideally color-codable. Maybe I want to tag something \"mastered\", or \"difficult\", \"somber\", etc. - After entering the search box, escape key or outside click should dismiss and return to the home layout. Currently the sections get reorganized, Favorites and Recents disappear and Pieces shows up at the bottom, but I can&#x27;t get back without closing the app. - \"Choose Random\" button to open a piece - Composer interface, create new pieces from scratch or modify from the library using something similar to the playing interface (n.b. a decent interface for this if no keyboard&#x2F;midi-in would be present a 1+-octave keyboard with some modifiers, so multiple key taps can create individual notes, optional rest interval, or extend a continuous note. Row-level actions so you can duplicate creating repeats, shift up&#x2F;down, etc. Slight differences between macOS&#x2F;iOS.) - Allow user editable text, emoji, or color highlight in the play scroll. Noting a section of the piece is one obvious use but it could be handy for several uses. - (semi serious) watch integration to vibrate on tempo. - Music box mode, notes only play as you scroll (I see you did this actually. My daughter is gonna love this...) reply jacobp100 19 hours agorootparentThanks again for the suggestions!What OS were you using where you couldn&#x27;t get out of the search page? On the main page, the layout is altered so there&#x27;s no duplication on results - but if you exit the search interface, it&#x27;ll go backAlso note you can press the chevron to the left of a section to collapse it, and it&#x27;ll remember that setting reply ics 19 hours agorootparentOn macOS 13.5, entering the search shows no obvious way to end&#x2F;return. However I just pressed Enter and that took me back, which was unexpected. So it works, just oddly mapped I think. On iOS the search+cancel is just fine.For the sections, I noticed that but still find it odd that the home library view doesn&#x27;t actually show me... the full library. You have to discover pieces by composer which I missed at first. BTW, there is a typo on both mac&#x2F;iOS versions where the header is missing an r in \"Lib[*r]ary\". reply jacobp100 15 hours agorootparentAh yes - mac is particularly difficult to get that interaction rightThanks for pointing out the typo. I&#x27;m really bad for those! reply jacobp100 19 hours agoparentprevThanks for the suggestions! A few people are saying they were confused, so I&#x27;ll put some more effort around that wordingThe import dialog is unfortunately just the system dialog - I have some other apps using it and it&#x27;s frequently something people are confused about. There&#x27;s no real way around it though.I&#x27;m still experimenting with the catalog. The app used to have a lot of links to places to get MIDI files from, but I just don&#x27;t think it&#x27;s something most people wanted to bother with. But that remains to be seen! reply ics 19 hours agorootparentOn iOS, I don&#x27;t think the term MIDI is mentioned anywhere in app. Unless you recalled it from the app store description then the Import button seems quite mysterious; average users might mistake it for something to interpret and extract notes from MP3s or whatever.I have this site bookmarked for fun: https:&#x2F;&#x2F;bitmidi.com&#x2F; If I showed this app to some friends, the first thing they&#x27;d go looking for would be some video game music which is a whole different set than classical. Considering that, it would be nice to have separate libraries or playlists for genre organization. Offer some pre-populated as IAP, e.g. Classical is default but you can get popular songs, SNES tracks, etc. for $1-2 per collection if doable with individual licenses. reply jacobp100 1 hour agorootparentIt’s advertised in the screenshots - but I’ll double check the descriptionI’d love to expand the catalog. Classical was easy because they’re all dead and everything is in the public domain. Anything current I’d have to license and I don’t have the foggiest how I’d even do that reply jsphsl 20 hours agoprevI&#x27;ve been taking piano lessons for several months now and I&#x27;m still struggling with sheet music notes. I may give this a try! It reminds me of playing guitar hero back in the day :) reply jacobp100 19 hours agoparentYeah I was in the same boat. I came from guitar, so had some level of dexterity. I couldn&#x27;t use beginner tutorials that show you what note to play, because they were far too basic. But then with sheet music, I&#x27;d spend 90% of the time counting EGBDF - and getting it wrong a lot of the time too! reply billfruit 15 hours agoprevDoes Casio Chordana play do something similar? reply jacobp100 15 hours agoparentLooks like it! I&#x27;m definitely not the first to do this reply bregma 16 hours agoprevHmm. Looks like the classic piano roll notation. reply jjallen 20 hours agoprevHow do you only have one review?This looks super cool and would make me basically immediately able to roughly play quite a few pieces. Need to setup my keyboard and try it out. reply jacobp100 20 hours agoparentShort a",
    "originSummary": [
      "An individual has created an app that visualizes sheet music in a way similar to YouTube tutorials, with a feature allowing users to import their own files.",
      "The app introduced a subscription model for classical music access, however, this has not proven to be profitable.",
      "The creator is currently seeking feedback and suggestions for improvement."
    ],
    "commentSummary": [
      "The dialogue revolves around different elements of sheet music, highlighting challenges in reading it, the merits and limitations of classical notation, and potential of alternative notation systems or digital apps for learning and playing music.",
      "The importance of sheet music in the realm of music education and performance is being emphasized, while criticizing certain music learning apps and suggesting improvements.",
      "Focus is also given to aspects like pricing, user interface, and features of specific apps, and a comparison is drawn with existing apps in the market."
    ],
    "points": 191,
    "commentCount": 232,
    "retryCount": 0,
    "time": 1695387741
  },
  {
    "id": 37611136,
    "title": "Principles for building and scaling feature flag systems",
    "originLink": "https://docs.getunleash.io/topics/feature-flags/feature-flag-best-practices",
    "originBody": "Skip to main content Unleash Unleash Enterprise Search K About the docs First steps and tutorials Unleash introductory overview Important Concepts Quickstart Topic guides 11 Principles for building and scaling feature flag systems 1. Enable run-time control. Control flags dynamically, not using config files. 2. Never expose PII. Follow the principle of least privilege. 3. Evaluate flags as close to the user as possible. Reduce latency. 4. Scale Horizontally. Decouple reading and writing flags. 5. Limit payloads. Feature flag payload should be as small as possible. 6. Design for failure. Favor availability over consistency. 7. Make feature flags short-lived. Do not confuse flags with application configuration. 8. Use unique names across all applications. Enforce naming conventions. 9. Choose open by default. Democratize feature flag access. 10. Do no harm. Prioritize consistent user experience. 11. Enable traceability. Make it easy to understand flag evaluation. The Anatomy of Unleash A/B and multivariate testing Feature Flag Migrations Data collection Managing constraints Edge & Proxy hosting strategies How-to guides Unleash API guides Unleash Proxy guides Feature toggles, strategies, context Environments Users and permissions Single Sign-On (SSO) Troubleshooting Reference documentation APIs Application SDKs Deploy and manage Unleash Integrations Unleash concepts Unleash Edge Unleash Proxy Developer contribution docs Topic guides11 Principles for building and scaling feature flag systems 11 Principles for building and scaling feature flag systems Feature flags, sometimes called feature toggles or feature switches, are a software development technique that allows engineering teams to decouple the release of new functionality from software deployments. With feature flags, developers can turn specific features or code segments on or off at runtime, without the need for a code deployment or rollback. Organizations who adopt feature flags see improvements in all key operational metrics for DevOps: Lead time to changes, mean-time-to-recovery, deployment frequency, and change failure rate. There are 11 principles for building a large-scale feature flag system. These principles have their roots in distributed systems architecture and pay particular attention to security, privacy, and scale that is required by most enterprise systems. If you follow these principles, your feature flag system is less likely to break under load and will be easier to evolve and maintain. These principles are: Enable run-time control. Control flags dynamically, not using config files. Never expose PII. Follow the principle of least privilege. Evaluate flags as close to the user as possible. Reduce latency. Scale Horizontally. Decouple reading and writing flags. Limit payloads. Feature flag payload should be as small as possible. Design for failure. Favor availability over consistency. Make feature flags short-lived. Do not confuse flags with application configuration. Use unique names across all applications. Enforce naming conventions. Choose open by default. Democratize feature flag access. Do no harm. Prioritize consistent user experience. Enable traceability. Make it easy to understand flag evaluation Background Feature flags have become a central part of the DevOps toolbox along with Git, CI/CD and microservices. You can write modern software without all of these things, but it sure is a lot harder, and a lot less fun. And just like the wrong Git repo design can cause interminable headaches, getting the details wrong when first building a feature flag system can be very costly. This set of principles for building a large-scale feature management platform is the result of thousands of hours of work building and scaling Unleash, an open-source feature management solution used by thousands of organizations. Before Unleash was a community and a company, it was an internal project, started by one dev, for one company. As the community behind Unleash grew, patterns and anti-patterns of large-scale feature flag systems emerged. Our community quickly discovered that these are important principles for anyone who wanted to avoid spending weekends debugging the production system that is supposed to make debugging in production easier. “Large scale” means the ability to support millions of flags served to end-users with minimal latency or impact on application uptime or performance. That is the type of system most large enterprises are building today and the type of feature flag system that this guide focuses on. Our motivation for writing these principles is to share what we’ve learned building a large-scale feature flag solution with other architects and engineers solving similar challenges. Unleash is open-source, and so are these principles. Have something to contribute? Open a PR or discussion on our Github. Edit this page Previous Topic guides Next 1. Enable run-time control. Control flags dynamically, not using config files. Background Product Docs Unleash on GitHub Roadmap Unleash help center Community GitHub discussions Slack Stack Overflow Twitter Copyright © 2023 Unleash. Built with Docusaurus. Ask AI",
    "commentLink": "https://news.ycombinator.com/item?id=37611136",
    "commentBody": "Principles for building and scaling feature flag systemsHacker NewspastloginPrinciples for building and scaling feature flag systems (getunleash.io) 194 points by ferrantim 22 hours ago| hidepastfavorite84 comments mabbo 19 hours ago> Make feature flags short-lived. Do not confuse flags with application configuration.This is my current battle.I introduced feature flags to the team as a means to separate deployment from launch of new features. For the sake of getting it working and used, I made the mis-step of backing the flags with config files with the intent to get Launch Darkly or Unleash working ASAP instead to replace them.Then another dev decided that these Feature Flags look like a great way to implement permanent application configs for different subsets of entities in our system. In fact, he evangelized it in his design for a major new project (I was not invited to the review).Now I have to stand back and watch as the feature flags are being used for long-term configurations. I objected when I saw the misuse- in a code review I said \"hey that&#x27;s not what these are for\"- and was overruled by management. This is the design, there&#x27;s no time to update it, I&#x27;m sure we can fix it later, someday.Lesson learned: make it very hard to misuse meta-features like feature flags, or someone will use them to get their stuff done faster. reply zellyn 19 hours agoparentSadly, this is a battle you are destined to lose. I have almost completely given up. The best you can aim for is to use feature flags better rather than worse. - Some flags are going to stay forever: kill switches, load shedding, etc. (vendors are starting to incorporate this in the UI) - Unless you have a very-easy-to-use way to add arbitrary boolean feature toggles to individual user accounts (which can become its own mess), people are going to find it vastly easier to create feature flags with per-use override lists (almost all of them let you override on primary token). They will use your feature flags for: - Preview features: \"is this user in the preview group?\" - rollouts that might not ever go 100%: \"should this organization use the old login flow?\" - business-critical attributes that it would be a major incident to revert to defaults: \"does this user operate under the alternate tax regime?\"You can try to fight this (indeed, especially for that last one, you most definitely should!), but you will not ever completely win the feature flag ideological purity war! reply hamandcheese 17 hours agorootparentThank you for this great list of the immense business value derived from \"misusing\" feature flags! reply charrondev 9 hours agorootparentIn my org, I think I’ve go the feature flag thing mostly down.We started with a customer specific configuration system that allows arbitrary values matching a defined schema. It’s very easy to add to the schema (define the config name, types, and permissions to read or write it in a JSON schema document).We have an administration panel with a full view of the JSON config for our support specialist and and even more detailed one for developers.Most config values get a user interface as well.From there we just have a namespace in the configuration for “feature flags”. Sometimes these are very short lived (2-4 sprints until the feature is done), but others can last a lot longer.There are an unfortunate couple that will probably never go away at this point (because of some enterprise customer with a niche use case in the “legacy” version of the feature that we’ve not yet implemented compatibility with and I don’t know when it will get on our roadmap to do so), but in the end they can just be migrated into normal config values if needed.A little tooling layer on top lets us query and write to the configs of thousands of sites at once as well. reply baq 19 hours agoparentprevOr... see them for what they are: runtime configuration. The name implies a use case scenario, but in reality it&#x27;s just a configuration knob. With a good UI, it&#x27;s a pretty damn convenient way to do runtime configuration.So of course they&#x27;ll be used for long-term configuration purposes, especially under pressure and for gradual rollouts of whole systems, not just A&#x2F;B testing features. reply hinkley 14 hours agorootparentOur FF system uses our config system as its system of record. There&#x27;s some potential for misuse, and it&#x27;s difficult to apply deadlines. On the plus side all our settings are captured in version control. Before they were spread out over several systems, one of which had an audit system that was pure tribal knowledge for years. reply rubicon33 18 hours agorootparentprevThis hits the nail on the head.The term \"feature flag\" has come to inherently have a time component because features are supposed to eventually be fulled GA&#x27;d.What I&#x27;ve seen in practice is feature flags are never removed so a better way to think about them is as a runtime configuration. reply dasil003 13 hours agorootparentI think the reason feature flags are never removed is because the timeframe that a given feature-flag is top-of-mind is also when it&#x27;s at its most useful. Later when it&#x27;s calcified in place and the off-state may be broken&#x2F;atrophied, no one is really thinking about it.I&#x27;m also not convinced it&#x27;s always a huge problem. I can imagine sometimes it is, but in most codebases I&#x27;ve worked on, it&#x27;s more of an annoyance but not cracking the top 3 or 5 biggest problems we wanted to focus on.IMHO the best solution is not something heavy handed like a policy that we only use run-time config for fixed timeframes, or a process where we regularly audit and prune old flags. It&#x27;s simply to keep a record of the config changes over time so anyone interested can see the history, and a culture where every engineer is encouraged to take a little extra time to verify and remove dead stuff whenever it crosses their path . reply ignoramous 15 hours agorootparentprev> What I&#x27;ve seen in practice is feature flags are never removed so a better way to think about them is as a runtime configuration.SaaS won&#x27;t sell itself unless it redefines the problem and presents itself as a solution... reply mabbo 18 hours agorootparentprevThere is a need for runtime configurations, yes, but it&#x27;s important to put them behind an interface intended for that, and not one intended for something else. reply baq 18 hours agorootparentI can immediately see if the config is being requested, which system requests it, what are the metadata of the request, etc. I can do conditional rollout of a configuration based on runtime data. I can reset the configuration to a know-good failsafe default without asking for approval with a break-glass button. I can schedule a rollout and get a reviewer for the config change.IME the feature flag interface is next to perfect for runtime configuration. I don&#x27;t care for intended usage at all. You could say feature flags have found a great product-market fit, just that a segment of the market is a bit unexpected but makes perfect sense if you think about it. reply NBJack 6 hours agorootparentThis gets messy at larger scales, both as teams grow and software grows.Resetting to a know failsafe works as long ask the risk of someone changing a backend service (or, multiple services) at the same time is low. Once it isn&#x27;t, you can most definitely do more damage (and make life harder for oncall).Who controls the runtime config? One person? Half a dozen? One hundred plus? Is it being gated by approvals, or can anyone do it? What about auditability? If something does go wrong, how easily can I rule out you turning on that flag?Finally there is simply the sheer permutations you introduce here. A feature flag is binary in many cases: on or off. A config could be in any number of states.These things make me nervous as an architect, and I&#x27;ve seen well intentioned changes fail when good flag discipline wasn&#x27;t followed. Using it as fullblown runtime config seems like a postmortem waiting to happen. reply bertil 17 hours agorootparentprevI am tempted to agree: if separating the two is key (I’m not convinced that it is, but happy to assume) why not copy the interface and the infrastructure of the feature flag and offer it as a configuration tool.I feel like you could easily add a status to flags, to mark whether they are part of a release process, or a permanent configuration tool, and in the latter case, take them off the release interfaces. reply monknomo 13 hours agorootparentI think unleash offers \"toggle type\" which can take values that describe whether it&#x27;s a pure feature flag, something operation, config, etc. reply dastbe 17 hours agorootparentprevCould you expand on what you think the different interfaces should be? you keep stating that these things ought to be distinct but haven&#x27;t explained why beyond dogma. reply zellyn 19 hours agorootparentprevYeah, and assuming they are done well, they probably have better analytics and insights attached to them than anything else except perhaps your experiments! reply hinkley 14 hours agoparentprevLong lived features flags is a development process bug, I&#x27;m not sure we can solve it with the feature toggle system.I&#x27;m at the point of deciding that Scrum is fundamentally incompatible with feature flags. We demo the code long before the flag has been removed, which leads to perverse incentives. If you want flags to go away in a timely manner you need WIP limits, and columns for those elements of the lifecycle. In short: Kanban doesn&#x27;t (have to) have this problem.And even the fixes I can imagine like the above, I&#x27;m not entirely sure you can stop your bad actor, because it&#x27;s going to be months before anyone notices that the flags have long overstayed their welcome.I&#x27;m partial to flags being under version control, where we have an audit trail. However time and again what we really need is a summary of how long each flag has existed, so they can be gotten rid of. The Kanban solution I mention above is only a 90% solution - it&#x27;s easy to forget you added a flag (or added 3 but deleted 2) reply gastonfournier 19 hours agoparentprevI faced something similar, and I think it&#x27;s unavoidable. Give people a screwdriver and they&#x27;ll find a way of using it as a hammer.The best you can do is expect the feature flagging solution to give some kind of warning for tech debt. Then equip them with alternative tools for configuration management. Rather than forbidding, give them options, but if it&#x27;s not your scope, I&#x27;d let them be (I know as engineers this is hard to do :P). reply llbeansandrice 15 hours agorootparent> Give people a screwdriver and they&#x27;ll find a way of using it as a hammer.I feel like feature flags aren&#x27;t that far off though. They&#x27;re fantastic for many uses of runtime configuration as mentioned in another comment.There&#x27;s multiple people in this thread complaining about \"abuse\" of feature flags but no one has been able to voice why it&#x27;s abuse instead of just use beyond esoteric dogma. reply bluefirebrand 15 hours agorootparentAllow me to try:Feature Flags inherently introduce at least one branch into your codebase.Every branch in your codebase creates a brand new state your code can run through.The number of branches introduced by Feature Flags likely does not scale linearly, because there is a good chance they will become nested, especially as more are added.Start with even an example of one feature flag nested inside another. That creates four possible program states. Four is not unreasonable, you can clearly define what state the program should be in for all four states.Now scale that to a hundred feature flags, some nested, some not.It becomes impossible to know what any particular program state should be past the most common configurations. If you can&#x27;t point to a single interface in a program and tell me all of the possible states of it, your program is going to be brittle as hell. It will become a QA nightmare.This is why Feature Flags should be used for temporary development efforts or A&#x2F;B testing, and removed.Otherwise you&#x27;re going to have a debugging nightmare on your hands eventually.Edit: Note that this is different from normal runtime configurations because normally runtime configurations don&#x27;t have a mix of in-dev options and other temporary flags. Also, they aren&#x27;t usually set up to arbitrarily add new options whenever it is convenient for a developer. reply baq 14 hours agorootparentSorry, not buying it.Branches are difficult to reason about? Yes, I agree.Are branches necessary to make the product behave in a different way in some circumstances? Most of the time.Do those circumstances require a branch? Unless you’re super confident about some part of code, yes? But why would you be?Runtime configuration is not about making QA easy. It’s introduced because QA has been hell already so you can control rollout of code which you know wasn’t properly QA’d - or it was but turns out the thing you built isn’t the thing users want and the release cycle is too long to deploy a revert.I’d say ‘branches are bad but alternatives are worse’. reply bluefirebrand 10 hours agorootparentThere is nothing worse than code with dozens to hundreds of possible configuration states that you must test for every new feature.If your QA was bad before, you&#x27;ve made it worse.\"I can toggle it off without pushing a new release\" is a terrible bandaid for the problem. reply x0x0 11 hours agorootparentprevThe fundamental diff between feature flags and config is the former is meant to be a soft deploy of code where everyone is expected to eventually be on the new code. Thus it should have a timer built in where it stops, and you should consider all new customers launching with it on.As for why: if you don&#x27;t deprecate the feature flag in some time span, you&#x27;re permanently carrying both code paths. With ongoing associated dev and qa resources and costs against your complexity budget.Permanent costs should only be undertaken after careful consideration, and should be outside the scope of a single dev deciding to undertake them. Whereas flags should be cheap to add to enable dev to get stuff into prod faster while retaining safety.Permanently making something a config choice should be done after heavier deliberation because of the aforementioned costs, and you often want different tools to manage it. Including something heavier duty than a single checkbox&#x2F;button in your internal CS admin tooling. These are often tied into contracts or legal needs, and in many cases salesforce should be the source of truth for them. Or whatever CPQ system you&#x27;re using. reply strken 13 hours agoparentprevI think it&#x27;s better to admit they actually are config, just a different kind of config that comes with an expiration date.Accepting reality in this way means you&#x27;ll design a config management system that lets you add feature flags with a required expiration date, and then notifies you when they&#x27;re still in the system after the deadline. reply Dirak 14 hours agoparentprevI feel like this is a solvable problem: 1) make feature flags be configured to have an expiration date. If over the expiration date, auto-generate a task to clean up your FF 2) If you want to be extra fancy, set up a codemod to automatically clean up the FF once it&#x27;s expiredI don&#x27;t see the problem with developers using flags for configuration as a stopgap until there&#x27;s a better solution available. reply tantalor 15 hours agoparentprevSounds like \"other dev\" found some business case they could unblock with existing system, and you thought the business was better off not solving that, or finding a more expensive solution.Curious how you plan to justify cost to \"fix it\" to management. If it ain&#x27;t broke... reply accountantbob 19 hours agoparentprevWe did the same. We were early adopters of unleash and wrangled it to also host long term application configuration and even rule based application config.The architecture of unleash made it so simple to do in unleash vs having to evaluate, configure, and deploy a separate app config solution. reply gastonfournier 19 hours agorootparentVictim of your own success. As others were saying, when it works for short-lived its easy&#x2F;no effort to use it for long-lived configurations. reply brightball 10 hours agoparentprevIt’s one of the main reasons to start with something like unleash because they have stale flag warnings built in. Plus, since you already have a UI it’s harder for it to be hijacked. reply ivarconr 19 hours agoparentprevThanks for sharing. I have seen systems grow in to thousands of flags, where most developers does not know what a particular flags do anymore. reply dabeeeenster 16 hours agoprevFor those that dont know about the project, check out Open Feature https:&#x2F;&#x2F;openfeature.dev&#x2F; which is sort of like Open Telemetry but for feature flags. Helps avoid vendor lock in. We&#x27;re a young project and looking for help and to build the community! reply triyambakam 1 hour agoparentWow, part of the CNCF. That&#x27;s awesome reply staplung 19 hours agoprevThis feels a bit like the dicta on 12 Factor: rules handed down from a presumed authority without any discussion of the tradeoffs. Engineering is tradeoff evaluation. Give me some discussion about the alternatives, when and why they&#x27;re inferior and don&#x27;t pretend like the proposed solution doesn&#x27;t have shortcomings or pitfalls. reply imiric 18 hours agoparentI agree with you that tradeoff evaluation is crucial in engineering, but I don&#x27;t see the 12 Factor methodology as a set of strict rules. They&#x27;re more like guidelines that are generally a good idea to follow for building modern applications or services. Some of the suggestions apply for any type of software, like having a single version controlled codebase, separate build&#x2F;release&#x2F;run stages, and using stateless processes.So it&#x27;s good to be aware of _why_ those guidelines are considered a good thing, but as with any methodology, an engineer should be pragmatic in deciding when to follow it strictly, and when to adapt or ignore some of it.That said, I wouldn&#x27;t want to work on software that completely ignores 12 Factor. reply tiberriver256 20 hours agoprevItem #1 depends on the reason you&#x27;re using feature flags.For a more nuanced and careful discussion of the topic I like to reference: https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;feature-toggles.html reply gastonfournier 19 hours agoparentIt&#x27;s true that there are more long-lived use cases, but if you have the ability to choose, runtime controlled ones cover both cases, while compile time only cover some use cases. But fair point reply tvink 2 hours agoprev>Organizations who adopt feature flags see improvements in all key operational metrics for DevOps: Lead time to changes, mean-time-to-recovery, deployment frequency, and change failure rate.Is this true? unfortunately there&#x27;s no sources indicated, and a quick check on scholar doesn&#x27;t show me anything of the sort. reply jt2190 20 hours agoprevI just item 1 (“Enable run-time control. Control flags dynamically, not using config files”) and it’s almost exclusively focused on what to do but not on why to do it.It seems to be skipping past the use-cases and assumptions, in particular, describing what a system with feature flags looks and acts like, what the benefits and drawbacks are. reply ivarconr 19 hours agoparent> It seems to be skipping past the use-cases and assumptionsThis is a great feedback. Our intention was to describe how such a system work at scale, but I see we could do better in this section, thanks!Do you have some use-cases in mind? reply tmpX7dMeXU 20 hours agoparentprevYeah, because it’s describing how a product works, being passed off as knowledge. reply eximius 12 hours agoprevThe system we&#x27;re building now meets most of these but not necessarily in the way described.First, we&#x27;re building a runtime configuration system on top of AWS AppConfig. YAML&#x2F;proto validation that pushes to AppConfig via gitops and bazel. Configurations are namespaced so the unique names is solved. It&#x27;s all open in git.Feature flags are special cases of runtime configuration.We are distinguishing backend feature flags from experimentation&#x2F;variants for users. We don&#x27;t have (or want) cohorting by user IDs or roles. We have a separate system for that and it does it well.The last two points - distinguishing between experimentation&#x2F;feature variants and feature flags as runtime configuration are somewhat axiomatic differences. Folks might disagree but ultimately we have that separate system that solves that case. They&#x27;re complimentary and share a lot of properties but ultimately it solves a lot of angst if you don&#x27;t force both to be the same tool. reply zellyn 20 hours agoprevBackground: I work at Block&#x2F;Square, on the team that owns (but didn&#x27;t build) our internal Feature Flag system, and also have a lot of experience with using LaunchDarkly.I like the idea of caching locally, although k8s makes that a bit more difficult since containers are typically ephemeral. People will use feature flags for things that they shouldn&#x27;t, so eventually \"falling back go default values\" will cause production problems. One thing you can do to help with this is run proxies closer to your services. For example, LaunchDarkly has an open source \"Relay\".Local evaluation seems to be pretty standard at this point, although I&#x27;d argue that delivering flag definitions is (relatively) easy. One of the real value-add of a product like LaunchDarkly is all the things they can do when your applications send evaluation data upstream: unused flags, only-ever-evaluated-to-the-default flags, only-ever-evaluated-to-one-outcome flags, etc.One best practice that I&#x27;d love to see spread (in our codebases too) is always naming the full feature flag directly in code, as a string (not a constant). I&#x27;d argue the same practice should be taken with metrics names.One of the most useful things to know (but seldom communicated clearly near landing pages) is a basic sketch of the architecture. It&#x27;s necessary to know how things will behave if there is trouble. For instance: our internal system uses ZK to store (protobuf) flag definitions, and applications set watches to be notified of changes. LaunchDarkly clients download all flags[1] in the project on connection, then stream changes.If I were going to build a feature flag system, I would ensure that there is a global, incrementing counter that is updated every time any change is made, and make it a fundamental aspect of the design. That way, clients can cache what they&#x27;ve seen, and easily fetch only necessary updates. You could also imagine annotating that generation ID into W3C Baggage, and passing it through the microservices call graph to ensure evaluation at a consistent point in time (clients would need to cache history for a minute or two, of course).One other dimension in which feature flag services vary is by the complexity of the rules they allow you to evaluate. Our internal system has a mini expression language (probably overkill). LaunchDarkly&#x27;s arguably better system gives you an ordered set of rules within which conditions are ANDed together. Both allow you to pass in arbitrary contexts of key&#x2F;value pairs. Many open source solutions (Unleash, last I checked, some time ago) are more limited: some of them don&#x27;t let you vary on inputs, some only a small set of prescribed attributes.I think the time is ripe for an open standard client API for feature flags. I think standardizing the communication mechanisms would be constricting, but there&#x27;s no reason we couldn&#x27;t create something analogous to (or even part of) the Open Telemetry client SDK for feature flags. If you are seriously interested in collaborating on that, please get in touch. (I&#x27;m \"zellyn\" just about everywhere)[1] Yes, this causes problems if you have too many flags in one project. They have a pretty nice filtering solution that&#x27;s almost fully ready.[Update: edited to make 70% of it not italics ] reply zellyn 20 hours agoparentOne more update. I spent a little time the other day trying to find all the feature flag products I could. I&#x27;m sure I missed a ton. Let me know in the comments!LaunchDarkly Split Apptimize CloudBees ConfigCat DevCycle FeatBit FeatureHub Flagsmith Flipper Flipt GrowthBook Harness Molasses OpenFeature Posthog Rollout UnleashHere&#x27;s my first draft of the questions you&#x27;d want to ask about any given solution: Questionnaire - Does it seem to be primarily proprietary, primarily open-source, or “open core” (parts open source, enterprise features proprietary)? - If it’s open core or open source with a service offering, can you run it completely on your own for free? - Does it look “serious&#x2F;mature”? - Lots of language SDKs - High-profile, high-scale users - Can you do rules with arbitrary attributes or is it just on&#x2F;off or on&#x2F;off with overrides? - Can it do complex rules? - How many language SDKs (one, a few, lots) - Do feature flags appear to be the primary purpose of this company&#x2F;project? - If not, does it look like feature flags are a first-class offering, or an afterthought &#x2F; checkbox-filler? (eg. split.io started out in experimentation, and then later introduced free feature flag functionality. I think it’s a first-class feature now.) - Does it allow approval workflows? - What is the basic architecture? - Are flags evaluated in-memory, locally? (Hopefully!) - Is there a relay&#x2F;proxy you can run in your own environment? - How are changes propagated? - Polling? - Streaming? - Does each app retrieve&#x2F;stream all the flags in a project, or just the ones they use? - What happens if their website goes down? - Do they do experiments too? - As a first-class offering? - Are there ACLs and groups&#x2F;roles? - Can they be synced from your own source of truth? - Do they have a solution for mobile and web apps? - If so, what is the pricing model? - Do they have a mobile relay type product you can run yourself? - What is the pricing model? - Per developer? - Per end-user? MAU? reply konradlekko 16 hours agorootparentA few more: https:&#x2F;&#x2F;featurevisor.com&#x2F; https:&#x2F;&#x2F;configcat.com&#x2F;I will toss our hat in the ring but we are early in this space! https:&#x2F;&#x2F;lekko.com reply blawson 17 hours agorootparentprevTogglz is another option: https:&#x2F;&#x2F;www.togglz.org&#x2F; reply vlovich123 19 hours agorootparentprevDo you have the answers to that questionnaire for the services you mention? reply zellyn 19 hours agorootparentI more or less know all the answers for LaunchDarkly (except pricing details), and for the internal feature flag service we&#x27;re deprecating, but I haven&#x27;t gone through and answered it for all the other offerings. It would be time-consuming, but very useful.Also, undoubtedly contentious. If you want an amusing read, go check out LaunchDarkly&#x27;s \"comparison with Split\" page and Split&#x27;s \"comparison with LaunchDarkly\" page. It&#x27;s especially funny when they make the exact same evaluations, but in reverse. reply vijayer 18 hours agorootparentprevCould you add Statsig to your research? reply daigoba66 19 hours agoparentprev> One best practice that I&#x27;d love to see spread (in our codebases too) is always naming the full feature flag directly in code, as a string (not a constant).Can you elaborate on this? As a programmer, I would think that using something like a constant would help us find references and ensure all usage of the flag is removed when the constant is removed. reply zellyn 19 hours agorootparentOne of the most common things you want to do for a feature flag or metric name is ask, \"Where is this used in code?\". (LaunchDarkly even has a product feature that does this, called \"Code References\".) I suppose one layer of indirection (into a constant) doesn&#x27;t hurt too much, although it certainly makes things a little trickier.The bigger problem is when the code constructs metric and flag names programmatically: prefix = \"framework.client.requests.http.{status%100}s\" recordHistogram(prefix + \".latency\", latency) recordCount(prefix + \".count\", 1) flagName = appName + \"&#x2F;loadshed-percent\" # etc...That kind of thing makes it very hard to find references to metrics or flags. Sometimes it&#x27;s impossible, or close to impossible to remove, but it&#x27;s worth trying hard.Of course, this is just, like, my opinion, man! reply dgorton 16 hours agorootparentAgreed. Flags are a type of technical debt. Keeping them as full strings in the code encourages and facilitates cleanup.This sort of programmatic naming is a dangerous step down a slippery slope. reply athenot 19 hours agorootparentprevNot OP but multiple code bases may refer to the same flag by a different constant. Having a single string that can be searched accross all repos in an organization is quite handy to find all places where it&#x27;s referenced. reply joshuamorton 10 hours agorootparentespecially when you have different languages with different rules, `MY_FEATURE_FLAG` and `kMyFeatureFlag` and `@MyFeatureFlag` might all be reasonable names for what is defined as `\"my_feature_flag\"` in the configuration.Using just the string-recognizable name everywhere is...better. reply grork 19 hours agorootparentprevIME searching for the name of the flag name and getting 1 result is less helpful than 15 results that directly show point-of-use. reply zellyn 20 hours agoparentprevAfter typing that, and realizing I have a lot more to say, I guess I should write a blog post on the subject reply snorlaxmorlax 19 hours agorootparentYou definitely should! These questions are great, and could use some appropriate context for evaluation. reply ferrantim 19 hours agorootparentprevYes please. Blog would be awesome. reply gastonfournier 19 hours agorootparentprevYes, please! reply zellyn 20 hours agoparentprevOh, and one last(?) update.If you create your own service to evaluate a bunch of feature flags for a given user&#x2F;client&#x2F;device&#x2F;location&#x2F;whatever and return the results, for use in mobile clients (everyone does this), PLEASE *make sure the client enumerates the list of flags it wants*. It&#x27;s very tempting to just keep that list server-side, and send all the flags (much simpler requests, right?), but you will have to keep serving all those flags for all eternity because you&#x27;ll never know which deployed versions of your app require which flags, and which can be removed.[Edit: speling] reply baq 14 hours agorootparentYou should be collecting metrics on used flags and their values if you’re rolling your own. A saas offering will do that for you. reply zellyn 19 hours agoparentprev> I&#x27;d argue that delivering flag definitions is (relatively) easy.I&#x27;d argue that coming up with good UI that nudges developers towards safe behavior, as well as useful and appropriate guard rails -- in other words, using the feature flag UI to reduce likelihood of breakage -- is difficult, and one of the major value propositions of feature flag services. reply Lutger 19 hours agoprevWe use Unleash. There are many things you can do with feature flags and Unleash helps with a lot of them. However, my feeling is 80% of the value comes from 20% of the features. Even a much simpler system provides a ton of benefit. For me, it is top of the list after having automated tests and automated deployments. reply aranchelk 19 hours agoprevWith regard to web-based services, once you’ve got the ability to do canary testing, IMO flags&#x2F;toggles are less compelling — busier code and logic you’ll have to pull out later. reply erik_seaberg 15 hours agoparentCanarying gets you a 1&#x2F;n treatment group, but it might be skew geographically (all affected users are near the canary’s datacenter). You need a percentage in a feature flag if 1&#x2F;n is too big and you want, e.g., 0.1% of traffic. reply gastonfournier 19 hours agoparentprevI agree that if you have only a few changes going to prod, fast and doing canary testing, you should be covered. In my experience that&#x27;s rarely the case because of multiple teams deploying changes at the same time, and even deployments in external services causing side effects in other services. reply aranchelk 17 hours agorootparentEmergent inter-service issues are challenging to deal with regardless.I’ve absolutely seen canary testing work in large environments with a lot of teams doing frequent deploys. The teams need to have the tooling to conduct their own canary testing and monitoring.As soon as you’re involving external services or anything persistent you may not be able to undo the damage of misbehaving software by simply disabling the offending code with a flag.In practice the cost&#x2F;benefit of feature flags has never proven out for me, better to just speed up your deploys&#x2F;rollbacks, the caveat is I’ve only ever worked in web environments, I can imagine with software running on an end user device it could solve some difficult problems provided you have a way to toggle the flag. reply baq 14 hours agoparentprevOTOH a flag gives you an ability to deploy and revert independent of the product’s release cycle. reply rubicon33 18 hours agoprevAs an engineer, I am generally against feature flags.They fracture your code base, are sometimes never removed, and add complexity and logic that at best is a boolean check and at worse is something more involved.I&#x27;d love a world where engineers are given time to complete their feature in its entirety, and the feature is released when it is ready.Sadly, we do not live in that world and hence: feature flags. reply hn_throwaway_99 18 hours agoparentThis misses the point. A big point of feature flags is that you don&#x27;t yet know how features will be perceived until you get them in front of real users.I get what you&#x27;d like \"as an engineer\", but it ignores the needs of the business. reply PH95VuimJjqBqy 17 hours agorootparentThat is not what feature flags are typically used for.They&#x27;re typically used as a way of enabling a change for a subset of your services to allow for monitoring of the update and easier \"rollback\" if it becomes necessary.They can be used for A&#x2F;B testing, but this is not what they&#x27;re typically used for. reply rubicon33 18 hours agorootparentprevIsn&#x27;t that the job a product manager? There are other means and methodologies for gathering user sentiment before you go and build something.You should get as close as you can, release the product, and iterate.Todays world is release the product in some ramshackle form or fashion, collect feedback, iterate. To do that introduces a new construct of Feature Flags that would otherwise not be necessary. reply baq 13 hours agorootparentYeah product manager says ‘run this on 5% of traffic for 2 weeks and then we’ll see what the next iteration should be’. reply Rapzid 7 hours agorootparent\"Also, if one customer is having a particularly bad time we need to be able to disable the feature for them while continuing to collect feedback from everyone else.\" reply mrcarrot 3 hours agorootparent“And management’s priority for Q4 is feature Y, so we’re just going to leave feature X like it is for now” replyadasdasdas 17 hours agoprevMore principles- Require in code defaults for fault tolerance- Start annoying the flag author to delete if the flag is over a month old- Partial rollout should be by hash on user id- Contextual flag features should always be supplied by client (e.g. only show in LA, the location should be provided by client) reply hamandcheese 17 hours agoparent> Partial rollout should be by hash on user idWith a per-flag salt as well, otherwise the same user will always have bad luck and be subject to experiments first. reply zellyn 10 hours agorootparentOur in-house solution hashes flagname+key, and LD does the same but adds salt reply stravant 4 hours agoparentprevBetter yet require always the same default for boolean flags, so that it&#x27;s easier to reason about lifecycle for them. reply tantalor 15 hours agoparentprev> Start annoying the flag author to delete if the flag is over a month oldNo problem, filter that email directly to spam folder. reply angarg12 19 hours agoprevOfftopic but relevant:TL;DR if you break long posts into pages, at least have an option to see the whole thing in a single page.I use a browser extension to send websites to my Kindle. It&#x27;s great for long-ish format blog posts that I want to read, but I don&#x27;t have the time at the moment. However, whenever I see long blog posts that are broken into sections, each one in it&#x27;s own page, it becomes a mess. It forces me to navigate each individual page and send it to my Kindle. Then in the Kindle I have a long list of unsorted files that I need to jump around to read in order.I understand breaking long pieces of text into pages makes it neater and more organized, but at least have an option to see the whole thing in a single page, as a way to export it somewhere else for easy reading. reply dgorton 22 hours agoprevOpen Source knowledge sharing. I like it:\"Unleash is open-source, and so are these principles. Have something to contribute? Open a PR or discussion on our Github.\" reply jacomoRodriguez 18 hours agoprev [–] Is it just me or does this articles text structure and wording strongly indicate that is was written by gpt? reply pests 15 hours agoparentThe only thing worse than AI generated content is now everyone thinks everything is AI generated. reply gingerrr 18 hours agoparentprev [–] Definitely getting strong uncanny valley prose vibes.Hard to tell if it&#x27;s generated or written in an attempt to be as plain English as possible, but either way feels strangely vacuous for a technical opinion piece. There&#x27;s no writer&#x27;s voice. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The document outlines principles for constructing and scaling feature flag systems, a software development technique that enables runtime control of specific features without code deployment.",
      "The outlined principles ensure stability, scalability, and security and include strategies like not exposing personally identifiable information (PII), evaluating flags close to users, limiting payload size, and prioritizing consistent user experience.",
      "These principles are based on the experience from building and scaling the Unleash feature management solution, shared to guide architects and engineers in building large-scale feature flag systems."
    ],
    "commentSummary": [
      "The main focus of the article is the concepts and difficulties related to establishing and scaling feature flag systems for runtime configuration in software development.",
      "The author recommends adopting an Open Telemetry client SDK approach for managing feature flags effectively and discusses the advantages, compromises, and best practices, along with the use of canary testing.",
      "Various suggestions are made for distinguishing between feature flags and app configurations, with different opinions on their function and application in software development reflected in the discussion."
    ],
    "points": 191,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1695385872
  },
  {
    "id": 37614177,
    "title": "Rapidpages – OSS alternative to vercel's v0",
    "originLink": "https://github.com/rapidpages/rapidpages",
    "originBody": "Hey everyone,Really excited to share what I&#x27;ve been working on. Rapidpages is a prompt-first online IDE, think midjourney for front-end developers. I&#x27;ve been working on this for a while and it&#x27;s great to see some interest from companies like Vercel in this space.All you need for self-hosting is an OpenAI key and a GitHub oauth app. Simply clone the repo and play with it. It&#x27;s also available on the cloud at www.rapidpages.ioPlease give it a try and let me know if you have any feedback, and if you like what I&#x27;m doing with Rapidpages, please give it a star on GitHub.Thanks!",
    "commentLink": "https://news.ycombinator.com/item?id=37614177",
    "commentBody": "Rapidpages – OSS alternative to vercel&#x27;s v0Hacker NewspastloginRapidpages – OSS alternative to vercel&#x27;s v0 (github.com/rapidpages) 187 points by muratsu 18 hours ago| hidepastfavorite47 comments Hey everyone,Really excited to share what I&#x27;ve been working on. Rapidpages is a prompt-first online IDE, think midjourney for front-end developers. I&#x27;ve been working on this for a while and it&#x27;s great to see some interest from companies like Vercel in this space.All you need for self-hosting is an OpenAI key and a GitHub oauth app. Simply clone the repo and play with it. It&#x27;s also available on the cloud at www.rapidpages.ioPlease give it a try and let me know if you have any feedback, and if you like what I&#x27;m doing with Rapidpages, please give it a star on GitHub.Thanks! nibab 17 hours agoGreat work! I think the barrier to entry here is going to gradually become smaller and smaller (as models become better and we see more multi-modal models) and the big differentiator here is that you will have lots of open source developers building functionality that is relevant to them (vs keeping this closed-source like Vercel).I am curious how much of the functionality in this area is \"write code that does scaffolding and prompt engineering\" vs \"finetuning and model-level improvements\". reply toddmorey 15 hours agoparentI think this kills the CMS market—-companies like Contentful & Sanity that charge $400&#x2F;mo+ just for a team to be able to edit their own website. There’s been a lot of money made (and web stack complexity added) because of how much domain-specific skill is required to created and edit html content.The only missing piece is direct framework integration (Next, Astro, etc) but at the rate of development I&#x27;ve seen for these projects we&#x27;ll have that by next week. Then you have an intuitive site builder that operates directly on the page code just like another dev on the team.One thing Vercel got really right is being able to click on any element in the page for it to become the context of your prompt. That way, you don&#x27;t have to type \"change the top icon inside the third pricing box to red\". Also you&#x27;ll get faster responses because you don&#x27;t have to feed the AI the entire page &#x2F; component each time. reply kill_nate_kill 13 hours agorootparentHard disagree, this ain&#x27;t gonna kill CMSs, what are you talking about?! Content management goes beyond just a website, especially in the headless cms world. Also those products can be as low as free. reply toddmorey 7 hours agorootparentBeen involved with a lot of Contentful projects large and small that only existed to publish content to web properties. I guess it kills that use case. reply rymate1234 3 hours agorootparentDepends imo. If it&#x27;s purely just a few static pages then yeah I can see this happening but as soon as you have anything like a blog you&#x27;re going to want some sort of content management system surely to manage it?What I see this more doing is eliminating the need for someone to code the glue between the CMS and the website -- you can just ask the AI to add code to get your blogs from Contentful reply crooked-v 14 hours agorootparentprevThere&#x27;s one huge not-immediately-obvious element there: Vercel bandwidth is expensive. My company switched our CMS content over to Prismic in part because serving all media content directly from them was significantly cheaper than doing so through Vercel, even at a fairly low volume. reply BoorishBears 12 hours agorootparentVercel&#x2F;Guillermo Rauch are really onto somethingIt&#x27;s established that cloud is paying a premium for not having to hire: but they&#x27;ve gone a step further and started testing the limits of how much you can overcharge on top of cloud pricing for good DXClerk.dev (another investment of his often pitched along side Vercel) follows a similar model, and almost without fail if I see a Vercel sample pushing a SaaS, Rauch is usually listed as an investor reply satvikpendem 6 hours agorootparentI wonder how it&#x27;ll actually work out for them though, their revenues don&#x27;t seem to justify their valuation, especially since the Zero Interest Rate Phenomenon is now over. For example, in 2022 they only hit $25 million on a $2.5 billion valuation [0].[0] https:&#x2F;&#x2F;getlatka.com&#x2F;companies&#x2F;vercel reply toddmorey 7 hours agorootparentprevYou&#x27;re right. I&#x27;ve noticed this pattern, too. reply re-thc 9 hours agorootparentprev> Clerk.dev (another investment of his often pitched along side Vercel) follows a similar modelNot when there’s auth0 &#x2F; Okta charging 5x more. Completely different. reply BoorishBears 2 hours agorootparentClerk.dev charges like Okta and then gets pushed to people who should be using something like Cognito which costs ~1&#x2F;100th as much.If you&#x27;re not building some $100&#x2F;per&#x2F;month&#x2F;seat enterprise tool there&#x27;s no way you should be reaching for something like Clerk.dev, but obviously that&#x27;d be a constrained market.So now it&#x27;s pushed as a general bandaid for Next.js having a poor auth story, complete with the \"official authentication partner\" badge (but of course, no mention of the investment) reply muratsu 15 hours agorootparentprevYeah - this space is moving really fast. Codesandbox (https:&#x2F;&#x2F;codesandbox.io&#x2F;blog&#x2F;meet-boxy-ai-coding-assistant) released the click on any element functionality back in May.Funny because my original idea was to build a browser extension to modify existing pages with \"click on any element and prompt\" type of workflow. That approach also has certain limitations&#x2F;gotchas too. eg if you click on a list element and ask it to push it down the list, it won&#x27;t work. It&#x27;ll fail as expected but it may be counterintuitive for someone playing with it for the first time. Having said that, I still believe that there&#x27;s value in this UX and will most likely implement it soon. reply muratsu 16 hours agoparentprev100%!! You need one model to understand the initial prompt and figure out a development plan. Once the plan is created, the subtasks can be delegated to specialized smaller models (I think OSS will play a big role in this!). reply nibab 15 hours agorootparenthave you explored using something more lightweight than react ? for example, wouldn&#x27;t it be easier to generate vanilla html with tailwindcss ? reply mellosouls 17 hours agoprevSounds promising but website seems to require a login which shouldn&#x27;t be required for examples. reply muratsu 17 hours agoparentThanks for the advice! I&#x27;m working on building a gallery for people to be inspired next.In case if anyone wants to see what things may look like after a few simple prompts: https:&#x2F;&#x2F;www.rapidpages.io&#x2F;r&#x2F;clmuv2p2r0003l808x4pzdpe6 reply benjaminwootton 3 hours agorootparentYou should just let people try it a few times. It seems a crime to get someone to your website then they click away because they can’t try it. reply morgante 17 hours agoprevThe hosted version doesn&#x27;t seem to work at all. Any time I enter a prompt it just brings me back to login. reply muratsu 17 hours agoparentAh sorry if it wasn&#x27;t clear, you need to login to be able to prompt. I need accounts to prevent openai abuse. reply morgante 17 hours agorootparentI did log in. It still just keeps bringing me back to the login page when I enter a prompt. reply muratsu 17 hours agorootparentThat&#x27;s odd! Do you have anything installed that would prevent from storing the session?Also happy to debug further if you don&#x27;t mind jumping over to discord: https:&#x2F;&#x2F;discord.gg&#x2F;W6jYq46Frd reply residentraspber 17 hours agoparentprevThis was happening to me until I started with a much shorter prompt at first. Then once you get to the editing view, you can use longer prompts. reply DLA 17 hours agoparentprev+1 do loop of login reply HakuG 15 hours agorootparentHad it too, but worked with the the OP on discord. It&#x27;s fixed for me now. reply fuddle 17 hours agoprevThis is great, I&#x27;d love to see an explainer in the readme of how it works with OpenAI. reply chamoda 7 hours agoparentPretty self explanatory in this section of the code base.https:&#x2F;&#x2F;github.com&#x2F;rapidpages&#x2F;rapidpages&#x2F;blob&#x2F;c5f9eacbaba93c... reply sarupbanskota 6 hours agoprevCongrats on the launch Murat. What types of websites is it most suitable for in its current form? reply muratsu 4 hours agoparentThanks!! So far, I have most success with more structured designs. B2B SaaS, simple shopping pages, and forms work the best. It’s really weak with graphic heavy designs (eg Apple). reply codetrotter 16 hours agoprevSame problem here as experienced by others.When I try to use it it asks me to sign in with GitHub, but after having signed in with GitHub and I try to use it again, it still asks me to sign in again.The hamburger menu on your page shows that I am logged in, displaying my GitHub username and my email address.The prompt I used was not long either. reply muratsu 16 hours agoparentDo you mind refreshing and giving it another shot I&#x27;ve just pushed a quick fix reply codetrotter 15 hours agorootparentThank you, now it works :) reply willsmith72 13 hours agoprevOk this is awesome.First ux is pretty shitty. Taking time to create a prompt, getting redirected to login, login successfully, then lose the prompt. Surely you can preserve the prompt with a cookie or even in the url.But the product is cool after that reply willsmith72 13 hours agoparentI can&#x27;t get styling to work nicely. E.g. \"make it dark mode\" or \"make the background dark and text light\" reply ilrwbwrkhv 14 hours agoprevI think the future is about to have a fork: dumb content and smart content. dumb content will be all the ai created articles, websites, music etc. and the actual creative people will move to creating much more intelligent works. reply sramam 14 hours agoparentNot sure I understand the rationale behind this comment in the context of OP. How would you classify RapidPages on your measure: smart or dumb? reply ilrwbwrkhv 12 hours agorootparentIt will be used to create dumb sites which all look the same. reply just-tom 1 hour agorootparentThere&#x27;s no shame in websites looking similar. Not all websites must have a unique design and creative layouts. Some just want to make it about their unique content, and making it look like others&#x27; helps users navigate the familiar. Most cars, dishwashers and phones look the same, while only little small changes differenciate them from competitors. Not everyone should be the Apple or Tesla of their field. Tools like this make the deliverability of content faster, in familiar layouts. reply TheSisb2 14 hours agoprevHow difficult would it be to feed in design system components to the AI? Design system building blocks could serve to improve the quality of outputs vs straight CSS&#x2F;Tailwind reply fy20 8 hours agoparentAre there any open source tools that do something like that (not nessaarily with design &#x2F; UI)? I&#x27;m wondering how you would &#x27;teach&#x27; the AI about your system. I guess it would need fine tuning as the prompt would be too big otherwise. reply muratsu 13 hours agoparentprevThis is a good idea. I think this is worth experimenting with. Are you familiar with any repos with good design systems? I&#x27;ll take a look when I&#x27;ve time. reply nwienert 12 hours agorootparentIf you&#x27;re interested in collaborating, I&#x27;ve been thinking of a feature like this for our platform (https:&#x2F;&#x2F;tamagui.dev) to integrate with the studio we&#x27;re launching soon, send me an email or DM on Discord. reply geniium 11 hours agorootparentThis would be amazing reply yawgmoth 9 hours agorootparentprevMaterial UI &#x2F; MUI is really popular. Fluent UI is another. reply geniium 14 hours agoparentprevAm wondering about the process it would require to build such thing. Maybe cut out in smaller component and then prompt from this smaller component image to code? reply geniium 14 hours agoprevThis is amazing! Have been looking at this. First steps to get prompt to Ui reply k_vi 15 hours agoprevpretty cool to include xkcd for the loading screen :) reply marcc 16 hours agoprev [–] Type a prompt and then get asked to log in. I see this as a dark pattern because if I don&#x27;t want to log in, I&#x27;ve put data and time into your site and not getting results. If you want to keep this workflow, I&#x27;d suggest maybe letting people try it once without logging in?Curious if you measure this and how much drop off there is between fill out a valid prompt and not logging in to see the results. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The speaker introduces Rapidpages, a novel online IDE (Integrated Development Environment) optimized for front-end developers.",
      "This project requires an OpenAI key and a GitHub OAauth app to operate, featuring flexibility as it's accessible on both self-hosting and the cloud platform at www.rapidpages.io.",
      "Rapidpages has garnered interest from tech companies like Vercel and invites users to provide feedback and support the project by starring it on GitHub."
    ],
    "commentSummary": [
      "RapidPages, an open-source competitor to Vercel's v0, strives to limit the reliance on traditional CMS platforms by offering scaffolding, quick engineering, and context-providing prompts via clickable page elements.",
      "While RapidPages might disrupt the CMS market according to some, others assert that CMS software still possesses significance, revealing a controversial viewpoint regarding RapidPages.",
      "Despite minor issues, such as login problems and malfunctioning prompts, which are being resolved by the developer, RapidPages has primarily received positive reviews and proposals for enhancements."
    ],
    "points": 187,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1695400515
  },
  {
    "id": 37619151,
    "title": "Croc: Easily and securely send things from one computer to another",
    "originLink": "https://github.com/schollz/croc",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up schollz / croc Public Sponsor Notifications Fork 1k Star 23.9k Code Issues 115 Pull requests 18 Actions Security Insights schollz/croc main 36 branches 143 tags Go to file Code Latest commit schollz Merge pull request #587 from ferebee/main … f91c7a9 Git stats 1,766 commits Files Type Name Latest commit message Commit time .github Merge pull request #547 from schollz/dependabot/github_actions/docker… src Merge pull request #587 from ferebee/main .gitignore chore(git): ignore .idea and .vscode folders .goreleaser.yml remove twitter .travis.yml update version Dockerfile update dockerfile LICENSE Update year README.md bump 9.6.5 croc-entrypoint.sh Don't force users to set $CROC_PASS croc.service croc.service: use DynamicUser go.mod update deps go.sum update deps main.go update version README.md This project is supported by Github sponsors. croc is a tool that allows any two computers to simply and securely transfer files and folders. AFAIK, croc is the only CLI file-transfer tool that does all of the following: allows any two computers to transfer data (using a relay) provides end-to-end encryption (using PAKE) enables easy cross-platform transfers (Windows, Linux, Mac) allows multiple file transfers allows resuming transfers that are interrupted local server or port-forwarding not needed ipv6-first with ipv4 fallback can use proxy, like tor For more information about croc, see my blog post or read a recent interview I did. Install Download the latest release for your system, or install a release from the command-line: curl https://getcroc.schollz.combash On macOS you can install the latest release with Homebrew: brew install croc On macOS you can also install the latest release with MacPorts: sudo port selfupdate sudo port install croc On Windows you can install the latest release with Scoop, Chocolatey, or Winget: scoop install croc choco install croc winget install schollz.croc On Unix you can install the latest release with Nix: nix-env -i croc On Alpine Linux you have to install dependencies first: apk add bash coreutils wget -qO- https://getcroc.schollz.combash On Arch Linux you can install the latest release with pacman: pacman -S croc On Fedora you can install with dnf: dnf install croc On Gentoo you can install with portage: emerge net-misc/croc On Termux you can install with pkg: pkg install croc On FreeBSD you can install with pkg: pkg install croc Or, you can install Go and build from source (requires Go 1.17+): go install github.com/schollz/croc/v9@latest On Android there is a 3rd party F-Droid app available to download. Usage To send a file, simply do: $ croc send [file(s)-or-folder] Sending 'file-or-folder' (X MB) Code is: code-phrase Then to receive the file (or folder) on another computer, you can just do croc code-phrase The code phrase is used to establish password-authenticated key agreement (PAKE) which generates a secret key for the sender and recipient to use for end-to-end encryption. There are a number of configurable options (see --help). A set of options (like custom relay, ports, and code phrase) can be set using --remember. Custom code phrase You can send with your own code phrase (must be more than 6 characters). croc send --code [code-phrase] [file(s)-or-folder] Allow overwriting without prompt By default, croc will prompt whether to overwrite a file. You can automatically overwrite files by using the --overwrite flag (recipient only). For example, receive a file to automatically overwrite: croc --yes --overwriteUse pipes - stdin and stdout You can pipe to croc: cat [filename]croc send In this case croc will automatically use the stdin data and send and assign a filename like \"croc-stdin-123456789\". To receive to stdout at you can always just use the --yes will automatically approve the transfer and pipe it out to stdout. croc --yes [code-phrase] > out All of the other text printed to the console is going to stderr so it will not interfere with the message going to stdout. Send text Sometimes you want to send URLs or short text. In addition to piping, you can easily send text with croc: croc send --text \"hello world\" This will automatically tell the receiver to use stdout when they receive the text so it will be displayed. Use a proxy You can use a proxy as your connection to the relay by adding a proxy address with --socks5. For example, you can send via a tor relay: croc --socks5 \"127.0.0.1:9050\" send SOMEFILE Change encryption curve You can choose from several different elliptic curves to use for encryption by using the --curve flag. Only the recipient can choose the curve. For example, receive a file using the P-521 curve: croc --curve p521Available curves are P-256, P-348, P-521 and SIEC. P-256 is the default curve. Change hash algorithm You can choose from several different hash algorithms. The default is the xxhash algorithm which is fast and thorough. If you want to optimize for speed you can use the imohash algorithm which is even faster, but since it samples files (versus reading the whole file) it can mistakenly determine that a file is the same on the two computers transferring - though this is only a problem if you are syncing files versus sending a new file to a computer. croc send --hash imohash SOMEFILE Self-host relay The relay is needed to staple the parallel incoming and outgoing connections. By default, croc uses a public relay but you can also run your own relay: croc relay By default it uses TCP ports 9009-9013. Make sure to open those up. You can customized the ports (e.g. croc relay --ports 1111,1112), but you must have a minimum of 2 ports for the relay. The first port is for communication and the subsequent ports are used for the multiplexed data transfer. You can send files using your relay by entering --relay to change the relay that you are using if you want to custom host your own. croc --relay \"myrelay.example.com:9009\" send [filename] Note, when sending, you only need to include the first port (the communication port). The subsequent ports for data transfer will be transmitted back to the user from the relay. Self-host relay (docker) If it's easier you can also run a relay with Docker: docker run -d -p 9009-9013:9009-9013 -e CROC_PASS='YOURPASSWORD' schollz/croc Be sure to include the password for the relay otherwise any requests will be rejected. croc --pass YOURPASSWORD --relay \"myreal.example.com:9009\" send [filename] Note: when including --pass YOURPASSWORD you can instead pass a file with the password, e.g. --pass FILEWITHPASSWORD. License MIT Acknowledgements croc has gone through many iterations, and I am awed by all the great contributions! If you feel like contributing, in any way, by all means you can send an Issue, a PR, or ask a question. Thanks @warner for the idea, @tscholl2 for the encryption gists, @skorokithakis for code on proxying two connections. Finally thanks for making pull requests @maximbaz, @meyermarcel, @Girbons, @techtide, @heymatthew, @Lunsford94, @lummie, @jesuiscamille, @threefjord, @marcossegovia, @csleong98, @afotescu, @callmefever, @El-JojA, @anatolyyyyyy, @goggle, @smileboywtu, @nicolashardy, @fbartels, @rkuprov, @hreese, @xenrox and Ipar! About Easily and securely send things from one computer to another 🐊 📦 schollz.com/software/croc6 Topics golang tcp transfer peer-to-peer file-sharing data-transfer pake Resources Readme License MIT license Activity Stars 23.9k stars Watchers 245 watching Forks 1k forks Report repository Releases 140 v9.6.5 Latest + 139 releases Sponsor this project schollz Zack Sponsor Learn more about GitHub Sponsors Used by 16 + 8 Contributors 82 + 71 contributors Languages Go 82.8% Shell 16.7% Other 0.5% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37619151",
    "commentBody": "Croc: Easily and securely send things from one computer to anotherHacker NewspastloginCroc: Easily and securely send things from one computer to another (github.com/schollz) 182 points by tentacleuno 11 hours ago| hidepastfavorite71 comments tptacek 9 hours agoA more popular and, I think, carefully analyzed alternative, from which croc was inspired, is Magic Wormhole; a good Golang implementation that compiles down to a single binary is wormhole-william:https:&#x2F;&#x2F;github.com&#x2F;psanford&#x2F;wormhole-william&#x2F;releasesI believe croc has some features wormhole doesn&#x27;t (and some anti-features, like being able to pick curves and hashes). But also just that it&#x27;s worth knowing that Magic Wormhole is kind of the \"default\" tool that does this. reply qrv3w 5 hours agoparentI think the main advantage that I like croc over many utilities is that it can resume file transfers from where it left off. I&#x27;m not sure if wormhole has this yet. Of course torrents do this, but I find sharing via torrenting still not super easy for the layperson. reply Bu9818 4 hours agorootparentTorrents also don&#x27;t provide encryption between peers, unless you use SSL torrents, but it&#x27;s clearly designed towards sharing between a group, not one-on-one transfers. reply eviks 4 hours agorootparentHow does the group design hurt 1-1(BitTorrent&#x2F;Resilio sync uses SSL and seems fine for 1-1 design-wise) reply Bu9818 3 hours agorootparentIt&#x27;s just a bit more involved to use for this use case, especially if the data is confidential (having to set the private flag so clients don&#x27;t publish the infohash to DHT, using a built-in tracker in your client, transport layer encryption not provided by default). Things like Resilio are fine, they build on top of the protocol and provide a different UX. reply forty 3 hours agoparentprevIt&#x27;s weird croc doesn&#x27;t mention magic wormhole in their readme, if only to explain the differences with this well known tool, and why one would use croc rather than wormhole, which people are probably more used to using and that they can apt install, etc reply forty 3 hours agorootparentHere is the answer from the project website\"magic-wormhole has most everything (currently its missing capabilities for multiple file transfers and file resuming), but it requires installing lots of the Python ecosystem which is tricky for non-developers (and Windows users).\"For the python part, I guess wormhole-williams works too then. reply pepa65 1 hour agoparentprevI think Wormhole William is great, also has a mobile app. But when I discovered croc, I switched to that, it has been very reliable. From the developer:AFAIK, croc is the only CLI file-transfer tool does all of the following:- allows any two computers to transfer data (using a relay)- provides end-to-end encryption (using PAKE)- enables easy cross-platform transfers (Windows, Linux, Mac)- allows multiple file transfers- allows resuming transfers that are interrupted- does not require a server or port forwarding reply throwaway-4LGvv 2 hours agoparentprevwinden.app is a Magic Wormhole web app for files up to 200MB https:&#x2F;&#x2F;github.com&#x2F;LeastAuthority&#x2F;winden reply cphoover 7 hours agoparentprevThere is also https:&#x2F;&#x2F;wormhole.appWhich looking at your link I guess is unrelated reply tptacek 7 hours agorootparentThis is totally unrelated to Magic Wormhole, and the name is problematic; it has a different security model. reply mc10 7 hours agorootparentprevThis looks very different; it requires having a server to temporarily store the file, while croc and magic-wormhole directly connect two peers (via a relayer) to send the file. reply PBnFlash 5 hours agorootparentIt&#x27;s based on webtorrent, so it will p2p but it is dog slow for serious files. reply auxfil 8 hours agoparentprevWhat does \"carefully analyzed\" mean in this context? Who analyzed it? reply Zambyte 7 hours agorootparentAlso if GitHub stars are anything to go off of, croc is several orders of magnitude more popular. Also croc is written in Go and compiles to a single binary, but there are some helper scripts in the repo for a few things. I really don&#x27;t know why they said all that in their comment. reply tptacek 7 hours agorootparentWormhole-william is a Go port of Magic Wormhole. Github stars are not anything to go off of. If you&#x27;re unaware of Magic Wormhole but have strong opinions about croc, we&#x27;re not speaking the same language and there&#x27;s little point in us irritating ourselves by trying fruitlessly to hash things out. reply wolverine876 7 hours agorootparentprevEmailing files is even more popular; does that make it more secure? reply pepa65 1 hour agoprevAbout relying on the developer to provide the relay server (this was early 2022):The cost of croc is mostly bandwidth - over 8 terabytes of data is sent every month through croc! That&#x27;s amazing to me since I started this project just as a way for me to share files with friends. Four years ago, the public relay server only costed $5&#x2F;month, but now it is costing me $40-50&#x2F;month. The higher cost is enabling file transfers for thousands of people all around the world. reply ajkjk 5 hours agoprevWhich public server does it use by default? I&#x27;m surprised the docs don&#x27;t mention it.More generally, it feels like in 2023 that connecting two computers via a public relay ought to be a solved problem, on the level of, like, DNS. Or maybe it is and I haven&#x27;t heard? reply mc10 3 hours agoparentThe default relay can be found in constants.go [1]: &#x2F;&#x2F; DEFAULT_RELAY is the default relay used (can be set using --relay) var ( DEFAULT_RELAY = \"croc.schollz.com\" DEFAULT_RELAY6 = \"croc6.schollz.com\" DEFAULT_PORT = \"9009\" DEFAULT_PASSPHRASE = \"pass123\" INTERNAL_DNS = false )[1]: https:&#x2F;&#x2F;github.com&#x2F;schollz&#x2F;croc&#x2F;blob&#x2F;f91c7a9948f94007d6be2b0... reply crabbone 59 minutes agoparentprevWhere I live ISPs give static IPs with subscription, so, at least sending files from office home is a non-issue.In principle IPv6 should&#x27;ve solved this problem a long time ago... without a need for third parties. reply IshKebab 4 hours agoparentprevIt is! RustDesk has a really great 2-pane file manager for sending files. Works really well. reply rurcliped 7 hours agopreva recent audit claims the author \"doesn&#x27;t have enough resources to address\" security issues: https:&#x2F;&#x2F;www.openwall.com&#x2F;lists&#x2F;oss-security&#x2F;2023&#x2F;09&#x2F;08&#x2F;2 https:&#x2F;&#x2F;github.com&#x2F;schollz&#x2F;croc&#x2F;issues&#x2F;594 etc. reply hn_throwaway_99 4 hours agoparentI appreciated the links to the audit, but your quote was misleading to me when taken out of context like you did. I interpreted it as basically saying that the author couldn&#x27;t or wouldn&#x27;t address the issues identified. The full quote was:> The upstream author doesn&#x27;t have enough resources to address them on its own and wants to develop fixes in the open. Therefore I have created GitHub issues in the upstream project and publish the full report today.I.e. the \"and wants to develop fixes in the open\" part left me with a very different interpretation from when I first read your comment. reply qrv3w 5 hours agoparentprevThese issues are pretty recent. I would greatly appreciate sponsorship to address issues faster: https:&#x2F;&#x2F;github.com&#x2F;sponsors&#x2F;schollz or just help with PRs. reply AequitasOmnibus 4 hours agorootparentJust wanted to say that Croc is one of the most reliable and straightforward file transfer tools I’ve ever used. It worked so well that I used it for Android (via Termux) to Windows transfers regularly. I only wish there was a way to use it on iOS but I imagine that’s challenging. reply aborsy 4 hours agoparentprevThere was a deadly security flaw two years ago, that required a protocol breaking fix (done within a week I believe):https:&#x2F;&#x2F;redrocket.club&#x2F;posts&#x2F;croc&#x2F;But audits finding vulnerabilities are better than no audit and no known flaw.Do these tools have iOS apps? reply fmajid 4 hours agorootparentMy CVE feed just had a raft on croc:https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43616https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43617https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43618https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43619https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43620https:&#x2F;&#x2F;nvd.nist.gov&#x2F;vuln&#x2F;detail&#x2F;CVE-2023-43621I will stick with wormhole-william, thank you very much. reply mrintegrity 3 hours agorootparentPerhaps you missed this https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37608110 but it has given me fresh, sceptical, eyes with which to read cve reports. reply fmajid 2 hours agorootparentYes, I subscribe to Daniel Stenberg&#x27;s RSS feed and have seen his many articles bemoaning excessive classification of bugs as vulnerabilities. One of these bugs, however, show serious cryptographic deficiencies. Unfortunately there are a lot of cryptography amateurs making stuff without a proper understanding ond making grandiose claims, so my default stance is one of skepticism unless reputable cryptographers have looked at it.I use wormhole-william, the Go version of the Python magic wormhole, and age, mostly because of this Latacora endorsement:https:&#x2F;&#x2F;www.latacora.com&#x2F;blog&#x2F;2019&#x2F;07&#x2F;16&#x2F;the-pgp-problem&#x2F; replygyrovagueGeist 9 hours agoprevI&#x27;m surprised it&#x27;s not listed on the README directly but in case you looked for it like me :) here is what their site says about the alternative you&#x27;re probably thinking of:\"toss cleverly encodes port information in the code phrase, making it simple but it requires using connected computers (no firewalls) and the long random-ish code phrase is hard to “tell” someone. magic-wormhole has most everything (currently its missing capabilities for multiple file transfers and file resuming), but it requires installing lots of the python ecosystem which is tricky for non-developers (and windows users).\" reply vdm 4 hours agoparenthttps:&#x2F;&#x2F;schollz.com&#x2F;tinker&#x2F;croc6&#x2F; reply gregschlom 8 hours agoprevHaven&#x27;t tried this but I recently started using syncthing.net and I highly recommend it.Like rsync, it only sends the chunks of the file that changed, so it can be extremely fast for small changes in large files. It&#x27;s able to use a variety of methods to connect including good through relay servers if the machines can&#x27;t directly talk to each other. reply ekianjo 2 hours agoparentSyncthing is not for ad hoc file sending. Totally different use case reply _-_-__-_-_- 7 hours agoparentprevI also use syncthing. It&#x27;s been working so well that it&#x27;s magical for sending files and keeping a passwork manager up-to-date between devices. My next step for my homelab, is to run my own announce server and relay on my local network. reply blooalien 4 hours agorootparentAlso fun to run yourself a little private wireguard server for easy access to all that your homelab offers from anywhere \"outside\" your home network. reply dennis-tra 3 hours agoprevI’m currently working on a new version of pcp [0]. Based on croc, magic-wormhole and the likes it doesn’t require a relay. It uses the IPFS DHT as a discovery point to connect two machines. Haven’t touched the currently released code in two years but the new hole punching capabilities of libp2p show promising result so I’m working on a new version.[0] https:&#x2F;&#x2F;github.com&#x2F;dennis-tra&#x2F;pcp reply garganzol 18 minutes agoparentHere is my feedback about the pcp&#x27;s main GitHub page, if you don&#x27;t mind: - Move \"Motivation\", \"Project Status\", \"How Does It Work?\" somewhere else - Add \"What is It?\" and \"Encryption\" sections and place them just before the \"Usage\" section. Keep them reasonable small, the smaller the betterI believe that it will help the project to have a much better resonance with the target audience. reply mc10 3 hours agoparentprevDoes this run a mini IPFS node on the sender and relayer and rely instead on the IPFS network being up to propagate the DHT changes through the network? reply dennis-tra 3 hours agorootparentIt’s just running a very lightweight libp2p host that speaks the DHT protocol. It’s basically just taking the bare minimum part of Kubo (IPFS) that’s necessary to interact with the DHT.It’s then relying on the rest of the IPFS network to propagate the record for discovering the sender and receiver. reply stkdump 3 hours agoparentprevCan you send files from one mobile network connected computer to another? reply zelphirkalt 1 hour agoprevTried it with a friend a few weeks ago and unfortunately it failed. It first began transferring the file, then for seemingly no reason I stopped receiving and then after waiting a bit got EOF and the file was not fully transferred. Seems like it is not that reliable in transferring files, or it has requirements, like open ports or so. But then why would it start and then stop trnasferring? reply Zetobal 1 hour agoprevI like croc, wormhole, snapdrop and whatever else there is I just don&#x27;t get that there is no universal convenient standard for transferring files from one device to another over a wired&#x2F;wireless connection. Mindboggling that most people use cloud hosting or email to transfer a file from one device to another when they are just 30cm from each other. reply Gabrys1 1 hour agoparentUsed to be \"put it on a USB stick\". Now no-one carries those so email&#x2F;google drive it is :-)When sharing files between devices I own (including my mobile phones) I attach them to a draft email to myself, then get them from the drafts on the other device. reply m000 1 hour agoprevI wish there was a gui version for croc. I&#x27;ve used it a couple of times to send files to non-techie friends. While croc worked great, having to spend 15&#x27; on the phone guiding them how to run the command felt like an unnecessary hassle. reply rkangel 1 hour agoparentFor that application, Web Wormhole is unbeatable: https:&#x2F;&#x2F;webwormhole.io&#x2F; reply mr_mitm 1 hour agorootparentBut here you download the source code every time you use it. It&#x27;s not end-to-end anymore, as the person who designed the website can deliver malicious code, unless you pin the JS somehow.I wish magicwormhole or croc came with every major OS preinstalled. reply forty 1 hour agorootparentYou can apt install magic-wormhole on Debian.I&#x27;m not aware of any other major OS ;) reply winrid 4 hours agoprevI don&#x27;t see KDE Connect mentioned so I&#x27;d like to just say it&#x27;s great. Send files and clipboard between PC&#x2F;Mac&#x2F;Linux&#x2F;Android&#x2F;iOS. And it&#x27;s a native QT app so pretty light. Only works on same network though. reply mixmastamyk 2 hours agoparentUnfortunately didn&#x27;t work well for me using the gnome libraries on linux or mobian&#x2F;phosh. (If you don&#x27;t want to install KDE just for file transfer, etc.) scp on the other hand is bulletproof when hosts are directly accessible. reply jdironman 8 hours agoprevI am having a hard time understanding. Does this allow you to send &#x2F; receive anywhere? Across the internet I mean. what external server does it use for &#x27;stapling&#x27; the connection or is it also expected that you self host a relay server + set up the necessary ports etc. Do both ends require a relay server? reply jdironman 8 hours agoparent>I am having a hard time understanding. Does this allow you to send &#x2F; receive anywhere? Across the internet I mean. what external server does it use for &#x27;stapling&#x27; the connection or is it also expected that you self host a relay server + set up the necessary ports etc. Do both ends require a relay server?Sorry, I have spoke too soon. I see now it uses a public relay by default, and you can self host as needed. Sorry for the unnecessary comment! reply lopkeny12ko 2 hours agoprevThis isn&#x27;t really \"sending files from one computer to another\" aka P2P, as the title claims, if a relay is required. reply jmbwell 5 hours agoprevPrinting and transferring files: two operations that computing will never solve once and for all reply pkulak 4 hours agoparentOr what to call it. reply carterschonwald 8 hours agoprevSo one thing is that this by default uses a specific public relay server to setup the handshake. So there’s a little mitm by default. reply mc10 7 hours agoparentmagic-wormhole (which croc was inspired by) also uses a public relay server: https:&#x2F;&#x2F;magic-wormhole.readthedocs.io&#x2F;en&#x2F;latest&#x2F;welcome.html...Any tool that wants to reliably connect two clients P2P is going to need something like a TURN server to traverse restrictive NATs. See for instance Tailscale&#x27;s use of DERP servers: https:&#x2F;&#x2F;tailscale.com&#x2F;blog&#x2F;how-tailscale-works&#x2F;#encrypted-tc... reply ComodoHacker 2 hours agoparentprevThere&#x27;s no MITM, transfers are end-to-end encrypted. You don&#x27;t have to trust the relay. reply dheera 2 hours agoprevI wish there was an easier way to send things to&#x2F;from a phone. I use a 1-person slack channel for this because I can&#x27;t find a simpler way.Google Drive and Dropbox are both awful mobile clients. reply mixmastamyk 2 hours agoparentWas just dissing KDE connect but it works well in most combinations.Also you can connect a USB cable. reply dheera 2 hours agorootparentUSB cables involve about 5 steps and half my cables don&#x27;t work because they were not built sturdy enough and got chomped by my office chair, standing desk, or something else.There should be a way to just right click and \"send to phone\" reply eviks 4 hours agoprevWhat about mobile computers? reply celtoid 7 hours agoprevhttps:&#x2F;&#x2F;drop.lolGithub: https:&#x2F;&#x2F;github.com&#x2F;mat-sz&#x2F;filedrop reply Freedom2 9 hours agoprev [–] I have a few qualms with this app. I&#x27;ve easily and securely sent things from one computer to another using a simple FTP server, with all of the features that croc has listed. As for CLI support, I&#x27;ve written a small helper tool that allows me to transfer via CLI - giving me more security since I don&#x27;t pull in any dependencies in my own code. reply klabb3 9 hours agoparentFTP requires one-time config though, setting up credentials. Of course, it also needs a port to be opened. Croc and other apps like this[1] target different use cases.[1]: I am building a UX-focused app over at payload.app, but there are many others, both CLI and GUI&#x2F;web apps. reply rajamaka 9 hours agoparentprevYour qualm with the app is that you like FTP? reply ajot 7 hours agorootparentWhy would anyone use Dropbox? reply rajamaka 1 hour agorootparentWhy would anyone use TikTok when they can FTP videos to each other? reply johng 9 hours agoparentprev [–] Isn&#x27;t FTP still plaintext? reply LinuxBender 8 hours agorootparentIsn&#x27;t FTP still plaintext?It can be or it can be encrypted. FTPS(i|e) implements encryption over FTP. I prefer SFTP as it just uses one port which I can define. SFTP also works better through firewalls and NATs.VSFTPD is an example of an FTP server that supports encryption or FTPS. reply chrisweekly 9 hours agorootparentprev [–] I read \"FTP\" as \"SFTP\". replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"croc\" is a file-transfer tool that utilizes a relay system and end-to-end encryption for secure file and folder transfer between computers.",
      "The tool has cross-platform compatibility and supports resumed interrupted transfers and multiple file transfers. It works with platforms such as macOS, Windows, Unix, and Android.",
      "Features of the tool include sending text, using a proxy, changing encryption curves and hash algorithms, and self-hosting the relay. The project is open-source and backed by Github sponsors."
    ],
    "commentSummary": [
      "The article delves into various file transfer tools, namely Croc and Magic Wormhole, detailing their features, shortcomings, and user experiences.",
      "It emphasizes the importance of security audits and vulnerability findings, shedding light on issues involving public relay servers, their maintenance cost, and alternative options.",
      "User discussions focus on different file transfer methods including P2P, relay servers, FTP, Dropbox, and mobile clients, along with their convenience and security aspects."
    ],
    "points": 178,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1695425701
  },
  {
    "id": 37616171,
    "title": "CFPB kicks off rulemaking to remove medical bills from credit reports",
    "originLink": "https://www.consumerfinance.gov/about-us/newsroom/cfpb-kicks-off-rulemaking-to-remove-medical-bills-from-credit-reports/",
    "originBody": "Skip to main content An official website of the United States government Español 中文 Tiếng Việt 한국어 Tagalog Pусский العربية Kreyòl Ayisyen (855) 411-2372 Submit a Complaint Search Consumer Education Rules & Policy Enforcement Compliance Data & Research News Newsroom CFPB Kicks Off Rulemaking to Remove Medical Bills from Credit Reports Proposals under consideration would help end coercive debt collection tactics, clean up inaccurate data, and improve credit score predictiveness SEP 21, 2023 SHARE & PRINT WASHINGTON, D.C. – The Consumer Financial Protection Bureau (CFPB) today announced it is beginning a rulemaking process to remove medical bills from Americans’ credit reports. The CFPB outlined proposals under consideration that would help families financially recover from medical crises, stop debt collectors from coercing people into paying bills they may not even owe, and ensure that creditors are not relying on data that is often plagued with inaccuracies and mistakes. “Research shows that medical bills have little predictive value in credit decisions, yet tens of millions of American households are dealing with medical debt on their credit reports,” said CFPB Director Rohit Chopra. “When someone gets sick, they should be able to focus on getting better, rather than fighting debt collectors trying to extort them into paying bills they may not even owe.” A 2022 report found that roughly 20% of Americans report having medical debt, but previous research by the CFPB has shown that medical billing data on a credit report is less predictive of future repayment than reporting on traditional credit obligations. Mistakes and inaccuracies in medical billing are common and can be compounded by problems such as disputes over insurance payments or complex billing practices. The Fair Credit Reporting Act restricts creditors’ ability to use medical information in making credit decisions and places limits on the inclusion of medical information on credit reports. The FCRA also granted five financial regulators authority to create regulatory exemptions to the restriction on creditors’ use of medical information, and in 2005, those regulators created an exception to allow creditors to rely on medical data if it could be characterized as “financial information.” The document released today is an outline of proposals and alternatives under consideration for the CFPB’s medical debt rulemaking. If finalized, they would: Remove medical bills from consumers’ credit reports: Consumer reporting companies would be prohibited from including medical debts and collection information on consumer reports that creditors use in making underwriting decisions. Stop creditors from relying on medical bills for underwriting decisions: The proposal would narrow the 2005 exception and prohibit creditors from using medical collections information when evaluating borrowers’ credit applications. Stop coercive collection practices: As unpaid medical bills would no longer appear on consumers’ credit reports used by creditors in making underwriting decisions, debt collectors would no longer be able to use the credit reporting system as leverage to pressure consumers into paying questionable debts. The proposal would not stop creditors from obtaining medical bill information for other purposes, such as verifying the need for medical forbearances, or evaluating loan applications to pay for medical services. In advance of beginning the rulemaking process, the CFPB has engaged with the public on this issue. In a public hearing in July 2023, the CFPB met with and listened to people from across the country on the impact poor medical billing practices and coercive credit reporting have on patients and families. The CFPB, in partnership with other agencies, is currently reviewing information submitted by the public on medical billing practices, including high-cost specialty financial products such as medical credit cards and installment loans. The CFPB continues to receive complaints from the public about illegal debt collection and credit reporting practices related to medical billing. The CFPB is taking steps to empower consumers by having them take more control over their personal financial data and how it is being used by companies. In addition to today’s announcement, the CFPB previously launched an inquiry into the practices of data brokers, and how companies that track and collect information on people’s personal lives impact consumers. As announced on August 15, 2023, the CFPB is considering proposals relating to data brokers. The document released today is an outline of proposals and alternatives under consideration for the CFPB’s Fair Credit Reporting Act Rulemaking. The medical debt announcement, and the August announcement on data brokers, are part of that rulemaking. Read today’s Outline of Proposals and Alternatives Under Consideration. Read Director Chopra’s remarks at a call hosted by Vice President Kamala Harris Additional related materials are available on our rulemaking page. Consumers can submit complaints about financial products or services by visiting the CFPB’s website or by calling (855) 411-CFPB (2372). Employees who believe their companies have violated federal consumer financial protection laws are encouraged to send information about what they know to whistleblower@cfpb.gov. ### The Consumer Financial Protection Bureau is a 21st century agency that implements and enforces Federal consumer financial law and ensures that markets for consumer financial products are fair, transparent, and competitive. For more information, visit consumerfinance.gov. Topics: • CREDIT REPORTS AND SCORES • MEDICAL DEBT • RULEMAKING • DEBT COLLECTION PRESS INFORMATION If you want to republish the article or have questions about the content, please contact the press office. Go to press resources page STAY INFORMED Subscribe to our email newsletter. We will update you on newsroom updates. Email address Sign up See Privacy Act statement Subscribe to our RSS feed to get the latest content in your reader. Subscribe to RSS About Us Contact Us Careers Events Industry Whistleblowers CFPB Ombudsman FOIA Privacy Website Privacy Policy & Legal Notices Data Open Government Information Quality Guidelines Diversity & Inclusion Administrative Adjudication Plain Writing Accessibility Office of Civil Rights No FEAR Act & Cummings Act Tribal USA.gov Office of Inspector General An official website of the United States government",
    "commentLink": "https://news.ycombinator.com/item?id=37616171",
    "commentBody": "CFPB kicks off rulemaking to remove medical bills from credit reportsHacker NewspastloginCFPB kicks off rulemaking to remove medical bills from credit reports (consumerfinance.gov) 173 points by geox 16 hours ago| hidepastfavorite176 comments seatac76 14 hours agoTangential but kudos to Rohit Chopra, he has done a stellar job at CFPB, between the credit reporting changes and the elimination of bank fees alone he has had quite the impact. Just a few years it looked more likely that the CFPB would be dissolved. reply capital_guy 14 hours agoparentI agree that Chopra is excellent at his job. Unfortunately, It&#x27;s still in danger of being dissolved. The Supreme Court is hearing a case in October challenging the legality of the agency&#x27;s funding mechanism. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Consumer_Financial_Protection_... reply voldacar 14 hours agorootparent>Its structure included a director that could not be fired by the President except for cause, and the ability to request funding from the Federal Reserve rather than the United States CongressI mean, that does sound pretty insane reply MarkMarine 13 hours agorootparentIts structured this way because it was a reaction to the 08 crash and subsequent bailout of wall street. Seems to be the only reform that came out of that area, and measured against how much the banks chafe against the CFPB, I’d say it was working.This would also challenge the federal reserve structure. reply butlerm 10 hours agorootparentThe Federal Reserve started as a government sponsored banking cartel to solve a specific problem. It was not intended to be a regulatory agency until not that many years ago, and is not appropriate for the job. Bank and consumer finance regulation should fall under the Treasury Department or the Commerce Department somewhere. There are agencies that have similar responsibilities now. Those agencies should be regulating the banks, not the banks or some subsidiary of a banking cartel regulating themselves. The recent bank failures are a case in point. reply rgbrenner 11 hours agorootparentprevThe CFPB is part of the federal reserve and both of those rules also apply to the federal reserve. It makes sense that a bureau of the Fed would follow Fed rules.The Fed is tasked with financial regulation, and did some of the work of the CFPB before it was created.By design the Fed is independent, including funding, from Congress. If you&#x27;re curious why, there&#x27;s lots of history around how and why a central bank was created... dating all the way bank to Andrew Hamilton. reply majormajor 12 hours agorootparentprev\"director that could not be fired by the President except for cause\"This is the same as the FTC and others.\"This Court, as the majority acknowledges, has sustained the constitutionality of the FTC and similar in- dependent agencies. See ante, at 2, 13–16. The for-cause protections for the heads of those agencies, the Court has found, do not impede the President’s ability to perform his own constitutional duties, and so do not breach the separation of powers.\"https:&#x2F;&#x2F;www.supremecourt.gov&#x2F;opinions&#x2F;19pdf&#x2F;19-7_n6io.pdf reply pyuser583 12 hours agorootparentIt’s different from the FTC because its funding comes directly from the federal reserve.So it’s independent of both the President and Congress.It’s more independent than many courts.What could possibly go wrong? reply rgbrenner 11 hours agorootparentIt’s different from the FTC because its funding comes directly from the federal reserve.So the CFPB--a bureau within the federal reserve--cannot be funded by the federal reserve?So it’s independent of both the President and Congress.Just like the federal reserve.The federal reserve doesn&#x27;t just set interest rates and lend money... they&#x27;re also tasked with regulation of the financial system. So it makes sense that the CF(inancial)PB would be part of it. In fact, the creation of the CFPB was just the consolidation of work done by several bureaus, including the federal reserve. Kind of like when DHS was created--just a reorganization. reply pyuser583 7 hours agorootparentThe Federal Reserve is quite different from the FTC, so my statement still stands. reply kadoban 12 hours agorootparentprev> What could possibly go wrong?They might accidentally get something done that helps people? reply tivert 12 hours agorootparent>> What could possibly go wrong?> They might accidentally get something done that helps people?Since you&#x27;re missing the point: make me dictator, so I can finally get stuff done that helps people.Too much independence is a recipe for serious problems, even if (theoretically) it could be used accomplish major things. reply kadoban 12 hours agorootparentIf there&#x27;s serious problems, then Congress can act. The structure just makes it harder for Republicans to kill it quietly for an unsupportable reason. reply butlerm 10 hours agorootparentIt is quite difficult for Republicans to reverse any act of Congress without another act of Congress. The assent of the House, the Senate, and (usually) the President is required. reply kadoban 10 hours agorootparentAnything that specifically needs a law passed to undo it is safer than one that can just have its budget ~zeroed out in the yearly budget, or any of the more-than-yearly CRs and debt-ceilings and whatever other nonsense negotiations.This is for both reasons of public scrutiny (there&#x27;s so much in the budget that it&#x27;s easy for things to get relatively lost), but also because the budget, in practice, just needs 50+1 votes. Usual laws need 60 due to Senate procedures. Ignoring the House since there&#x27;s not much difference there. replydragonwriter 11 hours agorootparentprev> This is the same as the FTC and others.No, its not; the Fed has a board of five commissioners, not a single director. This is rather the norm for independent executive-branch agencies with leadership that can be removed only for cause. reply majormajor 10 hours agorootparent> No, its not; the Fed has a board of five commissioners, not a single director. This is rather the norm for independent executive-branch agencies with leadership that can be removed only for cause.Is there a specific Constitutional requirement for a board as well as a Chair if it&#x27;s for-cause-only?Because otherwise that seems like a very narrow difference to ask the Court to rule on regarding the appointment&#x2F;firing of the head... reply dragonwriter 10 hours agorootparent> Is there a specific Constitutional requirement for a board as well as a Chair if it’s for-cause-only?Well, no.The specific rule is that for-cause-only removal is inconsistent in general with the vesting of executive power in the President in Article II, with two exceptions:(1) Agencies with a role similar to that of the FTC in 1935 that exercise no part of the executive power but serve solely as a legislative&#x2F;judicial aid, and(2) Inferior officers (not principal officers of agencies) with limited duties and no policymaking role.(While each of these rules comes from separate lines of cases, they were summarized together and referenced in support of the decision by which the Supreme Court struck down the for-cause-only rule at the CFPB [0], which specifically found that the for-cause-only provision combined with the single-director structure would clearly violate separation of powers as a reason not to further extent the existing exceptions to the prohibition of for-cause-only restrictions to allow the one at the CFPB.)> Because otherwise that seems like a very narrow difference to ask the Court to rule on regarding the appointment&#x2F;firing of the head…The Court has already ruled against that, the present challenge is to the funding structure.[0] https:&#x2F;&#x2F;www.supremecourt.gov&#x2F;opinions&#x2F;19pdf&#x2F;19-7_new_bq7d.pd... reply gmerc 13 hours agorootparentprevDoes it in the light of how the US government actually works? reply voldacar 5 hours agorootparentCreating a separate arm of the government accountable to neither the president nor congress seems like the legal equivalent of a rootkit reply leereeves 13 hours agorootparentprevTrying to prevent some future elected government from changing course? I can see the appeal, but yeah, it sounds like a bad precedent. reply MarkMarine 13 hours agorootparentCongress could always change the laws that govern it. This just prevents a single executive from replacing the head and neutering the agency as the tides change reply butlerm 10 hours agorootparentThe president and the entire executive branch have an obligation to faithfully execute the law. For all officers of the United States, that is a sworn obligation. reply gmerc 3 hours agorootparentAnd how has that been going with Trump? This feels like a prayer at this point reply arcbyte 12 hours agorootparentprevThat&#x27;s not a desirable feature in a representative democracy. reply turquoisevar 7 hours agorootparentYou’d be surprised how few representative democracies suffer from the same whiplash inducing pendulum effect the US suffers from.In most western nations the top civil servant and all those below them are non-partisan career civil servants that keep the ship running at all times and have better employment protections than the average employee (which already requires for cause in those countries).A new Minister’s (Secretary in US parlance) role is mainly that of someone who plots a course and the civil servants in the ministry try to follow it.As a side note, the concept or “government shutdown” is also entirely foreign in those countries, if not outright ridiculous. reply rightbyte 12 hours agorootparentprevI think you kinda want some institutional inertia though. reply maxerickson 11 hours agorootparentprevNot having a unitary executive seems perfectly compatible with representative democracy. reply MarkMarine 12 hours agorootparentprevYour representatives are in congress reply ipaddr 11 hours agorootparentprevSimilar to supreme court judges reply leereeves 9 hours agorootparentprevOf course that&#x27;s appealing when it&#x27;s something you want, but what would think of it if the Republicans win the House, Senate, and Presidency again (as they did in 2016) and do something similar?For example, they might create an Administration of Land Management with authority over all extraction rights on federal land, funded by fees paid for those rights, and with a director the President cannot remove except for cause.And it wouldn&#x27;t be possible for Democrats to change that until they too won the House, Senate, and Presidency at the same time.A government full of agencies like that would make elections mostly irrelevant, and things would change only when one party won everything. reply MarkMarine 4 hours agorootparentSomeone said it earlier, but this horror you’re describing is the case in plenty of developed countries. replyJumpCrisscross 14 hours agorootparentprev> in danger of being dissolvedDefunded, not dissolved. reply capital_guy 13 hours agorootparentIn government there is no difference. reply Supermancho 9 hours agorootparent> In government there is no difference.The defunding means that future budget cannot be allocated. There is a window for the aggregate organization, structure, and assets to be renamed or absorbed (changed) to satisfy the implied decision&#x27;s objections. In this case, it&#x27;s a matter of how it&#x27;s funded: as an arm of the Federal Reserve, as I understand it. If Biden claims it (in some way), it could remain. reply plussed_reader 12 hours agorootparentprevSame ephemera. reply user3939382 15 hours agoprevThe newest FICO models already exclude this debt, though this is a much more significant step since most lenders and loan types you care about use very old FICO models that do include it and are unlikely to be updated any time soon. reply nradov 15 hours agoparentDo you know why lenders still use very old FICO models? Is this just inertia, or are the new models more expensive, or do the old models predict default risk better for those loan types? reply InTheArena 11 hours agorootparentThe big reason is that the different scores come out of the models. That may seem counter-intuitive, but models tend to be very tied to specific populations in specific ranges, and stability is often as valuable as predictability. Different model behavior - up or down - means that financial institutions have to retest their entire strategy to make sure that it doesn&#x27;t screw up the segmentation and models that they have layered on top of various credit scores. This is not a trivial or short process - It&#x27;s pretty common to see 6 month and 12 month champion&#x2F;challenger tests.Even then, assuming that there is not a significant lift in predictability (unlikely as the FICO score is good at what it does) or addressability (do people who previously had a thin file now have enough data to make a decision) then you also end up looking and saying that it&#x27;s not worth the changes to move to a newer score.Also, scores are incredibly regulated. Proving that the model you layer on top of the FICO score doesn&#x27;t have a disparate impact (something standing in as a proxy to a protected bit of information such as ethnicity) is expensive.VantageScore doesn&#x27;t really change this; it&#x27;s a copycat of the FICO score that came about because the credit unions don&#x27;t like having the score aspect out of their control and would rather people just pay them instead of an independent third party instead.The only thing that really would change the score in any way is additional data - but social media mining for scores is not acceptable outside of China (where their score predicts compliance with government not credit risk). reply supertrope 8 hours agorootparentprevConsumer credit is heavily regulated. Not only is discriminating based on protected class illegal, the bank has to be able to explain its credit risk model to regulators. They can&#x27;t use stuff like machine learning because that would be an unexplainable black box.Credit risk modeling is literally the core of their business. Often banks don&#x27;t use FICO directly. They run their own model. They want to pick up as many customers who are likely to successfully finish their loan payments without picking up too many customers who are relatively more likely to default if there&#x27;s a recession. A few basis points here and there is a big deal. There&#x27;s models for mortgages, car loans, credit cards, boat loans, etc.The licensing cost of a new model, or just the upgrade costs must be justified by some benefit. Banks are stereo-typically slow moving. reply user3939382 14 hours agorootparentprevJust a complete guess. Banks and related insurance are using historical data with prediction models to forecast risk. Once the FICO version changes all that data is apples to oranges and the forecasting is less accurate. reply dmoy 14 hours agorootparentprevI think up until last year it was federal policy for Fannie Mae & Freddie Mac to use fico 5, and the rest of the industry kinda follows.Now I think they can use a new model, but it&#x27;s probably some inertia on changing. reply FireBeyond 15 hours agorootparentprevMore expensive, for one. That&#x27;s why CreditKarma and other &#x27;free score&#x27; services often use Vantage, rather than FICO. reply adamsb6 15 hours agoprevWhat are going to be the second-order consequences of such a policy?Are providers going to run credit checks on you before they agree to take you on as a patient?Require that you sign a document that gives them the right to garnish your wages for non-payment?Require up-front payment for services?Increase prices to cover the revenue lost to people that realize how little consequence there is for non-payment? reply bushbaba 15 hours agoparentPlease do upfront pricing. It’s so annoying getting a bill afterwards how the fully covered treatment was actually not covered and multiple thousands. Leading to haggling with the insurance company and hospital. reply flutas 15 hours agorootparentMy favorite ones.\"Payment is due at the time services are rendered\"So you pay what they say it costs.Then months later you get a random bill from them for more. reply Arrath 8 hours agorootparentI&#x27;ve gotten &#x27;bills&#x27; (well, the insurance company telling me I owe a provider some money) for services that haven&#x27;t been rendered! Just because my provider tried to pre-approve something and insurance denied it but the letter was phrased in a way that implied I was on the hook for it. Luckily a call to my doctor cleared that up. reply thmsths 14 hours agorootparentprevHow can they reasonably expect you to pay in these circumstances? They were clear about wanting payment upfront, you agreed to the price, (presumably) paid them, received the service&#x2F;treatment. That should be the end of the story. What legal basis do they possibly have to send a bill months later? \"We felt like we needed more money because we had a bad quarter\" is not going to cut it. reply callalex 12 hours agorootparentBecause what are you gonna do about it? They have the ability (unless this goes through) to prevent you from seeking employment, renting, or buying a roof over your head if you don’t bend over and do whatever they tell you to do. reply nradov 14 hours agorootparentprevIn many cases the patient has insurance with set co-pays so providers collect only the co-pay at time of service based on a good faith assumption that the insurer will pay the rest of the claim at an agreed rate. But if the insurer doesn&#x27;t pay by a certain deadline then the provider might bill the patient for the balance. Then the patient has to argue with their insurer over the claim.This is a screwed up system that leaves patients caught in the middle of commercial disputes. But providers do deserve be paid for services rendered and it would be unfair to just stiff them. reply bb88 13 hours agorootparentBut also, the patient paid for health insurance for the explicit reason that insurance provides protection against surprise costs, often paying thousands of dollars per year for it.So fuck the patient? That&#x27;s the current regime. reply nradov 11 hours agorootparentYou may have a misunderstanding of medical insurance. Such policies are very specific and never promised blanket protection against surprise costs.Let&#x27;s say you crash your car and take it to an auto body shop for repair. If for some reason your auto insurance doesn&#x27;t pay for the repairs would you tell the mechanic to fuck off and eat the cost? I understand there are issues in healthcare with price transparency and estimates, but the basic principle is the same. Regardless of insurance or lack thereof, customers are obligated to pay for services they receive. reply bb88 9 hours agorootparentYou must be confused about how health insurance works in the US, as well as the effectiveness of a bad analogy. Also people who disagree with your must certainly be ignorant -- particularly on HN.> If for some reason your auto insurance doesn&#x27;t pay for the repairs would you tell the mechanic to fuck off and eat the cost?I have a free choice of both auto insurance and car mechanic. On the other hand I may not have a choice about health insurance company (usually from the employer) or the emergency room I&#x27;m sent in the ambulance to -- particularly if I&#x27;m unconscious. reply nradov 8 hours agorootparentActually I am quite familiar with how health insurance works in the US. If you don&#x27;t like the plans available through your employer you are welcome to buy another policy elsewhere. You have free choice, although you might lose your employer&#x27;s subsidy. reply supertrope 7 hours agorootparentThat employer subsidy is a massive difference!e.g. Your payroll deduction is $50 per pay period. The deductible is $2000 per year. Out of pocket max $4000. The network is wide. This is because your employer is paying for the other 85% of this plan and employed people need less medical services on average than the public as a whole.You switch to a plan off Healthcare.gov. It costs $500&#x2F;mo. Deductible is $8000&#x2F;year and out of pocket max is $15000. The network of providers is only in one state and only at one brand. I don&#x27;t think anyone would actually reject a cushy employer plan for an exchange plan. replySilasX 11 hours agorootparentprevI’ve had this happen to me as a cash&#x2F;self-pay&#x2F;no insurance involved patient before. They’re shameless. reply toomuchtodo 15 hours agorootparentprev> Starting in 2022, there are new protections that prevent surprise medical bills. If you have private health insurance, these new protections ban the most common types of surprise bills. If you’re uninsured or you decide not to use your health insurance for a service, under these protections, you can often get a good faith estimate of the cost of your care up front, before your visit. If you disagree with your bill, you may be able to dispute the charges. Here’s what you need to know about your new rights.https:&#x2F;&#x2F;www.cms.gov&#x2F;newsroom&#x2F;fact-sheets&#x2F;no-surprises-unders...https:&#x2F;&#x2F;www.cms.gov&#x2F;NOSURPRISEShttps:&#x2F;&#x2F;www.consumerfinance.gov&#x2F;about-us&#x2F;blog&#x2F;no-surprises-a... reply darth_avocado 13 hours agorootparentThe problem is that disputing claims is hard and puts an unnecessary burden on the patient at a time when they are struggling elsewhere. Companies operate in bad faith and more needs to be done to regulate companies (hospitals and insurers). reply AuryGlenz 13 hours agorootparentprevWhy the hell shouldn’t that apply to people that are going to use insurance? The reason our healthcare costs are so high is because everyone with insurance past their deductible is price insensitive. People might at least care about their copay enough to make a difference.I know providers will balk because they negotiate with different insurers, but if they know how much they’re going to bill after the fact surely they can give you an estimate before. reply YeBanKo 14 hours agorootparentprevHow can you do an upfront pricing for emergency situations? reply FireBeyond 13 hours agorootparentWait til you hear about how United Healthcare was sued for not covering Lifeflight flights from car accidents because \"no preauthorization was obtained\"... reply YeBanKo 12 hours agorootparentCan you link to a good source for this story? reply marcus0x62 11 hours agorootparentprevSince 1986 in the United States, for all practical purposes, you don&#x27;t. You provide stabilizing treatment before inquiring as to the patient&#x27;s ability to pay[0].Like most [1] significant [2] healthcare legislation in the US, this was passed via budget reconciliation.0 - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Emergency_Medical_Treatment_an...1 - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Consolidated_Omnibus_Budget_Re...2 - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Health_Care_and_Education_Reco... reply Arrath 8 hours agorootparentprevLoved the $1,200 bag of saline the EMT squirted into my eyes because I expressed concern about debris being in them after a crash in which my side window exploded into my face. reply Danjoe4 11 hours agorootparentprevYou can&#x27;t, but the vast majority of US healthcare expenses are routine&#x2F;primary care. If we have price transparency, then price sensitive individuals seeking routine care will drive prices down to a reasonable cost. Many emergency treatments are used in non-emergency situations, and charging a wildly different rate would certainly violate some price gouging law.The debate around US healthcare often misses the point. We all agree it is too expensive. The next question we should ask is: how much does it cost? And the answer is we don&#x27;t know. That is fundamentally an issue, because price discovery cannot occur if the price is unknown. Our current healthcare system is not a failure of capitalism; it is anti-capitalist. Collusion between big insurance, big pharma, and hospitals have captured the system.We need robust price transparency legislation. reply YeBanKo 7 hours agorootparentI support price transparency legislation, but I don&#x27;t think that this is what is going to solve the healthcare affordability. This is a monopoly by design, price transparency is good for markets that are more open to shopping around. reply dheera 13 hours agorootparentprevUpfront pricing AND optional upfront payment for non-emergency services. If you choose to pay upfront you should receive no further bills, period. reply supertrope 7 hours agoparentprevA pull back in \"credit.\" This rule is a blunt instrument. It will reduce medical debt stress caused by the way American healthcare is financed. It will also allow more people to default on their medical bills even the ones that are reasonably priced and correctly coded. It&#x27;s kind of like how the CARES Act for COVID-19 banned reporting mortgage forbearance to credit. Then Chase Bank narrowed new business to 20% down and excellent credit score in response to the future reduced information environment.Since high deductible health plans become common (with multi-thousand deductibles) some hospitals and doctor&#x27;s offices have required patient responsibility balances to be paid before the surgery or procedure. Some providers refuse service if you have past due bills with them. Providers in the medical-industrial complex already cherry pick customers by often not accepting Medicaid or Medicare. You may have noticed that doctor&#x27;s offices are more likely to be opened in affluent areas. In effect your choices for local medical services can be affected by not just your health plan but the average purchasing power of the area! reply ISL 11 hours agoparentprevProbably charging everyone more to accommodate the potential lost revenue. reply rqtwteye 14 hours agoparentprevHow about the insurers and providers working together on reasonable billing and not make patients pay random charges over which they had no control and information about cost? reply jfghi 15 hours agoparentprevBe less profitable by not price gouging? reply cyanydeez 14 hours agorootparentIn America, hospitals cannot refuse emergency care.So, while price gouging and insurance gouging are a thing, the actual hospitals may be poorly compensated in many places.That&#x27;s why rural areas are losing hospitals. reply p_j_w 12 hours agorootparent>In America, hospitals cannot refuse emergency care.Can they do this in any developed country?>That&#x27;s why rural areas are losing hospitals.Maybe a system with only privately run hospitals is a stupid plan. reply supertrope 7 hours agorootparentIt is hard to operate a rural hospital. Rural areas not only are dwindling in population but tend to be poorer. There&#x27;s a higher mix of Medicaid&#x2F;Medicare plans versus employer health plans. With our current fee for service medical service economic model, rural hospitals that don&#x27;t do as many surgeries or have to transfer people to the city hospital literally send patients and the revenue they bring in off to big cities. Recruiting staff is harder due to in demand professionals wanting the services and opportunities a big city provides. County hospital are partially local taxpayer supported but once again rural areas have a thinner tax base. HHS sends Federal dollars but this is limited.Certain states are trying extra hard to exacerbate the problem by not expanding Medicaid. reply cyanydeez 11 hours agorootparentprevSorry, forgot to clarify: most other places provide socialized medicine. reply cscurmudgeon 8 hours agorootparentSo too in the US. You are probably not aware of the insane socialized mess that is the US health system due to initial good intentions.Medicare, Medicaid, govt supported controls on number of new doctors per year, so much regulation and red tape.The US govt spends more on healthcare than most other nations. If that isn’t socialized medicine, I don’t know what is.Thankfully we are just indirectly socialized unlike our neighbors to the North who suffer from many things like longer wait times for emergencies and vital surgeries. reply maxerickson 11 hours agorootparentprevMeh, hospitals put uncompensated care at about $40 billion a year in 2020:https:&#x2F;&#x2F;www.aha.org&#x2F;fact-sheets&#x2F;2020-01-06-fact-sheet-uncomp...That&#x27;s not just unpaid emergency care that they are forced to provide, it&#x27;s all their billing that isn&#x27;t paid.That&#x27;s out of $1.3 trillion of hospital revenues in 2020:https:&#x2F;&#x2F;www.cms.gov&#x2F;data-research&#x2F;statistics-trends-and-repo...3% is a lot (because it&#x27;s coming out of their net income from other procedures), but it shouldn&#x27;t be driving hospitals out of business. reply blendergeek 8 hours agorootparentprev> That&#x27;s why rural areas are losing hospitals.Yes. And they are being run into the ground by \"venture capital\" as if they were local newspapers. reply jfghi 14 hours agorootparentprevI agree entirely but just don’t think that credit reports solve or help anything in this domain. reply JumpCrisscross 14 hours agorootparent> don’t think that credit reports solve or help anything in this domainThey help hospitals collect. Not saying that makes it right. Just that it has a purpose beyond greed and gouging. reply jfghi 13 hours agorootparentI’d have to see data in order to confirm this is true. Once a delinquency gets placed on a credit report paying the bill doesn’t help the person that owes. It also assumes that the people not paying are choosing to do so rather than not being able to. Given the debts are sold at a steep discount, I’d say it’s more efficient to have lower prices up front which could potentially be affordable for more of the customers. reply supertrope 7 hours agorootparentWhen one is applying for a mortgage one of the conditions is to pay off any debt in collection status. I agree that lack of universal healthcare with reasonable out of pocket costs is the underlying issue. reply flangola7 12 hours agorootparentprev> In America, hospitals cannot refuse emergency care.How is that unique to America? What other developed nation doesn&#x27;t have this rule? reply maxerickson 11 hours agorootparentThe way it is funded in the US is probably special. EMTALA is enforced by making it mandatory part of Medicare participation.If you don&#x27;t bill Medicare you don&#x27;t have to provide care to anyone. replydylan604 15 hours agoprevI hope this truly has the effect that it is meant to have. But being the pessimistic type towards US healthcare and insurance and credit agencies, I really expect this to go nowhere, or become so watered down that it is essentially meaningless. reply p1mrx 15 hours agoprevUnder this system, what would be the reason to pay your medical bills? reply fisherjeff 15 hours agoparentI mean, getting sent to collections sucks regardless of whether it affects your credit score - see, e.g., patio11’s recent blog post[0]. If you don’t pay, chances are you will still regret it.[0] https:&#x2F;&#x2F;www.bitsaboutmoney.com&#x2F;archive&#x2F;the-waste-stream-of-c... reply mike_d 15 hours agoparentprevOnly emergency rooms are legally obligated to treat you to the point of stabilization.As most doctors are now part of hospital ran conglomerates, a failure to pay your bill for an orthopedic consult can still be recorded in the hospitals system and you could be denied an appointment by your OBGYN. reply wefarrell 14 hours agorootparentThe obvious consequence would be that people go to the emergency room for any kind of healthcare. That’s a much worse outcome for hospitals so I doubt they would deny people primary care. reply mike_d 13 hours agorootparentEmergency rooms are already the treatment of last resort for the uninsured. Visit any ER on a Tuesday afternoon in a major city and you&#x27;ll be stuck in a two hour queue behind what are 95% primary care issues.The $400 Tylenol people love to complain about in the hospital is a direct result of the government mandate to treat thousands of patients a day effectively for free because we can&#x27;t get our shit together and provide universal healthcare. reply wefarrell 13 hours agorootparentIt’s terrible for a hospital’s business to have their ER clogged by people who don’t have emergencies and can’t pay. It means they see a much lower volume of people who can pay.So they aren’t going to deny people primary care because doing so will just cause them to wind up in the ER. reply mike_d 12 hours agorootparent> It’s terrible for a hospital’s business to have their ER clogged by people who don’t have emergencies and can’t pay.It is already a big enough problem they don&#x27;t seem to care. Hospitals in less affluent areas are getting interest free loans from the state to keep emergency care from bankrupting them: https:&#x2F;&#x2F;calmatters.org&#x2F;health&#x2F;2023&#x2F;08&#x2F;california-hospitals-b...> So they aren’t going to deny people primary care because doing so will just cause them to wind up in the ER.You seem to be confused that I am speaking to some hypothetical future situation. Hospital networks require you to either pay outstanding balances or meet with someone to arrange a payment plan before you can be seen. Taking away the ability to report to credit is only going to make them more aggressive in this practice. reply mindslight 14 hours agorootparentprevHave you been to an \"emergency\" room lately? reply callalex 12 hours agorootparentNope, and almost everyone reading this hasn’t either. This is not a helpful or productive comment. Instead consider saying “at my last visit to the ER, I encountered many people seeking treatment for XYZ which I do not think should be considered an emergency” or something similar so others can learn from your experience that they don’t have. reply maxerickson 11 hours agorootparentIt&#x27;s interesting that we just assume it makes sense for the patient to self assess what level of care they need.I wonder if there are sensible reasons to not have a single point of contact for unscheduled care, or if it is just dumb inertia?I know there are some hospitals that have provided urgent care type services at urgent care type prices in their emergency rooms, I haven&#x27;t looked to see if it worked well or if they are still doing it. reply mindslight 7 hours agorootparentprevSpelling out what I implied - my experience has been the exact opposite of how OP is insisting that it should be. I&#x27;m not interested in typing up a report of my various experiences with the medical industry and scrubbing it of the right amount of identifying information merely to refute some prognostication that&#x27;s so abstract it&#x27;s not even wrong. reply nradov 14 hours agorootparentprevThat&#x27;s true from an EMTALA standpoint. But in certain circumstances once a doctor-patient relationship has been established and a course of treatment has started the doctor may be legally and&#x2F;or ethically bound to either continue that treatment or pass the patient over to another willing doctor. They aren&#x27;t necessarily always allowed to immediately drop a patient for failure to pay. reply singleshot_ 14 hours agorootparentKeyword: “abandonment.” reply dcow 14 hours agorootparentprevHospitals and doctors don’t do this. It’s unethical to deny someone treatment because you’re not sure they can pay. reply repiret 14 hours agorootparentEmergency rooms don’t do this. Non-emergency health providers of all sorts will deny you services if you have an outstanding balance. reply gensym 13 hours agorootparentprevIt may be unethical, but it happens all the time. My father got cancer in 2020 and died earlier this year. During that time, I was continuously shocked at the delays in tests and treatments that he experienced because specialists wouldn&#x27;t see him until he had approval from Medicare. Without those delays, I think there&#x27;s a good chance that we&#x27;d be looking forward to another Christmas with him.(We live in the US if this anecdote didn&#x27;t make it obvious). reply mike_d 14 hours agorootparentprevI assume you live outside the United States. Healthcare here is... special. reply toomuchtodo 15 hours agoparentprevWhy should people pay their medical debt that only exists because Congress refuses to implement a functioning national healthcare delivery system?If Congress refuses to act, the executive branch can sidestep them providing temporary relief until Congressional reps turn over enough to pass material legislation to fix the system. reply nradov 15 hours agorootparentWhy should people pay for food when Congress refuses to hand out free food for everyone? reply toomuchtodo 14 hours agorootparent> when Congress refuses to hand out free food for everyone?Can you say that when USDA food security and nutrition assistance benefits are around $183B a year? Certainly, it isn&#x27;t for everyone, but for those in need. Why would we not extend similar policy to healthcare in a more efficient manner? No one is arguing for free healthcare (although that phrase is used colloquially), but a more efficient payer and delivery system, versus all of the bloat between patients and providers as exists today (insurance companies, pharmacy benefit managers, etc). Sibling comment by willcipriano touches on this bloat.https:&#x2F;&#x2F;www.ers.usda.gov&#x2F;data-products&#x2F;ag-and-food-statistic... reply jefftk 14 hours agorootparent> Certainly, [free food] isn&#x27;t for everyone, but for those in need. Why would we not extend similar policy to healthcare in a more efficient manner?But we do have a similar system for healthcare! If you&#x27;re poor enough you qualify for Medicaid [1], and if you don&#x27;t qualify for Medicaid but your income is too low to afford the full price plans the ACA provides pro-rated subsidies.It&#x27;s not that different from SNAP, and both are a mix of working well and poorly.[1] Unless you live in Alabama, Florida, Georgia, Kansas, Mississippi, North Carolina, South Carolina, South Dakota, Tennessee, Texas, Wisconsin, Wyoming, which opted out of Medicaid expansion. Even though expansion had the federal government covering >90% of costs... reply dmoy 14 hours agorootparentprevNote that Medicare and Medicaid budget dwarfs federal food budgetIt&#x27;s like literally an order of magnitude more spending reply bogwog 14 hours agorootparentprev> versus all of the bloat between patients and providers as existsbloat and illegal monopolization: https:&#x2F;&#x2F;www.reuters.com&#x2F;legal&#x2F;us-accuses-investment-firm-ane... reply willcipriano 14 hours agorootparentprevUS citizens, per captia, spend more on socialized medicine than any other nation. Then we pay again for the private system. With those facts in mind I see no moral reason to pay, we already did.https:&#x2F;&#x2F;data.oecd.org&#x2F;healthres&#x2F;health-spending.htm reply datavirtue 14 hours agorootparentprevFood is the only thing congress has happened to manage. Prices have been low and stable for generations due to agricultural policies. Everything else has spiraled out of control. reply supertrope 7 hours agorootparentAgriculture can be mechanized. Diagnosis and treatment of disease and injury has not yet been automated. America has an awful medical financing system where a hospital sends a bill for 10x the market price and then the health insurance boasts that they got you a 90% discount. reply LapsangGuzzler 15 hours agoparentprevMy understanding is that medical debt would still be collectible and could be sold to third party debt collectors. It just couldn&#x27;t hurt your credit report. reply matthewaveryusa 15 hours agoparentprevYour wages can still be garnished. reply doctorpangloss 12 hours agoparentprevOne thing’s for sure, the lawyers and finance professionals at the CFPB aren’t going to remove your legal defense fees and delinquent mortgage payments from your credit report, even though being in jail and being homeless also massively increase your mortality. reply jeffbee 14 hours agoparentprevMedical “debts” are almost always unilateral fees you never agreed to. No provider will state upfront what the fees will be! I got billed after the birth of my first child for services that had not been rendered by a physician who wasn’t even present, which my attorney characterized as “fraud” in a stern letter but that the hospital viewed as “debt”. I prevailed obviously but imagine the range of outcomes. reply FireBeyond 13 hours agorootparentThe other people to contact there are your insurers. Despicable as some of them may be, they too hate provider fraud. Even if they don&#x27;t appear to do something to censure the provider, it is on their file, and enough complaints will be problematic.I had a similar situation with a kidney stone. Transferred from my hospital to another by ambulance - I was moved from the ambulance gurney to the surgery bed in the hallway of the ER, and was billed for a ER visit among everything else, though no care had been rendered, no ER staff had been involved (hospital transport techs), it just happened to happen in the ER, and not even in a room. reply DoneWithAllThat 14 hours agoparentprevCivil action could be started against you in court. If you don’t show up the other party would win a default judgement. If you did you could and likely would still lose and have to pay. At that point your assets could be legally taken from you and wages garnished. reply Eumenes 15 hours agoparentprevI haven&#x27;t paid a medical bill under $1k in years ... it never goes into collections and I never hear about it after the 2nd or 3rd letter in the mail. My providers never mention it, my insurance company never mentions it. reply CPLX 10 hours agoparentprevThey can sue you.Presumably an actual legal judgement against you would still go on your credit report, as it does today. reply kevmo 14 hours agoprevAmerica needs universal healthcare instead of this weird, expensive, less effective Frankenstein graft machine they have. reply dantheman 11 hours agoparentHow about just enforce fraud laws and mandate up front billing&#x2F;estimates. Like we do everywhere else? reply loco5niner 14 hours agoparentprevgrift? reply jowea 12 hours agorootparentGraft is a word too.> graft (countable and uncountable, plural grafts) > (uncountable) Corruption in official life. > (uncountable) Illicit profit by corrupt means, especially in public life. reply loco5niner 4 hours agorootparentInteresting. That is a completely different (and legitimate) use of the word graft than I&#x27;m used to. reply clircle 12 hours agoprevGet ready for more debt. reply consz 15 hours agoprevI’ll repost my comment from a recent thread, but this article is a surprise to me, I thought this had already been the case for years?Reposted comment —As far as I can tell, this is the correct way to handle this? I haven’t paid attention to any medical bills sent in the mail since I started working 15 years ago (I generally pay what they ask at the point of service), and I’ve never noticed any consequences (no denial of service anywhere, has never shown up in any way on my credit report, etc) — as far as my experience has shown, any bills sent after the fact are completely optional to pay. reply joe5150 14 hours agoparentIf the hospital&#x2F;provider sends your bill to a collections agency, then it can definitely show up on your reports. Especially so if you are actually sued for the debt, in which case the judgement is also a public record.I&#x27;ve had this happen a couple times in the past when I was in treatment for cancer and underemployed. One agency reported the collections action and it went on my credit report (no indication that it&#x27;s medical debt or anything else, so I imagine it would be up to the consumer to contest these things with the bureau?) Another collector didn&#x27;t, so I never paid the bill or heard from them again! reply consz 14 hours agorootparent>If the hospital&#x2F;provider sends your bill to a collections agency, then it can definitely show up on your reports.So I agree this was the impression I got in theory, but in practice I’ve never seen this happen. Why is there this mismatch? I check my credit reports once a year, there’s nothing showing up reply joe5150 14 hours agorootparentIt&#x27;s entirely up to the hospital and the collectors they use (if they use any at all) how aggressively they pursue unpaid bills and whether they will involve your credit report to encourage people to pay. If you&#x27;ve mostly been going to the same places (or as another comment said, live somewhere where it&#x27;s not as easy to send medical bills to collections), I can see it not really being a problem for you. reply eek2121 14 hours agorootparentprevI have, sometimes bills go to collections without me even receiving a bill from the doctor&#x2F;hospital themselves. reply idiotsecant 14 hours agoparentprevWow you&#x27;ve lived a charmed life, friend. This is not the experience of the vast majority of people. Medical debt is real, and crushing. reply knodi 14 hours agorootparentYes, crushing indeed. Number one cause of bankruptcies in the US is medical expenses. reply ch4s3 14 hours agorootparentThat&#x27;s not really true, or at least it would be hard to say for sure. Every source saying that cites the same survey where a majority of respondents claimed that it was at least a contributing factor. Its actually really hard to get good breakdowns of the numbers on this. reply brewdad 12 hours agorootparentIt&#x27;s sort of a straw that breaks the camel&#x27;s back situation in most cases I would wager. It&#x27;s less that medical debt caused bankruptcy than it, added on top of housing debt and car loans and credit cards and student loans etc., finally pushed a household to a point where getting out from under it all was too much. reply ch4s3 7 hours agorootparentYeah, I don’t exactly disagree. Many years ago I worked at a debt counseling company and had occasion to look at the records and listen in on phone calls. It was really quite fascinating and heartbreaking. There definitely seemed to be a few common patterns. Big debts around car crashes and complicated births were not uncommon. But on the other hand almost everyone had a crazy mortgage and a pile of credit card debt too. replyrqtwteye 14 hours agoparentprevMy ex had collectors calling her several times a day for months while she was disputing a bill. It probably depends on whether the hospital writes the bill off or sells it to collectors. reply wizerdrobe 14 hours agorootparentI feel for your ex, I have three (3) in office visits covered by my insurance that are overdue as of August. I’ve had to go back and forth on the phone in a Kafka-hell to get my insurance to cover a covered visit because of some opaque clerical error (and I write medical insurance review software and I’m still confused as to who is to blame…). Insurance issued a payment last month finally, but the doctor has yet to recognize it so I still get reminders on being “late” for a bill I don’t ultimately owe.I cannot imagine how infuriated I would be if I were being punished on my credit for someone else’s clerical error. reply rqtwteye 10 hours agorootparent\"I’ve had to go back and forth on the phone in a Kafka-hell to get my insurance to cover a covered visit because of some opaque clerical error\"the same happened to my ex. Something had gone wrong between hospital and insurance and both refused to fix it. Which left her in between trying to figure this out while trying to recover. It&#x27;s really infuriating that they can treat people that way. Once you experience this together with billing for things that never happened and insurance refusing things they have to cover, you can only conclude that insurances and hospitals are basically fraudsters that for some reason are allowed to get away with it. reply consz 14 hours agorootparentprevBut I guess that’s my whole point is once they sell it to collectors it’s equivalent to the bill not existing? My confusion is around wondering if I’ve somehow fallen through the cracks and got lucky or other people have the same experience.Why do other people pay bills they receive in the mail? reply joe5150 14 hours agorootparentThat&#x27;s not always the case. Some hospitals will still keep a record of the unpaid bill on your account even after they pass the debt to a collector, and the collector will report whether you pay to the hospital.The practice and billing parts of the system are usually mostly separate, so the person checking you in for your appointments may not know or have any way to see that you have unpaid bills and you won&#x27;t necessarily be denied care for it, but there&#x27;s no real standard here either. reply datavirtue 14 hours agorootparentprevI doubt the collection agencies would even purchase these at this point. reply rincebrain 12 hours agoparentprevI stopped getting any care at a large hospital near me&#x27;s outpatient office because they had a bad habit of just sending bills to collections before my insurance responded to them, and then not updating anything once they did, so I&#x27;d get a debt collector notice and call the hospital, and they&#x27;d say \"oh you paid that in full, you shouldn&#x27;t be getting a notice\" \"well you should probably tell that to the debt collector\".Over and over again.So if those started showing up on my credit report eventually, it&#x27;d be a significant impact, even though I was not involved in any failure to pay. Fortunately, they never did, but for many people, that&#x27;s not true. reply gwbas1c 13 hours agoparentprevI assume you&#x27;re in the US.What you&#x27;re probably seeing are the bills that your service provider sends to insurance, and then your insurance sending you a statement of benefits.If these were real bills, they would keep sending them.(Sometimes these can be amusing: I had surgery in 2011, and the hospital billed the insurance company $100,000. The insurance company responded that the agreed cost for services should be $20,000. The hospital ended up getting $20,000. IMO, $20,000 was plenty to pay everyone involved.) reply bdcravens 14 hours agoparentprevIt does go on your credit REPORT. However, the impact it has on your credit SCORE is what varies, especially with newer models. reply vondur 14 hours agoparentprevI have someone in Las Vegas who stole my identity and is using it for medical services. I get collection notices for these services sent to my house (I&#x27;m not near Las Vegas) and I have to dispute every one of them. I&#x27;ve had to file police reports on it, but the Police in Vegas don&#x27;t really care about helping me. reply dcow 14 hours agoparentprevDo you live in California? I know CA has much more consumer-friendly restrictions on sending medical bills to collections. It essentially can’t happen in CA. reply xwdv 14 hours agoparentprevThey are letting the interest build to such a magnitude that they can eventually sue your estate and easily recover the losses and more if you have assets at the time of death. reply singleshot_ 12 hours agorootparentIt would be surprising if this worked, given that a creditor who did not mitigate his damages reasonably and instead lurked, awaiting a windfall is not entitled to damages. reply dheera 14 hours agoparentprevHad a echocardiogram that I was told would be covered but insurance didn&#x27;t pay, and they balance billed me for $5K. I never paid. Got handed to debt collectors. Wrote to them saying it isn&#x27;t my debt and to cease contacting me.If they take it to court I&#x27;ll lawyer up and fight.In any case, I gave neither debt collectors nor medical office my residential address or mobile number. I suggest you NEVER give your residential address to medical offices either, or they&#x27;ll happily tell debt collectors where you sleep. Which personally I think should be a HEPA violation but apparently it isn&#x27;t.Give them a virtual mailbox or office address where you can receive mail. reply jorblumesea 15 hours agoprevnext [5 more] [flagged] Uvix 15 hours agoparentWe pay for it one way or another. I&#x27;d rather pay for actual usage instead of getting taxed for stuff I might or might not have used. reply ericmay 15 hours agorootparentIn the US you get it from both ends. You pay for insurance, they decline your claims, you have co-pays, minimums, etc. and then you pay more than you otherwise might because the hospitals have to cover those who need care but don’t have insurance. That’s why your aspirin is $300. You’re paying for lots of other people.And then you also pay taxes for Medicare and Medicaid programs, the VA, and other various, duplicative programs.I don’t have a strong opinion on either system on its own philosophical merits, but what I see today is that the health insurance industry is a jobs program with extra cost added in for profits and I’m just not really sure what the point of it is.If we are willing to let people die on the streets and refuse care, let’s get the government out and just go all-private. If we aren’t willing to do that we should drop the jobs programs and waste (insurance) and just go with tax-based healthcare and eliminate redundant programs (Medicare, Medicaid, etc.) and also the subsidization of insurance companies.Getting people the care they need to is almost certainly going to lead to a healthier and happier population that’s more productive as well, which is another economic benefit. reply gnulinux 15 hours agorootparentprevAbsolutely not true and this is simply American propaganda. The truth is American insurance industry is an extremely inefficient middleware that makes everything more expensive and worse than other developed countries. [1][1] \"US spends most on health care but has worst health outcomes among high-income countries, new report finds \" https:&#x2F;&#x2F;www.cnn.com&#x2F;2023&#x2F;01&#x2F;31&#x2F;health&#x2F;us-health-care-spendin...Not to mention it&#x27;s complete lunacy to think taxes are low in the US. I live in US but also pay taxes in a different country (that I&#x27;m a citizen of) that has healthcare and all the Federal tax I pay to US is significantly more (the other country is a fraction of fraction of US taxes). Not to mention, US taxes are extraordinarily, out-of-this-world level complicated if you have foreign assets so you pay thousands of $$$ to a CPA as well. reply skyyler 15 hours agorootparentprevI&#x27;d much rather pay a small percentage of my income and have a guarantee that my fellow Americans aren&#x27;t suffering through treatable illness. reply Madmallard 14 hours agoprevGreat time for disabled people to die because they won’t be able to get care. Disabled people can’t pay for psychotic medical bills as it is and this will just result in medical providers denying care without upfront pay. reply mehlmao 14 hours agoparentI&#x27;ve never had a doctor run a credit report on me before, have you? reply Madmallard 13 hours agorootparentorganizations will start doing it to protect profits probably reply iuhfdsakljhfads 15 hours agoprevDoes this mean I don&#x27;t have to pay any medical bills unless they sue me? Awesome, that&#x27;s one less thing! reply CPLX 10 hours agoparentI mean by the logic you&#x27;re using you don&#x27;t have to pay ANY bill or abide by ANY contract unless someone goes to court to make you. reply drak0n1c 15 hours agoprevHopefully they have a plan for a better mechanism to discourage frivolous ambulance calls and ER visits. Those resources are overloaded by casual abuse resulting in higher costs and wait times for those who truly need emergency care. Without an alternate disincentive that problem will only get worse with this change. reply jkingsman 15 hours agoparentI think having cost be the anti-abuse disincentive is the worst of all worlds -- cost is clearly not an effective deterrent of abuse given our current state of overutilization. It IS a deterrent in the case of avoidance, or arguably worse, a punishment in the case of attendance, for those who DO need it.I&#x27;m a volunteer EMT and my org runs free clinics staffed by doctors+nurses at major events to handle emergencies. It&#x27;s truly free -- we don&#x27;t bill anyone, insurance included -- but I&#x27;ve had people in dire medical distress avoid coming with me because they&#x27;re afraid of the bill. Hell, I&#x27;ve had people in the midst of full blown psychosis and their single lucid thought is to yell \"DON&#x27;T TAKE ME I CAN&#x27;T AFFORD AN AMBULANCE BILL\" and my heart breaks.The American healthcare system is continuously setting and raising the high water mark for how deeply in failure the system is, but bankrupting people is not the holistic solution we need, in my opinion. reply init2null 15 hours agoparentprevPeople make \"frivolous\" visits because they are legally required to stabilize patients. This is what passes for a social safety net in the US, and we have failed in developing anything better for those not covered by Medicaid.People often make frivolous ambulance calls if they have trouble getting to the hospital or PCP.There are often reasons, and we would have a more reliable, more humane system if we focused on cheaper care over penalizing the poor. Providing only guaranteed emergency care is absurdly expensive. reply AuryGlenz 11 hours agorootparentThat’s not the only reason. A (well known, national) turkey company considered building an on-site clinic just because so many of their Somali immigrant employees were going to the ER over frivolous things.They have insurance. Of course, that’s certainly not limited to immigrants. I think anyone who has spent any time in an ER waiting room has thought “you’re in here for that?” I’ve heard plenty of anecdotes from doctors about people with insurance or no going to the ER for colds.As an aside, even though the Somali population is just a small fraction of the total population in the area they seem to be about half of the people in the (non-ER) clinic. I’ve always wondered what was up with that. reply wilg 15 hours agorootparentprevIIRC this gap exists in states (guess which!) that opted out of Medicaid expansion. So a solution is available if states take it. reply init2null 14 hours agorootparentTo be fair, someone making $25,000 a year will have almost as much trouble paying out of pocket for an MRI as someone making $15,000. But the former won&#x27;t qualify for Medicaid and the heavily-discounted health insurance won&#x27;t do much to help with their first $10,000 of medical debt.Good but worthless advice to the majority living without any savings: don&#x27;t get sick and don&#x27;t get injured. Can anyone blame them if they avoid expensive testing? Medicaid is a great bandage, but the US needs a better system. reply LapsangGuzzler 15 hours agorootparentprevThis is a nationwide problem, it&#x27;s not restricted to states that opted out of expansion. Federal Law requires that ERs treat anyone who comes in, regardless of ability to pay. Until the poor are able to access other resources like urgent care clinics, this is going to continue to be a problem. reply wilg 6 hours agorootparentWell the poor have access to Medicaid, and if they make more than the Medicaid maximum, subsidized ACA plans. In neither of those cases should you have to go to the ER for non-emergency care.I believe the biggest problem is the coverage gap I mentioned, where 10 states for political reasons have not opted into the higher Medicaid maximums which creates a gap between Medicaid and ACA. This is dumb as hell.I am having trouble figuring out where exactly the other coverage gaps are or how big they are. I&#x27;m sure there are some.I would definitely support a switch to single payer to smooth out this mess. reply indymike 15 hours agoparentprev> Without an alternate disincentive that problem will only get worse with this change.The ER is the only place that people can get care when they are uninsured and not wealthy. Your family doc will say no. Immediate care will say no. But the ER can&#x27;t say no. People in this situation are mostly upper lower class and lower middle class who have lost their jobs or fell into an administrative crack. If you are poor, you will qualify for something to cover the cost. It&#x27;s terrifying and is probably one of the best arguments for reform there is. reply amluto 15 hours agoparentprev> Without an alternate disincentiveThe problem isn’t (IMO) an insufficient disincentive — it’s lack of a credible alternative. I have perfectly fine insurance, and getting an appointment for a merely slightly urgent issue is a pain in the rear. If I’m traveling, it’s almost impossible.COVID made this all worse. Last year, I saw a resort clinic (well staffed by assorted medical professionals) turning away anyone with any symptoms of illness and sending them straight to the ER (10 miles or so away through the snow) because they “might have COVID”. reply sp0rk 15 hours agoparentprev> Hopefully they have a plan for a better mechanism to discourage frivolous ambulance calls and ER visits. Those resources are overloaded by casual abuse resulting in higher costs and wait times for those who truly need emergency care.Do you have any statistics regarding this? I&#x27;m sure there are some people that use the services unnecessarily, but is it really enough that it&#x27;s a significant issue? reply foobiekr 15 hours agoparentprevUrgent care facilities ought to be offloading ERs in most cases. Something as trivial as needing some stitches is an ER visit instead. I think this kind of ends up trivializing ER.That and drug seeking... reply brewdad 11 hours agorootparentI&#x27;ve had to use urgent care a half dozen times over the past 20 years. In all but one case, they sent me to the ER because they didn&#x27;t want to be responsible for my care outcomes. None of them were really \"emergencies\".I&#x27;m lucky if there is an actual MD on premises at my in-network urgent care. reply AuryGlenz 11 hours agorootparentprevOur local urgent care closes at 7:30pm on weekdays and 4pm on weekends. That doesn’t help. reply shadowgovt 15 hours agoparentprevThis is yet another problem that could, hypothetically, be addressed by centralizing &#x2F; single-payering the system.With one administrator having access to all that data, it would be straightforward to see where ERs and ambulances are being over-used for non-emergencies and address that in the community with both more funding for preventative care and intervention &#x2F; education initiatives to get people using preventative care. reply corinroyal 12 hours agoparentprevImagine thinking a visit to the ER was \"frivolous\". As if significant numbers of people would subject themselves to an ER for fun. Imagine looking at a situation in which significant numbers of people have no other access to care but ERs and think, \"Those freeloaders!\" What sort of twisted mirror-world ethics are these? How does one get to the point where they could type this, read it over, and hit send? You&#x27;d think the shame alone would be lethal. reply _jal 15 hours agoparentprevThe hilarious thing is that the emergency room mandate has long been used as an excuse for opposing universal coverage. People used to say thing like \"nobody in America is dying because they can&#x27;t go to the hospital,\" as if that was bar.Now it apparently serves an excuse for claiming ER should cost more. Truly a universal policy, I guess. reply hnrodey 14 hours agoprev [–] I think it should be acceptable that unpaid medical debt appears on the credit report. The medical debt should be removed once the debt is paid.The above is for medical debt only and how I would prefer the system to work. There are other good comments about possible second and third order effects from such changes to debt reporting. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Consumer Financial Protection Bureau (CFPB) has initiated a rule-making process focused on eliminating medical bills from credit reports to assist families recovering from medical crises, hinder debt collectors from enforcing payment for possibly non-owed bills, and increase credit score data accuracy.",
      "According to CFPB's investigation, medical billing data has lower predictability concerning repayment against conventional credit obligations and is frequently riddled with errors. Proposed rules would ban companies from including medical debt in credit reports and creditors from using this information for their underwriting decisions.",
      "Furthermore, CFPB aims to thwart debt collectors from exploiting the credit reporting system to push consumers into paying dubious debts. The bureau is also assessing several other proposals related to data brokers and continues to communicate with the public regarding high-cost specialty financial products linked to medical billing practices."
    ],
    "commentSummary": [
      "The discussion revolves around diverse issues concerning the Consumer Financial Protection Bureau (CFPB), medical debt, the requisite for healthcare reform, and their effect on credit reports.",
      "It accentuates mixed views on the CFPB's funding and structure, apprehensions regarding medical billing practices, lack of transparency in healthcare pricing, and the pros and cons of universal healthcare.",
      "The conversation goes on to emphasize the impact of medical debts on credit scores, the inefficiency of the U.S insurance industry, and discussions on utilizing cost as a deterrent in healthcare, underpinning the need for improved regulation, affordable healthcare, and comprehensive reforms."
    ],
    "points": 173,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1695409012
  },
  {
    "id": 37616513,
    "title": "JPL Open Source Rover Project",
    "originLink": "https://github.com/nasa-jpl/open-source-rover",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up nasa-jpl / open-source-rover Public Notifications Fork 1.2k Star 7.7k Code Issues 38 Pull requests Discussions Actions Projects 2 Security Insights nasa-jpl/open-source-rover master 2 branches 4 tags Go to file Code Latest commit Achllle Merge pull request #411 from nasa-jpl/fix/regulator-links … 318253c Git stats 839 commits Files Type Name Latest commit message Commit time .github typo electrical Move pcb readme to pcb folder, add instructions for configuring roboc… examples Major cleanup/overhaul images Add link to youtube video showing OSRv2 roving around mechanical Add image with cabling result for rocker-bogie parts_list Generated by GitHub Actions (Parse parts lists / generate_md) .gitignore Build site with MkDocs DISCLAIMER.txt Add final newline LICENSE.txt Add final newline README.md Update README.md mkdocs.yml Build site with MkDocs requirements.txt Bump pymdown-extensions from 9.2 to 10.0 README.md JPL Open Source Rover Project NOTE: For the previous major version of the OSR, please see v3.1.0. The JPL Open Source Rover is an open source, build it yourself, scaled down version of the 6 wheel rover design that JPL uses to explore the surface of Mars. The Open Source Rover is designed entirely out of consumer off the shelf (COTS) parts. This project is intended to be a teaching and learning experience for those who want to get involved in mechanical engineering, software, electronics, robotics but is also an excellent research platform for rugged terrain. No prior skills or knowledge is required. A gallery of some community builds including previous versions of the rover can be found here. Drive a simulated rover around straight from your browser: opensourcerover.jpl.nasa.gov About the OSR Motivation JPL is always looking to inspire the next generation of scientists, engineers, and roboticists to help us explore and learn about our solar system (and beyond!). We release the plans for this rover as a way to try and give budding enthusiasts a fun robotics project that will help teach them and get them involved in robotics sooner and at a lower cost. At a glance The OSR has been around since 2017 and has undergone many iterations. It is a premium and robust robot with a unique look, high customizability, and powerful abilities. The hardware and electronics were designed with expansions like a head display and robot arm in mind. spec value top speed ~1.6m/s (~slow running, subject to motor selection nb motors 10 structural material aluminum total cost ~$1600 (about the cost of a TurtleBot 3 Waffle) The OSR mostly uses parts from GoBilda for the mechanical assembly. For GoBilda's (international) shipping options, see here. Other open-source, cheaper alternatives exist but are slower, less strong, and are more fragile. See Additional Projects. Features This rover is designed to function similarly to the 6 wheel rover designs on Mars and employs a few of the major driving mechanics that the mars rovers use to traverse rocky surfaces: Rocker-Bogie: The Rocker-Bogie suspension system allows all 6 wheels to continually be in contact with the ground while climbing over obstacles Differential Pivot: Allows weight to be mechanically offloaded from one side of the rover to the other while climbing 6-Wheel Ackerman Steering: Driving and steering/turning mechanism that governs where the wheels point and how fast each of them will move. A Raspberry Pi acts as the \"brain\" of this rover for its versatility, accessibility, simplicity, and ability to add and upgrade your own modifications. Any method with which you can communicate with a Raspberry Pi (bluetooth, WiFi, USB devices, etc) can be interfaced into the control system of the robot. Join a community of hundreds of builders Considering building one yourself? The best way to ask questions, reach maintainers, learn about modifications, and join the community of Open Source Rover builders is to join our Slack group: Note: JPL and Caltech have no official affiliation with this forum; it is run by individuals of the general public. On these you can ask questions if you need help or clarification on any aspects of the project. Additionally, you can post and promote any modifications or addons that you have created on this project. We highly encourage additions and modifications to be posted so that this project and community can grow. Maintenance Status As an open-source hardware project, the rover is continuously improving. Please check issues, pull requests, and the Slack forum to see if any big changes are expected soon. Online 3D Model You can view a 3D model of the latest version of the rover in your browser at OnShape. Skills Necessary This project has elements in mechanical assembly/fabrication, uses a host of electrical components, and has software that will run it all. In order to complete this project, you will need to have some experience in the following: Fabrication/Machining: All parts are Consumer Off-The-Shelf (COTS) parts and no metal machining should be required to complete the 'base' version of the rover. However for any optional expansions, it may be useful to have access to the following skills/tools: Metal cutting using band saw/dremel Drilling using drill press/hand drill Filing and sanding for part cleanup General Fabrication/Machining Safety Electronics: This project uses components like motors, motor controllers, and batteries. While prior experience with the following skills is not required, having access to someone who can help will save a lot of time: Soldering Electrical debugging Wiring Electrical Safety Software: The rover's brain is a Raspberry Pi. All code can be found in the osr-rover-code repository along with step-by-step instructions to set it up. Basic familiarity with Linux, ROS, Git, and Python will be helpful though. Most of the above are skills that you can learn and pick up fairly quickly from watching videos and doing research on the internet, and throughout the project we try to give supplemental information on some of these as well. See the build documents for more information. Tools Necessary This project assumes you have some standard tools to help assemble the project. If you do not have any of the optional tools, we provide examples of online services that you can use to have the parts fabricated and sent to you. Mandatory tools Metric hex keys Pliers Wire Snips Wire Strippers Solder Iron Solder Digital Multimeter Wire strippers, e.g. these Optional Tools 3D printer Laser Cutter (for the body plates, online services available) Benchtop Power Supply (to test without using battery) Items for operating a Raspberry Pi (Keyboard, mouse, monitor, 5V micro USB power adapter) Expected time commitment In our experience, this project takes no less than 100 person-hours to build, and depending on the familiarity and skill level of those involved could be significantly more. Experienced builders may be able to build this project in this amount of time. However, this project is generally meant to be a teaching and learning tool. Throughout the documentation, we try to give supplemental information for those who might be new to this kind of project. Getting Started Rover Build Roadmap Stage 1: Order parts. You'll want to get started on this ASAP! Stage 2: Create the wiring. The cables connect the Printed Circuit Board (PCB) in the body to each motor and integrate into the rocker-bogie and corner assemblies so they need to be built first. Stage 3: Make the electronics: Soldering the PCB and installing into the rover along with peripheral connections. We'll also use the wiring to test your PCBs. Stage 4: Make the mechanical assemblies: the body, the two rocker-bogies, the drive and corner motor assemblies. The instructions will guide you through how to do these step by step while integrating the cabling from Stage 2. You'll then attach them into something that will start to look like a rover! Stage 5: Setting up and configuring the operating system rover code. The Rover Code repo's README files will walk you through all necessary steps for getting the rover software up and running on the Raspberry Pi. These steps can be completed at any point during the project, all the way up to when all the electronics and mechanical parts are completed and you are ready to start driving and controlling the robot. What's next? Add your own upgrades! We chose Raspberry Pi as the brain of the project so that it should be easy to add, change, and upgrade to build exciting things on top of this already cool robot. Some upgrade ideas to get you brainstorming: sonar for collision detection, IMU for orientation / closed-loop driving / obstacle mapping, camera for object identification and tracking, sensor packages (temperature, pressure, humidity), solar panels, or even a robotic arm! Ordering parts Parts Lists The Parts List Readme contains all the parts necessary to build the entirety of the robot as it is listed in our documentation. You can select higher RPM motors (to drive your rover faster) at the sacrifice of max stall torque. A selection of motors that would integrate easily with the rest of the suggested rover design can be found at GoBilda - 5203 series. The rover design and the software can accommodate different wheel sizes if you find wheels you like better. The body plates that attach to all sides of the body are designed to be made from laser cut acrylic, MDF, hardwood, or similar. The 2D cutout files are the .DXF files in the laser cut parts folder. They were designed to be around 3mm thick (1/8\"). You can choose a material and cut them at your local makerspace's laser cutter or order them from an online service like Sculpteo or SendCutSend. Additional Projects Take a look at these alternative Mars rover replicas: Sawppy Rover ESA ExoMy Disclaimer Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise, does not constitute or imply its endorsement by the United States Government or the Jet Propulsion Laboratory, California Institute of Technology. Government sponsorship acknowledged. By downloading, cloning, or otherwise using the contents of this repository, you agree to the terms specified in the attached DISCLAIMER.txt file. About A build-it-yourself, 6-wheel rover based on the rovers on Mars! opensourcerover.jpl.nasa.gov Topics robot robotics mars mars-rover Resources Readme License Apache-2.0 license Activity Stars 7.7k stars Watchers 453 watching Forks 1.2k forks Report repository Releases 4 v2 design (v4.0.0) Latest + 3 releases Packages No packages published Contributors 31 + 20 contributors Languages Prolog 88.9% AMPL 9.4% HTML 1.2% Python 0.5% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37616513",
    "commentBody": "JPL Open Source Rover ProjectHacker NewspastloginJPL Open Source Rover Project (github.com/nasa-jpl) 165 points by kscottz 15 hours ago| hidepastfavorite23 comments throwaway892238 8 hours agoDumb question, kind of unrelated: In the process of building a remote controlled cart to haul small heavy loads offroad. Have no experience in engineering or robotics. Where could one go to learn what&#x27;s needed, say, starting at the motor&#x2F;drivetrain? (ex: what kind of motor to use, exterior or interior gearing, how to calculate motor size&#x2F;voltage&#x2F;gearing needed to haul X weight up Y gradient, steering geometry, actuators for remote steering, etc) reply nvy 6 hours agoparentThe engineering process is always the same.First, quantify your requirements. How much torque needs to be delivered at the wheel&#x2F;ground interface, in order to get your maximum load over an arbitrary obstacle like a stone or a tree root, uphill on your maximum rated grade?That requirement will tell you whether you can source a motor (based on the torque it&#x27;s rated to deliver) or whether you need to buy a drivetrain or (RIP your budget) design a custom drivetrain.Accounting for the weight of the motor&#x2F;drivetrain will require you to iterate on that first requirement. Welcome to the pain of engineering design. reply mitthrowaway2 5 hours agoparentprevI recommend starting by looking through vendor&#x27;s websites. At the end of the day if you aren&#x27;t going to be fabricating your own custom motor and gearbox, you&#x27;ll have to pick something out of a catalogue anyway, so check what&#x27;s available and for what price. That will help you get a sense of what&#x27;s possible, and then you can check that against what you want to accomplish and go back and forth until you&#x27;ve narrowed down something for a prototype. reply JellyBeanThief 8 hours agoparentprevDefine \"small heavy loads\". How small is small in terms of volume? How heavy is heavy in terms of density? reply tylerritchie 7 hours agorootparentI&#x27;m curious too how about some arbitrary requirements. it&#x27;d be fun (maybe useful?) to be able to pack in a cooler or a couple tires so let&#x27;s say..it should be able to carry a 0.5 m^3 cube and 70kg. maybe optimize for low cost and the ability to roll over some sporadic large cobble? reply theodric 4 hours agorootparentE-bike parts. Seems like a good application of something like a Bafang BBS02 (or knockoff) + thumb throttle. Chain drive, plug in a thumb throttle. Could instead use a hub motor, but their starting torque isn&#x27;t great. Either way, you save having to re-invent the wheel in terms of motor control electronics integration. reply rasz 2 hours agoparentprevYou wont be hauling anything in a remote controlled buggy, if it was feasible military would be all over this.Buy a used Quad instead. reply Arcanum-XIII 5 minutes agorootparentHow come ? We have drone that can follow you while keeping the camera on you, without any big issues. And that for a very low price. I thought we already got \"autonomous\" cart, following employees around stocks. So why not a remote buggy ? reply mdorazio 9 hours agoprevInteresting that they went with the top-mounted differential version rather than the central gearbox version. I&#x27;m guessing it&#x27;s cheaper. The rockers are also a lot more angular than the real mars rovers to save on needing to bend struts. Very interesting trade-offs to make this buildable with off-the-shelf parts, but I personally like the 3D printable iterations of the same concept ex. [1].[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=90HxqwZaWRA reply dang 10 hours agoprevRelated:JPL Open-Source Rover Project Based on the Rovers on Mars - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=17676730 - Aug 2018 (67 comments) reply ZiiS 2 hours agoparentThis is the forth major version since then; six times the speed and half the inflation adjusted price must broaden the appeal. reply bmitc 2 hours agoprevHas anyone tackled this or adapted it?I wonder if it would make for a fun summer or semester project to assign teams to various subsystems. reply SillyUsername 2 hours agoprevBOM > $1000. Bit too rich for my taste. :&#x2F; reply pryelluw 12 hours agoprevNice, I contributed to the software for this a while back. Wanted to really get into building my own robot by following the linked resource. Covid happened. Maybe someday.Anyone here built it? reply dylan604 12 hours agoparentI would never have thought a rover branded with NASA would ever move that fast. i&#x27;m now curious on what i could add to it to make it more useful to my purposes other than being a radio controlled toy... i have some ideas though reply pryelluw 11 hours agorootparentI wanted to take it to undeveloped land and see how it would handle it. Do a sort of stress test. reply m3kw9 11 hours agoprevI’m thinking someone could make this run in 3d graphics saving me a few $$ reply eep_social 10 hours agoparentAccording to tfa you can at https:&#x2F;&#x2F;opensourcerover.jpl.nasa.gov&#x2F; though I am getting an error from that site at the moment. reply jakeinspace 10 hours agoparentprevSure, just use gazebo reply westurner 10 hours agorootparentGazebosim > ROS with Gazebo: https:&#x2F;&#x2F;github.com&#x2F;gazebosim#using-ros-with-gazebo reply westurner 10 hours agorootparent\"Ghidra Plays Mario\" (2023) https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37475761 :[RL, ..., MuZero unplugged w&#x2F; PyTorch ]> Farama-Foundation&#x2F;Gymnasium is a fork of OpenAI&#x2F;gym and it has support for additional Environments like MuJoCo: https:&#x2F;&#x2F;github.com&#x2F;Farama-Foundation&#x2F;Gymnasium#environments > Farama-Foundatiom&#x2F;MO-Gymnasiun: \"Multi-objective Gymnasium environments for reinforcement learning\": https:&#x2F;&#x2F;github.com&#x2F;Farama-Foundation&#x2F;MO-Gymnasium Idea: Generate code like BlenderGPT to generate drone rover sim scenarios and environments like the Moon and MarsTIL about teh \"Bush Winch\" which mounts to a tire for off-road vehicle recovery. Note the winch line blankets, snatch blocks, and tree protectors in this video about off-road vehicle recovery: https:&#x2F;&#x2F;youtu.be&#x2F;OXxLh8shMu8?si=bv59t8T1or07-K7lAlso RIL about o3de, which does PhysX: https:&#x2F;&#x2F;github.com&#x2F;bernhard-42&#x2F;jupyter-cadquery&#x2F;issues&#x2F;99#is...O3de has an ROS2 module: https:&#x2F;&#x2F;www.docs.o3de.org&#x2F;docs&#x2F;api&#x2F;gems&#x2F;ros2&#x2F; reply sam_bristow 11 hours agoprev [–] The licencing isn&#x27;t as clear as I&#x27;d like. LICENSE.txt says it&#x27;s Apache 2.0 but DISCLAIMER.txt says you need explocit permission to do anything commercial. reply teraflop 8 hours agoparent [–] \"Our position is that the license chosen overrides the disclaimer. We have approval to license this software under the Apache License, version 2, which allows others to do what they wish (even build commercial software on it). That should supersede the attached disclaimer which are artifacts of an evolving OSS release process that we are trying to improve.\"https:&#x2F;&#x2F;github.com&#x2F;nasa-jpl&#x2F;open-source-rover&#x2F;issues&#x2F;2 replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The JPL Open Source Rover, a smaller replica of Mars rovers, can be constructed using readily available components and serves as a learning experience for folks interested in robotics and mechanical engineering.",
      "It employs the Rocker-Bogie suspension system and 6-Wheel Ackerman Steering for maneuvering over rocky terrains, and is powered by a Raspberry Pi, which allows customization and upgrades.",
      "A roadmap and resources for constructing the rover are provided by the project, promoting hands-on learning and engineering skill development."
    ],
    "commentSummary": [
      "The JPL Open Source Rover Project is a mission to construct a remote-controlled cart utilized for off-road heavy loads, targeting individuals without a background in engineering or robotics.",
      "Users on Hacker News are seeking advice on various components of the project like motor selection, drivetrain configurations, and steering mechanisms.",
      "The licensing of the project sparks debate, even as the project team provides clarification, and there is growing interest in adapting the rover for varying uses due to advances in speed and cost efficiency."
    ],
    "points": 164,
    "commentCount": 22,
    "retryCount": 0,
    "time": 1695410639
  },
  {
    "id": 37611191,
    "title": "Amazon Prime Video content to start including ads next year",
    "originLink": "https://www.bbc.co.uk/news/business-66887717",
    "originBody": "Let us know you agree to cookies We use cookies to give you the best online experience. Please let us know if you agree to all of these cookies. Yes, I agree No, take me to settings BBC Homepage Skip to content Accessibility Help Sign in Notifications Home News Sport Weather iPlayer Sounds Bitesize More menu Search BBC BBC News Home Cost of Living War in Ukraine Climate UK World Business Politics Culture Tech More Business Your Money Market Data Companies Economy Technology of Business CEO Secrets Artificial Intelligence Amazon Prime Video content to start including ads next year Published 16 hours ago comments Comments Share IMAGE SOURCE, AMAZON STUDIOS Image caption, TV shows like The Lord of the Rings: Rings of Power and The Marvelous Mrs Maisel have proven huge hits for Amazon By Lora Jones Business reporter, BBC News Amazon is set to introduce adverts to its Prime Video streaming service in 2024 as it seeks to put more cash into creating TV shows and films. UK Prime customers, along with those in the US, Germany and Canada, will see ads early next year unless they subscribe for an \"ad-free\" option at an additional cost. In a statement, Amazon said Prime Video still offered \"very compelling value\". It follows similar moves by rivals including Disney+ and Netflix. Amazon said that the ads would be introduced across France, Italy, Spain, Mexico and Australia later in 2024. It will roll out the \"ad-free\" subscription tier for an extra $2.99 (£2.44) per month for Prime subscribers in the United States. Pricing for other countries will be announced at a later date, Amazon said. At the moment, a Prime subscription, which includes free one-day delivery on goods as well as access to its streaming service, costs £8.99 per month, or £95 a year, in the UK. \"To continue investing in compelling content and keep increasing that investment over a long period of time, starting in 2024, Prime Video shows and movies will include limited advertisements in the UK,\" Amazon said. But in the wake of similar announcements by other streaming companies, customers have expressed their disappointment. Disney to launch cheaper ad-supported service in UK Will people sign up for Netflix's cheaper ad service? Disney+ expanded its ad-supported service to the UK in August, while Netflix introduced its \"basic with ads\" streaming plan last year. It marked a massive change for Netflix, which pioneered the world of ad-free, subscription-based, streaming. Analyst Hanna Kahlert at Midia Research said many people do not like the idea of adverts on services they have already paid for - though some accept the practice if it makes the streaming plan cheaper. But she said Amazon has the power to make the change without fearing a wave of cancellations, since streaming is just one part of the Prime package. \"The competition is not like-for-like,\" she said. \"Audiences are not just making the decision to subscribe because of its content or viewer experience in video, but rather a whole host of convenience factors... Ads or no ads, Amazon still wins on convenience, with its content arguably a bonus.\" In its announcement on Friday, Amazon said that it would aim \"to have meaningfully fewer ads than linear TV and other streaming TV providers\". The company said it would get in touch with Prime members a few weeks before ads are introduced to show how to sign-up for the ad-free option if they wish to. Live event broadcasts, like sports matches, will still include adverts even for those who sign up to the ad-free option. Data previously released by analysts Kantar showed that people cut back on video streaming services in their droves last year as they sought out different ways to deal with the spike in the cost of living. It found that the number of paid-for video streaming subscriptions in the UK fell by two million, from 30.5 million to 28.5 million. Although demand picked up around Christmas, Kantar said, people quickly looked to cut back again afterwards. Insider Intelligence senior analyst Max Willens said ad-supported tiers have become standard in the streaming industry, setting the stage for Amazon's move. \"It is slightly unusual for Amazon, which relentlessly positions itself as a customer-first company, to degrade a service it offers those customers, especially a service whose price has risen 75% since it was first introduced, but this feels unsurprising,\" he said. Related Topics Companies Amazon Streaming More on this story Disney to launch cheaper ad-supported service in UK Published 10 August View comments Top Stories US to give Ukraine long-range missiles - reports Published 10 hours ago Watch: Moment missile hits Russia's Black Sea fleet HQ. Video Watch: Moment missile hits Russia's Black Sea fleet HQ Published 12 hours ago Johnson warns against 'mutilated' version of HS2 Published 3 hours ago Features Households still face tough times despite better inflation news The Papers: HS2 row and smoking ban for next generation 'We're under attack' - how life is changing for Italy's gay families How shy schoolboy became YouTube millionaire sensation The last of the great photojournalists Picasso and the ‘trail of female carnage’ he left behind Panic in Karabakh as people fear ethnic cleansing Turner and Jonas: How an 'amicable' split went nuclear. Video Turner and Jonas: How an 'amicable' split went nuclear Morocco quake: Sisters' nightmares and a plea for lipstick Elsewhere on the BBC The '60s hippy who became a multibillionaire Sir Richard Branson tells Amol Rajan how it all began Attribution iPlayer Fancy a film tonight? There's something for everyone on BBC iPlayer Attribution iPlayer Inside the notorious Maghaberry Prison... Stephen Nolan gets unprecedented access to one of the UK’s most notorious high-security jails Attribution iPlayer One of the most dramatic cases of UK coastal erosion... The residents of Hemsby don't want to leave, but their houses are on the edge of a cliff Attribution iPlayer Most Read 1 Brand makes first comments since allegations made 2 Bully XL dog owner sought after attack in park 3 Scans reveal new clues to long Covid symptoms 4 US to give Ukraine long-range missiles - reports 5 'We're under attack' - how life is changing for Italy's gay families 6 Johnson warns against 'mutilated' version of HS2 7 How shy schoolboy became YouTube millionaire sensation 8 HS2 row and smoking ban for next generation 9 Chris Mason: The week politics changed gear ahead of general election 10 Woman re-bailed after school crash deaths BBC News Services On your mobile On smart speakers Get news alerts Contact BBC News Best of BBC iPlayer An unflinching look at Picasso's legacy. Video An unflinching look at Picasso's legacy Attribution PICASSO The race from Africa to the Arctic. Video The race from Africa to the Arctic Attribution RACE ACROSS THE WORLD A joyride through chaotic family life. Video A joyride through chaotic family life Attribution JUICE Can Scotland's team rise to the top? Video Can Scotland's team rise to the top? Attribution BALLERS BALL OR NOTHING Home News Sport Weather iPlayer Sounds CBBC CBeebies Food Bitesize Arts Taster Local Three Terms of Use About the BBC Privacy Policy Cookies Accessibility Help Parental Guidance Contact the BBC Make an editorial complaint Get Personalised Newsletters Why you can trust the BBC © 2023 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.",
    "commentLink": "https://news.ycombinator.com/item?id=37611191",
    "commentBody": "Amazon Prime Video content to start including ads next yearHacker NewspastloginAmazon Prime Video content to start including ads next year (bbc.co.uk) 164 points by mellosouls 22 hours ago| hidepastfavorite304 comments rendall 21 hours agoI flat out do not watch ads. If a platform has ads, I do not watch it full stop. I pay YouTube for no ads. If I lost that option, I would not watch YouTube. Same with all of the other streaming services. Netflix pushed it last year with preview rolls. It was barely acceptable&#x2F;tolerable. But I will eagerly jettison any service that makes me pay for ads.Heck, I even look askance at people who willingly pay money to unironically wear logos. Why do you do that? You, yes, you reading this. Why do you buy Nike clothing or Adidas track suits or Louis Vuitton anything?? Explain yourself. reply transcriptase 21 hours agoparentFind me an unbranded pair of basketball shorts that will last 10 years, have consistent sizing, and cost less than $20 at an outlet and I’ll gladly buy them.I could gamble on “YAWHOHOMELIFE Men&#x27;s Running Workout Shorts Training Gym Athletic Joggers Sweat Short Pants Quick Dry Breathable with Zip Pockets”, or pay like $5 more for a little white embroidered check mark and the aforementioned benefits without needing to trial a bunch of junk from companies that won’t exist in a year. reply vladvasiliu 20 hours agorootparentWhat I&#x27;ve found is that \"serious\" equipment tends to have subdued branding, or at least has some options like that.I have a pair of basketball shorts that are still going strong after something like 12 years. They&#x27;re Nike, but the logo is black on black, so barely visible if you don&#x27;t look for it. Ditto for the basketball shoes. The logo is barely visible since it&#x27;s the same color as the shoe. The shoes are somewhat recognizable, though, because of the air thing at the heel.Decathlon (French sports brand) also has gym shorts that are subdued. Small black logo on dark green cloth. They&#x27;re also cheaper than the Nike shorts, but do seem flimsier. Their \"running\" t-shirts are great and have options with barely visible branding.Now, motorcycling gear is a whole different story... For some reason, it&#x27;s very hard to find something that doesn&#x27;t look like a freaking billboard. reply 6D794163636F756 16 hours agorootparentSimilarly high end consumer brands like Gucci don&#x27;t blast their labels on their high end products. The cheap stuff is cheap because you become a walking billboard. The expensive stuff is expensive because you just paid for quality. That&#x27;s even within one company so your point is even more extreme across an industry. reply malaya_zemlya 12 hours agorootparentDior and Louis Vuitton love putting their logos all over their products, especially accessories. I think it cheapens the brand, but i&#x27;m not their marketing person. reply 6D794163636F756 8 hours agorootparentEven with those if you sort their products by price the higher cost ones have a subtler logo because you&#x27;re right, it does cheapen the product. The higher cost&#x2F;higher end from these brands are basically a separate company with a shared name.The lower cost ones have the logo because that&#x27;s how the people you&#x27;re around will know. The higher cost ones don&#x27;t have the logo because the people around you will recognize quality. reply Velofellow 19 hours agorootparentprevre: motorcycle gear: Rev&#x27;it has some pretty neutral branded options, but not inexpensive... I&#x27;ve had good luck with the quality and fit. reply nicbou 19 hours agorootparentprevCycling gear goes the opposite direction. Decathlon is great, but they have a weird fetish for a really intense shade of blue. reply tensor 16 hours agorootparentprevSeriously. I was trying to find socks without a logo. Just simple black ankle socks, made of mostly cotton. IT&#x27;S ALMOST IMPOSSIBLE! As you said, the only options are cheaply manufactured stuff online. reply makeitdouble 10 hours agorootparentMUJI socks are comfortable and well made. And no logo, ever. reply rendall 21 hours agorootparentprevThis is a false dichotomy. Your choice is to pay extra for a logo, or pay less for equivalent quality but no logo. You choose logo. Why? reply idopmstuff 20 hours agorootparentEven if this were the case (it&#x27;s not), there&#x27;s still a time cost - I have to find the brand without the logo that&#x27;s the same quality. I buy athletic shorts maybe once every 2-3 years almost always on Black Friday. I know Nike shorts will be high quality, and I know they&#x27;ll fit. Wading through the many non-logo brands, trying them on, returning the ones that are bad, etc. might take me several hours to save tens of dollars.The point here is that you&#x27;re misunderstanding why the logo matters. I don&#x27;t care if there&#x27;s a logo on my shorts or not - I care what the logo represents, which is a brand that consistently produces high-quality goods. I&#x27;m willing to pay more for that, especially when it saves me time shopping. reply rendall 20 hours agorootparentIf you take the time to understand what makes a quality shoe, it will save you time and money and embarrassment (like, you wouldn&#x27;t be caught dead wearing Common Projects and would be embarrassed for someone wearing them). No need to rely on logos, which is weakly correlated to quality.Check this channel: https:&#x2F;&#x2F;www.youtube.com&#x2F;c&#x2F;RoseAnvil reply idopmstuff 19 hours agorootparent> you wouldn&#x27;t be caught dead wearing Common Projects and would be embarrassed for someone wearing themY&#x27;know, you seem more focused on logos and their importance than anybody else here. I would never been embarrassed for someone wearing a certain kind of shoe. I&#x27;m not judging people based on logos, since what brand of shoe someone else is wearing has absolutely no impact on my life.For athletic shoes, I wear Mizunos. Went to a good running store once, spent an hour with the old grizzled guy there until I found a shoe I liked, and I&#x27;ve stuck with the brand ever since. They&#x27;ve got a big logo on the side, but again, I don&#x27;t care about that; I care about the fact that I know the shoe will be high quality and fit well.> No need to rely on logos, which is weakly correlated to quality.No, that&#x27;s a made up fact that is wrong. Brands tend to be pretty consistent in their quality over time, especially those that have been around a while.> Check this channel: https:&#x2F;&#x2F;www.youtube.com&#x2F;c&#x2F;RoseAnvilI&#x27;m not going to check that channel because, again, the point here is that I don&#x27;t want to spend a bunch of time learning about how shoes are made. I just want to buy a good quality shoe (or short, or whatever) and brand is a fine proxy for that. The amount of money I spend buying a reputable brand is well worth it given the time I save by not watching videos like whatever the one you linked is. reply rendall 11 hours agorootparent> No, that&#x27;s a made up fact that is wrong. Brands tend to be pretty consistent in their quality over time, especially those that have been around a whileYou said you use logos as a proxy for quality because you don&#x27;t have time to understand how to evaluate quality, nor learn what brands have quality but no logos. There is an inconsistency there. How would you know quality if \"does it have a logo?\" is how you evaluate it?> The amount of money I spend buying a reputable brand is well worth it given the time I saveDo you save time and money though, for real? Clothing is literally the thing that touches your body the overwhelming majority of your time and clothed is the only way the vast majority of people will ever see you. Isn&#x27;t it worth taking an afternoon or a weekend and learning the fundamentals of how to look good? I mean if you want to spend a lot of money on a reputable brand and be sure of quality, try https:&#x2F;&#x2F;www.jcrew.com or if you want to be adventurous https:&#x2F;&#x2F;makia.com&#x2F;Alright, internet stranger, I&#x27;m sorry to have upset you. If you genuinely love Adidas track suits and the Nike swoop on your hat and the LV on your bag, then fly that flag high and proud! No one can stop you. reply pfannkuchen 19 hours agorootparentprevWell sure, they have identified that people wearing logos is strange and they don’t like it. Why wouldn’t they be more focused on logos than someone who hasn’t noticed this? It is kind of hard to notice given how common it is, and I think one has to be at least slightly detached from the zeitgeist to really notice the strangeness. reply ecshafer 19 hours agorootparentprevI buy whatever sneakers are currently on sale at Costco when I need new ones. There is usually a logo, I don’t think anyone looks at me askance.Your solution is to spend hours upon hours of research and spend more money on a product to avoid a logo, which most people actually don’t ever notice or care about.Why would someone be embarrassed about common projects? reply Given_47 16 hours agorootparentprevDid not expect a reference to that viral common projects vid on here haha. Though I did snatch a decently used pair of achilles for $60 and have been my go to for the last three years (the soles r now smooth as a rock so I have been wearing them less out of caution). But I absolutely love those shoes: ridiculously comfortable, easy to clean, go with literally everything.Now I can’t say they’re worth $450 or whatever. And no idea if they’re better than Koio’s—had I found a used pair of those for cheaper, I’d own those instead. So with all things, YMMV. I agree with the sentiment of “don’t equate brand&#x2F;price with quality” tho reply rendall 20 hours agorootparentprevLearn to recognize quality by sight, particularly by stitching and materials, not logo.Logos are not emblematic of quality, but of good marketing (shoes aside - Nike makes good sneakers). reply blairbeckwith 18 hours agorootparentDo you ever buy anything online? You are taking this really self-righteous, “explain yourself” attitude while seemingly not understanding that you are the one who is odd. reply thfuran 13 hours agorootparentprevYeah, any truly talented couturier can simply lick the monitor to get a sense of the product they&#x27;re looking at. reply dmd 20 hours agorootparentprevBecause, as he said, it&#x27;s NOT necessarily equivalent quality. Yes, often it is, but also quite often it&#x27;s utter crap that falls apart.For these particular type of products - and I&#x27;m not claiming this is true in all product categories! - that logo does in fact mean it is a quality, well tested product. reply trip-zip 20 hours agorootparentprevIs your statement not a false dichotomy?I like 1 particular brand of backpack with a slightly prominent logo on it.I do not believe there is an equivalent quality made by a brand without the logo I buy. reply makeitdouble 10 hours agorootparentprevYou could replace the example with cars, the point is more obvious IMO. Try buying a car with no logo.You&#x27;ll find one, but it probably won&#x27;t be the car that you wanted the most nor the one that fitted your needs the best. reply isoprophlex 21 hours agoparentprevIt is really not so repulsive to see the poor asking for money as to see the rich asking for more money. And advertisement is the rich asking for more money. reply lisper 20 hours agorootparent-- G.K. Chesterton reply isoprophlex 19 hours agorootparentThanks. I forgot the exact quote, found it searching the internet on some shady quote aggregator site, but no attribution... reply parineum 19 hours agorootparentprevPresumably, the poor here asking for money is beggars literally just asking for money while advertisements are telling you about things you could get with money. It&#x27;s a nice quip but it doesn&#x27;t represent reality at all. reply aendruk 18 hours agorootparentThis sounds backwards to me. The way I experience it, the reality of advertisements is that they are attempts at manipulating me, and the framing as mere news about nice things is part of the trick. reply throw7 21 hours agoparentprevYou brought up my pet peeve... it&#x27;s really difficult for me to shop for sports&#x2F;outdoorwear. I absolutely can&#x27;t stand being a walking billboard. The worst part is I&#x27;m paying to be one. grrrr. reply dpkirchner 19 hours agorootparentI try to find clothing that has no logos or logos that are easily removed (Eddie Bauer, for example). It&#x27;s a pain, though. reply tzs 20 hours agoparentprevLogos on shoes are useful. Here&#x27;s how I used to buy shoes:1. Go to a Payless ShoeSource store.2. Find the sneaker (AKA trainers, tennis shoes, kicks, takkies, sportex, and many other names depending on where you are in the world) aisle.3. Look at the logo on the shoes I&#x27;m wearing.4. If they have the same shoes in my size, and I don&#x27;t see any others that are noticeably less expensive, buy those shoes again.5. If they no longer have the same shoes or there are shoes that are noticeably less expensive, try on shoes to find out what they have that is comfortable and ergonomic. Then pick a pair and buy them.I say \"used to\" because after 40 years of buying shoes that way Payless closed. When the announced they were going to close I went to the two local Payless stores and bought all the comfortable ergonomic sneakers in my size. I have not yet settled on a new shoe buying strategy. reply wildrhythms 19 hours agorootparentPayless filed for bankruptcy in 2019 and hasn&#x27;t had a brick and mortar store in years. It begs the question: how often are you buying in a physical store? reply Rant423 2 hours agoparentprevRelated: https:&#x2F;&#x2F;www.gocomics.com&#x2F;calvinandhobbes&#x2F;1992&#x2F;08&#x2F;27 reply m_eiman 21 hours agoparentprevAgreed.I&#x27;m somewhat furious at Apple for having ads for their other shows before showing me what I&#x27;ve selected to watch on Apple TV+. Is there any way to disable that? reply tpmx 21 hours agorootparentOn tvOS:Settings -> Accessibility -> Vision -> Motion -> Auto-Play Video Previews -> OffIt actually seems to work. Amazingly well hidden, I must say. Bravo. reply garblegarble 17 hours agorootparentI wonder are we thinking about the same thing - I assumed the original poster was referring to the pre-roll trailers that play ahead of an episode of a TV show or film. I tried this setting but unfortunately it doesn&#x27;t seem to remove those... does it do that for you? reply tpmx 16 hours agorootparentI was thinking about those pre-roll trailers, yes. It seemed to remove them for me, but perhaps it was a random false \"negative\". reply omega3 20 hours agorootparentprev-> Accessibility -> Vision -> Motion ->Agreed, no other reason other than to make it harder to find, shameful. reply jghn 21 hours agorootparentprevI actually don’t mind this - there skippable, not disruptive to the show itself, and sometimes I learn about a new to me show I want to watch. reply ctvo 18 hours agoparentprev> I flat out do not watch ads. If a platform has ads, I do not watch it full stop. I pay YouTube for no ads.Great. Now you can pay 3 dollars for no ads on Prime Video if you want it too.Did this simple take have to be embedded in so much judgement and moral grandstanding? reply keernan 16 hours agoparentprevFor 50 years of my life, my dad always finalized a deal for a new car with one last requirement: the car must be free of all dealership logos (back then the dealership glued - or in some instances screwed - the dealership placard&#x2F;logo onto the back trunk of the car). He was nasty about it and it always made me cringe. But they also always complied. reply anakaine 11 hours agorootparentWe still do this today. It&#x27;s not that uncommon an ask. Get it added as a sales note on the contract, and don&#x27;t accept delivery unless they have complied. We tend to have heavily branded number plate holders and window stickers. reply JeremyNT 19 hours agoparentprev> I flat out do not watch ads. If a platform has ads, I do not watch it full stop. I pay YouTube for no ads. If I lost that option, I would not watch YouTube. Same with all of the other streaming services. Netflix pushed it last year with preview rolls. It was barely acceptable&#x2F;tolerable. But I will eagerly jettison any service that makes me pay for ads.Well, Amazon will include an ad-free option that you can pay more for.I think it makes sense to think of this is a price hike for the current service, combined with a new ad subsidized service offering.They probably realized that a price hike with no alternative would cost subscriptions, and just shoving existing customers into the new worse service at the old price point would retain them longer. reply tomcam 3 hours agoparentprevHad a rich girlfriend when young. Her family loved LV luggage because it lasted forever and looked perfect.When I got rich, I bought a bunch of it for my family a long time ago and it looks to be in mint condition now, decades later. It’s also super easy to recognize on the luggage carousel. Never regretted it.Other than that I have to admit I never pay to advertise anything. I live on a farm and dress like a plumber, so I never actually match the luggage. reply ajdude 8 hours agoparentprev> I pay YouTube for no adsExcept you still do get ads. With every single major YouTube video dropping a \"now to talk about our sponsor\" segment. reply joshstrange 2 hours agorootparentSponsorBlock is an amazing tool to stop this. I’m constantly surprised at how well it works. reply redhale 7 hours agorootparentprevTrue, but these are almost always very easily skippable. reply folkrav 21 hours agoparentprevI wear some brands, but I buy them at the discount&#x2F;clearance store, I&#x27;m not directly looking at buying specific brands, most of the time. However, in the case of some brands (e.g. Vans in my case) I just... genuinely enjoy their stuff. Is it that weird to have preferences? reply rendall 16 hours agorootparentDo Vans have logos? I wear a pair of white Vans in Summer. reply natpalmer1776 21 hours agoparentprevFor certain items it is part of the cost for the quality of good being procured at a given price point. I’m sure there are no-label options of equal quality and comfort, but the process of finding those options is a much greater (time) cost than the item itself is worth to me.In a different context, if an artisan knows they are the best (by a large margin) and put their mark on every item produced, few seeking the artisan for their quality would stop using that artisan due to the mark as the alternative would be inferior goods. Same thing but much bigger scale, with a dash of marketing and broken trust (brand acquisitions followed by bad products) thrown in. reply rendall 21 hours agorootparentI would understand if the choice were good quality with logo versus questionable crapshoot with no logo. That&#x27;s not usually the option, though. Perhaps you can&#x27;t just look at clothing and see whether it is quality or not? Look at the stitching and materials, for instance? I happily pay more for good quality, no-logo than, frankly, logo with middling quality. reply jdbartee 20 hours agorootparentGood luck checking out the stitching on Amazon. Even if you can see it in a picture, the item in the picture might not be the one you’re getting.And good luck finding “no brand” options in a Brick and Mortar store. reply mumblemumble 21 hours agoparentprevIt&#x27;s signaling. Wearing prominent logos sends yourself and others a message that you have the disposable income to pay twice as much for a version of the thing that has a special picture on it. reply rendall 21 hours agorootparentYes, agreed. It still does not explain the practice in a way that makes sense to me. There are so many and much better ways to signal disposable wealth. To me it immediately signals \"more money than sense\". reply FrankoDelMar 20 hours agorootparentI think there are multiple sides to this. Some people legitimately do not care whether or not they wear branding or at least prefer to be assured of reliability of the clothing fit and quality. This approach isn&#x27;t necessarily more expensive either. Something from Nike, Adias, UnderArmor sold at a discount, say at Nordstrom Rack, is superior in quality to the destined-for-landfill clothing of H&M and Primark.I don&#x27;t like branding either. For normal cotton wear, it&#x27;s largely Uniqlo peppered with more unique pieces from minimally branded designers. For sportswear I tend to purchase from Lululemon because it&#x27;s high quality and minimally branded. However, I understand it would be much cheaper to buy a bunch of discount Nike, Adias, or New Balance clothing. So I don&#x27;t necessarily associate overt branding with disposable wealth per-se and I would say it depends on the brand and the context the clothing is being worn (but maybe that&#x27;s only because of my understanding of brand differences). I would assume someone wearing all Lululemon to be more wealthy than someone wearing all Adidas even though it&#x27;s less branding.That said, certain designer brands serve only to be a status symbol like Gucci, LV, Supreme, Kenzo, Bathing Ape, Off-White, Balenziaga..the list goes on. Hell, at least if someone is driving a Mercedes or BMW they&#x27;re getting a well built car, there&#x27;s almost no excuse to pay more than $50 for a T-shirt just because it&#x27;s from Fendi or Maison Kitsune.As we pointed out in other comments, sneakers are an exception and it&#x27;s almost impossible to find decent sneakers without branding and this probably has to do with the economies of scale. reply lisper 20 hours agorootparentprev> There are so many and much better ways to signal disposable wealth.These are not mutually-exclusive options. reply distcs 21 hours agorootparentprevHonest question. Where you buy your clothes from? As much as I would like to buy clothes without logos, they are not easy to find where I live. reply rendall 21 hours agorootparentI live in Finland. My favorite place to get sportswear and just daily wear is H&M. No logos. My favorite design house is Makia. Really amazing stuff. https:&#x2F;&#x2F;makia.com&#x2F; but if it has a big-assed Makia logo I don&#x27;t buy it.When I lived in New York there were so many options it was hard to choose, but I&#x27;d check out used clothing boutiques for fun things. reply dpkirchner 19 hours agorootparentFWIW, in the US, H&M is known for fast-fashion, garbage-tier clothing. I&#x27;ve heard the brand is better outside the US, though. reply rendall 12 hours agorootparentHmm. You may be right. Here is the men&#x27;s pants section on the Finnish site https:&#x2F;&#x2F;www2.hm.com&#x2F;fi_fi&#x2F;miesten&#x2F;osta-tuotteen-mukaan&#x2F;housu...Equivalent items do generally look better, to me at least, compared to the UShttps:&#x2F;&#x2F;www2.hm.com&#x2F;en_us&#x2F;men&#x2F;products&#x2F;pants.htmlEquivalent prices, too.For example, compare the \"cargo joggers\" Finland https:&#x2F;&#x2F;www2.hm.com&#x2F;fi_fi&#x2F;productpage.1002227020.htmlto the equivalent item from the US store https:&#x2F;&#x2F;www2.hm.com&#x2F;en_us&#x2F;productpage.1002227011.htmlTo me the one available from the Finnish store has a better cut and seems to be made of a thicker material. reply rendall 12 hours agorootparentprevIf I lived in the US in a place that didn&#x27;t have many good stores around I&#x27;d buy from retailers online and try out different things. I&#x27;ve had luck with https:&#x2F;&#x2F;www.uniqlo.com reply fshbbdssbbgdd 17 hours agorootparentprevI keep hearing people say this, but the few things I bought there lasted many years. reply FrankoDelMar 20 hours agorootparentprevYou may be interested -- Karhu is from Finland and makes minimally branded sneakers reply rendall 20 hours agorootparentThanks for the tip! reply parineum 18 hours agorootparentprev> To me it immediately signals \"more money than sense\".There is an amount of money one could have that no amount of sense could make up for.In reality flagrant wealth is often tied to poor financial decisions that have lead to a lack of actual wealth. reply fipar 19 hours agoparentprevMost people I stumble upon wearing logos due it for signaling. The logos send signals like \"I can afford this\", or \"I&#x27;m into sports\". As a side effect, they&#x27;re walking billboards for the brands, but that&#x27;s just that: a side effect. reply esistgut 21 hours agoparentprevI buy Nike running shoes because they are cheap, durable and comfortable, I don&#x27;t actually use the to run. The other obvious answer to this question is \"because they are status symbols\", for some people anyway. reply rendall 21 hours agorootparentShoes, sure, because they do make great running shoes, and I suppose - forgive me - if one doesn&#x27;t care about making a good visual impression, they are quite comfortable for everyday wear. I&#x27;m more confused by the visors and shirts and such. Any ostensible status garnered by being an ad is immediately overbalanced by the questionable taste and decisions of its wearer. reply HeyLaughingBoy 19 hours agorootparentYou seem to be going to great lengths to avoid confronting the fact that most people simply don&#x27;t care about logos, or, if they do, are doing it to fit in with whatever crowd they&#x27;re a part of. reply MisterTea 20 hours agorootparentprevI think the OP was more focused on basic clothing items and accessories like tee shirts with logos.I would give their running shoes a pass as my downshifters are amazing - they make me want to run - so quite comfortable and functional. A Nike branded shirt or pants however are just decorated cloth. reply iamnotsure 19 hours agoparentprevAlgorithmic ads (AA) vs plain old ads (POS). reply Mindwipe 21 hours agoparentprevThe article pretty clearly states that there&#x27;s an ad free tier for an extra $3 a month. reply tzs 20 hours agorootparentYup. The other way to view this story is that Amazon is raising the price of Prime by $3&#x2F;month and introducing a new product, Prime with Ads, that will be $3&#x2F;month less than Prime. reply verdverm 20 hours agorootparentThe most relevant, succinct pair of commentscheers! reply browningstreet 20 hours agoparentprevYou can opt out of ads for an additional fee. I don’t want ads either. I’ll figure out which platforms I’ll pay the no-fee level and cut some. I do have a small password sharing friend group tho — the total costs of all the streaming networks we like is getting stupid. reply NickC25 21 hours agoprevImagine a world where a guy worth over 150 billion dollars who owns a company worth over a trillion dollars and has a quasi-monopoly over the internet is in such desperate need of more money to the point where he&#x27;s going to put advertising on his video platform, even though people already pay for the platform. Instead of raising prices moderately, or putting better content on the platform, they decide to instead put ads on the platform.Some people just don&#x27;t have the ability to say \"yeah, we&#x27;ve got enough\". Sad. reply kleinsch 19 hours agoparentYou ignored the first paragraph of the article that says you can pay for an ad-free option, which would qualify as “raising prices moderately” to me.Odds are near 100% that Amazon has been running Prime Video at a loss since it started. They spent $16B on content last year. They can stop producing so much content or they can find ways to make more money. Either way people will snark about how greedy they are for not running a service at a loss forever. reply Brendinooo 19 hours agorootparentYeah, people get so weird about this stuff. It&#x27;s TV shows, not food and water. There should be no obligation for anyone to produce and distribute this stuff at a loss.Price increases are fine. Inevitable, really. I just really hope that in the long term we&#x27;ll get to keep the month-to-month model and the \"pay more for no ads\" model. reply missedthecue 15 hours agorootparentLow interest rates created an exceptionally entitled consumer mindset. It&#x27;s been interesting to watch it break over the last year. reply lennixm 18 hours agoparentprev1. Jeff Bezos no longer controls Amazon operations. 2. He doesn&#x27;t own the company either, he owns a minority stake. 3. In what universe does Amazon come even remotely close to having a \"quasi-monopoly\" over the internet? This isn&#x27;t true when limiting it to just e-commerce. 4. The majority of people actually prefer to watch ads over increasing prices. Streaming platforms ad-supported plans are MASSIVELY successful. reply NickC25 18 hours agorootparent1. He&#x27;s the chair of the board, so he has an outsized amount of control. He could easily fire the CEO or any other C-Suite members if he wanted to.2. He owns a bit more than a minority stake, he owns (I&#x27;ve found several estimates, so I&#x27;m putting in a range here) between 9% and 12.5%. That&#x27;s hardly a minority stake for a company worth nearly $1.5 trillion. He&#x27;s the single largest shareholder.3. Maybe not a full on monopoly, but AWS has the same market share in the cloud space as the next two providers combined. (MSFT + Google). That&#x27;s as close to a monopoly as I can think in of a competitive industry without getting trust busted.4. Most people I know would prefer to keep things the way they are - they pay for a premium service on top of already paying for Prime. If Amazon offered Prime Video for free but it was ad-supported, I&#x27;d be fine with that. I don&#x27;t think I&#x27;m alone when I say that if I&#x27;m paying for a premium service (Video) on top of already paying for a service (Prime), Amazon shouldn&#x27;t be allowed to triple-dip by selling ads.Streaming platforms usually have ad-supported tiers, yes, but most of those are either free or very cheap. reply lennixm 17 hours agorootparent1. I&#x27;m not saying he doesn&#x27;t still have control over governance at Amazon. As executive chair he most certainly does. Operational decision like these are not subject to the board of directors though. He also couldn&#x27;t \"easily\" unilaterally fire Jassy. With all the clout he likely still has if he told the board they should vote to fire Jassy over the decision to run ads on PV they would tell him to get bent.2. You&#x27;re literally describing a minority stake here.3. Last data point I saw was around 3% of internet traffic running through AWS. Also I&#x27;d say there&#x27;s quite a large difference between the internet as an entity and the cloud infra a tiny part of it is run on.4. Most people I know would prefer to get Prime for free but that&#x27;s never gonna happen either. I&#x27;d wager that at this point the only cash flow positive streaming platform out there is Netflix which is simply not sustainable. So it&#x27;s either cancel the product eventually, raise prices, or introduce ads. The vast majority of people would opt to go with the ads. reply mumblemumble 21 hours agoparentprev> Some people just don&#x27;t have the ability to say \"yeah, we&#x27;ve got enough\".It seems fairly clear to me that having more stuff makes people more greedy. And, yes, there is causation there, not just correlation.You can even see this in young children. Give a pack of preschoolers a mountain of toys, more than they could possibly use, and they will immediately begin hoarding and fighting over them. Give that exact same group of preschoolers three empty cardboard boxes and a wooden spoon, and they will use them as props in a cooperative game. reply TeMPOraL 20 hours agorootparent> It seems fairly clear to me that having more stuff makes people more greedy. And, yes, there is causation there, not just correlation.My hypothesis for this is that wealth isn&#x27;t free; the more you have, the more expensive maintaining it is, the more rapidly it&#x27;ll evaporate if you fail to maintain it, and the worse it&#x27;ll hurt. In case of Amazon, it&#x27;s probably less that they&#x27;re bored and are coveting more money for no reason - it&#x27;s more likely that they face the usual pressures for growth and continue to seek opportunities to squeeze more money out of people.> You can even see this in young children. Give a pack of preschoolers a mountain of toys, more than they could possibly use, and they will immediately begin hoarding and fighting over them. Give that exact same group of preschoolers three empty cardboard boxes and a wooden spoon, and they will use them as props in a cooperative game.I question that. I have two small children, and whether they&#x27;re dealing with a mountain of toys, or three pans and a wooden spoon, they&#x27;ll switch between fighting over a single thing and playing cooperatively every couple minutes. They&#x27;re very quick to get into a fight, and even quicker to make up again. reply dgudkov 18 hours agoparentprevAmazon is a publicly traded company. Shareholders want to increase their stock value by increasing profits. Blaming only Bezos for greediness is not fair. He may be greedy but so are all the shareholders. reply sneak 19 hours agoparentprevIf he&#x27;d stopped when he had enough, I wouldn&#x27;t be able to order stuff at 23:00 and have it delivered at 07:00.If Musk had stopped when he had enough, I won&#x27;t be able to take weekend vacations to orbital hotels in my lifetime.Enough money to live comfortably is just one goal; building cool things is another orthogonal one. reply flandish 6 hours agorootparentWhen those “cool things” are made through exploitation (and they are), being ok with it makes you a deplorable shithead.These are not things worth the human costs associated. reply parineum 18 hours agoparentprev> quasi-monopolyAKA, not a monopoly.Monopoly is such a funny buzzword to me because it&#x27;s both wildly misused and completely misunderstood to be an inherently bad thing.In reality, there is rarely a true monopoly and the only bad thing about them is that they enable anti-competitive behavior and that&#x27;s the thing that&#x27;s illegal and bad.Amazon \"quasi-monopoly\" comes from having the best service. Great service is good for consumers. reply mrcrumb1 13 hours agorootparentNo true Scotsman argument aside, anti-competitive practices by very powerful firms are a bad thing, even if the firm got the market power because they have or had the best product. reply Vt71fcAqt7 16 hours agorootparentprevAgreed. Products&#x2F;companies can be anticompetitive even if they are not a monopoly. Products can also contain their own submarket in which they achieved a monopoly through anticompetitive practices. For example ios on Iphones. That last bit is somewhat controversial but is the opinion of the current justice department of the executive branch of the government and seems to be the correct reading of the Kodak case[0]. In any event I don&#x27;t think Prime video is anticompetitive except in as much as it can take losses for years to price others out of the market but that doesn&#x27;t seem to be happening.[0]https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eastman_Kodak_Co._v._Image_Tec.... reply epups 20 hours agoparentprevIf Jeff Bezos said \"I&#x27;ve got enough\", perhaps Prime Video wouldn&#x27;t exist, which would be a net loss to their employees and their consumers who pay for that. It would also mean that Netflix and Disney would very likely be charging more, due to less competition.Now, if you meant he should just be running this kind of stuff pro bono, consider that Prime Video cost about $16 billion USD per year just for content last year. Even if he puts all his wealth into it, Prime Video would last less than 10 years as a free service before it had to shut down.I think we should tax the hell out of billionaires by the way, but that&#x27;s an unrelated issue. reply NikkiA 10 hours agoparentprevCapitalism demands that all products and services are maximally enshittified for profit to the breaking point line, and no further. reply ChatGTP 19 hours agoparentprevHe didn&#x27;t get rich from being charitable! He got rich from being greedy and IMO stingy. reply crazygringo 10 hours agoprevProbably most people will disagree, but I&#x27;m happy with this.I pay for Prime exclusively for the shipping. I never wanted video in the first place.So if Amazon needs to raise prices&#x2F;revenue, I prefer that they keep Prime the same, and raise the price (now +$2.99&#x2F;mo.) for people who are big watchers of Prime Video and don&#x27;t want ads.So this price segmentation makes sense to me. reply clay_the_ripper 9 hours agoparentAlthough I hate ads, the option to pay $3&#x2F;mo to not have them seems entirely reasonable.The value I get from prime is far in excess of what I pay for it - even at a much higher price. reply flandish 6 hours agorootparentExcept it’s not reasonable and they outright lied. To say they are not increasing prices but then to keep the same quality &#x2F; category of service you have to pay more … is sociopath &#x2F; gaslight speak for “we are raising prices.”Being ok with it because it’s “only 3 bucks” is just letting them know it’s ok and they and others will do it more and more.Amazon makes plenty of profit. They can have a lower price option with ads.. and keep ad free the same. reply AuryGlenz 6 hours agoparentprevIt’s too bad that ever since COVID prime shipping no longer means 2 day shipping - at least in my area. I question why we’re still paying for it as we don’t use Prime Video much either. reply mmahemoff 21 hours agoprevIt’s funny how blatantly every streaming service waits for Netflix to do anything bold before doing same thing.It’s like what happens when Apple does something like removing headphone socket. Backlash from the loud minority “I’ll never buy another iPhone again”. then every competitor quietly follows.(In Australia, Binge app – the main local streamer with HBO shows etc – also started ads a few months ago, with a higher ad-free tier.) reply 1980phipsi 21 hours agoparentStill made about the removal of the headphone socket though... reply nemacol 21 hours agorootparentSame. BT is expensive garbage. reply mortehu 21 hours agorootparentSome headsets now come with USB-C connectors instead of 3.5mm jack. For example Koss PortaPro. reply nemacol 21 hours agorootparentIn a decade or two when every device has the USB-C instead of 3.5, I will be pretty excited about that. Until then I have to spend my time searching out those dongles. reply coldpie 21 hours agorootparentIt&#x27;s not so bad. Buy a half-dozen dongles, grab a new one from the pile when your current one breaks, and buy another half-dozen when you take the last one from the pile. I find Best Buy&#x27;s Insignia brand lasts longest. Is it as good a headphone jack? No. But it&#x27;s not that bad either. reply nemacol 20 hours agorootparentYeah, it is not the worst thing to deal with. I have adopted this strategy and the end result is I have to spend more money and walk around my house looking for them from time to time. Not terrible.I&#x27;m still mad about it. reply mavhc 20 hours agorootparentprevNeed at least 2 usb-c connectors so you can charge as well reply entropyie 21 hours agorootparentprevNokia, Fairphone Androids have 3.5mm headphone sockets still btw. reply bigstrat2003 1 hour agorootparentFairphone got rid of the headphone jack last I looked. reply drbobmd5 19 hours agorootparentprevAs does Sony reply chung8123 19 hours agoparentprevIn this case Netflix followed the other ad supported networks. reply kar1181 21 hours agoparentprevJust waiting for spotify to do it too. reply ahoka 21 hours agorootparentThey already have ads in podcasts. reply nintendo1889 21 hours agoparentprevI adamantly refuse to buy a USB c headset because I&#x27;m sure in 2 years there will be a new standard. reply ilyt 21 hours agorootparentUSB micro was introduced in 2007 and is only now on its way out.I&#x27;m pretty sure we have at least decade or two of USB-C.It also got to the point when nothing but laptops and external hard drives need full capability of it so I think it will live for longer. reply pavlov 21 hours agorootparentprevUSB-C is legally mandated in the EU, and Apple finally switched over their entire lineup. It doesn&#x27;t seem like it&#x27;s going anywhere any time soon. reply seanmcdirmid 20 hours agorootparentThis isn’t exactly true. An industry consensus is demanded in the EU, that just happens to be USB-C ATM. The rules are flexible enough to allow for technology advance, as long as everyone does it all at once. reply sneak 19 hours agorootparentWhere everyone is defined by everyone big enough to send delegations to implementer forums and dictate top down standards to everyone else.Remember HDCP? reply praisewhitey 18 hours agorootparentprevUSB 4 uses the same port so it will be around for another 10 years most likely. reply yffi_bit 22 hours agoprevThis is equivalent to shrinkflation: pay the same, get less. Streaming platforms want to retain most users, but also extract more value from them. Slowly a new threshold for what&#x27;s \"normal\" is set, and perhaps then -more- adds can be added. There&#x27;s no need to speculate where things go from there. Just look at where cable TV is. reply pradn 22 hours agoparentLet&#x27;s coin a new term for this, \"adflation\". reply hef19898 22 hours agorootparentStreaming just came full cycle to traditional TV broadcasting. An impressive feat of disrupting an industry right there. reply sarchertech 22 hours agorootparentYou need a streaming aggregator for the cycle to be complete. reply Copernicron 21 hours agorootparentAt least one telecom provider in Canada has already started doing that [0]. I expect it won&#x27;t be long before others join in.[0] https:&#x2F;&#x2F;www.telus.com&#x2F;en&#x2F;streamplus reply Krutonium 20 hours agorootparentMy Cable TV package comes with at least 5 different streaming platforms. I only have said package because it actually brings my bills total cost down, somehow. reply Velofellow 19 hours agorootparentprevSeeing the writing on the wall that we could be headed back to the cable TV era, I had a hairbrained idea (haha- really just a name) back in like 2011&#x2F;12, that would aggregate the three big streaming platform&#x27;s libraries in a single interface. called: HuFlixPrime.My idea to get cooperation and buy-in across the streaming providers was to try and \"nudge\" customers to subscribe and bundle competing services by directly showing all programming that could be accessed in one interface. Ideally streaming and account management and signup would be done through this single clearing house. Perhaps an incentive if all three services were active.Obviously would be fraught with issues, and I could never really see any cooperation like that working. but I liked the name... reply 34679 21 hours agorootparentprevThe Pirate Bay reply nobody9999 21 hours agorootparentI&#x27;d add that I actually pay for Amazon Prime (mostly for the free shipping -- heavy stuff costs a fortune otherwise), but use other means to access Prime Video content because of the ads (there are a raft of Prime Video offerings that already have ads) and the spying. reply 34679 20 hours agorootparentI had a similar experience when I recently purchased Need for Speed: Heat on sale from Steam. The mandatory EA launcher that was installed along with game had separate spyware that launched at boot and couldn&#x27;t (easily) be disabled. The \"alternative version\" didn&#x27;t have that, so that&#x27;s what I ended up playing. reply reaperman 21 hours agorootparentprevIt splintered enough at the end with cable vs. DishNetwork vs. DirectTV. i remember specific local sports games only being on one and then another. reply darkwater 21 hours agorootparentprevI think every country has at least 1-2 telco operators doing exactly that in their top-tier connectivity packages (usually pretty expensive) reply bombcar 21 hours agorootparentprevI’ve noticed that the Apple TV app on Apple TV drags in content from other apps somehow. reply notyourwork 18 hours agorootparentprevComing 2025. reply phone8675309 21 hours agorootparentprevAmazon was advertising during the football game last night that they could aggregate your subscriptions to at least Amazon Prime Video, Max, Paramount+, and AMC+ so you could get content from all of those platforms in the same place. reply swexbe 21 hours agorootparentprevNor sure why anyone would expect somwthkng else. Streaming doesn’t make things any cheaper than traditional tv, production might be slightly cheaper but not because of streaming. Shareholders still want the same roi.Everything being VoD is a pretty nice feature though. reply ilyt 21 hours agorootparent> Streaming doesn’t make things any cheaper than traditional tvStreaming is oodles cheaper than owning traditional TV station. reply swexbe 39 minutes agorootparentIt really isn&#x27;t cheaper. Netflix pays $1bil&#x2F;yr to aws. The only advantage streaming providers have is that you&#x27;re already paying for an internet connection. But TV over internet solutions have been a thing for a long time so even this doesn&#x27;t really matter. At the end of the day it&#x27;s just bits going through a plastic tube from one computer to another. If anything, the 1 to 1 on-demand aspect of streaming would make this the more expensive option. reply ghaff 21 hours agorootparentprevBut the networks didn’t (mostly) own the traditional TV stations. Streaming cuts the middlemen out of the loop which is probably a bit cheaper though overall. reply swexbe 36 minutes agorootparentThe new middlemen are cloud (unless you&#x27;re amazon&#x2F;google) and internet providers. replygdulli 21 hours agoparentprev> Just look at where cable TV is.With a cable DVR you can arbitrarily control the video stream. You never have to watch an ad if you don&#x27;t want to. Amazon won&#x27;t let you conveniently skip these ads.Streaming was always going to be about losing that freedom. Cable companies weren&#x27;t bold enough to take that away, or it never occurred to them.The last time I had Spotify installed, it wouldn&#x27;t even credit me with having heard an ad if I muted my speakers. reply ToucanLoucan 21 hours agorootparentEven putting aside the ubiquity of tech like this: we had a particularly busy year and I ended up traveling a lot more often for work than I usually do, and it was insane to me how many fucking ads are in television now.Mind you I was a from the go cord cutter, when I left my parents and spread my wings, I never once wanted cable. I had it through them and it was... fine. Certainly not worth the absurd prices it goes for and as such, I have never, ever had it. In general my interests are niche too so even OTA TV is just not interesting to me. I watch YouTube, my iTunes library, and a plex box for... other stuff. That&#x27;s it.And it just blew my mind, I&#x27;m doing some work in the hotel room and I want some background noise, so I flip on the TV and... ads. Ads ads ads ads ads. For every 30 minute block I would say it&#x27;s 55&#x2F;45 between content and ads. And endless parade of medications, medical devices, lawyers promising to get you more medicare money, shitty fast food, how to lose all the weight you gained from eating the shitty fast food.And the repetition. Oh. My. Lord. Like I genuinely can&#x27;t tell if this is just because I haven&#x27;t watched TV to any extent since I was living with my parents during schooling, but I do not remember the mix of ads being so lean. Or maybe it&#x27;s because they&#x27;re running more of them, I don&#x27;t know. But I swore over the course of a week long hotel stay I saw a particular ad for Wendy&#x27;s at least a hundred fucking times. reply monetus 18 hours agorootparentA lot of channels, opinion news ones IME, seem to have reverted to early Crunchyroll levels of ad redundancy. Are there fewer bids for the ad spots? Is the audience too small or a narrow part of it so valuable that the prices for the spots only make sense for a few products that happen to be scammy shite? You&#x27;re not alone in feeling like the ads have changed a bit. reply gdulli 20 hours agorootparentprevAds aren&#x27;t going away, the war is lost, no service will leave that money on the table anymore past its temporary startup customer-friendly phase. It&#x27;s not worth complaining about.What does still matter is whether the video stream tech gives you the freedom to seek&#x2F;skip or not. Then the ads become more or less moot. Plex for local media gives you freedom, sure. My cable box does. Streaming will not. reply tomjen3 20 hours agorootparentIts worth complaining about to hold back the stream of shit for a while.But you are right eventually ads will get everywhere and even if you are willing to pay more it just means you are making enough that they can charge you even more.The solution is to abandon any platform you can where you can&#x27;t block ads. reply notyourwork 18 hours agoparentprevAnyone who thought streaming and cutting the cord was a solution to the cable tv was ignorant of businesses desire to make money and reduce cost. reply brunoqc 22 hours agoparentprevenshittification? reply dudefeliciano 21 hours agorootparentthis was also my first thought after watching the DEF CON talk: An Audacious Plan to Halt the Internet&#x27;s Ensh*ttification[1]1: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rimtaSgGz_4 reply fidotron 21 hours agorootparentprevMaybe it&#x27;s me, but this word seems overused to the point that it ends up destroying discussion.That said, in this case it&#x27;s relevant. reply IshKebab 21 hours agorootparentprevSuch a cringeworthy word though. reply jfghi 21 hours agorootparentI like the term because it strikes the appropriate nerve for the behaviors it accurately describes. reply manishsharan 22 hours agoparentprevArrr, &#x27;tis a right letdown! Shiver my timbers! Raise that black flag! reply nblavoie 22 hours agoprevAnd those companies wonder why piracy is back on the rise. We have been duped. reply ilyt 21 hours agoparentI have no problem paying for content, I pay for Spotify and video games, but I refuse to pay for video until company delivers a non-DRMed video file to my hard drive that I can watch where and how I want.Piracy is a service problem, as Gaben says so it is. reply CaptainZapp 20 hours agorootparentMy TV provider allowes me to store up to 2000 hours high definition TV in the cloud.Combined with 6 movie channels, which show virtually every movie synchronized and in its original language[0] version without ad interruption this setup works for me.[0] Granted, the original version wasn&#x27;t too helpful in watching Parasite, which I had to enjoy in the German dub. reply jayknight 19 hours agorootparent> My TV provider allowes me to store up to 2000 hours high definition TV in the cloud.That you are free to watch until you stop paying for their service. Those movies do not belong to you. reply kervantas 21 hours agoparentprevI cancelled nearly all my subscriptions and set up an old notebook at home with Jellyfin and qBittorent + search plugins. Pretty simple and satisfies my needs. reply catach 22 hours agoparentprevIs piracy on the rise? That seems like a difficult thing to reliably track. reply Fluorescence 21 hours agorootparentThere are lots of decent signals out there if someone did want to track it: standard site&#x2F;search term tracking, the number of leechers of torrents, activity in pirate subreddits&#x2F;discords, installs of Jellyfin&#x2F;Plex servers etc.FWIW I can&#x27;t say I have noticed any radical increase in popularity. The number of Leechers on the most popular piratebay torrents are only in the 100s so I assume it&#x27;s very niche. I suspect that \"playing an .mkv file\" is already too technical&#x2F;clunky for much of the public compared to using streaming app. Let alone setting up a seedbox and media server behind a VPN or whatever for the best experience. reply aqme28 21 hours agorootparentI think (from my and my friend&#x27;s behavior), that a lot of movie streaming has moved away from torrents and onto free streaming sites. There&#x27;s no longer any reason to download a movie you&#x27;re going to watch once, and it&#x27;s harder for ISPs to track you down. reply aqme28 21 hours agorootparentprevAnecdotally, I&#x27;ve found myself doing it again. I used to when I was young, but totally stopped up until about a year ago. Illegal streaming sites have become impressively good. Better UX than Netflix. reply slowmovintarget 22 hours agoprevI&#x27;m willing to buy Blu-Rays. I&#x27;m also willing to stop watching \"content\" altogether. I&#x27;m already hating the experience of the forced unskippable ads for Paramount shows that play at the beginning (AT MAX VOLUME) of every Paramount+ channel stream (Star Trek... sigh).If I have to watch ads like regular network TV, which I now find unwatchable, I&#x27;d just have to do without. reply lsaferite 21 hours agoparentYeah, the recent NFL ads are obnoxious. I don&#x27;t like sports. I never watch sports. I avoid sports related content. Forcing me to watch an ad for NFL before every episode of a show is beyond annoying. I think I&#x27;ve hit my limit and will be researching running my own content library now. reply Copernicron 21 hours agorootparentI find live sports are the one thing actually worth subscribing to myself. But then again I enjoy a good hockey, football, or baseball game. I know there are alternative streams but the quality is always poor and they&#x27;re iffy at best. Any conventional show I can find in other ways. reply coldpie 21 hours agoparentprevWeirdly, I&#x27;m able to skip Paramount&#x27;s pre-roll ads on Xbox, but not on their iPhone app. Anyway, I&#x27;ve heard Paramount&#x27;s streaming service isn&#x27;t doing so well[1], so with any luck they will give up and go back to Netflix.[1] https:&#x2F;&#x2F;www.yahoo.com&#x2F;entertainment&#x2F;paramount-just-quit-stre... reply danaris 15 hours agorootparentSo long as they don&#x27;t give up and try to get a tax write-off by just black-holing all those shows instead like some other studios did... reply smileysteve 20 hours agoparentprevYou have \"content\" in quotes, but during the actors and writers strike, there isn&#x27;t even \"content\" reply slowmovintarget 19 hours agorootparentThe business of media distribution drives us to talk about the stories we enjoy engaging with as though they are toiletries we&#x27;re restocking from the store. I replaced my empty box of tissue with more \"content,\" yay! I put that in quotes because I actually dislike the viewpoint that term comes from. I watch stories and performances, think on them, talk about them, and sometimes come back to them. I don&#x27;t consume content, as if it were used up after I watch it once.I hope the writers and actors get a fairer shake, especially with unreasonable terms for generative AI based on actor likenesses and voices. (We get to scan you once, pay you once, and use that \"data\" forever without ever paying you again.) reply drbobmd5 19 hours agorootparent> I don&#x27;t consume content, as if it were used up after I watch it once.You may be in a minority here, many people I know (like my wife) very rarely will go back to something when they&#x27;re done with it. Most people are on the lookout for something new to keep them entertained, so I would definitely argue that they are in fact consuming media. reply blagie 10 hours agoprevI recently left Prime. I was disappointed to see ads introduced into Amazon Music, for music I&#x27;d paid for. I could get the same music with ads elsewhere.To me, if I can&#x27;t keep music I&#x27;d paid for, there&#x27;s a strong case for piracy. reply allthecybers 10 hours agoprevSo they’ve abandoned being the world’s best employer by forcing return to office and return to hub. Now they are publicly abandoning customer obsession by putting ads in the middle of a movie. Unless of course you pay them extra on top of a $100+ subscription fee that has already increased YoY. This is just the start of the Amazon extracting more and more from their customers. Enshitification of everything continues. reply SpaceNoodled 9 hours agoparentIt&#x27;s day 2 at Amazon. reply allthecybers 9 hours agorootparentWell said. I agree 100%. reply passwordoops 22 hours agoprevSo we all cut the cord to get away from restrictive, over-priced packages riddled with ads so we can end up with restrictive, over-priced packages riddled with ads. Say hello to the new boss, I guess reply mumblemumble 21 hours agoparentMy public library has thousands of DVD. More than I could watch in a lifetime, I think. There&#x27;s even a bit of streaming. And, outside of the Disney stuff, none of it has ads I can&#x27;t skip. All free.I mention this and someone always complains that that Game of Mad Men is Breaking the New Black isn&#x27;t at the library. Which gets me thinking that the real boss might be our own consumerism. reply passwordoops 20 hours agorootparentI&#x27;m not complaining. My kid loves it - the library has titles that are difficult to find or not in my streaming service du jour, plus she gets exposed to just plain discovery by browsing. Something targeted, personalized suggestions have taken away from us reply danaris 12 hours agorootparentprevI am absolutely and wholeheartedly in favor of public libraries. They&#x27;re fantastic places, and deserve and need much more support than they&#x27;ve got.But the idea that just because some crappy knock-offs and overdone franchises exist, every piece of entertainment media is just interchangeable with every other one, and no one should ever be upset that they can&#x27;t easily access the specific piece of media they want to see, is just absurd on the face of it. reply hotpotamus 18 hours agorootparentprevI can&#x27;t imagine the idea of a public library being proposed in modern times. I&#x27;m glad that my local system is there and they seem very dedicated to serving the public. reply diyftw 21 hours agoparentprevPeople who \"cut the cord\" yet signed up for the various alternatives didn&#x27;t really cut anything. They just plugged their cord into a different hole. reply mcpackieh 20 hours agoparentprevIf you dropped cable&#x2F;satellite only to resume watching TV daily on streaming services, are you really a cord cutter, truly? If watching a television for hours a day is still how you burn your free time, if television shows are still your go-to topic for smalltalk, if this television programming still preoccupies so much of your mind that cancelling your streaming services and not replacing them with another kind of television service seems inconceivable, then have you truly cut the cord? The real cord is that ethereal tether between you and the tube, cut that if you want to be free.It took me a few years to realize this, but cancelling your cable subscription only to spend just as much time staring at the same television mindlessly &#x27;consuming content&#x27; on netflix or prime is fundamentally the same lifestyle. reply thiht 19 hours agoprevThey&#x27;ve already killed Prime Video in the last year.I cancelled my Amazon Prime subscription yesterday because:- 1-day delivery is not a thing anymore- Prime Video used to be my favorite streaming service, now it sucks. Every time I want to watch something, I have to pay an additional subscription, and it&#x27;s way too hard to find what&#x27;s actually included- it&#x27;s too expensive for the value it provides (70€). Actually I&#x27;m not sure what value it provides anymore reply duffyjp 19 hours agoparentThe thing keeping me on Prime has been their unlimited photo backup service. The desktop app either doesn&#x27;t work anymore or I have too much content for it to handle. It spins and spins but nothing happens. I can manually backup via the web client but it&#x27;s a huge pain and there&#x27;s no automatic sync of new content. I never really know if I&#x27;m 100% backed up either.I was excited to see Apple announce new iCloud tiers above their old 2TB limit, but the prices go up linearly with storage and as an amateur photography enthusiast I&#x27;m not sure even the 6TB $30&#x2F;mo plan would cover me. The only other choice is an eye-watering $60&#x2F;mo plan for 12TB. reply pers0n 16 hours agoparentprevonly buy it when you need it and when its cheaper than regular shipping, which is rare if you hvae over $25 of stuff.I rarely buy stuff, there are only like 1 or 2 times a year when I need something fast that I need Prime. I try to get from Walmart of other sites if possible. reply joe__f 19 hours agoparentprev1 day delivery is still going for most products in the UK reply lucidguppy 21 hours agoprevI am definitely getting more books from the library now.I&#x27;m sorry but everything sucks now. There&#x27;s no point anymore in trying to find good content. They&#x27;ve done this on purpose - and you can&#x27;t fight it. reply Tokkemon 21 hours agoparentI don&#x27;t think it was on purpose, just perverse incentives of the system. reply joobus 21 hours agoparentprevAgree, and I do the same. So many books, so little time. reply flanked-evergl 22 hours agoprevI can barely find something to watch on Prime which is why I only subscribe like 1 month a year, and for that month I spend maybe 8 total hours watching.Maybe if Amazon made better content, then they could get more revenue. reply usefulcat 21 hours agoparentThe Expanse was excellent, IMO. Apart from that I mostly agree. I&#x27;ve tried Jack Ryan and Wheel of Time, which were good but not amazing. reply humanlion87 21 hours agorootparent+1 to Expanse, one of the best sci-fi shows in recent times. I also saw saw Reacher and felt that it was good. reply 4RealFreedom 21 hours agorootparentprevI agree there isn&#x27;t a lot of good content on Prime. Expanse was excellent (even though they rushed the last season) and The Boys is really good. reply rerx 21 hours agorootparentprevThe Marvelous Mrs. Maisel was fabulous. They had lot of good shows in the prestige comedy or dramedy (is that still a thing?) genre. Transparent, Red Oaks, Mozart in the Jungle, Fleabag (bought from BBC) reply throwaway2203 18 hours agorootparentprevI found Wheel of Time to be terrible. Great spectacle, but trash acting (outside of the MC) and worse writing. reply mindslight 18 hours agorootparentprevDoes Amazon really deserve credit for The Expanse? The first three seasons were SyFy, the next two were Amazon and notably less good (but still good), and then with Alex and the whole sixth season they basically took it out back and shot it for the fuck of it. I&#x27;m not saying that if they made a seventh season as a musical where the characters were furries with the effects from Cats I wouldn&#x27;t still lap it up. But it feels like something Amazon bought into to milk rather than having created it. reply wellthisisgreat 21 hours agoparentprevAnimal Kingdom is exceptional reply epups 20 hours agoparentprevThe Expanse, The Boys and New Bandits are three original series with very different styles that I found entertaining. reply raldi 11 hours agoprevMods, I suggest a title change to something like, “Ads coming to Prime Video” reply verandaguy 10 hours agoparentEditorializing titles is generally frowned upon on HN, even if your suggestion is accurate reply BugsJustFindMe 10 hours agorootparentThat&#x27;s true, but in this case I would argue that the title \"An Update On\" is itself aggressively editorialized into fake bland neutrality. Correcting that is very different than the normal prohibition on title changes. reply verandaguy 10 hours agorootparentI don’t make the rules, but i do think it’s funny how “an update on” has taken on a bit of a life of its own.For example when Google says it, they’re probably killing off a service. reply tech234a 9 hours agorootparentYeah that&#x27;s part of the reason I left the title as-is when I submitted the article replyDennip 10 hours agoprevWhilst I use prime video, thats only because it comes &#x27;for free&#x27; alongside shipping, which (at least in the UK) still is pretty good in terms of next-day, sometimes even same day.I wish they would do a cheaper tier without all these additional &#x27;benefits&#x27; (Video, Music, Twitch etc), but I suspect the reality is that its sort of a loss leader even without those benefits. reply c0pium 9 hours agoparentGood news then, that’s what they did. You get a $36&#x2F;year discount for not getting ad free movies and a $120&#x2F;year discount for not getting music. reply hprotagonist 22 hours agoprev1983: “pay for cable and it’ll be ad free!”2023: “hey charlie brown, …” reply falcolas 10 hours agoprevI cant think of one positive thing to say about this. It’s a dick^wcorporate move whose sole purpose is to extract more money out of its existing users.I guess they believe the market can bear siphoning a bit more profit. At least for a little while. reply Copernicron 21 hours agoprevI only use prime for the expedited shipping. I&#x27;ve tried finding something to watch but it&#x27;s nothing but endless garbage. reply alwaysrunning 21 hours agoprevI was surprised that Prime is ranked 3rd according to 2022 data from Statista, I almost never watch anything on it but watch several channels through it and wonder if that counts towards their stats.https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;1368336&#x2F;video-streaming-... reply happytoexplain 21 hours agoparentIf I get in mind to watch a movie or show that&#x27;s not a popular current series, I find most of the time that only prime has it, or prime and some streaming service that I&#x27;m not going to add to my stack of subscriptions just for one movie&#x2F;show, especially because nowadays thanks to my experience with Hulu, it takes a little research to tell if I&#x27;m going to get ads even if I pay for the service, and I&#x27;d rather not spend that time. reply yomlica8 20 hours agorootparentIt does seem like Amazon has bought up rights to a lot of older content. reply BoxFour 21 hours agoparentprevI had a similar curiosity and just inquired about it at work.It turns out there&#x27;s quite a bit of children&#x27;s programming (possibly exclusively) available on Prime Video, which could be at least one reason for its popularity among families. reply bombcar 21 hours agorootparentIt’s huge but getting worse.There used to be large swaths available on Prime but it seems reduced, and you might as well just watch it on YouTube directly. reply pasc1878 21 hours agoparentprevMany Prime users will have it for the delivery options (and the black pattern they got to buy it). Once you have that the video streaming is there so why not use it. reply t1mmen 21 hours agoprev20 years ago, Steam was the reason I stopped pirating games. Netflix et al had the same effect for TV & movies.Today, I subscribe to 5 different streaming services, and occasionally do a month of various “channels” in those apps.I want to pay for content, but the camels back is about to break. I truly don’t want to set sails again, but the bullshit has been adding up for a while. Ads is where I draw the line. reply chung8123 19 hours agoparentYou can still buy almost everything from Prime&#x2F;iTunes&#x2F;Blu Ray without ads. reply blibble 19 hours agorootparentunless you have a DRM&#x27;less file it&#x27;s still rentingyou own nothing reply dannyphantom 21 hours agoprevWas never really able to find a great way to land in a role where you track and measure conversions but it&#x27;s always been a [admittedly lame...] interest of mine. TV ads seem to be more about brand awareness instead of actually generating conversions (as much as Hulu tries on FireTV) but it&#x27;s kind of cool to look at objectively all the same.Curious to see what kind of ads Amazon will allow on their streaming platform, how much those ads will cost, how much more expensive it will be to inject ads into any of their &#x27;most watched this week&#x2F;month&#x27; programs, and blah blah blah - the numbers and metrics will be fun to look at once they are published.All the streaming services are in the process of migrating to this model which was kinda the main thing they advertised as not doing...but we&#x27;re in 2023 now...so c&#x27;est la vie, I guess. Another user used the term \"adflation\" which is a pretty concise way to view the shifting model. reply bluescrn 21 hours agoprevGives me a good reason to cancel Prime. Haven&#x27;t been getting so much value out of free delivery as I&#x27;m not buying much physical media any more.Between Prime Video and the occasional delivery, it seemed worth keeping it. But I won&#x27;t watch a streaming service with ads. Its value to me would be reduced right down to zero. reply neilv 20 hours agoparentYeah, I&#x27;m currently paying monthly for Amazon Prime, and every time I think of canceling, I decide that I&#x27;m still using Prime Video as my only streaming service.I experimentally tried the Prime Video \"free with ads\" content, and there&#x27;s no way I&#x27;m going to tolerate that, much less pay for it.Oh, besides Amazon&#x27;s \"free with ads\" ruining the content experience, and also being a little creepy and making me feel dumber, they recently pulled a whopper of a faux pas: every Prime Video ads break included a commercial for HIV medication. Assuming that ads are somewhat personalized, as many other ads seemed to be, this was startling. I don&#x27;t have HIV, my doctor would&#x27;ve told me, I&#x27;m not at elevated risk, I haven&#x27;t browsed about it, I haven&#x27;t searched Amazon for anything I know to correlate, haven&#x27;t knowingly shared my WiFi, what is Amazon smoking this time, etc. All thoughts I went through. Was I watching a show before that? For entertainment and relaxation?Just now, I remembered the phrase \"Netflix and Chill\", and imagined someone getting this barrage of presumably targeted HIV video commercials on their personal Amazon account, on an evening that they had a special someone over. Would that someone persevere until the fourth time the video was interrupted for an extended discussion of HIV medication, before they said, \"I&#x27;m gonna go now\"?The first of the Amazon Leadership Principles:> Customer Obsession -- Leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers.I don&#x27;t see how anything about the FreeVee \"free with ads\" is consistent with the customer&#x27;s trust. I suspect this and some other recent changes are more like people frittering away others&#x27; past long-term investments, in an attempt at short-term returns. reply dpkirchner 18 hours agorootparentI&#x27;ve seen the same ads on their \"free\" movies. The way I see it, either some big pharma screwed up their ad targeting or Amazon is scamming them (the real customer) big time. reply tycho-newman 21 hours agoprevAnd we are back to the cable model! We did it everyone! We cut the cable and chained ourselves to the tech companies! reply 2OEH8eoCRo0 20 hours agoparentWhy can&#x27;t cable companies innovate and spend billions in VC money to subsidize cable and make it $5&#x2F;mo? reply sarchertech 21 hours agoprevAs long as they have an add free option for a reasonable price I’m fine with it. It seems likely that with the money they are spending on shows streaming isn’t currently profitable.Looks like $2.99 extra a month gets you no ads. reply rz2k 21 hours agoparentAt some point advertisers are going to say they don’t want to reach people who don’t pay the $2.99, and eventually the ad-free tier will become “limited ads”. Why would Amazon leave all that money on the table? Even PBS has about a minute and a half of “major corporate funders” ads on their nightly news. reply sarchertech 18 hours agorootparentThat’s a real possibility. The more money you pay to avoid ads, the more valuable you are to advertises.I hope that it’s not inevitable though because there are so many streaming services, and because piracy and VPNs are an option.If I had my way I’d create regulation that forces companies to offer ad free versions for some multiple above the ad supported price. reply tensor 16 hours agorootparentprevAnd at that point I cancel and find other ways to get the content ad-free. Maybe I can buy shows I like individually on Apple TV, or I don&#x27;t watch them. I have a hard no ads policy. reply JadeNB 21 hours agoparentprev> Looks like $2.99 extra a month gets you no ads.That&#x27;s only a reasonable price if you discount the $15&#x2F;month you&#x27;re already paying. I mean, maybe it&#x27;s reasonable anyway, and sure that $15&#x2F;month is also paying for other things; but let&#x27;s not discount the existing price just because it&#x27;s existing. reply throw9away6 21 hours agorootparentI’d be happy to drop prime video out of the normal package. The only good show is the expanse. The rest is mostly meh. The lord of the rings bonfire is mostly a flop reply ctvo 18 hours agoprevAmazon Prime Video spent 16 billion dollars on content last year and it&#x27;s the worst of all the major streaming platform when it comes to original programming.In the last year, their big budget bombs:- Wheel of Time barely watchable CW quality TV- Lord of the Rings oh my gosh level bad- Citadel unwatchable it&#x27;s so badI will admit they do have some OK recent content. The Peripheral was entertaining, for example.But man, who gets fired for those billion dollar bombs? reply effingwewt 15 hours agoparentThose should have all been runaway hits. WoT and LOTR especially, all they had to do was stick to what made it successful in the first place.Instead Rand was sidelined, they made me hate Galadriel, et al.I can&#x27;t imagine paying millions for a recipe and then throwing it out because I think I know better. reply jamesmontalvo3 21 hours agoprevThis is the final straw for me. I’ve wanted to cancel Amazon services for a while but since I have several bundled it was just painful enough to not want to make the effort. reply julieturner99 22 hours agoprevwon’t watch it with ads. can’t imagine handing over more cash than i already do to amazon. so, guess i’ll just have to focus on the other many channels i subscribe to. reply kar1181 21 hours agoparentMore pertinently than that, it&#x27;s a quick win for a kids show, ads when young kids are involved increase friction so much it&#x27;s not worth it. reply maxerickson 10 hours agoprevI wonder if they would make more money if they focused on providing a good service instead of on incrementally maximizing revenue.Like imagine a streaming service where you could rent shows for a couple weeks for almost nothing, with a huge catalog. People would be all over it.Instead, they are looking at how to segment people that are using their service into groups that get a shitty experience or pay a bit more per year. reply beej71 8 hours agoprevJust ordered bicycle fenders from my local shop. Ordered a new moto air filter from the local shop. Same prices as Amazon. Yes, I have to bicycle there to pick them up, but I think I&#x27;m going to enjoy it. Thanks for the encouragement, Amazon! reply thoughtpalette 21 hours agoprevJust cancelled my prime and set to not auto-renew a week or so ago. As I was doing that, I noticed the pricing was going to increase by ANOTHER $20 USD, from $120 currently, to $140. I&#x27;ve been getting so many delivery delays lately it&#x27;s just not worth it. I&#x27;ll stick to the other streaming services for now. reply anakaine 11 hours agoprevThis is the point where I will stop paying for Prime membership. I was sucked in via dark patterns (which they are now being taken to task over by federal gov) and I&#x27;ve just idly maintained it because I occasionally watch stuff. Once they inject ads, I disconnect the service because I&#x27;m not paying to be served intrusive advertising. reply dylan604 10 hours agoprevSo, $2.99&#x2F;month * 12 = $35.88&#x2F;year. Are they really saying that they are going to make less than $36USD per year from viewers being served ads? Otherwise, why would they allow an ad free experience if it is leaving money on the table? reply macNchz 10 hours agoparentPerhaps anticipated churn from users who are heavy video users but will not tolerate ads? reply mintplant 10 hours agorootparentThis is me. I won&#x27;t be using Prime Video once they start showing ads with it. I don&#x27;t think I&#x27;ll spring for the ad-free upgrade, though, because the whole thing has left a bad taste in my mouth. reply nerdponx 10 hours agoparentprevThey think removing ads will be worth $2.99 to people, and that they&#x27;ll make enough off of this + the ads themselves to offset the loss of some people leaving due to the add. reply swader999 22 hours agoprevTime to write a &#x27;VCR&#x27; for Prime lol. reply XorNot 21 hours agoparentIt strikes me that auto-stripping ads after DVRing the shows should be a pretty simple AI problem these days. reply isykt 21 hours agorootparentThis reminds me that the Alamo Drafthouse used to have a program called “TV at the Alamo” and it was brilliant.It was $5 to reserve a seat, and that $5 went towards food and drink purchases. They would show the previous week’s episode while the current episode was airing, strip out the ads and then project the current week’s episode. I watched Mad Men and Breaking Bad this way. reply bluescrn 20 hours agorootparentprevGiven how ads tend to be louder than the content, you could probably detect it based on the average audio level without any fancy AI reply readthenotes1 18 hours agorootparentThat&#x27;s supposed to be illegal now in the US. reply rerx 21 hours agoprevEarlier submission today where this is already being discussed: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37610500 reply physicsguy 21 hours agoprevFreevee was an obvious step towards this. reply rerx 20 hours agoparentFreevee disgusts me. I don&#x27;t think there&#x27;s any paid option to watch Bosch: Legacy without ads. reply readthenotes1 18 hours agorootparentIt&#x27;s free (doesn&#x27;t require amazon). Is Bosch so bad that it&#x27;s not worth renumerating the publisher&#x2F;actors&#x2F;etc? reply molave 21 hours agoparentprevYes. I don&#x27;t mind ads if the service is free. Put it in a paid service, I&#x27;ll consider my outlay \"money on the table\" better spent on more productive&#x2F;fulfilling ventures. reply mgarfias 8 hours agoprevI signed up for two day delivery. I haven’t had that with any regularity in years. This might just be the thing that makes me unsubscribe reply dzonga 21 hours agoprevpirate - download content.play it off a usb &#x2F; hard-drive. offline.win. or buy blueray disk. either ways that&#x27;s a win. reply 54 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Amazon plans to incorporate advertisements into its Prime Video streaming service in 2024, targeting revenue generation for its TV shows and films.",
      "Customers in the UK, US, Germany, and Canada will start seeing these ads early next year, but they can opt for an \"ad-free\" subscription at an extra cost, mirroring actions of competitors Disney+ and Netflix.",
      "While there are concerns, Amazon assures that ad frequency will be less compared to linear TV and other streaming platforms; analysts believe Amazon's convenience factors and bundled services might offset potential subscription losses."
    ],
    "commentSummary": [
      "Amazon Prime Video is considering integrating advertisements into its streaming service, causing distress amongst subscribers, many of whom are threatening to cancel their subscriptions.",
      "Users voiced their frustration over the rising number of commercials on streaming platforms, arguing it may lead to piracy. Some even suggested alternative ways to consume ad-free content.",
      "The discussion broadened to touch on topics like minimal branding and the influence of wealth on companies like Amazon, underlining the general disappointment and concern about the potential erosion of streaming quality for monetary gain."
    ],
    "points": 164,
    "commentCount": 304,
    "retryCount": 0,
    "time": 1695386169
  },
  {
    "id": 37614279,
    "title": "Apple fucked us on right to repair (again)",
    "originLink": "https://pluralistic.net/2023/09/22/vin-locking/#thought-differently",
    "originBody": "Skip to content Pluralistic: Daily links from Cory Doctorow No trackers, no ads. Black type, white background. Privacy policy: we don't collect or retain any data at all ever period. Books About Forums Podcast Newsletter RSS Twitter Mastodon Medium Tumblr Pluralistic: Apple fucked us on right to repair (again) (22 Sept 2023) Today's links Apple fucked us on right to repair (again): \"Parts-pairing\" is a scam. Hey look at this: Delights to delectate. This day in history: 2003, 2008, 2013, 2018, 2022 Colophon: Recent publications, upcoming/recent appearances, current writing projects, current reading Apple fucked us on right to repair (again) (permalink) Right to repair has no cannier, more dedicated adversary than Apple, a company whose most innovative work is dreaming up new ways to sneakily sabotage electronics repair while claiming to be a caring environmental steward, a lie that covers up the mountains of e-waste that Apple dooms our descendants to wade through. Why does Apple hate repair so much? It's not that they want to poison our water and bodies with microplastics; it's not that they want to hasten the day our coastal cities drown; it's not that they relish the human misery that accompanies every gram of conflict mineral. They aren't sadists. They're merely sociopathically greedy. Tim Cook laid it out for his investors: when people can repair their devices, they don't buy new ones. When people don't buy new devices, Apple doesn't sell them new devices. It's that's simple: https://www.inverse.com/article/52189-tim-cook-says-apple-faces-2-key-problems-in-surprising-shareholder-letter So Apple does everything it can to monopolize repair. Not just because this lets the company gouge you on routine service, but because it lets them decide when your phone is beyond repair, so they can offer you a trade-in, ensuring both that you buy a new device and that the device you buy is another Apple. There are so many tactics Apple gets to use to sabotage repair. For example, Apple engraves microscopic Apple logos on the subassemblies in its devices. This allows the company to enlist US Customs to seize and destroy refurbished parts that are harvested from dead phones by workers in the Pacific Rim: https://repair.eu/news/apple-uses-trademark-law-to-strengthen-its-monopoly-on-repair/ Of course, the easiest way to prevent harvested components from entering the parts stream is to destroy as many old devices as possible. That's why Apple's so-called \"recycling\" program shreds any devices you turn over to them. When you trade in your old iPhone at an Apple Store, it is converted into immortal e-waste (no other major recycling program does this). The logic is straightforward: no parts, no repairs: https://www.vice.com/en/article/yp73jw/apple-recycling-iphones-macbooks Shredding parts and cooking up bogus trademark claims is just for starters, though. For Apple, the true anti-repair innovation comes from the most pernicious US tech law: Section 1201 of the Digital Millennium Copyright Act (DMCA). DMCA 1201 is an \"anti-circumvention\" law. It bans the distribution of any tool that bypasses \"an effective means of access control.\" That's all very abstract, but here's what it means: if a manufacturer sticks some Digital Rights Management (DRM) in its device, then anything you want to do that involves removing that DRM is now illegal – even if the thing itself is perfectly legal. When Congress passed this stupid law in 1998, it had a very limited blast radius. Computers were still pretty expensive and DRM use was limited to a few narrow categories. In 1998, DMCA 1201 was mostly used to prevent you from de-regionalizing your DVD player to watch discs that had been released overseas but not in your own country. But as we warned back then, computers were only going to get smaller and cheaper, and eventually, it would only cost manufacturers pennies to wrap their products – or even subassemblies in their products – in DRM. Congress was putting a gun on the mantelpiece in Act I, and it was bound to go off in Act III. Welcome to Act III. Today, it costs about a quarter to add a system-on-a-chip to even the tiniest parts. These SOCs can run DRM. Here's how that DRM works: when you put a new part in a device, the SOC and the device's main controller communicate with one another. They perform a cryptographic protocol: the part says, \"Here's my serial number,\" and then the main controller prompts the user to enter a manufacturer-supplied secret code, and the master controller sends a signed version of this to the part, and the part and the system then recognize each other. This process has many names, but because it was first used in the automotive sector, it's widely known as VIN-Locking (VIN stands for \"vehicle identification number,\" the unique number given to every car by its manufacturer). VIN-locking is used by automakers to block independent mechanics from repairing your car; even if they use the manufacturer's own parts, the parts and the engine will refuse to work together until the manufacturer's rep keys in the unlock code: https://pluralistic.net/2023/07/24/rent-to-pwn/#kitt-is-a-demon VIN locking is everywhere. It's how John Deere stops farmers from fixing their own tractors – something farmers have done literally since tractors were invented: https://pluralistic.net/2022/05/08/about-those-kill-switched-ukrainian-tractors/ It's in ventilators. Like mobile phones, ventilators are a grotesquely monopolized sector, controlled by a single company Medtronic, whose biggest claim to fame is effecting the world's largest tax inversion in order to manufacture the appearance that it is an Irish company and therefore largely untaxable. Medtronic used the resulting windfall to gobble up most of its competitors. During lockdown, as hospitals scrambled to keep their desperately needed supply of ventilators running, Medtronic's VIN-locking became a lethal impediment. Med-techs who used donor parts from one ventilator to keep another running – say, transplanting a screen – couldn't get the device to recognize the part because all the world's civilian aircraft were grounded, meaning Medtronic's technicians couldn't swan into their hospitals to type in the unlock code and charge them hundreds of dollars. The saving grace was an anonymous, former Medtronic repair tech, who built pirate boxes to generate unlock codes, using any housing they could lay hands on to use as a case: guitar pedals, clock radios, etc. This tech shipped these gadgets around the world, observing strict anonymity, because Article 6 of the EUCD also bans circumvention: https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#medtronic-again Of course, Apple is a huge fan of VIN-locking. In phones, VIN-locking is usually called \"serializing\" or \"parts-pairing,\" but it's the same thing: a tiny subassembly gets its own microcontroller whose sole purpose is to prevent independent repair technicians from fixing your gadget. Parts-pairing lets Apple block repairs even when the technician uses new, Apple parts – but it also lets Apple block refurb parts and third party parts. For many years, Apple was the senior partner and leading voice in blocking state Right to Repair bills, which it killed by the dozen, leading a coalition of monopolists, from Wahl (who boobytrap their hair-clippers with springs that cause their heads irreversibly decompose if you try to sharpen them at home) to John Deere (who reinvented tenant farming by making farmers tenants of their tractors, rather than their land). But Apple's opposition to repair eventually became a problem for the company. It's bad optics, and both Apple customers and Apple employees are volubly displeased with the company's ecocidal conduct. But of course, Apple's management and shareholders hate repair and want to block it as much as possible. But Apple knows how to Think Differently. It came up with a way to eat its cake and have it, too. The company embarked on a program of visibly support right to repair, while working behind the scenes to sabotage it. Last year, Apple announced a repair program. It was hilarious. If you wanted to swap your phone's battery, all you had to do was let Apple put a $1200 hold on your credit card, and then wait while the company shipped you 80 pounds' worth of specialized tools, packed in two special Pelican cases: https://pluralistic.net/2022/05/22/apples-cement-overshoes/ Then, you swapped your battery, but you weren't done! After your battery was installed, you had to conference in an authorized Apple tech who would tell you what code to type into a laptop you tethered to the phone in order to pair it with your phone. Then all you had to do was lug those two 40-pound Pelican cases to a shipping depot and wait for Apple to take the hold off your card (less the $120 in parts and fees). By contrast, independent repair outfits like iFixit will sell you all the tools you need to do your own battery swap – including the battery! for $32. The whole kit fits in a padded envelope: https://www.ifixit.com/products/iphone-x-replacement-battery But while Apple was able to make a showy announcement of its repair program and then hide the malicious compliance inside those giant Pelican cases, sabotaging right to repair legislation is a lot harder. Not that they didn't try. When New York State passed the first general electronics right-to-repair bill in the country, someone convinced New York Governor Kathy Hochul to neuter it with last-minute modifications: https://arstechnica.com/gadgets/2022/12/weakened-right-to-repair-bill-is-signed-into-law-by-new-yorks-governor/ But that kind of trick only works once. When California's right to repair bill was introduced, it was clear that it was gonna pass. Rather than get run over by that train, Apple got on board, supporting the legislation, which passed unanimously: https://www.ifixit.com/News/79902/apples-u-turn-tech-giant-finally-backs-repair-in-california But Apple got the last laugh. Because while California's bill contains many useful clauses for the independent repair shops that keep your gadgets out of a landfill, it's a state law, and DMCA 1201 is federal. A state law can't simply legalize the conduct federal law prohibits. California's right to repair bill is a banger, but it has a weak spot: parts-pairing, the scourge of repair techs: https://www.ifixit.com/News/69320/how-parts-pairing-kills-independent-repair Every generation of Apple devices does more parts-pairing than the previous one, and the current models are so infested with paired parts as to be effectively unrepairable, except by Apple. It's so bad that iFixit has dropped its repairability score for the iPhone 14 from a 7 (\"recommend\") to a 4 (do not recommend): https://www.ifixit.com/News/82493/we-are-retroactively-dropping-the-iphones-repairability-score-en Parts-pairing is bullshit, and Apple are scum for using it, but they're hardly unique. Parts-pairing is at the core of the fuckery of inkjet printer companies, who use it to fence out third-party ink, so they can charge $9,600/gallon for ink that pennies to make: https://www.eff.org/deeplinks/2020/11/ink-stained-wretches-battle-soul-digital-freedom-taking-place-inside-your-printer Parts-pairing is also rampant in powered wheelchairs, a heavily monopolized sector whose predatory conduct is jaw-droppingly depraved: https://uspirgedfund.org/reports/usp/stranded But if turning phones into e-waste to eke out another billion-dollar stock buyback is indefensible, stranding people with disabilities for months at a time while they await repairs is so obviously wicked that the conscience recoils. That's why it was so great when Colorado passed the nation's first wheelchair right to repair bill last year: https://www.eff.org/deeplinks/2022/06/when-drm-comes-your-wheelchair California actually just passed two right to repair bills; the other one was SB-271, which mirrors Colorado's HB22-1031: https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB271 This is big! It's momentum! It's a start! But it can't be the end. When Bill Clinton signed DMCA 1201 into law 25 years ago, he loaded a gun and put it on the nation's mantlepiece and now it's Act III and we're all getting sprayed with bullets. Everything from ovens to insulin pumps, thermostats to lightbulbs, has used DMCA 1201 to limit repair, modification and improvement. Congress needs to rid us of this scourge, to let us bring back all the benefits of interoperability. I explain how this all came to be – and what we should do about it – in my new Verso Books title, The Internet Con: How to Seize the Means of Computation. https://www.versobooks.com/products/3035-the-internet-con (Image: Mitch Barrie, CC BY-SA 2.0; Kambanji, CC BY 2.0; Rawpixel; modified) Hey look at this (permalink) Book giveaway for The Bezzle (Martin Hench #2) https://www.goodreads.com/giveaway/show/371380-the-bezzle-a-martin-hench-novel West of House https://brokenneedle.gumroad.com/l/westofhouse (h/t Wil Wheaton) T-Shirts Now Available! http://www.imagineeringdisney.com/blog/2023/9/19/t-shirts-now-available.html This day in history (permalink) #20yrsago New voting machines are criminally bad https://www.salon.com/2003/09/23/bev_harris/ #15yrsago Your chance to mark up the Wall Street bailout bill https://web.archive.org/web/20080929041702/http://publicmarkup.org/ #15yrsago Hank Paulson’s bailout 419 letter https://web.archive.org/web/20080923194140/https://www.thenation.com/blogs/jstreet/363133/bailout_satire #15yrsago Stanford and Harvard b-school profs vs. free/open source software https://news.slashdot.org/story/08/09/22/2254228/stanford-teaching-mbas-how-to-fight-open-source #15yrsago Sexist pigs earn more than normal men https://www.science20.com/news_releases/old_fashioned_men_make_more_money_study #15yrsago Corrupted Science: the history, cause, effect and state of bad science https://memex.craphound.com/2008/09/22/corrupted-science-the-history-cause-effect-and-state-of-bad-science/ #10yrsago Chaos Computer Club claims it can unlock Iphones with fake fingers/cloned fingerprints https://www.ccc.de/en/updates/2013/ccc-breaks-apple-touchid #5yrsago Anonymous stock-market manipulators behind $20B+ of “mispricing” can be tracked by their writing styles https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3198384 #1yrago Twitch does a chokepoint capitalism: \"Amazon is charging Amazon so much money to run the business via Amazon that it has no choice but to take more money from streamers.\" https://pluralistic.net/2022/09/22/amazon-vs-amazon/#pray-i-dont-alter-it-further Colophon (permalink) Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/). Currently writing: A Little Brother short story about DIY insulin PLANNING Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. FORTHCOMING TOR BOOKS JAN 2025 The Bezzle, a Martin Hench noir thriller novel about the prison-tech industry. FORTHCOMING TOR BOOKS FEB 2024 Vigilant, Little Brother short story about remote invigilation. FORTHCOMING ON TOR.COM Moral Hazard, a short story for MIT Tech Review's 12 Tomorrows. FIRST DRAFT COMPLETE, ACCEPTED FOR PUBLICATION Spill, a Little Brother short story about pipeline protests. FORTHCOMING ON TOR.COM Latest podcast: Plausible Sentence Generators https://craphound.com/news/2023/09/17/plausible-sentence-generators/ Upcoming appearances: DIG Festival (Modena, Italy), Sept 22 https://dig-awards.org/en/dig-festival-2023-first-speakers-announced/ Launch for Justin C Key's \"The World Wasn’t Ready for You,\" Book Soup (LA), Sept 22 https://www.booksoup.com/event/justin-c-key Launch for \"The Internet Con\" and Brian Merchant's \"Blood in the Machine,\" Chevalier's Books (LA), Sept 27 https://www.eventbrite.com/e/the-internet-con-by-cory-doctorow-blood-in-the-machine-by-brian-merchant-tickets-696349940417 An Evening with VE Schwab (Boise), Oct 2 https://www.thecabinidaho.org/all-events/ve-schwab Wired Nextfest (Milano), Oct 7-8 https://eventi.wired.it/nextfest23-milano The Internet Con at Moon Palace Books (Minneapolis), Oct 15 https://moonpalacebooks.com/events/30127 26th ACM Conference On Computer-Supported Cooperative Work and Social Computing keynote (Minneapolis), Oct 16 https://cscw.acm.org/2023/index.php/keynotes/ 41st annual McCreight Lecture in the Humanities (Charleston, WV), Oct 19 https://festivallcharleston.com/venue/university-of-charleston/ Seizing the Means of Computation (Edinburgh Futures Institute), Oct 25 https://efi.ed.ac.uk/event/seizing-the-means-of-computation-with-cory-doctorow/ Recent appearances: Against EnshittificationMedium Day 2023 https://www.youtube.com/watch?v=mSeBelDVrgE The Jim Rutt Show https://www.jimruttshow.com/cory-doctorow-2/ How to Take Back the Internet (Wired Have a Nice Future) https://www.wired.com/story/have-a-nice-future-podcast-21/ Latest books: \"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245). \"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com. Signed copies at Dark Delicacies (US): and Forbidden Planet (UK): https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/. \"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com \"Attack Surface\": The third Little Brother novel, a standalone technothriller for adults. The Washington Post called it \"a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance.\" Order signed, personalized copies from Dark Delicacies https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html \"How to Destroy Surveillance Capitalism\": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59 (print edition: https://bookshop.org/books/how-to-destroy-surveillance-capitalism/9781736205907) (signed copies: https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html) \"Little Brother/Homeland\": A reissue omnibus edition with a new introduction by Edward Snowden: https://us.macmillan.com/books/9781250774583; personalized/signed copies here: https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html \"Poesy the Monster Slayer\" a picture book about monsters, bedtime, gender, and kicking ass. Order here: https://us.macmillan.com/books/9781626723627. Get a personalized, signed copy here: https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/. Upcoming books: The Lost Cause: a post-Green New Deal eco-topian novel about truth and reconciliation with white nationalist militias, Tor Books, November 2023 The Bezzle: a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books, February 2024 Picks and Shovels: a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books, February 2025 Unauthorized Bread: a graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2025 This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net. https://creativecommons.org/licenses/by/4.0/ Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution. How to get Pluralistic: Blog (no ads, tracking, or data-collection): Pluralistic.net Newsletter (no ads, tracking, or data-collection): https://pluralistic.net/plura-list Mastodon (no ads, tracking, or data-collection): https://mamot.fr/@pluralistic Medium (no ads, paywalled): https://doctorow.medium.com/ (Latest Medium column: \"How To Think About Scraping: In privacy and labor fights, copyright is a clumsy tool at best https://doctorow.medium.com/how-to-think-about-scraping-2db6f69a7e3d) Twitter (mass-scale, unrestricted, third-party surveillance and advertising): https://twitter.com/doctorow Tumblr (mass-scale, unrestricted, third-party surveillance and advertising): https://mostlysignssomeportents.tumblr.com/tagged/pluralistic \"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla Like this: Loading... Apple’s Cement Overshoes May 22, 2022 In \"Medium\" Apple’s Right-to-Repair U-Turn Celebrate, but keep your eye on the prize Image: Ifixit, Apple, Lucasfilm It’s been a pretty great week. Ever since Apple announced that it would sell its customers spare parts and tools to affect their own repairs, and supply them with the documentation to do so, I’ve been thrilled to do… November 21, 2021 In \"Medium\" Pluralistic: 30 May 2022 Today's links Podcasting \"Apple's Cement Overshoes\": Thinking different about right to repair. Hey look at this: Delights to delectate. This day in history: 2002, 2007, 2012, 2017 Colophon: Recent publications, upcoming/recent appearances, current writing projects, current reading Podcasting \"Apple's Cement Overshoes\" (permalink) This week on my podcast, I read my… May 30, 2022 In \"apple\" Author Cory Doctorow Posted on September 22, 2023 Categories Uncategorized Tags apple, california, dmca 1201, ewaste, felony contempt of business model, fuckery, ifixit, iphones, parts pairing, Repairwashing, right to repair, sb244, serialization, vin locking Post navigation PREVIOUS Previous post: Pluralistic: \"Efficiency\" left the Big Three vulnerable to smart UAW tactics (21 Sept 2023) ARCHIVES September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 CATEGORIES Medium Uncategorized META Log in Entries feed Comments feed WordPress.org PREVIOUS EDITIONS Pluralistic: Apple fucked us on right to repair (again) (22 Sept 2023) Pluralistic: \"Efficiency\" left the Big Three vulnerable to smart UAW tactics (21 Sept 2023) Pluralistic: Kashmir Hill's \"Your Face Belongs to Us\" (20 Sept 2023) Pluralistic: Justin C Key's \"The World Wasn't Ready For You\" (19 Sep 2023) Pluralistic: Biden should support the UAW (18 Sept 2023) Search for: SEARCH READ CAREFULLY By reading this website, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer. Optimized for Netscape Navigator. Pluralistic: Daily links from Cory Doctorow Proudly powered by WordPress",
    "commentLink": "https://news.ycombinator.com/item?id=37614279",
    "commentBody": "Apple fucked us on right to repair (again)Hacker NewspastloginApple fucked us on right to repair (again) (pluralistic.net) 160 points by jrepinc 18 hours ago| hidepastfavorite136 comments cmiller1 17 hours agoThe article claims that Tim Cook said a certain thing\"Tim Cook laid it out for his investors: when people can repair their devices, they don&#x27;t buy new ones. When people don&#x27;t buy new devices, Apple doesn&#x27;t sell them new devices\"It also provides a link to a source... in which Tim Cook said something totally different\"While macroeconomic challenges in some markets were a key contributor to this trend, we believe there are other factors broadly impacting our iPhone performance, including consumers adapting to a world with fewer carrier subsidies, US dollar strength-related price increases, and some customers taking advantage of significantly reduced pricing for iPhone battery replacements\"It seems to be a pretty big jump from \"one of the reasons we didn&#x27;t perform as well as possible this quarter is because of customers taking advantage of our reduced price battery replacement program\" which could impact their bottom line by just operating on thinner margins than normal battery replacements, to \"repairs are stopping people from buying new phones\" reply criddell 17 hours agoparentYeah, I looked at that too. Seems like a very bad faith interpretation of what Cook was saying. reply dpkonofa 17 hours agorootparentThe whole article is bad faith. It links to a Vice article claiming that Apple is lying about its environmental stances because it doesn’t reuse old iPhones and MacBooks. Then, they breeze over the fact that Apple literally breaks these devices down into their core materials for use in new devices and falsely claims that they’re “shredded into immortal e-waste”. How is that not reuse? Are they suggesting that the parts from an iPhone 4 can somehow be reused more effectively? How many old iPhones are still out there that would even be able to use any of those parts? reply _aavaa_ 17 hours agorootparentThat is in fact not reusing. That’s recycling.And what they could do instead is yes sell those parts, or extend their certified refurbished program. It currently only goes back to the iPhone 12, even though their newest OS supports much older phones. To say nothing of how far back security updates are still (selectively) being released. reply dpkonofa 12 hours agorootparentThe logistics of doing that are nearly impossible. Old phones are old phones. No one wants them. reply bzzzt 17 hours agorootparentprevTechnically \"reuse\" means wholesale reuse of components, shredding them would be recycling.But you&#x27;re right. The whole right-to-repair is just lobbying from independent iPhone repair companies who want to make a quick buck at Apple&#x27;s expense. It&#x27;s part penny-pinching, part fake environmentalism and lots of hate for everything Apple. Even if Apple would bring out the most repairable phone ever it wouldn&#x27;t be enough since it&#x27;s all about the control they don&#x27;t want Apple to have (even if that control is advantageous to the customer) reply fragmede 16 hours agorootparent> The whole right-to-repair is just lobbying from independent iPhone repair companies who want to make a quick buck at Apple&#x27;s expense.That is a very interesting take. Basic repairability, whether by an independent shop, or a skilled individual (aka you), should be a goal so the manufacturer doesn&#x27;t have a monopoly on repairs. Market economies abhor a monopoly, and the vendor-only repair scheme is a big one. Looking at cars, The US has the federal Magnuson-Moss Warranty Act, which was fought for in the courts, to force vendors to accept that aftermarket parts didn&#x27;t void the warranty of the part wasn&#x27;t related. Which isn&#x27;t directly applicable here, but the point is that an outside vendor could create a replacement part, better in some way (cheaper is a kind of better), and repair shops and customers could choose to use that part instead. Apple shouldn&#x27;t have that much control. We decided this for cars, the same should be applicable with ebikes for the mind. reply whelp_24 17 hours agorootparentprevI staunchly refuse to buy an iphone or whatever else Apple sells. I both support right to repair and am affected by many non Apple companies that do anti-consumer stuff. The article here actually lists several companies that aren&#x27;t and hate right 2 repair, including Wahl (learn something everyday).I can&#x27;t understand why anyone who isn&#x27;t a manufacturer would be against this. reply eternityforest 15 hours agorootparentprevHow is it advantageous to the customers? Are there commonly shady phone repair people doing bad work? I&#x27;ve never had a phone repaired(Rugged cases prevent the need pretty effectively!) so I might be out of the loop. reply Kirby64 14 hours agorootparentThis isn&#x27;t specific to repair shops, but there are a plethora of 3rd party battery options for many, many cell phones. iPhone included. Even stuff sold from companies like ifixit. My experience with replacing those batteries with anything except the OEM battery has been always .. let&#x27;s just say underwhelming.Maybe I&#x27;ve just been consistently unlucky, but there doesn&#x27;t seem to be any quality control and plenty of outright lying from 3rd party vendors on battery capacity and expected performance on aftermarket cells. reply dpkonofa 11 hours agorootparentprevThat’s fine. It’s not the Apple Reusing Program. It’s the Apple Recycling Program. Why are they complaining about reuse when the market for reuse would be a drop in the bucket. Recycling and making new phones that people actually want to buy is a better strategy than attempting to salvage components. Yes, reuse parts would be better if people wanted to keep the same phone for that long. The problem is that they don’t. reply wtallis 17 hours agorootparentprevThe complaint about trademarks on refurbished parts also sounds a bit off, implying that nothing used with a logo on it can be legally imported. There may not be a good and legal solution, but it seems like refurbishing operations and repair shops are trying to avoid having to tell end customers that the assemblies they use for repairs are \"a mix of used Apple components and third-party components not approved by Apple\". If a disclaimer like that can&#x27;t get the parts through customs, then maybe we have a problem. reply alwa 17 hours agoprevSeveral years back, before Apple clamped down on this kind of commercial behavior, I made the mistake of taking my iPhone to a third-party repair firm for a screen replacement. They claimed to be “Apple-authorized,” but it’s unclear for what. The knockoff part they used to replace the screen was palpably awful-dim, purple-tinted, discolored around the edges, somehow flickering like a CRT, and a millimeter or two thicker than the real deal so that it stuck out from the body of the phone.The guy said “it’s fine, it looks great, it’s working perfectly, there’s no problem with it.” Basically “a screen is a screen.” I suppose in some situations and some parts of the market that may be true, and I’m glad that part of the market is adequately served by commodity Android manufacturers. But part of the small premium I pay to Apple for my low-end model iPhone, I pay specifically to avoid having to look my repairman in the eye and attempt to divine his judgment and trustworthiness before he makes off with my money. Consistency and trust in the repair ecosystem is a feature, to me.There’s a balance to be struck, sure, but I’d hate to think of somebody doing the equivalent “what, it’s fine!” type of repair to a safety- or life-critical device and claiming it’s just as good as new. Even if somebody were to track such repairers down and prosecute them after their repairs injure somebody, we’d be moving from a high-trust to a low-trust kind of environment in exactly the areas where I least want to have to worry about trust.Anyway, as to phones, I’ve since been very happy to pay Apple the $4&#x2F;month to cover quality, authentic repairs should I damage my device—and I take them up on that coverage fairly often. $48&#x2F;year plus the $29 deductible per incident works out even cheaper for me than that unacceptably poor third-party repair cost me years ago. reply dpkonofa 17 hours agoparentThis is only slightly comical to me because the article actually mentions ventilators and how evil they were that they could only be serviced by the OEM due to the “VIN” on the parts.I would not want to be the person strapped to a medical device where “it looks fine, it works great” guy was the one that fixed it on the cheap so he could make an extra few dollars. reply itishappy 16 hours agorootparentIf first party repairs are an option, my choice is clear. If my choice is between a third-party repair and death, I&#x27;m less principled. reply dpkonofa 9 hours agorootparentYes, that&#x27;s my point. The article had to use a once-in-a-lifetime&#x2F;millenium global pandemic to make its point. reply Clamchop 7 hours agorootparentEmergencies happen. Were inappropriate or flawed repairs ever a significant problem? Are there other solutions to that problem? Could there exist a third-party repair service or parts manufacturer competent enough to be authorized? Even besides an emergency, is the measure worth, say, severe delays to or even the impossibility of getting a repair somewhere that&#x27;s disadvantaged either by being too far away from official services or by economics?And why couldn&#x27;t this be a post hoc PR rationalization for what just as well could be profiteering?Now apply all those questions to the far less life-threatening concern of smartphones and laptops. reply dpkonofa 2 hours agorootparent>Were inappropriate or flawed repairs ever a significant problem? Are there other solutions to that problem? Could there exist a third-party repair service or parts manufacturer competent enough to be authorized?Yes, and they continue to be. Potentially, but no manufacturer, Apple or otherwise, has found one. Yes, but not at the scale that Apple operates. That&#x27;s why Louis Rossman is a shyster. He has skills that are very rare but peddles his right to repair schtick as if every repair shop has those skills and then misrepresents the situation to create drama to drive engagement to his business and YouTube channel. replytgma 17 hours agoparentprev> somehow flickering like a CRTBacklight dimming can be implemented via PWM, which turns signal on and off at different frequencies to achieve the desired brightness setting from the backlight source. When it is poorly executed you tend to see that effect (more so at the lower backlight settings) reply bbarnett 17 hours agoparentprevConsistency and trust in the repair ecosystem is a feature, to me.You can always go to a real apple repair depot, instead of the crook changing your screen, as you cited.3rd parties having access to real apple parts, an easier ability to replace them, makes it easier for you to get good independent support. It has nothing to do with that crook you mentioned. reply tgma 16 hours agorootparent(Just to steel-man the counterargument) it is not as clear-cut to me that everyone is realistically able to make such choice (depending on the geo, quality control of the authorized centers). The repair process is opaque enough that you are compromising the user who is choosing to pay for premium parts to get ripped off with some probability. Even a small percentage of bad parts in the ecosystem will disproportionally diminish the value of used&#x2F;repaired iPhones so there is a non-trivial calculation to be done on the social impact of such individual choice. reply jtode 16 hours agorootparentPerhaps they should design the machines so that they are user-serviceable.This was the default at one point. Look at the manual for any home appliance from the 1950s.The difficulty in replacing an iphone screen is not that it&#x27;s hard to plug it into its receptacle - the difficulty is in acquiring a part (they won&#x27;t sell them) and then in opening the device, which requires skill and a specialized tool in pretty much every case.Maybe, hold them together with small screws, instead of that.\"but then it will weigh an extra .237oz!\"Shut up. reply nemothekid 15 hours agorootparent>\"but then it will weigh an extra .237oz!\" Shut up.It&#x27;s not fair to dismiss this argument. The vast majority of people don&#x27;t care if it&#x27;s user serviceable and will prefer that the device weighs .237oz less than be user serviceable. This isn&#x27;t some niche market we are talking about, we are 16 years after the release of the first iPhone. My account on this forum is 11 years old, and this point has been argued for almost that entire time. As much as been hand wringing about customers not caring about .237oz in favor of user serviceability, there have been countless smartphones released that people didn&#x27;t buy. \"Shut up\" isn&#x27;t a product strategy. \"Perhaps they should design something users don&#x27;t want\" is a silly statement at this point. reply tgma 14 hours agorootparentExactly. The whole \"modular phone\" and related phenomena are effectively nerd porn and against 50+ years of industry progress towards cheaper, better, denser integration. reply dpkonofa 11 hours agorootparentI’m glad that the nerd porn exists because I do care about sustainability but operating on Apple’s scale means those devices are a fantasy for the majority of people. Apple’s approach seems more sustainable considering how many claims they can continue to make. Maybe it’s all marketing but I can’t find anyone that invalidates their claims without mischaracterizing them (as this article does a ton). reply bbarnett 4 hours agorootparentThe problem is, you have two ways to build.One way, is to make it non-user serviceable, the other, to make it user serviceable.Now, which do you spend immense sums researching? Which people do you hire for your company? And after you spend years down this path, tooling, hiring, designing, someone says \"the environment counts, it should be user serviceable\".Well of course, with billions spent designing, and predicated upon current methods, AND with all the people you hire experts in closed, non-servicable design?What sort of answer will you get?Apple, and others, the entire industry, has created this industry to be like this.If the same R&D was spent on user serviceable, it would happen. Cheaply. Easily.So of course it&#x27;s \"very hard\" to do user serviceable, because no one knows how, and no one has the experience, and no one is researching it.And no, these little firms working at it, don&#x27;t equate to Apple working at it.It may not be on purpose, but to claim it isn&#x27;t possible is unfair.You know if the auto industry was left to its own devices, it would still be claiming electric cars weren&#x27;t feasible too, right? And from their perspective, they were not! Because without billions in research, and iteration, it wasn&#x27;t.Just like with Apple and user serviceable parts.Just as with cars, and bags, and everything else, we should legislate such requirements. So all players in the market must comply. reply dpkonofa 2 hours agorootparentThis seems a little disingenuous. The entire reason that user-serviceable devices aren&#x27;t possible is that the tooling required to service them becomes more and more specialized as the devices get smaller. It&#x27;s not a matter of whether or not they can make user-serviceable parts (which why I replied to a comment about things like Fairphone and other modular&#x2F;serviceable phones) but whether they can scale that and the reality is that 1) it doesn&#x27;t scale without being so expensive that users can&#x27;t afford the devices and 2) most users just don&#x27;t care about user serviceability. So the idea that there are 2 ways to build is a false dichotomy. replyjwells89 16 hours agorootparentprevThere should probably be regulations mandating that electronics replacement parts meet certain minimum QA and performance standards, particularly those with the significant capacity for harm such as batteries and components handling power. Parts not meeting these standards would get rejected at the border. reply kuchenbecker 13 hours agorootparentprevStandards are preferable, and I&#x27;d like to pick and choose which portions of the ecosystem I like, and others where I&#x27;d like to use something different.Android isn&#x27;t a malware riddled ecosystem and you can install 3rd party hardware and software. reply tgma 13 hours agorootparent> Android isn&#x27;t a malware riddled ecosystem and you can install 3rd party hardware and softwareNot sure if this is serious or sarcastic. reply spacecase-25 11 hours agoparentprevOof, this just proves that their strategy works. By limiting the availability of panels, 3rd party repair shops are left with very poor quality rejects. What happens is that Apple disallows any of their suppliers to sell panels on the open market, so 3rd party repair shops aren&#x27;t able to get good panels, then Apple points to the 3rd party repair shops with shitty screens and tells you that you shouldn&#x27;t trust 3rd party repair shops because the quality of their repairs aren&#x27;t up to par. If appropriate parts were available, there would be no reason that someone with basic soldering skills and the ability to use a screw driver wouldn&#x27;t be able to replace your screen with one just as good as it came with out of the box.You&#x27;ve fallen for the scam. reply dpkonofa 11 hours agorootparentYou act like there wasn’t a full decade and more of history where 3rd party repair existed en masse for electronics and the situation that he’s describing was exactly the result.There’s no scam here. Most of us find the official repair stuff to be a feature, not a crutch. reply Kirby64 17 hours agoprevMan this article sure does seem to claim some specific ill intent or malice from Apple.I don&#x27;t really know why there&#x27;s so much focus on permitting scrapping of parts that are deemed unsalvageable. From Apple&#x27;s perspective there is no guarantee the parts are any good, or the cost of salvaging exceeds the benefit of just scrapping them for raw materials as is.Frankly, the prices that Apple seems to be charging for common repairs seems quite reasonable nowadays. I&#x27;m not sure what the profit motive is at the prices they list. The new 15 series batteries can be replaced by Apple for $99... Which seems like a bargain for a first party battery that you know is going to be done properly. reply FireBeyond 14 hours agoparent> Frankly, the prices that Apple seems to be charging for common repairs seems quite reasonable nowadaysMacBook Air. Damaged charging chip. Laptop runs fine on AC. Battery is at 100% health. It just can&#x27;t be charged (this is the summary from Apple after diagnostics).Fine, I think. Maybe what, $2-300 with parts and labor?\"That will be $890 if you want to repair it. Maybe we can talk about getting you into a new Mac instead?\"$890. To repair a $1,100 laptop that is functioning perfectly other than being able to direct energy into a battery. reply wtallis 13 hours agorootparentNo other laptop manufacturer is going to offer you a repair that involves soldering, either. Everyone is just going to offer to replace the motherboard for a failure like that, and that motherboard contains all the most expensive components aside from the display. Nobody wants to lose money on the repairs, which is why soldering is right out and why a replacement motherboard is going to be over half the price of the machine before labor is thrown in. Your expectations were unrealistic. reply sudosysgen 12 hours agorootparentI&#x27;ve gotten multiple laptops repaired by independent repair shops which did in fact desolder, change, and solder a part.It&#x27;s not actually as difficult as you think. The chip itself is likely just a few bucks, and it takes about an hour to make such a repair, so plenty of shops are happy charging a couple hundred dollars to do this. reply wtallis 12 hours agorootparentYes, some independent repair shops can do this. It doesn&#x27;t scale. People who can diagnose such problems and solder well enough to make such repairs quickly and reliably are rare, and can usually make more money putting those skills to use elsewhere. There&#x27;s no way every Apple store genius bar could have such a technician on staff. reply sudosysgen 12 hours agorootparentIt scales fine. Diagnosing and repairing these issues is not as hard as you think, and there aren&#x27;t that many places that will pay, say, 40$&#x2F;h for such a skill. It&#x27;s also something you can train people on. The biggest problem is that you can&#x27;t get the parts.That&#x27;s because if you have a schematic, you can build a diagnosis flowchart from it, so all you need is to know how to use a multimeter and you can follow the flowchart. If you can&#x27;t figure it out from there, you cut your losses. Then the skill remaining is to be able to hand-solder SMD components - it&#x27;s not an easy skill, but there are plenty of jobs that pay worse for harder skills and not many places that will pay you well for it (if you know one, I&#x27;m all ears).You don&#x27;t need to be particularly quick either. Such a repair for a really good technician might only take 20 minutes, an average one maybe 1.5 hours. At 50$&#x2F;h, with a 50% success rate, you still make 150$ of expected marginal profit if you charge 300$. And of course many repairs are even easier. However most places pay around 25$&#x2F;h and just ask that you have a high school diploma and some soldering experience.But the fact that you just can&#x27;t buy parts means that you need to buy donor boards, and that doesn&#x27;t scale well. reply wtallis 11 hours agorootparent> You don&#x27;t need to be particularly quick either. Such a repair for a really good technician might only take 20 minutes, an average one maybe 1.5 hours.Total bullshit. It takes more than 20 minutes just to disassemble and reassemble a laptop to get the motherboard out without damaging anything. Diagnosing the failed component can be quicker in some cases (eg. scorch marks), but checking the extent of collateral damage isn&#x27;t that quick. A more realistic estimate would be about two or three repairs per day, unless you want to complicate things by stipulating that all the less skilled parts of the process (disassembly, fetching replacement parts reassembly, verifying repair worked) are to be done by a less skilled technician and only the actual board inspection, probing, and rework are done by the skilled technician. And then you have to consider that such repairs will never have a perfect success rate, so you need to be able to regularly eat the cost of wasted time on failed repairs while still keeping the cost of labor and maintaining an extensive parts inventory cheaper than the cost of a new motherboard. reply sudosysgen 11 hours agorootparentIt really doesn&#x27;t take more than 20 minutes to get access to the motherboard of a MacBook. Are you under the notion that you need to fully strip down the computer before being able to diagnose it? You don&#x27;t. You just pop the back cover, replace the battery with a bench power supply, and start testings. You can do most tests without removing the board from the chassis. You might eventually need to get access to the other side of the board, but again it doesn&#x27;t take 20 minutes to do that.Here&#x27;s a video where they remove and put back a MacBook Air motherboard in 13 minutes, on camera (https:&#x2F;&#x2F;youtu.be&#x2F;Sk8kj_y32mU?si=4fUoXux_zLIGg-9B).I already took into account a pessimistic 50% repair success rate at a salary double what most shops pay. reply dpkonofa 10 hours agorootparentSo then the parent is right. If disassembling it took 13 minutes, then they’d have 7 minutes left to reassemble and that wouldn’t involve any actual repair. reply sudosysgen 10 hours agorootparentIt took 13 minutes to both disassemble and reassemble.So then you have another 20 minutes to diagnose. If you can repair 50% of boards that make it far enough that you need to dissassemble for diagnosis and then you take an additional 30 minutes to do the repair with 50% success rate, you&#x27;re spending 3.6 hours per repair, which is perfectly fine if you&#x27;re charging 300$. These are pessimistic assumptions too - you often don&#x27;t need to dissassemble the board to diagnose it, the person disassembling the board doesn&#x27;t need to be paid as much as the person doing the repair, and you&#x27;ll probably have a better than 50% repair success rate. reply wtallis 10 hours agorootparent> It took 13 minutes to both disassemble and reassembleTry linking to a video that doesn&#x27;t fast forward the boring bits before doubling down on that 13 minute claim. reply gameoverhumans 17 hours agoparentprev99$ isn&#x27;t really a \"bargain\" in the absolute sense. I encourage you to look at eBay buy it now listings for used&#x2F;refurbished Lenovo ThinkCentre NUCs, for example. You can get an entire computer with 8GB RAM, 128GB SSD and a Skylake+ CPU for that kind of money. reply Kirby64 16 hours agorootparentA Skylake CPU is an 8 year old CPU. Why are you even comparing old desktop-class CPUs to the cost of a battery replacement on a brand new device?I can buy an ancient server that consumes hundreds of watts for $100 too, it doesn&#x27;t mean it&#x27;s a good value.I can also buy an entire iPhone SE 2020 or something, for $100 as well. reply gameoverhumans 15 hours agorootparentWhat does age have to do with the value proposition I put forward?Has the battery chemistry in a iPhone 15 advanced significantly in the last 8 years? I don&#x27;t think so.> I can also buy an entire iPhone SE 2020 or something, for $100 as well.Exactly, thanks for reinforcing my point. reply Kirby64 14 hours agorootparentI honestly don&#x27;t know what you&#x27;re even saying. The value proposition of an 8 year old piece of hardware that doesn&#x27;t even have a battery in it is essentially unrelated to the cost or value of replacing a battery in a brand new phone.Likewise, the used cost of a device that is functional today (iPhone SE 2020 in my example) is almost unrelated to the cost of the battery replacement. I think you&#x27;d find that attempting to repair the NUC you highlighted would soon exceed the $100 if you needed to do anything more than very basic repairs. reply gameoverhumans 14 hours agorootparentI was trying to put your original \"100$ isn&#x27;t unreasonable\" into context. I think making a comparison between a roll of graphite dipped in some lithium salt and an entire computer made up of billions of transistors is a reasonable one.You didn&#x27;t address my parent question either. Because you either don&#x27;t know (that&#x27;s fine), or don&#x27;t want to address the fact that there&#x27;s very little that has changed in smartphone battery (or any lithium-ion battery, for that matter) composition or manufacture in a long while.> I think you&#x27;d find that attempting to repair the NUC you highlighted would soon exceed the $100 if you needed to do anything more than very basic repairs.Well I thought you didn&#x27;t see the point of this comparison, so I don&#x27;t know why you want to open that can of worms ;) But okay! A replacement 1TB nvme SSD costs 40 bucks (that&#x27;s a new, in retail box, btw). A used stick of 16GB RAM costs 30 bucks. A used i5-6500T is 30 bucks.Since you don&#x27;t like comparing apple to ora--- er, batteries to computers, how about this? An iPhone 13 Max battery harvested from a broken-screen unit can be had for 30EUR on eBay. Except Apple doesn&#x27;t want you to have that option. It wants to be the only game in town, and have folks like you justifying its monopolistic and unsustainable behavior. reply Kirby64 13 hours agorootparentAnd what exactly is stopping you from using said harvested battery? It works. You plug it in, and it&#x27;s fine. Literally the only thing you miss is the battery life indicator (which, seems reasonable, since a harvested device may have had its battery life reset or something) and the pop-up that says this battery may not be an original component if you check the Settings menu. That&#x27;s it. What&#x27;s the issue here? reply gameoverhumans 4 hours agorootparentWell see now we&#x27;ve well and truly wandered away from the discussion of your original comment, and veered straight into the territory of what the original article was addressing.> That&#x27;s it. What&#x27;s the issue here?I guess you didn&#x27;t read the original article, but it does touch on specifically why this is problematic, and can only lead to even worse outcomes in future.It also links to this iFixit article, which might make things clearer for you?https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;69320&#x2F;how-parts-pairing-kills-in... replyfragmede 16 hours agoparentprev> the prices that Apple seems to be charging for common repairs seems quite reasonable nowadays.That is besides the point. If Apple is the only one allowed to do repairs, they can set whatever price they want. That they&#x27;ve deigned to make it $99 is a price not determined by the market. reply Kirby64 14 hours agorootparentI didn&#x27;t realize that Apple forbade anyone from doing repairs? If I want to replace the battery in my iPhone, there are a multitude of 3rd party vendors I can buy from. It&#x27;ll tell me it can&#x27;t verify the battery is authentic... but you can still use the battery. Same with screen, camera, etc.If Apple wanted to actually forbid repairs, they wouldn&#x27;t let you turn on the device if the battery wasn&#x27;t authenticated, or the display wasn&#x27;t authenticated, etc. reply fragmede 14 hours agorootparentThe point is that we shouldn&#x27;t have to live under Apple&#x27;s good graces and just hope they remain benevolent. reply Kirby64 5 hours agorootparentWhat is there to \"live under\"? You can already buy 3rd party parts, nobody is stopping this.If Apple started bricking devices if they didn&#x27;t have authentic parts in them... yeah, sure, I can see you point. But they don&#x27;t, and you&#x27;re free to repair devices yourself or take them to a repair shop who does this for you.Frankly I don&#x27;t see how this is particularly different from Samsung or any other android manufacturer, besides maybe aftermarket parts won&#x27;t warn you that they&#x27;re possibly not authentic. replypzo 16 hours agoprevI don&#x27;t understand some people here that are clapping apple for DRM their devices as kind of protection from thefts. There is a way to have a cookie and eat it too in this case if they would allow user easily to remove DRM via iCloud or even better when disconnecting from iCloud.In the last 10 years I never had any electronics stolen from me but almost every smartphone got broken in some way: worn out USB&#x2F;lightning port, broken battery, broken screen, shattered glass, broken Face Id.Imagine if we would apply the same scenario for human organ transplants. Let&#x27;s enforce (using similar logic) that after someone dies we throw such body straight to oven to burn it because there exist in the world illegal human organs trade - no even if you want to be an organ donor after your death you can&#x27;t because we want to remove incentive for illegal human organs trade! &#x2F;s reply tzs 12 hours agoparentIf we are going down the organ analogy road, imagine a world in which organ transplants are easy enough that there are plenty of third parties that will perform organ transplants without limiting themselves to using organs obtained through legitimate channels.If you want to know how that could turn out badly, read Larry Niven&#x27;s stories set in the first century of his \"Known Space\" universe [1]. In particular the stories collected in this [2], but everything in Known Space written through 1980 is great if you like hard science fiction. (I don&#x27;t know about the Known Space stuff written later, because by then I was out of school and didn&#x27;t have much time for fiction).[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Known_Space[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Flatlander_(short_story_collec... reply stouset 8 hours agoparentprev> In the last 10 years I never had any electronics stolen from me but almost every smartphone got broken in some way: worn out USB&#x2F;lightning port, broken battery, broken screen, shattered glass, broken Face Id.You’re in luck! Apple will happily let you pay $150 for two years of AppleCare+ or $8&#x2F;mo for AppleCare+ for the life of the device. You can break a screen as often as you wish and it’ll only put you out like $20 to have it repaired. reply itishappy 16 hours agoparentprevDoes it actually deter thieves? I can&#x27;t imagine their decision making process goes much beyond \"that looks expensive.\" Maybe I&#x27;m just not cutout to be a theif.A quick search has turned up little, but I&#x27;m curious if anybody collects statistics. It feels like it should be easy to show a drop in theft when Apple released Activation Lock, right? reply nemothekid 15 hours agorootparentI think it&#x27;s less you are cutout for a thief, and you just not considering thieves are real people with functioning brains. Any rational human will do some risk&#x2F;reward analysis. Furthermore, Apple introduced Activation Lock in iOS 7 in 2013. I doubt any statistics would show a \"drop\" given smartphone growth exploded over that same time period. Lastly it seems iPhone theft, today, has been regulated to more sophisticated crime rings who will go through the trouble of sending the phones to china where they can be either stripped for parts or trying to trick the original owner into unlocking the phone. reply stouset 9 hours agorootparentprevThieves steal things they can use or that they can turn around and sell. If you can’t use or sell a stolen iPhone, there’s not much of an incentive to steal it. Especially when you could have grabbed a different model that can be easily fenced to someone who will open it up and sell it for parts. reply fragmede 16 hours agoparentprevGiven that human organs can currently only be created inside humans, and not mechanically in factories like iphone components can be, I&#x27;m not sure that scenario really tells us anything. I can imagine reading a dystopian scifi novel about it though.(making organs the human body can use, instead of harvesting them from a donor body is a fascinating area of research! https:&#x2F;&#x2F;3dprintingindustry.com&#x2F;news&#x2F;bladder-grown-from-3d-bi...) reply pzo 16 hours agorootparentThen imagine future were we made progress and can make organs the human use in some biolab.Would you still prefer to enforce burning human body after death just to (supposed to) avoid illegal human organ trade?What if the company that create such human body organs biolab has monopoly on it, can charge anything they want and force you to use their own privately owned hospitals and their certified doctors for transplant operation?I definitely wouldn&#x27;t want to live in such a world. reply itishappy 16 hours agorootparentIt&#x27;s for your own good! Our manufactured organs are designed and tested to ensure consistant quality, you don&#x27;t want to know what Dave&#x27;s been doing to his liver these past 20 years.There&#x27;s probably a point I could be trying to make, but I have yet to figure out what it is. reply fragmede 14 hours agorootparentprevTrying to invoke taboos about human remains is weird. There are plenty of things that apply to cellphones that don&#x27;t apply to human bodies and vice versa. It sounds like a skit out of \"Who&#x27;s line is it anyway\". Still, cremation happens in many cultures around the world, for various reasons.Fascinatingly, in the distant past, protecting cadavers was actually a thing! They used to have to have guards, among other methods, to protect the bodies of the deceased from being used for scientific research in the 18 and 19th century. reply ZeroGravitas 17 hours agoprevThis is much more in-depth and interisting than the sweary title might lead you to believe.The bit about ventilators in particular is tragic. reply brianpan 17 hours agoparentBut just as rant-y and opinionated as you might be lead to believe from the sweary title. reply ZeroGravitas 17 hours agorootparentI&#x27;m not sure I&#x27;d use the word \"opinionated\" here, but yeah he&#x27;s angry about something which he has a strong opinion on. reply dpkonofa 17 hours agoparentprevTragic and entirely misleading. Medical devices are regulated beyond belief. You don’t want some random repair tech cobbling together pirate boxes for them. How would anyone know if they’re compromised? reply dredmorbius 16 hours agorootparentMark your sarcasm if that&#x27;s your intent.DIY ventilators were in fact a vital lifesaving measure at the onset of the COVID-19 pandemic, a little over two years ago: reply jtode 16 hours agorootparentWhy was that?Couldn&#x27;t source enough.Why was that?Supply chains stretched so taut that a single disruption shut the whole world down.Why was that?Profit.Capitalism is the problem. reply wtallis 15 hours agorootparent> Supply chains stretched so taut that a single disruption shut the whole world down.Saying \"single disruption\" here is almost as bad as saying the dinosaurs were wiped out by a single rock. It&#x27;s not a matter of the number of underlying causes but a matter of the scale of the disruption. reply dredmorbius 15 hours agorootparentprevMy recollection is that there was an intentional limit on what parts were compatible with what ventilators, essentially DRM or filter tying&#x2F;bundling. This denied healthcare facilities the flexibility to pair consumable components from third-party manufacturers with a specific ventilator.(I&#x27;ve been looking for articles to support this without joy so far, though there were numerous articles on \"open source\" ventilator concepts, such as this one: .)This goes above and beyond basic market function, though yes, I suppose you could say that it was rooted at some level in capitalist short-term-profit-maximising practices. reply asdefghyk 14 hours agorootparentprevChanging from Capitalism, does not mean the new solution will be automatically better. could be much worse reply MrDrMcCoy 12 hours agorootparentprev> You don’t want some random repair tech cobbling together pirate boxes for them.What if I actually do want that for my own self? Shouldn&#x27;t that be my right to decide? reply dpkonofa 11 hours agorootparentFor yourself? Of course. For a hospital or anyone that would realistically be buying that for use? Absolutely not. reply mig39 17 hours agoprevWhen you sell an old iPhone, the first thing you do is turn off the iCloud bound feature, so someone else can activate it.There should be a method to do the same for parts.ie: I broke my phone, it&#x27;s not functional at all. I should be able to sell it for parts. But I can&#x27;t. Because the parts are tied to a particular device ID? reply microtherion 15 hours agoparentThat would make iPhones more attractive for theft, since someone else could then also break down your iPhone and sell it for parts. reply Nextgrid 13 hours agorootparentOnly if they can coerce you to release the lock. Which does happen occasionally (that’s how large-scale crime gangs currently do it, by sending phishing texts&#x2F;emails in an attempt to get the user’s Apple credentials) but it still raises the cost of the attack dramatically. reply tzs 12 hours agoparentprevI bet that in most cases you&#x27;d make more if you got the broken phone repaired and then sold the now working phone. reply bzzzt 17 hours agoparentprevIt&#x27;s the other way around: the phone only wants to talk to the parts it shipped with. Not with some knock-off battery that will also be dead in 6 months or TFT replacement screen for an OLED phone. reply bbarnett 17 hours agorootparentThat&#x27;s a false equivalency. Phones are also rejecting perfectly good parts, not the parts you cited.That&#x27;s the whole problem here, and you try to make it seem as if it&#x27;s about crappy parts not working.It&#x27;s not. At all. Never has been. reply dpkonofa 11 hours agorootparentIn nearly every case this has been claimed, it’s a part that has some security functionality or a part like a display or battery that requires some kind of calibration. Maybe they should put more effort into making that calibration easier but I don’t think anyone that currently uses their devices would trade that if it means the quality of the calibration or the security of the device goes down. reply bbarnett 4 hours agorootparentThis presumes Apple isn&#x27;t lying through their teeth, claiming it is about security, or calibration, when it isn&#x27;t. reply dpkonofa 2 hours agorootparentExcept it is. What part on the phone can&#x27;t be replaced? What is Apple lying about? Even if you don&#x27;t calibrate the parts, the phone is still usable, you just don&#x27;t get the features of the calibration - battery status&#x2F;level, Touch ID, Face ID, etc.Can you give me an example of what you&#x27;re referring to? A part that prevents use and doesn&#x27;t require calibration or a part that Apple is lying about - either works. replylordfrito 13 hours agoprevTime was when a person could build and program their own computer using any parts they wanted. Tech types valued their ability to build, diagnose, repair, and optimize their own equipment.From the responses here, I can only surmise that&#x27;s attitude is considered old fashioned now.I lost interest in Apple product after going go through a Kafkian experience trying to use the standard serial port on the early iPod&#x2F;iPhone connectors. Was trying to build a prototype of a handheld compass app, using a magnetometer board we designed that plugged into the connector and drew power from the phone. Everything worked fine, except I couldn&#x27;t get the serial port software working in the phone app. Apple wouldn&#x27;t let me use the serial port without a special MFI chip, requiring me to fill out tons of financial paperwork (Dun and Broadstreet etc), business plans, sales estimates, target markets, etc. They were not interested in helping me out at all.Not sure why Apple decided that serial ports were off limits. This is about the oldest comm technology out there. sighAnyhow, I read that hobbyists were working around the limitations by using the microphone port as a modem. Basically modulate the serial data, send as a waveform into microphone port, then demodulate the audio stream in software. Clever.So I went and built this. Only to find that Apple had recently decided to close the \"audio hole\", forcing me to use an MFI chip to get access to the microphone port.The more I dug, the more I found everything locked down. I realized Apple didn&#x27;t want me actually using any of the standard interfaces I&#x27;d come accustomed to using in my decades long career in tech. Beautiful phone, I just couldn&#x27;t use it outside of the curated experience. Not without their permission (read: tax).It was the most anti-consumer piece of electronics I&#x27;d ever enountered. I&#x27;m assuming it&#x27;s much much worse now.If Apple dared, they&#x27;d consider locking down WiFi access as well. I&#x27;m sure they&#x27;ve toyed with the idea of forcing all WiFi router manufacturers to purchase an MFI chip to interoperate with Apple product.What the kids here seem to want is a curated experience, and they&#x27;re willing to pay $$$ every month for a device they can&#x27;t open, repair, modify, etc.Good luck to you and your leased phone experience, you only compute at Apple&#x27;s pleasure. I fear for the subsequent generations raised in a market where this exploitive behavior has become normalized.&#x2F;old-timer-rant reply spacecase-25 11 hours agoparentWe still very much do want to, and enjoy, building our own computers. You just won&#x27;t find many of those folks in the comments section of any article about Apple. Instead, what you&#x27;ll find is mostly Apple cultists defending their beloved massive, multi-national corporation.Those of us who build our own computers have very little interest in running Apple&#x27;s software or OS. Instead, we run Linux or Windows. Software freedom is still alive and well in the land of Linux and FOSS.The main difference is that computers have gotten much more complex than they were back in the day and operating systems are far more complex. The days of throwing together a kit running BASIC and writing your own tools are long gone, and this is mostly for the best. While there is a lot of educational value in that type of computing, we have come quite a long way from the fancy calculators of yore. reply Clamchop 12 hours agoparentprev> forcing me to use an MFI chip to get access to the microphone port.How does this work? We are talking about the now-deceased analogue minijack, right? reply lordfrito 10 hours agorootparentWell back then (~10 years ago?) it was just a standard three signal minijack (left out, right out, mic in)I think the audio out was open to software, but the incoming mic data required an MFI chip to be able to open&#x2F;read the channel in software.I never did get my hands on an MFI chip, so I never got far enough to figure out what it interfaced with. I assumed at the time it must somehow talk to the phone over the mic line, otherwise how could you build a microphone that used the standard mic jack? I&#x27;m sure it&#x27;s encrypted, I know they were like 10¢ or so in volume, and once Apple approved&#x2F;blessed your idea you could get tech docs and samples. That&#x27;s about all I know, as I couldn&#x27;t get them to work with us, as my company refused to hand over and project plans, market data etc to them. It was going to take multiple months before we got anywhere, and we had weeks to get a demo running. Spent about 3x time and money on that project as it should have taken because of their user hostility. So f*ck em.Maybe some one else here can add some details on how MFI works on microphones.Edit: should follow up saying that once I figured out that they weren&#x27;t locking out WiFi, we added a small WiFi hotspot module to the PCB. So you plugged it into the phone, it drew power from the phone to run a hotspot. You then had to go into the phone and join the hotspot. Then our app would open a port on the local wireless LAN to tunnel a few hundred bytes of data a second. Blew my mind that I could only get around Apple blocks by sticking another radio on the phone. reply fingerlocks 4 hours agorootparentI don’t know what special chip you’re talking about.I wrote firmware for both wired USB and wireless IAP2 for external hardware support on iPhones, and it didn’t require anything more than the standard developer account.Shipping and getting the device certified by Apple, with a literal stamp on the box that says “Made for Apple Devices” or whatever, is where MFi comes into play.MFi is an account you sign up for to get spec sheets, support, and access to order custom components like lightning connector modules. But that’s all optional for hobby programming.https:&#x2F;&#x2F;mfi.apple.com&#x2F;en&#x2F;how-it-works reply zuminator 17 hours agoprevI was unfamiliar with the practice of \"parts pairing\" in Apple devices, which it seems can even prevent you from cannibalizing functional parts from an old iPhone to replace damaged parts in your current device. Does Apple even have some kind of consumer friendly justification for this practice, or is it just unabashed fuckery? reply criddell 17 hours agoparentSome parts need to be cryptographically linked for security reasons. For example, when the phone used to have a fingerprint sensor I believe all communication between that module and the rest of the phone used public key cryptography so that you couldn&#x27;t replace the sensor with something less secure.A second reason for doing this is to make theft of devices less lucrative. If you can&#x27;t sell a stolen phone for parts, then there&#x27;s less incentive to steal the phone.I think there&#x27;s more that Apple could do to make third party repairs easier without sacrificing security or theft disincentives. Maybe there could be a setting where I, as the owner, can authorize parts salvage of the phone before I sell it. reply JoshTko 17 hours agorootparentI love that Apple is doing this. Making thieves not want to steal my phone is 50x more valuable to me than having a slightly easier time repairing my phone. reply pixl97 17 hours agorootparentThis is a case of conflicting needs of users.If security is your primary need, it is great.If sustainability is your primary need then it sucks. reply bzzzt 17 hours agorootparentApple supports and repairs phones for a long time. It&#x27;s not about sustainability, it&#x27;s about the price Apple charges for repairs. What is so sustainable about having and using the right to mount a cheap, bad battery that will have to be replaced again in a year or so? reply pixl97 15 hours agorootparentThings have a long tail. The world is unstable. Politics can suddenly change and now you&#x27;re throwing tons of things in the trash not because the items cannot be fixed, but that Apple directly cannot sell you parts. reply JoshTko 15 hours agorootparentprevThis. reply zuminator 16 hours agorootparentprevBut instead of making parts unexchangeable by default, couldn&#x27;t they blacklist parts that come from phones specifically reported as stolen? And then any phone with a blacklisted part installed could be disabled&#x2F;reduced in functionality&#x2F;reported to authorities, etc. Meanwhile people who just wanted to recycle their old screens or whatever wouldn&#x27;t be penalized. reply JoshTko 15 hours agorootparentDeterring criminals requires consistent, accurate, fast reporting by customers which will never happen since customers have no incentive at all to report (not even considering the level of effort of educating the iPhone customer base abotu how to report). You can recycle your phone today by dropping it off at Apple. reply bzzzt 17 hours agorootparentprevIt&#x27;s not the parts that are locked, it&#x27;s the phone that wants specific parts. If you give people the possibility to change their phones to accept other parts you instantly create a market for stolen parts. Maybe Apple should lock both sides.Another reason for locking parts to the phone is to prevent non-genuine parts. Those cheap batteries or TFT replacement screens for OLED iPhones will not give the experience Apple intended and will damage their reputation. reply philwelch 17 hours agoparentprevIt’s an anti-theft measure. reply EPWN3D 15 hours agoprevR2R activists and open source activists have this insane view that giant corporations are making decisions for the sole purpose of thwarting their movement&#x27;s goals. These people just can&#x27;t see past their own agendas and have to portray every mundane decision about hardware and software design as specifically calibrated to inflict maximum harm to them personally. Like the engineers, managers, and executives at Apple literally have nothing else to do all day but contemplate how every decision they make harms R2R and open source advocacy.These people are just exasperating. reply spacecase-25 11 hours agoparentFeel free to vote yourself off the island or, perhaps, simply choose not to engage in topics that you don&#x27;t care about. reply JCharante 17 hours agoprev> There are so many tactics Apple gets to use to sabotage repair. For example, Apple engraves microscopic Apple logos on the subassemblies in its devices. This allows the company to enlist US Customs to seize and destroy refurbished parts that are harvested from dead phones by workers in the Pacific Rim:Dead phones that were potentially stolen? A major reason I choose to buy iPhones is for their VIN-locking. I would rather my phone, if stolen, explode in the theif&#x27;s hand, than allow for any 3rd party repair, even a battery swap. I want as close to 100% of the phone components to be serialized. reply gpvos 17 hours agoparentThat, uh, seems unnecessarily violent and vindictive. reply YuriNiyazov 14 hours agorootparentThat seems the correct amount of violent and vindictive. reply stalfosknight 17 hours agoparentprevVIN? reply gpvos 17 hours agorootparentThat&#x27;s explained at length about a dozen paragraphs into the article. reply stalfosknight 16 hours agorootparentI&#x27;m familiar with Activation Lock but there are no VINs involved. reply anakaine 12 hours agorootparentIt&#x27;s a reference to the article, and the way the article talks about what&#x27;s happening here. reply ThePowerOfFuet 4 hours agorootparentprevThe practice came from the automotive sector originally.RTFM, or quit arguing with those who have. replystuaxo 16 hours agoprevWow a lot of astroturfing in the comments here in favour of DRMd parts. reply nemothekid 16 hours agoparentI think it&#x27;s unfair to call anyone who has a differing opinion than you an astroturfer. reply fragmede 16 hours agorootparentThe guidelines specifically calls this out, even.> Please don&#x27;t post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you&#x27;re worried about abuse, email hn@ycombinator.com and we&#x27;ll look at the data.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply spacecase-25 11 hours agoparentprevIt&#x27;s an article about Apple, did you expect anything other than cultists defending their beloved multi-national corporation? reply stouset 8 hours agorootparentPeople have been complaining about Apple cultists since at least the original iPod, 20+ years ago. Probably before then too.In the intervening decades, Apple has managed to grow their “cult” following exponentially, by hundreds or even thousands of times the size that it used to be.Do you ever stop and wonder why that might be exactly? reply QVVRP4nYz 16 hours agoparentprevI am not sure if it is astroturfing but I sure remember people apeshit when car manufactures tried to do same thing (including John Deere that AFAIR still uses DRM for parts.) reply stouset 8 hours agorootparentHow often are people grabbing tractors out of people’s hands while walking down the street? reply onewheeltom 15 hours agoprevDo google and samsung have similar practices (parts pairing, serialization)? reply gameoverhumans 15 hours agoparentIf Apple gets away with this awful practice for long enough, I&#x27;m sure the other manufacturers will follow suit if they haven&#x27;t already.Remind me who it was to remove the headphone jack first, again? ;) reply dotnet00 14 hours agoprevhttps:&#x2F;&#x2F;youtu.be&#x2F;Lxo6l_whDeESo much for \"we need to do this for security!\" lol reply khaki54 12 hours agoprevThey ship you 79 lb. Pelican case to do self service battery swap? And a technician needs to login to review your work! reply jiofj 17 hours agoprev [–] Thanks Apple for pairing more and more components thus making my phone a less desirable target for thieves. One of the reasons I will keep buying iphone. reply fiddlerwoaroof 17 hours agoparentYeah, approximately no one actually repairs their repairable devices, so making them smaller and more integrated might be better and less wasteful overall. reply gpvos 17 hours agorootparentI&#x27;ve replaced the battery at least once in all the phones I&#x27;ve had, and two other parts in my last phone. On the other hand, none of my phones has ever been stolen. And it&#x27;s not just me, my neighbourhood has several repair shops. reply fiddlerwoaroof 15 hours agorootparentIt’s still an optimization problem, and the results might be surprising reply gpvos 13 hours agorootparentFair enough. I&#x27;m open to data on that. reply johnnyworker 17 hours agoparentprevScrew the future, just so you don&#x27;t have to keep your phone in your pocket or in your hand? Are the other reasons equally shitty? reply BrainBacon 16 hours agoparentprevI think cheaply available replacement parts ready from the manufacturer would be a much more desirable deterrent for thieves. Louis Rossman&#x27;s battle with calibrating the angle sensor on the MacBook Pro is a great indicator that these restrictions aren&#x27;t always done for security reasons since the part in question is worth pennies. reply dpkonofa 10 hours agorootparentLouis Rossman is also a dishonest person who makes money off the whole controversy. He purposely does things to make the situations seem worse and has even been called out for outright lying (I stopped following after he claimed there was an issue with MacBooks when he purposely used an unshielded cable to cause the issue he was claiming). reply arunabha 9 hours agorootparentI didn&#x27;t know that. Mind sharing the source? reply mouzogu 17 hours agoparentprevyou think losing the right to repair just so that some hypothetical thief can&#x27;t hypothetically take and resell your phone is a reasonable trade....?absolute nonsense. reply devwastaken 17 hours agoparentprevPairing components doesn&#x27;t make the device theft proof.Overwhelmingly phones are stolen and sold as-is, not chop shopped. Chop shopping is generally not a lucrative business because availability of 3rd party parts is a lower cost than the time required to disassemble.The availability of manufactured parts significantly out scales independent sales.Contrary to common thought, Apple has a particular issue wherein they are focused upon for repair because their vertical integration results in few models. Less models = more focus on methods to repair.This means that apples intentional methods to prevent repair are not for your benefit, they&#x27;re for profits. You can have security and repair. reply jiofj 17 hours agorootparent>Overwhelmingly phones are stolen and sold as-is, not chop shopped.That&#x27;s not true. An icloud-locked iphone is a paperweight. Only the components are worth something. Well, were ;) reply e44858 9 hours agorootparentWhich is why thieves will sometimes ask you to unlock your phone. reply Kirby64 6 hours agorootparentMost phone thefts are snatch and run. No chance to rob you and demand your passcode. Every second they have to deal with you trying to give your passcode is one they might get caught. Also, it requires your apple ID passward to remove iCloud lock, not just the passcode. reply sschueller 17 hours agoparentprev [–] Enjoy your government approved apps. &#x2F;sLetting companies lock down devices to this point will result in governments creeping in and taking the opportunity to control its population. Devices like this are a direct threat to people trying to rise up against a dictatorships or oppressive governments. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple purportedly opposes the right-to-repair movement to monopolize repairs, using methods such as logo engraving and vehicle identification number (VIN) locking. The complexity and high cost of its repair program have garnered criticism.",
      "Independent companies are presenting more affordable repair solutions—an alternative many consumers prefer.",
      "The push for right-to-repair legislation is gaining momentum, with outcomes like the passage of relevant laws in California, advocating for more freedom in repair and product interoperability."
    ],
    "commentSummary": [
      "The article addresses the right-to-repair issue revolving around Apple devices, accentuating Apple's barriers to device repairability.",
      "The discussions in the comments section spotlight debates on user choice, device serviceability, regulations pertaining to replacement parts, and the cost implications of repairs.",
      "It also explores other related topics such as Digital Rights Management (DRM), Apple's anti-theft safeguards, parts pairing, and effects on environmental sustainability and government regulation."
    ],
    "points": 160,
    "commentCount": 136,
    "retryCount": 0,
    "time": 1695401038
  },
  {
    "id": 37620507,
    "title": "TinyML and Efficient Deep Learning Computing",
    "originLink": "https://efficientml.ai/",
    "originBody": "6.5940 Logistics Schedule TinyML and Efficient Deep Learning Computing 6.5940 • Fall 2023 • MIT Large generative models (e.g., large language models, diffusion models) have shown remarkable performance, but they require a massive amount of computational resources. To make them more accessible, it is crucial to improve their efficiency. This course will introduce efficient AI computing techniques that enable powerful deep learning applications on resource-constrained devices. Topics include model compression, pruning, quantization, neural architecture search, distributed training, data/model parallelism, gradient compression, and on-device fine-tuning. It also introduces application-specific acceleration techniques for large language models, diffusion models, video recognition, and point cloud. This course will also cover topics about quantum machine learning. Students will get hands-on experience deploying large language models (e.g., LLaMA 2) on a laptop. The slides and lab assignments from the last semester are available for access here. Online Lectures: Lecture recordings are available at YouTube. Live Streaming: Lectures are live streamed at live.efficientml.ai every Tuesday/Thursday 3:35-5:00pm Eastern Time. Location: 36-156 Office Hour: Thursday 5:00-6:00 pm Eastern Time, 38-344 Meeting Room Discussion: Discord Homework submission: Canvas Resources: MIT HAN Lab, HAN Lab Github, TinyML, MCUNet, OFA, SmoothQuant Contact: Students can ask all course-related questions on Discord. For external inquiries, personal matters, or emergencies, you can email us at efficientml-staff@mit.edu. If you are interested in getting updates, please sign up here to join our mailing list to get notified! Instructor: Song Han Associate Professor, MIT EECS https://songhan.mit.edu/ TA: Ji Lin PhD Student, MIT EECS https://www.linji.me/ TA: Han Cai PhD Student, MIT EECS https://han-cai.github.io/ Announcements Jul 30, 2023 The course will be returning in Fall 2023, with live sessions on YouTube! TinyML and Efficient Deep Learning Computing MIT HAN Lab efficientml-staff@mit.edu © Copyright 2023 MIT. Powered by Jekyll with al-folio theme.",
    "commentLink": "https://news.ycombinator.com/item?id=37620507",
    "commentBody": "TinyML and Efficient Deep Learning ComputingHacker NewspastloginTinyML and Efficient Deep Learning Computing (efficientml.ai) 156 points by samuel246 6 hours ago| hidepastfavorite24 comments jimmySixDOF 3 hours agoI highly recommend the tinyML Talks to anyone interested in pushing edge compute past the last mile they have a huge library and a full upcoming schedule most of the slides are available so there is a huge amount of content it&#x27;s amazing what you can get running on embedded systems.https:&#x2F;&#x2F;quip.com&#x2F;MENbAvuQkrb0 reply matt_daemon 5 hours agoprevI feel like this should be at the forefront of thinking on ML. Seeing how many computing resources Big Cloud companies are planning due to demand for ML infrastructure is pretty concerning from an energy use standpoint. reply hnfong 5 hours agoparentThis is a false dichotomy.Bleeding edge research work should not be hindered by premature optimization concerns. Take quantization for example. Before people were able to train a model with the usual floating point precisions, nobody knew that INT8 or q4 quantization was feasible. (In fact, nobody would have a full precision model to compare performance with.)Also, the idea that energy efficiency should be a top concern basically undermines the whole idea of developing new technology. It&#x27;s obvious that if fancy things are to come out of the research, it&#x27;s going to cost more energy to run than not running anything at all. That itself is an argument that if we don&#x27;t want energy usage to keep ramping up, we should shut down ALL research that potentially give us new energy-depleting toys.So, really, I&#x27;m personally not concerned with \"one-off\" resource usage if they advance human understanding of the state of the art. Since energy actually costs money, capitalist pressures will make people think of ways to save energy (and time). The moralistic arguments are just misguided in the big picture. IMHO it feels like luddites putting on the environmentalist hat here.Instead of shaming machine learning researchers over their energy use, it&#x27;s probably more effective from a energy use standpoint (for example) to ban \"proof of work\" schemes in cryptocurrency. reply derangedHorse 20 minutes agorootparentInstead of shaming machine learning researchers over their energy use, it&#x27;s probably more effective from a energy use standpoint (for example) to ban “dirty” energy plants.Banning a class of high energy consuming algorithms used towards a non-violent technological development you disagree with makes absolutely no sense to me. reply rlt 3 hours agorootparentprevCouldn’t cryptocurrency proponents make a similar argument? reply WithinReason 2 hours agorootparentNo, how does a lot of crypto mining infrastructure now reduce the cost of cryptomining 5 years down the line?I will say though that at this point in time it&#x27;s ridiculous how little research has gone into reducing the energy use of networks. reply arthurcolle 3 hours agorootparentprevYes they could. Does that make it harder to reason about? reply imadj 4 hours agorootparentprev> Bleeding edge research work should not be hindered by premature optimization concernsExcept nothing here is hindering the ability of scientists to develop whatever new technologies they want in their labs. > shut down ALL research > shaming machine learning researchersYou&#x27;re being sensationalistic. They&#x27;re not banning super computers. AI research isn&#x27;t facing an existential threat. reply imjonse 4 hours agorootparentprevAs you know, energy efficiency is not related to research and training only, but increasingly to inference and productionizing of the models. This is mostly what this course emphasizes too.It&#x27;s not about luddites putting on the environmental hat, if environment was the main concern your capitalist pressure couldn&#x27;t care less (\\o&#x2F; externalities). It&#x27;s about not draining phones batteries and not racking up datacenter bills. reply katella 5 hours agorootparentprevDo you hold the same opinion for crypto? reply mratsim 5 hours agorootparentprevVideo encoding uses a *lot* of energy, Youtube, Netflix and friends.And capitalistic force are not fast enough and d not take environmental impact into account has carbon taxes are not there or not high enoigh or lobbied against or not measurable and gamed. reply tonyhb 4 hours agorootparentCRT TVs used a lot of energy. It’s getting better. reply uoaei 4 hours agorootparentprev> Since energy actually costs money, capitalist pressures will make people think of ways to save energy (and time).This and similar facile arguments are getting tiresome. They seem predicated on nothing but the most basic Econ 101 understanding of value. Nothing exists in that idealized world -- in reality, complex mechanisms keep this kind of excess spend relevant (marketing and public image, \"first to market\" concerns, sunk cost spending, and a million more) regardless of more material considerations, so to lean on this trope is not really up to the standards of HN discussion in my book. reply cosmo13 4 hours agoparentprevInitiatives like green data centers are there which are designed to minimize environmental impact reply choppaface 5 hours agoparentprevDeepSpeed and Hugginface Accelerate already include a lot of these features and they’re indeed already used in production. This class would be a great intro to said features given most people barely have access to one GPU let alone hundreds.Moreover, the class also covers topics related to using and hacking with foundational models of all you have is the model versus a cluster.Energy used to train foundation models is indeed extreme but the gross expenditure is more a function of corporate spending and competition than deep learning technology. reply tysam_and 4 hours agoprevI&#x27;m curious if anyone knows people who would help me bring some efficient ML project work I&#x27;ve done to spheres like Africa. I&#x27;ve visited a couple times and loved being there so much, but definitely feel extremely disjoint from that part of the world. It would be really nice to me to help make some of those connections. <3 :&#x27;)))) reply EddTheSDET 4 hours agoparentCould you write to a university near where you’d like to work and ask them for some advice too? reply tysam_and 4 hours agorootparentI think you may have replied to the wrong comment (I might be misunderstanding, however). reply joshvm 4 hours agorootparentI think the suggestion is to try to collaborate with local universities. From experience, a lot of research&#x2F;fieldwork in Africa is only practical with local experts and communities.Also look into attending or supporting the next Deep Learning Indaba. This year has just finished I think. It&#x27;s one of the largest African ML communities and they have a mentorship program.https:&#x2F;&#x2F;deeplearningindaba.com&#x2F;2023&#x2F; reply CamperBob2 5 hours agoprev$25 billion endowment, and we get the audio quality of a 1930s-era wire recorder. Annoying. reply zxexz 4 hours agoparentOOC, what are you listening to? The youtube playlist has 2 videos for each lecture, a zoom recording focusing on the slides with the professor visible on camera, and a classroom recording - the latter definitely has better audio quality, but the audio quality of both is far better than your average OCW lecture from 10 years ago. reply gozzoo 2 hours agorootparentIt&#x27;s ironic that the audio quality of most AI online courses is terrible.I&#x27;m looking forward to the moment when AI can be used to improve the audio of these lectures, especially older ones like the Feynman lectures.[1][1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=-kFOXP026eE&list=PLS3_1JNX8d... reply gozzoo 2 hours agoparentprevwith subtitles it&#x27;s bearable reply facu17y 2 hours agoprev [–] seems that the course doesn&#x27;t include Google&#x27;s highly efficiemt \"step by step distillation\" method, which was discussed on HN yesterday replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The \"TinyML and Efficient Deep Learning Computing\" course aims to educate on efficient AI computing techniques, allowing robust deep learning applications even on devices with limited resources.",
      "Course topics will encompass model compression, pruning, quantization, neural architecture search, and distributed training. Hands-on experience will be provided in deploying large language models, supplemented by online lectures and live streams.",
      "Prosecuted by Professor Song Han with two teaching assistants, the course encourages real-time interaction, permitting students to ask queries on Discord. The course is set to return in Fall 2023."
    ],
    "commentSummary": [
      "The post emphasizes the importance of TinyML, the necessity of efficient deep learning computing, and recommends TinyML Talks.",
      "It argues that energy efficiency in Machine Learning (ML) infrastructures should not obstruct cutting-edge research and technology development. It touches on the implication of banning \"proof of work\" schemes in cryptocurrencies.",
      "Collaboration with universities is discussed, and the potential for bringing efficient ML projects to Africa is outlined, providing insights about Google's \"step by step distillation\" method."
    ],
    "points": 154,
    "commentCount": 23,
    "retryCount": 0,
    "time": 1695441983
  }
]
