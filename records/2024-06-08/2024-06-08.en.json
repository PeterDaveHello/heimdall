[
  {
    "id": 40614227,
    "title": "Apollo 8 Astronaut William Anders Dies in Plane Crash Near San Juan Islands",
    "originLink": "https://www.fox13seattle.com/news/william-anders-wa-plane-crash",
    "originBody": "William Anders, Apollo 8 astronaut, killed in San Juan Islands plane crash By FOX 13 News Staff Published June 7, 2024 3:35pm PDT San Juan County FOX 13 Seattle William Anders, Apollo 8 astronaut, killed in WA plane crash The pilot of a plane that was destroyed in a fiery crash just off the San Juan Islands was confirmed to be former Apollo 8 astronaut Bill Anders, who is now confirmed dead. SAN JUAN COUNTY, Wash. - Retired American astronaut William Anders, who was a member of the Apollo 8 crew, was killed in a plane crash just off the San Juan Islands on Friday afternoon. Anders' son, retired Air Force Lt. Col. Greg Anders, confirmed the death to The Associated Press. The plane that crashed was a vintage Air Force T-34 Mentor, which is owned by Anders, who is also a San Juan County resident. Close-up of American astronaut William Anders, of NASA's Apollo 8 mission, during a panel interview held at the Museum of Science and Industry, Chicago, Illinois, April 5, 2018. (Photo by J.B. Spector/Museum of Science and Industry, Chicago/Getty Images) Anders was reportedly piloting the plane when it crashed. \"The family is devastated,\" Greg Anders said. \"He was a great pilot and we will miss him terribly.\" Video shows fiery small plane crash into WA waters near Orcas Island Crews responded to a plane crash in the San Juan Islands on Friday afternoon. Officials with the United States Coast Guard Pacific Northwest said the crash happened near Orcas Island before 11:45 a.m. Early life of William Anders William Anders was born on Oct. 17, 1933, in Hong Kong, but he grew up in San Diego. In 1955, Anders graduated from the United States Naval Academy with a bachelor of science degree, and received his master of science degree in nuclear engineering from the Air Force Institute of Technology in 1962. He completed the Harvard Business School Advanced Management Program in 1979. Recruited by NASA In 1964, Anders was selected by the National Aeronautics and Space Administration (NASA) to be an astronaut with responsibilities for dosimetry, radiation effects and environmental control. He was a backup pilot for the Gemini XI, Apollo 11 flights, and was lunar module pilot for Apollo 8. Apollo 8 mission In 1968, Anders operated the Apollo 8 mission alongside Air Force veteran Frank F. Borman II and Navy veteran James A. Lovell, Jr. In total, he logged more than 6,000 hours of flying time. During this mission, their command module floated above the lunar surface, and the astronauts beamed back images of the moon and Earth and took turns reading from the Book of Genesis, closing with a wish for everyone \"on the good Earth.\" From L to R, Apollo 8 astronauts spacecraft Commander Frank Borman, Command Module Pilot James Lovell and Lunar Module Pilot William Anders, who became the first humans to escape Earth's gravity and the first humans to see the far side of the Moon, l Expand According to NASA, the mission was also famous for the iconic \"Earthrise\" image, snapped by Anders, which would give humankind a new perspective on their home planet. Anders has said that despite all the training and preparation for an exploration of the moon, the astronauts ended up discovering Earth. FILE - This Dec. 24, 1968, file photo made available by NASA shows the Earth behind the surface of the moon during the Apollo 8 mission. Retired Maj. Gen. William Anders, the former Apollo 8 astronaut who took the iconic \"Earthrise\" photo showing the Expand William Anders' retirement In 1988, Anders retired from the Air Force Reserves and became the chairman and CEO of General Dynamics Corporation in 1991. After two years, he retired from General Dynamics and stayed as chairman until 1994. Anders and his wife Valerie moved to Orcas Island in 1993. They have six children and 13 grandchildren. Group portrait of, from left, American astronauts William Anders, James Lovell, and Frank Borman, all of whom participated in NASA's Apollo 8 mission, as they pose together at the Museum of Science and Industry, Chicago, Illinois, April 5, 2018. (Pho Expand Shortly after retiring, the couple established the Anders Foundation supporting educational and environmental concerns as a vehicle for supporting several of their interests, including Yosemite National Institute and the Olympic Park Institute. In 1996, the couple started the Heritage Flight Museum around the P-51 Val-Halla. It has steadily grown ever since and currently resides at Skagit Regional Airport in Burlington. As the museum grew, their two sons found a passion for aviation and joined them in the Puget Sound area to help run the museum. The Associated Press contributed to this report. MORE HEADLINES FROM FOX 13 SEATTLE More than 300 new WA state laws went into effect June 6 WA schools superintendent responds to new 'Parents' Bill of Rights' Amanda Knox vows to 'fight for the truth' after slander reconviction in Italy 17-year-old shot, killed at Seattle's Garfield High identified To get the best local news, weather and sports in Seattle for free, sign up for the daily FOX 13 Seattle newsletter. DAILY NEWSLETTER All the news you need to know, every day By clicking Sign Up, I confirm that I have read and agree to the Privacy Policy and Terms of Service. Streaming Now on FOX LOCAL Latest News View More Massive signs of iconic Enumclaw restaurant stolen overnight Washington judge denies GOP attempt to keep financial impact of initiatives off November ballots Oregon closes more coastal shellfish harvesting due to 'historic high levels' of toxins Healing garden for gun violence victims unveiled by Seattle city leaders Seattle traffic: Weekend events to create delays on local roads Latest Videos View More video Seattle weather: Mostly sunny and warm weekend video UW: Device helps people with spinal injuries improve hand function video 4 kidnapped Israeli hostages rescued video Families affected by gun violence gather at new healing space video Families affected by gun violence gather at new healing space Download FOX 13 Apps Trending Now Seattle-based film 'Know Your Place' hits the big screen at SIFF Cinema Uptown Tacoma teacher, pastor accused of child molestation back in jail after bail violation: docs WA DNR predicting a tough fire season: How to minimize the fire danger surrounding your home Baby shower attendees kill man after fender bender, Dallas police say Sue Rahr discusses first days as SPD interim police chief Vote in our Poll!",
    "commentLink": "https://news.ycombinator.com/item?id=40614227",
    "commentBody": "Apollo 8 astronaut William Anders ID'd in WA plane crash (fox13seattle.com)401 points by TMWNN 18 hours agohidepastfavorite202 comments toomuchtodo 18 hours agohttps://en.wikipedia.org/wiki/William_Anders He took the Earthrise photo, which Nature photographer Galen Rowell described as \"the most influential environmental photograph ever taken\": https://en.wikipedia.org/wiki/Earthrise https://www.abc.net.au/science/moon/earthrise.htm reply dmix 15 hours agoparent> Joni Mitchell sings on her 1976 song \"Refuge of the Roads\": \"In a highway service station / Over the month of June / Was a photograph of the Earth / Taken coming back from the Moon / And you couldn't see a city / On that marbled bowling ball / Or a forest or a highway / Or me here least of all …\" Great lyrics https://youtu.be/VfLH0xJByiI?si=W953IQPO98QSSq0K&t=284 reply akavel 12 hours agoparentprevWikipedia links to a nice visualization on youtube of the moments when the photo was taken, synced with the recording of the actual conversation of the Astronauts as recorded by the Apollo 8 equipment: https://www.youtube.com/watch?v=dE-vOscpiNc reply alextheterrible 4 hours agorootparent\"calm down, Lovell!\" That's a fun listen. reply insaneirish 15 hours agoparentprev> He took the Earthrise photo, which Nature photographer Galen Rowell described as \"the most influential environmental photograph ever taken\": https://en.wikipedia.org/wiki/Earthrise Heh. I'd never read/heard that quote before. But no one's photos have touched me more than Galen Rowell's, so it bears an incredible amount of weight to read. Thank you for sharing it. reply detourdog 6 hours agorootparentI don't know how true this story is but here is one version of the creation of the photo. https://www.coquelicot-translation.com/picture-earth-earthri... reply jvm___ 16 hours agoparentprevThe shutter speed was 1/250th of a second, so the earth rotated about 4 miles or 6 kms while the shutter was open. Not enough to blur the photo obviously, but crazy to think about. reply Cerium 13 hours agorootparentI have no idea how to calculate it, but I interpreted this to mean not that the earth rotated (which everyone is trying to calculate) but that the earth was crossing the horizon of the moon such that four miles of earth crosses the horizon during the shot causing earth blur for a moon-stable reference frame. reply Thorrez 4 hours agorootparentRevolved I think would be the correct term for that. reply danielecook 16 hours agorootparentprevI’m confused. Does this math check out? Circumference is 24,901 - so about 1000 mph at equator. 1000 mph / 3600 s / h = 0.27 mps 0.27 * (1/250) = 0.001 miles? Doing this math on my phone but am I missing something here? reply mrb 15 hours agorootparentYou are correct. Using GNU units: $ units '2 * pi * earthradius / day * (second / 250)' Definition: 1.8532517 m Which is 0.0011515572 miles... reply re 14 hours agorootparentprevI think the parent comment was confusing/misremembering the rotational speed value in miles per hour as miles per second. reply Choco31415 15 hours agorootparentprevEven if we stretch out and look at how fast the Earth orbits the sun, it still doesn't explain the 4 mile figure. Earth's orbital speed: 66,200 mph 66,200 mph / 3600 s/h = 18.38 mps 18.38 * (1/250) = 0.07 miles reply thsksbd 15 hours agorootparentprevI got the same answer reply tomrod 14 hours agorootparentprevI think it's relative and phrased poorly, since the orbiter has to circle the earth at a certain faster speed. But quick googling shows Apollo 8 was traveling about a mile a second? reply serf 15 hours agorootparentprevrotation: 360/86,400=0.0041667deg/sec 0.0041667 * 0.004sec = 000016667degR circumference: 2pi * 6371km = 40,030km land covered by rotation: 40,030 / 360 = 111.194km/deg 0.000016667deg × 111.194 km/degree = 0.001854 km km to m: 0.001854km × 1,000 meters/km = 1.854 meters more like 0.001 miles. ... oh, woops. I see your answer is in kms. it was something like 0.46km/s. reply lamontcg 12 hours agorootparentprevIf the orbital period was 80 minutes then that is 1/1,200,000th of a period and with Earth's circumference being ~25,000 miles that should only be about 0.02 miles. Or if the orbital velocity was 17,000 mph and neglecting the height of the orbit, 17000 / 3600 / 250 = 0.018 miles. So either way, about 100 feet. reply adastra22 12 hours agorootparentIt was taken from the moon, not low earth orbit. reply jandrewrogers 13 hours agoprevAn absolute legend going out like a total badass. I know people will disagree but there is much to be said for living your life on your own terms and accepting the potential consequences without reservation. He was clearly one of those guys. He probably did not expect to die that day, but he knew he would die some day and he wasn’t going to nerf his life to buy a few more years. reply krisoft 10 hours agoparentMy grandad at a ripe old age had a stroke and the doctors told him and the family that he won’t ever be able to walk. So he got a wheelchair and was eventually sent home to recuperate. A few days later my mom visited him and found him wheeling around in the wineyard. It seemed that my grandad (her dad), ever the engineer, pimped his ride to make it more off-road worthy and was in the process of figuring out how he can continue with yard maintenance in his new state. My mum was very angry with him. From her perspective her dad was “risking his life” doing what he was doing. I tried to gently point out that while she is right that staying in bed would be safer for him, wouldn’t he be one step closer to the grave if he were to give up on his favourite activities? reply throwup238 5 hours agorootparent> I tried to gently point out that while she is right that staying in bed would be safer for him, wouldn’t he be one step closer to the grave if he were to give up on his favourite activities? More than one step closer! Being bedridden is usually the beginning of the end. Once you can’t even get basic exercise done, everything starts to degrade rapidly. reply lukan 9 hours agorootparentprevGood for him! Living is not the same as existing. reply gcanyon 7 hours agorootparentprev\"A ship in a harbor is safe but that is not what ships are built for\" reply bilater 39 minutes agoparentprevReminded me of the film Secondhand Lions https://en.wikipedia.org/wiki/Secondhand_Lions reply lambdasquirrel 1 hour agoparentprevI wonder if something happened and he knew he wasn’t going to make it, and so crashed intentionally to avoid the possibility of hitting something when the fuel ran out. There are so many little islands in that area, and he could have plausibly ditched in the water, however cold it would be. Badass yes. reply K0balt 7 hours agoparentprevThis is precisely why I have elected to put off my riskier hobbies until my later years. I find my tolerance for risk goes up as I become less instruyan in the lives of my loved ones. One day, I’ll feel free to take the risks implicit in my stupider ambitions. reply robohoe 5 hours agorootparentIf you make it that long reply adastra22 12 hours agoparentprevBut would you \"net your life\" to buy a billion years? reply bicx 18 hours agoprevI saw the headline earlier, and my first thought was \"I hope he was the pilot, because that would be a fitting way to go for a legend.\" Not only was he the pilot, but he was flying solo at 90 years old. reply Wistar 2 hours agoparentHe was flying a vintage T-34 Mentor, a pretty bad-ass craft. https://wingsmuseum.org/exhibits/beechcraft-t-34-mentor/ reply schiffern 17 hours agoparentprevWhat a legend indeed. Godspeed, Bill. :salute: reply lkdfjlkdfjlg 6 hours agoparentprev> I hope he was the pilot Which was how Gagarin died btw. https://en.wikipedia.org/wiki/Death_of_Yuri_Gagarin reply tzfld 13 hours agoparentprevI hate this reasoning. Why is this a fitting way to die? What would be a fitting way to go for a cook or an athlete then? reply krisoft 10 hours agorootparent> What would be a fitting way to go for a cook or an athlete then? Whatever they liked doing? Being an astronaut at that time implied that he was an aviator. Keeping his licence to fly into the old age of 90 means he most likely loved flying. That is why it is a “fitting way to die”. I don’t know the cook you mention. Maybe they loved cooking for loved ones. In that case a fitting way to die would be while they are doing that. But maybe it was just their profession, but what made them enjoy their life was watching musicals in the theatre. In that case a fitting way to die would be them dying after watching a great performance on their way out of the theatre. Maybe it would help if we would contrast this with an “unfitting” way to die? Let’s take the same cook who loves musicals. If she were to try to climb her roof to fix a leak (something she never before professed to care much about) and they slip and fall off the roof. That would be an unfitting way to die. Dying is probably painfull, scary and confusing in many cases. But the circumstances surrounding it can make it worse or better. Dying in an accident doing something you always hated is worse than dying in an accident doing something you loved. reply lukan 9 hours agorootparent\"Dying in an accident doing something you always hated is worse than dying in an accident doing something you loved.\" Dead is dead, though. I do not think the final moments matter as much as all the years before them. So even if I will one day die on the toilet being old, that would be way better, than me dying soon in an climbing accident, even though that sounds more dramatic and I am way more into climbing than toilets. reply weebull 50 minutes agorootparent> Dead is dead, though. I do not think the final moments matter as much as all the years before them. Well indeed. How many people give up what they love because of the fear that it will kill them? This man kept his love for aviation alive until the end. reply lannisterstark 7 hours agorootparentprevHe was 90. You're reading too much into it. It's like when people get angry about a \"Bless you.\" reply lukan 7 hours agorootparentDid I sound angry? I was just adressing the point that some people seem to value the circumstances of their death more, then the years before that. Wiliam Anders did what he wanted, fine by me, unless he actually was not fit to fly anymore (as this endangers other people), but no one had the guts to tell him that, being a national hero. reply sunir 4 hours agorootparentThe expression is a social game to respond to death. It’s not real. We are not happy how he died. We are happy the way he lived. The game is to invert and mix the two. It’s a form of cognitive dissonance to manage our emotional response so it is positive not negative. You may not feel it yourself which is fine but appreciate that’s what others are doing. It’s not meant to be logical. It’s meant to be illogical. reply nytesky 3 hours agorootparentprevI do wonder if perception of time changes as you die — maybe those last moments feel oh so much longer, and you experience them as another lifetime (part of why afterlife descriptions of near death can be so rich). Like ST TNG The Inner Light episode. reply larodi 13 hours agorootparentprevBecause an unfitting way to die is to be stuffed with tubes, half conscious in a bed, shitting your pants uncontrollably. The perspective of dying lying helpless in a hospital or care house is not very appealing to people who had an active life. reply ojosilva 11 hours agorootparentDying in a last scream of fear, angst and struggle regretting a thousand things that may have gone wrong or maybe were just your fault, without having the chance to tell your loved ones how much you love them, and being remembered not only by the incredible flights where no one had gone before, but finally and uttermost by the one that ended your life which will be replayed endlessly in the internets. Not sure what would be fitting to be honest. reply lordnacho 11 hours agorootparentI'm going to visit someone who is having it worse, in my opinion. He's slowly deteriorating from Alzheimers. He won't acknowledge it and has become seriously grumpy. He used to know everyone in his town. He was a good guy. Now, everyone thinks he's an asshole. Everyone who didn't meet him before he started this decline has had a terrible time with him. He curses all the time. Last week, he forgot to shut off the gas and was found unconscious by the fire department. Now, he will be in a care home against his wishes until the inevitable. This is not the first incident where police had to be phoned, either. So he's gone from a week liked, active member of the community to being the grumpy old guy that the authorities have to be phoned about in just a couple of years. I'm going to go see him for a final farewell later this month, I hope he recognises me. reply sva_ 9 hours agorootparentDying from Alzheimer's is truly terrible. From what I understand, in your final moments the neurons that move your lungs and beat your heart will give up, which is usually the end. And it's not the kind of opioidic kind of forgetting that you have to breathe either. It's pure struggle 'til the final moment. Back in school I had an art teacher whose father went that way, and it was clear that he was extremely traumatized by witnessing that. My condolences. reply closewith 9 hours agorootparentprevWe might be different types of people (your comment about regret strongly suggests we are), but I've been in some very hairy situations where I was fairly sure I was about to die traumatically and I didn't experience any of what you're suggesting. Instead it was a calm resignation or acceptance that was oddly peaceful. Not that I don't want to live, but I don't fear death and would take the plane crash over wasting in a hospital any day. I have a DNR registered with the health service in my country to make sure that never happens. reply gradascent 10 hours agorootparentprevOr maybe the final moment was a sigh of acceptance and gratitude for the live he lived. Nobody knows but him. reply sokoloff 8 hours agorootparentprevThere is zero risk of this astronaut being primarily remembered for how he died. reply simonh 10 hours agorootparentprev> Dying in a last scream of fear, angst and struggle regretting a thousand things that may have gone wrong or maybe were just your fault… I think you’re projecting. I didn’t know him obviously, but from what people who did have said about him, that doesn’t seem like the way he’d go out. reply jandrewrogers 13 hours agorootparentprevHe went out on his own terms subject to the rules of the way he lived. No excuses. It may not have been his intent to die but he was willing to take the risk. That is the price of true agency. reply patrec 9 hours agorootparentWhen you are prepared to die in a plane crash because of your decrepitude, how much risk to others is entailed in a case like this? If the plausible answer is “not that much” I am with you. But nonagenarian self-actualization at the cost of other people’s lives and limbs is a different story. reply closewith 9 hours agorootparentThe medicals for pilots are exhaustive and frequent, so you can be assured he was probably in better health than the majority of the population. reply rgmerk 8 hours agorootparentprevThe risk of dying while flying in a light plane is reasonably high. The risk of dying from a light plane crashing into you while you are on the ground is negligible. reply overstay8930 13 hours agorootparentprevMost people die painful and slow deaths in a bed surrounded by people they don’t know, or most likely entirely alone. Almost nobody dies peacefully in their sleep, it’s usually some horrible disease or failing bodily function. If you’re going to die a “fitting” way, it’s going to be because you took your life passion to the extreme. reply closewith 9 hours agorootparentMost people die at home with family. Only certain over-medicalised countries have a preponderance of the elderly dying in hospital. reply cooper_ganglia 5 hours agorootparentprevProbably falling into an industrial sized fryer or getting a tennis racket wrapped around their neck, respectively. reply accrual 12 hours agorootparentprevMy take is that he passed doing what he clearly loved: flying. He made some of his greatest achievements in life while in flight and was still flying during his final moments. reply PKop 1 hour agorootparentprevDifferent lifestyles, and different deaths, have different glory and honor attached to them, whether you like it or not. Being an astronaut that went to the moon and a pilot that dies flying at 90 will always and forever be cooler and more impressive than a cook, and most athletes too. I love this reasoning. reply sva_ 9 hours agorootparentprev> athlete Something like cycling down a mountain and dying from a lack of decreasing elevation. reply nurettin 13 hours agorootparentprevMaybe doing what they like the most, and taking all the risk/responsibility that comes with it. reply cjk2 11 hours agorootparentprevAs a mathematician I'm going to fall on a slide rule and poke my brain through an eye socket. Yeah doesn't work does it. reply szvsw 10 hours agorootparentChoke on chalk, nerd! Or maybe have an aneurysm trying to remember some latex command. reply cjk2 10 hours agorootparentOh hell that last one got me. Now how do I do that equals with two bars and a squiggle ... ERK ... THUD. reply szvsw 7 hours agorootparentProbably would have been better if I had instead suggested figure formatting and page layout… I think I’ve come close to stroking out over that… reply cjk2 7 hours agorootparentOh don't. I spent an hour yesterday trying to get a damn table to stay on the right page. reply jrootabega 17 hours agoparentprevnext [9 more] [flagged] sillysaurusx 16 hours agorootparentDoes a solo plane crash have a statistically smaller chance of hurting anybody else? reply TylerE 15 hours agorootparentHe was flying aerobatics over a lake (or possible bay, etc) at low altitude on a summer day. Higher risk. reply jrootabega 5 hours agorootparentprevI don't think it matters. Too much risk of a crash, hurting multiple people, one person, damaging property, triggering emergency response, is reckless. reply knodi123 16 hours agorootparentprevmost plane crashes are at takeoff or landing, which means it's not as simple as calculating how populated their flight path is.... but yes, it's pretty rare to be smooshed by a plane. reply KennyBlanken 16 hours agorootparentprevCrashes are most common on takeoff and landing, and that means you're over populated areas. GA and military crashes that kill people on the ground happen all the time. Used to happen all the time at airshows, too - until airshows adopted very strict rules around planes never having a trajectory that heads towards the audience. But that's all beside the point. A 90 year old has no business flying a fighter jet, and I don't care if he was a former astronaut or not. He certainly didn't have any business doing so alone. Reaction time goes down dramatically with age and nothing can be done about that. Mental capacity diminishes, too; mistakes skyrocket, which is why we have so many elderly people ramming their cars into convenience stores and such. Health risks like a stroke, especially in an aircraft that can generate high g's.The body's tolerance for heat and cold goes down. It was incredibly selfish of him to keep flying. reply knodi123 16 hours agorootparent> flying a fighter jet It was a military trainer propellor plane. But your point stands. https://en.wikipedia.org/wiki/Beechcraft_T-34_Mentor reply pfannkuchen 15 hours agorootparentprevThe area where he crashed is quite rural at least AFAIK (and I don’t just mean the water). reply avalys 16 hours agorootparentprevThat’s how I plan to go out. reply INTPenis 9 hours agoparentprevnext [14 more] [flagged] nvarsj 8 hours agorootparentThe guy was a legend - flew fighter jets, was a test pilot, and then an astronaut. Let's give him the benefit of the doubt - I'm sure he knew exactly what he was doing. reply mycologos 7 hours agorootparentI mean, he certainly would have known exactly what he was doing at some point in his life, but skills and judgement do degrade with age. reply TechDebtDevin 7 hours agorootparentAnd the obvious degradation of the body's capabilities and its potential failure points (potentially increased by traveling 300mph at 10,000 ft). Commenter is right, 90 year olds shouldn't be driving cars let alone flying. Incredibly irresponsible. Also there's really nothing that cool or heroic about dedicating your life to testing and operating flying death machines on behalf of a military. Get a grip. reply dev_tty01 3 hours agorootparentIf you follow your argument to a logical conclusion it would require that we ban millions of people with mild impairments from operating machines. That is the worst kind of ageism, discrimination, and ableism. Imagine that you studied and went through pilot training and got your license. Do you really believe that when you start solo flying that you, an inexperienced pilot, would be a safer pilot than someone like Bill Anders at 90? Experience, guile, and cunning count for far more than you can imagine. When my mother was getting older I looked at age related accident data. I apologize that I don't have the reference handy, but it was quite striking that teenagers are far more likely to have an accident than an elderly driver. I guess we should ban teenagers from driving also? Experience matters a great deal. How about if we find that recent immigrants are more likely to have an accident due to lack of familiarity with local driving regs? According to your logic we should make a law banning immigrants from driving. And on and on... As far as your comments about military service, even if we are anti-war (who isn't?), it is still possible to admire the hero who is willing to put their life on the line to defend their community. reply sethammons 6 hours agorootparentprevGet outta here with this ageist crap. I've know several 90+ year olds who are fully capable of independence and driving. My grandma was one of them. Hell, I watched a 93 year old deadlift 450lbs. While the likelihood of some 90 year old being too old for something is high, that means less when looking at an individual. reply jrootabega 5 hours agorootparentAgeism is not inherently wrong. This also deals with a public space, where idealism and liberties are already restricted. If you make individual exceptions based on close examination, then fine. But I think it's fair for observers to assume that this individual flying was a mistake. reply rizzom5000 4 hours agorootparentUsing the same logic you might say that people shouldn't be allowed to drive until they are 24. Statistically far more lives would have been saved yesterday if we'd only simply restrict more liberties based on age alone. reply jrootabega 3 hours agorootparentWorth discussing! You might also suggest that driving tests should be harder/longer/repeated, specialized based on different types of driving, and license privileges restricted based on years/miles safely driven. We already do it to truck drivers. Remember, most societies have already crossed over into treating driving on public infrastructure as a privilege, not a right/liberty. reply throwAGIway 4 hours agorootparentprevThe statistic would just move to 36 then. It's about experience with driving, not the age. reply lotsofpulp 6 hours agorootparentprevAnd 10 to 12 year olds can drive too. I wonder why governments of developed countries ban them from driving outright. Most places don’t even let 14 to 15 year olds drive. reply sethammons 5 hours agorootparentThere is a difference between having something and then losing it vs not having it yet. If you get a license to do a thing you should be able to keep doing it until you are deemed incapable and that will vary between people. Also, plenty of children those ages drive on private property, especially farms. There are kids doing backflip jumps on dirt bikes at those ages. Many of them are likely safer to be driving than others who are of \"prime\" age. I drove with a 30yo who terrified me with his dangerous lack of skill. People are variable in capacity and skill. The bureaucracy finds it more manageable to put policy in place than to determine individual skill. reply lotsofpulp 5 hours agorootparent>There is a difference between having something and then losing it vs not having it yet. I disagree. The reason for the policy would be the same. Probability of person of age x causing collision is too high. >The bureaucracy finds it more manageable to put policy in place than to determine individual skill. Yes, of course. Testing every single person all the time can get costly, and it may or may not be deemed worthwhile by a society (or whatever government leader). Obviously, when people are young, their faculties are getting better, so testing once is not unreasonable. But at advanced ages, faculties can degrade, and degrade at varying rates. For this scenario specifically, maybe it is not onerous to sufficiently test 90+ year olds that want to fly, since there are so few. However, since an airplane crash in an urban area has a high likelihood of causing damage to others, society does have an interest in controlling who is in the pilot's seat. reply INTPenis 7 hours agorootparentprevIdealistic thinking. Legends are just motivated people who are often at the right place, in the right time. It was never my intention to take anything away from this legend of a human. I'm just trying to bring the discussion back down to earth. No harm, or pun, intended. reply greenyoda 17 hours agoprev> the plane that crashed was a vintage Air Force T-34 Mentor... About the plane: \"The Beechcraft T-34 Mentor is an American propeller-driven, single-engined, military trainer aircraft derived from the Beechcraft Model 35 Bonanza.\" https://en.wikipedia.org/wiki/Beechcraft_T-34_Mentor reply consumer451 16 hours agoparentHere is a photo of Major Anders in his T-34, from 5 years ago. https://www.flickr.com/photos/dschultz742/33725755078 reply dtparr 13 hours agorootparentMajor General Anders, actually. O8 vs. O4. reply consumer451 13 hours agorootparentThank you for the correction. The man certainly deserves it. reply dclowd9901 14 hours agoparentprevMan what a cool plane. reply Simon_ORourke 48 minutes agoprevThat photograph is a mere footnote to the sheer audacity of Apollo 8 - first crewed flight of the Saturn V. - first crewed spacecraft to leave Earth's orbit. - first crewed spacecraft to enter Lunar orbit. - first humans to see the far side of the moon. - most watched (at the time) live TV broadcast. Those guys had balls of steel, and I'll be pouring one out on the stoop for Bill Anders and the crew later today in memory. reply rrrrrrrrrrrryan 18 hours agoprevWas he doing loops/flips intentionally, or did he lose control of the plane? Either way, what an absolute legend to be flying solo at his age. reply AmVess 16 hours agoparentIntentional loop. He entered it too fast and too low. On the descent, he was going too fast for his aircraft to have any type of control authority and he was a passenger at that point. The aircraft basically stalled out in a dive, and with no cohesive airflow over the control surfaces, the aircraft continued to stall to the point of impact. reply dmix 15 hours agorootparentThat's one hell of a way to go out, especially at 91. On brand for an astronaut. reply dh-g 7 hours agorootparentprevI don't believe the wing was in a stall in this situation. There would have been an abundance of airspeed over the wings. While performing a Split S the issue is that you are pulling too many G's and you and the sooner you level out the more you are pulling. reply jrootabega 2 hours agorootparentOver the wings in which direction, though? reply wszrfcbhujnikm 16 hours agorootparentprevWhat could be the reasons for this? Misread the altitude? Sudden wind? reply TylerE 15 hours agorootparentBarring a pre-crash sequence mechanical failure, this was pilot error. There is a safe speed called Va, or maneuvering speed. While most aircraft will have higher maximum allowed speeds, maneuvering speed is the most important figure for aerobatics because it's the maximum speed at which the airplane's flight controls can be used at full deflection (i.e. maximum effort) without exceeding the structural capabilities of the aircraft. What most likely happened was was a loss of situational awareness in the pre-loop dive, resulting in a steeper and faster dive than intended. reply rconti 13 hours agorootparentWouldn't be altitude since it was at sea level, but maybe air pressure due to temperature? But, at sea level, seems like he'd be cutting it way too close regardless. reply TylerE 13 hours agorootparentNo. That's just... such a marginal thing. It's like complaining your supercomputer melted because the CPU got 0.1C too hot. Like - it's technically possible, but if it's that close you were already way way way past safe and sane margins. reply cladopa 11 hours agorootparentprevWhen doing loops there are rapid changes of acceleration, specially on inverted loops. It can make you pass out easily, even if you are young. Being 91 years old, I would be extra careful. reply xoxxala 4 hours agoprevSpeaking about his famous Earthrise photograph, Anders said: \"We came all this way to explore the Moon, and the most important thing that we discovered was the Earth.\" reply cowsandmilk 16 hours agoprevWent kayaking with two of his sons in Costa Rica. They’re an adventurous bunch. reply spoonfeeder006 11 hours agoprevThis is a Baha'i Prayer I like to say for people who pass on to the next life Its hard to describe how I feel about it, its just so deep and profound... Consciousness itself, as apart from the behavior and computation that goes on in the brain, is a mystery of neuroscience. So maybe somehow it persists after we die? NDEs kinda shed light on that RIP up in the stars man https://www.bahaiprayers.io/prayer?id=204020 reply __m 4 hours agoparentJust because we can’t explain it yet doesn’t mean there is some voodoo involved reply trentnix 17 hours agoprevDied at 91 flying his jet. What a badass. Godspeed. reply jefftk 16 hours agoparentnit: the T-34 Mentor is a propellor plane reply kibwen 16 hours agorootparentWhen you've ridden a Saturn V, the difference between a jet engine and a prop engine becomes immaterial. reply jefftk 16 hours agorootparentI'd be surprised to see a pilot endorse that reply BenFranklin100 15 hours agorootparentDevelopers are such on-the-spectrum nitpickers. I guess that is what makes them good at their jobs and such unenjoyable cocktail party companions. reply pfannkuchen 12 hours agorootparentIs it even a nitpick in this case? It would have been substantially more badass to die flying a jet at 90. If it's relevant to the point I don't see how it's a nitpick. Now picking on a particular model distinction or something like that I could get on board with. reply throwup238 5 hours agorootparentIt depends on what you mean by “jet.” There’s no way he’d be allowed to fly a fighter jet or anything else with a turbojet engine at this point in his life. The medical waiver he was on wouldn’t allow it. reply meat_machine 9 hours agorootparentprevso many fails in such a short response. Assuming someone's profession based on almost nothing, general stereotyping, armchair mental diagnosis, insult based on 'diagnosis' that's needless and honestly irrelevant. Reminds me of the common backhanded insult on reddit, \"you must be a blast at parties\" What kind of pilot would be taken seriously if they mix up such a basic aspect of professional knowledge? Jets and prop planes are very different beasts. I can't think of any job where you can just casually mix up different classes of objects and not eventually have it result in some significant failure. \"Why did you feed the mules and not the horses?\" \"Don't be so autistic. I bet you're a blast a parties\" \"Why did you give me cheeseburgers? The customer ordered plain burgers.\" \"Don't be so autistic. I bet you're a blast at parties\" Yes, being specific about the things you work with is generally a sign that someone is good at their job, but it generally doesn't have much to do with autism. But I guess being condescending is what makes a good cocktail party companion? reply BenFranklin100 54 minutes agorootparentYou must be a blast at parties. reply hiddencost 14 hours agorootparentprevSays the one who managed to insult autistic people and engineers at the same time? Many of the best partiers I know are on the spectrum. reply BenFranklin100 55 minutes agorootparentYou guys dress poorly too. reply RobRivera 16 hours agorootparentprevDare I bite: Why? reply omoikane 15 hours agorootparentOnce you have ridden a rocket, everything else seems slow: https://xkcd.com/1701/ reply MobiusHorizons 16 hours agorootparentprevTurboprop, I guess you are both basically right reply mikepavone 13 hours agorootparentOnly the T34C is a turboprop. It appears Anders had a T34A which is equipped with a piston engine. reply SigmundA 5 hours agorootparentprevTurboprops are not jets, it is the wrong term. A turbine engine may be a jet engine or it may not in the case of a turboprop. Jet aircraft use jet propulsion not propeller propulsion. A jet gets significant thrust from exhaust gases, a turboprop gets almost none from exhaust gases, some turboprops actually are reversed intake in the rear pushing exhaust out the front like the PT6. Turbofans are considered jet propulsion as the both the exhaust gas and fan gas are pushing though an exhaust orifice rather than the fan being in open air as is the case with a turbo-prop. https://en.wikipedia.org/wiki/Jet_propulsion reply trentnix 3 hours agorootparentprevYou are correct and no offense taken at all. Thank you for the additional detail. reply barrenko 9 hours agoprevThis is a minor nitpick, as English is not my native language, but wouldn't it make sense to say \"died in\" more so than \"was killed in\"? The guy was not a passive observer by any means and should be paid respect. reply rafram 6 hours agoparentNo, “was killed in” is just as standard when you’re talking about things like plane crashes. reply narrator 3 hours agoprevI avoid getting in small planes since the statistics say they are as dangerous as riding motorcycles. reply satisfice 9 hours agoprevI once met Bill Anders on Orcas Island. Years ago I was making a video about describing a stone that I found on an Orcas beach, and I was consulting with geologists and biologists. I met at a local cafe with a marine biologist to get her opinion about barnacles on the stone. As we were talking, a man at the next table mentioned that he thought the stone was possibly volcanic. He also said he had a petrologist friend I should talk to. Nice coincidence. The guy said his name was something-something... I'm not good with names and pretty much forget them instantly. Later, I'm with the biologist on the beach, looking at barnacles when a P-51 Mustang comes screaming overhead on a low pass over the island. I lived on Orcas and I had never seen that before. \"Oh, that's Bill Anders,\" said the biologist. \"Remember, you met him at the Orcas Hotel cafe. He was on Apollo 8.\" That made a lot of sense. The Apollo astronauts were trained field geologists! I suspect his crash was a suicide. I come from a flying family and this is how pilots commonly fantasize about dying on their own terms. reply iamtheworstdev 5 hours agoparent> I suspect his crash was a suicide. I wouldn't count on that. Most of us wouldn't do that to the aviation world. Decreases plane availability, especially for something like a T-34 Mentor, increases insurance rates, increases FAA stance on already asinine policies, etc. occams razor - he misjudged his aerobatics. reply gcheong 4 hours agorootparentUnless you leave a note or tell someone, could the FAA determine it was intentional? Given the type of aircraft could a pilot plausibly commit suicide in a way that made it look like pilot error? reply cbxyp 7 hours agoprevGod blessed him to be able to die doing what he loved at the ripe old age of 91. Prayers for his family or foundation to be able to keep the flying heritage museum well maintained in his honor. reply avalys 16 hours agoprevSince there’s a lot of commenting about his age, I’ll remark (as a 36-year-old private pilot) that in my opinion an elderly man flying recreationally is actually much less hazardous to the general public than an elderly man driving a car. Flying is a specialized skill, but once you learn it it’s not especially difficult and requires less sustained focus, reflexes and reaction time than driving. It’s not as if there’s any chance you’ll run over a 6-year-old who jumps out in front of your plane at 7,500 feet. reply subhro 15 hours agoparent> Flying is a specialized skill, but once you learn it it’s not especially difficult and requires less sustained focus, reflexes and reaction time than driving. Respectfully disagree (as a 40-something year old aerobatic pilot) with the less sustained focus part, not the specialized skill part. reply filleduchaos 11 hours agorootparentI'm not a pilot, but I have a bit of a morbid fascination with aviation incidents, and I think I agree with both of you somewhat? The average flight deck is a hell of a lot more complicated than the average driver's seat in terms of things the operator needs to pay attention to, so I'd definitely say that flying requires more sustained focus. However, during routine flight (not counting taking off and landing, because I know those are very high workload periods?) pilots have a lot more time and space than drivers do to recover from a situation before it becomes a catastrophic failure, especially when it comes to danger to others outside the vehicle. So I'd also say that driving on average requires better reflexes and reaction times to prevent accidents. Take collisions for example; as GP alluded to, a driver's window to recognise and start responding to a developing problem is often mentioned in fractions of a second or a few whole seconds at best, because they can come out of practically nowhere. On the other hand, my impression of warning systems like TCAS and EGPWS is that the pilot has several seconds or more to start responding to the initial warning and still safely execute an avoidance/escape manoeuvre. reply mannykannot 7 hours agorootparentAviation contains a number of scenarios where pilots can (and do, not all that infrequently) slip from being in a safe situation to being in immediate danger without noticing the transition. Things like spatial disorientation and losing situational awareness (particularly in IMC), not taking into account a changing weather situation, not tracking fuel consumption, navigational errors... Technology is increasingly mitigating these risks, but as of now, they contribute to general aviation being significantly more risky, statistically, to its participants than driving, even when taking into account the prevalence of bad driving. On the other hand, it is considerably less dangerous to non-participants than driving is. reply filleduchaos 2 hours agorootparent> Aviation contains a number of scenarios where pilots can (and do, not all that infrequently) slip from being in a safe situation to being in immediate danger without noticing the transition. I am aware of this (and as I already said this is why piloting requires greater focus), but I don't see how that changes the fact that there actually is a transition that takes a heck of a lot longer than going from a completely safe (given all available information and proper operation) to a completely unsafe situation takes on the road. reply kragen 14 hours agoparentprevalso you're more likely to crash somewhere where you don't hit anybody else reply blackeyeblitzar 14 hours agoparentprevBut I read he was doing a loop right before the crash. Is the same true for acrobatics? reply Kalanos 6 hours agoprevI keep telling my friend not to fly small planes, but he is hooked. reply ls612 17 hours agoprevMan flys to the moon and back, and then 55 years later as a 91 year old dies flying a jet aircraft. Some are just built different. reply rmason 17 hours agoparentIn my opinion Chuck Yeager was the best pilot ever. A World War 2 ace who shot down 13 German planes. First to break the sound barrier. But Yeager took his last flight in a jet at 79 (with a copilot) and surrendered his pilots license at age 80. I am not taking anything away from William Anders but 91 might have been just too old to be responsibly flying a jet. reply mulmen 16 hours agorootparentThe T-34 is not a jet. reply AceJohnny2 16 hours agoparentprev> flying a jet aircraft Not a jet. The T-34 is a propeller aircraft, used for training. reply knodi123 16 hours agoparentprevLawrence of Arabia was at the forefront of so many skirmishes, but in the end he got killed driving a motorcycle back at home. reply TMWNN 16 hours agorootparentOne of the inventors of the motorcycle \"died in the saddle\" at the age of 72.reply TMWNN 18 hours agoprevI learned about this from Reddit . Title edited by me from \"WA\" to \"Washington State\". Besides making history as the first human expedition to the Moon, Apollo 8 produced not one, but two future CEOs of Fortune 500 companies: Anders (General Dynamics) and Frank Borman (Eastern Airlines). Jim Lovell \"merely\" survived Apollo 13. reply rconti 13 hours agoparentAs a WA native: happy for the edit of the ambiguous and US-centric acronym WA -> Washington. Also as a WA native: screw those DC assholes, why are we the only state that have to append \"state\" to our name? reply acheron 3 hours agorootparentShould have picked a different name then, Washington DC had already been around for a century. (Also, New York has to append “state” too.) reply mannykannot 7 hours agorootparentprevNew York calling... Disambiguation is sometimes necessary and, a bit more often, just a good idea. reply lamontcg 12 hours agorootparentprevThen sometimes Western Australia pops up randomly. reply defrost 11 hours agorootparenthttps://www.youtube.com/watch?v=Z6kTOVW7CXk reply pcl 10 hours agorootparentprevWell, at least you get representation in Congress! reply outcoldman 13 hours agoprevBlue skies. He died by doing what he loved. No better way to go. reply FpUser 16 hours agoprevWhat a life. And be able to pilot at 91 is nothing short of a miracle. Godspeed reply Sparkyte 13 hours agoprevLegend he was. reply buzzergfxkjkl 14 hours agoprevRIP legend. reply dzink 15 hours agoprevThey never mention if there was another person in his 2 person plane. What a life! reply kragen 14 hours agoprevthis graph took another step down today https://xkcd.com/893/ has anyone made an updated version? reply DennisP 5 hours agoparentI really like the popup text on that: \"The universe is probably littered with the one-planet graves of cultures which made the sensible economic decision that there's no good reason to go into space--each discovered, studied, and remembered by the ones who made the irrational decision.\" reply hashmash 13 hours agoparentprevWilliam Anders never walked on another world. reply kragen 7 hours agorootparentyou're right; thank you for the correction reply Dalewyn 17 hours agoprevRest in peace, I'm sad to hear this especially with so few Apollo astronauts still around. reply BSOhealth 18 hours agoprevAll respect, this guy is was ~91. I’m uncomfortable driving with my mom. As a total layperson, what sort of tests does a person have to pass annually(?) to maintain a pilot’s license? Or is this dude just so O.G. that he was bound to go out living his dream? reply parsimo2010 17 hours agoparentI’ve seen a few people mentioning medical certifications, but nobody has mentioned that 8 years ago the FAA passed a system called BasicMed which allows pilots to continue flying without getting a medical examination as long as they meet certain conditions. The plane must not exceed 6,000 lbs and must carry less than six passengers. You also can’t have failed your last medical exam. The plane he crashed had a maximum takeoff weight of 5,500 lbs and only carried two people. As long as he flew below 18,000 ft and 250 knots, he was legal (I’m not saying anything about whether he was healthy enough to fly). In all likelihood he hadn’t had a physical in 8 years. He still would have had to have passed one in his eighties, but he probably hadn’t had an FAA exam in a while. Source: I’m a private pilot and my dad in his 60s is as well, he flies on BasicMed because he hates going to the doc. Edit: someone actually had mentioned BasicMed a few minutes before I started typing, but I’ll leave my comment up. reply tjohns 17 hours agorootparentYou still need to get a physical (and sign off) from your primary doc every few years under BasicMed. Just not a full FAA flight physical. If someone has not had a documented physical at all in 8 years, they're not legal to fly. This is also a matter of public record, you can look up exactly what medical class he's operating under and when his last physical exam was on the FAA website. There no need to speculate. Edit: I just looked it up. He had his last BasicMed physical from his primary doc last year, so he was current. reply ominous_prime 6 hours agorootparentThe FAA only knows when you last took the BasicMed quiz and attested that you will follow the rules. Getting a physical, storing the form signed by the doctor, and maintaining a valid drivers license are up to the individual. reply ColinWright 9 hours agorootparentprevSpeaking with several astronauts, including Jim Lovell, Gen Tom Stafford, and TK Mattingly, my memory of those conversations is that all Apollo-era astronauts had and continue to have complete physicals from NASA every year. If that's the case he would probably have had feedback, even if the results aren't publicly available. My memory may be faulty ... I offer this in case someone knows better. reply p51-remorse 18 hours agoparentprevAt a minimum, flight reviews every two years. More applicable to a 90yo is keeping a medical. reply SoftTalker 15 hours agorootparentFor private flying, the medical is a lot less stringent (as I understand it.... I'm not a pilot). reply pkilgore 15 hours agorootparentYou're probably still healthier than most of the country if you have a Third Class. According to the FAA airman registry he was flying on BasicMed (less strict than third class, but comes with loss of certain privileges). WILLIAM ALISON ANDERS Airman opted-out of releasing address Medical Information: Medical Class: Third Medical Date: 10/2013 MUST HAVE AVAILABLE GLASSES FOR NEAR VISION. NOT VALID FOR ANY CLASS AFTER 10/31/2014. BasicMed Course Date: 3/22/2023 BasicMed CMEC Date: 3/22/2023 Certificates reply losteric 13 hours agorootparentprevand one can absolutely get examined by a “pilot’s doctors” reply p51-remorse 15 hours agorootparentprevEh… a third class medical still is highly sensitive to your medical history. See /r/flying for various tribulations even young people have gone through for relatively benign things. reply imoverclocked 18 hours agoparentprevPilots in the US need to pass a biennial flight review with a few hours of ground… or add a rating instead. It’s possible he was operating under BasicMed so he may not have needed a recent medical. reply ultrarunner 17 hours agorootparentHe absolutely was on BasicMed; his last medical was 11 years ago. His last BasicMed course was about a year ago. reply tjohns 17 hours agorootparentprevA BFR is not just ground... you have to demonstrate airborne skills as well And even with BasicMed, your primary doctor has to certify that you are fit to fly. It's less rigorous than a full FAA flight medical by design, but it's not a rubber stamp. (You're also limited to smaller aircraft that are unlikely to do much damage on the ground.) reply p51-remorse 18 hours agorootparentprev(But would have needed to self-certify health and maintain a valid driver’s license) reply imoverclocked 18 hours agorootparentAs in, “yup, I’m feeling good enough to fly today” and then pass our nations highly rigorous driving tests :) I wouldn’t be surprised if he was in very good mental+physical condition though. The crash might have nothing to do with age. reply leetcrew 16 hours agoparentprevoverall, the bar for skills and medical is significantly higher for flying vs driving. the other comments do a good job addressing the specifics. it's worth keeping in mind that the sky is a big place. so is the ground when you're not driving a car. it's not a great idea to keep flying in your 90s, but it's extremely unlikely that anyone gets hurt who didn't choose to be in the plane. reply thfuran 16 hours agorootparentThough you still leave a big fucking mess for someone to deal with. reply colechristensen 18 hours agoparentprevHere's a brief guide https://www.faa.gov/ame_guide/standards \"Old guy crashes airplane\" is a somewhat common occurrence that leads to obvious question if they really should have passed their medical. There's a tendency to not want to be the one to say no, especially if you've known the doctor signing the forms for decades... or if you were a fricken astronaut. reply WorkerBee28474 17 hours agorootparentThe aircraft is unfortunately known for crashing without pilot error https://en.wikipedia.org/wiki/Beechcraft_T-34_Mentor#Civilia... reply tom_ 16 hours agorootparentAnd 91 year olds are unfortunately known for dying simply because they fell asleep. I hope to be 91 myself one day - nevertheless, I remain suspicious. reply TMWNN 16 hours agorootparent>I hope to be 91 myself one day From the Los Angeles Times, 1988 : >Woody Allen was once asked what he would like people to say about him 100 years from now. He said: \"I would like them to say, 'He looks good for his age.'\" reply darby_nine 17 hours agorootparentprevAt least with an airplane you're not much risk to others.... reply andrewinardeer 17 hours agorootparentSarcasm doesn't translate well via text. reply darby_nine 17 hours agorootparentThis wasn't sarcastic at all—any driver of a car is far more dangerous than one in a plane. 9/11 is essentially meaningless in the shadow of auto deaths (to provide a direct comparison). I can't get a firm number on number of plane fatalities in the US (or auto fatalities worldwide), but 9/11 alone would amount to about only 0.04% of total vehicle fatalities in the US since 2000. reply fargle 16 hours agorootparentif i live to be 90, i'd wish to die quietly in my sleep like my grandpa. not screaming in terror like his passengers. reply almostnormal 14 hours agorootparentBoth scenarios are unlikely. Most likely it will be a long time of being tortured by doctors trying everything in the book to squeeze a few more days of money from your insurance. reply pkilgore 14 hours agorootparentprevNo passengers. https://aviation-safety.net/wikibase/389197 reply colechristensen 17 hours agorootparentprevA very large proportion of private aviation accidents involve only the people in the aircraft. reply kube-system 16 hours agorootparentprevRoads concentrate traffic near other people. A vehicle running off the road is much more likely to hit something than a plane falling out of the sky. reply nvy 17 hours agoparentprevIt's an open secret in the aviation community that large numbers of aging boomers are medically unfit to fly but are able to maintain their medicals, for a variety of reasons. reply WhackyIdeas 16 hours agorootparentI personally don’t think that people that age should be driving even a car in public. Any time I am stuck behind a car driving slow, eg. doing 30 on a 60, it’s an old person. It’s dangerous, nearly seen so many accidents with people overtaking. But then again, if it’s someone’s own plane and there’s little risk to anyone but themself, then maybe fire in. But wow should the insurance be through the roof. reply PyWoody 16 hours agorootparentI try to be sympathetic to older drivers. I can't imagine what it's like to be 70+, have no immediate family or friends, but still be a half an hour from the closest grocery store. Until we properly take care of our elders, I don't know what else they can do. Meals On Wheels, et alia are saviours, imho. reply ultrarunner 13 hours agorootparentSame thing for children. One of the hardest things to watch as a parent is kids who are utterly trapped by urban hell infrastructure. Society doesn't treat people without cars well at all. reply SoftTalker 13 hours agorootparentprevMy wife's grandfather drove like a bat out of hell. He wasn't safe either. reply BurningFrog 15 hours agorootparentprevAnother reason self driving cars will be one of the greatest inventions in our lifetimes! reply ehnto 13 hours agorootparentA bandaid to a society being built on car reliance. Even as a fit and healthy person with a car, getting anywhere in that kind of city is such a chore. reply glenstein 17 hours agorootparentprevIs there any more you can say about (1) how you know this and/or (2) whether there are reports or books that talk about this at all? reply parsimo2010 17 hours agorootparentThis is the main way: https://www.faa.gov/licenses_certificates/airmen_certificati... Lots of old pilots in the general aviation community are on BasicMed. reply sokoloff 11 hours agorootparentFAA studied the results of BasicMed and found no statistically significant differences in crash rate between BasicMed and FAA/AME issued physicals. https://www.faa.gov/sites/faa.gov/files/data_research/resear... reply nvy 16 hours agorootparentprevI doubt there are reports. Such is the nature of open secrets. Once they're reported in an official fashion they cease to be \"secret\" and regulators' hands are forced. reply glenstein 5 hours agorootparentSo you have no personal connection and no knowledge of any particular reports. That doesn't make you wrong, but surely you can understand how reading this and not knowing what you know, this raises every possible red flag for unsubstantiated internet speculation. reply tgtaptarget 15 hours agoprev [–] Quite a career... Almost sounds fake reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Retired Apollo 8 astronaut William Anders died in a plane crash near the San Juan Islands, Washington, on June 7, 2024, while piloting his vintage Air Force T-34 Mentor.",
      "Anders was part of the historic Apollo 8 mission, which captured the iconic \"Earthrise\" photo, and had a distinguished career in both the Air Force Reserves and as chairman and CEO of General Dynamics.",
      "He is survived by his wife, six children, and 13 grandchildren, and was also the founder of the Anders Foundation and the Heritage Flight Museum."
    ],
    "commentSummary": [
      "Apollo 8 astronaut William Anders, known for the iconic \"Earthrise\" photo, was involved in a plane crash in Washington, sparking discussions on various topics.",
      "Key points include the cultural impact of the \"Earthrise\" photo, the balance between pursuing passions and safety, and the FAA's BasicMed program, which allows older pilots to fly with less frequent medical exams.",
      "The debate also covers the regulation of public spaces, age-related restrictions on activities like flying, and the relative dangers of flying versus driving."
    ],
    "points": 401,
    "commentCount": 202,
    "retryCount": 0,
    "time": 1717805795
  },
  {
    "id": 40613287,
    "title": "Debunking Myths: The True Role of PID 0 in Unix Systems",
    "originLink": "https://blog.dave.tf/post/linux-pid0/",
    "originBody": "Written by David Anderson on June 5, 2024 What is PID 0? I get nerd-sniped a lot. People offhandedly ask something innocent, and I lose the next several hours (or in this case, days) comprehensively figuring out the answer. Usually this ends up in a rant thread on mastodon or in some private chat group or other. But for once I have the energy to write one up for the blog. Today’s innocent question: Is there a reason UIDs start at 0 but PIDs start at 1? The very short version: Unix PIDs do start at 0! PID 0 just isn’t shown to userspace through traditional APIs. PID 0 starts the kernel, then retires to a quiet life of helping a bit with process scheduling and power management. Also the entire web is mostly wrong about PID 0, because of one sentence on Wikipedia from 16 years ago. There’s a slightly longer short version right at the end, or you can stick with me for the extremely long middle bit! But surely you could just google what PID 0 is, right? Why am I even publishing this? The internet is wrong At time of writing, if you go ask the web about PID 0, you’ll get a mix of incorrect and misleading information, and almost no correct answers. After figuring out the truth, I asked Google, Bing, DuckDuckGo and Kagi what PID 0 is on linux. I looked through the top 20 results for each, as well as whatever knowledge boxes and AI word salads they organically gave me. That’s 2 pages of results on Google, for reference. All of them failed to produce a fully correct answer. Most had a single partially correct answer somewhere in the first 20 results, but never near the top or showcased. DDG did best, with the partially correct answer at number 4. Google did the worst, no correct answer at all. And in any case, the incorrect answers were so prevalent and consistent with each other that you wouldn’t believe the one correct site anyway. The top-2 results on all engines were identical, interestingly: a stackoverflow answer that is wrong, and a spammy looking site that seems to have embraced LLM slop, because partway through failing to explain PID 0 it randomly shifts to talking about PID loops, from control system theory, before snapping out of it a paragraph later and going back to Unix PIDs. Going directly to the source of the LLM slop fared slightly better, on account of them having stolen from books as well as the web, but they still make shit up in the usual amount. I was able to get a correct answer though, using the classic prompting technique of already knowing the answer and retrying until I got good RNG. If we set aside the few entirely wrong answers (“there is no PID 0”, “it launches init then exits”, “it’s part of systemd”, “it’s the entire kernel”, “it spins in an infinite loop and nothing else”), the most common answer follows a single theme: PID 0 has something to do with paging, or swap space, virtual memory management in some way. This theme comes straight from, where else? Wikipedia’s article on PIDs, which said: There are two tasks with specially distinguished process IDs: swapper or sched has process ID 0 and is responsible for paging, and is actually part of the kernel rather than a normal user-mode process. Process ID 1 is usually the init process primarily responsible for starting and shutting down the system. That text has been on Wikipedia for 16 years, and in that time has been quoted, paraphrased and distorted across the web to the point that it’s displaced the truth. It’s a pretty funny dynamic, and also a bit sad, given the source code for Linux and the BSDs is right there, you can just check. (Later note: after I published this, someone went and updated the article to have the correct information. The link above takes you to the old version so that the rest of this explanation still makes sense, but at time of writing this update the current version of the PID article is accurate) To explain why Wikipedia was inaccurate here, we need to take a little history lesson. The history of PID 0 in Unix As I said in the opening TLDR, PID 0 does some scheduling and power management, and no paging. It’s what the scheduler runs when it has nothing else for a CPU core to do. The exact implementation obviously varies across kernels and versions, but all the ones I inspected follow the same broad pattern: when PID 0 gets to run, it tries to find something else that could run in its place. Failing that, it puts the current CPU core to sleep until something else wakes it back up, and then loops around and starts over. Don’t take my word for it. Here’s do_idle in the Linux kernel, which is called in an infinite loop by PID 0. nohz_run_idle_balance tries to find alternate work. The while loop puts the core to sleep. After wakeup, schedule_idle lets the scheduler take over and put the core to work again. But maybe that’s just linux, I hear you say. Okay, here’s sched_idletd in the FreeBSD kernel. tdq_idled tries to steal runnable tasks from another core. Failing that, cpu_idle puts the core to sleep. Rinse, repeat. Okay sure but these are modern kernels, maybe it was different in the olden days? Okay, how about sched in 4.3BSD, from the summer of 1986? Computers are getting smaller and OSes more compact, so the scheduler and idle loop are now smushed into one routine. It tries to find something to schedule, and failing that sleeps until an external event wakes it back up. Incidentally, this is the origin of the vague allegation that PID0 is sometimes called “sched”: in earlier Unixes, the function that implements PID 0 is literally called sched. Still not sure? Maybe it’s just a weird BSD thing that leaked into Linux? Okay fine, here’s sched in Unix V4, the first known version of the Unix kernel written in C. Again the scheduler and idle loop are firmly intertwined, and there’s also some PDP-11 esoterics that are confusing to modern eyes, but the same bones are there: find a runnable process and switch to it, or idle and then try again. You could go further back. The source code for Unix V1 is out there, as well as an early prototype on PDP-7. However, it’s all in PDP assembler, uses some mnemonics that don’t seem to be listed in the surviving assembler references I could find, and the kernel’s structured a fair bit differently from the C version. That said, if you want to go digging, I believe the swap routine is the meat of the scheduler. And finally we get a clear idea of the root of the Wikipedia claim: in the earliest Unix implementation, the scheduler was sometimes nicknamed the “swapper.” It was called that because, now that we’re back at the beginning of Unix, one routine encompasses not only scheduling and idling, but also moving entire process memory images between the small core memory and secondary storage. Hard drives in this case, references in the kernel code as well as the Computer History wiki confirm that Bell Labs’s PDP-11 at the time ran an RS11 disk for the core OS and process swapping, and an RK03 for the user filesystem. (Sidebar! This is where the / vs. /usr split comes from. /usr was the part of early Unix stored on the RK03 disk, whereas the smaller root filesystem was on the RS11. Unless you’re still running on a PDP-11 with single RS11 and RK03 disks, a split /usr is vestigial and causes a variety of problems in early boot) So now the history is hopefully fairly clear. In the first Unix the world at large saw (Unix V5), entry zero in the process table initialized the kernel, then looped in the sched function, defined in slp.c. Those two names clearly telegraph the loop’s primary functions. However, the scheduling algorithm is quite simple at this point, and so almost all of sched’s code is concerned with swapping process images in and out of core memory in order to make scheduling happen. Thinking of this function as the “swapper” is reasonable, even if the original source code never uses that name. This essential structure survives to this day, with a lot more complications. Whole-process swapping gave way to demand paging, and so PID 0 stopped concerning itself with even a little memory management. As both the scheduling algorithms and the mechanics of idling a CPU became more complex, scheduling and idling were split out into separate pieces of code, and you end up with what we’ve had for at least two decades: the function implementing PID 0 has sched or idle in its name, and has a supporting role in doing those two things. Going back to the Wikipedia article, it seems the author of that edit wanted to write “swapping”, in the classic Unix V5 sense of swapping out whole processes as a consequence of scheduling. But the edit didn’t clarify that “swapping” was being used in an archaic sense that was likely to confuse the modern reader. Furthermore the edit wrote “paging” rather than “swapping”. I don’t know why, but my guess is that it’s because the canonical article for this general memory management concept is titled “Memory paging”, whereas “swapping” is a disambiguation page. In the moment of making the edit, I could definitely see myself swapping out for the seemingly preferred term. Unfortunately, in this particular context, replacing “swapping” with “paging” makes the sentence incorrect. And there it sat for 16 years, slowly leaking into the rest of the web as people quoted wikipedia at each other and paraphrased or elaborated further in the wrong direction. Okay, end of rant about how the web is turning to ash in our hands. It’d be nice if it didn’t, or at least it’d be nice if half the industry wasn’t breathlessly building ways to spray more petrol on what’s left. So it goes. Back to PID 0 now. Are those functions really PID 0? Above, I claim by fiat that the functions I’m linking to are PID 0. Tracing all of them would take a lot more words, but I’ll demonstrate the point on Linux and leave you to trace the others. I encourage you to do so! It’s remarkable how similar to each other different kernels are in this area, both across current OSes and over time. They’ve become more complex, but the family tree is still evident. Disclaimer, the Linux kernel is a very complex beast. I’m not going to walk through every single thing the kernel does before reaching do_idle. Think of this as a signposts to help orient you, not a comprehensive breakdown. This was written using the 6.9 kernel source code, so if you’re visiting from the future: hello! I hope your dilithium matrix is cycling well, and things may have changed. We begin! The bootloader jumps to the first instruction of kernel code. The first few steps from here are extremely specific to the CPU architecture and nearby chipset hardware. I’m going to skip that and begin at start_kernel, where the machine has been set up to a common baseline and architecture-independent kernel code takes over (albeit still assisted by arch-specific helpers). At this point, start_kernel is the only thing running on the machine (yes I know about ring minus 1 and SMM and so on, I said I was simplifying). On multicore systems, the bootloader/firmware/hardware arranges for a single CPU core to be running, called the bootstrap core. That single thread of execution is what we’re looking at, and it’s all we get until the kernel starts the other cores itself. The first thing to get called is set_task_stack_end_magic(&init_task). Well that looks relevant! It’s a very simple function that writes a magic number to the top of init_task’s stack space to detect overflows. init_task is statically defined in init_task.c, and the leading comment tells us it’s the first task. What’s a task though? task_struct, PIDs TIDs TGIDs and oh no Here we have to take a detour into something very confusing: the Linux kernel and its userspace disagree on the meaning of PID. In the kernel, the unit of running things is the task_struct. It represents one thread of execution, rather than a whole process. To the kernel, a PID identifies a task, not a process. task_struct.pid is the identifier for that one thread only. The kernel still needs to represent the concept of a userspace process somehow, but it’s not a nice crunchy data structure you can point at. Instead, threads are collected into “thread groups”, and groups are identified by a thread group identifier, or TGID. Userspace calls thread groups processes, and thus the kernel TGID is called the PID in userspace. To add confusion, these numbers are often the same. When a new thread group is created (e.g. when userspace runs fork()), the new thread is given a new thread ID, and that ID also becomes the new group’s TGID. So for single-threaded processes, kernel TID and TGID are identical, and asking either the kernel or userspace what this thing’s “PID” is would give you the same number. But that equivalence breaks once you spawn more threads: the new thread gets its own thread ID (which is what the kernel calls a PID), but inherits its parent’s thread group ID (which userspace calls a PID). To add even more confusion, the arrival of containers forces threads and processes to have multiple identities. The thing that’s PID 1 in a docker container is very much not the same as PID 1 outside the container. This is tracked in a separate pid struct, which keeps track of the different thread IDs a task_struct has, depending on which PID namespace is asking. I’m a userspace enjoyer by day, so when I started this rabbithole I interpreted “PID 0” in the question as an analog to the PID 1 I know, that /bin/init thing. But now the question is ambiguous! PID 0 could mean thread 0, or it could mean thread group 0. At the beginning of the kernel, the answer is fortunately easy: init_task represents PID 0 by everyone’s definition. It’s the thread with ID 0 (which is the PID according to the kernel), it’s the only thread in the group with ID 0 (which is the PID according to userspace), and no child PID namespaces exist yet, so there’s no other numbers for init_task to be. This will get muddier later on because thread group 0 is going to grow more threads, so in userspace terms we’ll have a PID 0 process that contains several threads, one of which has TID 0. In the rest of this post I’m going to try and say “task” or “thread” to mean a single thread of execution, the thing described by a task_struct; and “thread group” for the thing userspace would call a process. But it’s not just you, it’s terribly confusing. Okay, back to the code walk… The path to the idle task So, we know init_task is the PID 0 we’re looking for, albeit now it’s actually two different PID 0s at the same time because it’s the thread with ID 0 within the thread group with ID 0. How do we know that init_task describes the currently-executing CPU context? There’s a few things. We know we’re the only thread of execution currently happening, and init_task is described as the first task, aka the first thread. That sounds like us. It’s using init_stack as its stack, which is the stack we’re currently using (proving this requires digging into arch-specific code and gcc linker scripts, so I’m going to skip it, but have fun!). Its __state is TASK_RUNNING, which means it’s either running right now, or it’s runnable and waiting for CPU time. The kernel scheduler isn’t initialized yet, so there can’t really be any other runnable task at this point. This could be a setup for an elaborate trolling, but the evidence suggests that this init_task is us. And spoiler, we’re not being trolled, init_task is indeed the initial thread that executes start_kernel. At this point a lot of early kernel initialization happens. We can skip over all that for our purposes, and pick up at the call to sched_init. This function does basic initialization of the CPU scheduler’s data structures. A lot happens because the scheduler is a large beast, we’ll just peek at a couple of relevant lines: /* * The idle task doesn't need the kthread struct to * function, but it is dressed up as a per-CPU * kthread and thus needs to play the part if we want * to avoid special-casing it in code that deals with * per-CPU kthreads. */ WARN_ON(!set_kthread_struct(current)); /* * Make us the idle thread. Technically, schedule() * should not be called from this thread, however * somewhere below it might be, but because we are the * idle thread, we just pick up running again when this * runqueue becomes \"idle\". */ init_idle(current, smp_processor_id()); The first line describes the currently executing thread as “the idle task,” and mentions that it’s a special kernel thread: most kernel threads are run by kthreadd, which is task 2 and doesn’t exist yet. If you’re on linux, ps axgrep kthreadd will show that kthreadd is PID 2 in userspace, in addition to also being thread/task ID 2 in the kernel. The second line explicitly tells the scheduler that the currently running thread is the “idle thread” for the bootstrap CPU core. current is a pointer to the currently-running task_struct, which at this point in execution points to init_task. The implementation of current is another very architecture-specific piece of code, so I’m going to encourage you to go poke at it if curious, and move right along. Going back to start_kernel, the remaining initialization code doesn’t concern us, so we can skip straight to the call to rest_init. This function is short and sweet: it spawns task 1, which will become the init process in userspace; and task 2 for kthreadd, which manages all future kernel threads. We’ll be following the life of task 1, and although it will someday become PID 1 in userspace, to start it’ll run kernel_init. Not yet though. These new tasks exist and are known to the scheduler, but they’re not running yet because we haven’t asked the scheduler to do its thing yet. (caveat: in some kernel configurations, the scheduler may get a chance to switch to task 1 and 2 sooner than what I’m about to describe, but these first tasks are orchestrated such that the outcome is nearly identical.) Finally, rest_init calls cpu_startup_entry, which goes into an infinite loop of calling do_idle. And here we are, we’ve become the idle task on the bootstrap CPU core. On the first iteration, we don’t put the CPU to sleep because there are other runnable tasks (the two we just made). So we drop to the bottom of do_idle, and go into schedule_idle. The scheduler finally gets to run, and we switch away from task 0. kthreadd in task 2 isn’t terribly interesting, it does a little initialization then yields the CPU again until something else asks to create kernel threads. Let’s follow task 1 instead, it’s much more fun. Task 1 starts at kernel_init. This does even more kernel initialization, including bringing up all device drivers and mounting either the initramfs or the final root filesystem. And then, at last, it calls run_init_process to drop out of kernel mode and execute userspace’s init program. If init(1) asks the kernel who it is, it’ll be told that it is thread 1, which is part of thread group 1. Or thread 1 in PID 1, in the conventional userspace vocabulary. It was a surprise to me that task/pid 1 does a whole bunch of kernel work before if morphs into the familiar userspace process! A large chunk of what I think of as the kernel booting technically happens in PID 1, albeit in a very different looking universe to init(1) in userspace. Why not do those bits in task 0, like the earlier bits of init? PID 0 in multicore systems If you’ve been following carefully so far, you may be wondering about the other CPU cores. So far we’ve run entirely single-threaded, and when we initialized the scheduler we explicitly told it to pin task 0 to the bootstrap core. When does that change? The answer is, in task 1! The first thing kernel_init does is start up all other CPU cores. This means the bulk of the boot process that happens in kernel_init can make use of all available CPU power, rather than being stuck on a single thread. Starting CPU cores is quite intricate, but the exciting bit for our purposes is the call to smp_init. In turn, it calls fork_idle for each non-bootstrap core, creating a new idle thread and pinning it to that core. This is where the “PID 0” term gets muddy, because these new idle tasks have non-zero thread IDs, but they are still part of thread group 0. So, in userpace parlance, PID 0 is a process that contains one pinned thread per core, with thread 0 pinned to the bootstrap core. After that, smp_init runs bringup_nonboot_cpus, which does architecture-specific incantations to wake up the cores. As each core starts, it does a bit of arch-specific setup to make itself presentable, then runs cpu_startup_entry and do_idle, just like the bootstrap core did with task 0. All CPU cores are now alive and can run tasks, and kernel_init proceeds with the rest of boot. I’m bad at conclusions And that’s it! To summarize: PID 0 does exist, it’s the one thread that starts the kernel, provided by the bootstrap CPU core. PID 0 runs early kernel initialization, then becomes the bootstrap CPU core’s idle task, and plays a minor supporting role in scheduling and power management. PID 0 has done this, with different degrees of fanciness but the same broad strokes, since the first Unix kernels. You can go read the source code of many of them and see for yourself! That’s cool. PID 0 has nothing to do with memory management. In early Unix kernels it did some incidental memory management as part of process scheduling. PID 0 stopped doing that many decades ago. On Linux, “PID 0” is ambiguous because userspace and the kernel disagree on what a PID is. The kernel’s definition wins in practice for PID 0, because none of the entities that make up PID 0 are visible to userspace through the traditional Unix APIs. On multicore systems, every CPU core gets an idle thread. All those idle threads are part of thread group 0, which userspace would call PID 0. Thread ID 0, which is what the linux kernel calls PID 0, is as described above. Seemingly all Q&A websites on the internet function primarily by paraphrasing Wikipedia. This is made evident and awkward when Wikipedia accidentally makes the web repeat incorrect information for 16 years. Having worked all this out, I’d love to go edit the Wikipedia article and set the record straight… But would that count as “primary research”? Would the edit be reverted because it disagrees with most of the web? Does publishing this post mean editing wikipedia would now count as some variation of sockpuppeting or self-promotion? I don’t know, and I’ll try to figure it out. In the meantime, thanks for joining me on this chronicling of how I end up going on very large sidequests when presented with a short, odd questions. ← Top",
    "commentLink": "https://news.ycombinator.com/item?id=40613287",
    "commentBody": "What Is PID 0? (dave.tf)348 points by todsacerdoti 21 hours agohidepastfavorite59 comments caseyy 18 hours agoPeople are far overconfident online for what they know. The definitive and confident tone most online commenters speak in should probably only be spoken by experts in their own fields. I sometimes wonder if that is why LLMs can so confidently hallucinate — because they were trained on piles of overconfident human texts. It's an interesting thing to ponder. reply ultra_nick 18 hours agoparentPeople should be suspicious of statements regardless of tone. Conmen, hackers, cult members, job applicants, and AIs are all trying to trick people who only listen to tone. reply caseyy 18 hours agorootparentIt takes a lot of cognitive work to doubt and analyze everything. It's not really feasible, is it? reply autoexec 11 hours agorootparentIt's also not really necessary a lot of the time. If some random person online confidently says that the newest tesla uses an engine which contains ball bearings made in Indonesia by child slaves, I don't have to spend the time to doubt and analyze that because it doesn't impact me personally. I'd only ever need to take the time to double check that if I were going to buy a tesla or before I went and spread that information around as if it were fact. How true or false it is doesn't affect my life in any way. It can just be something a random person said online and I can treat it as such. Whenever you see information that sounds like it could be extremely important to you and your situation (and when being wrong could really hurt you) then no matter how authoritatively the information was delivered that's really when you should invest the time to verify it. Much of the time that investment is just a quick internet search anyway. reply ilc 17 hours agorootparentprevReview enough code, and even 2 + 2 can look sus. Where's the operator overload? ;) reply tinyhitman 8 hours agorootparentIn the garbage language that we dont use anymore. Right? Right!? :) reply smitty1e 3 hours agorootparentUnfortunately, due to budget cuts, we could not afford to vanquish all of the antiques in the architecture. We do have an infinite spell of Ben Gay, however.... reply smitty1e 23 minutes agorootparents/spell/supply/ reply kevindamm 4 hours agorootparentprevwell yeah but there's that legacy system, the replacement isn't ready for GA yet so... reply n4r9 9 hours agorootparentprevAs with many things, it becomes easier with practise. Also, you can pace accordingly: do I quickly read 10 articles today, or pick 2 and peruse them in depth? reply Bjartr 5 hours agorootparentprevSo safe the effort for the things that actually matter in your life. reply brightlancer 4 hours agoparentprevPeople want to listen to folks who are confident. And that sentence right there is an example of what I mean. I could write 10 words, 100 words or 1,000 words adding caveats to \"People want to listen to folks who are confident,\" but most people don't want to hear it and they'd tune out. But nine words, they'll listen to and use that, even if it's not right all the time. This isn't just an \"online\" issue. Anecdotally, I'd say it's in human nature. I've read plenty lamenting how men are (over)confident at work and garner (unwarranted) success relative to less confident women. And IME, confidence at work is pretty successful, if only because folks _try_ the confident suggestion. The person with a host of caveats might have a better suggestion, but they are less confident in their result, which folks sense and shy away from. And then there are casual situations (which most of \"online\" discourse is), where I regularly see strangers confidently offer one another advice which is usually received positively. A lot of the advice is wrong, but that doesn't really matter. > I sometimes wonder if that is why LLMs can so confidently hallucinate — because they were trained on piles of overconfident human texts. The LLMs that I have worked with have no concept of \"true\" and \"false\". They have no sense of confidence in what they sense. They _phrase_ it definitively because that's what we want. \"What is the capital of Australia.\" \"The capital of Australia is Timbuktu.\" The LLM doesn't know if that's true. It's just making a statement we asked it to make. reply maxrecursion 2 hours agorootparentThere is a reason con man is short for confidence man. People are extremely susceptible to someone who sounds confident. reply scottlamb 19 hours agoprevSome nice archaeology here, but I think it's important to say \"pid 0 is part of the [Linux] kernel\" (much less the further details) is only useful from a certain perspective—if you are debugging the kernel itself, using its more idiosyncratic interfaces like trace points within e.g. eBPF to examine the system as a whole, etc. From the perspective of a userspace process using standard APIs, I think a more useful approximation is \"pid 0 refers to myself\". It's what fork returns in the child. It's what you pass in to kill(2) to signal your own entire process group. Probably other variations too. reply hi-v-rocknroll 18 hours agoparentThere is no PID 0, it's a ABI convention just as using a negative PID is a convention to use the PGID instead like kill -9 -1. PIDs start at 1. The Linux kernel allocates PIDs to kernel threads that are \"processes\" without a separate address space running in a privileged mode with separate stacks, and generally ignore kill() signals. Command to get when a Linux box was started as opposed to just running uptime -s: ps -p 2 -o lstart= reply scottlamb 17 hours agorootparentOkay. I said approximation, and saying that the approximation is not completely true is not that interesting. reply wzdd 16 hours agorootparentEven in your own examples 0 means different things. It’s not an approximation, it’s wrong. reply echoangle 9 hours agorootparentBeing slightly wrong is kind of the thing that makes an approximation an approximation reply bvaldivielso 11 hours agorootparentprevAll models are wrong, some are useful. I found his explanation useful while knowing it was not correct reply helpfulContrib 10 hours agorootparentBut this statement is wrong and should not be propagated: \"pid 0 refers to myself\". pid 0 refers to the thing that is running 'myself', not to myself, itself. It is the thing which gave way to allow 'myself' to be executing in the current context. It is more accurate to say \"pid 0 is the source of cpu 'attention' which allows myself 'awareness'\", as it discovered I was not idle, and granted me power to proceed with processing .. reply mrits 5 hours agorootparentprevI think generalization would have been a better word but everyone understands what they meant reply userbinator 16 hours agoprevOn NT-based Windows, PID 0 is \"System Idle Process\" and is quite similar in function to the Linux one. On DOS-based Windows, IIRC there is no such thing as PID 0 since PIDs there are actually kernel memory pointers and thus very high: http://www.thescarms.com/VBImages/RunningProcs.gif -- instead, the idle loop is inside VMM32. reply therein 11 hours agoparentHaving written some code that did some DKOM in Windows, I'd say PID 4 comes closer. reply blueflow 14 hours agoprevHah. Another topic where the \"common knowledge\" is just utter garbage and actual research yields a different picture. That doesn't stop people from being convinced of it. The author of this post did the only correct thing and checked the kernel's source code, with is the authoritative source for this information. The conclusions at the end are a bit whacky. reply o11c 15 hours agoprevThere's a third use of PID 0, besides the already-mentioned \"idle\" and \"self\". On Linux, `getppid` returns 0 if the parent is a process in another PID namespace. reply bhasi 18 hours agoprevThis is very interesting. For those interested in following all the parts of early kernel booting that were out of scope for this article, please read this fantastic resource: https://0xax.gitbooks.io/linux-insides/content/ reply kalleboo 6 hours agoprevOn Darwin/macOS it's easy - kernel_task shows up with PID 0 right there in top! reply ykonstant 12 hours agoprevI can't help sharing one of the loveliest uses of `kill 0` I know: #!/bin/sh # # Usage: upto LIMIT COMMAND # Run COMMAND until LIMIT seconds have passed, then exit. # test \"$1\" -gt 0 || { printf '%s' \" Error: first argument must be a positive integer.\" exit 1 } sh -ic ' sleeptime=$1 shift exec 3>&1 2>&3 { \"$@\" >&3 kill 0 }{ sleep \"${sleeptime}\" kill 0 } ' sh \"$@\" reply eloh 3 hours agoprevIsn't it lovely how all these detailed code references are just a link away via GitHub? reply nickelpro 8 hours agoprevPID 0 on most academic Unixs used for teaching operating system design still swap out the entire process, and call into the memory subsystem (\"paging\") to do so. Linux is not the owner of the concept of PID 0. Saying that PID 0 frequently is involved with paging in and out memory is not incorrect. reply fanf2 1 hour agoparentI checked xv6 and it doesn’t swap out processes. What teaching OSs are you thinking of? reply rzzzt 24 minutes agorootparentMinix? https://github.com/0xffea/MINIX3/blob/c25ee5d4eac28560ea0caf... reply Taniwha 6 hours agoprevIt's interesting that the v4 code linked reuses pid 0 (the code that assigns pids simply does \"p->p_pid = ++mpid;\") - I vaguely remember having to fix that in kernels we were working on in the mid 80s reply thayne 14 hours agoprevIt seems like TID would be a better term for the in-kernal concept of a \"pid\", which could stand for \"task id\" or \"thread id\", whichever you prefer. And wouldn't be as confusing. reply lionkor 12 hours agoparentAnd afaik that is sometimes a thing via gettid() reply naleshniki 7 hours agoprevI agree with the author's complaint about the problems of Wikipedia being taken as authoritative on operating systems. I have seen all kinds of bizarre claims which are at odds with reality, but which, being described in a wikipedia page, are taken for gospel, and end up reproduced and sometimes embellished further. His article is probably quite a good discussion of what happens on Linux. It is over-reaching however if it is supposed - as it seems to be in the conlusions - to be talking about modern Unix-likes generally. PID 0 on NetBSD (and I suspect of Free, DragonFly, Open, etc, as well) simply means the kernel process. Here are a few of the threads that run under the kernel process in NetBSD: PID PPID CPU LID NLWP PRI NI VSZ RSS WCHAN STAT TTY LTIME COMMAND 0 0 0 118 106 123 0 0 28132 physiod DK- ? 0:00.00 [system] 0 0 0 117 106 125 0 0 28132 pooldrai DK- ? 0:00.00 [system] 0 0 0 116 106 124 0 0 28132 syncer DK- ? 0:00.00 [system] 0 0 0 115 106 126 0 0 28132 pgdaemon DK- ? 0:00.00 [system] These are all true and authentic threads, they just don't spend any time executing userland code. The work they carry out is, respectively: to carry out I/O to/from buffers in userland, because this may incur page faults and cannot therefore be done in a soft interrupt which has no thread context; to reclaim pages from the pool (slab) allocator; to lazily synchronise dirty buffers back to disk; and to carry out page replacement. All of these listed above carry out memory management, so it is not correct to say that PID 0 \"has nothing to do with memory management\" or that the Wikipedia article is wrong to discuss paging as a responsibility of PID 0. That's what pgdaemon is doing! There are many other threads that are part of the kernel process (or \"PID 0\") on NetBSD - modern kernels generally use a lot of them to carry out all sorts of tasks. A few others on NetBSD include worker thraeds for running asynchronous I/O completions and for processing various kinds of input in the networking stack. Illumos should also be considered. Looking at its PID 0: root 0 0 1 1 0 11:22:53 ? 0:02 sched We can see it is called sched. Why sched? This article talked about the historic role of PID 0 in process swapping. Process swapping is a scheduling problem (like a lot of problems in software). This is why swappers are traditionally called medium-term or memory schedulers. Illumos generally gives most groupings of kernel worker threads their own processes with their own PIDs, but one, called \"sched\", remains in PID 0, and its responsibility? Process swapping: https://github.com/illumos/illumos-gate/blob/579c23696ac6891... The Wikipedia article has now been hastily edited, and replaces a claim that was true only of certain Unixes other than Linux with a claim true only of certain Unixes including Linux. Is this an improvement? reply wizzwizz4 3 hours agoparent> I have seen all kinds of bizarre claims which are at odds with reality, but which, being described in a wikipedia page, are taken for gospel, and end up reproduced and sometimes embellished further. Editing Wikipedia is fun, but sometimes it is hard to know where to edit. Here's a simple process to find correctable errors! (1) Sneak onto your local university's campus. (2) Sit in any operating systems lecture. (3) Watch for nonsense in the slides. (4) Locate the relevant Wikipedia page. (5) Rewrite the entire two-page section around whatever was on that slide, because chances are it's all nonsense. reply amelius 5 hours agoprevWhen I type \"ps -aux\", why do I get all the information from other users too? Shouldn't this be private information by default? reply sva_ 5 hours agoparentYou can harden your system using hidepid. Chapter 4.1: https://www.kernel.org/doc/html/latest/filesystems/proc.html reply amelius 5 hours agorootparentMy point: why isn't this private __by default__? (Also, I fear that by setting this flag it will break a lot of tools that expect the flag to be 0) reply GranPC 5 hours agoparentprevIt's configurable - \"hidepid=1\" mount option on procfs. reply hxelk1 5 hours agorootparentCareful, this won't stop systemctl from showing the full process command line in its output. reply fragmede 8 hours agoprevWhy not just edit wikipedia to be correct? reply lelandfe 6 hours agoparent> I’d love to go edit the Wikipedia article and set the record straight… But would that count as “primary research”? Would the edit be reverted because it disagrees with most of the web? Does publishing this post mean editing wikipedia would now count as some variation of sockpuppeting or self-promotion? reply immibis 3 hours agorootparentWikipedia has now been edited, citing this blog post as a source. Him editing Wikipedia to include his own research is \"primary research\". Him editing using his own blog post as a a citation is presumably self-promotion. But someone else editing it in seems okay. reply Ferret7446 18 hours agoprevKind of clickbait/misleading title? The article even states that PID is a userspace concept. There is no PID 0. PIDs is how userspace refers to processes in syscalls. You can't refer to a PID 0 because `kill(0)` has a special meaning. But \"What is TGID 0?\" is much less catchy of a title. Hence, clickbait. reply singron 15 hours agoparentSpecifically, kill()ing pid 0 kills every process in the process group of the calling process. Pid 0 is more like a NULL pointer. You can put something in memory there, but a lot of systems will treat it as an invalid identifier for their own purposes. I had some ruby code that called kill(str.to_i) and killed every process when the string wasn't an integer, which is when I painfully found out that to_i returns 0 on invalid strings and kill(0) kills (potentially) a lot of processes. reply EatFlamingDeath 14 hours agoprevnext [10 more] [flagged] lionkor 12 hours agoparentinstall DarkReader and never be mad about this again reply Kwpolska 11 hours agorootparentAnd instead be mad at the extension's flakiness and random style changes. reply bowsamic 13 hours agoparentprevWhat? Why not? Many many websites have white backgrounds reply h4ch1 12 hours agorootparentdark mode cultists are truly a strange breed. personally i like neither dark nor light mode, but more of a sepia tone at a lower brightness that I feel is much more soft on my eyes. both dark and light mode feel way too harsh, both in terms of contrast and the usual color pallettes people often choose (bright whites [ #eee and above] and dark blacks [ #111 and below] ) reply kennu 12 hours agorootparentLack of automatic dark mode support on websites is very annoying at night, when you've turned dark mode on and everything else is dark, except that one website you just opened, and it now hurts your eyes or bothers other people in the bedroom. reply ptspts 11 hours agorootparentI never use dark mode on a laptop (because I hate it, it's a personal preference), not even at night. I don't bring a laptop to the bedroom if anyone else is there. reply kennu 11 hours agorootparentThat's why automatic dark mode on websites doesn't have any effect unless you turn on dark mode. It lets you choose. reply wszrfcbhujnikm 10 hours agorootparentprevWe need to put the UA back into UA and let people decide how they want sites to look. reply Dalewyn 12 hours agoparentprevWhite background is fine. What is not fine is gray text on white background. Sincerely, anyone who utilizes low contrast between text and background has utterly no respect for peoples' eyes. Yes, that includes Hacker News with downvoted comments. reply kazinator 5 hours agoprev [–] Wow, this entire article is completely off the mark. 0 is a special value in the POSIX kill function. It denotes every process in the process group of the caller. That's it. (OK, so because of that, a given OS based on POSIX can internally get away with using the value in some ways, to denote some process that nothing in user space would ever know about, let alone try to send a signal to.) Don't get nerd-sniped! Know the 15 second answer and move on. reply Karellen 4 hours agoparent [–] Maybe it was only used as the `all in progress group` sentinel because it was used by the kernel and could never be the pid of a userspace process? There's no reason that Unix couldn't have defined `PID_ALLPROCGRP = -2` instead. I mean, what do you think came first the development of Unix? The pid taken by the kernel thread used for scheduling, or a special value to a syscall when someone realised \"hey, maybe being able to kill the entire process group would be handy. What spare values do we have we can use to indicate that?\" (And remember, POSIX codified existing practice. Unices don't use pid 0 for a reason because POSIX says so; POSIX says so because that's what Unices did) reply kazinator 1 hour agorootparent [–] > Maybe it was only used as the `all in progress group` sentinel because it was used by the kernel Ah, but for that we have to long beyond/before Linux. kill(0, signal) existed before a line of Linux was written. Linux followed the existing POSIX spec which gave it PID 0 to do whatever. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "David Anderson's blog post from June 5, 2024, addresses misconceptions about Unix process IDs (PIDs) and user IDs (UIDs), particularly the role of PID 0.",
      "Contrary to popular belief, PID 0 is hidden from userspace and is responsible for kernel initialization, scheduling, and power management, not virtual memory management as some sources claim.",
      "Anderson provides historical context and details the Linux kernel's initialization process, emphasizing the complexities of process and thread identification and the distinction between kernel and userspace PIDs."
    ],
    "commentSummary": [
      "The discussion examines how overconfidence in online comments can influence AI language models and stresses the importance of skepticism towards confident statements.",
      "It covers technical topics like the role of PID 0 in operating systems, memory management, and process scheduling, highlighting the need for authoritative verification.",
      "Additional topics include challenges in editing Wikipedia, user interface preferences such as dark mode, and technical details about the POSIX kill function."
    ],
    "points": 348,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1717796578
  },
  {
    "id": 40613126,
    "title": "MIT's 6.1810 Course Teaches OS Engineering with Unix-like xv6 System",
    "originLink": "https://pdos.csail.mit.edu/6.828/2023/xv6.html",
    "originBody": "Toggle navigation 6.1810: Operating System Engineering Schedule Class Overview Course Structure 6.1810 2022 Labs Tools Guidance Lab Utilities Lab System calls Lab Page tables Lab Traps Lab Copy on-write Lab Multithreading Lab network driver Lab Lock Lab File system Lab mmap xv6 xv6 xv6 book References Piazza 2023 Xv6, a simple Unix-like teaching operating system Introduction Xv6 is a teaching operating system developed in the summer of 2006, which we ported xv6 to RISC-V for a new undergraduate class 6.1810. Xv6 sources and text The latest xv6 source and text are available via git clone https://github.com/mit-pdos/xv6-riscv.git and git clone https://github.com/mit-pdos/xv6-riscv-book.git Unix Version 6 xv6 is inspired by Unix V6 and by: Lions' Commentary on UNIX' 6th Edition, John Lions, Peer to Peer Communications; ISBN: 1-57398-013-7; 1st edition (June 14, 2000). An on-line version of the Lions commentary, and the source code. The v6 source code is also available online through The Unix Heritage Society. The following are useful to read the original code: The PDP11/40 Processor Handbook, Digital Equipment Corporation, 1972. A PDF (made from scanned images, and not text-searchable) A web-based version that is indexed by instruction name. Feedback If you are interested in using xv6 or have used xv6 in a course, we would love to hear from you. If there's anything that we can do to make xv6 easier to adopt, we'd like to hear about it. We'd also be interested to hear what worked well and what didn't. Russ Cox (rsc@swtch.com) Frans Kaashoek (kaashoek@mit.edu) Robert Morris (rtm@mit.edu) You can reach all of us at 61810-staff@lists.csail.mit.edu. Questions or comments regarding 6.1810? Send e-mail to the course staff at 61810-staff@lists.csail.mit.edu. Top // 6.1810 home // Last updated Wednesday, 16-Aug-2023 06:53:08 EDT",
    "commentLink": "https://news.ycombinator.com/item?id=40613126",
    "commentBody": "Xv6, a simple Unix-like teaching operating system (csail.mit.edu)217 points by arkj 21 hours agohidepastfavorite86 comments positive_ev 18 hours agoTook this class at MIT. 20/10 would recommend, especially for people who don't come from a systems background. The textbook is quite easy to understand and the labs are a very good check of your comprehension. Just maybe skip the network driver on the first go around :P reply imiric 17 hours agoparentThanks! Do you know if the course is taught online? I couldn't find any lecture recordings on OpenCourseWare. I did find this YouTube playlist about xv6[1], which looks very good, but it's not from MIT. [1]: https://www.youtube.com/playlist?list=PLbtzT1TYeoMhTPzyTZboW... reply apengwin 12 hours agorootparentThe lectures are here https://pdos.csail.mit.edu/6.S081/2020/schedule.html reply bombdailer 15 hours agoparentprevTook a class at UCI which copied much of the MIT class and dumbed it way down for us. Would recommend reply rustypotato 14 hours agoprevI also took the class that uses this OS at MIT. Absolutely fantastic. I was just browsing the class website today actually, and you can totally kinda take the class yourself. The site has all the lecture notes, the labs, and even a version of xv6 in a repo with branches for all the labs, along with instructions for getting it all working yourself. It's kinda amazing how open it is. The first lab: https://pdos.csail.mit.edu/6.1810/2023/labs/util.html I do plan to work through the whole thing myself again at some point soon. reply bgschulman31 20 hours agoprevMany of the projects in my OS class in college involved building on top of the xv6 operating system. I remember one of the projects was building a scheduler for xv. It was definitely a great way to learn about different pieces of an operating system! reply user20180120 11 hours agoprevPlan9 was/is used at a university is Spain for teaching reply asystole 7 hours agoparentBracing myself for the next generation of self-important monochrome tech ‘zines coming out of Spain reply anthk 1 hour agorootparentI wish, but most IT manuals everywhere are in English. But this is IT/CS, so using English at least to being able to read technical articles it's mandatory. Nothing too difficult, as my non-tech SO (native Spanish speaker) had read novels written in British English and to me that prosody and style it's hell compared to either an Stephen King or a Preston&Child one. reply mhw 10 hours agoprevHa, on first read of the title I thought this might be a new release of the venerable xv image viewer - http://www.trilon.com/xv/ reply hnthrowaway0328 15 hours agoprevI have ways wanted to understand the Windows NT kernel -- maybe the earlier versions as they are simpler. I heard the first version is close to VMS. Is it true? Is there any material on VMS? OpenVMS is open sourced but the version is too high. reply kelsey98765431 11 hours agoparentFor a good look at the development of the NT kernel, read the book show stopper from 1996. It is correct that Dave Cutler did lead a number of projects inside DEC including projects related to VMS, the only inheritance the Microsoft New Technology kernel received from VMS was spiritual at the design and architecture levels. Dave was already in the process of a major overhaul or successor to VMS when his team was shown the door at DEC and many of these visions made their way into windows at the cost of the robustness of the minicomputing established design patterns. Cutler saw the MSDOS team as rookie programmers writing themselves into spaghetti solutions for the wrong problems but papa gates had it locked up tight with the OEM contracting agreements so Bill paid him in blank checks to deal with the kids in the room and ship a real kernel to compete with what steve was cooking at NeXT. So no, NT is nothing at all like VMS from a featureset or likeness perspective, nothing at all from an implementation perspective (VMS had beautiful clean C standard library and compiler suite), but very much was the race to the bottom by the mini crowd to play games in the micro world. check dave plumbers interview with cutler on youtube for more color. reply hnthrowaway0328 5 hours agorootparentI am reading the book, now that you mentioned. I only reach the part when David was hired by Microsoft though. Actually I'm super interested in his earlier works in Dupont and DEC as they paved the way. I took him as an inspiration. His “What I really wanted to do was work on computers, not apply them to problems.” rings so true with me, and he as a natural leader also makes me look up to him. reply kelsey98765431 21 minutes agorootparentDifficult realm for me to investigate myself. I have found that better than any book is to pull old VMS images out and get them up on a SIMH/Vax emulator and poke around! It's a quite laborious process and documentation of the process is sparse, last time I ended up using the Computer History Museum remote access program to interact with ancient VMS. To actually learn how to use the thing I ended up diving deep into textfiles.com archives for references to VMS and got the hang of the basics enough to start learning via the online (built in) documentation. I would also point you towards usenet archives if you want to learn more about the development history of VMS, what what i have been able to piece together it was really rock solid and loved and quite a shame that \"open\"VMS is mostly just a legacy compatibility licensing agreement and the technology is in a bit of a glacial deep freeze. The fact that every file on the entire OS had version control - by default - before 1990... that blows me away and I feel like there's so many beautiful secrets to learn from this codebase. I always imagined it would be written in some abstract arcane language, when I learned it was in C i got a bit scared knowing what microsoft calls C has very little resemblance to how C is typically used on unix likes, and with the knowledge that many VAX admins dumped VMS for BSD I was quite afraid I may be out of my element. I was surprised to find the C library is essentially just posix, I felt pretty much completely at home on VMS compared to any version of windows I have had to write C for. Pleasant experience, shame what happened to it, wish there was more about its story told in an authoritative context like a book. If you stumble across anything nifty please feel free to share I may come back and read this read again someday. Cheers reply nickpeterson 5 hours agorootparentprev\"Work on computers, not apply them to problems\" feels like the kind of mentality that gets a lot of people into trouble :) reply hnthrowaway0328 4 hours agorootparentI think what he means is system programming, not application programming. But TBH I'm so sick of my DE job that I indeed don't care at all about business problems. Sure we all need them for jobs, hey but that doesn't mean I have to love them. Would that impede my career progression? Sure, but as long as I can get into a system programming without being too close to business, I'm happy for life. Other people can climb the greasy pole, good luck for them. reply pjmlp 14 hours agoparentprevWindows Internals book series, old MSTech Journal and DDJ issues, VMS manuals on digital archives. reply hnthrowaway0328 5 hours agorootparentThanks, I have a book about win32 programming, published 25 years ago but seems to be still relevant. I'll read the internals after I get some ideas about user space programming first. reply justin66 3 hours agoparentprevWindows 2000 source code is out there in the wild (I expect newer versions have been leaked as well) and has even been used as a teaching tool. reply hexagonwin 10 hours agoparentprevHuh? OpenVMS was open sourced? reply nialv7 18 hours agoprevWhy Unix v6? Why teach with a 50 years old design? I feel to teach the fundamentals of an operating system, i.e. scheduling, IPC, address space management, a microkernel design would be better. reply imiric 17 hours agoparentStudying precursor technologies to ones popular today is a great way to learn what led us to this point, what tradeoffs were made and why, and perhaps what we might've lost as well. Students can get a deeper appreciation for new technologies when they're eventually exposed to them. This can only broaden their horizons in their future careers. As someone who missed this part of history, I would love to have learned about it in college. reply mindwok 18 hours agoparentprevYou gotta walk before you can run. Xv6 is basic, but it’s a great intro to operating system fundamentals that can fit in a semester for people who’ve never seen these concepts before. reply chrsw 18 hours agoparentprevI'm guessing many professors don't choose Xv6 for their operating systems class because it's a great design. Some probably pick it because it's good enough, simple and easier to teach in a single semester where students are also taking other classes. Are you saying the microkernel design is not only better but also easier to teach? reply anta40 14 hours agorootparentPerhaps build simplicity is also an attractive point? Basically a rather simple Makefile, gcc, qemu, xorriso... I see lots of open source hobbyist OS projects require you to build your own GCC, which is not fun. Xv6 works with the standard gcc (provided by distro package manager). On macOS: just install homebrew-i386-elf-toolchain, and tweak some lines on the Makefile. Done. You are ready to build Xv6, which should take about a minute or less. reply halayli 17 hours agoparentprevVonn Neumann architecture is 80 yrs old. Why is it relevant how long a design is if it's still the most relevant and widely used one? The basic abstractions of unix v6 still holds to this day. The main difference between Microkernels and Monolithic is how address space get to be shared between userland and kernel. I don't see how microkernel design would be \"better\". Why teach a design that isn't widely used? reply darby_nine 17 hours agorootparentThe Vonn Neumann architecture does not expose the same structural flaws monolithic kernels do—namely, their (of course tendency in modern computing to be) massive size and their failure scenarios in the event of a problem. Old is not always a problem, but monolithic kernels face the same problems they did in the 80s. It's not surprising Apple is moving away from kernel drivers and into userspace functionality. reply halayli 12 hours agorootparentMy comment was in the context of which is better for learning purposes. You spun my comment and turned it into mono vs micro kernel. System Design is about trade offs. You conveniently say \"expose the same structural flaws monolithic kernels do\" and not mention anything about microkernels. System arch discussions are not about who \"wins\", but about trade offs. > but monolithic kernels face the same problems they did in the 80s Putting your lack of balance aside, what problems are you talking about specifically? Are you aware of how many new instructions have been added since the 80s that were designed specifically to address the shortcomings of monolithic kernels? Microkernels, even when resources were much scarcer back in the 1980s, still did not become popular. Both designs have their use cases. Micro and mono kernels have pros and cons but for learning purposes it makes more sense to teach about monolothic kernels since all popular operating systems follow this design. reply kragen 17 hours agorootparentprevapple started with mach, which was a microkernel, and linked basically all of the freebsd kernel into it, morphing it from a microkernel operating system into a monolithic operating system i agree that monolithic kernels are unpleasant and brittle, but unfortunately they don't actually seem to be obsolete reply pjmlp 14 hours agorootparentNeXT you mean. Additionally, Apple has a long term roadmap to fix that design decision, hence why they are killing one kernel subsystem at a time, moving them into userspace, with one year given for the developers to adopt each of them, after being made available as the new way. Finally, it is kind of ironic that systems that have doubled down on monolithic kernels, are now used to run an endless pile of containers and Kubernetes clusters. reply kragen 14 hours agorootparentwell said reply darby_nine 17 hours agorootparentprev> apple started with mach, which was a microkernel, and linked basically all of the freebsd kernel into it, morphing it from a microkernel operating system into a monolithic operating system The microkernel aspect of it had completely vanished by the time they hit the general public. > i agree that monolithic kernels are unpleasant and brittle, but unfortunately they don't actually seem to be obsolete Of course they aren't obsolete! The security in your phone depends directly on sel4, at least if you use an apple device. They just aren't relevant to most of the compute and most of the software you interact with today or in all of history. reply kragen 15 hours agorootparentyou seem to have thought i said 'unfortunately microkernels aren't obsolete', but that is the opposite of what i said reply userbinator 13 hours agorootparentprevIt's not surprising Apple is moving away from kernel drivers and into userspace functionality. That's largely a political decision because of Apple's totalitarianism. reply darby_nine 17 hours agoparentprevWhile microkernels play a vital role in our software ecosystem, most of the software anyone interacts with is not coordinated with a microkernel. Furthermore most of the software on the internet is not run by a microkernel, nor most of the software available on the internet. I suspect such a course would not prepare one well to either work with kernels or reason about the kernels you work with as a professional. reply pjmlp 14 hours agorootparentYou right, it is run by a pile of containers in Kubernetes clusters, on top of type 1 hypervisors. The irony. reply vkazanov 12 hours agorootparentAnd? What's wrong with k8s and containerized setups? Linux evolved numerous features over the years responding to server room challenges. Some of them look monolithic, others are decomposable, in any case linux became the default dev target platform for everything. Minix might be nice, but linux has won, and it was NEVER about os architecture. reply pjmlp 9 hours agorootparentBecause it is travesty of what is effectively a microkernel architecture. A free beer UNIX clone won, that is quite different than any technical advantages. Even Android does the same with Binder IPC, since Project Treble. reply vkazanov 8 hours agorootparentAndroid, SteamOS, WebOS and all the numerous Linux-based projects, mostly show that the world needs a stable target platform everybody can do a meaningful contribution to (and then make sure nobody steals the work later). Linux literally ate the world with its POSIX-compatible open-source proposition. I don't have a single device without Linux at home, and this includes a NAS, 5 notebooks, 1 PC, a handheld gaming console, my TV, a bunch of mobile phones, a washing machine. The world just couldn't care less if it is a microkernel, a hybrid or a monolithic kernel. Like you said, it's not about some boring technical advantages, and it never was. reply pjmlp 3 hours agorootparentJust wait until the Linux founding fathers are no longer around. Try to write Linux POSIX code for Android, WebOS, and ChromeOS apps, and see how many normies will buy your wonderfull app. Free beer ate the world, everyone likes free beer, even it is warm. reply anthk 1 hour agorootparentAlan Cox will do it fine, and the rest of the people have similar skills on GNU licensing and such. reply vkazanov 1 hour agorootparentprevYes, free as in beer and free as in freedom. No complicated licensing, code open for change, any scale, any use-case. Hard to compete against with all these \"license per working space\" or \"tcp stack not included\" or \"no code for you\" of the usual competitors. > Just wait until the Linux founding fathers are no longer around. Yes, things change all the time. People come and go. Just as companies do. reply kragen 17 hours agoparentpreva lot of people agree with you, which is why minix exists (though their source control system just fell offline this year), but none of windows nt, linux, os/360, and even really macos/ios are microkernel designs. sel4 and the other l4 variants are, and so is qnx, and linuxcnc runs linux under a microkernel, and xen is kind of a microkernel if you look at it funny, so we're definitely seeing significant mainstream use of microkernels, but it's not clear that that 50-year-old design is actually obsolete the way the pdp-11, the cray-1, and the system/370 are reply js8 15 hours agorootparentActually, z/OS (descendant of System/370) is more microkernel than Linux is. But the problem with microkernels is similar to the problem with microservices - you have to make the executive decisions somewhere, and that unfortunately ends up being the bulk of \"business logic\" that the OS does. In theory, I like the concept of functional core, imperative shell - the imperative shell provides various functions as a kind of APIs, and the functional core handles all the business logic that involves the connections between the APIs. (It's also sometimes called hexagonal architecture.) However, it is questionable whether it actually reduces complexity; I daresay it doesn't. Every interaction of different shell APIs (or even every interaction that serves a certain purpose) needs a controller in the core that makes decisions and mediates this interaction. So when you split it up, you end up with more bureaucracy (something needs to call these APIs in between all the services) which brings additional overhead, but it's not clear whether the system as a whole has actually become easier to understand. There might also be some benefit in terms of testability, but it's also unclear if it is all that helpful because most of the bugs will then move to the functional core making wrong decisions. reply kragen 15 hours agorootparenti admit to not being very familiar with the current version of os/360; can you elaborate? btw, when you say 'z/OS (descendant of System/370)', i think you are confusing hardware and software; system/370 was the hardware (obsolete), os/360 the software (sadly, not obsolete; later renamed os/370, mvs, and z/os in a series of increasingly desperate attempts to escape its reputation) generally the functional/imperative contrast centers on mutability: imperative style uses mutability, and functional style doesn't. is that what you mean? i'm not sure a functional core in the sense of 'mutation-free core' is a reasonable way to build a computer operating system, because limiting resource consumption and handling failures reliably are two central concerns for operating systems, and typically immutability makes them much more difficult. immutability does have a lot of uses in modern operating systems, but at least on current hardware, it makes more sense to me to build it as an functional shell around a mutable core than the other way around (the other aspect of the functional/imperative axis has to do with constructing new functions at runtime, passing them as arguments to subroutines, and returning them from subroutines: you do these things in functional programming, but not in imperative programming. i am at a loss how this could relate to what you're talking about at all.) it's not clear to me what https://web.archive.org/web/20070403130947/http://alistair.c... has to do with functional-core/imperative-shell or for that matter with operating system kernels. can you elaborate? for the most part operating systems design is an exercise in delegating as much as possible of those 'executive decisions' to userspace. 'mechanism, not policy' is the mantra for kernels and for system software in general, including things like device drivers and window servers. that way, you can use different policies in different parts of the system and change them over time without destabilizing the system. i feel like microkernels are generally better at this than monolithic kernels, and sel4 in particular takes this to the extreme reply js8 10 hours agorootparentAh, sorry for the inaccuracies. I mean MVS as a predecessor of z/OS, of course. What I mean by functional core/imperative shell is similar to what you mean by (the \"kernel\" is the \"imperative shell\" and the \"userspace\" is the \"functional core\"): \"for the most part operating systems design is an exercise in delegating as much as possible of those 'executive decisions' to userspace. 'mechanism, not policy' is the mantra for kernels and for system software in general, including things like device drivers and window servers\" And z/OS does that a lot, much more than Linux. On a typical z/OS, many of the functions that would be normally running inside Linux kernel are running in a separate address spaces, with limited authority. But the intractable problem IMHO is, to decide the policy, you still need the authority to do so (you need to be able to invoke the commands to the kernel), so you can still wreak havoc in the system. reply kragen 8 hours agorootparentlike what? reply js8 5 hours agorootparentFor example, on z/OS, the whole disk storage subsystem (SMS, but there is more) is separate from the MVS (kernel). Security is also externalized in RACF server (in fact there are alternate products from non-IBM vendors). You can run multiple TCP/IP stacks, which are also running in their own address spaces. Sysplex serialization has its own address space. All the address spaces involved in the operating system are coordinated through SVC or PC routines, which are like system calls, and scheduling of SRBs, which are kinda like kernel threads. I am not sure (although I am not aware of latest developments) if in Linux one can define a custom system call, like you can on z/OS. Or if you can schedule your own kernel thread from user space. You seem to know about MVS, yet we probably disagree on whether it is to be called a microkernel or not. I am not an OS expert, and I never did kernel-level programming for Linux or z/OS. But I did read Lister's Fundamentals of Operating Systems long time ago, and that book is somewhat based on what MVS (the actual kernel of z/OS) does. It was written before the whole microkernel debate, which AFAICT might be just an artifact of enormous variety and complexity of x86 hardware. So I would like to hear, in your opinion, what should have been different in MVS (or z/OS) for you to consider it a microkernel? reply kragen 51 minutes agorootparenti don't know enough about it to have an opinion. thanks! reply pjmlp 3 hours agorootparentprevWhile Windows and macOS aren't pure microkernels, they certainly are much more in architecture than pure UNIX clones will ever be. reply shawn_w 12 hours agorootparentprev>minix exists (though their source control system just fell offline this year), https://git.minix3.org/index.cgi seems online? reply kragen 46 minutes agorootparentthis started failing, i think, last week: : ~; git clone git://git.minix3.org/minix.git Cloning into 'minix'... fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. reply soraminazuki 3 hours agoparentprevWhy not? xv6 doesn't prevent you from learning about microkernels in any way. It's also a complete operating system with code that's friendly for beginners. reply monocasa 16 hours agoparentprevLion's Commentary on Unix is a classic tome on the subject, but unfortunately was illegal for quite some time. https://en.wikipedia.org/wiki/A_Commentary_on_the_UNIX_Opera... reply pjmlp 14 hours agorootparentThe way it was handled only proves the point UNIX would never had taken off outside Bell Labs, if AT&T was allowed to sell UNIX the moment it stopped being a toy project for playing games. reply monocasa 2 hours agorootparentWat reply pjmlp 2 hours agorootparentThe book was forbidden by AT&T from publishing, the moment AT&T got released from the ban to sell their research, in parallel to the BSD lawsuit. It kept being shared via piracy across universities, until AT&T and other commercial UNIX vendors, eventually allowed the book to be published again. https://en.wikipedia.org/wiki/A_Commentary_on_the_UNIX_Opera... Had the book never seen the light of the day, in the alternative universe of a commercial UNIX, universities wouldn't have adopted UNIX as research material to feed the next generation of UNIX clone makers. reply evil-olive 11 hours agoparentprev> Why teach with a 50 years old design? > a microkernel design would be better. why re-hash a 30 year old debate? [0] 0: https://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_deb... reply pjmlp 2 hours agorootparentI guess because Tanenbaum was right after all, instead of microkernel processes, we got containers and kubernetes pods. reply pjmlp 14 hours agoparentprevThat is how we end with students always cloning UNIX on their projects, instead of going alternative roots like Redox or SerenityOS. reply sham1 5 hours agorootparentThe irony here is that both SerenityOS and Redox are UNIX-like. Of course in their design, they're not purely like most other UNIXen, but they also don't stray away too far. reply pjmlp 3 hours agorootparentThey offer a POSIX like API on top, which isn't the same thing, as the key APIs, and overall system architecture, are something else. Also mostly because as it happens in most hobby projects, people keep wanting to replicate GNU due to the existing software, thus keeping the UNIX cycle alive. reply ori_b 1 hour agorootparentThe POSIX API comes with a large number of warts and constraints, and requires a great deal of specific machinery to support. reply z3phyr 51 minutes agorootparentprevOr maybe something like a lisp machine or a smalltalk os? reply linguae 4 minutes agorootparentI would LOVE to build a modern-day operating system using a high-level programming language, even if it were just a pedagogical toy. I love Unix, but it’s not (and shouldn’t be) the final word on OS design. In the meanwhile, Project Oberon from the late Niklaus Wirth (http://www.projectoberon.net/) is a good example of a pedagogical operating system (and programming language) that isn’t Unix. Project Oberon was heavily influenced by the Cedar and Mesa projects at Xerox PARC. reply anthk 10 hours agorootparentprevGNU/Hurd it's interesting. It replicates Unix, but it gives far more power to the user. reply pjmlp 9 hours agorootparentInteresting are systems like Xerox PARC Workstations (Mesa, Cedar, Smalltalk, Interlisp-D), ETHZ Oberon, Inferno, Apollo/Domain, Tru64, QNX. reply snvzz 5 hours agorootparentDo not forget Genode. reply anthk 8 hours agorootparentprevQNX it's another Unix in the end any the Photon GUI it's nothing odd to any KDE/Windows 2000 user. Smalltalk has issues on exporting your software to be run under a standalone way. On Interlisp, there's Mezzano, a Common Lisp OS, but it needs some tweaks and optimizations. Oberon UI wise it's the same as Acme under p9/9front/p9port. On Inferno, 9front and Go superseded it in some ideas. reply dailykoder 11 hours agoparentprevBecause it doesn't really matter. Processor design hasn't changed much in its fundamentals. KISS. Just KISS. reply tripdout 15 hours agoprevI used PintOS in my operating systems class last semester - wish there was a part 2 to that class where we go even more in depth! reply RACEWAR 18 hours agoprevWhat's a good way for autodidacts to fiddle through this? reply kragen 17 hours agoparentnext [3 more] [flagged] samatman 1 hour agorootparentWhile I also find the handle quite objectionable, I wouldn't say that \"racewar\" and \"genocide\" are words which can be freely exchanged without lack of meaning. A review of the contributors, well, contributions, suggests a 9front connection. They have a reputation for humor in very poor taste, but insofar as there's any sincerity to be found there, it isn't that of sincere genocide enjoyers. reply tolerance 16 hours agorootparentprevfair enough. (not trolling). reply opless 16 hours agoprevPlan 9 is also a pretty simple codebase to understand. reply bhdb33 13 hours agoparentOne has to respect some of the design decisions behind Plan 9. Per-process namespaces, binds, and treating everything as a file provides a certain level of elegance that just isn't seen in many other Unix-like OSes. reply renewiltord 20 hours agoprev [–] XINU is another simple teaching system. reply anonymousDan 19 hours agoparentWhat I would love is something similar that could boot on raspberry pi... reply dlachausse 18 hours agorootparentUltibo is pretty cool… https://ultibo.org/ It’s a bare metal Free Pascal environment for Raspberry Pi. reply MikeTheGreat 17 hours agorootparentDisclaimer: I've made LEDs blink with an Arduino and I think microcontrollers are cool, but I'm an embedded systems noob for sure :) I poked around the FAQ a bit and I'm kinda confused about this. Do you write bare-metal Pascal programs in this? I.e., do you write a Pascal program that uses Ultibo libraries to run without a separate operating system? How is the resulting program different from a unikernel? I think I'm mostly confused about why the IDE is bare-metal (why not write your Pascal programs in a normal environment and then run it bare metal on your RPi)D reply dlachausse 15 hours agorootparent> Do you write bare-metal Pascal programs in this? I.e., do you write a Pascal program that uses Ultibo libraries to run without a separate operating system? Yes, that's exactly how it works. > How is the resulting program different from a unikernel? I think that's essentially what Ultibo is. > I think I'm mostly confused about why the IDE is bare-metal (why not write your Pascal programs in a normal environment and then run it bare metal on your RPi)D You do run the IDE in a normal environment and then run it on your RPi. See below for a better description of how it works... https://ultibo.org/wiki/Getting_Started reply shrubble 18 hours agorootparentprevThere are versions for at least up to RPi 3: https://github.com/xinu-os/xinu/blob/master/docs/arm/rpi/Ras... reply renewiltord 18 hours agorootparentAmazing. I have to take a crack at this. reply tbrock 18 hours agorootparentprevhttps://github.com/patha454/xv6_pi_mp reply renewiltord 19 hours agorootparentprevXINU works on a Beaglebone Black it seems https://github.com/jarrocha/XinuBBB/tree/main reply bionsystem 8 hours agoparentprev [–] I like os161 from ops-class dot org too (Harvard course) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MIT's 6.1810: Operating System Engineering course utilizes xv6, a Unix-like teaching OS developed in 2006 and ported to RISC-V.",
      "The course covers system calls, page tables, traps, copy-on-write, multithreading, network drivers, locks, file systems, and mmap through various labs.",
      "The latest xv6 source and text are available on GitHub, and the course page was last updated on August 16, 2023."
    ],
    "commentSummary": [
      "The discussion highlights Xv6, a Unix-like OS from MIT, for its effectiveness in teaching operating system fundamentals.",
      "It explores the development of the Windows NT kernel, influenced by VMS, and debates monolithic versus microkernel designs.",
      "The thread also mentions alternative OS designs like SerenityOS, Redox, and educational tools such as PintOS, XINU, and Ultibo for Raspberry Pi, emphasizing the evolution and educational aspects of OS design."
    ],
    "points": 217,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1717795325
  },
  {
    "id": 40618079,
    "title": "Unveiling the Origins and Impact of the Internet's 'Backrooms' Legend",
    "originLink": "https://blog.archive.org/2024/06/01/the-backrooms-of-the-internet-archive/",
    "originBody": "The Backrooms of the Internet Archive Posted on June 1, 2024 by Jason Scott Like many bits of Internet Culture, this simple image of an empty series of rooms represents a deep-repressed or recently-remembered memory of a common Internet Legend, or it’s just a shot of nothing. If the answer is that it’s a shot of nothing, let’s get you up to speed. This image floated around message boards in the 2010s, posted with commentary or as a general use for a slightly off-putting photograph of a less-than-well-maintained location, and was, by most standards, rather indistinct. The internet, after all, is filled with odd images and weird drawings that cause a reaction, often after many different attempts to achieve the effect. Survivorship Bias for memes, one might say. So if one more image of an indistinct indoor landscape was out there, not much was going to happen of it. That changed in 2019, when the image was given a legend and history, made up out of the air, that it was a rare photograph of The Backrooms. The phrasing of the original declaration speaks for itself: “If you’re not careful and you noclip out of reality in the wrong areas, you’ll end up in the Backrooms, where it’s nothing but the stink of old moist carpet, the madness of mono-yellow, the endless background noise of fluorescent lights at maximum hum-buzz, and approximately six hundred million square miles of randomly segmented empty rooms to be trapped in God save you if you hear something wandering around nearby, because it sure as hell has heard you” If this writing strikes you as some sort of odd, rather dramatic addition to the image of a room, then you’re being introduced to creepypasta, or as some might call them, urban legends and campfire stories. It’s part of the overwhelming need for humans to tell tales that excite and frighten, to compose meaning or horror out of the darkness, and even the mundane. The concept of the “Backrooms” also touches on a very frequent theme of many different horror and science-fiction movies – that there are service tunnels and hard to access areas woven throughout life, known only to a special few. Movies such as The Matrix, The Adjustment Bureau, Us, Beyond the Walls, Dark City, The Cube, and many more have explored this theme – or used it as a jumping off point to tell another story. The difference, here, is nobody really knew where that very first image came from. For a very long time. This extended period of not finding the original source of the image left an unfinished tune, a half-written poem, about where it came from and what it meant. And the lack of information in the image as it showed up on these image boards seemed to ensure the mystery would never be found. So people filled in the blanks. A Subreddit called /r/backrooms, an extended web video series called Backrooms, and endless CGI models and creations meant to extend the legend and the origin story became years of effort by thousands to draw the missing pieces of a puzzle that was never a puzzle. A constantly shifting set of games with titles based off The Backrooms were created and presented for a willing and happy audience; it’d be unfair to choose one or even a few to highlight – there are dozens. All of them represent the efforts to bring you into a state of heightened fear or paranoia as you lurked through a series of dark hallways, overlit carpeted spaces, and a growing dread. There’s no question there was a huge audience for this, and it is sometimes thought that this entire legend brought mainstream attention to liminal spaces, a perception of the in-between geographies of less unsettling locations. It is now enjoying life as an aesthetic movement. Supporting this explosion of creativity and storytelling was the continued fact that nobody knew where the photograph came from. This situation, of a core image having a completely shadowy and unexplained origin, is arguably the foundation of its power. That changed, recently. This appears to be the origin of the Backrooms Photograph. In March 2003, there was a former furniture store called Rohner’s Home Furnishings in Oshkosh, Wisconsin whose second floor was being renovated by the (somewhat) new tenants, HobbyTown. Renovating the space from the sale of furniture to a new remote-controlled racing car track (among other aspects) meant pulling down partitions and ripping out carpet. This inspired taking photographs of the process, one of which, DSC001561.JPG, was the legendary “Back Rooms” image. 18 times in the last 20 years, crawlers affiliated with the Internet Archive moved through this page and grabbed portions of it, speculatively, to store for future research and reference. As the whole image was grabbed, reading the metadata of the original image reveals the date it was taken (June 12, 2002), and the camera used (a Sony Cyber-Shot model). The great unknown image, the unsettling photo of a mysterious place and time, was revealed. However the original, anonymous user stumbled onto this photograph, it appears it was taken from either the Wayback directly, or the Wayback Machine crawled the same site the user had found, and kept that webpage’s preservation for over 20 years. Emerging, Blinking, Into the Light Naturally, as news of the Backrooms being “found” travels throughout the world, responses have wildly ranged. For some, this is a proof that “with enough eyeballs, all problems are shallow”. While we might argue about the relative worth of a given effort, the fact that it is possible for word to travel about a mystery to the point of being solved means that the world is a hair less intimidating and scary. Our shared efforts and cooperation can find the answer to a seemingly impossible-to-answer question. The fact that an image with basically no information and a blurry set of components could be tracked down and revealed is a miracle. For others, the mystery being solved removes a little bit of magic and wonder from the world. It says that there’s no kayfabe, no holding of mystery in our hands without peeking further to tear out the secret. In this perspective, something special has been lost. But there’s another lesson as well. The Internet Archive’s crawlers moved through the pages of a hobby store multiple times over the years, capturing HTML, photographs, and time-stamping the process, with the equivalent care of an at-risk website, a politician on the national stage, or a legendary and obvious moment in history provided via a PDF file. This agnostic, wide-ranging crawl likely represented both the original source of the image, and a persistent, dependable URL to reference back to it, as thousands are doing at this very moment. This is the mission of the Wayback Machine – be the dependable, accessible connection to web history, and therefore all history. Give the Internet its Memory, which would otherwise be lost. If you mourn the loss of legend and mystery in our quest to keep the truth transparent, available and persistent, don’t worry – the process of internalizing and analyzing the image to give the Backrooms history its full and complete story has already begun: Here’s to the next mystery, and the next unsettling information being brought into the light and presented for the education, research and entertainment of the Internet, courtesy of the Wayback Machine. Posted in News1 Reply",
    "commentLink": "https://news.ycombinator.com/item?id=40618079",
    "commentBody": "The Backrooms of the Internet Archive (archive.org)204 points by passing 3 hours agohidepastfavorite31 comments Thorrez 2 hours ago>This agnostic, wide-ranging crawl likely represented both the original source of the image Why do they say it's likely that the person who first posted the image on the message board got the image from the Internet Archive? reply TZubiri 2 hours agoparentI thought the same thing. If you look at the crawled page, it's only one of like 20 images that survived. So either the crawl got lucky and saved the only relevant image, or there is survivor bias. Then again, the actual crawl might be triggered precisely because the image was linked. reply kwstas 2 hours agorootparentWhat do you mean there is survivorship bias? That the only image used is the one that survived? Or it survived because it was used? Something I noticed was that all other jpgs in this site have a lager number in the filename, for example: www.hobbytownoshkosh.com/Dsc00348.jpg So maybe the crawler that saved this webpage had a limit on how many suburls it would capture and it sorted by name and then stopped at around Dsc00161.jpg, which is the name of the image in question. Though there is a Dsc00164 that is lost so it seems kind of unlikely... reply adolph 47 minutes agorootparentThat might have been the 161st image taken by an old Sony camera. Cyber-shot model names use a DSC prefix, which is an initialism for \"Digital Still Camera\". https://en.wikipedia.org/wiki/Cyber-shot reply kwstas 15 minutes agorootparentThe filename for sure comes from the camera. My point was that the crawler stopped there and did not pick up the other images on the page because all of them have a higher number in the name and it stopped at an artificial number of sub urls reply jsjohnst 2 hours agoparentprevMy guess is because the image didn’t exist in other archives and it’s a very obscure site so why would someone have seen that? More probable they stumbled on something random like this in the wild or on Internet Archive? reply dooglius 58 minutes agorootparentWhy would someone have been looking at an very obscure site on the Internet Archive? Why is that more likely than looking at it on the web? reply jsjohnst 3 hours agoprevI remember seeing this before. Curious how / who found the original in the Wayback archives? Didn’t see that mentioned in the article. reply frob 2 hours agoparentHere's a YouTube video covering the discovery process. Ultimately, one person found it, but they were part of a wider team piecing together many parts of a puzzle, including outdated phone image numbering schema. I found it to be a worthwhile summary that doesn't really assume the viewer has much previous knowledge. https://youtu.be/-1EKIIM3ShI reply Chinjut 1 hour agoprevHow did people hunting for the origin of this image discover the random niche website preserved by the Internet Archive that this image happened to come from? reply beastoftheweast 34 minutes agoparentUp until last month, the earliest known post/repost of the Backrooms image was an archived 4chan post from 2018, but it was believed to have been taken in 2012 or earlier based on the filename. So people have been looking for earlier posts/reposts of the image for years in an effort to uncover its origin. During the recent successful search, the searchers trawled 4chan archives for early-2010s posts with similar image metadata to the 2018 Backrooms image copy. These archives were missing the original image files and thumbnails, but still retained some image metadata that could be filtered on (dimensions, image file md5s etc.) One of the searchers came up with a list of posts which might have originally included the image file, based on image metadata and context. Another searcher plugged the image md5 of one of these candidate posts (an April 2011 post recently added to an archive) into other archives, and hit on a post with a thumbnail matching the original Backrooms image from March 2011. At this point they'd finally found an earlier copy of the image, after years of searching. Soon after, one of the searchers plugged the filename of the March 2011 post into Twitter's search, and came up with a post from 2019 which included the physical address and a link to the image source (this Twitter user had already found the source before the search had really begun, but it had gone unremarked upon at the time). The website had been replaced with blogspam in the interim. A searcher plugged this domain into waybackmachine and found a page with the image and a full explanation (it was taken during the renovation of a commercial property in Wisconsin). Post from one of the searchers here: https://www.reddit.com/r/backrooms/comments/1d3pkif/how_the_... reply msephton 1 hour agoparentprevThe original URL of the photo was actually found on Twitter, where it had been posted in 2011. Wayback Machine was used only for the final confirmation. It's curious that this is not mentioned in the article, but I suppose it ruins the narrative. I read about the whole thing last week at 404media, via waxy blog, which is a much more comprehensive article: https://archive.is/sj846 reply oooyay 28 minutes agorootparentThat is actually kinda fascinating given that it's directly in opposition to this blog post. I wonder who's telling the truth? reply Jun8 3 hours agoprevIf you think that this would be right up SCP’s alley, you’d be wrong, it’s not included (yet). Here’s a Reddit discussion on the topic: https://www.reddit.com/r/TheBackrooms/comments/bs2zog/why_th.... The SCP 682 referred to here is, of course, the undestroyable creature: https://scp-wiki.wikidot.com/scp-682. reply jprete 3 hours agoprevI didn't know about the old meme, but the image made me immediately think of The Stanley Parable. Not surprising since TSP is probably a descendant of the meme. reply Waterluvian 2 hours agoparentStanley Parable outdates Backrooms by like 8 years. But they’re all basically about liminal spaces. reply worble 34 minutes agorootparentTSP isn't really about liminal space, it's about narrative decision making and the consequences of trying to account and develop for that in video games. I suppose you could say that it uses the liminal space of a barren office to achieve an awkward atmosphere that is meant to make you question everything about it, but that's a really small aspect of the game as a whole. reply Waterluvian 29 minutes agorootparentSure. But it can be about a lot of things. And almost the entirety of the game takes place in liminal spaces. reply fourteenfour 3 hours agoprevNow someone should make a game where you design indoor rc car tracks in the backrooms. reply TrianguloY 2 hours agoparentNot sure about design, but for driving them you have re*volt And, as expected, there is a backroom level: http://revoltzone.net/m/tracks/70429/Backrooms (There are probably others, this was the first result after a search) reply imglorp 2 hours agoparentprevSomeone should convert an unused warehouse or shopping mall into a real-world backroom maze escape game. reply Schiendelman 2 hours agorootparentThere should be more things in the world like Meow Wolf - this is an aspect of that in person exploration experience. I wonder if anyone has a list of that kind of space. reply textfiles 43 minutes agoprevSee you all in the backrooms reply exitb 2 hours agoprev [8 more] I love and appreciate the Wayback Machine, but using it is such a bittersweet experience. So many of the crawls are incomplete. I’ve managed to find pages that hosted content of interest to me, only to find that particular resource unavailable. And if it’s not on the Wayback Machine, it’s just gone forever. Feels like tracking an old friend down to their tombstone. reply samwillis 2 hours agoparentI quite like the fragility of it, it makes it more apparent that everything is transient. In a way I wish the IA had a half life on content, that it would decay over time, pages and images would be randomly deleted. Little by little it would rot and become nothing, a reflection of humanity. I suppose that's the internet itself... reply 627467 2 hours agorootparent> everything is transient I agree. Permanence should be tied to individual wills, not collective inertia. If you want a permanent thing, work for it, host it and publicize it reply andybak 1 hour agorootparentEvery future historian is hissing at you right now. So much of the past is completely opaque to us because of decay, intentional destruction and lack of interest. I think there's a moral imperative to preserve. reply samwillis 1 hour agorootparentThings that are important to society will naturally be preserved. I believe in the moral right to be forgotten. We cannot, and should not, preserve all of knowledge forever. Don't get me wrong, I love the internet archive, and the team behind it are incredible. As a resource it's very important to maintain and preserve. However, I'm sure that at some point, either due to the economics of it or through hardware failure, the content saved by the AI will begin to be lost. I don't see that as a bad thing. reply drsopp 1 hour agorootparentprevYes. Both content but also the technology to display this content. I put this on my personal web page 21 years ago: http://trondal.com/magisk/magic.html At the time (or maybe a few years before), clicking this button would show a dropdown menu linking to a bunch of web pages. Now, the button doesn't work anymore and I think most of the links go to missing content. reply PKop 1 hour agorootparentprevSort of describing entropy yes? All things will decay unless external energy is continually applied to the system to maintain an ordered state. reply WarOnPrivacy 1 hour agoparentprev [–] > Feels like tracking an old friend down to their tombstone. I did this yesterday. He went in 2016. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article \"The Backrooms of the Internet Archive\" by Jason Scott delves into the origins and cultural impact of the \"Backrooms\" image, an eerie photograph that became an internet legend.",
      "The image, which gained a backstory in 2019 about a vast, unsettling space, inspired creative content like subreddits, videos, and games focused on liminal spaces.",
      "The mystery of the image's origin was recently solved: it was taken in 2002 during renovations at a former furniture store in Oshkosh, Wisconsin, with the Internet Archive's Wayback Machine playing a key role in preserving its history."
    ],
    "commentSummary": [
      "Hacker News users are debating the origins of \"The Backrooms\" image, initially thought to be posted on a message board and possibly sourced from the Internet Archive.",
      "The discovery process included extensive searches through 4chan archives and metadata analysis, leading to a 2011 Twitter post confirmed by the Wayback Machine.",
      "The discussion highlights broader issues of digital preservation and the transient nature of online content."
    ],
    "points": 205,
    "commentCount": 31,
    "retryCount": 0,
    "time": 1717859873
  },
  {
    "id": 40615537,
    "title": "Replit's Legal Threats Force Intern to Take Down Open-Source Project, Later Reinstated",
    "originLink": "https://intuitiveexplanations.com/tech/replit/",
    "originBody": "How Replit used legal threats to kill my open-source project I think you should take it down and stop working on it. I'll be engaging our lawyers on Monday if it's still up by then. [...] We were a tiny company when you interned with us [...] Luckily we're bigger now, and crucially have a lot of money to pay for top lawyers now if we're forced to go that route. I received an official response from Replit and my open-source project will be back up soon; please see the bottom of the blog post for an update. The rest of the content here will remain as a historical artifact. Hi, my name is Radon. I graduated college last year and now work as a software engineer in DevOps/Infrastructure. In my free time, I also maintain a number of open-source projects. While I was in college, I interned at the startup Replit. This blog post is the story of how Replit is using legal threats and their venture-capital funding to bully me into shutting down an open-source project they don’t like. Table of contents What’s Replit? What was my open-source project? What happened when I shared my open-source project with Replit? What happened after Replit threatened to sue me? Is Replit right? Why would Replit do this? How did Replit respond to this blog post? So is Riju back up now? What’s Replit? Replit makes a webapp you can use to run code online in different programming languages. This is nothing new (just Google “run python online” for proof), so Replit’s value proposition is extra features like sharing your work, installing third-party packages, and hosting webapps. I worked for Replit in Summer 2019, where I was asked to rebuild Replit’s package management stack and make it open-source. If you like reading about tech stuff, here’s the post I wrote for Replit’s blog, and here’s the code on GitHub. I took a job elsewhere in Summer 2020, but still chatted with them occasionally by email when they reached out to tell me about something cool Replit had developed. What was my open-source project? The aspect of Replit that I really enjoyed was how it supported lots of different programming languages. (I wrote another blog post for Replit about how they do that.) That got me thinking: how many programming languages could you possibly cram into a single website? To explore that question, I put together my own little webapp that could run code online. After about a day, I had something that worked. (If you’re wondering why it was so fast—it turns out you only need 30 lines of code to let people run Python code in a webapp! This may be why there are so many websites for running Python online…) After it was working, I started adding as many different programming languages as I could. As you can see from this excerpt of my project’s version history, I got a little overexcited: languages --------- 2020-06-05 df9ba38 Initial commit0 2020-06-05 5e3a4a4 Install some packages into a Docker image 0 2020-06-05 e937c8f Simple Express server with \"Hello world\" 0 2020-06-06 0961498 Embed terminal on frontend app 0 2020-06-06 c66cf63 Embed Monaco editor on frontend 0 2020-06-06 27ab1f7 Add \"run\" button0 2020-06-06 f417858 You can run Python code now 1 2020-06-07 d543081 You can run many languages now 8 2020-06-07 e2a3e71 All languages 17 working now 17 2020-06-07 473c50c ALL THE LANGUAGES25 2020-06-08 3718315 even more languages33 2020-06-08 548c1c1 repl.it superiority!!38 2020-06-08 1ae424f More languages, we need all the languages 48 2020-06-09 c34ccf2 A lot more languages77 2020-06-09 846caf2 At this point the number of languages is absurd 79 I eventually ended up with 216 languages, including all 38 languages from Replit, all 100 languages from Yusuke Endoh’s “Quine Relay”, and a good deal more besides. You might ask: Why did I spend so much time adding obscure programming languages to a webapp nobody was going to use? Well, let me put it this way: Is it the weirdest 2020 hobby you’ve seen? What happened when I shared my open-source project with Replit? One day, I got an email from Replit letting me know about a new feature they released. I figured this was a good time to share my open-source project with them, in case they wanted to take inspiration from any of my work: At first, I got a positive response. But then, 30 minutes later, out of nowhere, Replit accused me of unethical behavior and stealing their design: Now, none of the ideas I used in my open-source project were “internal design decisions”: they’ve all been published publicly on Replit’s blog (I knew this because I’d been asked to write some of those blog posts during my internship). And my project also wasn’t any more of a Replit clone than any of the other websites on the first few pages of Google results for “run python online”, most of which look exactly the same: But I figured I might have missed something, so I asked for details: (The rest of this email is basically me repeating the previous paragraph of this article, but with a lot more technical details. You can read the whole email on Imgur, mirrored on the Internet Archive.) Unfortunately, Replit refused to provide any specifics on what they were saying I had done wrong, reiterated their previous statements, and threatened me with a lawsuit: And then just to put a cherry on top, Replit sent me another email reminding me that they just raised $20 million from their investors last month, and they weren’t afraid to use it against me. The “me” in question being one of their previous interns who just graduated from college a year ago, and who isn’t running any kind of commercial operation whatsoever. I’d like to point out two things about this email: The remark about “commits like this”—this is actually misleading. There’s only one commit in my project that mentions Replit, and it’s the one I already showed you earlier, from my third day of coding, when I’d just added all 38 languages that Replit supported, before moving onto the 178 other languages I wanted to add. The remark about me being a “demanding” intern—I’m not actually sure what this is meant to imply, especially since Replit had just tried to recruit me earlier that day (see the screenshot of their first email). But I’ll leave it alone because it’s not really relevant to the issue at hand. What happened after Replit threatened to sue me? Naturally, I took down my project right away, gave it some time for feelings to cool, and sent Replit an apology. I figured something might have been lost over email, so I asked to get on a call: Unfortunately, Replit ignored this email, so I sent them another one following up. This one got a response, but not the one I was hoping for: Just in case Replit didn’t understand that I wasn’t OK with this situation, I sent three follow-up emails explaining as such over the next few weeks, all of which were ignored. In other words, Replit stands by its threat: if I re-publish my open-source project, then they will sue me with “top lawyers”. Is Replit right? Replit claimed that my open-source project was: a clone of Replit based on their trade secrets (“internal design decisions”) unethical to build Let’s examine this claim, part by part: In developing my project, was I making a clone of Replit? In developing my project, did I make use of any trade secrets of Replit? Was it unethical for me to develop an open-source project that’s similar to Replit, after working for them? Questions 1 and 2 have a fair number of technical details, so I’ve put them in a separate post. The TL;DR is: My project isn’t any more similar to Replit than the 15 other (commercial!) ones you can find on Google by searching “run python online” or “online programming environment”. Every similarity between my project and Replit can be explained by looking only at GitHub repositories and blog posts that were published online by Replit itself, making them obviously not any kind of secret. Let’s address question 3 here: Q: Was it unethical for me to develop an open-source project that’s similar to Replit, after working for them? In my opinion, the answer to this question is no, for a number of reasons: Riju is entirely non-commercial. Unlike Replit, I didn’t seek funding from any source—advertising, donations, fundraising, subscriptions, whatever. I have no interest in running a business, and never really wanted Riju to become too popular, since I was the one paying the server bill. Riju wasn’t stealing customers from Replit. Based on my analytics data, there were 38 visits to Riju during the month of February. (Half of those were probably me.) Meanwhile, Replit had over 7 million users. There’s obviously no sense in which Riju was competing with Replit. Riju wasn’t built as a competitor to Replit, either. Since the architecture was limited to running on a single server, anyone could bring the entire system down just by typing in a fork bomb—and one of my friends did, just to see what would happen. (The system crashed.) If I were designing a product to compete with Replit, I certainly wouldn’t have picked an architecture that could only scale to toy-project size. Replit’s core value proposition isn’t letting you run code online (you can do this in dozens of places for free), it’s the features they offer on top of running code. Riju categorically lacked all of these features, including: having a user account, saving your work, sharing your work, publishing webapps, persistent workspaces, discussion forums, integration with GitHub, etc. etc. I had no bad intentions towards Replit when developing Riju, and wasn’t trying to hide anything. As proof of these claims, I offer the fact that I had the project public on my GitHub from the beginning, and the fact that Replit found out about the project because I openly shared it with them of my own volition, extending an offer for them to take inspiration from my work. Riju was never intended to be a product, it was intended to be a personal playground / art piece. As proof of this claim, I offer the fact that I spent dozens of hours adding languages like Hexagony and SNOBOL rather making it so you could save your work(!). I’m not a business person. I’m just an open-source dev who likes to build weird things for fun. (If you doubt my track record of building things that don’t make money, just check out the list on my website, and note the conspicuous absence of anything that’s ever made a cent of revenue.) I would never try to steal someone’s business after I worked with them. Hurting Replit was not my intent in working on Riju, and to accuse me otherwise—especially without asking a single clarifying question, and refusing all offers to have a discussion—shows a great deal of bad faith on the part of Replit, in my opinion. If you’d like to decide for yourself who is in the right, I’m happy to put all of the evidence out in the open (except the code, because Replit’s standing by its promise to sue me if I do). Again, I have a separate post with all the technical details. And you can also read all communications between me and Replit, in full and unabridged form, on Imgur, mirrored on the Internet Archive). (Technical details about Replit internals redacted, as well as any statement that could reveal such details indirectly.) Why would Replit do this? Replit’s stated ideals include: encouraging open-source development (e.g. open-sourcing parts of their technology, adding GitHub support to Replit; Replit’s CEO: “I owe my entire career to open-source”) giving back to the community (from the blog post Replit asked me to write: “we are migrating […] to do our part in improving the ecosystem for developers everywhere”; “Giving back to the community. The core of our language-agnostic package management is now open-source on GitHub”) making it easy to share and remix your creations (e.g. Replit’s CEO on learning to program: “I’d download projects related to what I wanted to build […] change & tinker with them, and get inspired”; he advises others to fork and remix too, and sells this philosophy as a differentiating feature of Replit) However, Replit’s actions in this case reveal hypocrisy: they say they encourage open-source development, but when my open-source project offended them, they shut it down with extreme prejudice they claim to be giving back to the community through their open-source and blog posts, but when I tried to use those ideas in a community project, they threatened to sue me they say they make it easy to share and remix your creations—but when I tried to remix Replit itself, I became a persona non grata In Replit’s emails to me, their threats were based on the fact that I had worked for them in the past. However, I believe this reasoning is a smokescreen. To see why, let’s take a look at some tweets that Replit’s CEO, Amjad, posted just after threatening me by email: Amjad later deleted these tweets because they proved controversial: In these tweets, Amjad points out that Athens Research was clearly inspired by another company, and argues that they should therefore be “ridiculed” and banned from receiving funding. Furthermore, he says: “I stand by what I said about copycats in general”, i.e. he disdains all people that he thinks are “copying” existing ones, not just the specific company in his tweet. There is a clear resemblance between Amjad’s comments on Athens Research and his legal threats towards my own project. He even used exactly the same word, “copycat”, in both. In the case of Athens Research, there was nothing Amjad could do to express his disdain besides denigrate them on Twitter. But in my case, since I had worked for Replit before, Amjad had an excuse to throw accusations my way—accusations that, if you aren’t familiar with the facts, sound like they could be legitimate. I’d also like to reiterate that the person Replit is threatening with “top lawyers” and “a lot of money” is a new grad with no company, no funding, and no commercial ambitions. If someone with an actual commercial enterprise were to offend Replit, I shudder to think what treatment they might receive. Radon Rosborough, June 2021 How did Replit respond to this blog post? After I posted the article in the morning, it was discussed extensively on Hacker News. Around 5pm, Amjad posted an apology on Hacker News, which has also been discussed. He also reached out to schedule a call, which I naturally agreed to: During the call, Amjad apologized for making legal threats, but reiterated that he felt I had made a clone of Replit and that I had acted unethically. Eventually we agreed to disagree, and he promised in writing that he was fine with my putting my project back up: In retrospect, I’m a little disappointed that Amjad: didn’t apologize for (or mention) publicly doubling down on his decision to threaten me, and didn’t post an update to that thread after the phone call didn’t apologize for (or mention) publicly retweeting an accusation that I “literally stole and published IP”, although he did at least delete the retweet didn’t apologize for (or mention) making a nebulous personal attack in writing that I was a “demanding intern” right after trying to hire me said in the phone call, right after “apologizing”, that he felt as if he had invited me into his house and I had betrayed his trust still refused to list any specific part of Replit he thought I had copied, even when I asked him for such details multiple times during the phone call, despite his continuing to claim both privately and publicly that I copied Replit unethically misquoted me in writing to make me look like I agreed with his accusations, right after reaching out to apologize for his behavior All in all, I think this could have gone better. Nonetheless, I’m happy that we were able to get the situation worked out amicably, and I look forward to moving on with my life—including putting Riju back up, after I can get things compiling again :) Peace. So is Riju back up now? Yes! Check it out at https://riju.codes/, and join the community on GitHub at https://github.com/raxod502/riju. I’d love to work on the project with you <3 (Please note that Riju is only available on IPv6-enabled networks due to the higher financial cost of supporting legacy protocols. If your network does not support IPv6 then please consider asking your network administrator or service provider to do their part in supporting modern internet standards. You can consider accessing Riju through a VPN as a workaround.) Mandatory legal notice: This blog post is maintained by Radian LLC.",
    "commentLink": "https://news.ycombinator.com/item?id=40615537",
    "commentBody": "Replit used legal threats to kill my open-source project (2021) (intuitiveexplanations.com)178 points by jaynpatel 13 hours agohidepastfavorite102 comments throwaway4good 11 hours ago\"Luckily we're bigger now, and crucially have a lot of money to pay for top lawyers now if we're forced to go that route.\" As a top dog CEO you may think that. But it is incredible stupid, arrogant, and immature to put that in writing when dealing with one of the little people. reply anonzzzies 10 hours agoparentThe ceo of replit is arrogant; just check his tweets, especially responses. reply raverbashing 8 hours agorootparentTrue Thanks but no thanks, my idea of work is not pursuing relentless work to help with somebody else's ego reply immibis 53 minutes agoparentprevNot to mention \"you were the most demanding intern we've ever had\" reply carrja99 7 hours agoparentprevYou should read that dudes Twitter account. It really can be something else sometimes. reply drivingmenuts 5 hours agoparentprevThe apology was a bit self-serving. Came across as something he had forced to do rather than something he needed or wanted to do. He pulled out the old hard-working kid-with-a-dream too soon. reply zer00eyz 13 hours agoprevNeeds a 2021 tag Last time on HN: https://news.ycombinator.com/item?id=27424195 (4022 points!!!) reply ak_111 10 hours agoparentIs there any reason why its been reposted now? Have Replit been in the news recently? reply saagarjha 11 hours agoparentprevAdded reply ayewo 11 hours agorootparent(Are you a HN mod now? :) ) Not clear from your reply whether you added it (as a mod) or you are announcing to the gp that the year has since been added as at the time of your comment (i.e. by the poster or a mod). reply saagarjha 11 hours agorootparent> you added it Yes > as a mod I consider adding a year to a post to be more of a janitorial service than moderation, similarly how some users can flag comments. But of course you can call it whatever you'd like reply ayewo 8 hours agorootparentWell, I certainly can flag comments but don't have any ability to adjust the title of a post as you can. In a way, that makes you a mod even if you don't agree with the moniker. reply pvg 5 hours agorootparentbut don't have any ability to adjust the title of a post as you can. I can't find the specific dang comment out of the zillions but you can just email hn@ycombinator.com if you are lusting after the power to fix the years in titles. reply jaynpatel 11 hours agoparentprevoh year sorry i forgot to add that. Thanks for pointing it out reply tomcam 12 hours agoprevAppears that OP, a former Replit intern, used Replit to create a site that might be construed as a Replit competitor. Replit responded with a heavy hand. I don’t care about Replit. But this just seems like a bad idea. reply ak_111 10 hours agoparentTbf Replit is an online IDE for full stack development, that means that almost any idea you work on Saas dev tooling could be construed as a competitor. reply throwaway290 9 hours agorootparentYes so you should keep that in mind if you sign documents specifically agreeing not to do this in the next 2 years... we may never know what the guy signed, but I assume interns at least sign NDAs. The fact that CEO is a (insert bad word) is also true, however. reply bitnasty 7 hours agorootparentIf NDAs were breached, that DEFINITELY would have been brought up in all of this. reply throwaway290 5 hours agorootparentTrue... reply Zak 7 hours agorootparentprevNoncompetes are illegal in California where Replit is based. As far as I can tell, they were illegal in 2021, and they've become more illegal since. reply throwaway290 5 hours agorootparentThat's nice. I wish more places worldwide followed. My contract has a noncompete:( reply yjftsjthsd-h 4 hours agorootparentI have excellent news: https://www.ftc.gov/news-events/news/press-releases/2024/04/... reply throwaway290 3 hours agorootparentNice, now I only need to move to the US. reply c0wb0yc0d3r 4 hours agorootparentprevEarlier this year the FTC banned noncompetes in the USA. https://www.ftc.gov/news-events/news/press-releases/2024/04/... reply michaelmrose 10 hours agoparentprevIt doesn't matter if he used replit they don't own the code you write with it and it doesn't matter if he used to work there they don't own former employees either. If you remove the irrelevant details it can be shortened to A personal created what could be construed as a replit competitor this seemed like a bad idea which only makes sense if it's a bar owned by the mafia. Furthermore they didn't respond \"with a heavy hand\" This statement carries the implication that some reaction was warranted and they overdid it. A manipulative sociopath reacted to a non-issue by using insane threats to silence someone on the off chance that he might become a legitimate competitor. Did you catch the part where he made it about him him growing up a \"struggling kid from Jordan\" whist still essentially asserting most of the same position. https://intuitiveexplanations.com/assets/amjad-hn-1.png This is basically a narcissist simulating a normal person territory. It's basically saying sorry you made the projected economic cost of my bad behavior negative I'm going to save face here. reply II2II 7 hours agorootparentOnce you create a product/project that is in some ways similar to that of a former employer, you have entered potential conflict-of-interest territory. If you can afford the time and legal expenses to argue that it is not a conflict of interest, that's fine. If you cannot, then you should think twice about what you are doing. Should it be that way? The answer is a definitive maybe. Part of the reason why the legal system exists is to resolve disputes like this. The real problem is the cost and time involved make it mean that both parties rarely have equal access to it, and that it is often used as a heavy handed threat by those who know they have better access to it (with the end result being to silence people rather than seek a just resolution). As for the personalities of the parties involved, that has nothing to do with it. You can be the biggest jerk in the world and be right, or the kindest person in the world and be wrong. reply _factor 6 hours agorootparentIf a former employee of mine uses proprietary information to build a competitor, I’d be upset. The key is what is classed as proprietary. You start barking up the software patent tree and you never know what the lawyers will throw back down. reply michaelmrose 1 hour agorootparentprevThe term conflict of interest is meaningless in context of someone who no longer works for you. There just can't be one. If you work for a McDonald's then and open a burger king next door there is no conflict your public goal was first to aid your employer and now it is to destroy them. It's not a dice roll to find out if you are infringing on IP. If you are aren't infringing you can discourage a lot of bullshit by simply ignoring their strongly worded letter. It costs 30 seconds to send an email but your lawyer needs something real to work with. reply tcfhgj 12 hours agoprev> Please note that Riju is only available on IPv6-enabled networks due to the higher financial cost of supporting legacy protocols. Like it. More people should do this reply skrebbel 11 hours agoparentThat line made me chuckle because if anything like that was on the original announcement, it should’ve become immediately obvious to the Replit CEO that this guy is not a threat. Excluding half the internet from your potential userbase isn’t much of a startup move. reply jolj 9 hours agorootparentand is also a window to the guy's psyche, which makes me believe the line where he was \"the most demanding intern\" they had reply dkarras 7 hours agoparentprevWhat is the limiting factor there? I don't understand. I assumed these programming languages were working in a browser (wrapped into wasm or some other VM) so everything was client side. Is that not the case? Are they running the language kernels in their servers? I don't understand what the \"cost\" here is. reply Volundr 4 hours agorootparentThey run server side. That's why his friend was able to take it down with a fork bomb. reply WarOnPrivacy 11 hours agoparentprev> Riju is only available on IPv6-enabled networks ... More people should do this Of the 12 wireline ISPs here, 2 support IPv6. One of the two is available to 2% of the customers; the other costs 50% more than IPv4-only. For the extra money you get 5% of the upload + much higher latency. I'm looking into starting my own ASN just to get IPv6 here. In the US there are millions of locations stuck with IPv4 only networks due to ISPs that are solidly committed to never supporting it. IPv6 evangelists don't give a meaningful crap about those millions - and are happy to push IPv6 rosiness in a way that denies their existence. Because of this, IPv6-only services can only ever get so far off the ground. An exciting service is less exciting when it's unreachable from point B. reply renewiltord 10 hours agorootparentYou can get a free 4 to 6 tunnel here https://tunnelbroker.net/ It's really not a big deal. reply 0x073 9 hours agorootparentNot sure if I fully understand how tunnelbroker works, but does the complete traffic get redirected over them? So it's as insecure as all these vpn services that sell your data. This is a big deal, for just getting access to ipv6. reply opheliate 8 hours agorootparentMuch of your traffic is probably passing through Hurricane Electric servers already, given their position on the backbone (https://he.net). reply 0x073 1 hour agorootparentok, didn't knew that it was a backbone. reply renewiltord 2 hours agorootparentprevTraceroute to various websites. You'll see that the IPs on the pathway are owned by companies that are neither you nor the guy you're accessing. It's how the Internet works at the network layer. You may find that some people are on every path. Your carrier, certainly, but often the first provider they're connected to. reply 0x073 1 hour agorootparentYes, didn't knew that this was a backbone. You'll see that the IPs on the pathway are owned by companies that are neither you nor the guy you're accessing. Yes, but you shouldn't add another one you didn't know (e.g. free vpn). reply Volundr 4 hours agorootparentprevIt depends how big a deal you consider Netflix. They block HE tunnels. reply js4ever 11 hours agoprevAnyone still using Replit? Or is it something from the past? reply wombat-man 7 hours agoparentI haven't used it in a while, but it was great for playing around with python ideas as someone who maybe doesn't want to set everything up on their own machine reply ak_111 10 hours agoparentprevAm actually interested in this question in a non-snarky way. Many years ago, I taught lots of programming workshops in academia and managing the student environments was always a pain. So when I heard of replit and similar tools it always seemed to me like a good solution for this problem. However, I was struck recently when I went back to teaching how little in roads it made in this space, out of 4 universities in the UK (cohorts of 100s) I saw hardly anyone using it or even heard of it. It seems the preferred option now is to just use google colab, which works great but doesn't give students the feel of a full-blown IDE. reply dave84 8 hours agorootparentThey messed up the pricing time and again sadly, then they made it free and now they killed the classroom product. reply IshKebab 7 hours agoparentprevI've used it occasionally. They provide some online compilers for languages that are hard to find elsewhere, e.g. TCL. reply desi_ninja 7 hours agoprevKid from Jordan was a typical PR speak to get sympathy even when he is acting like a bully reply ljf 12 hours agoprevImportant to read this first: https://intuitiveexplanations.com/tech/replit/#how-did-repli... reply snird 9 hours agoprevThe Replit CEO has proven himself time and time again to be.. this. I hope that every potential customer will consider the culture he cultivates. We don't need this in tech. reply pech0rin 7 hours agoprevNot sure why he thinks he is in the right here? I would be pissed too if an intern left and then made a website that was just copying the internal work. I love how he says with a straight face that he didnt use any of the code from replit when obviously as an intern he saw all the ideas and constructs. Its not like he had a mind wipe. I’m in a small minority on this site I’m sure but professionalism is important and this screams immaturity. reply Ray20 7 hours agoparent>but professionalism is important and this screams immaturity. Using knowledge that you have to create a competing product is professionalism, using Legal threats to eliminate competitors - is not. reply paulddraper 12 hours agoprevThis is a lot of drama about irrelevant stuff. The core questions are IP rights and non-compete. What agreement did the employee enter into concerning these, and to what extent is this project relevant. Excerpts and matters of fact. The rest is childish noise. reply LeonB 12 hours agoparentReplit didn’t make any specific claims about IP rights or non-compete (and if they did, the onus would be on them). When their behaviour was made public they immediately backed down and didn’t proceed with any legal fight. reply littlestymaar 12 hours agorootparentI'm not sure you can have non-compete close on an internship contract anyway (in my country you cannot for sure). reply paulddraper 7 hours agorootparentprevIDK if that is true or not. It could be. If that is true, that author should have just ignored it. reply ossm1db 12 hours agoparentprevnext [4 more] [flagged] dangysaurusx 12 hours agorootparentnext [4 more] [flagged] LeonB 12 hours agorootparentWho is “psychosaurusx”? reply mkl 12 hours agorootparentI think they're referring to sillysaurusx. I won't link to the thread, but I don't know what they mean by \"only thing of value\". reply LeonB 11 hours agorootparentThanks for the explanation. I kind of get it now. They made a sock puppet account, in order to make an accusation at someone - and deliberately obscured the name of the person they were insulting. That’s a kind of “dog-whistle” technique. Either they are genuinely scared of speaking out against this sillysaurusx person, or they know it’s an unfair accusation and they wouldn’t say it openly. It just struck me as a really out of place comment, a very odd way to act. And embedding dang’s username in their sock puppet account name? I get bad vibes from this one. reply coolThingsFirst 12 hours agoprevAnd the CEO was right, you can’t copy cat the idea of the place you worked at no matter how simple it is. It’s common sense - he did behave in an unethical way. reply bitnasty 7 hours agoparentThat’s like saying I can’t write my own hobby OS because I used to work for Microsoft. reply chii 12 hours agoparentprevi dont think that's unethical - provided that no copyright is violated. Ideas are not copyrightable, and surely they do not have a patent on sites like replit. reply rvnx 12 hours agorootparentIt can be unethical without being illegal. When I work for a company, I don't spin-off that company using corporate knowledge, I just find something else to do (and that's probably why I'm not rich :D), but it's the most elegant thing to do. Zuckerberg is a famous example of such behaviour. I think this Radon is talented too (good tech + doesn't wait for others to give permission + very interesting ideas), and what he did is probably okay-ish, a bit borderline but still on the ok-side (he seems more like a fan of Repl.it than anything). I just wouldn't go til the point where I complain about it publicly. reply consp 10 hours agorootparent> don't spin-off that company using corporate knowledge That is a very common way to do a spin off. Usually it involves some patents or non public knowledge and you make an agreement with the original company for it. But when it is all open there is nothing, legal or moral (in my opinion), from stopping you from making your own spinoff. Companies don't care about you, you shouldn't care about them. reply kwhitefoot 10 hours agorootparentprev> don't spin-off that company using corporate knowledge, If everyone followed this rule there would be no Fairchild and no Intel. reply ArdentAardvark 8 hours agorootparentThere'd be nothing. A lot of competitors have come about from people starting companies to compete in the same field. All of the modern gaming industry is basically based on disenfranchised game developers starting their own companies. reply Drakim 8 hours agorootparentprevCompanies want you hire you and for you to bring your existing knowledge, skills, and understanding to build a product. Then they want you to not use the knowledge, skills, and understanding to build a product when you aren't working for them. This is hypocritical and self-contradictory. They require you to do the very thing they don't want you to do, just as long as it's in their favor. reply immibis 0 minutes agorootparentEverything is subtle warfare. Act accordingly. Employers do what they think they can get away with to extract maximum value from you. If you are smart, you will do what you think you can get away with to extract maximum value from your employer, too. Playing fair when the other side doesn't is just forfeiting. ArdentAardvark 8 hours agorootparentprevI don't understand at all why this would be unethical. Maybe I'm working for a company making a product I have expertise for and I'm passionate about, but they're making decisions that I feel make it worse for users unnecessarily. I leave and start my own competing product to do it my own way that I consider to be the better way. This isn't unethical. This is the nature of all competition everywhere going back as far as anybody can remember. I've stolen nothing at all, so I'm not sure on what basis it would be unethical. And if it's a topic or industry I have expertise and knowledge of, why would I throw that all away just because I worked for a company where I used that expertise and knowledge? That's basically implying that we're all \"ethically\" subject to non-competes for the rest of our lives after working for a company making a particular kind of product. That's clearly and absolutely \"inelegant\", to use your phrasing. reply Brian_K_White 7 hours agorootparentprevIt's neither illegal nor unethical to open a bake shop after working for a bake shop, or even a single type of cookie shop, as long as it's not a solen private recipe. If the intern was under a no-compete, or stole any IP, this would be known and there would be nothing to talk about. reply coolThingsFirst 12 hours agorootparentprevLet's put it this way some CEO spent years finding a product market fit and they hire you - they pay you and let you have access to their internal conversations and ideas and you suddenly brainstorm a project with uncanny resemblance to what the company is making - that in my view is stealing IP and is very unethical and shady behavior. reply ArdentAardvark 8 hours agorootparentIt just isn't. You're allowed to make products that compete with products already on the market, even if you've worked for the company making that product. Unless there's specific IP that was stolen, I don't see how this is in any way unethical or shady. They hired you to develop that product, and you did. Nowhere in that contract is anything saying you can never use what you learned elsewhere. They'd need to pay you significantly more than what they paid you (which they won't). And there are great reasons why non-competes are basically invalid in most places. reply fragmede 8 hours agorootparent> Unless there's specific IP that was stolen, To wit, stealing trade secrets is recognized as an actual crime, and got someone 8 years of jail for trying to sell the formula for Coca-cola to Pepsi. reply michaelmrose 10 hours agorootparentprevWhat IP did they steal. Please be specific. reply Propelloni 10 hours agoparentprevIt is not the idea that matters but the execution. Execute well and you will succeed with a mediocre idea, execute badly and the best idea in the world is not going to help you. reply bryanrasmussen 12 hours agoparentprevwait - so I worked for Thomson Reuters Legal solutions once, so I can't make a better legal search solution? I mean I couldn't for the first year after working there because I had signed a contract saying I wouldn't which is what most people do, is that what you mean? That if you sign a non-compete agreement you can't? Because ok, but I would think if you don't sign the non-compete agreement it means you can because otherwise why would people have non-compete agreements? reply rvnx 11 hours agorootparentIf you worked for a small company (let's sayReally i wish we could all just work together on great things Indeed, but for that to happen you need to be open-source since day 1, and not work for profit. And even then you get ego issues, which this CEO apparently has. We'd need capitalism 2.0 because the current version just sets incentives to not make you work somewhat harmoniously together. reply michaelmrose 10 hours agoparentprevThe only thing causing the company from withdrawing illegal threats is social media. reply Mesopropithecus 10 hours agoprevIn the intern's place, I probably would not have bragged about copying that company's idea. Then again, as the company, if I felt a former intern could threaten my business like that, I'd ask serious questions about my value proposition and moat (which could be premium features, sales, or an attractive/viral free tier - not too familiar with what they do). On a personal level, I can see how it could feel unfair, but the idea does not seem that original. reply noncoml 10 hours agoparentYou cannot patent or copyright ideas. Furthermore it is quite debatable if it’s unethical to copy ideas. What the intern did is absolutely fine in my book. reply _shadi 11 hours agoprev [–] Someone interned at a company, saw and worked on the IP and architecture, and after leaving created something that can be viewed as a copy(the emails say that even some of the UI design and languages description were copied) of the core business of the place they worked at, maybe the response was a bit too heavy handed, but you don't exactly expect roses after doing something like that. This seems somewhat unethical, and whether it is legal or not that is up to lawyers and specialized people of law to decide, and the founder wanted those people to get involved to decide that, again nothing crazy to expect after you create a copy of a project you were paid (or at least trained) to work on and learn all about it. reply jdjankwkw 11 hours agoparentThe idea is hardly novel. On top of that, if lines of code were not copied, no foul. Not only was the CEO being a bully but he was wrong. There is no ethical dilemma here. It happens every day. You are allowed to copy an idea for software. Not the literal code. If he wrote it all himself this should be a non-issue. I also urge you to look at how the CEO “apologized”. I will never use their service for that alone. reply mvc 9 hours agoparentprevYou think it's unethical to work at a company and then later create a copy of what the company does. Fairchild Semiconductors would like a quiet moment with you. Does it still seem unethical if the proposition is inverted? What if a company figures out they no longer need your skills and/or labour. Is it unethical for them to lay you off? What if they actually had to do some work behind your back in order to figure out how to do this? What do you think about a company that offers people a home for their digital creativity, and then uses that creativity to build technology that makes the skills and network their \"users\" have acquired over their lives worthless. You'd expect the users to adapt to the situation, find new skills and get on with their lives right? Which is exactly what replit should do instead of sueing. Apparently they are well funded now so it should be a problem. reply jongjong 11 hours agoparentprev [–] This is deceptive as his specific role at Replit had nothing to do with his later open source work. Also, Replit is not innovative as there exist many similar solutions. How can you be accused to copying someone's work if that work is itself a copy of other existing work? Moreover, quote from his article: > I worked for Replit in Summer 2019, where I was asked to rebuild Replit’s package management stack What does a package management stack have to do with an open source IDE? If someone interned as a doctor's assistant at a medical center and then later started their own medical center. Can their previous employer sue them for that? It's nonsense. There is nothing innovative or exclusive about launching a medical center. Just like there is nothing innovative or exclusive about launching an IDE. It's old tech that has been implemented 1000 times. The author is the only one who innovated on the concept by making it open source. If Replit can sue this guy, then Cloud9 can sue Replit, WebStorm can sue Cloud9, Microsoft can sue WebStorm, etc, etc... Who even invented the first IDE? Replit was deceptive. They know they are in the wrong and used malicious, unfounded legal threats to scare him into doing what they wanted. reply _shadi 10 hours agorootparent [–] > If someone interned as a doctor's assistant at a medical center and then later started their own medical center. Can their previous employer sue them for that? It's nonsense. As I said the legality of this is not so simple to answer, yes you can intern as a doctor at one place and then open a similar one, and if someone tries file a suit about this then I think it will be very hard to find a sympathetic judge to look into it, but once you bring IP into this it becomes a lot more complicated, calculus is also about ideas, yet it didn't stop Leibniz or Newton from making accusations of plagiarizing. >If Replit can sue this guy, then Cloud9 can sue Replit, WebStorm can sue Cloud9, Microsoft can sue WebStorm, etc, etc... Who even invented the first IDE? the difference here is that the guy worked/interned at replit, this what moves it for me from the founder being an asshole to a grey area where he sees someone had access to all resources at the company and now wants to use that knowledge(or at least having access to it) to create an alternative and he decides to go with a heavy handed approach before it becomes a big headache, was he nice in how he went about it? no reply munchler 7 hours agorootparent> As I said the legality of this is not so simple to answer … but once you bring IP into this it becomes a lot more complicated, calculus is also about ideas, From a legal perspective, there is no such thing as “IP”. There are copyrights, patents, trademarks, and trade secrets. If you want to talk about legalities, you have to start by saying which of those four were violated. “Ideas” alone have no legal protections. reply michaelmrose 10 hours agorootparentprev [–] What IP was stolen. If neither you nor the CEO can specify there is none. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Radon, a former Replit intern, shared his experience of being legally threatened by Replit to take down his open-source project, Riju, which runs code in 216 programming languages.",
      "Despite initial compliance, Replit later allowed Riju to be reinstated after public attention and an apology from Replit's CEO, who still claimed Riju was an unethical clone.",
      "The incident highlights tensions between open-source ideals and corporate actions, with Radon disputing Replit's accusations and emphasizing Riju's non-commercial nature and use of public information."
    ],
    "commentSummary": [
      "A former Replit intern claims Replit used legal threats to shut down their open-source project, viewed as a competitor by Replit.",
      "The incident has sparked debate on non-compete agreements, intellectual property (IP) rights, and the ethics of using knowledge from a previous employer to create similar products.",
      "The discussion also critiques the CEO's aggressive response and highlights broader issues like the high costs of legal disputes and the role of social media in addressing corporate threats."
    ],
    "points": 178,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1717825428
  },
  {
    "id": 40612387,
    "title": "Playing Duck Hunt Without a TV: A Look at Nintendo's 1970s Projector Version",
    "originLink": "https://nicole.express/2024/no-screen-no-cpu-one-problem.html",
    "originBody": "Yes, You Can Play Duck Hunt Without a Television (but I can't) Jun 2, 2024 Duck Hunt is considered a classic of the Nintendo Entertainment System. But surprisingly, the concept of hunting ducks did not originate in 1984– people have wanted to hunt ducks since at least 1951, when Daffy Duck proclaimed it to be “Duck Season” in the Looney Tunes short Rabbit Fire. But Nintendo didn’t make video games that connected to your television until 1977. What if I wanted to hunt ducks in 1976? BONUS: The ducks are immortal! Duck Hunt Duck Hunt? Without a TV? Actually, it’s got quite a long history. In this case Nintendo was doing what Seg-already-did, as Sega had Duck Hunt as early as 1968. (It’s a generic term) But that was an electromechanical game, with physical moving targets, and a game for the commercial circuit to boot– Sega didn’t sell anything to the masses in those days. So it was up to Nintendo to package the concept in a nice beige box that you could bring home. Notice that text below the English text? That text says 光線銃ダックハント, “ダックハント” being simply “Duck Hunt” in katakana, while “光線銃”, kousenjuu, is the Japanese term for “ray gun”. For Nintendo, kousenjuu was a series of light gun toys, but they were not always intercompatible– for example, Duck Hunt required the specific gun it came with. Even the Famicom Gun was eventually sold as part of the kousenjuu series in Japan. (And it was the last) And that is one serious gun. It comes in two pieces because it won’t fit on its own. The rest of the box is taken up by the projector. Just to drive home the point of how big the gun is, here it is compared to the “I can’t believe it’s not a Zapper” I used in the lightguns on LCD post and the Famicom Gun. It’s longer than the two of them combined. Plus, being from the 1970s, no attempt was made to make this look like a toy. Don’t carry it anywhere around your local cops, at least here in the US. The projector takes four “D” cell batteries, which it refers to as UM-1, and the gun takes two “C” cell batteries, which it refers to as “C”; I guess Japan was in a period of transitioning between the two standard types at the time. The projector power switch literally just pushes down on the D cell batteries; this is a very mechanical device. (This also means the motor might go on for a second while you put the batteries in, don’t get startled like I did) And that projector raises the question: is this a video game? The first definition I find is: An electronic game played by manipulating moving figures on a display screen, often designed for play on a special gaming console rather than a personal computer. And this manipulates moving figures (the ducks) on a display screen (the projector). Sure, it’s a purpose-built projector, but a Game & Watch also uses a purpose-built screen. And sure, it’s a mechanical device, no CPU or software here, but hey, an early analog Pong console doesn’t have a CPU either, and are we going to be that biased against mechanical logic? And this is where the blog post takes a sudden turn for the worst. If you just want to read more about the Nintendo mechanical Duck Hunt, check out Before Mario. They even have a video and a technical breakdown. If you want to see the struggles of Nicole on her web log, well, keep reading. Quack goes the weasel Once you turn on the projector and point it at the wall, you see a duck. It’s a quite well-animated duck, flapping back and forth, and moving on an unpredictable course. (Actually, the unpredictable course is, like Blip, controlled by internal gears on a complex but predictable pattern) The light also turns on and off, presenting a duck flying up and down, disappearing before you can get too close to being able to predict it. When you shoot a duck, the light will bounce off your wall and some of it will go back into the projector. There is a light sensor mounted on a bar over the projector output; through the magic of optics, this isn’t too visible on the duck you see on the wall, but light passing back to the projector can still be amplified and then detected. At that point, the projector will show the duck falling, as is presented on the side of the box: But one thing I found is that I could not shoot the ducks. Now, I’m pretty bad at light gun games, and that’s been an obstacle several times on this blog. But it wasn’t just that– my wife couldn’t shoot them either, and she’s a much better shot. Plus, the gun wasn’t actually letting out any visible light at all. Now, it could be acting in a non-visible portion of the spectrum, but that was still a concern. Taking apart the gun The gun is held together by bolts and little hex nuts on the other side; no screwing into plastic here, thankfully. It’s a little bit more complicated than the Famicom gun inside here. Before we flip over the PCB to see the component side, let’s take a look at that circular mechanism. A punched metal disk has three little points, and a spring to keep the position accurate. When you cock the gun, the position of the three points changes, changing how the circuitboard is connected, and then when you fire the gun it snaps back to its regular position. Keep this in mind when we look at the circuitboard. As you can see, the circuit is basically set up to charge the capacitor, and then release the voltage across a small flash-bulb. We can snag some documentation on it from the patent to confirm. Unfortunately the patent also mentions that the gun must fire a predetermined signal, so I can’t cheat by shining a light into the projector. Unfortunately, my best guess here after checking out all the connections is that the bulb is dead. And this is where I’m stuck. So I’m going to ask anyone reading this: I know my blog posts sometimes get traction, if you happen to know a part number for this bulb, or where I could find a replacement, I’d love to try to get this gun back up and working. But for now, the ducks can keep flying indefinitely. Mocking me. At least that stupid dog isn’t there. Leaded Solder suggested I actually give the dimensions of the bulb, which might be useful: 3.3mm diameter, a hair over 27mm long. Good thought.",
    "commentLink": "https://news.ycombinator.com/item?id=40612387",
    "commentBody": "Yes, you can play Duck Hunt without a television (but I can't) (nicole.express)161 points by zdw 22 hours agohidepastfavorite65 comments smeej 19 hours agoI think I was in my 30s before I found out that with NES Duck Hunt, if you plugged in a controller, player 2 could control the duck. reply Dwedit 15 hours agoparentThe zapper goes into port 2, and a standard controller goes into port 1. The game manual says that you can control the duck with the control pad (which is in player 1's controller port), which would usually be controlled by a second player. This isn't a secret to anyone who bothered to read the manual. https://www.gamesdatabase.org/Media/SYSTEM/Nintendo_NES/manu... reply JohannesH 9 hours agorootparentA bit harsh. I didn't know this. I mean, it could be that some people were not able to read english. I was too young to read english and it wasnt my native tongue. Also, my dad used to let us rent a NES and some games at our local video rental shop, so it just didn't come with a manual to read in the first place. reply bazil376 8 hours agorootparentprevWho’d have figured a bunch of people who didn’t read the docs would go on to become software developers reply treflop 3 hours agorootparentIt’s not like we need to write docs /s reply wkjagt 7 hours agorootparentprevI don't remember reading any of the manuals of any of the games I played as a kid in the 80s. I don't even remember seeing them. I just remember putting the game in the console as quickly as possible and figuring it out. reply ilinx 4 hours agorootparentI remember getting charged $3 every time I returned a rented game without the manual. reply brewtide 1 hour agorootparentHaha. I completely forgot that game rentals came with a manual. I remember them always being absolutely beat up, and near shredded, but usually there! reply brightlancer 4 hours agorootparentprevSome games weren't intuitive, or had various power-ups and items that weren't obvious. Most of the manuals for the Sega Master System and Genesis games were just a few pages, so it only took a minute to read them. (And then there were the RPGs...) reply amarant 19 hours agoparentprevHe can WHAT? Omg I need to go buy a Nintendo! And a CRT! reply thsksbd 15 hours agorootparentDont bother, it sucks. The duck is still trying to fly a certain way and you're really just tugging at him. If you want to try it out just run Duck Hunt on an emulator. You dont need a crt to just play with the duck reply loloquwowndueo 3 hours agorootparentParent just needed an excuse to buy a vintage tv and NES :) reply thsksbd 1 hour agorootparentRookie mistake. My bad. reply vundercind 18 hours agoparentprevI think it was late 20s here, but I’d had the damn thing since I was like 6, including Duck Hunt. Mind was blown. The highest purpose of this feature is to surreptitiously control the ducks while someone who doesn’t know about the feature is playing. You’ll have them cursing in no time :-) reply foxandmouse 18 hours agoparentprevum... well, I just found this out at 32... granted I don't have access to my nes to confirm this. reply ownagefool 18 hours agorootparentCan confirm. 39 now, but as a child I liked to troll my bro with player 2. reply moron4hire 15 hours agorootparentI'm 42. Was doing this at age 8. Cuz what else was I going to do during times I wasn't allowed to play but read all the manuals? reply jzemeocala 21 hours agoprevI would personally check that capacitor first before even touching the bulb. That thing is well past the average shelf life for an electrolytic. reply nicole_express 20 hours agoparentProbably is worth a check; I usually default to assuming that a good brand capacitor without any evident signs of corrosion, leakage or swelling is probably fine, but this is very old and also a higher voltage circuit than what I'm used to. reply icehawk 20 hours agoparentprevSince that looks like your normal camera flash circuit with xenon tube (the cap values are on point for one) I'd agree its likely the cap, unless there is anything visibly wrong with the flash tube. reply pockybum522 15 hours agoparentprevThat was my suggestion of what to try first when I responded to her original post on mastodon. reply ffhhj 21 hours agoparentprevAnd he means check it without touching it with bare skin or unprotected eyes and mouth. reply stouset 20 hours agorootparentWho is checking capacitors by touching them to their eyes!? reply jowsie 20 hours agorootparentIt's not about testing it with your eyes, but about where the shrapnel might end up if things go very wrong. reply userbinator 18 hours agorootparentprevI think he means that this is a high-voltage circuit, the same as found in xenon strobes and camera flashes. The 350V rating on the cap definitely confirms that. reply cesaref 11 hours agorootparentIf it is a flash type circuit, the capacitor will be connected directly across the xenon tube, and a separate trigger circuit will generate a much higher voltage to start the xenon conducting, and allow the capacitor to discharge it's energy and trigger the flash. So, it might be the 350v capacitor has failed and is not storing enough charge to generate a meaningful flash, or the trigger circuit which is not generating the initial >5kV to get the xenon conducting. Either way, i'd check the circuit before the xenon tube. reply myrloc 22 hours agoprevAnyone have ideas on why there aren’t more of these point and shoot at home games? I loved the ones I played as a kid. It always felt like something relegated to arcades reply itishappy 21 hours agoparentIt was a major genre on the Wii. The Wii Zapper was an optional attachment that gave the WiiMote a pistol grip. Titles off the top of my head include CoD III, Metroid Prime 3: Corruption, Resident Evil: The Umbrella Cronicles, Resident Evil: The Darkside Chronicles, and House of Dead II & III Return. I think the main reason that it never took off much was that it kinda sucked. It worked great when it worked, but the tracking was often glitchy and it was super frustrating when you're counting bullets to have the occasionally shot go offscreen. I have a feeling we had a higher tolerance for this with Duck Hunt due to the novelty and arcade games due to the format. (I feel like arcade games tend to avoid showing you a reticle for this very reason, but I don't have data to back this up.) That being said, I still ended up beating Metroid and both Resident Evils, so they were still super fun! Also, I was in Dave and Busters recently and they had Time Crisis 5. Beat that too! reply jrm4 21 hours agorootparentFWIW, I had until now completely forgotten that I was playing these games at home, on a PC with a \"shooter\" experience. They were mouse controlled, but I had a gyration air mouse -- (with the clever thing of instead of requiring infrared, it just had a 3rd button that had to be depressed for actual movement) reply cubefox 20 hours agorootparentprevI'm surprised you call it glitchy. I heard elsewhere that Resident Evil 4 on Wii was easier than the GameCube original because the aiming was more precise than with a stick. reply itishappy 1 hour agorootparentThey can both be true! It worked great probably 97% of the time, but the 3% where it flicked 20px to the left for a frame or lost tracking entirely add up over the course of a boss fight. Missing when using a joysticks feels like a skill issue. Missing when using the WiiMote could be frustrating. reply unleaded 21 hours agoparentprevLCD televisions became popular which don't work with old light guns. We might have the sinden gun now but it kind of came too late, i don't think you can play much on it except for old/emulated games. although there was the Wii so i think people getting bored of light gun games could be a factor, they are all quite similar after all. reply lupire 17 hours agorootparentWhich people are voted of light guns? Young people never had a chance to try them. reply wvenable 21 hours agoparentprevThis is a common game type for VR headsets now. reply paulbgd 21 hours agoparentprevThere might not be many new games, but for the old games getting a used crt is free and the consoles are cheap too! I’ve been playing through the ps2 light gun games and it really does feel like you’ve got an arcade at home. reply fardo 21 hours agorootparentThe CRT requirement has pleasantly eroded recently. A kickstarter a few years back for the Sinden light gun [1] realized that by using webcams, some quick image processing and perspective transforms, you could make a light gun work anywhere and could get real-time performance on non-CRTs by essentially adding a small border region of the screen, making it work on essentially any monitor. He filmed and wrote extensive technical breakdowns about the build process and mechanics at play, which were great. The maker also seems to have had a solid understanding of what made those old light gun games cool, because he made sure to build versions with solenoid-based recoil as well as the big chunky metal foot pedal you’d use for games like time crisis. [1] https://youtu.be/grcGpr_8W9Y?si=z800V7f62dDS1KGs reply MegaDeKay 20 hours agorootparentSinden is no longer the way to go. Most lightgun enthusiasts have now gone the Gun4IR route [0]. It uses the IR sensor from a WiiMote plus a microcontroller in the gun (either a gutted commercial controller like the PS Guncon, a modified Nerf or similar, or something straight up 3d printed) and four IR LEDs placed around a monitor / TV at the midpoints of each each. This system is extremely accurate and there is no flashing border around the screen like with Sinden. Unfortunately, the whole shooting match (see what I did there?) is closed source code and (as of now) Window's only for the calibration-based PC software. The current open source competitor to Gun4IR is the Samco light gun [1]. It uses four LEDs as well, but with two on the top edge and two on the bottom edge of the screen. A couple Wii LED bars will do the job here as well. I don't think it is quite as accurate as the Gun4IR as I don't think it accounts for perspective correction if you move from the position it was originally calibrated at. But... Sam & a few others are readying a new design called OpenFire [2] that will be at least on par accuracy-wise as Gun4IR and will be fully open source and cross platform. It should be available relatively soon. Pair this with the PiCon [3] and you have a lightgun with a pretty crazy feature set. All the guns mentioned support some kind of solenoid & rumble support, but the PiCon kicks it up a notch with exclusive OpenFire features like an OLED display, NeoPixel LED, accelerometer, and analog joystick. [0] https://www.gun4ir.com/ [1] http://forum.arcadecontrols.com/index.php?topic=160517.0 [2] https://www.youtube.com/watch?v=aE9a-fsnMwU [3] https://diylightgun.com/lightgun-details/?lgid=506 edit: make more specific reference to OpenFire reply paulbgd 19 hours agorootparentprevThat's true, but crts are basically free and plug and play while looking extra crispy. I think if you're okay spending a lot more to get an equivalent setup those are good options, but harder to recommend. reply speps 17 hours agoparentprevIt still exists nowadays, works alright actually, very analog with interchangeable shapes, 2 guns, etc. https://www.smythstoys.com/uk/en-gb/toys/games-puzzles-and-b... reply blt 21 hours agoparentprev\"relegated\" seems like the wrong word - the best ones IMO were the later arcade versions like Gunblade NY (pivot mounted machine gun style) or the Time Crisis series (big foot pedal to take cover) with special hardware that would be too expensive for home sales. reply kodt 21 hours agorootparentThere were home console versions of most of the Time Crisis games on PlayStation consoles. I think the 3rd and 4th games were on PS3 along with light guns. There were probably about 10-15 games on each console (PS1/PS2/PS3) which supported light guns. Although I don't think the home console versions had foot pedals, instead using a button or gun movement to achieve the same thing. reply unwind 21 hours agorootparentSome dedicated players with soldering irons may have hooked up a simple pedal switch across the gun's \"cover\" switch. Omg how I loved Time Crisis and arcades in general. Sigh. reply desas 10 hours agorootparentprevYou could buy third party guns that had pedals though. I had one that also came with a cool realistic moving thing at the top that made cool shooting sounds when you pulled the trigger....and gave you a massive headache after a while. reply nottorp 20 hours agorootparentprevI played a Time Crisis on the ps3 using a gun handle attachment for the ps move [1]. Tbh I don't remember if it had a cover option or not. [1] https://www.amazon.ca/PlayStation-Move-Shooting-Attachment-S... reply jareklupinski 21 hours agoparentprevthe most recent one i had at home was the Resident Evil rails shooter for the Wii it was really fun with a friend reply msds 21 hours agoprevThat's exactly a disposable camera flash circuit. reply redbell 19 hours agoprevOh, Duck Hunt! I was a big fan of this classic in my childhood during the 90s, and I was always wondering how the gun does know if I am pointing it to the flying duck. Until recent years and, from nowhere, YT suggested this video to me where I finally deciphered this puzzle: https://youtu.be/cu83tZIAzlA reply fragmede 21 hours agopreva bunch more pictures of the bulb would help. reply IAmLiterallyAB 21 hours agoprevIf you could reverse engineer the expected signal you could probably make your own gun reply physhster 14 hours agoprevCapacitor might be toast. You can try replacing the flash bulb with one from a disposable camera, perhaps? reply bowsamic 21 hours agoprev> In this case Nintendo was doing what Seg-already-did Delicious reference reply riffraff 14 hours agoprevmaybe OT but what's the Saint Seiya-themed \"victory shoot\" box? Was it a game where you could shoot _people_? reply Luc 3 hours agoparentIt's a handheld pachinko game. A real one in a plastic case, not software. reply StanislavPetrov 19 hours agoprevBrings back memories. In the mid 1980s Duck Hunt was one of the games that came included in the bundle (along with Gyromite and ROB the robot) when you bought the NES. reply system2 20 hours agoprevCapacitor is #1 suspect. If not, probably flash tube is dead after dropped or had another type of impact. Just replace the flash tube with something similar to this: https://www.ebay.com/itm/165491505983 reply lupire 17 hours agoprevHow does the projector version work? Why doesn't a regular light work to trigger the hit? How can a shot of light bounce off the wall and back into the projector sensor, but only if the shot is near the duck image? A wall isn't a mirror, and the gun isn't a laser. reply djur 15 hours agoparentThe patent says that the gun receives \"invisible light\", rather than transmitting it. If the patent is referring to the same type of system as this Duck Hunt device (it's for a similar clay-shooting game), the purpose of the capacitor is to transmit a signal to the game device to tell it a shot has been fired. The gun wouldn't have a flashbulb but a photodiode. When the trigger is squeezed, if the photodiode is receiving the right frequency of flashing light, the gun will transmit the signal as a hit. This is similar to how I understand the NES Zapper to work. Caveat: I don't know enough about electronics to look at the photos in the attached article to confirm what I'm saying, but I am fairly confident that I'm reading the patent correctly. (It refers to the gun as \"light-receiving\" many times.) ETA: If this is how the non-functioning Duck Hunt works, it's possible that it isn't the gun that's broken but the infrared emitter in the projector. ETA again: Found a YouTube video where someone has this device and points it at the camera and shoots. There's a visible light flash. https://www.youtube.com/watch?v=Vsh-WTZFX58 So it's not the same as the patent. The projector itself has a sensor on it, as mentioned in the article, and the light emitted by the gun flashes in a predetermined pattern. reply curtisf 20 hours agoprev [–] > Plus, being from the 1970s, no attempt was made to make this look like a toy. This probably isn't just a '70s thing, but a Japan thing. Even today, toy guns in Japan don't have the tell-tale orange tips or plastic-y appearance; they try to look as real as they (cheaply) can. While walking up some stairs in a public park, I once stepped over a toy gun left on the edge of the steps. Being an American, the sight of a pistol just left lying in the open a step in front of me gave me quite a momentary shock, before I remembered what country I was in. My understanding is that this is because real guns are so uncommon in Japan, people generally wouldn't make the assumption that they're not toys. Supposedly it has the added safety benefit of dissuading would-be-robbers from using firearms in robberies, because even confronted with a real firearm, the victims would assume it's a toy rather than the real thing, and so it wouldn't be as effective of a threat. reply crazygringo 19 hours agoparent> the victims would assume it's a toy rather than the real thing, and so it wouldn't be as effective of a threat. I dunno... I was once mugged by a guy holding a gun that I was probably 95% sure didn't work. It was a pistol that was rusted and filthy and looked like he'd found it in the ocean or something... Nevertheless I have him what (small) money I had. I don't think a lot of people are willing to risk their life on the chance a gun might be a toy, you know? reply curtisf 14 hours agorootparentThe homicide rate in Japan is extremely low, owing largely to the extreme small number of firearms in the country: approximately 0.2% of the population own firearms (compared to 40% ish of US households) In a country of 125 million, there are only single-digit numbers of gun homicides each year. (The USA has about 20k, with a population a bit more than double at 333 million; about 800x the rate in Japan) It wouldn't even cross anyone's mind that it is a real gun. reply idunnoman1222 4 hours agorootparent‘owing largely’ is doing a lot of heavy lifting here have you been to the US or Japan? reply jojobas 12 hours agorootparentprevAmericans intentionally kill more people with non-gun means (per capita per year) than either the Japanese or say Europeans or Australians total. Whatever their problem is, it's not guns. reply hiccuphippo 6 hours agorootparentYes, the guns just helps with scale. reply thsksbd 15 hours agorootparentprevThere are basically no guns in Japan. reply mike_hock 19 hours agoparentprev [–] A little demonstration would take care of that. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post delves into the history and mechanics of a 1970s electromechanical version of Duck Hunt by Nintendo, which used a projector and a light gun.",
      "The author shares their experience with the game, highlighting difficulties in shooting the ducks, likely due to a dead flash-bulb in the gun.",
      "The post ends with a request for assistance in locating a replacement bulb to make the game functional again."
    ],
    "commentSummary": [
      "A Hacker News discussion revealed that many were unaware a second player could control the duck in the NES game Duck Hunt using a standard controller, as stated in the game manual.",
      "The conversation evoked nostalgia about renting games, troubleshooting old electronics, and the decline of point-and-shoot games, while also discussing modern alternatives like VR headsets and the Sinden light gun.",
      "Cultural observations were made about toy guns in Japan versus the U.S., highlighting Japan's low gun ownership and homicide rates, suggesting broader societal issues beyond gun availability in the U.S."
    ],
    "points": 161,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1717790547
  },
  {
    "id": 40615530,
    "title": "How Antarctic Research Stations Sustain Water Supply in Extreme Conditions",
    "originLink": "https://brr.fyi/posts/south-pole-water-infrastructure",
    "originBody": "Hello infrastructure enthusiasts! I had a lot of fun back in August 2023 talking about South Pole Electrical Infrastructure. Since then, several people have asked me to detail other infrastructure systems. I started this post while I was still at Pole, but I only finally got around to finishing it. Better late than never – enjoy! Overview This post will focus on how we produce fresh water and how we dispose of wastewater at the South Pole. The majority of the world’s population lives in coastal regions, and researchers in Antarctica are no exception. Most Antarctic research stations sit on or near the coast. Coastal stations are easier to operate, because the ocean provides a moderating effect on the climate, access to ship-based transportation, a water source, and a mechanism to dispose of (hopefully treated!) wastewater. In addition, many of the interesting scientific sites are located near the coast. The majority of human activity in Antarctica is for scientific research purposes, so it makes sense to situate these stations nearby the sites that they are designed to help study. In fact, there are only three year-round stations that are not located on the coast. Here’s a decent map of major Antarctic research facilities, from COMNAP (The Council of Managers of National Antarctic Programs). Yellow dots are year-round facilities, red dots are summer-only facilities. Major research facilities in Antarctica. Map courtesy of COMNAP. This is not an exhaustive map. I’m aware of stations that are not shown here. This is a decent estimation showing the general pattern of human activity in Antarctica. If your station isn’t shown here, please do not get mad at me. Take it up with CONMAP. The South Pole is one of those three inland yellow dots, far from the coast. We’re located high up on an inland plateau, about 975 miles South of McMurdo Station. (Of course, we are, by definition, South of literally everywhere.) Remember, McMurdo is the United States’ main coastal logistics hub for Antarctic research, and it’s where I spent the first 4 months after my arrival on-continent. In this post, I’ll quickly review McMurdo’s water infrastructure, before moving on to discuss water infrastructure at the South Pole. McMurdo Freshwater Infrastructure McMurdo Wastewater Infrastructure South Pole Freshwater Infrastructure Supply Treatment Distribution Fixtures South Pole Wastewater Infrastructure Conclusion McMurdo Freshwater Infrastructure In order to appreciate the unique challenges of water management infrastructure at the inland South Pole Station, it’s worth taking some time first to understand water infrastructure at McMurdo, right on the coast. As a coastal station, McMurdo has year-round access to liquid seawater, right at the bottom of the hill, at the edge of town. Sometimes it’s buried under ice, but there’s always liquid water available below that, even in the middle of winter when the air temperature is a brisk -30°F. McMurdo brings in raw seawater using a series of pumps. The raw seawater intake infrastructure is located in building 179, the Seawater Intake Facility: McMurdo seawater intake facility, up close. The seawater is pumped up a series of insulated pipes: McMurdo seawater intake, from afar. To safely transport water without it freezing in the pipes, we use thick, insulated pipes, with integrated heat trace cabling. Heat trace cabling is just controlled, high-resistance wiring that runs the length of the pipe. When electricity is passed through the wire, it heats up. The heat is trapped by the thick insulation, and it keeps the water in the pipe from freezing. This allows us to safely use above-ground pipes in -30°F weather: Cross-section of an abandoned insulated pipe, showing the thick insulation and heat trace cabling. Seawater is used for two purposes in McMurdo. The first use of seawater is for the salt water aquarium in Crary Lab: McMurdo aquarium, showing some of the seawater circulation infrastructure. Weird lil' guys hanging out in the McMurdo aquarium, part of one of the science projects here. The second use for seawater, is, of course, to produce potable (“domestic”) water for station operations. At McMurdo, seawater passes through several major steps. I’ll be brief here, because the real focus of this post is the South Pole. All of this processing takes place at the McMurdo water treatment plant: McMurdo water plant. The first step is heating. Liquid seawater enters the plant at about 28°F. Since the water is salty, it remains liquid at a lower temperature than fresh water. Before we can remove the salt, we have to heat it. We use waste heat from the power plant to heat the water to about 37°F. The second step is filtering. Raw seawater can contain sediment, which must be removed prior to further treatment. The third step is desalination. McMurdo uses a reverse osmosis system for this. In short – the seawater is pressurized, then forced through a fine membrane. This process allows only pure water through. Salt, along with several other naturally-occurring minerals, are left behind. These are returned to the sea. The fourth step is “polishing”. Pure water, straight out of the reverse osmosis system, isn’t actually desirable. It can cause issues with distribution piping, and it is less than ideal for human consumption due to both aesthetic (taste) and nutritional reasons. Polishing involves the use of chemicals to adjust the hardness and pH levels, for optimal distribution. A small amount of chlorine is also added, which helps mitigate the negative effects of any contamination in the storage and distribution system. Finally, the water is sent to storage and distribution! McMurdo stores hundreds of thousands of gallons of treated water, ready for distribution. Remember, peak summer population can exceed 1,000 people. Water is also used for firefighting, so a significant amount of storage is required. A genuine McMurdo bathroom, with running water! McMurdo Wastewater Infrastructure Lucky you! I wrote a whole post about this last year, back in October 2022. Check it out here. The McMurdo wastewater treatment plant. That’s McMurdo! It’s not that weird. Cold, but not too cold. Take raw seawater, keep it from freezing, purify it, distribute it, use it. Take the wastewater, treat it, release it. Again, not that weird. Now – let’s talk about water at the South Pole. South Pole Freshwater Infrastructure At the South Pole, there is no liquid water source available. Pole is hundreds of miles from the coast, high up on an inland plateau, and it’s absurdly cold. Vast, cold, barren nothingness, and no liquid water in sight. Luckily – that plateau is made up of several thousand feet of snow! It’s a lot of work, but we can melt this snow and produce potable water. This is no small feat of engineering, and the underlying physics means it’s an energy-intensive process. The deep-down snow at the South Pole is around -60°F. It takes 2.44 watt-hours (8.33 BTUs) of heat input to raise the temperature of 1 gallon of water by 1°F. Heating the equivalent of 1 gallon of water from -60°F to a reasonable liquid distribution temperature (50°F) means heating it up by a whopping 110°F. That’s 268 watt-hours of raw energy required just to bring a single gallon of water up to distribution temperature! This is one of the reasons we’re restricted to two-minute showers. Supply Water at the South Pole begins with a “Rodwell”, short for “Rodriguez Well”. The original design for the Rodwell comes from an engineer named Raul Rodriguez, who designed it for a camp in Greenland. The Rodwell is located below the Rodwell support building, which is located several hundred feet away from station. By “The Rodwell”, I should clarify that I’m referring to the current Rodwell. As I’ll discuss later, these don’t last forever. We’re on what is now officially called “Rodwell 3”. We’ve had more Rodwells than that in the history of the South Pole, but the naming convention began when Rodwell location planning was standardized. We have locations already planned out for several more Rodwells. The exterior of our Rodwell support building. Close-up of the door to our Rodwell support building, showing the herculean task to keep it clear from snow. The basic operation of a Rodwell is straightforward. You drill a hole in the snow. You start pumping hot water into the hole. The hot water melts the snow, which pushes outward and forms an underground lake. You can pump liquid water out of the lake! As long as you keep adding heat, by recirculating hot water down into the hole, you can keep expanding the lake and keep pumping water out of it. Diagram of the first experimental South Pole Rodwell from 1972. Diagram Credit: SouthPoleStation.com Inside the support building is all the equipment we need to manage the Rodwell. The building is heated, and it contains control and monitoring equipment. Interior of the Rodwell support building, looking at the infrastructure above the well. The well itself goes down several hundred feet. There’s two water lines, one for the water we pump out, and another for the hot water we recirculate down. There is also electrical wiring for the submerged pump, and signal wiring for sensors and control circuitry. The Rodwell itself! Below these blankets is a hatch. Below this hatch is a hole. The hole goes down hundreds of feet into the snow, to our current Rodwell. We keep it insulated, to avoid undesirable heat transfer in and out. The Rodwell itself, without the insulating blankets. We don't open the hatch very often -- only when we're doing maintenance tasks. This mitigates the risk of dropping items or contaminants inside. Normally, water is pumped out of the Rodwell, and then pumped hundreds of feet toward station, to the main water treatment plant. Some of the water is taken for station use. The rest of the water passes through a series of heat exchangers in the water plant, before it is then pumped back to the Rodwell. This heated, recirculated water is used to keep the underground lake serviceable. Temperature of the raw water we pump out of the Rodwell, about 36°F. Temperature of the heated water we recirculate back into the Rodwell to maintain and expand it, about 84°F. Since the Rodwell is located several hundred feet from the water plant, we need backup systems to ensure that there is always a hot water supply to the Rodwell, even if something happened to the return piping between the water plant and Rodwell. For resiliency, the Rodwell support building itself has backup boilers and heat exchangers. It’s essential that we never lose the recirculated hot water loop down into the Rodwell, else we risk damaging it. Constant heat input to the system is a critical requirement for its continued operation. Boilers, to provide onsite heat for the backup Rodwell circulation heating infrastructure. Used to maintain the Rodwell in the event we cannot provide hot recirculated water from the power/water plant. Glycol heat infrastructure in the Rodwell support building. We use each Rodwell for several years. Once it gets too big (we’re talking millions of gallons), we stop pumping fresh water out of it, and we start over with a new one in a new location. The old one gets converted to be used for wastewater disposal – more on that part later. Much more fascinating historical documentation about Rodwells can be found on Bill Spindler’s South Pole Station website. As discussed above, once water is pumped out of the Rodwell, it exits the Rodwell support building, and it enters into the ice tunnels below. Rodwell water pipes, passing through the floor of the Rodwell support building, into the ice tunnels. The water then travels through pipes in the ice tunnels, en route to the main water plant. The ice tunnels are a network of subterranean utility corridors, carved directly out of the hard-packed snow. These tunnels sit deep below the station and its outbuildings. Transporting water through the ice tunnels. Note the electrical infrastructure here -- that's powering the heat trace cabling that runs within the insulation for these water pipes. Emergency egress fom the ice tunnels. Emergency egress signage. Treatment The water pipes exit the ice tunnels and enter the main water plant. The water plant is located adjacent to the power plant, in the arches, at the bottom of the beer can. This means we can easily use a glycol loop carrying generator waste heat, from the power plant next door, to power these heat exchangers. Rodwell supply and return lines entering the water plant. When the water enters the treatment plant, it first passes through a series of limestone contactors. Limestone contactors are used to increase the pH of the water by adding minerals. This improves corrosion resistance and makes the water suitable for human consumption. Contactors can be brought online or taken offline as needed, depending on the amount of treatment needed to achieve desired target outcomes. Note that all water passes through the contactors, even water that will be recirculated back to the Rodwell. Limestone contactors, for pH stabilization. Another view of the limestone treatment contactors. After the limestone contactors, the majority of the water is sent toward heat exchangers, which are used to heat up the water that will be sent back to the Rodwell. The Rodwell circulation loop uses the majority of the water that is pumped out of the Rodwell. Only a small portion is diverted for domestic use. The water is about 36°F when it is pumped out of the Rodwell, and it reaches about 42°F after it makes it all the way to the water plant and through the limestone contactors. Domestic water does not receive any direct supplemental heating further along in the process. Additional heat gains are due to ambient heat absorption from the water treatment plant, or due to heating along the insulated, heat-traced piping. Rodwell recirculation water, on the other hand, needs to be heated quite a bit, up to about 84°F. Remember, this water is pumped back down into the Rodwell, to maintain and expand the underground lake. Here you can see the heat exchanger infrastructure. Hot glycol is pumped in from the power plant next door. The heat exchangers place the hot glycol loop and water loop in close proximity, separated only by small layers of thermally-conductive metal. This allows for the efficient transfer of heat without the contents actually touching. Heat exchangers, which heat up the water that will be returned back to the Rodwell. The heat exchangers heat up the water to about 84°F. This heated water is sent back to the Rodwell building, where it is pumped back down into the Rodwell. The remaining portion of the water is destined for domestic use. It receives additional treatment. First, the water passes through a series of sediment and carbon filters: Sediment and carbon filters in the water plant. Next, sodium carbonate (soda ash) is used for additional fine-grained pH control: Sodium Carbonate storage tank. Finally, chlorine (calcium hypochlorite) is used as a disinfectant: Chlorine storage tank. Once the domestic water has passed through all of these treatment steps, it is stored in bulk, unpressurized tanks. There are two tanks, so one can be taken offline for maintenance. The tanks are several thousand gallons, and they provide a storage buffer to guard against scheduled or unscheduled interruptions in the Rodwell supply or treatment process. Bulk storage tank for treated water. A treated water sample point is provided, to allow for scheduled checks of water quality, just prior to the water being pressurized for domestic supply: Treated water sample point, at the outflow from our bulk treated water storage tanks, just before the domestic water pumps. Water quality is checked at several points throughout the treatment and distribution process. A lab table contains a variety of tools used for these measurements: Lab table in the South Pole water plant. Distribution The final step in the domestic water treatment process is to pressurize and store enough water to provide a reliable domestic supply: Pumps, which bring the treated water up to an appropriate distribution pressure for the station. The pressurized water distribution tank, which stores water for station use. Domestic water for the main elevated station must be carried from the tank here, up the beer can, and into the station. This is a vertical gain of about 50 feet, which must be factored into the pressure setpoint for the distribution system. These pipes are insulated, because the beer can is not heated. Insulated pipe, carrying domestic water up from the water plant, through the Beer Can, to the Elevated Station. The pipes exit the beer can and enter the elevated station, into the subfloor. The subfloor is a sort of crawl space located just below the 1st floor. Water lines entering the Elevated Station, from the Beer Can. Red lights are indicators for the heat trace cabling along these water lines. The elevated station contains one additional, pressurized tank at station level, for fire suppression. We have automatic fire sprinklers installed throughout the elevated station. Here you can see the large, pressurized fire suppression water tank: Pressurized tank within the elevated station, serving the automatic fire sprinkler system. Other than that, the water is used to serve fixtures throughout the station, just like you’d expect in a normal building! Fixtures The kitchen is one of the larger water consumers. Here you can see our dish pit. Winter staff take turns washing dishes, according to a posted schedule: The South Pole dish pit. Here is an important permanently-installed water appliance – our espresso machine. This machine was critical to my morale during the long winter: The South Pole espresso machine. Laundry works much the same as it does back home. The South Pole laundry room! Most of the washers are only connected to cold water, as an energy saving strategy. A few lucky (and coveted) machines have both a hot and cold water connection: Washing machine connections. The only major difference in the laundry room is that our clothes dryers have direct glycol heat exchangers, instead of using electrical resistance heating: Dryer connections, showing the integration with the building's glycol heating loop. Moving on – this is one of the South Pole bathrooms! We participate in weekly “house mouse” cleaning tasks – this week, it was my team’s turn to clean. Other cleaning tasks include mopping the halls, vacuuming carpeted spaces, and shoveling snow from outside station entrances. Bathroom inside the Elevated Station. Another view of a bathroom inside the Elevated Station. Finally, completing our tour of domestic water fixtures, we have a genuine South Pole drinking fountain: A standard South Pole drinking fountain inside the Elevated Station. It’s an Elkay EZS8SF with the LK1110 glass filler add-on – an all-around solid choice for commercial drinking fountains. And that pretty much covers the freshwater infrastructure at Pole! South Pole Wastewater Infrastructure Wastewater at Pole is handled much differently from wastewater at McMurdo! As a reminder, from my McMurdo Wastewater Plant post, wastewater at McMurdo goes through a full wastewater treatment process. Treated wastewater is discharged into the ocean, and solids are processed and sent back to the United States for disposal. At Pole, we use the old, spent Rodwells for storing wastewater. When a Rodwell has reached its maximum size, we stop drawing fresh water from it, and we convert it into wastewater storage. From then on, it is known as the “sewage outfall”. Raw sewage and other wastewater flows into the current sewage outfall via a network of sewage pipes. The wastewater is stored underground indefinitely. No treatment is performed on this wastewater before it is sent underground. There are millions of gallons of raw, untreated wastewater stored in outfalls beneath South Pole Station. As of this writing (June 2024), a wastewater treatment plant is not currently planned or budgeted for South Pole Station, although one has been discussed at various points throughout the history of South Pole Station. A wastewater treatment plant does appear as a recommendation in the South Pole Station Master Plan Draft 2024 (32 MB PDF) document on the NSF website. Disposing of raw sewage by injecting it beneath the ice is permitted under the Antarctic Treaty System, which is codified in US law under 45 CFR § 671.12(f). As I stated in my post about South Pole Electrical Infrastructure, it is my sincere hope that we continue working, with urgency, to reduce the environmental footprint of US Antarctic research. Wastewater from the elevated station flows from domestic drains and collects in holding pits. There are two main holding pits in the elevated station. The purpose of these is twofold: First, these pits provide a temporary storage buffer, allowing use of plumbing fixtures within the station during periods of maintenance on the discharge piping or sewer outfall. Second, wastewater can be collected in these pits until they are full, and then the wastewater can be force discharged at a high flow rate. Discharging at a high flow rate allows for efficient and more complete carrying of suspended solids. If waste were discharged all the way to the sewer outfall at the rate it was produced, the system would suffer from blockages caused by solids that settled out in transit. The first pit, for the “B” pod, is also co-located with our emergency water purification infrastructure, inside the Emergency Power Plant (EPP). This is part of the “lifeboat”, a wing of the station with redundant infrastructure that could function on its own in case the rest of the station were compromised. Here you can see the wastewater holding pit, as well as some of the emergency water purification equipment. Wastewater holding pit, inside the Elevated Station B2 mechanical room. Plus emergency water purification. This wastewater pit collects all wastewater via gravity from the “B” pod. It normally discharges to the main sewage/wastewater outfall. However, in the event that this was compromised, it can also discharge to a much smaller emergency outfall. This ensures continuity of wastewater disposal in the event of an issue with the primary wastewater outfall. The emergency water purification infrastructure here can produce potable, domestic water by melting snow. A portable snowmelter can be set up just outside, with heat provided by a glycol loop. Up next is the “A” pod wastewater pit. This one is located inside a large mechanical room on the 1st floor of the “A” pod. Wastewater collects here via gravity from all fixtures in the “A” pod. It also discharges to the main outfall. Wastewater holding pit, inside the Elevated Station A2 mechanical room. Once the pits are full, they automatically discharge to the sewer outfall. This follows roughly the same path as the domestic water supply piping. The pipes exit the station, go down the beer can, and travel through the ice tunnels, until they reach the current sewer outfall. Insulated sewage discharge pipe, through the Beer Can. Here you can see the piping entering the ice tunnels, off of the corridor at the base of the beer can: Primary ice tunnel entrance, at the base of the beer can. Deep inside the ice tunnels, here is the current sewer outfall, showing the insulated pipes. This is the discharge point for all of South Pole Station’s wastewater, until we move to Rodwell 4 for freshwater, at which point Rodwell 3 will become the new sewer outfall. The sewer outfall, inside the ice tunnels. Close-up of the sewer outfall. Heat trace module for the final (vertical) leg of the sewer outfall. Sewage must be protected from freezing until it discharges into the sewer outfall. Of course, not every building is connected to the plumbing system. In fact, at South Pole, only the elevated station and the power plant arch have running water and wastewater connections. The outbuildings (IceCube, MAPO, DSL, ARO, etc) are too far away, and so far it hasn’t been cost-effective to connect them. For folks working outside away from station, there are a variety of options. During the summer, when the population is high, we have porta-potties strategically located around campus: A seasonal porta-potty, outside in the backyard, for people working away from station. No heat, no running water, no electricity. However, it is engineered to maximize passive solar gain, so it stays surprisingly warm. Inside the porta-potty. Without a permanent sewer connection, waste from porta-potties must eventually be carried back to station once the porta-potties fill up. Permanent outbuildings also often have an established solution for handling human waste from workers. These solutions range from simple buckets, to permanently-installed dry toilets with removable storage bins. For work that takes you away from station, without access to toilet facilities, many personnel also carry portable bottles. These are a formal item, provided by USAP, and marked for their intended use. They are 32oz “HDPE” Nalgene bottles. You can obtain one at the beginning of your season, and it’s your responsibility to return it, thoroughly cleaned and sanitized, before you depart. These are often used by personnel who travel to deep field locations, but they are also helpful for any situation where you may find yourself away from permanent facilities. Conclusion And there you have it – a brief tour of South Pole water and wastewater infrastructure! Much like South Pole Electrical Infrastructure, the infrastructure that makes all this possible is generally hidden from view. From an average user’s perspective, living and working in the elevated station, everything functions pretty much the way you’d expect it to. When you’re washing dishes in a windowless, heated room, and you turn on the faucet to fill the sink, it’s easy to forget all the work going on behind the scenes to make all this happen. But venture out to the Rodwell in the middle of winter, when it’s negative 100°F, and you’ll quickly be reminded of the forces we’re up against. From cold, to wind, to relentlessly accumulating snow, to the long, long supply chains for engineering expertise and spare parts, it’s a challenge to make things work at Pole. Our water and wastewater systems are critical infrastructure that enable humans to live at the bottom of the world. Thank you everyone, again, for your patience! I wrote most of this post last winter while I was at Pole, and I appreciate all the words of support from folks who liked my past writing. I hope everyone enjoyed reading this as much as I enjoyed writing it!",
    "commentLink": "https://news.ycombinator.com/item?id=40615530",
    "commentBody": "South Pole Water Infrastructure (brr.fyi)155 points by loeber 13 hours agohidepastfavorite35 comments theideaofcoffee 5 hours agoIt's always fun seeing these posts, it's a look into such a strange way of living and supporting life. And there's something subtly terrifying about the whole operation too, seemingly teetering on a knife's edge between the ever-forward marching of entropy and all of the energy they need to put in to keep that in check, even more so with it being so cold. How fast it could collapse if, say, there was a generator problem and how diesel fuel is the only thing that's keeping it afloat. I'd love to see a post, maybe there is, about maintenance of all of this, perhaps a story or two about an issue that maybe had some existential threat to the station and how it was overcome. I look at the majority of the infrastructure there and just keep in the back of my mind how fragile it all seems. And yes, obviously there are redundancies, but even with redundancy, things can still fail, they exist in the physical world after all. reply throwup238 2 hours agoparentNit: McMurdo uses diesel since its climate is more forgiving but the South Pole station the author was at uses kerosene-based JP8 jet fuel since it comes with additives for subzero temperatures. They even have their own arctic recipe called AN8. There is a lot of redundancy and they're equipped to fix things on site: https://www.jeffreydonenfeld.com/blog/2012/12/the-south-pole... reply m4rtink 1 hour agorootparentIIRC McMurdo even had a nuclear reactor for a while. :-) reply ironchief 1 hour agorootparentMore info on the PM-3A reactor http://large.stanford.edu/courses/2014/ph241/reid2/ reply namanyayg 7 hours agoprevAlways great to see a brr.fyi post on HN. Living in the south pole is basically like living on an alien planet. reply perihelions 7 hours agoprevOne thing not mentioned: McMurdo desalination (the first one in OP) historically used to be nuclear-powered, but they abandoned that and currently use diesel. https://en.wikipedia.org/wiki/McMurdo_Station#Nuclear_power_... reply consumer451 6 hours agoparentDiesel sounds much more practical: > “Nukey Poo” began producing power for the McMurdo station in 1962, and was refuelled for the first time in 1964. A decade later, the optimism around the plant had faded. The 25-man team required to run the plant was expensive, while concerns over possible chloride stress corrosion emerged after the discovery of wet insulation during a routine inspection. Both costs and environmental impacts conspired to close the plant in September 1972. > This precipitated a major clean up that saw 12,000 tonnes of contaminated rock removed and shipped back to the USA through nuclear-free New Zealand. The clean up pre-dated Antarctica’s modern environmental protection regime by two decades, and required the development of new standards for soil contamination levels. https://theconversation.com/remembering-antarcticas-nuclear-... reply langsoul-com 5 hours agoprevTo think that beneath the south pole lies a metric shit ton of shit. I think some things are better left unknown. reply bbarnett 3 hours agoparentTomorrow, a nuclear war happens. Next, nuclear winter and the slow death of the human race. Antarctica? Sits untouched for millions of years, then aliens land, and find a mysterious additional lake filled with all sorts of microbes. reply dudeinjapan 2 hours agorootparentGiven the extent of human impact on the planet, these aliens can probably deduce this whodunnit. reply Metacelsus 5 hours agoprev>Heating the equivalent of 1 gallon of water from -60°F to a reasonable liquid distribution temperature (50°F) means heating it up by a whopping 110°F. That’s 268 watt-hours of raw energy required just to bring a single gallon of water up to distribution temperature! It's actually more than this, because the phase change from solid to liquid takes a lot of energy too. reply jimmyswimmy 2 hours agoparentYes, this bothered me too. It's impressive how much energy is required to just melt water much less bring it to temperature. It's 330 kJ/kg, which is 1250 kJ/gallon: 350 Wh. So it costs more energy to defrost one gallon of water than it does to do the rest of the 110F temperature change. The physics term for this is the \"latent heat of fusion,\" or the energy required to change states from liquid to solid, or vice versa. A few years ago I saw someone calculate the energy required to melt the ice in front of a locomotive (I think) at speed; IIRC it required a (not small!) nuclear reactor's worth of energy. Not practical! reply davidw 3 hours agoprevThese are the sorts of deep dives into something interesting that I've always enjoyed on HN. I was also a bit surprised by everything being in Fahrenheit, even in the pictures. The ice tunnels are really cool. Having grown up with Star Wars, who wouldn't love those? reply anself 8 hours agoprevWhere did the wastewater go before the first rodwell was finished? reply cozzyd 3 hours agoparentAt Summit Station in Greenland (much smaller than Pole, Pole feels like a luxury resort comparitively), an outfall hole + usually we use the outhouses (which are just made using hot air). Fresh water comes from the snow cave, and shoveled into the water melter. reply bunabhucan 5 hours agoparentprevhttps://www.southpolestation.com/trivia/history/history.html... Lots of mentions of sewer outfalls, pipes freezing and lift pumps being replaced. Probably an excavated hole in the ground? reply joshvm 5 hours agoparentprevI guess something fairly simple - a hole in the ground. Or it gets bagged and put into waste drums (or deposited directly) - this is still what we do at outbuildings where there's no sewage or water infra. The answer is probably on Bill Spindler's website somewhere (southpolestation.com). reply jsjohnst 5 hours agoprevLittle surprised that there aren’t contamination concerns with pumping waste water back into the snow pack. I guess at -60° it doesn’t travel far, but still. reply ta1243 5 hours agoprevI was shocked that such a scientific station is using Fahrenheit to measure the temperature of the water reply ano-ther 46 minutes agoparentIt’s a US government operated facility, so this is not too surprising. Also, most equipment (especially things like plumbing) will be from US suppliers and that will just be easier to procure by the inch. reply defrost 5 hours agoparentprevIt's a blog for general US public reading, I'm inclined to think the seriousstuff is all Celsius and SI units and Fahrenheit is used in the social write ups so than regular folk in the US know what the tempretures are. reply cesarb 4 hours agorootparent> I'm inclined to think the serious stuff is all Celsius and SI units and Fahrenheit is used in the social write ups [...] There are two photos in this article which show thermometers (search for \"Temperature of the \"), which clearly are in Fahrenheit (the scale goes from 20 to over 140, which would be from \"comfortable room temperature\" to \"beyond boiling at normal pressure\" if it were in Celsius), and both having a printed label \"EACH LINE: 2°f\" (with lowercase F for some reason) glued below them. So, at least for this water treatment plant, it seems to be using Fahrenheit for the instrumentation. reply SoftTalker 54 minutes agorootparentApplication-specific industrial instrumentation probably sourced from USA. I'm sure all their scientific instruments are in Celsius. reply ta1243 4 hours agorootparentprevIt's the photos that confused me. They weren't even dual-marked in C and F, just in F reply __MatrixMan__ 1 hour agoparentprevFahrenheit is based on what a human body finds hazardous, and this is a life support system for humans. It's the right tool for the job. I doubt they're using Fahrenheit in contexts that don't benefit from a human bias. reply photochemsyn 3 hours agoprevFascinating! >\"Heating the equivalent of 1 gallon of water from -60°F to a reasonable liquid distribution temperature (50°F) means heating it up by a whopping 110°F. That’s 268 watt-hours of raw energy required just to bring a single gallon of water up to distribution temperature! This is one of the reasons we’re restricted to two-minute showers.\" Everyone reading this should try to get by on a two-minute shower once a day for one week, to see if we could be candidates for this job. reply SoftTalker 52 minutes agoparentOr even less often. Daily full-body bathing is unnecessary unless you do very physically demanding or dusty/dirty work. reply jimmyswimmy 2 hours agoparentprev> try to get by on a two-minute shower once a day This is pretty typical aboard ship for smaller vessels on long voyages. Not so hard as it sounds: get wet, turn off; lather up, rinse off, turn off. You can do with 20-30 seconds of water and be quite clean, with some practice. It's not satisfying though. And I can't imagine how those numbers scale if you have long hair, or use conditioner. reply __MatrixMan__ 1 hour agoparentprevI like what a cold shower does to my brain. It's uncomfortable in the moment but it sort of stays with you all day in a nice way. I used to time them at 5m when I was building the habit but now I gravitate to around 2m. Admittedly, Colorado \"cold\" is not Antarctica \"cold\". Just saying that 2m is plenty of time for a shower if you're not luxuriating in world of steam and shower thoughts. reply immibis 5 hours agoprev [–] TL;DR: They mine the Antarctic for ice, creating huge sinkholes, then fill the holes in with raw sewage, a gift for future generations. Environmentally friendly, right! reply noprocrasted 1 hour agoparentThe alternative would be to collect and ship it back which would require tons of energy that will have to be in the form of fossil fuels given current technology. Said fossil fuels have a huge environmental footprint (greenhouse gas emissions and depletion of fossil fuel reserves) that is affecting us now. In contrast, the ice shelf is huge and still has a lot of capacity to contain sewage. It should remain frozen for the foreseeable future - if it melts (to the level where this sewage will become liquid) it means the global warming situation is so bad that there's likely no longer any humans around to actually witness this sudden deluge of sewage. As long as we manage to keep that ice shelf frozen, we're fine. If we somehow fail at it it's likely there wouldn't be anyone around to complain about the sewage anyway. reply icapybara 2 hours agoparentprevDo you have a better idea? reply michael9423 1 hour agorootparentdrying and burning. reply consumer451 50 minutes agorootparentThere are some smart folks making the decisions for the procedures down there. I wonder how that decision process went, to end up with burial. I would love to know the details. reply unethical_ban 46 minutes agoparentprev [–] Wait until you learn about landfills! Although considering the desire to survive on the Moon and Mars, one would think recycling sewage in more of a closed system would be worth funding. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In August 2023, the author examined water infrastructure at Antarctic research stations, specifically McMurdo Station and the South Pole Station.",
      "McMurdo Station uses insulated pipes and heat trace cabling to access and treat liquid seawater, while the South Pole Station employs the \"Rodwell\" system to melt snow and create an underground lake for water extraction.",
      "The South Pole Station's water system is energy-intensive, utilizing waste heat from a nearby power plant, and includes emergency purification systems and portable solutions for remote work, highlighting the importance of these systems for human survival in Antarctica."
    ],
    "commentSummary": [
      "The Hacker News discussion focuses on the complexities of maintaining water infrastructure at the South Pole, emphasizing the energy-intensive process of heating water from subzero temperatures.",
      "Key points include the use of kerosene-based JP8 jet fuel for power, historical shifts from nuclear to diesel power at McMurdo Station, and the environmental impact of waste management.",
      "Commenters are intrigued by the practicalities of living with limited resources, such as taking two-minute showers, and the historical and technical details of the stations' operations."
    ],
    "points": 156,
    "commentCount": 35,
    "retryCount": 0,
    "time": 1717825303
  },
  {
    "id": 40613854,
    "title": "User Integrates 3dfx Voodoo 4 into Dell Precision M4800 with Custom Modifications",
    "originLink": "https://www.vogons.org/viewtopic.php?t=100871",
    "originBody": "Voodoo 4 M4800 Topic actions Post a reply Pagination Page 1 Page 2 First post, by sdz Posted on 2024-05-30, 15:28 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU MXM3.0/3.1 TYPE A VSA-100 video card, for finally making a laptop with 3dfx graphics. I'll document it here as I think it will be quite interesting, it's not that straightforward shoving a VSA-100 into a laptop. S1.jpg Filename S1.jpg File size 389.21 KiB Views 53268 views File license Public domain S2.jpg Filename S2.jpg File size 401.54 KiB Views 53268 views File license Public domain S3A.png Filename S3A.png File size 1.02 MiB Views 53268 views File license Public domain The PCBs arrived yesterday, and they look great: S4.jpg Filename S4.jpg File size 1.56 MiB Views 53268 views File license Public domain S6.jpg Filename S6.jpg File size 1.84 MiB Views 53268 views File license Public domain Reply 1 of 27, by sdz Posted on 2024-05-30, 15:46 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU Laptops with MXM slots, want a video card with an MXM BIOS. Obviously, the usual V4 BIOS isn't MXM compatible. Also, the system BIOS would probably need to be edited to add the VSA ID to the whitelist. I don't want to mess with the system BIOS, or to attempt to make the VSA BIOS MXM compatible. This means two things: 1. The laptop will not execute the BIOS on the video card. In the case of the VSA-100 it's not that bad. Many registers can be set with hardware straps, but not all. In this case, two important registers are not set to the value that is needed for such an application, vidInFormat[8] and vidInFormat[22] . Because of this, the digital RGB interface of the VSA will output scrambled Chrontel instead of unscrambled Brooktree format. S7.jpg Filename S7.jpg File size 129.63 KiB Views 53255 views File license Public domain And this is how DVI looks with in such a setup (V5 5500 DVI): S8.jpg Filename S8.jpg File size 28.95 KiB Views 53255 views File license Public domain S9.jpg Filename S9.jpg File size 42.12 KiB Views 53255 views File license Public domain On the V4 M4800 the usual TMDS encoder was replaced with an FPGA. 2. The laptop will behave as it doesn't have a video card plugged in. Because of this, if it's a laptop with an integrated GPU, it will not toggle the muxes to switch to the video signal coming from the MXM slot. I intend to use the card in a Dell Precision M4800, which has the LVDS connector close to the MXM slot, so for keeping the solution as much as plug and play possible, I added an LVDS connector on the MXM card. Otherwise, some traces need to be cut on the motherboard. With this also goes backlight control via keyboard, but it may be possible to implement a workaround for this. More on that later. Another important point is that a laptop screen has a fixed resolution. If the GPU is set to render at a resolution lower than the native resolution of the panel, the GPU will upscale that image so that the panel is always fed with it's native resolution. The VSA-100 will do no such scaling. Also the panel wants to receive dual channel LVDS/OpenLDI/FPDLIK-I signal. Because of this, the card has a Realtek scaler, that takes the HDMI signal from the FPGA, upscales it if needed, and outputs LVDS to the panel. This is basically what's inside a PC monitor, added on the MXM card. Reply 2 of 27, by Dothan Burger Posted on 2024-05-30, 16:20 Reply with quote Creative Commons Attribution 4.0 International license More actions Dothan Burger Offline User metadata Rank Newbie Rank Newbie Posts 87 Joined 2023-02-21, 16:40 This project sounds awesome. It looks like RTX founders edition level of density on the board. Reply 3 of 27, by sdz Posted on 2024-05-30, 17:04 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU It is a bit crammed, as it's basically a 64MB V4, plus PCIe to PCI bridge, FPGA, the scaler that's usually inside a PC monitor, a microcontroler, power supplies, various flash ICs/EEPROMs etc. The size of the board is 7x8cm. I just finished assembly (I'll wash the board better later). Here it is next to a standard Voodoo 4: S10.jpg Filename S10.jpg File size 1.55 MiB Views 53201 views File license Public domain More photos: S11.jpg Filename S11.jpg File size 1.48 MiB Views 53201 views File license Public domain S12.jpg Filename S12.jpg File size 1.75 MiB Views 53201 views File license Public domain S13.jpg Filename S13.jpg File size 1.87 MiB Views 53201 views File license Public domain S14.jpg Filename S14.jpg File size 1.73 MiB Views 53201 views File license Public domain Reply 4 of 27, by sdz Posted on 2024-05-30, 17:06 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU S15.jpg Filename S15.jpg File size 1.79 MiB Views 53199 views File license Public domain S16.jpg Filename S16.jpg File size 1.87 MiB Views 53199 views File license Public domain S17.jpg Filename S17.jpg File size 1.65 MiB Views 53199 views File license Public domain S18.jpg Filename S18.jpg File size 1.77 MiB Views 53199 views File license Public domain Reply 5 of 27, by sdz Posted on 2024-05-30, 17:08 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU Also made an MXM carrier, so I can bring-up the board in a normal PC: S19.jpg Filename S19.jpg File size 1.4 MiB Views 53199 views File license Public domain This looks absolutely ridiculous: S20.jpg Filename S20.jpg File size 1.91 MiB Views 53199 views File license Public domain S21.jpg Filename S21.jpg File size 1.35 MiB Views 53190 views File license Public domain S22.jpg Filename S22.jpg File size 1.35 MiB Views 53190 views File license Public domain Reply 6 of 27, by Dothan Burger Posted on 2024-05-30, 17:59 Reply with quote Creative Commons Attribution 4.0 International license More actions Dothan Burger Offline User metadata Rank Newbie Rank Newbie Posts 87 Joined 2023-02-21, 16:40 That's beautiful! Are you going to sell these? Reply 7 of 27, by sdz Posted on 2024-05-30, 18:27 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU Probably not, but I'll opensource the design. Some good news, the card works 😀 Here's it running in a PC, with VGA output: https://youtu.be/MKRf2rdHCFA?si=6mj1gPLrcQtiUlNY Next step is getting the HDMI output from the FPGA working. There is a mux on the board, and the HDMI can be routed to the onboard scaler or the MXM connector. This will probably take a while. Reply 8 of 27, by supercordo Posted on 2024-05-30, 23:23 Reply with quote Creative Commons Attribution 4.0 International license More actions supercordo Offline User metadata Rank Member Rank Member Posts 286 Joined 2020-08-09, 06:27 Location Ohio, United States At this point you should just make your own Win98/XP compatible laptop. I would buy it. Reply 9 of 27, by DrAnthony Posted on 2024-05-31, 12:04 Reply with quote Creative Commons Attribution 4.0 International license More actions DrAnthony Offline User metadata Rank Newbie Rank Newbie Posts 90 Joined 2021-04-16, 22:37 Well done dude! Looks like you've been really busy in the Voodoo lab lately. I know this has some shortcomings that look like a pretty major hill to climb to be a bit more universal, but do you think some outside of the box thinking might be able to improve things? I'm just spitballing here as I don't really tinker with laptops, but would you be able to integrate this into a little box and use thunderbolt for an external GPU? Or does that run headfirst back into the BIOS issues? Reply 10 of 27, by sdz Posted on 2024-06-02, 10:49 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU @supercordo That's actually something that I want to do at some point. @DrAnthony Thanks! Pretty busy indeed, another board will arrive in a week or so 😀 Using the card via Thunderbolt might actually be OK regarding the BIOS, however: -last time I wanted to develop a thunderbolt device with Intel's ICs, to get access to the documentation/tools, one would need to describe to Intel what's the application, and get their blessing. -there would be no way (at least no reasonable way) of getting the image on the laptop's screen. One would need to use an external monitor. At that point it's better just to use a PC. A couple of updates regarding the V4 M4800: I got HDMI working through the FPGA: 20240602_123557.jpg Filename 20240602_123557.jpg File size 1.44 MiB Views 52734 views File license Public domain https://youtu.be/MiMey5aXpYw?si=z9vBNY-1vv89CKvE The following resolutions (all 60Hz) work fine: 640x480 800x600 960x720 1024x768 1152x864 1280x720 1280x1024 1360x768 1600x900 1600x1024 1280x960 displays a black screen via HDMI, but it's the same on a V5 5500 DVI card, so it's a driver/VSA issue. 1920x1080 works but there are some timing issues to resolve inside the FPGA. I will work on this later, as 1080p is already problematic. On a regular V5 5500, with the timings provided by Dolenc here The Changeling 3dfx Voodoo 5 5500 , 1080p works only on an Alienware AW3423DWF. I tested with about 5 different other displays, and none work with those timings. First I need to other fix that somehow, or ensure that the scaler accepts those timings. After that, I'll fix the FPGA issue for that resolution. At the moment, everything works as intended, except the scaler, which is the last part to solve. M4800_DG1.png Filename M4800_DG1.png File size 84.82 KiB Views 52734 views File license Public domain I made this small board with just the scaler, so I can work on this easier: 20240531_192019.jpg Filename 20240531_192019.jpg File size 1.67 MiB Views 52734 views File license Public domain I ran a couple of benchmarks, 3DMark2001SE, XP SP3, SFFT1.9, default settings, 1024x768, 32bpp, and got the following results: 32MB RAM (2.8V VCORE): 166MHz: 1694 183MHz: 1872 192MHz: 1955 64MB RAM (2.8V VCORE): 192MHz: 2035 Reply 11 of 27, by amadeus777999 Posted on 2024-06-02, 18:59 Reply with quote Creative Commons Attribution 4.0 International license More actions amadeus777999’s avatar amadeus777999 Offline User metadata Rank Oldbie Rank Oldbie Posts 973 Joined 2013-07-04, 17:04 Awesome work! Reply 12 of 27, by sdz Posted on 2024-06-03, 19:24 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU @amadeus777999 Thank you! I got the cursed scaler working. It takes 16:9 resolutions and upscales them to 16:9 1920x1080 20240603_221030.jpg Filename 20240603_221030.jpg File size 1.43 MiB Views 52587 views File license Public domain And 4:3 resolutions, adds black borders, and upscales them to 16:9 1920x1080 20240603_221059.jpg Filename 20240603_221059.jpg File size 1.41 MiB Views 52587 views File license Public domain Everything mostly works, I fixed a ton of issues (wasted hours trying to \"fix\" the panel's timings until finally figuring out that a cropped image is not a timing issue (obviously), but overscan). It's not yet ready for the M4800 card. The scaler has two TMDS inputs, and I got only one working. Obviously not the same one I used on the VSA-100 M4800 card. Reply 13 of 27, by sdz Posted on 2024-06-04, 11:32 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU Got the other TMDS input working, and programmed the scaler on the VSA-100 card: 20240604_124648.jpg Filename 20240604_124648.jpg File size 1.94 MiB Views 52528 views File license Public domain 20240604_124705.jpg Filename 20240604_124705.jpg File size 1.61 MiB Views 52528 views File license Public domain https://www.youtube.com/watch?v=yuj_HG3H74w Next is to change the FPGA code a bit, for the messed up video format that the VSA-100 will output when plugged into a laptop. Reply 14 of 27, by sdz Posted on 2024-06-04, 12:32 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU Here it is, world's first 3dfx powered laptop 😁 20240604_150929.jpg Filename 20240604_150929.jpg File size 1.71 MiB Views 52508 views File license Public domain 20240604_150325.jpg Filename 20240604_150325.jpg File size 1.83 MiB Views 52508 views File license Public domain 20240604_150320.jpg Filename 20240604_150320.jpg File size 1.65 MiB Views 52508 views File license Public domain 20240604_150201.jpg Filename 20240604_150201.jpg File size 1.8 MiB Views 52508 views File license Public domain 20240604_150208.jpg Filename 20240604_150208.jpg File size 1.52 MiB Views 52508 views File license Public domain https://youtu.be/f1h572CyArk?si=btRd7BH3IB-1CR8d There are still a few things to do, fix brightness/contrast, figure out why the image is shifted right by about 5 pixels and fix it, read temperature sensors, control fan, send shutdown signal to host in case of overtemperature, and maybe figure out a way of controlling the panel's backlight from the OS. But the card works perfectly 😀 Reply 15 of 27, by DrAnthony Posted on 2024-06-04, 13:10 Reply with quote Creative Commons Attribution 4.0 International license More actions DrAnthony Offline User metadata Rank Newbie Rank Newbie Posts 90 Joined 2021-04-16, 22:37 Wow, wow, wow, wow,WOW! Thanks for sharing this along with your insights. I'm sure we've all got a display sitting somewhere in house that's got some pesky overscan setting. Mine just so happens to be a 2008 vintage Sony TV in my basement, but the pain is there nonetheless. Reply 16 of 27, by sdz Posted on 2024-06-05, 17:30 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU @DrAnthony No problem 😀 . I managed to fix the scaler brightness/contrast bug, and set them to some decent values (I'll tweak it to \"perfection\" later). Now the display looks so much better: 20240605_192327.jpg Filename 20240605_192327.jpg File size 1.34 MiB Views 52307 views File license Public domain Also measured VRMs temperature, as these are not covered at all by the existing heatsink. IMG_20220101_051228.jpg Filename IMG_20220101_051228.jpg File size 508.54 KiB Views 52307 views File license Public domain IMG_20220101_051231.jpg Filename IMG_20220101_051231.jpg File size 467.07 KiB Views 52307 views File license Public domain At 2.5V VCORE, 166MHz core/memory frequency, idle: 85.9C, load: 87.6C. This is well within spec, the VRM ICs are rated to operate at 125C. If it ever gets beyond that, the MCU will immediately shut down the power rails and issue an overtemperature event that will shutdown the laptop. This way nothing will ever get damaged. VSA temperature is good, I can't yet say exactly what it is yet, but the cooling system works really well. There is a temperature sensor right underneath the VSA, but it's not currently read by the MCU: Screenshot 2024-06-05 194516.jpg Filename Screenshot 2024-06-05 194516.jpg File size 288.25 KiB Views 52307 views File license Public domain Screenshot 2024-06-05 194534.jpg Filename Screenshot 2024-06-05 194534.jpg File size 494.75 KiB Views 52307 views File license Public domain When doing the VRM temperature measurements, I found a bug. When I tested the card plugged into a PC, I was able to overclock it just fine with V.ctrl or VSA100 OC. However, when I do the same thing with the card plugged into the laptop, the new clocks apply, but, as soon as a Glide or D3D application is started, the card clocks change back to the default 166MHz. Either something is messed up in that system, or this is somehow caused by the lack of VSA BIOS. Found some other issues as well. While the VSA-FPGA-HDMI works fine for 640x480,800x600,960x720,1024x768,1152x864,1280x720,1280x1024,1360x768,1600x900,1600x1024, and the HDMI-SCALER-LVDS works fine for those resolutions as well, when doing VSA-FPGA-SCALER-PANEL there are quite a few resolutions with major issues. I suspect most of this is caused by my FPGA code, as well as the whole image shifted to the right by about 5 pixels. Last edited by sdz on 2024-06-06, 13:36. Edited 1 time in total. Reply 17 of 27, by sdz Posted on 2024-06-06, 13:00 Reply with quote Creative Commons Attribution 4.0 International license More actions sdz Offline User metadata Rank Member Rank Member Posts 329 Joined 2019-12-28, 19:21 Location EU I changed the panel backlight control to the scaler instead of the MCU (the board was design to permit both, with a resistor position change). Now, when the system is on, but the screen should be off, it's black with no backlight, instead of black with backlight on. Also tweaked/fixed various other scaler related things, now the scaler does pretty much all what I wanted it to do. While I didn't manage to overlock the card with V.ctrl or VSA100 OC (in the laptop), it works with Voodoo 5 Overclocker 1.0. I managed to push the card from the stock 166MHz to 200MHz, at 2.9V VCORE. Not bad considering it's a 220 revision VSA-100 and 166MHz rated RAM. I have a couple of VSA-100 320 rev ICs, and I'll try to source 200MHz rated RAM. After that it should go higher. With the card installed in the laptop, 64MB RAM, 200MHz core/mem clock, XP SP3, SFFT1.9, 3DMark2001SE default settings, 1024x768 32bpp, no tweaked LOD: 2148 3D Marks. 20240606_144858.jpg Filename 20240606_144858.jpg File size 1.81 MiB Views 52018 views File license Public domain Reply 18 of 27, by progman.exe Posted on 2024-06-06, 13:47 Reply with quote Creative Commons Attribution 4.0 International license More actions progman.exe Offline User metadata Rank Newbie Rank Newbie Posts 93 Joined 2023-04-30, 21:09 Location C:\\WINDOWS\\ EDIT:I wrote and posted this before reading you'd got it OC'd with another program. Another reason to basically ignore it 😀 --------------------------------- sdz wrote on 2024-06-05, 17:30: When doing the VRM temperature measurements, I found a bug. […] Show full quote Staggering work. I showed a nerd-mate your website, he tried to be \"lol retro why\", but the still-gaming-nerd in him knew what he was looking at, and he ended up being impressed. All I can suggest is bodges: What about something like have a program sleep for 30 seconds, then run a program that turns up the clock. In that 30 seconds, you start your Glide/D3D program, and the overclock is applied in the background? Or is that recipe to insta-crash the drivers or program? Otherwise, can you use the FPGA to also hold a copy of the VSA BIOS? Just adding this idea to make it clear I don't know what I am actually looking at 😀 Keep up the good work sdz! Reply 19 of 27, by EriolGaurhoth Posted on 2024-06-06, 17:16 Reply with quote Creative Commons Attribution 4.0 International license More actions EriolGaurhoth Offline User metadata Rank Newbie Rank Newbie Posts 21 Joined 2023-01-17, 23:10 I've dreamed of this thing, pretty much my entire life: a proper 3Dfx-powered laptop! I just discovered this today while posting to an old thread about my desire for one of these things, haha! Re: Hardware experts, are we ever going to see replica 3D GPU's? Go to top of page Go to top of page Page 1 Page 2 Back to Video",
    "commentLink": "https://news.ycombinator.com/item?id=40613854",
    "commentBody": "3dfx Voodoo 4 video card in MXM format (2023) (vogons.org)145 points by zdw 19 hours agohidepastfavorite45 comments jadbox 3 hours agoThis is the kind of high-quality niche posts that makes HN for me. This is really an incredible hobby project that someone has also taken time to share details about. reply matthberg 18 hours agoprevMXM cards unfortunately seem to be incredibly niche and vendor locked with BIOs whitelists, but allowing for swapable GPUs on laptops would be amazing for e-waste reduction and upgradability. It's a shame the Framework laptops don't support them, it seems right up their alley. Cool to see a project messing with them though! reply windowsrookie 5 hours agoparentThe problem is it adds quite a bit of thickness to the device. The framework 16 solution where it slides into the back is better, but we will see how well upgrades are supported. Surprisingly the older iMacs are very upgradeable because of their socketed CPU and MXM GPU. I recently received a free 2010 iMac and was able to upgrade the dual core i3 CPU to a quad core i7, which then boosted the RAM limit to 32GB. I also grabbed an $8 FirePro M4000 MXM GPU from a dell laptop and flashed it for MacOS compatibility . This old 2010 iMac now has a quad core cpu, 32GB RAM, and a metal capable GPU running the current version of macOS Sonoma. It's running great, and I can essentially run every app on the machine without ever hitting swap, unlike my 8GB MacBook Air. reply qingcharles 1 hour agorootparentDamn, that's a sweet set of upgrades. And shoving in a decent SSD too? I just got given a 2010 MacBook Air with 2GB of RAM, and well, it's kinda sad :( reply windowsrookie 1 hour agorootparentThanks haha and yes I also installed an SSD. Unfortunately this iMac is only SATA II, so that limits the speeds a bit, but it is still much faster than an HDD. Apple's desktops of that era were quite upgradeable, but those old MacBook Air's were the beginning of what Apple devices became today. reply VagabundoP 4 hours agorootparentprevWhere is your blog about this?? So I can post it to hacker news :/ No seriously I have a could have 2010 iMac laying around. How much was the i7? reply windowsrookie 56 minutes agorootparentI have thought about blogging a bit but there are already many people blogging who are much more knowledgable than me. :) This iMac is the 21\" model, they have a smaller PSU and cooling, so the most powerful chip you can install is the i7-860s (82W CPU). I paid $25 from aliexpress. If you have the 27\" iMac you can install the i7-860 (without s) that is a 95W CPU and can boost to higher clock speeds. This is also a more common chip so likely cheaper than the i7-860s. Both chips should boost the default max of 16GB RAM to 32GB RAM. reply msk-lywenn 4 hours agorootparentprevWould you happen to have a breakdown on how to flash the gpu? reply windowsrookie 54 minutes agorootparentThis thread on MacRumors has everything you need to know. https://forums.macrumors.com/threads/2011-imac-graphics-card... reply nrp 3 hours agoparentprevWe had to develop a new interface for swappable GPUs to make the graphics card and mainboard co-planar. MXM requires the graphics card to be stacked above the mainboard, which results in really thick laptops. This is part of why MXM is largely dead for consumer usage and lives on mostly for industrial and embedded applications. reply hi-v-rocknroll 17 hours agoparentprevMaybe but it doesn't matter because they're not using it directly. The card was AGP/PCI while MXM on the laptop is PCIe, so they had to create an adapter including a AGP/PCI-to-PCIe bridge. In this case, they shoved this graphics card with its adapter into a Dell Precision M4800 released in 2013 because they needed to run Windows XP. They also created another PCB as a PCIe 1x adapter to run it on desktops. The card was probably intended to work with a specific model of gaming or workstation laptop from 2000 but it's doubtful any made it past the prototype stage. Maybe Dell or Acer sold one or two models of it. (My Voodoo2's are jealous BTW.) reply mjg59 8 hours agorootparentI think you're confused - this is a from-scratch new design, not an old prototype. There's no adapter other than the desktop mount, the VSA-100 is directly mounted to the board that plugs into the laptop. reply steelbrain 9 hours agoparentprevUnrelated to MXM but I've struggled with the same problem you described (swappable GPUs on laptops). The current solution I've settled with is to get a laptop with a pcie gen4x4 nvme slot, install an oculink adapter on it and connect my full size RTX 3090 to it. No performance diff far as I can see (oculink on pcie gen4x4 should have ~64GBps bw) and still super portable. and I can finally upgrade the CPU/display and GPU independently reply steelbrain 1 hour agorootparentPosting a correction since I can no longer edit the original. It's actually 64Gbps (bits not bytes) reply matthberg 18 hours agoparentprevIf anyone knows of a guide or layman-accessible reference talking more about them (compatibility, bios hacks, part sourcing best practices) I'd love to hear about it. reply okasaki 14 hours agoparentprevI think as power consumption only gets worse for GPUs, external GPUs is the solution that makes the most sense... reply hulitu 5 hours agorootparentOr better design ? /s reply clausecker 5 hours agoprevI have a Dell Precision M4800 and would like to upgrade the GPU to an Intel Ark A370M, which is available in MXM format. Does anybody know how to add this card to the BIOS whitelist? reply userbinator 15 hours agoprevIt seems enthusiasts are quite interested in 3dfx GPUs for some reason --- lots of NOS parts with detailed documentation available? There was this not too long ago: https://news.ycombinator.com/item?id=32960140 reply adastra22 10 hours agoparentMaybe you're too young, but in the late 90's 3Dfx was so hot. They weren't the first GPU, but they were the first to break out and make it big in the PC space. The difference between software rendering and hardware accelerated Voodoo graphics was nuts. It was mind blowing. Once one of your friend's had a Voodoo card, software rendering was never enough. You had to get one too. Between the release of the Voodoo 3 and Voodoo 4/5, NVIDIA would eat 3Dfx's lunch, but not (at first) by having better tech. They just built momentum by consistently releasing new cards every six months like clockwork, whereas the Voodoo 4 and Voodoo 5 cards were feature-oriented releases stuck in development hell. 3Dfx was still the sexy hotrod brand, although NVIDIA's market share kept growing. Then the GeForce 2 came along and it was clearly better than any 3Dfx offering, while people were tired of waiting for a new Voodoo card. The rest is history. reply nickpeterson 5 hours agorootparentI remember cutting grass for neighbors during the summer when I was 11 to save up money for a 3dfx voodoo2 8mb card to put into my parents computer (packard bell 200 megahertz pentium). The driving force behind this obsession was a foldout ad in pc gaming magazine with a screenshot of the game Unreal. I remember my Dad (who was very non-technical at the time) trying to talk me into one of the other cards at CompUSA (a PowerVR if I recall) and I was explaining why I wanted the 3dfx (I'm sure I was regurgitating whatever I read on HardOCP). We got home, figured out how to install it and the drivers ,and booted up Unreal. Amazing moment in my life, and probably one the main reasons I ended up being a software developer. Tweaking settings, learning commands in the 'in-game terminal', understanding basic networking to help pick servers, tinkering with the level editor. PC Gaming was an amazing introduction to 'How Computers work' with a really motivating example. I feel like my kids completely miss that because they just play games on an ipad which completely insulates them from any of it. reply goeiedaggoeie 8 hours agorootparentprevOMG i loved my 3dfx vodoo 3 card. I had a 20 port hub and we would basically have roaming LAN parties. You brought back a lot of good memories here. reply locallost 7 hours agorootparentprevI agree except for Nvidia not having better tech. Riva TNT was not on 3dfx level, but GeForce was groundbreaking. 3dfx managed to match it with Voodoo 4/5 although it didn't get great press after all the delays, but then GeForce 2 came out and 3dfx was toast. At the time, a big angle was also that 3dfx made its own cards and Nvidia just did the chips for dozens of manufacturers, so it had the advantage there. But that's a bit of survivorship bias IMHO because e.g. Apple also does everything today and vertical integration is touted as their advantage. In the end either your tech works and has a market fit or it doesn't. Pretty crazy how Nvidia grew from that to a top 5 company in the world in 25 years. reply adastra22 1 hour agorootparentI mentioned the GeForce 2 in my comment :) Apple was also on its dying legs at the time, and their stellar rise was even faster. reply pjmlp 3 hours agorootparentprevI was so pissed off, after managing to buy a Voodoo, having to come back to the shop and replace it with a Riva TNT, because for some odd reason it wouldn't work on my PCI bus. reply ZFH 3 hours agorootparentprevGot to agree here, in fact what I remember is that the Riva TNT 2 already was the smart pick vs. what 3Dfx had out at the same time, even though Voodoo was the cooler brand and had all that previous goodwill. reply bloatfish 3 hours agorootparentI had a Voodoo 3 3000, friend had a TNT2. If the game supported Glide and/or had a minigl driver available it blew the TNT out of the water. Direct3D-games however the reverse was true. reply nottorp 3 hours agorootparentprevRiva TNT was affordable. And since back then any hardware accelerated solution that was supported by games was millions of miles ahead of software rendering... that was enough. reply whaleofatw2022 6 hours agorootparentprevLet's also note that Before Voodoo3, 3dfx had other board partners. Also should note that back then, AFAIR ATI and Matrox only sold full cards. Nvidia also allowed, relatively, a lot of customization of their boards back then. My first GF2 had VIVO and even LCD shutter 3d glasses for a CRT. reply blt 15 hours agoparentprevFor people of a certain age, 3dfx is iconic. As a teenager, you read a bunch of reviews about how great it was. This was before widespread broadband and there wasn't much PC gaming content on TV, so you didn't really know what it looked like. After months/years of saving you finally bought one, put it in your PC, started up Quake 2, and it was f**ing amazing. GeForce came along soon enough and made it obsolete, but never had the same mystique. reply dehrmann 13 hours agorootparentI still remember being jealous of the kid at computer camp with the two SLI Voodoo 2s playing Unreal. reply dcanelhas 10 hours agorootparentSLI being \"scan-line interleaving\" at the time. Not to be confused with today's \"Serial Link Interface\" reply theandrewbailey 5 hours agorootparent> Not to be confused with today's \"Serial Link Interface\" Scalable Link Interface. And it's not available today either. The last cards that used it was the 1000 series. The 2000 and 3000 cards used NVLink, but that's disappeared from the 4000 series, too. reply sundvor 15 hours agorootparentprevYup! And when V2 came out, I had two of them, if memory serves. The 3dfx Voodoo II was awesome for the longest time. reply anthk 8 hours agoparentprevThe 3DFX jump was almost the same as playing games badly rendered from the GBA (or maybe the first Nintendo DS games) to the quality of the PSP. Or, as a better example, compare the V-Rally game for the GBA with Ridge Racer for the PSP. Deus Ex and Unreal could run under a 3DFX card. The jump from a software rendered Quake (or just any software rendered Unreal game) to a hardware rendered one was pretty noticeable. reply sgerenser 16 hours agoprevWhy is this marked (2023) but the post is from May 30th 2024? reply mk_stjames 11 hours agoprevAmazing. Were the 3dfx chips just openly documented enough for this kind of thing to be possible with original information sources, or have these chips been reverse engineered to get to the point where a project like this is possible? I ask because in today's hardware, it's almost laughable to even expect a pinout of a GPU to be publicly disclosed. reply Rinzler89 10 hours agoparent>Were the 3dfx chips just openly documented enough All chips have always been documented well enough, since that's the only way for the board partners and system integrators to know how to build cards with them and write drivers for them as was common back then, so everything had to be well documented, same how we have datasheets today with all the low level registers, and application notes with PCB and code samples. The question is always how sticky the NDAs are for you to also get your hands on them, but since 3dfx went bust, the leaks are no longer a problem. reply mk_stjames 6 hours agorootparentYes of course, hence my word 'openly'- I mean, at some point in the 90's designs started to get locked behind NDA's even just to get the docs. At the time of original manufacture (99/00?), if you were a company making cards, I assume the documentation of the Voodoo 4 was locked behind an OEM agreement? And then at some point that information has leaked out onto the web? Curious to when and how that went down. I fear that so many things now will never get to that point of seeing public light. reply Sharlin 1 hour agorootparentCertainly contracts become null when one of the parties stops existing as a legal entity. reply dark-star 6 hours agoprevThis looks cool. Is there a list of what laptops have (or had) MXM slots? reply SV_BubbleTime 14 hours agoprevI’m interested in that PCB. How many layers, min trace, and if it was blind/buried. Can’t seem to find any information on it. Looks like a nice layout. reply sdz-mods 9 hours agoparentIt's a 12 layer board, 0.15mm vias, 0.05mm annular ring size, plugged and capped vias. reply userbinator 14 hours agoparentprevThe pictures of the layout seem to have at least 4 layers I can see. Could be buried vias. reply mouse_ 19 hours agoprev [–] love this reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A user named sdz is integrating a VSA-100 video card into a Dell Precision M4800 laptop, addressing BIOS incompatibilities and using an FPGA and Realtek scaler to convert HDMI to LVDS for the screen.",
      "The project involves significant technical challenges, including motherboard modifications, backlight control, resolution scaling, and overclocking the graphics card, with progress shared through images and videos.",
      "The project has attracted interest and suggestions from the community, with plans to open-source the design, and excitement from users like EriolGaurhoth about the 3Dfx-powered laptop."
    ],
    "commentSummary": [
      "A Hacker News discussion explores a hobby project using a 3dfx Voodoo 4 video card in MXM format, emphasizing the niche and vendor-specific nature of MXM cards.",
      "Users highlight the benefits of upgradable laptops like Framework to reduce e-waste and share experiences with upgrading older Apple devices and systems using MXM and PCIe GPUs.",
      "The conversation reflects on 3dfx's impact in the late 90s, its competition with NVIDIA, and includes technical details on GPU upgrades, BIOS hacks, and a 12-layer PCB project, showcasing the evolution of graphics cards and nostalgia for 3dfx's legacy in PC gaming."
    ],
    "points": 145,
    "commentCount": 45,
    "retryCount": 0,
    "time": 1717801861
  },
  {
    "id": 40615786,
    "title": "Boeing 737-800 Narrowly Avoids Disaster Due to Known Autothrottle Software Glitch",
    "originLink": "https://www.independent.co.uk/travel/tui-boeing-flight-bristol-disaster-avoided-b2558536.html",
    "originBody": "Travel Disaster narrowly avoided as plane clears Bristol Airport runway with just seconds to spare Boeing aircraft, operated by TUI, departed for Las Palmas, Gran Canaria with 163 passengers on board when it struggled to take off Matt Mathers 1 day ago Comments Related video: New Boeing whistleblower claims he was pressured to hide plane defects Sign up to Simon Calder’s free travel email for expert advice and money-saving discounts SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy policy A potential disaster was narrowly avoided when a packed passenger plane took off just seconds before it was about to run out of runway because of a software glitch. The Boeing aircraft, operated by TUI, departed from Bristol Airport for Las Palmas, Gran Canaria on 9 March with 163 passengers on board when it struggled to take off. The 737-800 plane cleared runway nine with just 260 metres (853ft) of tarmac to spare at a height of 10ft. It then flew over the nearby A38 road at a height of just 30 metres (100ft) travelling at the speed of around 150kts (about 173mph). The A38 is a major A-class busy road, connecting South West England with the Midlands and the north. The Air Accidents Investigation Branch (AAIB), part of the Department for Transport, said the incident was the result of insufficient thrust being used during take-off. Pilots manually set the thrust level following a software glitch that Beoing was aware of before take-off. (Getty Images) “A Boeing 737-800 completed a takeoff from Runway 09 at Bristol Airport with insufficient thrust to meet regulated performance,” the AAIB report said. “The autothrottle (A/T) disengaged when the takeoff mode was selected, at the start of the takeoff roll, and subsequently the thrust manually set by the crew (84.5% N1 ) was less than the required takeoff thrust (92.8% N1 ). “Neither pilot then noticed that the thrust was set incorrectly, and it was not picked up through the standard operating procedures (SOPs).” The plane’s acceleration was significantly slower than 99.7 per cent of other aircraft of the same model departing the same airport, performance data collated by the AAIB showed. The autothrottle system on a Boeing 737-800 can control the thrust from takeoff to landing, the AAIB added. Boeing told investigators looking into the incident that they were aware of a “long history of nuisance disconnects during takeoff mode engagements”. It added that plane was fitted with and FDR recording device, known as a ‘black box’, which records flight data and a CVR, which records the recent sounds in the cockpit. The AAIB said: “G-FDZS was fitted with both an FDR and a CVR. The CVR fitted to G-FDZS was not removed from the aircraft as it continually overwrites itself, retaining only the last two hours of audio. “As such, the recording of the takeoff would have been overwritten during the flight to Las Palmas. However, the FDR was removed and downloaded”. The incident is the latest in a string of problems with Boeing jets in recent years. The aerospace giant’s safety standards are coming under increasing scrutiny following several recent incidents, including one where a disused door fell off a brand new 737 Max shortly after take-off. There were no injuries. In April a FedEx Airlines Boeing cargo plane landed at Istanbul Airport without the front landing gear deployed but managed to stay on the runway. Five years ago, Boeing agreed to pay $2.5bn and make safety improvements after two new 737 Max jets crashed within the space of five months - one in Indonesia in 2018 and one in Ethiopia in 2019, killing a total of 346 people. In May US officials warned Boeing it could face criminal charges after claims the airline failed to improve plane safety and adhere to a settlement after the deadly 737 crashes. A TUI UK&I spokesperson said: “We have worked closely with the authorities to provide all available information. “The AAIB recommendations and learnings resulting from this take-off will support the whole aviation sector and other airlines. The safety of our passengers and crew is always our highest priority.” Boeing was contacted for comment. More aboutTuiBristol AirportBoeing Most Popular Popular videos Sponsored Features",
    "commentLink": "https://news.ycombinator.com/item?id=40615786",
    "commentBody": "Boeing Passenger Jet Nearly Crashes Because of Known Software Bug (independent.co.uk)144 points by xrayarx 12 hours agohidepastfavorite59 comments HL33tibCe7 8 hours agohttps://avherald.com/h?article=5194536c and https://www.gov.uk/aaib-reports/aaib-special-bulletin-s1-sla... is the AAIB report Summary: > The aircraft took off from Runway 09 with a thrust setting significantly below that required to achieve the correct takeoff performance. Rotation for the takeoff occurred only 260 m before the end of the runway and the aircraft passed over the end at a height of approximately 10 ft. The N1 required to achieve the required takeoff performance was 92.8% but, following an A/T disconnect when the crew selected TOGA, 84.5% was manually set instead. Despite an SOP requirement to check the thrust setting on takeoff, the crew did not realise that the thrust was not set correctly until after the takeoff although they had noted how close to the end of the runway they were. The A/T had disconnected when the TOGA switch was pressed due to a fault with the ASM associated with the thrust lever for engine 1. This disconnect was a known issue with the older type ASMs fitted to the aircraft type. The manufacturer has issued a Fleet Team Digest for operators detailing the issue and the SB for replacing the ASMs with a newer model. reply mannykannot 6 hours agoparentThanks for the links. I had to go to the PDF [1] linked from the AAIB Special Bulletin to get a somewhat clear picture of the sequence of events (though if I were a 737 pilot or engineer, it all might have been obvious from the summary): \"Having completed their pre-flight preparation, the aircraft left the stand at Bristol to taxi to Runway 09 at 1041 hrs. The A/T arm switch on the Mode Control Panel (MCP) had been set to ARM during the before start procedures in accordance with the operator’s SOPs. The aircraft taxied onto Runway 09 at 1104 hrs and was cleared for takeoff shortly afterwards. The left seat pilot handed control of the aircraft to the right seat pilot who was to be PF for the sector. The PF advanced the thrust levers to 40% N1 and paused for the engines to stabilise before pressing the Takeoff/Go-Around switch (TOGA) which engages both the A/T in N1 mode and the autopilot/flight director system (AFDS) in takeoff mode. At this point, the A/T disengaged with an associated warning and the A/T arm switch on the MCP was reengaged by the PM almost immediately afterwards. At the same moment the PF advanced the thrust levers manually towards the required takeoff setting before releasing the thrust levers for the left seat occupant to control in accordance with the SOPs. \"When the A/T arm switch was re-engaged on the MCP after initial A/T disengagement, it did not control the thrust lever servos as the pilots expected and instead entered an armed mode. As a result, the thrust levers did not advance to the required thrust setting and neither pilot moved them from the position the PF had set them to. Despite the SOP requiring that the thrust is set by 60 kt and checked as correct at 80 kt, the incorrect setting was missed by both pilots. This resulted in the aircraft takeoff being conducted with significantly less thrust than required, 84.5% N1 was used instead of 92.8% N1, with the associated reduction in aircraft performance.\" At this point, it is clear to me that the pilots missed two mandated checks of the power prior to rotation, but it is not entirely clear to me at what point, in this rather complicated sequence of events, things first deviated from what should have happened if both the equipment and pilots were performing as intended - was the A/T disengagement after TOGA selection the intended and expected behavior, or was the first deviation when it went into armed mode after re-engagement? [1] https://assets.publishing.service.gov.uk/media/665092d816cf3... reply amenhotep 5 hours agorootparentNot an expert, but it seems very clear to me that autothrottle is not intended to disengage when you press the takeoff/go around button. The whole point of that button is that you press it when you need to take off or go around and the plane attempts to set itself to a configuration where as long as you point the nose in the right direction then that should happen. But it does rather sound like it was an expected behaviour. The system has a history of nuisance disconnects, the manufacturer recommends that you reject takeoff when that happens, and for some reason instead of doing that, the crew reacted to the disconnect warning by pressing the button again and, at that point, trusting that it was engaged and working. My reading of that is that the plane regularly has an A/T fault that can be fixed by simply pressing the button again, so this crew has developed a habit of doing that, but this time it was a different fault with different behaviour that their usual fix didn't work for, and they just failed to notice. The report is clearly limiting itself to describing the difference between what actually happened and what the procedures say should happen, rather than speculating about what the pilots were thinking, but that's the only way it makes sense to this very much not expert that you shouldn't pay too much attention to. reply Dalewyn 5 hours agorootparentWhat's damning about the pilots is they utterly failed to monitor their engine gauges, which for those who don't know are always prominently displayed on one of the big displays near the center of the instrument panel and easily visible to anyone anywhere in the cockpit. Takeoff is by far the most stress the engines will endure during a nominal flight, it is imperative that the engines are monitored closely during takeoff in case they fail so the pilots can respond immediately. We're talking Basic Flying 101 here and these guys failed it. reply kashunstva 10 hours agoprevThe title here and the text of TFA reduce the incident to a single point of failure. There are conditions in which the TO/GA mode when engaged will fail to set the calculated and the crew is required to manually set the takeoff thrust. Confirmation of takeoff thrust set should be called out. Was that done? Boeing is under justifiably intense scrutiny for many of its manufacturing and engineering practices but the press needs to apply intellectual honesty in reporting incidents like this. It seems that the crew may have known that the thrust was not properly set when TO/GA was engaged and then manually set an incorrect thrust. Like many incidents, this is likely to have layered causes. Why not report that upfront? reply VBprogrammer 7 hours agoparentThere is a lot of basic airmanship which has failed here. For example from your first day of PPL training you are taught to backup the throttles during takeoff and at low altitude to avoid them creeping backwards. You are also taught to cross check that you've achieved half the rotation speed at 1/3 of the runway available. Obviously these practices are less applicable to an airliner but the basics are still there. The pilots should be monitoring engine performance and acceleration to avoid these type of issues. In this case it was a software bug but it would be just as easy for it to have been a wrongly input takeoff weight or temperature to affect the calculated TOGA power. reply gklitz 9 hours agoparentprev> Boeing is under justifiably intense scrutiny for many of its manufacturing and engineering practices Well that yes, but not just the engineering and manufacturing practices or apparent lack of safety, also the extremely suspicious conditions of the deaths of whistleblowers who came forwards against them. So far two are dead. reply dash2 9 hours agorootparentThis is a conspiracy theory. At least one of the deaths is not suspicious, and the person's family have said so themselves. reply marginalia_nu 8 hours agorootparentWell, yes, it's the very definition of a conspiracy theory. That doesn't mean it's automatically false though. reply peterfirefly 8 hours agorootparentprev“To lose one parent, Mr. Worthing, may be regarded as a misfortune; to lose both looks like carelessness.” reply lupusreal 7 hours agorootparent\"Once is happenstance. Twice is coincidence. Three times is enemy action.\" reply shafyy 5 hours agorootparentprevThe conspiracy theory is that Boeing hired somebody to kill the whistleblowers. But even if they committed suicide (which is more likely), it is because of the immense pressure but on them by Boeing. Which, in my book, is as bad as hiring a hitman. reply lamontcg 2 hours agorootparentThe guy who died of MRSA in a hospital didn't die of suicide. That is a failure of our healthcare system. reply amelius 6 hours agoparentprevShouldn't there be a design rule that if an automatic setting can fail, then it should be completely manual? reply yuliyp 5 hours agorootparentNo. Every system can fail. Manual systems fail too (people aren't perfect). Having an automated system there for most of the time when it's more likely to do the right thing than a human is still good for the overall reliability of the system. reply amelius 2 hours agorootparentAnother rule could be that the system should sometimes set a random value and then when the pilot doesn't catch it there should be an automatic report about it (and the plane should refuse to start). reply amelius 5 hours agorootparentprevTrue, but in this case there was a __known__ bug. reply shadowgovt 7 hours agoparentprevIt's also a circumstance where even if the problem is known, the correct solution may not be to fix it on already flying models. Complicated professional transportation infrastructure isn't like a web app. Pilots become familiar with the quirks of the machine, and changes to said quirks sometimes require recertification or reevaluation; otherwise, they could jeopardize passenger safety as new behavior interferes with pilots' learned routines. It is reminiscent of the problem with the Apollo flight computer where it was known that rerunning the initialization program mid-flight would put the machine in a state where it had no understanding of its current position, but because they had already woven the computer core the solution was to come up with a way to restore flight state and correct the error instead of making the error impossible. reply Dalewyn 8 hours agoparentprev>Why not report that upfront? Because it doesn't pay to be honest. reply ArdentAardvark 8 hours agorootparentI don't see any dishonesty here. Boeing has designed a system that sets up pilots for failure. It's Boeing's fault, not the pilots', that the auto-throttle disengages for no reason and that they then have to manually set the correct thrust during an already high workload situation. It's absurd and unacceptable. This is the kind of unsafe work culture that I thought we were done with in aviation. reply Dalewyn 8 hours agorootparentBlaming Boeing and only Boeing is intellectual dishonesty, blaming the pilots for failing to fly their plane is also necessary. Remember, TOGA and autothrottle are not necessary for safe flight. It is also explicitly a pilot's job to manage the engines among many other things. It's why there are two pilots in the cockpit, one is in control of the aircraft while the other is keeping tabs on secondary and tertiary needs like radios and cross checking instruments with the pilot in control. If the aircraft isn't accelerating properly, it is the pilots' job to respond including rejecting the takeoff before it's too late. Takeoff is by far the most stressful part of a flight for the engines, if the pilots are not keeping close tabs on the engines during takeoff then they are fundamentally unfit to fly. Blaming Boeing and only Boeing is dishonest and doesn't address the problem, but it does pay the medias' bills by stoking the furor of readers such as yourself. reply conartist6 7 hours agorootparentJust because a system isn't necessary for safe flight doesn't meant that a) it can't kill you or b) you shouldn't use it. If you think that blaming the people will solve the problem, then I'm excited to be the one to introduce you to one of the most important and underserved fields of engineering: human factors, the study of which is a major reason we have safe aviation. reply zaphar 5 hours agorootparentHuman factors is an important field of study, yes. But just because we know humans make mistakes doesn't mean we can't hold them accountable for those mistakes when they happen. Our tendency to focus on one thing to the exclusion of the other things is bad for getting a full understanding of what is going on. Two things are true in this incident: 1. Boeing has a known unfixed software bug in their planes that puts pilots in a bad position. It has multiple known failures that look the same and created a learned response that was incorrect. This is bad and Boeing should answer for it. 2. The pilots are ultimately responsible for making sure they are hitting the correct speed for take off and should be aborting if they are having difficulty making that speed. They failed to do so in this case. This is bad and they should have to answer for it. Both of these are true and neither one excuses the other. reply TheOtherHobbes 7 hours agorootparentprevTOGA and A/T are not necessary, but if they're supplied they should work reliably. If they don't, and pilots have to cover for their failures manually, that's one more avoidable point of failure. Adding one more avoidable point of failure is NOT acceptable. reply Dalewyn 5 hours agorootparentThat this has to be an either-or crusade against Boeing instead of blaming all the relevant parties speaks volumes about how much fucking damage \"journalism\" like this does. Once again: Both Boeing and the pilots along with whoever else is involved in this are all to blame equally. If you're going to let pilots who don't properly check their engine gauges off the hook because you are far more interested in crapping on Boeing specifically, planes are eventually going to come down regardless of Boeing. reply DemocracyFTW2 40 minutes agoprev> The 737-800 plane cleared runway nine with just 260 metres (853ft) of tarmac > to spare at a height of 10ft. > It then flew over the nearby A38 road at a height of just 30 metres (100ft) > travelling at the speed of around 150kts (about 173mph). This got my head spinning, what a jumble of units reply ThinkBeat 7 hours agoprevThe pilots turned off the autopilot for takeoff due to a known bug. Flying manually the pilots made an error when setting the required thrust that nearly caused the plane to run off the runway without getting off the ground? Is that correct? In which case it seems like pilot error. reply ryankrage77 7 hours agoparentIt's not clear from the article whether A) The autothrottle disengaged due to the bug, and the throttle defaulted back to some previously set value, without the pilots knowledge. B) The pilots disabled the autothrottle to avoid a bug, and also failed to set the throttle correctly. reply pmontra 7 hours agoparentprevHuman errors happen. That's why they take off with the autopilot, but the autopilot doesn't work well enough and everybody AFAIK has to take off manually. Great job from Boeing. reply aaomidi 7 hours agoparentprev? lol. Disabling automation because of a bug and doing manual stuff is how things break. This is true in WebPKI, it’s true in planes as well. reply conartist6 7 hours agorootparentIt's actually the right way of thinking! When high-level automation fails you, messing around with the high-level system in a critical moment would probably be your death. Debugging takes minutes not seconds. This is why pilots are trained to drop from a high level automation to a lower one when necessary. Like most learnings about piloting, this insight was purchased with a lot of blood. If you want to know more, check out Children of the Magenta Line: https://www.youtube.com/watch?v=5ESJH1NLMLs reply worewood 6 hours agorootparentThe problem is not dropping automation when it fails. The problem is dropping automation BECAUSE it fails. They aren't able to rely on the automation because it's faulty - and as consequence error rate increases. reply ggm 11 hours agoprevBeing operator-conditioning-trained to click through warning signs is a huge problem for everyone. The car drivers with dashcams on that stretch of motorway they cleared at 30m must have some fantastic vision. I hope it's been uploaded to the Web (like sint maarten but not beach: trucks) reply whamlastxmas 6 hours agoparentGood argument for the morality of ad blocking reply ojosilva 5 hours agoprevI'm not comfortable with a future where Boeing becomes niche or \"commercially deprecated\", with current planes aging and no good maintenence path forward. It will become a safety liability that we passengers will have to bear. Boeing's demise would create an amazing opportunity for Chinese aviation to make its move. It takes decades to really enter the market but it could, slowly, happen. Embraer otoh is not in a position (huge investment) or just not interested (too risky) to enter those 737/MAX and long haul markets. reply ChrisMarshallNY 8 hours agoprev> Pilots manually set the thrust level following a software glitch that Beoing [sic] was aware of before take-off. Oooh... that's gonna leave a mark. reply agilob 7 hours agoparentBut this part should be more widely remembered: >The crew manually set the thrust to 84.5% N1 (rather than 92.8% N1 as needed) and continued takeoff. The aircraft rotated about 260 meters prior to the end of the runway and crossed the end of the runway at 10 feet AGL. The crew continued the flight to Las Palmas although whenever they tried to engage autothrust, it disconnected again. The aircraft landed safely in Las Palmas. 10 feet is 3 meters reply IG_Semmelweiss 6 hours agoprevIt is really disheartening to see a cutting-edge engineering company making news for failures of design or engineering, vs in the news for innovation engineering, new designs, and new trials. Its as if the soul of the company has been taken away forever. Contrast Boeing with Nvidia, Tesla, etc reply Zigurd 6 hours agoparentIt began long ago, with a series of Jack Welch acolytes starting with Harry Stonecipher and James McNerney. They brought hostility to in-house engineering, hostility to unions. That's when Boeing lost its soul. reply steve1977 5 hours agoparentprevEx-engineering company… reply ses1984 6 hours agoparentprevContrast Boeing with spacex, not Tesla. reply whoitwas 6 hours agoparentprevTesla way worse than Boeing. Robotaxis lol reply southernplaces7 7 hours agoprevBy this point, with all the news of Boeing disasters, I almost assume that if you wanted to commit suicide by skydiving without a parachute, a flight to the right height in a Boeing would be more likely to kill you than the jump. reply mateus1 7 hours agoparentWe should call this “Suicide by maximizing shareholder value” reply joshuahedlund 7 hours agoparentprevHow many people have ridden in a Boeing plane this year and how many have died? reply TheOtherHobbes 7 hours agorootparentIs that including the two currently in space who are wondering that? reply yuliyp 5 hours agoparentprevI didn't realize the probability of death in a drop of thousands of feet is under .00001% reply mrbluecoat 5 hours agoprev> The CVR fitted to G-FDZS was not removed from the aircraft as it continually overwrites itself, retaining only the last two hours of audio. As such, the recording of the takeoff would have been overwritten during the flight to Las Palmas In 2017, the date that aircraft began production, we had terabyte thumb drives and 24kbps Ogg Vorbis, why a two hour limit? reply germandiago 7 hours agoprevWhat's with Boeing lately? In the last years I see a lot of news related to crashes and problems with those. Is it me? I did not take a deep look into the topic. How does it compare to Airbus security-wise, with the real data from fatal crashes at hand? reply robxorb 7 hours agoparentA well-balanced comparison is well overdue, considering the amounts of one-sided coverage recently. Is it indicative of an issue with Boeing? Or with media reporting? Probably the former, but it's something we should really be more sure of. reply Havoc 8 hours agoprevIs this the one that was spewing flames yesterday or different incident? reply wkat4242 7 hours agoparentDifferent one. That one returned to base immediately, it's not safe to continue with a surging engine. reply K0balt 6 hours agoprevI suspect the most interesting part of this is why, precisely: If this is a known bug, incorrect setting of the throttle and subsequent disconnect of the auto throttle system, why is the aircraft still deemed airworthy while using the auto throttle during takeoff? How was using defective equipment critical to flight safety if engaged not specifically prohibited in an addendum to the POH? Because that would require additional training and be a bad look, that’s why, I suspect. If a FAR23 (light) aircraft had a defective throttle cable that sometimes failed to effect the commanded throttle setting under certain conditions, it would be grounded immediately pending remedial service or, if impossible, at least placarding of the prohibited configuration and modification to the POH to specified prohibit that configuration, as well as implicating changes into training materials if the aircraft fell into the high performance category. That Boeing is operating at a lower standard of flight safety than is typically required of SLA regulations is an indication of a deeply broken relationship with regulators. reply kayodelycaon 5 hours agoparentThere was nothing wrong with the throttle controls or the engines. The engines were at commanded thrust. What happened was the autopilot (autothrottle) failed to engage. Pilots set manual thrust and rearmed the system. It didn’t engage. Then the pilots failed to verify engine performance or throttle position twice during takeoff. This is dangerously negligent because engine performance may not match throttle setting due to mechanical fault. The computers may or may not detect this. See: https://en.m.wikipedia.org/wiki/Air_Florida_Flight_90 reply iLoveOncall 8 hours agoprevIt's amazing that Boeing planes are still allowed in the air at all at this point. reply mrjin 9 hours agoprevWow, Boeing again. reply userbinator 8 hours agoprev [–] Ultimately an unintended consequence of trying to reduce costs. Otherwise they'd just use full throttle. reply jnsaff2 7 hours agoparentThe engine wear and consequently the risk of engine failure during normal operations goes up with full throttle. Noise abatement is reducing the throttle when the plane has reached a certain altitude and not relevant for takeoff roll. reply the_third_wave 8 hours agoparentprev [–] Cost and noise, the latter possibly ending up more costly if the allowed noise level is exceeded. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A TUI-operated Boeing 737-800 narrowly avoided disaster at Bristol Airport due to a software glitch, with the plane barely clearing the runway and flying over a major road at low altitude.",
      "The Air Accidents Investigation Branch (AAIB) found that the pilots manually set insufficient thrust after the autothrottle system disengaged, an issue Boeing was aware of but had not resolved.",
      "This incident adds to a series of recent safety concerns involving Boeing aircraft, with TUI and Boeing cooperating with authorities to address the issue."
    ],
    "commentSummary": [
      "A Boeing passenger jet nearly crashed due to a known software bug that caused the autothrottle to disconnect, leading to insufficient thrust for takeoff.",
      "The issue was linked to older thrust lever actuators, with guidance already issued for their replacement, highlighting the importance of monitoring engine performance during takeoff.",
      "Broader concerns are raised about Boeing's safety practices, cost-cutting measures, and management decisions, sparking debates on the balance of responsibility between automation and manual control."
    ],
    "points": 144,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1717829529
  },
  {
    "id": 40614338,
    "title": "Efficient Function Computation in Embedded Systems with Chebyshev Approximation",
    "originLink": "https://www.EmbeddedRelated.com/showarticle/152.php",
    "originBody": "Blogs Home Blogs Forums Quizzes! Courses Tutorials Books Free PDFs Webinars Code Snippets Login / Register Home Blogs From the Editor Recent Posts Popular (this month) Popular (all time) Forums Quizzes! Courses Tutorials Books Free PDFs Webinars Code Snippets Blogs Jason Sachs Chebyshev Approximation and How It Can Help You Save Money, Win Friends, and Influence People Jason Sachs●September 30, 2012●20 comments Software Development Applied Math Well... maybe that's a stretch. I don't think I can recommend anything to help you win friends. Not my forte. But I am going to try to convince you why you should know about Chebyshev approximation, which is a technique for figuring out how you can come as close as possible to computing the result of a mathematical function, with a minimal amount of design effort and CPU power. Let's explore two use cases: Amy has a low-power 8-bit microcontroller and needs to compute \\( \\sqrt{x} \\) (square root) to get an accurate estimate of RMS power dissipated in a current sense resistor. She's finding that the math library implementation for sqrt() takes a lot of CPU time, and she's short on free program memory space, and is wondering if there is another way to compute square roots that takes less time and program memory. Bill is designing a sulfur dioxide (SO2) detector, with a sensor that outputs a voltage dependent on SO2 gas concentration, and a microcontroller that converts that voltage to a reading of SO2 concentration so it can be displayed. He's not greatly concerned about CPU time limitations, but somehow he has to figure out how to convert gas sensor voltage to a concentration, because the sensor is fairly nonlinear. In Amy's case, she has a known function that seems difficult to compute. In Bill's case, he has an unknown function that he has to figure out how to model. These are both cases of function evaluation with two very different priorities. Both are on embedded systems, which brings me to the Central Hypothesis of Mathematical Computation on Embedded Systems (CHoMCoES? It needs a better name, and I don't feel like calling it the Sachs Hypothesis): This article is available in PDF format for easy printing The only embedded systems that require precision floating-point computations are desktop calculators. Let that sink in for a minute. Your computer is a wonderful thing. It can calculate pi to hundreds of decimal places in milliseconds, or model the airflow patterns around jet engine blades. The origins of the computer have been consistently centered around mathematical computation, with a huge surge of development around the end of the Second World War and through the early days of solid-state transistors. If you needed a computer in the 1940's and 1950's, it was for some precise mathematical calculation. Computers were very expensive to own and operate; if you needed a quick estimate of some math, there were slide rules. This was also the era where whole books were published containing tables of engineering functions, so that if you needed to calculate Bessel functions to 5 decimal places, you could do it by looking it up in a table. The desktop computer uses a calculation strategy of \"full machine precision\": for a given bit representation, there is only one correct answer to sin(x), and it is the bit pattern that is the one yields the smallest error from the exact mathematical calculation. Someone has written and tested mathematical software libraries that do this, and from there on out, it's just a function call. Embedded systems, on the other hand, tend to contain inexpensive processors that are doing things with analog-to-digital-converter measurements. You can do math to the full 53 bits of IEEE-754 double-precision, but if your ADC readings, or the signal conditioning that precedes them, are only accurate to 0.1% (10 bits), then mathematical errors will be dwarfed by the errors of signal conditioning. When you have a system that can tolerate mathematical errors, and has computing resource limitations driven by cost, all of a sudden the priority of mathematical computing changes. Now we have to decide what we really need when we want to compute something. Let's take Amy's problem first: we need to compute a square root. That statement is only an overview of what is needed. There are two major decisions that need to be made up front: over what range of x does \\( \\sqrt{x} \\) need to be computed? what kind of accuracy does \\( \\sqrt{x} \\) need? (and how does it vary with x?) General full-machine precision math libraries have easy answers to these questions: any input needs to be tolerated, and for each input there is one correct output, even if the correct output is an error (e.g. \\( \\sqrt{x} \\) for negative inputs in systems that don't use complex numbers). In the embedded system, the accuracy and range requirements are judgement calls. Accuracy is an easy thing to understand: there are algorithms that take shortcuts to computing an expression, and the more inaccuracy can be tolerated, the more shortcuts can be taken. The range requirement is a bit more subtle. Obviously you have to support the expected range of inputs to an algorithm, and maybe you want to leave some engineering margin. But why would it be more expensive to calculate \\( \\sqrt{x} \\) over a larger range? If I were to tell you that I was much more concerned about the range of a computation than the accuracy, would you believe me? Let's use a real example. Amy thinks she needs \\( \\sqrt{u} \\) calculated over the range \\( u \\in [0.2, 5.0] \\). Her first instinct is to go find her calculus textbook and look up Taylor Series: How not to evaluate functions, part 1: Taylor Series Here is the Taylor series for \\( \\sqrt{1+x} \\): (equation courtesy of Wikipedia) But there's a little footnote saying this only works for x between -1 and 1, meaning it won't work to calculate \\( \\sqrt{2} \\) or the square root of anything 2 or larger. For \\( \\sqrt{5} \\), she has to use a trick, namely that \\( \\sqrt{5} \\) = \\( 2\\times\\sqrt{5/4} \\). So she decides to limit the actual input range of the Taylor series to cover the range of \\( \\sqrt{1+x} \\) for \\( x \\in [-0.8,+0.25] \\), and if \\( u = 1+x > 1.25 \\) then Amy will do the divide-by-4 trick: (we'll use Python here; assume that Amy does something equivalent in C) def sqrt1(x): # returns sqrt(1+x) for x between -0.8 and +0.25 return 1 + x/2 - x*x/8 + x*x*x/16 def sqrtapprox(u): # valid for x between 0.2 to 5.0 if (u >= 1.25): return sqrt1(u/4-1)*2 else: return sqrt1(u-1) Is this good enough? Hmm, let's think about this. We want to know the error between a function and its approximation(s). Let's graph that error. Here's a quick Python function that uses numpy and matplotlib to plot the results: import numpy as np import matplotlib.pyplot as plt def showplots(f,approxlist,a,b): x = np.linspace(a,b,1000) plt.figure(1) plt.subplot(211) plt.plot(x,f(x)) vfuncs = [np.vectorize(approx) for approx in approxlist] for vf in vfuncs: plt.plot(x,vf(x)) plt.xlim(a,b) plt.ylabel('f(x) and approximations fa(x)') plt.subplot(212) for vf in vfuncs: plt.plot(x,f(x)-vf(x)) plt.xlim(a,b) plt.ylabel('error = f(x)-fa(x)') plt.xlabel('x') plt.show() The results of showplots(np.sqrt,[sqrtapprox],0.2,5.0) will show us the error between the full-machine-precision sqrt() and our approximation: Yuck. A worst-case error of 0.038. Let's try some more terms in the Taylor series. That means we have to figure out how the coefficients work. A little pencil and paper algebra shows the coefficients starting from the quadratic term are $$\\begin{eqnarray} a_2 &=& -\\frac{1}{4\\times 2} = -\\frac{1}{8}, \\cr a_3 &=& +\\frac{3\\times 1}{6\\times 4\\times 2} = \\frac{1}{16}, \\cr a_4 &=& -\\frac{5\\times 3\\times 1}{8\\times 6\\times 4\\times 2} = \\frac{5}{128}, \\cr a_5 &=& +\\frac{7\\times 5\\times 3\\times 1}{10\\times 8\\times 6\\times 4\\times 2} = \\frac{7}{256}, \\cr a_6 &=& -\\frac{9\\times 7\\times 5\\times 3\\times 1}{12\\times 10\\times 8\\times 6\\times 4\\times 2} = -\\frac{21}{1024} \\end{eqnarray}$$ and so on, so we try again: def sqrt1a(x): # returns sqrt(1+x) for x between -0.8 and +0.25 return 1 + x/2 - x*x/8 + x*x*x/16 - 5.0/128*x*x*x*x def sqrtapproxa(u): # valid for x between 0.2 to 5.0 if (u >= 1.25): return sqrt1a(u/4-1)*2 else: return sqrt1a(u-1) def sqrt1b(x): # returns sqrt(1+x) for x between -0.8 and +0.25 return 1 + x/2 - x*x/8 + x*x*x/16 - 5.0/128*x*x*x*x + 7.0/256*x*x*x*x*x def sqrtapproxb(u): # valid for x between 0.2 to 5.0 if (u >= 1.25): return sqrt1b(u/4-1)*2 else: return sqrt1b(u-1) Here are the results for sqrtapproxa (a 4th-degree Taylor series): And here are the results for sqrtapproxb (a 5th-degree Taylor series): Yuck. We added two more terms and we only got the error down to 0.015. Here's what you need to learn about Taylor series for function evaluation. (Or rather, read this and whatever you don't understand, just trust me.) To get the coefficients of a Taylor series for a function f in a region around a point \\( x=x_0 \\), you evaluate \\( f(x_0) \\) and all of the derivatives of \\( f(x) \\) at \\( x=x_0 \\). You don't have to look at the function anywhere else; the behavior at \\( x=x_0 \\) somehow lets you know what \\( f(x) \\) is elsewhere. For some functions (like \\( \\sqrt{1+x} \\) ) the region of convergence is finite; for others like \\( \\sin x \\) or \\( e^x \\) the region of convergence is everywhere. Taylor series work on most everyday functions, because these functions have a property called \"analyticity\": all of their derivatives exist and are therefore continuous and smooth, and through the magic of mathematics this means that looking at an analytic function only at 1 point will tell you enough information to calculate it in some nearby region. Right near \\( x=x_0 \\), Taylor series are great. The error between the exact function and the first N terms of the corresponding Taylor series will be extremely small around \\( x=x_0 \\). As you move away from \\( x=x_0 \\), the error starts to become larger. In general, the more terms you use, the better the approximation will be around \\( x=x_0 \\), but when the approximation starts to do poorly at the edge of its range, it diverges faster. To sum this up: Taylor series approximations do not distribute the approximation error fairly. The error is small at \\( x=x_0 \\), but its error tends to be much larger at the edges of its range. Now I'm going to show you two more attempts at approximating \\( \\sqrt{x} \\) for \\( x \\in [0.2, 5.0] \\), but I'm going to wait before explaining how I came up with them. def sqrt1c(x): # valid for x between 0.2 to 1.25 coeffs = [0.20569678, -0.94612133, 1.79170646, -1.89014568, 1.66083189, 0.17814197] y = 0 for c in coeffs: y = y * x + c return y def sqrtapproxc(u): # valid for u between 0.2 to 5.0 if (u >= 1.25): return sqrt1c(u/4)*2 else: return sqrt1c(u) def sqrtapproxd(x): # valid for x between 0.2 to 5.0 coeffs = [0.00117581,-0.01915684,0.12329254,-0.41444219,1.04368339, 0.26700714] y = 0 for c in coeffs: y = y * x + c return y Approximation \"c\" splits the range between \\( [0.2,1.25) \\) and \\( [1.25,5] \\) as before; approximation \"d\" operates over the entire range \\( [0.2,5] \\). Both are 5th-degree polynomials. Here is the performance of approximation \"c\": You'll notice a peak error of about 0.00042. This is about 35 times smaller than the error in approximation \"b\" (the Taylor series version using 5th order polynomials with the same range split). Here is the error for approximation \"d\": That's about 0.011 worst case error, which is about 30% smaller than approximation \"b\". We got better worst-case error, without having to split up the range, with a polynomial of the same degree! A few things to note from this exercise: Good function approximations have error graphs with a characteristic \"wiggle\". Ideally they form a so-called minimax function, where the positive and negative peaks all line up. This spreads the error throughout the range of input argument, and can be orders of magnitude better accuracy than a Taylor series polynomial of the same degree. In practice, it is difficult to achieve the ideal minimax error graph, but there is an easy method that comes close to it, which I'll explain in a bit. Range reduction can improve the accuracy of function evaluation significantly. Approximations \"c\" and \"d\" both used 5th degree polynomials, but approximation \"d\" used the whole input range (a 25:1 ratio of maximum to minimum input), whereas approximation \"c\" only used a part of the input range (with 6.25:1 ratio of maximum to minimum input), and \"c\" was 25 times more accurate. How not to evaluate functions, part 2: lookup tables All right, so let's toss out Taylor series. The next approach is a lookup table. The idea is simple: you have an array of precomputed values for your function, and use those as a table to evaluate the function. Let's look at a solution for \\( \\sqrt{x} \\) over the \\( [0.2, 5.0] \\) range using a lookup table with 32 entries: import math def maketable0(func, a, b, n): table = func([(x+0.5)/n*(b-a)+a for x in range(0,n)]) def tablefunc(x): if xb: raise \"out of range error\" i = math.floor((x-a)/(b-a)*n) if i == n: i = n-1 return table[i] return tablefunc sqrtapproxe = maketable0(np.sqrt, 0.2, 5.0, 32 Using a lookup table involves the following process, which is fairly trivial but worth discussing nonetheless: At design time (or initialization time), divide the input range of the function into N intervals and evaluate the function within those intervals. (Usually the intervals are equal width and function evaluation is at the midpoint of each interval.) At runtime: handle out-of-range situations (either throw an error or return a value corresponding to min/max input) compute an index of which interval the function is in lookup the value in the table at that index Here's what the error of approximation \"e\" looks like: Note the stairsteppy result and the sawtooth error plot. This is typical for a plain table approach. The maximum error is roughly proportional to the slope of the function within an interval (the error is larger for small values of x where \\( \\sqrt{x} \\) is steeper), and proportional to the interval size. If we want to reduce the error by a factor of 10, we need 10x as many lookup table entries. If we want to improve the situation, the next improvement we can use is linear interpolation: At design time (or initialization time), divide the input range of the function into N intervals and evaluate the function at the N+1 endpoints of those intervals. (Usually the intervals are equal width) At runtime: handle out-of-range situations (either throw an error or return a value corresponding to min/max input) compute an index k of which interval the function is in lookup the value in the table at that index and the next index perform a linear interpolation: y = table[k]*(1-u) + table[k+1]*u, where u is the number between 0 and 1 representing the position of the input within the interval (0 = beginning of interval, 1 = end) import math def maketable1(func, a, b, n): table = func([float(x)/n*(b-a)+a for x in range(0,n+1)]) def tablefunc(x): if xb: raise \"out of range error\" ii = (x-a)/(b-a)*n i = math.floor(ii) if i == n: i = n-1 u = ii-i return table[i]*(1-u) + table[i+1]*u return tablefunc sqrtapproxf = maketable1(np.sqrt, 0.2, 5.0, 32) Here's the error plot for approximation \"f\": Much better — note the error plot containing parabolic sections. This is typical for interpolated table lookup. The maximum error is roughly proportional to the curvature (2nd derivative) of the function within an interval, and proportional to the square of the interval size. If we want to reduce the error by a factor of 10, we only need about 3x as many lookup table entries. This is one of the rare cases where table interpolation may be more appropriate than polynomial evaluation: the maximum error here is about 1/2 as much as the 5th-order polynomial we used in approximation \"d\". For a comparison in execution time: table lookup with no interpolation is roughly equivalent to a quadratic (2nd order) function, and table interpolation is roughly equivalent to a quartic (4th order) polynomial. That's only an estimate; it really depends on things like whether you're doing floating-point or fixed-point computation, whether the table has a length that is a power of 2 (it should be, so you can use bitwise operations to speed up the math), and how long it takes to perform table lookups on your processor. There are only a few situations, in my opinion, where table lookup is appropriate: If accuracy requirements are very low, a non-interpolated table lookup may be sufficient. If a function is very \"nonpolynomial\" then an interpolated table lookup may produce superior accuracy compared to a polynomial evaluation of comparable execution time. (This appears to be the case for \\( \\sqrt{x} \\) over the \\( [0.2, 5.0] \\) range. We'll define \"nonpolynomial\" shortly; for now just think of it as a function with a lot of wiggles or twists and turns.) If a function is very difficult to approximate with a polynomial over the whole range but needs very high accuracy, one option is to split the range into 4 or 8 subintervals and use table lookup to obtain polynomial coefficients for each subinterval. Table lookup is not appropriate when it requires such a large table size that you have to worry about memory requirements. Also note that the error in approximation \"f\" is not fairly distributed: the maximum error happens at the low end of the input range and is much smaller over the rest of the input range. You can use tricks to make the error distribution more fair, namely by using variable-width intervals, but there's no general process for doing this while still using an efficient computation at runtime. Chebyshev Polynomials The key to using polynomials to evaluate functions, is not to think of polynomials of being composed of linear combinations of \\( 1, x, x^2, x^3 \\), etc., but as linear combinations of Chebyshev polynomials \\( T_n(x) \\). As discussed in more detail in the Wikipedia page, these have the following special properties: they are minimax functions over the range \\( [-1,1] \\), e.g. all their minima/maxima/extrema are at ± 1 (see diagram below) they are orthogonal over the range \\( [-1,1] \\) with weight \\( \\frac{1}{\\sqrt{1-x^2}} \\) \\( T_0(x) = 1, T_1(x) = x, T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x) \\) \\( T_n(x) = \\cos(n \\cos^{-1} x) \\) Figure: Chebyshev functions \\(T_n(x)\\), courtesy of Wikipedia Let's say we have a given function \\(f(x)\\) over the range \\( x \\in [a,b] \\). We can express \\( f(x) = \\sum c_k T_k(u) \\) where \\( u = \\frac{2x-a-b}{b-a} \\) and \\( x = \\frac{b-a}{2}u + \\frac{a+b}{2} \\), which is a transformation which maps the interval \\( x \\in [a,b] \\) to \\( u \\in [-1,1] \\). The problem then becomes a matter of figuring out the coefficients \\( c_k \\), which can be done using the Chebyshev nodes: These are easier to understand graphically; they are merely the projections onto the x-axis of the midpoints of equal interval circular arcs of a semicircle: You will note that the nodes are spaced equally near 0 and more compressed towards ± 1. To approximate a function by a linear combination of the first N Chebyshev polynomials (k=0 to N-1), the coefficient \\( c_k \\) is simply equal to \\( A(k) \\) times the average of the products \\( T_k(u)f(x) \\) evaluated at the N Chebyshev nodes, where \\( A = 1 \\) for \\( k = 0 \\) and \\( A = 2 \\) for all other k. Let's illustrate the process more clearly with an example. Suppose \\( f(x) = \\frac{1}{3} x^3 + 2x^2 + x - 10 \\) over the range \\( [-1, 3] \\), with \\( u = \\frac{x-1}{2}, x = 2u+1 \\): Let's use \\( N=5 \\). The Chebyshev nodes for N=5 are \\( u=-0.951057, -0.587785, 0, +0.587785, +0.951057 \\). This corresponds to \\( x=-0.902113, -0.175571, 1, 2.175771, 2.902113 \\), and the function \\( f(x) \\) evaluated at those nodes are \\( y=-9.51921, -10.11572, -6.66667, 5.07419, 17.89408 \\). For \\( c_0 \\) we compute the average value of y = \\( (-9.51921-10.11572-6.66667+5.07419+17.89408)/5 = -0.66667 \\). For \\( c_1 \\) we compute 2 × the average value of u × y = \\( 2\\times(-9.51921\\times-0.951057+-10.11572\\times-0.587785\\) \\(+-6.66667\\times 0+5.07419\\times 0.587785+17.89408\\times 0.951057) = 14 \\) For \\( c_2 \\) we compute 2 × the average value of \\( T_2(u)\\times y = (2u^2-1) \\times y \\: \\longrightarrow \\: c_2 = 6 \\) For \\( c_3 \\) we compute 2 × the average value of \\( T_3(u)\\times y = (4u^3-3u) \\times y \\: \\longrightarrow \\: c_3 = 0.66667\\) For \\( c_4 \\) we compute 2 × the average value of \\( T_4(u)\\times y = (8u^4-8u^2+1) \\times y \\: \\longrightarrow \\: c_4 = 0 \\) The conclusion here is that \\( f(x) = -\\frac{2}{3}T_0(u) + 14T_1(u) + 6T_2(u) + \\frac{2}{3}T_3(u) \\) ; if you go and crunch through the algebra you will see that the result is the same as \\( f(x) = \\frac{1}{3}x^3 + 2x^2 + x - 10 \\). So what was the point here....? Well, if you already have the coefficients of a polynomial, there's no point in using Chebyshev polynomials. (If the input range is significantly different from \\( [1,1] \\), a linear transformation from x to u where \\( u \\in [-1,1] \\) will give you a polynomial in u that has better numerical stability, and Chebyshev polynomials are one way to do this transformation. More on this later) If you want to approximate the polynomial with a polynomial of lesser degree, Chebyshev polynomials will give you the best approximation. For example let's use a quadratic function to approximate \\( f(x) \\) over the input range in question. All we need to do is truncate the Chebyshev coefficients: let's compute $$\\begin{eqnarray} f_2(x) &=& -\\frac{2}{3}T_0(u) + 14T_1(u) + 6T_2(u) \\cr &=& -\\frac{2}{3} + 14u + 6\\times(2u^2-1) \\cr &=& -\\frac{20}{3} + 14u +12u^2 \\cr &=& -\\frac{20}{3} + 7(x-1) + 3(x-1)^2 \\cr &=& 3x^2 + x - \\frac{32}{3}. \\end{eqnarray} $$ Voila! We have a quadratic function that is close to the original cubic function, and the magnitude of the error is just the coefficient of the Chebyshev polynomial we removed = \\( \\frac{2}{3} \\). You will note that these two polynomials (\\( \\frac{1}{3}x^3 + 2x^2 + x - 10 \\) and \\( 3x^2 + x - \\frac{32}{3} \\)), expressed in their normal power series form, have no obvious relation to each other, whereas the Chebyshev coefficients are the same except in coefficient \\( c_3 \\) which we set to zero to get a quadratic function. In my view, this is the primary utility of expressing a function in terms of its Chebyshev coefficients: The coefficient \\( c_0 \\) tells you the function's average value over the input range; \\( c_1 \\) tells you the function's \"linearness\", \\( c_2 \\) tells you the function's \"quadraticness\", \\( c_3 \\) tells you the function's \"cubicness\", etc. Here's a more typical and less trivial example. Suppose we wish to approximate \\( \\log_2 x \\) over the range \\( [1,2] \\). A decomposition into Chebyshev coefficients up to degree 6 yields the following: $$\\begin{eqnarray} c_0 &=& +0.54311 \\cr c_1 &=& +0.49505\\cr c_2 &=& -0.042469\\cr c_3 &=& +0.0048577\\cr c_4 &=& -6.2508\\times 10^{-4}\\cr c_5 &=& +8.5757\\times 10^{-5}\\cr c_6 &=& -1.1996\\times 10^{-5}\\cr \\end{eqnarray} $$ You will note that each coefficient is only a fraction of the magnitude of the previous coefficient. This is an indicator that the function in question (over the specified input range) lends itself well to polynomial approximation. If the Chebyshev coefficients don't decrease significantly by the 5th coefficient, I would classify that function as \"nonpolynomial\" over the range of interest. The maximum error for the 6th-degree Chebyshev approximation for \\( \\log_2 x \\) over \\( x \\in [1,2] \\) is only about 2.2×10-6, which is approximately the value of the next Chebyshev coefficient. If we truncate the series to a 4th-degree Chebyshev approximation, we get a maximum error that is about equal to \\( c_5 = 8.6×10^{-5} \\): Neat, huh? Some further examples of elementary functions Here is a list of common functions, along with the first 6 Chebyshev coefficients: \\( f(x) \\) range c0 c1 c2 c3 c4 c5 \\( \\sin \\pi x \\) [-0.5,0.5] 0 1.1336 0 -0.13807 0 0.0045584 \\( \\sin \\pi x \\) [-0.25,0.25] 0 0.72638 0 -0.01942 0 0.00015225 \\( \\cos \\pi x \\) [-0.5,0.5] 0.472 0 -0.4994 0 0.027985 0 \\( \\cos \\pi x \\) [-0.25,0.25] 0.85163 0 -0.14644 0 0.0019214 0 \\( \\sqrt{x} \\) [1,4] 1.542 0.49296 -0.040488 0.0066968 -0.0013836 0.00030211 \\( \\log_2 x \\) [1,2] 0.54311 0.49505 -0.042469 0.0048576 -0.00062481 8.3994e-05 \\( e^x \\) [0,1] 1.7534 0.85039 0.10521 0.0087221 0.00054344 2.7075e-05 \\( \\frac{2}{\\pi}\\tan^{-1} x \\) [-1,1] 0 0.5274 0 -0.030213 0 0.0034855 \\( \\frac{1}{1 + e^{-x}} \\) [-1,1] 0.5 0.23557 0 -0.0046202 0 0.00011249 \\( \\frac{1}{1 + e^{-x}} \\) [-3,3] 0.5 0.50547 0 -0.061348 0 0.01109 \\( \\frac{1}{1 + x^2} \\) [-1,1] 0.70707 0 -0.24242 0 0.040404 0 \\( \\frac{1}{1 + x^2} \\) [-3,3] 0.30404 0 -0.29876 0 0.12222 0 Other comments A great reference for Chebyshev functions is Numerical Recipes by Press, Teukolsky, Vetterling, and Flannery, which covers Chebyshev approximation in detail. There are a few things to note when evaluating Chebyshev functions: It's better to compute the functions directly rather than trying to convert Chebyshev approximations to a standard polynomial form. (that is, if you want to calculate \\( 3T_0(x) + 5T_1(x) - 0.1T_2(x) \\) , don't convert to a polynomial, but instead calculate the T values directly.) Numerical Recipes recommends Clenshaw's recurrence formula, but I just use the following simple algorithm: u = (2*x-a-b)/(b-a) Tprev = 1 T = u y = c[0] for i = 1:n y=y+T*c[i] Tnext = 2*u*T - Tprev Tprev = T T = Tnext Remember to convert from x to u — this keeps the numerical stability of the algorithm, because polynomials tend to be well-conditioned for evaluating arguments between -1 and 1, and ill-conditioned for arguments with very large or very small magnitudes. Here is a Python class for computing and applying Chebyshev coefficients: import math import numpy as np def chebspace(npts): t = (np.array(range(0,npts)) + 0.5) / npts return -np.cos(t*math.pi) def chebmat(u, N): T = np.column_stack((np.ones(len(u)), u)) for n in range(2,N+1): Tnext = 2*u*T[:,n-1] - T[:,n-2] T = np.column_stack((T,Tnext)) return T class Cheby(object): def __init__(self, a, b, *coeffs): self.c = (a+b)/2.0 self.m = (b-a)/2.0 self.coeffs = np.array(coeffs, ndmin=1) def rangestart(self): return self.c-self.m def rangeend(self): return self.c+self.m def range(self): return (self.rangestart(), self.rangeend()) def degree(self): return len(self.coeffs)-1 def truncate(self, n): return Cheby(self.rangestart(), self.rangeend(), *self.coeffs[0:n+1]) def asTaylor(self, x0=0, m0=1.0): n = self.degree()+1 Tprev = np.zeros(n) T = np.zeros(n) Tprev[0] = 1 T[1] = 1 # evaluate y = Chebyshev functions as polynomials in u y = self.coeffs[0] * Tprev for co in self.coeffs[1:]: y = y + T*co xT = np.roll(T, 1) xT[0] = 0 Tnext = 2*xT - Tprev Tprev = T T = Tnext # now evaluate y2 = polynomials in x P = np.zeros(n) y2 = np.zeros(n) P[0] = 1 k0 = -self.c/self.m k1 = 1.0/self.m k0 = k0 + k1*x0 k1 = k1/m0 for yi in y: y2 = y2 + P*yi Pnext = np.roll(P, 1)*k1 Pnext[0] = 0 P = Pnext + k0*P return y2 def __call__(self, x): xa = np.array(x, copy=False, ndmin=1) u = np.array((xa-self.c)/self.m) Tprev = np.ones(len(u)) y = self.coeffs[0] * Tprev if self.degree() > 0: y = y + u*self.coeffs[1] T = u for n in range(2,self.degree()+1): Tnext = 2*u*T - Tprev Tprev = T T = Tnext y = y + T*self.coeffs[n] return y def __repr__(self): return \"Cheby%s\" % (self.range()+tuple(c for c in self.coeffs)).__repr__() @staticmethod def fit(func, a, b, degree): N = degree+1 u = chebspace(N) x = (u*(b-a) + (b+a))/2.0 y = func(x) T = chebmat(u, N=degree) c = 2.0/N * np.dot(y,T) c[0] = c[0]/2 return Cheby(a,b,*c) You can put this in a file cheby.py and then use it as follows (here we fit \\( \\sin x \\) between 0 and \\( \\frac{\\pi}{2} \\) with a 5th degree polynomial, and compute our approximation on angles 0, \\( \\frac{\\pi}{6} \\), \\( \\frac{\\pi}{4} \\), and \\( \\frac{\\pi}{3} \\)): >>> import cheby >>> import numpy as np >>> import math >>> c = cheby.Cheby.fit(np.sin,0,math.pi/2,5) >>> c Cheby(0.0, 1.5707963267948966, 0.60219470125550711, 0.51362516668030367, -0.10354634422944738, -0.013732035086651754, 0.001358650338492214, 0.00010765948465629727) >>> c(math.pi*np.array([0, 1.0/6, 1.0/4, 1.0/3])) array([ 6.21628624e-06, 5.00003074e-01, 7.07099696e-01, 8.66028717e-01]) Function approximation for empirical data Let's go back to the beginning of our discussion to Bill's problem. He has a nonlinear sensor relating a physical quantity (gas concentration) to a voltage measurement; the problem he faces is how to invert that relation so that he can estimate the original physical quantity: \\( y = f(x) \\) where x is the measurement and y is the physical quantity. Chebyshev approximation works well here too, but we have a problem. We can't just evaluate \\( f(x) \\) at Chebyshev nodes to get the Chebyshev coefficients, because we don't know for certain what \\( f(x) \\) actually is. Instead, we have to make some reference measurements to determine those coefficients, with known physical quantities (e.g. known gas concentrations in Bill's case), and tabulate these x and y values, then use them to estimate the coefficients. We have two choices in selecting the measurements: Try to plan the measurements so that the values x lie near the Chebyshev nodes over the expected range. This will allow us to use fewer measurements. Make a lot of measurements so the whole input range is well-covered In some situations, it's quick and easy to make measurements with arbitrary references. (For example, if you're trying to calibrate a microphone, you can change the amplitude and frequency of reference sound signals automatically with electronic equipment), and the second option is a viable one. In other situations, like the gas concentration problem, it may be inconvenient or expensive to make lots of measurements, and you have to select the reference values carefully. The best way I've found to estimate Chebyshev coefficients from empirical data, is to use weighted least-squares: Collect the measurements x and physical input quantity y into vectors X and Y For the vector of measurements x, compute u from x, and compute the values of the Chebyshev polynomials \\( T_0(u), T_1(u), T_2(u), \\ldots T_n(u) \\) and save each these as vectors in a matrix T. Each polynomial will be used as a basis function. Compute a weighting value \\( w(x) \\) to compensate for the density of values x. (e.g. if lots of x values are near \\( x=0 \\) but very few of them are near \\( x=1 \\), you may have to choose \\( w(x) \\) low near \\( x=0 \\) and higher near \\( x=1 \\) .) Express these values as a diagonal matrix W. Compute a vector C of coefficients \\( c_0, c_1, c_2, \\ldots c_n \\) using weighted least-squares to solve for C: $$(T^TWT)C = T^TWY.$$ To do this you will need some kind of matrix library. In MATLAB this would be computed as C = (T'*diag(W)*T)\\(T'*diag(W)*Y). In Python with Numpy, you can skip calculating the T matrix, and just use the numpy.polynomial.chebyshev.chebfit function on the x and y measurements; the weighting vector is an optional input. I would not use a degree greater than 5. If you find you're still not getting a good approximation with a 5th degree polynomial, you're probably using the wrong approach; the function is too sharp or wiggly or cusped. Higher degree polynomials can have problems with numerical accuracy. In any case, function approximation of empirical data is a little trickier than approximation of known functions. Always make sure you double-check your approximation by graphing the original data and the function you come up with. Wrapup The next time you need to turn to function approximation, give Chebyshev approximation a shot! Not only is it probably the best and easiest way to approximate a function with a polynomial, but it will also let you know how well polynomials approximate the function in question, by the behavior of the Chebyshev coefficients. Make sure you choose the required accuracy and input range of your function wisely. Too high of an accuracy and too wide an input range will require higher degrees of polynomials and longer execution times, and high degree polynomials are often numerically ill-conditioned. More efficient evaluation of functions will mean you can use less CPU resources for a desired accuracy. So this can save you money and influence your coworkers. Happy approximating! © 2012 Jason M. Sachs, all rights reserved. You might also like... (promoted content) Check out Memfault's New Sandbox! Check out Memfault's New Sandbox! New Research Report: The State of IoT Software Development New Research Report: The State of IoT Software Development Comments Comments Write a Comment Select to add a comment [ - ] Comment by markrages●September 30, 2012 3 Great stuff. These matplotlib plots remind me of John Hunter. http://numfocus.org/johnhunter/ Reply Reply [ - ] Comment by jkvasan●October 9, 2012 2 Awesome post! You won me as a friend and your post has definitely influenced me. Reply Reply [ - ] Comment by Rickyroko●July 24, 2013 2 Great post! This comes in really handy, thanks for the comparisons. One small change I would make is to clearly define the generating function in your recurrence relation as T_n(x) := cos(n cos-1 (x) ) instead of cos(cos-1 nx). Reply Reply [ - ] Comment by jms_nh●August 25, 2015 2 fixed! Reply Reply [ - ] Comment by jms_nh●July 26, 2015 0 Yikes -- that's an error, not just a suggestion. Thanks, I'll fix when I get the chance. (+ upgrade the equations in this article to MathJax.) Reply Reply [ - ] Comment by nimisht●August 23, 2015 1 The chebfun package in matlab is a very thorough expansion of this idea Reply Reply [ - ] Comment by macsdev●November 16, 2015 1 What an excellent article! Thanks. May be you can write a new article detailing this part of your post with an example :) \"The best way I've found to estimate Chebyshev coefficients from empirical data, is to use weighted least-squares\". Reply Reply [ - ] Comment by Mishu●July 28, 2013 0 Chebyshev approx vs Cordic for atan(a/b) :) Reply Reply [ - ] Comment by davidf12●July 21, 2015 0 Your syntax highlighting is broken Reply Reply [ - ] Comment by lemzwerg●August 25, 2015 2 in the python code listing after the sentence Here is a Python class for computing and applying Chebyshev coefficients: everything is grey after the first comment line Reply Reply [ - ] Comment by calkuta●August 27, 2015 1 I'm experiencing the same problem, appears that anything after a comment line is all grey. Cool article! Reply Reply [ - ] Comment by jms_nh●July 21, 2015 0 please add more details -- it seems to work fine for me. Reply Reply [ - ] Comment by jbwhitmore●September 21, 2015 0 Syntax highlighting is also broken for me (using Chrome). Here is a screenshot of what I see: https://www.dropbox.com/s/qtgnyvimiqicvvt/Screenshot%202015-09-22%2011.15.09.png?dl=0 Reply Reply [ - ] Comment by adam89●August 23, 2015 0 Slight typo in your definition of Tn(x). You wrote: Tn(x) = cos(cos-1 nx) Of course, this simplifies to Tn(x) = nx. I believe what you meant was: Tn(x) = cos(n*cos-1 x) Reply Reply [ - ] Comment by jms_nh●August 25, 2015 1 fixed! Reply Reply [ - ] Comment by jms_nh●August 23, 2015 0 yep, Rickyroko noticed that too + it's on my todo list along with conversion to MathJax. thanks! Reply Reply [ - ] Comment by Samir12●April 23, 2016 0 Thanks for the great article. When you calculate c(0) for Amy's problem I think it should be 2*average of y. Isnt it? thanks in advance. Reply Reply [ - ] Comment by soupie62●January 7, 2017 0 I thought I understood this article - but I've missed something. The acid test for me was to try to understand how on earth you got those values in sqrt1c(x) and sqrtapproxd(x). I tried calculating the Chebyshev polynomials, going step-by-step with an Excel spreadsheet, and came out with values that looked nothing like yours. Am I missing something? Is it related to how you evaluate a Chebyshev polynomial with a simple y = y * x + c ...when your code further down the page is much more complex? Reply Reply [ - ] Comment by atomq●January 4, 2019 0 Many thanks, great stuff alltogrther. After diving into the story I have the question regarding the coefficients of w(x) diagonal matrix in weighted least-squares method. Is it any procedure on how to compute them in relation to what? My guess is that the coefficients' values are related to measurement points values, their mean value vs. their density across the range or the range extremes? Thanks in advance! Reply Reply [ - ] Comment by jms_nh●September 29, 2019 0 Sorry for the late reply... I'm not 100% sure whether there's a systematic way to compute w(x). Low density = high weight, high density = low weight. That probably means that you want the cumulative sum of weights w[k]*x[k] to be a linear function of k. Blah blah blah, exercise for the reader, etc. I did something like this in a previous career about 10-12 years ago but I don't remember the details. Good luck! Reply Reply To post reply to a comment, click on the 'reply' button attached to each comment. To post a new comment (not a reply to a comment) check out the 'Write a Comment' tab at the top of the comments. Sign in Sign in Remember me Forgot username or password?Create account You might also like... New Research Report: The State of IoT Software Development About Jason Sachs Jason has 25 years of experience in signal conditioning (both analog + digital) in motion control + medical applications. He likes making things spin. Popular Posts by Jason Sachs Chebyshev Approximation and How It Can Help You Save Money, Win Friends, and Influence People Supply Chain Games: What Have We Learned From the Great Semiconductor Shortage of 2021? (Part 2) How to Read a Power MOSFET Datasheet Thermistor signal conditioning: Dos and Don'ts, Tips and Tricks Development of the MOS Technology 6502: A Historical Perspective Blogs - Hall of Fame So You Want To Be An Embedded Systems Developer Steve Branam Introduction to Microcontrollers Mike Silva Important Programming Concepts (Even on Embedded Systems) Jason Sachs How FPGAs Work and Why You'll Buy One Yossi Krenin MSP430 Launchpad Tutorial Enrico Garante Arduino Robotics Lonnie Honeycutt Free PDF Downloads Interrupt handling in an ARM processor Real-Time Operating Systems and Programming Languages for Embedded Systems Introduction to Microcontrollers All FREE PDF Downloads Quick Links Home Blogs Forums Quizzes! Courses Tutorials Books Free PDFs Webinars Code Snippets comp.arch.embedded About EmbeddedRelated.com Advertise Contact Privacy Policy Terms of Service Cookies Policy Social Networks The Related Media Group",
    "commentLink": "https://news.ycombinator.com/item?id=40614338",
    "commentBody": "Chebyshev approximation and how it can help (2012) (embeddedrelated.com)110 points by y04nn 18 hours agohidepastfavorite18 comments programjames 15 hours agoSome other useful things about Chebyshev approximations: 1. You can use a Fourier transform to get the coefficients in O(n log n) time. 2. So, multiplying two approximations only takes O(n log n) time. 3. Also, adding, integrating, or taking the derivative only take O(n) time. This is why chebfun/chebpy can run so fast while magically finding roots/derivatives/etc. A couple other interesting facts: 1. Remember the double-angle formula? There's a more general recursion for the Chebyshev polynomials: \\[ T_n(x) = 2x T_{n-1}(x) - T_{n-2}. \\] So, e.g. \\[ T_2(cos(theta)) = cos(2*theta) = 2cos(theta)^2 - 1 = 2cos(theta)T_1(cos(theta)) - T_0(cos(theta)) \\] 2. Computers actually use this recursion to calculate sines and cosines! So, it's a little inefficient to code your Chebyshev polynomials using `math.sin`. 3. Using generating functions, you can get a closed form for T_n(x) that only takes O(log n) time to calculate. (Note: assuming you count multiplications as constant. However, you actually need O(log n) bits to accurately represent x, so it's more accurately O((log n)^2 log log n).) reply alexcnwy 11 hours agoparentI’m gonna give this to my gpt system prompt as an example of how I want everything explained :) reply mhh__ 5 hours agorootparentGood luck. It uses to be this clear (modulo \"reasoning\" abilities) but it gets dumber and more waffly with every update reply herodotus 3 hours agoprevThis is so strange: a few days ago I commented on an HN post (https://news.ycombinator.com/item?id=40582712) about when \"programmer\" became an acknowledged job title, and, in my comment, mentioned how I used a Chebyshev approximation followed by two iterations of Newton's method to compute sqrt, and then today this article shows up with exactly that use case! I wrote that code (to compute sqrt 2) in 1974 or 1975 in IBM 360 Assembler. I used a conditional macro constant that increased the number of iterations of Newton's from 2 to 3 just in case the client wanted double precision. reply guyomes 8 hours agoprevIf you are ready to spend some precomputation time to compute a good approximation, you can use the Remez algorithm [1]. It is implemented in the Sollya library for machine precision [2,3]. It has notably been used to implement the Core Math library [4] to provide correct rounding for the math functions in the libc library. [1]: https://en.wikipedia.org/wiki/Remez_algorithm [2] : https://www.sollya.org/ [3]: https://www.sollya.org/sollya-weekly/sollya.php [4]: https://core-math.gitlabpages.inria.fr/ reply alleycat5000 16 hours agoprevA great book on this subject is Approximation Theory and Approximation Practice: https://people.maths.ox.ac.uk/trefethen/ATAP/ Also chebfun! https://www.chebfun.org/ reply kragen 14 hours agoprevchebyshev approximations are fucking awesome, but this article gives too short shrift to table lookup; it does go a bit beyond nearest-neighbor interpolation to linear interpolation, and correctly points out that this gives you error that is quadratic in the distance from the x-coordinate of the nearest table entry (and therefore worst-case error quadratic in your point spacing), and that this gives you half the error of the fifth-order chebyshev approximation. it says that this is a 'rare case', but in fact you will always get a lower error from table lookup if you use enough points. it's just that with only linear interpolation, the number of points rapidly becomes impractical as i understand it, other commonly-used strategies include spline interpolation (using second-, third-, or even fourth-order interpolation, requiring respectively three, four, and five multiplications, which can be done concurrently) and, in suitable cases like this example, newton iteration from an initial table-lookup guess unlike the piecewise-taylor approach outlined early in the article, spline interpolation only requires storing a tiny amount more data than simple nearest-neighbor table lookup (potentially three more points for fourth-order interpolation, so a 256-entry table becomes 259 entries) on a different topic, i think it's easy to find embedded dsp applications where the easiest solution uses fourier transforms, which usually do require high-precision floating point. machine vision, radio communication, musical applications, etc. incidentally, if you find yourself in a situation where you actually need the taylor expansion of √(1+x) or √(½+x) or something, and you don't want to do a bunch of pencil-and-paper algebra (or don't trust yourself), pari/gp has your back: ? sqrt(1+x) + O(x^5) %5 = 1 + 1/2*x - 1/8*x^2 + 1/16*x^3 - 5/128*x^4 + O(x^5) ? sqrt(1+x) + O(x^7) %7 = 1 + 1/2*x - 1/8*x^2 + 1/16*x^3 - 5/128*x^4 + 7/256*x^5 - 21/1024*x^6 + O(x^7) ? sqrt(1/2+x) + O(x^5) %6 = 0.70710678118654752440084436210484903928 + 0.70710678118654752440084436210484903928*x - 0.35355339059327376220042218105242451964*x^2 + 0.35355339059327376220042218105242451964*x^3 - 0.44194173824159220275052772631553064955*x^4 + O(x^5) reply dang 15 hours agoprevRelated: Chebyshev Approximation - https://news.ycombinator.com/item?id=10115336 - Aug 2015 (60 comments) reply richrichie 14 hours agoprevAs Boyd says in his book on Chebyshev Methods: when in doubt use Chebyshev polynomials. I use Chebyshev polynomials extensively in finance and have tried problems like MNIST with Chebyshev and they get close to CNNs in accuracy. ApproxFun Julia package pretty cool for Chebyshev work: https://juliaapproximation.github.io/ApproxFun.jl/latest/ reply skyde 2 hours agoparentWhat do you mean by close to CNN? What is your architecture? Is it just a fully connected layer of chebyshev? reply archermarks 16 hours agoprevNice article, thanks for sharing! reply inamberclad 14 hours agoprevOnce more, this is _exactly_ why Ada has arbitrary precision decimal arithmetic. One merely needs to specify type Result is range -100 .. 100 delta 0.0001; and the compiler will figure out how to give you fast math with only the accuracy and resolution that you need! reply AlotOfReading 13 hours agoparentHow does that feature work without a solution to the tablemaker's dilemma? Does the compiler just give up and give you arbitrary precision every time you use transcendentals or does it give up and use lower precision if the estimate exceeds some arbitrary bound? reply LegionMammal978 10 hours agorootparentLooking at the spec [0], it only demands 1 ULP of precision for the elementary operations, and 2, 4, or 8 ULPs for special functions. So there's no magic 1/2-ULP guarantee. [0] http://ada-auth.org/standards/22rm/html/RM-G-2-3.html reply kragen 9 hours agoparentprevhave you tested this? how fast and accurate were the results? or are you simply assuming that all compilers are perfect? my experience outside of ada is that decimal arithmetic is never fast on binary computers reply abecedarius 5 hours agorootparentaaui that Ada line would declare a fixed-point type, so decimal/binary shouldn't really come up except for overflow handling, here. (Haven't tried it though.) reply bryan0 15 hours agoprev [2 more] 2012 reply dang 15 hours agoparent [–] Added. Thanks! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Jason Sachs' blog post delves into the Chebyshev approximation, a technique for efficiently computing functions in resource-constrained embedded systems.",
      "The post contrasts Chebyshev polynomials with Taylor Series, highlighting their efficiency and numerical stability, and provides Python code examples for practical implementation.",
      "Practical applications include fitting Chebyshev polynomials to functions like sine and using them for sensor data estimation, making the technique highly recommended for embedded systems."
    ],
    "commentSummary": [
      "Chebyshev approximation is a mathematical technique for efficiently approximating functions, leveraging Fourier transforms and recursive definitions.",
      "Key benefits include computing coefficients in \\(O(n \\log n)\\) time and performing operations like multiplication and differentiation in \\(O(n)\\) time, enhancing the speed of tools like chebfun/chebpy.",
      "Chebyshev methods are versatile, applied in fields such as finance and machine vision, and can sometimes match the accuracy of convolutional neural networks (CNNs)."
    ],
    "points": 110,
    "commentCount": 18,
    "retryCount": 0,
    "time": 1717807077
  },
  {
    "id": 40612321,
    "title": "Challenges and Strategies for Debut Novels in a Fragmented Media Landscape",
    "originLink": "https://www.esquire.com/entertainment/books/a60924704/debut-fiction-challenges/",
    "originBody": "Every product was carefully curated by an Esquire editor. We may earn a commission from these links. Getty Images / Photo Illustration by Mike Kim EntertainmentBooks Why Are Debut Novels Failing to Launch? For first-time writers, it’s harder than ever to break out. That poses an existential crisis for publishing—and disturbing limits on your access to exciting new voices. By Kate DwyerPUBLISHED: MAY 30, 2024 SAVE ARTICLE On the Road was not Jack Kerouac’s first novel, but you’d be forgiven for thinking as much. Though 1957’s On the Road is widely considered to be Kerouac’s “debut,” the author’s first novel, The Town and the City, was in fact published in 1950. By all measures, it flopped. Between that book and the launch of On the Road, Kerouac started working with the literary agent Sterling Lord, who believed he could be the voice of his generation and laid the groundwork for his public reception as such. What, exactly, did Sterling Lord do to prime Kerouac’s audience? From 1953 to 1957, he leveraged his own professional connections to place excerpts of On the Road in magazines like The Paris Review and New World Writing, building hype for the young novelist’s next book. This is common practice today, but in the fifties, it was a novel solution to the name-recognition problem faced by unknown writers. After a few years of seeing Kerouac’s byline in print, the thinking went, readers would pay attention when they recognized his name on the cover of On the Road. It was one of the first literary “debuts” of its kind, explains Temple University professor Laura McGrath, author of the forthcoming book Middlemen: Literary Agents and the Making of Contemporary American Literature. McGrath argues that Sterling Lord created the blueprint for the literary “debut” phenomenon we still see today. related stories How Queer Morality Is Changing Fiction Why We Love Time Travel Stories Is “Doomslang” Making Us All Numb? But unlike in the late fifties, when there were only a handful of venues for reaching the public—national magazines with hundreds of thousands of subscribers, a few television channels—today’s overstuffed, under-resourced media landscape means that book coverage is more fractured and reaches fewer readers. These days, an unknown author’s chances of success hinge on cobbling together an audience through aggregate. Last fall, while reporting Esquire’s “Future of Books” predictions, I asked industry insiders about trends they’d noticed in recent years. Almost everyone mentioned that debut fiction has become harder to launch. For writers, the stakes are do or die: A debut sets the bar for each of their subsequent books, so their debut advance and sales performance can follow them for the rest of their career. For editors, if a writer’s first book doesn’t perform, it’s hard to make a financial case for acquiring that writer’s second book. And for you, a reader interested in great fiction, the fallout from this challenging climate can limit your access to exciting new voices in fiction. Unless you diligently shop at independent bookstores where booksellers highlight different types of books, you might only ever encounter the big, splashy debuts that publishers, book clubs, social-media algorithms, and big-box retailers have determined you should see. In December 2021, The New York Times called best-selling debut novels “the bald eagles of the book world.” Of the fifteen that appeared on the newspaper’s hardcover-fiction list that year, writer Elisabeth Egan wrote, “only five were by non-celebrity authors who had not been anointed by Oprah Winfrey, Reese Witherspoon, Jenna Bush, or the Good Morning America Book Club.” Today, it’s not enough to land a spot in one of these coveted book clubs. According to an editor at a venerable publishing imprint, debut novelists need three key publicity achievements to “break out”: one, a major book club; two, a boost from Barnes & Noble, Amazon, Indie Next, and/or Book of the Month; and three, a major profile. A few times a year, one of these breakout debuts lands on everyone’s reading list—think Jonathan Escoffery’s If I Survive You, R.O. Kwon’s The Incendiaries, and Stephanie Danler’s Sweetbitter—but those are few and far between. There were roughly five hundred thousand books published in 2023, per BookScan (which captures only about 85 percent of industry data), and no one knows how many debuts are published each year. Most come and go without much fanfare. The vast majority of titles sell fewer than five thousand copies, but across the entire industry, book sales are up. In 2004, there were at least 648 million books sold in the United States, and in 2013, 620 million; last year, there were at least 767,360,000 books sold—a significant increase. If that’s the case, then why does it seem like it’s harder now for a debut writer to “break out”? Debut novelists need three key publicity achievements to “break out.” For starters, the business of promoting books has changed. When publicist Nicole Dewey started working in publishing twenty-five years ago, she says, there would be “reams” of advance copies to send to booksellers, along with a robust ecosystem of national papers and magazines eager to review books. Regional media and alt-weeklies were thriving, too. “Getting the review on the cover of The New York Times Book Review, an NPR interview, People magazine, and maybe a morning-show interview used to be the golden ticket for a book,” Dewey says. (A literary agent shares a different winning combination: an excerpt in Time or Newsweek, a TV segment, and a review in The New York Times.) Today, there is no such formula. To succeed in our fractured media environment, Dewey says, her publishing imprint, Spiegel & Grau, sustains publicity efforts over a period of several months instead of halting a title’s PR efforts in the weeks after publication day. She believes the strategy works: Shelley Read’s debut novel, Go as a River, which came out in early 2023, has sold 120,000 copies across all formats and is now selling twice as many copies per week as it did a year ago. The days of unlimited advance copies are over as well. A publicist at a major publishing house (who requested anonymity) says that before the pandemic, they would have mailed “thousands” of advance reader copies (ARCs) to tastemakers in publishing, media, and bookselling, ensuring a buildup of industry buzz over several months. Many publishers realized they saved money by switching to digital galleys during 2020, when reviewers’ mailing addresses were changing and warehouses were short-staffed. “Now I’m lucky if I get seventy-five galleys,” that publicist says. “How am I supposed to ‘make’ a book if I don’t have galleys?” Today, publicists have a Spidey-sense that a book will pop when they receive more incoming requests than there are advance copies available, particularly requests from colleagues at other publishing houses who want to read a certain book for fun. With most titles, it’s the other way around, and publicists offer galleys to overwhelmed media workers who may or may not respond to their emails. While promoting On the Road, McGrath says, Sterling Lord highlighted the parallels between Jack Kerouac—the young, photogenic author who did actually embark on a road trip—and Sal Paradise, his protagonist. That way, readers would feel as though the world of the novel “extended beyond it,” McGrath continues, and readers could “participate in the publication” by buying a copy of the book. Such a “narrative arc” becomes a game changer for a debut author when it lands, says independent book publicist Lena Little. “I think the public is often eager for the intimacy of getting to know the writer,” she adds. Connecting an artist’s biography to their art—or, by another name, creating a parasocial relationship between readers and authors—has long been an effective marketing strategy. But for debut authors, it now goes beyond writing personal essays and includes becoming a bona fide social-media influencer. In his book Filterworld: How Algorithms Flattened Culture, the cultural critic Kyle Chayka argues that all creators must also be influencers to compete in the attention economy. “Influencers get attention by exposing parts of their life that have nothing to do with the production of culture,” Chayka says, whether by tweeting about it, posting visuals on Instagram, making TikTok videos, or writing newsletters. But lately, the social-media landscape has changed in a way that disadvantages unknown novelists specifically, more so than first-time nonfiction writers. In 2012, remembers Lisa Lucas, who recently departed from her role as Pantheon Books’ publisher, Book Twitter was “emergent” and Facebook showed which of your friends had RSVP’d to book launches. “The burgeoning utility of social media gave everyone this extraordinary opportunity to do more, be seen by new people, and connect with authors and writers and communities and institutions that they had literally never been able to connect with directly,” Lucas says. Just twelve years later, much of that infrastructure has splintered. “I think the public is often eager for the intimacy of getting to know the writer.” Publicists started noticing the cracks when Snapchat emerged in the mid-2010s. In 2016, when Kathy Daneman was promoting Tony Tulathimutte’s debut novel, Private Citizens, she booked the author on a magazine’s Snapchat channel. Yes, she explained to the novelist, he’d worked on the book for seven years, but now he had less than two minutes to pitch it to readers, and yes, the video would disappear in twenty-four hours. “I felt that this perfectly encapsulated where we were in publishing at that moment,” the publicist says. These days, “in order to get exposure, you have to make the kinds of content that the platform is prioritizing in a given moment,” Chayka says. On Instagram, that means posting videos. Gone are the days of the tastefully cluttered tableaux of notebooks, pens, and coffee mugs near a book jacket; front-facing videos are currently capturing the most eyeballs. “A nonfiction author at least has the subject matter to talk about,” Chayka says. (Many nonfiction writers now create bite-size videos distilling the ideas of their books, with the goal of becoming thought leaders.) But instead of talking about their books, novelists share unboxing videos when they receive their advance copies, or lifestyle videos about their writing routines, neither of which convey their voice on the page. Making this “content” takes time away from writing, Chayka says: “You’re glamorizing your writer’s residency; you’re not talking about the work itself necessarily.” BookTok—er, TikTok—is still considered the au courant emergent platform, but unlike Instagram and Twitter before it, publishers can’t figure out how to game the algorithm. “It’s a wonderful tool, but it’s an uncontrollable one,” Lucas says. As opposed to platforms like Twitter and Instagram, on which authors can actively post to establish a following, the runaway hits of BookTok (see: The Song of Achilles) grew from influencer videos. There is also the challenge of getting seen at all. Across both TikTok and Instagram, “what you see has already been filtered by the platform,” Chayka says. In the physical world, the same is true in retailers like Target and Walmart, where many of the stocked books are already on the New York Times best-seller list or elevated by celebrity book clubs. “Hopefully you get a shout-out from Isaac Fitzgerald on the Today show,” Daneman says, or a mention on a late-night show like Late Night with Seth Meyers, in addition to a boost from a national retailer’s sales and major media coverage. “There’s always a large group at the beginning of the race,” Lucas says. “The job is to differentiate yourself and to be seen in this moment.” In recent months, the literary Internet ignited with heated discussions about the concept of the “literary It girl.” The phrase is often deployed as shorthand for writers like Joan Didion and Zadie Smith, who are respected for their writerly prowess and aesthetic sophistication. Literary It girl status is coveted among debut novelists, and for a while, the phrase seemed to apply to writers who were also social-media personalities. But I would argue that the proverbial literary It girl status among debuts is reserved for the authors of genuinely anticipated books or those advance copies making waves in the book world several months before publication day. Thanks to his agent’s long-term investment in making his name, Jack Kerouac was a literary It girl long before On the Road hit bookstores. “Energy tends to attach itself to wherever energy is already attached,” Lucas says. “Fewer debuts have a chance of really breaking through the noise in this climate, because all of the energy attaches itself to the ones that have made it past a certain obstacle.” In some cases, the energy starts building as early as when a project is first announced. Booker Prize finalist Jonathan Escoffery, for example, became a writer to watch when his story “Under the Ackee Tree” won The Paris Review’s Plimpton Prize in 2020. Bonnie Garmus’s Lessons in Chemistry created buzz after it sold for $2 million to Doubleday and became the book of the 2020 Frankfurt Book Fair. (She also debuted later in life than most writers.) Meanwhile, Stephanie Danler’s waitress-turned-novelist backstory was reported in The New York Times—in a piece that also mentioned Emma Cline’s and Imbolo Mbue’s seven-figure advances—almost two years before Sweetbitter launched. “The job is to differentiate yourself and to be seen in this moment.” So how do authors create energy around themselves? Establishing a presence in the literary world helps. After roughly three years of publishing the glossy alt-lit publication Forever Magazine and hosting events around New York City, Madeline Cash, twenty-seven, and Anika Jade Levy, twenty-nine, sold their debut novels in quick succession earlier this year—Cash to Jackson Howard at Farrar, Straus and Giroux and Levy to Kendall Storey at Catapult. Both writers—who met in high school in Los Angeles—connected with their editors in person: Cash at a dinner party in Chinatown and Levy at the Storyfort writing conference in Boise, Idaho, where both she and Storey were speaking. Cash’s Lost Lambs, per her editor, was one of the hottest manuscripts at the London Book Fair, where she sold UK rights in thirty-six hours, along with translation rights in four other countries. Chayka believes that “you need enough people aware of your persona that they want to buy your book, regardless of what the book is,” but editors and publicists agree that a book needs a “there there” to have staying power, and that a persona without a substantial book won’t break out. “You need to create good art and you need to be professionalized,” Lucas says. Naomi Gibbs, executive editor at Pantheon Books, echoes this idea. “It’s fine for an author to be quietly writing on their own,” she says, but “it does mean the lift for a publisher is bigger. So I do think books like that are probably harder to sell as an agent.” The publicist at the major imprint agrees that there’s an “emperor’s new clothes” quality to promoting books that don’t feel substantial. “If the book is not good, I can’t make something out of nothing,” they say, since time is already spread too thin. Because staff publicists at publishing houses must split their workload among several authors, there is an expectation that an author will now spend untold hours working as their book’s spokesperson. When Kyle Dillon Hertz published his debut, The Lookback Window, which The New York Times called “gripping and savagely beautiful,” he got the impression that because he “wrote a very gay, very queer, very explicit book,” he says, his publicity team believed that he “would know the people to whom the publicist or marketer should connect.” But he didn’t. “I’m a writer; I’m not a BookTok person,” he adds. “I don’t have that set of knowledge.” Lately, more writers have been hiring freelance publicists to focus on their books. A literary agent at a talent firm tells me they believe that most of “the top 20 percent—sales- and media-attention-wise—of literary novels of the past two years had external publicists.” Such publicists charge into the mid-five figures for their services, so only writers with significant advances (or the independently wealthy) are able to afford them. The cost is justified, writers believe, because there can be a sense of panic around whether their book is doing “well enough.” In this precarious publishing climate, the panic is sometimes warranted. The agent at the talent firm describes a “one strike and you’re out” mentality, with some authors getting dropped by their agents if their debut doesn’t sell well. With second novels, the agent explains, those writers are “starting at square one but worse,” because “they’re back to querying and they have the burden of a bad sales track.” But one positive development amid this sense of precarity is the rise of the literary friendship. “On social media,” Isle McElroy wrote for this magazine in September, “writers are just as likely to hype their peers as they are to self-promote: linking where to buy books, posting photos of readings, and sharing passages from galleys.” There is now an all-ships-rise mentality among authors at every career stage, but particularly among first-time novelists. Now networks of writers are more important than ever. Community is the single most powerful tool for a debut writer. A writer’s community is where word-of-mouth buzz starts building, and where advocates emerge from surprising places. One of Gibbs’s 2024 debut authors, Gina María Balibrera, was an event coordinator at Literati Bookstore in Ann Arbor, Michigan, for several years. In addition to attending an MFA program and editing a literary magazine, Balibrera “did this work of supporting other writers for a long time,” Gibbs explains. When it was time to ask other writers for blurbs for The Volcano Daughters, Balibrera had friends who were excited to boost the book, but she could also rely on other writers who remembered her from Literati. “There was goodwill built up already,” Gibbs says. “Community is the right goal,” Chayka says. “Community is very possible outside of online spaces. You can build community in real life.” Some publishers, too, are building it among their authors. At the end of April, the imprint One World hosted a weeklong residency to foster community among twenty-one of its authors at the upstate New York retreat center Art Omi. “The process of writing is often a solitary process, and it can feel very isolating,” says Nicole Counts, the executive editor who organized the retreat and secured funding from the Hawthornden Foundation. For authors, she adds, community can be a grounding force, and those who feel unmoored might end up quitting the industry altogether. “When you have community,” Counts says, “you have a way forward through the ups and downs.” related stories Is Being An Author Still a Career? What's the Future of Books? The Rise of Literary Friendships WATCH NEXT Advertisement - Continue Reading Below books The Last Gay Erotica Store How We Broke the Social Safety Net How to Read ‘Game of Thrones’ In Order Books by ‘Under the Bridge’ Author Rebecca Godfrey Teddy Wayne Knows What Makes the World Go Round The Best Nonfiction Books of 2024 (So Far) All 77 Stephen King Books, Ranked How Queer Morality Is Changing Fiction What I’ve Learned: Stephen King Kevin Kwan Almost Didn’t Finish This Book Books About the Asian American Experience Read an Excerpt from Stephen King’s New Book Advertisement - Continue Reading Below",
    "commentLink": "https://news.ycombinator.com/item?id=40612321",
    "commentBody": "Why are debut novels failing to launch? (esquire.com)107 points by Caiero 23 hours agohidepastfavorite202 comments boznz 21 hours agoSpent several years writing and editing my first book before thinking the job was finished when I hit the publish now button. But it is literally only half the job done. The hell now is unless you get friends and family or an agency involved to push it and market it it will languish on the 500th page of any Amazon search forever. Oh and did I say that there are thousands of books a day released and there is nowhere you can self-promote stuff if you do not have social media, HN and reddit will also immediately block self-promotion even if relevant to the audience (I guess I can understand why). I guess the only ones destined to read it are the AI training algorithms. Still it wont stop me writing, having a book published, even if nobody reads it is very self-satisfying and leaves something of you in this world when you are gone. reply pavlov 21 hours agoparentTen years ago I wrote a science fiction novel in Finnish, printed 300 hardcover copies at my own expense, and gave them away to people over the years. I would guess less than 10% of those copies have actually been read. (A few people claim they liked it, but of course that doesn't necessarily mean they read it.) So, a waste of time and money? That's not how I feel about it at all. The creative process was illuminating. And as you say, it's satisfying to think that there's now a physical artifact of my mind that's longer and deeper than any other work I've produced, and it will probably stay for a while on somebody's bookshelf after I'm gone. reply hi-v-rocknroll 17 hours agorootparentExactly. Don't expect anyone to read what you wrote, much less commercial success, unless you were a Harvard undergrad English prodigy who joined Penguin publishing, or somehow wiggled into the circle of [City] Review of [Each Others'] Books. It's a one-way, time-traveling message in a bottle comprised of dead trees. Doing it for art is a wolf's howl that it lived and that it could. Although, it's gradually shifted into over-reliance on the linkrot of spinning rust, floating electrons, and burning transistors such that used and new bookstores and libraries are endangered species. Perhaps another cycle similar to the early medieval period maybe gradually happening as today's \"Romes\" decline in slow-motion, accelerated by climate change decline unless and until we save ourselves through economic and ecological limits. reply frutiger 7 hours agorootparent> It's a one-way, time-traveling message in a bottle So too is DNA in children. You don’t get to choose the entirety of the message but you do get to choose the half of the lottery that they must receive. And that message is likely to far outlive any message in any dead tree or electronic book. reply archon1410 2 hours agorootparent> And that message is likely to far outlive any message in any dead tree or electronic book. Berkeley News: Bottlenecks that reduced genetic diversity were common throughout human history (https://news.berkeley.edu/2022/06/23/bottlenecks-that-reduce...) Perhaps the assertion is true in the sense that an average, mediocre person will have a better chance of having his genetic line survive than writing something that immoratalises him in history, like Newton or Pascal. But But if one has the ability, the latter might be a safer option... reply serf 6 hours agorootparentprevwhere there is increased opportunity there is usually increased risk; it's hardly a relative comparison. also no one really chooses their offspring's 'half of the lottery', it's an accident of nature -- we only get to choose whether or not we try to propagate our own skew into the lottery roll. and to be very real here for a second, 99% of sexual interaction has nothing to do with genetic time-traveling bottle-messages, and just as few people really give a thought about the genetic combinations resulting from their actions. they just like to orgasm -- it's just not as poetic a concept to talk about. reply frutiger 5 hours agorootparent> also no one really chooses their offspring's 'half of the lottery', it's an accident of nature -- we only get to choose whether or not we try to propagate our own skew into the lottery roll In modern societies, most people choose their mating partner. That’s the lottery half that I am referring to. Of course no one chooses specifically which half of each mate goes into the child. That would be absurd. > and to be very real here for a second, 99% of sexual interaction has nothing to do with genetic time-traveling bottle-messages, and just as few people really give a thought about the genetic combinations resulting from their actions. For the individual sure “it’s just deliberate sex” but for the genome, transmission of the message into the distant future is all there is. Just look around you, you will likely see and hear more evidence of those billion year long message transmissions than anything else. reply psadri 13 hours agorootparentprevDigging the phrase \"wolf's howl\". I distinctly know this phrase is part of song's lyrics - but can't think of the name. reply beej71 14 hours agorootparentprev> A few people claim they liked it, but of course that doesn't necessarily mean they read it. Reminds me of that Groucho Marx quote: \"From the moment I picked up your book until I put it down, I was convulsed with laughter. Some day I intend reading it.\" :) reply pdonis 14 hours agorootparentThere's also the classic Churchill quote, when a friend who had just published a book gave him a copy: \"Thank you very much, I shall lose no time reading it.\" reply nothercastle 1 hour agoparentprevWhy write a book as your first attempt? It seems like you would need to write a bunch of short stories and establish a name for yourself before anyone would commit to reading your book. reply devbent 21 hours agoparentprev> HN and reddit will also immediately block self-promotion even if relevant to the audience ( HN doesn't block self promotion if it comes up as part of a conversation, e.g. \"I'm having this technical problem.\" Re: \"I wrote a book about how to solve that!\" Also you can at least put a link in your profile! Reddit has tons of self promos all the time, it just depends on the subreddit. Also it helps if you're a long time active member in a community. reply modeless 20 hours agorootparentHN doesn't block self promotion in stories either. There's a whole section for it, \"Show HN\". reply boznz 17 hours agorootparentMy comment was because my last three submissions were blocked. I emailed the moderator the first time it happened, and he said the algorithm probably thought it was self-promotion as I cross posted it to medium.com which I now know everybody hates. By blocked, I mean the articles showed as normal on my browser but was hidden to anybody else. I did not use the \"Show HN\" option because I have had articles submitted in the past from my website without this issue. I am not a prolific poster, maybe 2 or 3 a year, and appreciate HN efforts to keep the spam out, so I will give it another shot on my next original article using the \"Show HN\" option. Ironically my last submission that was rejected was exactly about this https://rodyne.com/?p=1400 reply jsnell 6 hours agorootparentYou shouldn't use Show HN for an article or blog post. See https://news.ycombinator.com/showhn.html I suspect the suggestion was made due to you talking about books originally, which (given a sample chapter) are the one stated exception to written materials being out of scope for Show HN. reply bryanrasmussen 11 hours agorootparentprevRight, I seem to get the same result on things I post from my medium publication - which started after I posted some links to some time travel stories I wrote in a post about time travel which seemed to me to relate and which got a few upvotes. After that if I posted a link to an article I wrote it got shadow blocked (at least for a bit) the thing is I only post things here that I think fit the site, which is about 10% of what I write, and I am a relatively prolific poster. Looking at my current submissions - in the last 30 submissions one was to an article I wrote. Why? Because I thought it fit HN, just like all the other things I post I think fit HN. Personally I think that's being a relatively well-behaved user of the site, but evidently not. reply joenot443 6 hours agorootparentLots of people submit their own work to HN all the time to great success. If your post was flagged, it probably just wasn’t as relevant to the community as you might have imagined. Perhaps take it as constructive criticism on your writing, rather than blaming the poor reception on the community. reply bryanrasmussen 6 minutes agorootparentso I wrote >After that if I posted a link to an article I wrote it got shadow blocked and you responded >If your post was flagged please take that as constructive criticism (explanation if you don't get my point: I did not use the word \"flagged\") raydev 2 hours agorootparentprevFunny to call it \"constructive\" when the reasoning for the flag is absent. reply bryanrasmussen 11 hours agorootparentprevthe Show HN guidelines as I understand it says it is not for stories or articles, but for projects you are working on or have made? Am I misunderstanding that. reply xhevahir 21 hours agoparentprev> I guess the only ones destined to read it are the AI training algorithms. I'm imagining a lone genius toiling away at a novel and dying in obscurity, with his work gaining recognition only after his death, à la Herman Melville, except in this future the writing eventually enters the canon by deeply impressing not human but machine readers. reply troutwine 20 hours agorootparentMelville was a prominent author, an early sex symbol even, owing to the success and popularity of his novels before Moby Dick. That novel was hugely controversial in its day -- perceived as blasphemous, overwrought -- and it ruined his reputation as an author. Also, he'd spent money he didn't really have during the writing of Moby Dick so that when it flopped he couldn't survive on the famine part of the feast/famine divide. Point being, had Melville continued writing south pacific adventure novels he probably would not be remembered today but might have died a well-off man. reply bowsamic 12 hours agorootparentThis doesn’t line up with what is written on his Wikipedia page at all, which claims it was his next novel that was more controversial, and he clearly wasn’t that poor because he did a grand tour of Europe and the Mediterranean a few years after reply troutwine 3 hours agorootparentI can’t speak to the Wikipedia page as I have not read it but the biographical material in my Norton Critical Moby Dick and Delbanco’s Melville line up: Moby Dick was a flop and ruined his reputation in society, Pierre not selling further precipitated the crisis built from choices made while riding a high into The Whale. Melville bought many things with debt: his farm, his rare books, clothes. I don’t find it unimaginable that he paid for the grand tour with debt spending either. reply mensetmanusman 8 hours agorootparentprevThe machine wept. reply malux85 13 hours agorootparentprevI wonder if the machines will be more impressed by elegant, efficient, bug-free code reply bryanrasmussen 11 hours agorootparentgiven what I see they put out when prompted - I suppose not. reply narrator 2 hours agoparentprevNot many people have read my novels because they are extremely dense and technical near future stuff, but I've made interesting friends from writing those books. In fact, one contact I made basically paid for the whole two year investment in writing the novel. I know a very successful writer of thrillers and he said that the technical content of the books would have to be completely stripped down to maybe what's contained in a few chapters of my book in order for it to be mainstream accessible. reply er4hn 21 hours agoparentprevI agree on it being self satisfying. I wrote a short story on my blog once that I seriously doubt anyone ever read. It was a cyberpunk story, but the themes were really very much about how I felt about having my startup crash and burn early on. After finishing it I felt like I'd finally been able to express how I felt about everything. reply laurex 21 hours agoparentprevIsn’t “Show HN” a thing that exists for self-promotion? It doesn’t guarantee anyone will upvote it, but seems like it’s fine? reply bryanrasmussen 11 hours agorootparenthttps://news.ycombinator.com/showhn.html Show HN is for something you've made that other people can play with. HN users can try it out, give you feedback, and ask questions in the thread. Off topic: blog posts, sign-up pages, newsletters, lists, and other reading material. Those can't be tried out, so can't be Show HNs. Make a regular submission instead. but if you make a blog post and you make a regular submission and those blog posts of yours get automatically pulled out...then what? reply soneca 8 hours agoparentprevAnother option is starting a newsletter, which feels more suited for a writer to gather readers (when compared to gather “followers” on any social media). Full disclaimer: I believe that so much that (as a fellow beginner writer) I created a “newsletter” platform more suited for fiction writers to slowly form an audience of readers owning the mailing list. https://writer.confabulists.com You still have to keep writing constantly (essays, short stories, chapters of a novel, or even some communication of what you are doing) but it feels more natural for writers to write than to keep posting cute pictures, hot takes or creative short videos. Also, I added the concept of “books” in my platform, so new subscribers to your newsletter start reading your old stuff (not only your future posts). Having a newsletter also is very satisfying that you keep some contact with people that like what you write, no matter how few they are. reply ghaff 21 hours agoparentprevSo it's either a hobby--which is fine!--or it's an adjunct to a day job which can be very profitable--which is very fine!. But, yes, publishing a book that you think will be a bestseller with or without exceptional promotion is probably a lost hope. reply ido 11 hours agoparentprevthere is nowhere you can self-promote stuff if you do not have social media Isn't the solution (I know it's not that easy) to have social media? reply Draiken 4 hours agorootparentI believe social media [with a big following] is implied. Otherwise it's useless too. reply desert_rue 4 hours agorootparentprevthere is nowhere you can self-promote stuff if you do not have social media [with a significant following] They forgot the last bit. reply ravenstine 3 hours agoparentprevWhy not sell physical copies of your book from out of the trunk of your car? reply dangus 4 hours agoparentprevFinancially successful writers embrace the sales and marketing game. Like you said, writing the book is only half (or less!) of the work required to get someone to read it. That means constantly engaging their target audience, setting up booths at conventions, posting interesting content on social media, etc. Writing for yourself is a wonderful thing. But if you do want more people to read your work, I would recommend scrapping the idea of avoiding social media and treat your social media presence like a business treats social media. For you it’s not a toxic doomscrolling app, it’s an app you use for your business during your business hours to market your business. Let’s be real, so far you’ve basically talked about how you’ve been unwilling to do anything besides write. > The hell now is unless you get friends and family or an agency involved to push it and market it it will languish on the 500th page of any Amazon search forever. Sure, that will be the case if you just click publish and sit back doing nothing hoping for some sales. I sure hope my family and friends market my book for me, because I don’t want to be in social media! And, hey, that’s fine, not everyone wants their hobby to be some kind of side business. But I sense a bit of disappointment in your comment almost like you tried everything and still haven’t gained traction, which doesn’t seem to be the case. reply gonzo41 4 hours agoparentprevConsider reading your book as chapters into a limited series podcast. reply unclebucknasty 19 hours agoparentprevYour comment resonates and I liken it to promoting when starting a business, which I have just recently done again. Feels like there is a massive imbalance between quality outlets where eyeballs exist and the volume of people /content/businesses vying for attention at those outlets. And, the idea that we need to all become influencers of some scale and amass our own audiences to get the word out about something is not practical or possible. Just creates a long-tail for the platforms. This leaves a relative handful of platforms and influencers through which everyone must flow. It produces an all-or-nothing effect, with tons of failures and a few outsized winners (relatively). I've solved this before, but things weren't as concentrated then. And, ironically, my latest business is intended to solve this for others. But, this startup phase is a beast. reply latentsea 9 hours agorootparentI guess we need to invent ads, so that we don't all have to become influencers? reply unclebucknasty 9 hours agorootparent>I guess we need to invent ads, so that we don't all have to become influencers? It's almost as if you've never bootstrapped a business, self-published a book, or similar. If you have, and had the resources to use paid ads to reach your desired scale, then congratulations. I think that does indeed entitle you to be smug and dismissive with everyone else. reply tomnipotent 4 hours agorootparentSo we're expected to feel sympathy for the broke bootstrapper? What I'm reading is someone wants all the upsides with none of the downsides. No one is entitled to an audience, especially that of another, just because they've produced some good or service. Participating in capitalism requires either time or money, usually both, and even then you're not guaranteed success. reply epicureanideal 2 hours agorootparent> So we're expected to feel sympathy for the broke bootstrapper? Yes. reply unclebucknasty 3 hours agorootparentprev>So we're expected to feel sympathy for the broke bootstrapper? No one is entitled to an audience... Participating in capitalism requires either time or money...and even then you're not guaranteed success. Wow. It's like I'm talking with a real, live Rockefeller! My comment was exactly about requesting sympathy and demanding government mandates to buy my products, and those of every bootstrapper. But, your brilliant, esoteric insight regarding the true nature of capitalism has shown me the light. Thank you! reply lotsofpulp 6 hours agorootparentprev> And, the idea that we need to all become influencers of some scale and amass our own audiences to get the word out about something is not practical or possible. Just creates a long-tail for the platforms. This leaves a relative handful of platforms and influencers through which everyone must flow. >It produces an all-or-nothing effect, with tons of failures and a few outsized winners (relatively The “it” you are referring to here is math, or just the way networks work when the barrier to entry is zero and the speed of information flowing through networks is almost instant. Lots of things in nature follow a power law distribution because of it. reply jimbokun 21 hours agoparentprevI don't understand why Hacker News and Reddit block self promotion. \"Hey, look at a thing I made!\" is a lot more interesting than a lot of the other drivel that gets posted. reply CM30 17 hours agorootparentIn theory, they limit self promotion so that people actually participate in the community, and don't just use it as a link dump. The ideal is that people discuss other topics more often, and share their own work only every so often. A lot of forums and chat servers have similar rules for the same reason. Unfortunately, this doesn't work very well on Reddit, since the smarter advertisers and astro turfers have figured out how to manipulate the system well enough that people don't suspect they're advertising. Add this to how certain types of low effort content get a ton of upvotes anyway, and how popular creators don't need to care since their fans will promote them anyway, and well, the end result is less \"participate in the community\" and more \"don't be unpopular or bad at pretending to be someone else\" reply modeless 20 hours agorootparentprevHacker News doesn't block self promotion. You are free to post your own stories linking to your own work, I've done it, people do it all the time. There's a whole section for it, 'Show HN' (although it's not required to post there). And you're free to post links to your work in comments when relevant. Of course spam is unwelcome everywhere. Don't overdo it and don't be deceptive about it, and you'll be fine. reply bowsamic 12 hours agorootparentHacker News does block self promotion as stated by a mod elsewhere in this thread reply pvg 4 hours agorootparentI can't find such a comment in this thread, can you link it? reply PheonixPharts 20 hours agorootparentprevAs mentioned repeatedly, HN doesn't block self-promotion. But reddit something else entirely. It so clear that all of the major subs are constantly being manipulated by firms working PR for large companies, but the second someone posts \"I made this!\" people get up-in-arms. Of course who really knows how much of reddit is even real people anymore. reply mattgreenrocks 6 hours agoparentprevSame experience for me in another domain (indie apps). I’m okay with getting better at marketing, and allowing for the possibility of lack of product market fit. I’m less okay with believing I have to become Extremely Online to “build my personal brand,” just to have a chance at launching things successfully. That’s some bullshit that they peddle to justify their own addiction. It’s learned helplessness to platforms. reply ghaff 4 hours agorootparentYou have to promote somehow. No one is going to do it for you for free. You can hire a publicist, take out advertising, speak at events, etc. and none of those probably count as \"social media\" but they're neither effort nor cost-free. reply mattgreenrocks 2 hours agorootparentYeah. So my journey's figuring out the way that works well for me. The goal of indie dev for me is to use the computer less ultimately. reply BarryMilo 17 hours agoprevI'm currently starting a publishing company in a niche Canadian market. What people in these comments (and really, most places on the internet) fail to grasp is the role of the publisher as a curator and editor. Unlike your friends, the editor is not your friend. They don't have a stake in your ego, they won't sugarcoat it beyond the veneer of professionalism. You need an editor who is not your friend, too say no to you. No, you shouldn't start your book with this cliché. No, you shouldn't have your character meandering aimlessly. No, you shouldn't use whedonisms. Exceptions apply, of course, but when the editor is your publisher and not your friend, \"shouldn't\" becomes \"can't\". Usually that involves saying no to 99% of manuscripts coming through the door. And this is how an okay story becomes a great book. Your editor, having read more books than you in their segment, knows the difference... usually. All manuscripts are at least a little bit bad, some books aren't. As you can tell, I'm no fan of self-publishing, I just don't believe anyone can be objective enough with their own baby. Now... I've read my fair share of bad books, especially recently. The publisher/editor is to blame 95% of the time. My theory is that being rigorous takes time, which is always in short supply, and skill. I believe people tend not to stay in the same role for too long anymore, lest they lose out financially. Which is totally fair, but skill (and the chutzpah to say \"no\") takes a while to develop, years really. And no one has \"years\" for anything. Except, of course, all the people in the industry who don't mind being poor. And people making bank, I suppose, but these are so few as to be statistically insignificant. reply lachaux 15 hours agoparent> Unlike your friends, the editor is not your friend. It is true. I would like to qualify it by saying \"At the beginning, the editor is not your friend.\" A friendship, even very strong one, can be developed along the time, based on mutual respect and appreciation, temperament match, etc. Even then, a good editor will still be professional and be honest when they edit the writer's draft. A good book may not be a \"successful\" book, especially in literary fiction, since the post talks about novels. The reverse can be true as well. It happens often that the editor tells the author it is a good book, and the publisher allocates resources to marketing it, schedules book tours, etc. while at the same time both the writer's agent and the editor/publisher expect the book may sell only ~2,000 copies. The target audience are expected to be other writers, a subset of avid literature readers, etc. They don't expect it will earn back the advance paid to the author. The publishers have portfolios and long term visions. Of course, this doesn't apply to small publishers, most of which cannot afford it. reply BarryMilo 14 hours agorootparentGood points all around! It's funny because I expect most of us do it for the art, but artistic merit doesn't pay the rent. This is why many smaller publishers have \"locomotives\" that are guaranteed to sell so they can publish \"good\" literature books that won't sell. Don't know about the big American ones, seeing as they're flooding the market I assume they're just playing a numbers game, let God sort them out... reply api 4 hours agorootparentLoads of industries use hits to pay for the entire rest of the industry with the “for the art” stuff often at best making small returns. It’s even true in tech. Most VC backed companies fail but the few mega-successes fund the entire ecosystem. reply BarryMilo 2 hours agorootparentTrue, I guess most artistic industries must work this way, since we all know that about 95% of all art is terrible (and that was before AI). I feel like there's a difference between a company and an industry, though in the end I suppose it's all a sort of natural selection. Good (or rather, \"fit\") authors publish second books and third books, while good companies get to exist into second, third years etc. reply api 4 hours agoparentprevIf I were writing a book I’d definitely consider a real publisher but before that I’d be tempted to pay someone independent to be an editor and be bad cop. A student or remote worker with literary chops would do that as a first pass. Pay them to tell me what about my book sucks before wasting an editors time with a submission. reply ghaff 2 hours agorootparentI'm not sure to what degree I'd trust a student or random online gig worker to give a really useful editorial option. Copy-editing or maybe technical edit? Possibly. I used an intern who worked for a magazine editor I knew to copyedit a book once and that worked fine. But I wasn't looking for substantive structural work. In fairness, I didn't really get that when I went through a publisher either. The second edition was IMO a lot better but that was because I personally came to see where the first edition was stronger and weaker. reply BarryMilo 3 hours agorootparentprevAll it takes more courage than most of us have after writing our first book! reply japhib 21 hours agoprevSeems like almost every creative industry (music, video games, art, writing) is having the same issue: Creation & publication tools are getting cheaper & easier to use, which means a lot more people can publish their creative ideas. With such a huge number of choices, discovery is now the issue. IMO discovery of what is truly high quality is still an unsolved problem. Seems like recommendation systems generally just recommend things that are already popular. For someone that has zero following, but an interesting creative product, there's not much they can do. You're kind of relying on either \"going viral\" or hoping that someone with a lot of followers takes notice of your work and draws other people in. reply photonthug 20 hours agoparent> With such a huge number of choices, discovery is now the issue. It's frustrating if people don't see that this is almost always a manufactured problem, not some an inevitable outcome of simply having more choices. Platforms want to disable the ability for users to differentiate between organic, self-directed discovery vs advertised or promoted content. Discovery needs to be just good enough so that users won't leave, and if there's no alternatives in a space, even that doesn't matter. Having poor discoverability directly increases engagement and nevermind that engagement is high because doing simple things is painful, the take-away for your stock-price here will just be that you're explicitly user hostile and no one leaves, so you must have a captive audience. Every notice how when you're looking for something obscure, you can only find something popular, and when you're looking for something popular, you can only find something obscure? It's not random, it's just the platform working out what profits the company the most. In the case of streaming content for platforms like spotify/amazon prime, some content is cheaper for them to offer. The perfect user is someone who wants low-royalty or completely unencumbered content, because it's cheaper for the platform to license, but the end-user sees the same number of ads for the same length of time. The average user is also someone who can be tricked into being a perfect customer. Suppose the user is searching for RoboCop, and it is missing from the catalog. Terminator might be a better recc, but why not just offer the user some shitty CyborgCopIII instead, just to cut your costs and bump your profits, just in case the user is a sucker? If the user is not a sucker.. great, they'll type more searches, engagement is up, and platforms win either way. Think about how much more data FAANG has than say, GoodReads. GoodReads is small enough that people just rank stuff and it works fine, and people curate lists, and you find what you like that way. It's not working because GoodReads has AI super-powers, it's working because they don't sabotage it away from working. reply plorkyeran 18 hours agorootparentGoodreads shot past the point of being too small to be worth bothering sabotaging years ago, and is now very heavily manipulated. reply badpun 9 hours agorootparentIt's pretty good for dead authors though. reply autoexec 19 hours agorootparentprev> Platforms want to disable the ability for users to differentiate between organic, self-directed discovery vs advertised or promoted content. It's not just that platforms don't want you to know if what they're showing you is an ad or an organic result/recommendation, if they made it easy for people to find what they want then companies wouldn't have to pay them for prominent placement in the first place. There's still a real problem (that AI will only make worse) with really good things being drowned out by a sea of garbage, but people wanting to act as gatekeepers (and collect tolls) only make the problem worse. reply StrangeDoctor 20 hours agorootparentprevGoodreads is faang? The problem isn’t manufactured or conspiratorial, it’s just baked into sorting so much content on so few metrics. And needing to account for what the user is currently in the mood for something specific, something generic. reply photonthug 19 hours agorootparentMy point is that GoodReads isn't popular enough for it to be profitable to sabotage (yet). And there's still a threat of something more relevant coming along. If they actually wanted to improve discovery for something like prime video/shopping, then they could/would copy what works from GoodReads. reply Ruthalas 19 hours agorootparentprevGoodreads is a subsidiary of Amazon. Edit: I realize I misread your comment. Disregard! reply downWidOutaFite 8 hours agorootparentprevAmazon bought goodreads and crippled its discoverability features. reply spondylosaurus 20 hours agoparentprevTrusted (human) reviewers and critics are more important than ever to me. Like you said, lists of whatever's popular or trending are just... things that are trending. For good reasons or otherwise. Meanwhile if I read a Richard Brody review I get a sense of whether a movie might be worth watching—even though we don't have identical taste, I've learned a lot about his, and now I know how his taste translates into reviews. Curation is totally the name of the game now. reply pjlegato 1 hour agorootparentThe problem with that arrangement is that it doesn't scale: a tiny number of popular critics become the gatekeepers. Success in the field then depends entirely on somehow gaining the notice -- and good reviews -- of one of these few critics. Countless other pieces of art are never noticed by anyone, countless talented artists are forced into day jobs and eventually abandon art -- no matter how high quality (for whatever definition of \"quality\" you prefer) -- simply because they were not able to catch the attention of one of the elite critics, for a variety of reasons, almost all unrelated to the quality of the work itself. reply RivieraKid 10 hours agoparentprevGood discovery wouldn't solve this problem. One one hand, you have an ever-increasing pile of good content (all of the games, books, blogs, videos, podcasts, films that were created in the past) but people only have 24 hours per day to consume. For example I've spent a huge amount of time playing a game that's over a decade old. And I'm reading a book that's from 1952. reply namaria 20 hours agoparentprevTime is a great filter. That's why it's commonplace to complain about 'art these days' and to be nostalgic about past books and music. Some of the greatest, most interesting books I've ever read are thousands of years old. reply hierophantic 6 hours agorootparentTime works wonderfully for books. It is a different problem with music though because I want to find newer stuff than Debussy and Miles Davis. reply rixed 19 hours agorootparentprevYou can't know wether time is a good filter without assessing the value of what's been lost forever, can you? reply namaria 11 hours agorootparentI can't know precisely how good of a filter it is but I'm not interested in finding out a definite figure. I have read enough great stuff from picking up a book from 300 BCE or so and I've seen enough BS ghost written flavor of the month non-fiction to know it's good enough heuristics to suggest it in this forum. reply samatman 3 hours agorootparentprevA filter can be good in a couple of ways: it can filter out ~all of what you don't want, and/or ~none of what you do want. Time is a good filter in the first way, which makes it a good filter. Because a filter which doesn't substantially do the first of these things isn't actually filtering: the null filter filters none of what you do want, by failing to reduce the data stream in any way. reply idontknowtech 14 hours agoparentprevGreat point. Editors are filters for what the general public sees. The analog here is probably BookTok or whatever the social media version of book influencers is. They similarly can be expected to promote what they like, or eventually lose authenticity and viewership. Or just start including cartoon sounds into every video. reply o11c 14 hours agoparentprev> discovery of what is truly high quality Sometimes nobody really tries. It doesn't help that there are a lot of perverse incentive systems out there. I'm approaching this from mostly an Internet-centric perspective: One observation I've made is that any story I first see by advertising is probably bad, even if I later see it elsewhere - if it were actually any good, I would've seen it in one of the non-advertising-based mechanisms first. But sites have a strong incentive to promote advertisements to the detriment of quality (and the inaccuracy of \"hot\" lists). The \"zero-initial-following\" problem can be solved by showing each story to a random small subset of active readers (since, as big as the supply of crappy stories is, the demand is always higher). This should be smeared across time-of-day, rather than having a \"new\" queue subject to gamification. There also needs to be a quick \"I'm not interested\" feedback, with reasons including \"breaks site rules\", \"bad story\", \"bad grammar\", \"bad initial hook\", \"bad continuation\", \"I just don't like it\" (featured prominently), and \"this story is badly tagged\" (because both positive and negative tag searches should be the primary way of using any reading site). Some particular ways that tagging implementations can fail: * categories and tags are different things, thus a tag is often missing * no tagging for things like \"this a fanfiction of\", \"this is translated from\", \"author is not a native English speaker\", ... * tag names are ambiguous, meaning completely different things in different contexts * tag names are contextual, providing a different shade of meaning depending on other tags * tags are not prominently displayed when actually looking at a work * user-made tags are permitted, so duplicates and typos are common * user-made tags are not permitted and essential tags that people wish to search for (or hide) are missing * hierarchial (DAG, not tree) tags are not supported, thus a tag is often missing (or if present the list takes up too much space) * no way to specify tag degree (does this just show up in the background, or is it the focus of the work?) * number of tags is artificially limited to a very small number * tag is applied but applicable content doesn't appear yet (mostly relevant for when published serially) Obviously with outright malicious actors, simply fixing these won't fix everything, but they are absolutely needed to function at scale for the honest actors. reply bluefirebrand 13 hours agorootparent> One observation I've made is that any story I first see by advertising is probably bad, even if I later see it elsewhere - if it were actually any good, I would've seen it in one of the non-advertising-based mechanisms first A similar observation I've been finding lately is that if something is highly rated by critics and lowly rated by audiences, it probably sucks I think the current batch of book/movie/game critics out there writing reviews are largely out of touch with what many people enjoy. They don't write useful reviews for consumers anymore There's always accusations of review bombing being the culprit of such skewed scores, but even after sites claim they've culled all of the bad faith reviews, the ratio almost always still exists reply ghaff 5 hours agorootparent>A similar observation I've been finding lately is that if something is highly rated by critics and lowly rated by audiences, it probably sucks Perhaps there is less skew today given that film critics are probably less a high-brow big city newspaper thing overall. But certainly I wouldn't expect the average Friday night young cinema-goer to have the same tastes as the film critic for the New York Times. reply o11c 12 hours agorootparentprevThere certainly are review-bombing campaigns, which can be known with certainty when caught at the same time and from the same source as review-boosting campaigns. Most bad reviews are well-deserved, even if they make the author feel bad. In particular, \"people shouldn't downvote if they've only read 5 chapters\" is an invalid complaint - as an author, your duty is to write a strong start! (I suspect some of these are actually tagging/description failures, but that's also the author's responsibility) reply l72 3 hours agoprevI'm not as familiar with the book scene as I am with the music scene, but I see a lot of similarities. Discovery is a huge issue, and takes a lot of effort. I listen to a specific sub-sub genre of metal that gets no mainstream (even from \"big\" metal publications) attention. The best way I have found to come across new albums is to subscribe to really small labels that specialize in the genre of music. Many of these labels are hobbies or part time jobs for their owners, but I find they do an excellent job curating music I'll be interested in. The problem, is often subscribing and keeping up to date with these labels is really tough. Fortunately, for music, we have bandcamp.com which does a pretty decent job of this (although it takes some additional work [1]). If bandcamp.com went away, I don't know how I'd discover most of my new music. Does the book scene have anything similar? [1] https://blog.line72.net/2021/12/23/converting-bandcamp-email... reply jonahbenton 22 hours agoprevMy long retired parents met and worked in publishing. The continued deterioration of the industry is a source of deep sadness for them. I personally however recently found my own ray of hope. By chance I started reading something I really liked, found it was published by a tiny house that has a subscription plan- which is different from an aggregator having a book of the month kind of thing- and publishes super niche unique voices, mostly translations into English. Have read 6 of their books this year, every single one has been just great. Think the breakdown of the big house and homogeneity of the star model leaves space for new shoots to find their audience. reply rudyfink 22 hours agoparentWhat you said reminded me of this Royal Road (https://www.royalroad.com/home) website I came across. It is not physical publishing (at least I don't think so), but it is a large collection of different authors who release books / work incrementally. The work mainly seems to be fiction of different varieties. reply davisp 21 hours agorootparentRoyal Road is a place for a lot of folks to get audiences seeded before they inevitably move on to some combination of Patreon, Amazon Kindle Unlimited, and Audible. One very notable example of this is Dungeon Crawler Carl by Matt Dinniman. He's even just announced that he managed to sell publishing only rights to Ace for large scale distribution which to my knowledge is a first (from authors that started on Royal Road). https://x.com/mattdinniman/status/1780998536529883622 Also, I'd highly recommend reading Dungeon Crawler Carl if you enjoy anything close to Douglas Adams-esque comedic sci-fi. Its definitely trends a lot more \"adult\" than Douglas Adams, but that's about as close as I can think of off the top of my head for comparison. And I'd very much recommend the Audible versions narrated by Jeff Hayes for anyone that does audio books. The Sound Booth Theater production is also good but I'd only recommend that if you're doing a re-listen. reply murphyslab 19 hours agorootparentThe Dungeon Crawler Carl series' first 4 or 5 books (it's been a little while) were excellent. Carl's tone reminds me of a detective novel, while the setting is more reminiscent of Ready Player One and The Matrix. The genre is a LitRPG novel (admittedly a genre I'd never known existed until reading DCC), heavily doused with comedic elements. Lots of mature themes and references to sex, drugs, politics, and violence, but with some of the allegorical or illustrative critique (to the point of absurdity) you'd find with Douglas Adams or Terry Pratchett when discussing serious topics with parallels to real life, in an imagined scifi/fantasy setting. I'd recommend the series if for those who haven't picked up a book in a while and who would appreciate those elements. reply o11c 13 hours agorootparentprevRoyalRoad has at least 3 major problems: * there's a significant conflict between \"this is a place to read stories\" and \"this is just a place to advertise for Amazon\" * the effective site rules are unwritten and quite arbitrary (one unwritten rule: you are not allowed to say anything positive about real-ish religions, only negative things) * way too much pedophilia, including in site-promoted stories. Unlike religion, it's clearly not something they put effort into removing. reply Narishma 4 hours agorootparentAnother problem is the ratings. Everything there seems way overrated. You'll see a ton of 5-star or 4-star ratings for things that are barely readable. reply dageshi 4 hours agorootparentWhen you've spent many a year reading machine translated chinese xianxia then indeed many stories on RR are 4/5 star worthy in comparison. Royalroad is not a place you go to find objectively good stories, it's the place you go to enjoy your particular blend of delicious trash because in the end you'd rather read chapter 1600 of the long running braindead litrpg than you would whatever just won the hugo's. reply api 4 hours agorootparentprevEww that’s not just a problem. The last two tell me something about the community. Hard pass. reply lachaux 15 hours agoparentprevI am very glad that you find your own ray of hope. I understand the sadness that you parents feel. I know some people in publishing. The industry was in an mode of existential crisis when Amazon Publishing was launched. It then went through social media, Goodreads, etc. It seems the industry survives, although the future is still murky. The industry indeed needs J. K. Rowling, Sally Rooney, Colleen Hoover, celebrity biographies & memoirs etc. to survive. Good books will find their way to be published, and get discovered, maybe dozens of years later. I happened to read a novel by an English author published ~100 years ago. It is a good book, IMO. The publishing house had only one person. The entire office was one room in his apartment. reply carabiner 21 hours agoparentprevNaturally, you mustn't mention the name in order to keep it exclusive. reply jonahbenton 20 hours agorootparentThe publisher is And Other Stories, UK based. Not a pitch. Just my experience. reply satvikpendem 21 hours agoparentprevWhat are the names of these books? reply jonahbenton 20 hours agorootparentMammoth, Inland, Down The Rabbit Hole, Open Door, Zbinden's Progress, The Luminous Novel, I Don't Expect Anyone To Believe Me. Actually that is 7. All very different, but arresting. Purity, All Dogs Are Blue, and Lightning Rods are next up for me, not sure which one will grab me, probably Purity. reply motohagiography 16 hours agoprevWrite something someone wants. Literary fiction was art that discovered and expressed the essential, where cultural production today explicitly militates against anything that could be percived as essential(-ist). New novels are failing because the culture has no eros. Readers have become too socially poor to risk investing in ideas that could compromise their cultivated homogeny, and it's just too hard to care with any sincerity what someone brand safe for public radio writes about. I guess I'm saying novels would sell better if the people selling and publishing them produced something people actually wanted instead of churning out what they are being told by their granting agencies is good for their readers. reply greenie_beans 4 hours agoparentsounds like you might like to read books from independent presses. this distributor is a good place to find stuff: https://asterismbooks.com/ > Write something someone wants. i don't think we should apply a VC-isms to art. so many great pieces of art were overlooked because the market didn't want them at the time, only to be discovered and appreciated later. reply stubish 15 hours agoparentprevI'd wager most books are content someone wants. A lot are even content a lot of people want. This is not good enough. Reaching the audience is the problem. Also, writing a book can take years. Writing for what people want today is how you fail, as people will have moved on in the five years it took to write, edit, sell and produce the work. If you can reliably predict market desires in 5 years time, you have a lot more than a best selling novel on your hands. reply bluGill 6 hours agorootparentThere are more good books than time to read. That is why reaching an audience is hard, you are not better than the other choices. reply grugagag 6 hours agorootparentYou can’t say that until people could reach you, read you and move on. reply adamc 16 hours agoparentprevThere are lots and lots of well-written, relatively obscure books. I don't think that has much to do with being \"brand safe\". It has to do with discoverability, network effects (people are more motivated to read books people they know have liked), and the vast number of books. reply bane 17 hours agoprevMany many years ago a friend did a stint at a major publishing house. Whenever she'd show up to parties she would bring in a small stack of unpublished manuscripts, we'd all get into the wine or beer or whatever and start reading particularly terrible passages to each other. Had she sought out especially bad manuscripts? No! She just grabbed whatever was on the \"will read, maybe, someday\" shelf in the editor's work area. I learned about Sturgeon's Law (90% of everything is crap) during these events. Most people think what they've written is interesting, or unique, or worth publishing. However, publishers have to make money, so they curate very carefully, edit the hell out of the raw manuscripts, and then only actually commit to publishing what they think there's a market for. Nearly zero of the random manuscripts that are sent in by unknown authors ever make it into this funnel, and the honest reason why, at least from what I have personally read, was because most of it was completely terrible -- in as many ways as you can think of terrible to be. Three other thoughts: 1. The great videogame crash of '83 happened because the dominant platforms at the time did not have a lockdown on curation, so anybody and everybody flooded the market with garbage. Consumers decided it was better to not buy anything than to chance spending the equivalent of nearly $200 in 2024 money and get trash. 2. A few breakout, self-published, authors are making it through the piles of junk, but they are few and far between. Andy Weir (the Martian) and Hugh Howey (Silo) come to mind. The \"secondary\" film and TV markets are so starved for good new ideas that their works are getting converted into non-print media almost as fast as they can get sets built and costumes sewed. 3. There's probably a new market for solid, well known, curators. People who make money sifting the dreck to find the Weirs and Howeys and surfacing the cream to the top. The creators are self-publishing, and the publishing houses aren't doing well these days. But the curation function is still wildly important and finding the right way to do it, and the business model around it, is perhaps the future. reply WalterBright 17 hours agoparent> The \"secondary\" film and TV markets are so starved for good new ideas There's a long list of very good scifi that has never been made into a movie. Instead, we get the Mandalorean which rehashes every spaghetti western trope. The character even sounds like Clint Eastwood. It has the hero breaking in the horse while the old ranch hand leans on the corral fence, for example. And training the village to defend itself from the bandits. And so on. reply vundercind 16 hours agorootparentIn the specific case of Star Wars, that’s exactly how you make something decent within the Star Wars framework: pick a few elements, including characters, plots, shots, scenes, lines, whatever, from a broad set of genre media, mash them together, and apply Star Wars lipstick. The first film basically defined the genre pastiche film, and it’s still the straightest path to making something Ok within Star Wars. Most failures (and there are so many) are creatives failing to appreciate this, or not leaning into it hard enough. Mandalorean has one episode that’s about 50% The Wages of Fear and I bet the other main element of accidentally finding some officer you’d really like to get revenge on but while in the middle of committing another crime is also from something else, but I’m not sure what. The AT-ST episode is basically a Conan the Barbarian story plus any of a few westerns (the training-the-town-folk thing—even the woman who’s an uncannily good shot for no reason ever explained is lifted from westerns). That show got how to do Star Wars. More broadly, yes, more original (at least, not based on an existing visual-media franchise) sci fi movies would be cool to see. reply bane 15 hours agorootparentprevI wish I could describe the near physical pain I feel that \"Rendezvous with Rama\" isn't yet a great Denise Villeneuve movie, and the \"Night's Dawn Trilogy\" isn't yet a multi-season series on Apple TV. The list goes on. reply ghaff 1 hour agorootparentRendezvous with Rama is basically a travelogue. I enjoyed it well enough but there are probably 100s of SF books/stories I would choose to adapt to film before that one. But we'll see. I may well be wrong but the necessary adaptations probably won't be loved by fans. reply WalterBright 12 hours agorootparentprevI've had enough of the Dune remakes, too. The world doesn't need more Planet That Went Ape remakes, either. The Mote in God's Eye would make a fine miniseries. reply ghaff 54 minutes agorootparentIn fairness, IMO the latest Dune(s) were the first that weren't deeply flawed. I do agree that The Mote in God's Eye--and perhaps associated shorts would make a fine basis for a series--hopefully one that ignored the sequels. reply badpun 8 hours agorootparentprevPlanet of The Apes remakes are not movies, they're just a way to reliably turn 200 million dollars into 300 million dollars - similarly to all the American comic book crap. As long as the multiplier stays above 1.0, the process will continue. reply Der_Einzige 1 hour agorootparentGlad to see this stuff called out for being low quality here. I prefer the term \"capeshit\". reply auggierose 8 hours agorootparentprevI want \"Gateway\". reply currymj 5 hours agorootparentprevVilleneuve is actively working on Rendezvous with Rama, it's likely to be one of his next projects. reply afpx 7 hours agoparentprevMy local bookstore dedicates a large part of their fiction section to \"local authors\". Maybe 30 or more authors there, some with several published books. Once, I went through all of them, randomly choosing a couple chapters and reading a few pages, hoping to find a hidden gem. Eating a can of Campbell's Cream of Mushroom soup would have been more satisfying. reply TillE 16 hours agoparentprevAside from Andy Weir (who got picked up by a publisher and properly edited), the self-published books I've read have been remarkably awful, including some stuff that was widely recommended. The fundamental truth of creative work is that if you make something genuinely great, you'll probably have a smooth path to success. I see a lot of anxiety among indie game developers about the sheer quantity of games being released, and yes bluntly, if you make a merely average game nobody will care. Make something great. reply AlbertCory 4 hours agorootparent> if you make something genuinely great Hindsight Bias is blinding here. Judge whether something is \"genuinely great\" before you know its success or failure, and then we'll see if that's a true statement. reply corimaith 14 hours agorootparentprevIndie games are interesting because you'd think given the nature of their development they'd do more interesting things, but stunningly they've mostly stayed within a few codified genres (roguelike/ deckbuilder/platformer galore). There aren't many successors to the giants of the old like Terrarria or Dwarf Fortress. I'd have to chalk it up to a lack of vision (I don't genuinely believe someone grows up wanting to make a roguelike deckbuilder), but then that begs the question of why are they in game dev in the first place. reply nottorp 10 hours agorootparentIndie means low budget (although even that is getting perverted), not hobby like development done as a labour of love. The latter are few and far between, but they have always been. Can a game historian count the Doom clones that showed up after Doom? Does anyone remember any of them with the exception of Hexen and Rise of the Triad? reply morkalork 12 hours agorootparentprevYou don't think it's because the audience is already familiar with those types of games? It's like asking why studios are all producing super hero movies instead of avant guard indie films. reply CM30 5 hours agorootparentprev> The fundamental truth of creative work is that if you make something genuinely great, you'll probably have a smooth path to success. I see a lot of anxiety among indie game developers about the sheer quantity of games being released, and yes bluntly, if you make a merely average game nobody will care. Make something great. Not necessarily, I've seen plenty of good or great works go unnoticed. In movies and gaming that's often a timing thing (releasing too near popular works, releasing at a bad time of year, releasing on a console that's on its last legs, etc), but for other types of works it can simply be a failure to market said work at all, or the subject not immediately catching people's attention. reply barbariangrunge 16 hours agoprevDiscoverability sucks, for almost everyone, but especially for new authors. And that was before ai started flooding out “content.” Even if you get a publisher, great authors sometimes sell only a handful of copies. You find amazing books on goodreads by award winning authors with only 5 reviews. And that’s people who can get their novels manuscript even looked at by an editor. Lots of self published authors end up with 0-1 reviews How do you stand out in that swamp? reply HDThoreaun 16 hours agoparentThis is why you see these massive advances for known names. The only thing publishers seem to know is that authors who create their own publicity sell copies, and those that dont have an audience dont. reply inanutshellus 16 hours agorootparent\"Step one: hype the human, step two: publish their books\" reminds me of being a senior in college and seeing and despairing at job postings saying \"MUST have 5 years experience in [tech that came out 9 months ago]\" reply ilrwbwrkhv 11 hours agoparentprevThe problem is that book publishing hasn't really been disrupted for a very long time. Amazon just switched it to selling online, but think about how much more you can engage with a book that you just read. Somehow no apps or ereaders allow for anything beyond reading the book text. reply dageshi 4 hours agorootparentIt is being quietly disrupted, just probably not in the way people want. Webnovels on sites like royalroad.com monetised via patreon and then published on Kindle Unlimited & Audible offer a different publishing model to that of traditional books and one that works really well for the right genres. The audience that reads them is reading purely for entertainment, has vastly lower standards and is willing to directly support their favourite authors to the point where the most successful authors who started 5 years or so ago are now millionaires. But this is mostly an anathema to the traditional publishing industry and for the most part they're pretending it doesn't exist because they literally cannot compete with it in the niches it now dominates. reply iteria 3 hours agorootparentThis is correct. I give $3/month on patreon for 2 chapters a week to this one author. $36/year isn't a lot, but it takes these authors' years to finish these books at this rate, and any author would kill for the amount of amount I sunk into 1 book. Multiply it out, and it becomes a livable wage if you can get enough people to support your patreon. I have a friend I personally know who did this. He's not even a good writer. He just found an underserved niche and made a livable wage $1from somebody at a time. His writing improved and I'd say it's passable, but no one would pay $10 at all once for any book he wrote. Apparently over a year is fine though. reply dageshi 3 hours agorootparentThis is the interesting thing about this entire thread. There are a lot of opportunities for authors to make a living, even potentially become wealthy writing but they actually have to write in niches people want to read. Instead I get the sense that the people writing these \"debut novels\" are really looking for fame/acceptance within the kind of social circles that value \"great intellectual novels\". reply intuitionist 3 hours agoprevOne thing that saddens me about the perceived necessity of new authors going on Twitter, BookTok, etc. to “build an audience” is that it seems to prevent anyone who wants to separate their literary life from their private life from ever again being supported by a publisher. Many authors over the years have felt the need to do this, for personal or professional reasons: J.D. Salinger, Thomas Pynchon, James Tiptree Jr., John le Carré, Joe Klein, Isabel Fall. I doubt that all those authors will be considered part of the canon in 100 years, and very possibly none of them will be, but I think the world would be poorer if they’d all been unable to become successful writers. reply ghaff 1 hour agoparentI don't know. This is sort of arguing that a world in which publishers were gatekeepers/PR agencies/etc. meant that authors could sort of hide behind that front--at the cost of putting their fate in the hands of their publisher. But I'm not sure how widespread/true that ever was. Authors went on book tours and TV shows all the time to promote their writing. I'm not sure how common the pseudonymous/reclusive successful author ever was. reply langsoul-com 5 hours agoprevReminds me of Diddy Squat, the farming show by Jeremy Clarkson. Farming, just by itself, is not profitable, so they need to do all kinds of things to make profit. Likr setting up a store, making a branded product, Ie making beer from the wheat, or social media on farm life. The tragedy is all the time required not farming. In the case of books, to first debut, you must already be successful or perish. Even getting accepted to a publishing house requires insane stats, and they're just beginning. reply ghaff 4 hours agoparentAnd it helps to know people. The one time I went through a publisher it was pretty much by accident because I had dinner with the appropriate acquisitions person and the managing director and then we ironed out details when I was in London a couple months later. I was intending to write the book anyway but wasn't planning on going through a publisher. Didn't make any material money but it was very useful professionally. reply AlbertCory 17 hours agoprevI used the public library to get a lot of books that I'd never want to waste my money on. You can call it \"market research.\" Verdict: there just isn't a market for serious fiction like there was 70 years ago, say. J.D. Salinger considered himself a failure until he finally got a story in The New Yorker. How many writers dream of that nowadays? Then there's Esquire, of course : https://www.goodreads.com/book/show/376430.Esquire_s_Big_Boo... The urges that led people to read fiction then are now directed to TV, movies, and serials. We could decry it, but that's how it is. reply api 2 hours agoparentMy impression is that a good novel today being turned into a series or screenplay is what huge scale novel success used to be. Huge scale success with just a book is very rare, though there are some writers who find a niche audience. The thing I decry is the worthless idle attention suck of “social” media. That competes with all forms of quality art and content. Instead of watching good movies or listening to music or reading a book people are scrolling TikTok, Xhitter, Instagram, etc. reply AlbertCory 2 hours agorootparentYep. Reading \"the current thing some imbecile said\" instead of \"the best that has been thought and said.\" reply SamoyedFurFluff 20 hours agoprevThere is a great podcast called the publishing rodeo where they talk about this. One of their episodes covered a minimum viable threshold where if there isn’t enough marketing points (a viral tweet, a lot of followers, marketing money, etc) there is no way for a book to succeed regardless of quality. reply mikemitchelldev 5 hours agoprevA debut novel that's not published is not necessarily a wasted effort. It can be adapted into a screenplay, which can be submitted to a variety of outlets, and the novel might be published later if successful. reply naveen99 4 hours agoparentLooks like I found a debut hn comment. reply mikemitchelldev 3 hours agorootparent?? reply naveen99 3 hours agorootparentGreen account. Hacker news comment history is the new novel. reply RivieraKid 10 hours agoprevThe total supply of good books and good content in general increases every year but the amount of time people spend consuming content is roughly constant. New books are not just competing with all of the books that were written in the past, e.g. East of Eden, but also YouTube, podcasts, movies, computer and mobile game - and the total supply of those increases every year. reply medion 20 hours agoprevPublishers only want to publish authors with large social followings. The first question they ask is a list of your socials. reply vundercind 19 hours agoparent… and lots of those are kinda bad. But it sells almost as well as a decent book, and you don’t have to spend as much promoting it, so it’s still what they want. reply Ekaros 8 hours agorootparentI would argue that those works are at least decent or at least on some level competent. They might not have too much some vague artistic merit. But they are unlikely be completely unacceptable. Like no major consistent spelling or typographical issues, mostly coherent and consistent plot and so on. We rarely see or interact with truly below mediocre medium. Or filter it very quickly. Looking for example at Steam and your nth asset flip with poor 3d graphics and so on. reply bitmasher9 19 hours agorootparentprevYou’re a social influencer with a non-fiction book out? Let me just watch your clips for 15 minutes and you’ll deliver all of the information in your three hundred page book. There’s no substance in most of them. reply _tom_ 9 hours agorootparentBut, boy are they fast to write! reply yxhuvud 8 hours agoprevHow can someone write an article on that theme without ever mentioning self-publishing? It may not be super big in mainstream books yet, but it is getting pretty common for genre literature to first publish and build an audience on something like RoyalRoad, then self-publish, and then get picked up by something bigger. And it also ties very much into some of the themes of the article to cooperate and do shout-outs to other authors, as that is super common in those circles. reply insane_dreamer 19 hours agoprevThis is why Amazon can’t supplant bookstores because they, and publishers, act as curators for the deluge of creative works out there. (Not saying they are always right in their choices and certainly good stuff gets written that is never submitted to a publisher, but I would rather browse the shelves of my local bookstore—especially an independent one run by someone who cares very much about literature (as booksellers do as they’re otherwise not in that difficult business), than scroll through Amazon. reply metabagel 12 hours agoprevI hope that AI improves discoverability. It would be great if an AI agent can give me a list of books which I am likely to enjoy, based on the books I have enjoyed in the past. Even better if some of those picks are obscure. reply gfourfour 12 hours agoparentI think this is a really underexplored use case for LLMs. LLM embeddings are really good at encoding rich semantic information that’s easy to query and hack around with in a variety of ways. Retrieving primary sources that correspond to one or many thematic dimensions is one such case for embeddings, but most applications that do this portray it as a driver of RAG chatbots, when it could be an end in and of itself. I have an app that does your book recommending idea but with Wikipedia articles. I am trying to release it soon, once I get past my perfectionism, if anyone is interested. Expanding to non Wikipedia sources is an eventual goal. I basically never want to read chatbot output for pleasure. I want to read primary sources. reply nottorp 10 hours agoparentprevOn one hand, that's a good idea. On the other hand, do you really want to get stuck in a bubble and only read the same thing that you've read before and nothing new? If it's bad when Facebook does it, it's bad with book recommendations too if you ask me. And on the gripping hand... reply pfdietz 21 hours agoprevBecause there are way too many books being written. reply surfingdino 21 hours agoparent\"Everyone has a book inside them, which is exactly where it should, I think, in most cases, remain.\" -- Christopher Hitchens reply UniverseHacker 20 hours agorootparentI find that to be an awful attitude... self-absorbed people with nothing interesting to write about will assume it doesn't apply to them because they are so interesting, and people not so sure of themselves but having an actual unusual idea or story they are passionate about, could easily be discouraged from sharing something valuable. I say, if you have something to say that fits well in a book, write it. Let other people decide if it is worth reading or not. A lot of the best books ever written were kept private, or were not well received at first. reply pfdietz 20 hours agorootparentI encourage you to read some random self-published e-books on Amazon. reply kayodelycaon 19 hours agorootparentThe problem is those people aren’t going to read that advice and follow it. Most of the people it’s going to discourage are those who “should” write. reply UniverseHacker 19 hours agorootparentprevI do! I have some niche hobbies and have read, and really enjoyed several self published amazon ebooks that had zero reviews. reply CuriouslyC 19 hours agorootparentprevI encourage you to read some random publisher published books, that have been on the top of best seller lists. 50 shades of hot garbage comes to mind. reply kredd 19 hours agorootparent50 shades of hot garbage, unironically, is one of the books that brought smut back into the mainstream. As much as I have no interest in reading the series, have to give credits to the author for making something incredibly popular. We can hate it, but there are millions of people who read and write fanfic on a daily basis, and targeting that audience is respectable. But I agree, being on bestsellers list nowadays doesn’t even as much as it used to. Everyone’s up there to game the system, whether through extreme SEO-boosting or buying their ways into shortlists and recommendations. reply nottorp 9 hours agorootparent50 shades is laser targeted. To the point that I tried reading it and abandoned it before 25% because the laser targeting is extremely precise and missed me :) Just because it's not depressing oscar bait or space opera it doesn't mean it doesn't have some merits. Although i find it hard to believe it was done as a \"labour of love\". reply RivieraKid 10 hours agoparentprevAnd way too many books already exist. The total supply increases every year but demand for consuming books is constant or in decline. reply beemanF 2 hours agoprevi think that books, movies, music are just becoming noise at this point. they are completely ephemeral. they are basically free, or ar least they would be if the markets were allowed to do what theyre supposed to do without copyright. and now with AI, the effect is only growing stronger. paying for media feels closer and closer to paying for air. it just doesn't make sense. its ephemeral and so abundant that its basically free. i think this might be our new reality. being an artist as a profession might not be a thing for much longer reply Animats 16 hours agoprevBecause Barnes and Noble has 14 checkout shelf positions devoted to Taylor Swift magazines. James Patterson (Enterprises) has about a quarter of the new novel space, and Tom Clancy (RIP) has maybe a tenth. It's all about the brand. reply thaumasiotes 11 hours agoparent> James Patterson (Enterprises) has about a quarter of the new novel space, and Tom Clancy (RIP) has maybe a tenth. It's all about the brand. There's an obvious reason for that: far and away the primary determinant - often the sole determinant - of whether you will like a novel, is the author. reply nottorp 9 hours agorootparentThat's sad, because once an author achieves some notoriety, they are basically stuck into writing the same thing for the rest of their career, for fear that they will lose their existing audience. reply richk449 2 hours agorootparentIs that why John Irving keeps writing about bears and high school wrestling? reply thaumasiotes 6 hours agorootparentprevNot at all. Like I said, the determinant of whether you will like the book is the author. If they write something radically different from their previous work, and you liked their previous work, the odds are very high that you'll like the new book too. reply nottorp 4 hours agorootparentAs a reader, but how about as a publisher, will you take the risk? :) reply ZeroGravitas 4 hours agoprevI assume I read far more than the average person (though possibly just average for HN) but I see clickbait headlines like \"10 Best New Hard Sci-Fi Novels Released This Month\" that just make me feel anxious as a reader that there's more content out there than I can possibly comprehend. Must feel even worse as a writer. reply _tom_ 9 hours agoprevWow, what a clueless article. Or maybe a deliberately biased article. The majority of sales and debut authors are ebooks, and traditional publishers aren't involved. This has been true for years. Read publishing is pretty much pointless if you aren't a celebrity. Yes, there are a few that make it, but a handful, compared to the numbers that make something significant self publishing. And the trad publishing process is so slow. You can write and market several books in the time is takes to get one book to reads the old way. If you aren't a celebrity, self publishing is the way to go. Not that publishing an ebook is easy, but the process of much more controllable by you. And the payback is much higher. reply richardatlarge 9 hours agoparentBut nothing here solves the problem of going from zero audience to some meaningful audience in a content saturated environment with a low attention span reply wslh 9 hours agoprevI think the answer is very short: marketing beats quality. We are paying too much attention to the content itself but the root cause is the distribution. It is the same with startups. This is already studied at nauseaum in search economics, long tails, the medium is the message, etc. reply api 6 hours agoprevThere’s a pretty huge overproduction problem in the arts, literature, and music, and it’s being made worse by spam and hustle culture shit at least in the short term. All the spam and hustlecrap is ironically making good works more special but at the same time harder to find. I’d say first and foremost: don’t make art unless it’s burning a hole in your head and it must be made. That helps solve the overproduction problem. As for the spam and junk problem that’s a discovery issue. I’ve actually gotten back into reading lately. Good new stuff is as hard to find as it is to get it found. Of course like most readers I have a backlog… hence the overproduction problem. reply johnea 20 hours agoprevEven though I still retain an entire bookcase of novels (mostly sci fi) from my youth, I now find fiction to be, well... boring. Personally I'd rather read about something that actually exists... reply mr_world 8 hours agoparentI almost exclusively read fiction, in particular science fiction. Why? Because the authors often spend a great deal of time thinking about new, interesting technology and ideas. It is all based on reality, the ideas are new combinations of existing concepts, and could be applied in the real world to inspire innovation. I get enough of the real world in the real world, when I read, I want see something new reply coliveira 20 hours agoparentprevThe thing about modern publishing is that it is too much driven by genre, so if you read a few dozen novels of a particular genre there are no surprises left. I am similarly unimpressed by new books, so I either read old ones or just don't. reply WalterBright 16 hours agoparentprevI know what you mean. I have turned to reading history books, that are far more interesting stories. reply all2 16 hours agorootparentHello, my friend. I enjoyed 1491, and I've been working my way through The Secret Life of Real Estate and Banking which is an economic analysis of the boom/bust cycle as it exists in modern fiat/debt based economies. Both are very different, but also very engaging and interesting. reply WalterBright 16 hours agorootparentI'm currently reading \"The Making of the Atomic Bomb\". It's the best scifi I've ever read, except it's true! reply sib 13 hours agorootparentGreat book! Sadly, I don't think the sequel (about the H-Bomb) is quite as good. reply richardatlarge 9 hours agorootparentRead: The Curve of Binding Energy (McFee)- will blow your mind for sure, NPI reply metabagel 12 hours agoparentprevChildren of Time is a standout sci-fi novel. I’m currently reading the second book, and it seems to be very good as well. It’s a unique take on an alternate/alien civilization. But, I have for many years been drawn to non-fiction books, typically about WW2, such as the battle of midway (Shattered Sword) or the Guadalcanal campaign. I have also listened to a lot of civil war audio books, including Battle Cry of Freedom and the Memoirs of Ulysses S. Grant. reply all2 16 hours agoparentprevI'm very much in the same boat. Fiction books haven't gripped me in nearly a decade. History, on the other hand, has become more and more interesting to me as I've aged. reply pfdietz 20 hours agoparentprevHow do you feel about history? reply thfuran 16 hours agorootparentThere's hardly anything new there. reply optimalsolver 9 hours agorootparentYogi Berra? I thought you were dead. reply pfdietz 7 hours agorootparentNo one reads history anymore, it's too popular. reply bowsamic 12 hours agoparentprevMaybe you should read something that isn’t sci-fi or genre fiction. Go back and read Middlemarch or Lolita reply defrost 12 hours agorootparentSocial Realism and Lolicon aren't genres ? reply bowsamic 8 hours agorootparent1. No, they aren't forms of genre fiction 2. Middlemarch isn't social realism. If you had to put a label on it, it would be psychological fiction a la Stephen King 3. Lolita is DEFINITELY not lolicon (if anything it's the opposite) and it's quite offensive to suggest it is The point is, OP is complaining about not liking reading, but if he's only read sci-fi, he hasn't read the classics reply defrost 6 hours agorootparentOddly enough Middlemarch is often cited in literary courses as being the template for social realism ... eg: This avowedly humanist world-building would come to be called realism. Middlemarch is often cited as a template of that now familiar mode. ~ https://www.unsw.edu.au/newsroom/news/2023/06/George-Eliots-... but I'm more than happy to leave the bunfight of opinions to those more invested. > Lolita is DEFINITELY not lolicon Well I wouldn't take that suggestion too seriously although it seems that you have. reply bowsamic 6 hours agorootparentThe point is that they’re classics, not genre fiction. The person I was replying to would be well served reading great classics reply defrost 6 hours agorootparentClassics like Charles Dickens and not some pulp genre trash pumped out for weekly social media installments? reply bowsamic 6 hours agorootparentSure, whatever old stuff that is loved by non-idiots that he hasn’t tried. Odyssey, KJV Bible, Shakespeare, Moby Dick, Dostoevsky, Dickens, etc. reply defrost 5 hours agorootparentHmmm. FWiW that was another literary jest, you know, what with Dickens famously: Dickens's literary success began with the 1836 serial publication of The Pickwick Papers, a publishing phenomenon that sparked Pickwick merchandise and spin-offs. ... His novels, most of them published in monthly or weekly instalments, pioneered the serial publication of narrative fiction, which became the dominant Victorian mode for novel publication. reply bowsamic 5 hours agorootparentHow are any of these lame jests actually helping the OP who is impoverished in his joy of reading? Keep them to yourself. reply Der_Einzige 1 hour agorootparentprevIn regards to 3, It might as well be. It's a sick novel for sick people, and I can't believe that it's read in high schools. Somehow we still read Marquees De Sade too even though everything he wrote is more depraved than most of what goes on 4chan today. reply ngcc_hk 15 hours agoprevWhilst reality bite and all said is the truth, there are odds. How about on a lady with kids on social welfare and had no name tried to publish a book about young witch growing up in a boarding school. And tbh I do not recommend her book for young kids, as it is very dark. Anyway, as said in another epic, there is always hope. reply surfingdino 21 hours agoprev [–] The market is dominated by large publishers. They do not need to compete, they have already won. At the same time, they don't want to loose the marketshare, which makes them less likely to bet on an unknown author. reply _tom_ 9 hours agoparent [–] The market is dominated by ebooks. Trad publishing gets a few home runs, but overall can't compete with the sheer volume of new independent books that come out each year. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Debut novels are struggling to gain visibility due to a fragmented media landscape, making it difficult for new authors to build an audience.",
      "Success for debut novels now requires sustained publicity efforts and leveraging social media, with authors often needing to self-promote and hire publicists.",
      "Despite these challenges, literary friendships and community support among writers are growing, aiding debut authors in gaining traction."
    ],
    "commentSummary": [
      "Debut authors face significant challenges in a saturated market, struggling with self-promotion on platforms like Hacker News and Reddit due to algorithms and policies that hinder visibility.",
      "The discussion highlights the importance of editors in refining works, the difficulties of marketing on social media, and the impracticality of everyone becoming influencers, leading to power concentration among a few platforms.",
      "Platforms like Royal Road and Goodreads offer alternatives for content discovery and audience building, but the necessity of a strong social media presence and the decline in demand for serious fiction pose additional barriers."
    ],
    "points": 107,
    "commentCount": 202,
    "retryCount": 0,
    "time": 1717790223
  },
  {
    "id": 40617786,
    "title": "Handling a Senior Hire Who Lacks Expected Skills: Invest in Training or Let Go?",
    "originLink": "https://news.ycombinator.com/item?id=40617786",
    "originBody": "We hired a developer at the senior level who is lacking basic skills.Essentially we had deficiencies in our technical interview that allowed for custom-fit preparation, the candidate excelled at selling themselves and negotiating, and there was a breakdown in internal communication where HR was under the impression we wanted to hire at any cost despite us giving the candidate a mediocre rating.Now we&#x27;ve found they&#x27;re struggling to do even basic stuff without help and are far from helping others or even taking ownership of minor areas.They suffer from imposter syndrome (appropriately for once), which further hampers their productivity, communication, and growth as they&#x27;re reluctant to ask for help with tasks they know should be easy, and equally reluctant to join the efforts of others who might notice their deficiencies.The result is net-negative productivity. It would probably take another 6-12 months of intense training to get them somewhat productive, and several years to get them closer to the level we hired them at, assuming we can accelerate their learning.This would require addressing the elephant in the room that they&#x27;re not at the level we assumed, so that they will understand why we&#x27;re changing the work mode, accept that learning should be a high priority, and feel permitted to seek more help when they need it. We probably can&#x27;t reduce the salary, so more productive devs might also be offended if they become aware of it.Even if we were to successfully address this elephant in the room, they might at some point realize they can&#x27;t catch up to the level they were hired at without years of dedicated effort and thus quit or \"quit internally\", making our investment pointless.I guess in most companies this would be a no-brainer, but we&#x27;re a small outfit with a focus on personal development, intrinsic motivation, good climate, and low turnover.Do you think there is any way to rescue this situation? Or should we make this (perhaps justifiably, after their misleading self-presentation) the first time we let someone go for performance reasons?",
    "commentLink": "https://news.ycombinator.com/item?id=40617786",
    "commentBody": "How to handle a senior hire turning out to be junior?87 points by throw94680732 4 hours agohidepastfavorite179 comments We hired a developer at the senior level who is lacking basic skills. Essentially we had deficiencies in our technical interview that allowed for custom-fit preparation, the candidate excelled at selling themselves and negotiating, and there was a breakdown in internal communication where HR was under the impression we wanted to hire at any cost despite us giving the candidate a mediocre rating. Now we've found they're struggling to do even basic stuff without help and are far from helping others or even taking ownership of minor areas. They suffer from imposter syndrome (appropriately for once), which further hampers their productivity, communication, and growth as they're reluctant to ask for help with tasks they know should be easy, and equally reluctant to join the efforts of others who might notice their deficiencies. The result is net-negative productivity. It would probably take another 6-12 months of intense training to get them somewhat productive, and several years to get them closer to the level we hired them at, assuming we can accelerate their learning. This would require addressing the elephant in the room that they're not at the level we assumed, so that they will understand why we're changing the work mode, accept that learning should be a high priority, and feel permitted to seek more help when they need it. We probably can't reduce the salary, so more productive devs might also be offended if they become aware of it. Even if we were to successfully address this elephant in the room, they might at some point realize they can't catch up to the level they were hired at without years of dedicated effort and thus quit or \"quit internally\", making our investment pointless. I guess in most companies this would be a no-brainer, but we're a small outfit with a focus on personal development, intrinsic motivation, good climate, and low turnover. Do you think there is any way to rescue this situation? Or should we make this (perhaps justifiably, after their misleading self-presentation) the first time we let someone go for performance reasons? UseofWeapons1 3 hours agoAs you consider the decision to let them go, consider the impact on other people in your work place too. Other developers notice someone like that underperforming and getting overpaid, and it can hurt the good climate you aim for. It may feel bad to fire them, but it may be worse to keep them. reply ewoodh2o 3 hours agoparentYou absolutely need to consider how the rest of the team will interpret you actions. Most probably know this individual is underperforming already. Teammates usually have a sense before the manager does. But the way you handle it will also be observed. Others need to know you won’t just fire someone on the spot if performance doesn’t match expectations. Life happens, people have personal life issues that may occasionally require attention, and you don’t want everyone else assuming they are one bad sprint away from unemployment. In most of the US at least, start with a performance improvement plan. Ideally one crafted with HR’s help. It should lay out specific expectations for a Senior Engineer, and call for immediate and sustained improvement. Use that to initiate a conversation and clearly lay out that they are not meeting expectations for the level at which they were hired. Present meeting those goals as a requirement for continued employment. You may also present a severance option here if you want them to have an out. This makes it clear to everyone that you treat all employees with respect, offer a clear warning, and then so long as you expectations in the PIP are clear, it’s a lot cleaner if you end up needing to part ways a week or four weeks later. reply czhu12 1 hour agorootparentAs a counter point to this, I’ve witnessed the practice of designing these processes to terminate someone creates a ton of burnout for the manager. Expect to spend at least 20% of your time managing the PIP. Documentation, one on ones, babying tickets being assigned, etc. On top of that I’ve never seen anyone get through a PIP successfully (n=6). Furthermore, it can also create a culture of just dismissing any candidates who don’t come from the right pedigree because the risk of a mishire is way too high. Its worth asking if it’s worth your time to do this for the sake of following process. Larger companies that need to standardize management for hundreds of managers have a greater need than startups do. reply ethbr1 2 hours agorootparentprevDo you have thoughts on offering PIP vs demotion and salary adjustment? If the individual doesn't have the skills (or seemingly temperament) for a senior role, I'm not sure PIP is setting them up for success. Versus demotion with possibility of promotion allows them to perform at their level of competence, leaving open the possibility for them to chose (or not) to aim for promotion. reply throwaway173738 3 hours agoparentprevThis 100%. Whether I would fire someone depends on why I thought they were underperforming. You should consider the first month on the job a work sample and if someone isn’t measuring up within the first week tell them what your expectations are and that they’re not being met. If they don’t remediate within a month let them go. I kept someone for too long once and people on an adjacent team didn’t want to get stuck with that person during a re-org and were vocal about it. And that person bungled some important projects that set us back years on our ambitions. Fire them and use this as an opportunity to address your interview process. The longer you keep them the worse it will be. reply bialpio 3 hours agorootparentHow do you reconcile this advice with the fact that in both places I've worked at, the expectation was that just the onboarding takes significant amount of time (up to ~0.5yr)? Even if I personally didn't need that much time, it was nice to know that it's available -it's not easy to get into the grind and catch up to others that already have all the institutional knowledge when starting a new job. reply brokencode 3 hours agorootparentYou shouldn’t need to be onboarded to basic development skills when you come in as a senior developer as the OP is saying here. Institutional knowledge specific to each company takes time to learn, but many dev skills should be directly transferable. reply 1123581321 3 hours agorootparentprevBe sure that half a year is thought through. I’ve seen places that pay too little attention to new employees in the first few months and then surprise them with complaints about performance. Those first few months should be drilling specific institutional knowledge (through bugs, presenting on parts of the stack, talking to a variety of people, shadowing, studying certain tech/tools most people don’t know.) You should be looking for the employee to be making good general efforts, just without taking everything into account yet. And the employee should see evidence that you are serious about helping them master specifics of their new environment. reply ratg13 3 hours agoparentprev>“The fastest way to demotivate a good employee is to show them the lengths you are willing to tolerate a bad employee” - a sheet of paper i found in a desk 20 years ago reply giraffe_lady 3 hours agorootparentFrom this post there's not really any indication they're a \"bad employee\" though. They aren't up to the needs of the team that hired them, but that was on that team to figure out before they hired them. It's probably fine to fire them, but also everyone involved should be open about the fact that the hiring and so also the firing is the direct result of their own failure. The morale implications of this could be lot more nuanced than you're implying. reply Fire-Dragon-DoL 2 hours agorootparentWell, not calling for help when needed makes them a very dangerous junior. I don't know by the post if they are a good person. Could they have also lied on the interview? I would consider personality as a strong factor in keeping them, and if the company has room for a junior. Lowering the salary is a hard requirement though. reply bob1029 3 hours agoprevWe had one of these. Excellent interview, couldn't even handle explorer.exe on the other side. We fired them within the week. No one felt bad about it. Just do it and move on. The longer you drag it out, the worse it will get. reply anthomtb 2 hours agoparentOut of curiosity, did you ever figure out the disconnect that caused: > Excellent interview to turn into > couldn't even handle explorer.exe. I had to deal with a similar situation. The size and scale of my employer at the time meant the employee stuck around for multiple years. They never got worse but sure never got better. In our case, the problem was that our interview questions were based on algorithmic knowledge with some OS fundamentals. This person happened to be really good at those types of problems. But ask them to change a few lines of Python or Javascript and they just could not figure it out. So the underlying flaw was assuming that anyone who could figure out algorithmic optimization in C++ (psuedo-code, we weren't looking for perfect syntax) under interview pressure would also figure out higher level languages, test frameworks, CI systems, etc, in an efficient fashion. My simple solution was to push for a more diverse set of interview questions and interviewers. Actually, a \"take home\" style problem might have fleshed out these weaknesses but that was too radical, relative to the company culture, to even propose. reply bob1029 1 hour agorootparentOur flaw was similar. We were asking high level questions. At no point did we ask things like \"have you ever used Microsoft Windows\" or \"have you ever used a desktop computer\". It would seem we cannot take these questions for granted anymore. The best strategy I've come up with is to build an intern program and source talent from that lower cost/risk pool. Pulling high level employees off the street was almost always a circus for us. reply pavel_lishin 25 minutes agorootparentWe had an apprenticeship/internship program, and it worked out great. It gave new grads (from both colleges and bootcamps) on-the-job experience as well as active mentorship, it gave us an extended but time-limited way to verify that these folks were actually good at their job, and for the most part, they were all excellent software engineers, and we extended offers to something like 75% of them, and 50% of those accepted and worked there for awhile before moving on to another company. imo, a very worthwhile investment of time and money. reply aPoCoMiLogin 1 hour agorootparentprevat my $work we are doing hires in 2 phases, first is mostly talk, and second is \"trial day\". on the \"trial day\", the candidate gets simple task (with few requirements and optional bonus points), that we could manage to do in 1/2 or 1/3 time that the candidate gets. the task has to solve something similar that we were working on, so that we test how the candidate perform in real scenario. in the past few years it worked quite nicely but that still is not bullet proof. and we had to refine our methodology further. for example one candidate solved the task perfectly, but on the end of the \"trial day\" the candidate was unable to answer some of our questions regarding his code. so we think that he had access to the task details upfront, or someone else helped; another example was with candidate that solved the task, answered our questions, but in the office was lacking everything that he presented to us in the \"trial day\". we suspect that the relative of the candidate helped here, as we found later that the relative has job in similar position in another company. so the \"trail day\" is good way to test candidate, unless he has early access to the details of the task, or relative is helping with the task. it sorted a lot of candidates that were unable to follow the task details, or worse lacked team working skills reply ok_dad 47 minutes agorootparentAs long as you pay for the trial day. Otherwise, that’s hilariously entitled of your company to ask. reply brunoarueira 1 hour agorootparentprevMy experience, mainly because when I was hiring through hunters and they participate on interviews, was to not take pre formulated questions and have questions based on the candidate resume, therefore I stress some points depending on the role. reply koonsolo 1 hour agorootparentprevI also had this problem with hiring a front-end developer. Someone was really good at the theory, but practically couldn't handle himself. I currently do a job interview where we start from a super easy app, and then I ask \"how would you add feature X\", then I go to the next (predefined) step. The challenge of the test is that we run into certain problems. Some senior devs can foresee them, but most don't. Then the question comes \"Why isn't this working and how to fix it\". I've done a crazy amount of interviews already, and this kind of job interview gives me the most confidence. I didn't have any false positives anymore. You could see the test as \"There is this junior that is stuck on something, can you help him out\". I want my candidates to be able to deal with the weird shit, and in the end that requires a proper understanding of the underlying technology. I don't like \"take home\" assignments, because you never know that someone's software dev spouse is sitting besides them. We have a HackerRank test to first filter out the worst, and next stage is this interview I described. We use the same for both juniors and seniors. reply laborcontract 3 hours agoparentprevYes. The training effort shouldn’t be spent on the new hire, it should be spent on improving the hiring process. reply brunoarueira 2 hours agoparentprevCouldn't agree more! I, personally, hired some devs which are good in a specific tech stack, but struggle to learn the stack which the company was using , keeping demands too much from themselves and I trying to teach them, doing pair programmings and they fired themselves! So, after this two cases, I tried to filter even more and had good new hires. reply codegeek 2 hours agoparentprevThe only correct answer in this situation. reply mushufasa 3 hours agoprev>I guess in most companies this would be a no-brainer, but we're a small outfit with a focus on personal development, intrinsic motivation, good climate, and low turnover. Do you think there is any way to rescue this situation? Or should we make this (perhaps justifiably, after their misleading self-presentation) the first time we let someone go for performance reasons? You have to fire. No hiring process is 100%. It is worse to have them stay. If your organization is unable to fire people because you have 'not firing people' as an objective, you're optimizing for things that aren't advancing the business, and essentially shooting yourselves in the foot. reply willmadden 3 hours agoparentNo, there is no way to rescue the situation. If you make this sort of weak/poor management process where you tolerate incompetent employees standard, you will end up with a money hemorrhaging, adult daycare facility where all of the performing employees hate you and their job. If you aren't a monopoly, non-profit, or government organization, you'll also be bankrupt in short order. reply strnisa 3 hours agoprevThe real mistake is not correcting a mistake when you see you've made one. It's always hard to let someone go, especially in a small company with a focus on personal development and a positive work environment. However, if you don't address this situation: 1) The morale of the company will likely decrease. 2) The productivity of the team will suffer. 3) Employees may start questioning the leadership's decisions. 4) Some may consider leaving as a result. Generally speaking, the well-being and efficiency of the entire team should be a top priority for the company. From this, it also follows that having a solid interview process is crucial. reply kjkjadksj 2 hours agoparentAt the same time I kept thinking if they did fire the dev those 4 points you listed would happen. Damned if you do damned if you don’t. reply noirbot 1 hour agorootparentYea, I think it really depends on if the team's manager is getting comments from other devs on the team about the person getting fired. I had a QA get fired from one of my teams way back and while I liked them as a person, it was clear they weren't doing good work or having any real focus on what they were assigned, unlike their peers in the role, so it made sense. I would add, a big point of the announcement should be \"And we'll be expediting backfilling them\". The worst sort of firings/quits is when management sits on their hands for weeks in replacing them. reply IshKebab 1 hour agorootparentprevI don't know, if they really are as bad as op says then I think most people would cheer them on. I certainly appreciate seeing the occasional \"we agreed it would be best for them to take a different path\" emails from my company. Bit weird for them to send a global email for that tbh, but it really does send the message that they are actually responding to complaints and taking performance seriously, which is good. In most companies in Europe it's incredibly hard to fire people even if they are bad at their job, and people know it. It's refreshing when managers actually do get rid of poorly performing employees. reply temporarely 0 minutes agoprevIt is not clear at all if you have even taken the most basic step -- provide feedback for this employee. It's just not clear how to reconcile this impression -- nothing has been said at all -- with the plea for \"rescue\" from this situation. You mentioned \"personal development\", so this is a great opportunity to develop those management skills. You need to provide feedback for your employee. Have a frank discussion about their performance and try and find out what is the actual problem. Assuming there has been little to no actual conversations, it seems you are merely projecting various ailments here. Maybe their cat died, maybe whatever. We simply do not know. reply throwaway42668 3 hours agoprevLet them go. Provide a respectable severance, since it's the company's fault they were hired in the first place. One of the most cost effective and humane things you can do is extend their health benefits out further than their monetary severance. For example, a month's pay with 2-3 months health benefits. At least in cases where I've had to let people go, I've found they appreciate an approach like this. It's a relatively easy way to thread the needle between human dignity and corporate finance demands. A rarity. reply ltbarcly3 3 hours agoparentIt was a mistake to hire, but they misrepresented thrmselves and aplied for a position they must have known they didn't qualify for. To be considered they must have significantly embellished their resume. Fire for incompetence, no severence. reply ethbr1 2 hours agorootparentIt's hard for me to morally justify firing an employee for incompetence without severance... for an issue that was created by HR's incompetence. (And potentially the interviewing team, depending on how \"mediocre\" the rating was) reply Wurdan 1 hour agorootparentprevOpportunistic applications are totally normal, and yes I’m a hiring engineering manager. If those aren’t caught in the recruitment process, then it’s the process that’s flawed. reply segmondy 4 hours agoprevFire them. You are obviously paying senior money for a junior. Unless of course you tried to rip them off by underpaying them. Then I suppose it balances out. Evaluate the hiring process, how did you mess up so bad? Fix it. reply dehrmann 1 hour agoparentI agree with the general consensus to fire them, but if by \"senior\" OP means 3-5 years and this is a junior with potential, people are so hard to find that I wouldn't worry about misleveling or the salary difference. But the key is someone with potential. If it's a mismatch, cut your losses. reply ethbr1 3 hours agoparentprevIt's important to take responsibility. HR and the company fucked up. The employee negotiated well and over-sold their skills. I'd sit down with employee, and present options. Start with: You're not performing at the level, technically or with leadership, that we were expecting. Some of this is our fault, for not figuring that out in the interview. So this is going to be an uncomfortable conversation... Option A: We decide you aren't a good fit for this position, part ways, and we wish you good luck in your next opportunity. Option B: We adjust your salary and title to fit with what we've seen of your productivity. We realize this is a hard ask. We also come up with a plan in which you have a training and responsibility plan over the next year to get you to what we'd expect for someone in your original role, at which time we'll consider you for promotion. A lot of responses here start and end with firing, which seems kind of callous to the individual for an HR fuckup. Better to at least present the demotion option. reply teitoklien 3 hours agorootparent> at which time we'll consider you for promotion. This can backfire, is this same training resource made available to the other devs in the team ? , are they being passed away for this promotion by guaranteeing it to the new entrant. The original poster specifically said its a small tight knit personal community of devs, if they could self promote inside, they would have provided training to existing dev itself. After demoting this person, they’ll need to hire a new senior dev, what’s the guarantee they will need 2 senior devs anytime soon ? Guaranteeing a future promotion if training goals are met would be a disingenuous commitment and dangerous for team building if other existing devs are not given equal opportunity to compete for that promotion. It would be even more complex. reply ethbr1 2 hours agorootparentI definitely wouldn't guarantee it. But I think at least extending the possibility seems reasonable, given the fault. If they're outright fired, that says something to the existing team too, and especially in smaller shops where each head holds valuable knowledge, I'm not sure that's the company-benefiting message to send either. Plus if the individual chooses to leave, \"I think we all noticed that so-and-so wasn't a good fit for the senior role. We extended them the opportunity to realign to a different level, which they declined\" is a message I'd feel more comfortable presenting to the team. \"We're not going to immediately shitcan you...\" is a powerful truth for retention in small teams/companies. Especially coupled \"... but we expect you to perform to your level, and we will address things if we see someone underperforming.\" I do agree with other comments that do-nothing and ignoring the problem will be cancer to building a high-performing team. reply idlewords 3 hours agoprevIt's only impostor syndrome if you're competent. reply grugagag 3 hours agoparentIt aint easy to trully assess a candidate at the beginning. They may be overwhelmed with on onboarding and accomodating to the workplace. But they may as well be incompetent, that’s a possibility. Firing on the spot is a rash decision though. I’m a senior myself but at times (not always) when starting a new job the amount of stress I take to feel and adapt to the new team makes my imposter syndrome spike like there’s no tomorrow. Give me some time to accomodate and I perform as expected and am very much liked. reply neilv 3 hours agoprev(Not an expert manager; just some thoughts based on things I've seen.) I can't tell from the description whether the candidate was outright deceptive, like claiming experience they didn't have, or candidate was just good at the normal interviewing rituals, and the real problem was mess-up on company's end (i.e., interviewers said \"mediocre\" but HR somehow heard \"hire at all costs\"). In any case, talk with appropriate management and HR -- with everyone clear on what the cause of the hiring mistake was -- and figure out what the acceptable options are. Then, if the candidate seemed to be dealing in good faith, then probably talk with the employee, candidly, about the problem, and what options you're presenting. If they're leaving, you can assist to do it in a gentle way. You might not have to assist much; they might hear it's not working out, and start job-hunting urgently. If they're staying but downleveled, you can probably figure out the details to do it in a sufficiently non-awkward, discreet way. If employees noticed a bad-performer, they might be relieved to see that corrected, but hopefully they can also see the sympathetic and constructive way it was done, and adopt that tone themselves. But, if the candidate wasn't in good faith, then they helped make this an adversarial situation, so talk with HR, and maybe also legal counsel, about how to terminate promptly and with a minimum of drama. reply otteromkram 2 hours agoparent> \"Then, if the candidate seemed to be dealing in good faith, then probably talk with the employee, candidly, about the problem, and what options you're presenting.\" I'm not pro-HR by any means, nor have I had to hire/fire a bunch of people, but the minute you hint that an employee could be terminated, there's a chance that they could take retaliatory measures. Further, OP stated, \"Essentially we had deficiencies in our technical interview that allowed for custom-fit preparation...\" So, it doesn't seem like the candidate had \"good faith\" intentions from the start. If OP is in the US, most states have an at-will employment clause, so a quick break isn't illegal by any measure (as long as they aren't terminating the employee for things like sex, race, religion, etc.). reply noirbot 1 hour agorootparentI'm not sure \"custom-fit preparation\" counts as not having good faith. If I was doing an interview process and was told the next step would involve a live coding exercise in a specific language/package that I wasn't already fresh on, I'd be cramming for it to a degree where my performance would mostly show how fast I can learn something and not my net level of skill in that language/package. If the hiring folks inferred the wrong thing from that, that's not my fault for studying based on the information and parameters they provided me. reply neilv 2 hours agorootparentprevIf the candidate was dealing in good faith, then company should too. The whole corporate-think \"this person might do something evil, though we have no reason to suspect that, so we should do evil first\" is wrong. (I said talk with management and HR first; they might counsel or instruct differently, but you should make an effort to stand up for employee while you have the chance, before you potentially have to disagree and commit.) If the candidate wasn't dealing in good faith, then, like I said, terminate. reply whatsakandr 3 hours agoprevWe hired a guy like that. Clear deficiency in hiring process. I wasn't in management, but letting the mistake fester won't make it better. Additionally, if someone is that \"senior\" and good at interviewing, but not at thier job, it's unlikely they will come up to speed at a reasoble rate. Thier primary skill is interviewing, they might not be able to learn the skills they need to succeed. Let him go! reply bialpio 3 hours agoparentAnd also change the interviewing process, because clearly it's not testing for the skills that are needed. reply WesolyKubeczek 3 hours agoparentprevI'm wondering if it's possible, given the current job market climate, to spend way too long trying to get a job, in multiple rounds of interviews, and basically pigeonhole oneself into passing the interview but losing other skills that are pertinent to performing and keeping the job. The stories I keep hearing, about companies ghosting the applicant after 5-6 exhausting rounds of interviews, are scaring me, to be frank. It feels like the companies are optimizing towards not hiring as much as possible, and it's very tempting to optimize for passing the interview and make it into the primary skill... reply hypeatei 3 hours agorootparentIMO, you don't lose a good engineering mindset or skills within a year or few months. Rusty, sure, but I'd say those skills quickly start to sharpen after working at a new job for a couple months. reply WesolyKubeczek 2 hours agorootparent> those skills quickly start to sharpen after working at a new job for a couple months. Given the comments here, you don't have the couple months to unrust your skills. You will be deemed unfit after the first one and fired, the prevailing sentiment seems to be. reply hypeatei 35 minutes agorootparentYeah, it's hard because sometimes you just know that it isn't going to work and others you can see promising signs. It's all very situational. reply whatsakandr 3 hours agorootparentprevMy experience with hiring is it's better to error on the side of not hiring. If you make a bad choice, unless it's a flagrant fraud, you're going to spend a couple of months trying to get them to be productive. That's way more time then doing a couple more interview. And firing is risky from a legal standpoint as well. reply dangallthumbsup 2 hours agorootparentprevNot possible for somebody who knows what they are doing. I've aced technical interviews with zero prep where the leetcode I was writing was the first code I'd written in six months. The bar is really, really low. You will have to step over it however. reply washadjeffmad 3 hours agoprevIt's not an elephant in the room. They misrepresented their experience and qualifications, and now they're flirting with gross incompetence. I'm assuming you don't have an HR department because why on earth would you be handling this and asking the internet if you did (LARPing aside), but if you want to go through the motions, notify them of their under-performance, ask them what resources they need to perform to the expectation of the role as applied for (which you also make clear and document), bring that to whomever for approval, and then set progress improvement checkpoints every week to see where they're at. This could be training, additional staff support, consulting, etc. Give the employee a week to decide and put together their proposal. If they don't get the picture and start applying elsewhere while they're still employed, then evaluate them per the agreed timeline or, if the resources aren't approved and the project can't be delegated, go ahead and terminate their employment. Otherwise, and this is more mature, better, kinder way to handle it, just let them know they weren't a good fit, don't apologize but do offer them a generous severance, and let them go. Or if you want, you can hire me for a day, and I'll do it. reply krisbolton 3 hours agoprevDo they know they're underperforming? While they may have imposter syndrome, it's a different thing to know you're actually under performing in the eyes of management. Have the difficult conversation and address the elephant in the room. Critically, discuss your options and intentions with HR. It can get messy for everyone if you don't approach dismissal in the right way. reply shijie 3 hours agoprevIrrationally, I always think that posts like this are about me in my own role at work. Thankfully, I’m not this out of my depth. My impostor syndrome has decreased by 6% today. reply jmkni 3 hours agoparentha I was reading this as well thinking shit, is this about me? reply pojzon 1 hour agorootparentIm happy there are comments like those, makes me feel Im not alone in this.. reply JTyQZSnP3cQGa8B 3 hours agoprev> addressing the elephant in the room that they're not at the level we assumed Your blaming the wrong guy. The elephant in the room is that your interview process massively fucked up, and you failed to understand the most basic question of this process: junior or senior. reply swiftcoder 3 hours agoprevYour hiring process screwed up, so let them go, and figure out how to fix it next time around. There's really no salvaging the situation as you have described it. The engineer is unlikely to take the option of a role that has lower status and pay, especially given that you've already introduced them to the team as a senior. At a large company they likely wouldn't recover from this situation either - but they have the financial and management resources to just sandbag him with the worst jobs until he quits, which I'm assuming you can't afford. reply schnebbau 3 hours agoprevFire immediately. The other devs are going to be PISSED if they find out they're making less, and everything will start derailing. There's loads of other good devs available instead. reply russfink 4 hours agoprevHave you had a direct conversation with them? If not, have one with a line manager, an out of the line technical expert, and a member of HR. Explain specifics, and how expectations are not being met. Then be silent and see how they respond. Develop an action plan with dates. Mention consequences later, if the action plan is not being followed. Bad things happen to good companies. You must use a process to get out of it. reply geor9e 3 hours agoprevConsider firing your HR department too https://www.youtube.com/watch?v=DKL47LUeHYM reply odshoifsdhfs 3 hours agoprevYou fucked up, but most likely you are playing with vc money so who gives a fuck? Pay him, keep him. Chances are you will fold in a year or two so at least you make someones life a bit better for a while. You not saving the world or anything like that, so just syphoon as much of the idiots vcs moneys to normal people lives. That is the goal with start ups right? reply shagie 2 hours agoprev> The result is net-negative productivity. There's a classic paper out there... The Net Negative Producing Programmer by G. Gordon Schulmey > We've known since the early sixties, but have never come to grips with the implications that there are net negative producing programmers (NNPPs) on almost all projects, who insert enough spoilage to exceed the value of their production. So, it is important to make the bold statement: Taking a poor performer off the team can often be more productive than adding a good one. [6, p. 208] Although important, it is difficult to deal with the NNPP. Most development managers do not handle negative aspects of their programming staff well. This paper discusses how to recognize NNPPs, and remedial actions necessary for project success. (The early 60s may be a reference to (from https://news.ycombinator.com/item?id=421858 ) > Gordon Bell, architect of the DEC VAX wrote \"High Tech Ventures\" and included this section on NNP's Negative Productivity is a principle that I claim is worthy of a Nobel Prize. Normal principles of productivity assume that workers create positive output. Brooks refined the concept of software productivity to express it in terms of the \"mythical man month,\" and in software engineering, it is understood that different programmers vary in their productivity by several orders of magnitude. According to the principal of negative productivity, it is possible for an individual to produce bad results that others must then redo; hence, someone who is very negatively productive can keep a whole team busy with damage control, preventing the team from producing any output whatsoever. Various locations of the paper - https://web.archive.org/web/20160305234708/http://pyxisinc.c... https://www.scribd.com/document/557220119/NNPP-Article And here it is discussed at C2 - https://wiki.c2.com/?NetNegativeProducingProgrammer reply HeyLaughingBoy 2 hours agoprevFire them immediately. I've been in this position before and the hire dragged down team productivity for almost a year as we struggled to find something that he was competent at. Wasted untold hours assigning other skilled devs to help him because we were sure that all he needed was a \"bit more guidance.\" After 9 months of this, our manager finally bit the bullet and he had to go. In nine months, we could not find a single task that he could be trusted to do and he had shown no improvement in that time. Learn from our mistake! reply red_admiral 3 hours agoprevEven in European countries with strong employee rights, the typical contract is allowed to have a 3 month or so \"probation period\" during which either party can terminate at short notice. I guess this is one of the situations that clause is meant for. Once you take into account not only the net negative you're getting from your recent hire, but the effect on other employees too, the rational decision is to let them go. Think of it this way: intrinsic motivation and good climate for everyone else means not having someone higher paid but clearly less competent on the team. reply coffeecloud 3 hours agoprevUnrelated: did this manage to work its way up to the #2 spot in under an hour because everyone on HN is worried this is about them deep down? reply hypeatei 2 hours agoparentI think a lot of people deal with this exact situation because some developers stumble into this field and \"get by\" for awhile until they get hired at place where their BS is obvious. reply solardev 3 hours agoprevOnly hearing your side of the story, it sounds like they significantly misrepresented themselves and then negotiated something way more than they're worth. It's the kind of developer that makes the rest of us look bad, IMO. Why not let them go? This one's on them. reply softwaredoug 3 hours agoprevDon’t drag out these decisions. It sucks to see an underperformer stick around and get lots of $$. It just tells your team that surrounding them with great people isn’t actually a priority. It also sucks to be a person in this position feeling like you’re underperforming for the long term. Or feel on the precipice of being let go without it happening. Gotta be OK being upfront with folks and ripping the bandaid off. It’s a day of feeling bummed on the team that’s better than months of team members feeling unmotivated. I’ll also say this should be really rare and if it keeps happening you need to review your hiring practices, as that’s actually the root cause of people getting into your team that aren’t a good fit. reply mvkel 3 hours agoprevI appreciate your willingness to try to salvage the situation, but the best thing for all parties in scenarios like this is to transition them out. I liked to use GWC for all employees: - do they \"get it\"? - do they want it? - do they have the capacity to do it? All three must be yes for a role to be a good fit. It's nobody's fault; perhaps they -were- at a senior level at another org, but your definition of senior might be more aligned with the market. Ultimately, it doesn't matter. Their capabilities do not match the requirements of the business. Take the emotion out and it's an easy decision. reply thinkingkong 3 hours agoprevFirst off which country youre in determines what you can do and how much it will cost you. If you don’t already have HR staff who are well versed in local laws and regulations then you should engage some outside help. Secondly, while your process might be biased or “broken” this is a situation where someone got through when they shouldnt have. Some people are slow to ramp up but others just wont ever do it. Ive hired former Google engineers who ended up being in this exact same situation. It cracked my brain to have to do it, but letting them go was better for everyone. 1. The team already knows theyre underperforming. If they know the titles and that salaries are banded to titles then they’ll easily infer they’re getting less than this person. 2. Values around personal development, motivation are noble but you can improve from all sorts of starting conditions. I believe in a growth minded environment but also that its not everyones job to invest in people. Some people just dont have it. 3. You can rescue it by thoughtfully letting them go. By adjusting your hiring process to avoid false positives (at the expense of some false negatives) and by talking to the team if it’s required. It sucks. Its never easy but its the kindest thing to do for you, for them, and for the team. reply _hl_ 2 hours agoprevIt is your responsibility to look after your team as a whole. Sometimes that means taking decisions that negatively affect a single individual. Your team members want to work with other great people who can help them deliver success - after all, the feeling of success is one of the most rewarding things a job can give you. I’ll also add that letting someone go (constructively) can be a net positive for them, if you can put them on a path for greater success in life elsewhere. Struggling to deliver for months or even years is also not a good use of their time. It might feel harsh, and it’s definitely a very difficult conversation to have, but I think if you remember that your responsibility is towards the team as a whole it can help you emotionally accept and navigate the situation. reply hrsnafu 40 minutes agoprev> there was a breakdown in internal communication where HR was under the impression we wanted to hire at any cost despite us giving the candidate a mediocre rating If HR hired the person despite a mediocre rating then they're the ones that need to be sacked. reply ZeroGravitas 1 minute agoparentIf someone had used the phrase \"hire at any cost\" to HR then a candidate being mediocre seems to not be a fatal flaw. Indeed, it feels as if the OP would be relatively happy if they'd hired a mediocre senior dev, but feel this guy isn't even that. reply smarm52 2 hours agoprevGot to hand it to them, they know how to play the game. Though, it would be a shame to not transfer them to sales or marketing, they sound very talented at that, at the very least. reply brink 3 hours agoprevI really appreciate that you want to salvage the situation. I've been at the opposite end of the spectrum at companies where the CTO wants a perfect team, and fired employees that weren't perfect or made (what we considered) reconcilable mistakes. We were all stressed out that we would be next on the chopping block. reply codegeek 2 hours agoprev\"Do you think there is any way to rescue this situation?\" No. \"Or should we make this (perhaps justifiably, after their misleading self-presentation) the first time we let someone go for performance reasons?\" You need to let them go. Whether you call it performance reason or not is your call. You made a mistake hiring the wrong person. It is your fault. But you need to correct it by letting them go. Doesn't matter whether you are a small team or large. Wrong hire is a wrong hire and things won't magically change just because you wish to. Fix the problem now and go back to hiring mode. Thank me later. Been there many times. reply mx_03 3 hours agoprevIt's not me, is it? reply Biganon 3 hours agoparentNah I think it's me reply jenscow 3 hours agorootparentWe better start doing some work, just in case. reply cgio 2 hours agoprevMediocre rating and imposter syndrome but excelled in selling themselves? I don’t feel like this is the full story. What is the purpose of this ask? To receive validation and an excuse to go against some self perceived principles? If you look to let them go do it without requests for psychological support or pursuit of excuses. You are a human too and you deserve support, but in this situation, the other party will need more of it and possibly bears less responsibility for the outcome. reply blablabla123 2 hours agoparentYeah this seems indeed missing details. It's not the candidate's responsibility to guess what the hiring manager is really looking for and kind of normal to get the best position possible. That said, the hiring process seems utterly broken if it wasn't possible to distinguish a junior from a senior. edit: personally I think though that the company should take responsibility and make sure the employee either gets ramped up or a very smooth exit financially since the application probably meant he missed other options reply redwood 3 hours agoprevThis is a good case study and how different the US versus European climate for scenarios like this is reply solardev 3 hours agoparentHow does Europe handle it? reply monotux 3 hours agorootparentYou can fire people in Europe too. In a lot of cases you have a six month trial period in which the employer or the employee can cancel the employment without any notice period. After six months there is a notice period from both parts, typically one to three months. reply JTyQZSnP3cQGa8B 3 hours agorootparentMost companies in France have a trial period of 3 or 4 months which can be doubled to \"make sure that everything is right.\" Which means that companies have to 6 or 8 months to fire new guys. I guess it’s the same amount of time in other countries. reply ties_ 3 hours agorootparentprevIt is expensive --- but here (the Netherlands) you can still fire or demote someone after the initial trial period. Instant dismissal without cause (for non-discriminatory reasons) is possible in the trial period, with trial period being time-limited (1 month for 12 month contract, 2-3 for permanent). The going rate for firing without cause is about 1/3rd of a month of salary per year of employment for an employee under 55 (?) on a permanent contract. On a yearly contract this is difficult - I would recommend hiring on permanent contracts because they are even seen as a positive. Demoting will mean that you overpay someone, but will at least clarify the new hierarchy to the team. reply swiftcoder 3 hours agorootparentprevProbation periods at the start of employment, mostly. And once the probation period is over, you need to provide robust cause to fire someone. reply oaiey 3 hours agorootparentprevIn many places, there is a trial period of 3 months and then usually you do a one year contract. So you have at least two decision points. Second thing is: most of our countries have a more direct conversation style. reply galangalalgol 3 hours agoparentprevCan you explain? reply atherton33 2 hours agoprevDo also consider that if this was your mistake (which you say), and they quit their previous job or declined other offers because of your erroneous offer, then you might have done them harm by your error, at least ethically if not legally. Be sure to talk to your lawyer, and consider what obligations you have to them in parting ways, both legally and ethically. reply EPWN3D 3 hours agoprevIf keeping this person onboard requires the effort of training them and keeping their comp a secret, it's not worth it. It will get out that this person is getting paid senior comp for entry-level work, and that isn't going to fly for the people who are performing. Don't overthink this. They're not fit for the role, and to boot, they misrepresented themselves. Your process screwed up, but the key is to not compound that. I'd encourage you to still be decent and give a good severance, because this is ultimately your company's fuck up, and you should take your medicine. reply namanyayg 3 hours agoprevThe same happened with me a while ago, I hired a dev with 8 YoE because he had the best resume and was good on a video call. Turns out he wrote some of the worst code I've seen, and worse, was unreceptive to feedback. Ended up firing him by the 3rd day. reply andrewaylett 2 hours agoprevThis (as a few others have noted) is the purpose of a probationary period. That cuts both ways, of course -- while I have only seen one person who \"failed\" their probationary period, I have myself left a job during my probationary period when it turned out to not be what I'd been promised. That's what the probationary period is for. reply exaldb 3 hours agoprevI’ve been in this situation when I was a junior engineer and found it really frustrating. I’d literally done more work in a week than the “senior” had done in their time at the company. They had shipped one change (a migration) and then nothing for 8 months. Why should I stay at your company as a junior engineer if the people I’m teaching things to are senior to me? It devalues seniority and the general appearance of meritocracy in your organization to keep this person at senior. If you really want to be nice, give them the title and compensation that is appropriate for them. If you can’t do that, the right thing to do is to politely say it’s not a great fit for the role and let them go. reply uhhhd 3 hours agoprevFast fire. You've gotten past the hard part, admitting the mistake. The quicker you let someone like that go, the better for you and your team. The mistake here would be to work on their performance and drag it on. Your team morale will take a big hit. At best you'll see a marginal performance improvement over months. At worst you'll waste months on this employee and have to fire them anyway. reply primaprashant 3 hours agoprevWas the candidate informed about the expectations before or after being hired? Has anyone communicated to them that they are not meeting those expectations? reply hnthrowaway0328 4 hours agoprevWhy it needs another 6-12 months to get them to be productive? Is it some system programming position? I can't imagine anything else that would require a year to get people into shape. reply pphysch 3 hours agoparentI think the belief that a 6 month bootcamp (or equivalent) is sufficient to create a competent developer even in \"easy\" domains like web is a big reason why most software sucks and why \"impostor syndrome\" is over-reported. Most 4 year degrees aren't even sufficient, as they just teach academic knowledge and \"hacking\" skills (as in \"hacking your grades\") that produce juniors that leave a massive wake of technical debt unless checked. But yes, 6mo could be enough to get a particular employee productive, assuming they are highly engaged (ideally not remote) and have someone available to train them every day, and so on. reply hnthrowaway0328 2 hours agorootparentOP merely asks for being productive. It is a pretty wide range. In fact, I'd argue that for anyone that knows some programming and in good GPA standing, 3 months is good enough for being productive. He can work on minor stuffs starting from 3 months. reply PartiallyTyped 3 hours agoparentprevKernel development, simulations, numerical methods, ML, graphics, database internals, compilers, infosec engineering, etc. reply CoastalCoder 3 hours agorootparentAgreed *, but (IMO) that's if you're starting with someone who has no prior experience in those topic areas. In my experience, usually some level of existing expertise is considered a prerequisite for senior dev positions. * Although a whole year sounds really long for a senior dev to get going in any of those topic areas. reply PartiallyTyped 28 minutes agorootparentA whole year for a senior is too much imho. I moved to something entirely different and it took me less than a week to find something that is useful to contribute to on the side while I am trying to better understand the context and everything we are doing. Being able to dive into different projects is, imho, a core skill for engineers and a good litmus test for seniority. reply hnthrowaway0328 3 hours agorootparentprevYeah that's why I asked if it's a system programming position. Anything else should not take a year. reply rvnx 3 hours agorootparentprev10 years ago yes, but nowadays that domain-specific knowledge can be solved with a $20 ChatGPT subscription (as it simulates very well pair-programming and spitting out explanations for you). It sounds more like legacy / messy systems with no dev/staging platform, or very bad documentation, or even a terrible onboarding process if you really need 9 months for someone to deploy code. reply seabird 3 hours agorootparentThis is a joke, right? reply rvnx 3 hours agorootparentIt is very true, ChatGPT makes it very easy to learn all the “domain-specific” knowledge, and makes the learning-curve less steep. Linux Kernel development is a fairly organized C software, it is no different than working on Chromium or Unity, or like any other large codebase. It used to be easy to get lost. However now, for only $20 you have an expert coder, sitting by your side (and this is what ChatGPT does), then your learning curve is certainly reduced from the 6-9 months, which seems gigantic. Simulations, number manipulations, data analysis, etc, you have, thanks to ChatGPT, turnkey code solutions. It was tough, when you had no internet, no GitHub, no AI, no documentation, no Wikipedia, no StackOverflow sites, but now the barrier for entry to be productive is much lower. If you need one year to start deliver one basic feature, and you have ChatGPT on your side, then it means the onboarding process is broken. reply seabird 2 hours agorootparentI get the sneaking suspicion that you don't actually do this shit. ChatGPT isn't an expert coder sitting by your side. It's not even remotely close. Go ahead and get ChatGPT to walk you through how to implement even a non-novel CFD analysis that won't get you laughed out of the room. Get it to help you port an Ada Ravenscar runtime to an exotic (or even a not-so-exotic) processor. Try and have it generate non-trivial ladder logic programs for industrial controls. Try to get any help from it at all when doing microcontroller programming that isn't just \"read the manual\". My question for you is -- what exactly do you do? What programming could you possibly be doing that is so trivial that you actually believe that ChatGPT is capable of solving these things? reply rvnx 2 hours agorootparentNo need to get so upset ? It is like if I say that reading a book will help you learn faster about a domain than if you have to discover all by yourself. Yes self-learning is better, but it takes a much longer period of time, whereas if you have a tutor, then it saves lot of time (and companies don't often have such resources, which is where AI and books fill the gap). I strongly believe that LLMs are a serious helping tool for programming that helps programmers to onboard their project faster. Regarding more exotic techs, as a cousin of ChatGPT, Google Gemini used to be very very bad, but with Gemini 1.5-Pro you can feed it very long documents, and this is super helpful for specific implementation (e.g. the exotic processors), and it's, really, really not bad at programming, or at least pushing you in the right direction. Of course it's not autonomous (and whether it can be in the short-term on complex projects is unlikely), but it reduces the onboarding time, and this was the point raised in the conversation. A dev paired with a LLM is much much more productive. I suppose that you are concerned that it may push people to lose their jobs in the long-term. I am as well, but we still have some time ahead. I don't like this situation either, but I have to recognize that it is a very helpful co-programming tool. reply CoastalCoder 3 hours agoprevI'm curious how much they're willing to invest in skills development for the sake of their future career. I.e., what if you agreed to let them keep their current job title, but gave them the responsibilities and salary of a junior dev until the skill gap was closed? Then (a) they have a way forward, (b) they avoid a career-limiting feature on their resume, and (c) you wouldn't be overpaying for their work. That's the best balance of kindness and fairness I can think of at the moment. reply solardev 3 hours agoparentNot knowing their side of the story, the OP makes it sound like they basically lied and practiced interviewing to score a high paying job. That sort of dishonesty shouldn't be tolerated, much less rewarded. The rest of us work and learn honestly for years if not decades. If an employer asked me about my skillsets, I would be honest about my experience and deficiencies and negotiate honestly from there, and make plans to address the weaknesses accordingly. Finding a good dev fit for any given project or team is already hard enough when people are honest and well intentioned. We have no good credential system or standard way to suss out ability. It's how we get endless whiteboarding challenges and leetcode that isn't relevant to the actual job. Allowing charlatans into the mix just makes it worse for everyone, both employers and other employees and prospective employees. It's one thing if this person came in honestly and needed some specific remediation, maybe a particular technology or domain knowledge or whatever, but were generally competent. But that doesn't sound like what happened here. They lied to get their foot in the door, abusing the company's family-like atmosphere. They'll just drag everyone else down. Let them go and have a better hiring process next time. Ask your other employees for better ways to evaluate candidate ability if you need to. They are often better able to evaluate whether someone can do their job or lead them. But show them that you care about fairness, not charismatic lying ability. reply avmich 3 hours agoprev> they're struggling to do even basic stuff without help and are far from helping others Question: how does that \"helping others\" look like? In companies there's a planning phase with meetings, the work phase with assigned tickets - how does the helping fits in? Is it in those cases when somebody asks about features - unknown to him - in the codebase which somebody else knows about? reply mikemitchelldev 3 hours agoprevThis is very strange that you're asking HN how to handle the situation. Who are the \"We\" that is running your company? Of course, if you're just posting something to generate some chat on HN that's fine, but if you actually need to ask the opinion of the HN community about what to do in this situation, then you have bigger problems. reply marnett 3 hours agoparentIt is perfectly acceptable to seek advice and opinions from a community you respect - not a problem whatsoever, it is a sign of making attempts at being the best leader one can be. reply jononor 2 hours agorootparentIt can also be good to get input from people that do not have any stakes, worries or agenda. Plus that have a wider ser of experience (collectively). Of course one should also discuss it inside the company. reply hypeatei 3 hours agoprevDealing with the exact same situation now but I'm not the manager. The new hire has a 12+ YoE but severely lacking technical ability. While they fall short in the specific stack we use (not a huge deal), they're completely unwilling or unable to adapt & learn it seems. reply aranchelk 2 hours agoprevIt may not be immediately obvious, but firing them asap is probably less disruptive for them: * They still have an up-to-date resume * They may still have warm leads for other jobs * Employment with you is probably short enough, they can just leave it off their resume entirely reply gdevenyi 3 hours agoprevThis is what probationary periods are for. reply savrajsingh 3 hours agoprevIf you’re willing to write all of this in a hacker news post, it’s clear that you take this very seriously, and it weighs heavily on your mind. Based on what you said, it’s also clear you must let this person go, but be helpful in finding them an opportunity that matches their skill level. Easier said than done! reply galangalalgol 3 hours agoparentMaybe they should create a startup teaching very talented people how to better represent themselves in interviews. reply npalli 3 hours agoprevAdd people slowly but let go quickly, nothing good will come out hanging on to this person hoping for the best. reply itg 3 hours agoprevAssuming your side of the story is true, can you downlevel them to a more junior position and reduce their salary? If they won't accept that, then the only reasonable option is to let them go. Other developers will notice and become disgruntled having a incompetent co-worker making more than them. reply mauvia 1 hour agoprevI've usually had a probation period clause in my employment terms. reply btbuildem 3 hours agoprevDo you need to demonstrate to others this person's incompetence before you can let them go? You could put them on a project by themselves, with expectations on par with other senior devs. Let them provide you with the evidence you need to make your case. reply drowsspa 2 hours agoparentYeah, he's talking about team morale, so I guess he has to make sure that the team also thinks he's underperforming. reply damezumari 1 hour agoprevOffer choice of either downrank (and criteria to get back), or fire. reply nobodyandproud 3 hours agoprevDon’t drag out a hopeless under-performer. I’ve learned that peers often won’t say what needs to be said even if it impacts the team, but they will expect leads and managers to pick-up on the problem and handle it all the same. reply sloaken 3 hours agoprevTrust me, others notice this person is GROSSLY overpaid. They also resent the fact that if that person is paid as a senior, and they are obviously better. They will move on to a company that appreciates their skill and not overpay a buffoon. reply jenscow 3 hours agoprevThis is why we need to have coding tasks during the recruitment process. It helps both sides. reply JTyQZSnP3cQGa8B 2 hours agoparentFor seniors it’s not that easy. The best interview process I had to do was in a restaurant where the recruiter and I were both ranting about how shitty C++ was. I got hired on the spot because the conversation we had proved that I was not bullshitting anyone. It may be more difficult for a junior, but that’s not the topic of the post. reply jenscow 2 hours agorootparentYes, one of the questions I ask is \"what do you hate most about X?\". However, in this case the person lacks \"basic skills\". reply EADDRINUSE 3 hours agoprevLet $dev go, and apologize to your team for messing up this badly. reply tayo42 3 hours agoprevI never understand these situations, it took me months to get a job offer and somehow incompetent people accidentally stumble into senior roles? reply Ekaros 2 hours agoparentRemember there is lot of incompetent people being interviewed. Majority of people being interviewed do not get hired. Some of it must be because incompetency, and they keep trying to get hired. So occasionally some of them do pass through the filter and this is one of the results. reply teitoklien 3 hours agoparentprevBecause there are incompetent interviewers too out there, its just you haven’t encountered those yet. reply edward28 3 hours agoparentprevYou can thank HR for that. reply gitowiec 3 hours agoprevIf you allow him to stay, and do the learning (if he's willing to) you would be magical fairy granting wishes. There is no such work place with such an attitude reply hnpolicestate 1 hour agoprevDoes this employee have any positive traits? reply itqwertz 3 hours agoprevGet that interview process fixed ASAP and let this lemon go. Don’t be surprised if there is pushback from non-technicals if this hire checked a bunch of boxes for other departments. A good strategy would be to have them be a lead on a minor project that requires technical chops and communication. Ensure there is a daily standup and grind them on details and timelines. Get them some juniors as direct reports to expose their lack of knowledge, then have meetings with these junior devs about project performance. The stress alone will probably make them quit. Document as much as you can in emails and messaging systems. reply neilv 3 hours agoparent> A good strategy would be to have them be a lead on a minor project that requires technical chops and communication. Ensure there is a daily standup and grind them on details and timelines. Get them some juniors as direct reports to expose their lack of knowledge, then have meetings with these junior devs about project performance. > The stress alone will probably make them quit. Document as much as you can in emails and messaging systems. My god, no. Unless you want to set a precedent for super-toxic, manipulative workplace environment. (You don't get to pick&choose when evil happens: \"I learned it from watching you\".) As well as expose the company to potentially an 8-figure harassment suit. reply quantgenius 3 hours agoparentprev> A good strategy would be to have them be a lead on a minor project that > requires technical chops and communication. Ensure there is a daily standup > and grind them on details and timelines. Get them some juniors as direct > reports to expose their lack of knowledge, then have meetings with these > junior devs about project performance. Do not do this. You do not need a “strategy”. Just do it! Rip off the band-aid. Either tell them the truth or give no reason even if asked. Reverse the mistake asap and get moving on your company’s mission. You don’t need one second more of this. Nor does anyone else at your organization. Do it today! Do it dispassionately. Do it as nicely as possible. You are going to feel bad because you are a good empathetic human. Some people will have a reaction. Some people will “have a reaction” to try to get more out of you. You are not responsible for either. You are responsible only for your own actions. Figure out what you should give them to be fair and add a little extra so you are sure it isn’t unfair. Plan what you will say and do in advance and have someone you trust with you in the meeting. Stick to your plan. Even the best hiring processes succeed only 50% of the time (though this goes beyond just a bad hire). Firing, and firing quickly is just as important as hiring well. Also remember that if an applicant tailors to a hiring process to this extent, that’s not just a failure of the process. It’s dishonesty. Even if the applicant were competent, you absolutely don’t want to entertain someone dishonest in your company. reply ssijak 3 hours agoparentprevThat is just evil to both that person and your team. Just let the person go if they do not satisfy what they were selling them self as. Dont play evil and stupid games. reply teitoklien 3 hours agorootparentUS is an exception in terms of at-will employment. In most other countries you cannot fire people just for reasons like this. In other countries people have to resort to backhanded ways like the parent comment mentioned if you want to get someone off the payroll. reply jenscow 3 hours agorootparentThat's \"constructive dismissal\", which is not allowed. Firing for \"performance\" is ok in the first year or two (country specific) reply teitoklien 3 hours agorootparent> \"constructive dismissal\", which is not allowed. I agree, but a lot of things that are not allowed but happen frequently. Doesnt matter what the law says is illegal, unless its enforced. Im not saying its a good thing to resort to such toxic measures. Parent comment said it is evil and should not be done, I just mentioned the reality that in most countries its one of the classical tried and tested method to bypass employment safety laws that almost rarely gets backlash. I myself dislike such toxic behaviour, but just stating the reality of what happens. reply ta1243 3 hours agorootparentprevYou can in the probationary period. If after several months you decide you no longer want them that's different, but if you hire someone, they're no good, you can fire them pretty easily, assuming you've specified the probationary period in the contract. reply _puk 2 hours agorootparentprevAnd those countries generally have laws against constructive dismissal (which is what a lot of these \"persecute then until they quit\" recommendations amount to) reply nkmnz 3 hours agoparentprevThis proto-sociopathic behavior is the direct result of European employment law. It's disgusting. reply btasker 3 hours agorootparentNo, it's the result of that poster's mindset - there's absolutely no need to do any of that. In fact, that type of behavior is against the law in a lot of countries and will leave the employer likely liable. If someone's under-performing whilst in their probation period getting rid of them is incredibly easy. Outside of the probation period there's a bit more of a process, but it's still not particularly hard - all you actually need to be doing is documenting. reply nkmnz 1 hour agorootparentThis is not true. It’s impossible to fire an employee for performance reason after the probation period in Germany. If an employee cannot deliver on the tasks assigned, they need to be assigned easier tasks. In order to risk your job you have to actively work against solving your skill gap, e.g. declining offers of upskilling. reply oaiey 3 hours agorootparentprevIt is not. You would fire the person in the trial period or after a year. What is expensive in most European jurisdiction to fire a permanent contract after the initial trial period/first year contract without wrongdoing. But that is typically after a year or more. The reason here is that they are trying to be a employer which focus on personell development. Which is contradictive to capitalism and obviously they have not figured out yet, how to deal with situations like this. reply teitoklien 3 hours agorootparent> which is contradictive to capitalism Capitalism doesnt have any 1 original author like Karl Marx, not everything can be made to fit in “capitalism” and villified. The latest devices you’re writing code and comments on here with are devices powered by latest silicon fabrication tech made by teams of engineers on whose careers, companies greatly invested long term to get to this. There are tons of capitalistic employers there who invest in their employees careers retain them and take their help to grow the company, even give them esops and stock options. High skilled labour isnt a cogwheel readily available on the market churning out of colleges, they are trained, retained and further developed throughout their careers to bring value to business and build new products. Capitalism isnt this great evil thing that wants to suck you dry and destroy you. It has perfectly healthy versions that give people a chance at Life, Liberty and the Pursuit of Happiness. reply JTyQZSnP3cQGa8B 3 hours agorootparentprevEntrapment is sociopathic. reply jrvarela56 2 hours agoprevObvious answer is to fire immediately. Huge red flag if you cant fire someone under these circumstances. reply Version467 3 hours agoprev> but we're a small outfit with a focus on personal development, intrinsic motivation, good climate, and low turnover. This is cool and all, but company culture is a two way street. Presumably you have this focus because you expect that employees appreciate it and in return are happier, more resilient and ultimately more productive because of it. But you can’t have this with someone who misrepresented themselves from the moment they walked in. Consider also how this looks for other employees. They were hired for a job, do it well and in return got a great employer who cares about their wellbeing. But if you keep this person on, then you devalue the effort everyone else puts in, because apparently you can just lie on your resume and get the same great treatment as everyone else without any consequences. reply jacknews 3 hours agoprevThis is what the 'probation' period is for? reply swiftcoder 3 hours agoparentWe don't have those in America. Mostly because your healthcare is tied to your job, so nobody would risk taking a probationary role that could land them out of work and without healthcare at the end of it... reply jetti 3 hours agorootparentThere most definitely are companies that have a probationary period in the US. It may not be common but it does happen. My first dev job had a probationary period and I put up with it because it was a job that was willing to employ me as a dev without a CS degree or prior dev experience. I lasted about 7 or 8 months before I quit for somewhere better. reply the_af 3 hours agorootparentprevI don't follow (not from the US, please excuse my ignorance). I was told that, with some exceptions, in the US every job is permanently \"on probation\" (\"at will employment\"). As in, you can get fired from one day to the other, no severance and no reason needed (as long as it's not discrimination based on sex, religion, etc). Is my understanding incomplete? reply jetti 3 hours agorootparentYou are correct, however, that isn’t the same as probation. Companies with a probation period may not grant full benefits until after the probation period ends. For example, a company may not let an employee take any time off during the probation period or the company may not let an employee participate i. The company 401k retirement savings plans until after the probation period. reply neilv 2 hours agoprev> breakdown in internal communication where HR was under the impression we wanted to hire at any cost despite us giving the candidate a mediocre rating. One way that breakdowns can happen is if people are too subtle in their reviews. For example, damning with faint praise, or being overly constructive. Lots of people aren't good at reading comprehension, and even less good when wading through the piles of communication noise that many companies tend to generate. Combining free-form text with unambiguous \"multiple-choice\" options on the interview reports can help (e.g., interviewer writes constructive things about growth potential, but clicks the \"lukewarm\" or \"not for this role\" radio button). Another way is if different interviewers had very different impressions, and one interviewer's takes precedence. (This can also happen the other direction: false-negative. As a team lead, I gave a very strong recommendation to hire this one very determined designer-y frontend engineer. But another team lead, who would have temporary loan of the hire before my team's project spun up, proceeded to Leetcode-haze them. I wouldn't say the candidate bombed it, but rather that the company bombed it. The company really didn't want to hire someone who got a strong negative, so they said no. Rejected candidate instead went to a different super-cool engineering-driven company, and I soon saw them featured in a tech demo video of that company on LinkedIn, explaining to customers this neat new product thing they built.) Other ways? reply teitoklien 3 hours agoprevFirst talk to this dev face to face to understand if they were lying to you and being disingenuous about their skill level or was it your own interview tests that just failed to detect they weren’t a senior If they lied, fire them. If they were honest during interview and their previous company salary, wasnt higher than your junior pay, give them an option for either demotion or resignation (with decent severance if you can afford to so that they have safety net to look for new jobs) If you were going to hire someone junior too in the short term, then just demote this new dev to his real level. If not, and you desperately need senior dev, make this current new dev resign or fire them. reply eloh 3 hours agoprevJust do the right thing and don't waste time on it. The candidate is out. reply aym62SAE49CZ684 3 hours agoprev> the candidate excelled at selling themselves and negotiating sales / executive track reply cozzyd 3 hours agoprevFix the glitch and let the problem work itself out naturally. reply ksherlock 3 hours agoprevFire their ass or downgrade the job title (and pay) to intern. reply animanoir 2 hours agoprevMake them senior. reply JojoFatsani 2 hours agoprevDocument document document and PIP reply lkramer 2 hours agoprevI was in a team where this happened. Management stuck their head in the sand for the longest time, while the morale of the team started tanking, as noone wanted to work with this person, who needed a lot of attention and never seemed to improve, even after years of trying. My recommendation would, for his sake and yours, to let him go sooner rather than later. Working in the wrong position is also going to tank his self confidence and will do him no favours. reply goodluckchuck 3 hours agoprevIf you were wrong then, maybe you’re wrong now. What are these basic skills and can you measure them across the new hire and the existing devs? In order to hire better next time, you’ll need to be able to apply this sort of screening at the front end. If you can’t, then maybe it’s a management / utilization issue. reply ookblah 3 hours agoprevno offense (okay, maybe some), but how is this even a question lol... fire immediately. it's not something tangential like communication, but about someone lacking the core skill that you are paying for. reply antisthenes 3 hours agoprevTo echo everyone else's sentiment - fire them. Also, this was HR's mistake, so give them in no uncertain terms your decision to let this person go, and let them handle the rest. reply petesergeant 3 hours agoprevIf you hired from an external recruiter, don’t delay getting rid of them — there’s probably a warranty clause where you’ll get most of your recruiter fee back if and only if you turn it around quick enough. 12 weeks in and the warranty is normally done. Letting go of someone sucks, but offset that against upsetting your current good, hard-working team. The quicker you let this person go, the more easily they can pretend the job never happened on their CV. reply rvz 3 hours agoprev> Do you think there is any way to rescue this situation? No. Let them go and move on. This is the problem with title inflation and it happens all the time. How did you evaluate this candidate for this role exactly? Some candidates are great at acing the interviews (since 90% of the time it is measured on predictable leetcode puzzles) but as soon as the real work begins, the new hire lacks basic skills, asks for too much help on issues that can be solved by 5 second googling or they take extremely long on simple tasks. If you used Leetcode and yet this was the result, then perhaps you might need to find another way of evaluating actual 'senior' hires. A wrong hire is worse than no hire. Not only the money is spent but time is also wasted and will be wasted further by training. reply willmadden 3 hours agoprevDocument the performance issues in writing, create an improvement plan for the employee that they sign, and if the employee cannot correct the issues, you fire them. You need to do the same thing with all of the employees involved in the hiring process, or get them out of the hiring process if that isn't their primary role and they are otherwise competent. reply baq 2 hours agoprevDude you’ve been lied to. Letting them go is salvaging the situation. reply paulcole 3 hours agoprev> I guess in most companies this would be a no-brainer, but we're a small outfit with a focus on personal development, intrinsic motivation, good climate, and low turnover. Really? You want low turnover in people who lie to you in the interview and are a drag on the rest of the team? That’s exactly how you get high turnover from the good-fit people. reply ltbarcly3 3 hours agoprev [–] It isn't impostor syndrome, they are literally an imposter. They committed fraud to get in the door, you didn't coerce them to get a much better paying job than they are qualified for. Now that they know they can't do the job, they are content to keep cashing paychecks and hope that your company is too hand wringing and soft to call them out. To your face they are worried and \"what will we do, oh no what a mistake we all made\", behind your back they think you are suckers (and based on your post they are probably correct). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A senior developer hired by the company lacks basic skills due to flaws in the interview process and miscommunication with HR.",
      "The developer struggles with basic tasks, experiences imposter syndrome, and has net-negative productivity, raising concerns about whether to invest in their training or let them go.",
      "The company, despite its focus on personal development and low turnover, is debating the best course of action to address the skill gap without demotivating the employee."
    ],
    "commentSummary": [
      "A company hired a senior developer who lacks basic skills due to flawed interviews and miscommunication, leading to low productivity and imposter syndrome.",
      "The company is debating whether to invest in the developer's growth or let them go to maintain team morale and productivity, considering performance improvement plans (PIPs) and possible demotion with salary adjustment.",
      "The discussion emphasizes the importance of promptly addressing underperforming senior hires to prevent long-term issues, suggesting diversified interview questions, take-home problems, intern or apprenticeship programs, and trial days for real-world tasks."
    ],
    "points": 87,
    "commentCount": 180,
    "retryCount": 0,
    "time": 1717857262
  }
]
