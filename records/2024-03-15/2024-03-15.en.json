[
  {
    "id": 39702604,
    "title": "Oregon enacts right-to-repair law despite Apple opposition",
    "originLink": "https://www.techdirt.com/2024/03/13/oregon-passes-right-to-repair-law-apple-lobbied-to-kill/",
    "originBody": "Darkness Of Course (profile) says: March 13, 2024 at 4:55 pm What a nice headline From Portland, that was nice to learn. I might keep my iPhone another year Reply View in chronology Make this comment the first word Make this comment the last word",
    "commentLink": "https://news.ycombinator.com/item?id=39702604",
    "commentBody": "Oregon passes right-to-repair law Apple lobbied to kill (techdirt.com)547 points by Lariscus 22 hours agohidepastfavorite140 comments Kon-Peki 21 hours agoThe text of this law is here [1]. The formatting is ridiculously bad, which makes it extremely hard to read: Subsections within subsections within subsections with approximately zero indentation. Anyway, as far as I can tell, this law defines an independent repair provider as someone with a valid and unexpired certification demonstrating that they have the “technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment” and that the manufacturer is allowed to decide which certifications they trust. Without these certifications, you are not an independent repair provider and manufacturers can refuse to allow you to do anything. You can be just an average person repairing your own device, in which case the manufacturer must work with you. But you can expect to be forced to prove that you own the device before that happens. [1] https://olis.oregonlegislature.gov/liz/2024R1/Downloads/Meas... reply throw10920 20 hours agoparent> Without these certifications, you are not an independent repair provider and manufacturers can refuse to allow you to do anything. If this is true, it doesn't seem like it's actually \"right to repair\" at all. reply AaronM 20 hours agorootparentI read things differently. Several sections clearly reference the owner of a device. For example under section C part i (C) Makes parts available directly or through an authorized service provider to: (i) An independent repair provider or an owner at costs and on terms that are equivalent to the most favorable costs and terms at which the original equipment manufacturer offers the parts to an authorized service provider and that: the word owner shows up 17 times in the bill, and seems to give the same rights to an owner, that an authorized repair shop has. reply Kon-Peki 19 hours agorootparentThat's what I'm saying. It looks like you can repair your device. But you can't repair devices for anyone else without a mountain of certifications. They're going to kill the independent repair industry. reply ssl-3 19 hours agorootparent> They're going to kill the independent repair industry. This bill does not kill anything that is not already dead. reply samtheprogram 5 hours agorootparentThis. The parts and information in question are already hard to get and aren’t being sold to authorized repair providers. reply hiatus 16 hours agorootparentprevIt's one thing to fix things for yourself, and a whole other kind of thing to hold yourself out to the public as an expert in something. Kind of like how you can defend yourself in court but not someone else unless you are a lawyer. Though I would be surprised if the law were written such that you couldn't repair someone else's device, so long as you did not receive compensation for it. reply kelnos 8 hours agorootparentThe problem is that it sounds like the device manufacturer gets to decide what certifications are sufficient. Presumably they could decide that no certifications are sufficient, and thus no one can run a certified repair shop. Or they could offer their own certification, but make attaining it prohibitively expensive or difficult. reply zelphirkalt 16 hours agorootparentprevSo as a non-certified repairer, you have to offer a city tour around the block, at a ridiculously high price, and then repair the device at no additional cost. All a matter of perspective. reply godelski 15 hours agorootparentprev> without a mountain of certifications. It's not a mountain of certificates, you just need one of many different options. They explicitly mention A+ which I assume is the CompTIA one.[0] Yeah, I'm not going to say it doesn't suck to have to pay $250, but there are free practice exams[1]. Here, I even took a screenshot of their sample questions[2] there are things like Which of the following password choices increases the chance that a brute force attack will succeed? A. Dictionary words B. Special characters C. Long passwords D. Capital letters I'm okay verifying that someone has this basic level of competence. I would be surprised if any given Hacker News user couldn't pass one of these tests without studying. You need like a 78%... But let's be real, if you're repairing for a friend, you just fucking order the stuff for them and put in their name and info (with their permission of course). The only \"for anyone else\" part that requires certs is if you're operating a business. I think you all are blowing this part out of proportion. Mountains out of mole hills. I know it is the internet and we like to complain without knowing what we're complaining about, but come on... [0] https://www.comptia.org/certifications/a [1] https://www.comptia.org/training/resources/practice-tests [2] https://imgur.com/a/X1ajlAy reply sqeaky 8 hours agorootparentIf the previous comments are to be believed (I don't know I didn't read the law), then individual repairperson will need many certs in practice. If I put myself out there as able to repair phones and there are a dozen popular phone manufacturers and each requires a different cert then I need to make them all happy to be able accept whatever customers walk in the front door with. reply godelski 6 hours agorootparent> If the previous comments are to be believed (I don't know I didn't read the law) It's probably worth doing so before taking a stance. I'd highly encourage this if you see people arguing about something in the comments. Especially when it is linked. Here, I'll save you the trouble (e) “Independent repair provider” means a person that: (A) Engages in the business of diagnosing, maintaining, repairing or updating consumer electronic equipment in this state but is not an authorized service provider; and (B) Possesses a valid and unexpired certification that demonstrates that the person has the technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment in accordance with widely accepted standards, such as a Wireless Industry Service Excellence Certification, an A+ certification from the Computing Technology Industry Association, a National Appliance Service Technician Certification or another certification that an original equipment manufacturer accepts as evidence that the person can perform safe, secure and reliable repairs to consumer electronic equipment that the original equipment manufacturer makes or sells. We can see that it literally says what I indicated. >> It's not a mountain of certificates, you just need one of many different options. Possesses __A__ valid and unexpired certification that demonstrates that the person has the technical capabilities and competence necessary to safely Nowhere does it say that many are needed and the continued text makes a stronger indication that these are examples of such sufficient certifications rather than the specific ones needed. If you're willing to believe the other comments maybe you're willing to believe I googled the requirements and can find no such clear description in Oregon Law that one must have a mountain of certificates. All I can find is that you must be certified (with similar but not identical examples provided) and a specific requirement about the certification including discussion of pollution. Which those practice exams I showed even have such a question. But also IANAL, but neither are most of the commenters. Still, I did read the text before responding and tried to do due diligence before taking a position. I hope we can reduce the number of arguments by RTFMing. reply userbinator 20 hours agorootparentprevThe subtle point in that sentence might be \"provider OR an owner\", as opposed to \"provider AND an owner\". reply basil-rash 19 hours agorootparentThere’s tons of prior art in Law saying that And and Or are the same thing and can be interpreted interchangeably based on context. Much to the chagrin of the computer scientists who think it’s some sort of robust formal specification for civil society. reply AdmiralAsshat 18 hours agorootparentWANTED: DEAD AND ALIVE reply cutemonster 17 hours agorootparentIf you look at \"wanted\" to be prefixed to everything in the list, it'd expand to: \"wanted: dead, and wanted: alive\". While this: \"Wanted: dead or alive\" could be interpreted as: \"We haven't decided yet what we actually want, if it's dead, or alive, but it's one of those\". Then it can be good to give them (the police) a call and ask if they have decided yet, before you go looking for the wanted person reply tcmart14 14 hours agorootparentprevObviously they want Schrodinger's criminal. You must get them before their wave function collapses. reply throw10920 19 hours agorootparentprev> based on context Does this specific context allow for interchanging? reply AaronM 18 hours agorootparentThe bill clearly defines an independent service provider and an owner as different entities. reply littlestymaar 18 hours agorootparentprev> Much to the chagrin of the computer scientists who think it’s some sort of robust formal specification for civil society. Law is actually code, just written in a language that is full of UB and you need to have if run on the system to know exactly what it does, the system being the hierarchy of jurisdictions. reply Sohcahtoa82 17 hours agorootparent> Law is actually code, just written in a language that is full of UB Which is why legalese exists. To try to limit undefined behavior by being extremely verbose to cut out any loopholes. Like...imagine a kid jumping on their bed. Mom says \"Stop jumping on the bed!\" and the kids stops. Comes back to the kid's room later, kid is jumping on the bed again, tells the kid to stop. Kid says \"I'm not jumping, I'm hopping!\" and goes into a diatribe about the difference between jumping and hopping, mom says to stop hopping and leaves. Goes back again later, kid is STILL jumping on the bed, and mom is angry! \"You said no jumping or hopping, I'm not doing either, I'm bouncing!\" Eventually the mom has to say something like \"Do not jump, hop, bounce, spring, leap, or otherwise propel yourself upwards or laterally from the bed, mattress, or any other part of furniture intended for sleeping\". reply zelphirkalt 16 hours agorootparentGreat example. And then it goes on even further, because she did not say, that the kid must never \"propel themselves upwards or laterally from the bed\", and only stopped that action in that moment ... reply rtkwe 19 hours agorootparentprevThe law there is defining two categories manufacturers need to provide the parts to, changing it to AND would mean owners would have to be certified repair people to be covered. reply filoleg 19 hours agorootparentNot trying to take a dig at your comment, but for others struggling to parse (as much as I was) what it was trying to say, here is the trick that helped me - place a comma right before “changing” or treat that word as the start of a new sentence. reply rtkwe 16 hours agorootparentVery fair I don't do the best job going and clarifying my comments some times. They come out a bit stream of consciousness. I did see your comment in time to make the change at least. reply filoleg 16 hours agorootparentAll good, no worries. I have the same tendency for writing singular sentences that should’ve honestly been paragraphs instead. I’ve got some feedback about it at work, so now I genuinely try to be a bit better about it. It is a bit easier for me to be mindful of it on HN, but, as evident by my comment history, I am still far from being consistently good about it. It is still often a “stream of consciousness written down as I would speak it outloud”, but now I at least started doublechecking the punctuation (or lack of it) for any potential confusion it could create before hitting send. reply olliej 18 hours agorootparentprevThere was an entire lawsuit about the presence or absence of an Oxford comma in some law, possibly even in Oregon? [edit: boo it was Maine! Happily \"Oxford comma lawsuit\" is sufficient search term: https://www.npr.org/2017/03/23/521274657/the-10-million-laws...] reply j33zusjuice 5 hours agorootparentThey were awarded $5M in the end. https://www.nytimes.com/2018/02/09/us/oxford-comma-maine.htm... reply rolph 18 hours agorootparentprevhttps://yt.artemislena.eu/watch?v=4AyjKgz9tKg [video] reply godelski 17 hours agorootparentprevThey're just saying you need like a CompTIA certificate and you can't just be some rando. But mind you, it also includes anything YOU own, so if someone is able to act on your behalf that's good enough too. Getting one of those certs to set up shop isn't that hard. Probably just to prevent people from mass ordering parts and redistributing. reply cortesoft 16 hours agorootparentprevThe very next sentence says: > You can be just an average person repairing your own device, in which case the manufacturer must work with you. reply chalst 19 hours agorootparentprevIt also could be misused by Apple. reply pierat 19 hours agorootparentprevWell, it's the same state that won't \"permit\" a non-certified engineer from recording and noting the time on a stoplight is outside of law. (Note: he won a first amendment lawsuit, and the state body used his formula in the end) https://ij.org/press-release/oregon-engineer-makes-history-w... So yeah, when I see verbiage about certifications like this as a barrier to repair electronics, it's pure protectionism and the state impeding actual ownership rights over whatever this crap is. (Put bluntly, my hardware is mine. If I want to take it to someone else for repair, that's 100% on me and my property rights to decide that. 'CerTiFicAtIoN', especially with the shit company or govt in question should have no say on who can or cant fix MY hardware.) reply AaronM 18 hours agorootparentIf you read the bill, they clearly differentiate between a service provider and an owner. The bill does not require an owner to be certified to purchase parts, manuals, tools or make repairs. It does require the manufacture to make those things available to both. reply zarzavat 18 hours agorootparentThe contention is whether or not you can fix someone else’s device without a certification. If you can only fix your own device then that’s useless to 90% of people who are not technically adept enough to do it. When I want to get a battery replaced I take my device to the repair shop and they replace the battery. I don’t ask them if they are “certified”. If they break something the liability is on them. Every single repair shop I’ve ever been to offers a warranty on their repair. reply TylerE 16 hours agorootparentYou mean those actual businesses with business licenses? Yeah, they’re fine. The guy ipersting out of The back of his car at a flea market? reply QuercusMax 18 hours agorootparentprevSo in theory I could buy the manuals, tools, and spare parts, and bring them to Chuck over there who runs an unaccredited repair shop? That doesn't seem awful. reply pierat 17 hours agorootparentprevWho exactly certifies a repair shop??? The state, the company, or some 3rd party independent org? reply AaronM 17 hours agorootparentIf you read the bill it states that a shop must \"Possesses a valid and unexpired certification that demonstrates that the person has the technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment in accordance with widely accepted standards, such as a Wireless Industry Service Excellence Certification, an A+ certification from the Computing Technology Industry Association, a National Appliance Service Technician Certification or another certification that an original equipment manufacturer accepts as evidence that the person can perform safe, secure and reliable repairs to consumer electronic equipment that the original equipment manufacturer makes or sells\". The bill also requires that a manufacturer does not \"impose a substantial condition, obligation or restriction that is not reasonably necessary to enable an independent repair provider or an owner to diagnose, maintain, repair or update consumer electronic equipment that the original equipment manufacturer makes or sells\" reply delfinom 20 hours agorootparentprevYep this law is just a giant handout to the industry. I wouldn't be surprised if they use this law to now sue \"uncertified\" repair shops. reply idiotsecant 19 hours agorootparentWhat mechanism in this law do you propose allows them to sue repair shops? reply ZanyProgrammer 20 hours agorootparentprevYes, it's such a giant handout that Apple came out against it. reply throw10920 20 hours agorootparentThe implicit claim being made in this sarcastic comment is that it's not possible for a law to be detrimental to one company while unfairly favoring another. Which, of course, is obviously false when you think about it. reply digging 19 hours agorootparentWhich major tech companies would it be good for while being bad for Apple? Keeping in mind that the owner of a device is also allowed to repair without certification. reply throw10920 19 hours agorootparentWhere did I say \"major\"? reply afavour 19 hours agorootparentThe OP said \"a giant handout to the industry\". If you're trying to make a point that excludes all the major players in the tech industry then by all means go ahead but it isn't the conversation you joined. reply CamperBob2 19 hours agorootparentprevI imagine the parable of Brer Rabbit and the Briar Patch is largely lost on today's audiences. More's the pity. reply jasonwatkinspdx 11 hours agoparentprev> The formatting is ridiculously bad, which makes it extremely hard to read: Subsections within subsections within subsections with approximately zero indentation. This is standard practice in the legal world because the nesting gets so deep if you indent you'd run out of page. reply WesternWind 18 hours agoparentprevI'm not a lawyer, but I don't think you are parsing that correctly according to legal canons of construction. Generally all language in a law must be considered relevant, and or implies a disjunctive list. Finally permissive language like such as grant discretion. https://www.law.uh.edu/faculty/adjunct/dstevenson/2018Spring... So the language says \"...in accordance with widely accepted standards, such as...\" and lists stuff like A+ and WISE certs. The per the OEM standards is probably best undrstood as modifying the or another certification, so I think the language you are referring to is allowing an additional certification that the OEM considers valid. It's unclear whether that means it counts as a widely accepted standard, or is allowed even if it's not a widely accepted standard, but pretty sure it's understood as modifying the last antecedent, rather than the clause as a whole in a way that eliminates the widely accepted standard portion.. It would require ignoring the widely accepted standard language and several other departures from the canons of construction to reasonably have the interpretation you use. The language could be cleaner like they could use either and two sub clauses, but it doesn't need to be. \"Possesses a valid and unexpired certification that demonstrates that the person has the technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment in accordance with widely accepted standards, such as a Wireless Industry Service Excellence Certification, an A+ certification from the Computing Technology Industry Association, a National Appliance Service Technician Certification or another certification that an original equipment manufacturer accepts as evidence that the person can perform safe, secure and reliable repairs to consumer electronic equipment that the original equipment manufacturer makes or sells.\" reply da_chicken 15 hours agoparentprev> The formatting is ridiculously bad, which makes it extremely hard to read: Subsections within subsections within subsections with approximately zero indentation. This is normal for legislation. The problem is that fairly often they end up with subsectioning so deep that you're running into the right margin -- I got about six levels deep -- so they simply don't do it. However, it's still standard to produce bills in PDF. It does get easier with practice, but I still find myself copying and pasting into a text editor to reformat it. It actually is a helpful exercise just to read the law. It's similar to reading a really long SQL query. Nobody formats them the way you prefer, so format them as you read and you'll force yourself to read the query with enough attention to understand it. It's simply the best way to read the things. > Anyway, as far as I can tell, this law defines an independent repair provider as someone with a valid and unexpired certification demonstrating that they have the “technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment” and that the manufacturer is allowed to decide which certifications they trust. That's true, but it also says: \"An original equipment manufacturer shall make available to an owner or an independent repair provider on fair and reasonable terms any documentation, tool, part or other device or implement that the original equipment manufacturer makes available to an authorized service provider for the purpose of diagnosing, maintaining, repairing or updating consumer electronic equipment that the original equipment manufacturer makes or sells and that is sold or used in this state.\" The critical bit is that they have to supply owners, too. “Fair and reasonable terms” means: A) Makes documentation available at no charge [except cost to prep and print] B) Makes tools for diagnosing, maintaining, repairing or updating consumer electronic equipment available at no charge and without impeding access to the tools or the efficient and cost-effective use of the tools [except cost to prep and ship] C) Makes parts available directly or through an authorized service provider to independent repair providers or an owner at costs and on terms that are equivalent to the most favorable costs and terms at which the original equipment manufacturer offers the parts to an authorized service provider [with a bunch of limitations that try to ensure the OEM can't cheat]. Oh, and [there's limtations that authorized service providers have to be fair and reasonable to owners and independent repair providers, too]. AND, they can no longer use parts pairing to prevent third party replacement parts. So: 1. An owner has a right to documentation at cost 2. An owner has a right to tools at cost 3. An owner has a right to replacement parts 4. Replacement parts going forward (essentially) can't employ parts pairing. So, yeah the manufacturer doesn't have to have an authorized service provider, and doesn't have to support independent repair services. BUT THEY STILL HAVE TO OFFER DOC, TOOLS, AND PARTS. Oh, and if the OEM doesn't have any authorized service providers, then the OEM is the authorized service provider. reply Spivak 21 hours agoparentprevIt's the same for doing work on your house. If you're the owner you don't need to be licensed to do most repairs or renovations but to work on other people's houses you need certification. Not saying it's a good system, just that it's consistent. reply idiotsecant 19 hours agorootparentNo, this would be like if the city's electrical supply house got to choose what counted as an electrical qualification. reply ClumsyPilot 20 hours agorootparentprevThe difference being is that electricians are certified by a real and reputable body and manufacturers don’t get to pick and choose. No doubt they will weaponise this ability reply samatman 15 hours agorootparentNo they won't. The disconnect between computer programming and law is a rich and perennial source of amusement here on Hacker News. What happens if the manufacturer decides to be unreasonable, by saying that no industry standard of certification is acceptable, or just the one organization they founded themselves, or that sort of thing, is that they get a sharply-worded letter from the Oregon DA. If they don't sort it out then legal action will be taken. So they're not going to do that in the first place, because everyone actually involved in this stuff already knows that. The law isn't compiled. Its function relies on a common understanding of context which is the major course of study in law school. If a CEO ordered a company to do the sort of thing you're proposing, it would be against the advice of council. reply autoexec 8 hours agorootparent> What happens if the manufacturer decides to be unreasonable, by saying that no industry standard of certification is acceptable, or just the one organization they founded themselves, or that sort of thing, is that they get a sharply-worded letter from the Oregon DA That assumes that the Oregon DA isn't collecting a bunch of campaign funds, gifts, etc from Apple in which case the DA will do nothing and taking apple to court yourself will likely end in a loss since our legal system is often pay to win and apple can out-spend you. >If a CEO ordered a company to do the sort of thing you're proposing, it would be against the advice of council. CEOs often break the law because they (and their council) know the risks of getting caught are small and/or that if they are caught the worst punishment they'll face is a fine which won't come anywhere close to the amount of money they'll make by breaking the law. Generally, it's a good thing that laws are subject to interpretation by humans and not treated like code written for machines because we want flexibility, but without enough oversight and accountability that doesn't work out so well for us either. reply passwordoops 18 hours agoparentprevIf that's the case then Apple must have been lobbying for show or misdirection reply FireBeyond 14 hours agoparentprev> Anyway, as far as I can tell, this law defines an independent repair provider as someone with a valid and unexpired certification demonstrating that they have the “technical capabilities and competence necessary to safely, securely and reliably repair consumer electronic equipment” and that the manufacturer is allowed to decide which certifications they trust. What obligates Apple (or anyone) to trust ANY certification? reply chalst 19 hours agoprev-> But it also takes aim at “parts pairing,” or the practice of preventing you from replacing device parts without the approval of a company or its restrictive software. Apple, which routinely uses this practice to try and monopolize repair, lobbied extensively against the Oregon bill. As usual, under the (false) claim that eliminating parts pairing would put public safety and security at risk: -> “We remain very concerned about the risk to consumers imposed by the broad parts-pairing restrictions in this bill,” John Perry, principal secure repair architect for Apple, said at a legislative hearing last month.” There was a time when interpreting the “risk to consumers” as a risk of being prevented from gouging consumers would be cynical. Now I guess something like that occurred to the lawyers. reply hedora 19 hours agoparentIt does sound like this means it's now easier to get a touch screen, embed a tap logger in it, and then swap someone else's screen with it. (Similarly, for the camera module, etc, etc.) A better approach would be to force Apple to allow the device owner to pair parts (third party or not), and for Apple to provide a list of authorized non-OEM parts to anyone that was considering buying a used phone. Also, I wonder what this does to the anti-theft mechanisms. Before touch id, basically nobody set screen passwords, and phones were stolen at extremely high rates. After that, and because a stolen iPhone is marked as such and won't work with Apple services, phone theft dropped to almost zero. If Apple's not allowed to prevent the pairing of the stolen parts in Oregon, I'm guessing it will lead to a black market industry there, where people launder stolen phone parts into refurbished phones by mixing them with parts from broken phones. reply concinds 15 hours agorootparentSee iFixit explain why parts pairing doesn't help reduce theft: https://www.ifixit.com/News/91648/banning-parts-pairing-wont... If Apple disagrees with iFixit and has genuine reasons to believe this will compromise security, they can share their reasoning publicly and let people judge. So far I don't think they have. reply whartung 10 hours agorootparentWell using the Petri dishes of State policy, perhaps someone can track iPhone thefts and see if the impact is imagined or real. reply hedora 5 hours agorootparentprevI like iFixit, but that part of the article is nonsense. They completely ignore the standard argument for parts pairing as a theft deterrent: A shady shop buys a box of broken, non-activation-locked phones, and a box of stolen, working, but activation-locked phones. They install parts from box two on mainboards from box one. This completely defeats activation locks and cell modem blacklisting. The same thing is commonly done for other high-value products. It is what automotive chop shops do (there, a wrecked car with a clean vin + stolen car with dirty vin is turned into a sellable car with a clean vin). reply dns_snek 18 hours agorootparentprevThe point of module-level pairing is to make every module is identifiable, correct? Furthermore, these devices are only usable when connected to the internet. IF their goal was merely to prevent theft, they could achieve that goal by simply blacklisting individual components when a device is reported stolen. Apple knows precise serial numbers of every paired component installed in that device, they just need to host a database of stolen parts that devices could query on every boot and on a set interval. Of course, that's not their true goal, so they treat everyone like thieves in the hopes that they buy a new device instead. reply threeseed 15 hours agorootparentWhat happens if that service is down. Or if a state actor decides to DDOS it to cause havoc. Of course since this process needs to access networking stack etc it's going to be trivial to bypass if the device is jailbroken. Which means that users buying stolen phones need to be informed not to upgrade the OS otherwise their device is bricked. E-waste implications would be staggering. reply dns_snek 15 hours agorootparentNothing happens if the service is down. They could just as easily DDoS other Apple services, most of them would cause actual havoc if they were down - iMessage, iCloud, Apple Pay, Sign in with Apple, etc. If the device is jailbroken then all bets are off regardless? If you can bypass the theft database check, you can bypass the current parts pairing check, too. > E-waste implications would be staggering. Is that meant to support your argument? That's the status quo. reply threeseed 15 hours agorootparentIf the service is down then how would the validation happen. Or if you just allow stolen components to be accepted whilst the phone is unvalidated then state security services will just DDOS the service. They would love to be able to swap out a screen and gain access to the password for journalists, dissidents etc. And you can't bypass the current pairing check since it is happening before the OS is launched. reply dns_snek 15 hours agorootparentI'm sorry but that's just a fairytale. Nobody is going to go through a 10 step process that hinges on someone's phone being stolen and returned without their knowledge while successfully pulling off a DDoS attack against one of the most powerful corporations on the planet that's already facing constant cyber threats. Extremely relevant: https://xkcd.com/538/ They'll just use a 0-day exploit or a $5 wrench. reply tadfisher 16 hours agorootparentprevYou mean like every other device in the world? Should Mazda be forcing me to buy a Mazda OEM or OEM-approved car battery through DRM? It would prevent theft of my car to steal its parts, but it would also have the curiously beneficial side effect of massive profit. reply burnerthrow008 14 hours agorootparentYou mean like how California bans installation of used catalytic converters? And how that law was passed explicitly to cut down on converter theft? You will never guess what California requires to be inscribed on every converter sold in the state. reply saratogacx 9 hours agorootparentIs it this :) ? WARNING: This product can expose you to chemicals including arsenic, which is known to the State of California to cause cancer. For more information, go to www.P65Warnings.ca.gov reply TylerE 16 hours agoparentprevAs someone who was mugged for his phone about a decade ago, I am very very very much in favor of Apple continuing to require this. It is very much pro consumer on the whole. reply chalst 12 hours agorootparentThe mugging scenario shows that there are risks associated with pairing removal, but the suggestion by lcnPylGDnU4H9OF [1] seems to deal with this particular issue. Are there any other risks? [1]: https://news.ycombinator.com/item?id=39707586 (in reply to you) reply lcnPylGDnU4H9OF 15 hours agorootparentprev- Allow to remove the pairing after a timed delay, say 30 minutes - Require authentication including a second factor to initiate and confirm the removal Assuming a mugger isn't likely to sit there for 30 minutes given the chance someone could walk by. If this is the only way to remove the part such that it can be paired with another device, doesn't it solve both problems? I get the feeling Apple is being a bit disingenuous with their \"risk to consumers\" claims. reply TylerE 14 hours agorootparentLook into the iPhone unlock scam networks. They’re using blackmail tactics as it is. Anyway, no, the mugger isn't going to try to unlock it while holding you at gun point. They'll rip and run, and sell it for $20 to a fence who will pass it up the chain. Usually they end up in other countries. Similar in concept to the groups that will take cars stolen in the US, grind off all the VIN plates and other identifying marks, fake paperwork, and then sell them into markets in Africa and the Middle East where the buyers don't ask questions, and government officials are easily and publically bribed. reply BeFlatXIII 11 hours agorootparent> drugs come in; cars go out How feasible would it be to tighten up port security to stop the export of stolen cars? reply sircastor 19 hours agoprevThere’s a lot about right to repair that’s important. One thing I’m curious about is how “certified” correlates with “how we want you to fix it” Apples approach has often been at a module level: replace the logic board, replace the battery, etc. Board repair houses often operate at the component level: replace a damaged chip. In the case of the latter, access to schematics and board layout makes this possible, and I’m sure Apple (and everyone else) has zero interest in making these available. Likewise with custom parts. Modules, but not chips. reply FireBeyond 14 hours agoparent> Apples approach has often been at a module level: replace the logic board, replace the battery, etc. Board repair houses often operate at the component level: replace a damaged chip. With a VERY liberal view of \"module\". I had an MBA with a damaged battery charging circuit. Battery was fine. Computer was fine on AC. Just couldn't get current to battery. Oh, okay, few hundred bucks? \"The estimate to repair is $850...\" Followed rapidly, \"Do you want to take a look at the new MBAs and maybe we look at you getting into something upgraded instead?\" reply UberFly 15 hours agoparentprevI don't understand who hands out the certifications. Apple? reply jetti 18 hours agoprevMost of the talk seems to be around Apple, which makes sense since they were opponents of the bill but I am more interested to see how this affects game console manufacturers. I had a longer post I had typed out about how console manufacturers have prevented non-authorized peripherals in the past with parts pairing and I was curious how that would affect the consoles going forward. I re-read the parts pairing section to make sure I read it correctly and then stumbled upon the section that refers to what the parts pairing restriction does not apply to and it is clearly written out that it does not apply to video game consoles. I find it very interesting that this applies to smart phones but not to video game consoles at all. reply dml2135 15 hours agoparentThe video game console question is very interesting. I think a lot of right-to-repair advocates, right now, are fine with carving out an exception, for a few reasons. One, video game consoles have no pretense to being generalized computing devices. They are more similar to appliances, and while that appliance status is arguable, they are definitely closer to that right now than smartphones. Two, people have nostalgia for video game consoles. They like the packaged nature of it and generally have more good will towards console manufacturers than computer manufacturers (although that part is arguable and may be changing). Three is politics. It's already hard enough to go up against companies like Apple to get these bills passed. You do not want Microsoft, Sony and Nintendo lining up to oppose you as well. With all that said though, there is no reason I can see that the arguments used for right to repair -- that users should have full control over the devices they own -- should not also apply to video game consoles. But doing so would mean that consoles are no different than PCs, and would have huge implications for the industry. Those lines are being blurred already with things like the Steam Deck and I think we're just a few years away from that upheaval, but it hasn't quite happened yet -- hence you see these carve-outs. edit: Upon rereading what I wrote I realize that I may be conflating right-to-repair with regulations around app stores and walled gardens. They're not exactly the same thing, but I do think they touch on the same issues of the meaning of ownership, which is what set me off. reply JohnFen 12 hours agorootparent> One, video game consoles have no pretense to being generalized computing devices. They are more similar to appliances I repair all of my other appliances, why should this particular type of appliance be any different? reply tantalor 13 hours agoprevLetting owners repair their own devices is great and should align well with existing warranties for tech stuff. The other day, a volume button on my bluetooth speaker stopped working and I could tell it was damaged so I opened it up and found the circuit board supporting the button was snapped. When I initially approached the manufacturer for a warranty, they declined because they assumed I had taken the device to a non-approved repair shop, which would void the warranty. When I explained, no I'm the owner (here's the receipt), and I opened it up to check for damage, then they fulfilled the warranty no problem. reply resource_waste 21 hours agoprevMaybe I read too much philosophy, but why doesnt anyone see that when Apple lobbies the government they are doing something measurably immoral(If you subscribe to ethical institution). Neurotransmitters signaling pain happen throughout our human population with these anti-consumer acts. What I can't understand is: If a single human lobbied the government for a selfish cause, they would be an a-hole. Why is this different? I'm all for an equal playing field, lets all go Realpolitik, everyone goes amoral. I just find it odd and a bit frustrating that corporations can commit immoral acts but humans cannot. I imagine this causes inequality. reply Workaccount2 21 hours agoparentKnowing both sides of the argument around this topic and apple, it's not hard to understand why apple has a compelling argument and why it still deserves to be heard. You have to remember that tons of people have near zero tech awareness, and regardless of the laws, will just bring their iPhone to the Apple store if it breaks. The same way people still go to dealers to fix their car, even out of warranty. This means Apple can say \"Hey, give us full control of your phone repairs, and we can kill the theft market for iPhones. You are going to come to us anyway, so might as well let us end iPhone theft too\" So this is why lawmakers still sit down with Apple. And the generous lunches. (Apple DRM'ing all the internal hardware does effectively make stolen iphones completely worthless, in whole or in parts.) -For the record, I have personally written my senator before asking him to support right to repair laws. reply jancsika 18 hours agorootparent> So this is why lawmakers still sit down with Apple. And the generous lunches. I have to say, this sounds trivially false, and I don't think I'm nitpicking. Lawmakers sit down with Apple because Apple has an enormous amount of money and power. After some of these lawmakers sit down for lunch with the lobbyist, perhaps they make the assessment that what Apple is asking for is still doable/ethical/practical/etc. Edit: clarification reply lnxg33k1 21 hours agorootparentprevApple has had the full control on supply, and it hasn’t killed the theft market, the same way having control on anything you can install on a iGadget has killed the scam industry, so if we need to get a phone stolen, might as well make it repairable, how long since we start classifying apple arguments as pure marketing detached from reality? reply dns_snek 18 hours agorootparentprev> (Apple DRM'ing all the internal hardware does effectively make stolen iphones completely worthless, in whole or in parts.) This claim, or to be more specific, the claim that this reduces theft, is missing evidence. Are iPhones really being stolen at a substantially lower rate than other brands, correlating with implementation of these locks? reply tombert 17 hours agorootparentSample size of one, and anecdotal at that, but someone snatched my iPhone out of my hands last July and ran away. I of course reported it stolen to the police and locked it down in FindMy, so in theory I think it's a brick, but I don't think that the fact that it was an iPhone really deterred them from stealing it from me. They actually tried to extort $300 from me to get it back which I of course would not pay, but maybe there's still a market in that for some people? reply pchristensen 17 hours agorootparentprevLots of articles starting 2013 that Activation Lock reduced theft by measurable amounts. I couldn't figure out how to search for articles about drm'ed parts. reply lotsofpulp 21 hours agorootparentprevI wonder what would happen if the law required devices with unpaired parts to be available, but still allowing the sale of devices with paired parts. reply Someone 21 hours agorootparentIf there would be enough unpaired devices in the wild, both types of devices would get stolen (or, worse, robbed, with risk of bodily harm). Thieves would not return the ones that are worthless to them to their owners (why would they take that risk?). So, it would make the protection worthless for those willing to opt-in. And no, making it somewhat easy to check whether a phone is locked down wouldn’t help. Thieves and robbers won’t spend even a second to do that check while still near the crime scene. It would have to be absolutely obvious (say by having orange and black devices) for thieves to not steal the locked-down ones. reply charcircuit 17 hours agorootparentPresumably the unpaired parts would pair after being installed reply Goronmon 21 hours agoparentprev...when Apple lobbies the government they are doing something measurably immoral Would you consider this to be true if the government was on the wrong side of an issue? Say politicians wanted to pass a law that every internet search query needed to reviewed and approved by a human before search results could be displayed. Would it be \"measurably immoral\" for Google to lobby against this law? reply CharlesW 19 hours agoparentprev> Maybe I read too much philosophy… Or maybe not enough? Several philosophical frameworks are perfectly compatible with Apple doing legal things to benefit themselves and their customers. reply ribit 21 hours agoparentprevWhy would you think that replacement part authentication is immoral? Quite in contrary, I’d say it’s an important safety feature for devices that have access to extremely sensitive data. It’s just important that the user has the authorization rights, and not the company. reply goku12 19 hours agorootparentDid anyone mention parts authentication? Regardless, you seem to have answered the question you raised. Concepts like parts authentication and secure boot are great in theory. The immoral part is their implementation. They're designed to wrestle the post-sale control of devices away from the customer and consolidate it in the hands of the manufacturer. Besides the subversion of the concept of ownership itself, this leads to increased cost of device ownership in many different ways. reply jajko 19 hours agorootparentIts a bit like PR stunt for the techies here, while giving master keys to whole cloud to NSA behind the doors. And to claim this will never-ever-pinky-promise-happen we shall show it on some highly publicized FBI case. Maybe there were good intentions in the beginning and path was truly a good one, but not for a nanosecond do I believe they really made it 100%. Phone is simply not a secure device, doesn't matter who manufactures it, period. Neither are all the networks used to connect anywhere. If all this lowers theft its a good strategy overall, but with terrible misguided marketing. reply dns_snek 18 hours agorootparentActual techies are interested in the inner workings and can see past marketing. The group you're referring to is either the wider public that doesn't have the technical expertise to analyze the claims made, or Apple loyalists who uncritically accept and defend Apple's reasoning. If this had anything to do with theft, Apple would only blacklist parts which were inside the device at the time of theft, and otherwise provide \"pairing\" tools for free. reply makeitdouble 21 hours agoparentprevTo play the devil's advocate, the US economic system doesn't have a clear notion of what is selfish or not. One reason why lobbying is allowed in the first place is to let corporations express what is good and bad for them and have their interests in the balance. The assumption is what's good for corporations increases the overall market and benefits society. Doubting that assumption is probably out of the current overtone window[edited] reply throwaway48476 17 hours agoparentprevCompanies are just a trick to make you think they're not made of of people when in fact it's just a mask for decisions made by real fleshy humans. When a company does something immoral it is because a human at the company did something immoral. reply latexr 21 hours agoparentprevYou’re starting from the assumption that no one thinks what Apple is doing is wrong or immoral, but that isn’t true. They have been and continue to be criticised to no end, for this very matter and others, including on Hacker News. Search for Apple and Right to Repair as keywords and see for yourself. Add Louis Rossmann to the mix and you can’t miss it. reply Drakim 21 hours agoparentprevModern capitalism has created a sort of new type of nobility out of corporations, a layer of entities above that of citizens. Just as you say, their actions are not judged by the same standard we'd use for normal people, and they can actually just get away with fines for breaking laws that would land normal people in jail. And actions we'd deep deeply immoral for normal people to engage in are morally acceptable for them. reply sQL_inject 21 hours agorootparentI would refine your statement slightly, it's modern corporatism, not capitalism. We hold corporations in too high of regard and have intermingled what should be free and open exchange of money and goods with governmental power, lobbying. reply Drakim 21 hours agorootparentSure, but names aren't what's important here. It's the logical conclusion to capitalism, even if it's more fitting to call it corporatism. Either the government is big and the corporations lobbies and gets undue influence over how society and it's laws operates though the government, or the government is small and the corporations get undue influence over how society and it's law operates though sheer unregulated societal power. The group who controls your means of getting food, shelter, medicine, and information will have power over your life, and will bend the rules to their advantage using that power. reply willcipriano 21 hours agorootparentprevBoss: \"If you don't like the pay they can find another job\" You: \"I found another job\" Boss: \"What about loyalty? Are you a job hopper?\" You feel bad for some reason. The morality we were taught in preschool largely serves the interests of the elite. Things like \"if someone does you wrong, don't seek revenge, forgive them\" are really helpful messages to have ingrained in society when you are a corporate looter with a name and a address. reply yungporko 21 hours agoparentprevdoes anybody not see it? isn't the issue just that we're powerless to stop it? reply finnjohnsen2 21 hours agoparentprev> Neurotransmitters signaling pain happen throughout our human population I love this formulation reply alistairSH 21 hours agoparentprevPersonally, I'm just jaded. Corporations have acted this way as long as I can remember. I just accept that corporations act like sociopaths and the people running the large corporations are more interested in buying a new yacht than doing the right thing. reply sumtechguy 21 hours agorootparentApple changed in about 1996. When Steve Jobs came back he ended all of that 3rd party business. It was costing his company money. They went from a starting to thrive secondary clone market. To a closed off eco system pretty much overnight. It used to be fairly easy to get info on parts and what to do from Apple. That singular act saved Apple from becoming the next IBM. However, it doomed the rest of us to this weird dynamic of Apple choosing when to help the little guy out or not. Usually it seems to fall on the 'not' side. If Apple had always been this way it would not be as frustrating. reply cqqxo4zV46cp 21 hours agoparentprevThis comes across as teenage thoughts masquerading as philosophy. “Neurotransmitters signalling pain…”. What? Massive citation needed. Words mean things. “People get sad about things, yet things happen” is thought-terminating nonsense. Nobody, not even Tim Cook, considers themselves the Bad Guy. The real world doesn’t work like that. This situation is certainly more nuanced than you’re making it out to be. If you’ve been part of basically any discussion about this topic, you’d see that there are multiple sides. Starting from a position of “my preconceived view is correct and no other view exists” is intellectually dishonest and wilful ignorance. reply dahdum 18 hours agoprevI don’t think bills like this will matter in several years for phones, unless they somehow start forcing manufacturers to design for manual repair. The end game for all these manufacturers is a phone assembled, repaired, and disassembled for recycling entirely by machine. I believe they already do this for the recycling. I support right to repair in general, and I’m not particularly opposed to this bill, but it seems a bit hopeless in the long run. reply dns_snek 18 hours agoparentEven if they don't explicitly design for manual repair, forcing them to publicly provide schematics, individual components (directly or through an agreement with their supplier), and any software required to successfully complete the repair would be a big step in the right direction. reply blkhawk 18 hours agoparentprevlol no thas not the end goal because its a net negative to repair stuff no matter how cheap and easy you can do it. Every repaired last years model is a this years model not sold. Manufacturers try to pretend that they are pro repair but very few are really. reply dahdum 17 hours agorootparentThe end goal is automation and functionality regardless of how difficult it makes manual repair. Almost nobody values manual repair capability when purchasing, so why would manufacturers? Consumers just want easy repair/replace when it happens, and the more resilient the product the less they care. reply blkhawk 18 hours agorootparentprevanybody who has manual manipulators and a manual can repair a manually repairable device. A device that needs special tools to break open or take apart increases the likelyhood that its just tossed and this years new model is bought instead. reply bobim 20 hours agoprevSo next phone is going to be a FairPhone. Some companies are playing the game, vote with your wallet. reply dangus 19 hours agoparentIf they supported the US it would be a lovely option. I’m personally just not buying a smartphone that isn’t being tested on US networks. reply bobim 19 hours agorootparentThe 4 seems to be available. 5 not yet. reply dangus 15 hours agorootparentEven the 4 being available through some kind of weird but official third party is kind of off to me. I really don’t understand how they haven’t prioritized the US market by now. It is probably the market that spends the most on phones. reply anticrymactic 20 minutes agorootparentThe US is also the region with the strongest iOS market dominance. Why compete for 30% of a saturated market, when EU/ME/India is more lucrative and also much closer to the EU based operation. It just makes more sense to focus on domestic markets. Same with many US brands. reply digging 19 hours agoparentprev> vote with your wallet. In other words, do nothing of any impact. reply bobim 19 hours agorootparentit's just that it's the only lever you have at hand that is actually wired to something. reply hedora 19 hours agorootparentPeople on this forum would likely have much more impact by writing + hosting an open-source SPA that replaces a proprietary phone app. Starter project: https://www.weather.gov/documentation/services-web-api reply ChrisArchitect 19 hours agoprev[dupe] Some more discussion last week: https://news.ycombinator.com/item?id=39606952 reply m463 10 hours agoprevI replaced my iphone 8 screen and battery at a third party repair service. What is great is that the repair was done in front of me while I waited. I didn't have to upgrade my OS or backup my data (though I did). It was fast and inexpensive. But... The automatic screen brightness no longer works. I have to manually adjust the brightness (which is sometimes challenging with dim screen in bright sunlight) I think the ambient light sensor must be calibrated, and only by apple. wonder if it can be fixed in oregon? reply mattbillenstein 17 hours agoprevRecently bought a Framework laptop - their mission is easily repairable diy hardware with good software (Linux!) support. Still using an iPhone though - it is a bit crazy how expensive these have gotten and how repairs can be so expensive. reply sashank_1509 10 hours agoprevconsider this, if Apple makes you sign a form that when buying this iPhone, you have no right to repair it on your own or take it to a non authorized repair shop. You must go to Apple to get those repairs. How many consumers do you think would sign this? I reckon a good large majority, at least the number of people buying Apple care now would buy this. This is what kills right to repair, Apple and similar companies obviously lobby against it, but that’s not what kills Right to repair, the fact is regardless of the number of laws passed to support right to repair, until a majority of consumers are willing to repair stuff on their own or with third party repair-ers, right to repair will only matter to the small minority of people who care about it. reply uncletammy 10 hours agoparentApple is not the only hardware manufacturer and there are millions of consumers of non-apple hardware that will gleefully welcome this legislation. I agree that consumers are the real problem but government intervention provides a much needed safety net to keep these oligopolistic practices at bay while users slowly figure out why right to repair matters. We should be happy for any and all help we can get on this front. reply mgarfias 6 hours agoprevI need to bug my neighbor about why he voted no. reply radicaldreamer 17 hours agoprevUntil recently you couldn’t pump your own gas in Oregon reply dependsontheq 16 hours agoprevI think it’s hilarious that a lot of people here talk about the bureaucracy in Europe and then immediately switch to specific state laws regulating technology for one state. reply lupusreal 16 hours agoparentThe people who oppose EU regulation of tech probably also oppose this. The people who support that probably also support this. The mistake you're making is \"everybody except me is one person.\" reply dependsontheq 1 hour agorootparentI didn't argue for or against regulation, my point is that the US regulations structure with specific states defining technological regulation is even more insane than EU regulations on technology. Because common market regulations are clearly defined as EU responsibility. reply lupusreal 8 minutes agorootparentYou implied that people here are being hypocritical for supporting one but criticizing the other. However you never established that it's the same people who have these evidently contradictory opinions. If it's different people having different opinions then there is no \"switching\", no hypocrisy, nothing for you to find hilarious. reply justinzollars 12 hours agoprevEasy solution. Just stop selling new devices in Oregon. reply shkkmo 18 hours agoprevWhat happens if a company refuses to sell in Oregon, can they skirt the law? reply mrinterweb 17 hours agoparentI wonder about this too. People would probably buy through 3rd parties (Amazon, etc). I don't know if the law would restrict Amazon and other vendors to not sell non-compliant devices in Oregon. Thing is, it is not just Oregon. Massachusetts, Colorado, New York, Minnesota, Maine and California all have right to repair laws. It is not possible for companies to remain competitive and not sell in those states. reply lotsofpulp 17 hours agoparentprevOregon’s laws can only apply to products sold in Oregon. reply pcdoodle 18 hours agoprev [–] Apple behaviour has invoked the \"pause button\" on my purchasing of new hardware from them. Nobody wants to build on your platform if you're a tyrant. reply RussianCow 17 hours agoparent [–] > Nobody wants to build on your platform if you're a tyrant. [citation needed] In practice, I think people mostly follow the money and idealism barely factors into it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Oregon has passed a right-to-repair law despite Apple's opposition, setting certification standards for independent repair providers.",
      "Debate ensues on how this law affects the repair industry, amidst worries about manufacturers controlling certification and analyzing the legal wording.",
      "The discussions also touch on Apple's stance, security features, e-waste effects, and ethical dilemmas in technology repair policies and lobbying strategies."
    ],
    "points": 547,
    "commentCount": 140,
    "retryCount": 0,
    "time": 1710416556
  },
  {
    "id": 39706968,
    "title": "Scaling Success: Figma's Postgres Sharding Revolution",
    "originLink": "https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/",
    "originBody": "March 14, 2024 How Figma’s databases team lived to tell the scale Sammy SteeleSoftware Engineer, Figma Inside Figma Engineering Infrastructure Table of contents Background Exploring our options Our unique approach Implementation Reflections and the road ahead Our nine month journey to horizontally shard Figma’s Postgres stack, and the key to unlocking (nearly) infinite scalability. Vertical partitioning was a relatively easy and very impactful scaling lever that bought us significant runway quickly. It was also a stepping stone on the path to horizontal sharding. Figma’s database stack has grown almost 100x since 2020. This is a good problem to have because it means our business is expanding, but it also poses some tricky technical challenges. Over the past four years, we’ve made a significant effort to stay ahead of the curve and avoid potential growing pains. In 2020, we were running a single Postgres database hosted on AWS’s largest physical instance, and by the end of 2022, we had built out a distributed architecture with caching, read replicas, and a dozen vertically partitioned databases. We split groups of related tables—like “Figma files” or “Organizations”—into their own vertical partitions, which allowed us to make incremental scaling gains and maintain enough runway to stay ahead of our growth. Read more about how we reduced potential instability by scaling to multiple databases. Despite our incremental scaling progress, we always knew that vertical partitioning could only get us so far. Our initial scaling efforts had focused on reducing Postgres CPU utilization. As our fleet grew larger and more heterogeneous, we started to monitor a range of bottlenecks. We used a combination of historical data and load-testing to quantify database scaling limits from CPU and IO to table size and rows written. Identifying these limits was crucial to predicting how much runway we had per shard. We could then prioritize scaling problems before they ballooned into major reliability risks. The data revealed that some of our tables, containing several terabytes and billions of rows, were becoming too large for a single database. At this size, we began to see reliability impact during Postgres vacuums, which are essential background operations that keep Postgres from running out of transaction IDs and breaking down. Our highest write tables were growing so quickly that we would soon exceed the maximum IO operations per second (IOPS) supported by Amazon’s Relational Database Service (RDS). Vertical partitioning couldn’t save us here because the smallest unit of partitioning is a single table. To keep our databases from toppling, we needed a bigger lever. Scaffolding for scale We outlined a number of goals and must-haves to tackle short-term challenges while setting us up for smooth long-term growth. We aimed to: Minimize developer impact: We wanted to handle the majority of our complex relational data model supported by our application. Application developers could then focus on building exciting new features in Figma instead of refactoring large parts of our codebase. Scale out transparently: As we scale in the future, we don’t want to have to make additional changes at the application layer. This means that after any initial upfront work to make a table compatible, future scale-outs should be transparent to our product teams. Skip expensive backfills: We avoided solutions that involve backfilling large tables or every table at Figma. Given the size of our tables and Postgres throughput constraints, these backfills would have taken months. Make incremental progress: We identified approaches that could be rolled out incrementally as we de-risked major production changes. This reduced the risk of major outages and allowed the databases team to maintain Figma’s reliability throughout the migration. Avoid one-way migrations: We maintained the ability to roll back even after a physical sharding operation is completed. This reduced the risk of being stuck in a bad state when unknown unknowns occur. Maintain strong data consistency: We wanted to avoid complex solutions like double-writes that are challenging to implement without taking downtime or compromising on consistency. We also wanted a solution that would allow us to scale out with near-zero downtime. Play to our strengths: Since we were operating under tight deadline pressure, whenever possible, we favored approaches that could be rolled out incrementally on our fastest growing tables. We aimed to leverage existing expertise and technology. Exploring our options There are many popular open source and managed solutions for horizontally sharded databases that are compatible with Postgres or MySQL. During our evaluation, we explored CockroachDB, TiDB, Spanner, and Vitess. However, switching to any of these alternative databases would have required a complex data migration to ensure consistency and reliability across two different database stores. Additionally, over the past few years, we’ve developed a lot of expertise on how to reliably and performantly run RDS Postgres in-house. While migrating, we would have had to rebuild our domain expertise from scratch. Given our very aggressive growth rate, we had only months of runway remaining. De-risking an entirely new storage layer and completing an end-to-end-migration of our most business-critical use cases would have been extremely risky on the necessary timeline. We favored known low-risk solutions over potentially easier options with much higher uncertainty, where we had less control over the outcome. NoSQL databases are another common scalable-by-default solution that companies adopt as they grow. However, we have a very complex relational data model built on top of our current Postgres architecture and NoSQL APIs don’t offer this kind of versatility. We wanted to keep our engineers focused on shipping great features and building new products instead of rewriting almost our entire backend application; NoSQL wasn’t a viable solution. Given these tradeoffs, we began to explore building a horizontally sharded solution on top of our existing vertically partitioned RDS Postgres infrastructure. It didn’t make sense for our small team to re-implement a generic horizontally sharded relational database in-house; in doing so, we’d be competing with tools built by the likes of large open source communities or dedicated database vendors. However, because we were tailoring horizontal sharding to Figma’s specific architecture, we could get away with providing a much smaller feature set. For example, we chose not to support atomic cross-shard transactions because we could work around cross-shard transaction failures. We picked a colocation strategy that minimized the changes required at the application layer. This allowed us to support a subset of Postgres that was compatible with the majority of our product logic. We also were able to easily maintain backwards compatibility between sharded and unsharded postgres. If we ran into unknown unknowns, we could easily roll back to unsharded Postgres. The path to horizontal sharding Even with these narrower requirements, we knew horizontal sharding would be our largest and most complex database project to date. Luckily, our incremental scaling approach over the past few years bought us the runway to make this investment. In late 2022, we set out to unlock nearly infinite database scalability, and horizontal sharding—the process of breaking up a single table or group of tables and splitting the data across multiple physical database instances—was the key. Once a table is horizontally sharded at the application layer, it can support any number of shards at the physical layer. We can always scale out further by simply running a physical shard split. These operations happen transparently in the background, with minimal downtime and no application level changes required. This capability would allow us to stay ahead of our remaining database scaling bottlenecks, removing one of the last major scaling challenges for Figma. If vertical partitioning let us accelerate to highway speeds, horizontal sharding could remove our speed limits and let us fly. Vertical partitioning Horizontal sharding Horizontal sharding was an order of magnitude more complex than our previous scaling efforts. When a table is split across multiple physical databases, we lose many of the reliability and consistency properties that we take for granted in ACID SQL databases. For example: Certain SQL queries become inefficient or impossible to support. Application code must be updated to provide enough information to efficiently route queries to the correct shard(s) wherever possible. Schema changes must be coordinated across all shards to ensure the databases stay in sync. Foreign keys and globally unique indexes can no longer be enforced by Postgres. Transactions now span multiple shards, meaning Postgres can no longer be used to enforce transactionality. It is now possible that writes to some databases will succeed while others fail. Care must be taken to ensure product logic is resilient to these “partial commit failures” (imagine moving a team between two organizations, only to find half their data was missing!). We knew achieving full horizontal sharding would be a multi-year effort. We needed to de-risk the project as much as possible while delivering incremental value. Our first goal was to shard a relatively simple but very high traffic table in production as soon as possible. This would prove the viability of horizontal sharding while also extending our runway on our most loaded database. We could then continue building additional features as we worked to shard more complex groups of tables. Even the simplest possible feature set was still a significant undertaking. End to end, it took our team roughly nine months to shard our first table. Our unique approach Our horizontal sharding work built on what many others do, but with some unusual design choices. Here are a few highlights: Colos: We horizontally sharded groups of related tables into colocations (which we affectionately call “colos”), which shared the same sharding key and physical sharding layout. This provided a friendly abstraction for developers to interact with horizontally sharded tables. Logical sharding: We separated the concept of “logical sharding” at the application layer from “physical sharding” at the Postgres layer. We leveraged views to perform a safer and lower cost logical sharding rollout before we executed a riskier distributed physical failover. DBProxy query engine: We built a DBProxy service that intercepts SQL queries generated by our application layer, and dynamically routes queries to various Postgres databases. DBProxy includes a query engine capable of parsing and executing complex horizontally sharded queries. DBProxy also allowed us to implement features like dynamic load-shedding and request hedging. Shadow application readiness: We added a “shadow application readiness” framework capable of predicting how live production traffic would behave under different potential sharding keys. This gave product teams a clear picture of what application logic needed to be refactored or removed to prepare the application for horizontal sharding. Full logical replication: We avoided having to implement “filtered logical replication” (where only a subset of data is copied to each shard). Instead, we copied over the entire dataset and then only allowed reads/writes to the subset of data belonging to a given shard. Our sharding implementation One of the most important decisions in horizontal sharding is which shard key to use. Horizontal sharding adds many data model constraints that revolve around the shard key. For example, most queries need to include the shard key so that the request can be routed to the right shard. Certain database constraints, like foreign keys, only work when the foreign key is the sharding key. The shard key also needs to distribute data evenly across all shards to avoid hotspots that cause reliability issues or impact scalability. Figma lives in the browser, and many users can collaborate in parallel on the same Figma file. This means that our product is powered by a fairly complex relational data model capturing file metadata, organization metadata, comments, file versions, and more. We considered using the same sharding key for every table, but there was no single good candidate in our existing data model. To add a unified sharding key, we would have had to create a composite key, add the column to every table’s schema, run expensive backfills to populate it, and then substantially refactor our product logic. Instead, we tailored our approach to Figma’s unique data model and selected a handful of sharding keys like UserID, FileID, or OrgID. Almost every table at Figma could be sharded using one of these keys. We introduced the concept of colos, which provide a friendly abstraction for product developers: Tables within a colo support cross-table joins and full transactions when restricted to a single sharding key. Most application code already interacted with the database this way, which minimized the work required by application developers to make a table ready for horizontal sharding. Tables sharded by UserID and by FileID are each colocated together Once we picked our sharding keys, we needed to ensure that there would be an even distribution of data across all backend databases. Unfortunately, many of the sharding keys that we had picked used auto-incrementing or Snowflake timestamp-prefixed IDs. This would have resulted in significant hotspots where a single shard contained the majority of our data. We explored migrating to more randomized IDs, but this required an expensive and time-consuming data migration. Instead, we decided to use the hash of the sharding key for routing. As long as we picked a sufficiently random hash function, we would ensure a uniform distribution of data. One downside of this is that range-scans on shard keys are less efficient, since sequential keys will be hashed to different database shards. However, this query pattern is not common in our codebase, so it was a trade-off we were willing to live with. The “logical” solution To de-risk the horizontal sharding rollout, we wanted to isolate the process of preparing a table at the application layer from the physical process of running a shard split. To do this, we separated “logical sharding” from “physical sharding.” We could then decouple the two parts of our migration to implement and de-risk them independently. Logically sharding gave us confidence in our serving stack with a low-risk, percentage-based rollout. Rolling back logical sharding when we found bugs was a simple configuration change. Rolling back a physical shard operation is possible, but it requires more complex coordination to ensure data consistency. Once a table is logically sharded, all reads and writes will act as if the table is already horizontally sharded. From a reliability, latency, and consistency perspective, we appear to be horizontally sharded, even though the data is still physically located on a single database host. When we are confident that logical sharding is working as expected, we then perform the physical sharding operation. This is the process of copying the data from a single database, sharding it across multiple backends, then re-routing read and write traffic through the new databases. Four logical shards on two physical shards The query engine that could To support horizontal sharding, we had to significantly re-architect our backend stack. Initially, our application services talked directly to our connection pooling layer, PGBouncer. However, horizontal sharding required much more sophisticated query parsing, planning, and execution. To support this, we built out a new golang service, DBProxy. DBProxy sits between the application layer and PGBouncer. It includes logic for load-shedding, improved observability, transaction support, database topology management, and a lightweight query engine. The query engine is the heart of DBProxy. Its main components are: A query parser reads SQL sent by the application and transforms it into an Abstract Syntax Tree (AST). A logical planner parses the AST and extracts the query type (insert, update, etc) and logical shard IDs from the query plan. A physical planner maps the query from logical shard IDs to physical databases. It rewrites queries to execute on the appropriate physical shard. Query parser Logical planner Physical planner Think of “scatter-gather” like a database-wide game of hide-and-seek: You send out your query to every shard (scatter), then piece together answers from each (gather). Fun, but overdo it, and your speedy database starts feeling more like a snail, especially with complex queries. Some queries are relatively easy to implement in a horizontally sharded world. For example, single-shard queries are filtered to a single shard key. Our query engine just needs to extract the shard key and route the query to the appropriate physical database. We can “push down” the complexity of the query execution into Postgres. However, if the query is missing a sharding key, our query engine has to perform a more complex “scatter-gather.” In this case, we need to fan out the query to all shards (the scatter phase) and then aggregate back results (the gather phase). In some cases, like complex aggregations, joins, and nested SQL, this scatter-gather can be very complex to implement. Additionally, having too many scatter-gathers would impact horizontal sharding scalability. Because the queries have to touch every single database, each scatter-gather contributes the same amount of load as it would if the database was unsharded. If we supported full SQL compatibility, our DBProxy service would have begun to look a lot like the Postgres database query engine. We wanted to simplify our API to minimize DBProxy’s complexity, while also reducing the work required for our application developers, who would have to re-write any unsupported queries. To determine the right subset, we built out a “shadow planning” framework, which allowed users to define potential sharding schemes for their tables and then run shadow the logical planning phase on top of live production traffic. We logged the queries and associated query plans to a Snowflake database, where we could run offline analysis. From this data, we picked a query language that supported the most common 90% of queries, but avoided worst-case complexity in our query engine. For example, all range scan and point queries are allowed, but joins are only allowed when joining two tables in the same colo and the join is on the sharding key. A view of the future We then needed to figure out how to encapsulate our logical shards. We explored partitioning the data using separate Postgres databases or Postgres schemas. Unfortunately, this would have required physical data changes when we logically sharded the application, which was just as complex as doing the physical shard split. Instead, we chose to represent our shards with Postgres views. We could create multiple views per-table, each corresponding to the subset of data in a given shard. This would look like: CREATE VIEW table_shard1 AS SELECT * FROM table WHERE hash(shard_key) >= min_shard_range AND hash(shard_key) < max_shard_range). All reads and writes to the table would be sent through these views. By creating sharded views on top of our existing unsharded physical databases, we could logically shard before we performed any risky physical reshard operations. Each view is accessed via its own sharded connection pooler service. The connection poolers still point to the unsharded physical instance, which gives the appearance of being sharded. We were able to de-risk the rollout of sharded reads and writes gradually via feature flags in the query engine and roll back at any time within seconds by just rerouting traffic back to the main table. By the time we ran our first reshard, we were confident in the safety of the sharded topology. By creating multiple views in an unsharded database, we can query the views as if the data was already physically sharded. Of course, relying on views also introduced added risks. Views add a performance overhead and in some cases could fundamentally change how the Postgres query planner optimizes queries. To validate that approach, we collected a query corpus of sanitized production queries and ran load tests with and without views. We were able to confirm that views would only add a minimal performance overhead in most cases, and less than 10% in the worst cases. We also built out a shadow reads framework which could send all live read traffic through views, comparing the performance and correctness of view versus non-view queries. We were then able to confirm that views were a viable solution with minimal performance impact. Tackling our topology To perform query routing, DBProxy has to understand the topology of our tables and physical databases. Because we had separated the concept of logical versus physical sharding, we needed a way to represent these abstractions within our topology. For example, we need to be able to map a table (users) to its shard key (user_id). Similarly, we needed to be able to map a logical shard ID (123) to the appropriate logical and physical databases. With vertical partitioning, we relied on a simple, hard-coded configuration file that mapped tables to their partition. However, as we moved towards horizontal sharding, we required something more sophisticated. Our topology would change dynamically during shard splits and DBProxy needed to quickly update its state to avoid routing requests to the wrong database. Because every change to topology is backwards compatible, these changes are never in the critical path for our site. We built out a database topology that encapsulated our complex horizontal sharding metadata and could deliver real-time updates in under a second. Having a separate logical and physical topology allowed us to also simplify some of our database management. For example, in our non-production environments, we can keep the same logical topology as production, but serve the data from many fewer physical databases. This saves costs and reduces complexity without having too many changes across environments. The topology library also allowed us to enforce invariants across our topology (e.g. every shard ID should be mapped to exactly one physical database) that were critical to maintaining the correctness of our system as we built out horizontal sharding. The physical sharding operation Once a table is ready for sharding, the last step is the physical failover from unsharded to sharded databases. We were able to reuse much of the same logic for horizontal sharding, but there were a few notable differences: Instead of moving data from 1 to 1 database, we were going from 1 to N. We needed to make the failover process resilient to new failure modes where the sharding operation could succeed on only a subset of our databases. Still, many of the riskiest components had already been de-risked during vertical partitioning. We were able to move much faster towards our first physical sharding operation than would have otherwise been possible. We’ve come a long way When we started this journey, we knew that horizontal sharding would be a multi-year investment into Figma’s future scalability. We shipped our first horizontally sharded table in September 2023. We successfully failed over with only ten seconds of partial availability on database primaries and no availability impact on replicas. We saw no regressions in latency or availability after sharding. Since then we’ve been tackling relatively simple shards from our highest write rate databases. This year, we’ll shard increasingly complex databases, which have dozens of tables and thousands of code call-sites. To remove our last scaling limits and truly take flight, we will need to horizontally shard every table at Figma. A fully horizontally sharded world will bring many other benefits: improved reliability, cost savings, and developer velocity. Along the way, we’ll need to solve all of these problems: Support for horizontally sharded schema updates Globally unique ID generation for horizontally sharded primary keys Atomic cross-shard transactions for business critical use-cases Distributed globally unique indexes (currently unique indexes are only supported on indexes including the sharding key) An ORM model that increases developer velocity and is seamlessly compatible with horizontal sharding Fully automated reshard operations that can run shard splits with the click of a button Once we’ve bought ourselves sufficient runway, we will also reassess our original approach of in-house RDS horizontal sharding. We started this journey 18 months ago with extremely tight timeline pressure. NewSQL stores have continued to evolve and mature. We will finally have bandwidth to reevaluate the tradeoffs of continuing down our current path versus switching to an open source or managed solution. We’ve made a lot of exciting progress on our horizontal sharding journey, but our challenges are just beginning. Stay tuned for more deep dives into different parts of our horizontal sharding stack. If you’re interested in working on projects like this, please reach out! We’re hiring. We couldn’t have shipped horizontal sharding without these current and former databases team members: Anna Saplitski, David Harju, Dinesh Garg, Dylan Visher, Erica Kong, Gordon Yoon, Gustavo Mezerhane, Isemi Ekundayo, Josh Bancroft, Junhson Jean-Baptiste, Kevin Lin, Langston Dziko, Maciej Szeszko, Mehant Baid, Ping-Min Lin, Rafael Chacon Vivas, Roman Hernandez, Tim Goh, Tim Liang, and Yiming Li. We’d also like to thank all of our cross-functional partner teams, especially Amy Winkler, Braden Walker, Esther Wang, Kat Busch, Leslie Tu, Lin Xu, Michael Andrews, Raghav Anand, and Yichao Zhao. Sammy Steele is the tech lead for Figma’s databases team. She previously worked at Dropbox, where she built out their petabyte-scale metadata storage and search systems. Subscribe to Figma’s editorial newsletter Enter email I agree to opt-in to Figma's mailing list. By clicking “Submit” you agree to our TOS and Privacy Policy. Related articles The growing pains of database architecture By Tim Liang How the Figma infrastructure team reduced potential instability by scaling to multiple databases. Inside Figma Infrastructure Engineering Keeping Figma fast By Slava Kim, Laurel Woods When a laptop crashed in an empty office, we knew it was time to overhaul our performance testing framework. Inside Figma Quality & performance Engineering Server-side sandboxing: Containers and seccomp By Hongyi Hu, Max Serrano Containers and secure computing mode (seccomp) are sandboxing primitives that offer a lighter weight alternative to virtual machines (VMs). Here we cover the differences between them, and how we use both at Figma to achieve security isolation. Inside Figma Security Engineering Create and collaborate with Figma Get started for free",
    "commentLink": "https://news.ycombinator.com/item?id=39706968",
    "commentBody": "How Figma's databases team lived to tell the scale (figma.com)516 points by pinser98 16 hours agohidepastfavorite202 comments thekhatribharat 11 hours ago1. They mention that the largest tables ran into several TBs, and they would have soon topped the max IOPS supported by RDS. RDS for PostgreSQL peaks at 256,000 IOPS for a 64 TB volume. For a multi-AZ setup, this costs ~$70K/mo. 2. Let's assume the final outcome was a 5-way shard with each shard supporting ~50,000 IOPS and ~12 TB data. For a multi-AZ setup, this costs ~$100K/mo. 3. It took 9 months to shard their first table. Since it required application changes as well, let's assume this was 9mo * 20 work days/mo * (3 DB engineers + 2 app engineers) = 900 work days. Even at $100K avg. annual pay for an engineer, this is ~$400K. 4. A PostgreSQL-compatible NewSQL like YugabyteDB should cost ~$15K/mo to match top-of-the-line RDS performance. So Figma spent ~25x ($400K/$15K) to implement horizontal sharding in-house, and is still on RDS which costs ~6x ($100K/$15K) reply bastawhiz 9 hours agoparent> A PostgreSQL-compatible NewSQL like YugabyteDB should cost ~$15K/mo to match top-of-the-line RDS performance. \"to match\" is doing a lot of work here. It's extremely unwise that a \"compatible\" database will have the same performance characteristics and no performance cliffs. > So Figma spent ~25x ($400K/$15K) They nearly got acquired for $20B, I don't think they give a hoot about 400K if it means keeping their stack the same and getting to keep all of the existing organizational knowledge about how to keep the thing online. reply __float 8 hours agorootparentThey're also using sticker pricing, which as we know is likely far from what they actually paid. (And the rest of the argument sounds a lot like our former employer with their...choice of document DB :) which I'll defend too!) reply thanksgiving 8 hours agorootparentprevThat’s the problem with case studies, isn’t it? What works for one company in one industry might be a death sentence for another organization with slimmer margins… reply weitendorf 7 hours agoparentprevFigma, worth $10billion, was migrating what seems like their core production data. They probably didn't want to bet the company on a comparatively small software vendor like Yugabyte. Most likely the engineering cost was much much higher than your quotes, but still insignificant compared to the potential risks. And migrating from RDS to not-RDS could easily not have been cheap in engineering time either, depending on how much software they've built around it. reply jimbokun 9 hours agoparentprevPast a certain data size, migrations are always a nightmare. For a much longer time than what you initially estimated, you are managing two systems with all the related operational costs and complexity, as well as all of the IOPs and bandwidth migrating the data. I imagine scaling out RDS instead mitigated a lot of those costs. reply avianlyric 10 hours agoparentprevTheir rationale for this choice is covered in the article somewhat extensively near the top. > Additionally, over the past few years, we’ve developed a lot of expertise on how to reliably and performantly run RDS Postgres in-house. While migrating, we would have had to rebuild our domain expertise from scratch. Given our very aggressive growth rate, we had only months of runway remaining. De-risking an entirely new storage layer and completing an end-to-end-migration of our most business-critical use cases would have been extremely risky on the necessary timeline. We favored known low-risk solutions over potentially easier options with much higher uncertainty, where we had less control over the outcome. TL;DR they were working in a short timeline, with a limited team size, and wanted to minimise any risks to the business. Clearly cost is an issue for Figma, but downtime, or worse data loss, would have a ginormous impact on their business and potential future growth. If your product is already profitable, your user base growing fast, and with your ARR. Why would risk that growth and future ARR just to save a few $10Ks a month? A very low risk DB migration that lets you keep scaling and raking in more money, is way better than a high risk migration that might save some cash in the long term, but also risks killing your primary business if it goes wrong. reply brigadier132 10 hours agorootparentOk, what risk? Cockroachdb is already proven technology and costs marginally more (if you use their serverless setup, it's free until you hit real scale). At the startups I've been at that hit scale, scaling sql was always a massive undertaking and affected product development on every single time. If you don't want downtime, don't use databases that require downtime to do a migration? Netflix, roblox, every single online gambling website all use cockroachdb. reply martin-adams 10 hours agorootparentSounds like their discomfort was in the migration path to 'any other database' alongside not having the experience with another database to mitigate any unknown unknowns. > During our evaluation, we explored CockroachDB, TiDB, Spanner, and Vitess. However, switching to any of these alternative databases would have required a complex data migration to ensure consistency and reliability across two different database stores. reply thesz 2 hours agorootparent> ensure consistency and reliability across two different database stores. This is main known known. And this is hard thing to attain. My favorite story on that is testing of tendermint consensus implementation [1]. The testing process found a way to break the consensus and the reason was that protocol implementation and KV store controlled by protocol used different databases. [1] https://jepsen.io/analyses/tendermint-0-10-2 reply kamikaz1k 10 hours agorootparentprevNever used cockroach so pardon my ignorance, but are there no operational challenges with running/using them? Or are they the same challenges? And how compatible is it from an application developer perspective? reply brigadier132 10 hours agorootparentThe managed service is hassle free and it's auto sharded so you don't have traditional scaling issues. You do need to think about how your index choices spread writes and reads on the cluster to avoid hotspots. It's almost completely compatible with postgres wire protocol but it doesn't support things like extensions for the most part. reply MarkMarine 8 hours agorootparentprevThere are TONS of operational issues running cockroach. At the last company I was at cockroach was probably over used as a magical way to run multiple DCs and keep things consistent without high developer overhead, but it was #1 source of large outages. So much so that we’d run a cockroach segmented out for a single microservice to limit the blast radius when it eventually failed. That and its comically more expensive than Postgres, if you think IOPs are expensive wait till you see the service contract. reply jamra 10 hours agorootparentprevCRDB is Postgres compliant so the wire protocol and SQL syntax is all Postgres. It should be a 1 to 1. reply jimbokun 9 hours agorootparentAre all the corresponding latencies for every query one to one too? reply hinkley 8 hours agorootparentIn ye olden times I used to stop bosses from throwing away the slowest machine we had, and try to get at least one faster machine. It’s still somewhat the case, but at the time the world was rotten with concurrent code that only worked because an implicit invariant (almost) always held. One that was enforced by the relative time or latency involved with two competing tasks. Get new motherboards or storage or memory and that invariant goes from failing only when the exact right packet loss happens, to failing every day, or hour, or minute. Yes, it’s a bug, but it wasn’t on your radar and the system was trucking along yesterday and now everything is on fire. The people who know this think the parent is a very interesting question. The people who don’t, tend to think it’s a non sequitur. reply chikitabanana 10 hours agoparentprevbhai, use the western numbering system, for clarity's sake. Thanks for the summary reply bjornsing 15 hours agoprevOne thought that comes up: Wouldn’t it be easier to have each customer in their own (logical) database? I mean, you don’t need transactions across different customers, right? So you’re essentially solving a harder problem than the one you’ve got. Not sure postgres (logical) databases would scale that well, but don’t see a principal reason why it couldn’t. Has anyone explored this further? reply tharkun__ 11 hours agoparentYes, we've been doing that at my place basically since the start. Each tenant is a schema in postgres. Works perfectly fine on the one hand, i.e. your tables don't grow to 'infinity' just because you're adding more and more tenants. If there's a particular tenant that has lots of data, only that tenant's indexes and tables grow huge and become slower because of that particular reason etc. If a tenant leaves, you keep the schema around for some time, so they can come back and then at some point you just drop the schema! It does mean having to upgrade each schema individually, which also makes it both easier and harder. Easier because the tables are smaller, so any schema changes that require things like say a table lock, are locking for a smaller amount of time and won't affect more than the one tenant at a given time. It also means that you can get into an inconsistent state of course, where some of your tenants have all the latest DB upgrades, while it failed on another subset. At some point Postgres's internal tables become a bit of a \"problem\", as you want to run as many of these updates in parallel as you can for speed, which could lead to contention on Postgres' administrative side. You'll also still need to shard across multiple actual RDS instances, because you still have many tenants running against a single physical piece of hardware that will show its limitations if too many large or active tenants happen to be on the same shard. And then you have the problem of keeping a record of which physical RDS instance (i.e. shard) the tenant is on. Your application code will need to look that up (and cache that info for some time ;)) and you have some choice there as well. I.e. do you shard those as well and juggle load balancing as basically a 1:1 mapping to shards or do you have your application layer connect to all database shards and handle any tenants? One is more complicated I would say while the other could run out of connections depending on how you need to scale the application layer and what kind of RDS instance you have. reply neeleshs 9 hours agorootparentThis is a very common approach and scales quite well. I worked for a company that had thousands of customers and each had their own schema. A single master database that kept track of which customer is on what physical db cluster, and this was globally replicated (EU,ANZ, NA). Certainly needs a bunch of tooling, but worked well. Some apps were stateless and could connect to any physical cluster. Some others were sticky and only connected to a subset. Similar architecture in my current company as well and we serve nearly a thousand customer instances served across 4 physical clusters. We do have some basic tools to provision new customers on the emptiest cluster, move customers from one cluster to another etc reply Syntaf 10 hours agorootparentprevI recall a popular rails gem[1] once upon a time that provided multi-tenancy via postgres schemas. As it turns out, even the company the initially developed the gem ended up ditching the approach due to some of the issues you outlined above. Managing separate schemas feels like one of those nefarious decisions that make things simple _initially_ but get you into a world of hurt when you need to scale. The company is since defunct but they have an article where they discuss why they ditched the approach [2], TL;DR it's too difficult to maintain and scale [1] https://github.com/influitive/apartment#tenants-on-different... [2] https://web.archive.org/web/20201108191323/https://influitiv... reply cqqxo4zV46cp 10 hours agorootparentThis is the conclusion I came to when faced with the same quandary. reply tharkun__ 9 hours agorootparentprevLet's address these one by one based on our experience (the part of the journey that I've been there at least as the implementation of the solution predates me but I live with it). Migrations Things slow down past 100 [...] No one wants friction in their deployment process, especially as we’re attempting to deploy daily or more frequently. We have more than a thousand schemas per database shard. That is why I said you want things to run in parallel for speed, yes. However, we deploy way more than daily and it's not really an issue in that sense. Schema updates are not that frequent but you do of course need to take into account that you will have to make the schema updates as a separate PR, wait and check that it worked and then deploy your actual change making use of the changes in application code. Which honestly isn't much different from ensuring that your BE changes and FE changes are compatible or made in the right order so that you don't get failed requests because an old FE happens to call a new BE node or vice versa :shrug: Database resources \"Need too large of an instance\" r3.4xl We seem to have m5.large. That has 2 virtual cores. Some r5.larges etc. Their r3.4xl has 16?! So not sure what kind of load pattern they have :shrug: Client Memory Bloat Ruby ActiveRecord something Yeah well, we don't have that, so not sure what to say :shrug: Definitely not a generalized reason to say \"can't do, is too complicated for scaling\". Record Identification One major drawback of schemas as tenants is that your sequence generators will reside independently in each tenant. I respectfully disagree. This is a great advantage because it means just because you get more and more tenants (some of which churn and you throw away their data anyway) your identifiers don't grow past limits as easily. In fact, in most cases the identifiers never run out of runway at all. They complain about \"what if you need to join this data somewhere else, then you need to also add the tenantId\". Yeah, so? We also have a data warehouse we we do just that. Not a problem at all. We also have other services than our main one, which do use different database technologies where we use tenant as part of the key (for loads that actually benefit from being in a NoSQL type DB) and there we do not have sharding other than what the NoSQL database does by itself so to speak by dividing the keyspace. That's it. End of article. Basically, we have none of these issues. They don't mention their actual scale. The only number they mention is the \"hundreds of schemas\". We have more than ten times that number per physical shard and have tens of thousands of tenants total. Again :shrug: reply nightpool 8 hours agorootparentThat's still 2 orders of magnitude smaller than the scale of Figma—they would need to somehow manage millions of Postgres schemas. I don't think it's a realistic possibility reply aledalgrande 6 hours agorootparentprev> a single physical piece of hardware that will show its limitations if too many large or active tenants happen to be on the same shard Shopify has pretty much mastered this https://shopify.engineering/mysql-database-shard-balancing-t... reply jerbear4328 13 hours agoparentprevActually, Apple does this for iCloud! They use FoundationDB[1] to store billions of databases, one for each user (plus shared or global databases). See: https://read.engineerscodex.com/p/how-apple-built-icloud-to-... Discussed on HN at the time: https://news.ycombinator.com/item?id=39028672 [1]: https://github.com/apple/foundationdb https://en.wikipedia.org/wiki/FoundationDB reply danpalmer 13 hours agorootparent> store billions of databases This is sort of true and sort of false. When you think of a \"database\", if you're thinking of a Postgres database, you're way off the reality of what \"database\" means here. FoundationDB has a concept called \"layers\", and essentially they have created a layer that looks like a separate database on top of a layer that is separately encrypted groups of keys. They don't have billions of FoundationDB clusters or machines, and at the infra level, i.e. the instances of the FoundationDB server software, it's unaware of individual \"databases\". A closer analogy would be like having billions of tables, but even that isn't accurate because in relational databases a table is usually a notably more static concept than data in a table. The closest analogy would be that each of the billions of users has a bunch of rows with a user-id field on them, and there's a proxy that filters everything such that you can view the table as if it only had one user's data in it. To be clear, FoundationDB is awesome and Apple have done some really cool stuff with it, but it's less crazy/impressive than it sounds. reply dexwiz 12 hours agorootparentThis sounds like a pretty standard multitenant datastore. Everything has a user/group Id on it, and a logical layer that locks a connection to a specific group. reply pests 8 hours agorootparentFoundationDB is really just a set of structures and tools to build any type of database you want on top of a solid foundation. \"FoundationDB decouples its data storage technology from its data model. FoundationDB’s core ordered key-value storage technology can be efficiently adapted and remapped to a broad array of rich data models. Using indexing as an example, FoundationDB’s core provides no indexing and never will. Instead, a layer provides indexing by storing two kinds of key-values, one for the data and one for the index.\" https://apple.github.io/foundationdb/layer-concept.html Then existing standard layers like the Record layer, providing \"(very) roughly equivalent to a simple relational database\" providing structured types, index, complex types, queries, etc. https://github.com/FoundationDB/fdb-record-layer Or one for documents, which speaks the MongoDB wire protocol https://github.com/FoundationDB/fdb-document-layer reply danpalmer 11 hours agorootparentprevYeah, the advantage or difference here is that these \"layers\" are a common design pattern with FoundationDB, several ship in FDB by default, and you're encouraged to make more, so the database certainly has better support than just adding a column for TenantID, but still you're right that it's not too out there. reply jakewins 15 hours agoparentprevThe problem - conceptually - is made much simpler this way; we make use of this at work. However you will still have shared resource problems - some rogue query destroys IOPS in one tenant now ends up bringing down all tenants etc. There are in theory databases that solve this as well, but my experience has been that at that point what you buy into is a bad version of resource sharing - ie what an operating system does - and you’re better off using OS mechanisms In other words: yes, but you still have noisy neighbours, and may be better off running lots of small fully separated DBMSes than a big logically separated one reply hacker_newz 12 hours agorootparentIf tenants are on separate databases how would that be an issue? reply sgarland 11 hours agorootparentBecause database, in Postgres terms, doesn’t mean physical node. It’s more akin to a VM than anything else. The term for an installation of Postgres is database cluster, which can contain N databases, each of which can contain M schemas. reply albert_e 10 hours agorootparentThanks! Is there a good primer to this terminology that clarifies these terms on various popular database and cloud platforms? It seems there is good potential for confusion unless we use the same terms consistently when discussing architecture and design across teams. Even the term RDS (Relational Database Service) is sometimes said to be inaccurate since it is a \"Relational Database SERVER as a Service\" A few related terms that cause confusion: \"Schema\" could refer to a Database Schema or in some contexts, a single table's logical data structure. (Or a single data set's data structure -- or a standard for one, like JSON Schema) Data Catalog products like \"AWS Glue Data Catalog\" which only store the metadata or schemas of the table they crawl ... refer to the entities they store as \"Databases\" and \"Tables\" (but no \"Schemas\") and documentation includes guides talk about \"creating a database\"[1] and \"creating a table\"[2] in AWS Glue. There has to be a better way to refer to all these entities without using the word schema with so many meanings -- or calling both physical tables and their metadata as \"tables\". Otherwise this is needlessly confusing and hard for beginners. --- EDIT: even more madness. This StackOverflow discussion [3] has more examples of confusing usage: > On Oracle .... A Schema is effectively a user. More specifically it's a set of tables/procs/indexes etc owned by a user. Another user has a different schema (tables he/she owns) however user can also see any schemas they have select priviliedges on. > MySQL: database/schema :: table > SQL Server: database :: (schema/namespace ::) table > Oracle: database/schema/user :: (tablespace ::) table [1]: https://docs.aws.amazon.com/glue/latest/dg/define-database.h... [2]: https://docs.aws.amazon.com/glue/latest/dg/tables-described.... [3]: https://stackoverflow.com/questions/298739/what-is-the-diffe... reply sgarland 9 hours agorootparentNot AFAIK. In MySQL, the only time “cluster” is used is to refer to NDB Cluster, which is a distributed DB product. Schema means a logical grouping of tables, the same (more or less) as Postgres. As to schema itself, yes, it’s heavily overloaded, and you just to grok it from context. I can talk about a table’s schema or a DB’s schema, or as you mentioned, JSON schema. Although the latter is helped by simply not using JSON in a relational DB. You must remember that SQL is an ancient language, and the relational model is even older. There are going to be oddities. reply jakewins 12 hours agorootparentprevSeparate logical databases, within the same RDBMs, so sharing CPU, disks, RAM etc reply ummonk 12 hours agoparentprevThis seems to be an architecture Cloudflare is aiming to support with their SQLite service. One database per customer, each database located in the customer’s primary region. reply fauigerzigerk 1 hour agorootparentThat would be fantastic. Unfortunately it's not true. D1 doesn't support the one database per customer approach unless you have just a handful of customers that you can set up manually. You have to create each database manually using wrangler or the website. Then you have to create a binding for each database in wrangler.toml so that the database becomes accessible as a variable in your Workers code. Then you have to change your Worker source code to do something with that variable. Then you redeploy. The issue is that Workers cannot create or list databases. There's no API for it. reply jasonwatkinspdx 11 hours agorootparentprevI think there's quite a few people chasing similar ideas, like Azure's Durable Entities. I've been calling it the Lots of Little Databases model vs the Globe Spanning Gorilla. Like the Spanner paper points out, even if your distributed database semantically appears like a single giant instance, in practice performance means developers avoid using distributed joins, etc, because these can lead to shuffling very large amounts of intermediate results across the network. So the illusion of being on a single giant machine ends up leaking through the reality, and people end up writing workarounds for distributed joins like async materialization. If we give up the single machine illusion we get a lot of simplification, at the cost of features devs were unlikely to use anyhow. I see having consistent distributed commit but without cross shard joins as a really interesting alternative. And besides scalability I like the extra security rope of fine grained partitioning from the start. I'll write a blog post along these lines if I get anything worthwhile done. reply themoonisachees 10 hours agorootparentAn advantage worth noting is that having actually separated databases means you physically can't make these expensive operations, so a junior dev can't write incredibly inefficient code that would bring down your entire infra. reply ummonk 6 hours agorootparentAlso makes it a lot harder for devs to do some footgun and leak data across domains. reply aledalgrande 6 hours agorootparentprevBring down the infra or foot you a 6 figures bill at the end of the month reply shalabhc 7 hours agorootparentprev\"Lots of Little Databases\" reminded me of https://www.actordb.com/ which does lots of server-side sqlite instances, but the project now looks defunct. reply ummonk 6 hours agorootparentprevInteresting. Durable Entities strikes me as closer to Cloudflare's Durable Objects (both in name and in design as actors backed by persistent storage). reply icedchai 11 hours agoparentprevI worked at a place that did this with MySQL. Every tiny, trial account got their own database. Every huge, actual customer got their own database. Migrations were kinda painful. I would think carefully about doing it this way. reply freefaler 11 hours agorootparentwe've been doing this for 20k databases with mysql for the last 10+ years. It solves more problems than it creates. Migrations are trickier, but you get sharding, data isolation and easier backups that way. reply icedchai 10 hours agorootparentI'm not saying it's always a bad idea, you just need to think about what you're doing. This was closer to 15 years ago now. We had to develop a bunch of our own tooling, and make our own modifications to frameworks that are now ancient history. reply paxys 12 hours agoparentprevThis works great until (1) your largest customer outgrows the largest available DB (happens sooner than you'd think for large companies) or (2) you do need transactions across different customers, say to facilitate some kind of sharing. Going all-in on the isolated tenant strategy means when you hit one of these cases it's a nightmare to unwind and rearchitect your entire DB layer. reply jasonwatkinspdx 11 hours agorootparentI'd respond by saying (1) is more rare than you're asserting. There is a huge long tail of companies with datasets that won't fit on a single machine but can be handled by a dozen or so, and where no single customer or service is near the limits of an individual node. These customers are poorly served at the moment. Most of the easy to implement SaaS options for what they need would be hugely costly vs a small fleet of db servers they administer. Meanwhile, most of the open source options are cargo culting Google or Facebook style architecture, which is a huge burden for a small company. I mean do you really want to run K8S when you have 10 servers in total? I think there's a lot of interesting stuff happening in this end of the market that's not trying to be a mini Google, like Fly.io. As for (2), I think a middle ground is supporting cross shard transactions but not joins. This works well enough for VoltDB et all. reply bastawhiz 9 hours agorootparent> that won't fit on a single machine It's rarely an issue with the number of bytes and more an issue with hot shards. Whatever shard Google is on (that is, Google the Figma customer) is surely going to be one _hell_ of a hot shard. They have more designers/engineers/PMs actively using Figma than most startups have _users total_. You don't need more than one really really hot customer for this to become more than a hypothetical problem. When you start to think about it that way, suddenly you need to seriously consider your iops (if you're on RDS) or how much redundancy that physical machine's SSDs have (if you're running it on your own boxes). reply ndriscoll 5 hours agorootparentGoogle still only has ~180k employees, and obviously not all of them use figma, and obviously not all of their figma users are performing actions simultaneously. I'd be surprised if it broke 10k QPS (would an org like Google even have 10k peak active user sessions? Seems doubtful). Human generated traffic tends to just not reach that large of scales unless you're trying to fit the entire planet on one instance. RDS can be absurdly limited with IOPS, granted, but a modern laptop for example ought to be up to the task. Realistically you could probably be fine even on RDS but you might need to pay through the nose for extra IOPS. reply zarzavat 11 hours agorootparentprevFigma is more or less a desktop application that happens to run in a web browser. If I use Photoshop to edit a .psd file I don’t think “man that psd file should really be stored in a single planet-sized database of all psd files in existence”. It’s just a file on my computer. Figma requires a little bit more intermingling of data than Photoshop, it has multiuser support for one, so a pure local storage based approach wouldn’t work. But, at its heart it’s still based on the document model. When you open a Figma document it’s its own isolated little universe, the connections with resources outside the document are limited, and that matches user expectations. reply joegibbs 23 minutes agorootparentAgreed - it's not like you'd ever have to do SELECT * FROM Shapes WHERE 'type' = 'circle'. Could they have stored each document as a file, stored references to the files in the database, opened the file in the backend when someone opened it in the frontend, and written it back when they've stopped editing it? reply jddj 11 hours agorootparentprevCan you give an example of when a single customer has outgrown the largest available DB? reply winrid 11 hours agorootparentprevA figma customer won't exceed the requirements of an i3.metal... reply eatonphil 15 hours agoparentprevI imagine it only gets you so far. What do you do about customers like Walmart or Oracle? Hundreds, if not thousands, of users all leaving hundreds of comments on Figma files every day. If you want good latency without giving up strong consistency (which the article says they want) you'll need to keep sharding. reply infecto 12 hours agorootparentI bet it gets you further than you imagine. Entirely depends on the backend services and what they touch but in this scenario you would be deploying/scaling that service based on the customer seat size. I suspect that even for large enterprise customers, the users actively touching Figma are not reaching he thousands but I am happy to be wrong. After all, Stackoverflow is running off of a handful of machines. reply jeremyjh 13 hours agorootparentprevThey were running their whole business on one RDS instance 4 years ago. Do you think they now have one customer larger than all their customers combined 4 years ago? reply eatonphil 13 hours agorootparent> Figma’s database stack has grown almost 100x since 2020 The first sentence from the article seems to suggest its possible? reply willsmith72 15 hours agorootparentprevA single db can handle that load easily reply paulryanrogers 9 hours agorootparentDo you mean an RDBMS running on a single, big-iron, bare-metal server? reply menthe 10 hours agoparentprevThis, seriously. The long-term maintenance, tribal knowledge & risks associated with this giant hack will be greater than anything they'd ever have expected. Inb4 global outage post-mortem & key-man dependency salaries. There's no virtually no excuse not spinning up a pg pod (or two) for each tenant - heck even a namespace with the whole stack. Embed your 4-phases migrations directly in your releases / deployments, slap a py script to manage progressive rollouts, and you're done. Discovery is automated, blast / loss radius is reduced to the smallest denominator, you can now monitor / pin / adjust the stack for each customer individually as necessary, sort the release ordering / schedule based on client criticality / sensitivity, you can now easily geolocate the deployment to the tenant's location, charge by resource usage, and much more. And you can still query & roll-up all of your databases at once for analytics with Trino/DBT with nothing more but a yaml inventory. No magic, no proprietary garbage. reply nightpool 8 hours agorootparentFigma has millions of customers. The idea of having a Postgres pod for each one would be nearly impossible without completely overhauling their DB choice. reply asguy 6 hours agorootparentThousands of directories over thousands of installations? It’s not that far fetched. reply menthe 5 hours agorootparentprevYou are making a major conflation here. While they do millions of users, they were last reported to only have ~60k tenants. Decently sized EKS nodes can easily hold nearly 800 pods each (as documented), that'd make it 75 nodes. Each EKS cluster supports up to 13,500 nodes. Spread in a couple of regions to improve your customer experience, you're looking at 20 EKS nodes per cluster. This is a nothingburger. Besides, it's far from being rocket science to co-locate tenant schemas on medium-sized pg instances, monitor tenant growth, and re-balance schemas as necessary. Tenants' contracts does not evolve overnight, and certainly does not grow orders of magnitude on week over week basis - a company using Figma either has 10 seats, 100 seats, 1000, or 10,000 seats. It's easy to plan ahead for. And I would MUCH rather having to think of re-balancing a heavy hitter customer's schema to another instance every now and then (can be 100% automated too), compared to facing a business-wide SPOF, and having to hire L07+ DBAs to maintain a proprietary query parser / planner / router. Hell, OVH does tenant-based deployments of Ceph clusters, with collocated/coscheduled SSD/HDD hardware and does hot-spot resolution. And running Ceph is significantly more demanding and admin+monitoring heavy. reply dhash 12 hours agoparentprevI believe physalia [0] explores this concept at production scale quite well. [0] https://blog.acolyer.org/2020/03/04/millions-of-tiny-databas... reply N_A_T_E 14 hours agoparentprevIt sounds like they actually did something like this. Their shard key selection could be customer, project, folder or something in their data model at a reasonably high logical level in their hierarchy. reply cavisne 11 hours agoparentprevSpanners interleaved tables seem like a similar solution, ie you interleave customer data so it all ends up on the same set of hosts for performance, while still having the ability to create transactions across customers. reply infra_dev 14 hours agoparentprevNile is a Serverless Postgres that virtualizes tenants/customers. It is specifically built for SaaS companies similar to Figma https://www.thenile.dev/. I am the CEO of Nile. reply aeyes 14 hours agoparentprevI have pondered about this for quite some time and came to the conclusion that it would make schema migrations more difficult to handle. I think Shopify is using an approach which is similar to what you are describing. The advantage is that you don't end up with hot shards because you can move around large customers independently. In practice there isn't a big difference, they just colocate several customers according to their sharding key in the same logical database. reply yard2010 11 hours agorootparentI worked in a place that had a database for each tenant and the schema migrations were a real pain. Every time everything goes smoothly except these few databases that have an edge case that screws the whole migration. reply jamesfinlayson 11 hours agorootparentprevI remember Postgres table spaces being used to separate customers at a previous job - I can't remember how migrations were handled (pretty sure they were applied per table space) but I don't think it was a problem (at our scale anyway). reply vmfunction 10 hours agorootparent>There is usually not much point in making more than one tablespace per logical file system, since you cannot control the location of individual files within a logical file system. However, PostgreSQL does not enforce any such limitation, and indeed it is not directly aware of the file system boundaries on your system. It just stores files in the directories you tell it to use. seems like the limitation is the logical file system. Which probably will work for most users. reply erikpukinskis 9 hours agoparentprevIm curious for anyone who has done this: what’s the point of going all the way from one-db to one-db-per-customer? Why not just split the customers to 2 databases, then to 3, etc? Seems like the same level of system complexity but you avoid the lots-of-databases scaling problem. You probably don’t even need to be able to migrate people between shards… just put everyone on one db until you hit 50% utilization, then spin up a fresh db and put all new customers on that one. Repeat whenever you run out of databases under 50%. reply GordonS 14 hours agoparentprevI've done something like this before, with each customer getting their own schema within a single Postgres instance. reply jimbokun 9 hours agoparentprevIf customers are not of similar size, and you have a lot of customers, managing all the different databases can be a big headache. Having a more granular partition key makes it easier to shard the data more evenly. reply petervandijck 11 hours agoparentprevOngoing product development with migrations, tweaking indexes etc. becomes really hard. Every small database tweak now has to be deployed over 1000s of databases. reply emptysea 15 hours agoprevSeems they’ve built out a PG version of MySQL’s Vitess Query rewriting seems interesting, having a layer between your DB and your application would also allow various ACL stuff as well reply metadat 5 hours agoprevIt looks like figma mostly just implemented the Instagram sharding paper, and then did the obvious next level of semi-intelligent yet delicate and fragile query routing. Definitely a technically challenging and overall fun / satisfying engineering exercise! https://instagram-engineering.com/sharding-ids-at-instagram-... reply mannyv 15 hours agoprevHmm, wonder why they didn't try FoundationDB. Interesting that they had problems with vacuuming. I always thought that part of Postgres was the worst part. I vaguely remember that you needed twice the space to vacuum successfully, which hopefully has changed in later versions. An article about why vacuum is needed in pg (as compared to mysql/innodb). http://rhaas.blogspot.com/2011/02/mysql-vs-postgresql-part-2... reply eatonphil 15 hours agoparentThe article mentions they're trying very hard to stick with Postgres. FoundationDB is great but doesn't even have a SQL access layer, let alone a Postgres SQL access layer. :) reply yashap 11 hours agoparentprevThey want pretty full SQL support, so FoundationDB would be out. I’d think “buy” options for them would be more like Citus, Yugabyte, Cockroach or Spanner. reply harikb 15 hours agoparentprevDo you know of any performant relational-db layer on top of FoundationDB? It seems there usecase would need at least simple join, which raw FoundationDB lacks. reply dakiol 15 hours agoprevI cannot help but think this all sounds pretty much like a hack (a clever one, though). We do not handle, let's say low-level I/O buffering/caching, by ourselves anymore, right? (at least the folks doing web development/saas). We rely instead of the OS APIs, and that's good. I think we are missing something similar but for db sharding. It seems to me that we are still missing some fundamental piece of technology/infrastructure to handle horizontal data sharding. reply simonw 12 hours agoparentCitus and Vitess are examples of horzontal data sharding technology for PostgreSQL and MySQL respectively. At Figma's size there are sometimes reasons to roll your own, which I think they explain pretty clearly in the article. They wanted a solution they could incrementally engineer onto their existing stack without doing a full rewrite or lift-and-shift to something else. reply efxhoy 10 hours agoparentprevI’m no computer scientist but I think the fundamental problem is that the CAP theorem makes it really tricky to do in a “cost free” way. You fundamentally need to sacrifice one, at least a tiny bit. reply yard2010 11 hours agoparentprevThis is Hacker News after all reply ing33k 3 hours agoprev\"Additionally, over the past few years, we’ve developed a lot of expertise on how to reliably and performantly run RDS Postgres in-house\". Isn't the whole point of paying AWS the premium is that they do it for you ? reply ijustlovemath 14 hours agoprev> NoSQL databases are another common scalable-by-default solution that companies adopt as they grow. However, we have a very complex relational data model built on top of our current Postgres architecture and NoSQL APIs don’t offer this kind of versatility. As I understand it, NoSQL is for people who need a backend that ingests just about any unstructured data, for teams that may not have a complex relational model worked out/stabilized. Postgres has this in its native jsonb datatype, but they wouldn't need to use that much since it sounds like they already have a good data model. What am I missing here? reply suhastech 13 hours agoparentUsing NoSQL might not be the best idea in this case. I've seen it backfire for many companies. They start with NoSQL, but then end up needing relational features as their business grows. This leads to performance issues, redundancy, and data sync problems early on, which shouldn't be happening. Especially in the early days, NoSQL companies used to market their databases as general-purpose database that scale easily, but that hasn't always been the case obviously. I usually recommend starting with a relational database like PostgreSQL. If scaling becomes necessary later on, you can invest in sharding the database. Figma's approach seems reasonable given the tools available at the time. I've helped small companies switch from NoSQL to SQL because the benefits of NoSQL weren't worth the trade-offs at their stage of growth. In case, anyone is in a similar boat: https://mongotosqlmigration.com/ reply opportune 14 hours agoparentprevWhat is your exact question? To me it makes sense that you’d not want to use NoSQL if you’re dealing with data that’s already relational, and heavily leveraging features common in relational DBs that may not come out of the box with NoSQL DBs. They’re saying basically that NoSQL DBs solve a lot of horizontal scaling problems but aren’t a good fit for their highly relational data, is my understanding. Not that they can’t get NoSQL functionality at eg the query level in relational DBs. reply ffsm8 14 hours agoparentprevI think they're equating relation database with databases with ACID guarantees, as thats basically a full overlap on a venn diagram. And we all know that acid has to go at some scale, even if that scale keeps getting pushed further out as our hardware gets better. (Same with the relational guarantees that eat performance... But only once you've reached a certain amount of throughput and data) reply jimbokun 9 hours agoparentprevIf scaling isn’t an issue, use a relational database. “NoSQL” only really pays off when you need to scale horizontally. And even then, one of the horizontally scaling SQL solutions might be a better bet. reply vmfunction 10 hours agoparentprevif you have postgres, just use https://github.com/FerretDB/FerretDB reply hintymad 13 hours agoprevGiven that sharding has become a pretty mature practice, is it still worth considering the NewSQL solutions like CRDB, Yugabyte, and TiDB for the sake of auto sharding, given that these NewSQL databases usually trade throughput and latency for auto-sharding and multi-region support? Another added cost is learning how to operate NewSQL databases, assuming one is already familiar with either MySQL or Postgres. reply emmanueloga_ 12 hours agoparentIn the OP they said they built their own sharding solution because it was risky to move to a different (newsql) solution and they already had sharding expertise with PG. I think if starting from scratch it makes sense to look at these newsql DBs that are built to horizontally scale from the very beginning. reply brigadier132 10 hours agoparentprevSharding mysql and postgres has been a shitshow at every company I've worked at. reply hintymad 6 hours agorootparentThanks. This is kinda of information I look for. Could you give more specifics? Why were they shit shows? If the tables are naturally shardable, say by user ID as described in the Figma's case, would the situation be different? reply paulryanrogers 7 hours agorootparentprevWhy? How did they shard? reply adastral 15 hours agoprevI see they don't mention Citus (https://github.com/citusdata/citus), which is already a fairly mature native Postgres extension. From the details given in the article, it sounds like they just reimplemented it. I wonder if they were unaware of it or disregarded it for a reason —I currently am in a similar situation as the one described in the blog, trying to shard a massive Postgres DB. reply gshulegaard 14 hours agoparentI have worked on teams that have both sharded and partitioned PostgreSQL ourselves (somewhat like Figma) (Postgres 9.4-ish time frame) as well as those that have utilized Citus. I am a strong proponent of Citus and point colleagues in that direction frequently, but depending on how long ago Figma was considering this path I will say that there were some very interesting limitations to Citus not that long ago. For example, it was only 2 years ago that Citus allowed the joining of data in \"local\" tables and data retrieved from distributed tables (https://www.citusdata.com/updates/v11-0). In this major update as well, Citus enabled _any_ node to handle queries, previously all queries (whether or not it was modifying data) had to go through the \"coordinator\" node in your cluster. This could turn into a pretty significant bottleneck which had ramifications for your cluster administration and choices made about how to shape your data (what goes into local tables, reference tables, or distributed tables). Again, huge fan of Citus, but it's not a magic bullet that makes it so you no longer have to think about scale when using Postgres. It makes it _much_ easier and adds some killer features that push complexity down the stack such that it is _almost_ completely abstracted from application logic. But you still have be cognizant of it, sometimes even altering your data model to accommodate. reply gen220 13 hours agorootparentYou also benefit from the tailwind of the CitusData team making continued improvement to the extension, whereas an in-house system depends on your company's ability to hire and retain people to maintain + improve the in-house system. It's hard to account for the value of benefits that have yet to accrue, but this kind of analysis, even if you pretty heavily-discount that future value, tilts the ROI in favor of solutions like Citus, IMO. Especially if your time horizon is 5+ or 10+ years out. Like you said, if they made this decision 3ish years ago, you would have had to be pretty trusting on that future value. A choice, made today, hinges less on that variable. reply wayne-li2 12 hours agorootparentHuh, I would have thought the opposite. Companies at Figma size are easily able to hire talent to maintain a core part of their engineering stack. On the other hand, they retain no control of Citus decision making. Those tailwinds could easily have been headwinds if they went in a direction that did not suit Figma. reply sgarland 15 hours agoparentprevI thought of that as well. The only thing I could think of is that they mentioned that they don't want to move off of RDS, and there is 0% chance of Citus coming to AWS since Microsoft bought them. reply junto 15 hours agoparentprevBefore clicking on the article I assumed it was Citus, and was surprised when it wasn’t. Maybe because CitusData was bought by Microsoft around the same time, so Microsoft could create “Azure Cosmos DB for Postgres Cluster”, yet another one of Microsoft’s typical product naming crapshoots. reply victor106 14 hours agorootparent> yet another one of Microsoft’s typical product naming crapshoots. Well said. I haven't seen any company as terrible as Microsoft at naming things. Anyone know why? reply salynchnew 12 hours agorootparentNaming things is hard. At a previous employer, I saw several cool-ish open source projects instantly doomed to obscurity by picking a name that either completely duplicated the name of an existing OSS project or were guaranteed to have terrible SEO for another reason. However, Microsoft seems to have a unique crossover of fragmented business units and centralized marketing. That's why you end up with Azure -> Subproject -> Actual Product/Service word soup. Perviously, they did this with the Windows Live brand from 2005-2012, and \"Xbox\" for a wide range of gaming projects (many of which were on PC). reply thomasjudge 11 hours agorootparentrelated, Microsoft on Microsoft marketing: https://www.youtube.com/watch?v=EUXnJraKM3k reply r-bar 10 hours agorootparentprevThe committee wanted Cosmos, Azure, and Postgres all in the name and wouldn't compromise. reply studmuffin650 13 hours agorootparentprevAWS is putting up good fight reply jabart 14 hours agoparentprevFigma uses AWS RDS, RDS doesn't list citus as a supported extension. reply gen220 13 hours agorootparentThis is my guess of why they didn't use Citus. They weren't interested in the options of (1) going multi-cloud [DB in Azure Cosmos / Backend(s) in AWS] (2) going all-in on Azure [DB in Azure Cosmos / Backend(s) in Azure] (3) self-managing Postgres+Citus in EC2. It'd be interesting to compare the expected capex of developing this in-house solution + the opex of maintaining it vs the same categories of expected costs for option (3) – because I imagine that's probably the most palatable option. They also may have pre-paid for dedicated RDS instances for the next X years (before this horizontal scaling initiative began, to boot), as AWS allows companies to do this at a pretty steep discount rate, which would probably tilt them away from (3). reply sgarland 12 hours agorootparentEspecially because Option 3 lets you go waaaay farther on vertical scaling, since you can get native NVMe drives (they mentioned hitting IOPS limits for RDS), more exotic instance classes with far more RAM, and do stuff like ZFS for native compression and snapshots. reply iamdanieljohns 15 hours agoparentprevI would love to see a comparison of the major PostgresQL services such as Citus, EDB, Crunchy, Neon, and some OSS distributions/packages reply _boffin_ 15 hours agoparentprevhow \"massive\" is massive in your case? reply dijit 15 hours agorootparentI've had CitusDB running across 68 bare metal machines (40 vCPU, 768GiB ram, 20TiB of storage each + 40GiB network links) and it ran decently well. Not sure what your definition of massive is, I think Spanner would easily beat it. Also, it's very use-case dependent, you can't \"just use\" Citus for everything, it's not quite as flexible as a bog-standard pgsql install due to the way it's sharding, you have to be a tad more careful with your data model. reply VHRanger 8 hours agorootparentIs there a reason there's comparatively little storage in your machines in relation to RAM or even CPUs? Do your machines do compute heavy loads or something? For a DB I'd expect a lot more storage per node reply dijit 5 hours agorootparentNVMe SSDs aren't so large unfortunately. a 1U server has capacity for 8 drives, we used 2 slots for the OS (RAID1), 2 slots for the WAL volume (2 slots) leaving only 4 slots in RAID10. So I'm already cheating a little and claiming WAL storage was part of total storage. reply skunkworker 13 hours agorootparentprevWhat is your definition of \"decently well\", and is your primary cluster (without replicas) above 1PB? reply simonw 12 hours agorootparentThey said 20TiB * 68, which I think is 1.5PB. reply adastral 15 hours agorootparentprevAround ten heavily-updated (50-400k updated rows/min) tables ranging between 500M and 5B rows, with a couple tables over 40B rows each (5TB each IIRC). reply gregors 13 hours agoparentprevWhere's the fun in that? I'm not being snarky either. Maybe it's not the best decision business-wise, but I guarantee it was more challenging and more fun. There's something to be said for that. reply vinner_roy 15 hours agoprevCould you use Aurora Limitless for this instead? https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-au... reply bearjaws 14 hours agoparentI doubt even VC money can afford this service. Serverless Aurora is incredibly expensive for most workloads. I have yet to find a use case for any SaaS product that is used >4 hours a day. Since all my products span at least 3 time zones there is at least 12 hours of activity a day. reply Scubabear68 14 hours agorootparentWe found this out the hard way in a small startup. The per query and I/O expense was through the roof. reply yard2010 11 hours agorootparentDid it work though? Did you achieve unlimited scaling? Because if so you should compare the price to the price of a team of great minds such as in this article, working for 2 years to get a solution. I bet it still would be cheaper to pay people over Amazon, but I'm curious about the numbers reply Scubabear68 10 hours agorootparentIt worked fine, the problem was our workloads were minuscule and it still cost $3,000 a month to support 50ish users on a lightly used platform. The same load in a non-Serverless instance was around $100/month. reply brcmthrowaway 14 hours agorootparentprevWhat products reply paulddraper 14 hours agoparentprev\"Limitless\" refers to the bill, not just the scale. reply sgarland 14 hours agoparentprevAt my company, we were given an early talk on Limitless. Never once did the reps mention that it ran on Serverless. Dear lord, that's going to be a hard no from me. Unless they've dramatically changed pricing for Limitless as opposed to normal Serverless, that'll be through the roof. reply vinner_roy 14 hours agoparentprevHaha alright I get the picture. Too expensive. reply MapleWalnut 14 hours agoparentprevYes, but that wasn't available when they did this migration reply jamesfinlayson 9 hours agorootparentHm, looks like it's only available as a preview too. I was wondering why I hadn't seen in mentioned before. reply nosefrog 15 hours agoprevComing from Google, where Spanner is this magical technology that supports infinite horizontal sharding with transactions and has become the standard storage engine for everything at Google (almost every project not using Spanner was moving to Spanner), I'm curious how Figma evaluated Cloud Spanner. Cloud Spanner does have a postgres translation layer, though I don't know how well it works. It seems like they've (hopefully only temporarily) given up real transactional support with their horizontal postgres scheme? reply umvi 15 hours agoparentNever a good idea to rely on Google proprietary tech (unless you are Google)... it could be sunset at any time without warning. I use GCP but I try my best to stay Google agnostic (avoid GCP-only offerings, etc) so that I can move to AWS if Google pulls the rug out from under me. reply weitendorf 13 hours agorootparentI'm biased having worked on GCP, but I think GCP actually has a very good track record of not sunsetting entire products or removing core functionality. When I worked on AppEngine, I would often see apps written 10+ years ago still chugging along. It is true though that GCP sometimes sunsets specific product functionality, requiring changes on the customers' part. Some of these are unavoidable (eg committing to apply security patches to Python 2.7 given that the rest of the world is mostly not upstreaming these patches anymore), but not all of them. I would certainly use Cloud Spanner externally now that I've left the company, and IMO spanner has such a compelling featureset that it's a strong reason to use GCP for greenfield development. The problem though is that it's only available on GCP, and could become expensive at large scale. reply nojvek 9 hours agorootparentMy previous employer was a GCP customer. Google did pull occasional shenanigans totally breaking us with random upgrades without notifying us. Their support wouldn’t acknowledge it was their fault until we were mad at them. My newer employer is AWS. Their offerings are a lot more stable and support is helpful. If you want to build a serious business I would avoid GCP. Google doesn’t really give a shit at winning Cloud. Ads is their core business. reply weitendorf 7 hours agorootparentUgh I'm so sorry, you should definitely have been notified in advance about breaking changes, unless they were accidental bugs and regressions. That was something we took pretty seriously for the products I worked on. I have definitely enjoyed using AWS support. But I've also encountered some broken/janky functionality (eg using custom domain + api gateway + websockets + Lambda for the apparently niche-task of having a real website use the Lambda-websockets integration) on AWS that I don't think would have made it to production at Google. I also really dislike how they handle project-level logging compared to how it's done on GCP. Ultimately I do think some GCP products like Bigquery, Cloud Run (I'm biased here), and Spanner as well as general DevEx/reliability factors are compelling enough for GCP to be worth serious consideration, even if AWS offers better support. reply jerrygenser 12 hours agorootparentprev>It is true though that GCP sometimes sunsets specific product functionality, requiring changes on the customers' part. Some of these are unavoidable (eg committing to apply security patches to Python 2.7 given that the rest of the world is mostly not upstreaming these patches anymore), but not all of them. A good example is probably IoT. I've heard first hand anecdotes of very difficult migrations off this service. reply rockostrich 14 hours agorootparentprevGCP products have a much better track record than Google consumer products when it comes to support since there are usually enterprise customers with multi-year contracts worth tens, if not hundreds, of millions of dollars using them. reply callalex 14 hours agorootparentThat’s what AppEngine customers thought. reply tempnow987 10 hours agorootparentDidn't they also hammer folks using google maps in a business / cloud context? I was also an old app engine user, but bailed ages ago (original app engine). reply weitendorf 14 hours agorootparentprevI worked on AppEngine (well, Serverless Compute) at Google for over 4 years and left on Friday. Did something happen to AppEngine in the last week? reply callalex 13 hours agorootparentI’m talking about the pricing disaster that happened in 2017/2018 where user prices went up from 10x-100x because Google wanted to kill the product without actually killing it. reply jerrygenser 12 hours agorootparentprevIoT is one example of a big backbone service that was sunset. reply endisneigh 12 hours agorootparentIt had barely any usage though from what I can tell from searching about it. Not that it’s any solace to those affected. reply marcinzm 11 hours agorootparentprevAI Platform is a recent example that’s been deprecated. reply opportune 14 hours agoparentprevMy perspective from working both inside and outside of Google: The external spanner documentation doesn’t seem as good as the internal documentation, in my opinion. Because it’s not generally well known outside of G, they ought to do a better job explaining it and its benefits. It truly is magical technology but you have to be a database nerd to see why. It’s also pretty expensive and because you generally need to rewrite your applications to work with it, there is a degree of lockin. So taking on Spanner is a risky proposition - if your prices get hiked or it starts costing more than you want, you’ll have to spend even more time and money migrating off it. Spanner’s advantages over other DBs (trying to “solve” the CAP theorem) then become a curse, because it’s hard to find any other DB that gives you horizontal scaling, ACID, and high availability out of the box, and you might have to solve those problems yourself/redesign the rest of your system. Personally I would consider using Cloud Spanner, but I wouldn’t bet my business on it. reply nojvek 9 hours agorootparentIf you really have that much data and traffic, the $ costs start to add up to multiple engineer comp costs. At that point it’s cheaper to move to something you have good control over. I.e sharding at application layer and connecting to the DB instance replica where the customer data is hosted. reply weitendorf 7 hours agorootparentDepends. The cost may pay for itself but the engineers you have already may have higher ROI things to do. It's also nice to have operational stuff managed for you. Personally I'd be happy to pay extra for the kinds of problems Spanner solves to free myself up to do other things (to a point, ofc). > sharding at application layer and connecting to the DB instance replica where the customer data is hosted. Spanner does global consistency/replication. If having good performance per-tenant globally is a concern, this helps a lot, and is hard to implement on your own. It can also ultimately save you money by limiting cross-region traffic. reply shalabhc 15 hours agoparentprevGlobal consistency is expensive, both latency-wise and cost-wise. In reality most apps don't need global serializability across all objects. For instance, you probably don't need serializability across different tenants, organizations, workspaces, etc. Spanner provides serializability across all objects IIUC - so you pay for it whether you need it or not. The other side of something like Spanner is the quorum-based latency is often optimized by adding another cache on top, which instantly defeats the original consistency guarantees. The consistency of (spanner+my_cache) is not the same as the consistency of spanner. So if we're back to app level consistency guarantees anyway, turns out the \"managed\" solution is only partial. Ideally the managed db systems would have flexible consistency, allowing me to configure not just which object sets need consistency but also letting me configure caches with lag tolerance. This would let me choose trade-offs without having to implement consistent caching and other optimization tricks on top of globally consistent/serializable databases. reply foota 13 hours agorootparentWhile it doesn't help much with the costs of replication, Spanner can be configured with read only replicas that don't participate in voting for commits, so they don't impact the quorum latency. Reads can then be done with different consistency requirements, e.g., bounded staleness (which guarantees data less stale than the time bound requested). See https://cloud.google.com/spanner/docs/reference/rest/v1/Tran... or https://cloud.google.com/spanner/docs/reads#read_types and https://cloud.google.com/spanner/docs/create-manage-configur... reply eatonphil 15 hours agorootparentprevSee also: \"Strict-serializability, but at what cost, for what purpose?\" https://muratbuffalo.blogspot.com/2022/08/strict-serializabi.... reply zenbowman 12 hours agoparentprevI wouldn't say \"infinite\", its still susceptible to read hotspotting; and while fine-grained locking enables generally higher write throughputs, you can still get in a situation where interconnected updates end up being pretty slow. That said, its way better than anything else I've used in my career. reply ksb 15 hours agoparentprevPing time from AWS data centers to GCP ones reply hipadev23 15 hours agoparentprevThe problem is nobody outside Google trusts them to run or operate anything. Edit: To the Googlers downvoting these comments. Your behavior only reinforces our views. reply szundi 15 hours agorootparentGoogle means: good chance discontinued after you have worked out the bugs and have a stable system at last reply groestl 14 hours agorootparentThis is definitely not the case with their core cloud products. > almost every project not using Spanner was moving to Spanner This even includes Datastore. Even Datastore moved to Spanner. reply echelon 15 hours agoparentprevWhy would anyone marry themselves to Google? That sounds like the most boneheaded move possible. First, you should never be beholden to a single vendor for the most critical technological underpinnings. You're backing yourself into a corner. But more importantly, Google can't even figure out how to prioritize their cloud efforts. That's not a good partnership to be in for anyone except Google. I wouldn't care if my solution was 10x worse than Cloud Spanner from a technology perspective. It'd be 1000x better from a strategy perspective. You can hire engineers to do consistency at scale. It's your core competency and you can't just handwave and outsource that, lest you wind up stuck in a crevasse. Hire smart engineers and do the work yourself. It'll pay off. reply Thaxll 12 hours agorootparentYou can't, that's why spanner only exists a Google. That tech is that good, not found anywhere else. reply echelon 11 hours agorootparentBut you don't need it. There are a limitless number of ways to deal with the problems spanner solves. And by choosing your own, you can focus on the subset that matter to your case and not be tied down to Google. reply cynicalsecurity 13 hours agoprevThey came up with a really over-engineered, over-complicated attempt at splitting data into multiple databases. I'm not sure this was the best idea or even a good idea, but then I also don't understand how it came to the situation when they only had a few months before their current database gets overflown and the whole system collapses. reply dwaltrip 13 hours agoparentCan you offer insight into what a better approach might have been? reply TheP1000 13 hours agorootparentAs others have mentioned, moving to per tenant databases can really simplify things at scale and doesn't leave a massive amount of engineering complexity and debt in its wake. I feel sorry for the team managing this 5 years from now. reply simonw 12 hours agorootparentMoving to a per-tenant database sounds like even more work to me than moving to shards. Moving to per-tenant means rewriting _everything_ - moving to shards has you rewriting a lot less. reply kgeist 4 hours agorootparentWhat do you mean by \"rewriting everything\"? Or maybe your definition of \"per-tenant database\" is different from mine. In our product, it's just a small layer which routes requests to the target organization's DB. When an organization is created, we create a new DB. Most of application code has no idea there are different DBs under the hood. There are logical DBs (folders/files on a single physical server), and there's a few physical servers. We're currently at the stage where the first physical server hosts most of smaller organizations, and all other physical servers are usually dedicated servers for larger clients with high loads. reply infra_dev 12 hours agorootparentprevThis is possible to do, but lots of engineering. You can provide the experience of a single DB while each tenant can be placed in their own dedicated Postgres compute. This would help the application to stay the same while tenants are moved to independent computes (you can even move only a few tenants and leave the rest on a shared Postgres compute). reply cynicalsecurity 13 hours agorootparentprevExactly this. But at this point, I don't even want to give them advice, I don't really like their service. I like Lunacy more. reply Xenya 4 hours agoprevamazing team, but the author doesn't seem to understand the details reply HermitX 14 hours agoprevI This is an intriguing article, clearly showing the team's fondness for Postgres. However, Postgres is an OLTP product. I'm curious about what system Figma's data team uses for their data analysis tasks. reply jerrygenser 12 hours agoparentThey mentioned analyzing query logs in Snowflake in this very article. So... at least they use Snowflake for some things? reply Thaxll 13 hours agoprevHow transactions work when you end up querying different shards? reply simonw 12 hours agoparentI imagine that's one of the reasons they have \"colos\" - you can aim to collocate tables that are likely to be part of the same transaction in the same shard by putting them in the same colo group. reply blauditore 13 hours agoparentprevIIUC they never have db transactions across shards, because customers are basically data silos, which makes sharding quite straightforward. reply AtlasBarfed 11 hours agoprev1 postgres 2 postgres replicas+sharding 3 Cassandra / dynamo If you are at stage 2, you are using bandaids. You need to start architecting a transition of your most heavily used data views to truly scalable databases like Cassandra / dynamo. I have not used foundation, but aphyr liked it. That transition takes time, evaluation, pro typing, and organizational learning both at the application programmer, support engineer, and management. reply tbarbugli 11 hours agoprevCitus seems incredibly close to what they built, I wonder why they did not use it reply DonnyV 7 hours agoprevIs it me or did they just recreate Mongodb Shard feature? But now they have to maintain it. They would of been better off going Mongodb or another document database. Then you wouldn't have to worry about scheme changes. Since your scheme lives there n your data model. You could just map changed fields. They should of just used a tenant based design. If a customer was hindering performance on neighboring tenants. They could just migrate them over to their own large server. reply goshx 15 hours agoprev\"Sorry, you’ve stumbled upon a temporary technical issue. Please try refreshing this page in a moment.\" Have they? :) I am excited to read the article when it loads reply nix0n 15 hours agoparentIt worked for me on the first try, but here's an archive link in case it goes down again: https://archive.is/xusR7 reply Lucasoato 14 hours agoparentprevThis might be another case of “death by HN” reply TkTech 15 hours agoprevAm I the only one finding the layout of this blog distracting? Kind of disappointing from a UX company. The images are also massive, the page was 42.21mb! Good article none the less! Always appreciate when companies like Figma document technical challenges. reply ghostly_s 12 hours agoparentOdd, it looks perfectly bog-standard for me on Firefox and iOS, aside from the lavender bg which I quite like. I even disabled my ad-blocker to see if it made a difference, no changing bg colors for me... reply zelphirkalt 13 hours agoparentprevMaybe someone designed this castle in Figma. reply renegade-otter 14 hours agoparentprevIt seems like someone at Figma decided to use the latest CSS tricks they just had discovered. Changing background color? Come on. reply Cwizard 14 hours agorootparentI thought this was a bug at first. Does anyone actually want this? reply cynicalsecurity 14 hours agoprevIt would have benefitted the article to use less of annoying corporate talk. reply jeffbee 14 hours agoprevGiven the list of authors and acknowledgees, what I'd really like to read is the differences between this solution and Dropbox's. reply sp1nozick 12 hours agoparenthorizontal sharding is such a foundational skillset in working with databases - it's essential to database architecture reply gfodor 13 hours agoprevHonestly it's depressing that I remember doing this same thing more than a decade ago and we still have to spend developer cycles on this nonsense in 2024. reply esafak 16 hours agoprev [13 more] This is such a familiar story. Company starts with a centralized database, runs into scaling problems, then spends man-years sharding it. Just use a distributed database. reply dang 15 hours agoparent\"Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.\" https://news.ycombinator.com/newsguidelines.html reply jack_riminton 16 hours agoparentprevIf every startup used every scale-proof method available from the beginning they'd never have the time or resources to build the products to get the customers that would require them to use the scale-proof methods reply esafak 15 hours agorootparentI agree with your general point but there are relational distributed databases, open source and \"serverless\", that are compatible with MySQL (planetscale, tidb, vitess...) and postgres (citus, cockroachdb...) edited for examples. reply mplanchard 15 hours agorootparentAnd many of these are substantially more expensive than RDS, or have terrible INSERT performance, or require making the correct decisions really early about what to use as partition keys. There's no free lunch, sadly. reply noja 15 hours agorootparentprevOne reason they don't is unhelpful comments like these: alluding to products without naming them. reply ofrzeta 15 hours agorootparentFrom the article: \"During our evaluation, we explored CockroachDB, TiDB, Spanner, and Vitess\". Three of them are open source if I am not mistaken. reply Closi 15 hours agorootparentprevI don't think these were mature products when Figma started to be developed in 2012. reply Closi 16 hours agoparentprevThis assumes that using a distributed database from the start doesn't offer it's own penalties/drawbacks (particularly in 2016). Particularly considering as per the figma note, they consider their data highly relational (i.e. presumably this means lots of joins in queries) What database would you have chosen? reply esafak 15 hours agorootparentThat's a fair response for then, but not today where you're spoiled for choice. Spanner was released as a service in 2017, which isn't far off. reply prisenco 13 hours agorootparentSpanner is quite expensive though. reply mamcx 15 hours agoparentprevThere are many kinds of apps that use of \"distributed\" databases is an antipattern...and useless to make them scale. MOST apps did not need more than \"tenant-per-company\" and then, maybe, distributed among a small set of servers. Is it just that the kind of app that shows here (and has this problems) are just niche apps like social networks and complex chat apps. reply battwell 15 hours agoparentprev [–] Doesn't seem a crazy way to start a company. RDS will have scaling problems but is very mature and fairly easy to use early on when you're working on your MVP I've used CRDB early on at a startup. There was some overhead. You don't get all the nice PSQL features Although it did save us a giant migration later on reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Figma's databases team successfully implemented horizontal sharding on their Postgres stack for nearly infinite scalability, opting for RDS Postgres over NoSQL databases due to expertise, enhancing scalability and reliability with minimal impact on product logic.",
      "Sharding keys and hash functions were key in routing data efficiently, with the creation of a new golang service, DBProxy, and sharded views on unsharded databases to streamline operations, addressing challenges like schema updates and cross-shard transactions.",
      "The team plans to evaluate their current solution and explore alternative approaches for future improvements in the system."
    ],
    "commentSummary": [
      "Figma opted for horizontal sharding over migrating to YugabyteDB to scale their tables, citing cost and migration risks as reasons for sticking with RDS.",
      "The discussion covers various database management strategies, including multi-tenancy, one database per customer, and using Citus for scaling, highlighting the complexities and benefits of each approach.",
      "Considerations for startups relying on distributed databases and the risks of vendor lock-in, like with Google Cloud Spanner, are also scrutinized in the conversation."
    ],
    "points": 516,
    "commentCount": 202,
    "retryCount": 0,
    "time": 1710438690
  },
  {
    "id": 39702568,
    "title": "SpaceX Delivers Innovative Mission to International Space Station",
    "originLink": "https://www.spacex.com/launches/mission/?missionId=starship-flight-3",
    "originBody": "Falcon 9 Falcon Heavy Dragon Starship Human Spaceflight Rideshare Starshield Starlink Shop Falcon 9 Falcon Heavy Dragon Starship Human Spaceflight Rideshare Starshield Starlink Mission Launches Careers Updates Shop 01. DEPARTURE 02. PHASING BURNS 03. TRUNK JETTISON 04. DEORBIT BURN 05. RE ENTRY 06. PARACHUTES DEPLOY 07. SPLASHDOWN 01 THRUSTER BURN THRUSTER BURN 02 03 03 01. LIFTOFF 02. ORBIT ACTIVATION 03. PHASING BURNS 04. APPROACH INITIATION 05. PROXIMITY OPERATION 06. DOCKING & PRESSURIZATION To The space station On its flight to the International Space Station, Dragon executes a series of burns that position the vehicle progressively closer to the station before it performs final docking maneuvers, followed by pressurization of the vestibule, hatch opening, and crew ingress. On its flight to the International Space Station, Dragon executed a series of burns that positioned the vehicle progressively closer to the station before it performed final docking maneuvers, followed by pressurization of the vestibule, hatch opening, and crew ingress. Mission To The space station On its flight to the International Space Station, Dragon executes a series of burns that position the vehicle progressively closer to the station before it performs final docking maneuvers, followed by pressurization of the vestibule, hatch opening, and crew ingress. On its flight to the International Space Station, Dragon executed a series of burns that positioned the vehicle progressively closer to the station before it performed final docking maneuvers, followed by pressurization of the vestibule, hatch opening, and crew ingress. 02 THRUSTERBURN THRUSTERBURN 03 01 03 04 05 06 FINAL COELLIPTIC K E E P O U T S P H E R E 01. LIFTOFF Falcon 9’s first stage lofts Dragon to orbit. Falcon 9’s first and second stage separate. Second stage accelerates Dragon to orbital velocity. 02. ORBIT ACTIVATION Dragon separates from Falcon 9’s second stage and performs initial orbit activation and checkouts of propulsion, life support, and thermal control systems. 03. PHASING BURNS Dragon performs delta-velocity orbit raising maneuvers to catch up with the International Space Station. 04. APPROACH INITIATION Dragon establishes a communication link with the International Space Station and performs its final orbit raising delta-velocity burn. 05. PROXIMITY OPERATION Dragon establishes relative navigation to the International Space Station and arrives along the docking axis, initiating an autonomous approach. 06. DOCKING & PRESSURIZATION Dragon performs final approach and docks with the International Space Station, followed by pressurization, hatch open, and crew ingress. SpaceX © 2024 PRIVACY POLICY SUPPLIERS",
    "commentLink": "https://news.ycombinator.com/item?id=39702568",
    "commentBody": "Starship's Third Flight Test [video] (spacex.com)476 points by BenoitP 22 hours agohidepastfavorite374 comments DarmokJalad1701 20 hours agoThe test is essentially a success at this point. Starship can take payload to orbit and open/close the payload doors. The remaining things are icing on the cake. They can refine re-usability while flying payloads. reply golol 19 hours agoparentOne technical modification: They need engine relight in orbit to work to deliver payloads, otherwise Starship will stay in orbit and they can not test reentry. reply neffo 18 hours agorootparentYou need a second burn just to enter orbit. You burn at the top of the sub-orbital arc (opposite side of the earth) to enter orbit. reply exDM69 17 hours agorootparentNo, that's inefficient and real spacecraft don't do that for typical low earth orbits. Works in Kerbal Space Program, though. Normal orbital insertion is a single burn to orbit (with staging). With the correct initial roll and pitch, the spacecraft follows a perfect gravity turn and ends up in a near circular orbit at main engine cut off. reply numpad0 17 hours agorootparentIIUC real launchers do a single burn to orbit because S2 TWR is not very high and relight is finicky. Launchers that has relightable S2 and/or hypergolic S3 routinely do circularization burns. There are reasons \"apogee\" is more recognized word than \"apoapsis\". reply lupusreal 13 hours agorootparent> There are reasons \"apogee\" is more recognized word than \"apoapsis\". What are you getting at? The -gee suffix means Earth. Apogee is apoapsis of an orbit around Earth. People playing KSP speak of apoapsis because Kerbin isn't Earth. reply numpad0 13 hours agorootparentIRL they always did and therefore discussed \"apogee kicks\" after payload release into elliptical transfer orbit(literally GTO). That's where I'm getting at. If you think about it, there can't be an ellipse that intersects a circle while also being fully encompassed by the latter. That's to say the periapsis can't be higher than the maneuver altitude that the off-apsis burn takes place as the other guy is suggesting. On real rockets they add small shelf-stable stage such as the spinny boi Star-48 or the notoriously narcoleptic Fregat, inside fairings between S2 payload interface to actual payload, or let the payload pull itself into the final orbit at a great expense. Yes, you can keep the S2 burning all the way to Ap and then burn at -45deg at Ap to deform the ellipse back into a circle, or fly a by the book gravity turn trajectory, but that's not the most energy efficient insertion, only what are situationally beneficial when there is land below and acceleration is limited. reply dotancohen 17 hours agorootparentprevDo they typically burn softly until near apogee, then put on the power until raising the orbit on the other side to their current altitude? In KSP, I can easily get an orbit on a single burn (with staging) but getting it circular obviously requires adding energy at apogee. reply exDM69 17 hours agorootparentNo, most rocket engines have quite limited amount of throttle capability and run near maximum thrust until cutoff. The rocket yaws and pitches in the first seconds of flight while the vehicle is still subsonic, then flies a gravity turn trajectory at zero angle of attack (facing the direction of travel) at near maximum thrust. Any errors accumulated during early part of the flight will be corrected by adjusting the timing of the second stage cutoff based on radar tracking. The initial pitch over is just a few degrees off vertical, but must be precise to a fraction of a degree (KSP tolerances are higher due to small planet). You can get a pretty good circular orbit in Kerbal Space Program with one burn if you do a few attempts and trial and error binary search for the optimal initial pitchover angle, but it's very difficult to do without throttling the 2nd stage burn. If I recall correctly, the MechJeb mod can do a precise single burn to orbit. reply dotancohen 17 hours agorootparentThank you. Yes, I figured that real life engines could not throttle enough for the maneuver as stated. I am familiar with the gravity turn, but I just don't see how energy can be added continuously, uniformly right up to a circular orbit. But I've not really put much effort into trying to understand that, I'll start looking more at real life pitch angles at various altitudes. Maybe I just need to start that gravity turn sooner - you mention that it already starts in the first few seconds. Thank you. reply exDM69 15 hours agorootparentIn vanilla KSP1 with a reasonable orbital launcher, fly up to 1000m altitude and tap D on your keyboard 1 to 10 times. Then hands off until 2nd stage and then throttle down to avoid overshooting the apoapsis. Finding the correct number of key taps to get the right pitch angle is the key. The throttle can only help so much. reply dotancohen 9 hours agorootparentWill do, thanks. 1000 m is in fact much lower than I usually pitch. Off the pad I've been giving just a touch of pitch to ensure that the rocket is on the right trajectory, but didn't start the gravity turn until maybe 5000 m or so to get out of the thick atmosphere sooner. Yes, I would have quite the AoA for a little while. Thank you. Though I don't expect to open KSP any time in the near future, I love to know how the real rockets do it. reply exDM69 56 minutes agorootparent1000m is much higher than real rockets pitch over, but good for KSP with forgiving aerodynamic stress. It's just a convenient round number and gives a few seconds of breathing room to make sure the fiery end of the rocket points to the ground before start of maneuvering. reply ericbarrett 12 hours agorootparentprevMechJeb + Realism Overhaul offers a \"Primer Vector Guidance\" ascent controller that (I think) is based on the space shuttle's Powered Explicit Guidance. It's definitely designed to work with more realistic spacecraft; it can ullage with RCS, doesn't need to throttle, etc. reply firebaze 12 hours agorootparentprevThey do this while performing the burn of the (in this case) 2nd stage. \"No, that's inefficient\" is misleading, IMHO. They also waste some delta-V by starting the circularization burn a little bit early. You surely know that, but mathematically it is unavoidable to have a 2nd burn at the apoapsis to have an orbit (with a periapsis > the initial launch altitude, minus gravity and atmospheric losses), albeit it may start earlier (while wasting a slight amount of delta-v). reply DarmokJalad1701 17 hours agorootparentprev> You need a second burn just to enter orbit Not necessarily - it is completely dependent on the ascent profile. For example, during the Apollo program, the Saturn V would fly directly into a parking orbit and only relight the S-IVB for the Trans-Lunar Injection burn. reply travisgriggs 19 hours agoparentprevI wouldn’t classify the re-entry survival problem as icing. But otherwise, I agree with you. reply DarmokJalad1701 19 hours agorootparentThey can launch payloads that bring in revenue while working on that problem. There is a good chance they put a bunch of Starlinks on the next flight. reply throwuwu 19 hours agorootparentExactly, they’ve reached feature parity with large expendable launch systems so they can piggyback paying customers with a high risk threshold (starlink) on flights they’d be doing anyways. Given their cadence this phase won’t last long, they’ll likely achieve at least one successful landing next flight. reply ortusdux 19 hours agorootparentThey have also been eager to launch version 2.0 starlink satellites, but they don't fit in the falcon fairing. The first couple batches of those would be test articles as well, so I'd be surprised if the next starship launch doesn't a few on board. reply dotnet00 18 hours agorootparentThey've been launching a version of the v2 sats that do fit in the Falcon 9 fairing and supposedly have all the functionality of the larger versions. The issue is that F9 can only carry ~24 of those at a time, which slows down the pace of expansion a lot. reply ortusdux 16 hours agorootparentThe new 'Pez dispenser' on the starship is designed for the full sized V2 sats, which are about 2x the mass of the V2 minis. reply gorkish 17 hours agorootparentprevYes this would all be true, if it were true. It is likely to become true at IFT-4 but they are very demonstrably not quite where you say they are. This was still a suborbital flight and they cannot do much of anything that is commercially practical on suborbital flights (like launch satellites, even if they raise their apogee). They appear to have not had good control authority in coast and reentry. They did not do a relight/deorbit burn test that is likely an obstacle to tackle before they can make orbital flights. I assume we'll get some confirmation about these things soon enough, but please, you can be optimistic without being hasty. reply DarmokJalad1701 15 hours agorootparent> This was still a suborbital flight and they cannot do much of anything that is commercially practical on suborbital flights If they had flown a slightly steeper ascent and burned for a little longer (possibly a minute if not less), they would have ended in a stable orbit. Not doing that was intentional. They do not need engine relight capability to reach orbit - plenty of orbital rockets exist that cannot relight their final stage. reply bdamm 13 hours agorootparentYes, but the point was that they can't launch starlinks or just about any commercially meaningful payload until they are reliably in orbit, and they can't reliably get into orbit until they demonstrate at least one relight, because they need to reliably re-enter the atmosphere for the reusability tests. So they are at least one more launch away from launching starlinks. reply DarmokJalad1701 12 hours agorootparent> commercially meaningful payload until they are reliably in orbit, Which then can do without a relight. > and they can't reliably get into orbit until they demonstrate at least one re-light And part of testing deorbit/landing capability includes testing that they can relight the engine. So they could launch the next one with Starlinks (possibly test articles of those as well since no full-size V2 satellites have been laucnhed yet). Get it into orbit and include a deorbit burn/re-entry as part of the flight plan. If the latter part somehow still does not work out ... they still got Starlinks into orbit. And they now have more data to fix it on the next flight. They already have several vehicles lined up for static fires and flight tests. reply bandyaboot 12 hours agorootparentThey won’t put starship into orbit until they can test relight. They won’t risk, nor would they be allowed to risk putting it up there without a demonstrated ability to bring it back down in a controlled manner. reply DarmokJalad1701 4 hours agorootparent> They won’t put starship into orbit until they can test relight. Why can't they test relight? Also, they are already filing paperwork for IFT-4: https://apps.fcc.gov/oetcf/els/reports/STA_Print.cfm?mode=cu... \"Application includes a sub-orbital first stage booster and an orbital second stage\" reply zardo 10 hours agorootparentprev> They do not need engine relight capability to reach orbit - plenty of orbital rockets exist that cannot relight their final stage. I don't think SpaceX is interested in having uncontrolled Starship re-entries. It's large enough that (even without a heat shield) debris will very likely make it down to surface. reply Laremere 19 hours agorootparentprevThey might do one to test deployment, but it'd be a throwaway. Their relight test was skipped (not said why), so they still don't have confirmation they can control where Starship re-eneters. Until that happens, it's very unlikely they'll target actual orbital velocity. The Starlink satellites do have thrusters, but they're ion engines, so not nearly enough thrust to get that last bit into orbit before they'd re-enter. reply toomuchtodo 18 hours agorootparentAs long as it is profitable when thrown away, the math works. Remember, until Falcon 9, they were always thrown away (except for Shuttle). Even if not profitable in the short term, the delta between cost and breakeven is an R&D expense. Payload able to be delivered to orbit safely and insurable? Ship it. The more you do, the faster you get better. reply baq 18 hours agorootparentprev99% chance that they lost attitude control hence couldn't point the business end towards wherever they wanted to. we know they can relight the engine on the booster and we know they can relight for landing burns. no surprise if the next launch has a couple pre-production big starlink birds. reply LorenDB 18 hours agorootparentOn the contrary, they absolutely had attitude control. Otherwise reentry would have seen the ship tumbling out of control and quickly breaking up. Instead, SpaceX was able to begin a controlled reentry in the upright position, indicating nominal orientation performance. reply Laremere 17 hours agorootparentMy bet on the re-entry failure is that they have really poor attitude control. They definitely had some, but you can also see at different points that the plasma was shifting directions. At T+46, it was doing a spin as the first plasma started to show. At T+47, it was going down on the edge of the heat shields. At T+47:40 it appears to be going down engine first. Moreover, I'm guessing the reason they skipped the mock re-entry burn was due to not being able to settle the propellant. Though it's really hard to tell if the turning of the Starship was to rotate which side was getting heating from the sun, or if it was spinning out of (or with less than desired) control. Tim Todd noticed that the gas thrusters were icing over and then releasing the ice. So it's a reasonable guess that this was part of the issue, but that's leaning even more into speculation territory. reply Laremere 15 hours agorootparentI just noticed that I typed \"Tim Todd\" instead of \"Tim Dodd\". It's past the edit period so I shall forever live with this shame. In my defense, I was on 5 hours of sleep so I could watch the launch. reply bdamm 13 hours agorootparentYou are a contemporary yet timeless sort of gentleman. Well done. reply Plasmoid2000ad 18 hours agorootparentprevI'm no so sure, it at least looked like it was tumbling before and throughout re-entry. If they had attitude control, I think they would have at least stopped the visible rotation at some point before re-entry? I'm not sure why the ship not immediatly breaking up, but eventually breaking up is proof that they at attitude control - especially against what the live feed showed - rotation. reply dotancohen 17 hours agorootparent> If they had attitude control, I think they would have at least stopped the visible rotation at some point before re-entry? Maybe they thought the flaps would help stabilize once hitting some atmosphere. In fact, that seemed to happen though not before quite a bit of plasma cooked the unshielded side. reply numpad0 17 hours agorootparentprevI'd speculate one of main tank bulkheads breached and gas kept leaking from payload door which overpowered RCS. Then, during reentry, the vehicle briefly managed to regain attitude by aerodynamic forces on the flaps, but became north-northwest aligned and broke up. reply baq 18 hours agorootparentprevthey were tumbling, just slowly. they started reentering side first. that it broke at 65km was unsurprising - shuttle experienced peak heating about there. reply bitcurious 17 hours agorootparentprev> know they can relight the engine on the booster and we know they can relight for landing burns. Do we know that? Booster crashed into the water at full speed; landing reignition failed. reply apendleton 17 hours agorootparentThey did demonstrate this during their Starship-only bellyflop/landing tests a couple of years ago. This wasn't in space, though, obviously, and wasn't after an extended coast period. So... we know they can relight them under at least some circumstances, but whether or not they can under _these_ circumstances is maybe unclear. reply wongarsu 19 hours agorootparentprevThey have a great pipeline for building ships. They want reusability, but for near-term needs like deploying bigger Starlink satellites and their moon lander contract they could probably power through without reentry survival. It would be expensive, but unlike in-orbit refueling not really mission critical reply ncallaway 17 hours agorootparent> but for near-term needs like deploying bigger Starlink satellites and their moon lander contract they could probably power through without reentry survival Starlink sat deployment, probably. I’m not convinced on the moon lander contract though. Each mission requires the moon lander itself, plus a number of tanker launches to refuel the moon lander. I think it’s something like 8-15 tanker launches. If each of those tanker launches is an expendable vehicle that’s… probably economically survivable, but definitely not sustainable. reply generalizations 16 hours agorootparentThough, if the tankers are expendable they won't have to reserve fuel for the landing, and the number needed to refuel would probably be at the lower end of that estimate - maybe even 6-10? reply imtringued 11 hours agorootparentprevIf you can't reuse the boosters, then a series of Starship launches to the moon will cost as much as one SLS. The complex launch architecture demands reusability. It's a deal-breaker without it. reply TMWNN 19 hours agorootparentprevMy understanding is that Starship is financially comparable to Falcon 9 on a per-payload basis even if fully expended. reply dotancohen 17 hours agorootparentComparable to Falcon 9? Unlikely - they've got three dozen Raptor engines on that thing, which alone account for the entire cost (not price) of a Falcon 9 flight. Maybe it is comparable to legacy launch providers, such as the Deltas and Atlases. But unlikely comparable to a Falcon 9 launch, even considering the larger payload. reply avmich 13 hours agorootparentIn https://payloadspace.com/starship-report/ the cost of Falcon-9 launch is estimated as $15M. One Raptor is less than $1M, but full Starship has 39 Raptors. Starship will be much more attractive when it will become fully reusable though. reply dzhiurgis 12 hours agorootparentprevYou are launching 8x more payload vs ~15 reuses of Falcon9 reply senectus1 9 hours agorootparentthe weights isn't the only upgrade, the SIZE is another very important metric.... They'll be able to get much larger objects up there without having to piece them together up there. Especially important for habitable objects and factory objects. reply dotancohen 2 hours agorootparentThe current iteration of Starship has a payload bay door fit only for the Starlink satellite. reply thinkcontext 7 hours agorootparentprevThat's what they aspire to. The only way to get there is if they are able to achieve reuse into the dozens of times and there's no guarantee they will be able to do that. I hope they are able to but there's still a lot of work to get there. reply cryptonector 19 hours agorootparentprevIf so that would be amazing. reply bell-cot 19 hours agorootparentprevIf their cost per kg to orbit, with total loss of both Booster and Starship, is substantially lower than any of their competitors - then it is success, and recovery is just icing on their profit margins. Er, cake. (And would be very cool marketing and PR, obviously. Not that SpaceX has much need for either of those.) reply avmich 16 hours agorootparentNo quite; even if 1st and 2nd stages deliver cargo to orbit cheaper than competition, you still has to make sure there is enough demand to pay back the cost of Starship creation. That demand may require not just being cheaper, but to being substantially cheaper than competition, to enable additional uses. What SpaceX is doing with Starlink reminds of the situation with early versions of Windows, when, as Bill Gates described, the industry wasn't keen to produce applications for it. So Microsoft started writing Word and Excel in house. Similarly, SpaceX created Starlink which needs lots of launches, and which couldn't exist with previous level of launch prices, but is able to make profits if the prices are as low as SpaceX can provide. reply cchance 17 hours agorootparentprevRe-entry is icing because every other cargo rocket besides falcon, lands just like IFT3 lol reply imtringued 11 hours agorootparentArtemis 5 only needs three New Glenn rockets. Artemis 3 and 4 need significantly more Starships. reply johnyzee 19 hours agorootparentprevYeah, breaking up in-air during re-entry (at 65 km going by last telemetry) seems like a potential big issue to fix. reply dotnet00 19 hours agorootparentOP's point is that the tests become a bit cheaper and a bit easier to get licenses for since they can get to orbit and can deploy Starlinks. The reentry problems of course have to be fixed, but the FAA mishap investigation will involve fewer delays, just like how Falcon 9 was able to keep flying, attempting landings without having to wait for a mishap investigation to finish every time a landing failed. reply usrusr 13 hours agorootparentIirc F9 had its main challenge in that final suicide burn. Usually the boosters made it there just fine and then \"only\" failed to get the parameters aligned just right. Based on what we saw today, the main chokepoint for Starship might be right in that hot reentry telemetry blind spot. Debugging without logs. reply DarmokJalad1701 12 hours agorootparentUnlike with F9, in this case they most probably had high-bandwidth telemetry all the way till the vehicle broke up (if the high-def video stream is anything to go by). So, they probably have a lot more data this time. Even the video can yield information - for example, given that the cameras were mounted on the flaps, they can probably back out the actuation angles from that. reply dotnet00 13 hours agorootparentprevIt sounded like they might have had flight data recorders on-board which might have survived through reentry with telemetry. If so, they'd have some logs, but yes, figuring out reentry will likely be the main challenge for now, not only is it hard to debug, even getting to it requires everything else to go more or less perfectly. reply smallmancontrov 12 hours agorootparentprevWith all the solid state gizmos we have today, is it really that difficult to make a blackbox that can survive serious impact G-forces, especially if it just needs to work and doesn't need to be safety rated? reply DarmokJalad1701 17 hours agorootparentprev> Yeah, breaking up in-air during re-entry (at 65 km going by last telemetry) seems like a potential big issue to fix. That's what pretty much every non-SpaceX rocket does today with very few exceptions. reply ta1243 14 hours agorootparentAnd indeed every spacex rocket. Starship is the second stage -- and a second stage on a F9 burns up in the atmosphere just as much as Starship from IFT3 did. The big things to fix seem to be 1) The roll rates for starship (which prevented the inflight relighting test) 2) The Booster relights, which didn't have enough lighting to soft land. Both of those feel like minor problems. I'm amazed that the propellant transfer demo seems to have worked first time, and of course they managed to get the tihng up there in the first place. The reusability of the Starship part of the system is a much bigger unknown, but that doesn't seem to be necessary for the next launch. Wouldn't surprise me if the next try is by the end of April reply aeternum 13 hours agorootparentprevWhy? Saturn V broke up in-air during re-entry on every \"successful\" launch as does every ULA rocket. reply johnyzee 13 hours agorootparentBecause that is their stated design goal for Starship. reply DarmokJalad1701 12 hours agorootparentAnd you don't need to meet that goal to start launching (risk-tolerant) payloads to orbit during their test flights. Especially with such a hardware-rich development program. reply tempaway444641 19 hours agorootparentprevThe point they were trying to make is that getting up is MVP, getting back down can be figured out later reply baq 18 hours agorootparentprevit's the expected outcome of an imperfect (literally not precisely perfect) reentry. something went wrong. it could be a very minor thing like a stuck valve somewhere. we'll know in the next test if they figured it out. reply engineer_22 14 hours agorootparentprevbright side: booster made it all the way to splashdown reply senectus1 9 hours agorootparenthaha, it was travelling at 1100 km/h... Not so much a splashdown but a smashdown :-D reply kristianp 12 hours agoparentprevMaybe the words \"success\" and \"failure\" are too difficult to shoehorn into describing these tests, especially with the first two tests. \"Great progress\" is a good intermediate. reply HeyLaughingBoy 12 hours agorootparentWhen you write a test case, you define what \"Passed\" means. If this test flight overall meets SpaceX's definition of \"Passed\", then it was a success, regardless of what anyone else thinks it should mean. reply pclmulqdq 12 hours agorootparentIf your test case for left pad passes when it outputs a string of the right length, your boss is going to judge whether it's a good test case. Since this is all being done on federal grant money, it's legitimate to have higher expectations. This test was good, though - the previous two were disappointing. reply f-securus 12 hours agorootparentHoly cow. How are people downplaying something so revolutionary. Without those other tests SpaceX wouldn’t have done what it did today and they show progress each step. They are doing what nasa couldn’t (send stuff to space orders of magnitude cheaper) because they aren’t afraid to blow stuff up. reply 2OEH8eoCRo0 11 hours agorootparentThey haven't gotten to the revolutionary part yet (fuel tankers in orbit, raptor relight, reusable first stage, reentry). reply f-securus 11 hours agorootparentRe-using rockets isn't revolutionary? reply jordanb 10 hours agorootparentI think it might have been back when the shuttle did it in 1981. reply f-securus 10 hours agorootparentThe shuttle that cost 450 million per launch? (And disposable boosters) reply paledot 9 hours agorootparentThe boosters parachuted to the ocean and were reused. Only the external fuel tank was not reusable. However, you're correct that the Shuttle failed utterly to realize the point of reusability, that being low cost and quick turnaround. reply pclmulqdq 11 hours agorootparentprevNobody has done anything revolutionary and nobody has gotten to space an order of magnitude cheaper. The best estimates of SpaceX's cost advantage per kilo put it at 30-50% better than a Soyuz. The Starship program so far has soaked up as much money as SLS, and hasn't even left orbit. reply thinkcontext 8 hours agorootparent> The Starship program so far has soaked up as much money as SLS, and hasn't even left orbit There's a bit of nuance to what you are claiming here. SLS cost $11B to develop, which is estimated to be in the neighborhood of what Starship will cost when development is complete. We don't know how much has been spent so far. A huge difference is that producing and launching an SLS rocket costs over $2B, while SpaceX is estimating $10M for Starship. Now, I don't trust that $10M number, that's what they aspire for it to cost. To do it they need to be able to reuse the stages dozens of times. It could take a long time to achieve that or they might not make it at all. However, $2B+ per launch is a whole 'nother level of expense. reply jiggawatts 11 hours agorootparentprevThey did several revolutionary things with starship: Full-flow staged combustion metholox engines. Stainless steel construction. Biggest rocket to have ever flown. Highest thrust at launch of any rocket by a factor of two or so. Live streaming of reentry via a space Internet network. Etc… reply pclmulqdq 11 hours agorootparentThose all sound like incremental technology advances to me that have yet to deliver any real advances in capabilities. Which is nice - don't get me wrong - but not exactly worth rolling out the aircraft carrier for. reply baq 2 hours agorootparentFull flow methalox is absolutely revolutionary. reply jiggawatts 10 hours agorootparentprevSomeone else in this thread pointed out that Starship could get the ISS built in just 3 launches! It originally took dozens. Quantity has a quality all of its own. You should be familiar with this from IT: there’s nothing fundamentally different about the first computer that I’ve ever used to the one I have right now, other than the factor of a million difference in performance! reply pclmulqdq 8 hours agorootparentStarship today can't launch anything. Saying that it can launch the ISS in 3 launches is what Elon Musk says it can do. I don't trust Elon Musk's word for things until I see what someone does with those words. Generally, he is off by a factor of 10-100 on his promises. reply DarmokJalad1701 4 hours agorootparent> Starship today can't launch anything Why not? With the capability demonstrated today, they can just as easily tweak the ascent profile to end up in a stable orbit outside the atmosphere. Their trajectory was suborbital on this flight on purpose. reply bandyaboot 11 hours agorootparentprevThe test flights have been right in line with how spacex does development and testing. I’m confident that everyone involved with granting them that money knew this going in. reply jordanb 10 hours agorootparentIt's fine that they've not yet completed any stated launch objectives in three tests and have, amongst them, 5 independent catastrophic vehicle loss events because that's what we expect out of SpaceX. reply thinkcontext 9 hours agorootparentprev> Since this is all being done on federal grant money Its true that SpaceX has gotten federal money contract for landing on the moon to the tune of $2.9B. But the Starship program is going to cost a lot more than that, Musk estimated $10B and has done stock offerings to raise money. And you have to take into account that the federal money has to support 100% of the moon specific parts of development. So, its true that the feds are helping w/ Starship development but \"all\" is not accurate. reply zer0c00ler 11 hours agorootparentprevI think each test served exactly its purpose and it's incredible to see the rapid progress. Unclear why you believe the first two were not a success at all? Did you expect a novel vehicle like this would just work the first time? reply pclmulqdq 11 hours agorootparentI do. SLS, Vulcan, and most other rockets from reputable space companies have worked first time. reply macintux 10 hours agorootparentThose are also: - More expensive than Starship, or - Took longer to develop than Starship, or - Are significantly less ambitious than Starship (and those are definitely not exclusive ORs) reply pclmulqdq 10 hours agorootparentGoing by total program cost, both of those are cheaper than Starship. SpaceX does this sleight of hand where they don't count their R&D cost in their calculations, but they do count it in other peoples' programs when comparing. SLS so far is about $2 billion in, and Starship seems to be at $2-3 billion. Vulcan is way cheaper than both. reply relativ575 8 hours agorootparentSLS flight cost is $2B. Each launch. Did you forget to include the decade prior? It's so expensive that it can fly no more than once a year. The next flight is scheduled for Sep 2025, three years after the first flight. I bet you think that isn't absurd. SLS use leftover engines from the Shuttle era. Yet it still cost 160 millions. Each. Thrown away after each flight. Vulcan is a conservative design with no reuse. It also uses BE-4 engine, which costs them nothing to develop. reply sobellian 9 hours agorootparentprev- Source for Vulcan total program cost? All I can find is their per-launch pricing. Tory Bruno himself apparently said that \"new rockets typically cost US$2 billion, including US$1 billion for the main engine.\" - Not sure where you're getting the SLS number, the GAO report at https://www.gao.gov/assets/gao-23-105609.pdf claims, \"Since 2011, NASA has spent $11.8 billion to develop the initial SLS capability.\" - I think the marginal cost is a fair question. The whole party line out of NASA was that this time Moon exploration would be sustainable. If each trip costs > $1B before you even put a payload on the rocket that's a big problem. reply pclmulqdq 8 hours agorootparentI completely agree with you on marginal cost, but I don't believe SpaceX to provide accurate numbers for their own rockets before they are actually built (they love wishful thinking) or their competitors' (making your competitors look bad is better for you). reply sobellian 8 hours agorootparentOkay well respectfully I looked at the number you provided for the closest comparison rocket, SLS, and it was 6x too charitable. reply gabesullice 9 hours agorootparentprevThe word reputable was an interesting choice to describe Boeing. It also carries a bold implication that the space company shuttling astronauts to and from the ISS—only two days ago [1]—is… disreputable? Meanwhile, Boeing Starliner certainly didn't perform nominally on its first orbital flight test [2]. Space flight is hard and different testing methodologies are no silver bullet. But, I suppose we will know them by their fruits. [1] https://en.m.wikipedia.org/wiki/SpaceX_Crew-7 [2] https://www.washingtonexaminer.com/?p=802006 reply tibbydudeza 3 hours agorootparentprevAnd the Saturn V reply bane 16 hours agoparentprevHere's a fun thought, how many Starship launches would it take to put the equivalent mass of the ISS up in the same orbit? reply DarmokJalad1701 16 hours agorootparentThe ISS weighs ~420 metric tons. That is 2-3 expendable launches or 3-4 reusable ones. reply trailynx 15 hours agorootparentfor comparison, building the ISS took 40 assembly flights [0] (36 of them from the Space Shuttle) [0] https://en.m.wikipedia.org/wiki/Assembly_of_the_Internationa... reply GeoAtreides 15 hours agorootparentprevJesus Christ, that really puts it into perspective what a game changer starship is reply bane 15 hours agorootparentNow do the same calculation in units of hubble space telescope and james webb space telescope masses. Then look at expected reusable launch cost and figure out how many HSTs or JWSTs we could have put in orbit for the same cost. reply 93po 14 hours agorootparentJWST would also be incredibly less expensive if it didn't have to do the very complex folding required by smaller rockets reply Retric 13 hours agorootparentJWST would still have been an extremely novel and therefore expensive on Spaceship. We just don't build anything that uses that kind of sun shield or those sensors etc and everything needs to work on one shot, thus serious engineering effort. reply Teever 11 hours agorootparentWith Starship flights it should be the right combination of cheap enough, frequent enough, and big enough to enable whole new paradigms of construction in space. We'll be able to design modular space telescopes that benefit from economies of scale, so that we'll be shipping up the sun shield in separate pieces anyways so if any particular one is lost that's okay we'll have an assembly line to produce more. reply Retric 10 hours agorootparentLaunching several doesn't solve the issue of needing a design and construction that actually works. For something nobody has ever built before and we can't really test in zero g without launching etc. Unfolding the heat shield was a relatively minor design issue compared to say the instruments, we just had less ability to actually test it on the ground. reply Shawnj2 11 hours agorootparentprevLaunching JWST on Starship would still be incredibly expensive because JWST is at the Lagrange point on the other side of the moon and 1 starship needs like 30 other starships to fuel it to get there reply 93po 6 hours agorootparentHow do you explain how the Ariane 5 used for the JWST, with a mass to GTO half that of Starship, was able to position the JWST without 60 launches? reply Shawnj2 5 hours agorootparentSimple, it’s designed to launch a payload into lunar orbit and starship isn’t. To move something using starship into lunar orbit you need to move an entire starship there while the Ariane 5 is designed to do it in 1 launch at the expense of much less payload capacity and no reusability. reply birdman3131 12 hours agorootparentprevHow much larger could we have made it still doing the folding on starship? reply 93po 5 hours agorootparentI have no idea. Ariane 5 rocket has payload dimensions of 15x50 feet. Starship is 26x56ft. The unfolded mirror is 21 feet across, so if you increased that by 73%, then 36 feet. This is all probably really unfounded assumptions The benefit of starship here is probably being able to massively reduce the expense and risk of future JWST duplicates that don't need to fold. Also in the launch cost, which was $1 billion for Ariane 5 whereas Starship would be in the tens of millions. reply danw1979 14 hours agorootparentprevNot just the capacity per launch but the cost per launch also. reply 2OEH8eoCRo0 14 hours agorootparentprevHow many launches are required to land on the Moon? reply DarmokJalad1701 13 hours agorootparentDepends on what lunar lander hardware is being used. If we were using Apollo hardware: Apollo LM: 16 metric tons (landing about 5 tons on the moon) Apollo CSM: 29 metric tons The third stage of the Saturn V, called the S-IVB, (which was used for the trans-lunar injection burn) weighed 123 tons - however this was also used to get into the initial orbit. Starship can launch 150 tons to LEO in reusable mode or ~200 mt when expended. The Saturn V was able to launch 141 tons to LEO. So it should theoretically be possible for Starship to launch an LM+CSM stack with an S-IVB with enough fuel for a trans-lunar injection burn. Then fly the rest of the mission as in Apollo. Or we can refuel the Starship a few times in LEO using a bunch of re-usable flights and land 100 tons of payload on the lunar surface. The latter is probably cheaper and simpler at this point. reply GuB-42 11 hours agorootparentprevAccording to this: https://youtu.be/OoJsPvmFixU?si=Df6Eq9uq6IJCApUs&t=1730 Six... eight... more like twelve... at least 15 reply rtkwe 15 hours agoparentprevBig things they still need to hit are soft splashdown of both stages because recovery and reuse are critical to the economics of Starship. From the stream it looks like they had barely any engines light during the landing burn and I could see several missing tiles on the second stage. Way fewer were missing though which is a bonus, last time they were visibly missing a lot of tiles even before they lost the stage. reply ajross 19 hours agoparentprevNot quite: the apogee burn they had planned didn't happen (no word as to why yet), so the ship didn't technically demonstrate the capability reach orbit. It came back down in the Indian ocean on its original suborbital trajectory, essentially like an ICBM. reply DarmokJalad1701 19 hours agorootparentThat is a matter of the trajectory they chose on purpose for this test flight. A different flight profile would have given them a perigee above the atmosphere (rather than -50 km) reply Laremere 19 hours agorootparentParent's (correct) point is that it isn't a matter of the ascent trajectory. They can't leave the Starship up in orbit, and where it reenters needs to be controlled. reply DarmokJalad1701 19 hours agorootparent> They can't leave the Starship up in orbit, and where it reenters needs to be controlled. Why? Plenty of boosters re-enter uncontrolled and burn up all the time. reply dotnet00 18 hours agorootparentTypically American policy is to have a controlled reentry option for as much as possible. The disposable first stages of all rockets don't need a controlled reentry because they are always suborbital and thus their splashdown location is relatively well known ahead of time. The second stages are typically supposed to deorbit and burn up over water after a launch to LEO. There are occasional cases where something goes wrong and they fail to deorbit, which is when we sometimes hear of the burn up due to gradual orbit decay being witnessed over land. reply Laremere 19 hours agorootparentprevAfaik, when talking about objects large enough that some debris will actually hit the ground, only China intentionally lets their final stage re-enter uncontrolled. Everyone else at least has a plan for controlling re-entry. SpaceX has lost control of some of their Falcon 9 second stages before, but that's the exception not the rule. reply terramex 19 hours agorootparentprevNon-reusable boosters don't go into orbit and perform calculated crash into ocean soon after launch. Small second stages and spacecrafts can be allowed uncontrolled orbital reentries because they usually burn-up. Starship is too big for that, debris would rain like when Space Shuttle Columbia disintegrated over land. They most likely will need to show engine relight capability to control reentry point before going orbital. reply Toutouxc 19 hours agorootparentprevFirst thing that comes to mind: Starship has a lot of protection against burning up, so huge chunks of it could survive and cause damage. reply wolf550e 18 hours agorootparentprevStarship is huge and heavy and made of steel, it will not burn up on reentry, if it falls on a populated area it will kill people. They will not be allowed orbital trajectories until they demonstrate they can control the deorbit burn. reply dotancohen 17 hours agorootparentAn empty Starship has a very low ballistic coefficient, it will be torn apart by the atmosphere if not carefully controlled. Add to that the FTS and there is no real danger to population on the ground. reply wolf550e 16 hours agorootparentOf course it will not maintain its shape, but the pieces that land will be large. It's made of 4mm thick steel sheets, and the FAA disagrees with you. reply mlyle 13 hours agorootparentprevColumbia was torn apart by the atmosphere... and dropped huge chunks that were a danger to people on the ground-- some as large as a VW Beetle. reply golol 18 hours agorootparentprevOk so they could leave Starship in orbit and launch payloads like that. The idea however is to launch payloads WHILE testing reentry and landing. This requires an engine relight in orbit. reply DarmokJalad1701 13 hours agorootparent> WHILE testing reentry and landing. > This requires an engine relight in orbit. The latter is part of the test at this point of development reply ajross 19 hours agorootparentprevStated simply: zero-thrust \"orbits\" repeat the same trajectory again and again. So if you end your burn in the outer atmosphere near your launch pad, the next time around you will be back in the outer atmosphere (near where the the launch pad \"was\", ignoring the rotation of the planet). And since there's air there providing resistance, you'll re-enter and crash. Getting to orbit requires at least one more burn near the apogee of the original orbit to circularize it and ensure the spacecraft doesn't approach the atmosphere again. Starship didn't do the apogee burn they intended to do, so didn't demonstrate this capability. reply DarmokJalad1701 17 hours agorootparent> Getting to orbit requires at least one more burn near the apogee of the original orbit to circularize it and ensure the spacecraft doesn't approach the atmosphere again The Saturn V went direct to Earth orbit without requiring relighting the third stage engine. reply DiggyJohnson 17 hours agorootparentprevSinge burn to orbit is pretty common though in reality, with the dynamics of staging, engine throttling, and precision insertion capabilities most modern rockets can hit the mark. reply iwontberude 19 hours agorootparentprevnext [13 more] [flagged] dang 16 hours agorootparentPlease don't replace the text of comments like this once they have replies. It's unfair to the users who responded because now their comments lack the necessary context to be understood. We're all wrong sometimes and it would be fine to add an \"Edit:\" after the original text followed by an explanation or retraction or whatever you want. reply dotnet00 19 hours agorootparentprevThat's impressive revisionism. Where's the Soviet reusable launch vehicle that is half the price, is able to reuse even one stage and takes less than a month to refurbish? reply iwontberude 19 hours agorootparentNevermind reply dotnet00 19 hours agorootparentThe latest Soyuz revision is ~$50m per launch, it has a payload less than half of a Falcon 9 that lands on a droneship, and ~2/3rd of a Falcon 9 that returns to launch site. Making it twice the cost per kg. The highest flight rate it has ever achieved has been 2/month. It has a 96% success rate. The latest Falcon 9 revision is ~$67m per launch. Lately it flies every ~3 days. Over the past year it has flown ~100 times. It has a 99.4% launch success rate, and a 98% landing success rate. Clearly this shows that the Russians are superior. reply golol 18 hours agorootparent>The latest Falcon 9 revision is ~$67m per launch And that is the price, the cost is unknown but likely lower. reply dotnet00 18 hours agorootparentYeah, the internal cost is believed to be ~$30m, but I didn't compare on that number since we don't have a well known number for Soyuz's internal cost. reply iwontberude 18 hours agorootparentprevI don’t know what I’m talking about. Thanks for the info. reply tempaway444641 17 hours agorootparentProps for replying reply GolfPopper 19 hours agorootparentprevSounds like the Russians could clean up in space-launch market. Why aren't they? reply DarmokJalad1701 19 hours agorootparentprevInteresting. What is this amazing Russian rocket that can put 200 metric tons in Low Earth Orbit while being expendable? reply blkhawk 19 hours agorootparentprevGood thing that falcon 9 is already very much less than \"half\" the price. And starship should be utilized fully will probably ven cheaper for the same mass-to-orbit reply tempaway444641 19 hours agorootparentprevShow me anyone that _ever_ got a cost per kg to leo cheaper than spacex reply gameshot911 17 hours agoparentprevI'm not sure the payload doors successfully opened and closed. Anyone have more details? reply hagbard_c 17 hours agorootparentI heard the announcement about the door opening and saw - what I assume to be - live images from the inside which showed the door first opened, then closed so it seems that test worked. reply MostlyStable 11 hours agorootparentScott Manley seems to believe that there was some kind of malfunction with the doors[0]. I couldn't really tell from the video, but he certainly knows a hell of a lot more in this domain than I do. He does agree that overall the test was highly successful though. [0]https://youtu.be/8htMpR7mnaM?t=512 reply jkjkjjjkjkj 15 hours agoparentprevWell, the second stage definitely needs to survive re-entry if it wants to carry passengers. But it seems to work as-is for orbital cargo. reply mgiampapa 14 hours agorootparentPassenger rating isn't even in the cards for Starship for a long time. You ride to LEO on a Falcon-9 with a proven track record for the foreseeable future. reply avmich 13 hours agorootparent\"Foreseeable\" is roughly \"five years\"? Starship HLS (Human Landing System) is currently planned to land on the Moon, with people, in 2026. It may very well slip a year, two or three - but landing on the Moon this decade still seems quite possible. Or you consider \"passengers\" different enough than \"crew\"? reply mgiampapa 13 hours agorootparentYes, landing on the Moon without an atmosphere is vastly different from orbital flight on earth and has an entirely different risk profile. reply grecy 12 hours agorootparentprevInteresting Asterix on that is the humans will only be on Starship from Lunar orbit down to the moon surface and then back to lunar orbit again. No humans aboard during Starship launch, transit to and from the moon or re-entry. (For completeness, humans will do all that other stuff aboard SLS and Orion. Starship literally only ferries them down the moon and back up again) reply avmich 11 hours agorootparentYes, but HLS is just one example. In, say, ten years it may look very possible that Starships with people will fly on LEO. Is it beyond foreseeable future?.. I just don't understand why such a pessimistic estimate. reply mgiampapa 11 hours agorootparentIn my view, since I was the one that said it, anything more than 5 years away is perpetually 5 years away until it's been proven. Yes, eventually when Starship has enough launches and a track record it will get human rated by NASA to carry astronauts. This is the only actual certification for human space flight worth paying attention to right now. It's possible to get on a rocket otherwise, but the US government isn't going to pay for the ride. Getting flight certified by NASA is expensive and requires a level of experience with the vehicle that doesn't make sense for at least 5 years given we have a cheap and safe ride to LEO via Falcon / Dragon. Nobody is going to rush human flight on Starship, it's only going to have people on it once it's already in space. reply avmich 11 hours agorootparentI'll still take this as progress. With thermonuclear reactors it's perennial 20 years, similar for flying cars, in-house robots, manned flight to the Mars, so 5 years as a stand-in for \"foreseeable future\" sounds like a good step ahead. reply grecy 9 hours agorootparentprevI just looked it up. The first Falcon 9 flight was June 2010. The first Falcon 9 with astronauts was May 2020. 10 years to get human certified. reply mgiampapa 8 hours agorootparentThat was also with a rush order on it due to the Shuttle's retirement. reply grecy 6 hours agorootparentGood point. In those 10 years Falcon 9 flew 84 times [1]. So I would think Starship needs to fly roughly a similar number of times before it will be human rated. Even if they launch one a month from now on, it will take ~7 years. So I think we're a while away from NASA certifying Starship for human flight, though I wonder in SpaceX would just put their own people on it regardless. [1] https://www.popularmechanics.com/space/rockets/g32758515/fal... reply enraged_camel 19 hours agoparentprevI think they also successfully demoed in-space fuel transfer. reply xondono 19 hours agorootparentFuel transfer with what? That would require things like docking reply Tor3 19 hours agorootparentThey transferred something like 10 tonnes of fuel from one end of the ship to the other. reply cchance 17 hours agorootparentprevThey used tanks inside the ship to transfer from 1 to another to prove the process, was discussed and called out as success, and talked about many times before the flight reply enraged_camel 19 hours agorootparentprevThey performed an in-ship fuel transfer, from one chamber to another. My understanding is that this is a very important pre-requisite for an actual transfer from one ship to another, because of the need to keep the fuel at cryogenic temperatures during the transfer, which is apparently not easy. Last time it was done was decades ago, but in kilograms. SpaceX just demoed a transfer of tons of fuel. reply extraduder_ire 17 hours agorootparentBigger problem than keeping it cryogenic is getting it to one side of the tank while in orbit, so the pumps don't run \"dry\". Harder than just doing an ullage burn first too, because moving that amount of mass around also moves the vehicle. reply hagbard_c 19 hours agorootparentprevTransfer internally between tanks in the bottom and top of the ship. This was one of the planned tests, I have not heard whether it was accomplished though. reply dotnet00 19 hours agorootparentThere was a callout saying that it was successful. Edit: On the other hand tweets from Gwynne suggest that they still need to review the data to see if it was a success. reply senectus1 9 hours agoparentprevthe open and close of the payload doors was a failure. Not that i think its a big deal... but its important to acknowledge failures so we can learn from them. reply fernandotakai 19 hours agoprevthose plasma views when starship was coming into atmosphere were absolutely mind blowing. it makes a lot of sense to use starlink for this, but it never ever crossed my mind. reply kkoyung 19 hours agoparentHaving those plasma views in livestream. It is incredible. reply schnitzelstoat 19 hours agorootparentYeah, in HD. It's sci-fi stuff. reply yreg 17 hours agorootparentJust like the first belly flop video. The thirty seconds from 1:00 are unreal. https://www.youtube.com/watch?v=gA6ppby3JC8 reply chinathrow 19 hours agorootparentprevAs of today, it's the new normal! reply mrandish 16 hours agorootparentThe new norminal! reply chasd00 19 hours agorootparentprevyeah that was really cool, it looked like an artist rendition of what it could look like hah. I'm looking forward to high-res photos of those views. reply ordu 19 hours agoparentprevThe booster puncturing spheres of clouds on a way back was awesome also. reply danw1979 14 hours agorootparentThat was my highlight of the test: live video of the biggest rocket booster hitting the ocean at 1000km/h. reply tempaway444641 19 hours agoparentprevvideo: https://twitter.com/SpaceX/status/1768279990368612354 Note the camera moves because its also on a flap reply mrandish 12 hours agoparentprevIndeed! I just want to thank SpaceX for giving me yet another \"This looks like insane Hollywood special effects but it's real\" moment. reply tempaway444641 20 hours agoprevT+37: Seems a little turny-aroundy in orbit there and a bit \"small-pieces-falling-offy\" Still, good job getting it there T+43: seems to be turning around a bit too much for something thats got heat shields on one side and is about to re-enter T+45: flaps moved, maybe that is supposed to get it the right way round, I get it now - it uses the flaps to orient for re-entry T+46: the little bits of debris must be tiles coming off T+46: flap glowing red, can see plasma (edit: spacex tweeted a video of this bit, its quite something https://twitter.com/SpaceX/status/1768279990368612354 note the camera position moves because the camera is on one of the forward flaps) T+47: \"biggest flying object ever in space\" uh-oh T+47: serious re-entry flames T+48: loss of signal T+54: still no signal T+62: saying they lost signal via starlink and TDRS at same time so maybe that was the end of it T+65: confirmed lost during re-entry T+67: the presenters all eat a large pie. each. reply namaria 19 hours agoparentI'm still in awe that I got to watch a reentry live stream just now. I wish I could tell my child self what wonders were in store. Watching humanity progress in real time is amazing. reply AnimalMuppet 16 hours agorootparentKids. I got to watch a moon landing live. (Not a stream, and crummy resolution, but still...) [Edit: I meant to be talking smack a bit, but don't let me ruin your enjoyment of the really amazing things that are happening now.] reply twh270 14 hours agorootparentYeah, it's pretty awesome to watch \"the first\" of something! I wasn't born early enough to watch the moon landing, but I did watch the livestream of the first successful landing of a Falcon 9. Watching that bit of science fiction turn into reality was one of the more memorable moments of my life. reply namaria 13 hours agorootparentprevIt's all good, I feel like we're all kids when we wonder about the universe reply pixl97 19 hours agoparentprev>T+46: the little bits of debris must be tiles coming off Seemed like ice to me, which itself can be it a problem. The vehicle didn't seem very stable even before this point so I'm wondering if we're getting ice build up on the cold gas thrusters which changed the control dynamics keeping the ship from flying stably. reply rtkwe 15 hours agorootparentRight after the engine cut-offs for the second stage from the first burn you can see at least one tile missing and during the burn before that I also saw some dark flecks fly off. It certainly looked like there was either a fairly continuous firing of the cold gas thrusters, a stream from the second stage engines, or some atmospheric effects from being in such a low orbit. reply tempaway444641 19 hours agorootparentprevYeah could be. Some of the debris looked very specific in shape though. On some shots of starship you can see missing tiles (not many though) reply K0balt 12 hours agorootparentIt looked to me like a good portion of the debris was in fact tiles. It also seemed to me that there were significant attitude control deviations, both of which might have been significant factors in the unplanned disassembly event. reply namaria 21 hours agoprevI was just watching Spacex official stream and at ignition they switched to Musk hawking cryptocurrency. What just happened?? edit: wild I just realized take off is 50 minutes from now... what had I been watching?? they did a countdown and there was ignition... was that a time wrap? Am I going insane? edit2: @spacex034 is not @spacex... today I learned... reply cam72cam 21 hours agoparentSpaceX does not stream on YouTube, you are watching an old launch on a fake channel. Please report them. reply dpcx 21 hours agorootparentIs that new? Because SpaceX has streamed launches on YouTube for years. reply TOMDM 21 hours agorootparentYes, the official stream is only on Twitter now. reply greedo 20 hours agorootparentThey also stream the launch live on the spacex.com website. reply ta1243 20 hours agorootparentThank you I tried signing up for twitter but gave up at the \"match these dice with these symbols (1 of 10)\" stage. It's not a great interface compared with youtube etc, not rewinding etc, but at least it works reply sneak 20 hours agorootparentprevThat’s a Twitter embed on the SpaceX website. It’s still streaming from Twitter. reply dylan604 19 hours agorootparentbut no Twit...er, X account required reply namaria 14 hours agorootparentI will be deep in the cold cold ground before I recognize Twitter's new name reply dylan604 11 hours agorootparentyou see how I refer to it. it gets both names in there, and expresses the disdain and the confusion all in one go. reply Hamuko 20 hours agorootparentprevMusk decided that Twitter is now a video platform and he's decided to dogfeed with SpaceX. reply atonse 20 hours agorootparentTwitter was a video platform before Musk took over. They were doing Thursday night football (NFL) and other things. Looking at the SpaceX feed, they seem to be using whatever tech they got from the Periscope acquisition (at least the servers were still pscp.tv). reply Hamuko 19 hours agorootparentTwitter was not a video platform – it had (some) video features. Very different. And people always considered Twitter videos to absolutely suck. reply hnbad 12 hours agorootparentThat hasn't really changed though. He's just decided to manifest \"Twitter is a video platform\" into existence. The controls are still total ass though. reply pixl97 21 hours agorootparentprevThey did that for IFT-2 and the first channel I went to was one of those crypto bullshit things too. Very dumb decision on SpaceX's (well probably Musk himself) part. reply namaria 21 hours agorootparentprevDang I got got. Thanks for letting me know reply bluescrn 20 hours agorootparentYou weren't the only one, I clicked on it too, as did thousands of others, before finding a real stream reply sneak 20 hours agorootparentYouTube does a bad job of real time takedowns of spoofed live streams. You’d think for big events like this they would have somebody just standing by and monitoring social stuff so that things like this don’t happen. Then again you'd think one of Amazon's 1.5M employees would have the job of finding fake USB sticks for sale on the site, but apparently nobody has that title either. reply dylan604 19 hours agorootparent> You’d think for big events like this they would have somebody just standing by This implies that YT has humans that are not in sales. It feels like YT just has bots building more bots at this point. reply jfoster 21 hours agoparentprevThere's a fake SpaceX YouTube account that looks official because they included videos from the real channel in playlists to get verification ticks & have managed to harvest thousands of subscribers. YT's interface is a bit dumb for including the verification ticks in that use-case. reply trollied 19 hours agorootparent> looks official because they included videos from the real channel in playlists to get verification ticks That is not how it happens. The account is verified because it is a stolen account that had lots of subscribers & views. They hide/delete the existing videos & rebrand the channel. It famously happened to Linus Tech Tips last year after a staff member fell for a spear phishing attempt. reply smallmancontrov 20 hours agorootparentprevYT's interface fights negative feedback harder than a spoiled toddler. Hiding downvotes, squirreling the \"block channel\" feature into a dot menu, breaking it completely on recommended pages, and then breaking search pages... it's almost like they don't want to fight spam. reply sph 19 hours agorootparentThey're in the ads business - watched hours = money. Why remove spam and clickbait when it means less money? Youtube is the stereotype of post-hype company that is just milking its users to increase their bottom line, driving the entire product to a slow death. reply dylan604 19 hours agorootparentprevThey get paid to serve that spam. Why would they reduce the avenues to serve the spam? reply sph 21 hours agoparentprevYou got bamboozled by an AI Elon deep fake. reply namaria 20 hours agorootparentOh man and I had just downloaded the top result when searching app store for bitcoin wallet to send him bitcoin so he would double it for me! reply bbarnett 19 hours agorootparentWait, double it? Would you please link me? reply fallingknife 19 hours agorootparentScrew that! I'll triple any BTC you send to this address: fjreisorhsksjshsjsjsj reply bbarnett 18 hours agorootparentI'm sorry sir, but my software won't take that address, a typo? Please resend. reply elif 20 hours agoparentprevthis is probably exactly why x started doing video. youtube is so full of fake channels that it readily presents fake ones at the top of search results. the x stream has been great and had a far greater reach (2.5 million) than any of the youtube streams by a factor of 10x or so. reply russdill 18 hours agorootparentNSF had 1.5M views on their stream, Everyday Astronaut had 1.8M views. reply ajross 20 hours agorootparentprevTwitter is awash with garbage too, likely even worse. Every major account, without exception, has multiple fake clones (often many created per day) running around trying to steal clicks and occasionally phish users. The Internet is just hard. You're just saying that the Twitter official account is official. No reason you can't have an Official Account anywhere else, SpaceX just doesn't. reply elif 20 hours agorootparentwhen you search spacex on x, you are presented the official account first. when i searched spacex on multiple youtube apps this morning, i couldn't even find the official spacex account after going through pages of menus. reply ghufran_syed 20 hours agorootparentThis is what shows up for me: https://www.youtube.com/spacex reply elif 19 hours agorootparentyou are searching channels. that is not available on, the roku app, for instance. if you search by channels on x, for fair comparison, there are no spoofed spacex accounts to be seen anywhere. https://twitter.com/search?q=spacex&src=recent_search_click&... reply ajross 20 hours agorootparentprevAgain, because there is no official SpaceX feed on YouTube, they deleted it. Can you link to the channel you think you should be seeing? To be clear: if you search for \"SpaceX\" on Google, you get the corporate website as the first link and the Twitter account as the second. But YouTube has nothing to show you, by SpaceX's choice. reply cchance 17 hours agoparentprevya theirs a shitload of fake spacex streams with AI generated crypto scams reply cruffle_duffle 13 hours agoparentprevDude, we encountered that yesterday. Somebody really figured out how to successfully pretend to be a spacex livestream! It was super weird, right? reply mavhc 21 hours agoparentprevyou were not watching the Spacex official stream? reply fabian2k 20 hours agoprevLooked very impressive and there is enormous progress compared to the earlier tests. Especially as all engines seemed to work throughout the entire launch, the earlier tests had significant engine troubles so they seem to have a handle on that now. The reentry burn failing doesn't seem like a huge deal in this case, especially as the engines worked very well earlier. reply XorNot 19 hours agoparentIts still an issue because they haven't really confidently demonstrated a relight of the engines while flying. Hot staging avoids a relight, but they still need to do it. It does mean they technically have an expendable heavy launch vehicle though. reply hughes 19 hours agorootparentThe boostback burn demonstrated relight today. reply Daneel_ 18 hours agorootparentThe key demonstration is “relight in a vacuum”, which was the test that was skipped late in the stream. If you can do this then deorbiting is possible. Relight of the booster doesn’t demonstrate this, unfortunately. reply hagbard_c 19 hours agorootparentprev> It does mean they technically have an expendable heavy launch vehicle though. That is how they started using Falcon 9 as well: first expendable but testing recovery - which failed several times in several interesting ways - until that process was refined into what now seems to be a normal thing: the first stage launches, drops off a second stage, turns around and makes its way back to either the launch site or a floating platform. I assume they have the same plans for this system: launch expendable while using the hardware to refine the process of recovery until in not that many years from now they launch and land and launch again. reply perihelions 20 hours agoprevIt's in orbit! (\"...and we have a callout for nominal orbit insertion...\") edit: Not actually in orbit! This is a suborbital flight. Mea culpa reply preisschild 20 hours agoparentTechnically its suborbital reply dotnet00 19 hours agorootparentTechnically it's a transatmospheric orbit. That is, an orbit such that it'd stay up there if the atmosphere were not present. The difference between this and full orbit is just a few seconds longer burn, so it's a difference with little meaning in terms of proving out the ability to reach orbit. reply perihelions 19 hours agorootparentI don't believe that's the case—see the math in my sibling comment. reply dotnet00 19 hours agorootparentThe number going around from people who typically do this kind of thing is a ~55x235km orbit: https://twitter.com/planet4589/status/1768270310199935299 I'm not really in a place to judge your math right now to really add anything on that. reply perihelions 18 hours agorootparentYeah, that guy's absolutely a domain expert! But note that he writes -55 km, not +55 km—that is a suborbital trajectory. Its perigee is below the earth's surface; -55 km is a negative altitude. (He's also clearly using a different set of data than I have access to. I can't read the context of the Twitter thread so I don't know what numbers he's looking at). reply dotnet00 18 hours agorootparentOoh that's a good catch, I subconsciously substituted the -55 for ~55! reply ghufran_syed 20 hours agorootparentprevIt's at 26000 km/h which sufficient for orbital velocity. It looks like it's in an elliptical orbit. I guess we'll see soon if they need to do a de-orbit burn, or if the orbit just intersects the atmosphere and they use atmospheric braking? reply perihelions 19 hours agorootparentI did the math. So, the minimal orbit at 180 km, the one that grazes the earth's surface at its perigee, is about 7.75 km/s or 27,900 kph. The other commenters are right: it was never technically orbital. edit: (let* ((μ 398600.0) ;; km^3/s^2 (r 6371.0) ;; km (peri (+ r 0.0)) (apo (+ r 180.0)) (a (* 0.5 (+ peri apo)))) (sqrt (* μ (- (/ 2.0 apo) (/ 1.0 a))))) ;; 7.745844595118488 reply ghufran_syed 19 hours agorootparentThanks! On one of the feeds, it sounds like they didn't want to leave a bunch of debris in orbit if they had an anomaly reply BenoitP 19 hours agorootparentprev> 26000 km/h > 27,900 kph Seems like they want to test the limit. Same speeds as LEO, but guaranteed to come down. reply eagerpace 16 hours agorootparentprevBut it would have been if they executed the burn in at a slightly different angle. reply grecy 19 hours agorootparentprevThat is really cool. For those of us that are space nerds but don't have the depth of understanding, do you mind walking us through the calculation above? reply perihelions 19 hours agorootparentI apologize I don't have a good explanation of it at hand! It's a form of the vis-viva equation [0] that's basically a restatement of conservation of energy. It derives the (scalar) speed of an object in a 2-body orbit, at any position within that orbit, as a simple function of their separation distance. In the form I'm using, I'm using standard parameters of an elliptical orbit: the periapsis (the closest approach to the center of mass of the massive body (which is a focal point of the ellipse which the orbit traces)), apoapsis (farthest distance), and semimajor axis (their arithmetic mean [1]). I'm evaluating the orbital velocity at the highest point, the apoapsis. μ is a short form for the product G*M, the standard gravitational parameter [2] of Earth (which is known to much higher precision than either the universal gravitational constant G, or the mass of the earth M, individually). The particular orbit I'm applying it to is one whose periapsis is equal to the Earth's radius—an orbit that touches the surface of the Earth. This is the dividing line for orbital / suborbital: a suborbital trajectory is one that (mathematically) goes beneath the Earth's surface. [0] https://en.wikipedia.org/wiki/Vis-viva_equation#Equation [1] https://en.wikipedia.org/wiki/Semi-major_and_semi-minor_axes... [2] https://en.wikipedia.org/wiki/Standard_gravitational_paramet... reply grecy 12 hours agorootparentNo apology needed, thankyou very much! reply thelittleone 20 hours agorootparentprevIsn't orbit above 125 miles (200km)? reply KineticLensman 19 hours agorootparentOrbit is when you turn the engines off and stay up there. reply apendleton 20 hours agorootparentprevOrbit is mostly about speed, not about height. Going straight up and down doesn't count, even if you pass the height that some orbital vehicles attain. This vehicle is actually going orbital speed, but not quite orbital height (or rather, it's in an \"orbit\" that has a very eccentric elliptical shape that would cause it to hit the atmosphere on its way back around; it'd be well above a typical orbital height at apogee, though). reply ta1243 14 hours agorootparentTechnically you can orbit the earth at a pretty low speed. Geostationary satellites orbit about 5,500kph, which is far slower than the 26,000kph starship reached today. You just need to get high enough, and be pointing in the right direction. reply usrusr 19 hours agorootparentprevOrbit is a speed, not a distance. You could do a suborbital hop that has its highest point beyond the orbit of the moon. (if you aim very, very well) reply WithinReason 19 hours agorootparentAt the same time, if your velocity vector is pointing towards the ground you're not achieving orbit no matter your speed reply the8472 19 hours agorootparentIt works if you're a black hole or a chunk of degenerate matter. For transatmospheric orbits being a large ball of iridium will work too. reply madaxe_again 20 hours agorootparentprevOrbit is when you drop an apple off a dining room table - it’s just a very crappy orbit. “On orbit” typically means in a stable orbit around a body - but in the case of starship, it could have been on orbit, the delta v is more than sufficient, but that’s an unsafe configuration if you don’t know your engines will relight. reply malfist 19 hours agorootparentprevIt's in space (above the Kármán line), but not in orbit. Orbit implies it has the velocity for staying in space, which isn't the intention here. If anything goes wrong they want to be able to not leave junk in orbit reply hoorayimhelping 19 hours agorootparentprevSpace is generally defined to be 100km above earth's surface, an arbitrary point called the Karman Line [1]. Orbit is when an object is traveling so fast that it reaches the horizon of a body before the body's gravity can pull it down to the surface, but perpetually. It's basically perpetually falling around the body. Imagine one of those guys in a wingsuit skimming along the surface of a mountain, never actually touching the surface. It's similar to that, but at a much higher scale. 1) https://en.wikipedia.org/wiki/K%C3%A1rm%C3%A1n_line reply oconnor663 9 hours agoparentprevClose enough. If the ship had to ignore the flight plan and press to orbit, there's no doubt that it would've succeeded. reply 110 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary explains the SpaceX mission to the International Space Station via the Falcon 9 rocket and Dragon spacecraft, covering liftoff, orbit activation, phasing burns, docking, and pressurization stages.",
      "SpaceX executes meticulous positioning burns and docking maneuvers for crew ingress after approaching the station.",
      "Moreover, it highlights SpaceX's additional projects like Starlink and Starship, emphasizing their privacy commitment and collaborations with suppliers."
    ],
    "commentSummary": [
      "The discussion delves into SpaceX's Starship program, highlighting successful flight tests, re-entry challenges, orbital velocity, and future mission possibilities.",
      "Mention of fake social media accounts posing as SpaceX, rocket trajectory specifics, and the significance of in-space fuel transfer are also covered.",
      "Comparisons between various rocket initiatives and the potential for human lunar landings via SpaceX's Starship are explored."
    ],
    "points": 476,
    "commentCount": 374,
    "retryCount": 0,
    "time": 1710416252
  },
  {
    "id": 39708957,
    "title": "FCC Increases Minimum Broadband Speed to 100Mbps",
    "originLink": "https://www.pcmag.com/news/fcc-officially-raises-minimum-broadband-metric-from-25mbps-to-100mbps",
    "originBody": "After years of talk, the Federal Communications Commission has officially raised its definition for minimum broadband speeds from 25Mbps to 100Mbps. On Thursday, the commission voted 3-2 to raise its broadband metric from 25Mbps for downloads and 3Mbps for uploads. Going forward, the FCC will define high-speed broadband as 100Mbps for downloads and 20Mbps for uploads. “This fix is overdue,” said FCC Chair Jessica Rosenworcel, who added: “It also helps us better identify the extent to which low-income neighborhoods and rural communities are underserved.” Raising the speed metric is important because it helps the commission determine which areas in the country are receiving adequate internet speeds, and if more government funding is necessary. In 2015, the FCC raised the metric from 4Mbps/1Mbps to 25Mbps/3Mbps. But since then, US senators, government watchdogs, and FCC officials have urged the commission to raise the metric even higher, citing the US’s growing reliance on internet services and apps. According to FCC data from December 2022, an estimated 45 million Americans “lack access to both 100/20Mbps fixed service and 35/3Mbps mobile 5G-NR service.” As part of Thursday’s vote, the FCC also adopted a long-term goal of raising its broadband metric to 1,000Mbps for downloads and 500Mbps for uploads. Rosenworcel added: “Millions of people in rural, urban and Tribal communities still do not have the broadband they need to fully participate in modern life. We are working on it.\" However, the two Republican Commissioners dissented in Thursday’s vote. Commissioner Brendan Carr noted that satellite internet services, such as SpaceX’s Starlink, don’t qualify for the speed benchmarks, which only considers ground-based internet. RECOMMENDED BY OUR EDITORS FCC Tries to Lower Internet Costs at Apartments by Banning 'Bulk Billing' FCC Moves to Protect Domestic Abuse Survivors From Connected Car Stalking Group Urges FCC to Let ISPs Bail From Rural Broadband Fund Commissioner Nathan Simington added that it makes sense to disregard older satellite internet services, but not Starlink, which already provides high-speed internet across the country. “SpaceX’s LEO-based [low-Earth orbiting] service Starlink has completely changed the game,” he said. “Starlink is in fact available at this moment in almost every corner of all 50 states, and offers low latency and speed near or exceeding 100/20Mbps, especially in rural areas.\" According to Simington, the FCC is concerned that satellite internet services such as Starlink face capacity constraints. But he expects the company’s technology to improve over time, and urged the FCC to allow SpaceX to compete for federal subsidies on an “equal footing” with other broadband providers. In December, SpaceX lost an appeal to receive $886 million in federal funding to expand Starlink in rural areas.",
    "commentLink": "https://news.ycombinator.com/item?id=39708957",
    "commentBody": "FCC Officially Raises Minimum Broadband Metric from 25Mbps to 100Mbps (pcmag.com)449 points by rosaleia000 13 hours agohidepastfavorite200 comments notfried 10 hours agoI like they raised the broadband minimum upload speed from 3 to 25Mbps. Spectrum's 300 Mbps broadband is only 10 Mbps up. Let's see how fast they change their statement that \"an upload speed of 3 Mbps is enough for most households\" [1]. [1: https://www.spectrum.com/resources/internet-wifi/what-is-a-g...] reply gamepsys 9 hours agoparentZoom recommends 3.8Mbps for uploading 1080p video. Being able to do 1080p video conferencing is an expectation of broadband. Raising the definition of broadband to meet this basic requirement is clearly a win. I do think 25Mbps up is more than what's required for a large number of households (>33%). I have advised family that 15Mbps is adequate when they needed to do office work from home. Perhaps the only good thing about this is that it will force ISPs to upgrade their infrastructure, but I'm worried the cost of that will be passed onto consumers at a time when inflation has already taken a toll on budgets. reply lolinder 9 hours agorootparentI've been coping with 6 Mbps upload speeds from Xfinity for years now. This morning I got an email from them saying they were raising my speeds at no cost, and after a modem restart I'm now getting ~20 Mbps up. This whole time I've been told that Xfinity couldn't provide decent upload speeds because of infrastructure reasons, but now that's been proven a lie. reply selectodude 8 hours agorootparentCATV was designed as a one-way pipe. There are filters everywhere in the network that block inbound traffic because there wasn't much of a reason for cable boxes to need to communicate with the wider network which meant that the bandwidth on the cable that was actually usable for upload bandwidth was orders of magnitude smaller than downloads. As Comcast basically rebuilds their network (fiber to the edge), they're bypassing and removing all of those filters which means that there's plenty of frequency for uploads. reply Scoundreller 5 hours agorootparentDesigned, maybe, but it's not like the cabling is directional. I thought one of the reasons why DOCSIS was straightforward to rollout was because they only really needed bi-directional amplifiers to do it. Though in the early days of cable internet, some setups used a telephone modem for your uplink. And if you already had Hybrid-Fibre Coaxial infrastructure (which was rolled out for noise reasons in the pre-data analog days) you were already a step ahead of the game in terms of segmenting nodes/worrying about CPE noise. Upload is crap because they have to dedicate channels to it at the cost of download channels, and upload has more overhead because of the coordination required. 70s/80s cableTV companies basically won the lottery by being able to re-use their existing last-mile plant for high-value data. Telcos not so much. reply rayiner 5 hours agorootparentThe wires weren’t unidirectional but the amplifiers were. Amplifiers capable of full duplex have only come out in the last few years. https://www.telecompetitor.com/comcast-gains-a-key-element-n.... reply conradev 8 hours agorootparentprevIt’s not a lie – they can’t provide upload speeds anywhere near their download speeds. 20 Mbps vs 6 Mbps is still quite small compared to 1000 Mbps. DOCSIS 3.1, the latest and not fully deployed standard goes up to 10Gbps down and 1Gpbs up. It looks like DOCSIS 4.0 is actually a path forward to symmetric upload/download speeds over the same cables reply lolinder 8 hours agorootparentI didn't say that asymmetric upload speeds being required was a lie, but until today Xfinity wouldn't allow me to pay for >6 Mbps upload without going up to some sort of business-tier package. Now, the day that the FCC sets 20 Mbps up as the minimum, I magically get that exact number for free. reply boneitis 8 hours agorootparentprevI feel like this does more to affirm the \"been proven a lie\" statement than refute it. 20 Mbps, while still suffocation, provides a massive amount of breathing room from 6. reply ksec 2 hours agorootparentprevI was under the impression DOCSIS 4.0 was basically a rebranded maximum feature of 3.1? reply rqtwteye 7 hours agorootparentprevThe 20Mpbs is definitely very welcome and so far it’s pretty constant. I hope one day we will have symmetric connections everywhere. reply jtbayly 8 hours agorootparentprevI just got an email saying my provider is bumping my fiber upload from 200 to 400. Seemed crazy to me, but I guess they are just staying well ahead of the crappy competition. reply chiefalchemist 8 hours agorootparentprevI got the same email. I was kinda assuming it was spam. reply SOLAR_FIELDS 4 hours agorootparentprevIt’s also a good opportunity to remind family that bandwidth is cumulative. That is nonobvious to quite a few people I’ve talked to that are not super internet savvy. What I mean by that is that if zoom uses 3.8Mbps that means they probably maximum two people can probably be on a zoom call simultaneously comfortably in a 15 Mbps household while other people are doing regular things. 3 if that’s the only thing happening in the household. reply gruez 4 hours agorootparentprev>Zoom recommends 3.8Mbps for uploading 1080p video. Being able to do 1080p video conferencing is an expectation of broadband You can't even get 1080p on zoom unless you're using \"Business, Education and Enterprise\". Pro and free users are limited to 720p and 360p respectively. Moreover people don't even have 1080p webcams, much less webcams where you can tell the difference between 1080p and 720p. That's not to say there are other reasons for wanting > 3.8 Mb/s up, but \"video conferencing\" is a poor one. reply sologoub 4 hours agorootparentprev25Mbps up may be adequate in a pinch, but it’s laughably outdated. Symmetric down/up enables a lot of great use cases including seamless backup. I briefly lived with AT&T fiber symmetric 1gbps (actually more like 940mbps at the router, but close enough). It was a game changer and losing it definitely undid a bunch of great use cases. If you WFH, it’s even more important. Meanwhile our Swiss friends have 10+gbps to home… reply ksec 2 hours agorootparentprevI really think it should be a ratio with minimum cap of 25Mbps. It would great if DL/UL would be at least 10:1. So 1Gbps user would get 100Mbps upload. reply ezfe 7 hours agorootparentprevThe technology to do asymmetric upload/download exists and many fiber-based companies offer it at the same rate as older infrastructure. It is not more expensive to offer symmetric service, but it may require infrastructure being brought more modern. For example, in the same region of Massachusetts (around Worcester) I previously paid $40/mo for 300/300 Mbps to Verizon FIOS but now after moving I pay $40/mo to Spectrum for 500/15 Mbps. reply iszomer 6 hours agorootparentI think I'll keep my Verizon 100/100 for ~68$. Still using the old copper coaxial not straight FttH though. reply lotsofpulp 7 hours agorootparentprev> I do think 25Mbps up is more than what's required for a large number of households (>33%). I have advised family that 15Mbps is adequate when they needed to do office work from home. Yet my experience when streaming high def video is much better in places with symmetric fiber with much higher upload bandwidth (> 100Mbps) than it ever is in places with coaxial cable bandwidth. reply RiverCrochet 5 hours agorootparentTCP ACKs back up are needed even for downloads and can get crowded if the bandwidth in that direction full or crowded. If those tiny ACKs don't get through downstream may stall. Linux QoS can help, but only if your router is Linux and you can run the appropriate commands on it. reply redox99 7 hours agorootparentprev3.8Mbps 1080p is an atrocious bitrate. You'd want at least 6Mbps. reply Scoundreller 5 hours agorootparentDepends what you're watching. A videoconference with a mostly fixed background and infrequently shapeshifting face or a screenshare won't chew up much. reply gilfoy 9 hours agoparentprevI get, realistically, like 30Mbps up with Spectrum with their 1Gb plan. At my last place they had a smaller competitor that did 1Gb up and down, so they changed existing 1Gb plans to the same. Now I live 8 minutes away from there and it's not an option! But competition is coming to my building soon so I can only hope. reply itsgrimetime 9 hours agoparentprevMakes sense why Xfinity just emailed me that they graciously decided to “double my upload speed completely free of charge” reply Modified3019 7 hours agorootparentYep, same here. reply LegibleCrimson 6 hours agoparentprevMy Comcast gigabit internet is only 25Mbps up. I'm pretty unhappy about it, as somebody who regularly has to push large docker images and wait forever each time. reply candiddevmike 9 hours agoparentprevOn coax/cable lines like Charter/Spectrum, the upload speed limit is due to protocol/DOCSIS limitations. Supposedly the new version of DOCSIS fixes this/allows for symmetrical service, and Spectrum has been rolling it out for a while now. Still waiting for it where I'm at... reply m463 9 hours agorootparentI've seen this explanation, but it makes no sense ver year download upload 1.0 1997 40 Mbit/s 10 Mbit/s 1.1 2001 40 Mbit/s 10 Mbit/s 2.0 2002 40 Mbit/s 30 Mbit/s 3.0 2006 1 Gbit/s 200 Mbit/s 3.1 2013 10 Gbit/s 1–2 Gbit/s 4.0 2017 10 Gbit/s 6 Gbit/s the version previous to the \"new version\" uploads at 1-2gbit/s which is 40-80x the FCC value https://en.wikipedia.org/wiki/DOCSIS#Comparison reply akerl_ 8 hours agorootparentYou may want to scroll down to the “throughput” section, instead of looking at the theoretical max. The theoretical max up and download aren’t additive. It’s like saying that an egg carton can hold a max of 12 white eggs or 12 brown eggs. Good luck putting 24 eggs in it. The DOCSIS standards carve up the available throughput, using some of that for upload and some for download. reply candiddevmike 9 hours agorootparentprevAFAIK they're on DOCSIS 3.0 and upgrading to DOCSIS 4 reply pwarner 8 hours agorootparentprevThese are the spec. Implementations vary. They vary in terms of chips, but also the way they get deployed on existing cable plant. reply lotsofpulp 9 hours agoparentprevFor coaxial cable, I assume they will still allocate the same 50Mbps upload between 200 houses, and then let you get a 25Mbps burst for a few seconds by taking it from others. reply Scoundreller 5 hours agorootparentSometimes the issue is legacy CPEs that couldn't access channels that newer ones could (or couldn't bond as many). That's why sometimes a modem upgrade could \"unlock\" higher speeds. reply vlan0 9 hours agoparentprevWhat’s interesting is I’ve been pushing 20-25 up for the last month or so. reply devindotcom 11 hours agoprevThat explains why I got this email from my broadband provider this morning: >We've increased your internet speeds to show you our appreciation I was wondering what I'd done to deserve it! reply chandlerswift 10 hours agoparentI got the same message, also from Xfinity. It does sort of make me wonder: If the FCC declared broadband to be 100/50, would I have 50mbps upload speeds this morning? To me, this seems to be a clear positive outcome of the FCC's change: Xfinity had this capacity, the FCC raised their standards, and now all(?) Xfinity customers have increased upload speeds for zero additional cost. Seems like pretty much a best-case result of this metric increase. Edit: Formerly 200/10, now 300/20. Email arrived 10am today. reply tzs 9 hours agorootparentI didn't get a message from Xfinity and a speed test showed no increase, but checking my plan on their website it said 300 mbps whereas it used to be 200 mbps. A modem reboot later and I'm getting 355 down/24 up on a speed test site, and 373 down/25 up on \"what my ethernet card sees\" test [1]. When the plan was 200 mbps I'd get around 240 down on speed tests. Xfinity has always been 10-20% faster for me than whatever the sticker on the plan says. I'm not sure, unless they actually say it is, that this is in response to the FCC. In the almost 20 years I've had Xfinity I've had numerous speed bumps like this, much more often than the FCC bumps the speed in their definition. My plan went from 100 mbps to 200 mbps sometime in the last few months for example. [1] Run netstat once a second to get the byte counts in and out per second, multiply by 8 to get bits. reply lolinder 9 hours agorootparentWhat's different about this speed bump is that suddenly upload and download are closer together than was ever possible before. When we moved in a few years ago there were no options that provided >10 Mbps up but ) saying they bumped my upload speed from 35->100mbps. I didn't expect that given the new minimum upload speed is 20mbps reply ww520 9 hours agoparentprevSame here. I thought they sent that email out to incentivize me not to move to fiber. Turns out that FCC is the reason. reply supportengineer 10 hours agoparentprevYes - same from Xfinity reply Pokerface777 9 hours agorootparentI didn't get the same... (same provider) reply riley_dog 9 hours agorootparentXfinity bumped the lower tier plans earlier in the week or maybe last week. They obviously knew this was coming. reply tzs 9 hours agorootparentprevTry rebooting your modem. That got it for me (the increase, not the notice of an increase). reply Pokerface777 8 hours agorootparentI actually just changed my modem today because I was using Comcast's modem/router combo and wanted to use my own... I'm still at about 50-60mbps. I guess I will contact them again. I talked to them and they say I am still on the 50/20 plan... they replied saying I would need to pay more to get 100mpbs. I don't need it, so I won't. reply ProllyInfamous 10 hours agoparentprev>\"We appreciate providing you with the bare minimum, as required by statute.\" reply tzs 9 hours agorootparentISPs aren't statutorily required to meet the FCC's speed bare minimum. It is just that doing so lets them be counted as broadband and might qualify them for some incentives to deploy broadband to underserved areas. Also I believe that an ISP is counted as broadband by the FCC if they have some plans available that meet the FCC's minimums. They do not have to meet them with all plans. reply johnnyanmac 9 hours agorootparentI mean, \"we're chasing the easy carrot on the stick we coulda always given customers\" instead of \"we're avoiding being punished\" isn't that much better a framing. reply tootie 10 hours agoparentprevVerizon bumped me to gigabit for no good reason a few years ago. I think I had only signed up for 50 initially. I clocked it at 800/800 but I'm not going to complain. reply michelangelo 10 hours agoparentprevSame! reply probably_satan 10 hours agoparentprevnext [4 more] [flagged] ghaff 9 hours agorootparentThe idea of usage caps was intensely controversial on sites like this a number of years back because it was mostly related to downloading \"Linux distributions\" from torrent sites. Today, with the download activity mostly driven by Netflix and other video streaming services, it's mostly untenable (within reason). In a market where so many households have an expectation of essentially unmetered video streaming I'm not sure there's much of a demand for 10-year-old bandwdith caps for $10-$20 less per month (which were probably more at the time even with the caps anyway). I don't get cable TV or landline and I pay less than I did 10 years ago. ADDED: In a context, people develop expectations about what should be metered and what should be unmetered at least up to a point. You want a metered service where most people, at least in the US, have developed an expectation of an unmetered one. And I doubt you're asking for what actually passed for unmetered telecoms 20-30 years ago. reply AnthonyMouse 4 hours agorootparentData caps have always been a scam because they don't match the economics of providing service. Idle capacity goes to waste, and there is always idle capacity during off-peak hours (that's what off-peak hours are), so deterring usage during those times is wasteful and spiteful. You could have on-peak data caps, but then you'd have people who e.g. watch an hour of streaming a day hitting them because they do so at the same time as everybody else does, and then the people clamoring about someone else torrenting \"all day long\" would find themselves hitting the cap, because their usage is during peak hours and what somebody else is doing after midnight or before 4PM is irrelevant. The better solution is to simply sell connection tiers with different speeds. If you pay for 200Mbps, the network is designed to be able to provide you with 200Mbps during peak hours. Not that you have 200Mbps dedicated but rather that under typical actual aggregate load, there will be 200Mbps of capacity available for someone on your service tier to use. Meanwhile if you try to download something at 3AM, you might get 1000Mbps, because why not? Nobody else is using it. But someone who wants to pay less can buy less expensive slower service -- slower, but only during peak hours. If the person who pays for 50Mbps wants to download something at 3AM, they can get 1000Mbps too, but at 7PM they're getting 50Mbps instead of 200. The actual reason cable ISPs like data caps is that it discourages people from using video steaming services (which eat up the cap even when used off-peak) rather than subscribing to cable TV (which does not). reply ambichook 7 hours agorootparentprevcapped data is ass, as someone who couldn't get uncapped until about a month ago when i moved, if someone tried to legislatively require data caps i would be on their ass trying to make them stop SO fast reply hedora 11 hours agoprevWith how many 9's of availability, and at what latency? Frontier is advertising 3 nines average network-wide availability for their new fiber network. Three nines is completely unacceptable, but our neighborhood barely got one nine last year. Based on their current behavior, there's zero chance of them providing the bandwidths they're advertising for the new build out, even when the network is completely up and completely idle. Currently, if we try to sign up, they say we can get25Mbps to the FCC. reply Johnny555 11 hours agoparentWhy isn't 3 9's acceptable for residential home internet? That's less than 9 hours of downtime a year, 44 minutes/month. Sure, I'd like 4 or even 5 9's, but I don't want to pay for it -- each additional 9 is exponentially more expensive to guarantee, and few people are willing to pay for that much reliability for their own network gear. reply Retric 11 hours agorootparentActually averaging 3 9's isn't that bad. However, 3 9's looks much worse when you also miss the target. The target for phones used to be significantly higher, but with cellphones home internet is generally less safety critical. reply fbdab103 9 hours agorootparentprevThe average US customer in 2022 averaged 5.5 hours of power disruptions[0]. So somewhere between 3-4 9s. [0] https://www.eia.gov/todayinenergy/detail.php?id=61303 reply tomrod 11 hours agorootparentprev4 nines is reasonable, 5 nines a good target. ISPs have become utilities, especially since covid. reply mysteria 9 hours agorootparentThe commercial internet services with 4 or 5 9 SLAs have multiple redundant lines to the building to guarantee this and they charge handsomely for it. Otherwise a downed telephone pole or something will automatically bring the service down for a day or more. BTW I run a serious network at home (Proxmox cluster, all enterprise gear, virtualized router with HA, UPS power) and only target 4 nines on the LAN. System updates and things like server crashes making the router failover to another node cause around 30 minutes worth of network downtime a year. If a core or floor switch fails it'll automatically take me over an hour to swap in a spare and configure it. I don't bother trying for that fifth nine and I'm a very demanding user. Now if one of you have a consistent 5 nine home system I'd be curious to learn more about it. I'm guessing that would practically be a datacenter setup with CARP, dual switches, etc. - or you're just really really lucky. reply uxp100 10 hours agorootparentprevMy electrical utility does not hit 4 nines, maybe not even 3. Water and sewer? Definitely. reply jltsiren 10 hours agorootparent5 nines is reasonable for electricity, if you live in an urban area with no extreme weather or other major natural hazards. When I was still living in Helsinki, blackouts were basically an once-in-a-decade thing, and they didn't last long. Today in California, I'm getting 3 nines in an urban area. Those living a couple of blocks further towards the suburbs are not so lucky. And many people in the mountains don't get even 2 nines. reply nucleardog 9 hours agorootparentHey, 3 nines ain’t too bad! In 2023 our availability only had one nine. We had power ~96% of the year. And it wasn’t like it was a lot of hour long outages that added up or something. Longest was 8 days. I am not in a dense urban area, but I am connected directly to a line connecting a couple of larger towns along a major highway, so we’re generally restored fairly quickly. During the 8 day outage, quite a few people in the major city nearby were actually still without power when mine was restored. Maybe unsurprisingly, my internet has actually been vastly _more_ reliable. reply fy20 7 hours agorootparentThat's sounds pretty terrible... In my Eastern European country the SLA from the (state owned) power company is no more than 6 hours of down time per event, after which they need to pay compensation. Within highly populated areas it's shorter. Admitidely the most remote place is less than 1.5 hours from the nearest reasonable sized town, so we aren't as remote as some parts of the US. The purpose of this was to force them to make their network more reliable by upgrading old equipment, burying overhead lines (lots of trees used to fall on lines during winter) and ensuring redundancy. reply ghaff 10 hours agorootparentprevI don't have town sewer but being without water is very rare. Being without electricity for maybe the total of day a year? Not rare. (Though semi-rural albeit on a major road.) ADDED: I don't. But people having backup generators in snow country is not a weird thing. reply maxerickson 9 hours agorootparentprevIf they have to do maintenance on a water main, you'll easily get an hour of downtime, likely followed by a boil water advisory. They replaced several hydrants near me a couple years ago and there were disruptions on a couple of days. reply dietr1ch 10 hours agorootparentprevDude, my DSL back in my second world country fared better. The US has enough money to have moderate standards reply Johnny555 10 hours agorootparentThe DSL network piggybacked on the analog voice network which, at least in this country, was built to a higher standard. But I don't want to go back to the days of the 1990's where I was paying $40/month (around $100/month in today's dollars) for an analog phone line. It was reliable, so reliable that \"as reliable as dial tone\" was something to aspire to, but also costly and limited in capability. Even if I could get DSL today, my fastest speed would top out around 12mbit/sec due to my distance to the CO, which doesn't even meet the current definition of broadband. reply jdminhbg 11 hours agoparentprev> Three nines is completely unacceptable Less than 9 hrs of downtime per year is unacceptable for consumer internet? reply hedora 11 hours agorootparentTraditionally, it was unacceptable for landline service, since it's safety critical. (You need to be able to call 911.) I poked around to try to figure out what the current requirements are, and it looks like they've mostly been scrapped. \"Central office backup power\" is required, which matches my experience attempting to get terrestrial internet or cell service during power outages. reply cogman10 11 hours agorootparentprevIf we limit it to issues that the ISP owns, then I'd say yes. What does the ISP have that can cause 9 hours worth of outages throughout the year? The only thing I could think of is the ISP being targeted by a massive DDOS attack. reply Johnny555 10 hours agorootparentWhat does the ISP have that can cause 9 hours worth of outages throughout the year They have the real world -- ice storms, trees blown down by wind storms, power outages, backhoe outages, etc. A tree took out internet in my neighborhood for 2 days, others had longer outages since it was a big storm and it took a while to repair. reply Scoundreller 5 hours agorootparentprevNot every year, but Rogers in Canada managed to black itself out across digital TV, corp circuits, home internet, mobile, 3rd party internet providers that used their lines, their own employees, and cellular for the good part of a day (from like 5AM until midnight) nationwide. Their CTO was on holiday and was unreachable because their phone went into SOS mode and they just assumed it was them. https://en.wikipedia.org/wiki/2022_Rogers_Communications_out... In 2021, their mobile network went down for like 9 hours: https://www.thestar.com/news/gta/rogers-identifies-root-caus... The Nashville AT&T explosion didn't take out the data lines, but took out the electric service. Then the gas company cutoff the gas lines so their backup generators couldn't run (wiki says it was due to fire/water damage, so maybe I have that part wrong). The facility didn't have roll-up generator connections, so they had to figure out how to wire them in at a big time cost. https://en.wikipedia.org/wiki/2020_Nashville_bombing In 2003, the \"Slammer\" worm slowed down ISP's core routers (including Rogers' to the point of not working anymore) with the quantity of small packets. https://en.wikipedia.org/wiki/SQL_Slammer reply wmf 11 hours agorootparentprevIt's easy to have a single outage over 9 hours if they wait 8 hours to send somebody out. reply cogman10 11 hours agorootparentlol, well yes I guess :D. I guess I'm really just spoiled. In the last 10 years I think I've only really experienced like 1 or 2 outages caused by my current ISP and they were resolved within the hour. My assumption is that like most people, all the ISP equipment is buried so the only things that can really go wrong are either at the colo or the home (like a router that dies). Having a line cut is simply a hyper rare event. On the other hand, my overhead powerlines have caused most of my outages. An idiot crashing into the telephone poll has made my power less reliable than my internet. reply vel0city 10 hours agorootparentHaving a line in the ground won't save you when there are wild backhoes in your biome. reply tw04 10 hours agorootparentprevAn ice storm taking down a utility pole will blow that out of the water for several years. reply dghlsakjg 11 hours agorootparentprevI live in semi-rural Canada and get better service than that, but I would be fine with more downtime. OTOH, I frequently have scheduled power outage times that exceed that metric so it sort of doesn't matter, and that's ignoring unscheduled power outages (a necessary part of life in a temperate rain forest with above ground power). I've taken to keeping a small generator handy to power the modem. reply hedora 11 hours agorootparentOur Internet + phone service go down if there's a power outage, which implies the cell network also goes down in practice. The tower might be up and on backup power, but it either has nothing to talk to or it's completely overwhelmed. reply sib 10 hours agorootparentprevYes, given that that's also the phone line for many people and therefore is an emergency service... reply jedberg 11 hours agorootparentprevIt is when you work from home. reply jzb 11 hours agorootparentI would be annoyed at losing a day or so of work, if the outage was all at once - but nine hours a year is tolerable. I wish my ISP was that reliable. Hell, I wish my power company was that reliable. Where I live it's common to have a number of outages longer than eight hours every year. Last year a moderate storm caused power outages for a couple of days in August affecting thousands. reply jdminhbg 10 hours agorootparentprevGenerously, if you work 2000 hrs/year, that's less than 25% of a year's total hours, so it's only 2 hrs of work downtime on average. If you need better connectivity than that, you should pay for a higher SLA or make sure you can tether a cell connection or something. reply dwheeler 11 hours agorootparentprevOften you can use cell phone or a coffee shop if it's say 2 days/year of internet downtime. If you need it for an emergency call, you need higher reliability, but you can prioritize, and I don't know how common landlines are any more. reply groby_b 11 hours agorootparentprevIt is? 44 minutes outage per month is critical? I doubt that's true for most jobs. But yes, there are jobs where it is, and some of us (e.g. me ;) are just finicky about network connectivity. In which case I highly recommend having a fallback connection, with a different modality than the main one. For most of us, that means LTE. Tethering is fine if you can live withIt could also mean nine one hour outages during working hours or one out of 1000 web browser requests fail on average. Totally fine with both of these, even as someone who works from home. > However, I suspect that the actual availability is extremely skewed, given the one nine they delivered to our area. And this is what I'd find unacceptable. reply tw04 10 hours agoparentprevYou can and should challenge the map then. The FCC actually has a means to do that and does respond. Ideally get an email follow up stating speeds, frontier has a habit of refusing to create a paper trail. https://help.bdc.fcc.gov/hc/en-us/articles/10476040597787-Ho... reply FactolSarin 10 hours agorootparentI did this about 18 months ago, and surprisingly, Spectrum came out and actually put a new line up my road. I'd asked them off and on for years to get broadband. Last time I'd been quoted 12k to cross the little creek they stopped at and service the dozen or so houses on my side. But for whatever reason, this time they did it for free (well, normal hookup costs) after I challenged them on the FCC site. reply nsporillo 6 hours agorootparentGlad to hear that. I've been fighting to get Frontier to service my neighborhood and the best they could tell me is that there is some hidden ticket and they have no idea what the real status is. Frontier is labeled as a fiber provider for my address on the New York State PSC Broadband map and I made sure to provide some feedback to them about that claim. Would love to have even just a single alternative option besides satellite internet. I'm only 10 miles outside of the downtown area. reply JumpCrisscross 10 hours agoparentprevThe FCC is working on an internet service notice format “modeled after the FDA nutrition labels” [1]. [1] https://www.fcc.gov/broadbandlabels reply fbdab103 9 hours agorootparentAh, so one with huge amounts of input from lobbyists. It is ridiculous that nutrition labels are not forced to standardize on something like x/100 grams (even Freedom units would be acceptable). Plus a x/package. None of this 3/8 serving size nonsense. reply faeriechangling 11 hours agoparentprevI don't see three 9's as being unreasonable for home internet at all, getting more reliability than that is non-trivial and most people have redundancy in the form of internet on their phones or can buy a second line. reply SkyPuncher 11 hours agoparentprev3 9s is completely fine. Internet is not subject to the 911 uptime requirements. 3 9s is essentially an outage or two from a major storm. That’s fine for residential internet. reply Dylan16807 10 hours agorootparent> 3 9s is completely fine. Internet is not subject to the 911 uptime requirements. It's all going over the same wire. Why not put in the extra fraction of effort? reply SkyPuncher 8 hours agorootparent> It's all going over the same wire Yes and no. Even if it's going over the same wire, there are different data flows. Voice uses predictable amounts of bandwidth per phone number. reply Dylan16807 8 hours agorootparentMinimum speed still requires almost all the equipment to be running. reply SkyPuncher 8 hours agorootparentYes and no. * Last mile has a downed line, yes that will result in a local outage * Backhaul gets taken out. Re-route traffic. Drop/throttle non-SLA traffic reply Dylan16807 21 minutes agorootparentIf you're able to reroute then you should almost always be able to keep Internet service running, just slower. Not many connections are so weak that they can only carry voice. reply simlevesque 11 hours agoparentprev> our neighborhood barely got one nine last year Internet it available less than 10% of the year where you live ? reply bhelkey 11 hours agorootparentOne nine should be 90% availability I would imagine. reply simlevesque 10 hours agorootparentYeah that makes sense, I feel stupid now. reply hedora 11 hours agorootparentprevIt was out for about a month total for some of our neighbors. (Repeated outages, not just one.) reply ssalka 9 hours agoprevI wonder if this is the reason Comcast suddenly decided to double my internet speed today (they were forced to and then took credit because they're such good guys): > # We've increased your internet speeds to show you our appreciation >You can now enjoy 2x faster upload speeds and improved download speeds for smoother connections when you’re working, gaming and streaming. >We’re excited to share this increase to your current internet package at no additional cost. Not seeing the faster speeds yet? Restart your gateway. Enjoy! reply johnnyanmac 9 hours agoparentAlways kinda spin any forced regulation as if it comes from the goodness of the ISP's heart. Either way, good. 100 is a reasonable minimum for modern society. Now if only I could get a steady connection on T-mobile. reply pcloadletter_ 8 hours agoparentprevGot it too. Strikes me as extremely disingenuous. I feel like they shouldn't even be allowed to represent this as a decision they made out of the goodness of their hearts. Makes me hate them even more, which is pretty amazing because I had thought we already bottomed out. reply ChrisArchitect 11 hours agoprevOfficial release: https://www.fcc.gov/document/fcc-increases-broadband-speed-b... reply superkuh 11 hours agoparentIt's always funny sad when I try to open a link on fcc.gov or congress.gov and get blocked by an impassible cloudflare wall. You'd think these services would be important enough to have a non-default cloudflare configuration. Here's a mirror of the text I grabbed from another computer/IP for anyone else getting blocked: FCC INCREASES BROADBAND SPEED BENCHMARK Annual Agency Assessment of High-Speed Internet Service Deployment Establishes New Standard to Better Reflect the Broadband Needs of American Households -- WASHINGTON, March 14, 2024—The Federal Communications Commission today adopted its annual assessment of whether advanced telecommunications capability is being deployed in a reasonable and timely fashion across the U.S. In addition to deployment, the Report considers broadband affordability, adoption, availability, and equitable access, when determining whether broadband is being deployed in a reasonable and timely fashion to “all Americans.” The Commission’s Report, issued pursuant to section 706 of the Telecommunications Act of 1996, raises the Commission’s benchmark for high-speed fixed broadband to download speeds of 100 megabits per second and upload speeds of 20 megabits per second – a four-fold increase from the 25/3 Mbps benchmark set by the Commission in 2015. The increase in the Commission’s fixed speed benchmark for advanced telecommunications capability is based on the standards now used in multiple federal and state programs (such as NTIA’s BEAD Program and multiple USF programs), consumer usage patterns, and what is actually available from and marketed by internet service providers. The Report concludes that advanced telecommunications capability is not being deployed in a reasonable and timely fashion based on the total number of Americans, Americans in rural areas, and people living on Tribal lands who lack access to such capability, and the fact that these gaps in deployment are not closing rapidly enough. Using the agency’s Broadband Data Collection deployment data for the first time rather than FCC Form 477 data, the Report shows that, as of December 2022: · Fixed terrestrial broadband service (excluding satellite) has not been physically deployed to approximately 24 million Americans, including almost 28% of Americans in rural areas, and more than 23% of people living on Tribal lands; · Mobile 5G-NR coverage has not been physically deployed at minimum speeds of 35/3 Mbps to roughly 9% of all Americans, to almost 36% of Americans in rural areas, and to more than 20% of people living on Tribal lands; · 45 million Americans lack access to both 100/20 Mbps fixed service and 35/3 Mbps mobile 5G-NR service; and · Based on the new 1 Gbps per 1,000 students and staff short-term benchmark for schools and classrooms, 74% of school districts meet this goal. The Report also sets a 1 Gbps/500 Mbps long-term goal for broadband speeds to give stakeholders a collective goal towards which to strive – a better, faster, more robust system of communication for American consumers. Action by the Commission March 14, 2024 by Report (FCC 24-27). Chairwoman Rosenworcel, Commissioners Starks and Gomez approving. Commissioners Carr and Simington dissenting. Chairwoman Rosenworcel, Commissioners Carr, Starks, Simington, and Gomez issuing separate statements. GN Docket No. 22-270 reply andrewaylett 11 hours agoprevIMNSHO, latency is more important than raw bandwidth, and raw bandwidth for consumer Internet is more useful as a latency improvement (because the high speed drains the buffers that much faster) than for actually using the bandwidth. If you've got actually decent Internet, or you actually do use the bandwidth, great! My experience is that only a few applications will max out my 115Mbit/s connection, and given I have semi-decent kit and a decent ISP using the full bandwidth doesn't have a big impact on latency so I can be streaming, downloading, and have multiple people video-calling and that's fine. Looking at my stats, there's only been a five minute period in the past 24h with sustained speeds used of over 20Mbit/s. reply Shank 10 hours agoparent> My experience is that only a few applications will max out my 115Mbit/s connection, and given I have semi-decent kit and a decent ISP using the full bandwidth doesn't have a big impact on latency so I can be streaming, downloading, and have multiple people video-calling and that's fine. My experience is that people rarely feel constrained by bandwidth because everyone is fighting to optimize every last bit, often using varying techniques that sacrifice quality. Not a single video calling app that I’ve used recently feels like it’s actually delivering good video to me. They're all bitcrushed. They work for some meetings at work, but I would really love a much higher bandwidth connection for screen sharing on Discord and practically every streaming app. Latency is also important: don’t get me wrong about that. But the fact that I have 1Gbps and I can’t get high bitrate video down kills me. reply Wowfunhappy 10 hours agorootparent> Not a single video calling app that I’ve used recently feels like it’s actually delivering good video to me. They're all bitcrushed. I suspect this is largely done for the sake of latency, due to buffer bloat. Well, that and as a result of typical upload speeds being much lower than download speeds. reply yakkityyak 8 hours agorootparentprevCan’t forget low bit rate “4k” saves them tons of money on storage and bandwidth costs as well. reply outcoldman 10 hours agoparentprevThe only thing personally I want is the same upload speed as download. So I can connect to my home server and download/upload stuff from it. reply sokoloff 10 hours agorootparentI can see the desire for higher upload (because I have the same desire), but I don't care at all if they're the same. I'd rather have 200/20 than 15/15 or 20/20 (obviously), but I would also rather have 200/20 than 25/25. reply outcoldman 6 hours agorootparentBy the same, I mean to match what we already get in most places as download speeds, at least 100-200mbps. Every household use google or apple photos app that upload backups to cloud services. reply olyjohn 10 hours agorootparentprevHow are we supposed to have middlemen SAAS services making you subscribe to basic things if you can just do it yourself? reply DaiPlusPlus 8 hours agorootparentIt's not just upload speeds though, don't forget also needing a static IP address (or two...) and unblocked ports, and a decent router and other networking gear. And when residential Internet goes IPv6-only (...eventually) you'll likely still need dual-stack IPv4 to avoid problems with connections from IPv4-only endpoints. Oh, and an SLA too... UPnP was meant to help alleviate some of those requirements but I don't think there's been any progress on that front since the spec came out in 2001... reply TheJoeMan 6 hours agoparentprevHave you set up bufferbloat prevention on your router? You would restrict your router to only say 100mbps, to avoid saturating the connection. reply devwastaken 10 hours agoparentprevThis is not at all accurate when considering that internet access for one home is on average for 3 people, not 1, and internet is now used for work which requires video streaming and large file downloads. reply aaomidi 10 hours agoparentprevAnd latency under load is an even more important measure. reply nerdjon 12 hours agoprevGoing to be interesting to see how they respond. Do consumers care or differentiate “broadband” anymore? Why do I feel like they might just pivot to not using the word “broadband” at all anymore and use some internal branding like the stupid 10g crap Comcast tried. Thankfully they were told to stop but if they are more careful… reply joe_guy 12 hours agoparentThe definition appears to be more for the government than marketing. > Raising the speed metric is important because it helps the commission determine which areas in the country are receiving adequate internet speeds, and if more government funding is necessary. In 2015, the FCC raised the metric from 4Mbps/1Mbps to 25Mbps/3Mbps. But since then, US senators, government watchdogs, and FCC officials have urged the commission to raise the metric even higher, citing the US’s growing reliance on internet services and apps. reply dtnewman 9 hours agorootparentMost people don't need 100mbps. Netflix recommends 5mbps for HD and 25mpbs for UHD. As a country, let's make sure that everyone has the ability to watch netflix in HD on 5 TVs simultaneously in one home. Or to watch UHD on a single TV. But if there's a home out there that currently gets 50mbps but the infrastructure for 100mbps isn't in place, do we really want the government throwing money to solve that (non) problem? reply Cody-99 7 hours agorootparentThe goal shouldn't be to have just enough internet. 25mbit/3 is incredibly slow for 2024. A single 4K stream saturates a 25mbit connection. 3mbit upload is super low too since a 1080p zoom call is around 3mbit/s upload. When you get close to using that upload your ping and download are going to tank. The average household size in the US is 2.5 people so 25/3 is easily saturated by 2 people just going about their day. There is no reasonable justification for 25/3 at this point in time. > do we really want the government throwing money to solve that (non) problem? The FCC isn't saying you can't sell internet under this requirement. Plenty of places have still offer ADSL even though it is under the old 25/3 requirement for broadband. They just can't call it broadband and receive the federal money that goes along with providing broadband. The new rule requires ISPs that offer broadband and receive federal funds to meet the new rules. The new rule forces ISPs to provide a better service to millions of Americans or lose the money they have been receiving for years. Without the new rule ISPs get to collect the money anyways while providing an objectively worse service. >but if there's a home out there that currently gets 50mbps but the infrastructure for 100mbps isn't in place, What situation would that be? ADSL don't meet the old requirements anyways so its not relevant, cable based systems like DOCSIS have supported well over 100/25 for 2 decades (DOCSIS 3 can do 1gbit/200mbit and that came out in 2006 lol), and any fiber based system can obviously do more than 100/25. Even if there was some situation were 50mbit was possible but 100/20 wasn't it doesn't mean they lose internet or anything. The ISP is just forced to upgrade their system or not receive federal funds. reply lotsofpulp 7 hours agorootparentprevOne of the reasons the big tech companies are so big is because it is so hard to roll your own NAS backup and syncing solution. With sufficient upload connectivity and ipv6, it could be possible to make “cloud” connectivity an appliance you can buy and put in your home, so that you can be freed from having to use an external cloud provider. reply akira2501 11 hours agoparentprevConsumers don't. Monopolistic corporations filing paperwork to get their hands on tax dollars probably do. Thankfully for them, the FCC is about as toothless and captured as you can get, so it probably even only barely matters to them. reply rsynnott 10 hours agoparentprevThere’s a reasonable practical difference between 25Mbit/sec and 100; in particular, 25 isn’t _really_ good enough for 4K streaming. _Today_, most consumers aren’t going to be that bothered between the difference between 100 and 1000. But that’s today; the sensible telecoms regulator thinks on a longer scale, because otherwise they just have to revisit the whole thing in a decade. In Ireland we’re on our third try; the first saw a lot of subsidised satellite and fixed wireless in rural areas, the second, better fixed wireless (a minimum latency requirement killed off the satellite option), and FTTC; in the third, they do seem to have finally decided to stop screwing about, and are rolling out FTTH in otherwise-poorly-served rural areas. (From a practical point of view, I do get that a state rural fibre wholesaler probably would not fly politically in the US, but this approach of repeatedly easing the minimum standard up is ultimately kinda wasteful.) reply Dalewyn 11 hours agoparentprevPersonally, I can't remember the last piece of marketing that tried to sell me \"broadband\" internet. They all say \"high speed\" internet. Anyway, the 15/3mbps down/up I get in the Oregon countryside is indeed high speed compared to the 5/1mbps down/up I had smack in the middle of the Los Angeles suburbs. reply bitwize 10 hours agorootparentBroadband was usually differentiated against dial-up. Today it may be compared to cellphone service, but 4G and 5G nowadays are plenty fast enough. reply bufferoverflow 4 hours agoprevWe have 400 Mbps symmetric with Hotwire, and whenever I do a speedtest, I get at least that much, sometimes it bursts to 600. But then there's something wrong with their peering or something. Youtube videos randomly buffer even at 1080p. Downloads randomly drop from 400 Mbps to 10. Sometimes the problem lasts an evening, and then goes away. I have no idea. reply stumpylog 10 hours agoprevMeanwhile, my parents, in a not really rural area (less than 5 minutes to a town), are capable of reaching ... 0.2 MBps. And that is just in theory, actual speeds may vary. reply wmf 10 hours agoparentThat's when you get Starlink. reply rsynnott 10 hours agoparentprevHuh, what’s that, ADSL1 or something? reply Kerbonut 11 hours agoprevGreat, now do data caps. reply kerkeslager 7 hours agoprevAs it turns out, a lot of HN is a lot more for government regulating business when it affects them personally. Have you ever seen an HN thread with so much pro-regulation sentiment? reply LegibleCrimson 6 hours agoparentYes. Literally every thread about monopolies. reply gnicholas 4 hours agoparentprevI have said on several occasions that this is getting out of hand. I was perfectly happy with 20 down, and am now forced to buy 75 because that is the lowest tier that Comcast offers. They keep pushing up the minimum rate so that they can show a high rate of \"compliance\" with the ever-increasing broadband standard. And of course, they push the price up with every speed increase. reply darkwizard42 5 hours agoparentprevThe prevailing sentiment on average across HN is regulate where competition is stifled (monopolistic practices by Apple, Google) or it is a public good (utility threads on PG&E come to mind, homegrown broadband, public transportation) or the law is being broken (copyright, fair use, open source violations). Using a wide brush to paint all of HN and similarly all of gov't regulation is what leads to cognitive dissonance where there is nuance. reply lotsofpulp 7 hours agoparentprev> Have you ever seen an HN thread with so much pro-regulation sentiment? Yes, when the service in question is a physical monopoly where there is no choice except to move. reply dangus 7 hours agoparentprevI’m not sure what you’re trying to say. HN isn’t a singular entity, a lot of people here have different opinions. Almost everyone in the world is in favor of some form of regulation of businesses. reply Cadwhisker 10 hours agoprev\"Broadband\" will now be 100Mbps for downloads and 20Mbps for uploads. I'm more impressed by the long-term goal of 500Mbps upload speeds. reply dtnewman 9 hours agoprevI oppose this. 100mbps just isn't what most people need. To most readers, this probably sounds innocuous, but I have some involvement in my city's digital equity community, so I have some insight into what this translates to for local governments and community organizations. Now what will happen is someone at the county level in charge of digital infrastructure will look at at a map and say \"oh no, 40% of our population doesn't have broadband, and 20% don't even have access to broadband\". This news will find its way to local politicians and organizations and eventually, a lot of money will get thrown at this problem. Naturally, Comcast and ATT have entire departments skilled at filling out RFPs, so they will get tons of money to expand their coverage to \"communities that wouldn't be profitable to service without government grants\". Meanwhile, the net result will be that we'll spend a lot of money on this, and the result will be that some households can now watch Netflix in UHD on three televisions at a time instead of two. Meanwhile, the vast majority of people have $30 wifi routers that are incorrectly configured and positioned behind a concrete wall in the garage. So 100mbps comes into their house, but their laptops, TVs and phones see 20mbps. There's also a huge amount of government money going into rural connectivity. It seems to me that StarLink is an ideal solution to this. Rather than running lots of cable to houses that are miles apart, give people subsidies to get StarLink. But if you make legislation that StarLink isn't \"broadband\", then the money needs to go to the incumbents, who will want billions of dollars in subsidies to lay expensive cables to service a small number of people. If I had to guess, some of those large players might have lobbied for this change, because they want some of that $18 billion pie that the FCC authorized for rural broadband expansion [1]. Anecdotally, Comcast has a 50mbps plan in my neighborhood for $20/month. If I needed more than that, I would gladly pay for it... affordability isn't the issue, I just get very little benefit from a connection faster than that, and the faster plans still have the same 10mbps upload speeds [2]. What I would 100% definitely pay for is more reliable internet that (almost) never goes down, but there's only two options in my neighborhood and I'm not sure the alternative is better. And I'm a software engineer... I'm on my computer all day, often downloading large files, on lots of zoom calls, while my kids are watching Netflix. I doubt most people's needs are substantially higher than mine. [1] https://www.fcc.gov/document/fcc-authorizes-over-18-billion-... [2] they actually gave me a free bump to 150mbps a few days ago, probably in response to this new ruling. I haven't really noticed any difference. reply hedora 8 hours agoparentStarlink is giving me over 150 up and 20 down during peak hours in a waitlist / oversubscribed area with a previous generation modem. They more than meet the new definition for broadband. However, it doesn't scale nearly as well as just running fiber to the home, either in number of subscribers, or in per-home cost. Some relatives live in an area with a phone co-op, and they ran trenchless underground fiber to each home in their service area. Population density is something like 1.2 people per square mile, and median income is ~ $20K. Monthly rates are extremely low. I watched the installers. It was two people and they were covering a good fraction of a mile per day. Equipment and material costs are negligible. There are communities in the SF bay area that are outside of telco monopoly territory. Trenching fiber here (in the mountains) runs something like $10K/house, which is $27/month when you amortize the cost out over 30 years. The equity / subsidy programs I've seen are always just handouts for large ISPs that have established monopolies and that refuse to reinvest even a small fraction of their monthly revenue into network upgrades. Establishing municipal broadband or broadband co-ops and giving them automatic right-of-way priority over the incumbents would fix this problem overnight. Either there would be a second fiber network that didn't suck, or the incumbents would actually invest in their networks. reply tzs 8 hours agoparentprev> Meanwhile, the vast majority of people have $30 wifi routers that are incorrectly configured and positioned behind a concrete wall in the garage. So 100mbps comes into their house, but their laptops, TVs and phones see 20mbps. Why would they have the routers in their garage instead of in their house? Most houses that have cable have cable outlets inside the house, since the reason cable was originally put in was to support cable TV and generally people have their TVs in the house. reply vel0city 4 hours agorootparentFor a period a lot of FTTH deployments put ONTs in the garage. As some of those networks upgraded CPE ONTs and integrating ONTs into their residential gateways, they often didn't bother actually bringing those fiber runs into the house. I wouldn't say this is incredibly common though, it really depends on which network and when the original install took place. reply Cody-99 9 hours agoparentprevStrange logic IMO. Internet service providers already receive money from the government through grants, loans, and other programs. Opposing increasing the pretty low requirements on ISPs who already receive this money just doesn't make a lot of sense to me. Millions of people are getting an increase in their internet speed (including many in this thread!) at the flip of a switch. Seems like a pretty big win. >Anecdotally, Comcast has a 50mbps plan in my neighborhood for $20/month. If I needed more than that, I would gladly pay for it... affordability isn't the issue Nothing is stopping Comcast from still offering that plan to you. They just can't call it broadband or keep receiving money from the government. They now have to provide a slightly better service if they want to keep receiving those federal funds. >There's also a huge amount of government money going into rural connectivity. It seems to me that StarLink is an ideal solution to this. Rather than running lots of cable to houses that are miles apart, give people subsidies to get StarLink. But if you make legislation that StarLink isn't \"broadband\", then the money needs to go to the incumbents, who will want billions of dollars in subsidies to lay expensive cables to service a small number of people. If I had to guess, some of those large players might have lobbied for this change, because they want some of that $18 billion pie that the FCC authorized for rural broadband expansion [1]. Sorry this just silly. We already run electricity to basically everywhere so hanging some extra fiber on the polls that already exist isn't really hard. Rural electric coops exist and have been rolling out fiber across their existing power network with great success! Starlink is not a serious solution to providing reliable, fast broadband to rural America. It doesn't have the capacity to meet the needs of rural America either. Put aside the long term future concerns of starlink (whose satellites are all in LEO and have to constantly be replaced) the price argument alone isn't great. The local electric coop that covers 9 rural counties near me offers a base plan of 100mbit up and down at $70 a month via fiber. Starlink is $120 a month for a speed that varies between 250mbit to less than 40mbit. Internet speed demands are only going to increase so we should keep in mind the ability to scale up; which is an area fiber wins at again. We already have the polls and electric coops ready to serve rural America. No need to gamble on a more risky and worse product like starlink. Worrying about subsidies for \"incumbents\" while in the next sentence suggesting subsiding for Starlink/Elon is pretty funny! >but I have some involvement in my city's digital equity community, so I have some insight into what this translates to for local governments and community organizations. Now what will happen is someone at the county level in charge of digital infrastructure will look at at a map and say \"oh no, 40% of our population doesn't have broadband, and 20% don't even have access to broadband\". GOOD. They should be looking at it! If 40% of the county can't get a basic 100mbit/20mbit internet package then something should be done to address that. DOCSIS has been able to push multi gbit speeds over coax for a decade so I don't buy it Comcast or whoever in your county can't provide 100/20. reply gnicholas 4 hours agorootparent> If 40% of the county can't get a basic 100mbit/20mbit internet package then something should be done to address that. The problem isn't that they're offering higher speeds. The problem is that they're getting rid of lower speeds. I've been repeatedly forced off my old plan as Comcast has sunset them. It appears very clear that their moves are in response to FCC definition changes. I wish I could still have my 25 down service, along with my old price ($19). But I can't! They killed that service years ago, before they killed the 40 down service and the 50 down service. The lowest tier I can buy is 75 down. I'm all for options, but it's clear that rejiggering the definition of broadband has the (perhaps) unintended side effect of eliminating low-cost options that would be fine for many families. reply LoganDark 8 hours agoparentprev> I oppose this. 100mbps just isn't what most people need. It's a quality of life improvement. :/ reply h4x0rr 11 hours agoprevMewnwhile germany just raised it to 10Mbps reply mbwgh 2 hours agoparentI was going to say that, then I noticed people are arguing about the \"number of 9s of availability\". You guys have WHAT? reply zachmu 9 hours agoprevThis reclassifies Starlink as not broadband, at least for the basic plan. reply zeristor 9 hours agoprevI guess there’s nothing about latency in this? I envy the LPBs. reply JohnTHaller 11 hours agoprevtldr; Today: 100Mbps down / 20Mbps up (45 million Americans lack access as of Dec 2022) 2015 onward: 25Mbps down / 3Mbps up Pre-2015: 4Mbps down / 1Mbps up The commission's longterm goal is 1Gbps down / 500Mbps up. These distinctions of 'broadband' help determine where to focus resources. reply SteveGerencser 11 hours agoparentWe are in the 45 million. When we moved here over a decade ago we were told by TDS that they were expanding their service and should be able to provide us with 50Mbs 'soon'. 10 years later we are still 5Mbs (3 in real-world situations). With no plan to expand here ever. Fortunately, the local electric company got a grant and is rolling out 1Gbs fiber to 100% of their customers. TDS couldn't do it because it wasn't 'profitable'. The electric company is fast-tracking the build-out and we should have service less than 18 months after they started. reply AngryData 6 hours agorootparentI got 1 gig fiber to the home just this last year thanks to a an electric company fiber co-op. Couldn't get DSL before because the lines were so degraded and no one offered it. Until now the only available internet was wireless in a highly forested area. reply mattmaroon 10 hours agoparentprevDespite living in a city, I was one of those 45 million until pretty recently. Due to some weird network topography, I only had one option, spectrum, and it never worked very well, and they never were very incentivized to fix it. Now that 5G Internet exists, I am paying $25 a month for 300 Mb access and my life is better. I debated over years just because of the inability to get decent Internet at home. reply rrr_oh_man 11 hours agoparentprevSo they would like to get to the level of Romania. reply happytiger 9 hours agoprevThis is excellent news. Good job FCC. reply partiallypro 10 hours agoprevMy parents to this day still don't have real broadband access. The best they can get is a bad 4G signal to their rural area. Even Starlink only has speeds of 40mbs in their area. They only live about a mile from a fiber line, but AT&T won't run it over because it would only service maybe 10-15 homes, and there are no cable lines. I think this is more common than people think. reply gnicholas 4 hours agoparentWhat's wrong with 40mbs? I honestly don't need more than 20. The only time I even notice faster speeds is when my podcasts download. I'm curious what types of situations require more than 40mbps, and why the inability to do those tasks would mean that someone doesn't haver \"real broadband access\". I was pushed from 50 to 75 a while back and seriously hardly notice it. reply cute_boi 9 hours agoprevthe problem is upload speed is around 15mbps which is extremely bad. reply theodric 11 hours agoprevI appreciate any effort on the part of a government to exert pressure on industry to deliver a product to citizens that keeps up with the times, but I'm not sure it really matters anymore. Any connection that can stream YouTube at an acceptable resolution is 'broadband' in my eyes, while someone who's rsyncing terabytes daily would probably suck up as much bandwidth as they can get and come back for a second helping. Maybe, just maybe, everyone has learned the Nerd Words well enough that we can simply refer to connection performance by X number of megabits per second (probably not). Good thing the FCC doesn't control Ireland, or I'd no longer be able to declare that I have broadband via satellite! Well, part of the time, anyway. reply rsynnott 11 hours agoparent25Mbit/sec isn’t really good enough for 4K video. > Good thing the FCC doesn't control Ireland, or I'd no longer be able to declare that I have broadband via satellite! Well, part of the time, anyway. I mean, you can call it what you want, but it’s under the minimum standard set by the NBP in 2012 (30Mbit, 25ms). Fortunately, if that’s the best you can get, you’re almost certainly in an NBI intervention area, so a minimum of 500Mbit via FTTH should be available to you at some point. You can check here: https://nbi.ie/map/ reply snapplebobapple 11 hours agoprevThey missed a zero... reply google234123 11 hours agoprevThis is over regulation imo. If you support this then you can’t complain about there not being any low cost housing because it’s regulations akin to this that is increasing the costs. 25->100 is more of a luxury then a necessity reply cogman10 11 hours agoparentHow much do you pay for internet? Maybe you should be directing your ire elsewhere. I currently pay $60/month for 600 down. An ISP that actually struggles to provide 100mbps down at a reasonable rate, today, is simply one that refuses to update their hardware. 100mbps is not hard to achieve with semi-modern hardware. I know of ISPs servicing remote small communities with 1gbps down at $100/month. 300 down for $30/month. reply l72 8 hours agorootparentIt is really frustrating. I live in a US city (close to the city center) where my options are Spectrum or AT&T. AT&T still only provides ADSL (recently updated to 30/10). 5 years ago, AT&T tore up our street and laid fiber. 3 streets over, fiber is available, but still not on my street. reply rsynnott 10 hours agorootparentprevIt’s less a hardware problem and more a medium problem; to go over 100Mbit/sec reliably you’re realistically looking at fibre (or maybe coax, but coax isn’t particularly cost-effective or practical in the rural areas that tend to have problems in this direction.) reply Cody-99 10 hours agorootparentDOCSIS has been able to push 100Mbit/s over coax for nearly 2 decades. Hanging fiber isn't really a complex process anymore anyways. We already run power to basically everywhere people live so hanging some fiber as you go isn't that hard. Electric coops have been receiving federal funding to hang fiber in even the most rural areas for the last 8-10 years with great success. reply rsynnott 9 hours agorootparentOh, sure, but deploying high-speed DOCSIS only really makes sense relative to fibre in _relatively_ dense areas; it’s not a particularly sensible solution for rural ones. reply bongodongobob 10 hours agorootparentprevHuh? Business class coax in my area is 1 Gb down. And yes, it does reach those speeds. Are you thinking of DSL? reply rsynnott 10 hours agorootparentIs this a relatively urban area, though? Generally, high speed coax networks these days consist of a relatively short, often shared stretch of coax, connecting back to a fibre-optic node. You’re looking at something like this: https://en.wikipedia.org/wiki/Hybrid_fiber-coaxial#/media/Fi... If the premises served are low-density enough, you may be looking at only one or two per coax section, and at that point you’re probably cheaper just using fibre to the premises anyway. reply bongodongobob 9 hours agorootparentAh I see what you mean now. Yeah, it's most likely fiber backbone and coax last mile. I thought you meant it was a limit of the physical medium. reply faeriechangling 11 hours agoparentprev25mbps being \"broadband\" is a bit of a joke, a single 4k stream can exceed that. 100mbps is about what is needed for todays \"broadband\" applications. Raising the floor to 20mbps for uploads is also fairly important for more practical things, having to backup a laptop at 3mbps was wholly impractical. 20mbps is a good bump if you're running some backups overnight, or uploading a 4k video file. I don't see any reason to raise the definition of bandwidth higher for the next decade though. But I should stress, the amount of money needed to make these upgrades is pretty marginal in the grand scheme of things, we're not talking about replacing a ton of last mile wiring. reply google234123 10 hours agorootparentEvery increase to the cost of living is probably marginal alone reply RacerCrispTaru 33 minutes agoparentprevYou're all getting scammed. I pay 29€ for 1000/100 (2/3ms to first hop) but the contract is a few years old. I could upgrade to 2500/500 at the same price. reply rrr_oh_man 11 hours agoparentprev> 25->100 is more of a luxury then a necessity Not if you work remotely. reply l72 8 hours agorootparentAgreed. I work from home, but my upload speed still kills me at time. It is not uncommon to need to share a 500M+ file with a colleague, and 30-60 minutes is just too slow. I still have to go into the office on some days when I know I'll be doing stuff like this. Not to mentions that for my personal computers, I want offsite backups. I have to take a hard-drive and personal laptop to the office every few months to seed a full backup, since it is just too slow from home, other than the incremental backups. reply tzs 8 hours agorootparentprevNot necessarily. If your work uses AWS and only needs the smaller instance sizes 25 mbps might be plenty. Those instances do not have very high network performance. I don't think I've ever managed to get above 20 mbps downloading from my employer's little AWS instances. reply chgs 10 hours agorootparentprevI’ve worked remotely for well over a decade. I currently t have 32/8. I rarely use even half that. The occasional large file may take a few seconds to download, it’s hardly a problem to wait 10 seconds though. reply rsynnott 11 hours agoparentprev… WAit, how, precisely, does this make housing more expensive? Like, what is the method of action? reply cogman10 11 hours agorootparentIt's the (IMO faulty) theory that all regulations increase prices. Sort of like \"if you require all houses to meet code, you can't have a market for very low quality houses that would decrease the prices of mid quality houses\". The problem with this theory, particularly in the case of an ISP, is you need an actual free and open market with a large amount of competition before it starts making any sense. When you talk about things like ISPs which are region locked and have low or even no competition then it's meaningless. A region locked ISP can (and will) charge pretty much any price the market will bear divorced from the actual cost of service. reply google234123 10 hours agorootparentCalifornia has at least 24,000 regulations applying to residential housing FYI reply cavisne 10 hours agorootparentprevDepending on how they treat oversubscription, Wireless ISP's cant really offer this speed reliably, so they would lose their subsidy. So building housing in a remote area only served by a WISP gets more expensive. In practice I don't think the FCC really thinks about oversubscription. reply Cody-99 10 hours agoparentprevThis is a wild thing to comment. Nothing is stopping internet providers from selling internet below broadband standard and many do. Changing the exact meaning of broadband allows the government to raise the standard of service people receive and pressure ISPs to be better. Now ISPs have to be at 100/20 minimum otherwise they will not be able to receive grants or other government funding. It isn't over regulation to mandate ISPs who take government money to meet some pretty basic speed requirements. 100/20mbit isn't even a high bar. reply dghlsakjg 10 hours agoparentprevChanging the definition of something for statistical purposes is over-regulation? reply kalkr 11 hours agoparentprevwhat would you propose instead? would you keep it the same? reply m463 10 hours agoprev [–] If you happen to have 100mbps service, will your rate go down? reply chrisfinazzo 8 hours agoparentI’d sure like to know this, as we’re on Optimum 100, which isn’t sold to new customers anymore. Also of note, some uploads might actually go up substantially - a bunch of people on 100 down plans have seen uploads cut to almost nothing, e.g, 35 -> 5. Time will tell. reply m463 4 hours agoparentprev [–] edit: I meant: will your monthly bill go down? I \"splurged\" for 100mbit and now it seems like it might be the bottom tier. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The FCC increased the minimum broadband speed from 25Mbps to 100Mbps for downloads and 20Mbps for uploads to improve identifying underserved areas and allocating government funds.",
      "Future plans include raising the broadband metric to 1,000Mbps for downloads and 500Mbps for uploads.",
      "Republican Commissioners dissented, suggesting that satellite internet services like SpaceX's Starlink, offering high-speed connectivity, should be recognized in the speed benchmarks."
    ],
    "commentSummary": [
      "The FCC has raised the minimum broadband speed requirement to 100Mbps, leading to debates about the necessity of higher upload speeds and the evolution of internet technology.",
      "Users note improvements from providers, emphasizing the importance of symmetric connections and the impact of FCC regulations on broadband speeds.",
      "Discussions highlight the significance of faster speeds, reliable infrastructure, and equitable access to the internet for all users amidst concerns about potential cost increases and access challenges."
    ],
    "points": 449,
    "commentCount": 200,
    "retryCount": 0,
    "time": 1710450254
  },
  {
    "id": 39709089,
    "title": "CEO of Onerep.com Linked to Multiple People-Search Firms",
    "originLink": "https://krebsonsecurity.com/2024/03/ceo-of-data-privacy-company-onerep-com-founded-dozens-of-people-search-firms/",
    "originBody": "March 14, 2024 8 Comments The data privacy company Onerep.com bills itself as a Virginia-based service for helping people remove their personal information from almost 200 people-search websites. However, an investigation into the history of onerep.com finds this company is operating out of Belarus and Cyprus, and that its founder has launched dozens of people-search services over the years. Onerep’s “Protect” service starts at $8.33 per month for individuals and $15/mo for families, and promises to remove your personal information from nearly 200 people-search sites. Onerep also markets its service to companies seeking to offer their employees the ability to have their data continuously removed from people-search sites. A testimonial on onerep.com. Customer case studies published on onerep.com state that it struck a deal to offer the service to employees of Permanente Medicine, which represents the doctors within the health insurance giant Kaiser Permanente. Onerep also says it has made inroads among police departments in the United States. But a review of Onerep’s domain registration records and that of its founder reveal a different side to this company. Onerep.com says its founder and CEO is Dimitri Shelest from Minsk, Belarus, as does Shelest’s profile on LinkedIn. Historic registration records indexed by DomainTools.com say Mr. Shelest was a registrant of onerep.com who used the email address dmitrcox2@gmail.com. A search in the data breach tracking service Constella Intelligence for the name Dimitri Shelest brings up the email address dimitri.shelest@onerep.com. Constella also finds that Dimitri Shelest from Belarus used the email address d.sh@nuwber.com, and the Belarus phone number +375-292-702786. Nuwber.com is a people search service whose employees all appear to be from Belarus, and it is one of dozens of people-search companies that Onerep claims to target with its data-removal service. Onerep.com’s website disavows any relationship to Nuwber.com, stating quite clearly, “Please note that OneRep is not associated with Nuwber.com.” However, there is an abundance of evidence suggesting Mr. Shelest is in fact the founder of Nuwber. Constella found that Minsk telephone number (375-292-702786) has been used multiple times in connection with the email address dmitrcox@gmail.com. Recall that Onerep.com’s domain registration records in 2018 list the email address dmitrcox2@gmail.com. It appears Mr. Shelest sought to reinvent his online identity in 2015 by adding a “2” to his email address. A search on the Belarus phone number tied to Nuwber.com shows up in the domain records for askmachine.org, and DomainTools says this domain is tied to both dmitrcox@gmail.com and dmitrcox2@gmail.com. Onerep.com CEO and founder Dimitri Shelest, as pictured on the “about” page of onerep.com. A search in DomainTools for the email address dmitrcox@gmail.com shows it is associated with the registration of at least 179 domain names, including dozens of mostly now-defunct people-search companies targeting citizens of Argentina, Brazil, Canada, Denmark, France, Germany, Hong Kong, Israel, Italy, Japan, Latvia and Mexico, among others. Those include nuwber.fr, a site registered in 2016 which was identical to the homepage of Nuwber.com at the time. DomainTools shows the same email and Belarus phone number are in historic registration records for nuwber.at, nuwber.ch, and nuwber.dk (all domains linked here are to their cached copies at archive.org, where available). Nuwber.com, circa 2015. Image: Archive.org. A review of historic WHOIS records for onerep.com show it was registered for many years to a resident of Sioux Falls, SD for a completely unrelated site. But around Sept. 2015 the domain switched from the registrar GoDaddy.com to eNom, and the registration records were hidden behind privacy protection services. DomainTools indicates around this time onerep.com started using domain name servers from DNS provider constellix.com. Likewise, Nuwber.com first appeared in late 2015, was also registered through eNom, and also started using constellix.com for DNS at nearly the same time. Listed on LinkedIn as a former product manager at OneRep.com between 2015 and 2018 is Dimitri Bukuyazau, who says their hometown is Warsaw, Poland. While this LinkedIn profile (linkedin.com/in/dzmitrybukuyazau) does not mention Nuwber, a search on this name in Google turns up a 2017 blog post from privacyduck.com, which laid out a number of reasons to support a conclusion that OneRep and Nuwber.com were the same company. “Any people search profiles containing your Personally Identifiable Information that were on Nuwber.com were also mirrored identically on OneRep.com, down to the relatives’ names and address histories,” Privacyduck.com wrote. The post continued: “Both sites offered the same immediate opt-out process. Both sites had the same generic contact and support structure. They were – and remain – the same company (even PissedConsumer.com advocates this fact: https://nuwber.pissedconsumer.com/nuwber-and-onerep-20160707878520.html).” “Things changed in early 2016 when OneRep.com began offering privacy removal services right alongside their own open displays of your personal information. At this point when you found yourself on Nuwber.com OR OneRep.com, you would be provided with the option of opting-out your data on their site for free – but also be highly encouraged to pay them to remove it from a slew of other sites (and part of that payment was removing you from their own site, Nuwber.com, as a benefit of their service).” Reached via LinkedIn, Mr. Bukuyazau declined to answer questions, such as whether he ever worked at Nuwber.com. However, Constella Intelligence finds two interesting email addresses for employees at nuwber.com: d.bu@nuwber.com, and d.bu+figure-eight.com@nuwber.com, which was registered under the name “Dzmitry.” PrivacyDuck’s claims about how onerep.com appeared and behaved in the early days are not readily verifiable because the domain onerep.com has been completely excluded from the Wayback Machine at archive.org. The Wayback Machine will honor such requests if they come directly from the owner of the domain in question. Still, Mr. Shelest’s name, phone number and email also appear in the domain registration records for a truly dizzying number of country-specific people-search services, including pplcrwlr.in, pplcrwlr.fr, pplcrwlr.dk, pplcrwlr.jp, peeepl.br.com, peeepl.in, peeepl.it and peeepl.co.uk. The same details appear in the WHOIS registration records for the now-defunct people-search sites waatpp.de, waatp1.fr, azersab.com, and ahavoila.com, a people-search service for French citizens. The German people-search site waatp.de. A search on the email address dmitrcox@gmail.com suggests Mr. Shelest was previously involved in rather aggressive email marketing campaigns. In 2010, an anonymous source leaked to KrebsOnSecurity the financial and organizational records of Spamit, which at the time was easily the largest Russian-language pharmacy spam affiliate program in the world. Spamit paid spammers a hefty commission every time someone bought male enhancement drugs from any of their spam-advertised websites. Mr. Shelest’s email address stood out because immediately after the Spamit database was leaked, KrebsOnSecurity searched all of the Spamit affiliate email addresses to determine if any of them corresponded to social media accounts at Facebook.com (at the time, Facebook allowed users to search profiles by email address). That mapping, which was done mainly by generous graduate students at my alma mater George Mason University, revealed that dmitrcox@gmail.com was used by a Spamit affiliate, albeit not a very profitable one. That same Facebook profile for Mr. Shelest is still active, and it says he is married and living in Minsk (last update: 2021). The Italian people-search website peeepl.it. Scrolling down Mr. Shelest’s Facebook page to posts made more than ten years ago show him liking the Facebook profile pages for a large number of other people-search sites, including findita.com, findmedo.com, folkscan.com, huntize.com, ifindy.com, jupery.com, look2man.com, lookerun.com, manyp.com, peepull.com, perserch.com, persuer.com, pervent.com, piplenter.com, piplfind.com, piplscan.com, popopke.com, pplsorce.com, qimeo.com, scoutu2.com, search64.com, searchay.com, seekmi.com, selfabc.com, socsee.com, srching.com, toolooks.com, upearch.com, webmeek.com, and many country-code variations of viadin.ca (e.g. viadin.hk, viadin.com and viadin.de). The people-search website popopke.com. Domaintools.com finds that all of the domains mentioned in the last paragraph were registered to the email address dmitrcox@gmail.com. Mr. Shelest has not responded to multiple requests for comment. KrebsOnSecurity also sought comment from onerep.com, which likewise has not responded to inquiries about its founder’s many apparent conflicts of interest. In any event, these practices would seem to contradict the goal Onerep has stated on its site: “We believe that no one should compromise personal online security and get a profit from it.” The people-search website findmedo.com. Max Anderson is chief growth officer at 360 Privacy, a legitimate privacy company that works to keep its clients’ data off of more than 400 data broker and people-search sites. Anderson said it is concerning to see a direct link between between a data removal service and data broker websites. “I would consider it unethical to run a company that sells people’s information, and then charge those same people to have their information removed,” Anderson said. Last week, KrebsOnSecurity published an analysis of the people-search data broker giant Radaris, whose consumer profiles are deep enough to rival those of far more guarded data broker resources available to U.S. police departments and other law enforcement personnel. That story revealed that the co-founders of Radaris are two native Russian brothers who operate multiple Russian-language dating services and affiliate programs. It also appears many of the Radaris founders’ businesses have ties to a California marketing firm that works with a Russian state-run media conglomerate currently sanctioned by the U.S. government. KrebsOnSecurity will continue investigating the history of various consumer data brokers and people-search providers. If any readers have inside knowledge of this industry or key players within it, please consider reaching out to krebsonsecurity at gmail.com. This entry was posted on Thursday 14th of March 2024 05:13 PM A Little Sunshine Breadcrumbs 375-292-7027-786 ahavoila.com azersab.com Constella Intelligence constella.ai d.sh@nuwber.com Dimitri Shelest dmitrcox@gmail.com findita.com findmedo.com folkscan.com huntize.com ifindy.com jupery.com look2man.com lookerun.com manyp.com nuwber.at nuwber.ch nuwber.dk nuwber.fr onerep.com peeepl.br.com peeepl.co.uk peeepl.in peeepl.it peepull.com Permanente Medicine perserch.com persuer.com pervent.com piplenter.com piplfind.com piplscan.com popopke.com pplcrwlr.dk pplcrwlr.fr pplcrwlr.in pplcrwlr.jp pplsorce.com qimeo.com scoutu2.com search64.com searchay.com seekmi.com selfabc.com socsee.com srching.com toolooks.com upearch.com viadin.ca viadin.com viadin.de viadin.hk waatp1.fr waatpp.de webmeek.com",
    "commentLink": "https://news.ycombinator.com/item?id=39709089",
    "commentBody": "CEO of data privacy company Onerep.com founded dozens of people-search firms (krebsonsecurity.com)438 points by todsacerdoti 12 hours agohidepastfavorite107 comments SteveGerencser 11 hours agoA not-so-secret dirty little secret is that many of the reputation management agencies also own many of the public records websites that publish mug shots, court records, and so on. When you hire them to remove that information from the internet it puts you into a cycle of being removed from one or two of their website and added to something else. You end up in a never-ending game of whack-a-mole. Complete with monthly fees. reply vmfunction 50 minutes agoparentThe lesson for the modern ago. Don't put stuff into digital form if you want privacy! Some places don't allow use of smart phone. They actually ask you check your phone into a coat check type thing at door! One journalist friend often leaves the smart phone at home. reply noir_lord 1 minute agorootparentNever did. It wasn't paranoia it was a healthy dose of \"if this is possible, someone is doing it\" Turned out they in fact were doing it. reply jojobas 3 minutes agorootparentprevThis lesson can't be bashed into children enough. reply philjohn 37 minutes agorootparentprevMore theatre performances are doing this now. Cabaret at the Kit Kat club in London places a sticker over any camera lens. The Burnt City, an immersive theatrical experience, makes you place your phone in a pouch that is then sealed with a tamper evident fastening before you enter the venue. reply _factor 10 hours agoparentprevRelated, proofpoint is notorious for this as well. They will block your mail server without cause, forcing you through their process of delisting. Pay and your problems magically go away. Proofpoint was consistently the only block hit. reply calvinmorrison 8 hours agorootparentTbf putting up cash is a great signal for 'not a spammer'. reply _factor 7 hours agorootparentTrue, but not the only method. You’d be surprised how many spammers drop with greylisting enabled. reply greggsy 11 hours agoparentprevIt’s racketeering reply m463 10 hours agorootparentthis seems to fit the definition. In many cases, the potential problem may be caused by the same party that offers to solve it, but that fact may be concealed, with the intent to engender continual patronage. https://en.wikipedia.org/wiki/Racketeering reply throwaway2474 6 hours agorootparentSee also https://en.m.wikipedia.org/wiki/Worldcoin reply andirk 3 hours agorootparentLol those orbs! Oddly, Worldcoin's main exchange is Binance which stopped doing business in USA so I couldn't get a bag. Up almost 10x. Not bad for a sphere that proves \"personhood\". With AI making actual people vs machine created more difficult to discern, it may have evermore applications. reply walterbell 8 hours agorootparentprevFrom \"The Sopranos\", Patsy and Burt failed extortion attempt at \"Starbucks\", https://www.youtube.com/watch?v=_Gsz7Gu6agA reply dylan604 5 hours agorootparentI always loved that scene. The times, they are a-changin reply Arrath 11 hours agorootparentprevWatch these vultures frame it as clever vertical integration. They control the supply (the sites with your info) and the demand (the sites you can go through to request it get taken down) /s, obviously reply maximinus_thrax 11 hours agorootparentprevIt's been going on for years https://www.theguardian.com/technology/2018/jun/12/mugshot-e... reply api 10 hours agoparentprevProstitution is not the oldest profession. Racketeering probably is. Probably started with the most basic form: giving your food to Ugg to pay him to stop his brother Grug from punching you. reply friendlyHornet 10 hours agorootparentProfessional bullying reply cellis 6 hours agorootparentprevAka taxation! reply vkou 5 hours agorootparentI'm pretty sure you can tell the difference between the two. reply 9991 3 hours agorootparentBanditry is when the baddies drop by periodically to demand a portion of your labor on threat of violence. Government is when they don’t leave. reply EasyMark 3 hours agorootparentthe last guy who stole an Amazon box off my porch didn't put up a school for my kids, the road in front of my house, help the homeless guy I gave my second burger to the other day get out of the cold, make sure the water out of my tap didn't kill me, etc reply Dudhbbh3343 2 hours agorootparentMany large drug cartels pay for schools, give out food to the poor, and control some forms of crime to increase public support or at least prevent their protest. Once organized crime gets big enough, it's really difficult to distinguish from a weak government. reply bryanrasmussen 37 minutes agorootparentSure and many feudal warlords grew the same way but at some point the Castle decayed away and became a tourist destination and what was left behind was the community and governance. Once organized crime gets really big, it stops being crime and persists on organization alone. reply Dudhbbh3343 5 minutes agorootparentI agree, but I would argue that the label of \"crime\" is mostly semantics. The violence (or at least the threat of violence) of the crimes still persists, but whoever is the most powerful group gets to change the label of their violence from \"crime\" to \"law enforcement\". yMEyUyNE1 2 hours agorootparentprevYeah, there is a huge difference between opportunist petty thiefs and organized crime bosses. reply ta234234234234 3 hours agoparentprevImagine living with yourself as this person; you actively engage in this shenanigans. What a scumbag way of life. reply rqtwteye 1 hour agorootparentAs long as you make good money you will be a very respected member of society. reply patcon 8 hours agoparentprevIsn't this just a white-hat/black-hat hacker dynamic, except in this case the latter is legal? reply ironmagma 6 hours agorootparentWell, both hats ostensibly are at least doing real work (finding vulnerabilities). reply omnimike 11 hours agoprevI can’t give specifics, I know someone who had to deal with “delete me” requests from these “privacy” companies. The privacy company would literally take your personal info (name, email), and _email it to every company they could think of_ asking the company to delete your account _even if you didn’t have one_. reply imiric 11 hours agoparentI had a suspicion these services actually do more harm than good, even if they're well intentioned and not actively running a data collection scheme. But this is really a chicken-egg situation. How do you tell companies to delete your information without telling them what identifies your information? It's in these companies' interest to make this as difficult as possible, so a solution based on data hashes is highly unlikely to appear out of their good will alone. This requires strict regulation and high fines. There's also the issue of proving ownership of the data requested for deletion. Even in the EU with the GDPR, which is arguably the most progressive data privacy regulation we have, companies routinely violate this by requesting even more personal information from the requester. reply dpkirchner 10 hours agorootparentIdeally a regulator would intervene, demanding that the data provider prove that each person in their database has explicitly opted in. That should be really easy for these companies -- it's just another record to include in our files. If they can't prove it, they must delete all related data. reply hirsin 6 hours agorootparentAnd when they autofill that value with 1, because they obviously got all of that data legitimately? Will consumers be asked to prove a negative? Even test cases will run into data sharing issues. reply bryanrasmussen 33 minutes agorootparent>And when they autofill that value with 1, amazingly enough the law is more clever than programmers assume it is, and the clever dodges programmers come up with tend to be seen through and just lead to jail time. Prime Exhibit - https://en.wikipedia.org/wiki/Hans_Reiser reply databroken 6 hours agorootparentprevWhy not just outlaw data brokers entirely? reply mk89 1 hour agorootparentBecause they need them for their stupid election campaigns, surveys and crap like that. reply planede 34 minutes agorootparentprevAh, the evil bit. reply notclive 6 hours agorootparentprevWhat does proof look like? On past projects we've recorded the time the user submitted a from (with a checked consent checkbox), but this doens't feel like rigorous proof. reply letitbeirie 10 hours agorootparentprev> actually do more harm than good I've wondered about this too. I have a common enough name that about 2/3 of the info data brokers have on me is garbage. If every data broker could be relied on to faithfully delete my info I would sign up for Optery or Incogni today. I don't, because if even one of those 2/3 is a bad actor I'm just expending effort to clean up their data. Specifically, the data I don't want them to have. reply godelski 9 hours agorootparentprevMy impression is that it depends what company you use. I don't really trust them but at the same time, there are a lot of other companies. All I can really say is that Optery will give you a free report with very minimal information and on a test they dug up far more information that I provided (the minimum). Given that these companies, like Incogni and DeleteMe, are now sponsoring big time YouTubers I'd imagine they are soon going to get a much closer look. At minimum, they are making far more people aware of the situation and data out there. Even though many of the VPNs fall far short of the promises, it is setting a strong signal that people care about privacy and entering the public lexicon is the first step. I hope these can be a catalyst towards more state or federal privacy protection. reply EasyMark 3 hours agoparentprevDevil's advocate here, n=1 is just a data point is rarely the whole story. I would assume, but obviously I could be wrong, that the legit ones actually can check if your info exists in a company before they send a take down request. I have no proof of that but it's probably nearly as good as n=1. reply tlogan 8 hours agoparentprevWhen you use these ‘delete me’ services to remove your information from a platform like Dropbox, there’s a hidden catch. These services are often linked to companies that trade in email addresses. By submitting your email for deletion, you might unwittingly end up having it sold to marketers or data brokers, potentially leading to even more spam and unwanted contacts. Or maybe nice target ads … depending who bought your email address reply j-bos 11 hours agoprevThis kind of thing feels better left to trusted 1st parties, oneself. Link to a list of data broker opt out methods:https://github.com/yaelwrites/Big-Ass-Data-Broker-Opt-Out-Li... reply dheera 3 hours agoparentI used Onerep until I was told it was shady. I now use Optery (https://www.optery.com/) which is a YC company. I'd love to hear if there are any issues with it. The problem is there are 200+ data brokers out there and I don't have time to deal with that many. reply emmanueloga_ 8 hours agoparentprevhas anyone tried the service advertised by the author of the list? Looks interesting / useful. [1] -- 1: https://securityplanner.consumerreports.org/ reply ugh123 10 hours agoparentprevGreat list! My first thought was: \"why stick all this info in a readme and not some nice json list I could scrape\". I then thought: \"maybe I can just have my AI friend scan the readme and do all the opt-out work for me\" reply Animats 11 hours agoprevIt's like the old days of Ironport. Ironport built a rack-mount spam filtering appliance for business. They also built a rack-mount spam-sending appliance for business. That blew their reputation. reply runjake 11 hours agoparentI’m pretty sure Ironport getting bought by Cisco and then Cisco letting their product rot while simultaneously jacking up prices blew Ironport’s reputation. They were excellent appliances before the acquisition. reply carimura 12 hours agoprevin the same category of \"Best of the Internet\", my favorite are the sites that claim every person on the planet has an \"arrest record found\" and you can see those records for $49. Or if you're that person, pay us $99 to remove it. reply fnordpiglet 11 hours agoparentWell in the US we are on track for that to be true. But seriously - trading both sides (or, selling protection, as the case may be) is quite a profitable business model. reply omoikane 11 hours agoprevI wonder if there are reputation protection companies that try a different strategy: for every user that requests their service, prop up thousands of fake identities with the user's name, but each with some inconsistent profile that are almost, but not quite, entirely unlike the original user. So if someone search for a person, their search results would be flooded with garbage. Since it seems very difficult to try to get a leaked identity removed, maybe try to hide a tree in the forest? reply sangnoir 11 hours agoparentThe former British prime minister executed a similar technique to hide his scandal by releasing search-engine chaff. He had a press interview where he claimed one of his hobbies was painting miniature red buses, and the scandal he was hiding was false and distateful ads on a (real) red bus as part of a campaign for Brexit. reply Terr_ 9 hours agorootparentTIL: > For example, the disaster surrounding London’s new Routemaster city buses disappeared into the depths of the web after Johnson made completely nonsensical statements in the media about building model buses from wine crates. Coverage of these statements triggered a flood of search queries on Google that displaced negative search queries and Google Suggest results related to Boris Johnson. > Research showed that before the wine crate buses interview, 100% of Google Suggest and search results on page one that were displayed in connection with Boris Johnson had negative connotations. After the interview, it was only 20%. > Additionally, when news broke that British Government members had flouted Covid guidelines to meet for wine and cheese during a ‘work meeting’, it was seized upon by the British press as “partygate.” Soon after, Johnson was quoted in interview saying, “I don’t work from home. The cheese will distract you.” As a result, negative coverage of the British Government’s party-gate incidents were glossed over by search suggestions and results, and keywords with negative connotations no longer appeared in Google Suggest prompts. Source: https://blog.searchmetrics.com/us/cheese-wine-and-whistles-m... reply geraldhh 1 hour agorootparentprevalmost as if the public appreciated the diversion reply runjake 11 hours agoparentprevReputation management companies do this. It’s normally referred to as “disinformation”. reply actualwitch 12 hours agoprevApparently it is also the same service that Mozilla Monitor uses, as per ToS. Big yikes. https://www.mozilla.org/en-US/about/legal/terms/subscription... reply apimade 10 hours agoparentIn my opinion, this is a failure of due diligence on behalf of the Mozilla Corporation. I'm sure their legal team is jumping into incident response mode right now. I think this is one of the problems of organisations not doing anything themselves, and offloading responsibility and liability to both external partners. If you trusted Mozilla Monitor with your personal data, their legal contact information is listed on their terms page: https://www.mozilla.org/en-US/about/legal/terms/subscription... The same terms page you agreed to which both limited their liability to $500, and granted them indemnification from liability. reply WhatsName 11 hours agoparentprevThat is probably the bigger story right here. Not trusting scammy businesses is easy. Getting fooled by big name like Mozilla a different story. reply actualwitch 11 hours agorootparentThey should have definitely done a more thorough due diligence before partnering with them. reply LoganDark 9 hours agorootparentprevMozilla has never been trustworthy. The Mozilla Foundation is probably what most people are confusing it for, the nonprofit that actually cares, but Mozilla the corporation just wants money. reply mozempthrowaway 7 hours agorootparentYou’re partly right. MoCo only cares about money. MoFo though is/was Mitchell’s political slush fund. TBD how things will shake out once there is a permanent CEO but Mitchell is remaining chair of the foundation. She’s also got really deep ties to how MoCo is funded (google) so it’s likely the new CEO will be her puppet. reply Dalewyn 11 hours agoparentprevConsidering how much Firefox phones home, I daresay Microsoft and Google are more private than Mozilla because they're at least god damn honest about their practices. reply LegibleCrimson 11 hours agorootparentI don't understand the logic. They're more private for admitting that they don't respect your privacy? reply Dalewyn 11 hours agorootparentMicrosoft and Google don't even try to hide the fact they will siphon your data, whether you like it or not. You can turn off some of the egregious siphoning, but that's about it. Mozilla meanwhile claims to be the champion of digital privacy, marketing Firefox as the private browser of choice along with a host of ostensibly privacy products such as VPN, all the while also siphoning data. Turning it all off requires digging deep into about:config. One group is honest (or at least relatively more so) about what they do. The other entity is a pathological liar led by a queen on Google's leash for controlled opposition purposes. As such, I daresay Microsoft and Google are more private than Mozilla because you know what you sign up for. reply LegibleCrimson 6 hours agorootparentI don't think that's what the word \"private\" means. It's not the same thing as \"honest\". Compare the data. Mozilla may be less honest than Google and Microsoft (a premise I also disagree with), but they are demonstrably harvesting much less data. reply st3fan 1 hour agorootparentprev\"siphoning data\" is a pretty bold claim. you can't just type those words without being very specific. reply rrix2 8 hours agorootparentprev> The other entity is a pathological liar led by a queen on Google's leash for controlled opposition purposes Oh come on, Baker was around since the Netscape days. You just don't like her cause she was a Suit, and that's fine. But except for a bunch of engineers Netscape had a bunch of Suits. It's not some conspiracy that a Suit is still running things. reply actualwitch 11 hours agorootparentprev> Microsoft and Google are more private than Mozilla Having used an app firewall, I have determined this to be false. reply charcircuit 10 hours agorootparentprevThe amount of \"phoning home\" is not correlated to how bad an app is for the user's privacy. reply lagrange77 11 hours agorootparentprevGod damn honest is maybe slightly exaggerated. reply srvmshr 6 hours agoprevAsking as a complete amateur, how do these people databases & privacy companies work? They claim to get personal details, family connections, social media content and even court records etc for not-so-exhorbitant price ($30 per report as ballpark?) Do they just scam people by compiling whatever is available on search engines? In one or two cases, I have seen them at least giving the house address or family member details right. So there seems to be more at play. reply siva7 8 hours agoprevYou're fine if a search machine returns zero results about you. Never put your personal information out in the wild. This includes a linkedin profile. I haven't found a solution if you're a business owner but even then try to limit exposure as much as possible. reply nottorp 2 hours agoprevGood bussiness. He has a duty for profit to his shareholders yadda yadda yadda. Why even complain? reply anigbrowl 11 hours agoprevYou see this a lot these days (though I suppose it's just more visible now). Another example is people selling political t-shirts (many offensive or obnoxious) to both sides of a partisan divide. reply ummonk 11 hours agoparentI don’t think that’s bad unless the seller claims to be representing the causes they’re selling for. reply anigbrowl 9 hours agorootparentThey do via their advertising copy, which strongly implies it. The productization of opinion is a Bad Thing in my view, for the simple reason that it becomes profitable to stoke conflict and commercial entities are therefore incentivized to do so. reply DoodahMan 8 hours agoparentprevthat merch spam is so damn prevalent on Twitter right now! with hyperpartisanship and emotions so high i often wonder what the profits are like.. reply greggsy 11 hours agoparentprevElvis’ manager did this with ‘I hate elvis badges’. It’s not quite comparable though - this is deliberately deceiving a market into acquiring a service they didn’t need, which is basically racketeering. reply lotsofpulp 11 hours agoparentprevIn the US, I feel like I only see one side buying merchandise. Especially offensive and obnoxious merchandise. reply akira2501 10 hours agorootparentA few seconds worth of work reveals how false this is. Perhaps it's just that you find one type of merchandise offensive but find the other type pleasant. Perhaps this open bias is coloring your perceptions? reply lotsofpulp 10 hours agorootparentI’m mid 30s, and I don’t recall anytime other than the last 7 years in which I saw people wearing stuff that came anywhere close to “Fuck ”. Or chanting it at random non political sporting events with families with children in attendance. And I don’t see the other party doing anything equivalent, from giant flags on pickup trucks, to roadside merchandise stalls, to pick up truck convoys that harass and bully other candidates on the road… reply vkou 4 hours agorootparentDon't forget people modding their trucks to roll coal. I guess the liberal equivalent is driving a Prius or something. Both sides, right..? reply EdwardDiego 5 hours agorootparentprevYeah nah, that's some sweet Dark Brandon merch out there. Guarantee someone's already selling some Jacked Up Joe merch already. There's always someone selling merch though, a few years back a rather famous/infamous politician in NZ, Winston Peters, came out of left field to win a by-election in the electorate of Northland that the ruling National party government expected to win easy, the same party that had snubbed his offers to work together. So people started selling \"King in the North\" t-shirts with ol Winnie photoshopped onto Jon Snow. I, being honest, nearly bought one, because you had to admire his schtick. So yeah, there's always merch. But, AFAIK, at least no-one is selling Joe Biden fan art NFTs yet. It's like a double grift. And obviously Trump loves the merch far more because he gets a cut. reply hn_throwaway_99 11 hours agoprevSell the disease, and then sell the cure. Capitalism at its finest! reply jval43 10 hours agoparentrent the cure. FTFY. reply geraldhh 1 hour agorootparentbig pharma entered the chat reply dheera 3 hours agoprevWorth a mention here -- there's a YC company that submits opt-out requests and seems much less shady than Onerep to me: https://www.optery.com/ (I'm just a user, not associated with them.) reply szundi 10 hours agoprevGenius. Makes the reason of the demand for his company! reply DANmode 12 hours agoprevNow do DuckDuckGo! reply rexreed 11 hours agoparentTell me more reply DANmode 9 hours agorootparentGabriel Weinberg, DDG's solo-founder, previously co-founded NamesDatabase, acquired in 2006. reply wly_cdgr 11 hours agoprevTakes one to know one! reply mozempthrowaway 8 hours agoprevGentle reminder that Mozilla Monitor is just OneRep, albeit marked up for Mozilla Corporation’s profits (yes Mozilla is a for profit, its foundation is not). reply ufocia 3 hours agoparentNon-profit doesn't mean no profit. reply st3fan 1 hour agorootparentIt is nuanced and not really well explained with a hot-take. How about https://crscpa.com/blog/how-much-profit-can-a-nonprofit-make... reply samstave 11 hours agoprevSo on a serious note, we were discussing this in another thread about: https://news.ycombinator.com/item?id=39698546 and using that to automate the unsub from trackers: --> This really needs to be used to make a tool to automate all the \"delete my data\" requests and have users map out deleting their data/PII etc from data brokers to a git something and people can submit the recipes to delete your personal data. I just did so on one of the more terrible ones yesterday - and the dark pattern was it would put you in captcha-loops... and youd have to reload/retry several times before stopped asking you firehydrant bus traffic motorcycle crosswalk over and over. but to save unsub/delete me scripts with this would be nifty. A recipe bounty would be neat - for example - Optery found me in more PII dbs than I expected - and it would be cool for people to see which brokers they are found in and there is a bounty list for all the brokers people are finding for someone to create a Delete-Me for each thing, so that one hopefully has the help of many to navigate the minefield of dark patterns in such. reply akira2501 10 hours agoparentYour data is sitting in an unencrypted excel spreadsheet somewhere as it moves between entities. Good luck. Your best bet is what the government minister mentioned elsewhere in this thread did. Generate noise. So much noise that none of your \"PII\" is even remotely accurate. You can't hide, but you can paint an incredibly inaccurate picture. reply imiric 9 hours agorootparent> You can't hide, but you can paint an incredibly inaccurate picture. How do you reasonably do this? You would have to spend an incredible amount of effort creating fake data everywhere, without having any clue if what you're doing is even working. With new AI tools and technologies it's likely that someone with enough resources and motivation would be able to filter out the signal from the noise anyway. I currently lean towards just minimizing my digital footprint, and carefully choosing the hardware and software I use. It still takes a lot of effort and sacrifice, and I don't expect this method to be foolproof, but at least it's reasonably manageable. At some point you do have to accept that absolute privacy is impossible in the modern world, even if you shun all technology. reply NSMutableSet 5 hours agorootparent>How do you reasonably do this? You would have to spend an incredible amount of effort creating fake data everywhere, without having any clue if what you're doing is even working. With new AI tools and technologies You answered your own question. reply imiric 4 hours agorootparentNot really. AI wasn't an option until very recently. How was this managed before? And even with AI, it would take a considerable amount of effort to flood all public channels with fake data. Do you do this via APIs for every service? Do you generate image and video as well? You would still have no idea whether your efforts are actually working. Not to mention that using this approach contributes noise to an already noisy medium. Your fight with an imaginary enemy worsens the online experience for everyone else. We have enough junk on the internet as it is. reply frankhhhhhhhhh 6 hours agoprevDirtbag. reply alexnewman 12 hours agoprevsigh, i never trusted these sites and it never achieved anything for me. reply ghaff 11 hours agoparentOne redeeming thing about the monetization of the Internet is that these deep web people search sites are generally not free any longer. There was a time when, for free, you could basically search a person who didn't have an especially common name with maybe a couple for tidbits about them and could you find a huge part of their life history and, of course, info like birthdays. reply j-bos 11 hours agoprev [–] Indusrty connections aside, it's not a good look that thaf the CEO of a privacy company did not register domains with some form of Whois privacy. reply SkyPuncher 11 hours agoparentWhy? I don’t understand this at all? It’s largely unnecessary for corporate owned domains. You know who owns it from the website they publish. reply altairprime 11 hours agoparentprev [–] Some TLDs prohibit Whois privacy altogether; this stance isn't maintainable globally. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Onerep.com, a data privacy company, is under scrutiny for operating from Belarus and Cyprus, with its founder launching multiple people-search services.",
      "Despite denying any connection, Onerep has suspected ties with the people-search site Nuwber.com, raising ethical concerns about selling personal data while charging to remove it.",
      "Founder Dimitri Shelest, known for past aggressive email marketing and spam affiliate programs, contradicts the company's commitment to online security, prompting investigations by KrebsOnSecurity into data brokers and people-search providers."
    ],
    "commentSummary": [
      "The conversation covers data privacy, reputation management, and the ethics of political merchandise sales, addressing challenges in removing personal information online and the role of data privacy companies.",
      "Topics include the use of AI technologies, the influence of tech giants on privacy, and debates on the effectiveness of 'delete me' services and ethical implications of data collection practices.",
      "It emphasizes the complexities of online privacy maintenance and advocates for tighter regulations in the digital realm."
    ],
    "points": 438,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1710451053
  },
  {
    "id": 39706330,
    "title": "Why Modern Sofas Fall Short: The Rise of Disposable Furniture Culture",
    "originLink": "https://www.dwell.com/article/dtc-sofa-crisis-32304b9e",
    "originBody": "Home Tours Dwell Exclusives Before & After Budget Breakdown Renovations Prefab Video Tours Travel Real Estate Vacation Rentals Photos Editor’s Picks Bathrooms Kitchens Staircases Outdoor Projects Editor’s Picks Modern Midcentury Industrial Farmhouses Scandinavian Find a Pro Sourcebook Post a Project Collections Editor’s Picks Shopping Recently Saved Planning Shop Shopping Guides Furniture Lighting & Fans Decor & More Kitchen & Dining Bath & Bed Guides ADUs Furnishings & Finishes Gardening & Plants Kitchen & Bath Mortgages & Budgets Prefab Pros & Project Management Sustainability Tech & Automation Magazine Current Issue All Issues SubscribeSign In View 4 Photos Why Are (Most) Sofas So Bad? The most important piece of furniture in your home is in need of assistance. How did we end up here? And how can we fix it? Text by Dan Nosowitz View 4 Photos \"Don’t even bother,\" the upholsterer told me. I was on the phone, asking for a theoretical quote to reupholster a five-year-old or so midrange sofa, which cost more than $1,000 when new. That task, the upholsterer told me, would run me several times more than the couch was originally worth, and, owing to its construction, it was now worth nowhere near its sale price. The upholsterer proceeded to lecture me, in a helpful, passionate, and sometimes kindly manner, about how sofas made in the past 15 years or so are absolute garbage, constructed of sawdust compressed and bonded with cheap glue, simple brackets in place of proper joinery, substandard spring design, flimsy foam, and a lot of staples. Until recently, people had no reason to suspect that a $1,200 sofa would be anything less than high quality; the vast majority of the stuff in stores was fairly well made, and you could sit on it to test it. Today, not so much. Instead of going to a furniture or department store, says Sami Reiss, a journalist and Dwell contributor who operates Snake, a newsletter about furniture design, modern consumers \"are buying a couch online that looks four times as good, costs two times the price, and is made twenty times more poorly.\" A combination of factors, including world-altering shifts in labor, manufacturing, transportation logistics, and middle-class American aesthetics, has created a grim scene: a two-year-old, $1,200 Instagram sofa—busted, on the curb, waiting for the large-item trash pickup or an enterprising scavenger who doesn’t realize just how shitty this thing is. Forget fast fashion and spend your time hunting for vintage classics. Traditionally, North Carolina is the seat of the American furniture industry. Marcus Houston, the senior vice president of client growth and development at shipping strategist Transportation Insight, is based in the western part of the state. This region includes the city of High Point, which calls itself the furniture capital of the world. High Point and surrounding towns are a hub for construction, assembly, and even sales, and the area is home to High Point Market and Furnitureland South, the world’s largest furniture store. \"I’ve seen a lot of change over the last fifteen years as it relates to the specific furniture vertical. All the suppliers to the industry have been here for a hundred years,\" says Houston. Today, the industry has spread out across multiple continents, with more products, and more philosophies, than ever before. Instead of a retail business with domestic construction and shipping performed by specialists, we’ve got drop shipping in containers from Southeast Asia, venture capital funding for Instagram photography, and, perhaps most distressingly, some really poorly made sofas. There are absolutely sturdy, beautifully made sofas constructed in the United States. There are custom designer pieces made here or in France or Italy or Scandinavia, which tend to be prohibitively expensive for the masses. But low- and mid-priced sofas are a relatively new phenomenon, and, frankly, they often suck. A middle-class family that wanted to buy a new couch in the 1980s, for example, might have gone to a department store or a local furniture store or traveled to one of the gigantic furniture markets scattered across the country for a product that would have been designed in-house and made domestically out of good leather, dense foam, and American solid wood: oak, maple, poplar, pine. Then, importantly, it would have been wrapped up and shipped via a specialist. \"Fifteen years ago, you had to ship that on a furniture carrier, because when they finished the sofa, at a facility in Mississippi or North Carolina or something like that, they only trusted a furniture carrier to know how to blanket-wrap it, set it on there, and then they’re gonna move it throughout the country that way,\" says Houston. This was a slow, expensive, and delicate operation, requiring skilled labor and purpose-built materials. The big change in shipping logistics came when furniture manufacturers developed new ways of deconstructing and flat-packing their product, allowing sofas to be shipped via regular carriers, both more cheaply and more quickly. This innovation opened up new avenues for penny-pinching. Favorable tax situations, cheap labor, and a surging wood and wood-type-product industry in Asia made it suddenly very inexpensive to construct furniture there, and those new shipping tactics made transportation feasible. They don't make them like they used to. Starting in the late 1990s, according to the Bureau of Labor Statistics, the number of Americans in the furniture-manufacturing industry plummeted, from nearly 700,000 in the year 2000 to below 500,000 just before the economic crash in 2008. After that, things only got worse: Today, they’re down at around 350,000—half the industry gone in two decades. Really great furniture is still out there, but labor is more expensive and harder to find, as are some of the raw materials. To fill its place is stuff that costs what a good sofa used to cost—but without the good part. Designs changed to accommodate the new location, new costs, and new workers. Wood was replaced with compressed wood, a wood-adjacent product made from sawdust, wood chips, and scrap and glued into the shape of a board, kind of like a McRib. Manufacturers realized they could cut all kinds of corners, from materials to process. One of those is a technique called \"eight-way hand-tying,\" a method of attaching individual seating coils together and to the frame of a sofa for support, usually using twine. (The eight ways: front to back, side to side, and diagonally in each direction.) It’s a time-consuming process that requires training, but serious furniture folks love it: It allows for only the springs you sit on to mold around your body, without altering the position of the rest of the suspension—like a hammock, Houston says. In place of traditional joinery, backs and arms are attached to bases with brackets, which the consumer can assemble at home. The results of these changes are tangible: a lighter, flimsier sofa with maybe some wobble in the arms and legs, too stiff to sit on or lacking in support. This development created Wayfair-type sofas at absurdly cheap prices, a category that didn’t really exist before. It also forced the middle-tier manufacturers to start cutting corners as well, since their labor pool was shrinking and becoming more expensive. But it did not lead to a cheaper price for these middle-tier products. Today’s $1,000 sofa is not in the same league of construction as a $299 Sears sofa (about $1,100 today) from 1980. That thing was made of actual wood. So where are these profits going? Not to the low-cost labor in Vietnam. Not toward the materials or the shipping. \"If you’ve figured out a good way to market and target the consumer and you become that marketing machine, that’s where the margin’s at,\" says Houston. \"I’ve seen the P&L [parts and labor costs] and I saw what they paid us [in shipping], and then you see what it’s sold for, and it’s like, wow.\" Secondhand steals are still out there, and this Artifort classic from the 1990s is due for a comeback. Sofas are very much not immune from the direct-to-consumer bonanza, and those brands make a compelling pitch. Why bother with an outdated, 20th-century concept like a brick-and-mortar store when you can cut out much of that overhead by moving to a direct-to-consumer (DTC) model? DTC gives an illusion of control: You can customize every part rather than rely on what’s on hand at a local store. Of course, you’re also giving up the ultimate control: actually sitting on the sofa. These brands have been extremely aggressive and successful in their marketing, especially on social media, and in polishing the purchasing process to a fine sheen. A major reason for that success is that the design language for mass-market furniture these days is weirdly narrow. Simply put, the midcentury-modern aesthetic dominates all other styles. \"The groundswell began around thirty years ago, and my theory is that, for lack of knowledge about other movements, and because so much of the midmodern stuff is American and therefore there’s more of it in the wild, it hasn’t really been overtaken,\" says Reiss. \"It’s almost like these are the [Levi’s] 501 of furniture.\" The neutral or muted colors, unadorned wooden legs, and simple shapes have become the baseline for sofas. These items, at least in well-lit, well-staged, and beautifully edited photographs, look great and expensive—which is exactly the point. The other advantage of the DTC model is that you’re relying on those photos, which works to the manufacturer’s benefit. While a 30-day return policy comes standard with most DTC companies, that’s still a fair amount of work: You have to initiate the return, schedule a pickup, and go through the shopping and shipping procedure again for a new sofa. It’s understandable when people end up just dealing with something that they aren’t thrilled with. When you ship something via these common carriers, typically a manufacturer purchases space in a container, which then has to be filled to maximize profits. That leads to a sort of Taco Bell–style design: a lot of the same ingredients, just moved around. Take the tufted seat back from this sofa and put it on this one. Use the same wooden legs on 30 different sofas. Use the same brackets, the same compressed-wood platform. Midcentury modern is perfect for this: There aren’t very many details in the first place, so you can make what looks like a robust product line with very few variations. The politics of the midcentury-modern movement are well documented, especially its ties to postwar welfare states in Europe, affordable design for the masses, and warm and homey use of fabrics and woods. A sofa that looks just like those references but is designed by a company that exists only on Instagram, made cheaply and badly, and shipped around the world in order to satisfy the bottomless maws of investors in \"the Netflix of couches\" or whatever, that’s a change. Midcentury design was still a product to be made and sold in a capitalist system, but it wasn’t the grimmest possible expression of that system, the way contemporary sofas can be. \"This is kind of the way it goes with all products,\" says Reiss. \"They become more efficient, but it’s just about cutting costs. The incentives to have a great $2,000 couch—I mean, who’s going to fight for that?\" This has also led to a resurgence of interest in vintage sofas, something Reiss knows well. \"I’m a vintage proponent, and it’s just out of my practical consumer experience,\" he says. My own shopping experience mirrored his. I hated every sofa that was being blasted into my eyeballs through social media, so I spent weeks, literally, on Craigslist and Facebook Marketplace and Kaiyo and OfferUp, waiting for that perfect one. It came after six weeks of effort and required a mover with a pickup truck, a lot of research into how to wash 50-year-old wool cushion covers, and a new roll of foam to replace the cushions. I’m really happy with it, but it’s not realistic to expect everyone to have access to a big city’s selection of used sofas, nor would I want anybody else to have the specific kind of brain damage I have that encourages that kind of research and commitment. \"I have people who come in all the time who have bought a sofa, and it looks great online. Then it shows up and doesn’t necessarily look as good in person. And then when they sit on it, it doesn’t feel as nice as they had expected,\" says Steve Heiss, the manager of Sunbeam Vintage, a warehouse-y shop in Los Angeles that sells classic sofas (sometimes reupholstered in-house) as well as some new designer items. \"I think that when it comes to quality—I hate to say it—but I don’t know that people really notice,\" he adds. \"The buyers are not that educated.\" But education often comes only with time. And when the alternative is to just click something on your phone and have it show up in three to five days, it’s hard to blame anyone for making the easy choice. Even if it kind of stinks. — Top illustration by Matheus Castro. Photos courtesy Carl Hansen & Søn; Comstock/Getty Images; courtesy Chairish Head back to the March/April 2024 issue homepage Published March 12, 2024 Last Updated March 14, 2024 Topics LifestyleShopping Guides Save Responses Get the Dwell Newsletter Be the first to see our latest home tours, design news, and more. Subscribe The Dwell House Is a Modern Prefab ADU Delivered to Your Backyard Learn More About About Contact Us FAQ Editorial Standards Careers Advertise Media Kit Subscriptions Subscribe to Dwell Gift Dwell Magazine Dwell+ Subscription Help Magazine Subscription Help Dwell Wine Club Professionals Post a Project Sell Your Products Contribute to Dwell Promote Your Work Follow @dwellmagazine on Instagram @dwellmagazine on Pinterest @dwell on Facebook @dwell on Twitter @dwell on Flipboard Dwell RSS © 2024 Recurrent Ventures Inc. All rights reserved. Privacy Terms DMCA Sitemap",
    "commentLink": "https://news.ycombinator.com/item?id=39706330",
    "commentBody": "Why are most sofas so bad? (dwell.com)423 points by jtsnow 16 hours agohidepastfavorite430 comments btbuildem 11 hours agoTwenty some years ago I used to work at a business that made and delivered sofas. They've got showrooms in key large cities in North America, fancy schmancy top end stuff. The factory was a real place; the frames were made of solid wood and plywood, there was a sewing floor and even one (incredibly kooky) person whose sole job was to stuff the pillows. This guy was in a little room full of feathers all day, and they'd follow him around to the cantina and bathroom like a cartoon character.. but I digress. My job there for a while was to make the sofa legs -- that was a sixteen step process, and they didn't even trust me to glue the boards together, just to do the cuts and shape the pieces. Sand and stain and wax and polish, yes sir! They had a dedicated delivery crew, and what the article mentions about packaging is true -- things would be blanketed and wrapped up just the right way, then tetris-ed onto the truck. Sitting shotgun on that truck and hauling sofas up stairs and through various spaces was what I did after making the legs got too boring. These sofas sold for $3000 ~ $4000 and up, and that was at the break of the millennium. I think the cheapest chair they had was around $2000. I should really swing by the showroom and see how much these are now -- and whether they're still made like they used to be. reply hammock 10 hours agoparentYou can still get made in the USA sofas with real hardwood, not rubber wood, which is fine, or worse, soft pine or particleboard or OSB) North Carolina was and is the center of solid wood furniture), and they still cost several to many thousands of dollars, and they will still last 100+ years with a couple reupholsterings or so, but most furniture comes from Asia now and is sold for 10x less, and is not worth reupholstering, and you will be lucky if it lasts 10 years. The was a great company an old colleague of mine started called Interior Define that sourced custom furniture from China for a BluDot price but much higher quality, but they did not survive the pandemic and have since been sold in bankruptcy to a company that has reduced the quality to par reply linsomniac 6 hours agorootparent>or worse, soft pine or particleboard or OSB Having done a lot of DIY projects over the last decade, I've really shifted my view of OSB. Originally I would lump it in with particleboard, but I've since drastically changed my view of it. Particleboard is, truly, junk. OSB and plywood are both pretty good products, and for some uses superior to hardwoods (dimensional stability, for example). High quality plywoods are amazing products. OSB for structure or underlayments are really quite good. reply Wohlf 5 hours agorootparentParticleboard is absolutely useless, MDF is mostly useless except using as a guaranteed flat surface on top of something to support it, hardboard is pretty useful in certain applications though. OSB is great and extremely affordable as sheathing, and there's a massive variety of plywood that's great for their respective purposes - from cheap rough sheathing, mid-grade for shop projects and filling large gaps in furniture, all the way up to beautiful and supremely strong Baltic birch. reply teleforce 5 hours agorootparentAvoid particleboard like a plague if you can afford it, appparently most of IKEA products now made of these since they are widely being used in dirt cheap furniture construction. They melt like ice once in contact with water. Recently, just had to chopped off all four legs of a bookshelf then replaced them with metal legs. The bookshelf legs somehow got damaged in contact with accumulated air-cond water droplets. reply Symbiote 1 hour agorootparentIkea has two or three price points for each product. The cheapest will be made from chipboard or even cardboard. The most expensive varies, it might be pine or even something better. reply alexey-salmin 3 hours agorootparentprevOSB is durable but you still need to be wary of formaldehyde in your home reply doublesocket 1 hour agorootparentThere's a good choice in formaldehyde free boards these days. In the UK a popular one is Sterling Zero. reply cherrycherry98 8 hours agorootparentprevBought our sectional from a Bassett showroom almost 10 years ago. Extremely comfortable and the thing still looks brand new. Checked a few items on their website and found that they're still made in North Carolina. reply ecliptik 5 hours agorootparentWe have a Bassett sectional going on almost 10 years too. Family friend'd mom worked for/with Bassett and got us a B2B price somehow - only caveat was I had to pick it up myself at the distribution warehouse in LA. It's a fun memory renting a box truck, driving to the industrial heart of LA while listening to Will Wheaton narrate \"Masters of Doom\" to pick it up. reply sarchertech 6 hours agorootparentprevWe bought 2 Stickley sofas made in North Carolina. They cost close to $10k a piece. You can still get quality, you just have to pay for it. reply nostromo 10 hours agorootparentprevRoom and Board sells great sofas that are made in the US. We've been very happy with ours. It's made from solid wood and stuffed with real feather down. It's several years old now and has shown no signs of aging. reply caseyohara 8 hours agorootparentRoom and Board makes very good furniture. When my wife and I moved into our new home a few years ago, we decided to invest in high quality furniture that would last decades. Originally we ordered a sofa from Interior Define that never arrived. Something wonky was going on with that company, many people never received their orders and they wouldn’t issue a refund. Thankfully we were still within the window to do a chargeback. We have a sofa, coffee table, bed, nightstands, and some wall sconces from Room and Board. I am very impressed with the materials and build quality; I can tell everything will wear well and age nicely. Worth the investment, highly recommended. reply bradgessler 10 hours agorootparentprevI recently cut open a heavily used R&B sofa and found 1” thick plywood used through the frame. It was solid. The down feather pillows didn’t do well—lots of feathers made their way out of the pillow. reply jasondigitized 9 hours agorootparentprevAgreed. We researched a ton of sofas and landed on Room and Board. Super happy so far. reply ipqk 8 hours agorootparentprevI just wish their designs weren’t so staid. reply emodendroket 3 hours agorootparentprev> You can still get made in the USA sofas with real hardwood, not rubber wood, which is fine, or worse, soft pine or particleboard or OSB) Where? I went around furniture stores and found it hard to discern any relationship between price and quality. reply jseliger 7 hours agorootparentprevThe was a great company an old colleague of mine started called Interior Define My wife and I have one of their sofas—it's quite nice, although our lives might've been easier with one of the Burrow-style sofas that are easily disassembled for moves. reply lotsofpulp 4 hours agorootparentprev>and you will be lucky if it lasts 10 years. I have at least 20 various pieces of furniture from IKEA that have lasted more than 10 years, some even closing on 20, even after multiple moves to various college dorms. Dresser drawers, dining table, sofa, bed platform, sit stand desk, etc. I do not think I have ever thrown something out for breaking. Maybe gets scuffed or scratched up or chipped, but you can mostly use one of those latex paint touch up markers and make the damage nearly invisible. reply salad-tycoon 54 minutes agorootparentI agree with the comments below but would like to add that the IKEA of 10-20 years ago is not the IKEA of today. Many of their product lines have been made “more eco friendly” per their argument but in reality are cost saving measures. E.g wood countertops are veneer now and other things that you could buy as solid wood are veneer. You got in when the going was good. I think you can still buy decent enough stuff but having moved a few times myself and then friends and family a lot of the newer stuff is one time use, don’t pick it up, don’t look at it cross eyed, kinda stuff and it shows. reply thesaintlives 38 minutes agorootparentMore agreement! Ikea 20 years was twice the material you get today. Products could be taken apart and put back together multiple times. Not so today. Put together once, modify it if you want it to stay like that and if you really have to move it cross your fingers! reply cdchn 3 hours agorootparentprevIKEA products seem to vary wildly between \"partical board disposable\" to \"made from actual wood and somewhat decent.\" reply Doxin 2 hours agorootparentIKEA sells many products in a couple tiers. E.g. if you get the cheapest billy bookcase it'll just about barely hold up if it's full of books and you don't nudge it. If you get one of the more expensive models it'll be surprisingly sturdy instead. Same sort of thing applies to nearly all their products. Yes they sell cheap crap -- that still serves its purpose mind you -- but they also sell slightly more upscale furniture that'll actually survive a couple decades. And it's not like going for a \"normal\" furniture store is any guarantee either. My previous couch was from a regular furniture store and it broke right in half at around the 5 year mark. Upon inspection one of the cross members was significantly tapered, still had bark on it and everything. On one end it was a solid 2x4, on the other it was barely a 0.2x0.4. reply Hamuko 1 hour agorootparentAnd even the cheapest crap you can get from IKEA doesn't seem that bad to me. I've had one of those 5-euro LACK coffee tables for around six years and it really only has some minor surface damage on the top. Far away from throwing out. Although at the same time, I think I'm on my third MARKUS chair because of the gas spring leaking. Thankfully they do have long warranties, so you can exchange them if it doesn't last for 10 years. reply planede 8 minutes agorootparentFYI you don't necessarily have to throw away an otherwise good office chair if the gas spring is leaking. You can replace just the gas spring. boringuser2 10 hours agorootparentprevA lot of meh furniture that uses steel will last, too. reply m463 6 hours agoparentprevI think the problem I've noticed is - the furniture that is built to last very frequently fails the partner test - \"that looks like old fart stuff\". Same sort of issue with cool remote controls. For example, la-z-boy has pretty good controls - remotes have better designs, have lots of adjustments, and motors seem to move faster. And they too fail the partner test - \"that looks like old fart stuff\" I kind of like some stressless recliners. oh, there is one class of furniture that has a lot of control - the massage chairs. Except they seem to be furniture you want to hide from everyone, they fail the \"normal human being\" test. maybe I need to know pointers to other furniture/designs? reply OscarTheGrinch 50 minutes agorootparentEven Ikea has a \"granny shit\" sofa selection. reply namaria 2 hours agorootparentprevPartner sounds like a fashion victim. If social media consumption is making one's taste fond of low quality flashy crap I'd say grow some critical thinking skills. reply OscarTheGrinch 42 minutes agorootparentMany furniture stores have a section with old timey stuff, I guess targeted at the 60+ market: ruffles and pleats and doily type shit. You can't expect anyone younger than a mummy to be enthused about buying that stuff new, whether or not it is better quality, and it's probably all the same cheap crap under the ruffles. reply mynameisvlad 56 minutes agorootparentprevI mean… not really. Quality and style generally are pretty correlated, with higher quality pieces traditionally being more “old school”. And that was basically GP comment’s point. One can value form over function, especially if there’s a specific style that the rest of your house uses. If your entire house is decorated in a contemporary style, then a traditional sofa is just going to stand out like a sore thumb. reply rlonstein 8 hours agoparentprevWhen I was in grad school I accidentally wandered into the workshop for Montauk (https://montauksofa.com/collections/sofa/montauk/) with my girlfriend. They were very polite and I took their card. A few years later when I had some money, and my girlfriend was my wife, I still had the card and we bought one. More than twenty years since we still have it and it's just starting to get to where some of the cushions need the down stuffing refreshed. Quality. reply btbuildem 5 hours agorootparentHow did you accidentally wander into their workshop? That place was in a random industrial zone off the 20 somewhere near Point St Claire.. Also super spooky, how did you know I was talking about them? reply TylerE 4 hours agorootparentHe didn’t, you just accidentally doxed yourself. reply BenFranklin100 7 hours agorootparentprevGorgeous design. reply gexla 10 hours agoparentprevPlease give us an update on how stuffed pillow guy is doing these days. reply theendisney 6 hours agorootparentIt was some how relevant. I had a similar job making sofas in similar price range. We also had a crazy person stuffing everything. I asked why his job was not in the normal task roulation. They said for that job you have to be insanely strong, have insane endurance and you have to be insane. The guy tried it one time. How hard could it be? After 3 hours he literally couldnt lift his arms. reply selcuka 10 hours agorootparentprevHe stopped cheating at poker, so they set him free. reply karim79 7 hours agoparentprev> things would be blanketed and wrapped up just the right way, then tetris-ed onto the truck. *tetris-ed and Sokoban-ed onto the truck (Sorry, couldn't help myself) reply al_borland 11 hours agoprevWhen I moved to an area for work I wasn’t planning to live long-term I ended up buying the cheapest sofa in the store. I think it was around $270. After a prolonged illness I grew more and more displeased with it, to the point that I went and bought a better one after I was better. I bought from a place that advertised the inside of the sofa more than the outside. It was all about the build quality and how long it would last. Ended up coming out to around $3k if I remember correctly, but it has a lifetime warranty on everything but the cushions, and even the cushions after 6-7 years of daily use are just now only starting to get to the point of feeling like they are beginning to break in. Quality can still be found, it just can’t be assumed. I think that’s the case for far too many things these days. reply scoofy 11 hours agoparentI've been wanting to buy nice furniture for a very long time... unfortunately the housing crisis has prevented my from ever having a sense of permanence. If I had known I'd live in my last place for nearly a decade I would have purchased nice things, but as it stands, until I have a mortgage of my own, I refuse to spend good money on something I may need to replace next year. reply neilv 8 hours agorootparentI'm glad I'm not the only one. The buying up of precious housing as investments by non-residents should mostly be banned, starting with institutional and overseas investors. AirBnb should also be banned. And the people who profited off that startup, who must've known they were creating illegal hotels and destroying rental markets, should be hit with devastating fines, maybe also imprisoned. reply maxerickson 7 hours agorootparentWe should just build lots of housing. reply BriggyDwiggs42 4 hours agorootparentLets do both :) reply gruez 3 hours agorootparentprev>The buying up of precious housing as investments by non-residents should mostly be banned, starting with institutional and overseas investors. What's the issue with them buying houses as investments, as long as they're being rented out? If that's the case, their net effect on the housing supply is zero. >maybe also imprisoned. I find it extremely disturbing that people are effectively demanding for bill of attainders for jail sentences for what are basically zoning violations. reply cdchn 3 hours agorootparent>What's the issue with them buying houses as investments, as long as they're being rented out? Because it prevents people from owning and now have to be permanent renters because of somebody's greedy rent seeking behavior. reply gruez 1 hour agorootparentSounds like the actual problem is that landlords can engage in \"greedy rent seeking behavior\" at all. Allowing people to opt out, but only if they can afford a 6 figure downpayment and keep 7 figure amounts of their wealth parked in a single non-productive asset that's highly correlated with their job prospects is an imperfect solution to say the least. Everyone deserve protections from \"greedy rent seeking behavior\", not just the people who are in a position to buy. reply Repulsion9513 1 hour agorootparentHow does that happen when all the houses are being purchased as investments to rent out (or not, as often happens)? reply Repulsion9513 1 hour agorootparentprevAl Capone got a jail sentence for not paying his taxes. There's no bill of attainder involved when you break a law that existed before you were even born. reply cdchn 3 hours agorootparentprevBe careful what you say here about businesses that try to \"disrupt an industry\" aka \"operate quasi-legally until someone tries to stop them.\" reply ghaff 11 hours agorootparentprevSofas, perhaps especially, are pretty hard to fit for non built-in furniture. I bought a used sofa off my brother. (Ironically, their replacements ended up being terrible because they lasted about a year with their dogs.) I was also very lucky though. I thought I could configure the sectional in a couple different ways. Turned out I rolled the dice the right way because I couldn't. And only discovered this after many months because I was on crutches at the time and couldn't do anything about the sofa sitting in my garage. reply dylan604 11 hours agoparentprevQuality ain't cheap, and cheap ain't quality. In furniture, you definitely get what you pay for...or not. I've found anythingQuality ain't cheap, and cheap ain't quality. The problem here is, that expensive doesn't mean quality. Buying a cheap ikea piece and replacing it in a few years might still be a better choice than overpaying for an expensive piece, that's the same quality as ikea, but with a different tag on it (both 'brand tag' and 'price tag'). reply Gigachad 9 hours agorootparentThe ikea stuff also seems to be perfectly fine. Almost my entire apartment I ikea stuff and I’m yet to have anything fail. With some of the oldest bits being the Malm draws which are about 15 years old now and still perfectly fine. Sure, if you move them around a lot or leave them in the sun they will degrade, but just using them as normal they seem to last way longer than you’d think. reply ascagnel_ 8 hours agorootparentIKEA is highly variable. I’m writing this while sitting on a leather loveseat that’s more than a decade old and holding up great. I also have a chest of drawers that, despite my best efforts during construction, immediately began to sag. Their expensive furniture is good mid-range stuff, the cheap stuff is cheap. reply OJFord 7 hours agorootparentYeah the cheap stuff is on par with up to 10x cheaper stuff on Amazon (you just have to deal with drop shipped branding and dodgy/no instructions), the more expensive stuff has better quality competitors IMO. Such as Dwell.co.uk, coincidentally, completely unrelated afaict to OP. They make veneer-grade non-flat-pack furniture (and upholstered stuff) at a mid-high Ikea price. Made similar I think, or any number (including local showrooms) of suppliers of either drop shipped or wholesale manufactured oak+paint-grade, it seems quite common/popular. I have a couple of items from cotswoldco.com for example that have absolutely matching (but differently named) pieces available from an unrelated local independent shop, that I might otherwise assume had a small manufacturing operation too. reply pbowyer 2 hours agorootparentDwell.co.uk is sadly now part of DFS, so whether the quality and range continues... reply doubled112 8 hours agorootparentprevAll my Ikea stuff has been perfectly fine as well. A photo fell off the wall and put a rather large hole in a Lack coffee table one time. We were pretty amazed that the photo frame won. It was a $25 table. I could buy many for the price of something nice. Having small kids around, and seeing how they play, learn to use a fork, etc, I feel like we made the right choice buying cheaper. Plus what kid doesn't want to play at the table mom and dad let them sticker bomb? reply zeroonetwothree 5 hours agorootparentI still have the Lack end table I bought for $7 20 years ago. reply doubled112 4 hours agorootparentAt some point between then and now they changed how they made them. They have more empty space inside now. reply throwaway2037 2 hours agorootparentprevI have seen people using these on YouTube as a server rack substitute. They are still frighteningly cheap after 20 years. reply VHRanger 8 hours agorootparentprevThe problem with Ikea is once you have to move them around. Or if you have kids/dogs jumping up and down the sofa, etc. The particleboard connections aren't very sturdy. reply ajsnigrutin 7 hours agorootparentWell sure, but in many cases, you can go to a \"proper\" furniture store, buy a piece that is a couple of times more expensive than the one from ikea, and get the same particle board and same shitty connections... especially with stuff where the wood is hidden (eg. sofas). Also the assembly for ikea stuff is usually perfect.. everything aligns to the last millimeter... which again, I can't say for much more expensive furniture pieces. reply gruez 3 hours agorootparent>Also the assembly for ikea stuff is usually perfect.. everything aligns to the last millimeter... which again, I can't say for much more expensive furniture pieces. Probably because the ikea stuff you bought tend to be particleboard and the \"expensive furniture pieces\" are solid wood. Solid wood tend to wrap/deform more due to moisture than particleboard, which means even if they're drilled with millimeter precision at the factory they end up not aligning when it reaches your house. From personal experience the solid wood furniture I got ikea were definitely not aligned \"to the last millimeter\". reply VHRanger 7 hours agorootparentprevAgreed, there's a big gap between Ikea and the next step up. And most people can't differentiate between quality (nor should we expect them to!). \"Proper\" furniture stores you find in malls and outlets are generally high margin crap. There's lots of soft scams out there. There's a reason many people go back towards antiques and similar. reply throwaway2037 2 hours agorootparentI feel like beds are in the same category. There is a sea of choice, but very hard to distinguish which is actually higher quality... or if the price difference has tangible benefits (better sleep, etc.). reply giantrobot 7 hours agorootparentprevIKEA stuff is also relatively easy to \"harden\" with some extra strategically placed metal brackets from Home Depot. For instance you can make a particle board bookshelf very sturdy by screwing some L-brackets on the back corners. Corner braces screwed under the shelves will likewise keep them from bowing under the weight of books. It's a few extra dollars and will make the pieces survive a move and just generally feel sturdier. It's not a replacement for \"good\" furniture but will make the cheap stuff much better. reply throwaway14356 4 hours agorootparentyeah, add lots of glue and metal L profiles or some nice decorative wood. Good glue alone makes a better attachment than the screws and nails but you do have to glue it before it gets wobbly reply Hamuko 1 hour agorootparentprevWhen I was shopping for a TV console, I went to a \"proper\" furniture shop and checked out console in the 150 to 200 euro range. Zero consideration for cable management and doors slammed hard when you closed them. Then I went to IKEA and bought a BESTÅ system that totalled like 130€ or something. Soft-closing doors, cable management holes and the lot. Was very happy with my BESTÅ after seeing what other stores had in a similar price range. reply ornornor 4 hours agorootparentprev> the assembly for ikea stuff is usually perfect.. everything aligns to the last millimeter... What? How? I’ve moved a lot in the last 15 years and always defaulting to ikea for convenience. “Fits together well” isn’t what I’d use to describe their furniture. reply graemep 24 minutes agorootparentprevThis is part of the enshittification of everything. Not long ago you could be a good brand an rely on it being good. Now most of them are just charging for the brand and not providing higher quality. I am in the UK, I have also inherited Sri Lankan furniture from my parents and grandparents and I have lived there as well. The decline in quality is the same in both those countries. I guess it is global. reply resolutebat 11 hours agorootparentprevUnfortunately the premise of the article is that you can now easily drop $1k+ on a sofa that looks good on Instagram, but is constructed of particleboard and falls apart when you look at it sideways. reply bombcar 11 hours agorootparentYou can drop way more than $1k and be stuck with something that's really kind of crappy. You have to know enough to know who is actually building the good stuff, and who is building good-looking marketing. reply dylan604 10 hours agorootparentI have bought things online and been burned by the not know the who part. I'm now to the point that if it is anything I will be spending a lot of time on, I'm not buying it unless I can see it in person. One vendor's medium firmness might be another's firm. Other furniture is less critical to me, so I haven't put the in-person only rule for that stuff reply al_borland 10 hours agorootparentIn-person seems like it should be a hard requirement for anything a person will sit on. There is no way to tell anything just by looking at a picture. The sofa I got had one in-store that was cut in half at all levels, so the construction and materials could all be seen. Any company doing that is probably going to be pretty solid, and if not, it should be obvious. reply dylan604 10 hours agorootparent> In-person seems like it should be a hard requirement should but yet online sales of furniture is not a small market reply ghaff 10 hours agorootparentA lot of people these days are into the mode of order online. Certainly there are a ton of podcasts that offer deals on some of the online furniture companies. I don't think I'd personally do it but then my parents probably wouldn't have ordered a lot of stuff online that I do. (But furniture and big electronics appliances are arguably much more of a hassle to return than other things.) reply bombcar 8 hours agorootparentI’m actually much happier ordering appliances online vs furniture- because appliances I can evaluate in multiple ways that don’t need me to sit on it. Unfortunately some very comfortable furniture turns out to not be long lasting, as I discovered, even when moderately pricey. Steel frame sofas can bend and break under repeated use because the steel is so thin - if you can bend it by hand, it will fail eventually. reply ghaff 8 hours agorootparentWell, yeah, appliances. Even if I order one at my local Lowe's, as I just did, it's not like I'm going to run a bunch of controlled dishwashing tests with it. Durability of furniture is harder to measure even if you try it out. reply dylan604 10 hours agorootparentprevYMMV also includes adjusting for today's $. My $300 is today's $1k. So it still stands reply bradleyjg 10 hours agorootparentDid you last buy a couch in 1982? reply dylan604 10 hours agorootparentMe? I haven't bought a couch. I'm on the same couch I grew up on at my parent's house that was bought circa 1978, so essentially, yes. Solid wood frame. Re-stuffed cushions. My couch can be found in those \"If you recognize this, you're old\" memes. AKA, I'm old Edit: re-reading almost reads if I'm still at my parent's house couch surfing. I'm not a zillenial. I'm in my place with that furniture from back then. reply bradleyjg 10 hours agorootparentI ask because $300 -> $1000 is roughly 1982 to today. reply oarsinsync 3 hours agorootparentI bought a leather sofa in 2012 that was priced at £389. Today (2024) it’s priced at £899. ¯\\_(ツ)_/¯ reply TylerE 4 hours agorootparentprevThe entire problem is that “decently expensive, good quality, but luxury/fashion” largely doesn’t exist any more. reply generic92034 38 minutes agoparentprevOn the other hand I bought the current sofa some 20 years ago for about 600 Euro and it is still performing like day one. Probably a design failure. ;) reply makeitdouble 7 hours agoparentprevWe had an ikea klippan for around 10 years, and had to give it up when moving. During these 10 years I haven't sat on any sofa, be in office lobbies, hotels, showrooms, friends' home that made me feel like it could be a significant upgrade upon my 400 USD sofa. Sure that might not be usual, and I actually wouldn't recommend any other Ikea sofa in general (many were crappy when we were choosing ours). But price and marketting (\"made in XXXX\") is still only one factor in the wether the product will be any good. reply angry_moose 15 hours agoprevI've posted about our ~$2000 West Elm sofa that disintegrated within 2 years in a similar previous thread: https://news.ycombinator.com/item?id=37393399 The whole thing is just stapled together OSB. I ripped the dust cover off and added 3 new frame stretchers made from 2x8 construction lumber (and tied other loose joints back together) and its done pretty well since then: https://imgur.com/a/bqlLgW3 (wish I'd gotten a few more pictures, but I was tired by this point). Just shocking how terrible the construction is. reply nerdponx 15 hours agoparentAs if it wasn't bad enough that most consumer goods have completely bifurcated into \"junk\" and \"luxury\", now it's hard to even tell which products fall into which category, because there is so much junk now being sold as luxury. reply amluto 15 hours agorootparentI’ve had multiple fancy chairs, purchased from a famous high end brand with a very high end showroom in a very high end design center, fail very quickly. The failure was due to their vendor (fancy, in France) using nice solid finger jointed hardwood, well finished, in a place where that construction was completely inappropriate. High quality Scandinavian-style plywood probably would have lasted decades. Nice materials + pretty design does not necessarily result in a good product. reply jahewson 11 hours agorootparentFinger jointed hardwood is not a nice material. It’s short bits of knotty new-growth wood chopped up and glued back together. reply amluto 9 hours agorootparentThis wasn’t (as far as I can tell) cheap finger jointed knotty wood. It was some furniture maker who thought “well, this part needs the grain one way and this other part needs the grain the other way, and I have a finger jointing machine, so I’ll finger joint it!” Even if they somehow found a shop that stocked sheets of finger jointed wood with a 90 degree grain rotation across the joint, it would have been an incredibly inefficient way to produce the part in question. But they didn’t think very hard — see my other comment. I don’t think a single solid piece of hardwood would have performed a whole lot better. Either metal reinforcement or plywood or much more carefully considered joinery was needed. reply lttlrck 5 hours agorootparentprevThat sounds like hardboard? Hardwood is natural. reply BizarroLand 10 hours agorootparentprevThe glue will probably be the strongest part of it, but finger-jointed hardwood isn't that terrible. Any decent wood glue is crazy strong. The problem with knots is that they resist drilling and screwing. The problem with new growth is that the pith is the weakest part of the wood, and new growth has the most pith. Still, it's not a weak and terrible pos wood-like material like 1990's MDF, it will probably be ok for most uses as long as the grain direction is respected in regards to shear direction (typically you want the grain direction to run perpendicular to the shear forces) and everything is properly braced. reply amluto 9 hours agorootparentThe piece in question involved one of the starting wood sections being finger jointed with the grain running along the joint line. It failed where the bases of the fingers were tangent to the grain, which seemed pretty predictable to me just looking at the wood. reply idiotsecant 6 hours agorootparentSounds like someone who owns some fancy equipment but doesn't actually know carpentry. Strange combination in qa commercial product. reply Ekaros 14 hours agorootparentprevReminds me previous sets of dinner chairs my parents had. Glued together. Slowly dried and then they were less than ideal... Even if the materials are good it means nothing if techniques are wrong. reply plugin-baby 14 hours agorootparentprevWhere is hardwood inappropriate? Genuinely curious to know reply amluto 12 hours agorootparentThe chairs had four legs, each of which radiated out horizontally from a central point (they were swivel chairs) then turned downward to the floor. The legs were about 1/2” wide, maybe a bit more. They were maybe 1” tall (vertically in the horizontal section and horizontally in the vertical section). So the grain needed to run horizontally in the horizontal part to support the bending load. It was probably best for the grain to be vertical in the vertical part, although that was maybe less critical: that section was mostly in compression. It probably also looked better that way. In any case, the actual construction put a finger joint in the horizontal section just past the turn, so a tiny bit of vertical grain wood extended horizontally over the turn. And several of the legs cracked just along the side of the finger joint, and one failed completely after about a month of gentle use. The design plausibly could have worked if the joint went diagonally through the turn or was below it. But plywood is strong along both in-plane axes, and the legs could likely have been cut in single pieces from sheets of plywood with strength to spare. Attractive plywood, even from hardwood species, is readily available. The plies are visible along the cut edge, but this is actually a style people like, especially in Scandinavian furniture. Even IKEA sells some nice chairs with plywood elements, at entirely reasonably price points. reply TylerE 11 hours agorootparentprevI think he meant \"place\" as in literally \"the location on the furniture\" rather than the (very reasonable from context) interpretation I suspect we both had that it mean \"place\" in the geographic, or at least climatic sense. Which is itself important as certain woods deal with extremes of humidity better than others. In a temperate climate, just about any old wood will do, but somewhere that is very dry OR very wet, woods like mahogany and teak are best. Teak especially is so good at dealing with water that it was harvested to near extinction in the 19th century just to build ship's decks and cabins out of it. reply gspencley 14 hours agorootparentprevI don't think that amluto is saying that the hardwood itself is inappropriate, or is necessarily ever inappropriate. I think they are saying that the specific joinery in their example was form over function, to the point where the joint was a critical point of failure. Having done a bit of woodworking as a hobby, I would say that hardwood could be inappropriate if it is used for an element that is purely structural, internal (and thus will be hidden by external features) and there are cheaper alternatives that are just as good, or stronger materials available and we are talking about a critical structural element. That's a pretty abstract answer but it's always going to depend on the specific project. Sometimes a piece of furniture has no hidden internal structure, or the appeal of the furniture is that it is all bare wood and you want it made entirely out of a beautiful \"furniture grade\" hardwood. For certain upholstered furniture, such as many sofas, using expensive materials for inner framing could not only be superfluous and add unnecessary cost to the piece, but in certain circumstances there may be better materials available even if you could make a perfectly adequate structural support that will last a lifetime using expensive hardwood and the right joinery for critical stress points. I read amulto's point as being \"expensive material and fancy joinery doesn't matter if you have a weak design.\" reply bombcar 11 hours agorootparentprevPlywood is amazingly structurally sound, because it's got grain going all which ways. Especially when thin, wood is surprisingly easy to break, and it doesn't handle being pulled on very well at all. reply gerdesj 11 hours agorootparentprevI recently visited Hong Kong. In a mall I spotted a shop called Sinéquanone (sic). It was flogging \"French fashion\", quite pricy \"French fashion\". Who knows, it might be French inspired. You can tell its authentic French thanks to the e acute and the trailing e! Sine qua non is Latin. To be fair, the quality did look pretty decent but marketing needs to try harder. Mind you that's not the daftest brand name or trademark ever! Who could forget the Rolls Royce Silver Mist? Mist in German means dung, manure or shit. Someone thankfully noticed before it was released (Frankfurt motor show) and it became the Silver Shadow. Then there was \"Consignia\" ... reply Terr_ 11 hours agorootparent> To be fair, the quality did look pretty decent but marketing needs to try harder. When I lived in Hong Kong, I once saw a boutique grocery store that had a wooden hanging-sign/plaque, and IIRC it was 1997 and the sign said \"Since 1996.\" Far more amusing were the businesses non-ironically translated as things like \"1000 Golden Fortune\"-something-or-other. reply gerdesj 9 hours agorootparent\"1000 Golden Fortune\" or Jolly good luck ... something. I think that's fair enough - translation of idioms is very hard when the languages are so far apart. There's quite a lot of history involved too so that I suspect there are routine translations between the various Chinese languages eg Cantonese and Mandarin to English which might be a bit behind the times but they still work despite sounding a bit twee nowadays to the relevant ears. I say: \"viva la difference\". reply m463 4 hours agorootparentprevthe one that gets me (not furniture, but consumer good) is Yeti. they seem to be slightly better made, but for SO MUCH more money. They have huge stores devoted to their products. Are people really spending money, and that much, on coolers? reply angry_moose 15 hours agorootparentprevYeah. Even at the time we knew West Elm wasn't high end, but we were at least expecting decent. We know more now (and could afford better) whenever we have to finally replace this, but $2000 is a not-insignificant investment that shouldn't be a complete piece of crap. reply elteto 15 hours agorootparentMy problem is that I don’t even know where to buy _good_ stuff. I don’t want to pay $5k for a couch, but maybe I will _once_ in N years, for some large N, if I know it’s very well made and I like the design. But I have no idea where to go for this. The overlap between junk and luxury is too large nowadays. reply drchickensalad 10 hours agorootparentAggregated reddit searches are amazing. Leads you to the gold mine that is american leather etc, which are often rebranded to more well known brands on a model by model basis. Lots of insiders on reddit with that info too. reply beAbU 2 hours agorootparentMaybey cynicism broke me but I find it impossible to trust recommendations from Reddit. It's too easy for these companies to pay for astroturfing these days. I've noticed a very prevalent \"hail corporate\" subculture on reddit that put me off believing anything anyone said. reply JohnFen 14 hours agorootparentprevAs with so many goods these days, I find that buying stuff made at least a couple of decades ago works best. It's much easier to tell the garbage from the treasure if you aren't buying stuff made recently. reply pfannkuchen 10 hours agorootparentprevI’ve had a consistently good experience with room and board so far and I am very anal about construction quality (as perceived by myself, anyway, I’m not a furniture expert). reply earleybird 14 hours agorootparentprevAs sibling comment says: survivorship bias as a heuristic is useful. reply layer8 13 minutes agorootparentIt's often not, because today's company is not the same as it was 10-20 years ago. The longer you want something to last, the less reliable past experience becomes. reply theGnuMe 15 hours agorootparentprevIt’s even worse with carpet and carpet install. Thieves. reply throwaway14356 4 hours agorootparentbeds are the worse reply eightysixfour 10 hours agorootparentprevLuxury does not have to be premium or vice versa. Premium conveys quality, luxury conveys status. reply thfuran 8 hours agorootparentLuxury implies comfort or quality. reply mrguyorama 14 hours agorootparentprev>junk now being sold as luxury. That's always been the case though. There has always been junk marketing itself as \"luxury\" to milk the nouveau riche. It's not like real Coach bags utilize some magic leather that doesn't degrade just the same as the $200 leather purse you buy from a local artisan. It's not like the brick that Supreme sold was made of some sort of magical clay. The luxury purse companies don't burn their leftover product to protect some secret of Dr Who purses that are bigger or magically organized on the inside, but because the entire value of the brand is \"I can afford this and you cannot\" Luxury has ALWAYS been about signalling and displaying status and power. It's always about rubbing the prole's faces in their supposed supremacy. Remember, they have money because they are better than you, definitely not because there are systems and structures in place that make it easier to get rich for the already wealthy and connected. Unfortunately it seems so many people really struggle to understand that while quality often costs a lot, costing a lot does not imply quality in any way. If you can afford to spend oodles on marketing for your product, you probably aren't spending as much on quality as people assume you would. reply nemothekid 11 hours agorootparent>It's not like real Coach bags utilize some magic leather that doesn't degrade just the same as the $200 leather purse you buy from a local artisan. Not sure why Coach was chosen for this example - I don't believe they are expensive; last I checked they were in the range of $200-500, which doesn't seem egregious as the actual luxury brands (ex. Hermes, where the entry level bags are $4,000). That said, I feel there is a real difference in quality at various price points, and focusing on the material (\"magic leather\") is wrong. When I'm paying a premium I'm usually looking for in the dimensions of construction, and usually that means paying an actual professional who may charge $100/hr, vs 19 year old in Bangladesh. The two might be using the same material but the price difference comes from the person assembling the item. The problem is you have a ton of companies (even \"luxury\" ones), that in an attempt to juice their stock price, have also focused on getting costs super low and are now using the same factories as junk brands but just slapping their logo on it. Even products of the same brand can vary wildly in quality depending even on the year it was made. I have jackets from \"luxury\" brands that I bought 10 years ago that still look brand new for thousands of dollars (and probably saved money in the long run), but buying a similar item new or even trying to replace it is impossible. reply decafninja 10 hours agorootparentSome brands like Hermes, Rolex, etc. also require you to establish a “relationship” with them to acquire their most popular items (Birkin or Kelly bags, stainless steel watches). This entails a lengthy purchase history, and some schmoozing of your assigned sales associate doesn’t hurt either. Unless you’re some well known figure, just waltzing into a boutique with a suitcase full of cash won’t get you what you want to buy on your first visit. Other brands are catching on. I hear Porsche (or at least some dealerships) have started gatekeeping 911s this way. reply brianwawok 10 hours agorootparentAnd what’s funny is a budget model 3 you order online totally smokes the Porsche. It’s really just trying to sell a badge not a product. reply c0pium 6 hours agorootparent…on the straight away of lap one. The top trim model 3 performance best time around the green hell is like 9 minutes. There are factory Porsches that will do it in under 7. This is a very ironic comment to have made in a thread about how cheap things aren’t as good as they seem once you look a bit deeper. reply VHRanger 8 hours agorootparentprevTypical American thinking. Your model 3 can't handle a corner. The reason car enthusiasts like Porsches is that they handle particularly well. reply imp0cat 4 hours agorootparentBut that's not his point. He's right about the badge. reply decafninja 4 hours agorootparentNope, he’s not. Or at least not entirely. Even their models that share platforms with “lesser” brands in the corporate stable go through a lot to differentiate them. But if you don’t care about cars or enjoy driving, then all of it is a moot point and probably meaningless to you, and you might as well enjoy a Toyota Camry and call it a day. reply decafninja 9 hours agorootparentprevWith all respect, 0-60 times is not the only reason why you buy a Porsche. A Toyota Corolla probably ticks more boxes for the average person than any Porsche if cars are not your thing. reply jbm 4 hours agorootparentprevNothing gives me more joy than watching car geeks furiously posting when they see things like this. Thank you, I had a long day at work. Daily reminder that your \"super cars\" are worthless. Merging onto the highway is far more important than \"winning in the corners\". reply dlp211 4 hours agorootparentprevThis is, and I cannot overstate this, one of the most ridiculous, tech bro statements I've read on here in a while. reply jerkstate 10 hours agorootparentprevCoach is probably a bad example here because they are known for using high quality leather, and they are also among the less expensive \"designer\" brands (there are Coach leather purses in the $200-500 range, wheras you are looking at $2000-5000 for a brand like Louis Vuitton - also high quality leather, but not worlds apart from Coach). There is a huge amount of variability in quality of leather, from top grain to full grain to split grain, to \"genuine\" and \"bonded.\" In general though I agree with your point that it's possible to get the same quality as a luxury brand for cheaper, and luxury brands are about signalling, but it's a continuum. There are also plenty of \"luxury\" bag brands in the $200-500 range that use crummy leather and you'd be way better off with Coach (or a local artisan like you mentioned.) reply TylerE 4 hours agorootparentThe most important thing to remember that the strongest thing they can say about genuine leather is that it isn’t fake. Even that’s debatable. reply doctorpangloss 11 hours agorootparentprev> degrade just the same as the $200 leather purse you buy from a local artisan. Where are there local artisans selling leather purses they made for $200? Are you sure you don't mean $4,000? Surely if you are buying a $200 hand made purse, it was made by hand in a low labor cost country and relabeled. reply littlelady 1 hour agorootparentSome years ago I found a leatherworker, who sells simple handbags/clutches starting at about 300 EUR. He also sells wallets and belts. He has a limited selection of styles, but they are made-to-order thus you can select the colors when you place your order. He isn't local to me, but I've met him and watched him stitch his bags together and chatted about his style (minimalist, sleek). I couldn't afford anything from him at the time (his smaller items were sold out), but kept his card handy. I'll provide a link, in case anyone is interested. http://www.foerster-taschen.de/ reply bombcar 10 hours agorootparentprevhttps://saddlebackleather.com/everyday-purse/ is a bit over $200, and doesn't hide that it's made in Mexico (though they do use machines and tooling to process the leather so perhaps it's not \"hand made\"). reply tiltowait 10 hours agorootparentI’ve got one of their backpacks. It’s very nice. Heavy, though, at around five pounds. Sadly it almost never gets any use, because I rarely have need for a backpack. I should have bought some luggage instead. Like the other poster, I also have a couple of their wallets. They’re simple but obviously high quality. They don’t feel as slick as the Coach wallet I was given as a gift, but I have no doubt they will hold up longer. reply ghaff 10 hours agorootparentLeather is actually not a great material for a backpack or an outdoor (non-dressy) shoulder bag from a practical perspective in the 21st century. Nylon and related synthetics is a lot more practical. If you gave me a leather outdoor bag I'd probably thank you nicely and stick it in a closet or sell it. I do like leather wallets though I almost exclusively use small front pocket ones these days because of sciatica and minimal needs for carrying either cash or a lot of cards. reply TylerE 4 hours agorootparentGoing from a trifold to a bifold is pretty game changing if you haven’t. Drastically reduced thickness for a very minimal change in capacity. reply ghaff 10 hours agorootparentprevI don't have a purse. (Well, I have something from Mountainsmith I've had for decades that a friend calls a man purse. I'm sure it's been in dozens of countries.) But I have a front-pocket wallet/business card holder from Saddlebackleather that wasn't particularly expensive and will probably last as long as I need it to unless I lose it. reply JohnFen 14 hours agorootparentprevThis is why I differentiate between \"quality\" and \"luxury\". Luxury goods are very often just expensive junk that people buy in order to signal that they have money. Quality goods are well-designed, well-made, etc. And you can't be sure about quality based on price. reply schneems 11 hours agoparentprevAbout 8 or so years ago my wife and I were really excited to buy our first “adult” piece of furniture (read, not-ikea). And we found a leather sofa we loved the look of at West Elm. But it really sucked. Thankfully we had another room that needed to be furnished and we threw it in there. But the thing was just not comfortable and the pillows started sagging after minimal use. Since then almost every other couch we got was from ikea, since if it ended up sucking at least we didn’t pay 2-3x the cost for it. Which is sad really, I want a nice couch. I just don’t that paying 10-20x the cost wind just be a piece of junk. reply imp0cat 4 hours agorootparentIKEA has some interesting options (cheap copies of designer sofas/other stuff). Here's a quick overview: https://www.youtube.com/watch?v=f0nPPc2-jpE It's almost like a \"How to shop for nice stuff at IKEA 101\" and covers: 00:22 Sofas 01:28 Morning Brew 02:29 Lounge Chairs 03:41 Dining Chairs 05:34 Tables 07:34 Lighting 09:02 Others reply brandensilva 7 hours agoparentprevWest elm has been pretty bad for most stuff for us too. Surprisingly we have an okay Urban couch from them that's held up well the last 5 years. The cushions haven't maintained their shape all that much and the feathers occasionally poke through which are my only complaints. Our little kids used to jump on it before we moved it downstairs so the frame was at least built well and it's still pretty comfortable. Id never buy one again from them though after having everything else fail on us. reply jwells89 6 hours agoparentprevThe quality of the frame makes a big difference. About 3 years ago after moving into a new house, I needed a new couch and wanted something that would wear reasonably well without getting into the higher end ($3k+). I found one on Apt2B which they were touting was built around an robotically-welded steel frame, lending to consistent durability. After reading many sofa reviews mentioning buckling particleboard, that sounded pretty good. There weren’t a ton of options due to pandemic shortages so I went for it, which cost me $1500. It’s held up well so far. Cushions are showing some wear but nothing out of the ordinary, and the steel frame is indeed solid. It might even be worth reulphostering at some point down the road. reply pyb 15 hours agoparentprevWest Elm has a bit of a reputation in that regard reply some-guy 15 hours agorootparentI don't live in the Bay Area anymore, but once great thing about living there was the amount of secondhand West Elm / Williams Sonoma furniture for reasonable prices that you could buy from rich people. Most of their quality is a crapshoot but at the right price you can find good deals for some of their items. reply Arrath 8 hours agoparentprevI'm considering doing exactly this kind of surgery on my couch, how hard was it to put the fabric cover back together? reply angry_moose 6 hours agorootparentThe only part I had to rip off was the bottom dust cover. Installing new is pretty cheap and easy - $10 roll and a staple gun. Or just leave it off reply Arrath 5 hours agorootparentHmm I don't know if coming in from the bottom will get me the access I need, I'm afraid. I've got some bowing across the middle of the backrest. But, maybe I'll give it a go anyway! Thanks. reply tptacek 11 hours agoprevThis article echoes something I've learned since we moved into a larger house this past summer: don't buy new furniture.† We bought very nice leather couches a few years back (we have dogs, leather is the only option) and paid dearly for them. And they're great. (We looked carefully at the construction details before buying.) This summer, we had some rooms we cared a lot about and others we just needed to fill in some blanks in, and we camped Facebook Marketplace looking for stuff. Pretty soon, even the living room was getting stuff we found on Facebook, at comparable levels of quality to our old \"new\" furniture, and at pennies on the dollar. People are simply always getting rid of good stuff, and there isn't a meaningful secondary market for it; they're just thrilled you're getting it out of their house and getting a couple bucks in the process. I submit that you would end up with a better-furnished room faster, more easily, and at a fraction of the cost of high-end furniture retailers simply with Facebook Marketplace and TaskRabbit (for near-instant delivery). † Leastways, not if you live in a major North American metro. reply arp242 11 hours agoparentFew years ago I moved to another country and had to get rid of everything I had minus ~25kg. It's bloody hard to get rid of a lot of stuff. I had a great leather sofa, about 15-20 years old (inherited from my grandparents) still in great condition, but I couldn't get rid of it at any price and none of the charity shops took it because it was missing some fire hazard label (sigh...). Same with almost everything: I sold my 2-year old £1,200 mattress for £50 (and I had to practically beg to guy to take it, because it would have been a complete shame to chuck it). Washing machine, fridge, all the \"little stuff\" (cutlery, books, DVDs, what-have-you). I ended up putting a lot outside \"free stuff\" and that got rid of a lot. Actually the only things I managed to sell was an IKEA sleeping sofa and an IKEA dinner table set. That said, since then I found that actually finding good stuff isn't always easy. reply freddie_mercury 8 hours agorootparentI've moved countries three times and that's been my experience each time. What's more, actually selling stuff is often such a time consuming hassle (posting, dealing with replies, scheduling pick ups, dealing with flakes) that in a lot of cases you're better off just paying trash hauling service to just come pick it all up in a single go. reply thrdbndndn 8 hours agorootparentprevI ended up having to discard a perfectly good desktop computer and a high-end scanner because nobody wanted them, not even for free. It's really frustrating, not because I missed out on making some money, but because of how wasteful it feels. However, monitors seem to sell immediately every time. reply TylerE 6 hours agorootparentprevThe mattress one is a bit of an interesting one. It's actually illegal to sell a used mattress in the US - and there are very legitimate public health reasons for the being the case. You can't really clean one - that's especially true of foam, and they can be riddled with lice, bedbugs, and all kinds of creepy crawlies. reply neuah 5 hours agorootparentRegulations vary by state, but it is not in general illegal to sell a used mattress. reply arp242 5 hours agorootparentprevPeople sleep in hotels, at friends, and whatnot. It's really not that big of an issue with basic due diligence, just like any second-hand goods. reply gilfoy 9 hours agorootparentprevI've looked around for some quality used furniture at a decent price, it's very hard to find. Just gave up and bought some stuff on article.com which has been pretty ok bang for the buck for me in the past. reply _xerces_ 11 hours agoparentprevAre you not worried about bedbugs buying furniture off Facebook? reply tptacek 11 hours agorootparentI would worry about stuff like that if I was buying cloth furniture. I am not worried about it buying high-end leather furniture. It seems about as likely as getting bedbugs from a used car (which also happens! but nobody blinks about buying a used car). You're generally buying from people's houses. Maybe I'd be concerned about grabbing something from an apartment. reply paholg 11 hours agorootparentprevI think bedbugs are a regional problem. reply BizarroLand 10 hours agorootparentI can't say I fully agree or disagree: https://www.mattressclarity.com/blog/bed-bugs-by-state-city-... It seems to be related to population density, at least in America, and only somewhat ameliorated by climate. reply TylerE 4 hours agorootparentThat’s just lazy lying with a map. They’re just literally mapping population. If you controlled for population the signal disappears utterly. Look familiar? https://xkcd.com/1138/ reply BizarroLand 3 hours agorootparentDo you have a link to an alternative site with information about bedbug density made since 2018 or so? I'm not saying you're wrong, I'm saying that in lieu of additional information this is what I have to work with, so I will need a better source of data before I change my mind. reply TylerE 1 hour agorootparentJust read the legend. It’s raw numbers, not per capita. It’s not even worth taking seriously. It’s not showing rates at all, just raw case numbers. NY has a lot. Alaska and Wyoming have almost none. Things happen where people live. News at 11. That site is also obvious affiliate spam SEO bait. reply verticalscaler 11 hours agorootparentprevOr ghosts? I mean if the house it comes from is haunted maybe an evil spirit will migrate with it. You never know. reply bombcar 10 hours agorootparenthttps://www.penny-arcade.com/comic/2007/06/22/perfectly-reas... reply echelon 11 hours agorootparentprevI got pesky moths from getting something used once. It isn't worth the hassle. reply tptacek 11 hours agorootparentFor me it's the other way around: anything I might want that's of reasonable quality will take 1+ months to arrive (usually, it'll have to be constructed to order), where I'm only a couple clicks away from having the new thing the next day buying used. I want to be clear that I'm not saying everything on Facebook Marketplace is great. Most of it is crap! You still have to be discriminating. But everybody is always unloading high-quality furniture, and, at least for now, Facebook is full of excellent deals. reply anon-sre-srm 3 hours agoparentprevLearned this 30 years ago. Durable quality goods are generally best bought used, but furniture requires close inspection to avoid pests. Custom Macy's extra long couch from ~2000 is the best thing ever. You sink into it and it holds up. Bought used-new for $1k when a friend paid $4k but was delivered 2 by mistake. reply tonyarkles 10 hours agoparentprev> People are simply always getting rid of good stuff I suppose there’s an interesting survivorship thing going on here. A poorly-built couch probably won’t even last 10 years. And if it does, somehow, you’ll know as soon as you sit on it if it’s about to turn into dust based on the squeaking and general instability. If it still feels solid and you don’t sink into it so deep that you can’t stand up again there’s a decent chance it’ll last another 10 years. reply api_or_ipa 4 hours agorootparentI suppose furniture also follows the [Lindy Effect](https://en.m.wikipedia.org/wiki/Lindy_effect) reply secretsatan 2 hours agoprevThe article goes on about the quality of manufacturing, which is very fair, but something that bugs me, and it seems to apply to cheap sofas as well as very expensive ones. Why are so many of them just plain uncomfortable? I'm looking for one I want right now, and I have to go around a furniture shop and try each out and I reckon, maybe 1/4 of them are suitable for a place you might enjoy sitting in. The high end furniture shops seem to be the worst, i've seen 4 figure sofas that are the most uncomfortable thing I ever tried. Champions of form over function. My last favourite sofa was around 2500 I guess, lasted 10 years, was excellently comfortable, but was unfortunately the wrong shape for my new place, I have not found anything anywhere near as good as that one. It may be my height, much furniture seems a little off to me, and it is hard in general for me to find things I'm happy with. reply swatcoder 1 hour agoparent> Champions of form over function. Sofas have many different functions. The plush sofa you sink deep into for TV at the end of the day has a different function than the firm sofa your dinner guests sit on the front of while sipping cocktails, etc Many of the sofas you were looking at were probably designed for a different function than you were seeking. reply pixxel 1 hour agorootparentCocktail sofas. I’m not posh enough to have imagined such luxury. reply rsynnott 15 hours agoprevI hear this a lot, but my fairly inexpensive IKEA sofa is about eight years old with no problems at all so far. EDIT: Actually, in general I've found that my IKEA furniture has done pretty well (basically everything in the house is IKEA) with the sole exception of a \"Lack\" coffee table, whose surface is kinda disintegrating after 8 years (I think it's basically made of cardboard with a veneer...). The name should perhaps have been a warning. reply baby 15 hours agoparentFor some reason people hate IKEA in the US. Was trying to sell a standing desk I bought there for 750$ and nobody wanted it. Ended up selling it for 150$. I also had a Jarvis and it was gone in an instant, even though the IKEA one was much much better. I Often hear people saying that IKEA furnitures don’t travel well or don’t last long. It’s like we’re not going to the same IKEA. reply swatcoder 15 hours agorootparentIKEA is beloved by many in the US and generally one of the most specifically in-demand brands in the market for used contemporary furniture. You might just be in an unusual region or had some other reasons why your listings didn't perform the way you expected. That said, I am one of those people who doesn't get a lot from them so I can speak to some of criticism. Part of it is just the aesthetic, and theirs doesn't match how I decorate my own space or what I usually feel good around. That's just the nature of aesthetics, though, and there's always going to be some difference in taste between any two people and any two regions. As for quality, though, I think the critique you hear reflects the quality of their budget products. If you're eyeing modern or euro designs at a fancy furniture studio and then go to IKEA to find a cheap approximation, you discover that much of the cheapest stuff has the same flimsy glueboard, peeling laminate, and unstable joinery of the cheap stuff at Wal-mart. That shouldn't rally be a surprise (cheap is cheap for a reason) and doesn't hold true for their mid-range and higher products. And heck, it's not even really fair when Walmart and Target furniture isn't any better, but it's enough to keep feeding the reputation. reply alright2565 11 hours agorootparent> you discover that much of the cheapest stuff has the same flimsy glueboard, peeling laminate, and unstable joinery of the cheap stuff at Wal-mart. I'm not going to argue too much with this, but I think this is underselling Ikea quite a bit. Their cheap stuff is definitely made out of cheap materials. But I've found it to be well-engineered compared to walmart with reinforcements in critical places and general overall good quality control (doesn't come pre-scratched). Walmart-level furniture on the other hand is often designed to look a certain way, with no consideration for how loads will be placed on it or long-term durability. reply rtpg 7 hours agorootparentI feel like the cheapest thing in a certain price category in IKEA is \"doesn't survive two moves\" stuff, but everything above it is ... basically fine. Like it's a table, there's only so many ways to put 4 metal bars and a piece of wood on top. It'll be fine. reply bombcar 10 hours agorootparentprevFor what it's worth I've had better luck with Walmart furniture than Ikea, but that was because I was careful about the Walmart stuff and just trusted the Ikea would be fine. reply maxglute 12 hours agorootparentprevIf one wants durable from IKEA, shop by material. They have sheet steel and solid wood that will outlast any particle board. The steel is a little thin on the budget line and the wood is not very aesthetic for some tastes, but they usually have options that last or outperforms more expensive particle board furniture that are more complex due to aesthetics. Hell even plastic there is fine, so many cafes with shitty beater IKEA cafe furniture. reply tonyarkles 10 hours agorootparentThe other thing you can do is glue-and-screw instead of just using the screws. I’ve had a bookshelf or two break due to the screws blowing out of the chipboard during a move. Using regular wood glue/PVA meant that that never happened again although it also means you can’t disassemble it. Disassembling is kind of overrated though, the screws don’t ever go in as tight the second time, especially after it’s been sitting loaded with books for a few years. reply BonoboIO 8 hours agorootparentUnderrated trick for ikea furniture. Do not use the ikea nails, they are junk … use staples. Much stronger, easier to remove and you can remove them without damaging the part like the back of PAX reply mindslight 6 hours agorootparentprevWhen replacing screws in soft material, I slowly turn them to the left to feel when they drop into the existing thread rather than making new grooves. And in my experience, IKEA furniture reassembles fine multiple times. You also have to make sure such screws are and remain tight, because if they start getting loose that working back and forth will destroy the threads of the softer material. If a piece of furniture isn't solid, figure out why and shore it up before it gets progressively worse. reply TylerE 6 hours agorootparentprevI think more than a bit of it is typical American trademark laziness and inability to follow directions. I see so many of the bookcases without the backing sheet on them. Even if it's just thin cardboard, it provides a lot more of the structural integrity than you might think. The point is to keep the cubes from deforming and having a progressive failure. reply azza2110 10 minutes agorootparentThe bracing provided by the backing sheet makes all the difference. Some of the simple desks the sell are nothing more than a tabletop and four screw in legs. With no bracing the desk is unpleasantly wobbly. The very popular Ikea cube bookcases (https://www.ikea.com/us/en/cat/kallax-shelving-units-58285/) aren't sold with a backing sheet - thankfully they seem stiff enough without it. reply Aeolun 10 hours agorootparentprevThe quality of IKEA budget products is far higher than you should expect for the price. reply rsynnott 12 hours agorootparentprevYeah, they’re definitely opinionated about design. Personally, I like it, but if the design doesn’t work for you, Ikea isn’t going to work for you. reply JohnFen 12 hours agorootparentprevI legitimately had no idea IKEA sold anything of real quality. TIL. reply munificent 9 hours agorootparentI think IKEA is sort of like the Toyota of furniture. It doesn't look amazing, but it's higher quality than the price would lead you to believe because they work very hard to design things economically. reply Gigachad 9 hours agorootparentIt’s also engineered incredibly well. There are no weak points or flaws in the design. It feels like someone poured their heart and soul in to producing the absolute strongest and most practical item possible given the budget. reply KerrAvon 12 hours agorootparentprevHave you never been in an IKEA store? They sell a lot of solid wood. I have IKEA furniture that's lasted for decades. It's value-optimized, but it's usually well designed; if you put it together properly, it will last. reply rsynnott 12 hours agorootparentprevI mean, it depends what you mean by ‘real quality’; you’re not going to get hand-crafted expertly made stuff that will last for centuries or anything. But for the price, their mid to high end stuff is excellent. reply ghaff 11 hours agorootparentYeah, I have a couple of Ikea chairs in a room that replaced (cheap) wicker that was falling apart. They haven't been used hard but, to me, they were pretty inexpensive, look good, and are very comfortable. On the other hand, I bought a dresser with a lot of particle board and, no, it's by no means well made. But it's in a bedroom and it works. I could have spent 4x (or more) for a nicely made hardwood dresser from a good New England brand. But even getting it into the bedroom upstairs might have been a bit of an adventure. reply JohnFen 12 hours agorootparentprevI don't mean anything like artisan or hand-crafted. I mean well-built, out of quality materials. A good quality table, for instance, should last decades. reply valicord 5 hours agorootparentI'm writing this comment sitting at a basic IKEA particleboard desk that I've had since 2014. It has survived daily usage for 10 years and 2 moves (one coast-to-coast). The only signs of wear is some scuffed paint where the hands rest in front of the keyboard and veneer is starting to peel slightly in one the corner. reply rsynnott 11 hours agorootparentprevI think a lot of their solid wood stuff (it’s not all chipboard!) would fit the bill, tbh. You do have to be slightly careful with the assembly (it’s not difficult, but some people like to treat the instructions as suggestions, and then get annoyed when it falls apart…) reply mortenjorck 14 hours agorootparentprevI think the reason for this is simple: Ikea does make some pretty poor-quality furniture, but it's often on the floor right next to some very well-built stuff that will last for many years. Price is sometimes an indicator (I bought two Ikea dressers ~15 years ago; I kept the cheaper one for only a few years while the more expensive one is still going strong) but not always (my 18-year-old sofa was the entry-level option at the time). reply nytesky 14 hours agorootparentprev$750 for an IKEA desk is crazy money. Does it have hydraulics to raise and lower the desk? But depreciation on IKEA is huge because while it can last a long time within a household, it moves very poorly so if it has been moved or reassembled once or twice, it’s likely near end of life. But hard to evaluate that, it’s not like it has an odometer — hence value for used it very low. reply koyote 12 hours agorootparentThose desks do have hydraulics: https://www.ikea.com/au/en/p/bekant-desk-sit-stand-white-s09... Ikea's goods usually come in different price ranges with the most expensive often not being 'cheap' but 'cheap given the quality'. That being said, often their cheapest stuff is the best value for money because it's so cheap that it lasting more than a year would be a miracle (but they usually do!). reply askvictor 11 hours agorootparent> Those desks do have hydraulics: Well, an electric motor reply sircastor 15 hours agorootparentprevI think a lot of this is attached to a puritan-based work ethic. If something isn't hard to do, or require a lot of time and energy then it's not of high quality or worth having. It's probably a signaling thing too... reply etrautmann 13 hours agorootparentPossibly, though some products like the PAX just truly don’t move well even once. reply fabioborellini 1 hour agorootparentYes, Pax is only sturdy when mounted to a wall. It is very unstable by itself. But isn’t it meant to be permanently installed? I’m expecting to leave my Pax when I’m moving out. reply xandrius 3 hours agorootparentprevYeah, most stuff at Ikea is either decent or crap temporary things. Also the style does get really old pretty fast for me. I think good second hand furniture is where it's at: you get to not buy yet another new thing and get something solid and good. reply quartesixte 11 hours agorootparentprevSame here — I have an Ikea bedframe that’s nearly a 2 decades old at this point and has moved four times. An office chair lasted me 7 years. Bookcases over a decade old. I grew up in a nearly all Ikea household, and it’s only later in life I have discovered their reputation. Am I missing something? reply StressedDev 8 hours agorootparentNo - Some of Ikea’s furniture really lasts. I have a 25 year old Ikea couch. It needs to be reupholstered but it is still comfortable. reply rsynnott 12 hours agorootparentprevYeah, I dunno, maybe it’s different stuff in the US? I know at least some of the items are different. With the exception of the aforementioned table (which I think cost about 8 euro at the time, so, really, what did I expect) I’ve found all their stuff to be of very decent quality, certainly better than what you could get from ‘traditional’ furniture stores at the same price. reply JohnFen 12 hours agorootparentprevI don't hate IKEA at all, but I've found that a lot of their furniture doesn't last more than a couple of years. I consider it \"temporary furniture\". reply jghn 12 hours agorootparentIt really depends. IKEA runs the entire range of very temporary to actually pretty good. The trick is knowing which is which, although price points are usually a good indicator. reply KerrAvon 12 hours agorootparentprevThe problem with used IKEA furniture is that it's all DIY-assembled. You don't really know if it was built properly. reply swader999 11 hours agorootparentprevI just don't like walking through their ENTIRE store. reply onli 10 hours agorootparentYou don't have to. Every IKEA store has shortcuts to quickly go to the section you want. And at the start, after the stairs usually, you can go directly to the restaurant and to the small stuff section, if you want to skip the furniture show rooms completely. IKEA is actually awesome for this scenario. reply swader999 5 hours agorootparentWife no shortcut. reply Tagbert 11 hours agorootparentprevYou should start at the warehouse section and walk though it in reverse to get where you want to be. reply Aeolun 10 hours agorootparentprev> I Often hear people saying that IKEA furnitures don’t travel well or don’t last long. It’s like we’re not going to the same IKEA. I mean, if you are comparing with heirloom class furniture then that’s certainly true. After taking the cabinet or bed apart and sticking it together 4 or 5 times, you certainly start to notice some degradation. But then we’re talking about a factor 100 price difference. reply ericd 6 hours agorootparentThe thing is, antique stores are stuffed to the gills with heirloom class furniture, and it doesn’t cost 100x the amount. Gorgeous solid cherry, mahogany, etc, where even the backs and drawer bottoms are solid can be had for a song. We recently tried to find a mostly solid wood IKEA dresser, but because they’re switching all their designs to new anti-tip designs over the next few months, almost everything was out of stock. So we decided to look a bit further afield, and we went to our local antique shop. We ended up spending $600 for a totally refinished solid cherry dresser, delivered into our room. It’s stunning, totally solid cherry, and I think slightly less expensive than the IKEA dresser we were trying to get. Not spending 2 hours cranking screws was a really nice bonus. reply resource_waste 14 hours agorootparentprevBack in 2012 I furnished a home with Ikea furniture. Yes I hate them. You'd spend $60 on a book case and spend the next 4 hours trying to understand what the instructions mean and how to build it. You also needed a partner to hold corners together. Now today, the furniture instructions are better and instead 16 different weird fastener, there are 8. Its a frustration thing. Ikea didn't really do anything but be low cost. We blame Ikea like we blame Walmart for having drug addicts. reply illiac786 14 hours agorootparentI think this every time I built something ikea, then I build something from another brand and I discover a new abyss, then I go back to ikea. It's a cycle. reply vundercind 12 hours agorootparentYeah I don’t get the complaints about IKEA instructions. They have the best furniture-assembly directions I’ve seen. They have a lot in common with old LEGO set instructions. Maybe people who hate them didn’t do a bunch of that as a child? reply Aeolun 10 hours agorootparentI have a really hard time understanding people that don’t get how to assemble furniture of that kind in general. Instructions or no instructions, there’s only so many ways you can put a bunch of planks together. reply kayodelycaon 9 hours agorootparentI know these people. They aren’t stupid. Many of them just aren’t good at visualizing things they haven’t done or been shown before. They may know X should go into Y but the task is so unfamiliar or counter to how they think that they hit their working memory limit before it makes sense to them. Impatience just makes that worse. IKEA’s instructions are extremely helpful in this case. reply Gigachad 8 hours agorootparentprevProbably poor spacial reasoning skills. Didn’t spend enough time playing with Lego or sticking wood blocks through shaped holes. reply rsynnott 10 hours agorootparentprevYeah, I’m not particularly handy (I break out in a cold sweat whenever anything requires more than trivial assembly), but I’ve never had any issue with assembling Ikea stuff. reply KerrAvon 11 hours agorootparentprevI'm with you -- I've assembled a lot of random stuff recently and I wish everyone had instructions half as good as IKEA's. reply nytesky 13 hours agorootparentprevAgreed, self assembly is terrible but IKEA is generally the least terrible. reply adaml_623 11 hours agorootparentprevI love IKEA instructions and construction. I honestly get a buzz from the puzzle. If I have to construct more than one of an item then I'll compete with myself on speed and efficiency. reply askvictor 11 hours agorootparentIt's basically Lego for adults (which was more exciting until Lego pushed its market into the adult demographic). Which is actually part of Ikea's brand identity. When you put it together yourself, you feel closer to the furniture than if someone just plonked it at your house. OTOH, if you hate that kind of thing, you'll never go back, but I guess they have an assembly service these days. reply mortenjorck 15 hours agoparentprevI have an Ikea Lillberg sofa from 2005 that I never dreamed I would hold onto as long as I have. Every time I've moved, I think this will be the time I replace it, but the joinery has stayed rock-solid, the wood has aged beautifully (though I admit this is likely owing to a lack of pets or children) and even the upholstery has never pilled or visibly worn (though I keep thinking about ordering a replacement slipcover set from Comfort Works, which makes aftermarket upgrades for long-since-discontinued Ikea products). And the minimalist, Danish-influenced style somehow never looks out of place no matter what else I put around it. This article has me thinking I may yet keep the Lillberg for years to come. reply i80and 15 hours agoparentprevI got an IKEA couch about 9 years ago. It was like... $700? The construction is definitely very cheap and you can tell if you flip it on its back, but it's very comfortable and sturdy enough that it still feels solid in normal use. I don't think \"cheap\" construction is necessarily a bad thing, honestly. There's ways to do cheap construction such that it works just fine. reply AtlasBarfed 12 hours agorootparentIkea has to engineer it. They are a global company and they can invest in engineering to avoid as many returns/refunds. It's worth it to them. So while the materials are cheap and the style not high end, from what I've seen they maximize the engineering to make it durable. reply tonyarkles 10 hours agoparentprevCongrats on the new server rack when you decide to take it out of service as an end-table: https://wiki.eth0.nl/index.php/LackRack Also… I haven’t priced out Lack tables in a while but it looks like they’re still only $20?! I last bought one in probably 2006 and they were $20CAD at the time. reply vizzier 15 hours agoparentprevYou're quite correct about the Lack. They're cheap as hell (15 bucks at time of writing?), but as a result quite manipulatable, such as creating 3d printer enclosures [0]. You can see some of their insides as they go through the process. [0] https://blog.prusa3d.com/mmu2s-printer-enclosure_30215/ reply shagie 12 hours agorootparentThe LACK RACK https://news.ycombinator.com/from?site=eth0.nl Though I'm also going to point out that a LACK side table ($13 now) for 8 years is a rather good deal. The internals are revealed on the Ikea page too: https://www.ikea.com/us/en/p/lack-side-table-black-brown-801... reply evilduck 6 hours agorootparentprevI made a Lego table out of one Lack end table, four Lego baseplates and some rubber cement. The baseplates cost about 2x what the table did. reply Ekaros 14 hours agorootparentprevNow that I look Finnish prices it is surprising. The coffee table is 40/50€, tv stand is 15€. Side table 8€ or 10€ for next size. Okay those cheap ones make sense, but for coffee table it is robbery... reply Scoundreller 12 hours agorootparentThe \"enterprise edition\" is more than three times as expensive, while providing less stability than two of the regular products combined. https://wiki.eth0.nl/index.php/LackRack reply al_borland 11 hours agoparentprevI avoided the LACK after seeing someone spill drink and watching it bubble up like paper. My coffee table is still from IKEA, but it’s metal. I’ve had it for 11 years now. It’s on wheels and some of them look like they’ve seen some stress over the years… and it’s been moved to 8 homes in those 11 years, which could have been the cause. But it still works great and I don’t know the the average person visiting my home would notice that. I have been thinking of getting something a little larger and more grown up, but I love the functionality of the wheels, how it can get out of the way, and that I don’t have to baby it. It doesn’t look like they sell it anymore, but it was $40 well spent. reply atomicfiredoll 15 hours agoparentprevAfter a lot of digging a few years ago, I settled on the IKEA Finnala. So far it's held up pretty well. It's not as well made as quality pieces, but I worked from the assumption that any couch I bought would be trash. Some of the nice things about a buying into a system like the Finnala are that when an arm, cushion, cover, or whatever fails, I can just replace that piece; there are aftermarket covers and legs; if I move it can be disassembled; and if a new place is smaller, the whole thing doesn't have to be trashed. I love quality furniture, but it doesn't always fit the bill for a society where people can't afford a single family house or put down roots. (Note: that still doesn't necessarily justify all the items being sold today that are destined for a landfill in a few years.) reply HdS84 13 hours agoparentprevAt least in Germany quality has gone downhill. I still own some Billies made in 1995 or so by Ikea. Literally massive wood and damn good book shelves. The ones bought by me in 2008 or so very noticeably less well build but still ok. The ones we bought in 2018 or so are shit, especially the shelves are so thin that they begin to sag. In 2008 or so a friend of mine bought a \"kallax\" (another name then) and it was awesome, it's still in his basement and looks good. We bought one in 2023 and it's basically only paint, some \"wood\" and air. It's ok to store stuff in, but it's impossible to drill a screw into the wood. It's like trying to screw paper. reply atombender 13 hours agorootparentKALLAX used to be EXPEDIT. Both were made from honeycombed cardboard (mostly air, as you say) covered with very thin sheets of painted MDF. Maybe there was a time EXPEDIT was more solid, but I had one in the 1990s, and it was just like this. You can drill the thin wood in IKEA furniture like this, but you have to reinforce it. IKEA has always had a mix of wobbly instacrap and solid stuff. I remember they made a short-lived modular shelf called BRODER [1], which was solid steel and came in wall-mounted or freestanding configurations, the kind of solid thing you want in a garage or storage space. I was shocked at how high-end it was. It was discontinued to cost and low sales. [1] https://c2.staticflickr.com/4/3209/3641557199_eb0860e9eb.jpg reply HdS84 12 hours agorootparentThanks, that's fascinating. Ar least in my recollection, the expedit I knew was comparable to a Billy in wood density, but I might be mistaken - it's nearly twenty years. Funnily, the most sturdy piece of furniture we own is from Ikea. Two massive desks build from solid steel frames and a plate made with wood furnishing. Totally indestructible, weighs a ton and was made by Ikea in the 99s or so. Funnily enough, we didn't even know that they where from Ikea. We inherited them from my father in law and were cursing their weight like \"man I wish Ikea made this, than it would be easier to carry\". After dismantling them for transport we discovered various Ikea stickers. Sadly we don't know the model, just that they where manufactured by Ikea. The most endurable piece of furniture I know of is the kitchen of my mother in law. Made in the 70s or so it uses resopal finishing and the counters itself looks like new, despite years of heavy use and non stop smoking. reply AtlasBarfed 12 hours agorootparentprevKallax is cardboard? Those brilliant bastards. Honestly those cubes at least the 4x4 are perfectly fine. And cardboard is a hell of a lot more sustainable than solid wood and probably particle board reply maxglute 11 hours agorootparentKallax redesign thinned out outer walls of previous Expedite by 1cm so it looks closer to the thickness of the shelves and dividers. Also saves on a lot of material I imagine with the volumes involved. Also soften edges to be kid friendly and more scratch resistent finish. Cheaper, looks more aesthetically balanced IMO, and basically as statically strong holding stuff and doing furniture work. But thinner walls makes difficult/wobbly moving in larger 4x4, 5x5 variations. I had to cinched a band of webbing around the outside of the shelf during move to prevent it from falling apart. Gluing all the dowels/joints/connection also helps with strength a lot, but who has time for that. reply atombender 12 hours agorootparentprevStructurally they're fine, and can hold a fair amount of weight. Just treat them well; don't cut/drill into them or let them near water (the cardboard gets soft), don't overload them, and don't move/lift them while they're filled with heavy objects. While they're cheaply made, they're not among IKEA's worst products, I think. reply imp0cat 4 hours agorootparentYes, they are suprisingly versatile. Also, thanks to their low weight (aka \"cheapness\") they are easy to transport and assemble. reply munificent 9 hours agoparentprevIKEA is a fascinating outlier in this discussion. At some point in my twenties, I decided it was time to upgrade from my broke college student IKEA lifestyle which to me meant West Elm. Every thing I got from West Elm was absolute garbage and none of it lasted more than a handful of years. Now I'm in the prime of my career and could move up to something actually nice if I really wanted to, like Design Within Reach (truly the most ironic business name in existence). But it's just so hard for me to justify a 5x or more price jump, when, honestly, the IKEA furniture I have has been so good. I have a decade-old IKEA couch that is still in great shape despite surviving cats, dogs, young children, a snoring spouse who slept on it every night for about a year, and being mostly occupied throughout the entire pandemic. It's a tank, and still looks good to me. I think I've committed myself to having a style that is basically \"IKEA + some vintage stuff\" which seems to work well quality wise and is about an order of magnitude cheaper than getting new quality non-IKEA furniture. reply Wohlf 5 hours agoparentprevI've found Ikea furniture is great and lasts a long time as long as you don't move it to another apartment, that seems to really stress the joints and it will get rickety after 2-3 moves. reply IggleSniggle 15 hours agoparentprevYup, we've had the same IKEA furniture for 16 years now, it's still going strong. reply theGnuMe 15 hours agoparentprevIKEA is better then almost everything by Ashley home furnishings. reply denton-scratch 19 minutes agoprevNot a sofa; but I'm sitting in an Ecornes Stressless recliner. It's the best piece of furniture I've ever bought. It's made from \"engineered wood\", covered in quite good leather; I should have chosen a lower grade of leather, because hide isn't as easy to look after as some of the lower-grade leathers. FTR, I've bought sofas and armchairs from artisan/craftsman makers, from junk shops, and I've also bought cheap disposable shit. After the Stressless, my best buys were all from junk shops. But this Stressless, I more-or-less live in it. reply 180 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article points out the decreasing quality of modern sofas caused by cheaper materials and production methods, fostering a culture of disposable furniture.",
      "It suggests opting for vintage, high-quality pieces over trendy yet poorly constructed alternatives to combat this trend.",
      "The shift towards overseas production in the American furniture industry, especially in North Carolina, has led to a decline in local manufacturing jobs, prompting consumers to turn to vintage sofas for better quality and uniqueness."
    ],
    "commentSummary": [
      "Users have mixed opinions on the quality and durability of IKEA furniture, with some praising its longevity and others facing issues with materials like particleboard.",
      "Recommendations to enhance IKEA furniture durability involve opting for solid wood choices and meticulous assembly.",
      "Preferences for antique or high-end brands are expressed by some users for superior durability, with additional suggestions given for navigating IKEA stores and assembling furniture efficiently."
    ],
    "points": 423,
    "commentCount": 430,
    "retryCount": 0,
    "time": 1710435420
  },
  {
    "id": 39712618,
    "title": "Former Boeing Whistleblower Predicted Death; Family Friend Suspects Foul Play",
    "originLink": "https://abcnews4.com/news/local/if-anything-happens-its-not-suicide-boeing-whistleblowers-prediction-before-death-south-carolina-abc-news-4-2024",
    "originBody": "News Weather Current Weather Mount Pleasant Fair 58 83 54 Today 83 54 Saturday 80 61 Sunday 80 58 Latest Weathercast Interactive Radar Radar Maps Weather Cams Flight Info Hurricane Center Hurricane Maps Lowcountry Live Features Game Center Watch Now 58 Sat 80 Sun 80 'If anything happens, it's not suicide': Boeing whistleblower's prediction before death by Anne Emerson Thu, March 14th 2024 at 6:56 PM Updated Thu, March 14th 2024 at 7:58 PM 5 VIEW ALL PHOTOS John Barnett's family friend Jennifer doesn't think the Boeing whistleblower committed suicide in Charleston. In fact, she says he predicted what may happen to him days before he left for his deposition. March 14, 2024. (Provided-FILE, WCIV) ... CHARLESTON COUNTY, S.C. (WCIV) — A close family friend of John Barnett said he predicted he might wind up dead and that a story could surface that he killed himself. But at the time, he told her not to believe it. \"I know that he did not commit suicide,\" said Jennifer, a friend of Barnett's. \"There's no way.\" Jennifer said they talked about this exact scenario playing out. However, now, his words seem like a premonition he told her directly not to believe. \"I know John because his mom and my mom are best friends,\" Jennifer said. \"Over the years, get-togethers, birthdays, celebrations and whatnot. We've all got together and talked.\" READ MORE: \"Mystery lingers around Boeing whistleblower's death at Charleston hotel.\" When Jennifer needed help one day, Barnett came by to see her. They talked about his upcoming deposition in Charleston. Jennifer knew Barnett filed an extremely damaging complaint against Boeing. He said the aerospace giant retaliated against him when he blew the whistle on unsafe practices. For more than 30 years, he was a quality manager. He'd recently retired and moved back to Louisiana to look after his mom. \"He wasn't concerned about safety because I asked him,\" Jennifer said. \"I said, 'Aren't you scared?' And he said, 'No, I ain't scared, but if anything happens to me, it's not suicide.'\" Jennifer added: \"I know that he did not commit suicide. There's no way. He loved life too much. He loved his family too much. He loved his brothers too much to put them through what they're going through right now.\" Jennifer said she thinks somebody \"didn't like what he had to say\" and wanted to \"shut him up\" without it coming back to anyone. READ MORE: \"'John was brave': Boeing whistleblower's lawyer responds to news of his death.\" \"That's why they made it look like a suicide,\" Jennifer said. The last time Jennifer saw Barnett was at her father's funeral in late February. He was one of the pallbearers. Sometimes family and friends referred to him by his middle name – Mitch. \"I think everybody is in disbelief and can't believe it,\" Jennifer said. \"I don't care what they say, I know that Mitch didn't do that.\" Just because Barnett is dead doesn't mean the case won't move forward. His attorney said they're still prepared to go to trial in June. News 4 reached out to Boeing following Barnett's death. They provided the following statement: \"We are saddened by Mr. Barnett’s passing, and our thoughts are with his family and friends.” READ MORE: \"Boeing whistleblower dies in Charleston, Charleston County Coroner's Office confirms.\" Stay Connected Like Us Follow Us Newsletter Sign up /sign-up © 2024 Sinclair, Inc. TermsEEOFCCFCCPrivacy PolicyCookie PolicyCookie Preferences Loading ...",
    "commentLink": "https://news.ycombinator.com/item?id=39712618",
    "commentBody": "A friend of John Barnett said he predicted he might wind up dead (abcnews4.com)392 points by BostonFern 3 hours agohidepastfavorite242 comments Sebb767 3 hours agoJohn Barnett appears to be the recently deceased Boeing whistleblower, in case anyone else wonders. reply geek_at 3 hours agoparentWhile I can't see \"Boeing\" (as a whole command structure) can be blamed for his death I do see the possibility of some corrupt person in a high position fearing what he had on him personally and ordered a strike against him. reply KingOfCoders 3 hours agorootparentI worked for an eBay Inc. company as an executive, never thought that could happen https://en.wikipedia.org/wiki/EBay_stalking_scandal reply lukan 1 hour agorootparentNever heard of that before. What stands out to me is, that the executive person ordering it, Steve Wymer, was not charged at all, despite making very plain statements: \"Wymer texted Baugh that Ina Steiner was a \"biased troll who needs to be BURNED DOWN\"; that he wanted \"to see ashes\"; and that Baugh should do \"whatever it takes.\"\" I would imagine the same will happen here(if it was murder). Some pawns get executed, who \"missunderstood their orders\". Mafia bosses seems to operate like this as well. They don't give plain orders to kill someone. But their underlings know what is expected of them, by a certain nod or comment. reply publius_0xf3 1 hour agorootparent[Will no one rid me of this turbulent priest?](https://en.wikipedia.org/wiki/Will_no_one_rid_me_of_this_tur...) reply dylan604 1 hour agorootparentprevIt's always hard for that lone wolf to know if it's just a dog whistle or a true call to action. But I'm sure that's exactly the way it's intended to allow for plausible deniability. \"I never meant for someone to take me seriously. I was just venting. Locker room talk.\" reply namdnay 1 hour agorootparentprevhttps://www.youtube.com/watch?v=U6cake3bwnY reply KingOfCoders 1 hour agorootparentprevOnce in another company, the CEO told the legal counsel in a meeting, don't send me emails, do what is needed. reply dullcrisp 1 hour agorootparentprevI do wonder what happened there. CEO texts the chief communications officer that someone posting online needs to be taken down, chief communication officer takes that literally and relays the order to the head of security? reply lukan 1 hour agorootparentWell, how do you take down some blog, if there is no legal base for it, because all the content was obvious legal? If there would have been a legal angle, they would have send out lawyers letters instead. That was apparently not an option, so crime was the only way to go. And that no one at the top gets prosecuted for this, is quite disappointing. reply thecatspaw 1 hour agorootparentYou can still ask their hosting company to take down the content for example, or try to pay them off, or other things. Or since it was in the US make up some bogus claim and take them to court and hope they cannot afford court proceedings and fold. reply latchkey 1 hour agorootparentprev> Never heard of that before. https://news.ycombinator.com/item?id=38959248 reply DonHopkins 2 hours agorootparentprevI could certainly believe Boeing would do something like that before I'd ever imagine eBay would, yet eBay did what they did. The stakes are MUCH higher for Boeing, and we already know quite well that Boeing decided to put many human lives at risk to save money, and that's already resulted in many deaths. And they have a long history of making products designed specifically for killing humans. https://www.boeing.com/defense >This trusted partnership continues as defense customers once again look to Boeing to help them solve their toughest challenges. Faking a suicide isn't a particularly tough challenge. reply johnnyanmac 1 hour agorootparentI could never imagine eBay doing this in 2019. 2 bloggers really got a CEO this hot and bothered? Were they really causing that much of a hit to ebay's sales or rep? This sounds like one of those early 2000's trolling moments before such commentary conformed into a blob on modern social media. But given the rest of the events of the '20's I shouldn't be that surprised. reply themoonisachees 1 hour agorootparentprevBoeing also has very privileged relations with various three letter agencies. reply echelon_musk 59 minutes agorootparentIndeed. https://www.spiegel.de/international/germany/bnd-intelligenc... reply raizer88 2 hours agorootparentprevBoing is so entrenched with defence contractors that any one of them could have killed him to preserve existing contracts to be canned do to some \"deep restructuring\" due to the trial. reply hughesjj 1 hour agorootparentI really wish Boeing defense got spun off, them being under the same leadership is a threat to national security. The infection is only growing as they continue to share leadership. Could the union elect/nominate new leadership, or are they corrupt these days as well? reply otherme123 1 hour agorootparentCuriously, the Boeing branch that works for defense comes from the McDonell-Douglas buy: pre-merge Boeing main bussiness was comercial airplanes, MD was focused on military contracts. And arguably, all the current Boeing problems come from that buy/merge. reply hayst4ck 1 hour agorootparentprev> I really wish Boeing defense got spun off, them being under the same leadership is a threat to national security. Don't look at their board of directors unless you want to fully realize the magnitude of what you don't yet realize you're saying! reply jonathankoren 2 hours agorootparentprevKaren Silkwood died under very suspicious circumstances. She had documents that described Kerr-McGee lax safety at a plutonium fuel plant, that went missing after her car was found with damage to rear in an ostensibly single car front end fatal accident, along with a cocktail of illegal drugs. https://en.wikipedia.org/wiki/Karen_Silkwood reply buran77 7 minutes agorootparentWhen people think these things must be \"conspiracy theories, couldn't happen here, we're not Russia or China\", what they should think instead is how dire are the consequences and for whom. But that's impossible for a normal person to know or properly estimate. So they fall back to the original line of thinking. reply madaxe_again 2 hours agorootparentprevBoeing is also deeply entwined with state/political entities with a strong vested interest in preserving the status quo who may not be squeamish about direct action. Against the general backdrop of Boeing’s woes, suiciding a whistleblower is low-hanging fruit. Who knows. Maybe he has a deadman’s set up. reply XorNot 2 hours agorootparentContrary to popular belief, there is not a readily and highly available supply of assassins and hitmen in the world. The problem with this whole \"he totally didn't kill himself\" thing is...okay, so how did they kill him? Because you can't just put a gun in the hand of an unwilling person and force them to shoot themselves without leaving evidence. reply LudwigNagasena 2 hours agorootparentYou are talking about a company that participated in CIA kidnappings. Surely they can find a way. https://www.aclu.org/press-releases/aclu-sues-boeing-subsidi... reply ImHereToVote 2 hours agorootparentThe CIA and NED are way to interested in the wellbeing of Americans to do something so heinous. /s reply max_ 2 hours agorootparentprevI think you heavily under estimate what normal people motivated by money are capable of doing. In my friends highschool, some businesses guy was paying highschool kids (16 - 17 ish) to strangle car owners and steal their cars. They were later caught. Also, watch or read Killers of The Flowers Moon. The problem with planned murder is that it is all hidden, and the details are fuzzy. So there is alot of reasonable doubt. But trust me, there is alot do planned killing going on out there. reply didntcheck 1 hour agorootparentOut of interest do you have an article on the case at your friend's school? reply kashunstva 2 hours agorootparentprev> normal people motivated by money… strangle car owners and steal their cars… Those are not in any way normal people. If someone makes it to 16-17 y/o without acquiring that fundamental moral lesson, I would not characterize them as normal, whatever the cause of that failure. reply max_ 1 hour agorootparentI think what I meant was that they \"looked normal\". They were just attending classes like their class mates. It's not like they had a horns on thier head or walked around with pitchforks that made them obviously seem like killers. reply braymundo 1 hour agorootparentprevAgree, not normal. Then again, what percentage of high level executives or contractors with companies like Boeing are \"normal\"? reply whacko_quacko 1 hour agorootparentprev\"Normal\" means common here, and the fact that common people happily commit heinous acts is nothing new. E.g. the holocaust was comitted by \"normal\" people. Moral grandstanding won't change the fact that civilization is rather thinly veiling the violent ape in most of us reply psychoslave 35 minutes agorootparent>Moral grandstanding won't change the fact that civilization is rather thinly veiling the violent ape in most of us I don’t think civilization is a panacea here. To my mind, civilization is not exactly a strict synonym of peaceful generous enlightened humanism. Of course as a phenomenon it can encompass this kind of behavior, but just as well as it can help foster genocides, war and torture. Holocaust didn’t happen despite civilized minds, it happened specifically through a civilizational scheme. reply renewiltord 1 hour agorootparentprevAll There is to Know About Adolph Eichmann by Leonard Cohen EYES:……………………………………Medium HAIR:……………………………………Medium WEIGHT:………………………………Medium HEIGHT:………………………………Medium DISTINGUISHING FEATURES…None NUMBER OF FINGERS:………..Ten NUMBER OF TOES………………Ten INTELLIGENCE…………………….Medium What did you expect? Talons? Oversize incisors? Green saliva? Madness? reply bostik 3 minutes agorootparentBack in Finland I saw an incredible play: https://www.tinfo.fi/en/NPfF-Plays/48/I-Am-Adolf-Eichmann - the utter banality of the thing, how the convicted mastermind behind the genocide was \"merely solving ongoing logistical problems\". And how the trial turned into a massive media circus, likely letting a number of equally culpable war criminals off the hook. Turns out there is currently a fresh play in works that may have some of the same undertones: https://www.eventbrite.com/e/the-trial-of-eichmann-world-pre... thaithrowawayy 1 hour agorootparentprevWelcome to America and the education system :) reply dheavy 2 hours agorootparentprevCan you provide non-anecdotal evidences for your first statement? Because it's fairly easy to do so for the opposite statement. e.g. https://assassination.globalinitiative.net/monitor/ reply forgetfreeman 2 hours agorootparentprevNo but do you know what your average medical examiner makes? Professional hitmen might be rare af but bribing or otherwise pressuring local officials is pretty pedestrian. reply Thlom 1 hour agorootparentprevOne of the richest men in Norway cultivated a relationship with a torpedo and used his services on several occasions. It happens. reply vidarh 1 hour agorootparentAs a fellow Norwegian now living in the UK: That term is so archaic and unusual in English that odds are quite a few people won't know it at all (In 24 years in the UK I don't think I've ever heard it used) For the non-Norwegians: \"Torpedo\" in Norwegian has adopted the 1920s US slang for a hit man / hired gun, and in Norwegian it's in common, contemporary use, though more often for threats and violence than outright murder. reply vasco 2 hours agorootparentprevYou put the gun in their hands after you shoot them, as in every movie ever. reply sfn42 2 hours agorootparentFiring a gun leaves residue on your hands etc. They can tell whether you fired it reply vintermann 1 hour agorootparentSure, they can tell, if they look. But people with well-developed career instincts might not want to look. I think you overestimate how much the regular policeman, coroner etc. cares about truth for its own sake. Do you really want to pick a fight with Boeing? It's very easy to play Nelson and turn the blind eye. Making up a coherent narrative in a lie is hard. But the lie \"I didn't notice anything suspect\" is very safe. reply withinboredom 55 minutes agorootparentprevThey can tell whether you fired A gun, not necessarily that you fired that specific gun into your specific body. It's circumstantial evidence at best. Better evidence would be signs of a struggle or calculating bullet velocity to see if it came from the gun in that position. However, there are ways of doing this without actually causing a struggle. Wait for them to go to sleep; you could even give them some melatonin or something to make them drowsy. If it's in a car, put some nitrogen canisters on the A/C intake to make them pass out. If it is nefarious, there will be evidence somewhere. Whether you care to look for that evidence, know where to look for it or have the technology to find it ... that's another matter altogether. reply sethammons 1 hour agorootparentprevI'm not a trained killer, but I have watched some movies. To account for residue, just place the firearm in the corpse's hand, point in a random upward trajectory and pull back on the dead person's trigger finger. Optionally, replace the spent bullet in the gun's magazine. I feel you would have come up with this same solution had you needed to. reply temp-of-course 1 hour agorootparentthis works better with a blank. Take that shell and leave the one you actually used, of course. reply timschmidt 2 hours agorootparentprev> Contrary to popular belief, there is not a readily and highly available supply of assassins and hitmen in the world. See: Lake City Quiet Pills reply publius_0xf3 1 hour agorootparentLCQP has been conclusively proven to be some random guy inventing a character. https://www.youtube.com/watch?v=DHWYTwY0hiw reply eggdaft 2 hours agorootparentprevCitation needed for your first statement, certainly doesn’t rhyme true with what I hear in the UK. As for mocking suicide… I think you’d have to talk to a professional about what they do it. Given David Kelly, Epstein, and many other high profile cases, it does seem to be as difficult as you imagine. reply vidarh 1 hour agorootparentThe more \"interesting\" case in the UK was GCHQ analyst seconded to the Secret Intelligence Service (SIS/MI6) who supposedly killed himself by stuffing himself in a bag padlocked from outside, placed in a bathtub, and suffocating himself in a Security Service safe house. The inquest concluded his death was \"unnatural and likely to have been criminally mediated\" though with to little evidence to outright state it was an unlawful killing. The police eventually decided he'd likely locked himself in, despite the lack of fingerprints on both the bath and the padlock having made it a rather extraordinary feat for him to get into the bag and lock the padlock. Which to me goes to show that whether or not you get away with faking a suicide likely has relatively little to do with how well - or plausible - you fake the suicide vs. how well you sufficiently prevent a link to yourself and the power you have to prevent a proper investigation. At least in the case of David Kelly the circumstances were plausible. [1] https://en.wikipedia.org/wiki/Death_of_Gareth_Williams reply Charlie_32 2 hours agorootparentprevYeah where’s your evidence for this? reply j-krieger 1 hour agorootparentprev> Contrary to popular belief, there is not a readily and highly available supply of assassins and hitmen in the world What? There certainly are killers for hire in existence. reply hulitu 2 hours agorootparentprev> Contrary to popular belief, there is not a readily and highly available supply of assassins and hitmen in the world. https://en.m.wikipedia.org/wiki/List_of_assassinations_by_th... reply ImHereToVote 1 hour agorootparentThis is just a bunch of conspiracy theories. As in, a list of various government factions conspiring on various assassination campaigns. It's a good theory mind you. I would love to see evidence for the opposing theory. reply phpisthebest 2 hours agorootparentprevThere is a case where a woman \"stabbed her self\" 17 or so times, including in the back of the head and it was ruled a \"suicide\" It does not take much for a motivated medical examiner to rule a death a suicide, their are plenty of examples where clearly not suicide was been rule suicide in history. Then there is always the movie \"The Shooter\" where they had an arm contraption purpose built to force someone to \"commit suicide\", The device itself is plausible reply dudeinjapan 2 hours agorootparentprevHaven’t you ever played Assassin’s Creed? reply gonzo41 1 hour agorootparentprevTime for everyone to rewatch Michael Clayton. Boeing is a defense contractor. They'll have 'contacts'. reply jraby3 3 hours agoparentprevWouldn’t the time to have killed him be before he testified? reply vnchr 3 hours agorootparentHe was killed between pre-trial deposition interviews pertaining to a trial that is still upcoming.[1] One might speculate he was killed immediately after it was confirmed in a deposition that he had knowledge damaging to Boeing, and he intended to testify in that upcoming trial. [1] https://au.news.yahoo.com/boeing-whistleblower-john-barnett-... reply Kluggy 1 hour agorootparentI believe in certain cases, a judge may allow the deposition to be entered into evidence in the trial. The time to disappear someone is before their testimony is recorded. reply topspin 1 hour agorootparentprevIANAL. However: SC civil law Rule 32 USE OF DEPOSITIONS IN COURT PROCEEDINGS: (a)(3) The deposition of a witness, whether or not a party, may be used by any party for any purpose if the court finds: (A) that the witness is dead; or etc... This aligns very closely with the Federal rule on the same: Federal Rules of Civil Procedure Rule 32. Using Depositions in Court Proceedings (4) Unavailable Witness. A party may use for any purpose the deposition of a witness, whether or not a party, if the court finds: (A) that the witness is dead; etc... I can't tell which jurisdiction applies here because the news stories on the case itself are all hot garbage, I'm not trying that hard and IANAL, but my guess is it's the latter. Either way, the deposition(s) will likely get in. Now, anything can happen, but it's hard to imagine Boeing or whomever, knowing that the deposition(s) is likely admissible in the event of the death of Barnett, would then assassinate him. The cynic in me wonders if Barnett had recently learned his case was about to fall through for some reason we haven't learned of yet. [1] https://www.sccourts.org/courtReg/displayRule.cfm?ruleID=32.... [2] https://www.law.cornell.edu/rules/frcp/rule_32#:~:text=A%20d.... reply lupusreal 24 minutes agorootparentprevHe may have been killed not because his own testimony was a threat to Boeing, but rather to make other presently unknown potential whistleblowers think twice and decide to never come forward in the first place. Sending an implied threat to Boeing employees. For instance, any Boeing/Spirit employees who might be thinking about going to the FAA with information about who in management knew about and okayed the plug door \"opening\" scheme. Boeing surely wants the investigations to conclude that this is something no more than a few workers did of their own initiative and successfully hid from management, but that's probably not true. reply neffo 1 hour agorootparentprevThis still has a chilling effect. If it happened... ...actually it has a chilling effect even if it didn't happen to be honest. reply ZoomerCretin 3 hours agorootparentprevIf the goal is to scare others into silence, the timing is better when a suicide makes less sense. reply passion__desire 1 hour agorootparentI think Joe Rogan should have done a podcast with him just to hedge his bets and provide a publicity cover to John. reply dylan604 1 hour agoprevMight be a good idea to make these kinds of statements in a more public manner on the socials. @ing the company your commenting against as well as any local police, FBI, or other pertinent TLAs. Let the opposition know they are no longer operating in the shadows. Of course the TLAs won't actively do anything about it proactively, but maybe it'll give more credence than the grieving friend's say-so later??? Have it in writing notarized, and on display in the video you post. This isn't a Grisham novel from the 90s. It's much easier to document things today. reply ChooseClawBroad 1 hour agoparentThat's what ian murdock did, and yet.. reply ixaxaar 3 hours agoprevOh so in Russia its jumping out a window and in the USA its some random method of suicide? Why not be specific, and consistent, like Russia? reply snickerer 2 hours agoparentBecause in Russia it is an open message to the public 'don't mess with the KGB or we kill you and maybe your children'. Everybody knows and understands who is the sender and the message. Classic mafia move of intimidation. It is a message to the living. In the Western World the secret services kill to silence people, not to broadcast messages to the public. Quite the opposite PR strategy. reply roenxi 2 hours agorootparentAnd when powerful people want to show off their power it tends to be less fatal and more drag-through-the-mud style tactics. Like what happened to Julian Assange. Killing him was an option on the table as far as I recall, but it wasn't what they ended up doing. Although that being said, I wouldn't rule this out as being organised by Boeing's management or a major shareholder or something. It is a company in the military-industrial complex. reply lucioperca 1 hour agorootparentShould have given him protection, quite bad for the USA that they cannot let the truth succeed in this case. In the long term there is no cheating about safety possible anyhow. reply pydry 1 hour agorootparentprevAssange talked about his dead man's switch previously. If it weren't for that the powers that be probably would have Putined him. reply generic92034 1 hour agorootparentIs that plausible, though? Why would he not have used that leverage to prevent captivity? reply pydry 1 hour agorootparentI don't know. He never talked about a captivity switch. Perhaps he is an object lesson that one should create a \"switch escalator\". Perhaps a dead man's switch used in captivity could also potentially make captivity worse and remove what last remnants of hope he has. I suspect if he pulled the switch now then a lot of the sympathy he got for exposing a war crime might go out the window. reply generic92034 48 minutes agorootparentThe purpose of a dead-man switch is that an action automatically happens, if a person cannot trigger that action themselves anymore. This is not required in any kind of normal captivity, where the captured still can talk to lawyers and other visitors. So, frankly, if Assange is not using the leverage (using in the sense of using it as a threat) my best explanation so far is that he does not have any (at least not anything substantial enough). But I am open to be convinced otherwise. reply vintermann 54 minutes agorootparentprevEveryone with career sense in Russia will deny that, of course. They probably even believe it, in the sense that they're so indifferent to the truth of the matter that they don't even feel they are lying when they say the window-jumper was just a suicide and accusing FSB is preposterous. Maybe you'll find a few who will say, off the record, that of course it wasn't a suicide. But those people aren't rare in the US either! Feds are just as \"paranoid\" as the rest of in these matters. reply ak_111 39 minutes agorootparentprevThink this comment is a bit too naive on the western side. There are some high profile cases were the west (or the deep state) very clearly went \"full Russian\" on some figures to send a \"don't mess with us\" message. David Kelly and Epstein come to mind. As also noted in this thread Assange is arguably being given a fate worse than death, rotting in a dungeon an example to terrify whistleblowers around the world. Granted, it is only used much more sparingly than the KGB, but it is there. reply rawTruthHurts 1 hour agorootparentprev> In the Western World the secret services kill to silence people, not to broadcast messages to the public. Quite the opposite PR strategy. Yep. I totally didn't get the \"don't mess with big corps\" message at all. reply eggdaft 2 hours agorootparentprevI think also in the west you can’t be as blatant. There are checks and balances. Every murder invites journalistic investigation, so plausible deniability is important should things get out of hand. reply medo-bear 2 hours agorootparentprevExactly. People need to understand that the murding methods in the West are just so much more civilised and polite, otherwise they just might commit suicide reply wordhydrogen 3 hours agoparentprevJust speculating here but isn’t jumping out a window in Russia usually an implication it was ordered by the Russian state (ex: FSB) while in the US a framed suicides are assumed to be done by numerous non-associated actors. So in one place a single entity is responsible and in another it’s multiple entities. It doesn’t seem surprising to me that there would be an affinity towards a particular method within entities. reply lostlogin 2 hours agorootparent> jumping out a window Or a poisoning with a ludicrously rare poison, a strange car crash, a plane falling out the sky, dying at a gulag when you were fine a few days earlier etc etc. It’s a very unsafe place when you don’t toe the line. reply card_zero 2 hours agorootparentTechnically I don't think Navalny was fine a few days earlier, I understood that he had ongoing poor health due to, uh, being previously poisoned. reply pydry 1 hour agorootparentprev>It’s a very unsafe place when you don’t toe the line. Very much like America, apparently. The part where plenty of people express skepticism that theses death were really suspicious seems to be similar too. reply whacko_quacko 1 hour agorootparent> Very much like America, apparently. No. America isn't in the habit of regularily murdering dissidents reply lostlogin 1 hour agorootparentIs anyone refuting this? It’s hardly a wild claim. reply whacko_quacko 1 hour agorootparentDid you read the parent? reply dijit 2 hours agorootparentprevthat's what the parent is saying. reply tarruda 1 hour agoparentprevWith Yevgeny Prigozhin, the method was ingestion of surface-to-air missile: https://babylonbee.com/news/leader-of-failed-russian-uprisin... reply lupusreal 15 minutes agorootparentGive the alternative methods known to be used by the Russian government, Prigo's assassination almost seems like a sort of royal treatment. reply threatripper 2 hours agoparentprevOne might deduce a number of factions offering those services from clustering the methods used. reply ZoomerCretin 2 hours agoparentprevWe don't know that this was the result of a state actor. It could also have been someone who bought a ton of Boeing calls before the safety scandals. reply pavlov 2 hours agorootparent> “It could also have been someone who bought a ton of Boeing calls” Now I’m imagining a show set in Greenwich, Connecticut, where a gentle white-haired family man trades options during the day and manages assassinations after the kids go to bed. “The Americans” meets “The Big Short”? reply jiggawatts 18 minutes agorootparentI would binge watch that. reply DonHopkins 2 hours agorootparentprevI hope they cast esteemed character actress and fugitive from the law Margo Martindale as the hitwoman! https://www.youtube.com/watch?v=Lvyzv-G5q3w reply ImHereToVote 1 hour agorootparentprevOk bro. Whatever helps you sleep at night. reply orwin 2 hours agoparentprevDGSE (French secret service) really like to drown people, so avoid cities with canals and/or river if you feel you can be a target :) reply littlestymaar 1 hour agorootparentInteresting, I had never heard of that before. Do you have references that I could read on the topic? reply orwin 1 hour agorootparentIt's tongue in cheek, we kill in many different ways. Drowning related however, the most known is this one (even got a wiki page, so it's really well known!) en.m.wikipedia.org/wiki/Robert_Boulin But Choukri Ghanem also managed to drown himself in Vienna. A related death was Albichari, a 37 yo dying of diabetes, and 6 years later, Bechir Saleh assassination attempt by a commando (with his bodyguard crew saving him), so the DGSE clearly have multiple ways of doing business. reply karambahh 5 minutes agorootparentSmall nitpick, if (which is very likely to me but unfortunately hasn't been proven) Robert Boulin has been murdered, it's definitely not by the DGSE or it predecessor, as they operate outside of France. If you agree is that it's not a suicide, opinions differ on whether it's government team that did it or the \"SAC\", a paramilitary group linked to the then ruling party, not an official secret service reply DonHopkins 2 hours agoparentprevNot random. In Russia, they blame it on an open window in a tall building. In America they blame it on a black guy with a gun. Man in Sioux Falls, South Dakota shoots himself in penis and tries to blame black guy: https://www.independent.co.uk/news/world/americas/man-shoots... ‘We failed the city of Boston’: how a racist manhunt led to chaos in 1989: https://www.theguardian.com/tv-and-radio/2023/dec/07/we-fail... Blake Masters blames Black people for gun violence. But remember, he's no racist: https://eu.azcentral.com/story/opinion/op-ed/laurieroberts/2... reply littlestymaar 1 hour agorootparentWhile racism is indeed a very acute issue in the US, I don't see what it has to do with anything in this thread… reply fragmede 1 hour agorootparentsaying \"a black man did it\" is being used in America as the same sort of explanation for a death as \"fell out of an apartment window\"in Russia. its racist as hell, but it's a plausible cover story over what really happened. reply johnohara 2 hours agoprevThese kinds of things happen and the waters immediately get murky. Even those closest to the person in question are never really 100% sure. Reminds me of the death of journalist Michael Hastings in 2013. https://en.wikipedia.org/wiki/Michael_Hastings_(journalist)#... Richard Clarke's assessment seemed to carry the weight of truth. But only to a point. Just enough to engage the suspicions of family and friends, but no more. Same for John Barnett. reply whimsicalism 1 hour agoparentIn my view, almost all of these are accidents or suicides and people watch way too many hollywood films. The Hastings thing is classic mania for those of us who know people who have experienced that. reply regentbowerbird 1 hour agorootparentBut people _do_ die when exposing corruption of the rich. Such as Daphne Caruana Galizia and Ján Kuciak for the Panama papers. Would you call their deaths \"hollywood films\"? And it'd be natural to think killers would try to hide their traces, such that most such deaths would look like an accident or suicide. reply whimsicalism 27 minutes agorootparentI am more skeptical of the perfect staging to make it look like a suicide theory. Both of those killings were in pseudo-mafioso states. Both were also immediately recognized as murder. State-sanctioned murder of your own citizens on your own soil is a lot less commmon in a country like the US, although there are well as Mafia and organized crime murders. But I think successful staging as a suicide is uncommon outside of Hollywood and repressive governments. reply asdfgjkl 49 minutes agorootparentprevJust a correction, Kuciak wasn't killed for Panama Papers, but regular investigative journalism into the corruption of the rich (your point still stands). reply lukan 34 minutes agorootparentprevI wouldn't be so sure. I dropped that point of view, after I read about the Lucona incident in europe and all the dirt behind it: https://en.wikipedia.org/wiki/Lucona Which lead me to: https://en.wikipedia.org/wiki/Operation_Gladio \"According to several Western European researchers, the operation involved the use of assassination, psychological warfare, and false flag operations to delegitimize left-wing parties in Western European countries, and even went so far as to support anti-communist militias and right-wing terrorism as they tortured communists and assassinated them\" Opened a whole box of pandora for me. So I rather think there is much more dark shit going on, than what makes the news, we just see the tip of the iceberg. And not just about the big players. Probably also common people have way more corpses in their basements, than what you would expect, if you grew up in a safe space. reply whimsicalism 31 minutes agorootparentDefinitely stuff going on that does not make the news, but a lot of people also just commit suicide, swear to their friends and family they wont, and do it anyways. But there is a world of difference between doing this as a small business owner vs. a massive publicly traded company. reply lukan 23 minutes agorootparentTrue, most things are also much more mundane and boring, than what people would expect. No hidden 5 layers of conspiracy are deployed everywhere. But that now still reminds me of: \"A Report on the Banality of Evil\" by Hanah Arendt about Eichmann and a holocaust trial. reply yieldcrv 1 hour agorootparentprevyeah the other issue with these things are that they are unlimited statements and indefinite in length \"look this person wrote on twitter 2 years ago that it won't be suicide\" hm. a solution I imagined for this was some sort of point cloud emitting off of everyone's body, so we would have a point cloud based rendering of what happened near someone, could reveal a lot about human interactions reply kromem 3 hours agoprevIt seems like that's said very often before whistleblower or journalist deaths subsequently ruled a suicide. reply eastbound 3 hours agoparentThey don’t even know the details of the weapon, but in the minute of it being published, they claimed to know it was “self-inflicted”. reply gruez 3 hours agorootparentMaybe the authorities do know and it's simply not published/released? After all, assuming he shot himself and the gun is right there, it seems fairly reasonable to tentatively presume it's self inflicted. reply defrost 2 hours agorootparentAssuming he shot himself, yes, it would generally follow that it's self inflicted. I'm unable to think of anyway in which someone can shoot themselves and not have it described as \"self inflicted\", even an accidental self shooting would be described by some in either form. However, in general, with a gunshot wound and and a gun discarded right there some people might not assume that it was self inflicted and perhaps check for handedness, gunshot angle, residue, etc. before leaping to any premature assumptions or conclusions. reply Gumbledore 2 hours agorootparentThat wouldn't matter. If they really want to send a message, you get suicided with two shots to the back of the head. Having the entire media apparatus complicit in gaslighting the public into accepting absurdity is all part of the demonstration of power and demoralisation ritual. reply gruez 2 hours agorootparentSo which one is it? So far as I can tell he didn't get \"suicided with two shots to the back of the head\", but despite that you still think the media is complicit in \"demonstration of power and demoralisation ritual\"? reply aydyn 2 hours agorootparentIt's not a contradiction. There are levels. reply rymiel 1 hour agorootparentprevHow did he get the gun? Didn't he have to travel for the proceedings? reply fl7305 52 minutes agorootparentAccording to one news report, he was found in his own truck. If that is correct, he could easily have brought it with him from his home. reply phpisthebest 2 hours agorootparentprevYes we all know the authorities do a terrible job of actual investigation instead jumping to assumption, speculation, and \"gut\" of their \"experience\" to intuit the \"truth\" of the matter with out any logic or reason.. Presuming and Assuming when it comes to a death investigation is often the start of how innocent people go to jail reply zer00eyz 2 hours agoprevYea... SO if you really feel this way you say this to every reporter you see. You write it down and give it to your lawyer. Your wife. Your kids. You put copies in the safety deposit box. You give notarized copies to every 3rd homeless person you meet. You don't just tell one friend. reply politelemon 2 hours agoparentThis is a poor take. People don't find themselves in this situation normally and we should not be expecting them to have TV-murder-mystery style hypervigilance. reply zer00eyz 1 hour agorootparent>> TV-murder-mystery style hypervigilance. The tv-murder-mystery plot where Boeing killed him and he told ONE friend is much more likely? Anxiety, PTSD, and a hand gun. This is a recipe for a suicide attempt that succeeds from a purely statistical point of view. reply lukan 42 minutes agorootparentMost people do not like to be drama queens, that might also be a possible reason, he did not shouted it out to the world. Also, it is of course possible, to plan suicide and still tell people it won't be suicide. We all lack the details here. But since Boeing is involved with military and intelligence work who do not like traitors(whistleblowers) in general and have the expertise in covert murder, I think murder is a valid theory that should be really investigated by a neutral agency. reply steve_adams_86 1 hour agoparentprevIt depends a lot upon how certain he was of the risk. He might have said it to a friend as an expression of anxiety or fear, not recognizing how pressing the threat really was. A lingering worry might not motivate someone to be diligent about a post-assassination alibi. reply reedf1 1 hour agoparentprevI would think that you are implicitly stating your want to live by the fact you are alive. Also - would all that really move the needle? Surely the only way is 24/7 surveillance. Even then I'm sure there are remote methods of execution that seem natural... reply whimsicalism 1 hour agorootparentso all suicides are murders? reply pindab0ter 2 hours agoparentprevThis is the rational thing to do, yes. I'm not sure I would've thought of getting that notarised myself. reply asah 1 hour agoparentprevAlso, you record your testimony. reply mort96 2 hours agoparentprevI mean he could just not have expected to be murdered? If you're a whistleblower and truly expect there to be a high chance you get suicided, sure, you tell as many people as possible, but if it's not something you think is likely to happen, just telling one friend seems reasonable. reply silisili 3 hours agoprevThis happens way too often, and I'm genuinely curious why. The easy answer is that paranoid people with a vendetta say exactly this to throw guilt onto the other party. The hard answer is harder to swallow. What can we do about it? reply gruez 3 hours agoparent>This happens way too often 1. What some other recent occurrences? 2. What's the baseline rate of suicides we should expect for people in high stress positions, like being a whistleblower? How many people could plausibly be categorized as \"whistleblowers\"? reply silisili 2 hours agorootparentI knew this would come up, but couldn't think of specifics other than I've seen it go by on social media seemingly yearly. I vividly remember one two or three years ago, of an Asian man I think in NYC who kept videoing the police calling them corrupt, telling the world if he died it was the police. Well, he died. The police said it wasn't the police. Sadly, I can't find this Googling. I'd say it's happened enough to become a meme. When people post controversial things about big companies or politicians, people will reply telling them to make a video to say they aren't suicidal. * Well some people aren't happy with my handwavy answer, so here are a few https://fresnopeoplesmedia.com/2016/01/2829/ https://www.nbcnews.com/news/us-news/home-explodes-washingto... https://www.hindustantimes.com/world-news/us-news/who-was-ja... (same case, some context) https://www.irishtimes.com/life-and-style/people/jeffrey-eps... reply publius_0xf3 1 hour agorootparentThe Asian victim you're thinking of is Sunny Sheu. https://en.wikipedia.org/wiki/Death_of_Sun-Ming_Sheu reply bmer 2 hours agorootparentprevOne prominent one in recent memory is the Epstein \"suicide\". Aaron Swartz is another, although not so recent. reply whimsicalism 2 hours agorootparentTo me it still seems more likely than not that these people committed suucide, especially Swartz. reply hughesjj 1 hour agorootparentI mean, I think Schwartz committed suicide, but Epstein? reply 4ggr0 2 hours agorootparentprevJohn McAfee? EDIT: Not saying that I believe it or care, but even wiki mentions it. Thought it would fit the other mentions... > McAfee's death ignited speculation and conspiracy theories about the possibility that he was murdered. Such speculation was particularly fueled by a 2019 post McAfee made on Twitter that read, in part, “If I suicide myself, I didn't. I was whackd [sic].”[133] > Several times, McAfee claimed if he were ever found dead by hanging, it would mean he was murdered.[137] The day after his death, his lawyer told reporters that while he regularly maintained contact with McAfee in prison, there were no signs of suicidal intent.[138] McAfee's widow reaffirmed this position in her first public remarks since her husband's death, and also called for a \"thorough\" investigation.[139][140] https://en.wikipedia.org/wiki/John_McAfee#Death reply gruez 1 hour agorootparentIn this case there's at least the motive for Boeing to kill him. But in McAfee's case what's the motive for killing him? It seems like the only one going after him was the US (for tax evasion charges). He was already going to be extradited. Why kill him at that point? reply fragmede 1 hour agorootparentWe don't know. But I can imagine that when the rich American that comes into your country and has very young girls as his girlfriends ends up in jail, and you're a local and get very involved with that situation, that there's going to be a lot of drama. maybe one of those girls was your lover or is your sister. and then there's drug business happening. the guy ends up in jail, which means he gets to go home to America and never face consequences for what he did to your family? It's not hard to imagine why he was murdered. we'll never know the true story but whatever it is, I'm sure it's a good one. He wasn't killed over not paying his us tax bill. reply 4ggr0 1 hour agorootparentprevThe only thing I can come up with is this tweet: https://twitter.com/officialmcafee/status/113777734891968102... It mentions the CIA, that must've been it!!!! /s > I've collected files on corruption in governments. For the first time, I'm naming names and specifics. I'll begin with a corrupt CIA agent and two Bahamian officials. Coming today. If I'm arrested or disappear, 31+ terrabytes of incriminating data will be released to the press. reply publius_0xf3 38 minutes agoparentprevThere's another \"easy\" answer: friends and family of the deceased make up these claims, because they want to ensure a thorough investigation of any potential homicide to put their suspicions to rest and so make it look as suspicious and scandalous as possible in the public eye. Not saying that's what happened here, of course. reply drewcoo 1 hour agoparentprev> This happens way too often, and I'm genuinely curious why. It's probably what you're paying attention to. There are lots of shocking occurrences that most people don't notice. Or don't want to notice. Death is among the things we'd rather not think about. Unseemly death more so. Consider how many US military deaths are suicide every year. https://dcas.dmdc.osd.mil/dcas/app/summaryData/deaths/byYear... Or how many people are killed by police in the US every year. https://en.wikipedia.org/wiki/Lists_of_killings_by_law_enfor... Or consider that suicides are more common than either firearm or car crash deaths. https://deadorkicking.com/death-statistics/us/per-year/ reply hello_computer 2 hours agoparentprevIt is the way of the world. Television, magazines, social media, etc do their best to conceal it, but it is always there in the background. It boils down to power. Boeing can make fighter jets, I can't. This is where the socialists err. \"If we just take their money!\" They'll make it all back within the year. \"If we just had a law!\" They'll buy legislators, bribe judges & law enforcement. If that doesn't work, they'll kill people. The public will clutch its pearls over this, for a while anyway, then promptly forget. The only solution is to remember and to retaliate on an individual basis (stop the wars, don't fly, shun execs, boycotts). And not just until they relent, because they are machines, and have no conscience. Do this until they hit the pink sheet, and then keep doing it. reply SturgeonsLaw 1 hour agorootparentI'd say this is where the socialists are right, because they're actually saying we should take the means of production reply codetrotter 1 hour agoprevThe OP link https://abcnews4.com/news/local/if-anything-happens-its-not-... has two different cookie consent banners on top of each other and on iPhone using Safari I can’t scroll down to click any buttons to dismiss the banners which cover the screen. Screenshot of unreadable page: https://i.imgur.com/LNjbgK5.png I’m in Europe, maybe that’s why they are serving me the page with these overlays. Thankfully however, archive.today is able to identify those kinds of overlays in many cases and remove them, including for this page. Readable archive link: https://archive.is/lgFFJ reply MaxikCZ 25 minutes agoparentThats an easy signal from the page to me that they really dont want me to read their content, so I just dont. There is 0 need for a cookie for me reading an article, so 0 need for a cookie disclaimer/consent box. reply IncreasePosts 1 hour agoprevThese statements would only be meaningful if suicidal people couldn't say them. No one ever seems to invest in a security system, or a gun, when they make these statements. Why? reply User3456335 1 hour agoparentBro, where do you get your food? Do you grow it in your house? Where do you get your water from? Hell, where do you get your air from? How do you think getting a security system fixes it? reply aydyn 2 hours agoprevEvery single person in the previous thread who ridiculed others for saying that suicide was _not_ the most likely explanation needs a serious re-evaluation of their priors. reply hoffs 2 hours agoparentStress and pressure can lead to performing actions that you thought you couldn't do. They don't specify how early this event took place but mentions that deposition was yet to take place. So a lot could have changed after that as there's kind of no turning back. reply DonHopkins 1 hour agorootparentAre you talking about John Barnett killing himself, or Dave Calhoun ordering the hit? Your argument applies to both. reply code_runner 1 hour agoparentprevalso everyone saying they wouldn’t avoid certain planes and there is so much redundancy that little simple non-aviation folks shouldn’t worry themselves. We’ve got a fishy death, no documentation on the door plug, and more incidents. reply b-side 1 hour agoparentprevI don't think people are misaligned on the P(suicide) it is just due to the recent behaviour of Boing that P(murder|Boing) is elevated. reply dijit 2 hours agoprevinteresting that Sinclair media would run this story. That ironically means its less likely to be US gov related. reply notorandit 2 hours agoprevThey need to investigate among investors. They will find surprises... A lot of surprises. reply windowshopping 3 hours agoprevThis is kind of mind-blowing to me. First case in my lifetime where a US corporation appears to have murdered someone for political reasons. Has this happened before? I assume it has but it's very rare. reply regentbowerbird 51 minutes agoparentNot a US corporation but when it came to light that French defense contractor Thomson-CSF (now Thales) had bribed Taiwan official to award them a defense contract, no less than six whistleblowers died, three of them defenestrated; most famously Thierry Imbot, who fell from the fourth story closing his window shutters on a windy evening, supposedly the night before he was to meet a journalist. reply gruez 2 hours agoparentprev>First case in my lifetime where a US corporation appears to have murdered someone for political reasons Is there anything supporting this theory other than the fact the death benefits Boeing? reply timthelion 2 hours agorootparentHe was shot and there aren't any double blind studies that prove that police are capable of reliably distinguishing self inflicted wounds from non-self inflicted wounds. reply lostlogin 2 hours agorootparentIt’s a bit dark, but the idea of trying to get ethics approval for a study of this sort had me laugh. reply siriaan 2 hours agorootparentWell a university in New Zealand got the ok to blast pigs in the head with a Glock for a blood spatter study - https://www.rnz.co.nz/news/national/284438/how-did-shooting-... reply fl7305 48 minutes agorootparentprevIf you are an organ donor, it will surprise you what kind of research is done using corpses. For example, \"body farms\". reply tsimionescu 2 hours agorootparentprevThe article we're commenting on, where a friend attests he was told explicitly that any \"suicide\" is fowl play. Sure, it's nowhere near \"beyond a reasonable doubt\", but it's plenty, together with the obvious motive, to form an opinion. reply gruez 2 hours agorootparent> The article we're commenting on, where a friend attests he was told explicitly that any \"suicide\" is fowl play. Isn't there obvious reporting bias here? People typically don't go around saying \"btw I'm going to kill myself, if that happens assume it's not foul play\", so it shouldn't be too surprising that people kill themselves even though they said they wouldn't. Moreover people who actually tell people they're going to kill themselves likely will receive intervention (eg. suicide watch/hospitalization), which further drives up the relative rate of people committing suicide \"unexpectedly\". reply hnfong 2 hours agorootparentIf you dismiss all the evidence \"supporting this theory\" (your words) then obviously you wouldn't find anything that supports it. Evidence does not have to be perfect. Even biased evidence should update your priors. There is evidence supporting this theory. It doesn't mean it is definitely true. reply gruez 1 hour agorootparent> If you dismiss all the evidence \"supporting this theory\" (your words) then obviously you wouldn't find anything that supports it. Right, and the converse is you accepting any evidence that vaguely conforms to the narrative of \"he got killed by boeing\", regardless of how shaky it is. >Evidence does not have to be perfect. Even biased evidence should update your priors. There is evidence supporting this theory. It doesn't mean it is definitely true. This feels like a motte and bailey. You claim that we should update our priors even based on biased evidence, but I never claimed otherwise. My previous comment merely pointed out the issues with taking statements like \"if anything happens don't assume it's a suicide\" at face value. Moreover the comment I was replying to wasn't merely claiming that we should update our priors, it was that the evidence in question was \"plenty, together with the obvious motive, to form an opinion\". That's a much stronger claim. reply hnfong 1 hour agorootparent> Right, and the converse is you accepting any evidence that I literally said one must update their priors, not just \"accepting\" it. Or maybe updating priors is a form of \"acceptance\", but now you claim it isn't a problem: > You claim that we should update our priors even based on biased evidence, but I never claimed otherwise The comment you replied to just answered your question: \"is there anything supporting this theory\". Presumably everyone here knows basic Bayesian probability, or at least knows how to weigh supporting evidence without just blindly accepting it. Claiming otherwise seems to be rather uncharitable interpretation of the comment you replied to. reply renewiltord 1 hour agorootparentWatching people with binary-valued probability measures talk to people with multivalued probability will never not be amusing. The resulting conversations have such fundamental disagreements. reply pdpi 2 hours agorootparentprev> fowl play You probably meant foul play. \"Fowl\" means chicken-y (galliformes) or duck-y (anseriformes) birds. reply dataflow 2 hours agorootparentFowl play was what the DoJ suspected when they were investigating the chicken industry. reply georgespencer 2 hours agorootparentprev> fowl play It's \"foul\" play. > Sure, it's nowhere near \"beyond a reasonable doubt\" To the extent that I do not think it would even be admissible in court in many (all?) states. Hearsay, not under oath, not cross-examinable. Just as possible she misunderstood the dark joke of an obviously suicidal and self-reflective man as people like you and me at Boeing literally arranged to have someone killed lmao. I can basically only think of more plausible explanations: coincidental victim of murder, suicidal due to stress of whistle-blowing, witness misheard, witness misunderstood, witness made it up… I can really hear the bottom of the barrel being scraped around here lately. reply georgespencer 2 hours agorootparentprevIt's far more likely that he simply changed his mind after making the statement attributed to him than it is Boeing would arrange for him to be murdered five years after the fact. reply saulpw 2 hours agorootparentNot \"Boeing\" in its official capacity, but it has a lot of executives and shareholders, only one of which needs to have the hubris to think they can get away with it. That seems a lot more likely. reply georgespencer 2 hours agorootparentYes with their stock at a near record low for the decade, now is certainly the time for Boeing's largest shareholders (Vanguard and Blackrock) to take decisive action by inexplicably murdering someone five years too late to make a difference, and who - if left alive - could have potentially been the single most effective means for the shareholders to take revenge on the executives responsible for the company's demise. Jesus christ. reply windowshopping 2 hours agorootparentprevI did say \"appears,\" but this is some Epstein levels of \"coincidence.\" I'm not really a conspiracy-theory type, but I mean c'mon. Does anyone believe that Epstein killed himself? Makes me think of this little stand-up comedy snippet. https://www.reddit.com/r/StandUpComedy/comments/14rcr7n/cons... \"I understand not believing in most conspiracy theories, but NONE? You really think the government's batting 100? They ain't lying about ANYTHING?\" reply publius_0xf3 1 hour agorootparent>Does anyone believe that Epstein killed himself? Yes, I do. Like you, I found the circumstances of Epstein's death incredibly suspicious and thought it was a murder. But the more information that has come out, the more it looks like it was a typical prison suicide. [The latest AP article](https://apnews.com/article/jeffrey-epstein-jail-suicide-pris...) is pretty good. >Two weeks before ending his life, Jeffrey Epstein sat in the corner of his Manhattan jail cell with his hands over his ears, desperate to muffle the sound of a toilet that wouldn’t stop running. reply georgespencer 2 hours agorootparentprevIf you believe Epstein was murdered you are in a tiny, tiny, tiny minority of very gullible or very simple minded people. Upon a cursory review of both the facts of the matter and the very best arguments conspiracists can copy and paste, it is self-evident that he killed himself. reply ummonk 2 hours agorootparentAnd the cameras just happened to be out of order when he chose to kill himself of course. reply ImHereToVote 1 hour agorootparentIt's easy when your world view hinges on the fact that responsible adults are running the world. reply alexey-salmin 1 hour agorootparentprevHow is it self-evident? I agree that evidence of a murder is not conclusive but evidence of a suicide is virtually nonexistent. What facts in this case are consistent with suicide but not with murder? reply blackhawkC17 2 hours agorootparentprev> Does anyone believe that Epstein killed himself? Yes, I believe that Epstein was a coward who took the easy way out rather than face repercussions. If it was a grand conspiracy, why is Ghislaine Maxwell (Epstein’s partner-in-crime) still alive in prison? reply chii 2 hours agorootparent> Ghislaine may be she just knew less incriminating shit. Could also be that one death as an example, to keep her in line from saying anything too incriminating (against somebody who's capable of orchestrating a prison \"suicide\"). reply optimalsolver 2 hours agorootparentprev>Does anyone believe that Epstein killed himself? Yes. People of high status frequently take their lives when they realize everything's gone down the drain. reply hughesjj 1 hour agorootparentOn suicide watch, with both guards asleep and the cameras out? reply gruez 2 hours agorootparentprev>\"I understand not believing in most conspiracy theories, but NONE? You really think the government's batting 100? They ain't lying about ANYTHING?\" \"government lying about something\" =/= \"my pet conspiracy theory is true\" The government was responsible for the Tuskegee Syphilis Study, but that doesn't mean the covid vaccines contains 5g nanobots or whatever. reply hughesjj 1 hour agorootparentI hope that, at a minimum, this gets the government to realize/reaffirm how destructive it is to them when they do shit like this reply carabiner 2 hours agorootparentprevIt doesn't benefit Boeing because of all of this brainless conspiracy thinking, and his allegations over the past 5 years had nothing to do with the current 737 MAX stuff. It was all 787 related which by all reports has been a successful, safe aircraft. The horse has been out of the barn, his words were reported in the NYTimes years ago. Assassinating him now had no upside for Boeing and large downside because of all this predictable inane speculation. reply doodlebugging 2 hours agoparentprevKaren Silkwood comes to my mind.[0] Kerr McGee whistleblower back in the 1970's. Maybe not your lifetime but definitely in mine. [0] https://en.wikipedia.org/wiki/Karen_Silkwood reply otherme123 49 minutes agoparentprevThere's mounting evidence that someone could had dismissed safety to get more profits, and then some planes fell off the sky. That could escalate to involuntary manslaughter quickly. reply Qem 1 hour agoparentprevCoca-Cola ordered some Colombian workers killed. See https://en.wikipedia.org/wiki/Sinaltrainal_v._Coca-Cola_Co%2... reply dboreham 2 hours agoparentprevSee: Octopus murders. reply pulse7 2 hours agoparentprevThe mafia took over the Boeing Corporation... reply dotancohen 2 hours agorootparentMcDonnell Douglas are hardly the Mafia. reply sedatk 2 hours agoprevNo. If you’re concerned that you might get murdered, and want to make it clear that you have no intention of killing yourself, telling your one friend about it in a conversation in the midst of moving a sofa with no records to prove it whatsoever is the worst possible way of doing it. Tweet it, send it in a message, leave a note in your home. But, “hey push that side, and let’s lift this in 3..2…. oh by the way I have no intention of killing myself… 1… go! There you go”. No. That doesn’t check out. Even if that conversation actually took place, it’s not helpful at all because it’s so easy to dismiss as hearsay. That’s actually a curse you put on your friend if it really happened. EDIT: Apparently, the aforementioned help in the article was being a pallbearer at the friend’s father’s funeral. That turns out to be a less and less proper conversation for the occasion. reply switch007 2 hours agoparentWhile evaluation of someone's behaviour to work out the truth is a valid endeavour, I find people have a tendency – and I notice it often in our community – to expect perfect rationality in humans at all times. I guess as it makes it easier to criticise them. People who are stressed, sick, anxious, depressed etc often operate more on emotion and in aa reactive way rather than with foresight, clarity and rationality. reply sedatk 55 minutes agorootparentI mean, yes, but when we take irrationality into account, we can't discount the irrationality of saying \"if it's suicide, it's not me\" to a friend, and then committing suicide right after. My point isn't about what he supposedly did made sense or not, but what he did was completely useless if true, and even debating it is useless now because of the way it was done. That's why I mentioned how he cursed his friend with that. reply xeornet 1 hour agoparentprevSo you’ve never made a comment about something in passing that turned out to be true? Completely reasonable for this to be said in conversation with a friend but not taken seriously enough to write it down. reply sedatk 55 minutes agorootparentI'm not arguing that at all. See my comment here: https://news.ycombinator.com/item?id=39713557 reply Jomus 2 hours agoparentprevrealest comments get no love reply max_ 1 hour agoprevReading the comments here is now making me even more skeptical about society. It really looks like; It is a waste of time to take risk yourself and expose unethical practices conducted by the powerful. Because, A) The masses don't really care (I expected riots and protest). B) You may mysteriously die. C) Your death instead of sparking an outrage will mostly be labeled a \"conspiracy theory\". Given these three items, I can very confidently predict this in the future. 0. We shall have less exposés. 1. Corporations and other powerful entities will engage in more unethical behaviour. Due to majority of worker being spinless and complicit to corner cutting and other unethical practices. 2. Powerful entities will know they can get away with evil if they leave enough blanks in the engagement. Since the masses will label these as conspiracy theories. And they will be stuck in these academic \"plausible deniability\" kind of foggy minds. With this, I expect powerful entities to get away with more evil deeds. In a crowd of a hundred, 50 percent of the wealth, 90 percent of the imagination, and 100 percent of the intellectual courage will reside in a single person—not necessarily the same one. — Bed of Procrustes reply sebstefan 1 hour agoparent> Due to majority of worker being spinless and complicit to corner cutting and other unethical practices. I think companies that might end up doing that kind of stuff first off cultivate that culture. Either in their entire company, or with the people who are going to engage with criminal activities. Security people, upper management, ... Like in the ebay case linked above https://en.wikipedia.org/wiki/EBay_stalking_scandal#Stalking... I'm not sure we can deduce that most employees of the corporate world are cynical and unethical from just individual cases like this reply eternauta3k 47 minutes agoparentprev> Due to majority of worker being spinless Are you seriously accusing most employees of being pions? reply pulse7 2 hours agoprevMaybe Boeing is part of \"National Security\" and they are allowed to do anything with anyone... reply darkhorn 2 hours agoparenthttps://youtu.be/YjVdq5tJSto?si=3u16AEx9tll_uga9 > Obama: I'm Boeing's second biggest salesman reply d--b 2 hours agoprevOk there are conspiracy theories, making claims about things that are unlikely. And then there is the key witness that dies in a parking lot by gunshot wound the day before he is to testify on the case he spent decades building. And then there is his friends who swears that he wouldn’t commit suicide. Call me crazy all you want, but murder is the most probable theory here. The money interests are massive. People kill for tens of thousands of dollars. We’re talking millions of dollars here. reply gruez 2 hours agoparentThe \"case\" in question is a defamation suit he initiated against Boeing. This has nothing to do with the recent 737 MAX incidents, and the 787 issues he did whistleblow on was litigated to death years ago. reply michaelmrose 2 hours agoparentprevBillions. Its annual profit not revenue is 7.7B a 10% decrease in revenue this decade is worth 7.7B and a 10% decrease in valuation is worth 11B reply carabiner 2 hours agorootparentYeah a single employee's testimony against an aircraft, the 787, that has safely flying every day since then, does not have that effect. Especially when all of that Barnett testified on years ago. Boeing does not make $7B from the 787. If you want to take someone out, make it a 737 MAX whistleblower. reply 317070 1 hour agorootparentThey didn't know who was going to be the 737 MAX whistleblower. The whistleblower might not have known himself. But the 737 MAX whistleblower was also taken out yesterday. reply littlestymaar 1 hour agorootparentprevHow could Boeing make sure to limit the amount of whistleblowers on the 737 MAX case? Killing former whistleblowers is a great way to send a message to everyone considering the option right now. reply jack_riminton 2 hours agoprevIf he suspected he was going to be knocked off I wouldn't be surprised if he had recorded or wrote down somewhere all the damming evidence he had reply avereveard 2 hours agoparentif he suspected he was a target why didn't he buy some home surveillance equipement reply dotancohen 2 hours agorootparentMaybe he did? He was found dead in a vehicle in a hotel parking lot. reply jl6 1 hour agoprevAs a conspiracy theory, this still lies beneath the surface of hard evidence, but perhaps is now upgraded from benthic to pelagic. reply justinzollars 2 hours agoprevcould be foreign meddling too. reply treprinum 2 hours agoprevIt's pretty brutal if nobody cares about the optics of this anymore, just kill off whoever is inconvenient. I guess after Epstein's \"two cameras malfunction\" nobody cares about any public backlash and there is \"normal day in Russia\" to be inspired from... reply hnfong 1 hour agoparentWhat public backlash? It seems people here are content to call those who suspect Epstein suicide \"very gullible\"... It's interesting how the English language labels people \"conspiracy theorists\", like how the totally batshit crazy ones gets lumped together with those that actually seem to be suspect. reply logicchains 1 hour agorootparentIt's not the \"English language\", the term \"conspiracy theorist\" was literally invented by the CIA to smear people who alleged the CIA was conspiring against the public. reply defrost 1 hour agorootparentThat's a conspiracy theory: The term \"conspiracy theory\" is itself the subject of a conspiracy theory, which posits that the term was popularized by the CIA in order to discredit conspiratorial believers, particularly critics of the Warren Commission, by making them a target of ridicule. [..] The idea that the CIA was responsible for popularising the term \"conspiracy theory\" was analyzed by Michael Butter, a Professor of American Literary and Cultural History at the University of Tübingen. .. and that analysis concluded \"yeah, nuh\". https://en.wikipedia.org/wiki/Conspiracy_theory#Origin_and_u... reply hilux 2 hours agoprevMaybe he was killed by the agents of whoever. I have no non-public knowledge about this. On the other hand, if you were obsessed with some conspiracy theory, were feeling suicidal, and wanted to create maximum effect with your death ... \"it's not suicide\" is exactly what you'd say. reply dukeofdoom 2 hours agoprevManaging complexity is complex. I can't imagine how complicated building an airplane is. If the top people are not being retained, then problems will follow. Sometimes it's just one genius (Von Braun) that moves an entire field forward. reply sundvor 3 hours agoprevConsidering how many deaths Boeing are responsible for through their blatant ineptitude, I wonder how far a stretch it would be that this one was indeed intended. reply ImpassionataVox 3 hours agoprevnext [13 more] [flagged] ImpassionataVox 3 hours agoparentnext [13 more] [flagged] lionkor 3 hours agorootparentI dont think you're being reasonable, which sucks because I believe you gave a good point underneath all that reply ImpassionataVox 2 hours agorootparentTHEN SAY THE GOOD POINT ELSEWHERE OR STFU reply colechristensen 3 hours agorootparentprevIf you had a point that you expressed without rambling anger, you might have a place. Go somewhere else if you want to express yourself like that, plenty of other places for that kind of attitude. reply ImpassionataVox 1 hour agorootparentyour attitude is extremely concerning reply ImpassionataVox 3 hours agorootparentprevnext [9 more] [flagged] toast0 3 hours agorootparentHow are we supposed to pay for our own healthcare if we can't have 1M in assets? You'll make us all slaves, you will. reply promiseofbeans 3 hours agorootparentprevMate that's everyone with a house reply Rebelgecko 2 hours agorootparentThe easiest way to have equality is to make everyone homeless reply anon-sre-srm 3 hours agorootparentprev$2m+ for San Jose retirees with Prop 13. $300m houses and every billionaire are absurd and policy failures. Correct without over correcting/ping-ponging between anarcho libertarianism and communism should be the goal. reply _puk 3 hours agorootparentprevDr Evil has entered the room [0]! \"Don't you think we should ask for maybe more than a million dollars\" 0: https://m.youtube.com/watch?v=EJR1H5tf5wE reply itake 3 hours agorootparentprevA lot of people would lose their homes if $1m usd was the limit. reply com2kid 3 hours agorootparentprevThat is every farmer. That is almost every small business owner. That is most people with a house in large cities. I need to save up $350,000k for my kid's college before he heads off to keep him from having any loans, that means people with two kids who fully fund college for their kids will have $700k in assets just in college savings[1]. Saving for retirement takes 3-4 million. 1 million was a lot of money back when I was a kid in the 90s, now not so much. [1] College prices are truly obscene. reply blackhawkC17 3 hours agorootparentprevThen watch the economy tank when the state now owns everything. reply dustedcodes 2 hours agoprevJohn Barnett, Jeffrey Epstein, Alexei Navalny, those suicides and bad health episodes always happen when it suits powerful people. reply anon-sre-srm 3 hours agoprev [–] Perhaps: A. Most people dismiss an actual conspiracy to murder a whistleblower witness as a conspiracy theory automatically. Such a cliché seems possible. Remember, Boeing is run by MD dickhead bros who traded in camel fucking magazine covers. B. He wanted additional scrutiny on Boeing, and was willing to die for it. C. Friend is seeking attention. It will require honest and diligent investigation to be sure it was truly suicide because none of us know from afar. C seems most likely. reply vmttmv 2 hours agoparentAny other alternative should surely be dismissed immediately in the land of the brave and home of the world police, the bonafide benefactors. reply XorNot 2 hours agoparentprev [–] Option 0: people tend to be blindsided when someone in their life suffering from depression kills themselves. This is because if you see it coming, usually you go all out to intervene. It is ridiculously common for people to report that someone who seemed like they enduring mental hardship \"was doing better\" in the days before their suicide. I'm finding the immediate \"it was an an assassination\" rhetoric gross and unproductive here, because what it's dismissing is a very real problem: becoming a whistleblower tends to ruin people's lives between the media scrutiny, the legal scrutiny, the career jeopardy and being in and out of court rooms. Marriages breakdown, and people get depressed or develop substance problems. \"He was assassinated\" is just casually ignoring the fact that Boeing can kill this man dead completely legally through the normal shitshow which is the legal wringer whistleblowers get put through. reply anon-sre-srm 2 hours agorootparent [–] Duh. I mentioned A to dismiss it rather than invite inevitable conspiracy theories. His lawyers came out almost immediately claiming he seemed in good spirits. Perhaps this was a superficial assessment or he was hiding his true feelings. Like I said, wait until the investigation is complete because we don't know. It seems like the friend and media are grabbing attention rather than doing anything constructive. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Former Boeing whistleblower John Barnett predicted his death before passing away, with his family friend suspecting it was not a suicide.",
      "Barnett previously raised concerns about Boeing's unsafe practices and feared retaliation for speaking out.",
      "The case against Boeing continues despite Barnett's death, and Boeing has expressed sadness over the situation."
    ],
    "commentSummary": [
      "The conversation delves into suspicious deaths, conspiracy theories, and controversies related to whistleblowers, corporations such as Boeing, and prominent figures like Jeffrey Epstein.",
      "It encompasses concerns about foul play, safety, ethics, skepticism of official stories, and the importance of investigations and safeguarding individuals who expose powerful entities.",
      "Additionally, the discussions explore societal standards, the concept of evil's ordinariness, and the difficulties whistleblowers encounter while uncovering malpractice."
    ],
    "points": 391,
    "commentCount": 242,
    "retryCount": 0,
    "time": 1710484359
  },
  {
    "id": 39706004,
    "title": "Automate Browser Tasks with Skyvern's LLMs and Computer Vision",
    "originLink": "https://github.com/Skyvern-AI/skyvern",
    "originBody": "Hey HN, we&#x27;re building Skyvern (https:&#x2F;&#x2F;www.skyvern.com), an open-source tool that uses LLMs and computer vision to help companies automate browser-based workflows. You can see some examples here: https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#real-world-examples-of... and there&#x27;s a demo video at https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern#demo, along with some instructions on running it locally.We provide a natural-language API to automate repetitive manual workflows that happen within the companies&#x27; backoffices. You can check out our code and play with Skyvern here: https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;SkyvernWe talked to hundreds of companies about things they do in the background and found that most of them depend on repetitive manual workflows. The breadth of these workflows surprised us – most companies started off doing things manually, and eventually either hired people to scale the manual work, or wrote scripts using Selenium-like browser automation libraries.In these conversations, one common point stood out: scaling is a pain either way. Companies relying on hiring struggled to adjust team sizes with fluctuating demand. Companies using Selenium and similar tools had a different problem: it can take days or even weeks to get a new workflow automated, and then would require ongoing maintenance any time the underlying websites changed because their XPath based interaction logic suddenly became invalid.We felt like there was a way to get the best of both worlds with LLMs. We could use LLMs to reason through a website’s layout, while preserving the advantage of traditional browser automations allowing it to scale alongside demand. This led us to build Skyvern with a few core functionalities:1. Skyvern can operate on websites it’s never seen before by connecting visible elements with the natural language instructions provided to us. We use a blend of computer vision and DOM parsing to identify a set of possible actions on a website, and multi-modal LLMs to map the natural language instructions to the available actions on the page.2. Skyvern is resistant to website layout changes, as it doesn’t depend on any predetermined XPaths or other selectors. If a layout ever changes, we can leverage the methodology in #1 to complete the user-specified goal.3. Skyvern accepts a blob of information when navigating workflows—basically just a json blob of whatever information you want to put, and then we use LLMs to map that to information on the screen. For example: if you&#x27;re generating a quote from Geico, they commonly ask “Were you eligible to drive at 21?”. The answer could be inferred from the driver receiving their license in 2012, and having a birth date of 1996.The above strategy adapts well to a number of use cases that Skyvern is helping companies with today: (1) Automating materials procurement by searching for, adding to cart, and transacting products through vendor websites that don’t have APIs; (2) Registering accounts, filing forms, and searching for information on government websites (ex: registering franchise tax information for Delaware C-corps); (3) Generating insurance quotes by completing multi-step dynamic forms on insurance websites; (4) Automating the job application process by mapping user-specified information (such as a Resume) to a job posting.And here are some use-cases we’re actively looking to expand into: (1) Automating post-checkup data entry with patient data inside medical EHR systems (ie submitting billing codes, adding notes, etc), an (2) Doing customer research ahead of discovery calls by analyzing landing pages and other metadata about a specific business.We’re still very early and would love to get your feedback!",
    "commentLink": "https://news.ycombinator.com/item?id=39706004",
    "commentBody": "Skyvern – Browser automation using LLMs and computer vision (github.com/skyvern-ai)345 points by suchintan 17 hours agohidepastfavorite124 comments Hey HN, we're building Skyvern (https://www.skyvern.com), an open-source tool that uses LLMs and computer vision to help companies automate browser-based workflows. You can see some examples here: https://github.com/Skyvern-AI/skyvern#real-world-examples-of... and there's a demo video at https://github.com/Skyvern-AI/skyvern#demo, along with some instructions on running it locally. We provide a natural-language API to automate repetitive manual workflows that happen within the companies' backoffices. You can check out our code and play with Skyvern here: https://github.com/Skyvern-AI/Skyvern We talked to hundreds of companies about things they do in the background and found that most of them depend on repetitive manual workflows. The breadth of these workflows surprised us – most companies started off doing things manually, and eventually either hired people to scale the manual work, or wrote scripts using Selenium-like browser automation libraries. In these conversations, one common point stood out: scaling is a pain either way. Companies relying on hiring struggled to adjust team sizes with fluctuating demand. Companies using Selenium and similar tools had a different problem: it can take days or even weeks to get a new workflow automated, and then would require ongoing maintenance any time the underlying websites changed because their XPath based interaction logic suddenly became invalid. We felt like there was a way to get the best of both worlds with LLMs. We could use LLMs to reason through a website’s layout, while preserving the advantage of traditional browser automations allowing it to scale alongside demand. This led us to build Skyvern with a few core functionalities: 1. Skyvern can operate on websites it’s never seen before by connecting visible elements with the natural language instructions provided to us. We use a blend of computer vision and DOM parsing to identify a set of possible actions on a website, and multi-modal LLMs to map the natural language instructions to the available actions on the page. 2. Skyvern is resistant to website layout changes, as it doesn’t depend on any predetermined XPaths or other selectors. If a layout ever changes, we can leverage the methodology in #1 to complete the user-specified goal. 3. Skyvern accepts a blob of information when navigating workflows—basically just a json blob of whatever information you want to put, and then we use LLMs to map that to information on the screen. For example: if you're generating a quote from Geico, they commonly ask “Were you eligible to drive at 21?”. The answer could be inferred from the driver receiving their license in 2012, and having a birth date of 1996. The above strategy adapts well to a number of use cases that Skyvern is helping companies with today: (1) Automating materials procurement by searching for, adding to cart, and transacting products through vendor websites that don’t have APIs; (2) Registering accounts, filing forms, and searching for information on government websites (ex: registering franchise tax information for Delaware C-corps); (3) Generating insurance quotes by completing multi-step dynamic forms on insurance websites; (4) Automating the job application process by mapping user-specified information (such as a Resume) to a job posting. And here are some use-cases we’re actively looking to expand into: (1) Automating post-checkup data entry with patient data inside medical EHR systems (ie submitting billing codes, adding notes, etc), an (2) Doing customer research ahead of discovery calls by analyzing landing pages and other metadata about a specific business. We’re still very early and would love to get your feedback! dtnewman 15 hours agoI tried it out and it's pretty pricey. My OpenAI API bill is $3.20 after using this on a few different pages to test it out. Not saying I wouldn't pay that for some use cases, but it would limit me. One idea: making scrapers is a big pain. But once they are setup, they are cheap and fast to run... this is always going to be slower. What I'd love to see is a way to generate scrapers quickly. So you wouldn't be returning information from the New York City property registry... instead, you'd return Python code that I can use to scrape it in the future. edit: This is likely because it was struggling, so it had to make extra calls. What would be nice is a simple feature where you can input the maximum number of calls / tokens to use on the entire call. Or even better, do some math and put in a dollar cap. i.e., go fill out the Geico forms for me and don't spend more than $1.00 doing it. reply suchintan 14 hours agoparentI love all of these ideas!! 1. You can set a \"max steps\" limit when you run it locally https://github.com/Skyvern-AI/skyvern/blob/d0935755963b017ed... We also spit out the cost for each step within the visualizer. Click on any task > Steps > there's a column that's dedicated to how much things cost to run https://github.com/Skyvern-AI/skyvern/issues/70 2. We have a roadmap item to \"cache\" or \"memorize\" specific tasks, so you pay the cost once, and then just run it over and over again. We're going to get to it soon!! reply suchintan 14 hours agorootparenthttps://github.com/Skyvern-AI/Skyvern/?tab=readme-ov-file#fe... reply keremyilmaz 14 hours agoparentprevYou've raised valid points about the cost and efficiency of our approach, which aims to make the LLM function as closely as possible to a human user. We chose this approach primarily for its compatibility with various websites, as it aligns closely with a website's intended audience, which is typically human. Addressing complex website interactions is a key advantage of this approach. For instance, in the process of generating an auto insurance quote, the sequence of questions and their specifics can vary greatly depending on prior responses. A simple example is the choice of a foreign versus a California driver's license. Selecting a foreign license triggers additional queries about the country of issuance and expiry date, illustrating the complexity and branching nature of such web interactions. However, we recognize the concerns about cost and are actively working on strategies to reduce it: - Optimizing the context provided to the LLM - Implementing caching mechanisms for certain repeated actions and only use LLMs when there's a problem - Anticipating advancements in LLM efficiency and cost-effectiveness, with the hope of eventually finetuning our own models for greater efficiency reply dinobones 11 hours agorootparentThere are two things here: 1) Using the LLM to find elements/selectors in HTML 2) Use LLMs to fill out logical/likely/meaningful answers to things I highly recommend you decouple these 2 efforts. While you gave a good example of \"insurance quote step by step webapp\", the vast majority of web scraping efforts are much more mundane. Additionally, even in this instance, the selector brain/intelligence brain don't need to be coupled. For example: Selector brain: \"Find/click the button for foreign drivers license.\" Selector brain: \"Find the country of origin field.\" Selector brain: \"Find the expiry date field.\" LLM-intelligence brain: \"Use values from prompt to fill out the country of origin and expiry date fields.\" Not-LLM intelligence brain: Inputs values from a JSON object of documentSelector=>value. reply suchintan 10 hours agorootparentInteresting. We've decoupled navigation and extraction for specifically this reason, but I suppose decoupling selector with input could let us use cheaper smaller LLMs to \"select\" and answer We've been approaching it a little bit differently. We think larger more capable models would actually immediately improve the performance of Skyvern. For example, if you run it with LLaVa, the performance significantly degrades, likely because of the coupling But since we use GPT-4V, and it's rumoured to be a MoE model, I wonder if there's implicit decoupling going on. I'm gonna spend some more time thinking about this reply bravura 9 hours agorootparentI still think you're missing the point. The idea is that you should use vision APIs and LLMs to build traditional browser automation using a DSL or Python. I don't want to use vision and LLMs for every page. I just want to use vision and LLMs to figure out what elements need to be clicked once. Or maybe every time the site changes the frontend. reply suchintan 9 hours agorootparentThis is a great point. This is something already on our roadmap. We call it \"prompt caching\", but I realize writing this that it's a terrible name. Will update! (https://github.com/Skyvern-AI/Skyvern?tab=readme-ov-file#fea...) Thank you for this feedback reply pmontra 2 hours agorootparentThe AI would be a compiler that generates the traditional scraper / integration test. It would save all that long time spent going manually thought every page and figuring out which mistake we did, when that input string doesn't go into that input field or the button on the modal window is not clicked. Change the UI? Recompile with the AI. reply bravura 2 hours agorootparentI didn’t check the code but there would be a few good ways to specify what you want: * browser extension that lets you record a few actions * describing what you want to do with text * a url with one or two lines of desired JSON to extract reply dtnewman 14 hours agorootparentprevI like this approach. Just as an example, if I'm getting a car insurance quote, I'd rather pay $1 to have the tool fill out the forms for me and be 90% that it filled them out correctly rather than pay $0.01 and only be 70% sure it did it correctly. And there are plenty of use cases like that. reply Kerbonut 28 minutes agorootparentYou would still be willing to pay $1 if it got it wrong 10% of the time, or if it got 10% of the information wrong every time? reply amne 12 hours agorootparentprevisn't that crazy rabbit thingy supposed to do just that? I hope you pre-ordered. I hear they're in great demand. reply daniel_iversen 6 hours agorootparenthttps://www.rabbit.tech/research reply daniel65464 6 hours agoparentprevInteresting enough I made a chrome extension that does almost exactly what you are describing. It’s called automize and it lets you very quickly generate custom selectors and export the code to puppeteer, playwright, selenium etc. it handles all the verifications as well as provides a handy ui that shows what you are selecting reply bigfatfrock 8 hours agoparentprev> instead, you'd return Python code that I can use to scrape it in the future Bravo, I would pay for this one, or hopefully run it on my GPU - it would be so fast to even just shove out your selectors (xpath, css, dealer's choice) for point-by-point update after you had done an initial code gen, or perhaps it could just diff and update chunks of code for you! My local code model can already do the diff update stuff in nvim, but being able to pass it a URL and have it slam in all of the pertinent crawling code, wow. reply tmountain 14 hours agoparentprevJust piggybacking here, but this is a great suggestion. It makes the cost a one-time expense, and you get something material (source code) in return. reply jumploops 13 hours agoparentprevScrapers are one of the main use cases we're seeing for Magic Loops[0]. ...and you've hit the nail on the head in terms of our design philosophy: use LLMs to generate useful logic, then run that logic without needing to call an LLM/Agent. With that said, we don't support browser automation. Skyvern is very neat, it reminds me of VimGPT[1], but with a more robust planning implementation. [0] https://magicloops.dev [1] https://github.com/ishan0102/vimGPT reply suchintan 13 hours agorootparentNice! Thanks for sharing this. We tried approaches like VimGPT before but found the rate of hallucinations to be a bit too high to be used in production. The sweet spot definitely seems to be to combine the magic of Dom parsing AND vision We're going to definitely work on logic generation and execution, but we're taking it a bit more carefully. Many of the workflows we automate have changing workflow steps (ie I've never seen the exact same Geico flow twice), but this certainly isn't true for all workflows reply umaar 12 hours agorootparentprevReally like the simplicity of your website. I think when you first announced it, you mentioned you might open source Magic Loops, might you do that? reply jumploops 10 hours agorootparentYes! We’re in the middle of cleaning things up, just need to make the Loops a bit more portable/easy to run, but finally happy with the state of the tool. reply anhner 2 hours agorootparentThis brings me so much joy! Thank you for considering this! reply enlyth 11 hours agoparentprevIt's getting genuinely difficult these days with everything walled behind Cloudflare, various anti-bot protections and increasingly creative CAPTCHAs reply kilroy123 11 hours agoparentprevYes, exactly what I want. I want to be able to have it code robust Cypress tests for e2e testing. reply James_K 11 hours agoprevGod this is depressing. Not the product itself, but the need for it. That software has failed to be programmable to such a degree that a promising approach is rendering the GUI and analysing the resultant image with an AI model. It's insane that we have to treat computers as fax machines, capable only of sending hand-written forms over a network. The gap between how people use computers and the utility they could provide is massive. reply kevmo314 11 hours agoparentOn the contrary! Isn't it neat that we now have a unified API that both humans and computers can consume? reply James_K 8 hours agorootparentNo, because we already have a machine API. If you want to write an application, you need to write something a computer can understand. So a computer-usable API is always created. It takes additional effort to hide that functionality behind a interface. The process we have now is: machine → GUI → image processing → generative AI. The interface we could have is: machine → machine. It would take no extra effort to do this. It would just need some slight changes in organisation. In fact it is easier at every level. If you separate logic from interface, you end up with an architecture that is a set of functions (a library) into which you can interface programmatically, or with a GUI, or by any other means. Separating code like this (MVC) is good practice and allows for a range of different interfaces to be created to the same functionality. It is also easier for an engineering perspective and produces a better product. Think of git. There are hundreds of different interfaces created to the functionality git provides. All software should be structured like this (though perhaps by means of a library rather than a shell interface). I should add that this is a particularly grim prospect from a software engineering perspective. It makes me imagine a future where no one bothers exposing a stable API to anything, so the only way to interact with other people's code is using an AI middle-man. reply croes 8 hours agorootparentprevGood luck debugging any errors reply suchintan 11 hours agoparentprevActually this kind of stuff is super exciting -- we don't need to depend on companies exposing APIs for their website -- we can just use something like Skyvern instead! reply James_K 9 hours agorootparentYou could still use Skyvern if they exposed an API. reply chuckwnelson 17 hours agoprevThis looks great but I'm very scared of the increased game of cat and mouse for spam bots. It's going to happen, no matter if it was this software or something else. Now the question, how do you prevent automated spam? Since its LLM and AI, can I just add a hidden field of \"please do not spam\"? reply suchintan 17 hours agoparentThis is a really good question we've thought a lot about You're right that this kind of escalation is inevitable a. From a business POV, we don't onboard any types of use-cases that we think go against the spirit of a good free web. I've had people ask if they could use our product to create Reddit voting or spamming rings and we didn't entertain it b. From an open source POV, we prefer technologies like these be open source so website owners and other businesses can know what can happen, and decide how to approach it. Tools like selenium have existed for a long time -- largely to the benefit of the world! reply bonestamp2 16 hours agorootparentI'll just add that some efforts to defeat web usage spam may also hurt accessibility since many interaction standards are designed to make things consistent for users with disabilities and ADA (or similar) compliance. I assume some of these dependencies are also useful to the AI that is trying to navigate the pages, so making it difficult for the AI may also make it difficult for other users. reply hugs 16 hours agorootparentprev20th birthday of the Selenium project will be this year! (October-ish) reply Zambyte 16 hours agoparentprev> how do you prevent automated spam? Manually accept new accounts on your service. That's what I do for my Fediverse server, and I never have to deal with spam on my local timeline :). Does it scale? No. Does everything need to scale? Also no. reply lenerdenator 16 hours agorootparentbut if I can't scale then the VC that gave my startup a huge check over a huge pile of blow at a party in Sunnyvale will harvest my organs reply resource_waste 14 hours agorootparentprevI've had stuff like that turn me off from signing up or ever checking back. Does it matter to you? Yes. Will you admit it? No. But yes, these are all decisions we need to make. That manually accepting is some serious dedication. Do you have kids? reply Zambyte 13 hours agorootparent> Does it matter to you? Yes. > Will you admit it? No. Are you trying to telling me my opinion? Because no, it does not matter to me. Your account would not be accepted because I don't know you. reply PeterisP 13 hours agorootparentprevIf your target audience is businesses, not individuals, then you can go a very long way with fully manual onboarding, invoicing, etc. It's different for things like consumer services or e.g. forum users, but why couldn't you manually vet every business your business trades with? reply schappim 6 hours agoparentprevI'm not good at finding fire hydrants either. reply MattGaiser 16 hours agoparentprevI am not aware of anyone really successfully, defeating spam at the moment. I mod a 1 million+ Facebook group and they can’t even prevent someone from making 200 posts in a minute with the word “crypto” in it. The word list will flag it, but the spam filter won’t. Reddit constantly has people messaging you in chat about “opportunities.” Email is a disaster. My personal blog has over 100,000 spam comments sitting in the filter so at least they were caught, but processing them is impossible. reply suchintan 15 hours agorootparentI've heard of a lot of success sifting through email spam using custom gmail scripts + GPT-4. Kind of interesting that we can use LLMs to both create and detect spam to some degree of effectiveness reply cute_boi 16 hours agoparentprevthe only way to prevent spam is charge appropriate money, I don't see other solutions. Thats why many company use credit card to verify users. But, with virtual cards, they have some ability to spam, but not so much. reply crotchfire 15 hours agorootparentThis. If you charge enough, the spammers become valuable customers. Of course they tend to leave before that point, but you don't really care if they leave or stay; you make money either way. Value for value. reply dinobones 16 hours agoprevRoughly how much does it cost to run to scrape a page? I see from the code this is basically an OpenAI API wrapper but you make no mention of that anywhere on your landing page/documentation, nor any mention of which LLMs this is capable of working with. Also, an idea is to offer a \"record\" and \"replay\" mode. Let the LLM run through the instructions, find the selectors, record and save them. Then you can run through again without using the LLM, replaying the interaction log, until the workflow breaks, then re-generate the \"interaction log\" or whatever. reply suchintan 16 hours agoparentThis is a great call-out. It's something currently in our roadmap Re: cost for execution. This really depends on the page, but currently it costs between 5 cents and 20 cents per page to execute (today). We have an improvement planned to help it \"remember\" or \"cache\" actions it's done in the past so it can just replay them and bring the cost down to near zero. Re: LLMs it's capable of working with, currently it's only GPT-4V. I'll get this updated soon! reply pstorm 15 hours agoparentprevBased on #2, it seems like they only use the LLM when the page changes. I had a prototype of this sort of system working and it was surprisingly fault tolerant. reply pkiv 16 hours agoparentprevIf you want to build it yourself, you could try using https://browserbase.com/. We offer managed headless browsers work everywhere, every-time. It costs $0.10 per browser session/hour (billed minutely). Feel free to shoot me an email if you want access! paul@browserbase.com reply dvngnt_ 16 hours agoprev> Skyvern understands how to solve CAPTCHAs to complete complicated workflows this seems like this could be used for abuse. the CAPTCHAs are specifically designed to stop botting on 3rd party websites. or this will just be another cat and mouse game where the next level of CAPTCHAs get more annoying and invasive to verify we are human reply wutwutwat 4 hours agoparenteveryone seems to forget that stopping bots with google captcha was never the main goal... humans have been training google's ai models for a decade or more each and every time they answered a captcha at any rate, if someone wants to abuse your site, captcha, and even cloudflare won't help you > the next level of CAPTCHAs get more annoying and invasive to verify we are human like the solving puzzles ones? Or more advanced object identification, like selecting the correct orientation? Training more advanced AI now reply lm411 10 hours agoparentprevUnfortunately, CAPTCHA's are already easy for bots to bypass or solve. There are quite a few services that will solve them in a few seconds, costing less than a dollar per 1000 solved tokens for most common CAPTCHA's (e.g ReCAPTCHA v2 and v3). I recently had to deal with an attacker doing credit card testing that was using one of these services. Related, I came across this last week, bypassing ReCAPTCHA with Selenium/Python/OpenAI Whisper API: https://www.youtube.com/watch?v=-TMNh64ubyM reply worldsayshi 15 hours agoparentprevIt seems to me that the logical conclusion for captcha is to connect it indirectly to electronic id. This could be done in a privacy respecting way. You could get some token from the website. It could include encrypted service name and policies, like rate limit, that the authority should enforce. The client passes the token to the eId authority. The authority signs it and adds timestamp, but no user info. Client gives token to the service. Something like that. This is a bad top of mind example. I think we'll need to rely a lot more on eID in the future. I think it can be done in a good way but then it needs to be thought through before it gets adopted. And we have to be able to trust the eId institutes. reply hirako2000 15 hours agorootparentBut it's the same problem all over again, spammers would get an id, auth, then spam. Anti spams are about detecting whether activities are spam. Binding an identity, is the naive mechanism that makes us think spam wouldn't happen. All it does is say ok we know it's pug35372 that teared the linens apart. We can put all measures to authenticate users, won't makes them not potentially bots running havoc right after a manual authentication. There are even farms, manually created accounts by gig seekers who would fill forms, email and phone number verification for less than a dollar. reply suchintan 15 hours agorootparentprev2FA and logged-in experience is sort of a proxy for eID. I suspect that's why so many companies require that you log in with something that knows your identity (log in with google), or ask you for your phone number to confirm your account reply suchintan 15 hours agoparentprevAgreed. We didn't open source this functionality on purpose, and are very very specific about what use-cases we onboard that require it. That being said, we've gotten to learn a lot more about browser fingerprinting and captcha solving and it's a really interesting space. If you're curious about it, check out this blog post: https://antoinevastel.com/bot detection/2018/01/17/detect-chrome-headless-v2.html reply chadash 15 hours agoprevFirst of all, wonderful work. I'm gonna be using this for sure. I can think of many use cases. What would be nice though is a simple API. I send you what I need, you send me a jobId that I can use to check the status of my job and then let me download the results when I'm done. I played with the Geico example, and it seems to do a good job on the happy path there. But I tried another one where it struggled... I want to get me car rental prices from https://www.costcotravel.com/. I gave it airport + time of pickup and dropoff, but it struggled to hit the \"rental car\" tab. It got caught up on hitting the Rental Car button at the top, which brings up a popup that it doesn't seem to read. When I put in https://www.costcotravel.com/Rental-Cars, it entered JFK into the pickup location, but then failed to click the popup. reply suchintan 15 hours agoparentWe have a simple API we're building as a part of our cloud offering. It's in private beta today -- if you'd like to check it out please email me at suchintan@skyvern.com and I'd be happy to chat Thanks for the feedback re: costcotravel.com Skyvern definitely does NOT have 100% coverage of the web. This is one of the reasons we were excited to open source -- so we could learn about more websites where it doesn't work as expected I've filed an issue for this case here: https://github.com/Skyvern-AI/skyvern/issues/69 reply giamma 16 hours agoprevAt first I thought this was a test tool for Web applications, but now I understand it's meant to be a better RPA. Would it be usable for test automation? Would API allow to create asserts? reply suchintan 16 hours agoparentYes absolutely. You can prompt it to \"terminate\" if some state isn't met (ie XYZ text isn't displayed on the screen), and treat terminated results as failures For example, you could instruct it to go to hackernews and terminate if you don't see a comment from giamma by passing in this payload: { \"url\": \"https://news.ycombinator.com\", \"navigation_goal\": \"goal is met if you see a post from giamma. Terminate if you don't\" } reply dvngnt_ 16 hours agoparentprevthere are already some existing solutions for e2e testing. I would say playwright with codegen works well enough but there are ones that make it even easier by wrapping around openapi but seems overkill reply denidoman 11 hours agorootparentIt sounds interesting, could you please share the links if it is open sourced? reply ushakov 16 hours agoparentprevThere's a startup called Octomind (https://octomind.dev) doing exactly that and ZeroStep (https://zerostep.com), but on a lower level reply t14000 2 hours agoprevExciting stuff, my employer would be interested but it's AGPL3 licensed so it's a non-starter for them. reply smusamashah 5 hours agoprevComing up next in Windows and Chrome, unrecordable unscreenshotable pages, to avoid all AI tools. Banking apps on Androidare already unscreenshotable now. Given how LLMs just bypass all html obfuscation, that's going to be the next step to protect these (ad) businesses. reply Zuiii 3 hours agoparentThe analog hole. Until all recording and general computing devices become tamper-proof and locked down, people will always be able to take perfect (yes, perfect) recordings with some work or good-enough recordings trivially. For this, I'd use a usb camera. For those apps that disable screenshots, I'd just take a picture using the phone of the first person next to me. In my experience, only the ignorant, fools, and lawyers/lawmakers willingly waste resources on this security theater, with the later group using it trick other people or prevent them from exercising their rights (recording media). Google should remove this misfuture. This future is only enabling abuse at this point. reply tonyoconnell 9 hours agoprevTo keep costs down, you could start at sitemap, use an open source model via open router to guess the page to navigate to and scrape the text, links, forms, from the page using regex and fall back to GPT 4 and Vision. reply BasieP2 12 hours agoprevIs this (finally) a step towards a better way of automated frontend testing? We're currently testing dom instead of vision. reply suchintan 11 hours agoparentThis can definitely be used for front end testing. Just tell it to do something like a user and monitor whether it's successful or not Here's a prompt example to try out { \"url\": \"https://news.ycombinator.com\", \"navigation_goal\": \"goal is met if you see a post from basiep2. Terminate if you don't\" } reply agreeahmed 17 hours agoprevExciting to see this on HN. I think very soon agents like Skyvern will account for the vast, vast majority of web traffic. reply MattDaEskimo 16 hours agoparentMaybe for a transition period. There's no reason for somebody to create a website, pay for resources, and hope for some sort of revenue if their visitors are mostly AI. So why bother creating a UI? Instead it would make more sense to close the website and offer the same information as a paid API service. Any sort of website that needs to validate human visitors will be plastered with DRM. Rendering these web browsing LLMs useless. And good riddance as well. Using an LLM to browse the internet feels like a huge waste of resources. Instead it would make more sense to have a wikipedia-like for AIs to crawl via embeddings. reply suchintan 16 hours agorootparentI suspect that web traffic will encapsulate both. Many websites (government ones in particular) aren't interested in API-based access patterns. This kind of pattern makes it so you can serve both users and agents with a single interface reply MattDaEskimo 16 hours agorootparentThis would be ideal. The only issue here is trust. If my website relies on advertising then of course I would prefer to serve more content to a human visitor. So what? I bot protect my site, redirecting the AI to a minimalistic part that most likely expects some sort of value given? People will just breach this trust, like OP and abuse tools like Selenium (as they always have) to imitate being a human. reply suchintan 16 hours agorootparentI think this is pretty interesting -- I wonder if websites could allow agents to self-identify, and not count them towards advertising CPM to prevent dilution in the advertising metrics Perhaps a similar thing as robots.txt is in order (agents.txt?) reply Spivak 16 hours agorootparentprevI mean what kind of websites are we talking about here? The kinds of websites where all the value can be extracted by via a LLM are just content farms. And yeah, that sucks for content farms but putting up content and getting nothing in return is already how ad blockers work and it hasn't destroyed the them. I seriously doubt that AI traffic will even put a dent 1/1000th of the traffic loss of Google snippets. reply failuser 16 hours agoparentprevThat’s why we can’t have nice things. Are we at the end of Eternal September? Will all the signs of human life be restricted to paid or otherwise closed groups? If all free users are bots, who will even run ads that feed the Web 2.0 internet? I still have fear that the real internet has already split from what I see and I was left behind. reply hipadev23 16 hours agoparentprevWhy would the majority of web traffic turn into extremely expensive to operate agents? reply failuser 16 hours agorootparentThe expectation is that the price of AI bots will go down and get below the human-driven click farms we have now and thus make fighting bots too expensive because identifying humans gets harder every day. reply somethingAlex 9 hours agoprevI don’t know what my use case for this would be. I don’t tend to do anything regularly through a browser that I’d want to automate. Would be kind of handy to have a “pull all my relevant tax info documents from these sites and zip them up” automation but I only do that once a year. I’m probably being unimaginative. Anybody have any interesting use cases? Anyone have reply suchintan 8 hours agoparentImagine that exact use-case -- pulling up relevant tax information and filling it Now imagine it from the accountant POV, where they have the same use-case for hundreds of clients This is where we've seen something like Skyvern really shine. It's targeting industries and companies that are doing rote work at a significant scale reply andy_ppp 4 hours agoprevI think I’d really like a react-native version of this! Any plans? reply wintonzheng 1 hour agoparentwe're a pretty small team and don't have a plan for it in the near future :( I would love to know the reason you're interested in react native though if you don't mind sharing! pls email me or suchintan at shu@skyvern.com / suchintan@skyvern.com or join our discord reply barfbagginus 4 hours agoprevI wonder if the focus of this system can be shifted from corporate needs and applied to the needs of individuals who wish to organize and build tools seeking to de-enshittify platforms. There are a great deal of platform features designed to atomize, isolate, and exploit individuals. Finding meaningful connection on platforms increasingly means navigating past the noise of antagonist individuals, overcoming profit extracting attacks on our attention, and endlessly doomscrolling until we find those ephemeral opportunities to genuinely connect. I wonder if llms and browser automation tooling could help us build overlays that dynamically peel back the layers of enshitware that have been bolted on to our cybernetic perceptions of the world. If you feel they can, and if you feel people with those aims are welcome in your community, and can find each other to collaborate, then I would be very interested in sending in PRs and helping you burn down backlogged items that benefit non-commercial de-enshittification use cases. reply wintonzheng 2 hours agoparentI'm Shu, also cofounder of skyvern. first of all, you are more than welcome to join our coummunity. one big reason of open sourcing skyvern is to serve the individuals. This project was inspired by problems we learnt from tlking to corporates but it doesn't have to always serve those use case. problems like boring form filling are pretty common in real life. Second, llms definitely can help bridge the gap. My 58y old mom who grew up in the rural area of China doesn't know much about internet and doesn't know how to order takeout on her phone. She only knows the basic usage of wechat, the whatsapp in China and text messages. I've been a coder for 10+ years and I still find it so darn hard to keep up with tools and information out there. I do hope skyvern becomes what you're saying and help people get access to more in the world. reply hirako2000 16 hours agoprevIt reminds me of that bug a kid found to bypass the password locked screen of a very popular Linux distro. Might be great for pen testing. reply suchintan 15 hours agoparentThat's a great idea! I hadn't thought of pen-testing as a possible value prop for this product reply aussieguy1234 6 hours agoprevThere was another AI/browser automation project posted yesterday that got to the front page https://github.com/lavague-ai/LaVague I guess the main advantage of this new project is that its probably more accurate by using computer vision, but as others has said it uses much more resources. Costs will come down over time though. Get ready for alot of \"Back Office\" jobs to be automated away. reply cryptoBros2023 6 hours agoprevI wonder if we could reduce the call by switching to a local llama? reply wintonzheng 1 hour agoparenthttps://github.com/Skyvern-AI/skyvern/issues/76 we're planning to introduce a llm router in a week and you should be able to call your local llama after that. We're prioritizing on cloude 3, as its performance seems to be good. That said, please join our discord and bring more thoughts/requests to us. code contribution is also more than welcome reply razfar 15 hours agoprevI'm curious about the computer vision aspect of this tool. Specifically, how was the model which draws bounding boxes around interactable elements trained? Definitely a step beyond existing browser automation software! reply suchintan 15 hours agoparentIt's surprisingly dumber than you think! I'm always fascinated by how far you can get with heuristics in certain situations. Check out the code here -- https://github.com/Skyvern-AI/skyvern/blob/d0935755963b017ed... reply spxneo 14 hours agoprevHow does it compare to this posted less than 24 hours ago? https://news.ycombinator.com/item?id=39698546 reply suchintan 14 hours agoparentSaw the launch yesteday. Love all of the excitement in the space! LaVague is all about generating selenium code to interact with a specific page, and do it step-by-step Skyvern is all about taking a simple instruction and converting it to a series of LLM-driven actions. It's meant to be more autonomous (\"tell Skyvern what to do\") reply spxneo 14 hours agorootparentIsn't that the same thing when you interact with the underlying webpage? reply suchintan 14 hours agorootparentWe're quite different than LaVague. LaVague passes in the entire HTML DOM to the LLM to help it generate XPaths and valid Selenium code. (https://github.com/lavague-ai/LaVague/blob/main/src/lavague/...) Try this at your own risk.. any reasonable website would result in extraordinarily high input token costs We spend quite a bit of our time building a layer between the HTML and the LLM call to distill important pieces of information down to actions the LLM can take.. better weighing cost vs output. We're still not at 100% coverage. reply LZ_Khan 5 hours agorootparentprevIt is similar. hence the timing of the plug, probably :) reply hubraumhugo 16 hours agoprevAI should automate tedious and un-creative work, and data entry tasks definitely fit this description. Rule-based RPA will likely be replaced by fine-tuned AI agents for things like form filling and similar. Can you share some data on costs and scalability? At Kadoa, we're working on fully automating unstructured data ETL from websites, PDFs, etc. We quickly realized that doing this for a few data sources with low complexity is one thing, doing it for thousands of sources daily in a reliable, scalable, and cost-efficient way is a whole different beast. Using LLMs for every data extraction would be way too expensive and very slow. Instead, we use LLMs to generate the scraper and data transformation code and subsequently adapt it to website changes, which is highly efficient. reply suchintan 16 hours agoparentNice! We love what you're doing at Kadoa. We're trying our best not to move into the web scraping space -- we're focusing on automating uncreative, boring, tedious tasks. We've seen a lot of success going after form-filling on government websites, which would usually be very boring, but happens to work pretty well for us reply mosselman 16 hours agoprevIf I were to build some custom GPT powered thing for this. Is there a similar project I can use with a command line interface or some programmatic interface? reply keremyilmaz 16 hours agoparentSkyvern is actually an API-first product! The UI we built is mainly for simplicity and being able to debug the steps our agent takes. You can easily copy sample curl requests through our UI. Feel free to check out the quickstart on our GitHub and let us know if you have any questions. reply mosselman 15 hours agorootparentThanks I will check it out. Any idea on pricing/business model? reply suchintan 15 hours agorootparentWe tend to charge per request our users send us.. although the exact amount depends a lot on the exact task you want to run. Want to send Skyvern on a 40+ page journey to answer a question? It's a bit more expensive than just navigating to a page and extracting information I'd love to chat about your use-case. Happy to follow-up over email (suchintan@skyvern.com) or over a quick call (https://meetings.hubspot.com/suchintan) reply msikora 10 hours agorootparentprevWait, this is not Open Source?? reply suchintan 8 hours agorootparentWhat do you mean? All of our code can be found here https://github.com/Skyvern-AI/Skyvern reply shnkr 15 hours agoprevthe moment I saw vision in the title I knew what was going on. it was first demoed[0] by AI Jason around 4 months back. is it any different? https://m.youtube.com/watch?v=IXRkmqEYGZA reply suchintan 15 hours agoparentLove this video > self-operating-computer This is quite different than https://github.com/OthersideAI/self-operating-computer Self-operating-computer uses pixel mapping to control your computer. This is a very good approach, but it's extremely unreliable. GPT-4V frequently hallucinates pixel outputs, causing it to miss interactions, or enter fail-loops >The approach by AI Jason AI Jason is using image-only methods to interact with the browser. This is a great first step, but this approach tends to be rife with hallucinations or errors. We do dom parsing in addition to image anaylsis to help GPT-4V correlate information in the image to the interactable elements within the DOM. This dramatically boosts its ability to perform the same task over and over again reliably (which proved impossible with the image-only approach) reply shnkr 15 hours agorootparentnice. I was looking for simpler hacks as V didn't scale for me. Later I couldn't find time and this got back burnered. interesting concept for problem solving though. congrats! reply suchintan 14 hours agorootparentThanks! We definitely experimented with V only (that's the dream), but there's too much context missing: 1. What's behind a select option? You don't know until you click it, which means you need another iteration. This sucks. 2. How do you consistently correlate things in the images to actual actions (ie upload a file to a file input, click on a button, insert a date into a date)? Having the additional HTML Tag information dramatically improves the action selection process (click vs upload vs type) reply ilaksh 13 hours agoprevLooks terrific. I hope you will consider adding support for Claude 3. reply suchintan 13 hours agoparentWe DEFINITELY will. I think we're planning on pushing that next week -- we've been super excited about it Just created this: https://github.com/Skyvern-AI/skyvern/issues/72 reply xeonmc 5 hours agoprevWhat do you call an LLM with vision? LLVM ...oh, that's why it's called Skyvern reply ushakov 16 hours agoprevHow does this compare to OpenAdapt? I have a feeling that this tech will become a commodity and will probably be built-in into the OS or Browser. Props for open-sourcing though! reply suchintan 15 hours agoparentAh cool -- we weren't familiar with OpenAdapt. Will check it out. One big decision we made was to focus on browser automations (instead of computer automation like Adept or OpenAdapt). The reason for this was that we wanted to leverage the information available inside of a DOM to improve the quality of our agent's actions. We found that relying on image-only analysis with X,Y coordinate interactions wasn't able to offer high enough reliability for production workflows reply suchintan 16 hours agoparentprevI agree -- this will likely get commoditized, which is why we didn't focus on making this a chrome extension. The API access pattern makes this particularly appealing as you can run multiple instances in the cloud reply samstave 15 hours agoprev>>(1) Automating post-checkup data entry with patient data inside medical EHR systems (ie submitting billing codes, adding notes, etc), FULL FUCKING STOP. [We talk about AI alignment. THIS is an aligment issue] Do you understand billing code fraud? If you supply this function - you will *eliminate ANY AND ALL human accountability* unless you have ALSO built a fully auditable provenance from DRcodes. Codes ARE why the US health system is BS. Here - if you want to be altruistic - then you will take it upon the fact that CODES are one of the most F'd up aspects of costing. Codes = [medical service provided] so code = 50 = checkup = [$50 <--- WHO THE HECK KNOWS] So lets say I am Big Hospital. \"No, we will only allow $25 for code 50\" - and so they get that deal. I am single clinic so they have to charge $50 Build a dashboard for what the large medical groups can negotiate per code, vs how a small hospital or clinic group gets per code. Only automate it if you can literally show a dash of all providers and groups and what they can charge per code. Infact - code pricing is a medical stock market. (each hospital group negotiates between the price they will pay per code, how much lobbying is a factor and all these other factors... what we really need an LLM for is to literally map out all the BS in the Code negotiations btwn groups, pharma, insurance, lobbying, kickbacks, political) Thats the medical holy grail. [EDIT: Just to show how passionate I am on this issue - here are some SOURCE: I have designed and built & commissioned out 11+ hospitals. Built the first iphone app for medical.. it was rejected by YC (hl-7 nurse comm system on iTouch devices) (2006?) opensourced that app to OpenVista. Brother was joint chiefs dr / head of va worked with building medical apps and blocked by every EHR... Zuckerbergs name is on top of some of the things I built at SFGH before he got there...(and ECH mtn vw) Ive seen way beyond the kimono reply suchintan 15 hours agoparentWe know very little about this space, except that the entire process is a little bit crazy. We've talked to a few companies now that would use a product like Skyvern to just automate billing information gathering to make sure patients don't get screwed in the billing process Are you open to chatting? I'd love to pick your brain about what's behind the kimono suchintan@skyvern.com or https://meetings.hubspot.com/suchintan reply is_true 16 hours agoprevWeeks to automate something? Anyone experienced would be able to automate most workflows in a couple of days top. reply suchintan 16 hours agoparentYou're right -- we should have written days to weeks. What's interesting here is that large companies like UI Path charge thousands of dollars to build a single robot for companies.. I wonder if that large up-front expense will still be necessary in this new world reply is_true 13 hours agorootparentThat's crazy. We usually create robots and most of the time we charge less than a thousand USD. We have a lot of tooling in place now so most things take minutes. The harder step is getting the data in the client's infrastructure reply suchintan 13 hours agorootparentWhen you say \"getting the data in the client's infrastructure\", do you mean self-hosting the robots? or something else? reply is_true 10 hours agorootparentNo. Getting the data on the client's DB, filestore, or similar. For some ERPs we create insert queries, others have import functions. reply dang 15 hours agoparentprevI've edited the text above to say \"days or even weeks\". reply suchintan 15 hours agorootparentthank you!! reply 999900000999 12 hours agoprev [–] Don't make me sign up for a demo, I'd rather just give you my credit card number and try it myself. Aside from that cool project! reply suchintan 11 hours agoparent [–] We're gonna build a self-serve UI soon! We just wanted to get it into people's hands ASAP :) Feel free to email me at suchintan@skyvern.com -- I can let you know when the self-serve UI is live reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Skyvern is an open-source tool utilizing LLMs and computer vision to automate browser-based workflows with a natural-language API for back-office tasks.",
      "It tackles workflow scalability challenges by leveraging LLMs to analyze website layouts and adapt without XPaths, currently supporting tasks like procurement and government interactions.",
      "The tool plans to venture into automating medical EHR data entry and customer research, remaining in the early development phase and seeking user input."
    ],
    "commentSummary": [
      "Skyvern is an open-source tool utilizing Large Language Models (LLMs) and computer vision to automate browser-based workflows, offering a natural-language API for back-office tasks like procurement and job applications.",
      "Discussions revolve around leveraging LLMs for web scraping, automation challenges such as cost and spam prevention, and potential vulnerabilities in CAPTCHA services.",
      "Future plans include expanding into medical data entry, introducing an LLM router for user aid, and creating a self-serve UI for improved client database accessibility."
    ],
    "points": 345,
    "commentCount": 124,
    "retryCount": 0,
    "time": 1710433894
  },
  {
    "id": 39702479,
    "title": "The Legacy of Švejk: A Humorous Satire on War",
    "originLink": "https://blogs.loc.gov/international-collections/2018/03/the-good-soldier-vejk/",
    "originBody": "“The Good Soldier Švejk” March 7, 2018 Posted by: Anchi Hoh Share this post: (The following is a post by Helen Fedor, Reference Specialist in the European Division.) The most famous work by Czech writer Jaroslav Hašek (1883-1923), and probably the best known work of Czech literature, is “Osudy dobrého vojáka Švejka za světové války” (The adventures of the good soldier Švejk during the world war), or as it is known in its English translation, “The Good Soldier Švejk.” The most translated Czech novel—read in some 60 languages—it satirizes bureaucracy, the military, and war. Jaroslav Hašek. “Osudy dobrého vojáka Švejka za světové války.” Prague: K. Synek, 1948-49. Illustration by Josef Lada. Švejk rubs ointment into his knee while the cleaning lady tells him of the assassination of Archduke Franz Ferdinand—an event that triggered World War I and brought about Švejk’s many adventures. Set in Austria-Hungary, the book opens with the 1914 news that Archduke Franz Ferdinand of Austria (1863-1914) has been assassinated in Sarajevo, an event that would trigger World War I. Josef Švejk, the antihero, enlists in the army and spends the war blundering from one ludicrous adventure to another. He seems earnest in his desire to carry out his orders, yet takes them to extremes and frustrates his superiors. For example, when Švejk is assigned to the barracks in České Budějovice (in southern Bohemia) as a prelude to going to the front, he manages to miss all the trains heading there. In his ‘zeal’ to reach the barracks and join the rest of his battalion, Švejk meanders all over southern Bohemia, vainly searching for České Budějovice, gets arrested as a suspected spy and deserter, and is escorted to the barracks. Švejk bears more than a passing resemblance to the author, Hašek, who loved practical jokes, had a checkered career, and was himself drafted into the Austro-Hungarian army. Hašek’s pretended suicide attempt (by jumping off Charles Bridge into the Vltava River in Prague) ended with the police taking him to a mental institution. Also, during elections to the Austro-Hungarian parliament, Hašek ran for office as a member of his own newly founded Party of Moderate and Peaceful Progress Within the Limits of the Law. He eventually joined the anarchist movement and was arrested and imprisoned more than once. Jaroslav Hašek, Karel Vaněk; illustrations Petr Urban. “Švejk za první světové války, v ruském zajetí a v revoluci” [Švejk during the first world war, in Russian captivity, and in the revolution]. Prague: XYZ, 2009. As Švejk and 40 other captive soldiers are being transported eastward across Russia, his train pulls out of a village station without him, and despite his pursuit, strands him there. The illustration shows Švejk running after the train. Jaroslav Hašek. “Osudy dobrého vojáka Švejka za světové války.” Prague: K. Synek, 1948-49. Illustration by Josef Lada. Two soldiers escorted Švejk to the home of the chaplain for “spiritual consolation” before his hanging. By the time Švejk and his escorts got there, the soldiers were drunk, and Švejk ended up guarding them while the chaplain (himself drunk) unsuccessfully tried to telephone the barracks, mistaking a coat rack for his nonexistent telephone. Hašek planned to write the Švejk story in six parts. The first three were published 1921-23, but Hašek died in 1923, while working on part four. After his death, his publisher asked journalist and humorist Karel Vaněk to complete the work. Vaněk finished part four and later also wrote about Švejk’s adventures in Russian captivity and during the Russian Revolution. The most famous illustrator of Švejk’s adventures was Josef Lada. His classic illustrations are instantly recognizable and have come to define Švejk, even though Hašek apparently never saw Lada’s drawings. A more recent illustrator is the delightful Petr Urban whose artwork is shown here. Two other sequels to the Švejk story were set in the Nazi-controlled Protectorate of Bohemia and Moravia (1939-45); both were written in the 1940s by anonymous authors. The first was the English-language “Švejk in the Protectorate,” published in London, 1942, by the exile publishing house The Czechoslovak. This small booklet begins with an account of the 1939 assassination attempt on Hitler: “So they’ve nearly killed our Adolf…,” echoing the opening words of Hašek’s novel. The preface of this work describes it as “a cruel and bitter satire where laughter is mingled with the fighting spirit of revenge and hatred.” “S̆vejk in the Protectorate,” London: “The Czechoslovak,” 1942. Medius (pseud.). “Loyální občan Josef Švejk v protektorátě Čechy a Morava.” Prague: K. Synek, 1948. The other work, “Loyální občan Josef Švejk v protektoráte Čechy a Morava” (Loyal citizen Josef Švejk in the Protectorate of Bohemia and Moravia), was published in Prague by the unknown ‘Medius,’ in 1948. Only part one of this work was ever issued. The Protectorate of Bohemia and Moravia was established on March 16, 1939, after Germany had occupied Czechoslovakia. Germany had already annexed the Sudetenland, composed of territory in the northern, southern, and western parts of the Czech Lands (Bohemia and Moravia), in October 1938; an independent Slovak Republic had been established on March 14, 1939. The first English translation of Švejk was published by Paul Selver in 1930, but it was an abridged version that reduced the book to less than two-thirds of the original. Perhaps the best known English-language translation of Hašek’s book is by Cecil Parrott, originally published in 1973. His translation used Lada’s original drawings, and included maps showing Švejk’s travels. “The Good Soldier Švejk and His Fortunes in the World War,” Cecil Parrott (trans.). London: Heinemann, 1973. The very first translation of Hašek’s book however, was into German, by Grete Reiner, in 1926. “Die Abenteuer des braven Soldaten Schwejk während des Weltkrieges” (The adventures of the good soldier Švejk during the world war) was published in Prague, which had a large German-speaking population. Ms. Reiner, a native of Prague who was later killed at Auschwitz, was the executive editor of the anti-fascist magazine, “Deutsche Volkszeitung,” (German’s people daily ), and was largely responsible for spreading Švejk’s fame throughout Europe. Her translation, burned by the Nazis in 1933, was said to be one of playwright Bertolt Brecht’s favorite books. In 1927, Brecht himself wrote a stage adaptation based on the first three parts of the Švejk story. The songs for this production were written by Hanns Eisler, an Austrian who later composed the national anthem of the German Democratic Republic (East Germany). “Die Abenteuer des braven Soldaten Schwejk während des Weltrieges.” Transl. Grete Reiner, Illus. Josef Lada. Prague: A. Synek, 1926. “Schweyk im zweiten Weltkrieg.” (Svejk in the second world war) Berlin: Suhrkamp Verlag, 1962, c1957. Since then, Švejk has inspired further plays, films, comic books, several restaurants (in Prague, throughout the Czech Republic, and abroad), statues, an opera, TV adaptations, a BBC radio broadcast, an animated film, and books such as Joseph Heller’s “Catch-22.” No doubt Švejk will continue to inspire future generations. Categories European Reading Room",
    "commentLink": "https://news.ycombinator.com/item?id=39702479",
    "commentBody": "The Good Soldier Švejk (2018) (loc.gov)307 points by palmfacehn 22 hours agohidepastfavorite172 comments hilbert42 21 hours agoHašek's The Good Soldier Švejk is an absolutely essential read, it has to be in the list of the top 100 books to read before one departs this planet! Not only is it hilariously funny it's also full of the tribulations of life and how the system—bureaucracies—here the army—lands one in absurd and unexpected situations. It's a great shame Hašek died so young (he was a great observer of human nature). Do yourself a real favor, read it or get an audio book. reply The_Colonel 21 hours agoparentŠvejk is what I call a \"scalable\" book. It works for readers of almost any level. The first time I read it I was maybe 8 years old and had a lot of fun, even though I completely missed most of the nuance. reply lukan 19 hours agorootparentMore examples of \"scalable\" books please? reply gumby 18 hours agorootparentThe lord of the rings is a good one, especially if you skip the songs. Then it’s simply an adventure story. The Sword in the Stone is pretty good in this regard. Apart from that first book (which is published as a standalone book) the entire Once and Future King is too complex for a child, I think (instead it would come off as boring and obscure). But in general almost any book a kid wants to try to read will be fine. Also: back in the day when small towns had a single cinema screen, movies would travel around as physical media and play for a week or two. So they had to be appropriate for anyone in town else the cinema owner wouldn’t take them. My kid loved those Fred Astaire musicals. I do too. For him they were just fun. To me, many of them were quite racy and quite explicit! But all that just went over his head. reply willismichael 18 hours agorootparentprevMy neighbor gave me a great tip: check out anything by Terry Pratchett that I can find in the youth fiction section of the library. My wife and I are reading them to children ages 9 - 16, and all of them are liking the books. reply fransje26 35 minutes agorootparentA big yes for Terry Pratchett! It can easily be read as funny little books following the sagas of recuring (anti)heroes. But the light-hearted stories belie a sharp-eyed critique of society, with the most well known example probably being Vimes' Boot theory of socioeconomic unfairness. Often, the subtility is hidden in a word or a choice of words that can easily go unnoticed, but are all small hints of the vast pluridisciplinary depth of knowledge of the author. The esoteric, historical, literary and physical sciences references (to name just them), are delightful small winks to the reader sprinkled throughout the books. reply imp0cat 4 hours agorootparentprevAnother vote for Terry Pratchett. He is a master of blending the fantasy and contemporary worlds together. Stuff like in-sewer-ants vs insurance. reply mrob 16 hours agorootparentprevThe Wind in the Willows. As a child, I read it purely as an adventure story. Re-reading it as an adult, I realized it's actually two stories: one a eulogy to the British countryside, and the other a comedy about the self-inflicted troubles of Mr. Toad. The humor was lost on me as a child. reply gumby 15 hours agorootparentAs a kid, I was terrified by Mr Toad and stopped reading the book because of him. reply mcepl 12 hours agorootparentprev“The Little Prince” by Antoine de Saint-Exupéry. Whatever age I read it, I am always surprised how much it deals with the actual problems I have. reply jamonserrano 18 hours agorootparentprevI remember enjoying these as a child without understanding any of the subtext or satire: Jonathan Swift: Gulliver's Travels Umberto Eco: The Name of the Rose Bohumil Hrabal: Cutting it Short Antal Szerb: The Pendragon Legend reply Nition 13 hours agorootparentprevThe Earthsea trilogy by Ursula Le Guin is another one (there are also books beyond the first three now, but they're more targeted at older readers). reply russfink 7 hours agorootparentNow every petal of the rose has a name. . . reply j_french 18 hours agorootparentprevMy older brother gave me Animal Farm to read as a child, I enjoyed it as a (somewhat depressing) story about animals taking over a farm. reply HanClinto 17 hours agorootparentI was probably 7 or 8 my first time through Animal Farm. I cried so hard when Boxer died. reply HanClinto 17 hours agorootparentprevYoung Adult fiction is my \"go-to\" place for this. Nearly anything that has won the Newberry Award is great for the whole family. Some standouts in my mind: * Island of the Blue Dolphins * Chronicles of Prydain (Book of Three, The Black Cauldron, etc) Chronicles of Narnia aren't Newberry winners, but are good regardless (if you don't mind the religious subtext). +1 for other people mentioning The Hobbit and Lord of the Rings. Our whole family has enjoyed classics like Pride and Prejudice and Dracula -- such books are called \"classics\" for a reason. Modern YA fiction has some very good books as well -- we all enjoyed Hole by Louis Sachar. Some good modern sci-fi too -- Project Hail Mary by Andy Weir was well received, as was Ender's Game. Brandon Sanderson's stuff is very good. Whole family enjoyed The Way of Kings and the books that follow. (For context, \"whole family\" is mix of genders, ages 10-15) reply mcarmichael 7 hours agorootparentprevMelville's Moby Dick. It can be about adventure, about whaling, about the fellowship of man, about mortality... Intruder in the Dust, the best of William Faulkner's \"young adult\" novels. The short story collection Knight's Gambit is also well worth a look. reply tsc 18 hours agorootparentprevThe Little Prince reply thesz 14 hours agorootparentprevKarel Čapek: R.U.R. His short stories are beyond fascinating and adorable, BTW. One, for example, equates accounting to hunting and detective work. The Stars My Destination by Alfred Bester. Works of James Herriot. reply UncleSlacky 13 hours agorootparentČapek's \"War With The Newts\" is good too. reply lelanthran 16 hours agorootparentprev> More examples of \"scalable\" books please? In addition to what the other replies recommended, I read Tom Sharpe at a young age and enjoyed all of them with sometimes uncontrollable giggles. Start with Wilt, I think. Then maybe The Throwback. reply dboreham 11 hours agorootparentprevDostoevsky's \"The Idiot\" reply MaysonL 8 hours agorootparentprevA Wrinkle in Time… reply flipthefrog 12 hours agorootparentprevThe Moomin books by Tove Jansson reply croisillon 14 hours agorootparentprevthe little Prince, i'd say reply smoldesu 14 hours agorootparentprevEvery Gary Larson collection you can find. reply bookofjoe 14 hours agorootparentprev\"The Little Prince\" reply hilbert42 20 hours agorootparentprevVery true, I wouldn't have recognized many of the nuances had I not had military training and having worked in government bureaucracies. reply runlaszlorun 10 hours agorootparentOh yeah? I’ll add it to my list. I’ve served and I was thinking of passing on it. Luckily I was well versed before I showed up to Uncle Sam’s doorstep. Catch-22 paints paints a good picture. And had a high counselor who was a Vietnam vet and said Apocalypse Now was the most realistic Vietnam movie he’d. And I can’t say that my experiences in were too far from my expectations. I think the thing people don’t get about the military, at least speaking of my experience in the US’s, is even in places like special operations units and doing the stuff that reads great in a newspaper, often enough there’s an absolute, epic, comedic shitshow going on inside with a cast of characters that you couldn’t even do justice to in a goofball comedy. Suppose that might apply to lots of things. Luckily, no military really has to have their shit together, they just gotta be better than the other side. reply 48864w6ui 1 hour agorootparentOne of Napoleon's cavalry generals said his average trooper's horsemanship was mediocre at best, yet they still made the tour of Europe. (Later, in the time of Napoleon III, the Prussians would outdo the French in utilizing mediocrity, providing yet another example that for a conscripted military, quantity is its own quality) reply poloniculmov 21 hours agoparentprevHis short stories are also hilarious and in the same vein as Svejk's adventures. reply mcepl 12 hours agorootparentYes, they are only hilarious. Švejk on the other hand is in my opinion much more serious. One Czech literary critic call it even “Kafka by other means”. Yes, Hašek was a satiric writer, so that’s how he wrote, but Švejk is IMHO actually a serious book about the horror of a human being liquidated by the impersonal power of modern society. reply Anotheroneagain 1 hour agorootparentThe pre- war books are much more lighthearted, the post war one (the well known one), it's just gallows humor, or outright depressing. reply weinzierl 21 hours agorootparentprevI've enjoyed Švejk's adventures, but never read any Hašek's short stories. Can you recommend a particular one you like? reply dhosek 8 hours agorootparentThere was a recent collection of new translations of his stories, many of which had never previously appeared in English. They’re not ideal in that the translations are translations of a German edition of his stories and not the original Czech texts, but they’re still a fun read. https://paradiseeditions.net/products/the-man-without-a-tran... reply rompledorph 3 hours agoparentprevOrdered! reply sigma5 19 hours agoparentprevwhat's the other books that are on your 100 books list to read before one departs this planet ? reply niccl 14 hours agorootparentNot the original commenter but I'd include: Vanity Fair by Thackeray Mr Johnson by Joyce Cary Lavengro and Romany Rye by George Borrow The Descent of Woman by Elaine Morgan Fluid Concepts and Creative Analogies by Douglas Hofstadter et al. Identity Crisis by Ben Elton reply mooreds 21 hours agoparentprevHow does it compare to Catch-22? reply sireat 17 hours agorootparentI thought Švejk to be much funnier. Rather I thought Catch-22 to be a so-so imitation of Švejk. Then again I've been re-reading Švejk since childhood. Similarly, how you can tell when Hasek dies before finishing Švejk and his friend takes over with the ending, the jokes just fall off a bit. reply Lariscus 21 hours agorootparentprevJoseph Heller claimed he would have never written it had he never read The Good Soldier Švejk. reply mooreds 21 hours agorootparentHmm. A quick Google didn't find that. From https://www.nytimes.com/2004/11/17/theater/newsandfeatures/t... \"Heller, who died in 1999, told various interviewers that Céline and Kafka were his most powerful influences and that \"Svejk\" was \"just a funny book.\"\" reply Zircom 20 hours agorootparentFound a quote, had to use the anglicized spelling though. https://www.vanityfair.com/culture/2011/08/heller-201108 \"The Czech writer Arnošt Lustig claimed that Heller had told him at a New York party for Milos Forman in the late 1960s that he couldn’t have written Catch-22 without first reading Jaroslav Hašek’s unfinished World War I satire, The Good Soldier Schweik. \" reply malermeister 14 hours agorootparentGermanized, really. reply _visgean 18 hours agorootparentprevthere are some references in catch-22 and its follow up Closing time. reply bee_rider 15 hours agorootparentI was really surprised by Closing Time. I forget all the details of it, but I remember finding it just relentlessly depressing. The only degree to which I thought it worked was, it really emphasized the extent to which we really don’t need to know what happens to characters after the story is done, it is better if we just imagine they go on to have their lives. reply _visgean 10 hours agorootparentSame. It was so heavy compared to catch-22. But I am not sure the aging perspective could have been written any different. reply red-iron-pine 16 hours agorootparentprevCatch-22 is funny during the read but after the end, and in reflection, is pretty dark. Svejk is generally funnier, IMO reply mcepl 12 hours agorootparentŠvejk is too much slanted by the expectations of “just funny” and by (absolutely awesome, but too nice) illustrations by Josef Lada. When listening to the audio version of the book, I was shocked how actually horrific story it is. I have mentioned elsewhere in this thread a Czech literary historian (M. C. Putna) who called “The Good Solider Švejk” as “Kafka’s ‘Trial’ by other means”. I think he is quite correct. reply rightbyte 21 hours agorootparentprevI think if you like one, you like the other. I think the Svejk book have a more innocent tone and is less cynical. But I was way to young when I read them to have a \"deep\" understanding of the contexts. reply romwell 9 hours agorootparentI'd say it's more cynical. There's a place for hope in Catch-22. In Svejk, the gruesome absurdity of the war prevails in all situations. reply imjonse 20 hours agorootparentprevI found Catch-22 much more hilarious than Švejk. reply ufocia 20 hours agorootparentI thought Svejk was more available to a younger reader. However, like someone already mentioned, it has enough layers for a reader of almost any age to enjoy. I'd read them both. reply romwell 9 hours agorootparentprev>How does it compare to Catch-22? It's the Catch-22 of WW1. A bit more gruesome and obscene, both less serious and much darker than Catch-22, and highlighting a wider scope of social (and military) issues. reply watwut 19 hours agorootparentprevIt makes sense unlike Catch-22 that does not make sense. reply soperj 17 hours agorootparentit only makes sense once you've already read it once. reply scandox 13 hours agoparentprevThe audio version read by David Horovitch is incredible. reply maciekpaprocki 20 hours agoprevFor those that loved the book. Hasek also wrote an autobiography, which is even funnier than the life of Svejk. It's definitely made up quite a bit, but the stories in it are great. I cannot find english title ( it might have been not printed ), but transleting from polish it's called \"3.5 beer\". Spoilers!!! Stories include: - One time he wrote to paper called animals and unfortunately run out of animals to write, so he just started inventing them. It ended up in year long trip to Australia paid by some wealthy women who really wanted to get her own \"Tasmanian Vampire\" - Russian general invades city. Hasek knows the best way to stay alive is to have a drink with him. They get very drunk and general ask Hasek what's his biggest problem. Hasek says that the fact that people cannot read. Next day he wakes up to bunch of posters around the city saying that whoever will not be able to read by noon tomorrow will be executed. reply avodonosov 8 hours agoparentRemember that some autobiographical themes are used in the Shvejk book itself. In particular, the volunteer Marek had been an editor for an Animal World journal, where he published articles about made up animals. And even entered a public debate with some ornithologist who questioned his articles. That's in the chapter Skvejk's Adventures in Kyralyhida. If I remember correctly, Hashek was also selling dogs in real life (Shvejk's profession in the book). reply ufocia 8 hours agoparentprevThere are a number of beer themed books, but none of them even close to 3.5 beer. Perhaps you can post the Polish title. reply weinzierl 21 hours agoprev\"When the war is over, let’s see each other\", said Švejk. \"You will find me every day after six o’clock in the 'U Kalicha'\" \"Then, see you after the war, at six o’clock in the evening.\" Vodička said. \"Better come at six-thirty to be safe if I’m late,\" Švejk replied. https://commons.m.wikimedia.org/wiki/Category:U_Kalicha_(Pra... reply bitsinthesky 16 hours agoparentWenn die Leute auseinandergehen, da sagen sie “Auf Wiedersehen” reply chalst 19 hours agoparentprevYou’ve linked to a Wikimedia category of pictures. I assume this is not intended. reply romanhn 18 hours agorootparentIt takes me, on mobile, to a picture of what looks to be the real-world \"U Kalicha\" establishment. reply projektfu 14 hours agorootparentFrom Mobile Wikipedia, always use the browser's share button to get the canonical URL. https://commons.wikimedia.org/wiki/Category:U_Kalicha_(Pragu... reply romwell 9 hours agoparentprev>You will find me every day after six o’clock in the 'U Kalicha' Context: \"U Kalicha\" refers to a bar in Prague (translation: At the Chalice). The wikimedia link takes one to a photo of the bar today. reply weinzierl 8 hours agorootparentI wouldn't call it bar. It's more like a pub or an inn. reply romwell 5 hours agorootparentWhatever you'd call a place where you sit down for a beer (...or ten) and have conversations with friends. reply pdimitar 21 hours agoprevOne of the very few books that literally had me rolling on the floor laughing -- not exaggerating for effect here, I have in fact fell from the sofa on the floor and started laughing until I wheezed and couldn't breathe. Especially the segment with the military preacher whom Švejk was an assistant of -- and when he had to get him home after he got dead-drunk. My gods, I can almost remember how much my tummy hurt back then! That being said, all the stuff about censorship and getting arrested for \"treason\" (basically for a political joke at the bar) hit too close to home for me, and I am from a former Soviet block country, and I found those pieces very depressing. Still, I went through all books -- several times -- and enjoyed them a lot. The author really captured a lot of absurdities very well. reply avodonosov 20 hours agoparent> all the stuff about censorship and getting arrested for \"treason\" (basically for a political joke at the bar) hit too close to home for me, and I am from a former Soviet block country, and I found those pieces very depressing. You may probably find it curious that Hashek ended up being a bolshevik and a red army commissar. reply pdimitar 20 hours agorootparentI would never endorse this but I also kind of understand: it's very easy to switch sides when you're seeing your own government face-plant all the time and never get anything meaningful done. That's one of the ways the ruling class wins: a new \"promising\" system gets promoted, it points at the mistakes of the current system and the people, tired of all the crap, end up voting for the new stuff, only to discover it's even worse... :( That has happened quite a lot in history, sadly (also I am aware that in the case of the USSR there was no voting involved, it was just a figure of speech). reply avodonosov 19 hours agorootparentIn case of USSR the people were choosing sides of the civil war and fighting voluntarily - a more serious commitment than simply casting a ballot. reply ihaveajob 17 hours agorootparentIf it was anything like the Spanish Civil War, lots of people just happened to live in an area that was controlled by one or another side. Those who were committed to their cause probably did their best to escape or take arms. Most were simply recruited and complied to avoid further trouble. Both my grandfathers happened to live on the side they disagreed with when hostilities started, so they had no choice. reply dragandj 17 hours agorootparentprevIn vast many cases they were either forcefully conscripted by whomever was holding power in the particular area, or were simply choosing to enter armies because they were very young people who lost everything and did not have many options. Do not also discount that during the post-revolution civil war, food shortages were the norm, and the place to eat is army. reply avodonosov 8 hours agorootparentI mean that the side winning a civil war probably needs to have a sufficient degree of public support. If enough people went as far as fighting voluntarily, then there was also a significant number who supported this side more passively. I am not a historian, but I think the society turned this way, in a sense. It's not like some external force coerced them, when everyone was against it. Hashek is an example. He was not forcefully conscripted, it was his choice. I've just recently listened to Kerensky's interview (the chairman of the Provisional Government that was ousted by the October Revolution in 1917). He was unable to gather any forces, no-one defended him. https://www.youtube.com/watch?v=wA225DBywU4&t=4842s (the interview is in Russian) reply FpUser 18 hours agorootparentprevMost of the people were not involved in fight. They were busy growing food for example. But sure the ones that actually fought did choose their sides voluntarily. Sometimes they flipped. reply duxup 19 hours agorootparentprevIt's unfortunate but it's often the case when someone talks about a given ideal such as being critical of censorship, authoritarianism, etc. They often mean: \"I don't like THAT censorship. Mine is fine.\" reply hilbert42 20 hours agoparentprev\"...had me rolling on the floor laughing...\" Same here, I was in tears I was laughing that much. I found it funny because I recognized those silly maddening situations from my own life. We all experience them but it takes a master like Hašek to remind us about how absurd they really are. reply Anotheroneagain 15 hours agoparentprevThat being said, all the stuff about censorship and getting arrested for \"treason\" (basically for a political joke at the bar) I think you didn't get it right. The joke is that they go out of their way to not say anything offensive, knowing that the situation is tense, but they get arrested anyway. reply pdimitar 14 hours agorootparentStrange that you're saying this because that's exactly how I understood it: people were extremely mindful of what they're saying but even with that you had \"agents\" in disguise who really stretched the definition of \"treason\", many times over, just to be able to do a few arrests daily. In the books it was also shown that the mere fact of singing along a song that praised their emperor was also grounds for being arrested (which was quite absurd because praising that guy was a requirement anyway). reply Anotheroneagain 5 hours agorootparentThe book starts with the event that lead to the war getting announced. It's the pre war paranoia, not state censorship. reply lioeters 21 hours agoprevFrom all the books I've read, the good soldier Švejk stands out as one of the most memorable characters. I love the style of the writing, how it shows the absurdity of bureaucracy, war, and society through the person of Švejk, perpetually drinking and getting into trouble, innocent like a dove and wise as a serpent, he always finds his way out of any predicament, while having his fun. He represents an aspect of the indomitable spirit of humanity and humor. The illustrations by Josef Lada are wonderful too, they are essential to the reading experience and imaginary world of the book. reply isolli 21 hours agoparentDid you read it in Czech? Apparently, finding a good translation is a bit of a minefield. reply lioeters 20 hours agorootparentI read it in English, but some knowledge of Czech culture and geography (towns and Prague neighborhoods) added to the enjoyment of the book. The one I read was translated by Cecil Parrott (in 1973), but I learned there's a new translation (1997~) by a native Czech speaker: The Fateful Adventures of the Good Soldier Švejk During the World War, translated by Zdeněk \"Zenny\" Sadloň, in three volumes. reply fransje26 27 minutes agorootparentOne of the comments at the end of the article touches on the new translation. reply jiripospisil 21 hours agoprevA classic. The movie versions are available on YouTube with English subtitles but it's not the same. A part of the charm of Švejk played by Rudolf Hrušínský is the way he talks and that gets lost if you don't speak Czech. https://www.youtube.com/watch?v=LI9OKaz6yQ0 reply flipthefrog 12 hours agoparentRemoved for copyright reasons, it says. Theres also a 1950s puppet film version directed by Jiri Trnka reply jiripospisil 12 hours agorootparentHah, some ahole must have reported it. It was working fine a few hours ago. Can you even claim copyright of a 70 years old movie? Oh well. reply yread 20 hours agoparentprevThe czech audiobook read by Jan Werich https://youtu.be/JaNO4ZG3zn8?si=oc2YRdNurUNcX9LQ is also great! reply pomian 8 hours agorootparentExcept it only shows up in Czek! reply leiaru13 1 hour agoprevA favorite of both my dad and I. I've only read it twice -- once as a teenager and once as a college junior -- and loved it both times, while he rereads it every so often. As my dad would say, it's the type of book that you can read many times and discover something new every time. reply drewzero1 4 hours agoprevI was introduced to the character by way of Bertolt Brecht's Schweyk im zweiten Weltkrieg (Švejk in the Second World War)[0], which was meant as a sequel to Hašek's original and which I read in school- unfortunately too long ago to remember much of anything but Švejk's good-natured bumbling. We also read Biedermann und die Brandstifter (The Fire Raisers/The Arsonists)[1], also by Brecht, which I remember somewhat more vividly. The main character is an ordinary guy who thinks he could never be fooled by arsonists, but allows a pair of them to fill his home with flammable material and ends up aiding them in his own demise. I worry that we have failed to learn the lessons of this kind of Nachkriegsliteratur (Post-WWII literature). 0: https://en.wikipedia.org/wiki/Schweik_in_the_Second_World_Wa... 1: https://en.wikipedia.org/wiki/The_Fire_Raisers_(play) reply bitsinthesky 17 hours agoprevI think an entrepreneur should establish a tour in the Czech lands, to walk in the footsteps of švejk as of when he drank away the money for his train ticket sending his company to the front, thereby forcing him to zig zag across the land in the hope of rejoining them. It will be the Czech Camino de Santiago, and one must carry a pipe and a bottle of slivovic as they go. reply romwell 9 hours agoparent>I think an entrepreneur should establish a tour in the Czech lands, to walk in the footsteps of švejk as of when he drank away the money for his train ticket sending his company to the front, thereby forcing him to zig zag across the land in the hope of rejoining them. It will be the Czech Camino de Santiago, and one must carry a pipe and a bottle of slivovic as they go. Pretty sure I've seen ads for exactly that kind of tour. Might be a false memory. But in any case, it's my goal to do that sort of pilgrimage when I get to properly spend time in Czechia. reply fransje26 14 minutes agorootparenthttps://www.turistika.cz/trasy/po-stopach-svejka/detail reply coredog64 19 hours agoprevThere’s an American version of this called “No Time For Sergeants” [0]. One of my favorites bits is when he takes color-blindness to the extreme. [0] https://en.m.wikipedia.org/wiki/No_Time_for_Sergeants reply troad 11 hours agoprevAmusing anecdote - last year I tried to buy a copy of Švejk in Prague and I had the following exchange in a bookshop (in Czech). Me: \"Hello, do you have a copy of Švejk?\" Assistant: \"No.\" M: \"Uh, OK, do you know of anyone that might?\" A: \"No, no one has any Švejk right now!\" M: \"I see. Is there any reason for that?\" A: \"Everyone has already read it.\" walks off in a huff It seemed somehow fitting. 'You can't read Švejk because everyone has already read it, and we're insulted you'd even ask for it in our bookshop.' There's a reason the Czech lands have given the rest of the world both Hašek and Kafka! reply ufocia 6 hours agoparentThey probably read copies from their libraries. reply limaoscarjuliet 19 hours agoprevI was raised in Eastern Bloc in 70 and 80s. Svejk was the classic we all read as teenagers. We have seen that as parody of communism and always wondered how is that book not censored or forbidden? Now I realize it describes any sufficient evolved (i.e. broken) system, which might have been good enough excuse for the soviets not to make it verbotten. reply Andrew_nenakhov 22 minutes agoparentI think it wasn't censored because it was so critical of imperialism, so soviet censors viewed it as 'progressive' and aiding their cause. I think it never occurred to censors that the satire of the book would transcend the Austro-Hungarian Empire and would work as a satire of a soviet bureaucracy just as well. This, it was widely available both in USSR and in other Eastern Block countries, and even had luxury editions, I still have one such edition. reply 082349872349872 18 hours agoparentprevLike the joke about Stalin's underling muttering under his breath about \"that bastard with the moustache\", I wouldn't be surprised if either (a) the original censors had said \"anti Austria-Hungary good\" without giving a moment's thought as to how well the satire fit their own system, or (b) a particularly bright censor (or set of censors) realised they could always fall back on (a) for plausible deniability. Compare https://news.ycombinator.com/item?id=39697389 (or https://upload.wikimedia.org/wikipedia/ru/b/ba/Sharik_Figvam... ?) reply analog31 19 hours agoprevIn English, there is at least one Bowdlerized translation, which ruins it. I found the Penguin Books edition to be quite good. It was my grandfather's favorite novel. He fought on the other side. reply c-smile 5 hours agoprevI am not sure that \"good soldier\" is a correct translation. Czech \"dobrého vojáka\" is more \"of brave (in `dashing` conotation) soldier\". So Hašek's humor starts right from the title. reply rekoros 6 hours agoprevI loved this book growing up - I’ve read it many times and remember it being really funny. I only read it Russian and have never seen the words “Švejk” or “Hašek” in non-Cyrillic. Also! In Russian, “the good” is translated as “the brave”. reply isolli 21 hours agoprevGlad to see this book promoted here! However, having compared the French translation to the original in Czech, I have to warn French-language readers that the translation was atrocious. As in, completely making up words and sentences that were not in the original. (Unfortunately, I know nothing about translations into English, and cannot recommend a good one.) Interestingly, Milan Kundera wrote a book (in French) that I highly recommend [0]. He draws examples from many different artistic works to weave a fascinating story discussing to what extent we can or should stay faithful to the original intention of an artist or creator. [0] https://www.goodreads.com/book/show/44382.Testaments_Betraye... reply isolli 21 hours agoparentThis prompted me to check, and the first translation in French was in fact the translation of a translation of a translation [1]. No wonder it strayed from the original! The English translation went through similar ordeals [2]. The more recent ones are presumably more faithful: > The first translation by Paul Selver was heavily abridged, reducing the novel to about two thirds of its original length. Selver's translation also bowdlerized the original text, omitting paragraphs and occasionally pages that may have seemed offensive; despite this he has been praised for preserving some of the tension in the work between Literary and Common Czech. [1] https://fr.wikipedia.org/wiki/Les_Aventures_du_brave_soldat_... [2] https://en.wikipedia.org/wiki/The_Good_Soldier_%C5%A0vejk#Tr... reply dmurray 21 hours agorootparentThe second comment on the article - worth reading in itself - is signed by Švejk himself, with a detailed criticism of the Parrott translation, recommending instead a 2000 translation by Sadlon. Anyone else have insight on which translation I should read? reply bitsinthesky 17 hours agorootparentSadlon sells books in parts, i read the first book of his translation. Thought it was good, but given the needing to buy multiple books and the ugly cover art, I’m happy with Penguin. If it is true Penguin is an inferior translation or too flowery, it still reads as a very entertaining book. reply dhosek 8 hours agoprevThere are a pair of Czech films based on the novels which are delightful to watch. I don’t know if they’re streaming anywhere, I watched them in the days of DVDs in the mail from Netflix. reply jug 17 hours agoprevRelated, popular Czech pub in Stockholm :D https://maps.app.goo.gl/GbNAjLTPCpNwkSwf9 reply KingOfCoders 21 hours agoprevLoved watching Švejk films as a kid. reply projektfu 14 hours agoprevI love this book and, having read it, it gave me a new was of looking at \"Gomer Pyle, USMC\". Probably not the intention of the series creator, but imagining Pyle as much smarter than he lets on and quite mischievous is a lot of fun. reply MichaelRo 19 hours agoprevI tried to read the book as a kid when I was maybe 6h or 7th grade, along with Jules Verne and what else. Didn't finish it, heck, I abandoned it quickly. Maybe it's one of those things that you need to be an adult to appreciate. Unfortunately there's no lack of content nowadays, so I'm not sure I'll give the book another try. reply scyzoryk_xyz 16 hours agoprevMy underground Nazi-resistance fighter, Auschwitz survivor and later staunch-idealist socialist-communist grandfather loved this book and identified with it deeply. Edit: I might add that this book and author had a similar sort of status on this side of the iron curtain as Joseph Heller and his military Catch-22 humor. reply wly_cdgr 19 hours agoprevWow, what? How is my favorite novel the top result on HN right now. reply maximinus_thrax 17 hours agoprevThis is my comfort book. I've read it 6 or 7 times, first time when I was around 12 years old. It's a book which still has the ability to pull me out of whatever pit I am at certain times. reply chalst 19 hours agoprevIs the sense of humour comparable to the Flashman series? reply mikrl 18 hours agoparentIt’s like catch 22 but more crude, and more brutal. Lots of drinking, stealing, fist fighting, long winded anecdotes (with plenty of embellishments) telling lies to get into / out of trouble, and ethnic humour reflecting the attitudes which were typical of the imperial period: Germans/Austrians look down on Czechs, Czechs resent the Germans and are unfriendly with Hungarians, the imperial soldiers harass Jews (who get them back in various ways) and there is a scene where the Czechs in military jail are practicing their Russian: for an assumed surrender at the front. reply chalst 9 hours agorootparentI guess what you described, though unpleasant sounding, fitted the Czech Republic’s history. Perhaps that’s why hilbert42 liked it. reply talkingtab 21 hours agoprevOne must wonder about the Czechs. There is the language for one thing. There is the resilience - Nazis, Communists and the Velvet Revolution. Then Closely Watched Trains, Zelary, Divided We Fall, The Unbearable Lightness of Being. And this. Maybe having an singular language does something? reply mikrl 20 hours agoparentA large part of Švejk’s humor comes from the multilingual nature of the Austro-Hungarian empire at that time. The common soldiers speak Czech amongst themselves, German to the commanding officers, and a drunken old Polish colonel butchers both languages while giving them a pep talk. There are also miscommunications with Hungarians and Tatars. Central Europe is heavily multicultural and multilingual, even in 1914, but there are still strong national identities; because of, not despite. reply yreg 19 hours agorootparentSome parts of it used to be more multicultural and multilingual than they are now. Bratislava was 36% German, 33% Slovak and 29% Hungarian in the 1919 census. Now it's ~90% Slovak. reply ufocia 20 hours agoparentprevYou're whitewashing at least the WWII era. The Czecho-Slovak government capitulated pretty quickly after Germany's demands, ..., and the country was used to support Germany's was efforts. TBH, they did not receive a whole lot of support from their prior allies, to say the least, ahead of the capitulation. https://en.m.wikipedia.org/wiki/Second_Czechoslovak_Republic As an aside, hopefully the relative lack of support for Ukraine does not have similar outcomes. There are some significant similarities between the two. reply confidantlake 19 hours agorootparentThis does not seem like a fair criticism or framing of the situation. Every country Germany occupied was used to support Germany's war efforts. The country had little choice but to surrender, they were hung out to dry by their allies. Despite this, they still resisted at great personal cost. Heydrich was assassinated in Prague by Czech resistance fighters. The reprisals were brutal, with thousands killed in response. My grandmother who is still alive lived through this time. Every day at school they announced the names of those executed by the Natzis in order to intimidate the populace. reply ufocia 17 hours agorootparentIn my criticism I made a conscious effort to single out the Czechoslovak government (I should've probably narrowed it down to Beneš and Hácha in particular), as opposed to the citizenry. Perhaps surprisingly, after the outbreak of WWII, Beneš went on to be a leader of the resistance, though from exile. reply euazOn 10 hours agorootparentThe Hácha story may be a bit more complicated that it may seem at first. Not sure whether you're a Czech speaker, if so, check this out: https://www.youtube.com/watch?v=vBPXsaTgHGQ reply ufocia 6 hours agorootparentThanks. The clip appears to discuss the history of scouts and their participation in the resistance. Is there a segment that is particularly relevant? The whole Central European story is complicated. The countries were hashed and rehashed on fairly regular bases. Allegiances changed a lot. Leaders made serious mistakes. People were multidimensional. reply aba_cz 18 hours agorootparentprevThat's no whitewashing. Not sure where you got this idea from but if you read the link to https://en.m.wikipedia.org/wiki/Munich_Agreement you'd realize that what you wrote is completely incorrect and almost a lie. Czechia was not invited to that meeting and European superpowers decided that it should cede to Germany. Plus Germany invaded Czechia in 1939. Czechs would go to war and lost it in days (just look at the size and position) and would be a pariah in Europe if they didn't listen. reply ufocia 17 hours agorootparent\"The Czechoslovak capitulation precipitated an outburst of national indignation. In demonstrations and rallies, Czechs and Slovaks called for a strong military government to defend the integrity of the state. A new cabinet, under General Jan Syrový, was installed, and on 23 September 1938, a decree of general mobilization was issued. The Czechoslovak Army was modern, had an excellent system of frontier fortifications and was prepared to fight. The Soviet Union announced its willingness to come to Czechoslovakia's assistance. Beneš, however, refused to go to war without the support of the Western powers.\" reply aba_cz 16 hours agorootparentThere's no citation for this in Wiki and Soviet Union and Germany signed Molotov-Ribbentrop Pact not that long after. So this quote (and Soviet Union/Russia in general as it's obvious why they would \"help\") is really not trustworthy and not based on evidence. reply ufocia 5 hours agorootparentThe Ribbentrop-Molotov agreement was secret, so I'm doubtful that the Czechoslovak government was aware of the machinations until long after it was signed. Here's another quote restating the same info followed by a citation to Haslam, Jonathan (1983). Soviet Foreign Policy, 1930–33. The Impact of the Depression. New York: St. Martin's Press.: \"A new Czechoslovak cabinet, under General Jan Syrový, was installed and on 23 September a decree of general mobilization was issued which was accepted by the public with a strong enthusiasm – within 24 hours, one million men joined the army to defend the country. The Czechoslovak Army, modern, experienced and possessing an excellent system of frontier fortifications, was prepared to fight. The Soviet Union announced its willingness to come to Czechoslovakia's assistance\" Oh, and it was Czechoslovakia not Czechia. I'm curious why you're revising history yourself while questioning my sources. reply The_Colonel 19 hours agorootparentprev> TBH, they did not receive a whole lot of support from their prior allies, to say the least, ahead of the capitulation. The \"support\" Czechoslovakia received from the western allies was an order to capitulate to German demands. As a reminder, this was the situation in 1938: https://hosting.photobucket.com/images/u314/erding/Cz_map_15... The situation was much more hopeless than e.g. Ukraine was/is in. The Czech part was almost completely surrounded by Germany (controlling Austria and Silesia). Slovak part had a long border with Nazi-allied Hungary. Poland was not friendly at the time (taking part in the partition). The only kinda friendly neighbor was the tiny sliver of border in the east with Romania. If the Czechoslovakia decided to fight, it would be accused of aggression by the western powers (who basically declared Germany is in the right in Munich). reply ufocia 18 hours agorootparentThe claim of \"participation\" in the so called partition is inflammatory. You make it sound like Poland was a party to some kind of an agreement to dissolve Czechoslovakia, when there is no evidence of that, especially in retrospect. https://en.wikipedia.org/wiki/Polish%E2%80%93Czechoslovak_bo... I agree that the Czechoslovakian situation was less hopeful than that of Ukraine, at least for the moment. reply AmalgatedAmoeba 2 hours agorootparentI think it’s pretty clear the comment was referring to the partition of the sudetenland, which Poland was absolutely a (albeit minor) participant in. But thank you for linking the article. I’ve always kinda assumed that Poland was given the territories by the Nazis as a way to spread the blame. Turns out they demanded it themselves outside of the Munich conference. reply Toutouxc 20 hours agoparentprev> There is the language for one thing. > having an singular language What's that? reply NeoTar 19 hours agorootparentYeah - If singular means distinct, and even setting aside Slovak, then Czech is part of the West Slavic language family and my Polish-speaking partner says there is a degree of mutual intelligibility. reply imp0cat 13 hours agorootparentYes, they sound very similar, but (because of historical reasons) the spelling is quite different (multiple letters in Polish vs accents/diacritics in Czech). reply ufocia 5 hours agorootparentThey probably sound as similar to each other as German does to Danish. reply ufocia 19 hours agorootparentprevCzecho-Slovakia was a multicultural country with more than one language in common use. This was arguably one of the shortcomings that led to its WWII era capitulation. reply rightbyte 13 hours agorootparentShortcomings? What is up with these military strategic analysis that imply that Chechoslovakia could do anything but getting different degrees of crushed between Germany, Hungary and Poland? reply asveikau 13 hours agorootparentI've noticed an uptick in recent years of people who believe the multiculturalism is harmful to a society's survival. This is extremely popular with American right wingers who would like to limit immigration or segregate people by races. One of my favorite examples of a multi-ethnic state in Europe (kind of biased since I have some ancestry from there) is the Polish-Lithuanian commonwealth. That lasted a good long while with a mix of Balts, West Slavs, and East Slavs. reply ufocia 5 hours agorootparentThe Polish-Lithuanian Commonwealth being a federation was hardly a mix. Also, despite the union's somewhat long existence, it was the union's multiculturalism that arguably led to its demise. reply wormik 8 hours agorootparentprevRead this https://winstonchurchill.org/resources/speeches/1930-1938-th... It might shape your view a bit reply ufocia 5 hours agorootparentNot really, the Brits underestimated the Germans and Central Europe in general was sacrificed on the altar of presumingly keeping the war out of the West. reply imp0cat 19 hours agorootparentprevFirst, he OP specifically mentions \"the Czechs\", as in the Czech part of Czechoslovakia. Second, languages had nothing to do with it. There was an idea that sacrificing a part of Czechoslovakia will be enough to keep Hitler at bay (https://en.wikipedia.org/wiki/Munich_Agreement). reply ufocia 19 hours agorootparentWhich Czech part, Bohemia, Moravia, Czech Silesia, or ...? Was it the \"regions with German-speaking majority\"? Languages had everything to do with it. \"Bohemia became a part of Czechoslovakia, defying claims of the German-speaking inhabitants that regions with German-speaking majority should be included in the Republic of German-Austria.\" reply imp0cat 13 hours agorootparentBut German, the language, was spoken pretty much everywhere (thanks to the Austro-Hungarian legacy). The German-speaking inhabitants, that is a whole different story. reply ufocia 4 hours agorootparentOK, now you're backpedaling and muddying the waters. Language and customs are the most prominent aspects of a cultural identity. English is spoken pretty much everywhere. What's your point? reply hilbert42 19 hours agoparentprevI think you're onto something. I don't speak Czech but I've been there a number of times and I know people who live there. When Hašek wrote Švejk the Czechs were surrounded and influenced by vastly different nations—the crumbling remnants of the Austro-Hungarian Empire—which they were part of—the Russian Empire and Germany—both of which were in chaos after WWI. Even today they're still surrounded but at least now they're an independent nation with their own language so perhaps it's not surprising what comes out of them is quite unique. It's quite some years since I saw Closely Watched Trains with English subtitles and it had a huge impact on me. It's one of those films that one cannot get out of one's mind for days. In its own understated way it's a great film and it's not surprising that it was a Czech production. Its ending upset me greatly because whilst its story was fiction, it reminded me of similar tragic scenarios that were played out for real many times during WWII (it seems to me one of the purposes of the film was to remind us of the fact). BTW, when I first went to Czechoslovakia it was still under communist rule and the only practical (easiest) way to get from Vienna to Prague was by train from Franz-Josefs-Bahnhof and Emperor Franz Joseph Railway line. For some reason seeming known to the communists we had to use this single track line instead of the more modern dual track line via Brüno. I mention it because the Franz Joseph Railway was a once-in-a-lifetime experience to travel on, the track was in such terrible condition that one thought the train would derail any moment and the train only did about 30km/h max. After Communism fell the track via Brüno was opened up and although a much longer route the trip only took half as long. reply foobarian 17 hours agorootparentWhen I went there first it was also still under communist rule, and the thing I still remember the most is that bread loaves commonly sold in the grocery stores had the price embossed into the crust (IIRC \"5 Kčs\"). Centrally controlled economies eh? So stable that it was practical to make price stamps distributed to bakeries. I wish I could get my hands on one of these brands... reply inglor_cz 15 hours agorootparentYou reminded me of my own childhood. Yes, 5 Kčs was a standard price. I was not yet 13 when the no-longer-Communist Czechoslovak government liberalized the prices. Back then, I was profoundly unsettled by the idea that the same loaf of bread could cost a different amount of money in two different stores. It felt as unnatural as having multiple birthdays. reply hilbert42 1 hour agorootparentprev\"I wish I could get my hands on one of these brands...\" Ha, right. That brings back memories from when I was living and working in Vienna. When walking by building or construction sites around the city one would often come across bricks that were several centuries old and one could tell this because the molds from which the bricks were made had the coat of arms of whomever Hapsburg/Archduchy ruler of Austria was in power at the time embossed into them, thus bricks produced from them are time capsules time-stamped with the era from which they came. It was commonplace to see bricks made, say, in the time of Archduchess Maria Theresa who—as we're talking about Czechoslovakia—was also Queen of Bohemia around the time of the Silesian Wars/Battle for Prague. (It seems to me the many wars in and around Bohemia over the centuries only adds to the point about why the Czechs are the way they are; essentially wars and politics likely framed Hašek's worldview and thus Švejk.) Anyway, it had been my intension to souvenir one of these bricks in pristine condition and bring it back home to display on my mantelpiece but unfortunately I never quite got around to it. :-) For me, one thing that truly stood out in Czechoslovakia under Communism which was in stark contrast with noncommunist countries was the lack advertising and billboards on streets and roadways and that was especially evident in big cities such as Prague. Moreover, when I first went to Prague it seemed to me that I was stepping back in time as communist Prague had been preserved as a beautiful 18th Century city because the communists had done very little modernization during their time in power; that was also the situation for much of the country, witness my comment about the woefull state of the Emperor Franz Joseph Railway. I recall reading somewhere the reason for why the 1984 movie Amadeus, which was about Mozart and his rival Salieri, was filmed in Prague, and it was because its center remained so much like it was in the 1780s as that was the period in which the film was set. The film's producers specifically made the point that the lack of visible advertising and billboards was one† of the primary reasons for choosing the city. That's not the situation now, not long after Communism fell Prague began to look like other Western cities, which to me seems like a shame. That lack of modernization and not keeping up with best practice under Communism wasn't all positive. The crawling, almost walking speed of train trips on the Franz Joseph Railway line and various trips by car allowed me to spend much time looking out of windows at the countryside. On the train at some short distance south of Prague I recall seeing pollution from what seemed to be a cement factory. For miles around tree leaves were covered with a dirty cement-colored dust which gave the nearby countryside a horrible yellow-grayish appearance. I may be wrong but after viewing both cities and countryside and talking with those who lived there I formed the opinion that back then this sort 'malaise' was reasonably widespread over much of the country. Nowadays, that's changed much for the better. _ † Others were that Prague holds relevance for the story in that its present architecture is similar to Vienna of the 18th C. which made for an authentic backdrop, and that in the 1780s Mozart's Don Giovanni was deemed too salacious and sleazy for conservative Viennese society and had to have its premiere performance in more liberal Prague. reply arethuza 21 hours agoprevI learned of The Good Soldier Švejk from Alexei Sayle's autobiography \"Stalin ate my homework\" - which I can strongly recommend, particularly the audiobook narrated by the author. reply nutrie 16 hours agoprevInteresting. I didn't know Svejk was popular at all outside Czechia. I must say, it's somewhat a bittersweet realization. The way I and many other Czechs see it, Hasek did us quite a disservice. Still, if you guys enjoy it, hats down. reply spacechild1 16 hours agoparentIt is very popular in Austrian, in particular the TV series from the 70s with Fritz Muliar as the main actor 1972: https://de.wikipedia.org/wiki/Die_Abenteuer_des_braven_Solda.... The theatre plays are also quite popular. I even read the novel as a kid because my father had it in his library :) Why do you think Hasek did you a disservice? reply nutrie 15 hours agorootparentIn a nutshell, we did it to ourselves by excessively promoting the novel over the course of many decades. Starting with the avant-garde movements of the 20's, through the communism era (Hasek was a socialist and a communist) to this day, we've been essentially saying Svejk characterizes the true nature of what it means to be a Czech. You literally hear school teachers tell their students a drunk devious simpleton is considered a role model. The topic is quite complex, there's more history and politics involved, but I'm not going there. Disclaimer: By no means am I criticizing the book or people who like it. reply mcepl 12 hours agorootparentI am a Czech as well, and although I know exactly what you are talking about, I have found my own way towards Švejk lately. I am afraid (all of them awesome artists, but too much pushing the novel in the humour direction) Lada, Hrušínský, and Trnka are guilty a lot for the feeling which is prevalent now. Contrary to that, I was fascinated a lot by listening to M.C.Putna’s discussion of Švejk in https://www.mujrozhlas.cz/putnuv-jihocesky-literarni-mistopi... and by listening to the novel in audio, where he understands basically Švejk as “Kafka by other means”, and there is a lot to it. reply dboreham 11 hours agoparentprevI was introduced to him via a BBC radio adaptation in the 1970s (80s?). Around the same time as \"The Hitchhiker's Guide to the Universe\". reply rareitem 20 hours agoprev [–] > Hašek ran for office as a member of his own newly founded Party of Moderate and Peaceful Progress Within the Limits of the Law From wikipedia > The platform of the candidate for the Vinorhady election district, Jaroslav Hašek, consisted of seven points:[16] The reintroduction of slavery. The nationalization of janitors (\"similar to how it is in Russia [...], where every janitor is simultaneously a police informer\"). The rehabilitation of animals. The institutionalization of feeble-minded MPs. The reintroduction of the Inquisition. Judicial immunity for priests and the Church (\"In cases where a schoolgirl is deflowered by a priest\"). The mandatory introduction of alcoholism. reply ufocia 20 hours agoparent [–] Yes, humor. reply frantathefranta 20 hours agorootparent [–] Well his Soviet escapades seem to suggest that not all of them were wholly humorous. reply some_random 19 hours agorootparentReading this article and expecting him to be a prototypical anti-war writer only to see that he was at one point a COMMISSAR IN THE RED ARMY caused quite a bit of whiplash reply ufocia 19 hours agorootparentCentral Europe was the place of a lot of complex belligerence at the time. Given his penchant for humor, I'm not surprised that he was a commissar. 'The Bolshevik Party established political commissars in 1918 to control and improve morale in the military forces.\" For all I know it could've been for self-preservation. I'm not trying to be an apologist for him. Rather, I'd like to encourage people to learn a bit more about him and his environment before jumping to conclusions based on a single point in his life. reply ufocia 19 hours agorootparentprev\"In 1911, he founded The Party of Moderate Progress Within the Bounds of the Law. He founded it with his friends in the Vinohrady pub called U zlatého litru (The Golden Liter) to parody the political life of that time.\" He didn't become a Communist until about 1918. The most you can say is that he had a complex life. reply The_Colonel 20 hours agorootparentprevCan you be more specific? Which ones do you believe were serious? reply thriftwy 19 hours agorootparentprev [–] I believe these refer to the pre-Soviet state of affairs when the yard keeper (дворник) of an apartment block was basically subordinate to the city police - at least in the capital of St. Petersburg. reply ufocia 19 hours agorootparent [–] That was probably the case also during the Soviet era. It may well be the case even today. reply thriftwy 18 hours agorootparent [–] I believe that during the Soviet era, almost every position will be \"on the guard\" not just the yard keeper (as depicted in \"The Diamond Arm\" of 1968). After the Soviet era, yard-keeping services are way understaffed to be useful for that, and also mostly rely on immigrant labor lately. Still, you can never be sure. reply ufocia 17 hours agorootparent [–] I wasn't aware that Russia has immigrant labor, though I shouldn't have been surprised given their relative economic strength. reply 082349872349872 14 hours agorootparent [–] Some music video commentary on russian immigrant labour: https://www.youtube.com/watch?v=5Fix7P6aGXQ (Uzbek artist) https://www.youtube.com/watch?v=_7pSztJFomE (Circassian artist) https://www.youtube.com/watch?v=1ugivNRYfjc (Russian artist — for the taxi driving character introduced at 3:30) these are all from about a decade back; there's no doubt been much more since... reply thriftwy 13 hours agorootparent [–] Notes from the Underground Internets. reply 082349872349872 10 hours agorootparent [–] It is rather dark —an almost impenetrable night— in this crocodile, but at least it has USB-C charging and the 5G reception is excellent, so —thus far anyway— it hasn't affected my HN habit. (I must admit I ♥ the MC Doni lyric: \"إن شاء الله или c'est la vie\". Anyone know of a lyrical line that beats it, either with four languages, or scripts written in three different directions [r-to-l, l-to-r, u-to-d?], etc?) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"The Good Soldier Švejk\" is a satirical novel by Czech writer Jaroslav Hašek, depicting the antihero Josef Švejk in World War I, mocking bureaucracy, the military, and war.",
      "The novel has been translated into multiple languages and served as inspiration for various adaptations like plays, films, and comic books.",
      "Despite Hašek's untimely death before finishing the planned six parts of the story, the enduring legacy of Švejk continues to influence and inspire generations."
    ],
    "commentSummary": [
      "The discussion delves into classic books such as \"The Good Soldier Švejk,\" \"The Little Prince,\" and \"Catch-22,\" emphasizing humor and societal critiques in their narratives.",
      "Readers explore evolving perspectives on childhood favorites over time, reflecting on themes and subtext within the stories.",
      "Insights cover the enduring appeal of Švejk, its humor, illustrations, and examination of the human spirit, alongside discussions on military life, society, Czechoslovakia in WWII, cultural identity, and language differences, as well as the author Jaroslav Hašek's political views and immigrant labor in Russia."
    ],
    "points": 307,
    "commentCount": 172,
    "retryCount": 0,
    "time": 1710415393
  },
  {
    "id": 39710454,
    "title": "Getty Museum and Smithsonian Offer 88k Free Art Images",
    "originLink": "https://www.openculture.com/2024/03/the-getty-makes-nearly-88000-art-images-free-to-use-however-you-like.html",
    "originBody": "Online Courses Audio Books Movies Podcasts K-12 eBooks Languages Donate The Getty Makes Nearly 88,000 Art Images Free to Use However You Like in Archives, MuseumsMarch 8th, 2024 6 Comments Since the J. Paul Get­ty Muse­um launched its Open Con­tent pro­gram back in 2013, we’ve been fea­tur­ing their efforts to make their vast col­lec­tion of cul­tur­al arti­facts freely acces­si­ble online. They’ve released not just dig­i­tized works of art, but also a great many art his­to­ry texts and art books in gen­er­al. Just this week, they announced an expan­sion of access to their dig­i­tal archive, in that they’ve made near­ly 88,000 images free to down­load on their Open Con­tent data­base under Cre­ative Com­mons Zero (CC0). That means “you can copy, mod­i­fy, dis­trib­ute and per­form the work, even for com­mer­cial pur­pos­es, all with­out ask­ing per­mis­sion.” The Get­ty sug­gests that you “add a print of your favorite Dutch still life to your gallery wall or cre­ate a show­er cur­tain using the Iris­es by Van Gogh.” But if you search the open con­tent in their archive your­self, you can sure­ly get much more cre­ative than that. The por­tal’s inter­face lets you search by cre­ation date (with a time­line graph stretch­ing back to the year 6000 BC), medi­um (from agate and alabaster to wood­cut and zinc), object type (includ­ing paint­ings, pho­tographs, and sculp­tures, of course, but also akro­te­ria, horse trap­pings, and tweez­ers), and cul­ture. The selec­tion reflects the wide man­date of the Get­ty’s col­lec­tion, which encom­pass­es as many of the civ­i­liza­tions of the world as it does the eras of human his­to­ry. In the Get­ty’s open-con­tent archive, you’ll find ancient sculp­ture from Greece, Rome and many oth­er parts of the world besides; a frag­men­tary oinochoe (that is, a wine jug) from third-cen­tu­ry-BC Ptole­ma­ic Egypt; lav­ish­ly illu­mi­nat­ed medieval books of hours (of the kind pre­vi­ous­ly fea­tured here on Open Cul­ture); works by such inno­v­a­tive French painters as Édouard Manet and Edgar Degas; the stereo­scop­ic pho­tog­ra­phy of Car­leton H. Graves, who in the late nine­teenth and ear­ly twen­ti­eth cen­tu­ry cap­tured places from Den­mark and Pales­tine, to Japan and Korea; the dar­ing abstrac­tions of artists like Hannes Maria Flach, Jaromír Funke, and Fran­cis Bruguière. But what you do with them is, of course, entire­ly up to you. Enter the col­lec­tion here. Relat­ed con­tent: The Get­ty Dig­i­tal Archive Expands to 135,000 Free Images: Down­load High Res­o­lu­tion Scans of Paint­ings, Sculp­tures, Pho­tographs & Much Much More A Search Engine for Find­ing Free, Pub­lic Domain Images from World-Class Muse­ums 100,000 Free Art His­to­ry Texts Now Avail­able Online Thanks to the Get­ty Research Por­tal Down­load Great Works of Art from 40+ Muse­ums World­wide: Explore Artvee, the New Art Search Engine The Smith­son­ian Puts 4.5 Mil­lion High-Res Images Online and Into the Pub­lic Domain, Mak­ing Them Free to Use Down­load Over 325 Free Art Books From the Get­ty Muse­um Based in Seoul, Col­in Marshall writes and broad­casts on cities, lan­guage, and cul­ture. His projects include the Sub­stack newslet­ter Books on Cities, the book The State­less City: a Walk through 21st-Cen­tu­ry Los Ange­les and the video series The City in Cin­e­ma. Fol­low him on Twit­ter at @colinmarshall or on Face­book. by Colin MarshallPermalinkComments (6)Sup­port Open Cul­ture We’re hop­ing to rely on our loy­al read­ers rather than errat­ic ads. To sup­port Open Cul­ture’s edu­ca­tion­al mis­sion, please con­sid­er mak­ing a dona­tion. We accept Pay­Pal, Ven­mo (@openculture), Patre­on and Cryp­to! Please find all options here. We thank you! Comments (6) You can skip to the end and leave a response. Pinging is currently not allowed. Eileen Tipple says: March 8, 2024 at 4:48 pm Would like tolearn how to get images. Reply Janet Borders says: March 9, 2024 at 7:18 am Wow cool love the old Get­ty ! Why did you do this ? Is it legal To use these images in art work ? Crazy. Thanks by the way How do you sug­gest we use them in oil paint­ings ? Can I sell them? Any­thing I use in my oil paint­ings. ? Thanks so much. Reply Maureen Davenport says: March 9, 2024 at 11:46 am What an incred­i­ble gift! Thank you for open­ing your archives to the world ! Reply Susan says: March 9, 2024 at 6:35 pm Hi! I would like to know how to access your free art con­tent from the Get­ty. Do you have an on-line cat­a­log? I am reluc­tant to give a dona­tion before I see the qual­i­ty of the images. Thanks in advance for your response. Reply Matt says: March 9, 2024 at 10:35 pm More than a lit­tle con­cern­ing. A col­lec­tor sweeps up (robs graves and loots and then trades) cul­tur­al col­lat­er­al and mate­r­i­al cul­ture from around the world. Then decides, with­out exter­nal con­sul­ta­tion, which objects war­rant repa­tri­a­tion and then decides to “open it up” to the Inter­net free of charge, free of prove­nance; free of oblig­a­tion to, or even under­stand­ing of, the sig­nif­i­cance of the mate­r­i­al, the mate­ri­al’s val­ue to its com­mu­ni­ty or to the indi­vid­u­als (or decen­dants there­of) depict­ed with­in the mate­r­i­al. The mate­r­i­al is made avail­able to any­one curi­ous and on the inter­net, with no need to con­sid­er its right­ful cus­to­di­ans. Sim­i­lar­ly, there is no oblig­a­tion to con­sid­er any imma­te­r­i­al val­ue con­nect­ed to these trea­sures… let cen­turies of care, devo­tion, knowl­edge, fam­i­ly mem­o­ry, doc­u­men­ta­tion, trau­ma, explo­ration, spir­i­tu­al con­nec­tion, warn­ings, craft and men­tor­ship be splat­tered accross bill­boards, GIFS, fake news and social media trash-fires… Reply Michael McGuire says: March 14, 2024 at 2:08 pm How do I review the cat­a­logue of impres­sion­ists? Reply Leave a Reply Name (required) Email (required) Message Essentials 1,700 Free Online Courses 200 Online Certificate Programs 100+ Online Degree & Mini-Degree Programs 1,150 Free Movies 1,000 Free Audio Books 150+ Best Podcasts 800 Free eBooks 200 Free Textbooks 300 Free Language Lessons 150 Free Business Courses Free K-12 Education Get Our Daily Email Support Us We're hoping to rely on loyal readers, rather than erratic ads. Please click the Donate button and support Open Culture. You can use Paypal, Venmo, Patreon, even Crypto! We thank you! Free Courses Art & Art History Astronomy Biology Business Chemistry Classics/Ancient World Computer Science Data Science Economics Engineering Environment History Literature Math Philosophy Physics Political Science Psychology Religion Writing & Journalism All 1500 Free Courses 1000+ MOOCs & Certificate Courses Receive our Daily Email FREE UPDATES! GET OUR DAILY EMAIL Get the best cultural and educational resources on the web curated for you in a daily email. We never spam. Unsubscribe at any time. Click Here to sign up for our newsletter FOLLOW ON SOCIAL MEDIA Free Movies 1150 Free Movies Online Free Film Noir Silent Films Documentaries Martial Arts/Kung Fu Animations Free Hitchcock Films Free Charlie Chaplin Free John Wayne Movies Free Tarkovsky Films Free Dziga Vertov Free Oscar Winners Free Language Lessons Arabic Chinese English French German Italian Russian Spanish All Languages Free eBooks 700 Free eBooks Free Philosophy eBooks The Harvard Classics Philip K. Dick Stories Neil Gaiman Stories David Foster Wallace Stories & Essays Hemingway Stories Great Gatsby & Other Fitzgerald Novels HP Lovecraft Edgar Allan Poe Free Alice Munro Stories Jennifer Egan Stories George Saunders Stories Hunter S. Thompson Essays Joan Didion Essays Gabriel Garcia Marquez Stories David Sedaris Stories Stephen King Chomsky Golden Age Comics Free Books by UC Press Life Changing Books Free Audio Books 700 Free Audio Books Free Audio Books: Fiction Free Audio Books: Poetry Free Audio Books: Non-Fiction Free Textbooks 200 Free Textbooks Free Physics Textbooks Free Computer Science Textbooks Free Math Textbooks K-12 Resources Free Books Free Video Lessons Web Resources by Subject Free Language Lessons Quality YouTube Channels Teacher Resources Test Prep All Free Kids Resources Free Art & Images All Art Images & Books The Met The Getty The Rijksmuseum Smithsonian The Guggenheim The Tate The National Gallery The Whitney LA County Museum Stanford University British Library Google Art Project French Revolution Getty Images Guggenheim Art Books Met Art Books Getty Art Books New York Public Library Maps Museum of New Zealand Street Art Smarthistory Rembrandt Van Gogh Coloring Books Free Music All Bach Organ Works All of Bach 80,000 Classical Music Scores Free Classical Music Live Classical Music 9,000 Grateful Dead Concerts Alan Lomax Blues & Folk Archive Writing Tips Hemingway Fitzgerald Stephen King Ray Bradbury William Zinsser Kurt Vonnegut Toni Morrison Edgar Allan Poe Margaret Atwood David Ogilvy Steinbeck Billy Wilder Archive All posts by date Personal Finance Open Personal Finance Categories Amazon Kindle Animation Apple Architecture Archives Art Artificial Intelligence Astronomy Audio Books Beat & Tweets Biology Books Business Chemistry Coloring Books Comedy Comics/Cartoons Computer Science Creativity Current Affairs Dance Data Deals Design e-books Economics Education English Language Entrepreneurship Environment Fashion Film Finance Food & Drink Games Gender Google Graduation Speech Harvard Health History How to Learn for Free Internet Archive iPad iPhone Jazz K-12 Language Language Lessons Law Letters Libraries Life Literature Magazines Maps Math Media MIT MOOCs Most Popular Museums Music Nature Neuroscience Online Courses Opera Philosophy Photography Physics Podcasts Poetry Politics Pretty Much Pop Productivity Psychology Radio Random Religion Sci Fi Science Software Sports Stanford Technology TED Talks Television Theatre Travel Twitter UC Berkeley Uncategorized Video - Arts & Culture Video - Politics/Society Video - Science Video Games Web/Tech Wikipedia Writing Yale YouTube Great Lectures Michel Foucault Sun Ra at UC Berkeley Richard Feynman Joseph Campbell Carl Sagan Margaret Atwood Jorge Luis Borges Leonard Bernstein Richard Dawkins Buckminster Fuller Walter Kaufmann on Existentialism Jacques Lacan Roland Barthes Nobel Lectures by Writers Toni Morrison Bertrand Russell Oxford Philosophy Lectures About Us Open Culture scours the web for the best educational media. We find the free courses and audio books you need, the language lessons & educational videos you want, and plenty of enlightenment in between. Advertise With Us Great Recordings T.S. Eliot Reads Waste Land Sylvia Plath - Ariel Joyce Reads Ulysses Joyce - Finnegans Wake Patti Smith Reads Virginia Woolf Albert Einstein Charles Bukowski Bill Murray Hemingway Fitzgerald Reads Shakespeare William Faulkner Flannery O'Connor Tolkien - The Hobbit Allen Ginsberg - Howl W.B Yeats Ezra Pound Dylan Thomas Anne Sexton John Cheever David Foster Wallace Subscribe to our Newsletter Book Lists By Neil deGrasse Tyson Ernest Hemingway F. Scott Fitzgerald Allen Ginsberg Patti Smith Brian Eno Henry Miller Christopher Hitchens Joseph Brodsky W.H. Auden Donald Barthelme Carl Sagan David Bowie Samuel Beckett Art Garfunkel Marilyn Monroe Jorge Luis Borges Picks by Female Creatives Syllabi WH Auden David Foster Wallace Donald Barthelme Allen Ginsberg Zadie Smith & Gary Shteyngart Spike Lee Lynda Barry Junot Diaz Favorite Movies Kubrick Kurosawa's 100 Tarantino Scorsese Tarkovsky David Lynch Werner Herzog Woody Allen Wes Anderson Luis Buñuel Roger Ebert Susan Sontag Scorsese Foreign Films Philosophy Films Archives March 2024 February 2024 January 2024 December 2023 November 2023 October 2023 September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 January 2020 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 June 2019 May 2019 April 2019 March 2019 February 2019 January 2019 December 2018 November 2018 October 2018 September 2018 August 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2017 July 2017 June 2017 May 2017 April 2017 March 2017 February 2017 January 2017 December 2016 November 2016 October 2016 September 2016 August 2016 July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 December 2009 November 2009 October 2009 September 2009 August 2009 July 2009 June 2009 May 2009 April 2009 March 2009 February 2009 January 2009 December 2008 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 March 2008 February 2008 January 2008 December 2007 November 2007 October 2007 September 2007 August 2007 July 2007 June 2007 May 2007 April 2007 March 2007 February 2007 January 2007 December 2006 November 2006 October 2006 September 2006 Search ©2006-2024 Open Culture, LLC. All rights reserved. Home About Us Advertise with Us Copyright Policy Privacy Policy Terms of Use Bio Audio Books Online Courses MOOCs Movies Languages Textbooks eBooks Open Culture was founded by Dan Colman.",
    "commentLink": "https://news.ycombinator.com/item?id=39710454",
    "commentBody": "The Getty makes nearly 88k art images free to use (openculture.com)284 points by coloneltcb 10 hours agohidepastfavorite72 comments autoexec 8 hours agoIt looks like a lot of this stuff is already in the public domain and so they are just letting people use the scans/photos of these works that they took and are hosting. It's a shame that we don't already have this being done by public libraries. reply mikae1 3 hours agoparent> It's a shame that we don't already have this being done by public libraries. What makes you say that? It's already done by so many institutions within the GLAM sector. They usually don't have the same marketing budget as Getty though. Here's[1] a glimpse into the digital heritage of the EU. That's a good starting point for some exploration. [1] https://www.europeana.eu/en reply xniclb 2 hours agorootparent> Unfortunately, the item media as provided to Europeana can not be displayed at the moment. Please try to download the media or view the item on the providing institution's website. Download link is a dead dropbox account. And this is the first thing I tried. reply notachatbot123 1 hour agorootparentBad luck to get something like that in 50,000,000+ chances. Which item was it? reply courseofaction 47 minutes agorootparentthe number chances is not the problem, it's their outcome ;) reply dhosek 8 hours agoparentprevSome do. A lot depends on the library’s resources, but the Library of Congress has a lot of free imagery available, and I think a number of other large public libraries with art collections also do the same. reply autoexec 7 hours agorootparentHopefully they're taking advantage of this release and adding these images and scans into their own collections. reply chefandy 4 hours agorootparentI'd be shocked if the IA wasn't all over this already. reply GuB-42 11 minutes agorootparentMany AIs didn't care about whether images were free to use before training. Including many from Getty, with the watermark, and it resulted in a lawsuit that is still ongoing. And 88k images is tiny when we consider that LAION has billions of entries. reply Vinnl 2 minutes agorootparentIA = the Internet Archive, https://archive.org. notatoad 6 hours agoparentprev>just letting people use don't dismiss the value in simply making them accessible. they're providing a platform to access these works, which is great. reply chefandy 4 hours agorootparentI'm surprised to find myself defending Getty Images at all, but here I am. Before I dealt with huge collections as a developer, I didn't consider how much intellectual work went into managing collections as entities-- Things like ontology, or even maintaining consistent terminology usage in that much metadata is not trivial, and older materials cause the most problems. Even if these were exclusively public domain images, it would still be a praiseworthy effort. I'm sure some Getty archivist or the like fought hard for this. reply jvergeldedios 3 hours agorootparentThis isn't a Getty Images initiative, but rather being run by the Getty Museum which is under the Getty Trust. My partner actually works on some of these systems at the Getty and you're right, it's daunting. The sad part is that the Getty gets to do these kinds of things only because it's one of the best endowed institutions on the planet with funding to pay researchers/archivists/developers to do this work. There is so much more that is locked away at large, medium, and small institutions that would be available for the public, but just isn't because of lack of funding. reply smrq 3 hours agorootparentprevThe J. Paul Getty Museum, not to be confused with Getty Images. (I made the same mistake reading the headline.) Don't worry, you can continue to hate on Getty Images at your leisure. reply supermatt 3 hours agorootparentprevIt’s 88k images… I think you are massively overestimating the complexity reply notachatbot123 1 hour agorootparentWhich necessary steps and how much time would you estimate per image? reply imgabe 7 hours agoparentprevEven if the artwork is in the public domain, the photo of the artwork that someone takes still has a copyright and you need permission to use it. reply CrazyStat 7 hours agorootparentThis is not true in the US. The most relevant case is Bridgeman v. Corel [1], ruling that photographic reproductions of public domain paintings could not be copyrighted. Museums like to pretend that they hold copyrights on these photos. They do not. (In the US). [1] https://en.wikipedia.org/wiki/Bridgeman_Art_Library_v._Corel.... reply imgabe 7 hours agorootparentIn practice, you still need the museum's cooperation to do anything commercial with it, for most people who don't have the resources to defend a lawsuit. reply Animats 5 hours agorootparentWikipedia has assumed, since Bridgeman vs. Corel, that images of public domain works are public domain. Once some portrait museum in the UK threatened to sue, but backed down quickly. reply autoexec 7 hours agorootparentprevMore importantly, even though you can't copyright a photo/scan of a public domain work you also don't have to share those images with others at all, you could still paywall them off and (arguably) impose additional restrictions as a condition of getting access, and you certainly don't have to host the files online for everyone like this. reply ufocia 4 hours agorootparentYes, you could physically and contractually prohibit others from copying the original work. reply dtech 40 minutes agorootparentCould you though? Once you have a good image if it isn't copyrighted it sounds like any licencing agreement is void. You could just distribute not under terms of the license, but as a public domain images. reply VanTheBrand 7 hours agorootparentprevThat’s jurisdiction dependent. For example it’s not longer the case in the UK. https://www.theartnewspaper.com/2023/12/29/court-of-appeal-r... reply ronsor 7 hours agorootparentprevThis is not true in the US. reply nemo 7 hours agorootparentUnder U.S. copyright law, the person who creates a work is the copyright owner. So if a photographer takes a picture of an artwork, they own the rights to their image. Read more here: https://www.copyright.gov/engage/visual-artists/ reply sgentle 5 hours agorootparentYou might find it helpful to refer to the Copyright Office's Compendium, which covers copyright law specifics in more detail. It's big, but quite approachable. Chapter 300 covers copyrightability in general: https://copyright.gov/comp3/chap300/ch300-copyrightable-auth... > 313.4(A): A work that is a mere copy of another work of authorship is not copyrightable. The Office cannot register a work that has been merely copied from another work of authorship without any additional original authorship. [...] Bridgeman Art Library, Ltd. v. Corel Corp., 36 F. Supp. 2d 191, 195 (S.D.N.Y. 1999) (\"exact photographic copies of public domain works of art would not be copyrightable under United States law because they are not original\"). Chapter 900 covers visual art specifically and goes into more detail on the copyrightability of photographs: https://www.copyright.gov/comp3/chap900/ch900-visual-art.pdf > 909.3(A): [...] A photograph that is merely a \"slavish copy\" of a painting, drawing, or other public domain or copyrighted work is not eligible for registration. The registration specialist will refuse a claim if it is clear that the photographer merely used the camera to copy the source work without adding any creative expression to the photo. Similarly, merely scanning and digitizing existing works does not contain a sufficient amount of creativity to warrant copyright protection. reply autoexec 7 hours agorootparentprevA photo of a public domain work doesn't generally count as \"creating a work\". Especially not when there's nothing artistic added or any additional context to it. If I just take a photo of an artwork that's already in the public domain it is essentially little more than a reproduction. reply inglor_cz 1 hour agorootparentprevCopyright only protects creative works, where the author's artistic intent can be distinguished. Faithful reproductions of non-copyrighted two-dimensional work are considered non-copyrightable, because nothing of artistic value is added in the process. (There is a lot of mechanical work around photos, but mechanical work doesn't enjoy copyright.) reply mediumsmart 4 hours agorootparentprevBut the photo needs to be taken at a weird angle and it helps to place a live squirrel somewhere on the artwork. reply virtualritz 15 minutes agoprevIt seems the highest res. images for sizes over 10k (greater side res) constantly fail for me. For example I can't download the 11k version of this [1]. Is anyone else experiencing this? [1] https://www.getty.edu/art/collection/object/103RHN reply lovegrenoble 4 minutes agoparentWorked for me reply dhosek 8 hours agoprevWhen I was publishing a typography magazine in the 90s, most of my covers were non-typographic images. I used an image of a statue of Venus from the Getty for one cover. They not only provided the transparency free of charge, but offered to take a picture from a different angle if I needed a different image of the statue (also for no charge). The Getty does a lot to share their collections. (In contrast, I paid a couple hundred dollars to LACMA for the use of a transparency of a 17th century painting in their collection.) reply bastardoperator 3 hours agoprevIf you're ever in LA, I recommend checking out the Getty. I'm by no means an art buff in any capacity, and honestly I thought going might be boring because I did the Getty Villa in Malibu when I was in elementary school and wasn't appreciative, but it completely changed my mind. Even if you don't like the art or the exhibits, the views of Los Angeles are amazing, probably better than Griffith in my personal opinion. reply stefanvdw1 1 hour agoprevNice! I love using high quality images of art for some of my personal projects. Might built something similar with these like I did for the Rijksmuseum in Amsterdam[1]. 1. https://randomrijks.com reply impjohn 1 hour agoparentVery cool. How are you extracting the colors from the image? Trying to do something similar but without yielding anything I'm happy with reply stefanvdw1 1 hour agorootparentThanks! Some of the artworks have the colors as part of their metadata, so I directly use those. For a different project I’m looking in into using k-means to determine the dominant colors. reply encomiast 8 hours agoprevIt seems like these are all already in the public domain. They were already free to use however we liked and neither the Getty nor anyone else could use copyright to prevent that. It is nice that the Getty is providing some scanning and hosting to make them accessible, though. The article specifically mentions Irises by Van Gogh, but the link (https://www.getty.edu/art/collection/object/103JNH) takes you to a page where it seems like you have to ask nicely and agree to terms to use this public domain image. reply imgabe 7 hours agoparentThe artwork is in the public domain. The photo of it is not. You can take your own photo, but if you want to use a photo someone else took, then you need their permission. reply encomiast 7 hours agorootparentThis was a nice idea that was tested and failed in court: https://en.wikipedia.org/wiki/Bridgeman_Art_Library_v._Corel.... Making a reproduction with a camera does not create a new copyright because copyright protects creative expression, not skill with a camera. reply imgabe 7 hours agorootparentMaybe if you have money to burn taking it to court. In practice if you want to publish it you get permission. The publisher is not going to go to court for you. reply encomiast 7 hours agorootparentPeople can sue for anything they like and yet we still mangage to get up in the morning and do things. Bridgeman was 25 years ago — I would be curious if in that time, you can point to any cases where someone has challenged the use of a photographic reproduction of a public domain work? My hunch is no — not because people don't want to make money licensing things or enjoy going to court, but because most people actually agree with the premise of the decision. reply imgabe 7 hours agorootparentMy wife is an art historian, she's currently publishing a book and collecting permissions for all the images she wants to use. Why? Because if she doesn't the publisher won't publish her book and she won't get tenure. Do they care that there is a 25 year old legal precedent about how they could use the image for free? No, they do not. If it's an image the museum hasn't made publicly available on their website, then they still have to send it to you in order for you to use it and they're going to attach whatever terms and payment requirements to it that they want before they do that, no matter how much you tell them that it's a public domain image. reply mynameisvlad 33 minutes agorootparentThat sounds like it is entirely the publisher’s internal policy, not at all related to whether something is in the public domain or not. A publisher can certainly impose their own restrictions before publishing something to lower liability, but that does not mean the photographs themselves are not public domain, as GP comment explicitly showed. If you have any case law since then that proves otherwise, great, but an anecdote is not proof enough. reply encomiast 7 hours agorootparentprevWell, then your wife and her publisher are partially responsible for the continual erosion of our rights. The public domain is important and worth defending. reply imgabe 6 hours agorootparentJust because someone has an image that is in the public domain doesn't mean they're obligated to share it with you. They can simply say no. Your options are: 1. Hire a photographer to take a photo of the artwork that you want to use. You have to pay the photographer, and you still need the museum's permission to access the work in a setting where you can take a good photo suitable for publication. You probably can't just snap a photo while touring the museum and use that. 2. Use a photo that the museum has and pay them and/or agree to their terms. Maybe you could take that photo and then share it because it's technically public domain, but guess what's going to happen the next time you want to use one of their photos then? reply encomiast 6 hours agorootparentWell, they can't say no if you are already in possession of the image. Certainly, they are under no obligation to take the photo, deliver the photo, host the photo on a server, but once you have the photo, there is no legal mechanism from preventing you from using it. Your arguments in this thread have gone: copyright protects photos of public domain works -> well people can still sue you -> well people don't have to give you access. You have arrived at the truth: museums don't have to take photos or share them with you. They own the physical artwork and can control physical access to it. I don't think that was in dispute. reply imgabe 4 hours agorootparentIt’s a moot point that you can use it without permission if you can’t obtain it without permission. This is a distinction without a difference. That’s why it’s actually a big deal and a Good Thing that museums are making these images available online. It’s not as simple as “they were public domain anyway”. reply ufocia 4 hours agorootparentWell, once a copy of a public domain work is published, you can reproduce it from that publication without permission or license. reply ChrisArchitect 7 hours agoprevNot to be confused with Getty Images Holdings Inc who would likely fall quite on the opposite side of this move. reply jhanoncomm 4 hours agoparentI suggest a title update to “The J. Paul Getty Museum …” to the OP if they read this reply dreadlordbone 8 hours agoprevsounds like PR reply Smoosh 8 hours agoparentYes, I was disappointed to find only one or two images from each famous artist. reply ivanjermakov 7 hours agoprevI think those are called dark-sky preserves? https://en.wikipedia.org/wiki/Dark-sky_preserve reply tossit444 7 hours agoparentThink ya replied to the wrong thread, mate. reply promiseofbeans 7 hours agorootparentA lost explorer from https://news.ycombinator.com/item?id=39709981 reply ivanjermakov 7 hours agorootparentprevYou're right... somehow I jumped to the previous thread. reply tharakam 7 hours agoprevThose images have only a little commercial use IMO. reply tonymet 5 hours agoprev\"J. Paul Getty was not a billionaire known for his generosity. \" this is a rather disrespectful way to refer to the benefactor. reply SeanLuke 8 minutes agoparentTo the contrary, it is a very mild way of describing one of the most famously callous, cartoonishly vicious misers in modern history. This man was right up there with Mr. Burns. https://brightside.me/articles/the-story-of-the-richest-man-... reply TaylorAlexander 8 hours agoprev [13 more] [flagged] Devasta 8 hours agoparentWhats the benefit to artists to licensing works in a way thats favorable for AI models? Most artists hate the concept of AI art regardless of whether or not its a threat to their livelihoods. reply ssalka 8 hours agorootparentI could see it slowly approaching the open source model - you do it because you care, and maybe some people will donate to you because they want to see your work continue. You can also say you've done it, so if you're a prolific artist it would probably look good. Also, I feel like the main reason artists have a beef with AI right now is mostly because lots of their published works were used without permission to train models. I think if instead SD/Midjourney et al had used open datasets curated in the way TaylorAlexander described, there would be a lot less pushback, because everyone would know the models were trained with consent of the underlying artists responsible for the training data's existence. There is still the concern of automation eliminating demand for work done by humans, but I have a hunch that in the long term, artists will embrace these tools in the same way that's been done with Photoshop and every other digital tool. It still might be very different, i.e. AI is much more powerful/enabling than Photoshop, but I'm not sure that'll change the outcome. reply autoexec 7 hours agorootparent> I have a hunch that in the long term, artists will embrace these tools in the same way that's been done with Photoshop and every other digital tool. I think artists will too, but so will everyone else - including many who wouldn't have the skills to create the art they want without AI and who would have had to hire an artist. Photoshop did this is a small extent, but it is possible that AI will meet most people's needs in most situations. As someone with little ability to draw or paint I'm excited for that future personally, but I can't blame professional artists for being nervous. That their own artwork is being used to train their replacement is just rubbing salt into their wounds. Right now, AI is putting out a lot of substandard work, and artists may find themselves employed just to fix the quirks of AI output, but I doubt they'll find that fulfilling. Eventually AI art may become so homogenized, derivative, and censored that it won't satisfy clients and their customers and if that happens demand for real artists will improve, but I think things could get really difficult for many professional artists in the meantime and I don't think many will be willing to offer up their art for AI the same way most people wouldn't offer to weave rope or sharpen axes for their executioner. reply stale2002 7 hours agorootparentprevThe benefit is that each individual artist loses very little from their particular piece of art being licensed, but they can make money for that. The AI art models are still going to be trained regardless. One artist opting out, individually doesn't stop any of that. reply Devasta 7 hours agorootparentArtists lose little by licensing their art to AI models??? reply bongodongobob 6 hours agorootparentYeah, I don't see how they lose anything. reply ipaddr 8 hours agoparentprevSo an image uploaded by a random person (not necessarily the copyright owner) to twitter and it automatically is added to this public set? Not sure legally it would be any different. reply macksd 7 hours agorootparentThe understanding (or level of giving a crap) the average social media user has of copyright is pathetic. How often do you see \"DM for credit\" or \"no copyright intended\"? reply dheera 4 hours agoparentprev> we could use openly licensed images There simply aren't enough of them. Stable Diffusion is trained on 5 billion images. That kind of scale doesn't exist in public domain artwork. This dataset of 88k images is 0.0017% of that. Also, it's worth noting that intellectual property is a weird construct. Human artists are trained from looking at copyrighted works their entire lifetime. If you asked me to draw a cartoonistic bear I cannot guarantee you that it doesn't vaguely look like Winnie the Pooh or Baloo. I've seen those things and can't un-erase them from my head. And if you prevented me from ever seeing copyrighted works for my whole life, I might not be able to draw anything. So why are we holding AI to a different standard? reply TaylorAlexander 4 hours agorootparent> Stable Diffusion is trained on 5 billion images. That kind of scale doesn't exist in public domain artwork. Right, which is why work on sample-efficiency would be so valuable. > So why are we holding AI to a different standard? Because it is an automated computer system, not a human being. It can be held to a different standard because it is an entirely different system. reply ufocia 4 hours agorootparentprevI don't think we are on the training side. I think the artists would like us to. reply adzm 6 hours agoparentprev [–] This is pretty much what Adobe Firefly does, being trained on stock images that they have rights to. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Getty Museum and Smithsonian Museum provide high-resolution images and art books for public use under Creative Commons Zero license.",
      "Open Culture offers free educational materials like audio books, online courses, and movies, featuring prominent figures in art, literature, film, and philosophy.",
      "Open Culture, led by Dan Colman, has been advocating for free educational resources since 2006."
    ],
    "commentSummary": [
      "The Getty Museum has opened access to almost 88,000 art images, some falling under the public domain, for public use.",
      "Conversations revolve around copyright regulations, utilizing high-quality images, and the legalities/practicalities of leveraging museum images on the internet.",
      "Discussions also include artists licensing their creations to AI models, fears of AI substituting human artists, and the ethical dilemmas surrounding AI in the art sector."
    ],
    "points": 284,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1710460395
  },
  {
    "id": 39704914,
    "title": "Progress Made in Resolving Voyager 1 Communication Issue",
    "originLink": "https://www.theregister.com/2024/03/14/voyager_1_not_dead/",
    "originBody": "Science 57 Voyager 1 starts making sense again after months of babble 57 Veteran spacecraft shows signs of sanity with poke from engineers Richard Speed Thu 14 Mar 2024 // 13:15 UTC Engineers are hopeful that the veteran spacecraft Voyager 1 might have turned a corner after spending the last three months spouting gibberish at controllers. On March 1, the Voyager team sent a command, dubbed a \"poke,\" to get the probe's Flight Data System (FDS) to try some other sequences in its software in the hope of circumventing whatever had become corrupted. Readers of a certain vintage will doubtless have memories of poke sheets for various 1980s games. Not that this hack ever used a poke to get infinite lives in Jet Set Willy, of course. While Voyager 1's lifespan is not infinite, it has endured far longer than anticipated and might be about to dodge yet another bullet. On March 3, the mission team saw something different in the stream of data returned from the spacecraft, which had been unreadable since December. An engineer with the Deep Space Network (DSN) was able to decode it, and by March 10, the team determined that it contained a complete memory dump from the FDS. The FDS memory read-out contains its code, variables, and science and engineering data for downlink. Prior to NASA's announcement, Dr Suzanne Dodd, project manager for the Voyager Interstellar Mission, said in a Pasadena Star-News report that the data being transmitted from the probe was \"not exactly what we would expect, but they do look like something that can show us that the FDS is at least partially working.\" Work to resolve binary babble from Voyager 1 is ongoing Space exploitation vs space exploration: Humanity has much to learn from the Voyager probes 44-year-old Voyager 2 data sheds light on solar system's magnetic personalities NASA engineers scratch heads as Voyager 1 starts spouting cosmic gibberish Dodd was referring to the ones and zeroes streaming from the spacecraft. Previously, the probe's telemetry modulation unit (TMU) had begun in mid-December transmitting a repeating binary pattern as though it was somehow stuck. Engineers reckoned the issue was somewhere within the FDS. The next step is to study the memory read-out and compare it to one transmitted before the problem arose. A solution to the issue could then be devised. One of the original Voyager scientists, Garry Hunt, told The Register that engineers at JPL were determined to get communications with the stricken probe working again: \"This requires both skills and patience with the long time between communication instructions and response.\" The time lag is a problem. A command from Earth takes 22.5 hours to reach the probe, and the same period is needed again for a response. This means a 45-hour wait to see what a given command might have done. The availability of skills is also an issue. Many of the engineers who worked on the project - Voyager 1 launched in 1977 - are no longer around, and the team that remains is faced with trawling through reams of decades-old documents to deal with unanticipated issues arising today. ® Whitepaper: Top 5 Tips For Navigating Your SASE Journey Share More about NASA Space Voyager More like these × More about NASA Space Voyager Narrower topics Artemis Asteroid Astronomy Black Hole CSA Earth ESA Exomoon Exoplanet Galaxy Hubble Space Telescope ISS James Webb Space Telescope JAXA Moon Neil Gehrels Swift Observatory Perseverance Roscosmos Satellite Solar System Square Kilometre Array Broader topics Federal government of the United States More about Share 57 COMMENTS More about NASA Space Voyager More like these × More about NASA Space Voyager Narrower topics Artemis Asteroid Astronomy Black Hole CSA Earth ESA Exomoon Exoplanet Galaxy Hubble Space Telescope ISS James Webb Space Telescope JAXA Moon Neil Gehrels Swift Observatory Perseverance Roscosmos Satellite Solar System Square Kilometre Array Broader topics Federal government of the United States TIP US OFF Send us news",
    "commentLink": "https://news.ycombinator.com/item?id=39704914",
    "commentBody": "NASA engineers make progress toward understanding Voyager 1 issue (theregister.com)279 points by LinuxBender 19 hours agohidepastfavorite169 comments subract 18 hours agoFor those interested in learning more about the challenges in keeping the probes alive, the 2022 documentary It's Quieter in the Twilight follows the small, incredibly dedicated team working the project. Free to stream on Prime. The simple fact that many of the original engineers are no longer alive presents significant challenges in and of itself. reply ojosilva 18 hours agoparentI came to say the same, and post this link to the trailer: https://www.youtube.com/watch?v=8vJT8AW0wYw reply noelwelsh 16 hours agorootparentThose ancient Sun machines take me back a bit! reply dylan604 11 hours agoparentprevThanks for the reco. I would have never found this browsing Prime hidden in all of their FreeVee push. reply chgs 9 hours agorootparentI stopped my prime subscription after years (decade+?) because they decided to double dip and put in adverts. Such a shame. They’ve lost £360 so far from me based on my normal Amazon spending for their decision. reply dylan604 7 hours agorootparentOh Nooooo! Bezos won't be able to make his yacht payments now!! Won't you think of the starving billionaires before making your kneejerk reactions. Nobody wants to be humiliated and drop out of the 3 commas club reply andyjohnson0 12 hours agoparentprevLooks fascinating, but the only place I can find to watch it here in the uk is Prime Video. Does anyone know of legal options for those who don't want to give Amazon their money - still less sign up for a Prime subscription? reply greazy 12 hours agorootparentTry one of the options listed here https://www.itsquieterfilm.com/where-to-watch Most of the options don't offer the movie in my region :( reply mintycrisp 12 hours agorootparentprevHere is the official list of options to see if any alternatives work for your location -> https://itsquieterfilm.com/where-to-watch reply mbirth 7 hours agorootparentprevEh, even Prime Video shows “This video is currently unavailable to watch in your location.” reply Solvency 16 hours agoparentprevI fundamentally don't understand why this project is seemingly so poorly documented? I've read articles describing the current teams having to still reverse engineer things by scrutinizing random documents and sketches as if it's still this very unknown system. reply xenadu02 14 hours agorootparentThe project was not really designed to reach interstellar space originally. It was a somewhat rushed program to take advantage of the \"Grand Tour\" where the gas giants would all be aligned enough that a gravity-assist orbit could allow a spacecraft to fly by each of them. The alignment in question only happens every 175 years. The interstellar portion was an add-on after the success of the original mission. The spacecraft were still operating so why not just keep operating them? No one designing or building the probes imagined they'd still be operating 50+ years later. Even if they did space programs are constantly under threat from budget cuts so you can't exactly waste money on what-ifs for the future: you must focus on making the official mission succeed. Also remember that the \"desktop PC\" was not yet a thing when this was designed. Engineers were drawing everything on paper. Storage space was extremely expensive in any case. A modern program would (and most do!) put various versions of drawings in a version control system. Source would use an SCM so code history would be available. Even things like meeting notes would be available and searchable digitally. reply RajT88 12 hours agorootparentI have found that even the group I'm in being documentation-heavy, it's hard to read through everything and build the same context that another engineer has all stuffed into their head. As you mention: > available and searchable digitally. Even with 100% everything written down, it takes a while to build up that context, and even carefully written documentation can have subtleties which send a consumer the wrong way. Things are a lot easier than they used to be, but still not easy-easy. reply cduzz 6 hours agorootparentDocumentation is extraordinarily difficult to create. You need to anticipate the potential questions and answer them and anticipate all the potential perspectives and answer them from that perspective. What is enough? A reference describing all of a thing? The source code to a thing? The source code and build chain to make the thing? The source code, build chain, source code to the build chain to build the build chain to build the thing? The source code and the machine and the tape drive to read the tapes to build the .... How much documentation for TOPS-10 would you need to implement wireguard on a toad? How much context do you need to even make that sentence even make any sense at all? reply renhanxue 11 hours agorootparentprev>The project was not really designed to reach interstellar space originally. Not only that, Voyager 2's flyby of Uranus and Neptune in the late 1980's was originally not intended either. As an aside, to this day Voyager 2 remains the only spacecraft to ever have visited either planet, and there are no firm plans for a followup, just some loose ideas about maybe launching something in the mid 2030's. Anyway, doing the Uranus/Neptune part of the mission required extensive software upgrades, which introduced Reed-Solomon error correction and image compression capabilities, among other things - the software as launched would not have been capable of a meaningful mission to Uranus and Neptune. These days the Voyager program is lauded as an astonishing feat of engineering and one of the most inspiring science and engineering achievements of all time, but in the early 1970's the entire idea was NASA's red-headed stepchild and ended up cut down to a bare minimum. The Grand Tour mission concept (taking advantage of the extremely rare opportunity to visit Jupiter, Saturn, Uranus and Neptune in a single mission) was pitched as early as 1965, and by the early 1970's there were plans for launching four spacecraft, two bound for Jupiter-Saturn-Pluto and two bound for Jupiter-Uranus-Neptune. These were referred to as TOPS, Thermoelectric Outer Planets Spacecraft. But then people started complaining that it might cost a billion dollars (Apollo had cost $25 billion) and the whole thing became intensely political. Quoting from Voyager: The Grand Tour of Big Science (https://www.nasa.gov/history/SP-4219/Chapter11.html) by Andrew J. Butrica: > Further complicating matters was Senator Clinton P. Anderson (D-NM), champion of the Los Alamos nuclear weapons laboratories and an enthusiast, until his retirement in 1973, of the development of a nuclear rocket engine called NERVA. As chair of both the Senate Aeronautical and Space Sciences Committee and the joint Atomic Energy Committee, Anderson provided NASA and the Atomic Energy Commission over $1.4 billion, about $500 million of which was spent in Los Alamos, for the development of the NERVA engine, which, Anderson held, was ideally suited for exploration of the outer planets, as well as for more advanced missions. Anderson worried that NASA and the OMB were shifting money from NERVA to fund Grand Tour. When the NASA budget came before Anderson's Aeronautical and Space Sciences Committee on May 12, 1971, his committee voted five to two to reduce Grand Tour's budget, while an amendment to increase NERVA funding passed. Werner von Braun worried that ardent congressional interest in NERVA would force a loss of Grand Tour in favor of a NERVA that had \"no place to go.\" > Meanwhile, NASA was trying to include Grand Tour as a new start in its 1972 fiscal budget. The Friedman report moved the Office of Management and Budget (OMB), in March 1971, to ask NASA to study simpler, less costly spacecraft alternatives to TOPS. The OMB also attempted to delay the Grand Tour start-up to fiscal 1973. > (...) > As NASA prepared its fiscal 1973 budget, rumors spread that the \"budget pinch\" was going to affect planetary programs deeply and that the reduction of the Grand Tour payload from 205 to 130 pounds was \"a likely fact of life.\" Furthermore, Grand Tour now began to compete for funding with the latest NASA human program: the Space Shuttle. The fiscal 1973 budget request NASA submitted to the OMB on September 30, 1971 included both Grand Tour and the Space Shuttle. Throughout the autumn of 1971, several press reports presciently reported Grand Tour's vulnerability to a possible elimination or reduction. On December 11, 1971, James Fletcher, NASA administrator since April 27, 1971, learned from White House officials that Nixon was prepared to approve the shuttle program and that Nixon would not let NASA simultaneously fund the shuttle and the full TOPS Grand Tour in the 1973 budget or in subsequent fiscal years. Fletcher had to decide which was more important: Grand Tour or human flight. Fletcher chose the shuttle, and what could be squeezed into the budget was an extension of the Mariner program to visit Jupiter and Saturn only. For budget reasons the spacecraft development was kept in-house at JPL rather than contracted out, and at JPL the dream of the full Grand Tour was still alive: > Despite the limited aim of the Mariner Jupiter-Saturn, the mission had the Grand Tour launch window, that rare planetary alignment, and the engineers at JPL still had every intention of building a spacecraft that would last long enough to visit Uranus and Neptune. This intention was not emphasized; however, it was stated that a Mariner Jupiter-Saturn spacecraft might continue to Uranus if its mission at Saturn proved successful. The scientists working on the project knew that Mariner Jupiter-Saturn was going to go to Uranus and Neptune, too. As Bradford Smith, Leader of the Imaging Team, explained: \"We understood at the time the enormous potential of this mission, that it could very well be one of the truly outstanding if not the most outstanding mission in the whole planetary exploration program.\" Also for budget reasons, the spacecraft were limited to mostly reusing existing technology. Getting reprogrammable computers (without which they could never have been kept alive in the way they have) required a separate budget grant from Congress: > Despite the reliance on extant technology, some money was set aside to develop new technology. Congress and the OMB approved an additional $7 million to the Mariner Jupiter-Saturn appropriation for scientific and technological enhancements. Part of that appropriation went to develop a reprogrammable onboard computer, which proved vital to maintaining Voyager 2 as a functioning observatory in space. Without properly functioning hardware, no science could be conducted. In the end only Voyager 2 was launched on the full Grand Tour trajectory that would allow visiting all of Jupiter, Saturn, Uranus and Neptune; Voyager 1 was launched on an easier and much faster trajectory that would take it only to Jupiter and Saturn. Even then, the official decision to extend the Voyager 2 mission to Uranus was only approved in 1980. Human spaceflight and its enormous appetite for money has always been a huge threat to actually exploring the solar system beyond Earth orbit, and we should be very glad we got even the very diminished Voyager program that exists today. reply 0cf8612b2e1e 13 hours agorootparentprevShouldn’t this software archeology have been done decades ago? reply Someone 9 hours agorootparentWhat would be your argument for getting budget to do that? There are zillions of ways this hardware can break down. You can’t predict which ones you’ll have to handle, or whether there will be a way to recover from them. If you started researching this 30 years ago, and then something had killed this thing 20 years ago, that would be wasted effort. Also, in the early years, they still could ask the original engineers, and even lacking those, there likely were engineers who hadn’t worked on this specific hardware but were somewhat familiar with this kind of hardware. reply KineticLensman 14 hours agorootparentprevI remember reading about the inquiry into the UK RAF Nimrod aircraft that came down in Afghanistan in 2006 killing its crew of 14 [0]. A significant finding was that recovering the design history and maintenance records involved trawling a massive number of filing cabinets / cardboard boxes scattered in sites across the UK, and was a significant cause of the missed opportunities to uncover the design flaws and near misses that preceded the crash. (long story short: internal fuel leak near a very hot exhaust pipe) [0] https://en.wikipedia.org/wiki/2006_Royal_Air_Force_Nimrod_cr... reply TheCondor 11 hours agorootparentprevWhen was the first source code control system released? SCCS was like 1973 and the Voyager code was probably pretty much buttoned by then; with whatever practices that they thought was stable state of the art practices at the time. I imaging that this was a collection of \"golden tapes\" or something. Now the concept of revision control seems pretty self validating but you're talking about undergoing a culture change on your software team, pretty close to launch. Then the voyager hardware was bespoke. We just live in a different world now, they didn't know how to do software engineering like we do. They were just figuring it out. I really don't know the history of it but Voyager systems may have been produced on punchcard. Like the original source code might be physical for parts of the system. reply renhanxue 10 hours agorootparentThe Voyager software was updated repeatedly and significantly in flight while the spacecraft were still in their early years. They were very intentionally designed to be patched over the course of the mission. The software as launched was not capable of a meaningful mission beyond Saturn, because for budget reasons that was officially not on the cards at launch (the Voyager name came very late; the program was officially \"Mariner Jupiter-Saturn\" for a long time). Features like image compression were added in the early 1980's, after Voyager 2's mission extension to Uranus and Neptune had been approved. Without any inside information on the program, I would expect that a lot of development has been done more or less ad-hoc over the decades, as budgets have allowed and operational requirements demanded. reply zilti 10 hours agorootparentprev> they didn't know how to do software engineering like we do. Yes, luckily. If they did, it would have broken after four years, and would have needed a second nuclear battery due to the inefficient code. reply Johnny555 9 hours agorootparentprevI'd imagine that a lot of the undocumented stuff was for things that were obvious to an engineer at the time -- I doubt many engineers working on it at the time thought that the probe would outlive their own lifetime. I've run into lots of software comments in legacy code that refer to features or systems the company used to have that were deprecated years ago and are nearly meaningless today. Knowing that a flag was set to match the flags from the WOPR sytem isn't that useful when WOPR hasn't existed since before I joined the company. reply toast0 14 hours agorootparentprevIf they have random documents to scrutinize, doesn't that mean that it's documented? When I work on undocumented systems, it's because someone wrote code with no design docs, no (retained) notes, no requirements, no specs, and it's been determined that it doesn't work right. All I have is the code, and current observations. reply liquidpele 12 hours agorootparentHaha look at this guy, thinking you can trust the docs. ;) reply anigbrowl 11 hours agorootparentprevAt the time engineers imagined it having a relatively short operating life, and (imho) also thought we would be putting out a lot more probes. During the Cold War space exploration provided both prestige and a technological proving ground. After the USSR fell, a lot of Congressional enthusiasm for space projects diminished and management became increasingly risk-averse because budgets were much tighter. reply mardifoufs 12 hours agorootparentprevI think it's because it was more of an awesome moonshot project that didn't really fit into NASA's shifting goals at the time and with the shuttle overshadowing everything else that happened then. No one was really expecting this much from the probes reply nonethewiser 16 hours agorootparentprevI imagine its a problem of distance, feedback, and lack of any analogous test environment. reply loloquwowndueo 17 hours agoparentprevnext [9 more] [flagged] orev 17 hours agorootparentIf you have Prime, it’s free to stream, while other things on Prime might need you to pay to rent/purchase to watch it. reply abfan1127 17 hours agorootparentprevSome things are not free, even if you \"have prime\"... so if you have it already, then the cost is already paid... but that's a lot of words. perhaps \"included with price of admission\" reply dizhn 17 hours agorootparentThey usually say \"included in your prime membership\". reply Kwpolska 17 hours agorootparentprevPrime Video is both a subscription service and a one-off rental* service. Prime subscribers get free access to some movies offered for rental. * Either short-term rental, or long-term rental described as a purchase. reply AlecSchueler 17 hours agorootparentprevAnd don't forget the cost of your internet subscription, streaming drive and electricity usage. reply dgfitz 12 hours agorootparentAs well as the cost of the food you ate to remain awake and conscience while viewing, as well as water (or whatever liquid one chooses to consume). The cost of the clothes possibly being worn during viewing, the cost of furniture being used, the cost of the abode hosting the furniture. reply dpkirchner 17 hours agorootparentprevWe must also remember to address the opportunity cost whenever we describe how to use a thing, else we're not specific enough. reply enlightens 17 hours agorootparentprevPrime also has some shows you have to pay individually for above and beyond the subscription cost. This particular one is no extra cost, \"free\", once you have a subscription. reply vlovich123 17 hours agoprev> The availability of skills is also an issue. Many of the engineers who worked on the project - Voyager 1 launched in 1977 - are no longer around, and the team that remains is faced with trawling through reams of decades-old documents to deal with unanticipated issues arising today At least part of the problem is that we don't regularly send long distance probes. Of course, even with that maintaining a relevant skill set to maintain a 50+ year old technology from over 100 AU seems difficult. I think having it be a single team's life's work is probably our limit to keeping it alive. Our next best window for sending out another group of probes is 2152 and hopefully it'll become cheap enough to send out a bunch of them with even higher resolution imagery & maybe actually hit all the planets this time. Unfortunately, it's likely no one reading this will be alive to see that happen. reply jamiek88 17 hours agoparentLikely? I’d say certain! If not then some wonderful healthcare breakthroughs will have happened and wouldn’t that be great? I’d love to see us image exoplanets for example. I’ve often thought about a ‘relativistic chamber’. Some device that is in space looping at an appreciable fraction of light speed. Enter the box. Exit a year later and it’s 200 years passed down on earth. Have a mosey around, back in the box! Have a mooch, back in the box! And so on. reply shagie 11 hours agorootparentThe Worthing Saga by Orson Scott Card ( https://en.wikipedia.org/wiki/The_Worthing_Saga https://www.goodreads.com/book/show/40304.The_Worthing_Saga ) > It was a miracle of science that permitted human beings to live, if not forever, then for a long, long time. Some people, anyway. The rich, the powerful--they lived their lives at the rate of one year every ten. Some created two societies: that of people who lived out their normal span and died, and those who slept away the decades, skipping over the intervening years and events. It allowed great plans to be put in motion. It allowed interstellar Empires to be built. > It came near to destroying humanity. > After a long, long time of decadence and stagnation, a few seed ships were sent out to save our species. They carried human embryos and supplies, and teaching robots, and one man. The Worthing Saga is the story of one of these men, Jason Worthing, and the world he found for the seed he carried. --- Freeze Frame Revolution ( https://www.goodreads.com/en/book/show/36510759 ) > How do you stage a mutiny when you’re only awake one day in a million? How do you conspire when your tiny handful of potential allies changes with each job shift? How do you engage an enemy that never sleeps, that sees through your eyes and hears through your ears, and relentlessly, honestly, only wants what’s best for you? Trapped aboard the starship Eriophora, Sunday Ahzmundin is about to discover the components of any successful revolution: conspiracy, code—and unavoidable casualties. --- Also going to recommend the various Vernor Vinge books: The Peace War Marooned in Realtime A Deepness in the Sky and the short story \"The Peddler's Apprentice\" ( https://en.wikipedia.org/wiki/The_Collected_Stories_of_Verno... ) reply Vecr 16 hours agorootparentprevSimilar to the XKCD, Gwern says no: https://gwern.net/hyperbolic-time-chamber reply LeifCarrotson 16 hours agorootparentThe HTC is the opposite of the cryogenic freezer or relativistic chamber - it accelerates time for people inside it, allowing you to meet external deadlines while the world passes by slowly outside. A cryo freezer or relativistic spaceship decelerates time for people inside, allowing external activities to be accomplished while you don't age. reply Vecr 12 hours agorootparentYou are right, I'm wrong. I thought he had something in there for that anyway, but apparently not. Still, you're just on the other side of the Amdahl’s law problems, so you better hope no one is depending on you. reply ghodith 15 hours agorootparentprevThis is about a time chamber that works in the opposite direction. reply TremendousJudge 16 hours agorootparentprevhttps://xkcd.com/989/ reply brabel 16 hours agorootparentIn reality, they would wake up to find themselves in a landfill as everyone just forgot what those funny boxes were for and got rid of them. reply aembleton 11 hours agorootparentAs predicted by Idiocracy reply ribosometronome 16 hours agorootparentprevIt's a shame we probably live too early for cryogenic freezing to work, either. reply meragrin_ 16 hours agoparentprev> Our next best window for sending out another group of probes is 2152 Planet alignment? reply legobmw99 16 hours agorootparentYes, https://en.m.wikipedia.org/wiki/Grand_Tour_program reply dmead 13 hours agorootparentIt'll be a good year for planetary astronomy anyhow. reply piokoch 20 hours agoprevVoyager 1/2 is a pick of human achievements in XX century. A piece of hardware run by the computer having a power that today car keys have is flying for over 40 years in the space, outside Solar system, delivering priceless information. People do not realize how amazing engineering it must be. One can watch https://en.wikipedia.org/wiki/The_Farthest to appreciate fully what all those great man did and are still doing. reply detourdog 17 hours agoparentThe inverse is also true. This demonstrates how underwhelming current engineering is. reply class3shock 12 hours agorootparentI think most engineers from back then would be astounded with the engineering of today, not underwhelmed. reply detourdog 12 hours agorootparentI could see them being impressed with the human achievements. I have doubts if they would be impressed by the engineering. Everything I see looks more like the results of human hours spent. Consider giving those old timers the same problem with todays resources and I think we would get great results. reply magicalhippo 11 hours agorootparentprevTried checking out how they make the processors you're using to read this site on? https://www.youtube.com/watch?v=rdlZ8KYVtPU https://www.youtube.com/watch?v=1fOA85xtYxs reply detourdog 9 hours agorootparentCompared to voyager I see that as more of the same and almost disposable. I have a large collection of technical documentation and physical artifacts of the same computer implemented as discreet components amd integrated circuits. The company had to invent the lithographic process to print circuits. So ASML is very impressive but could also be seen as a derivative idea. reply magicalhippo 9 hours agorootparentSeen that way, the Voyager probes are also very impressive but also a derivative idea. After all they were really Mariner 11 and 12[1], if not in name, not even the first interplanetary probes. Rather I think it's more interesting to view engineering as finding solutions to a problem given a set of constraints. In that sense I think both the Voyager probes as well as lot of modern engineering is quite remarkable. [1]: https://en.wikipedia.org/wiki/Mariner_program#Mariner_Jupite... reply detourdog 3 hours agorootparentI would respond that Voyager is still going compared to Mariner. The Voyager project may be derivative but it has out performed all others. I would also lump all those early inertial guidance efforts of early computing together with Voyager as the high water mark. reply queuebert 16 hours agorootparentprevOr maybe hardware overkill. I have a soft spot for small, dedicated computers like the Apollo Guidance Computer that have physical buttons and simple functionality. The DDIs on jet fighters are another example. reply detourdog 16 hours agorootparentFrom my perspective microprocessor grew up around the general purpose computing model. Now the microprocessor power has far outpaced the the actual human needs the focus on general purpose is inefficient. I see efficiencies to be gained in the overall integration of very task specific computers in common network. reply malfist 13 hours agorootparentprevIs it? Key fobs probably cost dollars to manufacture. Voyager cost $865 million....in 1977. Maybe my key fob uses compute power wastefully. But I'd rather it cost a few dollars than everything that needs that amount of processing power costing hundreds of millions of dollars. reply detourdog 12 hours agorootparentI don't think a key fob is a good example. I think if you look at what goes into word processing for the average office or almost any other office task would be my example. My point is that early on general purpose computing was needed to drive the cost of computing down. I think we are past that stage and it is now time to look at making everything as simple and efficient as possible. reply anotherhue 20 hours agoparentprevThere's a second film that's a little more recent, was on Prime video last I looked. https://www.itsquieterfilm.com/ reply nickburns 19 hours agoparentprevhttps://en.wikipedia.org/wiki/Women_in_NASA reply itsthecourier 17 hours agoparentprevbox office: $6,900 Human race advances in leaps by a super small group of dedicated people, we are all indebted to reply nullhole 21 hours agoprevCalled a “poke” by the team, the command is meant to gently prompt the FDS to try different sequences in its software package in case the issue could be resolved by going around a corrupted section. The apparent foresight of the original programmers is impressive though maybe not too surprising given the conditions they expected. I'd be curious to know if anyone has any book recommendations on software design for space missions; I suspect there would be some lessons in there around testing and reliability that could inform more day-to-day stuff. reply isolli 20 hours agoparentI also read this a while ago [1]: \"The Voyager’s computer system was very impressive as well. Knowing the craft would be on its own much of the time, with the lag between command and response from Earth growing longer the farther the craft went into space, engineers developed a self-repairing computer system. The computer has multiple modules that compare the data they receive and the output instructions they decide on. If one module differs from the others, it's assumed to be faulty and is eliminated from the system, replaced by one of the backup modules. It was tested shortly after launch, when a delay in boom deployment was misread as a malfunction. The problem was corrected successfully.\" [1] https://science.howstuffworks.com/voyager.htm reply shagie 5 hours agorootparentSome of the fault protection and failover procedures: https://voyager.gsfc.nasa.gov/Library/DeepCommo_Chapter3--14... Page 74-75 > 3.7.3 Spacecraft Fault Protection > The CCS has five fault-protection algorithms (FPAs) stored in memory, as summarized in Table 3-9. The two algorithms most directly related to the telecommunications system are named RF Loss and Command Loss [19]. > 3.7.3.1 RF Loss. RF Loss provides a means for the spacecraft to automatically recover from an S- or X-band exciter or power amplifier degradation or failure affecting the unit’s RF output. The CCS monitors the output RF power at four points in the RFS: the S-band exciter and S-band power amplifier and the X- band exciter and X-TWTA. If the output RF power from one or more powered- on units drops below a threshold level, the algorithm will attempt to correct the problem by switching to the redundant unit. > 3.7.3.2 Command Loss. Command Loss provides a means for the spacecraft to automatically respond to an onboard failure resulting in the inability to receive or recognize ground commands. If a period of time set in the flight software goes by without the spacecraft recognizing a valid uplinked command, the Command Loss timer expires. The algorithm responds to the presumed spacecraft failure28 and attempts to correct that failure by systematically switching to redundant hardware elements until a valid command is received. Command Loss will be executed four consecutive times if command reception is not successful. After four unsuccessful executions, the CCS will disable Command Loss and activate a set of sequences of commands named the backup mission load (BML) and described below. > 3.7.3.3 Backup Mission Load. In the event of permanent loss of command reception capability, a BML command sequence stored onboard each spacecraft is programmed to continue controlling the spacecraft and achieving fundamental VIM objectives. The BML will begin execution two weeks after the first execution of Command Loss and continue until the spacecraft stops operating. It will transmit cruise science and engineering telemetry, store science observations on the tape recorder, and downlink playbacks regularly. reply maicro 17 hours agoparentprevAlso not a book, but I read this article a couple years ago and it's stuck in the back of my mind since: https://www.fastcompany.com/28121/they-write-right-stuff reply isolli 20 hours agoparentprevI can't recommend a book, but I watched this video a while ago, and I found it riveting: \"Light Years AheadThe 1969 Apollo Guidance Computer\" [0] > Robert Wills introduces the amazing hardware and software that made up the Apollo Guidance Computer, walks you through the landing procedure step-by-step, and talks about the pioneering design principles that were used to make the landing software robust against any failure. [0] https://www.youtube.com/watch?v=B1J2RMorJXM reply araker 13 hours agorootparentThanks for sharing, this is a great talk. reply anonymous_user9 19 hours agoparentprevSoftware isn’t the sole focus, but you may enjoy “Computers in Spaceflight: The NASA Experience”, a 406-page history of manned, unmanned, and ground computers from the beginning through the shuttle era. https://ntrs.nasa.gov/citations/19880069935 reply chasd00 16 hours agoparentprev> gently prompt the FDS do you suppose their system prompt ensures it responds more favorably to gentle commands? ;) reply KineticLensman 11 hours agoparentprevSunburst and Luminary by Don Eyles, one of the AGC coders, is an outstanding read. Specific to AGC but indicates some of the challenges reply CamperBob2 18 hours agoparentprevIt's not specifically a text on software design, but Sunburst and Luminary by Don Eyles is an enjoyable read ( https://www.amazon.com/Sunburst-Luminary-Apollo-Don-Eyles/dp... ). He manages to capture the Apollo-era zeitgeist in more ways than one. Not just another tale from the trenches. reply ndiddy 19 hours agoprev> But an engineer with the agency’s Deep Space Network, which operates the radio antennas that communicate with both Voyagers and other spacecraft traveling to the Moon and beyond, was able to decode the new signal and found that it contains a readout of the entire FDS memory. The FDS memory includes its code, or instructions for what to do, as well as variables, or values used in the code that can change based on commands or the spacecraft’s status. It also contains science or engineering data for downlink. Does this mean that someone could set up an antenna and get a copy of the Voyager software? Might be cool to see. reply shagie 5 hours agoparent> Does this mean that someone could set up an antenna and get a copy of the Voyager software? Might be cool to see. DSN NOW is neat to watch - and sometimes you see VGR1 and its related data https://eyes.nasa.gov/dsn/dsn.html And since no one is talking with it, I'm going to find a screen shot. https://space.stackexchange.com/q/17430 The DATA feed (at 159 baud - bits per second) is being received at -157.95 dBm ... seven years ago. 1.6 x 10^-22 kW. This is getting into the realm where noise will dominate the signal. https://www.seti.org/detecting-voyager-1-ata > The above assumes a receiver temperature of 120 Kelvin at 8.4 GHz. The receiver temperature could have also been measured using the quasar observation, but the 120 Kelvin figure is not far from reality given previous measurements. The Allen Telescope Array is probably the 'cheapest' way to detect the signal. > The telescope comprises 42 fully-steerable 6.1m-diameter telescopes, of which ~20 are fitted with wideband cryogenically cooled feeds. For comparison, liquid nitrogen is 77 Kelvin. They were able to detect the signal - but in that diagonal chart, note how difficult it is to see the diagonal from the visual noise. That is only detecting the signal - not decoding it. reply sidewndr46 19 hours agoparentprevYes. It would also need to be enormous and use the same type of supercooled receiver. reply CamperBob2 18 hours agoparentprevIt's possible to receive signals from some spacecraft with reasonable amateur-level antennas, but not this one, sadly. You'd be lucky to get a photon every day or two. reply malfist 13 hours agoparentprevTechnically yes. But currently you need a 70 meter (230 foot) dish to hear/talk to it. To talk back to voyager, DSS43 uses 75kw to transmit, so you might have to have a commercial account with your local power company. reply colechristensen 15 hours agoparentprevYou would need a dish measured in tens of meters across. When you were done you’d have a decent radio telescope. reply wolverine876 16 hours agoprev> A command from Earth takes 22.5 hours to reach the probe Voyager 1 is closing in on being the first human-made object to travel 1 light day. V1 has traveled ~22.5 light hours in ~46.5 years [0], and assuming that average rate of 2.07 years/light hour [1] it will reach 1 light day in around 3.1 years. Does anyone know its potential to have sufficent power to measuring anything and transmit at that point? [0] https://voyager.jpl.nasa.gov/mission/status/ [1] Notes on Voyager's average rate: Remember that V1 did not travel in a straight line or at a constant rate from Earth through its planetary explorations, so the average rate now is probably higher than that simple calculation. Also, if we are looking at distance and speed relative to Earth, and Earth's orbit around the Sun would cause some variation throughout the year. Could Earth's relative orbital positions at V1's launch decades ago and when V1 approaches 1 light day in three years significantly affect V1's distance from Earth? Earth's orbital diameter is roughly 300 million km; V1 travels at ~61,000 km/hr relative to the Sun [0], so the worst case would add ~4,900 hours or ~205 days. (Those are some quick calculations and I have to run to a meeting, so I hope there are no glaring errors!) Also, I assume the Sun's movement relative to Voyager 1 has been constant since its launch. reply consumer451 6 hours agoparentThere is a new (2020) interesting \"sun diver solar sail\" proposal which could get all the way to Voyager 1 in two to three years. Article: https://www.universetoday.com/148241/want-the-fastest-solar-... Paper: https://arxiv.org/pdf/2009.12659.pdf Interview with paper’s author: https://www.youtube.com/watch?v=W-E83lC-eN0 reply palijer 11 hours agoparentprevWhen the news of the breakage first spread I hacked together a fun shell alias to take the current distance of v1 or V2, calculate out the roundtrip signal time, then inject a sleep() before your command ran. The idea of troubleshooting a computer system with that sort of delay must make them incredibly creative. reply rebolek 15 hours agoparentprevcalling Voyagers V1 and V2 seems little bit strange... reply tcgv 14 hours agoprev> The time lag is a problem. A command from Earth takes 22.5 hours to reach the probe, and the same period is needed again for a response. This means a 45-hour wait to see what a given command might have done. Astonishing! reply layer8 9 hours agoparentI know some CI pipelines that are only barely faster. ;) reply IAmGraydon 13 hours agoparentprevI can hardly imagine how frustrating that scenario would be. Think about how rapidly you hack away at the terminal, and imagine that every time you hit “enter”, it takes 45 hours to find out if it worked. You would only be able to issue 194 commands in an entire year. reply DarmokJalad1701 16 hours agoprevI remember listening to a podcast where someone mentioned that there was a VM that they used for testing the flight software for Voyager -- possibly open source. Unfortunately, I do not remember what podcast it was. reply tetris11 16 hours agoparentHere's a nice CPUshack link detailing the CPUs that we have in space: https://www.cpushack.com/space-craft-cpu.html reply sph 21 hours agoprevIs Voyager 1 in hibernation mode because the RTG is not producing as much power, or is it because most components have failed, but could in theory still be powered on? I do not know how long an RTG lasts for. reply tokai 21 hours agoparentFrom wikipedia: \"generate approximately 157 Watts of electrical power initially – halving every 87.7 years\" It should still have power. https://en.wikipedia.org/wiki/MHW-RTG reply anotherhue 20 hours agorootparentThe thermo couples also degrade so halve the power again. Biggest issue is keeping the fuel warm so the antenna can stay aligned. https://www.itsquieterfilm.com/ reply smackeyacky 22 hours agoprevI don’t want to personify it but it’s like a last plea from space asking for help billions of kilometres from home. I hope the nasa engineers can either patch it up or quietly put it to sleep. reply Vecr 16 hours agoparentThere's no suffering issue, there's zero point in turning it off. The only thing you'd do is re-allocate DSN resources at some point if someone else really needs them. reply ciunix 14 hours agoprevI hope the communication will be established again and correctly with the farest device made by mankind. Voyager is giving us a lot of important information about what we have in the near around. reply tapoxi 17 hours agoprevIs the Voyager's software or data stream documented anywhere? I'm a little disappointed by the high level descriptions we get back. I'd love to know what its actually sending. reply crispyambulance 17 hours agoparentNASA does have a data portal (https://data.nasa.gov/). There's datasets relating to voyager, but just checking right now, I get '403 errors on those. reply tivert 17 hours agoparentprev> Is the Voyager's software or data stream documented anywhere? I'm a little disappointed by the high level descriptions we get back. I'd love to know what its actually sending. This has a chapter on the Voyager computer system, it's a lot more technical than typical, but I don't think it gets to the detail of the literal programs or data stream: https://web.archive.org/web/20190714113800/https://history.n... I don't know why NASA took down this nice HTML version. The live link now just redirects to a scanned PDF. I read NASA has a lot less documentation about Voyager than you'd think, and apparently they don't have a ground-based simulator or anything like that (which they have for later probes). reply NoMoreNicksLeft 17 hours agoprevWow. Some good news for once. Hope it's something they can repair/mitigate. reply ck2 16 hours agoprevMy favorite thought about the Voyager (and Pioneer) probes is that someday, thousands of years from now, humans will launch a ship or drone that will past by it in only a few days (if we last that long, odds are way down). Another far more hilarious thought is I am glad they chose the Voyager probe for the first Star Trek movie and not Pioneer (hint: the letters dropped in the \"mystery name\") reply ruune 16 hours agoparentThat's an incredibly interesting thing in my opinion. Even if we send colony ships now, the odds of them arriving to a planet thousands years later that is already inhabited by humans or human descendents because our technology evolved over that time it non zero. Combined with relative time it gets even more weirder, because an almost-lightspeed ship we'd send could be surpassed by something much more advanced in a matter of days (spaceship time). So when do we send ships? I think there's a Kurzgesagt video about this somewhere reply Vecr 16 hours agorootparentAs soon as possible, because you don't know you'll last that long. You do need to use resources wisely though. reply ck2 15 hours agorootparentprevThat concept for tic-tac sized probes reaching 10% of the speed of light via laser power transfer seems remotely plausible in a few hundreds years but personally I don't think humans are making it off this planet. We are running out of runway with overpopulation, overheating, overpollution, toxic everything and cutthroat politics will only allow space investment for weapons when there's no money for food and health. Even if there was a near-future miracle invention for cheap plentiful power, it would be turned into a weapon of war far before space use. Beyond the power requirement, accelerating mass near the speed of light is beyond our comprehension, we can't even deal with radiation in space forget hitting dust that fast. reply krallja 15 hours agoparentprevThe mystery name for Pioneer could be \"one\" or \"Pion\" or \"neer\". reply strangattractor 15 hours agoprevPresident Biden recently announced that software should be using memory safe languages. The command sent to Voyager - poke - is a command to directly set a memory location with a value - totally not memory safe:) reply oasisaimlessly 9 hours agoparentBiden administration outlaws gdb More news at 11 reply jgalt212 18 hours agoprevhopefully not a Killer Poke https://en.wikipedia.org/wiki/Killer_poke reply tetris11 16 hours agoprev> The availability of skills is also an issue. Many of the engineers who worked on the project - Voyager 1 launched in 1977 - are no longer around, Can you just imagine that? You wrote software in your 30s, and then 50 years later your grandchildren have to come visit you in the old folks home to ask you: \"Grandad, why did you write this goto statement at line 1892? Our AI think it might have to do with avoiding a hardware issue?\" to which you then reply, \"my dear, even if you asked me one year after I wrote it, I would not be able to tell you.\" reply cadr 16 hours agoparentNo, but I did find myself in the mid 90s as an intern trying to figure out code from the early 80s. It was really tricky code to get ECG processing working on some very small memory footprint or something. The name of the woman that wrote it was at the top of the file, and I looked her up in the HP company directory and she still worked there. As a hail-mary, I emailed her and asked a question about it. And she immediately got back to me with the answer. So, there are some engineers out there that do remember this sort of thing. reply HeyLaughingBoy 14 hours agorootparentLOL. I remember being asked to consult for my last employer on a problem they had while attempting to port some software that I had written almost 20 years earlier. It's amazing the random details that you remember when your memory is jogged. reply selimnairb 16 hours agoparentprevI would use my old person privilege to berate you for using \"AI\" to \"understand\" the code rather than getting your soft hands dirty. reply linsomniac 16 hours agoparentprevI'm kind of surprised, what with all the retro computing emulation software and skills I see getting posted here, that we don't have a Voyager emulator scene and a group of people standing by to run scenarios and propose fixes. reply bilegeek 14 hours agorootparentNot that I'm skillful enough to make an emulator, but I've tried years ago to find technical documents on the Honeywell HDC-402 used in Voyager and Viking (it's also apparently not related to the DDP-516 or 316 AFAIK.) There's SOME information[1], but not enough to make an emulator from what I've found. Aside from the lack of schematics or listings, there was the problem of the assembler being incomplete! \"One problem Lander software developers had was that no adequate assembler was ever written for the computer, perhaps because of the changing nature of the instruction set.(110) Patches had to be hand-coded in octal, with many jumps to unused memory space because of the lack of an assembler with relocatable addressing.\" p.174 on Viking, which used the same computer [1]https://ntrs.nasa.gov/api/citations/19880069935/downloads/19... (page 174 onwards) reply makomk 14 hours agorootparentAs far as I can tell the HDC-402 wasn't even the Viking computer that got reused on Voyager anyway - it was something NASA developed in-house from the orbiter side of the Viking mission and that presumably has even less documentation available. reply bilegeek 13 hours agorootparentYou're confusing the 24-bit HDC-402 on the lander with the custom 18-bit computer on the orbiter (p.164), which had it's origins in the sequencer for the Mariner missions (p.152-154). Though given the apparent level of NASA involvement in the 402's design, and the lack of evidence I can find for use outside of NASA, it might as well be called custom. reply hathawsh 15 hours agorootparentprevThat would be very interesting. Someone please tell me such a community exists somewhere. reply tetris11 15 hours agorootparentprevDarmokJalad1701 below mentions about hearing a podcast where new engineers did work on VMs reply ngcc_hk 15 hours agorootparentAny details? We have people work on a dead moon lander…why not a live v1/2. If sadly one is dead, the other still has some life left ? reply aardvark179 13 hours agoparentprevI have definitely had to do archeology on 20+ year old code, including disassembly to work out actual production code was when it clearly wasn’t the version we had source for, and that’s now 30+ year old code which I expect will still be in productions at least a decade from now. Equally I’ve seen COBOL compiled to new platforms because it has outlived all the systems it ran on. I’m pretty sure there must be areas of Java, or C++’s standard libraries that haven’t changed for a very long time, and will continue to be used for decades. The thing is, it’s often easier to just figure out the code, or rebuild the whole underlying platform, than to track down the original author and hope it wasn’t a Friday afternoon commit. reply jdminhbg 16 hours agoparentprev> Can you just imagine that? You wrote software in your 30s, and then 50 years later your grandchildren have to come visit you in the old folks home to ask you... Yes, I have nightmares like this all the time. reply LeifCarrotson 16 hours agorootparentIf only it was merely nightmares and not my day job. reply ceautery 16 hours agoparentprevI never thought of this before now, but tech from 1977 might not even be using ASCII. reply kayodelycaon 14 hours agorootparentGreat question! Voyager 1 does appear to be using ASCII. :D https://destevez.net/2021/09/decoding-voyager-1/ reply supportengineer 16 hours agoparentprevI know a developer in his 70's who maintains code he wrote in his 20's reply taylorfinley 15 hours agorootparentI would love to hear more about this if you can share any details reply bloomingeek 15 hours agorootparentprevGoing out on a limb here, wouldn't code written that long ago be almost impossible to hack with modern tools? (not to mention still using the old hardware.) reply HeyLaughingBoy 14 hours agorootparentOne of the Best Practices for maintaining software that you expect to support for decades involves archiving the development tools used. Of course, finding a platform to run it on could be a problem. Also, the License Server that so many proprietary tools need before they'll run. reply myself248 13 hours agorootparentI remember hearing about some hardware made for the government (military?) where the development tools ran on some 1970s minicomputer that had long since ceased to function, but it was no problem because in the 80s they wrote an emulator that ran on 68k, specifically an Amiga since that's what someone had sitting around the lab at the time. Then in the 2000's they realized the supply of Amiga parts wouldn't last forever so they bundled the whole thing up to run in an Amiga emulator that ran on whatever version of Windows was current at the time. Then 16-bit Windows ceased to be a thing, so.... reply supportengineer 12 hours agorootparentThis is pretty close reply wredue 14 hours agorootparentprevI’m not sure why that would be the case. If anything, I’d expect earlier code to be easier to hack. reply HeyLaughingBoy 14 hours agoparentprevI'm going to be a humorless pedant and reply by saying that with the level of forward and backward traceability required of aerospace software, it's unlikely that such a level of misunderstanding could occur. But maybe DO-178 wasn't a thing back then. That's just from what I've heard, though. I do medical devices. I'm told that my aerospace counterparts have it even tougher than we do. reply sho_hn 14 hours agorootparent> I do medical devices. Therac-25 happened in 1982 and changed that industry (and safety engineering in general) quite a bit, no? reply HeyLaughingBoy 14 hours agorootparentYes, but I don't get your point. reply malfist 14 hours agorootparentVoyager launched in 1977, well before the therac-25 reply HeyLaughingBoy 12 hours agorootparentOK. And? reply pkaye 15 hours agoparentprevThere is a nice documentary about what remains of the Voyager project team. The video is not free however. https://www.itsquieterfilm.com/ reply sho_hn 14 hours agorootparentI watched that a couple of months ago and loved it. It does a lot to humanize that team, I've been thinking of them during the recent news cycle. reply eichin 11 hours agoparentprevI (and at least couple thousand other people) are still running code I worked on in 1987. Maybe we should do something for the upcoming 40th anniversary... reply kstrauser 14 hours agoparentprevSee also: engineers of the B-52 bomber. It first flew 71 years ago and is expected to have another 30 years left. reply KineticLensman 14 hours agorootparentThere is at least one family that has three generations of B52 pilot (grandfather, father, son) [0]. Imagine being a coder who maintained code written by your grandfather and father... [0] https://www.minot.af.mil/News/Article-Display/Article/264580... reply kstrauser 14 hours agorootparentWell, my grandpa didn’t know jack about computers, so I very well could have maintained code he’s written based on the disquality of stuff I’ve had to work on in the past. But yeah. In “A Fire Upon the Deep”, Vinge talked about archaeological programmers. There’s no doubt in my mind we’ll reach that point. “Tell me again why time_t is only 64 bits?” “Pull up a chair while I dig out the LKML archive. You know, this was originally stored in electric fields, if you can believe it!” reply acheron 13 hours agorootparentFire up the subspace ansible and create a holodeck room for us to talk about it. You can't name the holodeck program \"CON\", \"LPT1\", \"PRN\", or \"AUX\", though, because those are MS-DOS device names. ( https://news.ycombinator.com/item?id=37076523 ) reply Arrath 10 hours agorootparentThere's an idea for another holodeck mishap episode right there. The ship's replicators start spitting out PacMan ghosts which quickly overrun the passageways ala Tribbles, in the end it turns out Ensign Crusher attempted to pipe his holodeck game to PRN and the Ship's computer mistook that as a command to begin (3d) printing. reply myself248 13 hours agorootparentprevTo this day, I use COPY CON FILENAME.TXT to make a quick-n-dirty note of something without leaving the terminal. reply kstrauser 13 hours agorootparentI use `cat > foo.txt` all the time for the same reason. reply bee_rider 14 hours agorootparentprevI bet they’ve replaced most of the computers by now, though. reply kstrauser 13 hours agorootparentProbably, but why’s that spar here? Why did they route that wire around the screw, and why doesn’t the 1960s bomb sight work right if the wire’s only twisted 3 times instead of 4? reply jamesy0ung 13 hours agorootparentBomb sights aren’t used anymore. The weapons used by the B-52 are all gps guided and the computer on board simply gives a timer for the pilot to press the pickle button. The weapon then self guides to the target. reply kstrauser 13 hours agorootparentThat sounds believable, but I bet they still have lots of surprisingly old equipment that works too well to bother replacing. reply wredue 15 hours agoparentprevIt’s funny which code I remember and which code I don’t. There’s code I wrote 10 years ago at work that I still remember and can point out exactly where everything is. Then there’s code I wrote last week that is completely gone. reply jacobriis 16 hours agoparentprevCan you just imagine that? No this is not a plausible scenario. reply thebruce87m 16 hours agorootparent> plausible scenario I’m not sure what you are calibrating against but I feel like the last 20 odd years are full absolute batshit crazy stuff that doesn’t make sense and this seems rather tame. reply dotps1 16 hours agorootparentprevI mean, this stuff does happen. There is an old electric station near me that is used for various things sometimes. Some band was in there shooting a music video and bumped something and somehow the whole area started filling with water. Nobody could stop it. The government, the water company, everyone was struggling to figure out what to do, and they decided to call the old guy that used to work there. He was in his 90s but he told them how to fix everything. reply flagged24 15 hours agorootparentI would love to read the full story on this. reply chgs 9 hours agorootparentIf it doesn’t end up with an itemised bill of $1 to turn off a stopcock and $999 to know where it is, I’d be disappointed. reply hathawsh 16 hours agorootparentprevI wouldn't dismiss that scenario. It seems plausible that the documentation is so extensive that it takes time and effort to answer some questions. It might be easier to just ask the authors, if they're still around. reply Vecr 16 hours agorootparentprevBecause you never write gotos? Many embedded and kernel programmers still do. I think it makes sense in general. reply williamcotton 15 hours agorootparentIt is known as error handling. Some languages renamed the practice to try/catch. Others added a Result type. reply trealira 14 hours agorootparentLikely you know this, and you're just being funny, but the try/catch statement is more like setjmp/longjmp in C. The Result type in Rust is syntactic sugar for integer return codes, returning early on errors, and tagged union structures. And where C programmers use goto statements, C++ programmers use destructors, and Rust programmers use the Drop trait. Walter Bright also says that nested procedures in D eliminate most use cases of goto for him. You can also always avoid goto, in C, but usually, either it has excessive if-statement nesting, it uses boolean flag variables in loop conditions, or it uses structures to create state machines, but these are usually just uglier and more error-prone than the equivalent version using goto. The same applies to avoiding break, continue, and early returns. reply xcv123 14 hours agorootparentprev> No this is not a plausible scenario. COBOL exists. Billions of lines of COBOL still in production today. The scenario is already happening now. reply zoeysmithe 16 hours agoparentprevMy understanding is that its very well documented, but the funding isn't there to do much with it. I mean most of the team behind things like the Atari computers, Acorn, Commodore, early Apples, etc are retired but we can emulate them and understand these things on a very technical level. I know this isn't a great analogy, but ultimately age of the project or the age of the original team members isn't the bottleneck. I sometimes see retro projects on hack-a-day done by people who could be the grandchildren of the original designers of those vintage chips and OS's. They probably know more about that chip or OS than the original people do just due to them being out of the game for so long. The same way people regularly lose to fifth graders in tests because they dont recall 5th grade science and civics. If anything your scenario might be the opposite! Grandpa might be asking his granddaughter how those registers worked or how to emulate his OS from 1982. I remember reading about the team that maintains the Voyagers. Its a skeleton crew using legacy equipment to keep the communication going with the assumption the next decade, or even earlier, is going to be it. NASA has the same problem the private sector has. Capitalism rewards things that will generate profit/prestige, not legacy cost centers, and NASA is not immune from that dynamic as NASA employees and managers want to maximize their income and prestige too. So the people maintaining or bug fixing old products are often lowest on the prestige, pay, recruiting, and profit spectrum than those chasing new things. They get the skeleton crew funding and can't do novel things, even if technically possible because of lack of staff and buy-in. Passion projects make for feel-good documentaries like 'It's Quieter in the Twilight' but ultimately if society isn't vested in these teams, their hands will always be tied. reply jcadam 15 hours agorootparentA young engineer must know that getting stuck on a legacy project is a career-limiting move. Happened to me when I got stuck on a old Ada codebase for a legacy aerospace system (unemployed in 2008, you take whatever job you can get), and it took years, and a good chunk of my spare time doing projects/studying, to find a company willing to give me a chance working on something modern again. Now, someday when I'm in my 60s/70s, and you have some legacy system written in some defunct language nobody under the age of 50 has any experience with, sure, I'll do it. But it'll cost you. reply robocat 13 hours agorootparentI don't hire, but that story would make me want to hire you. It takes certain skills and pig-headedness to successfully work on old software! I once asked a company to rehire me saying that I only wanted to do software maintenance work (I wanted low stress). I am good at it, and it's hard to find people that want to do that work. They didn't rehire because although the manager really wanted me back, his idiot boss had taken it personally when I had quit. Idiot boss later got ousted to their dismay: I shouldn't enjoy that but I did! reply trealira 14 hours agorootparentprevWhy do companies do that? Shouldn't it be enough that you have experience contributing to a large project long-term and you can program decently? Is it that modern programming just requires different/additional programming skills compared to most old codebases, like writing asynchronous code? reply justin66 14 hours agorootparentprevThe thing Voyager has going for it is, it's a small team. JPL is laying people off all over the place lately. I'm not sure if it's really \"society\" that is responsible for these funding difficulties, it's the politicians. If you ask a random member of the public how much of the federal budget is allocated to NASA, they'll generally give you a percentage that's wildly higher than the actual figure. reply ngcc_hk 15 hours agorootparentprevI hate people just random throw in capitalism. Is the communism better in maintaining old code … do they even exist. Not to mention please we are here not for the money as most does not, just awe of what can be done for a computer job which love to do and have such legacy. Capitalism does not really exist. It is money, incentives, job, human … or love to hack. reply quickslowdown 15 hours agorootparentI'm going to just outright dismiss this comment the way you're dismissing people talking about capitalism, a very real economic system we're all living under, since it's ridiculous on its face. reply ChrisArchitect 17 hours agoprev [–] [dupe] Some more discussion on the official post: https://news.ycombinator.com/item?id=39701473 reply dang 16 hours agoparent [–] Comments moved thither. Thanks! Edit: so many of those comments have to deal with the contents of this particular article (which does add more background) so I think we need to move them back. Let's keep the less baity title from the other post, though. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Voyager 1 spacecraft might have resolved its communication problems after receiving a corrective command, decoding a successful memory dump from its Flight Data System.",
      "Engineers are now working on analyzing the data and comparing it with past transmissions to troubleshoot further.",
      "Challenges include significant communication delays and finding engineers with the required expertise to address the issue."
    ],
    "commentSummary": [
      "Engineers working on legacy projects like the Voyager spacecraft face challenges such as poor documentation, software maintenance issues, and funding constraints.",
      "The text discusses potential future interactions with Voyager 1 and the idea of sending ships to explore space, alongside coding practices and understanding outdated technologies.",
      "It also explores the influence of capitalism on software development in the context of legacy projects."
    ],
    "points": 279,
    "commentCount": 169,
    "retryCount": 0,
    "time": 1710428549
  },
  {
    "id": 39710455,
    "title": "NY Disbars Copyright Troll for Unethical Practices",
    "originLink": "https://abovethelaw.com/2024/03/new-york-disbars-infamous-copyright-troll/",
    "originBody": "Technology New York Disbars Infamous Copyright Troll For whom the bell tolls; it tolls for copyright trolls. By Joe Patrice onMarch 14, 2024 at 11:43 AMMarch 14, 2024 at 11:43 AM 20 Shares For years, Richard Liebowitz ran a very successful operation mostly sending threatening letters to companies claiming that they had infringed upon copyrights held by his photographer clients. Under the best of circumstances it’s a niche practice area that’s… kinda shady. But Liebowitz gained a degree of infamy across a number of matters for high-profile missteps in cases that sparked the ire of federal judges. Now, finally, New York has disbarred him. Liebowitz wasn’t alone in the copyright trolling practice. A number of entities scour the internet looking for photographs that they can claim are “unlicensed” and demanding thousands of dollars to settle the matter knowing that between statutory damages for copyright infringement and the cost of litigation, most companies will just pay it. Many times, the photo in question actually is legally licensed through an agency like Getty Images, but the plaintiff photographer has, for whatever reason, pulled the image since the license was granted. This runs the risk that some plaintiff might do this on purpose hoping to catch some legal licenseholder unawares and bank on the target just settling to avoid bringing any lawyers into the situation. Which is why, for example, a judge in one case cited by the disbarment opinion ordered Liebowitz “produce to the defendant records sufficient to show the royalty paid the last three times that the picture at issue was licensed, and the number of times the picture was licensed in the last five years; if the picture was never licensed, the plaintiff was to certify that fact as part of the plaintiff’s production.” In this case, Liebowitz “did not timely produce the required royalty information to the defendant” per the disbarment opinion. Sponsored CloudLex - Purposefully Built To Help Plaintiff Personal Injury Firms Build, Manage, And Grow Their Business From CloudLex Though most of the opinion describes more fundamental case management problems. From a case brought in 2017: The respondent stated under penalty of perjury that he did not and had never made a settlement demand in this matter. In fact, the respondent had sent the defendant’s counsel an email in which the respondent proposed settling the matter for the sum of $25,000. And another case brought in 2017: On January 13, 2018, the respondent submitted a letter (hereinafter the January 13, 2018 letter) to the District Court, requesting an adjournment of the pretrial conference scheduled for January 19, 2018, and stating that the defendant “had yet to respond to the complaint” and that the plaintiff intended to file a motion for a default judgment. Judge Cote granted the request and ordered the motion for entry of default due on January 26, 2018. The respondent’s statement in his January 13, 2018 letter that the defendant “had yet to respond to the complaint” was false and misleading, and the respondent knew that it was false and misleading when he made it. The January 13, 2018 letter failed to advise the court of the months-long history of communication between the parties, beginning in July 2017, as mentioned above. Sponsored Sponsored CloudLex - Purposefully Built To Help Plaintiff Personal Injury Firms Build, Manage, And Grow Their Business From CloudLex Sponsored Early Adopters Of Legal AI Gaining Competitive Edge In Marketplace How to best leverage generative AI as an early adopter with ethical use. From LexisNexis Sponsored Document Automation For Law Firms: The Definitive Guide Legal document automation is no longer only for the exclusive few. From THOMSON REUTERS Sponsored Early Adopters Of Legal AI Gaining Competitive Edge In Marketplace How to best leverage generative AI as an early adopter with ethical use. From LexisNexis From yet another matter: The plaintiff admitted in a deposition and in other documents that the Photograph had been previously published on numerous occasions. To prevent the defendants from learning that the plaintiff did not hold a valid registration, the respondent stonewalled the defendants’ requests for documents and information. The respondent also failed to comply with an order by Magistrate Judge Debra Freeman to obtain and produce Copyright Office documents to demonstrate a valid registration. After it came to light that the Photograph was not registered, and despite the record stating otherwise, the respondent argued, without evidence, that the lack of registration was merely a mistake. If there’s a lesson to take away from these and the many, many more examples included in the opinion, it’s that copyright trolling outfits are largely unprepared for someone to push back on their demands. Firing off demand letters, memorializing boilerplate licensing agreements, and collecting cash is a tidy business model right up until a firm has to juggle hearings and discovery requests and experts and “not committing perjury.” But perhaps the most bizarre story involves Liebowitz missing an April 12, 2019 hearing, explaining that his grandfather had passed. When Judge Seibel directed Liebowitz under penalty of contempt to furnish evidence or documentation regarding the date of his grandfather’s death, Liebowitz shot back that the order “likely constitutes a usurpation of judicial authority or a breach of judicial decorum.” On November 7, 2019, the respondent retained counsel to represent him in the contempt proceedings, and on November 11, 2019, the respondent sent a letter to Judge Seibel admitting that he failed to carry out his responsibilities to the District Court and to his adversary. The respondent also admitted that his grandfather died on April 9, 2019, and was buried that same day. Sponsored Sponsored The Secrets Of Small Firm Success Read on for some specific, actionable ways to ensure clients continue to come in the door. From Above The Law Sponsored Are Small Firms Going Big On Legal Tech? Please help us benchmark your firm against your peers through this (always) brief and anonymous survey and enter for a chance to win a $250… From Above The Law Just. Wow. You know, “my grandfather died this week” is something you can tell a court before a hearing and they’ll probably grant it. It’s not like you’re asking to give birth or anything. But to lie about it to the court and then keep doubling down is… a choice. And a poor one as it turns out: ORDERED that pursuant to 22 NYCRR 1240.13, the respondent, Richard P. Liebowitz, a suspended attorney, is disbarred, effective immediately, and his name is stricken from the roll of attorneys and counselors-at-law…. Matter of Liebowitz [New York Courts] Joe Patrice is a senior editor at Above the Law and co-host of Thinking Like A Lawyer. Feel free to email any tips, questions, or comments. Follow him on Twitter if you’re interested in law, politics, and a healthy dose of college sports news. Joe also serves as a Managing Director at RPN Executive Search. Topics Copyright, Copyright Trolls, Richard Liebowitz, Small Law Firms, Technology Above the Law daily newsletter Sign up and get the latest news in your inbox. Subscribe Now We will never sell or share your information without your consent. See our privacy policy. Recommended Partner Parts Way With Firm -- See Also Anyone Out There Want To Manage Davis Wright Tremaine?: Pete Johnson is covering in the meantime. Kelly Clarkson’s Legal Team Doesn’t Play: $2.6m could be just the start. Northwest Law Ain’t Perfect: There have been complaints of mismanagement, among other things, for years. Right Wing Mad They Can’t Put Wrench In Legal Cogs As Easily: Sucks to suck, I guess. Goodbye, License!: Pour one out for Richard Liebowitz. By Chris Williams More From Above the Law Law Schools Public Interest Work Is Looking Better And Better Lawyering for good. By Kathryn Rubino Biglaw How Do Lawyers Celebrate Pi Day? Notes to my (legal) self. By Olga V. Mack In-House Counsel Lessons From The Movie 'Oppenheimer' The scientist J. Robert Oppenheimer commanded respect by earning it and had a very different view of how people should work together across disciplines and not hierarchies. By Jill Switzer Technology Exclusive: iManage Reveals Details On Its Growth, Lays Out Plans To Further Leverage Gen AI, Partnerships During 2023, iManage added more than 300 new companies and law firms as customers, bringing its total global customer base to 4,000 customers across six continents. By Robert Ambrogi From the Above the Law Network The Secrets Of Small Firm Success Source: Above The Law The State Of Small Law Firms In An Era Of Change Source: Thomson Reuters and Above the Law How You Can Use Tech To Strengthen Client Ties Source: Thomson Reuters And Above The Law This Is Why You Don’t Take Law Advice From Twitter — See Also Source: Associate Center Document Automation For Law Firms: The Definitive Guide Source: THOMSON REUTERS Differentiating Your Solo Firm In A Crowded Marketplace Source: Thomson Reuters & Above the Law 5 Things To Consider Before Hiring A Legal Marketing Partner Source: THOMSON REUTERS How Overture Law Is Revolutionizing Referral Fees Source: Above The Law Sponsored The Secrets Of Small Firm Success Read on for some specific, actionable ways to ensure clients continue to come in the door. From Above The Law Recommended Small Law Firms The Evolution Of Motherhood, Law Firm Ownership, And Work-Life Balance Don’t be afraid to change and evolve. Our kids don’t give a second thought to their own natural evolution; you shouldn’t either. By SARAH FELDMAN HOROWITZ Government DC Circuit Will Not Be Keeping Peter Navarro Out Of The Clink How is Peter Navarro going to jail? Let us count the ways! By Liz Dye Sponsored Are Small Firms Going Big On Legal Tech? Please help us benchmark your firm against your peers through this (always) brief and anonymous survey and enter for a chance to win a $250… From Above The Law Recent Jobs Commercial Litigation Associate - HONOLULU Location Honolulu, Hawaii posted by Starn O'Toole Marcus & Fisher Legislative Counsel or Senior Legislative Counsel (commensurate with experience) Location Washington, D.C., United States of America posted by Human Rights Campaign Labor & Employment Attorney Location 670 N. Commercial Street, Manchester, New Hampshire posted by Drummond Woodsum View All Sponsored Document Automation For Law Firms: The Definitive Guide Legal document automation is no longer only for the exclusive few. From THOMSON REUTERS",
    "commentLink": "https://news.ycombinator.com/item?id=39710455",
    "commentBody": "New York disbars infamous copyright troll (abovethelaw.com)251 points by Turing_Machine 10 hours agohidepastfavorite56 comments aragonite 8 hours agoMemorable quote a while back by an SDNY judge about Liebowitz: > In his relatively short career litigating in this District, Richard Liebowitz has earned the dubious distinction of being a regular target of sanctions-related motions and orders. Indeed, it is no exaggeration to say that there is a growing body of law in this District devoted to the question of whether and when to impose sanctions on Mr. Liebowitz alone. See, e.g., ... This Opinion is the latest contribution to that body of law. For the reasons stated below, the Court concludes that sanctions should indeed be imposed on Mr. Liebowitz for his repeated failure to comply with this Court’s orders, failures that imposed considerable and unwarranted costs on the Court, its staff, and Defendant NBCUniversal Media, LLC. https://www.abajournal.com/images/main_images/Lebowitz.pdf reply dmix 7 hours agoparentHe sued NBC? What a dummy reply ugh123 8 hours agoprev>The respondent’s statement in his January 13, 2018 letter that the defendant “had yet to respond to the complaint” was false and misleading, and the respondent knew that it was false and misleading when he made it. The January 13, 2018 letter failed to advise the court of the months-long history of communication between the parties, beginning in July 2017, as mentioned above. How is that not outright fraud? reply dllthomas 8 hours agoparentI'm also curious about that, but we should recognize that whether it's fraud and whether it should be prosecuted as fraud are different questions. For a conviction you need proof beyond a reasonable doubt, where disbarment seems (from a cursory search) to merely require preponderance of the evidence. If that's right, some people will rightly be disbarred for crimes they cannot be convicted of. reply starspangled 5 hours agorootparentLawyers rule the entire justice system. Not even the \"good\" ones want to normalize the prosecution of lawyers for committing crimes while practicing law. reply dllthomas 4 hours agorootparentThat may also be the case, and not knowing a lot about this case it does seem like prosecution is probably merited here, and we should push back on tendencies like that across industries. My comment still stands, though; we should be quicker to disbar over a thing than to prosecute, evidentiarily speaking. reply omeid2 3 hours agorootparentOn the contrary, I believe the existence of and ease of disbarring works as a substitute for prosecution, albeit under different terms of \"law\" and \"justice-- if you can call it that. At the same time, the very existence of disbarring without the due process required for convictions, also means, the \"good ones\" wouldn't risk it by speaking up and demanding \"prosecution\" of their peers. reply AnthonyMouse 2 hours agorootparentprev> Not even the \"good\" ones want to normalize the prosecution of lawyers for committing crimes while practicing law. Eh. Prosecuting someone for borderline calls and novel arguments is a slippery slope, but unambiguous and intentional fraud isn't that. reply MBCook 6 hours agoparentprevAs ridiculous as that is, claiming his grandfather died as an excuse then claiming the court lacked jurisdiction and decorum by asking for proof is really something. Damn. reply 3836293648 5 hours agorootparentHis Grandfather did die, just three days before the day he claimed, according to Leonard French (Lawful Masses)'s stream on the topic reply hibbelig 3 hours agorootparentMaybe I should read the article again but I thought the grandfather died in April but the excuse was for November. reply xymostech 2 hours agorootparentMy source was also the Lawful Masses stream, but it sounded like the original excuse was made in April, but it took until November for him to actually produce the death certificate to prove that he had lied about when his grandfather had died. reply justinclift 37 minutes agorootparentIt sounds like he didn't lie though? His grandfather did pass away a few days prior. Depending upon what was happening with the related family, there can be a whole bunch of things that need urgently taking care of in relation to it. reply ricardobeat 6 minutes agorootparentThat point is made in the article - he could have simply said the Grandfather died that week, and it would have been accepted. Instead he doubled down on going on attack, most likely because it did feel like a lie when he said it or was not the actual reason he missed the proceedings. dchest 3 hours agorootparentprev\"But perhaps the most bizarre story involves Liebowitz missing an April 12, 2019 hearing, explaining that his grandfather had passed.\" \"The respondent also admitted that his grandfather died on April 9, 2019, and was buried that same day.\" reply neom 7 hours agoprevLeonard French has almost obsessively covered this dude at length https://www.youtube.com/playlist?list=PLkdgWccrJAy6scjRxG7bf... 56 videos, heh. :p reply lelag 25 minutes agoprevThis discussion [1] from last week about a Cory Doctorow article sheds interesting lights on this type practices by copyright / copyleft trolls. [1] https://news.ycombinator.com/item?id=39610509 reply ryukoposting 6 hours agoprevI found out recently that a local artist was forced to cease operations because of a copyright troll. I can't imagine they're the only example of a small business getting flattened by this kind of abuse of the law. reply alexey-salmin 3 hours agoprev> For years, Richard Liebowitz ran a very successful operation mostly sending threatening letters to companies claiming that they had infringed upon copyrights held by his photographer clients. Under the best of circumstances it’s a niche practice area that’s… kinda shady. Why is it shady when done properly? Copyright violations are a valid concern for photographers. reply AnthonyMouse 2 hours agoparent> Why is it shady when done properly? The issue is that it isn't. The economics of it don't militate in favor of diligence and precision. An individual claim is rarely going to be for a lot of money so to turn it into a profitable business it requires scale. At which point they typically rely on automated systems with a significant false positive rate that don't take into account possible fair use etc. Meanwhile the coercion to settle applies just as much to an innocent party, because the premise is \"pay a little to avoid an expensive court battle\" which is still coercive even if you could win in court. Practices that involve shaking down innocent people are shady. reply cowsandmilk 29 minutes agorootparentFun thing is I’ve faced the same automation of incompetence at scale from the lawyers who run Florida’s child support system. There’s a deadbeat dad out there born 10 days before me with the same first and last name. Every time I move, the automation goes into action and it takes me hiring a lawyer remotely in Florida to get it to stop every time. reply Karellen 45 minutes agorootparentprev> An individual claim is rarely going to be for a lot of money Isn't it? I thought the MAFIAA had made it so that copyright violations incurred $150,000 in damages per work infinged? reply AnthonyMouse 39 minutes agorootparent\"In a case where the copyright owner sustains the burden of proving, and the court finds, that infringement was committed willfully, the court in its discretion may increase the award of statutory damages to a sum of not more than $150,000.\" reply alexey-salmin 2 hours agorootparentprevI agree that running an automated system with a significant false positive rate is shady, it's just I don't think that this counts as \"under the best circumstances\". I've seen cases of e.g. big newspapers publishing photos without permission and when asked politely to purchase a license reply that \"you should be proud of your work being published in such a respectable establishment as ours\". For a photographer in question an \"expensive court battle\" is an obstacle just the same and I have nothing against a lawyer who makes a living out of cases like this. reply AnthonyMouse 42 minutes agorootparent> For a photographer in question an \"expensive court battle\" is an obstacle just the same and I have nothing against a lawyer who makes a living out of cases like this. That this is an obstacle for the photographer is exactly the issue. The scale is required in order for it to become a \"practice area\" (as opposed to e.g. a pro bono case taken on the side), and the shady practices come with the scale. reply whatshisface 2 hours agoparentprevToll bridge sales do occur, but if you think that's not a shady practice area, I have a bridge to sell you. :-) reply alexey-salmin 2 hours agorootparentThat's a good example. Maybe I misunderstand the meaning of \"shady\" but I don't see toll bridge sales as such. It's either a perfectly legitimate deal or an outright fraud. It's not some grey area when selling toll bridge is semi-legal with courts disagreeing over whether to punish you or not. reply shmerl 8 hours agoprevDisbarring is not enough. Prison time for racketeering is proper. reply dudeinjapan 6 hours agoparentPrison is not enough. Patent trolls should be thrown into the deepest flaming pit of hell. reply asah 6 hours agorootparentSorry, flaming pits are patented. Can I offer you lava? reply reactordev 6 hours agorootparentLava is patented as well, can I offer you magma? reply brookst 5 hours agorootparentMy client has patented all forms of magma production that involve heat or pressure. Can I offer you lukewarm water? reply stove 5 hours agorootparentMy client Luke is suing for defamation reply diego_sandoval 3 hours agorootparentLuke Skywalker is a copyrighted character. My client, The Walt Disney Company, is suing your client, Luke, for copyright infringement. reply rprwhite 1 hour agorootparentMy client, the sky, is suing your client for copyright infringement. Additionally my client is suing GGP’s client for the offer of water, in which my client believes they have a valid interest but were not given due consideration in the making of this offer. reply porksoda 6 hours agoparentprevMaybe he's a bad guy, but prison is worse than you think, and probably doesn't fit the crime here. Imnsho. reply MBCook 6 hours agorootparentHe wasted a fantastic amount of the court’s time and various people’s time and money which they never got back. He clearly knew what he was doing was wrong. Why shouldn’t there be some criminal statute to punish him? Nothing here fixes any of the harm he’s caused. It just (hopefully) prevents him from doing it in the future. Though based on how he got here I’m guessing he’ll find a new way. reply lmm 5 hours agorootparent> He wasted a fantastic amount of the court’s time and various people’s time and money which they never got back. Virtually every crime costs other people time and money. We generally draw a line between that and more severe varieties of crime, such as those involving physical violence. reply AnthonyMouse 2 hours agorootparentFraud and extortion are both criminal offenses that can carry prison terms without committing any act of violence. reply shmerl 5 hours agorootparentprevWhat do you think the punishment for protection racket and extortion should be? Patent trolling is exactly that, except masking under the legal system. reply classified 29 minutes agoprevThe headline makes it seem that being a copyright troll is grounds for disbarment. If only! reply autoexec 7 hours agoprevGo after the guys working for Strike 3 Holdings next! reply prbuckley 5 hours agoparentFun fact Strike 3 holding files the 2nd most lawsuits annually in our federal court system (~3000), the US government is #1 reply tanepiper 48 minutes agoprevA quick search and yea the guy looks as slimy as he sounds. reply charcircuit 9 hours agoprevHe can still send such letters if even though he is disbarred, right? It's not like it's a trial. reply freejazz 9 hours agoparentNot ones claiming that he is an attorney that represents the photographer. reply charcircuit 8 hours agorootparentAn authorized representative does not have to be an attorney reply freejazz 6 hours agorootparentNo, but who cares what non-attorneys have to say about legal matters? Anyone that settles a claim asserted by a non-attorney is nuts. reply creshal 1 hour agorootparent> Anyone that settles a claim asserted by a non-attorney is nuts. Going by how many people fall for the most stupid of spam mails, that's gotta be a billion-dollar industry too, then. reply throwaway74432 7 hours agoprevIt's heartening to see people punished for operating in bad faith. Real scumbag behavior seems to thrive when what they do is \"technically legal\" but super corrosive to the social fabric. I know it's a fine line, which is why judges and other decision makers need to be wise. reply dclowd9901 6 hours agoparentIt doesn’t seem like he was punished for litigating in bad faith but rather for lying about his grandfather dying. Lying to a judge is about the worst thing a practicing attorney can do. reply freejazz 9 hours agoprev [–] \"Liebowitz wasn’t alone in the copyright trolling practice. A number of entities scour the internet looking for photographs that they can claim are “unlicensed” and demanding thousands of dollars to settle the matter knowing that between statutory damages for copyright infringement and the cost of litigation, most companies will just pay it. Many times, the photo in question actually is legally licensed through an agency like Getty Images, but the plaintiff photographer has, for whatever reason, pulled the image since the license was granted.\" This article is so poorly written and uninformed, it conflates asserting copyright infringement against an entity that licensed the photo, with the court demanding past licenses as a means of calculating actual or statutory damages. Liebowitz problem is that he has lied to courts several times previously, about things as trivial as scheduling issues, or the basic facts of his case as the article points out. His disbarrment has nothing to do with him asserting copyright cases, it has to do with him lying. Unfortunately the term troll is used against pretty much any photographer asserting their legal rights over the work that they own. reply paulgb 9 hours agoparentI think the term “troll” is generally accepted where someone’s MO is to spray-and-pray settlement demands that the troll doesn’t actually want to take to court. Given that his behavior was all related to trying to avoid demands of judges and court time, it sounds like it actually was related to his trolling indirectly. reply freejazz 8 hours agorootparentYeah, but look at any thread where patents are an issue, any plaintiff that isn't a big tech company gets called a troll. Also, Liebowitz had no fear of going to court, he'd sue before he'd send letters. Liebowitz was disbarred because he repeatedly lied. The issue with him not producing licenses is because they didn't support the damages award he wanted, not because he just didn't want to deal with judges or being in court. Like I said, the article is very poorly written. reply Eiim 8 hours agoparentprev [–] Part of Liebowitz's problem was that he did ~0 research before filing a lawsuit. Often the only thing he did was send the photographer a list of URLs and ask for \"GO\" or \"NO GO\" for each one. In at least some cases there was a license that he or probably should have known about, but he didn't even bother to check. He probably would've been fine with that though if he hadn't lied to the judge(s) so, so much. reply freejazz 6 hours agorootparent [–] In cases like these, you need to rely on the photographer, they are the ones who will know there is a license. So him relying upon the client, who might make a mistake, wont necessarily be the end of him as you point out, which I agree with. These photographers do not have agents, and to the extent they did, it'd be Getty, who pays them less than $5 for perpetual web-use licenses. That's why so many of them leave Getty. Getty then continues to offer new licenses for the photographs, despite their contract being terminated. The article seems to mistake that as well. I'm a copyright attorney and we have the opposite approach of Liebowitz. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Richard Liebowitz, a copyright troll in New York, has been disbarred for unethical behavior, such as lying, stonewalling, and ignoring court orders.",
      "Copyright trolls like Liebowitz would send intimidating letters to companies, alleging copyright violations and seeking hefty settlements.",
      "This disbarment stresses the dangers of pursuing predatory copyright practices without the necessary legal readiness, showcasing the consequences of dishonesty and evasion in court settings."
    ],
    "commentSummary": [
      "Richard Liebowitz, a copyright lawyer, disbarred in New York for unethical behavior, including dishonesty in copyright cases, sparking a debate on lawyer accountability.",
      "Concerns arise over misuse of copyright laws and unethical practices like sending threatening letters to companies, raising questions about legal ethics.",
      "The case underlines the significance of thorough research and ethical conduct in copyright and patent cases, emphasizing the impact of legal decisions in such matters."
    ],
    "points": 251,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1710460400
  },
  {
    "id": 39704304,
    "title": "Students Win Hackathon with Innovative Dining Habits Summary Project",
    "originLink": "https://jero.zone/posts/meal-plan-wrapped",
    "originBody": "A few weeks ago, my friend Ben and I won JumboHack, a hackathon at Tufts University. Our entry generates a Spotify Wrapped-like summary of students’ dining habits by scraping Tufts’ meal plan portal. Through some clever promotion on Ben’s part, we managed to get hundreds of students to use it in just a couple of days. We won the general track, ”most complete project,” and the whole shebang. You can try a live demo of our project here. Ben and I during judging Tufts, like Brown and many other colleges, uses a piece of software (protected under an expired patent that’s older than both of us) from a company called Atrium. Their marketing claims, in contrast to “legacy” systems, that it will “delight” users. As we will see, the irony of claiming Atrium’s software isn’t “legacy” is just too good. Tufts calls their installation “JumboCash” and it can be accessed at www.jumbocash.net. (Don’t forget the www.—it won’t resolve without it.) However, the site that is ultimately loaded is determined by the cid (campus/college/customer ID?) parameter. Here’s Brown’s portal loaded through Tufts’ domain: www.jumbocash.net/index.php?cid=248. You can even use the raw IP: 3.131.28.213/index.php?cid=248 in all its http:// glory. Bonus web development crime: Just as I've done here, the header of Tufts' JumboCash portal is hotlinked from the WordPress.com site of a long-deceased student organization The portal is really a wrapper around the reanimated corpse of much older software, its rotting flesh visible through nonsensical decisions and the occasional XML response. The first thing Ben and I noticed when logging into the JumboCash portal is that the session key is stored as a URL parameter, just like the cid. https://www.jumbocash.net/index.php?skey=20613b5ef40f04e15ecc5d5f56513b92&cid=233 While a cookie is set, it is ignored. You can copy the URL into a private browsing window (or change the domain to another school’s) and it will work just fine; remove the skey parameter and it won’t. Change to another IP address, and it…breaks? Clearly some attempt at security was made, and it feels a bit too complex to be the result of purely ignorance. Guest access Because we can’t instruct students to copy-and-paste the URL (and thus their session key), we needed another way to access students’ transaction history. We turned our attention to JumboCash’s guest access feature. Presumably intended for parents to reload their children’s accounts, it allows students to given an email address access and choose from a deceptively fine-grained set of permissions. I say “deceptively” because guests can change their own permissions and even add other guests. “Disabling” a guest’s access doesn’t actually restrict any features, and guests can re-enable themselves. Adding a new guest sends them an email with a password. We purchased the excellent domain jumbo.cash and had students add guest@jumbo.cash to their accounts. We intercepted the emails with Postmark and pulled out the password, running a job to log in and scrape the requisite information. The email from JumboCash is pretty much the same When it came to scraping the transaction history itself, we finally caught a small break: the portal allowed CSV export, making our job a bit easier. However, an HTML table, which is essentially XML, wouldn’t have been much trouble. The final hurdle At the time, we decided adding a guest to Atrium’s “delightful” portal was already enough friction and decided not to ask students for their email. In hindsight, we should have collected them at the beginning and given students a custom @jumbo.cash email address to keep things straight. To achieve this ✨magical✨ experience, we needed to figure out students’ email addresses from their name, since that’s all the portal seems to have. After an unsuccessful attempt at scraping Tufts’ Outlook directory, we took a closer look at the public directory, which includes the names and emails of every student. Popping the hood, it makes a nice little request to a JSON API, which appears to be a wrapper around one or more LDAP directories. But unfortunately, it’s not allowed to be that easy. The JumboCash portal displays students’ legal first and last names (e.g. Benjamin not Ben). The directory, on the other hand, can only be searched by students’ preferred names. Though not displayed in the interface, its API does return their legal names in Lastname, Firstname M. format. Our first idea was to search the directory by last name and lazily use the PHP standard library’s levenshtein() function to find the closest match. However, this doesn’t work well with common or short last names—for example, “Li” is not only common but is included in lots of names like Julian and Colin and returns dozens of matches. Since the directory’s pagination was broken (while I have a theory as to why, it looks like it’s already been fixed), we couldn’t page through to find an exact match. Our gross solution was to try a bunch of formats: Lastname, F. Lastname, etc. and pick the closest name. This works…enough of the time. Logging in Actually logging into JumboCash required two HTTP requests and four hours of reverse engineering. I spent so long on it that Ben, who had already scraped JumboCash for a previous project, started working on a Puppeteer solution in parallel. But first, here’s how authentication actually works. A POST request is sent to /login.php with a username and loginphrase, which creates a session key. Then, second, a GET request to the same page “activates” the token. Failing to do this second request puts the UI into a weird “half-logged-in” state. The first request returns, instead of a Location header, a snippet of JavaScript ( to be exact) to rediect to another page. The second page (also /login.php, just with some URL parameters) contains a loader and some nasty JavaScript. Processing...The spinner, unceremoniously copy-pasted from some tutorial While abnormal, this dance wouldn’t have taken the hours it did had one of our tools not lied to us. When using HTTPie to poke around the site, it would render the HTML returned by the first POST request, including executing the JavaScript it contained. However, while HTTPie’s webview still made the request (as a normal browser, without any of our headers), it didn’t show that it had. We were baffled as to why session keys generated with requests from HTTPie worked, but those using even the cURL code it generated did not. As it turned out, HTTPie was secretly making the second “activation” request. HTTPie’s webview should probably not execute JavaScript, especially without showing the result. (It would also be nice if the webview stayed disabled instead of turning itself back on after every request.) The JavaScript on the intermediary “loading” screen very responsibly checks if the browser supports the newfangled XMLHttpRequest API before polling an XML API for the status of the skey. While the concatenation in this script (included below) is out of control, I was luckily unable to find an XSS. That would have been quite fun, given the number of .edu domains this software runs on. Keep scrolling! There’re goodies after, I promise! var isIE = false; var req; var messageHash = -1; var targetId = -1; var centerCell; var size=40; var increment = 100/size; var attempts=0; function pollTaskmaster() { attempts++; var url = \"login-check.php?cid=248&skey=3620efdb97b88d111e8ec5388244e978\"; validate(url); } function validate(url) { if (window.XMLHttpRequest) { req = new XMLHttpRequest(); } else if (window.ActiveXObject) { isIE = true; req = new ActiveXObject(\"Microsoft.XMLHTTP\"); } req.open(\"GET\", url, true); req.onreadystatechange = processPollRequest; req.send(null); } function processPollRequest() { if (req.readyState == 4) { if (req.status == 200) { var message = req.responseXML.getElementsByTagName(\"message\")[0]; if (!message) { window.location.href='login.php?cid=248&'; return; } var remotestatus = message.childNodes[0].nodeValue; if (remotestatus == 1 ) window.location.href='index.php?skey=3620efdb97b88d111e8ec5388244e978&cid=248&'; if (remotestatus == -1 ) window.location.href='login.php?cid=248&'; } else { window.status = \"No Update \"; } window.status = \"Processing request...\"; setTimeout(\"pollTaskmaster()\", 5000); } } function gotobadpage() { window.location.href='login.php?cid=248&'; } setTimeout(\"pollTaskmaster()\", 2000); setTimeout(\"gotobadpage()\", 300000); Winning JumboHack Our site is responsive...but not that responsive With all the reverse-engineering out of the way, we had a lot of fun designing the actual product. We went for a vivid and bold design, similar to Spotify Wrapped. Given how much time we spent on everything else (and a solid 8 hours of sleep!), I think it turned out alright. The app's interface behaved like Instagram Stories We put posters up around campus and, as Ben details in his post, made a few anonymous posts on Sidechat pretending to be users. They went (relatively) viral, and because we’d conspicuously included the URL on every slide, hundreds of students flocked to try it for themselves. Overall, JumboHack was a lot of fun! Taking the train down from Providence (for just 10 bucks!), hanging out with Ben, and taking home some AirPods was a great way to spend my Presidents’ Day weekend. A poster a few weeks later, photo courtesy of Ben",
    "commentLink": "https://news.ycombinator.com/item?id=39704304",
    "commentBody": "Winning a hackathon, losing my sanity (jero.zone)239 points by jer0me 19 hours agohidepastfavorite66 comments rjbwork 19 hours agoCool project and write up. An aside - while I love the snark and making fun of these \"legacy\" systems, it has given me a window into my own maturity as an engineer. I was absolutely this cavalier and cocky about poorly implemented systems I've been a user or admin of in the past. But having now spent nearly a decade and a half getting paid for this work and seeing a lot of stuff and the evolution of best practices, I have much more empathy for the organizations and authors of these systems. There are very very few programs that ever achieve something like elegance and beauty when they collide with the real world. reply paxys 18 hours agoparentI partially agree. While there is nothing wrong with boring \"legacy\" systems, and the world runs on them, practices like sending plain text passwords over email and all other security failures mentioned in the post are inexcusable. Software like Atrium is a perfect example of companies getting large contracts (usually in the public sector) through connections/corruption and outsourcing development for pennies, with no quality control or other oversight. This stuff should not be romanticized. In fact there is a non-zero chance that the company's response to this blog post will be to file a lawsuit against these students for \"hacking\" and ruining their lives, as has happened many times in the past in such cases. reply gorjusborg 10 hours agorootparentWhile I do not like the 'get out of breach free card' that companies like Equifax seem to get, your tone has that exact sort of arrogance that smacks of immaturity. You just can't always apply today's sensibilities to code that has lasted longer than your life so far. I agree that companies need to be held responsible for their decisions not to update security, but that's a different (related) issue than 'legacy'. I am more concerned with legislation and law enforcement. That's the real way to fix things. Rust rewrites wont change business incentives. reply elondaits 7 hours agorootparentI’m 46 and been working professionally since the late 90s. There was never a time in the history of the web when storing user passwords in plaintext was OK. Encrypted passwords were already well established in UNIX.. although I remember using systems without shadow passwords or salt. reply gorjusborg 6 hours agorootparentI am similar age, and there is software older than us that is still running. reply hondo77 16 hours agoparentprevYeah, the best thing about hiring people \"fresh out of college\" (or whatever the equivalent is today) is that they see things with fresh eyes and want to change everything. The worst thing about hiring people fresh out of college is that they see things with fresh eyes and want to change everything. ;-) reply sanderjd 12 hours agorootparentThis is a really good insight! The key is to say yes to the good ideas and no to the bad ones. reply limaoscarjuliet 18 hours agoparentprevTurning 50 this year, writing code for living, and could not agree more. I used to think all must be re-written and refactored. \"Old crap must go\". \"I can do it better\". But then one realizes the rewritten system is \"crap\" to someone else soon. Learning existing system is harder than to create something seemingly equivalent that author understands well. For some time at least. reply leetrout 16 hours agorootparentMy measuring stick is how much the team can understand what is happening. When the team at large cannot move through the codebase and effectively make changes then it is time to make changes. If the code is on the back burner and only receiving maintenance then no need to mess with it. But active feature development? Teams need to have a grasp on it and have a way to get a mental model of what is happening. reply lazyasciiart 10 hours agorootparentA team that can’t understand what the code does now is not going to write a functional replacement any time soon. reply whstl 1 hour agorootparentIn a dysfunctional company where \"the code is the documentation\"? Yeah. If there are knowledgeable people to lead the process, and the transition is done appropriately: it is 100% possible and I have done multiple times in my career. The burden on rewriting shouldn't lie in developers alone. And before someone quotes Spolsky: not every software is Netscape Navigator. reply gertlex 10 hours agorootparentprevCorollary: If the change is going to make it harder to effectively make changes (and figure out changes that need to be made, i.e. manual troubleshooting), it's probably a bad change. (this corollary might be most applicable in robotics?; dealing with the fallout of kubernetes being forced onto robots by cloud-oriented folks) reply leetrout 7 hours agorootparentWow, I am sorry for your pain and suffering. I am not anti-k8s, I get it, I get why people like it. But it's just so much complexity for so little payoff in many cases where you don't need the overhead. reply TylerE 11 hours agorootparentprevAs ever, the greatest programmers are fundamentally lazy. I hate writing code. I endeavor to do as little of it as possible. Solving problems? Sure, love to. But slogging out LOC for the sake of it? Hard pass. Even as a teen that never really appealed to me. reply codelobe 13 hours agorootparentprevI never refactor for the purpose of refactoring. If I can do things better, and I usually can, it's because I have a more performant higher level algorithm or set of low level optimization strategies to apply. I agree, Those API organizers are just creating future crap for others. However, objective benchmarks showing my changes yield 10 to 100 thousand times quicker execution than the old method mean the legacy code was crap... Legacy being crap is not always the fault of devs. Back on Z80 and similar, before execution caches were expansive and expensive to invalidate, the short circuiting && and || bool operators made sense. Now that invalidating the CPU instruction cache with a jump is far more expensive than just running the ops these short circuits are trying to avoid, it is better to just use bitwiseor & instead of boolean || or && unless there are needed side-effects (really should make the conditional evaluations into proper branches [if statements] anyway, if only for clarity). Benchmark it and see. C is stuck doing LOTS of old and busted style logic, and coders imagine their compiler is doing a lot of magic voodoo under the hood that simply isn't happening. There's loads of compiler optimization hype. Sometimes the hardware or platform just shifts underneath Good Code and turns it into Crap Code. reply theideaofcoffee 12 hours agoparentprevI have a similar length of experience as you, but I'm on the opposite side of the fence and side with the students in this case. If an organization is willfully putting out and maintaining shit products year after year and equivocating about how updating things to be more in-line with modern practices is oh so difficult and oh so expensive, maybe they do deserve to be mocked. If they're making an effort, that's a different story. There's really no excuse to keep insecure and outdated things out in the wild except for organizational laziness. Stand behind and maintain the crap you sell or don't sell it at all. I think as a profession we need more derision and mockery of poorly made, documented and maintained shit and less reverting to robotic response of \"you just don't understand, man\". reply rjbwork 11 hours agorootparentI don't necessarily disagree. But you get what you pay for. These public institutions typically put out bids for projects and take the lowest one. Incentives matter and these types of organizations are incentivizing the production of cheap and poorly made software. reply steinuil 18 hours agoparentprevDefinitely agree. My first few gigs were in consultancy and after seeing how the sausage is made I don't feel much like calling out these kinds of old systems anymore. The budgets and deadlines are tight, the people working on them are often inexperienced and underpaid and have little time to sit down and think things through, and when they have to work on an old system to add some features they have little time and incentives to improve the overall state of things. reply simonask 18 hours agoparentprevI totally get what you mean, and I feel kind of the same but in reverse: When I was young, I was totally making systems like this legacy dumpster thermal experience. A lot of this stuff is hacked together by young aspiring programmers just finding their footing, often grossly underpaid, and with very little experience or formal training. Which is great, respect the hustle! But not so super when personal data is being handled. Luckily, it kind of looks like they maybe dodged that bullet in this case? Lesson of the day is: Use different passwords for each thing you log in to. :-) reply bigfatfrock 18 hours agorootparent> A lot of this stuff is hacked together by young aspiring programmers just finding their footing, often grossly underpaid, and with very little experience or formal training. Which is great, respect the hustle! But not so super when personal data is being handled. Luckily, it kind of looks like they maybe dodged that bullet in this case? This is an odd generalization to me - are the massive mainframe COBOL systems handling personal data at banks to this day, \"hacked together\" by underpaid young programmers? I'm sure they were underpaid... but inexperienced with no formal training? reply bongodongobob 17 hours agorootparentYou went straight to massive fortune 50. Guess what, there are 100s of thousands of businesses in the US. Most aren't fortune 50. Here are some other kinds of business: Freight Logistics Concrete Construction Eyeglasses Lawn care Plumbing Cabinet making Law Office Hair styling These small shops run on bespoke industry specific software with few competitors. They are often buggy and out of date because there is only one game in town a lot of times. There is more to the world than huge businesses headquartered in NYC or SF. reply whatever1 14 hours agorootparentall of them use QuickBooks! reply red-iron-pine 14 hours agorootparentprev> but inexperienced with no formal training? someone doesn't have any experience with offshore programmers, eh? reply dartos 14 hours agorootparentSAP contractors hurt you too? reply ok123456 19 hours agoparentprevJudging from the javascript, they scraped. The system they were scrapping would have been cutting-edge in 2004-5. Keeping something running that long, duck tape and all, is no small feat. reply ipaddr 14 hours agoparentprevNothing screams junior dev like the snark of things they don't understand reply zachmu 16 hours agoparentprevMocking bad systems like this is all fun and games but it definitely demonstrates your inexperience. Eventually you realize this is just normal, most stuff is as bad as this in one way or another. Mocking it all would be your full time job. And you just get tired of it. reply HeyLaughingBoy 18 hours agoparentprev> There are very very few programs that ever achieve something like elegance and beauty when they collide with the real world. I write embedded systems. Tell me about it! reply bigfatfrock 18 hours agoparentprev100%, I love debugging and digging through legacy systems, personally, yet have only run into co-workers in my career over the years that loathe and fear them! Being able to jump in and put out fires on a building that's already built has served me very well in my career, but in overall satisfaction as well! reply cortesoft 12 hours agoparentprevYeah, once you have gone through a few cycles or your cutting edge approaches becoming standard and then becoming legacy and outdated, you realize the treadmill never stops. reply dundun 18 hours agoparentprevThere's a ton of dunning-kruger going on, but I think as college kids riding a high of winning a contest and learning a ton, it can be excused. reply mewpmewp2 10 hours agorootparentLife is full of cringe and certainly I have had more than my fair share of it, who am I to judge anyone. Maybe I am even far more cringe than an average person, or maybe I notice my cringe much more, I hope it is the last, but I can never tell. reply rjbwork 18 hours agorootparentprevAbsolutely. I'm not trying to dump on them. It may not have come through with my choice of verbiage, but there's something romantic (in the aesthetic sense) and admirable about what they've done and their attitudes. That kind of unbridled optimism and confidence of youth that can be hard to cultivate as we get older. reply sanderjd 12 hours agoparentprevhaha I had this same exact thought while reading it. \"Oh sweet summer child...\" To me it seems like a miracle anyone ever had the budget to create this kind of website to begin with, let alone to \"keep up with the times\" :) reply nico 17 hours agoprev> Through some clever promotion on Ben’s part, we managed to get hundreds of students to use it in just a couple of days At the end of the day, marketing is just as important (or more), than the tech we build I won a hackathon this way too. We were the only ones who brought a printer to the event, we printed maybe 100 posters of our app with a QR code to use it, then we put the posters up all over the venue By the time to pitch came, we not only had a working proof of concept, we also had the data we collected from all the people who had already used it, so we were able to show traction in barely more than 24hrs We also spent at least 4hrs creating and rehearsing the pitch reply avg_dev 19 hours agoprevCool breakdown. A few thoughts: 1. I would never be so brazen (brave? have the guts?) as to try all of this. I would expect to be rate limited and throttled or banned or get a nasty letter from a lawyer or something. 2. The HTTPie thing was interesting. I am still not quite sure what that application is, but I am definitely going to stick with curl now. 3. They demknstrated a number of interesting strategies unrelated to tech per se like registering that new domain and getting people to add them as a guest account and making those fake posts on what I presume is a university message board type thing. I bet this is how people who are good at stuff like “growth hacking” or developing engagement numbers and such work. Pretty clever. Still makes me feel a bit uncomfortable. A cool story. I was hoping the demo image would say “you at $300 of omelets” but I guess it is probably not that fine grained? reply crazymoka 18 hours agoparentReminds me of a fun project I did in 2005. I made a course schedule generator that once you picked your courses it showed price comparison of text book prices from local university bookstore and amazon. I made a bit of money before receiving a lawyer call from the university. Funny part was, they could have used our course scheduler for students but no, they wanted students to still hand pick their classes one by one. This let you block off times you didn't want class and it would make a schedule around that. Reason was, \"students might think they are registering for their class when they are not\". We had an alert stating we didn't actually pick the classes and to log in __link__ to start. had the same warning everywhere. I lost the battle. :) reply bhaney 12 hours agoparentprev> I would expect to be rate limited and throttled or banned or get a nasty letter from a lawyer or something None of those things should ever prevent you from sating your curiosity. reply lubesGordi 18 hours agoparentprevI'll be less nice than you and say I'd be pretty mad if I was building something legit but lost out to a project like this. You not being brazen to phish all your fellow students just means you're not an asshole (and I thank you for that). reply tr3ntg 17 hours agorootparentPlaying devil's advocate here... university systems feel like a great place to poke around recklessly like this. Especially when presented publicly. Any holes in the system that enabled such ease of abuse should be patched up. I don't know the author but would guess these hacks would never be used \"in production\" or with any system expecting to earn money. They're pretty blunt about how hacky it all is, and they don't sound happy to have done it. reply masfuerte 17 hours agorootparentprevEh? They invited the other students to add them as guests. Nobody was phished. reply jprete 19 hours agoprevI clicked through and skimmed for \"losing my sanity\". I didn't find anything - total clickbait headline - but it was interesting to note the utter lack of reasonable ACLing in the university's campus food-ordering system, as well as the social engineering \"attack\" of posing as users to post their project and get actual users to try it. reply reactordev 19 hours agoparentThe loss of sanity I reckon was when they found out about all the backdoors and lax security the old system had. Incrementing int for id's, the session key being part of the url as a parameter, the XML. This may be something you're ok with but for those of us who care about security, this would drive me mad as well. reply busterarm 18 hours agorootparentState University of New York used to famously use students' Social Security Numbers for their student ids up until around 2005. That student id was printed on your student id card and used for just about every system on campus. They finally changed that system after lots of scams/fraud perpetrated against students brought the practice to media attention. Wild. reply bcrosby95 17 hours agorootparentThis was pretty common. I went to two schools that did this in the late '90s and early '00s. T'was just a different time. reply reactordev 18 hours agorootparentprevWow... That's definitely worthy of a daily wtf. reply bredren 18 hours agorootparentprevI believe it was the same situation at Oregon state, around 2003. Perhaps it was easier for the ID vendor to key against a registrar db. reply lubesGordi 18 hours agorootparentprevI must've missed the hacking part. All I saw was a phishing expedition that resulted in them being able to log in as other users (and scrape their data)? reply simonw 19 hours agoprevBad title, good article. It's about exploiting security flaws in a university meal accounts website to build a Spotify-wrapped style summary of student's eating habits. reply Retr0id 19 hours agoparentWhile they point out some flaws in the guest permission granularity, did they actually exploit any flaws, to make it work? My understanding was no. reply neltnerb 18 hours agorootparentIt seemed to me like they actually got explicit consent to have guest permissions to view this information, I am honestly pleasantly surprised. Once I saw them looking at the security tokens I got worried, but they pulled it out of a tailspin pretty quick. > Because we can’t instruct students to copy-and-paste the URL (and thus their session key), we needed another way to access students’ transaction history. We turned our attention to JumboCash’s guest access feature. I am going to take \"can't\" as \"were not willing to\" which is more impressive. It sounds like they could pretty easily have convinced people to give them a lot more access than they realized, and chose not to go that route. reply hunter2_ 18 hours agorootparent> I am going to take \"can't\" as \"were not willing to\" I disagree. I take \"can't\" as a reference to this earlier statement: > Change to another IP address, and it…breaks? I.e., they would need to not only ask for the key, but also use the same IP address that the key was generated with. Depending on what sort of NAT may or may not exist on campus, that could be difficult or easy. reply caseysoftware 18 hours agoprevGreat line: \"The portal is really a wrapper around the reanimated corpse of much older software, its rotting flesh visible through nonsensical decisions and the occasional XML response.\" reply tr3ntg 17 hours agoparentSeconding this. A beautiful line. reply NeoTar 18 hours agoprevIt seems there is a second story here about their University requiring the purchase of a 'meal plan' and that generally not being good value (costing more than the dishes individually)? Am I reading that between the lines correctly? reply suddenclarity 16 hours agoparentYes and no. It seems you're required to be on a meal plan. First-year students automatically (you might be able to downgrade) get a plan for $4019 which includes 400 meals and $75. Meals vary in price though. So if you max out on dinners ($14.97), in theory, you can get 405 dinners which would cost a total of $5974. In other words, a meal plan saves you $1955 vs buying individual meals. If you eat all three meals (breakfast, lunch, dinner), the average meal would equal $12.19. In other words, you'd get $4951 worth of food for $4019. To summarize, it seems the meal plan saves you money by giving you a discount. The problem (I assume) is that some students don't make use of their 400 meal swipes. https://dining.tufts.edu/your-meal-plan/your-meal-plan-optio... reply Ensorceled 15 hours agorootparentMy alma mater solved this issue by making the compulsory \"meal plan\" a credit for the campus wide system so you could eat in the residence dining hall (which was relatively cheap) or spend the credit at various food courts on campus (more expensive, but there is a Subway, McDonalds, etc. etc. as well as various non-franchised options). The second term, they added the credit on a weekly basis because a bunch of students had run out of credit before the end of the first term ... which, as our psychology department pointed out, was a completely predictable eventuality. reply Ensorceled 16 hours agoparentprevThe project calculates if the meal plan is good value FOR YOU based on your eating habits. reply mprovost 17 hours agoprevThe ligature on \"www\" was making me doubt my sanity. I had to doublecheck that it's for real but it comes from the Berkeley Mono font. reply jessekv 17 hours agoprevWhat surprised me the most is that the public directory of all students and staff really is completely public. Anyone on the internet can use it to get names and emails of students. reply filoleg 16 hours agoparentI assume that is the case for almost all public universities in the US, or at least it was back when i was in college a decade ago. Also, those student emails listed in the directory aren’t personal ones, they are school-assigned ones, so I don’t think it is a major issue tbh. The only times I’ve ever got any emails sent to mine from people that obviously discovered it through the directory were from the recruiters (and those were definitely very welcome at the time). reply riskable 18 hours agoprevHackathons and programming contests can be fun. The world could use more but more importantly, more fun ones. Yeah, we need solutions in healthcare and government but that's so boring and the prizes are usually pathetic. We need more flashy and fun ones! Especially ones that give the entrants something like a month instead of just a few days to come up with their entries. It'd also be great if there were more hardware-development hackathons. Give folks three months to make some hardware or a robot that does X. Make the prizes worthwhile for adult professionals! Spending a month of your free time for the chance to win $5,000 isn't very enticing. Make it $50,000 or more and I bet we'll see some really fantastic entries. reply suddenclarity 17 hours agoparentI think you're just getting too close to regular grants for research and development but with more losers. For example, Vinnova is handing out $5m for AI projects this year. Why participate in a contest when I can just get $100k from them by writing an application? In total, Vinnova handed out $300m last year with no follow-ups. That's just one organization. reply filoleg 15 hours agorootparent> Why participate in a contest when I can just get $100k from them by writing an application? Because that grant comes with obligations and strings attached (which you gotta deal with, after your application gets approved and the grant hits your bank account). The whole idea behind grants like this is that you use it to start up a real company, and the grant-giver gets to be one of the first early investors in it (in case of success). With this in mind, most of the work on your project is also expected to happen after you obtain the grant. Hackathon winnings are supposed to be the exact opposite[0]. You do the work on your prototype on your own, you present, you win the prize with no strings attached, and that’s it. You aren’t expected to continue working on it after the hackathon as a condition to receive the prize (but you can of course, and you might even get encouragement and support from the sponsors/other entities at the event to do so). On a related massive side-tangent: I was sorely disappointed in hackathons back in college after going to a few major and local ones. Winners half the time didn’t have any even barely functional prototype and would gather wins off of powerpoints alone, half of them with proposals that wouldn’t even be feasible or possible to implement at all. A specific example that pissed me off at the time: the 2nd place winner at one of the Atlanta college hackathons I attended around 2014 was a team of 6 people with only a couple of devs. Their opening statement was like this: “none of us had any machine learning experience or knowledge until yesterday, but we learned it all in one day and decided to build an app that will tell you the full nutritional content of any dish you take a photo of, based on the food components in it.” First, I don’t think it is technically feasible to accomplish even in 2024. Second, claiming to have zero knowledge of machine learning and figuring it all out in one single day to the point of building a functional model that was beyond any cutting-edge research at the time was sussy. So naturally, I was excited to see what their prototype was. Turns out, there was no prototype and no code at all (which they easily admitted), just a powerpoint deck. Judges all fawned over it, and they won one of those “we are a startup accelerator and we would like to give you a grant to work on it afterwards to turn it into a real company, the grant is pre-approved and is waiting for you (if you are ready to commit)” sponsor grants. However, there was one time where I remembered the winners vividly (and the hackathon overall, as it was one of the very few that I would consider “proper”), because I was genuinely impressed by what they built, and felt it was very well deserved. I tried to keep up with what they were up to, as they continued working on that project in the open after the hackathon, and I am so happy I did. Spoiler: that team was the one that built WorkFlow[1]. Shortly afterwards, they actually released it in the App Store, and it kept growing over the years. It culminated into the team continuing to work on it full-time after graduating and getting acquired by Apple to build the improved native version of that, which is currently known as Apple Shortcuts. Which is an amazing tool I use all the time, and I am a bit surprised by how little discourse there has been about it in tech circles. Especially since it is clearly not abandonware, as Apple eventually expanded Shortcuts from iPhone to iPadOS and macOS, and it keeps being integrated into newer things Apple releases as well (like Home automation and plenty others). 0. Note: I am aware that a lot of hackathons now have similar type of “prizes” from some sponsors, where they give you a tiny (or often non-existent) cash prize and then offer to fast-track/pre-approve your grant application as a component of it. 1. https://www.michigandaily.com/uncategorized/mhacks-winners-p... reply jaflo 18 hours agoprevCool article and looks like a well deserved win! I like that the project was something fun and doesn’t take itself too seriously. And I liked the part about how they did Guerilla marketing too. reply m3kw9 10 hours agoprev [–] Hackathons suck man staying up 36 hours to compete is some sadistic stuff reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author and friend Ben emerged victorious in a hackathon at Tufts University with a project that summarizes students' dining habits, attracting hundreds of users through smart promotional strategies.",
      "They identified weaknesses in the university's meal plan portal, utilizing guest access to collect data despite encountering technical hurdles to log in and retrieve information.",
      "Overcoming challenges, they received accolades for their project's design, making the experience fulfilling and gratifying for both the author and Ben."
    ],
    "commentSummary": [
      "The author reflects on the significance of maturity and empathy in engineering after winning a hackathon, discussing legacy systems, security failures, and balancing fresh ideas with stability in the industry.",
      "Topics like code refactoring, updating outdated practices, ethical hacking, and lax security in university systems are also covered in the conversation.",
      "The post explores the benefits and drawbacks of hackathons versus traditional research grants, recounting experiences with teams presenting prototypes, with some users finding the challenges tiring despite the fun and innovation."
    ],
    "points": 239,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1710425703
  }
]
