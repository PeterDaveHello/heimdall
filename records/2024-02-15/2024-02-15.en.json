[
  {
    "id": 39369653,
    "title": "European Court bans weakening of secure encryption, protects privacy and security",
    "originLink": "https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .big-button,body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .big-button,body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .big-button,body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"www.eureporter.co\",cType: 'managed',cNounce: '19747',cRay: '855cb7d4180b2273',cHash: '754bf64adc53e0b',cUPMDTk: \"\\/world\\/human-rights-category\\/european-court-of-human-rights-echr\\/2024\\/02\\/14\\/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans\\/?__cf_chl_tk=RB29DzqF0dw8voxC_kfylh_ziPR8Cu6vd1wLDTNp3CM-1707991376-0.0-4071\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '375000',cTplV: 5,cTplB: 'cf',cK: \"visitor-time\",fa: \"\\/world\\/human-rights-category\\/european-court-of-human-rights-echr\\/2024\\/02\\/14\\/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans\\/?__cf_chl_f_tk=RB29DzqF0dw8voxC_kfylh_ziPR8Cu6vd1wLDTNp3CM-1707991376-0.0-4071\",md: \"TY4D3_WGyS4v2ebbDoT6vqE4tLYWsltdnYdO._uCcdc-1707991376-1.1-AftLlzJcsrl654jDjddlOHb1GY75lTnP7qVOMh6yqQRbBh7Ewt-PxH0gD0jBxq6m9My3vIMAGXMPYHJ0Empoju148C2t8FgyI1vBIvpo2L8ggOTQmxFoH_ZtYwlmfz66CT7H3sEhFa-FZ2f1U59P7jMkuvQ0ZcSTVbrAbZl-3JZmB7_aneinnl8n1_N1Sv3BD_U_td3YoA_M2NVmKJcxUjzpmmbn3JTWPPwMNu57O35hk1Vl1FrDkxvVzjJ991qGCN01ddn3SZCtZCeFhHUK4z83TWbMkGM1YL58Q65zbFNF6J35py2Uisnza-mINzOHGgawWGk-HbXluQGchKeEKMFdVe2JxwqeouS3BnzN1mSAdjHHvoqP5BUD36LtP8sAApyF6v0jozHhaF6G32qA09Bijg8VW9hJXAsylYx3AC-gSgOtyDc3UBpLDG7jZEjfUdoMHZNy0j1pzaQZsfPNIwGooMzf3aMrk3sNtqqGd_v-JHVviKXAFaF0vhSexzlaNgSF_enZRv8vYp1VYXldm3PuG1UKKNH0i3pJbqgGR2Kqe7nHYdQYzETSdA2QJy-1VQzIhi8c-XUwy6xtQuhIRzDVX0MwO5GNzaiBgXv1f6D3PsvRkO6OZPiJzksLSL-Bv_FqSNVhFld71BY4ZrieenzIjuGo_mwa1QST6sjqYYdpMPy5rs9Oo9ip0TPGz0-2GPektf2ZkFas-xqzMqbT5d8N0B9atlsdqr3qvLselRa-bu_8zE7FrkoTBvLAc2tgMz7SVkzSJ7z-3iuhmtUqsqUxn9KJaaZ1xnesvfbkL9MIEB4UY8nq8-Z95aX4sZ9G7fMFpBnNmpWZMl5Dp56nEE5nIQzfD5fjMLTPLZnKerdv4ynzalDtVGWfpdM29CdOiBW1YKYWtPThYWHRlDRKAIdSisp4lQt7H710ZUIfWJCFGhhM3wRKg5KGrbyuG6k1Ckck0vLJVjhV_H7mOO-uds1wXy4lzTYg5XlBtdjwqX5jekYMZ7iTmIXdB5Y8UUdsUlxLgGC7UOBJGjZG98nL94nhA1LGHmsMFD5eN_qUKgxmNa6QT6VtnYNGseZYGzNdjw_x4UdxfIDM13znky9hbQE-vFQsi-S8oMFu_GyoqB5Nz00js0OGE5sJ4vEmUOqRZ_K2WSDayVzIVblPW-_F-pzNa_No8nUTBBMJz96LQuYvyWTrEFGdb-cEywV4QwRVt3vQiuy9zomSZyMJfaxOO76HkBudnT_VDxUnCGnLndd5qP8fyXhbxHpEcViVCpm0W21_o25UHGCFJeLSc9U67OYj6yHQUuQ8eRPwtB6bnOzXNtQf2asMrKGkkfEBHHBgruOmiOgwkL-nf54AKPbBWHOxikrMQtykkMmODFKyzn_i_BwgS2OuEyTNEFyDY622JaikVNjn8BfiQfXzNg65wngB8mX2YzciCFv7xI-hiWV8eNY038P6o2TdVCdUfpDRjnkWIMnw_pMwuhRyR0eC98Nc1n4b-u3-aydB89OLpuHApkev8x6XDq4rWXbNy9Yrbi2X3NJE9lVSgvZutrFM0YPWTuWcI4rH6oA5IivjXdd3noc0gBVpyvBUE-cL6qV8ArqtnMDqwXpnU-RrFtYxmIs21anXWwWXkTERxWb7DlITQHyz0IZGpRiKt0Nl2Q4U19tH2nbrfJSZtfCH6iliHwOpstTsk7RjvqPfJcw9BetRFpWCLViB_PtzNxoI8iADAHUY22R8xvr76eSMrG2xXDqyLq5SgLpUUwDzC5Cng93Qza0AIJkTtlCFLBy7feez4MJAvFzx2_fjjQXHcZA5qFOUXCtME8Sqhgl0SX3w4DZ621HHX97-Q16_wU51wQHHSaAaYZl8JNWBJFLQ8RiDe4cSYRP1RdxKTZcI7x5SlLrdtQUUQiyaNQPWjPJm589slQ6CUOZ00V-GNfbXLv9H2S6PKvVxW6R7Mwch65s79CcNTG8_hCoWaCqjCZ4iU-Bvnqt16e68Di6fLc-etRPIbySCx1yp7q0j4hZxfxrxXMEVmt8BRHREb9DqStM9SEDFzxescdLWdnRPXYbRdW2NtwakybWATYXInyxJlzd5gReEIhUtFVvgWXOsNARz-xrhFk6vyTstvjYP3EHQRL4Va9NNJlQQb_9zzyjv8ueoMcAX0hU2lZdT_wQWW--I7p79zcP5PnSZMPffAVnrQths2QIDI2z-Pnbk9eI1vzYdkXXuaTLHQWK0eRAnC3dCDEAX6e3vqbeuw2L0ZcYvEAJiC31I9qZ2fCcmca6ZikT7zDdIMbN67vnPBAeu7qOEx68U8VUHcYkTlrIakajXrV3d9Zh_rdWFndnYYTRYgEfG1Mauuf1W5yppfEGhlFxnMqw5aK8iUJnyj5iD-BSK8VlIyyBHc_SC1a7TC5Eq3LvjLVOcltCAT41kVul2UWmxJBR8Sc6ln0RFVKJt3PSvyzreSJo2jRJtFKgqcHHhfQuf6cY4EllwsTgFR7lDJMcDB3EN87cLyEv16Mk_ZPP8xG3T5hzYb8NO2394xMN3D-qynRLa0eS4t9AVKnCm2gDOitaaLA1HXHQF2B6lyvetALxG1r0K7eyT242CMcu6PZ0PEY1Fk8ASVR6O2uMkceUScFTnakG74Hp_Zfr6Y_1Bn2z5TplJZeOgiUo-wYFkq4zUtE5W9KX3xU-r1laIqIaSeKnW-iZCCw0AwUhPNp7ngYg83KpYPFHWAYqL-MQ1uDqvAOyCWvwCAW9CQN2JYg4FHj-UUCCXghPs6CdmaDYHrRjUzQxtDhJEnNPRMAN0xXQ_nSjPJPT7EkiosXhAPUfihNIoAbU_Brh-IWYe0CPQdLwBSO1J2OOEzEdDRIGdJrJcOB51-2r7VHYVDetN7TsIPs2GjR5Oo5FdHQESnrcs0z9ui9xtWva0J0F_NXcCMJHK5VF3L7Z2dLRs0QYBVrpWiJ-5nRnXVwWEbyQFwShjjCSENoGoRDjcK4wuvFQqOoXzJPvqobgV867ecO9mz_r_bvY-zJTv8J3I6TurXIzRDznTQUw_HVuAbZ3hS8EVAAGX0463KzOd2YL3LJYATMqQ1fhw0wTngemhUV0u0T5z7_qdyGK4X-BRfCCbjtSXqlSqey1u7PT5S-lVLbaMyIugjocOfaF77Hmkmg1HSVD4ouu5sGoObfKEDYscJZKYxjEghlhvgi8zUpzXy3z-aNYKKEzedJG_M8hCUMnpYSt3V4sQZrj0dmwJ72m4VgvWvXHORb75UbNJJ9GIqkDY3uHKxRyb-Ua7Waamp460sj6rr_PSgYTZxUlQD7V05k7uKc5FcdEvWz9W3LJ-olsVHvS-946v7Jhdka52itaUS7IhqRc1CiOWO1XKoez6ufBtMRXph4epjTx78jZtHH2kXTv-0VPCaL599VzmmyO1O96VNaRTo6PggCCBlEcN-yayWBL-ILLrZLAANRUuCSg9t-yHWC3HHc6I6lle0kfIbnt-rmgenz4uEytuvw52ZzlnOiSBKAOrag2nmaM0_Za9KygLK7My-nSXQhSR5wMyLdFwTOv4SCFJAwJQ0nLYydBw-Tj6KbGKn08Zu0nz_gu7FuAGjEm0WVqq6_ZIBF1PpZR_P5rhf25yh05K-Mr_xh2CJ_0V4v2NIR18z8H3-wldon0UkkoIr1vEAY56d_2WXWkZ1WoVng2x12MTnCjbjQxhD-lnWxCDLECVKsNsGL13Wse-mAl1vUJTJwyEmDy40eXtQ2foRjr_KQdMjwouKnvT_sO73wLgdE_gpunNrf7itB2EAIgJaNaEX8nYo9zlINzkwTfY0lSm7gG7D5xFATfKoqXmVCcdB-vjTY9Dhe_XpMeO0z7K-TEIghWfj-qjhbxlS676JFI-UIa1we5PrGQS51hhZ75A9Z9gHiB-FheGK_kHlXt8O4IOmqlr3KCgG5kgAlw-1sPXkTB6PTYGNEJKhvI13n5cWrI8GCGrUrnpgbIuGYPnNsVsOSbttyqqrjVYApoaKtgYlnpDoDs9ScXw0BGNYm5P\",mdrd: \"9kGA_EhdA0WHgL9urhm3Q3ucP.CAAstODw7r3KEyqys-1707991376-1.1-AcXYo4NcMnt-XbevIbC4J2WMslWM3FjG0TvH3B_UrNUUTsv_mhOv05U-juzLn7keD5h9Sl1b0i-S5J1OBPQG-Yq5iXKopmKJ5JpXaBVg1dF9Qo_kq0HJeoI5zSqhjVeYX3jMacDKe0dzMNIXVHrX1IvU6hbWnuOh2hhTUUoD-pBreevQhwq602BOSrmuvGVS9K0bawzqEc1QVMfXg7bAvyqk_QraROVWOVRNS5WLvTr2b1LsftBVkBum89J1wojVEC9yBebqB3P8wKAeUgG-5oszbsvbW81A_l9EpklHQZnEGV9X1TCT4KgP3fGhoOl7qkhDOfuCUZgUvIHJLXfKxWR4LlTY2bkY2p5HblTJmdF9yghUA-LMBdqIrUxpFrPtNWVHmmKrgG3RlFfdyK795wZs-h8qujMxLrlPgQJhXrf5G9Q9ltgnHbio8KyTUpTnxkNz7RDjkfL4o_lW1gUZ3nbOb9Y6y2EGUDUhZtBmar2gjiaafLxiBJX4godK1E0aTHp3-9EKE4VExWyiUbVQaAPLiAQZ7718qh2Ob5HuB3jEfjwHWiZnfOJSJcybZFf3lnI5PE9VKte-irO4almsS9WEOPSyctPWq3NNQ2IlcSmSw4GBV0NX99Cqp2vzYmduc-fJBDvsVfledhVF8qo75KFEcBoxNthcbTfzrZQln3kWnTzjLuQ2c5KLgK3H2idPFzBraPyjHA7nhc1zk8r0rEYC0O3KmAt58IV08qchW6XktxdAylInlzhtnoSHQQ306euqIATSR_1WZgvizDLbNVnEEmOtJQ5vd3MH3bWidm1t8ovmlCRXX7QmVM5ynAKfkBj_dmOi0SD2uObSRLbURqpl7JyDOw0SK3RtW6q4cjt1Zawm3AAsPR1oxC_-QAH_LoTNx5MdRNGunONwxUFYdZF1d9uOTd85i5-gYJ9mnEp24mlQBM0eCeEGJLzUeJSl8X4ToCS1bD0x9ti9l5bmkUtj7Y5rhqlaSWjp0Z0uZt2YZi9alb5TrtmvqBsmNZiDSHU-zkQBM2V1mAaatOD-WU_umSlwWATe6sxg319AtslOwzLGH2sQswmkDwLBUaCtUV2tqZrcUYlHtNf7CJTto51-mDyd1RDIUraxgHJtQ1-mrTZGtaZjSu5sLgZ2NuTCOMK7nSZotnr1Fhc010D4ftPYVVySyQYnzhmWk9q7wXlfiAWh-KNQjdzPgxynVjp4omTcwfUlc-ZxSV_vNXx61BQxlo6RTbBg3vJLF3aD1fF3z4t8vAGNudeuMGzcu8VTpauq8xdjQe23GxqTxM8kKTY3SYALp8TxsdjX1ahWnO06CNwx3BKeRUZ-PWH8PCTQj4NkXsvoQNTtGd6utAF2Va6kuzS4GfAXozJg2cxHcRYsuNWmQ1OM4xhZECxEZ-k1-1TNigU_GD0oE8hNtnOsYbPTopaucd5JVgFLfDe3-ttcZ5UEnjTqS-3ydu9pzbL9H8EzoKiKv64llk4OHzqZVN9XQsfcWPj3kwWuV0zu4lHGfzfStqkktw35kapBiCFy9NYneb-oKu6ogPJQnx_3CtjkB5yQqe6N5sFQlsOVBmRV8Gw2cnQi0XfZ8MP-dy7EfIkY2wmqIObHvjb3BRHcrpL4i00_rvIPxbgo1QfpIM8eiGqyX85PeIPTIOGNkT4QLjPLHQewO_yUJR5HgzFx_zEcyHUDYyClvsAoDjvnlV_JGSiCC_IL2mhANwcfkYvgTOp3U9z0JMnkum5VqwPzm8lKi-IRHzsKF_mLQXtCRXymkqzpYMd80FmYE3i-IWuY15mZ0Y3mBom28yM09mcX5ZBoCoL-obL6ldzSp128-8XAyv52BSrTv4KRpCTpK86of6JEiOaz3oeXG-5DtHOHKXUu7Clu7c7CrPHpqm4fbyjNbmnVTQSEaeV6fk2t8QdKCHtvjgEn1aD1pFg3Jxk5N8gj7OPCV6pdhm3zm43n2JKcTbDg5sSoCH5bcNH_cGSHxYVRqwKPu6XpXvitgQRocoT6WExhPErrkPTTMsQouL3F\",cRq: {ru: 'aHR0cHM6Ly93d3cuZXVyZXBvcnRlci5jby93b3JsZC9odW1hbi1yaWdodHMtY2F0ZWdvcnkvZXVyb3BlYW4tY291cnQtb2YtaHVtYW4tcmlnaHRzLWVjaHIvMjAyNC8wMi8xNC9ldXJvcGVhbi1jb3VydC1vZi1odW1hbi1yaWdodHMtYmFucy13ZWFrZW5pbmctb2Ytc2VjdXJlLWVuZC10by1lbmRlbmNyeXB0aW9uLXRoZS1lbmQtb2YtZXVzLWNoYXQtY29udHJvbC1jc2FyLW1hc3Mtc3VydmVpbGxhbmNlLXBsYW5zLw==',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: 'zmXwf+e7VM+K++uvRZ8yu9T/JMnR3SG2yXEoGwhvhQNYUTB6vNoBvD13R6yeH/85fYuVgm2qU0wuj29zt+Q2iRUMCE5U8lUAJisXV60kPplR2jeV9P2Q4n+uILpYu4mZzsyOj2nCjM/2sln49KAWpPEcg5ObWBZC7KiOFFmmwuJD+QjKy0uyrJOlapk2rz4tsz1TuzKy62W6yMkWceWHpoMk4B5sAxXGFEZBB/TZLIOladdgOXb2x1u/yf7Qm0z+K9PQ4qIXb6xjppGXLusqFnCENef4UO6Ze4gjrDJZ6AUg4vWr4ZXGdSWVTEzXgGDuu2G8pNxA+G7d+BIjm/vjxlNsQF1VpIB2cigxWe9EMR0onjj3hTVkMdEQ0Pit6Y0diLu6NIiWkINEgMO0Ikgsx57gnyeKDYsaJ5bIni2cF/2SL2g9+YK/++zveL5/A5RGMf9vTspWZuYjugAn0CtpPs9sDQ4MeVdUKFb86CG8Bll3hkrjTPEU4HnSIMdHUZ2HGVXsgQJrureLwA1f04SaAkVBoTjoLkZirmYOwaNI+Y0=',t: 'MTcwNzk5MTM3Ni4wMTkwMDA=',cT: Math.floor(Date.now() / 1000),m: 'EqaYuOy8pNArfbHAIldWlvs3BZrJoMOtgv0i4uYqJxI=',i1: '/yxwKbfDRXpEfkuvvNjNLw==',i2: 'Ds8xV29Re0VHARmRXU+0/w==',zh: 'sVHbXlG/OrX0KGQ2ZdYr/mw139TVAEwNNDFLqaiCGZ8=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'y6ETf5mJ2Yc+gAC9YIHC5Vb/5OU3R9lkuOKwz3UpWgk=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=855cb7d4180b2273';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/world\\/human-rights-category\\/european-court-of-human-rights-echr\\/2024\\/02\\/14\\/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans\\/?__cf_chl_rt_tk=RB29DzqF0dw8voxC_kfylh_ziPR8Cu6vd1wLDTNp3CM-1707991376-0.0-4071\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=39369653",
    "commentBody": "European Court of Human Rights bans weakening of secure end-to-end encryption (eureporter.co)1519 points by robtherobber 20 hours agohidepastfavorite229 comments Quanttek 19 hours agoFor a better understanding: The Court held (in the circumstances of this case) that a legal obligation to decrypt E2E communications is a disproportionate interference with the right to privacy. The law in question specifically obligated messengers such as Telegram to hand over communications alongside the \"information necessary to decrypt electronic messages if they were encrypted\". To come to that conclusion, it referred to the wide-scale impact such a weakening of E2E through backdoors would have and referred to \"calls for alternative 'solutions to decryption without weakening the protective mechanisms, both in legislation and through continuous technical evolution.'\" Looking at the cited material, these include traditional policing, undercover operations, metadata analysis, international police cooperation, live forensics on seized devices, guessing or obtaining private keys held by parties to the communication, using vulnerabilities in the target’s software or sending an implant to targeted devices. While a ruling on a specific case (and law), the Court seems quite skeptical towards any \"requirement that providers of such services weaken the encryption mechanism for all users\". If I were the UK government, I would be quite worried that the UK Online Safety Bill will be overturned by domestic courts (or the European Court) on the basis of this ruling. (It should be noted that, although the backdooring of E2E was considered to go beyond how the right to privacy may legitimately be restricted, the right to privacy is a so-called derogable right, i.e. a government can, upon declaration of a state of emergency, derogate from the right insofar that is necessary to address an emergency \"threatening the life of the nation\" (Art 15 ECHR)) Relevant paragraphs are paras 76-80 here: https://hudoc.echr.coe.int/eng/#{%22itemid%22:[%22001-230854...} reply M2Ys4U 18 hours agoparent>While a ruling on a specific case (and law), the Court seems quite skeptical towards any \"requirement that providers of such services weaken the encryption mechanism for all users\". If I were the UK government, I would be quite worried that the UK Online Safety Bill will be overturned by domestic courts (or the European Court) on the basis of this ruling. It's worth noting that UK courts can't overturn Acts of Parliament. The best they can do is issue a declaration of incompatibility, which enables ministers to use secondary legislation to correct any defect rather than having to go through the process of passing another act (if they have the political will to do so...). Having said that, a lot of how the Online Safety Act tries to get things done is through secondary legislation and statutory codes and guidelines; these all can be quashed by the courts (unless the Act constrains the way the other instruments are made in such a way that it'd be illegal not to make an infringing instrument) so it'll be interesting to see how that plays out. reply JNRowe 16 hours agorootparentI wholeheartedly recommend How Parliament Works¹ for people who want a deep dive on these points. It is nowhere near as dry as you'd imagine for a five hundred page book about parliament. While used copies are super cheap I'd also recommend picking up a current revision. Recent years have seen far more use(or attempts to use) some of the more obscure tools of both houses. The updates include more explanation of those topics, along with descriptions of recent cases before the courts. ¹ https://www.amazon.co.uk/dp/1032015012 reply chippiewill 17 hours agorootparentprevThe best isn't necessarily a declaration of incompatibility, that's mostly specific to ECHR. In general if parliament passes legislation that contradicts earlier legislation that wasn't repealed and it wasn't deliberate then a judge can determine that parliament didn't intend to override that earlier legislation and that the new legislation doesn't apply in a given context. Parliamentary supremacy exists, but only where parliament takes a deliberate action. reply skissane 5 hours agorootparent> Parliamentary supremacy exists, but only where parliament takes a deliberate action. Well, it exists under English law, it is an open question whether it exists to the same extent under Scottish law. As Lord Cooper said in the 1953 case of MacCormick v Lord Advocate, \"the principle of the unlimited sovereignty of Parliament is a distinctively English principle which has no counterpart in Scottish Constitutional Law\". Lord Cooper suggested that, at least in theory, an Act of the UK Parliament could be ultra vires under Scottish law if it were contrary to the Treaty of Union. In the 1975 case of Gibson v Lord Advocate, Lord Keith suggested that possible examples of such invalid Acts might be a hypothetical Act to abolish Scottish law and replace it with English law, or a hypothetical Act to establish the Church of England (or the Scottish Episcopal Church) as the state church in Scotland, usurping the traditional role of the Church of Scotland; although he refrained from definitively ruling on those questions (since the outcome of the case at hand did not depend on them). reply turquoisevar 14 hours agorootparentprevPrefacing this with the fact that I never had a good feel for UK law due, in part due to it being a common law system vs. the common law system I’m more familiar with on mainland Europe. Plus, I’ve not kept up with what, if anything, the UK maintained concerning supranational jurisdiction after Brexit. That said, what you describe is similar to that of some EU countries. Take the Netherlands for example. In the Netherlands, courts can’t test laws passed by the Dutch parliament to the Dutch constitution. Even the Dutch Supreme Court doesn’t have that power (and Dutch legal scholars will therefore deny that the Dutch Supreme Court is a so-called “constitutional court” like the Germans have, for example). Still, in practice, this is a non-issue because the legal hierarchy places international and EU law above Dutch law, making it the supreme law of the land. Subsequently, this allows Dutch courts to test against international and EU law, which, for the most part anyway, have similar provisions to that of the Dutch constitution when it comes to (human) rights. I suppose the question I’m asking is if in practice, the situation is the same or similar in the UK? reply bawolff 12 hours agorootparentAs a canadian, this is interesting, because i always thought our system was a copy of the UK system, but our courts strike down laws for being unconstitutional all the time. reply sandworm101 11 hours agorootparentIt is a copy. The UK has a constitution. The UK constitution just isn't a simple document one can hang on the wall. The UK constitution is a body of knowledge and traditions. Recognize and do something a particular way for a few hundred years and it can become constitutional irrespective of whether it was nicely codified in a single document. One can even say that the US and Canadian constitutions don't actually say all that much. They survive because they are so open to interpretation by courts ... which makes the body of constitutional knowledge needed to render decisions not all that different than that needed in the UK. reply PaulDavisThe1st 11 hours agorootparentMost people understand \"a constitution\" to mean something written down that you can point to, that has the force ofbehind it, that cannot be trivially elided by a government. None of these are true of the UK \"constitution\", whether it is one document or 5000 precedents. Any document written in a spoken human language will be open to interpretation - there's no getting away from that, regardless of the language, culture or country the document comes from. I still consider that a step up from the bullshit assemblage of \"constitutional law\" that claimed to be \"the UK constitution\". reply JAlexoid 10 hours agorootparentprev> The UK has a constitution. Yes, it's the parliament. There are practically no limits on The Parliament and they can pretty much issue any law they want. reply Aeolun 14 hours agorootparentprev> In the Netherlands, courts can’t test laws passed by the Dutch parliament to the Dutch constitution. What does that mean in practice? That the constitution always overrides any law passed by parliament? reply Gormo 12 hours agorootparentIt sounds like it means the exact opposite, i.e. that in the Netherlands, there is no judicial mechanism for overturning unconstitutional legislation. reply turquoisevar 12 hours agorootparentprevIt's the other way around, actually… sort of. It means that a Dutch court can't test the constitutionality of laws made by the Dutch government in concert with parliament. In legal parlance translated from Dutch, these would be called \"laws in the formal sense.\" The way it works is that the Dutch government (i.e., the Dutch ministers and the King, albeit the latter only in a ceremonious role) proposes a bill, and the two Dutch legislative houses (House of Representatives and Senate) vote to pass it. A law that is a product of this process is deemed a \"formal law\" or \"law in the formal sense.\" Courts cannot test these against the Dutch constitution (i.e., look to see if they're constitutional). Other forms of legislation can be tested against the constitution by courts. These are called \"material laws\" or \"laws in the material senses\" because, materially, they function as a law in the sense that they prescribe something and are generally binding. Still, they haven't been established in a \"formal\" manner through the process I described above that involves the government and parliament. Examples of such material laws are municipal ordinances and royal decrees issued by the Dutch government (akin to the American executive orders by the US president). Some laws that have been materialized through the process described above are also considered material laws instead of formal laws, but that's more a matter of exception when they don't have a generally binding character for all citizens (e.g., a permission law for the marriage of a specific member of the royal family). A judge can't look at these formal laws and rule that they're unconstitutional. Ironically, the Dutch constitution itself (art. 120) prohibits this test. The logic at the time was that they wanted to prevent the judicial branch from second-guessing the legislative branch and that if it misbehaved, the voters could punish them during the next election round. Additionally, they wanted to enshrine that the government, in concert with the two legislative houses, should be the unimpeachable sole authority to create laws. However, this means that the Dutch constitution functions more as a set of guidelines for the highest level of legislators than a strict set of rules to abide by. That said, nowadays, there is some political will here and there every couple of legislative sessions to reform it so that the courts are allowed to test against the constitution, with some ideas even going as far as establishing a formal constitutional court for this purpose. As someone who used to practice there, I think it's more a matter of trivia that raises eyebrows in your first year of law school than something with many practical consequences. As stated before, international and EU treaties have taken over the Dutch constitution's role in keeping the legislator in check. So far, legislators haven't sought to cross the lines in remarkable ways. Nevertheless, I'd welcome testing constitutionality as an extra layer in the legal firewall, provided it's designed in a way that leads to results seen in the German, French, and Scandinavian models, as opposed to the results and effects caused by the SCOTUS in the US. reply seanw444 17 hours agorootparentprev> It's worth noting that UK courts can't overturn Acts of Parliament. Interesting. I didn't know this, and as an American, it seems quite odd. Decisions by the parliament are treated as immutable there? Here, if a bill passed by Congress is deemed unconstitutional, it can be struck down by the Supreme Court. reply denton-scratch 17 hours agorootparentThe only constitution that the UK has consists of Acts of Parliament. So I don't know why it should seem odd; the US courts can't strike clauses of the US Constitution, and the UK courts can't strike Acts. Amusingly, the UK government is currently trying to pass an Act to the effect that black is equivalent to white, i.e. that Rwanda is a safe country to which asylum seekers can be sent. This is analogous to the State of Indiana trying to legislate that the value of Pi shall be 3.2. You can't legislate a fact. reply logifail 16 hours agorootparent> that Rwanda is a safe country to which asylum seekers can be sent Putting aside whether the UK government's approach is a sensible one (which in my view it isn't) we should be aware that: \"the UNHCR, with financial support from the EU, has transferred refugees from Libya to Rwanda under a scheme called the Emergency Transit Mechanism (ETM) [..] The ETM offers vulnerable refugees, taken into detention by the Libyan authorities, a choice to have their application processed in Rwanda.\"[0] \"In 2019, the [Rwandan] Government established the Emergency Transit Mechanism (ETM) Centre that hosted 824 refugees evacuated from Libya. Currently, the transit centre hosts 371 evacuees while working on long-term solutions continues. By the end of 2021, 462 refugees had resettled to third countries so far.\"[1] So Rwanda was apparently safe enough for the UNHCR to offer to process some refugees there. [0] https://www.bbc.co.uk/news/uk-politics-67431602 [1] https://www.unhcr.org/uk/countries/rwanda reply pmyteh 14 hours agorootparentThe UK courts partly relied on evidence that those asylum seekers were not always treated in accordance with the convention. The Supreme Court judgment noted cases of refoulement (expulsion to the state the asylum seeker is fleeing from) as well as structural deficiencies in the decision-making process. (https://www.bailii.org/uk/cases/UKSC/2023/42.html at paragraphs 89 and onwards). They also suggested that the UNHCR was mostly processing applications for asylum in third countries for ETM evacuees. An obvious difference with the UK scheme is that we expect Rwanda to grant asylum themselves. reply Aeolun 14 hours agorootparentprev> So Rwanda was apparently safe enough for the UNHCR to offer to process some refugees there. I think the key word here is safer. It wasn’t safe by any definition of the word, but a fair deal safer than the place they came from. reply logifail 11 hours agorootparent> It wasn’t safe by any definition of the word, but a fair deal safer than the place they came from (Playing devil's advocate) why would this not also apply to those refugees fleeing to Europe? Isn't Rwanda \"a fair deal safer\" than Afghanistan? (This is a genuine question) reply tpm 2 hours agorootparentWhen they are being removed from the UK to Rwanda (which is the aim of UK government), \"the place they came from\" is the UK. reply logifail 2 hours agorootparentQ: Is France \"safe\" compared to the UK? reply tpm 9 minutes agorootparentWhat does this have to do with anything? The reason people are trying to get to the UK from France (and other countries) is they are trying to apply for asylum in the UK. Not in France, in the UK. And the reason they have to do that in the UK is the fact the UK cancelled the possibility to apply for asylum at its embassies. So if you don't want people coming from France to ask for asylum, enable the option to apply at the embassy and you are done. Simple, and you will save many lives. Now of course the same applies to all western countries. There are lots of people trying to come here, some for legitimate reasons, some not, and also we need some of them because of shortage of workers, even if we don't say it loud, because even more would try to come. All western countries allow to apply for asylum only on their soil, thus creating a humanitarian catastrophe, because while the right to asylum is enshrined in the Universal Declaration of Human Rights, it does not say how hard can it be to apply. But all of this is to say it does not matter whether France is or is not a safe country. We could arrange for international cooperation where asylum seekers could ask for asylum and while their application is processed they would stay in some safe country, but next to no safe country will do this because of internal political reasons, so what remains is treating asylum seekers like hot potatoes and not people. It's a sad state of affairs, but there are too many factors and no easy way to direct the blame. pyuser583 5 hours agorootparentprevUS Courts can strike down clauses in the constitution. Any amendment that deprives a state of its senators is unconstitutional. Many states have “unconstitutional amendment clauses.” reply penteract 8 hours agorootparentprev> The only constitution that the UK has consists of Acts of Parliament. That's not completely accurate. The UK has an unwritten constitution, consisting of how everybody knows things work. reply Silhouette 3 hours agorootparentUnfortunately we've seen several times recently that not everyone \"knows\" things work the same way. A lot of what is \"known\" might be accepted by Parliament and our courts today but has historical foundations that we might generously call shaky if you look more closely into their origins. If you're claiming to be a democracy but no-one really knows exactly what your constitutional foundations and system of government are and there is no clear mechanism for the people to change them then are you really a democracy or are you just playing one on TV? For now we have a system where we elect MPs using a deeply flawed voting method on a timetable that MPs themselves can change any time they like, those MPs then result in a Prime Minister being appointed, that Prime Minister then forms a government in largely presidential fashion, the members of that government with executive authority wield much of the real power despite being at least three degrees removed from any popular mandate, and the main check to prevent this system running wild is a second house that is unelected and increasingly consists of political cronies with no particular qualifications except being mates with a previous Prime Minister. this_is_fine.jpg meme reply aftbit 17 hours agorootparentprevIn the US, it's quite hard to change the constitution. It requires agreement from 2/3rds of Congress followed by ratification by the individual legislatures of 3/4ths of the states. Such a thing has not been done since 1992, and not on a politically charged question since 1971. reply JumpCrisscross 16 hours agorootparent> Such a thing has not been done since 1992 We’re a 235-year old republic. Changing the firmware once every 10 to 15% of the time seems fine. > and not on a politically charged question since 1971 This is a feature. If a question is charged it should be resolved first federally, through the states, and then politically, via the legislature. Only once there is consensus should it be elevated to Constitutional status. That is the only way to get a Constitution Americans believe in with intergenerational force. reply LudwigNagasena 54 minutes agorootparentThe problem is that in reality it gets “resolved” through the executive branch or by legalisating from the bench. That ultimately degrades all political institutions. Can FBI arrest you for marijuana possession in a state where weed is “legal”? It should arrest you, weed is illegal, the government just decided to not enforce its own law. The government can just say “It will not be a priority to use federal resources to prosecute X”[1] and everyone is ok with that. If even simple laws get bent so easily, what’s left of the constitution? The words inside the Commerce Clause stayed the same for hundreds of years, yet what it “means” (ie how it’s used by the Federal Government to assert its power) have changed profoundly [2]. [1] https://web.archive.org/web/20091023034358/http://www.reuter... [2] https://en.wikipedia.org/wiki/Commerce_Clause reply jltsiren 11 hours agorootparentprevI believe that a constitution should get a full rewrite once every 50-60 years. That's to only way to ensure that the constitution remains legitimate and relevant. The US does not really have a constitution. There is a set of documents that claims to be the constitution, but it's so out of date that it can't serve as one. Then there is the Supreme Court, which can change the actual constitution easily with its creative interpretations. Because there is no need for a widespread consensus for changing the constitution, its legitimacy remains questionable at best. reply Andrex 9 hours agorootparentThe Constitution is a divining rod to cut through hundreds of years of patchwork caselaw and legislation. Its true use is in a psychological \"what would God/The Constitution want?\" sense. Does it make rational sense? Not really, but my reading of history shows a stronger national identity if tied to something \"beyond.\" Whether that be God, Pharaoh, the Founding Fathers, what have you. reply krapp 8 hours agorootparent>Its true use is in a psychological \"what would God/The Constitution want?\" sense. That's its purpose as the holy writ of the civil religion of the United States. And indeed, the Supreme Court derives their authority to judge the Constitutionality of matters from, in essence, divining the will of the Prophets (Founding Fathers) in interpreting this divine scripture. And as with the Pope, they remain infallible even when they contradict themselves, as well as unaccountable. However, my reading of history has shown that strong national identities built around the worship of state and national myths tend towards dark and bloody ends. In reality, The Constitution is what it is. A 200 year old legal fiction. A compromise between flawed, mortal men written to serve the needs of an agrarian society far closer to medieval than modern, created with the expectation that times and needs can change. reply PaulDavisThe1st 11 hours agorootparentprevYou cannot use that process for constitutional questions. Consider the dispute in the USA over the correct intepretation of the 2nd Amendment. A state (such as NY) implements legislation embodying that state's interpretation of the amendment. SCOTUS rules that the legislation in fact violates the amendment. No change is possible until the constitution is changed ... or the composition of the SCOTUS is modified, and a new court decides that stare decisis is not relevant, which leads to a different type of change to the constitution: interpretation. The only way to change the actual text of the constitution is to change the constitution, and that does not require consensus, just a super-majority. reply Gormo 12 hours agorootparentprevAnd given that the point of a constitution is to set the bounds within policy-making takes place, rather than to enact policy on any specific issue, this is a very important thing. Past attempts to shoehorn answers to specific policy questions into the constitution have been disasters, but even if they hadn't been, using constitutional amendment as a vehicle for policy is effectively the same as having no constitution at all. reply bluGill 16 hours agorootparentprevThere is also a convention of the states that can change the constitution. It has been talked about by various groups from time to time, but has never happened. reply etothepii 15 hours agorootparentAre you sure? Isn't that how the ban on alcohol was lifted? reply matthewowen 14 hours agorootparentThere are two types of constitutional convention. State ratifying conventions, which you are correct is the way that the 21st amendment was ratified by the states after having received a two thirds majority in congress: https://en.wikipedia.org/wiki/State_ratifying_conventions Article V conventions, which replace the legislature stage but then need to be ratified by the states either by the legislatures or by a state ratifying convention: https://en.wikipedia.org/wiki/Convention_to_propose_amendmen... the latter has never happened and the constitution is very vague about what they would entail, and I think is what the earlier poster was referencing (there has been some recent noise around them) this graphic is quite helpful: https://en.wikipedia.org/wiki/State_ratifying_conventions#/m... reply pyuser583 5 hours agorootparentprevBan on alcohol was lifted by 2/3 of each house approving. Instead of going to the state legislators, it went to state conventions convened specifically for that purpose. reply bluGill 15 hours agorootparentprevgood question. I'm not clear after reading Wikipedia how that happened. US congress called for this which is how amendments are normally handled, but then it seems to have done something weird. I'm not interested enough in the question to dig deeper to figure out what is what. I'll leave this as a \"I stand corrected\" but if you care do dig deeper. reply Andrex 9 hours agorootparentprev\"Safe\" is a judgment call, the value of pi is not. reply light_hue_1 16 hours agorootparentprevIt's definitely odd! That's not a reason for UK courts not to strike down acts, or more properly, to have judicial review. Take Canada. Canada has a Supreme Court and no written constitution. The formal divorce between Canada and the UK was not long ago so we inherited the same legal framework (modulo Quebec but it doesn't play a role here). Yet the Canadian Supreme Court can and does strike down federal laws! Actually, provincial courts can too, and then the federal government gets to appeal to them to the Supreme Court if it wishes. Take Israel. There's no written constitution. Just the Basic Laws. They're just laws, they can be amended at any time. Yet, the Supreme Court can and does strike down laws. It's even striking down changes to the Basic Laws. That's part of the current political strife. There is a worldwide movement for judicial review. Usually, supreme courts start with conservative powers and then grow them. Judicial review is not explicitly called out in the US constitution either. The US Supreme Court had to assert that it can strike down unconstitutional laws. This took about 15 years and some careful wrangling. The particular argument of Marbury v. Madison doesn't apply to the UKSC of course. But there are already law review articles spelling out other legal theories that could be used to assert that the UKSC has the power to strike down Acts. I suspect the UKSC will follow other supreme courts and free themselves of Parliament in the coming decades. reply bregma 13 hours agorootparentThe Supreme Court of Canada does not strike down federal laws. It follows section 52 of the written constitution [0] that states the following. 52 (1) The Constitution of Canada is the supreme law of Canada, and any law that is inconsistent with the provisions of the Constitution is, to the extent of the inconsistency, of no force or effect. All the SCC can do is rule whether or not a law (of any jurisdiction, including federal, provincial, or otherwise) is consistent with the Constitution of Canada. If a law is not consistent with the constitution, then the law has no force or effect, according to the law. That's not \"striking down\", since the inconsistent law or portion thereof was never valid in the first place. [0] https://laws-lois.justice.gc.ca/eng/Const/page-13.html#h-59 reply light_hue_1 12 hours agorootparentThat's what \"striking down\" a law is. Even in the US! From the Opinion in Murphy v. National Collegiate Athletic Association: > And courts do not have the power to “excise” or “strike down” statutes. See 39 Op. Atty. Gen. 22, 22–23 (1937) (“The decisions are practically in accord in holding that the courts have no power to repeal or abolish a statute”); Harrison 82 (“[C]ourts do not make [nonseverable] provisions inoperative . . . . Invalidation by courts is a figure of speech”) Which then goes on to cite this Virginia Law review that goes into detail about the confusion between the terminology vs the reality: https://www.supremecourt.gov/opinions/URLs_Cited/OT2017/16-4... > But the federal judiciary has no authority to alter or annul a statute. The power of judicial review is more limited: It allows a court to decline to enforce a statute, and to enjoin the executive from enforcing that statute. But the judicially disapproved statute continues to exist as a law until it is repealed by the legislature that enacted it, even as it goes unenforced by the judiciary or the executive. And it is always possible that a future court might overrule the decision that declared the statute unconstitutional, thereby liberating the executive to resume enforcing the statute against anyone who has violated it. Judicial review is not a power to suspend or “strike down” legislation; it is a judicially imposed non-enforcement policy that lasts only as long as the courts adhere to the constitutional objections that persuaded them to thwart the statute’s enforcement. That being said. You said the written constitution of Canada. From both the UK and the US perspective that's really confusing. Canada's constitution is partly written and partly unwritten and slowly expands over time as other documents are entrenched. From the US perspective, the Canadian constitution isn't the same kind of entity as the US constitution, it's just an Act of Parliament. From the UK perspective this means that anything goes because obviously Parliament should get to change its Act as it wishes (one of the core tenants is that past Parliaments cannot bind future Parliaments). Anyway. That's how striking down laws works. reply smnrchrds 16 hours agorootparentprevCanada's constitution has written and unwritten parts. The Constitution Act of 1982 (which includes the Charter of Rights and Freedoms), for example, is a written part of Canada's constitution. Changing the charter would require the procedure for constitutional change, which is rather difficult. It's not something that can be amended like a normal act of the parliament. reply light_hue_1 12 hours agorootparentThat's fair. I was using the term \"written constitution\" from the perspective of a US reader. There's no document that says \"I'm the constitution, that's it\". Canada works under the idea of an open constitution. There's a collection of documents that become entrenched and are considered part of the constitution. There are endless debates about exactly which documents should be considered. Since the amending formula has made changes impossible, basically all we can do is hope the Court will expand the constitution in a way that serves the public. It's unclear that we really wanted to give the Supreme Court this power. And some argue that this makes the Canadian Supreme Court the most powerful one in the world. Certainly not even the US Supreme Court can decide the contents of the Constitution, only its interpretation. And that's before we get to Quebec and their crazy theory about what section 45 means which would make the whole idea of a constitution a mess. And of course, we're not going to mention the notwithstanding clause. reply bawolff 11 hours agorootparent> There's no document that says \"I'm the constitution, that's it\". Umm section 52(2) of the constitution act? I mean,i guess that is not exhaustive, but its most of it. > There are endless debates about exactly which documents should be considered. I think you are significantly overstating that. There is some debate, but its mostly theoretical and rarely comes up in practise. > Since the amending formula has made changes impossible Its not easy but its not that hard, just nobody agrees on anything. The process for ammending the canadian constitution is roughly the hard as the american one (except for stuff to do with the monarch). Americans need 75% of states, we need 70% of provinces which must contain 50% of the population. Basically the same. > And of course, we're not going to mention the notwithstanding clause. What about it? I might personally not like it, but i don't see how it confuses anything in the constitution. reply nucleardog 4 hours agorootparentFor those that aren't up on their Canadian law and wondering what the \"notwithstanding clause\" is-- The notwithstanding clause allows a government to make a law \"notwithstanding\" parts of our Charter of Rights and Freedoms. The only thing it would take for the federal government to remove the freedom of the press is to pass a law explicitly declaring it it is being removed notwithstanding section 2 of the Canadian Charter of Rights and Freedoms. That law now does not violate the Charter, however it is time limited to 5 years, which is the maximum length that parliament can remain in power without an election at which point it would need to be renewed. The main things that cannot be overridden this way are our right to vote, that legislative assemblies must be re-elected at most every five years, that legislatures must sit every year, and that we have the right to move within or enter and leave Canada. The original idea was that this provided a balance against the judiciary. Even if the court were to declare something violated our rights, the legislature could just say \"okay, we acknowledge that and pass it anyway\". The primary balance against this being abused is simply that it would be unprecedented and everyone's scared to touch the \"nuclear\" button. The federal government has never invoked this clause. The only reason I can see to \"not mention the notwithstanding clause\" is because it directly contradicts the idea of the Canadian Supreme Court being the most powerful in the world. Except in a handful of very specific situations, their power is to declare something unconstitutional or against our rights at which point the legislature can simply shout \"NO U\" and it's in force anyway. reply bawolff 1 hour agorootparent> The only thing it would take for the federal government to remove the freedom of the press is to pass a law explicitly declaring it it is being removed notwithstanding section 2 of the Canadian Charter of Rights and Freedoms IANAL and not sure how the implied bill of rights works in the modern context, but historically laws restricting the freedom of the press have been struck down even without the charter E.g. https://en.wikipedia.org/wiki/Reference_Re_Alberta_Statutes However, The main thing i was trying to say though was simply that the rules around the notwithstanding clause are really clear. I think the original poster was trying to say is that what is constitutional can be ambigious, but the notwithstanding clause doesn't really contribute to that as it is pretty unambigious in how it works. reply denton-scratch 15 hours agorootparentprev> or more properly, to have judicial review. I think that in the UK, judicial review doesn't apply to Acts of Parliament. It applies to administrative decisions, so things like employment tribunals, benefits decisions, medical decisions and so on. Judges aren't supposed to be able to reverse legislation (although, in practice, they can fatally undermine it). reply cscurmudgeon 6 hours agorootparentprevpi is objective. Lets be objective here for safety: https://www.numbeo.com/crime/compare_countries_result.jsp?co... Rwanda is safe reply arethuza 17 hours agorootparentprevThey aren't immutable, but they can only be changed by Parliament: \"the courts cannot overrule its legislation and no Parliament can pass laws that future Parliaments cannot change. Parliamentary sovereignty is the most important part of the UK constitution\" https://www.parliament.uk/about/how/role/sovereignty/ reply pyuser583 5 hours agorootparentprevThe idea is once the Crown issues letters patent, it’s the law. In the recent past, legislation was reviewed for constitutionality by a committee in the House of Lords, called Law Lords. In the 2000s, the Law Lords were rebranded as the “UK Supreme Court”. But the idea is still that once the legislative process is done, the result is a law. reply TillE 17 hours agorootparentprevJudicial review isn't necessarily an obvious or completely desirable concept. It's not in the US Constitution either, and Marbury v. Madison is still somewhat controversial. reply Gormo 12 hours agorootparentFrom the outset, officials in all branches of government have sworn an oath to uphold the constitution in the conduct of their duties, and the constitution explicitly states that it is the supreme federal law, so it seems that Marbury vs. Madison would follow logically from the justices' obligation to only issue rulings consistent with the constitution as they understand it. One could regard the legislature as having an equivalent duty to refrain from enacting statutes incompatible with the constitution, and the executive as having an equivalent duty to refrain from enforcement actions inconsistent with the constitution, but historically, the judiciary seems to have been the only branch to take its duty seriously. reply dukeyukey 15 hours agorootparentprevParliament is sovereign. Basically, as long as Parliament says so, it can do what it wants, although it can be slowed down by institutions like the Supreme Court or the royal family. There is no real separation powers. Which _sounds_ bad, but the UK has an extremely long history of relative stability compared to basically anywhere else on the planet, so something must be going right. reply ben_w 14 hours agorootparent> Which _sounds_ bad, but the UK has an extremely long history of relative stability compared to basically anywhere else on the planet, so something must be going right. The more I learn about British history, the more I think this reputation for stability is merely due to how well all the civil wars (and parliament inviting in a new royal family) were brushed over. reply pyuser583 5 hours agorootparentBritain went 10 years without a general election from 1935 to 1945. By the time the 1945 election came around, nobody under the age of 31 had ever voted. reply ImJamal 6 hours agorootparentprevWhen was the last time the British had a civil war or invited in a new royal family? Having issues hundreds of years ago hardly seems worthy of denying the stability of a country. Many countries have come into existence and no longer exist in that same period of time. reply sorokod 15 hours agorootparentprevThis stability presupposes a presence of adults in the room. reply pmyteh 14 hours agorootparentIt's sometimes described as the 'good chap' theory of governance. Everyone is expected to be a gentleman, so flexibility is possible with an absence of formal guardrails. It obviously handles capture by bad faith actors fairly poorly; the hope is that such people or movements can be stopped before they get that far. Johnson was pretty marginal as a PM from this point of view. reply sorokod 13 hours agorootparentThanks, haven't heard of the 'good chap' theory of governance before. Lovely name that emphasizes how inadequate such system is in the 21st century. Or perhaps it was never adequate: https://www.prospectmagazine.co.uk/politics/37844/has-the-go... reply bemusedthrow75 16 hours agorootparentprev> Decisions by the parliament are treated as immutable there? Yes, and no. Parliament is sovereign -- it is the supreme legal authority. But it cannot bind its successors. So any law parliament creates, any decision can be overturned by a subsequent parliament. reply sorokod 15 hours agorootparentIs that not similar to how the US constitution is managed? It was amended and latter un-amended in the case of prohibition (18th and 21st amendments) reply bemusedthrow75 15 hours agorootparentThe \"parliament cannot bind its successors\" principle was absolutely (and deliberately) imported into US law, yes. It's more general -- no branch of government can bind its own successors. (With the exception of e.g. presidential pardons which cannot be undone) reply Aeolun 14 hours agorootparentI think this is generally true? It’d be weird if there were some laws from 30 years ago that nobody wanted, but were not legally allowed to be changed. You’d just change them anyway and nobody would care. reply bemusedthrow75 1 hour agorootparentIt's generally true precisely because British parliamentary democracy formalised the concept, mind you. Before that, yes, rulers made laws that would perpetually benefit them and their successors. reply pjc50 17 hours agorootparentprevYeah, I don't think it's quite as simple as commentators are making out, because ECJ rulings have roughly constitutional-level effects in disapplying Acts. reply blibble 9 hours agorootparentonly because Parliament allowed it to be so by passing the European Communities Act 1972 this power was removed by one line in the European Union (Withdrawal) Act 2018: > The European Communities Act 1972 is repealed on exit day. https://www.legislation.gov.uk/ukpga/2018/16/pdfs/ukpga_2018... reply glitchc 16 hours agorootparentprevYup, that's because the UK doesn't have a constitution. reply dfawcus 16 hours agorootparentWell it does, in written bits in various places, and some as precedent. However it is a bit more complex. England has a constitution (that collection above), Scotland has a different (and somewhat incompatible) constitution. The incompatibility being where the seat of Sovereignty lies. In Scotland with the people, in England with the Monarch (but wrested away by Parliament). So when the two countries formed the new state of Great Britain, and dissolved their prior states, they granted it a minimal constitution. However they couldn't grant more than they had, and the Scottish grantors did not hold sovereignty. Hence claiming that UK Parliament is sovereign is to presume that England annexed Scotland. That continuing incompatibility is (IMO) why we've never had a single written GB/UK constitution, and probably never will. It will require addressing the fact that we're acting as if Scotland was annexed, and to put that in writing will cause its own problems. reply arethuza 16 hours agorootparentprevIt doesn't have a codified constitution in the US sense but it does have a constitution: https://en.wikipedia.org/wiki/Constitution_of_the_United_Kin... Edit: I would certainly agree that having constitution in this form isn't a great idea... reply simonh 15 hours agorootparentFrankly, the US system isn't exactly a resounding vindication of written constitutions either. Arguably the UK system has displayed considerably greater flexibility. For example the US president is still basically an elected George III. reply bemusedthrow75 15 hours agorootparentprevA written constitution doesn't really seem to work out better, though, does it? reply pjc50 17 hours agorootparentprev> It's worth noting that UK courts can't overturn Acts of Parliament Eh. I think that grossly understates https://en.wikipedia.org/wiki/R_(Factortame_Ltd)_v_Secretary... ; while it does not remove the law from the books, incompatibility with ECJ rulings does effectively disapply the law. This is why there's such a fight over the Rwanda bill: https://www.bbc.co.uk/news/uk-politics-68283703 . ECHR is effectively constitutional law in the UK, not an ordinary Act of Parliament. Courts have ruled that deporting people to dangerous countries breaches ECHR. The government is trying to legislate the \"\"fact\"\" that Rwanda is \"\"safe\"\" in order to circumvent that, because they're not quite yet ready to throw out ECHR entirely and haven't had decades to pack the courts. reply M2Ys4U 17 hours agorootparentWell, yes, there's some nuance here. Where there's an Act of Parliament that says courts can dis-apply other Acts of Parliament then the courts can do so. But the Human Rights Act does not do this, even though it has quasi-constitutional status, and as far as I know now that the European Communities Act has been repealed no Act of Parliament does this. A better case to cite than Factortame would be R (Jackson) v Attorney General, where the House of Lords (in its judicial function before that was removed to the Supreme Court) entertained the idea that in extremis parliamentary sovereignty was not absolute. If the government continues its showdown over Rwanda the Supreme Court might be forced to re-visit that idea. But the law as it is applied right now means that courts cannot overturn actsof Parliament. reply thaumasiotes 14 hours agorootparentprev> It's worth noting that UK courts can't overturn Acts of Parliament. Is that true? I thought the UK had semi-recently (2009) introduced a Supreme Court for this purpose. https://www.unz.com/jderbyshire/lessons-from-britains-nation... says this, just a couple of months ago: > Just this week, on Wednesday, Britain’s Supreme Court struck down the latest attempt to implement the Rwanda plan. (Having a “Supreme Court” that strikes down Acts of Parliament is a fairly recent development in Britain.) reply pmyteh 13 hours agorootparentWe have a Supreme Court. It's the old House of Lords judicial committee with new robes, though: the powers are nearly identical and the legal business of the HoL has been done by the most senior judges since the 19th Century. The nuance here is that many Acts do not set out a whole scheme: they allow government to make subordinate regulations with the force of law. The Acts are (essentially, kinda) immune from judicial review, but the implementing statutory instruments aren't. (They haven't had full parliamentary scrutiny and are in practice just executive instruments - so can be struck down without parliamentary sovereignty problems as ultra vires the government). reply Aachen 19 hours agoparentprev> The Court held that a legal obligation to decrypt E2E communications is a disproportionate interference with the right to privacy. *when no adequate safeguards against abuse are in place Unfortunately it is not as straightforward as that it's incompatible altogether. Per this ruling, it's only incompatible when there are no good safeguards (they use the word \"adequate\" in one place and \"suitable\" in another, neither is very specific about what it means) reply Quanttek 18 hours agorootparentYes, that is very true. The Court generally does not oppose surveillance measures in general, as long as adequate safeguards are in place. However, I read the relevant paragraphs (paras 76-79) to be quite a strong rejection of any statutory obligation that would effectively require the installation of a backdoor undermining E2EE. The criticism of a lack of adequate safeguards and the risk of abuse is more focused on other aspects of the law. That also becomes clear in the key paragraph 80: \"The Court concludes from the foregoing that the contested legislation providing for the retention of all Internet communications of all users, the security services’ direct access to the data stored _without adequate safeguards against abuse_ and the _requirement to decrypt encrypted communications_, as applied to end-to-end encrypted communications, cannot be regarded as necessary in a democratic society\" The Court does not qualify the requirement to decrypt E2EE communications with the same safeguards requirements. That of course does not exclude the possibility of the Court finding that a more narrowly-construed law is not in violation. But the Court clearly signals its skepticism towards any \"requirement that providers of such services weaken the encryption mechanism for all users\" (para 79). reply bondarchuk 18 hours agorootparentYes, this was a problem all along with arguments against surveillance (/encryption weakening) based on \"it can be abused by bad actors\" - it implies that one would be ok with surveillance if it could not be abused by bad actors. While it's tempting to use such arguments (it looks like they had effect in this case at least) it remains necessary to emphasize the true reasons one takes a stand against surveillance e.g. authoritarian overreach or a fundamental right to privacy. reply Karellen 17 hours agorootparentDo you think that phone taps and mail-opening warrants, issued by judges, based on evidence submitted to the court that such warrants are appropriately targetted and based on existing evidence and reasonable suspicion, are intrinsically \"authoritarian overreach\"? reply JoshTriplett 16 hours agorootparentNot inherently, but they become overreach when they start claiming that they should be able to apply to E2EE protocols. If you want the data from an E2EE protocol, serve an appropriately targeted and scoped warrant to one of the endpoints. This also provides an opportunity for legal challenge (e.g. for scope overreach). reply burkaman 18 hours agorootparentprevFrom paragraph 64: > For a detailed description of safeguards that should be set out in law for it to meet the “quality of law” requirements and to ensure that secret surveillance measures are applied only when “necessary in a democratic society”, see Roman Zakharov, §§ 231-34, and Big Brother Watch and Others, §§ 335-39 I am not a lawyer and not motivated enough to go read those decisions, but if anyone is curious that is probably the place to start to figure out what might count as \"adequate safeguards\". reply iamthirsty 18 hours agoparentprev> the UK Online Safety Bill will be overturned by domestic courts (or the European Court) on the basis of this ruling. The UK wants to leave the ECHR[0], so they might be able to get around it — unfortunately. — [0]: https://www.chathamhouse.org/2023/03/uk-must-not-sleepwalk-l... reply stranded22 18 hours agorootparentThe UK DOES NOT WANT TO LEAVE THE ECHR. Select people in the government want to, not the whole of UK. reply noir_lord 18 hours agorootparentTo tack onto this I don't think most people in the UK understand what the ECHR does and why leaving the EU didn't alter our obligations under the ECHR. The media carries a lot of responsibility for that but not all of it - nearly every person in the UK carries a little box with access to a huge chunk of the sum total of all human knowledge, they just choose to not to use it. If that sounds elitist or arrogant it's because I've about reached my limit with ignorant people refusing to understand the world is messy and complex. reply robertlagrant 18 hours agorootparentIt doesn't sound elitist or arrogant - quite the opposite. It just assumes that people know what's true and what's not up front, and know when the media is telling them the truth. Their little box doesn't only tell them true things. reply tailspin2019 18 hours agorootparentprevGood clarification. Personally I just hope we can remove those “select people” from office before they can actually carry out their plan. reply ein0p 16 hours agorootparentYou can’t remove the administrative state. It’ll be happy to sustain the illusion of “democracy” for you by throwing a few of its representatives under the bus every now and again, but in the end all of the candidates you get to vote for are 100% acceptable to the administrative state and are anointed by it. reply zajio1am 16 hours agorootparentprevI think it is more correct to use 'UK' (or any other country) just for government and its institutions than for the body of its citizens. reply JoshTriplett 16 hours agorootparentI think the post you're replying to is rightfully observing that that semantic ambiguity creates harm, by equating the position of a country's government to the position of a country's people. Being more specific and saying \"a faction within the UK government wants to...\" seems like a better framing for any discussion. reply dfawcus 16 hours agorootparentprevA minor quibble. The UK is a 'state', not a 'country'. It comprises of countries: Scotland, England, Wales, and a small chunk of Ireland. reply iamthirsty 15 hours agorootparentAs recognized by the rest of the world, the United Kingdom actually is a country. Internally may be different, but technically it is a country. A political union of four member countries — but still recognized as a country. reply dambi0 12 hours agorootparentInternational football being one exception to this. reply willmadden 17 hours agorootparentprevThe coverage I heard on the BBC and NPR in the States about Brexit and UK public sentiment was a complete inversion of reality. I'm reluctant to believe anyone telling me what the UK wants. reply mobiuscog 17 hours agorootparentNobody really knows what public sentiment is in the UK, because nobody is asking. They're all just telling the people what they 'want'. The sample sizes for any polls are tiny, and the areas/people that are sampled are not comprehensive. It's fairly likely that the people (or a majority of) want the Tories out, as all sides are suggesting that and it's about the only consensus we see. Brexit was such a mess of misinformation and rushed voting, on something that the majority of people had no idea 'what' they were really voting for, that it should never have been taken as binding - and it probably wouldn't have been if the remain vote won. At this point, it's unclear if the UK will start to even recover in the next 5 years, or just keep getting worse. reply rsynnott 17 hours agorootparentprevThe UK leaving the ECHR, at this point, seems incredibly far-fetched; even amongst the Tories it's hardly a consensus position, and they realistically only have a few month of working time left before the next election. reply sandworm101 11 hours agoparentprev>> information necessary to decrypt electronic messages if they were encrypted That reminds me of Lavabit, which I once used as my primary email. In response to demands for decryption information, Lavabit handed over their private keys. On paper. Typed out. Possibly with a typo somewhere on page 6, or 12. https://thenextweb.com/news/you-wont-believe-what-email-prov... reply martingxx 16 hours agoparentprevThe UK government almost seem to be deliberately passing multiple pieces of legislation that they know will be overturned due to ECHR, because they believe such rulings would strengthen their argument for withdrawing from the convention. reply TheRealPomax 14 hours agoparentprevPerhaps a dumb question, but why would the EU courts be able to overturn laws in the UK now that the UK is not part of the EU anymore? reply AAAAaccountAAAA 12 hours agorootparentECHR is not an EU court, but a separate entity, having for long had many non-EU member states. reply Aachen 19 hours agoprevI am a bit confused. The article seems fairly political, quoting some promotional text by the pirate party and not describing what case was brought in front of a judge and what the ruling bans specifically, so I clicked through to the actual court case linked at the bottom. It has nothing to do with the pirate party or chatcontrol or any such thing. The court case was one person against the Russian government for fining Telegram when they didn't hand over plain text chat messages, if I'm skimming the initial facts section correctly. The whole article doesn't even contain the word russia. What is the article reporting on and why does it portray it as being related to the recent chatcontrol legislation?! Edit: found the decision > 80. The Court concludes from the foregoing that the contested legislation providing for the retention of all Internet communications of all users, the security services’ direct access to the data stored without adequate safeguards against abuse and the requirement to decrypt encrypted communications, as applied to end-to-end encrypted communications, cannot be regarded as necessary in a democratic society. > 81. There has accordingly been a violation of Article 8 [privacy] of the Convention [of human rights] Sounds like you can indeed extend that to any other encryption-circumventing law, like chatcontrol, but without considering the specific circumstances that were present in this Russian law, I'm not sure that it will be accurate. Note, for example, the wording in paragraph 80 \"without adequate safeguards against abuse\". Maybe chatcontrol had those, if that had been brought in front of the same judges reply tokai 19 hours agoparentIts a judgement that will provide precedence. A Pirate Party member of the European Parliament comments because its a core issue to the party. Why would there be anything about the Pirate Party in the ruling? reply Aachen 19 hours agorootparentWhy would you include \"We Pirates will now fight even harder for our digital privacy of correspondence!\" (and then continuing to link their website as a source of truth on the matter) in a non-promotional piece? This is an advertisement, not a news article One which I agree with, to be clear. I'm not opposed to the pirate party's views on digital matters. This party's goals/narrative just has no place in a piece about a court case reply chefandy 19 hours agorootparentThere’s a disclaimer at the bottom of the article that says they publish articles from a variety of sources, and that the viewpoints expressed aren’t necessarily their own, etc. Considering that it does seem to have an angle, the byline says it’s from their own unnamed correspondent, it’s not called an opinion piece, and there’s no link to the original, I’m guessing their slightly unpredictable correspondent’s surname is GPT. reply tokai 19 hours agorootparentprevI'm not arguing that with you. You misunderstood what was going on here, edited your comments many times, and now you want to discuss the article linked instead of the actual news (the judgement). Calm down. reply Aachen 19 hours agorootparentI edited in more info as I found it, trying to be helpful for what's currently the top comment. Sorry if that's not okay reply rmbyrro 15 hours agorootparentprevC'mon, let's let people write pationately about issues they hold in their hearts. I can totally understand why they're so passionate about this topic in particular. We don't have much left of democracy in the world. If electronic privacy is destroyed like some EU leaders want, there will be close to nothing left. reply krastanov 19 hours agorootparentprevI thought precedents only matter in the US \"common law\" framework, but most of the EU is following the \"civil law\" framework where precedents do not matter. Does this precedent really matter? reply tokai 19 hours agorootparentPrecedence is still a thing. Just less mechanically than in the US. This might be interesting: https://opensiuc.lib.siu.edu/cgi/viewcontent.cgi?article=101... reply sofixa 18 hours agorootparentprevIt's funny seeing \"common law\" referred as a US thing when it's literally been in use in the UK for centuries before the US was a thing, and that's where the US inherited it from. And precedent has it's place in civil law countries too, mostly around clarifying existing legislation in case of ambiguity, but it isn't an automatic ironclad thing. reply cycomanic 18 hours agorootparentprevWhile precedence is not the same thing in civil law as in common law, this is essentially a ruling by the highest European court on the interpretation of a law and its conflict with human rights. These rulings are typically on the matter of principle, so it does effectively \"bind\" lower courts and because of this the court is very unlikely to take on another case on the same \"conflict\" (at least before the law has been changed). reply SllX 15 hours agorootparentprevIt’s a Council of Europe institution (note, not EU), so really there’s no common legal philosophy, just the relevant treaties and conventions. The European Court of Human Rights’ whole raison d’être is the European Convention on Human Rights, so it interprets laws through the lens of whether they conform to that, and does have its own case law, albeit a short history of it. reply vaylian 14 hours agoparentprevThe article is not the original. The original text can be found here: https://www.patrick-breyer.de/en/european-court-of-human-rig... reply sackfield 18 hours agoprevIt's nice to know this also applies to the UK even after Brexit (still a member of the ECHR). reply TheFuzzball 16 hours agoparentThe Tories have been talking about leaving the ECHR for years now. reply hayd 12 hours agorootparentThey should've left, obviously, not sure what they've been doing with an 80 seat majority. But a silver lining is Cameron/May's \"Snoopers' Charter\" is utterly dead now. reply Georgelemental 17 hours agoparentprevAzerbaijan is in the ECHR too; doesn't stop them from imprisoning political dissidents, employing slave labor, committing war crimes, attacking other ECHR members, or performing ethnic cleansing. reply gpderetta 16 hours agorootparentWell yes, generally the ECHR has no powers to compel compliance. But ECHR rulings are binding to EU members (and the the various organs of the EU including the ECJ have way to enforce them). ECHR are also still binding in the UK because legislation that says otherwise hasn't been passed yet. reply jacobp100 17 hours agoparentprevOh sweet summer child reply infamouscow 11 hours agorootparentI'm not sure why this is being downvoted. Governments aren't accountable to their citizens, and there aren't any repercussions nor punishment for violating rights. Sure, the court might have ruled on this, but that's irrelevant when the government decides \"national security\" takes precedent and uses the media to manufacture the consent of the population into thinking extraordinary times require extraordinary measures. If most of the people with guns want to ignore the court, they will. reply tempestn 10 hours agorootparentI expect it's being downvoted because it's patronizing and lacking in any useful information beyond an implied disagreement. reply x-complexity 8 hours agorootparentprevIt's being downvoted because it's like saying \"lol\" or \"L\". Nothing substantive was added to the conversation. reply rrrrrrrrrrrryan 18 hours agoprevMan, Europe is really setting an example lately for how it's possible to roll out sensible technology regulations. reply miohtama 16 hours agoparentThis decision was needed because the EU was about to ban end-to-end encryption. It’s not the EU commission, but a judge that ruled. AFAIK Commission can still ignore this. reply ko27 15 hours agorootparentYou have it the other way around. Majority of EU member countries wanted to to ban E2E, but the EU institutions prevented that. reply dmichulke 3 hours agorootparentNo, the ECHR is not a EU institution, it's just European. The bad guys here are the commission and some EU member states. reply asyx 2 hours agorootparentprevAs far as I remember, the commission tried to introduce the chat control nonsense but the parliament shut it down. reply gpderetta 16 hours agorootparentprevThey in fact cannot. reply moffkalast 15 hours agorootparentUrsula on suicide watch. reply Georgelemental 17 hours agoparentprevNow if they could only do a good job developing the technology itself… reply klabb3 14 hours agorootparentIf only California could do a good job starting as many companies as Delaware. reply ulchar 14 hours agorootparentIs Delaware a good place for a startup? Or am I missing the joke. reply amirdadp 13 hours agorootparentMany companies incorporate in Delaware for benefits such as loose tax laws. reply scotty79 16 hours agorootparentprevWhy do what everyone can do if you can do the thing only you can do? ASML When there's a gold rush, make shovels. reply pb7 16 hours agorootparentThat’s it? One noteworthy company for a population of 440M? reply berkes 15 hours agorootparentObviously not. There are tons of large companies, many of which are often misread as American, because they are listed on the Nasdaq or another US exchange. Many EU companies have far higher revenues than their US counterparts (Airbus, Volkswagen, Alstom), are boring but crucial (Heidelberg, DTE) or not easily recognised (Novo Nordisk, Unilever). Even in tech, there's a lot of interesting ones: Booking.com, elastic search, takeaway (aka GrubHub), Adyen, for example are all Dutch. There's or was, Spotify, Skype, SoundCloud, Zalando, Mojang, Shazam and so on. Just be a bit more curious and less preoccupied and you'll see there's plenty going on in Europe. And don't forget that companies can be great and big and multinationals even if they aren't present in the US. reply xvector 12 hours agorootparentThe EU's entire modern tech industry does not even measure up to that of one US company. Dismissals of the EU's inability to compete in tech is why EU citizens have missed out on literally tens of trillions of dollars in economic growth post-2000s. The EU's lack of ability to innovate is becoming a serious problem for the progress of our species as a whole. reply geraneum 7 hours agorootparent> literally tens of trillions of dollars > ability to innovate Valuation and innovation could be related and could be not depending on the company, industry, fraud, etc. > The EU's lack of ability to innovate Modern American tech products are made of so many different parts, of which a significant portion is made (and designed) in EU, rest in US, Japan, Korea, China, etc. reply scotty79 10 hours agorootparentprevUS valuations are simply insane. Oligarchs money looking for an investment vessel inflate share prices. In most cases it has nothing to do with actual value of the companies or their revenue. In US empty company can be \"worth\" billions for a time. reply pb7 8 hours agorootparentThat's what happens when you're a wealthy country with a booming economy and flush with companies that serve the world. reply berkes 52 minutes agorootparentNo. That's what happens when there's no social system for pensions. In the US everyone and his dog has to \"invest\" in the stock market for their older days. In Europe this is happening more and more too, but there's also still a reasonable pension system in most countries that serves this purpose for individuals. There are simply far more investers putting money in already inflated assets in the US than in Europe. Take Tesla vs Volkswagen (or Porsche if you want). VW sells magnitudes more cars worldwide than TSL, even just the electric ones. Their ROI is much higher. And both their innovation is just as flakey at times (compared to e.g. Volvo who remain strong leader in all automotive innovation). Anyone who looks at the solid figures, sees that VW is simply the stronger and more boring company. Yet people bet on the future, in which TSL promises to overtake VW. And then inflates the already inflated bubble some more, praying for that promise to be delivered on. Praying, however, is not a good way to innovate an economy. reply scotty79 2 hours agorootparentprevNot really. That happens when you have concetration of capital in few hands that can do with it whatever they want but there's really not much to do with it. US stock market is analogue of Chinese real estate market. It's full of overpriced crumbling units and overt scams waiting to be exposed. In Europe this capital is dispersed and more often serves the purpose of building infrastructure, increasing prosperity and well being of societies as a whole and developing large number of smaller businesses priced realistically. It's less flashy, but healthier. reply berkes 1 hour agorootparentprevYeah. Airbus has proven to be unable to compete and innovate itself into an established market. /S reply corford 14 hours agorootparentprevIf we're talking chips, ARM is also quite noteworthy... FinTech is pretty awesome in Europe too: Wise, Revolut, Klarna, Adyen are all unicorns/decacorns. reply alkonaut 13 hours agorootparentprevThere are tons of large european tech companies. But we forget that because most of them are 50 or 100 years old. reply IlikeMadison 16 hours agorootparentprevthey already do reply pb7 16 hours agorootparentDo they? Examples? reply amarant 15 hours agorootparentSpotify, King, DICE and Mojang are some commercial software successes. All from Sweden. If you don't think the entertainment industry counts for much, I might remind you Linux was originally made in Finland. (Linus Torvalds is half Swede half Finn iirc) That's just from the top of my head. reply ganieldackle 15 hours agorootparentSpotify was made up of 75% US employees since the moment it validated its value. DICE is a failed studio. Battlefield 2042 was one of the worst AAA video game launches of all time (with Cyberpunk 2077 by Polish studio CD Projekt Red being another) after a rocky Battlefield V launch and there is no reason to believe they will come back from it. King makes low quality micro-transaction-riddled games for addicts. Mojang -- OK. reply matsemann 15 hours agorootparentFacebook is just scams and intervenes with elections. Google is just privacy hell that sells your data for ads. Amazon is in the business of abusing its workers. Point being, it was asked for success. Not if people like the company or not. reply pb7 8 hours agorootparentIf we're going to be reducing to absurdity, Europe is a museum. No one is looking to it for the next big thing. reply xvector 12 hours agorootparentprevWhat a cynical interpretation. These companies have QoL for billions, directly and indirectly. You are just normalized to it now. For some reason I don't see you blaming Cambridge Analytica - the actual company running the interference by exploiting APIs - for the interference itself. reply matsemann 15 minutes agorootparentDid the point go above your head? Because my point was that the EU companies mentioned also have earned money and been used by billions of people, no matter if the other commenter likes them or not. ganieldackle 14 hours agorootparentprevWhat an intellectually dishonest take comparing Candy Crush to US big tech. You should be embarrassed. reply matsemann 15 minutes agorootparentI wonder what's done more good for the world. amarant 14 hours agorootparentprevI mean, candy crush is the most downloaded mobile game ever, and it's income is measured in millions of dollars per DAY. I don't much like it either, but it's popularity is difficult to deny. By any objective measure, it's a successful company. reply Macha 19 hours agoprevHonestly, after so many things turning into \"they'll just come back and try again in two years\", it's a little reassuring to see some longer term roadblocks being put in place against these anti-E2EE proposals. reply p0w3n3d 16 hours agoparentyeah, preferably through the Agricultural and Fisheries Commission or a similar body reply Nostromos 9 hours agoprevThere's a degree of push/pull on government and industry as far as encryption is concerned. Government shouldn't be injecting vulnerabilities into algos but they also need a way to read messages from criminals and terrorists. Industry wants some way for customers to feel safe using their product to message or whatever their (legal) use case. Without some local pressure, this cedes encryption commercialization to the US. Sure academics will still love their novel algos but until someone can make money from them, they'll sit in papers, ready for the enterprising american dev to turn into the next big encrypted chat app that is more secure than Signal or something like that. reply max_ 18 hours agoprevEurope has done something that I actually love. I was worried the \"let's think of the children\" narrative would take over. The value of encryption has a future in Europe at least. reply guappa 18 hours agoparentDespite the name, it's not the eu :D reply max_ 18 hours agorootparentI was assuming it had jurisdiction over the EU? What is the actual real world impact of this? reply Deukhoofd 18 hours agorootparentIt's a part of the Council of Europe, which includes all European countries besides Russia and Belarus (who got kicked out last year). It has no real enforcement powers for its judgements, though most countries do adopt most its judgements, and it has pushed human rights in Europe forward a lot. While the EU could potentially just ignore the statement, there's a good chance they won't, especially as the European Parliament already tends to be against weakening encryption. reply tpm 18 hours agorootparentEU can't ignore it - while the ECHR is separate from the EU, the EU itself is legally bound to follow the ECHR rulings. reply M2Ys4U 16 hours agorootparent>the EU itself is legally bound to follow the ECHR rulings You'd think so, but it actually isn't. All of the EU's member states are, but the EU and its institutions aren't. The EU is legally bound to join the Council of Europe (and thus come under the jurisdiction of the ECHR), except the EU's Court of Justice threw a spanner in the works quite a while ago and this is on hold, pretty much indefinitely. The conflict is that the CJEU is supposed to be the authoritative interpreter of EU law, but if the EU joins the CoE then the ECHR could also rule on matters of EU law, potentially binding the CJEU, and it doesn't like that very much. reply Deukhoofd 14 hours agorootparent> this is on hold, pretty much indefinitely It's not, negotiations started again in 2020. https://www.coe.int/en/web/human-rights-intergovernmental-co...} reply M2Ys4U 13 hours agorootparentoh! I had totally missed that, thanks reply Deukhoofd 17 hours agorootparentprevECtHR rulings have been ignored in the past by members. Italy for example currently has over 2000 verdicts unimplemented. The ECtHR orders a country to implement changes to improve the situation, but does not set a deadline, so members could just ignore it. reply rsynnott 17 hours agorootparentprevThe EU requires EU members to be subject to the ECHR, but it is a separate body and various non-EU countries are subject to it (though, particularly outside the EU, compliance varies). reply yreg 18 hours agorootparentprevThe European Court of Human Rights enforces the European Convention on Human Rights. Its jurisdiction is recognised by the 46 member states of Council of Europe (which includes all of the 27 EU members) + Kosovo. reply yxhuvud 19 hours agoprevNice. I can imagine certain ISPs (that I will not shame by name) won't be very happy right now. This really throws a wrench in some proxy models. Good riddance. reply KoolKat23 17 hours agoparentPlease do name and shame. This would benefit everyone. reply LightBug1 18 hours agoprevExcellent news. The European Court of Human Rights ... the court our idiotic UK gvoernment are trying to paint with the same brush they painted the EU. reply kypro 18 hours agoprevI realise the article contains the same typo, but the title is bugging me – it needs a space between \"end\" and \"encryption\". \"Endencryption\" is not a word. @dang ? reply robtherobber 14 hours agoparentAh, apologies about that, I didn't even notice it. Happy to see it corrected. reply yusml 17 hours agoparentprevYeah, it's bugging me as well. haha. reply WalterBright 12 hours agoprevWeakening of secure end-to-end encryption means the encryption is worthless. reply nadermx 15 hours agoprevThey also ruled a while ago on site blocking, which has at least been tested in the Mexican supreme court[0] translated via google \"As the United Nations Human Rights Council has stated, blocking an Internet page implies any measure taken to prevent certain online content from reaching an end user. In this regard, it must be taken into account that restrictions on the human right of freedom of expression should not be excessively broad, on the contrary, they should refer to specific content; Hence, generic prohibitions on the operation of certain websites and web systems, such as blocking, are incompatible with the human right of freedom of expression, except in truly exceptional situations, which could arise when the contents of an Internet page are translate into prohibited expressions, that is, classified as crimes in accordance with international criminal law, among which the following stand out: (I) incitement to terrorism; (II) the advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence - dissemination of \"hate speech\" on the Internet; (III) direct and public incitement to commit genocide; and (IV) child pornography. Likewise, the exceptional situation regarding the prohibition of generic restrictions on the right of expression could also be generated when the entire contents of a web page are illegal, which logically could lead to its blocking, as it is limited only to hosting expressions that are not permissible by law. the legal framework.\" [0] https://vlex.com.mx/vid/tesis-aisladas-683012725 reply lacoolj 16 hours agoprevthis is a HUGE win and could very much help set precedent across the globe (looking at our congress specifically, USA). Still more hurdles to jump over but a great step in the right direction reply germandiago 11 hours agoprevGood news reply HenryBemis 19 hours agoprevThe article is semi-garbage (politics aside it is a badly written/biased article). Better read the decision. https://hudoc.echr.coe.int/eng/#{%22itemid%22:[%22001-230854...} CASE OF PODCHASOV v. RUSSIA (Application no. 33696/19) reply ryukoposting 19 hours agoparentRelevant English text from the Court's press release: > The applicant, Anton Valeryevich Podchasov, is a Russian national who was born in 1981 and lives in Barnaul (Russia). > Mr Podchasov was a user of Telegram, a messaging application which was listed as an “Internet communications organiser” (организатор распространения информации в сети Интернет) by the Russian State. It was therefore obliged by law to store all communications data for a duration of one year and the contents of all communications for a duration of six months and to submit those data to law-enforcement authorities or security services in circumstances specified by law, together with information necessary to decrypt electronic messages if they were encrypted. > Relying on Article 8 (right to respect for correspondence) and Article 13 (right to an effective remedy) of the Convention, Mr Podchasov complains of the legal requirements to store, pass on and decrypt data, and that he did not have an effective remedy for this complaint. > Violation of Article 8 > Just satisfaction: The finding of a violation constitutes in itself sufficient just satisfaction for any non-pecuniary damage sustained by the applicant Source: (this is broken) https://hudoc.echr.coe.int/eng-press/#{%22fulltext%22:[%2233...} Edit: Yuck, this website makes it impossible to permalink anything. What a horrible idea for an organization that's supposed to make very important decisions that people need to reference. reply Quanttek 19 hours agorootparentClick on \"details\" and you can permalink reply roenxi 19 hours agoparentprevIn defence of the article - it linked the decision. That means it is automatically in something close to the top 20% of articles about political topics. And the actual decision is quite readable; on a quick skim it seemed to agree with what the article said. reply dns_snek 19 hours agoparentprevHN markup seems to be breaking the link, here's an alternative one: https://hudoc.echr.coe.int/eng/?i=001-230854 reply 1f60c 19 hours agoparentprevFOR THESE REASONS, THE COURT Holds, unanimously, that it has jurisdiction to deal with the applicant’s complaints in so far as they relate to facts that took place before 16 September 2022; Declares, unanimously, the complaint concerning the alleged violation of the right to respect for private life and correspondence admissible; Holds, unanimously, that there has been a violation of Article 8 of the Convention; Holds, by five votes to two, that there is no need to examine the complaint under Article 13 of the Convention; Holds, by six votes to one, that the finding of a violation constitutes in itself sufficient just satisfaction for any non-pecuniary damage sustained by the applicant; Dismisses, by six votes to one, the applicant’s claim for just satisfaction. Done in English, and notified in writing on 13 February 2024, pursuant to Rule 77 §§ 2 and 3 of the Rules of Court. reply Quanttek 18 hours agoparentprevRelevant paras: > (γ) Statutory requirement to decrypt communications > 76. Lastly, as regards the requirement to submit to the security services information necessary to decrypt electronic communications if they are encrypted, the Court observes that international bodies have argued that encryption provides strong technical safeguards against unlawful access to the content of communications and has therefore been widely used as a means of protecting the right to respect for private life and for the privacy of correspondence online. In the digital age, technical solutions for securing and protecting the privacy of electronic communications, including measures for encryption, contribute to ensuring the enjoyment of other fundamental rights, such as freedom of expression (see paragraphs 28 and 34 above). Encryption, moreover, appears to help citizens and businesses to defend themselves against abuses of information technologies, such as hacking, identity and personal data theft, fraud and the improper disclosure of confidential information. This should be given due consideration when assessing measures which may weaken encryption. > 77. As noted above (see paragraph 57 above), it appears that in order to enable decryption of communications protected by end-to-end encryption, such as communications through Telegram’s “secret chats”, it would be necessary to weaken encryption for all users. These measures allegedly cannot be limited to specific individuals and would affect everyone indiscriminately, including individuals who pose no threat to a legitimate government interest. Weakening encryption by creating backdoors would apparently make it technically possible to perform routine, general and indiscriminate surveillance of personal electronic communications. Backdoors may also be exploited by criminal networks and would seriously compromise the security of all users’ electronic communications. The Court takes note of the dangers of restricting encryption described by many experts in the field (see, in particular, paragraphs 28 and 34 above). > 78. The Court accepts that encryption can also be used by criminals, which may complicate criminal investigations (see Yüksel Yalçınkaya v. Türkiye [GC], no. 15669/20, § 312, 26 September 2023). However, it takes note in this connection of the calls for alternative “solutions to decryption without weakening the protective mechanisms, both in legislation and through continuous technical evolution” (see, on the possibilities of alternative methods of investigation, the Joint Statement by Europol and the European Union Agency for Cybersecurity, cited in paragraph 33 above, and paragraph 24 of the Report on the right to privacy in the digital age by the Office of the United Nations High Commissioner for Human Rights, cited in paragraph 28 above; see also the explanation by third-party interveners in paragraph 47 above). > 79. The Court concludes that in the present case the ICO’s statutory obligation to decrypt end-to-end encrypted communications risks amounting to a requirement that providers of such services weaken the encryption mechanism for all users; it is accordingly not proportionate to the legitimate aims pursued. > (δ) Conclusion > 80. The Court concludes from the foregoing that the contested legislation providing for the retention of all Internet communications of all users, the security services’ direct access to the data stored without adequate safeguards against abuse and the requirement to decrypt encrypted communications, as applied to end-to-end encrypted communications, cannot be regarded as necessary in a democratic society. In so far as this legislation permits the public authorities to have access, on a generalised basis and without sufficient safeguards, to the content of electronic communications, it impairs the very essence of the right to respect for private life under Article 8 of the Convention. The respondent State has therefore overstepped any acceptable margin of appreciation in this regard. > 81. There has accordingly been a violation of Article 8 of the Convention. reply holoduke 13 hours agoprevWhat the hell is wrong with our democratic values to begin with? Why do we need high court decisions for these insane ideas of making a better world. Are these people infected by some corporate lobby or what is it why they cannot think in favour of human kind. I cannot phantom this. reply gjsman-1000 19 hours agoprevReminder that the European Court of Human Rights, although very powerful and influential, does not have the authority to force anyone to abide by their rulings. Also, here's a better article: https://fortune.com/2024/02/13/end-to-end-encryption-russia-... reply Quanttek 19 hours agoparentSlightly misleading: The Court's judgments are legally binding upon the State members of the Council of Europe. However, it is true that there is no armed enforcement mechanism – something that most domestic courts lack too – and instead decisions are enforced and monitored by the Council of Ministers (the equivalent of the UN General Assembly). However, most of its decisions are complied with most of the time by most nations (safe for Russia and Turkey), frequently because domestic courts will abide by the Court's rulings to overturn laws through its own decisions. reply sampo 19 hours agoparentprevAlso, despite its name and despite its location in Strasbourg, European Court of Human Rights is not an EU institution. https://en.wikipedia.org/wiki/European_Court_of_Human_Rights... reply Georgelemental 17 hours agoparentprevFor example, Azerbaijan (a brutal and militarily aggressive dictatorship) is a member reply hkt 19 hours agoparentprevNot so. The UK, for instance, appears to treat these rulings as binding. This is why the UK conservatives want to scrap the Human Rights Act and replace it with a supposedly identical Bill of Rights, the key difference being a presumption that the UK's supreme court would cease to defer to the convention court. A couple of examples relating to this that come to mind: * Deporting refugees to Rwanda was stopped by an injunction from the ECHR * Depriving prisoners of votes was ruled illegal in 2005 or so There are a few others but these two come to mind. My understanding is that although the treaties (plural?) of the CoE and ECHR don't assume judgements are binding, a number of countries made them binding in their legal systems via domestic legal instruments. reply shaoonb 18 hours agorootparentI believe both your examples are ones where the UK did not follow the decision of the ECHR. reply blackshaw 16 hours agorootparentThe Rwanda ECHR injunction was followed, which is one reason why no migrants have yet been sent to Rwanda despite nearly two years of harsh rhetoric. reply eastbound 19 hours agoprevIs there an exception for emergency purposes? reply nottorp 19 hours agoparentIf it's done right, it can't be subverted in case of \"emergency\" can it? If it's full of bugs, it simply doesn't matter. reply AJ007 19 hours agorootparentThe \"e2e\" concept that most are familiar with is basically fake: the provider is responsible for the client that does the encryption and decryption. Of course they can break it if forced. Software exploits are a separate matter and also easier to deal with when the end user isn't truly in control of the encryption (or easier if they don't know what they are doing.) reply hot_gril 15 hours agorootparentIt's more fake because you download the app, look up your friend's number \"1-555-333-2222\", and your client trusts their server to actually return your friend instead of a MITM. Some asterisks there, but basically it's far from trustless. reply procflora 10 hours agorootparentIsn't this what the \"safety number\" in Signal is for? Obviously you are still trusting many other things there (the client software, OS, hardware, whatever out of band method you use to compare the numbers, etc.), but I thought the safety number pretty much addresses the MITM concern specifically, if you bother to check it. reply hot_gril 9 hours agorootparentRight, the issue is that nobody checks it and they don't really tell users upfront why they need to. It also notifies you if the number changes later, but seems like that can happen for benign reasons too, so it might go ignored. WhatsApp and Telegram are similar. Someone could orient an E2EE app around these trusted identities, but it'd probably not be very popular. reply gjsman-1000 19 hours agorootparentprevIf the client is properly developed and secured, they cannot break it without shipping an update to that client to change its behavior - which then affects everyone. reply guappa 18 hours agorootparentI'm quite sure they can use the app store to push a targeted update just to some. reply px43 17 hours agorootparentYes, an operating system that uses a compromised software supply chain is at risk of compromise, but that really has nothing to do with e2ee. reply hot_gril 16 hours agorootparentprevNo need, push an update to all that only affects certain users. But if anyone ever de-obfuscates that, your reputation is gone. reply Quanttek 19 hours agoparentprevI think that depends on what you mean: a general state of emergency or a specific situation where the police deem there to be an emergency (e.g. classic hidden bomb scenario) Regarding (2), the Court found that a statutory obligation to decrypt E2E-encrypted data upon (judicial) request to be disproportionate, but it could still be imagined that – if more narrowly construed – a law could be considered to be proportionate. But the Court does seem quite unwilling to entertain the idea of backdoors for E2E encryption. Regarding (1), the European Convention on Human Rights (ECHR) allows so-called derogations from certain rights in \"time of war or other public emergency threatening the life of the nation\" (Art 15 ECHR), insofar as they are necessary and the state of emergency has been properly declared. The right to privacy is such a right, so a State that faces an insurgency may declare a state of emergency and, as part of its emergency measures, could probably demand the decryption of E2E communications if it's necessary to fight the insurgency (e.g. it's a guerilla group using an E2E messenger) - but hard to judge in the abstract. reply meindnoch 18 hours agoparentprevYes, in case of an emergency you can ask God to give you the prime factorization of 4096bit numbers. reply steelframe 18 hours agoparentprev> Is there an exception for emergency purposes? The problem is when the \"emergency\" is \"the citizen may be engaged in political activities that are against the interests of the ruling party.\" reply priprimer 19 hours agoparentprevthere’s only and opposing secret court mandating the opposite: publicly available encryption must be weakened on release reply layer8 18 hours agoparentprevExceptional circumstances can warrant exceptional measures, but also require exceptional justification, for example by means of a juridical decision for the individual case (i.e., a judge issuing a warrant allowing the police to install and use a backdoor on a concrete individual). reply eastbound 14 hours agorootparentLet’s just remind that “exceptional justifications” in Canada were “Truckers are protesting with honks in the middle of cities”, so not exactly a matter of national security and in the USA, NSA took it to mean “Any US or non-US citizen on US or non-US soil” (for national security letters). reply mratsim 19 hours agoparentprevWhen there is an emergency to break into a house, the police needs to get a mandate from a judge. reply rtkwe 19 hours agorootparentDepends on where you are. In the US there's the Exigent Circumstances exception to the warrant requirement. Not sure if the same theory has been included in EU countries but I would be surprised if it hadn't, a quick search didn't turn up much english language about it. https://www.ce9.uscourts.gov/jury-instructions/node/155 reply asmor 19 hours agorootparentprevNo, they don't. Many countries have the concept of \"imminent danger\", which allows police to skip the warrants. It's called \"Gefahr im Verzug\" in Germany, for instance. reply gjsman-1000 19 hours agorootparentprevWell, there is actually an exception to that too - the Police can break into any home, without a warrant, in the US, if they can prove they had reasonable cause to believe that there was imminent and immediate threat of bodily harm or death. If you are a police officer and see a guy clearly pointing a gun at someone else through the window, yes, you can break in if the circumstances warrant that. reply 05 19 hours agorootparentOr if you receive an anonymous call from a swatter.. reply JoshTriplett 16 hours agorootparentprevThe flip side of that is that if the police enter on that basis, any evidence they come across in the course of that action is going to be tainted and potentially thrown out of court, especially if that evidence wasn't in plain sight. reply vdaea 19 hours agorootparentprevThat's not true at least in Spain. There's \"In flagrante delicto\" which means if the police suspects something going on they can kick your door down. It was used many times during the pandemic: when they suspected you were having too many people over at home, they acted. Unconstitutionally, mind you. The EU is not the utopia many think it is. reply martimarkov 19 hours agorootparentYou’d need to define “unconstitutionally” as it seems if they have the right then it is constitutional reply vdaea 17 hours agorootparentThe constitutional court of Spain ruled the state of alarm (a kind of state of emergency) that was used to prohibit gatherings during the pandemic was unconstitutional. But by then the damage was made of course. reply denton-scratch 17 hours agorootparentThe constitutional court of Spain is an ultra-rightwing joke. Imprisoning Catalan nationalist politicians for calling for independence brought that court into disrepute. I'm not keen on written constitutions, or constitutional courts . reply vdaea 15 hours agorootparentErrr, that's not exactly what they did, as well as you know :-) In any case I hope we can agree that it's good that they said that restricting our constitutional right to free movement was illegal, even if it had no consequences for those who violated our basic rights so blatantly. reply denton-scratch 14 hours agorootparentIf I'm wrong about the constitutional court sentencing Catalan nationalist politicians to prison, that's not something I know; feel free to correct me. I don't know what that has to do with free movement, nor how that's related to the imprisoned politicians. FWIW, I don't accept the notion of \"human rights\" - there are in reality only those privileges that are actually granted. I would like it if there were some kind of universally-accepted set of rights; but only if they are congruent with my own views about what \"rights\" should look like. reply vdaea 13 hours agorootparentThey did more than just \"calling for independence\". Use your search engine of choice to find out what they did. And this was not a case of a violation of \"human rights\", in which I also do not believe. During the pandemic, there was a flagrant violation of our constitutional rights, among them, the right to free movement (which very roughly means, as a Spanish citizen, I can go anywhere in Spain, whenever I want) and free assembly. The constitutional court makes sure that the constitution has teeth, or so they should. reply hkt 19 hours agorootparentprevPeople think the EU is a utopia? I just think it is the best of a bad bunch reply duxup 19 hours agoprevThis article doesn’t actually contain any information that backs up the title, or if the title is true at all. There’s a quote from some party member who doesn’t seem directly involved, and almost no information about the actual case / ruling. reply Georgelemental 17 hours agoprevA \"Court of Human Rights\" that counts Azerbaijan as a member is not a court that should be taken seriously. reply denton-scratch 17 hours agoprev [–] > The judgement cites using vulnerabilities in the target’s software or sending an implant to targeted devices as examples [of legitimate ways to defeat E2E encryption]. That looks like a bad judgement, to me; exploiting vulnerabilities, or using implants, is generally some kind of criminal hacking. So the court seems to be saying that's not OK, unless you're a government. I.e., governments don't have to obey the law. There are quite a few EU governments that would prefer not to have to comply with the law. Every EU government gets to plant a judge on the ECHR bench. reply denton-scratch 16 hours agoparent [–] > Every EU government gets to plant a judge on the ECHR bench. Every EU Council member? Not sure why I was downvoted, because the downvoters didn't care to comment. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The European Court of Human Rights has issued a ban on the weakening of secure end-to-end encryption, directly impacting the European Union's plans for mass surveillance.",
      "This ruling is significant as it safeguards individuals' privacy and security by ensuring the protection of their encrypted communications.",
      "The decision effectively puts an end to the EU's intentions of implementing widespread surveillance measures."
    ],
    "commentSummary": [
      "The European Court of Human Rights has ruled that forcing individuals to decrypt encrypted communications violates their privacy rights.",
      "The court also expressed doubts about the idea of weakening encryption for all users.",
      "This ruling may have implications for the UK government's Online Safety Bill, which aims to regulate online platforms.",
      "Governments can temporarily suspend the right to privacy in emergency situations.",
      "The discussion includes topics like parliamentary sovereignty, the need for a written constitution, judicial review, the power of the Supreme Court, and the influence of international and EU law in different countries.",
      "The debate also touches upon the relevance of encryption, the jurisdiction of the European Court of Human Rights, and the balance between privacy and law enforcement."
    ],
    "points": 1519,
    "commentCount": 229,
    "retryCount": 0,
    "time": 1707918285
  },
  {
    "id": 39373327,
    "title": "Nginx Developer Launches Freenginx in Response to Changes in Security Policy",
    "originLink": "https://mailman.nginx.org/pipermail/nginx-devel/2024-February/K5IC6VYO2PB7N4HRP2FUQIBIBCGP4WAU.html",
    "originBody": "announcing freenginx.org Maxim Dounin mdounin at mdounin.ru Wed Feb 14 18:03:11 UTC 2024 Previous message (by thread): [nginx] release-1.25.4 tag Next message (by thread): announcing freenginx.org Messages sorted by: [ date ] [ thread ] [ subject ] [ author ] Hello! As you probably know, F5 closed Moscow office in 2022, and I no longer work for F5 since then. Still, we’ve reached an agreement that I will maintain my role in nginx development as a volunteer. And for almost two years I was working on improving nginx and making it better for everyone, for free. Unfortunately, some new non-technical management at F5 recently decided that they know better how to run open source projects. In particular, they decided to interfere with security policy nginx uses for years, ignoring both the policy and developers’ position. That’s quite understandable: they own the project, and can do anything with it, including doing marketing-motivated actions, ignoring developers position and community. Still, this contradicts our agreement. And, more importantly, I no longer able to control which changes are made in nginx within F5, and no longer see nginx as a free and open source project developed and maintained for the public good. As such, starting from today, I will no longer participate in nginx development as run by F5. Instead, I’m starting an alternative project, which is going to be run by developers, and not corporate entities: http://freenginx.org/ The goal is to keep nginx development free from arbitrary corporate actions. Help and contributions are welcome. Hope it will be beneficial for everyone. -- Maxim Dounin http://freenginx.org/ Previous message (by thread): [nginx] release-1.25.4 tag Next message (by thread): announcing freenginx.org Messages sorted by: [ date ] [ thread ] [ subject ] [ author ] More information about the nginx-devel mailing list",
    "commentLink": "https://news.ycombinator.com/item?id=39373327",
    "commentBody": "Freenginx: Core Nginx developer announces fork (nginx.org)868 points by bkallus 15 hours agohidepastfavorite336 comments sevg 14 hours agoWorth noting that there are only two active \"core\" devs, Maxim Dounin (the OP) and Roman Arutyunyan. Maxim is the biggest contributor that is still active. Maxim and Roman account for basically 99% of current development. So this is a pretty impactful fork. It's not like one of 8 core devs or something. This is 50% of the team. Edit: Just noticed Sergey Kandaurov isn't listed on GitHub \"contributors\" because he doesn't have a GitHub account (my bad). So it's more like 33% of the team. Previous releases have been tagged by Maxim, but the latest (today's 1.25.4) was tagged by Sergey. reply 687m786m78 14 hours agoparentIt is scary to think about how much of web relies on projects maintained by 1 or 2 people. reply ironmagma 14 hours agorootparentNot that scary when you remember there are some systems that haven't been significantly updated for decades (e.g. the Linux TTY interface). A lot of stuff can just coast indefinitely, you'll get quirks but people will find workarounds. Also this is kind of why everything is ever so slightly broken, IMHO. reply Gormo 13 hours agorootparent> Also this is kind of why everything is ever so slightly broken, IMHO. OTOH, things that update too often seem to be more than slightly broken on an ongoing basis, due to ill-advised design changes, new bugs and regressions, etc. reply rtpg 1 hour agorootparentThe problem with bug full updating software is usually that they don’t release changes fast enough, ironically. Apple routinely holds back changes for a .0 release for advertising reasons. This means that they routinely have big releases that break everything at once. Bugs could come from 4 or 5 different sets of changes. But if they spread out changes… bug sources would be way more easy to identify. And bug fix velocity going up could mean people stop treading water on bugs, and actually get to making changes to avoid entire classes of bugs! Instead, people think the way to avoid bugs is to avoid updates, or do it all at once. This leads to iOS .0 releases being garbage, users of non-rolling release Linux distros to have bugs in their software that were fixed upstream years ago, and ultimately to make it harder to actually fix bugs. reply ironmagma 13 hours agorootparentprevI am thinking with things that don't update often, we just get used to the broken parts. People learned to save every five minutes in Maya since the app crashes so often, for example. Every now and then, a PuTTY session will fill the screen with \"PuTTYPuTTYPuTTYPuTTYPuTTY[...]\" but it's been that way for at least 20 years, so it's not that remarkable. reply lmz 9 hours agorootparentThe \"PuTTY\" string is because a program sent it ^E: https://the.earth.li/~sgtatham/putty/0.67/htmldoc/Chapter4.h... reply indigodaddy 3 hours agorootparentprevWhen I was in Systems/Linux Operations you wouldn’t believe how many tickets from other internal teams we supported that said “Putty is down” in the title. It never ceased to make me chuckle every single time. reply sitzkrieg 10 hours agorootparentprevtangent but i havent seen that happen on any of my putty clients in years and i use it everyday, so i think that finally got fixed? or maybe was a side effect of something stupid reply ikt 3 hours agorootparentnext question: why are people still using putty reply toast0 2 hours agorootparentPutty met my needs in 2004 and my needs haven't changed. It still works as good in 2024. I'm not 100% sure when I started using putty, but I definitely used it in 2004. I still need a ssh client and terminal emulator for Windows. I still don't want to install a unix like environment just to have a terminal. I still don't want tabs in my terminal, lots of windows works just fine. I still need X11 forwarding so I can run programs on remote systems and display them on Windows (VcXsrv is an easier to get going X server than others I've used on Windows). I might like to have something that can do whatever magic so I can gcloud and aws auth on my remote machine without cutting and pasting giant urls and auth blobs to and fro all the time; but I'm using a auth token that needs to stay connected to the windows machine. In a more integrated corp environment this would probably be keberos/active directory/magic? reply baq 1 hour agorootparentThe difference in 2024 is that windows ships openssh client and server as a built-in optional component and it also ships a workable terminal emulator. No WSL needed in either case. (But yeah I'm still using putty, too) reply geraldhh 23 minutes agorootparentsame. if i want a term, it's putty. windows shell and builtin ssh is a backup for when i am working from a foreign system reply laxis96 2 hours agorootparentprevBecause Windows does not have a good SSH implementation and PuTTY has always worked extremely well for me as a serial and SSH terminal (also, it starts up instantly and never crashed on me). Are there any better alternatives? reply janosdebugs 1 hour agorootparentDoesn't Windows ship OpenSSH these days? reply n_plus_1_acc 2 hours agorootparentprevMany people I know just use SSH from the WSL CLI. reply xorcist 48 minutes agorootparentThat's a very limited terminal in terms of capabilities. Then there's things like x11-style copy-paste. reply LoganDark 2 hours agorootparentprevPuTTY is from before WSL, and old habits die hard. reply nolongerthere 2 hours agorootparentprevWindows 10 natively supports SSH as far as I can tell, I don’t use it a ton, but haven’t had any issues just typing ssh username@domain reply oblio 2 hours agorootparentprevThey're used to it, tutorials online recommend it, admins install it out of inertia, some places have old Windows versions, etc. reply yjftsjthsd-h 13 hours agorootparentprevThat only helps if it stays static. For example, if the Linux TTY interface was unchanged for decades to such a degree that nobody worked on it, but then had a vulnerability, who would be able to fix it quickly? reply korhojoa 2 hours agorootparentThis already happened with the kernel console, no more scrollback. https://security.snyk.io/vuln/SNYK-UNMANAGED-TORVALDSLINUX-3... reply ironmagma 13 hours agorootparentprevPerhaps someone with more knowledge can chime in. But, my impression is that there are vulnerabilities with TTY, it's just that we stay educated on what those are. And we build systems around it (e.g. SSH) that are secure enough to mitigate the effects of those issues. reply codetrotter 12 hours agorootparentSSH was a replacement for Telnet. But any weaknesses at the TTY level is orthogonal to that, right? Unless you mean, having thin clients use SSH as opposed to directly running serial cables throughout a building to VT100 style hardware terminals, and therefore being vulnerable to eavesdropping and hijacking? But I think when we talk about TTY we mostly don’t refer to that kind of situation. If someone talks about TTY today, I assume they mean the protocol and kernel interfaces being used. Not any kind of physical VT100 style serial communication terminals. reply tingletech 10 hours agorootparentI miss rooms of green and amber screen terminals hooked up via serial cable. As an undergrad I remember figuring out how to escape from some menu to a TTY prompt that I could somehow telnet to anywhere from. Later, I would inherit a fleet of 200 of them spread across 12 branch libraries. I can't remember how it worked except that somehow all the terminals ran into two BSDi boxes in the core room of the central library, and it had been hardened so you could not break out of the menus and telnet to arbitrary places. Over a year I replaced them all with windows machines that ran version of netscape navigator as the shell with an interface that was built in signed javascript. It was the early days of the web, and we had to support over 300 plug ins for different subscriptions we had. The department that ran the campus network didn't want to let me on the network until I could prove to them everything was secure. reply ciceryadam 10 hours agorootparentprevSSH was a replacement for RSH, not telnet. reply hnfong 8 hours agorootparentThis was on HN two(?) days ago: https://news.ycombinator.com/item?id=39313170 > I wrote the initial version of SSH (Secure Shell) in Spring 1995. It was a time when telnet and FTP were widely used. > Anyway, I designed SSH to replace both telnet (port 23) and ftp (port 21). Port 22 was free. It was conveniently between the ports for telnet and ftp. I figured having that port number might be one of those small things that would give some aura of credibility. But how could I get that port number? I had never allocated one, but I knew somebody who had allocated a port. Emphasis mine. Cheers. reply quesera 6 hours agorootparentprevWhere does this idea come from? I see it repeated a lot, but it's not correct. rsh was common on internal networks, but almost never used on the wider Internet. telnet was everywhere all across the net. ssh was a revelation and it replaced telnet and authenticated/non-anonymous ftp primarily. And also sometimes rsh, but less importantly. reply xorcist 29 minutes agorootparentHow could it be incorrect? rsh was clearly modelled after rlogin, and ssh was clearly modelled after rsh. The command line options were almost identical for an easy switch. ssh even respected the .rhosts file! Last time I checked, that functionality was still in place. Both the rlogin-family of commands and the telnet/ftp-family were in use across the Internet, certainly in cases where Kerberos was used. I would think telnet was more common, certainly so outside the UNIX sphere of influence, but things like Kermit also existed. They all got SSL-encapsulated versions in time, but Kerberos solved authentication for free, and for the simpler use cases ssh had already taken over by then. And in the longer run, simple almost always wins! reply TylerE 12 hours agorootparentprevI wonder how many of these things that are just coasting are gonna have issues in 14 years. reply the_duke 13 hours agorootparentprevNginx is still evolving a lot though. Eg: http3 support was stabilized with 1.25.1 , which came out June 2023. reply stusmall 10 hours agorootparentprevThis isn't one though. I think the issue he is talking about is around the CVEs that came out with the HTTP3 implementation. This is an area of very active and complex development. reply szundi 13 hours agorootparentprevNot the web though reply ironmagma 13 hours agorootparentCertainly the web can mostly coast indefinitely. There are webpages from decades ago that still function fine, even that use JavaScript. The web is an incredibly stable platform all things considered. In contrast, it's hard to get a program that links to a version of Zlib from 10 years ago running on a modern Linux box. reply KronisLV 10 hours agorootparent> Certainly the web can mostly coast indefinitely. I'm not sure about that, for anything besides static resources, given the rate at which various vulnerabilities are found at and how large automated attacks can be, unless you want an up to date WAF in front of everything to be a pre-requisite. Well, either that or using mTLS or other methods of only letting trusted parties access your resources (which I do for a lot of my homelab), but that's not the most scalable approach. Back end code does tend to rot a lot, for example, like log4shell showed. Everything was okay one moment and then BOOM, RCEs all over the place the next. I'm all for proven solutions, but I can't exactly escape needing to do everything from OS updates, to language runtime and library updates. reply 5- 12 hours agorootparentprevthis problem -- great forward compatibility of the web -- has been taken care of with application layer encryption, deceitfully called \"transport layer\" security (tls) reply quickthrower2 13 hours agorootparentprevThe web is the calm looking duck that is paddling frantically. You want to be using SSL from the 90s, or IE vs. Netscape as your choice etc. Nostalgia aside! reply colechristensen 13 hours agorootparentprevHTTP 1.1 isn’t really changing is it? That and a small collection of other things are standards based and not going though changes. reply mynameisvlad 13 hours agorootparentSure, but HTTP3 was proposed in 2022. reply ndriscoll 10 hours agorootparentYeah but you can just continue to use HTTP/1.1, which is simpler and works in more scenarios anyway (e.g. doesn't require TLS for browsers to accept it). reply jupp0r 8 hours agorootparentYou could have stayed with HTTP/1.0 as well. Or Gopher. reply dual_dingo 24 minutes agorootparentWithout HTTP/1.1 either the modern web would not have happened, or we would have 100% IPv6 adapation by now. The Host header was such a small but extremely impactful change. I believe that without HTTP/3, nothing much would change for the majority of users. reply whatever1 7 hours agorootparentprevMeanwhile my anaconda installation died after a casual apt-get update lol I now believe that every piece of software should be shipped as a container to avoid any system library dependencies. reply ironmagma 5 hours agorootparentThat is what Snap is for, but there are… issues reply 1vuio0pswjnm7 10 hours agorootparentprevIME, the best software is written by \"1 or 2\" people and the worst software is written by salaried teams. As an end user, it's only the encroachment by the later that scares me. reply BigJono 5 hours agorootparentYep. IME the only way to make a salaried team of 10 devs work efficiently is to have enough work that you can split it cleanly into 5-10 projects that 1-2 people can own and work on autonomously. Too bad every team I've ever worked on as a consultant does the opposite. The biggest piles of shit I've ever seen created have all been the product of 10 people doing 2 people's worth of work... reply cryptonym 5 hours agorootparentOn one hand projects developed by 2 passionate devs ; on the other hand a team of entry to mid level devs working on someone else's project for the money. That team changes every 6 month when another company offers more money. If only one or two people are working on a project, that's a high risk for the company. If you got one or two highly skilled people in that team of 10, you are lucky. Managers don't want them to work alone on their project, they want them to help the team grow. reply EasyMark 13 hours agorootparentprevI don't worry when it's open source, as if it's that valuable someone will pick it up, or corps would be forced to. I do wish those 1 or 2 devs got more support monetarily from the huge corps benefitting. reply Thaxll 13 hours agorootparentprevFor the vast majority of use cases nginx from 10 years ago would not make a difference. You actually see the nginx version on some html pages and very often it's old. reply DarkmSparks 11 hours agorootparentnginx from 5 years ago has some pretty nasty actively exploited CVEs. reply phkahler 10 hours agorootparentprev>> It is scary to think about how much of web relies on projects maintained by 1 or 2 people. This is one reason maintainability is very important for the survival of a project. If it takes an extra person to maintain your build system or manage dependencies or... or... it makes it all the more fragile. reply akira2501 8 hours agorootparentprevHTTP/1, HTTP/2 and HTTP/3 are huge standards that were developed, considered and separately implemented by hundreds of people. It's built in C which has an even more massive body of support through the standard, the compilers, the standard libraries, and the standard protocols it's all implemented on. 1 or 2 people maintain one particular software implementation of some of these standards. It's interesting to think of what a large and massive community cheap and reliable computation and networking has created. reply azinman2 3 hours agorootparentI mean at that point you might as well talk about the people building microchips and power plants. You can always abstract down, but you're ignoring the fact that nginx is ~250k very important LOC with huge impact on the world. That is non-trivial in its own right. reply rurban 3 hours agorootparentprevNot scary at all. I think much better of such projects compared to ill-functioning multi-people projects which get worse and worse over time. reply ozim 6 hours agorootparentprevIt is also why companies don’t buy SaaS services from single founders or small companies where risk of key people leaving is high impact. reply kjellsbells 4 hours agorootparentExpand on that comment for me, because it has high impact. I dont doubt the surface logic, but the implication is that to succeed in B2B SaaS, you _must_ be sufficiently well funded to have a decently sized staff team. That is, there are no organic 2 person startups in B2B SaaS. Is that really true? (Obviously once bigco buys such a startup's offering, that startup needs to hire, fast) reply ozim 9 minutes agorootparentYou probably can get your foot in with $500 a month recurring payment if some dev/employee wants to do or try out stuff and his manager puts in credit card. But that is peanuts and for me basically no difference than B2C and that is not something you can put on \"customers that trusted us\" banner on your landing page. If you want big company to rely on your services and have 50-100 users each seat paid $500 a month form a single company, that is not just some manager swiping CC and for that you have to have a team and business continuity. reply maxamillion 12 hours agorootparentprevEvergreen xkcd is evergreen. https://xkcd.com/2347/ reply hadlock 14 hours agorootparentprevThis is your semi-annual reminder to fork and archive offline copies of everything you use in your stack. reply Dylan16807 13 hours agorootparentThere's plenty of copies of the code. That doesn't help with the actual problems with the setup. reply jackcviers3 13 hours agorootparentprevIt's not that scary. If a project everyone depends on is broken and unmaintained, someone else will manufacture a replacement fairly quickly and people will vote with their feet. NGINX is the de facto standard today, but I can remember running servers off apache when I began professionally programming. I remember writing basic cross-broweser spas with script.aculous, and prototypejs in 2005, before bundlers and react and node. Everything gets gradually replaced, eventually. reply syslog 13 hours agorootparentI still deploy Apache httpd, because that’s what I know best, and it works. reply yard2010 2 hours agorootparentprevBest memberberries ever reply quickthrower2 13 hours agorootparentprevYou can also probably host without a reverse proxy. Also there are alternatives like Caddy. IIS!! And I imaging the big cloud would swoop in and help since their expensive CDNs and gateways will rely on it, or maybe Kubernetes maintainers, since most likely they use it. reply devwastaken 9 hours agorootparentprevThat's why they work well. Not corrupted by corporate systems or group governance. Individuals have better vision and take responsibility. reply Waterluvian 9 hours agorootparentprevI think if 2 people designed most of the world’s water treatment plants, that’s not scary. If 2 people are operating the plants, that’s terrifying. reply mrtksn 13 hours agorootparentprevObligatory XKCD: https://xkcd.com/2347/ reply up2isomorphism 11 hours agorootparentprevnext [4 more] [flagged] efreak 9 hours agorootparent0000? reply mike_hock 9 hours agorootparentAnd physical access to the football. reply ARandomerDude 11 hours agorootparentprevHad a nuclear launch code. He doesn’t remember it anymore. reply nimbius 12 hours agoparentprev>freenginx.org IANAL, but i strongly recommend reconsidering the name as the current one contains a trademark. reply tiffanyh 11 hours agorootparentThey could take the Postgres naming approach. Ingress was forked; the Post fork version of Ingress was called \"Post\"gres. So maybe name this new project \"PostX\" (for Post + nginx). Though that might sound too similar to posix. reply Nijikokun 11 hours agorootparentPostgres name is said to be a reference to ingres db, not a fork of ingres. > The INGRES relational database management system (DBMS) was implemented during 1975-1977 at the Univerisity of California. Since 1978 various prototype extensions have been made to support distributed databases [STON83a], ordered relations [STON83b], abstract data types [STON83c], and QUEL as a data type [STON84a]. In addition, we proposed but never prototyped a new application program interface [STON84b]. The University of California version of INGRES has been ‘‘hacked up enough’’ to make the inclusion of substantial new function extremely difficult. Another problem with continuing to extend the existing system is that many of our proposed ideas would be difficult to integrate into that system because of earlier design decisions. Consequently, we are building a new database system, called POSTGRES (POSTinGRES). [https://dsf.berkeley.edu/papers/ERL-M85-95.pdf] reply tiffanyh 9 hours agorootparentIsn't this a bit pedantic. Fork vs \"hacked up [Ingress] enough ... Consequently, building a new database system\" named Postgres. reply virtualwhys 11 hours agorootparentprev\"Postginx\" has a nice ring to it, could be an alcoholic beverage, a name of a generation, or even a web server. reply diego_sandoval 6 hours agorootparentgintonx reply agateau 50 minutes agorootparentSounds like an character from the Asterix comic book :) reply anotherhue 11 hours agorootparentprevGo roman? nginxii ? reply icybox 11 hours agorootparentprev... and postfix reply patrickmay 11 hours agorootparentprevnginy? reply austinjp 11 hours agorootparentBump each letter in nginx and we get.... ohjoy! reply skykooler 1 hour agorootparentWow, that's perfect! reply endofreach 10 hours agorootparentprevDude, please, just create a fork & explain the name. ohjoy sounds perfect and the meaning is brilliant. This must be it. reply Silasdev 10 hours agorootparentprevInsane find. Brilliant!! reply yakshaving_jgt 9 hours agorootparentprevJesus Christ. That’s incredible. reply 22c 8 hours agorootparentprevThere was also a time where ng postfix was used to denote \"next generation\", so they could go with nginxng :) reply CodeWriter23 7 hours agorootparentprevNot necessary. It’s not like F5 is going to go to Russia and file suit against any of them. reply osigurdson 5 hours agorootparentMaybe not today, but one day they might. Better to start with a workable long term name. reply thinkyfish 5 hours agorootparentprevHow about EngineF? reply ComputerGuru 14 hours agoprevThis isn’t just “a core nginx dev” — this is Maxim Dounin! He is nginx. I would consider putting his name in the title. (And if I were F5, I’d have given him anything he asked for to not leave, including concessions on product vision.) That said, I’m not sure how much leg he has to stand on for using the word nginx itself in the new product’s name and domain… reply stemc43 14 hours agoparent> not sure how much leg he has to stand on for using the word nginx itself in the new product’s name and domain pretty sure they can't really do anything to him in Russia. Russia and US don't recognize each others patents, same as China. reply nicolas_17 13 hours agorootparentWhat do patents have to do with this? reply ComputerGuru 14 hours agorootparentprevIt's a .org domain, the registry is held in the USA. reply bklyn11201 14 hours agorootparentprevRight, they will just go after the domain forcing either a rename or a move to a Russian domain reply amne 14 hours agoparentprevHe *is* nginx ? https://freenginx.org/hg/nginx I don't see it. Sure, he contributes. But in the last 3-4 years he definitely does not look like he is nginx based on that log. Or am I looking in the wrong place? reply kelnos 12 hours agorootparentAnd this is why counting commits doesn't give you an accurate picture of productivity. (Regardless, if you scroll back past March 2020, the timeline \"resets\" to this past year, and you see a ton of Dounin commits. Looks like an artifact of how the hg web viewer deals with large, long-lived branches getting merged.) reply flawi 14 hours agorootparentprevI think the mercurial log is not doing us any favors here, most of the first few pages is the history of the `quic` http/3 support branch which indeed Maxim is not working on. Scroll past it and he'll be much more prevalent. See for example the log of stable-1.24: https://freenginx.org/hg/nginx/shortlog/420f96a6f7ac reply jbverschoor 14 hours agorootparentprevAnd that's how 100x developers don't get the recognition they deserve. reply hinkley 8 hours agorootparentPhilosophically, if a lead developer is doing most of the commits on a project, then they are monopolizing both the code and the decision making process, which is a sure way to kill a project. If the basketball or soccer team captain were also a ball hog, they'd have trouble keeping the bench full. When you become lead, you have to let some of the code go, and the best way I know to do it is to only put your fingers into the things that require your contextual knowledge not to fuck up. If you own more than 10% of the code at this point, you need to start gift-wrapping parts of the code to give away to other people. If you own more than 20%, then you're the one fucking up. Obviously this breaks down on a team size of 2, but then so do concerns about group and team dynamics. reply Capricorn2481 1 hour agorootparent> which is a sure way to kill a project Nginx is one of the most widely used open source projects in the world. It's hard to read this without laughing, as if it's still to be determined whether Nginx could be considered successful. reply hsbauauvhabzb 6 hours agorootparentprevI think there are problems where this will apply to, such as crud applications, and projects where deep understanding of core components makes it difficult to scale teams horizontally as it will effectively require a hive-mind. reply hinkley 2 hours agorootparentIf the 'core components' are half of the project, there's no core. It's just important and less important components. And in all likelihood if you are expecting a core competency in enough domains for the situation you reference to be true, it's because you have a bad case of NIH, you aren't concentrating your efforts in the areas your company is purportedly focused on. That makes it difficult not only to scale up a team, but also to scale it down. The first major revenue hiccup you encounter may be your last. If you are concentrating on a narrow domain you intend to be experts in, then that will be 15-25% of the code. Meaning to maintain a decent bus number, you only need to be primary on about 10%, if you have half a dozen people or so. reply bhaney 7 hours agorootparentprev> which is a sure way to kill a project Nonsense reply hinkley 2 hours agorootparentGood luck with your empire building sans team building. reply goodpoint 45 minutes agorootparentHow about we live without empires? reply ComputerGuru 14 hours agorootparentprevThere's something wrong with the list. It's ostensibly sorted reverse chronologically but scroll further and you'll see it go from 2020-03-03 to \"9 months ago\" and from there on it's all him. reply jcranmer 14 hours agorootparentJudging from the graph view (https://freenginx.org/hg/nginx/graph), it has to do with the QUIC branch landing onto the main branch, suggesting he had little role in the QUIC development but heavy role outside of it. reply EasyMark 13 hours agorootparentprevyou should have googled his name, and you would have known within seconds. I mean it's everywhere nginx is mentioned (or dev of it) reply karolist 15 hours agoprev> Unfortunately, some new non-technical management at F5 recently decided that they know better how to run open source projects. In particular, they decided to interfere with security policy nginx uses for years, ignoring both the policy and developers’ position. Ah, I completely forgot F5 was involved in this, probably most of everyone else and F5 gets no money from this. Shouldn't matter to them, do they even have competition in enterprise load balancer space? I spent 9 years of my career managing these devices, they're rock solid and I remember some anecdotes about MS buying them by the truckloads. They should be able to cover someone working on nginx, maybe advertise it more for some OSS goodwill. reply salmo 14 hours agoparentI dunno about rock solid. I’ve had plenty of issues forcing a failover/reboot, multiple complicated tickets open a year, etc. But we have a sh ton of them. To be fair, some are kernel bugs with connection table leaks, SNAT + UDP, etc. Buuuut, they have by far the best support. They’re as responsive as Cisco, but every product isn’t a completely different thing, team, etc. And they work really well in a big company used to having Network Engineering as a silo. I’d only use them as physical hardware, though. As a virtual appliance, they’re too resource hungry. Nginx or HA-Proxy are technically great for anything reasonable and when fronting a small set of applications. I prefer nginx because the config is easier to read for someone coming in behind me. But they take a modern IT structure to support because “Developers” don’t get them and “Network Engineers” don’t have a CLI. For VMWare, NSX-V HA-Proxy and NSX-T nginx config are like someone read the HOWTO and never got into production ready deployments. They’re poorly tuned and failure recovery is sloooow. AVI looked so promising, but development slowed down and seemed to lose direction post acquisition. And that was before Broadcom. Sigh. reply kevin_nisbet 13 hours agorootparentI'm very out of date so take my opinion with a grain of salt. The customer support I received from F5 when they acquired a telco product was about the worst support I've ever seen. Now this wasn't the general LB equipment that F5 has the reputation around, it's some specific equipment for LTE networks. We'd get completely bogus explanations for bugs, escalate up the chain to VPs and leadership because there was an obvious training, understanding, and support for complex issues problem, and get the VPs trying to gaslight us into believing their explanations were valid. We're talking things like on our IPv4 only network, the reason we're having issues is due to bugs in the equipment receiving IPv6 packets. So it's one of those things where I've personally been burned so hard by F5 that I'd probably to an unreasonable level look for other vendors. The only thing is, this was awhile ago, and the rumor's I've heard are that no one involved is still employed by F5. reply salmo 13 hours agorootparentI completely get this. I feel like every product I’ve had outside of a vendor’s wheelhouse has gone that way. We just use the BigIP gear from F5 and they’re better than the load balancers we used in the past. Thank god Cisco just abandoned that business. I can’t imagine them supporting telco gear. The IPv6 thing has me LOLing because I just had a similar experience with a vendor where we don’t route IPv6 in that segment and even if we did, it shouldn’t break. Similarly, a vendor in a space they don’t belong that I imagine we bought because of a golf game. A thing I dread is a product we’ve adopted being acquired… and worse, being acquired by someone extending their brand into a new area. It’s also why we often choose a big brand over a superior product. It’s not the issue of today, but when they get bought and by who. I hate that so much and not my decision, but it’s a reality. It’s also a terrible sign if you’re dealing with a real bug and you’re stuck with a sales engineer and can’t get a product engineer directly involved. I have a list of “thou shalt not” companies as well, and some may be similar where a few bad experiences ruined the brand for me. Some we’re still stuck with and I maaaay be looking for ways to kill that. reply karolist 13 hours agorootparentprevWhen was this? I worked with them 2009-2018, support was really top notch. We could get super technical guys on the call and even custom patches for our issues, but our usage was relatively simple. I contrast them with McAfee products we've used, now that was a complete shitshow as a product and support. reply SteveNuts 15 hours agoparentprevThe last two companies I've worked for have paid for Nginx+ since software LB is all we really need. Handling a few thousand RPS is nothing to nginx, and doesn't require fancy hardware. That said, it replaced Kemp load balancers, which it seems is the next biggest competitor in the hardware load balancer appliance space. reply karolist 14 hours agorootparentThe world has moved on in the sense that \"good enough\" and cloud eats into their balance sheets I'm sure, but there's loads and loads of banks and legacy enterprises that maintain their ivory tower data centers and there's nothing to replace these with AFAIK. Google has Maglev, AWS perhaps something similar, MS no idea, everyone else just buys F5 or doesn't need it. reply jvolkman 14 hours agorootparentAmazon used to run entirely behind Citrix NetScaler hardware; no F5 at all. This was back in the early 2010s so I assume things have changed by now. reply doormatt 14 hours agorootparentYup - there was a massive internal push to move off of SSL terminating LBs back in ~2018 reply martinohansen 14 hours agorootparentHow come? reply doormatt 11 hours agorootparentCost. Now, SSL termination is done at the host level, using a distributed SSL termination proxy developed by S3 called \"JBLRelay\" reply JackSlateur 14 hours agorootparentprevLots of people are using haproxy reply eddieroger 13 hours agorootparentMy org moved off nginx for haproxy after we learned that (at the time, maybe it changed) reloading an nginx config, even if done gracefully through kernel signals, would drop existing connections, where haproxy could handle it gracefully. That was a fun week of diving in to some C code looking for why it was behaving that way. reply nullify88 12 hours agorootparentHow did you come to that conclusion? I always believed a reload spawned new workers and let the old one drain off. reply CogitoCogito 8 hours agorootparentYes I reload nginx all the time and it doesn’t drop connections. I just use the debian nginx package. Not sure what the gp is talking about. reply zetsurin 10 hours agorootparentprevwe went in the opposite direction, not because haproxy was bad, just because nginx had a simpler config, and i think we were paying for haproxy but don't pay for nginx. all that said, neither drops existing connections on reload reply jamespwilliams 10 hours agorootparentprevnginx supports graceful reloading and I’m pretty sure it has for a very long time - there are references to it in the changelog from 2005 https://nginx.org/en/docs/control.html reply yakshaving_jgt 9 hours agorootparentprevAnother issue with nginx IIRC is that it allows HTTP request smuggling, which is a critical security vulnerability. reply downrightmike 14 hours agorootparentprevAVI if you're using VMware already reply bkallus 13 hours agorootparentI'm pretty sure that AVI just wraps Nginx, even though they claim otherwise. I think this because Nginx has a bunch of parsing quirks that are shared with AVI and nothing else. reply reactordev 14 hours agoparentprevHAProxy is an enterprise load balancer that's available through Red Hat or other OSS Vendor. Nginx is just so easy to configure... reply bklyn11201 14 hours agorootparentHAProxy is a wonderful load balancer that doesn't serve static files thus forcing many of us to learn Nginx to fill the static-file-serving scenarios. Caddy seems like a wonderful alternative that does load balancing and static file serving but has wild config file formats for people coming from Apache/Nginx-land. reply LinuxBender 12 hours agorootparentJust for completeness sake and probably not useful to many people, HAProxy can serve a limited number of static files by abusing the back-end and error pages. I have done this for landing pages, directory/table of content pages. One just makes a properly configured HTTP page that has the desired HTTP headers embedded in it and then configure it as the error page for a new back-end and use ACL's to direct specific URL's to that back-end. Then just replace any status codes with 200 for that back-end. Probably mostly useful to those with a little hobby site or landing page that needs to give people some static information and the rest of the site is dynamic. This reduces moving parts and reduces the risk of time-wait assassination attacks. This method is also useful for abusive clients that one still wishes to give an error page to. Based on traffic patterns, drop them in a stick table and route those people to your pre-compressed error page in the unique back-end. It keeps them at the edge of the network. reply TimWolla 11 hours agorootparentFYI: Serving static files is easier and more flexible in modern versions of HAProxy via the `http-request return` action [1]. No need to abuse error pages and no need to embed the header within the error file any longer :-) You even have some dynamic generation capabilities via the `lf-file` option, allowing you to embed e.g. the client IP address or request ID in responses. [1] https://docs.haproxy.org/dev/configuration.html#4.4-return Disclosure: I'm a community contributor to HAProxy. reply LinuxBender 11 hours agorootparentNice, I will have to play around with that. I admit I sometimes get stuck in outdated patterns due to old habits and being lazy. I'm a community contributor to HAProxy. I think I recall chatting with you on here or email, I can't remember which. I have mostly interacted with Willy in the past. He is also on here. Every interaction with HAProxy developers have been educational and thought provoking not to mention pleasant. reply TimWolla 11 hours agorootparent> I think I recall chatting with you on here or email, I can't remember which. Could possibly also have been in the issue tracker, which I did help bootstrapping and doing maintenance for quite a while after initially setting it up. Luckily the core team has took over, since I had much less time for HAProxy contributions lately. reply mholt 13 hours agorootparentprevThat's the best part -- you can choose your config format when using Caddy! https://caddyserver.com/docs/config-adapters reply bklyn11201 13 hours agorootparentTrue and I've made use of the Nginx adapter, but the resulting series of error messages and JSON was too scary to dive in further. The workflow that would make the most sense to me (to exit Nginx-world) would be loading my complex Nginx configs (100+ files) with the adapter, summarizing what could not be interpreted, and then writing the entirety to Caddyfile-format for me to modify further. I understand that JSON to Caddyfile would be lossy, but reading or editing 10k lines of JSON just seems impossible and daunting. reply mholt 13 hours agorootparentThanks for the feedback, that's good to know. reply Piraty 13 hours agorootparentprev> but has wild config file formats for people coming from Apache/Nginx-land. stockholm syndrome reply philsnow 2 hours agorootparentthe syntax of nginx configs might not be hard, but its semantics (particularly [0]) is eldritch evil I don't relish dealing with [0] https://www.nginx.com/resources/wiki/start/topics/depth/ifis... reply Scramblejams 12 hours agorootparentprevI can see that. But for me, I was so very relieved to no longer deal with Apache config files after switching to Caddy. reply dingnuts 13 hours agorootparentprevI keep a Caddy server around and the config format is actually much, much nicer than nginx's in my experience. The main problem with it is that everybody provides example configurations in the nginx config format, so I have to read them, understand them, and translate them. This works for me because I already knew a fair bit about nginx configuration before picking up Caddy but it really kills me to see just how many projects don't even bother to explain the nginx config they provide. An example of this is Mattermost, which requires WebSockets and a few other config tweaks when running behind a reverse proxy. How does Mattermost document this? With an example nginx config! Want to use a different reverse proxy? Well, I hope you know how to read nginx configuration because there's no English description of what the example configuration does. Mastodon is another project that has committed this sin. I'm sure the list is never-ending. reply mholt 13 hours agorootparent> The main problem with it is that everybody provides example configurations in the nginx config format, so I have to read them, understand them, and translate them. This is so real. I call it \"doc-lock\" or documentation lock-in. I don't really know a good scalable way to solve this faster than the natural passage of time and growth of the Caddy project. reply CoolCold 2 hours agorootparent> This is so real. I call it \"doc-lock\" or documentation lock-in. I don't really know a good scalable way to solve this faster than the natural passage of time and growth of the Caddy project. I think you are totally right here - gaining critical mass over the time for battle tested solution. On the other hand, the authors [who prefers Caddy] of docs will likely abandon providing Nginx configs sample and someone else will complain on that on HN. \"Battle tested\" can be seen differently of course, but in my opinion, things like the next one, > IMO most users do require the newer versions because we made critical changes to how key things work and perform. I cannot in good faith recommend running anything but the latest release. from https://news.ycombinator.com/item?id=36055554 , by someone working at Caddy doesn't help. May be in their bubble (can I say your bubble as you are from Caddy as well?) noone really cares on LTS stuff and just use \"image: caddy:latest\" and everything is in containers managed by dev teams - just my projection on why it may be so. reply reactordev 13 hours agorootparentprevLLMs baby! Input nginx config, output caddy config. Input nginx docs, output caddy docs. Someone get on this and go to YC. reply bklyn11201 13 hours agorootparentYou're absolutely right. I'm going to do this today. It's clear from this thread that a) Nginx open source will not proceed at its previous pace, b) the forks are for Russia and not for western companies, and c) Caddy seems like absolutely the most sane and responsive place to move. reply francislavoie 13 hours agorootparentprevLLMs do a horrendous job with Caddy config as it stands. It doesn't know how to differentiate Caddy v0/1 config from v2 config, so it hallucinates all kinds of completely invalid config. We've seen an uptick of people coming for support on the forums with configs that don't make any sense. reply eropple 11 hours agorootparentFor just blasting a config out, I'm sure there are tons of problems. But (and I have not been to your forums, because...the project just works for me, it's great!) I've had a lot of success having GPT4 do the first-pass translation from nginx to Caddy. It's not perfect, but I do also know how to write a Caddyfile myself, I'm just getting myself out of the line-by-line business. reply m_sahaf 4 hours agorootparentYou could've used the nginx-adapter and skip the faulty LLMs https://github.com/caddyserver/nginx-adapter reply CoolCold 5 hours agorootparentprevHow would you imagine this in practice? Should one to provide instructions how to unwrap docker images/dockerfiles project uses (quite many do lean on Docker/Containers nowadays and not regular system setup) to for example setup the same on FreeBSD Jails? Where to stop here? reply kelnos 12 hours agorootparentprevA load balancer shouldn't serve static files. It shouldn't serve anything. It should... load balance. I can see why you'd want an all-in-one solution sometimes, but I also think a single-purpose service has strengths all its own. reply CoolCold 5 hours agorootparentQuite intersting - in theory, \"pure\" load balancer shouldn't not, but in practice most of my LBs, especially for small projects do. Even for larger projects I do combine proxy_cache on LB making it serve static files or using to serve websites public content and splitting load over several application servers for dynamic content. And I think it's fine. reply apatheticonion 12 minutes agoprevMy biggest gripe as an internet keyboard warrior with an opinion is not being able to understand the source control and build process of Nginx. Probably a skill issue but when I last tried to compile Nginx from the Github mirror I spent hours trying to figure it out. I wish there was a GitHub page with an easy to understand build process... and that I could just run \"cargo build --release\" lol reply sschueller 14 hours agoprevIs this what the security disagreements is about https://mailman.nginx.org/pipermail/nginx-announce/2024/NW6M...? reply MZMegaZone 14 hours agoparentYep. Maxim did not want CVEs assigned. reply lolinder 8 hours agorootparentIt would be worth flagging in this comment that you represent F5. I didn't realize that until I found your other comment below. reply ddxv 13 hours agorootparentprevWhy wouldn't he want CVEs assigned? reply mholt 13 hours agorootparentI haven't read the content of the patches to understand the impact of the bugs, but from my own experience [0] I can suggest a few reasons: - CVEs are gold to researchers and organizations like citations are to academics. In this case, the CVEs were filed based on \"policy\" but it's unclear if they are just adding noise to the DB. - The severity of the bug is not as severe as greater powers-that-be would like to think (again, they see it as doing due diligence; developers who know the ins and outs might see it as an overreaction). - Bug is in an experimental feature. I'm not saying one way is right or not in this case, just pointing out my experience has generally been that CVEs are kind of broken in general... [0]: https://github.com/caddyserver/caddy/issues/4775 reply TedDoesntTalk 11 hours agorootparentTo summarize: the more CVEs a \"security researcher\" can say he created on his resume, the more impressive he thinks he looks. Therefore, the incentive to file CVEs for any stupid little problem is very high. This creates a lot of noise for developers who are forced to address sometimes nonsense that are filed as \"high\" or \"critical\". reply otbutz 43 minutes agorootparentprevThe issue you linked to is an excellent example of why everyone and their dog is becoming a CNA these days. It's the only way to keep CVE spam at bay. The system has been broken by the gamification of CVEs and is in desperate need of reform. reply arp242 9 hours agorootparentprev\"Denial of service\" is never a security bug; it's a huge mistake people have started classifying these things as such to start with. Serious bug? Sure. Loss of security? Not really. reply dspillett 7 hours agorootparent> \"Denial of service\" is never a security bug That very much depends on what service is being denied. Nginx is _everywhere_. While not a direct security concern for nginx (instead an availablity issue) it could have security or safety implications for wider systems. What if knocking out nginx breaks a service for logging & monitoring security information? Or an ambulance call out management system? Or a payment progressing system for your business at the busiest time if your trading year? There are many other such examples. This sort of thing is why availablity can be considered a security matter and therefore why DoS vulnerabilities, particularly those affecting common software, are handled as security issues of significant severity. reply arp242 5 hours agorootparentAlmost every bug can be considered a security bug under the wrong set of circumstances. With fairly cheap ddos services you can \"just\" order you can knock most servers offline anyway. Internet reachability is rarely safety-critical, and if it is, that's probably a huge design flaw somewhere because there's tons of reasons outside of your control that can make the internet not work for either the server or clients. Is all of this inconvenient and (potentially) a serious problem? Sure. But not \"zomg criminals have credit card records / can spoof random domains / read private data / etc. etc.\" type serious. reply manquer 5 hours agorootparentprevWe could argue that about almost anything though . There are always secondary effects possible and sometimes even likely. I can only think of the proverb/poem - \"For want of a nail\". reply mholt 8 hours agorootparentprevEh, it's widely considered that part of security is availability. But I agree DoS is kind of a strawman since everything connected to a network is vulnerable to some form of DoS without extensive mitigation. reply tangus 13 hours agorootparentprev>The most recent \"security advisory\" was released despite the fact that the particular bug in the experimental HTTP/3 code is expected to be fixed as a normal bug as per the existing security policy, and all the developers, including me, agree on this. >And, while the particular action isn't exactly very bad, the approach in general is quite problematic. reply tptacek 13 hours agorootparentprevMegaZone as in Usenet MegaZone? reply MZMegaZone 13 hours agorootparentNo, a MegaZone. Haven't you heard, we come in six packs now. ;-) Yeah, very, very likely one and the same. Since 1989. reply tptacek 13 hours agorootparentWow, that's a throwback. I was an ISP person back in the Portmaster era. You're at F5 now, I guess! Can you say more about the CVE thing? That seems like the opposite of what Maxim Dounin was saying. reply MZMegaZone 13 hours agorootparentYeah, I've been with F5 since 2010 - gotta love those old PortMasters though, Livingston was good times, until Lucent took over. I was there 95-98. I don't know what else there is to say really. The QUIC/HTTP/3 vuln was found in NGINX OSS, which is also the basis for the commercial NGINX+ product. We looked at the issue and decided that, by our disclosure policies, we needed to assign a CVE and make a disclosure. And I was firmly in that camp - my personal motto is \"Our customers cannot make informed decisions about their networks if we do not inform them.\" I fight for the users. Anyway, Maxim did not seem to agree with that position. There wasn't much debate about it - the policy was pretty clear and we said we're issuing a CVE. And this is the result as near I can tell. Honestly, anyone could have gone to a CNA and demanded a CVE and he would not have been able to stop it. That's how it works. reply rlaager 7 hours agorootparentI don't know much about this situation, but from what I've read, you were clearly in the right. It doesn't matter if the feature is in optional/experimental code. If it's there and has a vulnerability, give it a CVE. The customers/users can choose how much they care about it from there. > Honestly, anyone could have gone to a CNA and demanded a CVE and he would not have been able to stop it. That's how it works. I recently did exactly that when a vendor refused to obtain a CVE themselves. In my case, I was doing it as part of an effort to educate the vendor on how CVEs worked. reply dgacmu 12 hours agorootparentprevOh my god, the Internet is such a small place. Good to hear you're doing well - we interacted a bit when I was running an ISP in the 90s as well. (Dave Andersen, then at ArosNet -- we ran a lot of PM2.5e and then PM3s). And appreciate the clarification about the CVE disagreement. reply MZMegaZone 6 hours agorootparentThose were great times. I learned a hell of a lot working at Livingston, because we had to. We were basically a startup selling to ISPs right as the Internet exploded and we grew like crazy. Suddenly we're doing ISDN BRI/PRI, OSPF, BGP, PCM modems, releasing chassis products (PM-4)... Real fun times, always something new happening. I even ended up our corporate webmaster since I'd been playing with web tech for a few years and thought it'd be a good idea if we had a site. Quite a way to jumpstart a career. And the customers were, by and large, great. reply kelnos 12 hours agorootparentprevOof. Presumably Dounin had other gripes about the company that had been building up? This seems like a pretty weird catalyst for a fork. Feels more like this was the last straw among many. I get that CVEs have been politicized and weaponized by a bunch of people, but it seems weird to object that strenuously to something like this. reply mholt 13 hours agorootparentprev> Honestly, anyone could have gone to a CNA and demanded a CVE and he would not have been able to stop it. That's how it works. Even if third parties can file CVEs, do you think it hits different when the parent organization decides to do so against the developer's wishes? Why do he and F5 view the bugs differently? It sounds like the fork decision was motivated less by the actual CVEs and more about how the decision was negotiated (or not at all). (PS. Thanks for participating in the discussion.) reply kayfox 12 hours agorootparentPersonally, I think its more honest if the parent org does not try to contest a CVE being assigned to a legitimate issue. If a CNA gets a report of a vulnerability in code, even if its an uncommon configuration, they should be assigning a CVE to it and disclosing it. The entire point of the CVE program is to identify with a precise identifier, the CVE, each vulnerability that was shipped in code that is generally available. Based on my observation of various NGINX forums and mailing lists, the HTTP/3 feature, while experimental, is seeing adoption by the leading edge of web applications, so I don't think it could be argued that its not being slowly rolled into production in places. reply nailer 12 hours agorootparentprev> Maxim did not want CVEs assigned. ... to this specific bug in an experimental feature. Originally I read your comment as Maxim doesn't want to use CVEs at all. reply dingnuts 13 hours agorootparentprevnext [2 more] [flagged] declaredapple 13 hours agorootparent> Nothing suspicious about that at ALL no sir nothing to see here. Yes, very suspicious that he didn't want to issue CVEs for checks notes Two DOS attacks that only apply to users that explicitly enabled experimental QUIC support (by default it's disabled) reply tiffanyh 11 hours agoparentprevI don't see anything more in that mail list thread beyond the post you linked too. Where was the disagreement hashed out, so I can read more? reply MZMegaZone 7 hours agorootparentInternally at F5 (where I work as a Principal Security Engineer in the F5 SIRT and was one of the people responsible for making the call on assigning the CVEs). reply arter4 14 hours agoprevI admit I haven't followed closely this issue, but what is he talking about? >In particular, they decided to interfere with security policy nginx uses for years, ignoring both the policy and developers’ position. reply MZMegaZone 14 hours agoparentWe (F5) published two CVEs today against NGINX+ & NGINX OSS. Maxim was against us assigning CVEs to these issues. F5 is a CNA and follows CVE program rules and guidelines, and we will err on the side of security and caution. We felt there was a risk to customers/users and it warranted a CVE, he did not. reply tky 13 hours agorootparentThis seems like a much larger story than the fork, given the install base of nginx. For clarity are you referring to CVE-2024-24989 and -24990 (HTTP/3)? reply ryukoposting 8 hours agorootparentThis is confusing. The CVE doesn't describe the attack vector with any meaningful degree of clarity, except to emphasize how you'd have to have a known unstable and non-default component enabled. As far as CVEs go, it definitely lacks substance, but it's not some catastrophic violation of best practices. It hardly reflects poorly on Maxim or anything he's done for Nginx. This seems like an extreme move, and it makes me wonder if there's something we're missing. reply MZMegaZone 13 hours agorootparentprevYes, those are the two CVEs I was referring to. All I know is he objected to our decision to assign CVEs, was not happy that we did, and the timing does not appear coincidental. reply mike_d 8 hours agorootparentQUIC in Nginx is experimental and not enabled by default. I tend to agree with him here that a WIP codebase will have bugs that might have security implications, but they aren't CVE worthy. reply MZMegaZone 7 hours agorootparentWe know a number of customers/users have the code in production, experimental or not. And that was part of decision process. The security advisories we published do state the feature is experimental. When in doubt, err on the side of doing the right thing for the users. I find that's the best approach. I don't consider CVE a bad thing - it shouldn't be treated like a scarlet letter to be avoided. It is a unique identifier that makes it easy to talk about a specific issue and get the word out to customers/users so they can protect themselves. And that's a good thing. The question I ask is \"Why not assign a CVE?\" You have to have a solid reason why not to do it, because of default is to assign and disclose. I don't think having the CVEs should reflect poorly on NGINX or Maxim. I'm sorry he feels the way he does, but I hold no ill will toward him and wish him success, seriously. reply braiamp 5 hours agorootparentWhat does policy says about reporting security issues with experimental/not-enabled-by-default/unstable code? reply arter4 2 hours agorootparentAs an outsider to this whole thing (having discovered this issue in this thread, like pretty much anyone), the CVE rules simply say that you cannot assign a CVE to vulnerabilities in a product that is not publicly available or licensable. Experimental, but publicly available features are still in scope. This makes sense IMHO: experimental features may be buggy, but they may work in your limited use case. So you may be inclined to use them...except you don't know they expose you in a critical way. reply nmjohn 14 hours agorootparentprevWhy did he not want CVE's assigned? reply MZMegaZone 13 hours agorootparentI think you'd have to ask Maxim. My take is he felt experimental features should not get CVEs, which isn't how the program works. But that's just my take - I'm the primary representative for F5 to the CVE program and on the F5 SIRT, we handle our vuln disclosures. reply Twirrim 13 hours agorootparentI'm inclined to agree with your decision to create and publish CVEs for these, honestly. You were shipping code with a now-known vulnerability in it, even if it wasn't compiled in by default. reply aaronbwebber 12 hours agorootparentif it's not compiled in by default, then you aren't shipping the code! Somebody is downloading it and compiling it themselves! reply anon-sre-srm 12 hours agorootparentIncorrect. Features available to users still require a minimum, standard level of support. This is like the deceptive misnomer of staging and test environments provided to internal users used no differently than production in all but name. reply kelnos 12 hours agorootparentprevIf the feature is in the code that's downloaded, regardless of whether or not the build process enables it by default, the code is definitely being shipped. reply anon-sre-srm 12 hours agorootparentYes. It's no different from any optional feature. Actual beta features should only be shipped in beta software . reply ramses0 11 hours agorootparentprevBRB, filing CVE's against literally any project with example code in their documentation... reply MZMegaZone 7 hours agorootparentThat's actually supported by the CVE program rules. Have at it if you find examples with security vulns. reply spicykraken 11 hours agorootparentprevI've actually seen CVEs like that before, I agree that's bonkers but I have seen it... reply numbsafari 8 hours agorootparentGiven how frequently people copy and paste example code… why is that surprising? Folks need to be informed. CVEs are a channel for that. reply mholt 7 hours agorootparentPssst: People who copy+paste example code aren't checking CVEs reply Twirrim 12 hours agorootparentprevYou and I have very different notions of \"shipped\". It's open source code, it's being made publicly available. That's shipped, as I see it. reply aaronbwebber 12 hours agorootparentThis is an insane standard and attempting to adhere to it would mean that the CVE database, which is already mostly full of useless, irrelevant garbage, is now just the bug tracker for _every single open source project in the world_. reply TedDoesntTalk 11 hours agorootparentThis. CVE has become garbage because \"security researchers\" are incentivized to file anything and everything so they can put it on their resume. reply xcrunner529 10 hours agorootparentprevWhy is it insane? The CVE goal was to track vulnerabilities that customers could be exposed to. It is used…in public, released versions. Why wouldn’t it be tracked? reply whoknowsidont 8 hours agorootparentBecause it's not actually part of the distribution unless you compile it yourself. It is not released any sense of the word. It is not even a complete feature. I am actually completely shocked this needs to be explained. Legitimate insanity. reply MZMegaZone 7 hours agorootparentYou're all also missing the fact that the vuln is also in the NGINX+ commercial product, not just OSS. Which has a different release model. Being the same code it'd be darn strange to have the CVE for one and not the other. We did ask ourselves that question and quickly concluded it made no sense. reply statquontrarian 26 minutes agorootparent\"made no sense\" from a narrow, CVE announcement perspective, but Maxim disagrees from another perspective: > [F5] decided to interfere with security policy nginx > uses for years, ignoring both the policy and developers’ position. > > That’s quite understandable: they own the project, and can do > anything with it, including doing marketing-motivated actions, > ignoring developers position and community. Still, this > contradicts our agreement. And, more importantly, I no longer able > to control which changes are made in nginx within F5, and no longer > see nginx as a free and open source project developed and > maintained for the public good. I'm not sure what \"contradicts our agreement\" means but the simple interpretation is that he feels that F5 have become too dictatorial to the open source project. The whole drama seems very short-sighted from F5's perspective. Maxim was working for you for free for years and you couldn't find some middle ground? I imagine there could have been some page on the free nginx project that listed CVEs that are in the enterprise product but that are not considered CVEs for the open source project given its stated policy of not creating CVEs for experimental features, or something like that. To nuke the main developer, cause this rift in the community, and create a fork seems like a great microcosm of the general tendency of security leads to wield uncompromising power. I get it. Security is important. But security isn't everything and these little fiefdoms that security leads build up are bureaucratic and annoying. I hope you understand that these uncompromising policies actually reduce security in the end because 10X developers like Maxim will start to tend to avoid the security team and, in the worst case, hide stuff from their security team. I've seen this play out over and over in large corporations. In that sense, the F5 security team is no different. But there should be a collaborative, two-way process between security and development. I'm sure security leads will say that they have that, but that's not what I find. Ultimately, if there's an escalation, executives will side with the security lead, so it is a de facto dictatorship even if security leads will tend to avoid the nuclear option. But when you take the nuclear option, as you did in this case, don't be surprised by the consequences. Twirrim 8 hours agorootparentprevIt's in the published source code, as a usable feature, just flagged as experimental and not compiled by default. It's not like this is some random development branch. It's there, to be used en route to being stable. People will have downloaded a release tagged version of the source code, compiled that feature in and used it. By what definition is that not shipped? > I am actually completely shocked this needs to be explained. Legitimate insanity. Right back at you. reply whoknowsidont 7 hours agorootparent>just flagged as experimental and not compiled by default Are UML diagrams considered in scope too? reply arter4 3 hours agorootparentUML diagrams are not code. You cannot file a CVE for something that is not an actual (software or hardware) implementation. reply YetAnotherNick 3 hours agorootparentprev> to be used en route to being stable Where did you get this info? It might be the feature is actively being worked on and the DoS is a known issue which would be fixed before merge. Lot of projects have contrib folder for random scripts and other things which wouldn't get merged before some review but users are free to run the script if they want to. Experimental compile time build flags are experimental by definition. reply xcrunner529 7 hours agorootparentprevI guess a vulnerability doesn’t count unless it’s default lol. Just don’t make it default and you never have any responsibility nor does those who use it or use a vendor version that has added it in their product. reply whoknowsidont 7 hours agorootparent>I guess a vulnerability doesn’t count unless it’s default lol. It's still being tested. It's not complete. It's not released. It's not in the distribution. The amount of people that have this feature in the binary AND enabled is less than the amount of people that agree that this should be a CVE. CVE's are not for tracking bugs in unfinished features. reply droopyEyelids 12 hours agorootparentprev(not explicitly asking you, MZMegaZone) Does anyone understand why a disagreement about this would be worth the extra work in forking the project? I'm not very familiar with the implications, so it seems like a relatively fine hair to split- as though the trouble of dealing with these as CSV would be less than the extra work of forking. reply kelnos 12 hours agorootparentIt probably wasn't. There's likely something else going on. Either Dounin had already decided to fork for other reasons, and the timing was coincidental, or there were a lot of reasons building up, and this was the final straw. Or he's just a very strange man, and for some reason this pair of CVEs was oddly that important to him. reply bogota 3 hours agorootparentprevGet out of here. Im sure this was just the final straw. Dont come here and try to make this look like a crazy decision. You are being willfully ignorant or malicious in an attempt to paint your employer in a better light. I would warn others to ignore this person. reply oefrha 44 minutes agorootparentIf you have more information, share it (I don’t think you do, as all you could say was “I’m sure”.). People actually involved sharing their side is a unique advantage of HN. Empty ad hominem attacks are not allowed here, and you have no right to tell anyone to “get out of here”. reply tommica 2 hours agorootparentprevCould you expand on your reasoning here? I'm genuinely curious what makes you react in this way? To me it seems like a very simple disagreement with policies, and because the implications of the decision that was made and the impact it has to the agreed relationships. reply fl0ki 11 hours agoprevGiven this fork still boasts a 2-clause BSD license, the corporate nginx can still make the effort to backport patches. It's certainly harder than requiring a single converged development branch, but how closely they track Maxim's work is ultimately up to them. If nginx continues to receive more attention from security researchers, I imagine Maxim will have good reasons to backport fixes the other way too, or at least benefit from the same disclosures even if he does prefer to write his own patches as things do diverge. Though history also shows that hostile forks rarely survive 6 months. They either get merged if they had enough marginal value, or abandoned outright if they didn't. Time will tell. reply WhyNotHugo 9 hours agoparentI'm curious to see where this fork will go. The whole situation is a mess: - nginx is \"open core\", with some useful features in the proprietary version. - angie (a fork by several core devs) has a CLA, which sounds like a bait and switch waiting to happen and distro's won't package it - freenginx is at least open source. But who knows if it'll still be around by June. reply perlgeek 2 hours agorootparentI remember being surprised by the open core thing some years ago. I had been an Apache user for quite some time, and thought I'd take a look at the (at that point, a few years old) \"new\" shiny thing. I found that something as simple as LDAP authentication required a payed plugin; a free Apache module has been available for this for ages. That made nginx a non-starter for this particular use case. I wonder if the fork will accumulate free plugins for things that the old core required payed plugins for, slowly eroding their business case. reply nly 25 minutes agorootparentMost of this simple premium features/plugins were probably funded by companies because they had business value. It's probably unlikely freenginx will re-create them without those contracts. Unpaid Open Source developers tend to focus on interesting/cool core stuff and ignore all the stuff businesses care about (like LDAP authentication). reply spindle 3 hours agorootparentprevFWIW, nixpkgs packages angie reply stefanos82 14 hours agoprevI don't get it...does not he knows about angie [1]? It was created by NGINX core devs after F5 acquisition if I'm not mistaken and it's a drop-in replacement for NGINX. [1] https://github.com/webserver-llc/angie reply reactordev 14 hours agoparentangie is run by a corporate entity that could do exactly what F5 did. reply chomp 14 hours agoparentprev> not run by corporate entities > webserver, llc reply bemusedthrow75 14 hours agoparentprevThis surely is the question. Why not Angie? reply sodality2 14 hours agorootparentCould be related to the fact that Angie offers 'pro' version: https://wbsrv.ru/angie-pro/docs/en/ From statement: \"Instead, I’m starting an alternative project, which is going to be run by developers, and not corporate entities\" reply bemusedthrow75 14 hours agorootparentHm. I guess this consultancy-on-a-paid-version model doesn't bother me (and clearly didn't bother the developer of freenginx while they were paying him). But a double fork can't be good. reply bklyn11201 13 hours agorootparentI assume USA companies are by far the highest revenue source for Nginx Plus. Both of these forks seem to be based in Russia. How is a USA company supposed to pay either of these vendors for their consulting or Pro versions? How long until F5 submits requests for domain ownership of freenginx.org, and how quickly does Angie get takedown requests for their features that look remarkably similar to Nginx Plus features (e.g., the console)? reply pests 13 hours agorootparent> features that look remarkably similar to Nginx Plus features (e.g., the console) Its illegal for products in the same space to have similar features? reply bklyn11201 13 hours agorootparentPlease compare the two and let us know if you think \"similar\" is the right word. reply arg98 13 hours agorootparentCompare what? Console/dashboard is open sourced by F5, so anybody can fork: https://github.com/nginxinc/nginx-plus-dashboard reply pests 13 hours agorootparentThanks, I was trying to find the license for the nginx console but thought it might just be part of the plus offering only. reply ImPostingOnHN 9 hours agorootparentprev> clearly didn't bother the developer of freenginx while they were paying him Clearly it did, so much so that he gave up all that pay. reply bemusedthrow75 1 hour agorootparentThat is not why he gave up all the pay, is it? F5 closed the Moscow office. reply WhyNotHugo 9 hours agorootparentprevThe main criticism is that it requires signing a CLA, so they might switch to a non-free license any day now. reply aleksi 5 hours agorootparentBut anyone, including you and me, could re-license MIT/BSD-licensed open-source project under a different license, including non-free. CLA does not affect that. reply resolutebat 11 hours agoprevPer the discussion at https://news.ycombinator.com/item?id=39374312, this cryptic shade: > Unfortunately, some new non-technical management at F5 recently decided that they know better how to run open source projects. In particular, they decided to interfere with security policy nginx uses for years, ignoring both the policy and developers’ position. Refers to F5's decision to publish two vulnerabilities as CVEs, when Maxim did not want them to be published. reply larodi 15 hours agoprevIs called \"rage-fork\" perhaps this. So proposed title: nginx dev rage-forks over security disagreement with boss company But then perhaps he also has every right to do it, even though AFAIR the original author was somebody else. reply Kluggy 14 hours agoparentRage-fork doesn’t show up anywhere in their announcement, nor does it read like they’re doing something specifically out of rage. Everyone has a right to forking the project. Only time will tell if they get critical mass of developers to keep it going. reply bklyn11201 14 hours agorootparentSurely \"Nginx\" is trademarked, copyrighted, etc. A cool and collected fork would do some basic work to avoid trivial lawsuits, consider the other forks already in the space, and write up a bit on how this fork will be different from the others. reply Thoreandan 14 hours agorootparentA quick glance at USPTO and https://www.f5.com/company/policies/trademarks confirms this. reply mike_d 8 hours agorootparentRussia has laws on the books that allow them to exempt domestic operations from international IP enforcement and to nullify any damages if the entity has a connection to an \"unfriendly state.\" reply MiguelHudnandez 14 hours agorootparentprevIt's worth pointing out that Maxim Dounin is, by himself, likely critical mass for Nginx. Since he started in 2011 he is by far the most active contributor to the codebase. reply allanrbo 14 hours agoparentprevIgor, the original author, left in 2022 according to wikipedia: https://en.wikipedia.org/wiki/Igor_Sysoev reply water-your-self 14 hours agoparentprevWhy does the identity of the original author matter here? reply allanrbo 14 hours agorootparentIn my opinion the original author did a really good job, so I found it interesting to know where and whether he might continue his vision. Edit: I see now from the hg history that Igor hasn't been coding on Nginx for a decade actually. reply larodi 14 hours agorootparentIndeed, the original work done by single dev (Igor) to get the nginx project running was very impressive timewise, and as a volume of code produced. I can't really recall why he left, but with other comments around the thread implies such forks have happened more than once. As a sidenote I believe the people who start projects that they themselves run in excellent manner, should be praised, supported, noted and there is nothing more for their identities to matter. It very much matters some particular person with weird nick burntsushi created this wonderful tool rg, and kept growing it for long time. Besides, I can bet for projects such as Cosmopolitan C, it absolutely matters that jart started/did it. reply webprofusion 4 hours agoprevOne of the most heavily used Russian software projects on the internet https://www.nginx.com/blog/do-svidaniya-igor-thank-you-for-n... but it's only marginally more modern than Apache httpd. In light of recently announced nginx memory-safety vulnerabilities I'd suggest migrating to Caddy https://caddyserver.com/ reply 86 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Maxim Dounin, a developer of nginx, is launching a new project called freenginx.org as an alternative to nginx.",
      "This decision is in response to changes made to the security policy of nginx by F5, the company that owns it, without consulting the developers.",
      "Dounin wants to maintain the free and open-source nature of the project and keep it free from corporate interference. Contributions and support for the new project are encouraged."
    ],
    "commentSummary": [
      "The summary discusses the debates and discussions surrounding Nginx and its fork, Freenginx, created by core developer Maxim Dounin.",
      "Topics covered include the reliance on projects maintained by a small number of people, staying informed about vulnerabilities, challenges of small teams in software development, and difficulties with configuration files.",
      "There is a disagreement between Maxim and F5 over the handling of vulnerabilities, resulting in a divide in the community and the creation of a fork. The discussions emphasize the importance of security, collaboration, and decision-making in software development."
    ],
    "points": 868,
    "commentCount": 336,
    "retryCount": 0,
    "time": 1707935380
  },
  {
    "id": 39374020,
    "title": "Inside the proton: unraveling its complex composition",
    "originLink": "https://www.quantamagazine.org/inside-the-proton-the-most-complicated-thing-imaginable-20221019/",
    "originBody": "Inside the Proton, the ‘Most Complicated Thing You Could Possibly Imagine’ Read Later Share Copied! Comments Read Later Read Later Multimedia Inside the Proton, the ‘Most Complicated Thing You Could Possibly Imagine’ By Charlie Wood +1 authors Merrill Sherman October 19, 2022 The positively charged particle at the heart of the atom is an object of unspeakable complexity, one that changes its appearance depending on how it is probed. We’ve attempted to connect the proton’s many faces to form the most complete picture yet. Read Later Researchers recently discovered that the proton sometimes includes a charm quark and charm antiquark, colossal particles that are each heavier than the proton itself. Samuel Velasco/Quanta Magazine Authors Charlie Wood Staff Writer Merrill Sherman Graphics Editor October 19, 2022 View PDF/Print Mode atomic physicsmultimedianuclear physicsparticle physicsphysicsQuanta Podcastquantum chromodynamicsquantum physicsAll topics Introduction More than a century after Ernest Rutherford discovered the positively charged particle at the heart of every atom, physicists are still struggling to fully understand the proton. High school physics teachers describe them as featureless balls with one unit each of positive electric charge — the perfect foils for the negatively charged electrons that buzz around them. College students learn that the ball is actually a bundle of three elementary particles called quarks. But decades of research have revealed a deeper truth, one that’s too bizarre to fully capture with words or images. “This is the most complicated thing that you could possibly imagine,” said Mike Williams, a physicist at the Massachusetts Institute of Technology. “In fact, you can’t even imagine how complicated it is.” The proton is a quantum mechanical object that exists as a haze of probabilities until an experiment forces it to take a concrete form. And its forms differ drastically depending on how researchers set up their experiment. Connecting the particle’s many faces has been the work of generations. “We’re kind of just starting to understand this system in a complete way,” said Richard Milner, a nuclear physicist at MIT. Quanta Science Podcast What’s inside a proton? Your answer may vary depending on how hard you hit it with electrons. All episodes 00:00/00:00 APPLE SPOTIFY As the pursuit continues, the proton’s secrets keep tumbling out. Most recently, a monumental data analysis published in August found that the proton contains traces of particles called charm quarks that are heavier than the proton itself. The proton “has been humbling to humans,” Williams said. “Every time you think you kind of have a handle on it, it throws you some curveballs.” Recently, Milner, together with Rolf Ent at Jefferson Lab, MIT filmmakers Chris Boebel and Joe McMaster, and animator James LaPlante, set out to transform a set of arcane plots that compile the results of hundreds of experiments into a series of animations of the shape-shifting proton. We’ve incorporated their animations into our own attempt to unveil its secrets. Cracking Open the Proton Proof that the proton contains multitudes came from the Stanford Linear Accelerator Center (SLAC) in 1967. In earlier experiments, researchers had pelted it with electrons and watched them ricochet off like billiard balls. But SLAC could hurl electrons more forcefully, and researchers saw that they bounced back differently. The electrons were hitting the proton hard enough to shatter it — a process called deep inelastic scattering — and were rebounding from point-like shards of the proton called quarks. “That was the first evidence that quarks actually exist,” said Xiaochao Zheng, a physicist at the University of Virginia. After SLAC’s discovery, which won the Nobel Prize in Physics in 1990, scrutiny of the proton intensified. Physicists have carried out hundreds of scattering experiments to date. They infer various aspects of the object’s interior by adjusting how forcefully they bombard it and by choosing which scattered particles they collect in the aftermath. Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters Introduction By using higher-energy electrons, physicists can ferret out finer features of the target proton. In this way, the electron energy sets the maximum resolving power of a deep inelastic scattering experiment. More powerful particle colliders offer a sharper view of the proton. Higher-energy colliders also produce a wider array of collision outcomes, letting researchers choose different subsets of the outgoing electrons to analyze. This flexibility has proved key to understanding quarks, which careen about inside the proton with different amounts of momentum. By measuring the energy and trajectory of each scattered electron, researchers can tell if it has glanced off a quark carrying a large chunk of the proton’s total momentum or just a smidgen. Through repeated collisions, they can take something like a census — determining whether the proton’s momentum is mostly bound up in a few quarks, or distributed over many. Even SLAC’s proton-splitting collisions were gentle by today’s standards. In those scattering events, electrons often shot out in ways suggesting that they had crashed into quarks carrying a third of the proton’s total momentum. The finding matched a theory from Murray Gell-Mann and George Zweig, who in 1964 posited that a proton consists of three quarks. Gell-Mann and Zweig’s “quark model” remains an elegant way to imagine the proton. It has two “up” quarks with electric charges of +2/3 each and one “down” quark with a charge of −1/3, for a total proton charge of +1. Three quarks careen about in this data-driven animation. MIT/Jefferson Lab/Sputnik Animation Introduction But the quark model is an oversimplification that has serious shortcomings. It fails, for instance, when it comes to a proton’s spin, a quantum property analogous to angular momentum. The proton has half a unit of spin, as do each of its up and down quarks. Physicists initially supposed that — in a calculation echoing the simple charge arithmetic — the half-units of the two up quarks minus that of the down quark must equal half a unit for the proton as a whole. But in 1988, the European Muon Collaboration reported that the quark spins add up to far less than one-half. Similarly, the masses of two up quarks and one down quark only comprise about 1% of the proton’s total mass. These deficits drove home a point physicists were already coming to appreciate: The proton is much more than three quarks. Much More Than Three Quarks The Hadron-Electron Ring Accelerator (HERA), which operated in Hamburg, Germany, from 1992 to 2007, slammed electrons into protons roughly a thousand times more forcefully than SLAC had. In HERA experiments, physicists could select electrons that had bounced off of extremely low-momentum quarks, including ones carrying as little as 0.005% of the proton’s total momentum. And detect them they did: HERA’s electrons rebounded from a maelstrom of low-momentum quarks and their antimatter counterparts, antiquarks. Many quarks and antiquarks seethe in a roiling particle “sea.” MIT/Jefferson Lab/Sputnik Animation Introduction The results confirmed a sophisticated and outlandish theory that had by then replaced Gell-Mann and Zweig’s quark model. Developed in the 1970s, it was a quantum theory of the “strong force” that acts between quarks. The theory describes quarks as being roped together by force-carrying particles called gluons. Each quark and each gluon has one of three types of “color” charge, labeled red, green and blue; these color-charged particles naturally tug on each other and form a group — such as a proton — whose colors add up to a neutral white. The colorful theory became known as quantum chromodynamics, or QCD. According to QCD, gluons can pick up momentary spikes of energy. With this energy, a gluon splits into a quark and an antiquark — each carrying just a tiny bit of momentum — before the pair annihilates and disappears. It’s this “sea” of transient gluons, quarks and antiquarks that HERA, with its greater sensitivity to lower-momentum particles, detected firsthand. HERA also picked up hints of what the proton would look like in more powerful colliders. As physicists adjusted HERA to look for lower-momentum quarks, these quarks — which come from gluons — showed up in greater and greater numbers. The results suggested that in even higher-energy collisions, the proton would appear as a cloud made up almost entirely of gluons. Gluons abound in a cloud-like form. MIT/Jefferson Lab/Sputnik Animation Introduction The gluon dandelion is exactly what QCD predicts. “The HERA data are direct experimental proof that QCD describes nature,” Milner said. But the young theory’s victory came with a bitter pill: While QCD beautifully described the dance of short-lived quarks and gluons revealed by HERA’s extreme collisions, the theory is useless for understanding the three long-lasting quarks seen in SLAC’s gentle bombardment. QCD’s predictions are easy to understand only when the strong force is relatively weak. And the strong force weakens only when quarks are extremely close together, as they are in short-lived quark-antiquark pairs. Frank Wilczek, David Gross and David Politzer identified this defining feature of QCD in 1973, winning the Nobel Prize for it 31 years later. But for gentler collisions like SLAC’s, where the proton acts like three quarks that mutually keep their distance, these quarks pull on each other strongly enough that QCD calculations become impossible. Thus, the task of further demystifying the three-quark view of the proton has fallen largely to experimentalists. (Researchers who run “digital experiments,” in which QCD predictions are simulated on supercomputers, have also made key contributions.) And it’s in this low-resolution picture that physicists keep finding surprises. A Charming New View Recently, a team led by Juan Rojo of the National Institute for Subatomic Physics in the Netherlands and VU University Amsterdam analyzed more than 5,000 proton snapshots taken over the last 50 years, using machine learning to infer the motions of quarks and gluons inside the proton in a way that sidesteps theoretical guesswork. The new scrutiny picked up a background blur in the images that had escaped past researchers. In relatively soft collisions just barely breaking the proton open, most of the momentum was locked up in the usual three quarks: two ups and a down. But a small amount of momentum appeared to come from a “charm” quark and charm antiquark — colossal elementary particles that each outweigh the entire proton by more than one-third. The proton sometimes acts like a “molecule” of five quarks. Introduction Short-lived charms frequently show up in the “quark sea” view of the proton (gluons can split into any of six different quark types if they have enough energy). But the results from Rojo and colleagues suggest that the charms have a more permanent presence, making them detectable in gentler collisions. In these collisions, the proton appears as a quantum mixture, or superposition, of multiple states: An electron usually encounters the three lightweight quarks. But it will occasionally encounter a rarer “molecule” of five quarks, such as an up, down and charm quark grouped on one side and an up quark and charm antiquark on the other. Such subtle details about the proton’s makeup could prove consequential. At the Large Hadron Collider, physicists search for new elementary particles by bashing high-speed protons together and seeing what pops out; to understand the results, researchers need to know what’s in a proton to begin with. The occasional apparition of giant charm quarks would throw off the odds of making more exotic particles. And when protons called cosmic rays hurtle here from outer space and slam into protons in Earth’s atmosphere, charm quarks popping up at the right moments would shower Earth with extra-energetic neutrinos, researchers calculated in 2021. These could confound observers searching for high-energy neutrinos coming from across the cosmos. Rojo’s collaboration plans to continue exploring the proton by searching for an imbalance between charm quarks and antiquarks. And heavier constituents, such as the top quark, could make even rarer and harder-to-detect appearances. Next-generation experiments will seek still more unknown features. Physicists at Brookhaven National Laboratory hope to fire up the Electron-Ion Collider in the 2030s and pick up where HERA left off, taking higher-resolution snapshots that will enable the first 3D reconstructions of the proton. The EIC will also use spinning electrons to create detailed maps of the spins of the internal quarks and gluons, just as SLAC and HERA mapped out their momentums. This should help researchers to finally pin down the origin of the proton’s spin, and to address other fundamental questions about the baffling particle that makes up most of our everyday world. Correction: October 20, 2022 A previous version of the article erroneously implied that lower-momentum quarks live shorter lives than higher-momentum quarks in the quark sea. The text has been updated to clarify that all these quarks are lower-momentum and shorter-lived than those in the three quark-picture. Authors Charlie Wood Staff Writer Merrill Sherman Graphics Editor October 19, 2022 View PDF/Print Mode atomic physicsmultimedianuclear physicsparticle physicsphysicsQuanta Podcastquantum chromodynamicsquantum physicsAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article The Computer Scientist Who’s Boosting Privacy on the Internet",
    "commentLink": "https://news.ycombinator.com/item?id=39374020",
    "commentBody": "Inside the proton, the ‘most complicated thing you could possibly imagine’ (quantamagazine.org)425 points by MetallicCloud 14 hours agohidepastfavorite370 comments andy_xor_andrew 12 hours agoI just had a really stupid thought, after finishing reading the article. So, the electron is an elementary particle, right? Compared to the proton, the electron is \"simple\", yes? Despite this difference in complexity, an electron has a charge of -e and a proton has a charge of +e. They are exactly complementary regarding charge (if I am understanding right, I am not a smart person). my question is... why? why must protons and electrons be perfectly complementary regarding charge? if the proton is this insanely complex thing, by what rule does it end up equaling exactly the opposite charge of an electron? why not a charge of +1.8e, or +3e, or 0.1666e, etc? Certainly it is convenient that a proton and electron complement each other, but what makes that the case? Does this question even make sense? so, there's a concept of a \"positron\", which I can understand - of course it has charge +e, it is the \"opposite\" of an electron. it is an anti-electron. at least that makes some kind of sense. but a proton is made up of this complex soup of other elementary particles following all these crazy rules, and yet it also ends up being exactly +e. reply importantstuff 2 hours agoparentNo one who has replied to your question has got the right answer. https://physics.stackexchange.com/questions/21753/why-do-ele... has the right answer. There are multiple aspects to this argument, but essentially, the symmetries of your system force the charges in the Standard Model (quarks and leptons) to be the way they are due to gauge anomaly cancellation. If you believe in quark confinement, which is extremely well motivated, computationally, theoretically and experimentally, then the fact that the proton has exactly charge +1 follows naturally. reply hansbo 1 hour agorootparentI am reading this as \"it has to be this way, or the model does not hold\", but it does not explain why. What causes it? Consistency of a model cannot be the ultimate reason, right? reply coldtea 1 hour agorootparentNot a physisist, but \"consistency with the model\" doesn't mean \"because that's how some arbitrary model says it should be\". It's more like: \"Because we have arrived at a model that describes well most other aspect of those particles and their behavior, and has verified predictive power, and given the constrains and calculations based on that model, that's what its charge would be\". reply awestroke 1 hour agorootparentStill does not explain \"why\" reply chaxor 1 hour agorootparentI just would like to point out that \"why\" is not a scientific question. Feynman mentions this quite a lot. The question \"why\" doesn't have answers in science. A question of \"How\" has a better chance of being answered in science. reply foldr 25 minutes agorootparentI think that was a fairly idiosyncratic point of view of Feynman's. In actual scientific practice you can find hundreds of examples of published scientific papers that address 'why' questions. Here are a couple of completely random examples: https://link.springer.com/article/10.1007/s11207-009-9338-5 https://www.mdpi.com/2624-8174/4/3/63 reply ljosifov 1 hour agorootparentprev\"Why\" is more of a philosophy question, pre-scientific or a-scientific if you like. Science question would be \"How\". Maybe not this particular Q, but having in mind that on every A-answer, one can again ask Q-question \"Why\". That's more philosophy not so much science, imo. reply hansbo 51 minutes agorootparentI don't think it explains \"How\" either, in this case. reply 15457345234 1 hour agorootparentprevThe 'why' is because 'it's what balances' i.e. it's the only combination that works. A proton is a bunch of other particles that, when combined together, balance out an electron. The 'why' is 'because that's a stable configuration' in the same way that water at 25c is liquid not gas because the 'rules' of the local environment dictate that. I mean, why do those particles exist at all? That's really what you're asking. Why do electrons exist, why do protons 'form' from subatomic particles to balance them out? Existential kinda question. reply XorNot 1 hour agorootparentprevIsn't the primary experimental argument beta decay from that link? A nucleus can emit a positron, and observably loses nuclear charge equal to one positive electron. So by a pretty simple inferrence you could conclude the proton has a positive in it, hence the charge (it of course isn't literally like this for other reasons though). And since we also observe antiprotons, the opposite can clearly apply. reply hansbo 52 minutes agorootparentSo a proton can emit a positron. Does that mean that the positron is somehow \"part\" of the proton? Does it mean that their wave functions interact in some specific way? Is there another reason? Quantum physics has always bothered me, personally, since I find it difficult to understand reasons. Not philosophical reasons, I am fine with axioms and foundations to models, but rather intuitive reasons why it works a certain way. I know it is an extremely strong theory which makes unexpected, later confirmed, predictions, but there is a frustration that the only explanation to things is \"math\". reply polskibus 2 hours agorootparentprevWhich answer on physicsexchange is the right one? The top scored ? reply clankyclanker 8 hours agoparentprevSo, PBS Space Time did a video on this “fine tuned universe” theory and it, like all of their videos, is great. The concept seems to be that in an unbalanced universe, life couldn’t form, and we’d be incapable of having this conversation. So, either there are infinite universes and we exist as a result of being in the right one, or there’s one universe and we exist as a result of the one we’re in being right. Either way, we’re pretty lucky. https://youtu.be/YmOVoIpaPrc reply timeagain 8 hours agorootparentI can’t get behind all these fine tuning arguments. Who’s to say what life might form if the proton had a charge of 1.01e or if the fine structure constant was 1/138? Something about the line of reasoning that there is a multiverse and we just happen to live in favorable conditions reminds me of Pascal’s wager. It doesn’t do anything other than unfalsifiably assure the wagerer that they are important reply kadoban 6 hours agorootparentA couple of the constants it's easy (for a real physicist, not for me) to prove there's no interesting structure to the universe anymore if they vary even a little. Like, no molecules are possible. So there's a question there for why the values are so exactly set, or if something forces them to be the value they are. The anthropic principle (that if the universe weren't suitable, we wouldn't be here to know) always struck me more of reasoning that we're _not_ special. reply raggi 4 hours agorootparent\"no molecules are possible\" does not imply \"absolutely nothing forms a structured dynamic\", the thought experiment ceases prematurely if it stops there, partly because the structural makeup is not yet well enough known to consider those outcomes. the claim of a completely uninteresting outcome approximating true nothing is empirically unlikely. abstractions tend to fall over far faster than reality does reply megmogandog 6 hours agorootparentprevWhich fine tuning arguments are you referring to? As I understand it, 'fine tuning' is simply a fact of the universe: that the fundamental constants have values that allow for the emergence of complexity, and that even slight changes to those values would lead to homogeneous and featureless universe. I don't have the physics background to demonstrate this for myself, but I believe it. To then reason from that fact to the existence of a multiverse or the existence of God is an extra step that one need not take, but not taking either of those steps doesn't invalidate the appearance that the fundamental constants of the universe were fine tuned for the production of complexity/life. reply timeagain 6 hours agorootparentOk here’s the problem. What hubris does it take to assume the fundamental constants could be changed? Just because they appear in math equations doesn’t mean they can be twiddled and tweaked like programming variables. We have no prior knowledge or justification to believe any constants have been “tuned”, because we have no justification in suggesting other possible values. We could just as easily say that life on earth was “tuned” to make ”intelligent life” evolve, but we don’t have any other 4 billion year test runs of earth to see what else might have evolved. In the same way we have no data at all about the phase space of other possible universes, their constants, or how their physics would play out on cosmological timescales. It’s not that it isn’t fun to think about. It’s just that it is unscientific. reply megmogandog 4 hours agorootparentI think I could've phrased my comment better. I'm not assuming the constants can be changed; axiomatically, they cannot, because they're fundamental constants of the universe. I'm also not assuming that some agent was around to do the tuning. In its basic form 'fine tuning' just means that if one of the values were even slightly different we wouldn't have anything like the universe we see today, including life. The values of the constants appear as if they were tuned. It's interesting you bring up evolution, because before that theory came about intelligent design was a reasonable assumption in trying to explain how well-adapted organisms seemed to be to their environments. It was as if someone had designed them for their roles! As it turns out the theory of evolution satisfactorily explains why organisms exhibit the appearance of design. In a similar way the fundamental constants exhibit the appearance of having been precisely set. It's hard to imagine a scientific theory getting 'behind' the constants the way evolution was able to get 'behind' the appearance of organisms... reply radarsat1 3 hours agorootparent> if one of the values were even slightly different we wouldn't have anything like the universe we see today This is a hallmark of a chaotic system. It's not impossible but the chances of sitting exactly on such an unstable point seems very low. It seems more likely that the constants are some optimum in a basin of attraction, a stable point in some higher order dynamic system. reply ryandamm 4 hours agorootparentprevYou're not entirely wrong that it's unscientific, I think we're answering metaphysical questions. (It seems like questions of \"why\" ends up unerringly in either metaphysics or religion at some point.) That said, I believe the chain of logic (haven't watched the PBS video yet) is simply that were these fine-tuned constants to take any other value, there wouldn't be intelligent life to observe them. If the values were to be anything outside a narrow range, they would remain unobservable by entities within that hypothetical universe, and because we are making an observation we are implicitly sampling from the distribution of observable values. It's a Bayesian metaphysical argument? That sounds like it presumes a multiverse, but I don't think you need an infinite number of universes or a god for that to be true... that said, it does purport to explain how fine-tuning doesn't violate certain (metaphysical?) principles of science that call for \"naturalness\" (which a friend once told me boils down to \"all unitless constants should be either 1 or 0 otherwise it's inelegant\" or something): the fine structure constant is what it is because otherwise nothing would exist to observe that it was 1/139 or 42 or whatever. I hope this is even slightly more satisfying to read than it was to write. reply cdogl 1 hour agorootparentYour comment was an excellent synthesis of the discussion that preceded it - thank you. reply felipeerias 4 hours agorootparentprevThose constants are a feature of our models. We don’t actually know whether the constants themselves are part of reality, or whether they are just there so our models can approximate our observations. The point is, there might be a mismatch between our model and the underlying reality. There could be an unknown deeper structure to reality which explained why those values appear to us as “fine tuned”. reply kadoban 6 hours agorootparentprev> Ok here’s the problem. What hubris does it take to assume the fundamental constants could be changed? Just because they appear in math equations doesn’t mean they can be twiddled and tweaked like programming variables. We have no prior knowledge or justification to believe any constants have been “tuned”, because we have no justification in suggesting other possible values. Nothing says that they couldn't be changed, but then there's the question of _why_ they can't be changed. What forced them to be the values they are? Some of them appear to be free, so are they? reply foobarbecue 8 hours agorootparentprevAKA the \"anthropic principle.\" reply jodrellblank 7 hours agorootparentAKA “God did it” with a sciencey sounding name. An answer which explains nothing, predicts nothing, satisfies no curiosity, and closes the book on any further questions. reply knightoffaith 6 hours agorootparentThe anthropic principle is actually the opposite - it's an objection to the fine-tuning argument that says something roughly like \"well, of course the universe is configured in a way that allows us to be around. if it wasn't, we wouldn't be around to discuss it. thus, there is no need to appeal to an intelligent designer of the universe to explain its fine-tuned nature.\" That aside, with respect to saying an intelligent designer designed the universe (\"God did it\"): >explains nothing Well, it explains why the universe is fine-tuned, if you buy the argument. >predicts nothing Yep, just like any other answer to the question, since it's a metaphysical question rather than a scientific one. >satisfies no curiosity It offers an explanation. >closes the book on any further questions No more than any other answer does. reply Mauneam 6 hours agorootparent>Well, it explains why the universe is fine-tuned, if you buy the argument. No it doesn't. Goddidit is not an explanation. >Yep, just like any other answer to the question, since it's a metaphysical question rather than a scientific one. Nope, not like any other answer. Like Satandidit. >It offers an explanation. No it doesn't. Goddidit is not an explanation. >No more than any other answer does. No, not like other answers. Science never closes the book on further questions. reply knightoffaith 5 hours agorootparentI suspect you're reading into my comment more than what I intended to say. In the context of fine-tuning arguments for God, we really are just arguing that an intelligent designer designed the universe. In isolation, this doesn't necessarily commit us to some mainstream religion, and in this context, God is just the intelligent designer of the universe, nothing more (though proponents of the arguments will go on, through other arguments, to ascribe more properties to this thing). >Goddidit is not an explanation. I don't know why it wouldn't be. Suppose I kept pulling a card from a deck and showing it to you. Every single time, it was the ace of spades. Why is this? Well, one pretty good explanation is that I know where the ace of spades is in the deck and I'm intentionally picking that card out and showing it to you. That is, there is intelligence/intentionality that explains this event. You would probably consider this as an explanation. The fine-tuning argument's conclusion is just as much of an explanation. >Nope, not like any other answer. Like Satandidit. I don't know what you mean to say here. Satandidit doesn't predict anything either. >No, not like other answers. Science never closes the book on further questions. This isn't a scientific question though. This is a question about why the fundamental constants of nature are what they are. This is a question beyond the domain of science. Elsewhere in this thread, someone linked a video of Feynman (an atheist) on \"why\" questions and how at some point they have to bottom out - and at this point, science cannot provide the answers. Besides, this doesn't close the book on further questions. We can still ask, \"what kind of existence is this intelligent designer?\", \"why does this intelligent designer exist?\", etc. And of course, questions that are normally under the domain of science are still under the domain of science. reply unethical_ban 5 hours agorootparentI consider the person to whom you are responding a troll, because they are taking a hard line stance, using abrupt terms, shutting down discussion, and putting much less effort into things than you are. That said, I agree with you roughly. I think suggesting an intelligent design as a possibility is not \"shutting down curiosity\". A scientific mind can entertain higher forms of power and look into it. Accepting the possibility of a creator is not equivalent to blind devotion to one of the many existing faiths. reply Mauneam 5 hours agorootparentprevSaying \"because God did it\" as an answer to any question has the same value as saying \"because pixel cooked the music\". If you want to consider those two groups of words \"explanations\" go for it. They are grammatically correct, and if they satisfy the curious mind they are good enough. reply namaria 2 hours agorootparentYou keep insisting that 'anthropic principle' = 'god did it' when it's anything but. It's like you don't even read to the replies to your comments. reply 15457345234 1 hour agorootparentIt's not uncommon now for people to use comment sections to deliver lectures, they already know what they want to say, they break it into multiple parts and they just paste it in assuming that other people will happily provide the right kind of conjugations. Good to point it out. reply cool_beanz 6 hours agorootparentprevThe Anthropic Principle explains why you are asking the question, not why the proton has that charge. Also see https://en.wikipedia.org/wiki/Cosmological_natural_selection reply jxdxbx 51 minutes agorootparentprevthe anthropic principle is why we find ourselves in such an unlikely place (a habitable planet) instead of somewhere that can’t support life. it’s not an argument for god. it’s not entirely trivial. if someone says “god did it” because we find ourselves on earth not mars the anthropic principle is a better explanation. reply Razengan 6 hours agorootparentprev> AKA “God did it” + \"Just for us\" ^^ e.g. Earth is the only place where life could have formed. We have yet to set foot on even 1 another planet but we are pretty sure we are alone in the entire damn Universe. reply freetime2 2 hours agorootparentThis is an incredible misunderstanding of the Anthropic principle. It has nothing to do with god, it does not suggest that life could only exist on Earth, and it does not suggest that we are alone in the universe. If anything it's an argument against Intelligent Design. E.g. life is the statistical result of a vast universe (or multiverse) of permutations - some of which are not conducive to life, and some of which are. And when life looks out and says \"wow it's uncanny how perfect this place is, there must be a divine hand at work\" - it's only observational bias that makes it appear that way. Because life could only exist to make such observations in regions of the universe which are suitable for life. But on the other hand it also prevents one from saying \"we exist, therefore intelligent life must be commonplace\". reply XorNot 1 hour agorootparenti.e. the puddle thinking how fortunate it is that the ditch it is in is the perfect size for it. reply knightoffaith 6 hours agorootparentprevThere doesn't seem to be any reason to believe that the defining constants of our universe are pulled from some uniform distribution though, which is the underlying assumption here. When you put it that way, that's a pretty strange and specific claim to make. reply okamiueru 3 hours agorootparentprevI strongly dislike PBS Space Time, but I find it hard to explain why. I might also be just too dumb to get it. It's just the feeling of the goal not being the \"listener gaining understanding\", but rather \"expressing how confusing and complicated it is\". reply cocoa19 3 hours agorootparentThe channel is definitely not targeted for the lay person. A counter example, Derek from Veritasium, he did a phd in physics education and it shows. Some of his videos are complex in content, but dumbed down so most people can understand. I enjoy PBS space time and listening to Matt O’Dowd, but I understand at the most 20-40% of what is covered on the videos. It is frustrating because I like the topics being discussed. reply hugryhoop 2 hours agorootparentDerek tackles easier subjects than PBS space. reply okamiueru 39 minutes agorootparentprevI'm not convinced. When he talks about things I understand, he does so in a way that I still find frustratingly convoluted. In these cases, it's not for a lack of education. It probably just means that this style of presenting topics just isn't for me, which is completely fine. Diversity in free education is great and commendable. But I think you touch on the part that I think is the reason why. Because PBS tries to dumb things down, but instead of doing it like Derek does, which adds clarity, PBS does it by \"mystifying\" it. Probably tickles someone's itch, but I find it annoying. Take the video posted, for example. It starts out immediately with thumbnail \"Life = Multiverse?\". If it really was for the niche audience, that title is remarkably dumb, although understandable for the same reasons clickbait titles work. Perhaps PBS meant to present the question whether one leads to or suggests the other? \"Life ⇝ Multiverse?\" would better express that. Though, the thought process of how multiverse and the anthropic principle go together is: \"Multiverse ⇝ Life?\". The video starts out by expressing three statements, related to the Anthropic Principle (https://en.wikipedia.org/wiki/Anthropic_principle). Had they instead worded those statements as to be correct, it would be a very nice way of introducing the topic. This is how it is presented: \"Life exists in our universe\" ⇝ \"Our universe is capable of producing and sustaining life\". Which is fine. We understand what producing and sustaining life is, because it is really just the first statement with some added anthropomorphism. The next one, which is the whole point of the \"hook\" for the video, and is probably intended to be a little bit cheeky, except that he keeps a straight face, so, unless you know enough, it'll probably just misinform you. \"Okay. Let's try one final uncontroversial statement. Therefore, there are countless universes\". Well, no. Multiverse theory is one way to explain the unlikeliness of the physical constants working out the way they \"conveniently\" do in our universe. But this logical inference is not an \"uncontroversial statement\". It doesn't qualify, yet it is dumbed down to suggest it does. I'm sure that the following \"Hm\", and look to the side, is meant to express this. What do I know. But I'm not particularly amused or impressed. So, so far, we've seen the thumbnail, and the first three sentences before the intro video rolls. And, it's been 1. Inaccurate information in thumbnail, 2. incorrect logical inference 3. false conclusion. I can probably continue the video, but this is why I dislike PBS so much. It doesn't really try to dumb things down. It just IMO, fails to communicate science well. reply stevenhuang 0 minutes agorootparentYeah, your confusion there is like being confused from the use of a literary device. The intent was exactly to illustrate why the implication 'life -> multiverse' may be problematic. You have a comprehension problem. dcow 3 hours agorootparentprevIt’s like a listicle that tells you every best coffee machine in 2024 is a valid purchase to the right kind of consumer when you’re looking for the best one. reply mianos 12 hours agoparentprevImagine you have a bunch of fulcrums in the air and items droping down. If the things that land on the fulcrums don't balance each other out the fulcrum tips and the items keep dropping. Eventually all the fulcrums are balanced. A lot of these things coalesce until they are stable enough they don't fall apart. If there is a stable form and you have enough of them, eventually you get a lot of stable forms. It is not some magical thing that makes all this balance, it is more of a settling thing where things eventually drop to a stable state. There is lots of matter that is still unstable. reply gizmo686 12 hours agorootparentThis explains why atoms have 0 charge, but not why protons, which are stable even without electrons, have a charge of 1. Put in terms of elementary particles, why is it that the ratio of electric charge between a quark and an electron is either 1:3 or 2:3? reply rolph 11 hours agorootparenta proton, in the simplist version, is made of 3 quarks. two up quarks one down quark. down qwark is -1/3 e ; up quark is +2/3 e. they sum up to +1 e. neutrons are the opposite made of 3 quarks. two down quarks one up quark. and sum to 0e the unitary quantity is a conveinience. 1 e = 1.602176634×10−19 coulombs, reply Balgair 10 hours agorootparentYes, yes, I also understand this. But why are they in units of 1/3(e). Why are down quarks not -0.398390847895...(e) and up quarks not +0.6234098129034809234...(e). Why do they add up so damn neatly? reply yummypaint 10 hours agorootparenthttps://en.m.wikipedia.org/wiki/Mathematical_formulation_of_... Mathematically it works out that way because the standard model is build up from symmetry groups. The hand wavy explanation is that the symmetries observed in nature wouldn't be reproduced if the charges differed by random irrational numbers. The same is also generally true of other conserved quantities in the SM. Noether's theorem unifies symmetries and conservation laws as the same thing. As far as a more fundamental explanation as to WHY the universe is this way, ask your god i guess. reply delecti 10 hours agorootparentprevCould be a bit of anthropic principle at play. Universes where things don't work out with some stability might not support chemistry, and biology is especially finicky chemistry. reply edgyquant 10 hours agorootparentprevBecause they are mathematical models built to describe a thing and thus their entire purpose as a concept is to add up “neatly” reply idiotsecant 8 hours agorootparentNo, these are models with simple, testable properties. You can't wave away the fundamental charges as something somebody made up to make the models nice, conspiracy theories don't work when there is a simply observable truth. reply DiscourseFan 10 hours agorootparentprevI'm getting very strong \"angels on a pinhead\" vibes from this reply jacquesm 9 hours agorootparentWith the minute difference that we do not have experimental validation for Angels dancing on a pinhead whereas there is a massive amount of experimental validation for the standard model. reply DiscourseFan 20 minutes agorootparentSo you're saying that all we need to do is experimentally validate the number of angels dancing on a pinhead? reply DonHopkins 8 hours agorootparentprevI thought he meant \"angles on a pinhead\". Now you're talkin' tri-angular! https://cidu.info/2022/05/06/thats-a-cute-angle/ Right angles are wrong angles! Death to th' T-square! https://comicskingdom.com/zippy-the-pinhead/2023-07-02 reply DiscourseFan 6 hours agorootparentThank you for your contribution, my fellow Pynchon Enjoyer reply wombatpm 6 hours agorootparentprevMeasure the area of a pinhead, divide by cross-sectional area of an angel. Easy peasy. reply snarfy 9 hours agorootparentprevMy layman understanding is that charge is not fundamental. It derives from something called weak hypercharge. https://en.wikipedia.org/wiki/Weak_hypercharge reply nojvek 7 hours agorootparentprevIt’s essentially asking why is the speed of light 299,798,452 m/s or the gravitational constant 6.67x10-11 Nm2/kg2 I’m sure a universe could work with those constants varied but that’s the one we have in our universe. There could be hypothetical universes with protons being half of electron and atoms would have twice the protons. However the fundamental constants are just that. A number that allows us to reason about how the universe works. As to why the number is that, gotta ask your God why they chose that specific value. reply Dylan16807 7 hours agorootparent> It’s essentially asking why is the speed of light 299,798,452 m/s or the gravitational constant 6.67x10-11 Nm2/kg2 No, because those constants are entirely arbitrary. The curiosity here is that you have multiple numbers lining up, only separated by small integers. reply lostemptations5 5 hours agorootparentThey are arbitrary in the sense that we could just change them and the universe wouldn't fl appart -- or are they derived from aonething deeper. reply fiddlerwoaroof 2 hours agorootparentThe obvious way in which those constants are arbitrary is that the meter is just a random length we compare other lengths to (and the gram is an arbitrary mass we use). So, the precise numbers are only meaningful as part of a system built on these units reply chii 6 hours agorootparentprevOr, there's some more fundamental rule that's being followed that we haven't discovered yet that explains these numbers. Physicists have been searching for the Grand Unified Theory since forever, and so far, no real luck. The closest is something i'm not too familiar with called M-theory (which is a derivative(?) of string theory). reply oldandtired 3 hours agorootparentprevThe first thing to point out here is that the > the speed of light is not > 299,798,452 m/s It is quite inaccurate to say this. The correct way to phrase this is that the speed of light is 1/sqrt(permeability * permittivity) of the medium through which the light is traveling. For a perfect vacuum, these two properties of that vacuum give a result as specified above. For other specified medium, you will get a different value, which could be greater than or less than the above figure. Little technicalities matter in such cases, as it opens up the discussion. Part of that discussion is that solar space or interstellar space or intergalactic space will have distributions of matter that can alter what the speed of light is away from the assumed perfect vacuum speed of light. Simple assumptions such as perfect vacuum are quite likely to affect how accurate our models of the universe are. The problem for us is that we are here and not out there making actual on location measurements of the permittivity and permeability of the relevant regions. The assumptions made in our models can come back and bite us in the long term. Now as for the models we use currently for proton and neutron structure, there are assumptions here that could well be misleading us even though our models appear to work. There are alternate models available (since at least the early 20th century) which have, as far as I know, not been investigated with any detailed effort. Now, of course, it doesn't mean that these alternatives are actually viable, but we don't really know at this time. reply ianburrell 9 hours agorootparentprevBecause that is the universe we live in. We don't know where the universal constants come from, if they are random, or selected. Science can't really answer the question of \"why\", it only does \"how\". reply bbor 6 hours agorootparentprevOk probably a dumb take but: doesn’t that “stable forms become more common over time” principle also apply to protons purely by principle of them being in opposition to electrons? Ie the field that coalesces into the quarks we see today because those quarks can ultimately form atoms. EDIT: after reading the great Wikipedia article above, and a connected one [1], I think I can restate: the only place we can look for these particles is in atoms, so it shouldn’t surprise us that they come in convenient forms to support atom formation. [1] https://en.wikipedia.org/wiki/Accidental_symmetry reply blueprint 10 hours agorootparentprevwhen you understand quantum theory correctly, you will realize that particles don't exist by themselves. They are a temporary localization. this means that the number of quarks inside a proton is not actually fixed. when a particle becomes disentangled with the system, that localized it, there's no longer a particle I mentioned this recently, in the context of the laziness in language, leading to the miseducation of those who don't know better, and was heavily downvoted and ridiculed keep it up, hn, you'll see idiocracy soon enough and then no one will trigger you reply anon84873628 5 hours agorootparentI was ready to up vote until the third paragraph. Reading your other comments down thread doesn't paint you in a good light. Maybe your argument about laziness in language wasn't as cogent as you thought. Maybe you aren't as good at presenting arguments as you thought. In other words, maybe you need some humility. reply blueprint 4 hours agorootparentyeah maybe but if you knew for sure you'd be able to be sure of that and also show the proof instead what you did is present the impression that you had which is a synthesis of what you encountered and what was in you from the past. If you study much philosophy, you'll have to admit the fact that a large number of people turn away from what is true. It's not pleasant to you, I know. nor is it pleasant for you to see the product of the system that you want to close your eyes to talking to you in an unpleasant manner. reply CoastalCoder 8 hours agorootparentprevHN is a great training ground for learning how to present arguments in a compelling, engaging manner. reply blueprint 8 hours agorootparentthat may be true, but I'm already highly trained at that. But hey, what if you just ratchet up the difficulty to infinity. Then it will train people even better. Either that or it'll destroy the community because you dont have any criterion of right and wrong in your claim. It doesnt matter how correct people are. The more correct people are the worse they're treated. The better we get at presenting true arguments the more you will resent us and the more you have no choice but to react with violence (being unable to admit your lie), as HNers do now with trap counterarguments and gaslighting. No wonder suicide is on the rise. reply AndrewKemendo 7 hours agorootparentI feel what you’re saying, but it’s incumbent on people who understand stuff to explain it to people who don’t in a way that they can comprehend The reality is that we’re all ignorant about most things, so having an attitude with someone around something you know - irrespective of how you know it - is a losing strategy and as you said leads to poor interactions Try to give people more grace and you’ll find people are more capable than you might know reply blueprint 3 hours agorootparentI'll try to keep it in mind. thanks for your kindness. reply Dylan16807 7 hours agorootparentprevWhat's the lie that needs to be admitted? reply blueprint 3 hours agorootparentthe lie i meant is if people claim to want to know what they dont yet. it usually happens without their realization. look in the history of the greater philosophers you see it in the mechanism of narcissistic abuse as well you might also read up on the girardian scapegoat. the point is people like the comfort of falsehood so it tends to propagate more easily. few who were around masters wanted the actual teaching rather than some life quality improvements and basic answers. One of the merits certain people can get by hanging out around a real teacher is that those people can pretend that they were one of the people who wanted to know in front of those who don't know any better. reply rolph 9 hours agorootparentprevthanks, i want to stress the model of the proton i had posited up thread is very simplified, for the purpose of explanation. reply rvba 8 hours agorootparentprevWhat do you mean by \"temporary localization\"? That protons move? That they can poof? They dont seem to self destruct. On a side note: are there any models that assume that there are fields/shapes that are constanly bombarbed by neutrinos and other stuff. Thks bombardment seems to be always ignored reply Avicebron 7 hours agorootparentby drawing a hypothetical box around your system with and measuring it, you've bounded it locally. reply blueprint 3 hours agorootparentprevwithout being localized, they remain a probability wave because the \"universe\" of information literally doesn't know enough about them anymore reply blueprint 7 hours agorootparentprevno, we're talking about quarks or any isolated quantum systen reply trenchgun 3 hours agorootparentprev>the unitary quantity is a conveinience. Ah right, so basically its just a convenience notation? We could as well say that proton has 3 and electron is -3 charge? reply mulmen 10 hours agorootparentprevHow does 2/3 - 1/3 not sum to 1/3? 2-1 is 1, right? What am I missing? reply eindiran 10 hours agorootparent2 up quarks, so 2/3 * 2 -> 4/3. And then 4/3 - 1/3 = 3/3 = 1 reply lostemptations5 4 hours agorootparentThanks I wondered the same reply mulmen 9 hours agorootparentprevAh ha, I thought it was 1/3 per quark. Thanks. reply riwsky 5 hours agorootparentprevA proton, electron, and a neutron walk into a bar… reply oldandtired 3 hours agorootparentAfter about 15 minutes, the neutron has changed into another proton and electron, so bar now has a bigger party on its hands. reply lazide 12 hours agorootparentprevIf the universe is old, then how do you expect atoms to exist if this was not the case? reply pdabbadabba 12 hours agorootparentCouldn't there be a different physics where protons had a charge of 0.5 and, therefore, every atomic nucleus would have twice as many protons as electrons? Or pick any other ratio you like. Or course, I don't mean to hand-wave away the potential implications of this. Maybe there would be no atomic nuclei in such a universe, for all I know. But if not, why not? reply yifanl 11 hours agorootparentHow would we ever distinguish what half-a-proton is in a universe where all protons ever are _always_ paired off? reply derefr 11 hours agorootparentPresumably the same way we distinguish individual quarks: by smashing the atoms up. (The more interesting question would be the opposite: what if it was two electrons per proton? Then you could throw around some photons and end up with a half-proton negatively-ionized molecule. What would that look like?) reply selecsosi 11 hours agorootparentYou are going down the path of theoretical particle physics! It is the ultimate question of that to answer what is the fundamental element that makes up matter and what should we \"name\" that has a useful property that can either be used or helps to explain how other things work. In reality, \"protons\" do not \"exist\" but are semi(very) stable collections of energy that interact in an interesting enough way in a group that it is useful for us to retain the name, rather than refer to it by its constituents. Electrons don't really glob up into things like atoms due to repulsion (no moderation by the stron/weak nuclear forces) so we don't have a really useful reason to keep going beyond the definition of the electron so we just stop trying to find additional constituent parts. reply Dylan16807 7 hours agorootparentprevWe see naked protons and mismatches between nuclei and electrons all the time, so I don't see why half-charge protons would be \"_always_\" paired off. reply lazide 8 hours agorootparentprevSure. Some interesting thoughts in sibling comments too. Personally, I find the taste of hot chocolate just as nice regardless of the exact mix of quarks composing its constituent elements. reply lavasalesman 9 hours agorootparentprevI like your explanation. > There is lots of matter that is still unstable. What are you referring to with this? reply undersuit 9 hours agorootparenthttps://en.m.wikipedia.org/wiki/Proton_decay I need to read the article, but yeah protons might not be stable, we just need to wait a long time to find out. reply mianos 7 hours agorootparentAnd free quarks within stars in conditions where they are not confined. They can exist unconfined for a real short time. At the start of the big bang there were a lot of them. reply exmadscientist 12 hours agoparentprevThis is called \"charge quantization\", and it is not definitively explained by modern theories. There are some very good arguments for it, to be sure, but I don't think they're quite case-closed, of-course-it-must-be-that-way good. It is related to C symmetry, as a discrete symmetry, which ties in to Lorenz invariance and all that, so there's that angle too. reply anon84873628 12 hours agoparentprevNo one knows. That's part of the great mystery. But also in some sense \"it has to be that way,\" since without charge balance atoms wouldn't exist as we know them, and thus neither would all the chemistry that creates the macroscopic world we inhabit. reply retrac 12 hours agorootparentThat's a variation on the anthropic principle: https://en.wikipedia.org/wiki/Anthropic_principle Maybe a kind of observer bias. If the universe weren't seemingly-perfectly balanced to allow emergent complexity in matter, we wouldn't be here to point out how seemingly-perfect it seems. (If you subscribe to a multiverse interpretation, perhaps most of the infinitely many other possible universes are dead and void.) reply knightoffaith 6 hours agorootparentI'm not very sympathetic to the view that we're very lucky to be in this universe. That said, there is an interesting response to the anthropic principle response, which I'll mention here just because I think it's interesting to think about what's wrong with this objection: Suppose you and I were living in a totalitarian state. The state decides that you and I are to be put to death. They drag us into a field, and a shooting squad of several marksmen surrounds us. They all fire - but miraculously, every single one of them misses us. I then turn to you and say, \"Wow, the odds that all of those bullets missed us by sheer chance are so incredibly low. Clearly, it wasn't by chance - they must have coordinated to ensure they missed us, intentionally.\" You then turn to me and say, \"No, that's silly. It's simply that if any of the bullets had hit us, we wouldn't be around to talk about it.\" Your line of reasoning here doesn't seem to be very compelling. Why? reply ccozan 11 hours agorootparentprevAn interesting point. How about the universe kept starting and collapsing/crashing in an infinite loop until by chance the electron and the proton had the exact charge and the universe as it is now could go beyong the initial stage and could continue? ( Ok this feels like a trial an error of somebody playing universe ). reply wruza 10 hours agorootparentHow about the universe that quantum-emerges in a truly random sequence of quasistates which disintegrate immediately, and once in a while it happens to be the state that includes \"your\" \"memory\" of the previous ones. I mean chronologically from your perspective, they don't even have to appear in order. By an amazing coincidence, this particular \"frameset\" is logically consistent and pretty boring, so you have no intergalactic empires, no magic, and no job. reply ryukafalz 9 hours agorootparentEssentially dust theory from Permutation City. I've thought about this a lot. reply p1mrx 9 hours agorootparentprevIf perception emerged directly from chaos like that, wouldn't you expect to perceive chaos, rather than a rich world built upon billions of years of evolutionary history? reply wruza 9 hours agorootparentI don't think there's \"rather than\" in this idea. You surely will perceive every state that is perceivable at all, but time and continuity have no meaning here. Specific history is just an image that always exists only for an instant. Eventually that universe might enumerate all states, so they'd form all sorts of sequences, but that's coincidental. reply p1mrx 8 hours agorootparentSure, such a universe would create all states, but if perception from chaos were possible, then there would be overwhelmingly more chaotic states to perceive than sensible ones, so you would expect to find yourself perceiving chaos. I think perception cannot exist without a robust evolutionary history to build upon, which is why you perceive something sensible. reply wruza 7 hours agorootparentIt depends on what we see as \"perception\". Imagine in our regular universe model, the \"perceptor\" quickly switched between all creatures just like a CPU core switches between all busy processes. That wouldn't invalidate any of the creatures/processes \"experience\" and wouldn't mix them (ignoring cache, processes aren't that isolated really). All these processes are transient states of the same physical CPU core. Back to the chaotic universe, the \"perceptor\" switches between the states, every state is a complete picture. Yes it does see more chaotic states, but they don't leak into each other, including through expectations. There's no memory outside of a state that it could accumulate and experience continuously. Eons of state changes pass between two attoseconds, but there's no way to remember. That's what I mean by perception. In-frameset perception obviously has to be continuous to make (or not make) sense. reply p1mrx 6 hours agorootparentThat would still make the human brain an exceptionally rare state, compared to all the other chaotic states the perceptor perceives. This particular human brain refuses to believe that the perceptor perceives anything when selecting a chaotic state. If you'd like to hear chaos' opinion on the matter, please pound on your keyboard for a while. reply p1mrx 11 hours agorootparentprevI could see why a charge imbalance prevents life from forming, but why would it also collapse the entire universe? reply FridgeSeal 8 hours agorootparentprevSssshhhh, you’ll summon all the simulation people out of the woodwork! reply buildbot 12 hours agorootparentprevThis made me think - is a concept like most even defined for infinity? reply kjeetgill 10 hours agorootparentProbably a cheeky response but certainly! We can say most positive integers are greater than 5. Or most real numbers are irrational. Half of all integers are even — even though there's just as many of both! reply wruza 10 hours agorootparentprevNot a mathematician, but if there's a computable limit, then why not? E.g. most integers aren't powers of 2, cause lim(n to inf: n / 2^n) = 0 reply XorNot 11 hours agorootparentprevIt is however, not an unreasonable one. The main problem with the anthropic principle is if you use it to justify adding free parameters to models which don't otherwise have any physical meaning, and then tune them so they correct out the problems, wave your hands and say \"it must be this way because if cannot be any other\". reply colordrops 12 hours agorootparentprevYes, could be the anthropic principal. reply DonHopkins 7 hours agorootparentprevOn the topic of the ‘Most Complicated Thing You Could Possibly Imagine’: Imagine that physics is like Microsoft COM (or C++ pure virtual function tables), so there's a base IUnknown interface, hiding innumerably different possible concrete implementation classes, that can expose arbitrarily many other abstract interfaces, so you can call iUnknown->QueryInterface(uuid, &otherInterface) to ask for other interfaces like IAtom, IElectron, IProton, IQuark, IParticle, and IWave, and there are also many other obscure higher level dynamic and reflective interfaces like IDispatch, ITypeInfo, and IPersist, just waiting to be discovered and exploited, if only we knew the right uuid to ask for. And then physics research boils down to QueryInterfacing objects with random uuids, and when that succeeds in finding new interfaces, calling their random functions with random arguments to see what happens. That's probably what the black hole supercomputer at the center of the galaxy is doing. https://news.ycombinator.com/item?id=12975257 https://news.ycombinator.com/item?id=20266627 https://news.ycombinator.com/item?id=29593432 reply cozzyd 7 hours agoparentprevDisclaimer: I am not a theoretical physicist (but I am an experimental one...). If the universe, at the time of the big bang, had no net charge to begin with, and charge is conserved, then it follows that we would have particles whose charge will on net cancel out, and therefore charge would be quantized in some reasonable way. Note that there are doubly charged particles (e.g Delta++) but they're not stable. Some theories do predict fractionally charged particles (millicharged is the term of art) but there is no experimental evidence. Now, was the universe neutral to begin with? If it wasn't , then that would presumably leave a strong imprint on early universe cosmology. I believe that current measurements of galaxy structure formation, cosmic microwave background and big bang nucleosynthesis probably place extremely strong constraints on early universe neutrality, though there may be caveats I'm not aware of. reply lIl-IIIl 12 hours agoparentprevThere's also a anti-proton which has a negative charge. I think this is probably the smallest charge there is. A neutron can decay into a proton, electron, and anti-neutrino. So maybe one way to think of it is that a proton is a neutron that is missing an electron, that's why it has the opposite charge of the electron. reply wiml 12 hours agorootparentThe quarks that make up a proton (or neutron, etc) have charges that are multiples of 1/3 the electron charge. So in one sense that is the real unit charge. But because as far as we know quarks can never exist in isolation we can only ever see particles with multiples of the electronic charge. reply a_gnostic 11 hours agorootparentThe number assigned to charge is an arbitrary convention. You could assign quarks with full numbered charges, instead of fractions, but you'd have to rework and recalculate all of physics and chemistry to get the new values right, and that's just too much work. reply calamari4065 10 hours agorootparentNo matter what arbitrary value you assign to the electric charge, quarks will always be 1/3 of that. That's the problem in question, not the absolute value. reply twic 8 hours agorootparentSo quarks have a charge of 2 or -1, and a two of the former and one of the latter make a proton, which therefore has charge 3. An electron is elementary, but also has charge 3. The question is: that seems like a weird coincidence, how come it's like that? reply aap_ 12 hours agoparentprevCharge is quantized. You cannot have just any amount of electric charge. An electron has three elementary units of negative charge, quarks have -1 and 2. Whether it's a coincidence that proton and electron charge are of the same magnitude (and the neutron is neutral) is another question, but at the elementary level you don't have that much choice for what the charge of a particle is. reply TheOtherHobbes 11 hours agorootparentBut why is charge quantised? In the Standard Model properties are defined as relationships within/between symmetry groups. There are only so many things you can do to/with/in a symmetry group, and that's where the quantisation comes from. But... that's a mathematical metaphor applied to observations. It's a good fit, but it doesn't explain why it's those symmetry groups and not others, or why symmetry groups are a good fit at all. There's likely some kind of fundamental mechanism that generates these symmetries, and no one knows what that is. reply timschmidt 10 hours agorootparentResonance seems a candidate. reply SECProto 12 hours agorootparentprev> quarks have -1 and 2. Wikipedia suggests the quarks that make up the proton have charge ⅔e and -⅓e https://en.wikipedia.org/wiki/Up_quark https://en.wikipedia.org/wiki/Down_quark reply bradrn 12 hours agorootparentThe post you’re replying to seems to be taking ⅓e as the basic unit of charge. reply opportune 12 hours agorootparentprevIs it true that the quarks themselves, in isolation, have that charge? Or is it that combining quarks into a baryon or meson gives the resultant particle a charge according to a fixed ratio of the constituent quarks? Gemini advanced says it’s the latter, because of color confinement. But I’d defer to a human expert reply lnauta 10 hours agorootparentQuarks can not be alone, because of this confinement. What we see experimentally is that when we add energy to particles at some point they split into new particles and we never see a naked quarks. We explain this by saying the quarks have a color charge and it must always be neutral. A single quark would be lets say red, but that's for some reason not possible. If we try to rip the quark out, it takes so much energy that this energy can be used to create another quark that results in a color neutral particle (red, antired)=meson, (red,green,blue)=baryon. NB: this is a bit simplistic and other comments explain this quite in detail NB2: this color charge is just a name, its not an actual color reply hazbot 12 hours agorootparentprevOP assigned -3 units of charge to the electron, so all works out. reply ajkjk 4 hours agoparentprevI don't know the actual answer, but from my understanding of QFT the answer is going to be roughly this shape: Charge is not actually a quantity on the real number line; it's more of a \"count\" of something. Not sure what exactly. The \"topological defect\" model of charges in 2d is a decent analogy though, in which a charge can be e.g. a count of how many vortices there are in a field which are oriented in a certain direction (picture a bathtub with a bunch of drains, and ask, how many tornado-like vortices, if we count clockwise vortices as +1 and counterclockwise as -1, are there? The number can vary but obviously it has to be an integer because what would half a vortex even mean?) But that model is too simple for charge, since quarks have +-1/3 or 2/3 but the result always adds up to an integer in a hadron. Maybe it's something like a type of winding number or linking number? I don't know. Whatever it is, when the \"correct\" explanation is found, it will be obvious why it is always an integer and why its constituents are always 1/3 or 2/3, and it will no longer seem interesting to ask why it can't be any old fraction, because that misunderstands the \"type\" of object that it is counting. reply trenchgun 3 hours agorootparentIs there a reason why we say quarks have fractional charge instead of having just +-1 or +-2? And Then electron and proton would have -3 and +3? reply vihren 3 hours agorootparentThat's purely by convention. It's just that we fist discovered electrons and protons and quarks with their fractional charges came in much later. reply sumitkumar 2 hours agoparentprevMaybe the proton is not complex but the process to probe it is. Proton is an aggregate of emergent phenomena like mass and its resultant properties. For a simplistic model assume that proton is a tetrahedron with energy wave generators at the vertices and how those waves interact with each other creates the emergent phenomena like mass, charge etc. It will be difficult to probe such a tetrahedron by just studying the properties of the waves and the peaks in those waves/interference which are perceived as particles by the probes. reply JumpCrisscross 11 hours agoparentprev> why must protons and electrons be perfectly complementary regarding charge? According to QED's spin origin of charge, it's because charge comes from spin. What values a particle's spin can take are restricted to certain integer or half-integer values. reply gwerbret 9 hours agorootparent> According to QED's spin origin of charge, it's because charge comes from spin. Children have the remarkable ability to see the world as it truly is, and so are able to ask the most profound questions. As adults, we learn to obfuscate our, ah, knowledge deficiencies in various ways, and so lose that ability over time. I'm of the opinion that great physicists are like children in being able to see through to the heart of the matter, and ask -- and answer -- questions that matter. This is certainly a theme you can see with Einstein, Bohr, Feynman, and others. Why do I say this? Because GP's question was profound, and saying \"it's because charge comes from spin\" is the sort of obfuscatory answer I see most physicists give very, very often when they're faced with such questions. That's completely aside from the fact that \"it's because charge comes from spin\" is entirely incorrect. All charged particles have spin, but not all particles with the same spin and other similar properties are charged. reply calamari4065 10 hours agorootparentprevThat just deflects the question one level down without explaining anything. \"Because it is\" is not a helpful answer to \"why?\" reply ravi-delia 10 hours agorootparentThe question wasn't \"why do protons have +1 charge\", it was \"why do protons have +1 charge, *considering electrons have -1 charge\". The fact that possible charges are restricted to a few values is a much more satisfying answer to the latter than the former reply JumpCrisscross 10 hours agorootparentprev> deflects the question one level down without explaining anything There’s a lot of levels to SOC. Which do you think is “because it is?” If you’re asking why spin values are restricted, it’s in the spin-statistics theorem [1]. If you’re asking why spin causes charge, that’s SOC. There are lifetimes of understanding contained within those layers. [1] https://en.m.wikipedia.org/wiki/Spin–statistics_theorem reply magicalhippo 8 hours agorootparentprevRichard Feynman addresses a similar \"why\" question in a great way in this interview[1], and how \"why\" questions are problematic in science. [1]: https://www.youtube.com/watch?v=36GT2zI8lVA reply marton78 9 hours agorootparentprevPhysics doesn't attempt to answer the question \"why\", it answers \"how\". reply empath-nirvana 7 hours agorootparentprevYou eventually have to take _something_ as given. reply gus_massa 7 hours agorootparentprevI never heard this. I'm almost sure it's wrong. Do you have a link? reply adrian_b 12 hours agoparentprevThe fact that the proton has the same charge in absolute value as the electron is just a consequence of the fact that the 8 elementary particles at the lowest energy level, i.e. electron and its neutrino, the 3 up quarks and the 3 down quarks have charges that sum to zero in a 3-dimensional charge space. These 8 particles and their 8 antiparticles are located in the corners of 2 cubes of unit edge in that 3-dimensional charge space. One cube is in the first octant of the coordinates, with 1 corner in the origin, while the other cube is in the opposite octant, also with 1 corner in the origin. The neutrino and the antineutrino are in the origin, while the electron and the positron are in the opposite corners of the cubes, in the points (-1,-1,-1) and (1,1,1), and the quarks and the antiquarks are in the 12 off-diagonal corners of the 2 cubes. As functions of the position vector of a particle in this 3-dimensional charge space, the electric charge is the component of the position vector that is parallel to the cube diagonal that passes through origin and the corners of the electron and positron, while the corresponding component that is orthogonal to the diagonal is the so-called color charge (hence chromodynamics; while the electric forces attempt to make null the 1-dimensional electric charge, the strong forces attempt to make null the 2-dimensional color charge), which is non-null only for the quarks and antiquarks, which are off-diagonal, and it is null for electron, neutrino and their antiparticles. The projections of the off-diagonal corners of the cubes on the diagonal are at one third and two thirds distances from origin, which is why the electric charges of the quarks are 1/3 and 2/3 in absolute value (where the unit of electric charge is the electron charge, i.e. the diagonal of one unit cube), even if in the charge space all the particles have coordinates that are either 1 or 0 in absolute value. While this symmetry of the charges is interesting, it is not known why it is so. In any case, if this symmetry had not existed, the Universe as we know it could not exist, because this symmetry ensures that in the nucleons the total color charge of the quarks is null, so they no longer interact through strong forces (except at very short distances, where the residual forces bind the nucleons into nuclei) and at the next level the total electric charge of the atoms is null, so they no longer interact through electric forces (except at very short distances, where the residual forces bind the atoms into molecules). The same symmetry exists for the other 2 groups of 8 particles and 2 groups of 8 antiparticles, where the muon and the tauon correspond to the electron, because those particles have greater masses but identical charges with the first groups. In the initial state of the Big Bang, this symmetry of the charges ensures that even if there were only particles in equal numbers and without any antiparticles, the total electric charge and the total color charge of all matter was null. While the neutrinos do not contribute to any of the charges, their presence ensures that the total spin, i.e. the total angular momentum, was also null. reply dist-epoch 11 hours agorootparentCan you please link to a picture of the 2 cubes? Is this image another visualization of the same thing?: https://en.wikipedia.org/wiki/File:Standard_Model.svg We know that the electric charge is not fundamental, but a projection of the weak isospin and hypercharge after the Higgs field symmetry breaking. How are weak isospin and hypercharge related to the 2 cubes? reply adrian_b 1 hour agorootparentNo, that figure is not it. I do not remember now where to find a suitable figure, but these are the coordinates of the corners of the 2 cubes: neutrino & antineutrino: (0,0,0) electron: (-1,-1,-1) positron: (1,1,1) down quarks: (-1,0,0), (0,-1,0), (0,0,-1) down antiquarks: (1,0,0), (0,1,0), (0,0,1) up quarks: (1,1,0), (1,0,1), (0,1,1) up antiquarks: (-1,-1,0), (-1,0,-1), (0,-1,-1) The particle-antiparticle pairs have an inversion symmetry over the origin. The quark triplets have a rotational symmetry of order 3 around the principal diagonal of the cubes that passes through the origin. The weak isospin and the hypercharge are an alternative equivalent expression of the charges, but I prefer this picture as it is easier to understand and visualize. It also demonstrates the quantized nature of the charges that determine the strong and electromagnetic interactions, and that they are based on the same quantum, so they are not independent interactions. The also quantized spin must be added as a fourth value, to completely determine the weak interactions too. The various sets of values that can be taken as charges are related by bijections (one-to-one correspondences), so which are taken as fundamental is a matter of convention. In any case the chromodynamics is useful only for providing qualitative insights and for distinguishing things that are possible from those that are impossible. It is completely useless for computing quantities that are useful in practice. As it is also obvious in the parent article, it is still impossible to compute the mass and the magnetic moment of the proton, much less for any more complex nuclei or hadrons. reply dario_od 11 hours agorootparentprevThanks! reply alex_smart 5 hours agoparentprevhttps://youtu.be/36GT2zI8lVA Richard Feynman on why questions reply ajkjk 4 hours agorootparentThat video really annoys me. He's right at one level but totally wrong at another. Yes, you have to explain everything in terms of things people can understand and if they don't know much you can't give a correct explanation... but also, if you actually try, people can understand a lot more than he's pretending they can. Not at a technical level, yeah, but intuitively, it is possible to get general understandings way beyond his attempts at answering that question. For instance fundamental charges are a lot like positive and negatively-oriented vortices in a fluid, which when they touch cancel each other out and radiate energy away. They're not _exactly_ like that, but they're a lot like it, and that's a model people can understand without knowing the first thing about quantum field theory. Sure, you won't understand from that why like-charges repel each other, not really, but if you play with the analogy for a while it starts to seem why that might be true as well. (See https://www.ribbonfarm.com/2015/09/24/samuel-becketts-guide-... for some pictures of this... I wish I had better though.) Magnetism is quite a bit trickier to explain in this model but it can done with some work. In particular: a charge radiates little linear packets of energy just by existing; when one of these packets hits another charged particle it moves a tick closer or further away (based on +/-). A current/moving charge/magnetic dipole radiates away little spiraling packets of energy which are aligned in the plane orthogonal to the conventional magnetic field; when these hit another charged particle they get rotated a tick. reply wrycoder 12 hours agoparentprevIt’s even more complicated. The charge on the electron is partially screened by virtual positive charges emerging briefly from the vacuum, so what we measure is less than the actual charge. reply AnimalMuppet 11 hours agorootparentBut isn't the same thing going on for the proton? (Of course, absent some good reason, one wouldn't expect the two screenings to exactly balance...) reply JohnMakin 10 hours agoparentprevI don’t think this is a stupid thought at all. It’s a very good question and appreciate all the answers, it’s something I’ve wondered myself reply strogonoff 7 hours agoparentprevDon’t take things described by physical models (proton, electron, the idea of “charge”, etc.) at too much of a face value. All it is is a web of predictions: we do A then B seems to happen, reliably. We then transform it into a story of sorts, to categorize and classify, find patterns and correlations—that’s just how our minds work—and those models are useful, as they create shortcuts for more useful predictions—but it’s all too easy to start thinking of entities these models describe as if they were real, concrete things (that’s also how our minds work). I recommend to maintain a sort of Schrödinger’s treatment (they exist if convenient, but otherwise they don’t really) for things described in physical models, because none of the above-mentioned categorization and classification is set in stone. None of it can be proven to be objectively true, unless you have some sort of exclusive access to the fabric of underlying reality that bypasses your consciousness. With that in mind, you would see that the weird coincidences are not that problematic. It just means there is a better model out there, and that will always be the case. reply quantified 6 hours agoparentprevFirst-principles question from an ignorant thinker: why couldn't it be that the presence of +/-e in one of them is due to the subtraction of +/-e in the other? Do we know anything about the finer details of quarks and electrons beyond what we currently can resolve? reply femto 12 hours agoparentprevIn the same vein, a neutron can decay into a proton, an electron and a neutrino (Beta decay), so in some sense the neutral neutron is the combination of an electron and proton. (A connection is there?) In a simplistic way, I see a neutron star as just being a lump of regular (atomic) matter where the high pressure has forced all the electrons into the protons. Question for someone who might know: Was pressure so high in the early universe that matter originally formed as neutrons, then as pressure reduced electrons and protons were able to separate? Sort of like the formation of a neutron star in reverse? reply lnauta 11 hours agorootparentIt was a plasma of quarks and gluons first (these particles make up protons and neutrons and other unstable particles) which did cool down and become these particles. [https://en.m.wikipedia.org/wiki/Chronology_of_the_universe] There is no reason to prefer any of the possible particles, but as all of them are unstable - minus the proton - they eventually decay to that state. (neutrons are not unstable in nuclei and such). NB: this is quite simplistic and I skipped many details reply mr_toad 11 hours agorootparentprevMakes me wonder if the universe as a whole is electrically neutral. Someone should check! reply bugbuddy 12 hours agorootparentprevI also have a question. Why should any theoretical predictions be regarded as Science if there is no feasible way to test them? reply NegativeLatency 11 hours agorootparentI think you might need to define your terms more specifically/clearly to be able to get an answer to this. There's always the layman vs scientists definition of true. Like I think most people would say we know gravity exists, but in actuality we don't really know what gravity is, but we can measure how objects behave and make useful predictions about our world and universe because of that, with it lining up with other stuff we think we know. Sorta similarly there's the scientific definition of something like dark matter/dark energy where there useful for modeling stuff but unlike what the general public thinks nobody has actually been able to point to a physical object that is dark matter to my knowledge, it's dark because it's unseen, not because it's like chunks of black stuff we can't see. reply bugbuddy 7 hours agorootparentI am going to get downvoted into oblivion again for asking this follow up question but that’s what I live for. What is the line between Physics, a scientific endeavor, and Metaphysics, a philosophical one? Please set my transparency as high as you can. I totally deserve it. Let me fade into oblivion. reply SAI_Peregrinus 6 hours agorootparentPhysics is testable within the known laws of physics. Metaphysics is not. reply gls2ro 3 hours agorootparentprevMetaphysics can answer Why questions while Physics is more concerned with How and What questions. reply knightoffaith 5 hours agorootparentprevBroadly speaking, philosophers of science don't think there's a generic answer to what differentiates scientific inquiry from not-scientific (or pseudoscientific) inquiry. Popper put forward the criterion of falsifiability (if it's falsifiable, it's science, otherwise, it's not science), but after Kuhn and Feyerabend's arguments, philosophers generally drifted away from thinking there's some hard-and-fast rule to differentiate science and pseudoscience. If you're interested in these issues, you might enjoy Chalmers' What is this Thing Called Science?, an introduction to the philosophy of science that addresses issues like these. Or a primary source like Feyerabend's Against Method, quite a fun read, though maybe not one that many philosophers of science today would give their full-throated endorsement of. reply dylan604 10 hours agorootparentprevAs long as it's called a theory instead of fact, then why isn't it science. We might not have enough tech or information on being able to create the test. reply instagib 6 hours agoparentprevThere’s a few good “particle zoo” videos out there for the building blocks. I took some advanced courses and from my understanding it comes down to the pieces that make up protons and electrons. In the quantum realm it adds some fuzziness to the answer by introducing quarks. The net charge may be one thing but I would defer to a physics paper for a deeper understanding. https://physics.stackexchange.com/questions/21753/why-do-ele... reply mkw5053 12 hours agoparentprevFirst, I am not a physicist. That said, he's my attempt at an answer that satisfies me: Part of the reason is charge quantization. Neither could be some fractional charge. We also observe charge conservation and electromagnetic force laws as described by quantum electrodynamics (QED). These necessitate that the electron and proton charges be precisely balanced for the universe to function as it does. reply AnimalMuppet 11 hours agorootparentBut in fact, quarks are fractionally charged: +2/3 and -1/3. For this to work, there have to be as many quarks in the proton as the denominator of the quark charge fraction. (And what mechanism forces that?) And why should the charges on quarks be some nice low-number fraction of the charge on the electron? Why not sqrt(3) or something? reply rainbowzootsuit 9 hours agorootparentI think this is more of a historical artifact rather than a fundamental measurement. In the Millikan oil drop experiment he was able to measure quantized units of charge by stripping a single electron from a drop [1], so much later when quarks are figured out they are proportional to the base unit of charge. This is similar to how Ben Franklin, having no knowledge of elementary particles, defined the positive and negative polarity of electricity, so we have \"electron holes\" flowing from the positive end of a battery to the negative end in \"conventional current.\" [2] Edit to add: the electron's non-even charge numbers comes into light when you see that the charge is 1.602176634×10−19 Coulombs, where 1C/second= 1 ampere. If we were trying to come up with the definition of an ampere with nice base 10 numbers of electrons this would be much different. [1] https://en.m.wikipedia.org/wiki/Oil_drop_experiment [2] https://eng.libretexts.org/Bookshelves/Electrical_Engineerin... reply Gravityloss 10 hours agorootparentprevThere exist \"stable\" exotic particles of that have non ordinary amounts of lower level quarks. https://www.symmetrymagazine.org/article/lhcb-discovers-long... Maybe they might have non integer charge. reply exmadscientist 8 hours agorootparentIn QCD, they cannot. All Feynman diagram vertices involved in producing these things (in fact all QCD vertices period) only deal in integer charge units and never leave fractional charges floating around. reply SECProto 12 hours agoparentprevNot a physicist at all but I'd offer the following thoughts on the question of \"why\": - Take a neutron, pull out an electron (and an antineutrino), and you're left with a proton. - Asking why protons and electrons are so different is a little bit like asking why hydrogen and iodine have exactly opposite charges even though iodine is so much more complex: they're made of different things reply empath-nirvana 7 hours agoparentprevOne thing to note is that up and down quarks are separated by exactly one unit of charge (2/3 is 1 more than -1/3). The charge coincidence is one of the reasons that scientists are looking for a grand unified theory -- part of which would ultimately mean that in some sense quarks and electrons are _the same thing_, and the electroweak and strong forces would be unified. reply ambyra 5 hours agoparentprevElectrons balance the nuclear charge by their distance from the nucleus. They’re not perfectly equal; the electrons move closer or farther to maintain balance with the nucleus. I think it’s called effective nuclear charge. reply rimunroe 12 hours agoparentprevSo first off: charge is quantized. Glossing over some weird particles (like quarks) which can't exist by themselves an integer multiple of e as their charge. It's been a while since I finished undergrad so my knowledge is rusty, but I don't recall any isolatable particles whose charge wasn't -1e, 0, or 1e. If that's the case, the easiest explanation for why they have the same charge is that if they didn't have opposite charges there wouldn't be anything holding them together in an atom. reply metricspaces 12 hours agorootparentclearly related to measure (in the abstract sense) and harmonics of natural numbers. what has fascinated me for years has been the sense that we need to rebuild number up using complex numbers and harmonic measures. what we get are still numbers but no longer this monotonic sequence which is a ‘lazy’ or ‘simple minded’ way of ordering N. when ordered by harmonic measures of primes, N itself has structure (beyond a simple incrementing list) but the order is strictly limited to measures provided (rational) with the prime roots of the measure. (an example is the ‘primorial’ harmonic measure of {2, 3, 5} - think rings). in these harmonic measures, ‘gaps’ between various levels naturally would arise from simple (x) op. For non-relative prime members, the mapping n x n is all over the place but for relative prime members, n x n always results in another relative prime in the ring, so, naturally those ‘lines’ are ‘stable’ and ‘in phase’ so ‘manifested’. in other words, there is stuff in the R realm — in between ‘quanta’ — but we’re not allowed, capable, ever, of seeing or measureing it.[edit: as in they ‘exist’ in the same realm that (sqrt -1) i exists in — an unseen realm we call ‘imaginary’..] reply ynniv 8 hours agoparentprevHuh. It would make a lot more sense if the \"complicated\" proton was +3 and always paired with three \"simple\" -1 electrons. Maybe someday we'll find the electron is really three of some even more fundamental particle. reply otabdeveloper4 4 hours agoparentprev> give me a religious explanation that isn't a religious explanation reply westurner 7 hours agoparentprevAre there intermediate [electron,] charge states between + and - in superfluids and/or superconductors? Is there superposition with electron charge states? reply anon84873628 5 hours agorootparentThe typical model of superconductivity says that electrons in the material pair up to form a quasiparticle -- the \"cooper pair\" -- with new properties, namely not experiencing resistance. The original quantized charge of the electrons still adds up to the same amount. Unlike protons an neutrons, electrons are considered elementary particles that can't be broken down any further, so their charge can not be \"divided\" into something less than 1. reply dboreham 11 hours agoparentprevSomething...something...gauge theory. Or perhaps -- it's a constant in the simulator source code. reply dylan604 10 hours agorootparentMaybe it's so difficult because it's not a constant, but a magic number used in the code. (yeah, I'm dealing with lots of magic numbers in some code currently being worked on) reply mise_en_place 2 hours agoparentprevI mean it's not that complicated to understand. e is just a physical constant. It's been measured as such, with varying degrees of precision. The creator is as lazy a programmer as we are. To make the math work, + and - are used. reply jkhdigital 12 hours agoparentprevBecause if it were any other way then you wouldn’t exist to sit there and ponder the question. That’s the unsatisfying answer. I think it makes sense to draw an analogy to evolution—stable arrangements of elementary particles that (somehow) reinforce similar arrangements around them will come to dominate the observable universe. reply xwolfi 4 hours agoparentprevMaybe think of it more simply, one precedes the other, this much positive charge in one place attracts negative charge of equal magnitude around it: if you send more electrons (and to be honest, talking of positive charge for a proton is a bit wrong: a positive charge being the absence of electrons... and electrons giving the \"negative\" charge as they add up), they'll detach and push away those that were already there. There is nothing convenient, it's as logical as saying that you were tshirts when you go out: there is nothing extraordinary that one torso = one tshirt, as having two or zero tshirts wouldn't help: 0 would make you want one more tshirt, 2 would make you want to remove one. reply api 10 hours agoparentprevAt the end of the day loads of these types of questions boil down to the anthropic principle. If it didn’t work out so that things could be stable, nothing would be asking the question. That’s not a satisfying answer but we don’t have a better one in the realm of science. All we have left is either randomness/serendipity or spirituality/religion. reply wruza 10 hours agorootparentOne issue I have with anthropic filter is that for some reason fundamental parameters fit into a tiny neat table. So out of the vastness of incredibly complex universes that boggle the minds of their creatures we ended up here: https://en.wikipedia.org/wiki/File:Standard_Model_of_Element... reply api 9 hours agorootparentMaybe there’s an inverse relationship between complexity and the odds of it being stable. Universes with 500000 elementary particles might end up as entropy baths with no interesting structure. Meanwhile those with too few might be “crystals” with no dynamism. In all kinds of systems including computational models like cellular automata there exists a threshold known as the “edge of chaos” where among other interesting things universal computation becomes possible. https://en.m.wikipedia.org/wiki/Edge_of_chaos Maybe our universe is in such a zone. Not too simple for dynamic open ended phenomena, not too complex for order. reply Mistletoe 8 hours agoparentprevI believe the end of my physics textbook in college just said “be grateful that the charge on the electron is what it is because without it our universe wouldn’t exist if it was even slightly different” or something to that effect. Our universe may be the trillionth trillionth one created and we are in an anthropomorphic universe just like we are on an anthropomorphic planet. It always makes me grateful. >The charge on a proton is +1.602 x 10-19 C, and the charge on an electron is -1.602 x 10-19 C. reply Mistletoe 1 hour agorootparentSorry that should say anthropic and not anthropomorphic haha. Too much time has elapsed to edit it. https://en.wikipedia.org/wiki/Anthropic_principle reply leptons 10 hours agoparentprev>why must protons and electrons be perfectly complementary regarding charge? if the proton is this insanely complex thing, by what rule does it end up equaling exactly the opposite charge of an electron? Perhaps \"complexity\" and \"anti-complexity\" are the forces that attract. Order and chaos. To have one you must have the other. Without both nothing about this universe would work. Sorry, I'm high. reply carabiner 11 hours agoparentprevWhy does light decay quadratically and not linearly? Why are the laws of physics algebraic at all? Why did the Big Bang happen? Ask enough why's and get to: we just don't know. Turtles all the way down. reply computerfriend 7 hours agorootparentThe first one is well known. It's because it's radiating in three dimensions. https://en.m.wikipedia.org/wiki/Inverse-square_law reply m3kw9 12 hours agoparentprevThen I’ll ask why can’t you use protons as electricity? reply gus_massa 7 hours agorootparentIt is posible if you remove the wires. In a CRT monitor, you have a ray of electrons that travel in vaccum and it is electricity outside wires. With a similar device, you can create a ray of protons and have also electricity with protons instead of electrons. Another posibility is to use a water solution with acid. A part of the electricity is made of H+ that are just protons. (Actually, each proton is atached to a water molecule, so it's more like H2O+ than a plain H+.) I'm triying to imagine a wire where protons can move. I don't think it's theoreticaly impossible, but they are mmuch heavier and bigger than electrons, so they it looks very difficult to find a material where they can move freely. reply AdamH12113 2 hours agorootparentprevIn solids (like metals and semiconductors) the atomic nuclei form stable structures (often crystals). Protons are bound to their nuclei, and the nuclei don’t move, so neither do the protons. Electrons, on the other hand, can move between atoms, which allows them to form an electrical current. There are special cases, but that’s the basic answer. reply sumitkumar 2 hours agorootparentprevProtons are electricity. But slow. All acid/base reactions. Proton gradients and pumps in the biological cells all work on slow proton electricity. reply s1artibartfast 11 hours agorootparentprevWho says you can't? Who says we don't always use it? reply jodrellblank 6 hours agorootparentNot sure, but Protons are ~1800x more massive than electrons even though they have the same electric charge, so it seems like they would need 1800x more energy to move them. Power in an electric circuit is Watts, which is current in Amperes times voltage. Amperes are one Coulomb or 6.241509x10^18 electric charges per second flowing through a conductor. So a fixed amount of power (Watts) moves a known amount of charges. If we were sometimes moving protons instead of electrons, maybe we’d notice three orders of magnitude difference in quantity of charges in different experiments? reply sumitkumar 2 hours agorootparentIt is not yet proven that electrons need to flow from point A to point B to transfer electric energy. There is local movement but not in the sense that electrons are flowing through a hose to transfer power. reply ludsan 10 hours agorootparentprevthe proton motive force powers us all reply sixQuarks 7 hours agoparentprevYou would think that with my username, I should know the answer. But I have no clue reply at_a_remove 12 hours agoparentprevI'll take a shot at this. The \"answer,\" such as it is, is symmetry. The electron belongs to a group called the leptons, which is to say they are lightweight. Leptons obey certain sorts of statistics and consist of the electron, the muon, the tau lepton, the electron neutrino, the muon neutrino, the tau neutrino, and their antiparticles. That's twelve in total. The mirror of the leptons would be quarks. Up, down, charm, beauty, top, and bottom ... and their antiparticles. Twelve again! Their charges are 2/3e, -1/3e, 2/3e, -1/3e, 2/3e, -1/3e, and the reverse for the antiquarks. One bundle of three quarks is the proton, and it happens to be 2/3e + 2/3e + -1/3e. But so what? There's all kinds of other bundles. Three-quark bundles are typically hadrons (heavyweight) and two-quark bundles are mesons (medium weight). So you have a lot of choices on the other side! The choices are caused by something called color confinement, which states that you will not get quarks alone. Indeed, you can take a pair of quarks in the aforementioned meson, and if you stretched them further and further apart, when the bond between them (mediated by gluons) snapped, you would have put so much energy into the stretching and snapping to create two new quarks, one at each end of your broken rubber band. Just as you cannot cut a piece of string such that it only has one end, so you have it with color confinement. I don't want to get too far away from the main point but because of this, quarks are found (normally, outside of Big-Bang quark-gluon plasmas) in combination ... and so eventually one of the combinations has a charge number resembling that of the electron. Also, positrons aren't really the opposite of electrons. They're opposite on the matter/antimatter axis, which automatically flips the charge, q. They are not opposite along the lepton-quark axis, nor are they opposite along the electron-neutrino axis. Instead of one mirror, imagine many mirrors at angles to one another, and \"opposite\" becomes a less useful term. reply fblp 5 hours agorootparentThis is hard to wrap my brain around but thank you for the explanation! reply oldandtired 2 hours agorootparentprevOne problem with your explanation is that the muon and the tau (and the pion as a decay product of the tau) all decay into electrons, neutrinos and photons, which would suggest that neither muon or tau are fundamental. This would put the fundamental leptons being only the electron (and its antiparticle) with the neutrino and the photon. Such an idea would upset the \"symmetry\" model. reply FredPret 9 hours agoparentprevHow can you ask that and also claim to not be a smart person lmao reply y04nn 12 hours agoparentprevI'm not an expert, but e is the smallest possible charge, so you can't have a fraction of it, probably related to to Plank constant. Edit: after verification, the smallest possible charge is e/3 (the quantum charge), e is the elementary charge. A relevant link to for the question: https://en.wikipedia.org/wiki/Elementary_charge?useskin=vect... reply dcow 3 hours agoprev“The proton is a quantum mechanical object that exists as a haze of probabilities until an experiment forces it to take a concrete form.” I’m getting really tired of hazy probability distributions and waves that only collapse and materialize when observed. I 100% accept that QM is a useful tool to model our current understanding based on increasingly sophisticated observations, but I fundamentally don’t believe that a proton is some shape shifting quantum soup of energy that doesn't form until someone comes around and thinks about it. That is unless reality is approximated and expensive compute is directed only toward what’s being observed to better enhance the simulation. I probably need to add that I am also tired of simulation theory. I really suspect we just aren't good enough at observing things or don’t exist in enough dimensions to understand what we’re observing. And so the cross sections we are able to pin down end up looking like they are part of some probabilistic system. I still have bets on this all being a massive game of life. reply sph 48 minutes agoparentI get what you mean, but still I'd rather accept probabilistic particles than the 11-dimensional bull that is string theory. reply vladms 2 hours agoparentprevIn the opposite direction, I feel mildly annoyed when people expect a precise/clear answer to questions which can be answered mostly/better with probability distributions. Considering how you can test statistics in real life (ex: Buffon's Needle) there must be something very \"statistical\" embedded in reality itself (it is true that quantum mechanics pushes everything very far so can seem to complex). reply desmosxxx 2 hours agoparentprevIIUC, that is just a hidden variables theory. Bells theorem tells us that it would at least be non-local which is just as weird/interesting IMO. reply notfed 2 hours agoparentprev> I fundamentally don’t believe that a proton is some shape shifting quantum soup of energy that doesn't form until someone comes around and thinks about it This is a pop-sci analogy. I find it tiring as well. The many worlds interpretation doesn't paint the picture this way. It paints it as a recursive for-each loop iterating over all solutions to the next step of the physics function. > I still have bets on this all being a massive game of life. ...on the back of a giant turtle, amiright? How bout placing your bets on this instead: it's the evaluation of an algorithm (\"physics\") on a data structure (\"the universe\"), and like all algorithms, exists eternally and independent of any substrate. reply scotty79 2 hours agoparentprevFor my personal purposes I resolved the issue by looking at elementary particles as if they are only the \"probability\" waves. Never anything else. Measurement is just an interaction and it reshapes the waves making them narrower. But they never become pointlike particles with specified location or momentum. They are always more or less fuzzy. If they are all bound into macroscopic object they are sharper and as a result they can make other elementary particles they \"measure\" (interact with) also sharper. If particles interact with fuzzier part of macroscopic object, like an edge of a slit, they can become fuzzier, more wavy. So the proton really is that shapeshifting soup. Never anything else. If you hit it with something hard enough it becomes momentarily disturbed into a bit sharper state that can tell us something but it immediately goes back to soup because of chaotic microscopic interactions inside. The matter looks sharp only on macroscopic level. At the level of particles it's always fuzzy, but we have trouble of ditching the concept of little balls bouncing of each other because the math describing exchange of energy and momentum between those fuzzy \"waves\" looks like there were some small balls bouncing. But this comes, I believe accidentally only from the fact that all forces have sort of spherical symmetry. reply blackhaj7 12 hours agoprevI have no doubt quantum physicists know what they are talking about but when I read stuff like: “changes its appearance depending on how it is probed\" \"you can’t even imagine how complicated it is\" \"the proton contains traces of particles called charm quarks that are heavier than the proton itself\" I always think it is the kind of excuse a schoolkid would give their teachers for their calculations being wrong reply Rayhem 12 hours agoparent> I have no doubt quantum physicists know what they are talking about but...I always think it is the kind of excuse a schoolkid would give their teachers for their calculations being wrong. Just to emphasize how extreme this dichotomy is, not only is quantum mechanics correct (in that it's a predictive model), it's the most correct physical theory humans have ever devised in that the measurements there have more significant figures than anything else. reply mcmoor 12 hours agorootparentIt's interesting that semiconductor engineers have to directly wrestle with the magic that's quantum tunneling. This theory is really not just a theory. reply tonyarkles 7 hours agorootparentIn some devices it's something they have to fight against. In others, like SSDs, it's the feature that makes them work! It's not just a theory and it's not just another flaw that we've got to work around, we've taken it from a theory and turned it into useful technology. reply neuromanser 10 hours agorootparentprevYou mean it's not just a hypothesis. I would really, really expect users of this site to know the difference. reply andrewflnr 8 hours agorootparentUsers of this site who pay attention to how science is actually practiced, and not the oversimplified cartoon version they teach us in school, know that the boundary between a \"theory\" and a \"hypothesis\" is rather blurry. For instance, have you ever noticed how it's called \"string theory\" despite having no real evidence for it? Have you ever heard anyone, let alone a real scientist, complain about this nomenclature? Early theories and fleshed-out hypotheses overlap a lot. There's no sharp transition from one to the other. reply snowwrestler 6 hours agorootparentString theory is supported by a ton of evidence in that it can produce many predictions and hypotheses that match observed data. That’s why it’s called a “theory” and why people continue to study it. What’s missing is a test that would produce evidence that would allow us to distinguish between string theory and competing theories. But that’s not nearly the same thing as saying it has “no real evidence.” reply andrewflnr 5 hours agorootparentIn fact that's exactly what I meant by saying it has \"no real evidence\". Otherwise you could claim the totality of the universe as evidence for your pet Theory of Everything as long as it's not actually falsified yet, including but not limited to a theory where fundamental particles are fairies who use slide rules to decide how to interact. reply volemo 1 hour agorootparentIf you fairy theory predicts the outcomes as well as the other theories that are on the table now then indeed it belongs there with them until someone finds a way to distinguish them and prove one is a better model of the reality. Better yet if the fairy model makes the calculations \"cleaner\" and easier. reply philipswood 6 hours agorootparentprevCorrect me if I'm wrong, but string theory is still in the \"it's so pretty and elegant is must be true kind of territory\". Not only do they have no proof, most of the potential experimental confirmations are at energies so high they're effectively out of reach for the foreseeable near future. reply infamouscow 7 hours agorootparentprevI think it's important to draw a distinction between the formal and natural sciences. HN is overrepresented by folks with backgrounds in mathematics and computer science where using \"theory\" is correct, e.g., set theory. Bret Weinstein explained the distinction between a hypothesis and theory a few weeks ago on YOUR WELCOME. https://www.youtube.com/watch?v=ac4MnNrs6g4 reply andrewflnr 6 hours agorootparentI specifically cited an example in the natural sciences, specifically physics. IIRC chemistry and biology do similar shenanigans at times. Again, consider how you could possibly draw a sharp distinction when accumulation of evidence is so often a gradual process. I'll consider responding to the video if you give me a reasonable timeslice, but I'm not going to watch the whole hour. reply elpocko 10 hours agorootparentprevWhat if they don't? Will they cease to be users of this site? What if they speak a lot more languages than you, just not perfectly? Does it even matter what you would expect? reply mcmoor 6 hours agorootparentprevThe (scientific) theory is really not just a (colloquial) theory reply sph 45 minutes agorootparentprevWe used fire in our daily lives even before organic chemistry existed. reply julianeon 8 hours agorootparentprevThe other famous example is PET scanners, which actually use a form of antimatter: positrons (the antimatter counterpart of electrons). reply hwillis 8 hours agorootparentYou don't even need that. The prediction he's referring to as most accurate is the magnetic moment of the electron, which is used in plain old MRIs. If we didn't have the quantum mechanical correction, all of our MRI images would be distorted. Only by a few pixels, but it'd be noticeable! reply seeknotfind 10 hours agorootparentprevSo many significant digits includes a level of self-consistency of the model, since we are assuming the model to some degree in order to measure it. Though in this case, it's not the calculations that are wrong, but the model, we hope is wrong. That is, a new perspective and a new way of thinking about things may reveal more. Of course, we are always fighting against the irreducible complexity camp. However, the fundamental lack of cohesion between quantum and relativistic theories demonstrates there is at least one big thing we are still doing wrong. reply hwillis 8 hours agorootparent> So many significant digits includes a level of self-consistency of the model No, that's incorrect. The specific measurement -the most accurate scientific prediction humans have ever made, the anomalous magnetic moment- is only to 1 in 10 trillion. The magnetic moment (think moment of inertia) is the ratio of force from the magnetic field to the mass of the electron. You put an electron into a magnetic field, and it'll turn to face the field at a certain speed. If you stick the electron in a vacuum, it overshoots (because of rotational momentum) and ends up wobbling back and forth at a specific frequency. That's how MRIs work; they make a big magnetic field (stronger on one end) and then measure how many electrons are wobbling in different areas, since the electrons in high-strength fields wobble faster. Specifically, you expect the wobble to get ~2.8025 GHz (similar to a microwave oven) faster for every 1000 gauss (please, no jokes about teslas). It's very convenient to measure a difference in frequency, since you can just measure the drift over time. Because that frequency is relatively high it takes about 30 minutes for the frequency to drift off by a half-cycle and totally cancel out your referenc",
    "originSummary": [
      "Physicists are continuing to investigate the intricate nature of protons, as they have been found to exhibit various forms depending on observation.",
      "Recent research has revealed that protons contain charm quarks that are actually heavier than the proton itself, challenging the traditional understanding of proton composition.",
      "The conventional quark model, which posits that protons are composed of three quarks, is considered to be an oversimplification in light of these findings.",
      "Machine learning analysis has demonstrated that protons can exist in multiple states, including a rare state featuring five quarks.",
      "Understanding the composition of protons is crucial for experiments conducted at the Large Hadron Collider and for studying cosmic rays.",
      "Future experiments aim to delve deeper into the structure of protons, providing more comprehensive information in this field."
    ],
    "commentSummary": [
      "The discussion includes multiple topics in particle physics and the nature of the universe, such as the possibility of multiple universes and the concept of fine-tuning.",
      "There is a debate about whether science can provide answers to \"why\" questions, and the limitations of scientific models and theories are also explored.",
      "The properties of particles, including their charges and stability, are discussed, along with the challenges of understanding quantum mechanics and perception of reality."
    ],
    "points": 425,
    "commentCount": 370,
    "retryCount": 0,
    "time": 1707938778
  },
  {
    "id": 39371669,
    "title": "Conformant M1 GPU: Supporting OpenGL 4.6 and OpenGL ES 3.2",
    "originLink": "https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html",
    "originBody": "Conformant OpenGL 4.6 on the M1 14 Feb 2024 For years, the M1 has only supported OpenGL 4.1. That changes today – with our release of full OpenGL® 4.6 and OpenGL® ES 3.2! Install Fedora for the latest M1/M2-series drivers. Already installed? Just dnf upgrade --refresh. Unlike the vendor’s non-conformant 4.1 drivers, our open source Linux drivers are conformant to the latest OpenGL versions, finally promising broad compatibility with modern OpenGL workloads, like Blender, Ryujinx, and Citra. Conformant 4.6/3.2 drivers must pass over 100,000 tests to ensure correctness. The official list of conformant drivers now includes our OpenGL 4.6 and ES 3.2. While the vendor doesn’t yet support graphics standards like modern OpenGL, we do. For this Valentine’s Day, we want to profess our love for interoperable open standards. We want to free users and developers from lock-in, enabling applications to run anywhere the heart wants without special ports. For that, we need standards conformance. Six months ago, we became the first conformant driver for any standard graphics API for the M1 with the release of OpenGL ES 3.1 drivers. Today, we’ve finished OpenGL with the full 4.6… and we’re well on the road to Vulkan. Compared to 4.1, OpenGL 4.6 adds dozens of required features, including: Robustness SPIR-V Clip control Cull distance Compute shaders Upgraded transform feedback Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1. While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set. How do we break the 4.1 barrier? Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on. For a taste of the challenges we overcame, let’s look at robustness. Built for gaming, GPUs traditionally prioritize raw performance over safety. Invalid application code, like a shader that reads a buffer out-of-bounds, can trigger undefined behaviour. Drivers exploit that to maximize performance. For applications like web browsers, that trade-off is undesirable. Browsers handle untrusted shaders, which they must sanitize to ensure stability and security. Clicking a malicious link should not crash the browser. While some sanitization is necessary as graphics APIs are not security barriers, reducing undefined behaviour in the API can assist “defence in depth”. “Robustness” features can help. Without robustness, out-of-bounds buffer access in a shader can crash. With robustness, the application can opt for defined out-of-bounds behaviour, trading some performance for less attack surface. All modern cross-vendor APIs include robustness. Many games even (accidentally?) rely on robustness. Strangely, the vendor’s proprietary API omits buffer robustness. We must do better for conformance, correctness, and compatibility. Let’s first define the problem. Different APIs have different definitions of what an out-of-bounds load returns when robustness is enabled: Zero (Direct3D, Vulkan with robustBufferAccess2) Either zero or some data in the buffer (OpenGL, Vulkan with robustBufferAccess) Arbitrary values, but can’t crash (OpenGL ES) OpenGL uses the second definition: return zero or data from the buffer. One approach is to return the last element of the buffer for out-of-bounds access. Given the buffer size, we can calculate the last index. Now consider the minimum of the index being accessed and the last index. That equals the index being accessed if it is valid, and some other valid index otherwise. Loading the minimum index is safe and gives a spec-compliant result. As an example, a uniform buffer load without robustness might look like: load.i32 result, buffer, index Robustness adds a single unsigned minimum (umin) instruction: umin idx, index, last load.i32 result, buffer, idx Is the robust version slower? It can be. The difference should be small percentage-wise, as arithmetic is faster than memory. With thousands of threads running in parallel, the arithmetic cost may even be hidden by the load’s latency. There’s another trick that speeds up robust uniform buffers. Like other GPUs, the M1 supports “preambles”. The idea is simple: instead of calculating the same value in every thread, it’s faster to calculate once and reuse the result. The compiler identifies eligible calculations and moves them to a preamble executed before the main shader. These redundancies are common, so preambles provide a nice speed-up. We usually move uniform buffer loads to the preamble when every thread loads the same index. Since the size of a uniform buffer is fixed, extra robustness arithmetic is also moved to the preamble. The robustness is “free” for the main shader. For robust storage buffers, the clamping might move to the preamble even if the load or store cannot. Armed with robust uniform and storage buffers, let’s consider robust “vertex buffers”. In graphics APIs, the application can set vertex buffers with a base GPU address and a chosen layout of “attributes” within each buffer. Each attribute has an offset and a format, and the buffer has a “stride” indicating the number of bytes per vertex. The vertex shader can then read attributes, implicitly indexing by the vertex. To do so, the shader loads the address: Some hardware implements robust vertex fetch natively. Other hardware has bounds-checked buffers to accelerate robust software vertex fetch. Unfortunately, the M1 has neither. We need to implement vertex fetch with raw memory loads. One instruction set feature helps. In addition to a 64-bit base address, the M1 GPU’s memory loads also take an offset in elements. The hardware shifts the offset and adds to the 64-bit base to determine the address to fetch. Additionally, the M1 has a combined integer multiply-add instruction imad. Together, these features let us implement vertex loads in two instructions. For example, a 32-bit attribute load looks like: imad idx, stride/4, vertex, offset/4 load.i32 result, base, idx The hardware load can perform an additional small shift. Suppose our attribute is a vector of 4 32-bit values, densely packed into a buffer with no offset. We can load that attribute in one instruction: load.v4i32 result, base, vertex << 2 …with the hardware calculating the address: What about robustness? We want to implement robustness with a clamp, like we did for uniform buffers. The problem is that the vertex buffer size is given in bytes, while our optimized load takes an index in “vertices”. A single vertex buffer can contain multiple attributes with different formats and offsets, so we can’t convert the size in bytes to a size in “vertices”. Let’s handle the latter problem. We can rewrite the addressing equation as: That is: one buffer with many attributes at different offsets is equivalent to many buffers with one attribute and no offset. This gives an alternate perspective on the same data layout. Is this an improvement? It avoids an addition in the shader, at the cost of passing more data – addresses are 64-bit while attribute offsets are 16-bit. More importantly, it lets us translate the vertex buffer size in bytes into a size in “vertices” for each vertex attribute. Instead of clamping the offset, we clamp the vertex index. We still make full use of the hardware addressing modes, now with robustness: umin idx, vertex, last valid load.v4i32 result, base, idx << 2 We need to calculate the last valid vertex index ahead-of-time for each attribute. Each attribute has a format with a particular size. Manipulating the addressing equation, we can calculate the last byte accessed in the buffer (plus 1) relative to the base: The load is valid when that value is bounded by the buffer size in bytes. We solve the integer inequality as: The driver calculates the right-hand side and passes it into the shader. One last problem: what if a buffer is too small to load anything? Clamping won’t save us – the code would clamp to a negative index. In that case, the attribute is entirely invalid, so we swap the application’s buffer for a small buffer of zeroes. Since we gave each attribute its own base address, this determination is per-attribute. Then clamping the index to zero correctly loads zeroes. Putting it together, a little driver math gives us robust buffers at the cost of one umin instruction. In addition to buffer robustness, we need image robustness. Like its buffer counterpart, image robustness requires that out-of-bounds image loads return zero. That formalizes a guarantee that reasonable hardware already makes. …But it would be no fun if our hardware was reasonable. Running the conformance tests for image robustness, there is a single test failure affecting “mipmapping”. For background, mipmapped images contain multiple “levels of detail”. The base level is the original image; each successive level is the previous level downscaled. When rendering, the hardware selects the level closest to matching the on-screen size, improving efficiency and visual quality. With robustness, the specifications all agree that image loads return… Zero if the X- or Y-coordinate is out-of-bounds Zero if the level is out-of-bounds Meanwhile, image loads on the M1 GPU return… Zero if the X- or Y-coordinate is out-of-bounds Values from the last level if the level is out-of-bounds Uh-oh. Rather than returning zero for out-of-bounds levels, the hardware clamps the level and returns nonzero values. It’s a mystery why. The vendor does not document their hardware publicly, forcing us to rely on reverse engineering to build drivers. Without documentation, we don’t know if this behaviour is intentional or a hardware bug. Either way, we need a workaround to pass conformance. The obvious workaround is to never load from an invalid level: if (level <= levels) { return imageLoad(x, y, level); } else { return 0; } That involves branching, which is inefficient. Loading an out-of-bounds level doesn’t crash, so we can speculatively load and then use a compare-and-select operation instead of branching: vec4 data = imageLoad(x, y, level); return (level <= levels) ? data : 0; This workaround is okay, but it could be improved. While the M1 GPU has combined compare-and-select instructions, the instruction set is scalar. Each thread processes one value at a time, not a vector of multiple values. However, image loads return a vector of four components (red, green, blue, alpha). While the pseudo-code looks efficient, the resulting assembly is not: image_load R, x, y, level ulesel R[0], level, levels, R[0], 0 ulesel R[1], level, levels, R[1], 0 ulesel R[2], level, levels, R[2], 0 ulesel R[3], level, levels, R[3], 0 Fortunately, the vendor driver has a trick. We know the hardware returns zero if either X or Y is out-of-bounds, so we can force a zero output by setting X or Y out-of-bounds. As the maximum image size is 16384 pixels wide, any X greater than 16384 is out-of-bounds. That justifies an alternate workaround: bool valid = (level <= levels); int x_ = valid ? x : 20000; return imageLoad(x_, y, level); Why is this better? We only change a single scalar, not a whole vector, compiling to compact scalar assembly: ulesel x_, level, levels, x, #20000 image_load R, x_, y, level If we preload the constant to a uniform register, the workaround is a single instruction. That’s optimal – and it passes conformance. Blender “Wanderer” demo by Daniel Bystedt, licensed CC BY-SA. Back to home",
    "commentLink": "https://news.ycombinator.com/item?id=39371669",
    "commentBody": "Conformant OpenGL 4.6 on the M1 (rosenzweig.io)409 points by patadune 17 hours agohidepastfavorite81 comments zdimension 10 hours agoAlyssa Rosenzweig is a gift to the community that keeps on giving. Every one of her blog posts is a guarantee to learn something you didn't know about the internals of modern graphics hardware. reply noiv 14 hours agoprevThis endeavour proofs to me skills beat talkativeness every single day. Just reading the blogs sets my brain on fire. There is so much to unpack. The punch line is not the last but the second sentence, nevertheless you're forced to follow the path into the rabbit hole until you enjoy reading one bit manipulation after the other. If there ever are benchmarks with eureka effects per paragraph Alyssa will lead them all. Just thanks! reply jokoon 10 hours agoprevOne day, Apple will deprecate opengl 3.3 core, and I guess everybody might end up deprecating it. I've read that generally opengl is just easier to use than vulkan, I don't know if that's true, but if something is too complicated, it becomes just too hard for less experienced devs to exploit those GPU, and it becomes a barrier to entry, which might discourage some indie game developers. Although everyone uses unity and unreal now, baking things from scratch or using other engines is just weird now, for some reason. It's really annoying, and it's fun to see gamedev wake up after unity tried to lock things more. Open source in gaming has always been stretched thin. Godot is there, but I doubt it's able to seriously compete with unity and unreal even if I want it to, so even if godot is capable, indie gamedevs are more experienced with unity and unreal and will stick to those. The state of open source in game dev feels really hopeless sometimes, the rise of next gen graphics API are not making things easy. reply taminka 9 hours agoparent> I've read that generally opengl is just easier to use than vulkan [here's](https://learnopengl.com/code_viewer_gh.php?code=src/1.gettin...) an opengl triangle rendering example code (~200 LOC) [here's](https://vulkan-tutorial.com/code/17_swap_chain_recreation.cp...) a vulkan triangle rendering example code (~1000 LOC) ye it's fair to say opengl is a bit easier to use ijbol reply _gabe_ 5 hours agorootparentYou’re getting downvoted for some reason, but OpenGL is absolutely easier. It abstracts so much (and for beginners there’s still a ton even with all the abstraction!). No need to think about how to prep pipelines, optimally upload your data, manually synchronize your rendering, and more with OpenGL, unlike Vulkan. The low level nature of Vulkan allows you to eek out every bit of performance, but for indie game developers and the majority of graphics development that doesn’t depend on realtime PBR with giant amounts of data, OpenGL is still immensely useful. If anything, an OpenGL-like API will naturally be developed on top of Vulkan for the users that don’t care about all that stuff. And once again, I can’t stress this enough, OpenGL is still a lot for beginners. Shaders, geometric transformations, the fixed function pipeline, vertex layouts, shader buffer objects, textures, mip maps, instancing, buffers in general, there’s sooo much to learn and these foundations transcend OpenGL and apply to all graphics rendering. As a beginner, OpenGL allowing me to focus on the higher level details was immensely beneficial for me getting started on my graphics programming journey. reply scheeseman486 4 hours agorootparentIt won't be OpenGL-like, it will probably just be OpenGL https://docs.mesa3d.org/drivers/zink.html reply zozbot234 9 hours agorootparentprevThis is a bit misleading. Much of the extra code that you'd have to write in Vulkan to get to first-triangle is just that, a one-time cost. And you can use a third-party library, framework or engine to take care of it. Vulkan merely splits out the hardware-native low level from the library support layer, that were conflated in OpenGL, and lets the latter evolve freely via a third party ecosystem. That's just a sensible choice. reply MindSpunk 9 hours agorootparentAnd often those LOC examples use GLFW or some other library to load OpenGL. Loading a Vulkan instance is a walk in the park compared to initializing an OpenGL context, especially on Windows. It's incredibly misleading. If you allowed utility libraries for Vulkan to compare LOC-to-triangle Vulkan would be much closer to OpenGL. reply xign 5 hours agoparentprevFWIW Metal is actually easier to use than Vulkan in my opinion, as Vulkan is kind of designed to be super flexible and doesn't have as much niceties in it. Either way, OpenGL was simply too high level to be exposed as the direct API of the drivers. It's much better to have a lower level API like Vulkan as the base layer, and then build something like OpenGL on top of Vulkan instead. It maps much better to how GPU hardware works this way. There's a reason why we have a concept of software layers. It's also not quite true that everyone uses Unity and Unreal. Just look at the Game of the Year nominees from The Game Award 2023. All 6 of them were built using in-house game engines. Among indies there are also still some amount of developers who develop their own engines (e.g. Hades), but it's true that the majority of them will just use an off-the-shelf one. reply SkiFire13 1 hour agoparentprevWGPU is kinda supposed to solve the problem by making a cross platform API more user friendly than Vulkan. The problem with OpenGL is that it is too far from how GPUs work and it's hard to get good performance out of it. reply badsectoracula 42 minutes agorootparentIt is hard to get the absolute best performance out of OpenGL but it isn't really hard to get good performance. Unless you're trying to make some sort of seamless open world game with modern AAA level of visual fidelity or trying to do something very out of the ordinary, OpenGL is fine. A bigger issue you may face is OpenGL driver bugs but AFAIK the main culprit here was AMD and a couple of years ago they improved their OpenGL driver to be much better. Also at this point OpenGL still has no hardware raytracing extension/API so if you need that you need to use Vulkan (either just for the RT bits with OpenGL interop or switching to it completely). My own 3D engine uses OpenGL and while the performance is perfectly fine, i'm considering switching to Vulkan at some point in the future to have raytracing support. reply zamalek 3 hours agoparentprevOpenGL is not deprecated, it is simpler and continues to be used where Vulkan is overkill. Using it for greenfields is a good choice if it covers all your needs (and if you don't mind the stateful render pipeline). reply pjmlp 2 hours agorootparentIt kind of is, OpenGL 4.6 is the very last version, the red book only covers until OpenGL 4.5, and some hardware vendors are now shipping OpenGL on top of Vulkan or DirectX, instead of providing native OpenGL drivers. While not officially deprecated, it is standing still and won't get anything newer past 2017 hardware, not even newer extensions are being made available. reply klausa 2 hours agorootparentprevIt is officially deprecated on all Apple platforms, and has been for five years now. Whether it will actually stop working anytime soon is a different question; but it is not a supported API. reply magicalhippo 4 hours agoparentprev> One day, Apple will deprecate opengl 3.3 core, and I guess everybody might end up deprecating it. And here I am, recalling all the games and programs that failed once OpenGL 2.0 was implemented because they required OpenGL 1.1 or 1.2 but just checked the minor version number... time flies! reply saagarjha 9 hours agoparentprevMy understanding is that one of the primary reasons Vulkan was developed was because OpenGL was not a good model for GPUs, and supporting it prevented people from taking advantage of the hardware in many cases. reply Wowfunhappy 11 hours agoprev> Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1. While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set. I'm very curious to know the performance impact of this, particularly compared to using Metal on macOS. (I'm sure the answer is \"it depends\", but still.) It's possible the article answers this question, but I didn't understand most of it. :( reply gilgoomesh 11 hours agoparentThere isn't necessarily much difference between implementing features in driver compute code versus GPU hardware support. Even the \"hardware support\" is usually implemented in GPU microcode. It often goes through the same silicon. Any feature could hit a performance bottleneck and it's hard to know which feature will bottleneck until you try. reply politician 16 hours agoprevThis is for Fedora on the M1. It would be amazing to get this for macOS. What's involved in pulling something like that off? reply jamesfmilne 15 hours agoparentUltimately they build command buffers and send them to the GPU. You'd need a way to do that from macOS. The original Mesa drivers for the M1 GPU were bootstrapped by doing just that, sending command buffers to the AGX driver in macOS using IOKit. https://rosenzweig.io/blog/asahi-gpu-part-2.html https://github.com/AsahiLinux/gpu/blob/main/demo/iokit.c So you'd need a bit more glue in Mesa to get the surfaces from the GPU into something you can composite onto the screen in macOS. reply skykooler 1 hour agoparentprevAccording to the devs, it isn't really possible due to Apple not having a stable public kernel API: https://social.treehouse.systems/@AsahiLinux/111930744188229... reply fayalalebrun 15 hours agoparentprevPerhaps already possible via MoltenVK -> Vulkan -> Zink? reply Guzba 14 hours agorootparentProbably needs one or two more layers just to be sure. reply shmerl 4 hours agoparentprevI think Apple bans third party kernel drivers? To write a proper Vulkan or OpenGL implementation you need a kernel counterpart for handling the GPU if I understand correctly. That's probably the reason no one bothers implementing native Vulkan for macOS. But if it's doable with Apple's driver - then not sure. reply saagarjha 9 hours agoprevI find it very amusing that transitioning out of bounds accesses from traps to returning some random data is called “robustness”. Graphics programming certainly is weird. reply wtallis 6 hours agoparentIt makes sense from the perspective of writing graphics drivers, and aligns with Postel's law (also called the robustness principle). GPU drivers are all about making broken applications run, or run faster. Making your GPU drivers strict by default won't fix the systemic problems with the video game industry shipping broken code, it'll just drive away all of your users. And on hardware where branches are generally painfully expensive, it sounds really useful to have a flag to tell the system to quietly handle edge cases in whatever way is most efficient. I suspect there are a lot of valid use cases for such a mode where the programmer can be reasonably sure that those edge cases will have little or no impact on what the user ends up seeing in the final rendered frame. reply monocasa 5 hours agoparentprevThe out of bounds accesses don't necessarily trap without the robustness checks, so the robustness is about delivering known results under those goofy cases. So it makes sense when you combine that with the fact that GPUs are pretty against traps in general. Carmack remarked once that it's was a pain to get manufacturers to be into the idea of virtual memory when he was designing megatexture. reply pjmlp 2 hours agoparentprevThis is one of the reasons why C and C++ have a rosy life ahead of themselves on graphics, HPC, HEP, HFT domains. In domains where \"performance trumps safety\" culture reigns, talking about other programing languages is like talking to a wall. reply breather 14 hours agoprevThis is obviously very exciting, but—why not target Vulkan first? It seems like the more salient target these days and one on top of which we already have an OpenGL implementation. reply mort96 11 hours agoparentOpenGL-on-Vulkan compat layers aren't magic. For them to support a given OpenGL feature, an equivalent feature must be supported by the Vulkan driver (often as an extension). That means you can't just implement a baseline Vulkan driver and get OGL 4.6 support for free, you must put in the work to implement all the OGL 4.6 features in your Vulkan driver if you want MESA to translate OGL 4.6 to Vulkan for you. Plus, this isn't Alyssa's first reverse engineering + OpenGL driver project. I don't know the details but I'd imagine it's much easier and quicker to implement a driver for an API you're used to making drivers for, than to implement a driver for an API you aren't. reply wtallis 14 hours agoparentprevThey started with targeting older OpenGL to get a basic feature set working first. I guess from there, getting up to a more recent OpenGL was less work than doing a complete Vulkan implementation, and they probably learned a lot about what they'll need to do for Vulkan. reply breather 12 hours agorootparentOk, this makes a lot of sense—OpenGL sort of forms a pathway of incremental support. reply simcop2387 12 hours agorootparentAlong with that, it's more immediately useful as it's used for desktops and compositers still, so getting a useful environment necessitates it. reply shmerl 14 hours agoparentprevI thought something similar, but from their comments, to support OpenGL over Vulkan you need higher versions of Vulkan anyway and it's still a big effort. So they decided to go with (lower versions of) OpenGL first to get something functional sooner. reply jauntywundrkind 15 hours agoprev> How do we break the 4.1 barrier? Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on. I wonder how much of this work is in m1 gpu code, versus how much feature-implemented-on-another-festure work could be reused by others. This feels very similar to what Zink does (runs complex opengl capabilities via a more primitive Vulkan), except there is no Vulkan backend to target for m1. Yet. reply zozbot234 11 hours agoparentMore generally, you could execute complex OpenGL or Vulkan on some more-or-less arbitrary combination of CPU soft-rendering and hardware-specific native acceleration support. It would just be a matter of doing the work, and it could be reused across a wide variety of hardware - including perhaps older hardware that may be quite well understood but not usable on its own for modern workloads. reply ics 16 hours agoprevAnother upvote, another article I wish I had the knowledge and patience to understand better in context. Still, Alyssa's writeups are a fun read. reply randgoog 15 hours agoparentSame, I wish I knew more about graphics programming. It seems like such a steep learning curve though so I get discouraged. reply yazzku 5 hours agorootparentDon't be discouraged, modern graphics APIs really are a mess, but you don't need to understand 1/100th of them to get graphics going. Also, this post is more about programming drivers than programming graphics. reply ryandvm 15 hours agoprevKind of crazy to think that the only reason OpenGL was ever a thing for 3D gaming was because of John Carmack's obsession with using it for Quake II back in the 90s. reply pjmlp 2 hours agoparentJohn Carmack a couple of years later, back in 2011: > Speaking to bit-tech for a forthcoming Custom PC feature about the future of OpenGL in PC gaming, Carmack said 'I actually think that Direct3D is a rather better API today.' He also added that 'Microsoft had the courage to continue making significant incompatible changes to improve the API, while OpenGL has been held back by compatibility concerns. Direct3D handles multi-threading better, and newer versions manage state better.' > It is really just inertia that keeps us on OpenGL at this point,' Carmack told us. He also explained that the developer has no plans to move over to Direct3D, despite its advantages. From https://www.bit-tech.net/news/gaming/pc/carmack-directx-bett... reply marcodiego 15 hours agoparentprevQuake is just (a probably small (not wanting to dimish it, of course)) part of the history. SGI and the enormous effort to get compliant implementations on many different systems and architectures are what made OpenGL what it eventually became. reply JohnBooty 13 hours agorootparentI think both SGI and Quake were absolutely crucial. Without Quake, OpenGL would have remained an extremely niche thing for professional CAD and modeling software. And Microsoft would have completely owned the 3D gaming API space. Quake (and Quake 2, and Quake 3, and the many games that licensed those engines) really opened the floodgates in terms of mass market users demanding OpenGL capabilities (or at least a subset of them) from their hardware and drivers. I'm not sure how to measure this in an objective way, but if the mass market of PC gamers didn't dwarf the professional CAD/modeling market by several orders of magnitude, I will print out my HN posting history and eat it. reply pjmlp 2 hours agorootparentMicrosoft never owned the 3D gaming API space, SEGA, Sony and Nintendo also have/had their own APIs. reply throwaway11460 19 minutes agorootparentI never heard about SEGA, Sony or Nintendo 3D APIs being used on a PC. I guess somebody somewhere did it, but it's so insignificant. reply cmovq 15 hours agoparentprevI don’t know that it was the only reason, but Carmack’s push for OpenGL certainly helped. A lot of things related to 3D games are thanks to doom and Quake. reply badsectoracula 11 hours agorootparentIt also helped that the API was actually user friendly compared to the earlier versions of Direct3D. reply pengaru 14 hours agorootparentprev> A lot of things related to 3D games are thanks to doom and Quake. Quake sure, but Doom? IIRC Doom is far more like Wolf3D's 2.5D/raycasting than the \"true 3D\" of Quake, it cpu rendered to a frame buffer with zero hardware acceleration. I find it hard to believe it made any lasting impact on any subsequent 3D rendering APIs. reply Narishma 13 hours agorootparentQuake didn't use hardware acceleration either. It was only the later VQuake and GLQuake releases that did. reply JohnBooty 13 hours agorootparentI think for the purposes of this discussion \"Quake\" is acceptable shorthand for GLQuake, Quake 2, Quake 3, all the games that used those engines, etc. reply babypuncher 11 hours agorootparentprevQuake got official 3D accelerated versions like GLQuake and VQuake. The improved visuals and better performance these versions offered drove a lot of early 3D accelerator sales in the consumer space. reply badsectoracula 11 hours agoparentprevFun fact: the earliest archived OpenGL site was a big \"FAST GAMES GRAPHICS\" banner with an animated Quake 1 graphic and a menu for other stuff :-P https://web.archive.org/web/19970707113513/http://www.opengl... reply Keyframe 14 hours agoparentprevFor context https://www.chrishecker.com/OpenGL/Press_Release reply bitwize 14 hours agoparentprevAnd yet it still got its ass kicked by Direct3D because Microsoft made better stuff. Better API, better tooling, better debuggability. Honestly, it would've been better to leave OpenGL to the legacy CAD vendors and standardize on Direct3D roundabout 1997 or so. reply Keyframe 14 hours agorootparentYe good ol' Microsoft stiffled OpenGL on Windows, hence open letter https://www.chrishecker.com/OpenGL/Press_Release not to mention insidious thing they did on Fahrenheit (next gen OpenGL+Direct3D, one to rule them all) when they were supposed to be working on it together with SGI. Microsoft did a well job after with it, but they were and are a shit company that made sus maneuvers to make success; Not all of them technical. reply breather 14 hours agorootparentprevWell, except for only working on xbox and windows, which pretty much destroys it as a viable direct target for modern games or apps. > Honestly, it would've been better to leave OpenGL to the legacy CAD vendors and standardize on Direct3D roundabout 1997 or so. If you remember what Microsoft was like in those days, the chances of D3D being standardized in a viable way on any platform but windows were about the same chances as an ice cube in hell stands. reply pjmlp 2 hours agorootparentNintendo and Sony 3D APIs are also exlusive to their consoles, people keep forgeting about them. reply TillE 10 hours agorootparentprev> a viable direct target for modern games Aside from PlayStation exclusives, nearly every AAA game in the past 20+ years has targeted Direct3D and HLSL first. Any other backend is a port. reply p_l 9 hours agorootparentThe XBox versions of DirectX aren't exactly compatible (in some pretty significant ways, IIRC) reply malermeister 14 hours agorootparentprevTechnically, also Linux (and probably other Vulkan platforms) with dxvk. reply breather 12 hours agorootparentI had no idea this was a thing! Cheers. reply malermeister 12 hours agorootparentThere's also VKD3D for dx12! reply marcodiego 15 hours agoprev [–] \"Unlike the vendor’s non-conformant 4.1 drivers, our open source Linux drivers are conformant to the latest OpenGL versions, finally promising broad compatibility with modern OpenGL workloads, like Blender, Ryujinx, and Citra.\" Looks like apple silicon are currently the best hardware for running linux and linux is the best OS for apple silicon machines. reply Aurornis 15 hours agoparent> Looks like apple silicon are currently the best hardware for running linux and linux is the best OS for apple silicon machines Blender has Metal support for Apple Silicon macs. The Metal API is better architected (largely due to being more modern and being developed with benefit of hindsight) so all things equal I'd pick the Metal version on Mac. In case you missed it in the article, the M1 GPU does not natively support OpenGL 4.6. They had to emulate certain features. The blog post goes into some of the performance compromises that were necessary to make the full OpenGL emulation work properly. Absolutely a good compromise if you're on Linux and need to run a modern OpenGL app, but if your only goal is to run Blender as well as possible then you'd want to stick to macOS. Ryujinx is a Nintendo Switch emulator. They added support for Apple Silicon Macs a couple years ago and have been improving since then: https://blog.ryujinx.org/the-impossible-port-macos/ Linux on Apple hardware has come a long way due to some incredible feats of engineering, but it's far from perfect. Calling it the \"best OS for Apple Silicon\" is a huuuuge reach. It's great if you need to run Linux for day to day operations, though. reply galad87 15 hours agorootparentRight, Blender Cycles for example can run on Metal, but neither on OpenGL or Vulkan. So while it's nice to have a working OpenGL, it depends if your workflow requires OpenGL apps. reply vetinari 14 hours agorootparentI would be very surprised, if Blender Cycles ever ran on top of OpenGL or Vulkan other than using OpenGL or Vulkan as a loader for compute shaders. That's why it is running as CUDA/OptiX/HIP/oneAPI on Windows and Linux. reply johnbatch 14 hours agoparentprevStrange the article doesn't use the word \"Apple\" once, and instead awkwardly uses \"the vendor\" to refer to Apple. reply breather 14 hours agorootparentIt's inline with how the linux/floss community refers to hardware vendors in general, even if Apple is a unique case in many circumstances. reply doubled112 10 hours agorootparentDidn't CentOS use \"the vendor\" instead of RHEL like this too? reply sho_hn 15 hours agoparentprevI would love for my employer to support that config at work. We have quite lovely Linux dev laptops, but the battery life of the M1/M2 machines in the IT shop is definitely enticing, and Asahi Linux gets closer to MacOS in that regard than you might think given the relative maturity and optimization. reply eek2121 11 hours agorootparentIt definitely isn’t ready for use as a daily driver. There are lots of bits missing (see below for an example) and power management isn’t great compared to macOS. reply rowanG077 4 hours agorootparentHow so? I'm daily driving it as my only machine since November.sure there are missing features but none that are really essential for most people. reply klausa 2 hours agorootparentYou and I have very different work environments for you to be able to claim that microphones aren't essential for most people. reply tarruda 11 hours agoparentprev> Looks like apple silicon are currently the best hardware for running linux I wonder if this effort to run Linux on apple silicon will continue if snapdragon X laptops become mainstream. reply seabrookmx 1 hour agorootparentI think it will. One of the main issues with desktop linux is still broad hardware support. Random crap like fingerprint readers or Wi-Fi cards still don't work on certain machines. By having a very constrained set of hardware options, it makes it a lot easier to support. The snapdragon devices are also starting way behind.. both the Surface X and Lenovo X13S snapdragon devices exist today but Linux support isn't close to Asahi. reply brucethemoose2 14 hours agoparentprevAnd Sodium! (For minecraft) reply specto 14 hours agoparentprevStill waiting for some hardware support and hardware video decoding. reply stirlo 13 hours agorootparentHardware video decoding is well on the way: https://github.com/eiln/avd reply vrodic 15 hours agoparentprevapparently a lot of hardware is still not properly supported, like speakers, microphones and energy saving reply acdha 14 hours agorootparentHere’s the list of very detailed support status: speakers are generally supported but microphones are not. They have a driver for some energy savings but it has some rough edges. https://github.com/AsahiLinux/docs/wiki/Feature-Support reply seba_dos1 15 hours agoparentprev [–] ...and you came to that conclusion because of OpenGL 4.6 - something that several other platforms enjoyed under GNU/Linux with FLOSS drivers for more than half a decade now? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The M1 graphics processor now supports the latest versions of OpenGL, making it compatible with popular applications like Blender and Citra.",
      "The M1's open-source Linux drivers have undergone extensive testing for correctness, passing over 100,000 tests.",
      "Although the M1 may not align perfectly with newer graphics standards, clever workarounds have been implemented to ensure robustness and compatibility."
    ],
    "commentSummary": [
      "The discussion revolves around the complexities of OpenGL in comparison to Vulkan and concerns regarding its deprecation.",
      "The dominance of Unity and Unreal engines, limitations of open source alternatives, and considerations for transitioning to Vulkan are highlighted.",
      "The conversation delves into the challenges and benefits of implementing GPU features, the impact on performance, and the advantages of using C and C++ in graphics programming.",
      "The history and popularity of OpenGL, its comparison to Direct3D, and Microsoft's influence are explored.",
      "The compatibility of Linux on Apple Silicon hardware and the limitations of certain hardware options are mentioned."
    ],
    "points": 409,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1707927524
  },
  {
    "id": 39372159,
    "title": "Reor: An Open-Source, Privacy-Focused AI Note-Taking App",
    "originLink": "https://github.com/reorproject/reor",
    "originBody": "Reor is an open-source AI note-taking app that runs models locally.The four main things to know are:1. Notes are connected automatically with vector search. You can do semantic search + related notes are automatically connected.2. You can do RAG Q&A on your notes using the local LLM of your choice.3. Embedding model, LLM, vector db and files are all run or stored locally.4. Point it to a directory of markdown files (like an Obsidian vault) and it works seamlessly alongside Obsidian.Under the hood, Reor uses Llama.cpp (node-llama-cpp integration), Transformers.js and Lancedb to power the local AI features.Reor was built right from the start to support local models. The future of knowledge management involves using lots of AI to organize pieces of knowledge - but crucially, that AI should run as much as possible privately & locally.It&#x27;s available for Mac, Windows & Linux on the project Github: https:&#x2F;&#x2F;github.com&#x2F;reorproject&#x2F;reor",
    "commentLink": "https://news.ycombinator.com/item?id=39372159",
    "commentBody": "Reor – An AI note-taking app that runs models locally (github.com/reorproject)315 points by samlhuillier 17 hours agohidepastfavorite79 comments Reor is an open-source AI note-taking app that runs models locally. The four main things to know are: 1. Notes are connected automatically with vector search. You can do semantic search + related notes are automatically connected. 2. You can do RAG Q&A on your notes using the local LLM of your choice. 3. Embedding model, LLM, vector db and files are all run or stored locally. 4. Point it to a directory of markdown files (like an Obsidian vault) and it works seamlessly alongside Obsidian. Under the hood, Reor uses Llama.cpp (node-llama-cpp integration), Transformers.js and Lancedb to power the local AI features. Reor was built right from the start to support local models. The future of knowledge management involves using lots of AI to organize pieces of knowledge - but crucially, that AI should run as much as possible privately & locally. It's available for Mac, Windows & Linux on the project Github: https://github.com/reorproject/reor kepano 14 hours agoThis is a good reminder of why storing Obsidian notes as individual Markdown files is much more useful than stuffing those notes in a database and having Markdown as an export format. The direct manipulation of files allows multiple apps to coexist and do useful things on top of the same files. reply michaelmior 13 hours agoparentIt's very possible to have multiple apps coexisting using a database. Although I'll certainly concede that it's probably a lot easier with just a bunch of Markdown files. reply kepano 13 hours agorootparentSure, it's possible, but whichever app owns the database ultimately controls the data, the schema, etc. The file system provides a neutral database that all apps can cooperate within. reply dietr1ch 9 hours agorootparentI guess what really matter is ultimate ownership of the data, if it's a sqlite-like db or a bunch of markdown files in my machine I can work with them, but if it's on a cloud (someone else's computer), then I'm doomed. reply Ringz 13 hours agoparentprevThat was the reason why I gave up Joplin very quickly. The last Joplin thread, here on Hacker News, has also shown once again that some still do not understand why \"But Joplin can export Markdown from the database!\" is not the same as simple, flat Markdown files. reply traverseda 13 hours agorootparentYeah, that's also why I dropped it. Got too complicated when I wanted to start linking my notes into my work timesheets. reply erybodyknows 12 hours agorootparentprevMay I ask what you switched to? Running into the same issue. reply mjochim 41 minutes agorootparentOn desktop, my favorite text editor plus my favorite file browser. On Android, Markor. reply Ringz 1 hour agorootparentprevI use Obsidian and Markdownload (a Browserplugin). reply msravi 2 hours agorootparentprevNot OP, but I switched to notable which also uses plain markdown. reply iansinnott 9 hours agorootparentprevNot OP but Obsidian (as mentioned) and Logseq are both good options. reply pokstad 8 hours agoparentprevFiles seem less useful for small bits of information. I feel the urge to fill a file with a minimum threshold. A database makes more sense for that. reply lannisterstark 4 hours agorootparent>I feel the urge to fill a file with a minimum threshold. Honestly that's more you subjectively than database v files. reply TeMPOraL 1 hour agorootparentEverything about database v. files is subjective like that. Filesystem is a database, just with more established tradition around schema and use patterns, and system level APIs. On the other hand, you get to implement concurrent access yourself. Multiple apps working on the same files simultaneously only works when none of them makes a mistake with caching or locking. reply snthpy 4 hours agoparentprevIs a filesystem not a database with a varchar unique primary key, a blob data attribute and a few more metadata fields? reply toddmorey 13 hours agoparentprevYes it was one of the best product decisions y'all made. Been so useful to have direct access to the files and options on how my data is processed and backed up. reply xenodium 12 hours agoparentprevI got an iOS journaling app on beta. It’s offline, no sign-in, no lock-in, social, etc. Saves to plain text. Syncs to your desktop if needed. https://xenodium.com/an-ios-journaling-app-powered-by-org-pl... reply samlhuillier 14 hours agoparentprevAbsolutely! Really respect the work you folks are doing. reply toddmorey 13 hours agoprev\"crucially, that AI should run as much as possible privately & locally\" Just wanted to say thank you so much for this perspective and fighting the good fight. reply samlhuillier 13 hours agoparentThank you! reply humbleferret 15 hours agoprevGreat job! I played around with this on a couple of small knowledge bases using an open Hermes model I had downloaded. The “related notes” feature didn't provide much value in my experience, often the link was so weak it was nonsensical. The Q&A mode was surprisingly helpful for querying notes and providing overviews, but asking anything specific typically just resulted in less than helpful or false answers. I'm sure this could be improved with a better model etc. As a concept, I strongly support the development of private, locally-run knowledge management tools. Ideally, these solutions should prioritise user data privacy and interoperability, allowing users to easily export and migrate their notes if a new service better fits their needs. Or better yet, be completely local, but have functionality for 'plugins' so a user can import their own models or combine plugins. A bit like how Obsidian[1] allows for user created plugins to enable similar functionality to Reor, such as the Obsidan-LLM[2] plugin. [1] https://obsidian.md/ [2] https://github.com/zatevakhin/obsidian-local-llm reply ilaksh 7 hours agoparentWhich model exactly did you use and how large? I feel like even the best 7b models are just a bit too dumb for most things that I have tried. A 70b model or Mixtral or sometimes 34b seem to be adequate for some things. But those are several times larger and don't run on my oldish hardware. reply samlhuillier 15 hours agoparentprevThank you for your feedback! Working hard on improving the chunking to improve related notes section. RAG is fairly naive right now, with lots of improvements coming in the next few weeks. reply monkmartinez 10 hours agorootparentI left an issue to explain this in more detail, but I don't think the problem is chunking. The issue is the prompt. The local LLM space does itself no favors by thinking about and using prompts as an after thought. IME, the prompt should be front/center in terms of importance and the key to unlocking the models potential. It's one of the main reasons why Textgen-Webui is sooooo good. You can really dial-in the prompt, from the template itself to working with the system message. Then begin futzing with the myriad of other parameters to achieve fantastic results. reply mcbetz 15 hours agoprevInteresting project, wishing you all the best! If you are using Obsidian, Smart Connections in v2 (1) does also support local embeddings and shows related notes based on semantic similarity. It's not super great on bi/multi-lingual vaults (DE + EN in my case), but it's improving rapidly and might soon support embedding models that cater for these cases as well. (1) https://github.com/brianpetro/obsidian-smart-connections reply fastball 16 hours agoprevDoes the future of knowledge management involve using lots of AI to organize pieces of knowledge? I think \"here be dragons\", and that over-relying on AI to do all your organization for you will very possibly (probably?) cause you to become worse at thinking. No data to back this up because it is still early days in the proliferation of such tools, but historically making learning and thinking and \"knowledge management\" more passive does not improve outcomes. reply bhpm 15 hours agoparent> I think \"here be dragons\", and that over-relying on AI to do all your organization for you will very possibly (probably?) cause you to become worse at thinking. Socrates said exactly this. But when they came to writing, Theuth said: “O King, here is something that, once learned, will make the Egyptians wiser and will improve their memory; I have discovered a potion for memory and for wisdom.” Thamus, however, replied: “O most expert Theuth, one man can give birth to the elements of an art, but only another can judge how they can benefit or harm those who will use them. And now, since you are the father of writing, your affection for it has made you describe its effects as the opposite of what they really are. In fact, it will introduce forgetfulness into the soul of those who learn it: they will not practice using their memory because they will put their trust in writing, which is external and depends on signs that belong to others, instead of trying to remember from the inside, completely on their own. You have not discovered a potion for remembering, but for reminding; you provide your students with the appearance of wisdom, not with its reality. Your invention will enable them to hear many things without being properly taught, and they will imagine that they have come to know much while for the most part they will know nothing. And they will be difficult to get along with, since they will merely appear to be wise instead of really being so.” reply fastball 8 hours agorootparentFair, but the difference is that \"remembering from the inside\" and \"writing stuff down\" are still both activities that you are doing. And to in spite of this quote, writing does make the process of remembering/synthesizing information more active – you are engaging more parts of the brain in order to think about and write down the material. We have seen this on fMRIs, and there is a decent amount of evidence that handwriting works even better for this than typing, due to the higher level of spatial awareness involved (that's the theory). An AI doing the work for you is the opposite of that. reply OJFord 14 hours agorootparentprev> > I think \"here be dragons\", and that over-relying on AI [...] > Socrates said exactly this. I roughly recalled where you were going to go with that afterwards, but I couldn't help but 'spit take' at that given some of the quotes he does get credited with! reply davidy123 14 hours agorootparentprevSo if you only converse with LLMs (and never write or read anything), is the problem solved? reply hgomersall 2 hours agoparentprevHonest discussion point: do you think organisational stuff is important thinking? IME it's precisely this sort of stuff that distracts me from thinking about hard stuff - the urgent displacing the important. reply samlhuillier 16 hours agoparentprevI agree with this. In some cases, hard thinking and searching for things manually can really enhance understanding and build your knowledge. In other cases, particularly when ideating for example, you want to be given \"inspiration\" from other related ideas to build upon other ideas you've had previously. I think it's a mix of both - reaching for AI as and when when you need it - but avoiding it intentionally at times as well. reply ParetoOptimal 14 hours agoparentprevI think you want to organize your own knowledge graph and then use the LLM to find novel connections or answer questions based upon it. reply fastball 8 hours agorootparentBut if you are the one finding connections in your knowledge graph, then the neurons are not only connected on your machine but in your brain as well. Probably a moot point once we have brain-machine interfaces, but we're not quite there yet. reply dvorka 2 hours agoprevRear is a really interesting project with admirable goals. I believe this is just the beginning, but you have already done a great job! I have been working on my note-taking application (https://github.com/dvorka/mindforger) for some time and wanted to go in the same direction. However, I gave up (for now). I used ggerganov/llama.cpp to host LLM models locally on a CPU-only machine with 32GB RAM, and used them for both RAG and note-taking use cases (like https://www.mindforger.com/index-200.html#llm). However, it did not work well for me - the performance was poor (high hardware utilization, long response times, failures, and crashes) and the actual responses were rarely useful (off-topic and impractical responses, hallucinations). I tried llama-2 7B with 4b quantization and a couple of similar models. Although I'm not happy about it, I switched to an online commercial LLM because it performs really well in terms of response quality, speed, and affordability. I frequently use the integrated LLM in my note-taking app as it can be used for many things. Anyway, Reor \"only\" uses the locally hosted LLM in the generation phase of the RAG, which is a nicely constraint use case. I believe that a really lightweight LLM - I'm thinking about a tiny base model fine-tuned for summarization - could be the way to go (fast, non-hallucinating). I'm really curious to know if you have any suggestions or if you will have any in the future! As for the vector DB, considering the resource-related problems I mentioned earlier, I was thinking about something similar to facebookresearch/faiss, which, unlike LanceDB, is not a fully-fledged vector DB. Have you made any experiments with similarity search projects or vector DBs? I would be interested in the trade-offs similar to small/large/hosted LLMs. Overall, I think that both RAG with my personal notes as a corpus and a locally hosted generic purpose LLM for the use cases I mentioned above can take personal note-taking apps to a new level. This is the way! ;) Good luck with your project! reply CrypticShift 15 hours agoprevSome suggestions : - Create multiple independent \"vaults\" (like obsidian). - Append links to related notes, so you can use (Obsidian's) graph view to map the AI connections. - \"Minimize\" the UI to just the chat window. - Read other formats (mainly pdfs). - Integrate with browser history/bookmarks (maybe just a script to manually import them as markdown ?) Thanks for Reor ! reply samlhuillier 14 hours agoparentThanks for your feedback! - Multiple vaults is in fact in a PR right now: https://github.com/reorproject/reor/pull/28 - Manual linking is coming. - Minimizing the UI to chat is interesting. Right now I guess you can drag chat to cover anything - but yes perhaps a toggle between two modes could be interesting. - Read other formats also something in the pipeline. Just need to sort out the editor itself to support something like this. Perhaps pdfs would just be embedded into the vector db but not accessible to the editor. - Integrating with browser history and bookmarks is a big feature. Things like web clipping and bringing in context from different places are interesting... reply haswell 11 hours agoprevLiterally yesterday I spun up a project with the intent to build something exactly like this for Obsidian. Excited to see something already far more realized, and I’m looking forward to trying this out. I’ve been working on a larger than small writing project using Obsidian, and my ultimate goal is to have conversations with the corpus of what I’ve written, and to use this to hone ideas and experiment with new ways of exploring the content. Not sure if local LLMs are powerful enough yet to enable meaningful/reliable outcomes, but this is the kind of stuff that really excites me about the future of this tech. reply sofixa 10 hours agoparentThere are these plugins: https://github.com/zatevakhin/obsidian-local-llm https://github.com/hinterdupfinger/obsidian-ollama Which already exist and if nothing else are decent starting points. > Not sure if local LLMs are powerful enough yet to enable meaningful/reliable outcomes I've dabbled, briefly, with Ollama running Mistral locally on an M1 MacBook Pro with 32GB of unified memory, and throwing a couple of hundred markdown documents at it via a RAG resulted in quite decent output to prompts asking questions about abstract contents/summariesbbased on those docs. So I'd say we're already at a point where you can have meaningful outcomes; reliability is a whole other issue though. reply haswell 9 hours agorootparentThanks for sharing these; I’ll definitely check these out. I somehow missed these during my initial search for similar projects. I recently got my hands on an RTX 3090 for my Linux workstation and I’m planning to try getting some kind of remote setup going for my MacBook Air. Great to hear about decent output. Reliability is negotiable as long as there’s some value and hopefully a path to future improvements. reply WildGreenLeave 2 hours agorootparentA starting point for that might be the way I am doing it. I am using LocalAI to expose OpenAI compatible endpoints and then get access to those via Tailscale. reply wbogusz 16 hours agoprevGreat to see something like this actualized. I’m a huge fan of Obsidian and its graph based connections for note taking. Always see parallels drawn between Obsidian note structures and whole “2nd brain” idea for personal knowledge management, had seemed like a natural next step would be to implement note retrieval for intelligent references. Will have to check this out reply elcombato 1 hour agoprevI really like this idea and the app, but beware when using your existing logseq folder it will mess up the structure/indentation/bullet-points of the notes. reply davidy123 14 hours agoprevSuper interesting project. I like its focus. Wondering if the author looked into Cozodb, or other databases that combine vector + graph/triples. Since probably neuro-symbolic is the best path. https://docs.cozodb.org/en/latest/releases/v0.6.html talks about this idea. reply jddj 1 hour agoparentExtremely interesting read, thanks for sharing. reply samlhuillier 14 hours agoparentprevInteresting. Thanks for sharing will take a look! reply nerdjon 13 hours agoprevI have been looking for a while for a better way to take notes, what I was using worked fine but it did tend to end up being a blackhole. I just downloaded this, I realize that it is still a new tool. But I think a critical feature needs to be context. The ability to have completely separate contexts of notes, maybe even completely different databases. That way similar sounding to an LLM but contextually different don't get brought up. I figured that is what \"new directory\" did but it does not appear that way. So is there any plans to implement a switcher for database? I can't find a way to change where it is right now. But doing some quick tests importing some notes in it does seem very promising and I really like where you are taking it. It is just confusing notes that should be in distinct contexts. Edit: I see this is already in PR! Awesome. reply dev_tty01 8 hours agoprevCan I still just run grep on my notes? Not trying to be snide, just wondering if the raw text remains available for simple text operations. reply bemusedthrow75 14 hours agoprevI think I struggle to see any application of LLMs for my notes that wouldn't, in practice, be just as easily implemented as a search facility. My main challenge with my notes (that I've been collecting for about 15 years) is remembering to consult them before I google. I suppose a unified interface to both my notes via LLM and internet search would help, but then I get that with my Apple Notes and the Mac's systemwide search, if I remember to use it. reply traverseda 14 hours agoparentIt's not the application of LLMs for your notes, it's the application of your notes for an LLM. Like if you're running a custom code-generation LLM, it could refer back to parts of your notes using retrieval aided generation to get some more context on the work you're having it do. But yes, a good application is probably a ways away. Still, LLM vector embedding make a good search engine pretty easy to implement, especially if you're working with small sets of well curated data where exact keyword matching might not work great. Like if you search for \"happy\" you could get your happiest journal entries, even if none of them explicitly mention the word happy. reply rcarmo 12 hours agoprevI did my usual test for these things - I tossed in the Markdown source for my site, which has 20 years of notes (https://taoofmac.com/static/graph). Surprisingly, indexing sort of worked. But since I have an index.md per folder (so that media is grouped with text for every note) the editor is confused, and clicking on links always took me to a blank screen. Also, pretty much every question gives an error message that says \"Error: The default context shift strategy did not return a history that fits the context size\", likely because there is too much context... Edit: Fixed most of it by using a mistral instruct model. But the editor does not know what front matter is (neither in editing nor in previews, where front matter looks like huge heading blocks) reply rcarmo 53 minutes agoparentAlso, it destroyed front matter on a few files I clicked on, which is a big no-no. Filed that as an issue. reply sigmonsays 3 hours agoprevserious question: when do you ever have your own notes and can't find the answer ? i would call it bad note taking to not be able to recall an answer you put into your notes. I like the idea of something like this but i've struggled to find a real use case. reply infectoid 3 hours agoparentYou underestimate the number of bad notetakers. I’m one of them. This tool might actually make me take better notes. Maybe. reply SamBam 16 hours agoprevSo if I point this at my existing Obsidian library, what happens? Does this add to existing files, or add new files, to store the output of things generated by the AI? Doe the chunking of the files only happen within the vector database? What if I later edit my files in Obsidian and only open up Reor after -- does the full chucking happen every time, or can it notice that only a few new files exist? Just wondering what the interaction might be for someone who uses Obsidian but might turn to this occasionally. reply samlhuillier 16 hours agoparentIt's filesystem mapping 1:1. Basically the same thing Obsidian does when you open a vault. You can create new files with Reor, create directories and edit existing files. Chunking happens only in vector DB and everything is synced automatically so you shouldn't notice anything if you reopen Reor after using Obsidian. In short, yes it'd work seamlessly if you wanted to use it occasionally. reply dkarras 16 hours agoprevI had been researching stuff related to this for some time. Interesting project! Why not an obsidian plugin to tap into the ecosystem? reply samlhuillier 15 hours agoparentTwo reasons: 1. The libraries I used to run models locally didn't work inside a plugin. 2. I believe AI is a fairly big paradigm shift that requires new software. reply cfcfcf 16 hours agoparentprevSeconded. I like this idea but wouldn't want to trade the Obsidian UI. Would love to see something like this as a plugin. reply 2024throwaway 11 hours agoprevRunning with a Local LLM on a Mac M1, this completely locked up my system for minutes. I tried to let it run, because the progress bar was ticking every now and then, but after 10 minutes I gave up and killed it. reply tarruda 11 hours agoparentI wouldn't recommend unless you got at least 16gb ram (though possibly more is needed depending on what model is used). reply 2024throwaway 11 hours agorootparentI do have 16gb ram. reply donclark 6 hours agoprevCould I share an idea(note) with a friend? And we grow the idea together? reply erickf1 13 hours agoprevI like the idea. Unfortunately, could not get it to work on Linux. Making a note caused a crash. Searching notes crashed. LLM chat would cause crash. Hope to see it work some time. reply nextaccountic 8 hours agoprevIs this really fully open source? What is the catch / what is the proprietary part? reply Donaldzibe 4 hours agoprevI entrusted EXPERT ELOISE WILBERT ON INSTAGRAM. and experienced triple profits within 24 hours. A true master in crypto and forex, her exceptional account management skills are matched by her unwavering emotional support. Join hands with her for unparalleled success............ reply gavmor 14 hours agoprevSeems cool, but didn't utilize my GPU? At any rate, definitely a futuristic POC, and prototype for the way I see desktop software going in the next few years. reply samlhuillier 14 hours agoparentYes unfortunately not implemented yet. Will be coming soon though :) reply donclark 6 hours agoprevHow would I use this as a mobile user? reply calebdre 16 hours agoprevThis is really cool! Something i've actually been thinking about for a while. Would you mind a pull request that spruces up the design a bit? reply samlhuillier 16 hours agoparentAbsolutely! Would love your help. reply calebdre 16 hours agorootparentis there a roadmap for features/improvements that you're wanting to make? what's your vision for the future of the app? reply lenerdenator 11 hours agoprevHow would this run on, say, a M2 Pro MBP with 32GB RAM? reply alsetmusic 11 hours agoparentThat should be more than enough. I've been running Ollama on an M1 Max with 64GB of RAM without issue. reply outside1234 9 hours agoprevWhich local model works best for folks? Sort of intimidated by the large number of models on Hugging Face and it is hard to conceptualize which of the variants work the best. I downloaded: mistral-7b-v0.1.Q4_K_M.gguf Q4_K_M 4bits 4.37 GB 6.87 GB medium, balanced quality - recommended Was that a good choice? reply frankcort 16 hours agoprevWow cool, can I import my One Note notebooks?!!?? reply clscott 15 hours agoparentYou can use Obsidian to create markdown from One Note. https://help.obsidian.md/import/onenote reply samlhuillier 16 hours agoparentprevIf you can convert your One Note notes to markdown files then yes. On startup, you'll be asked to choose your vault directory - which needs to be a directory full of markdown files. reply mrtesthah 13 hours agoprev [–] It doesn't seem to view my plain text notes. What file formats are currently supported, if plain text is not? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Reor is an open-source AI note-taking app that focuses on knowledge management with AI and privacy.",
      "It allows users to connect and search for notes using semantic search and supports RAG Q&A.",
      "The app runs all models and data storage locally and works alongside Obsidian, utilizing Llama.cpp, Transformers.js, and Lancedb."
    ],
    "commentSummary": [
      "Users engage in a discussion about AI-powered note-taking apps like Reor and Obsidian, exploring their functionalities, benefits, and areas for improvement.",
      "They delve into topics such as local models and plugins, the advantages of using plain markdown files, and the potential pitfalls of relying overly on AI.",
      "Privacy and data interoperability in knowledge management tools are also addressed, with emphasis on their significance."
    ],
    "points": 315,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1707930052
  },
  {
    "id": 39368561,
    "title": "The Matrix Chat Platform: Onboarding Woes and Security Concerns",
    "originLink": "https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html",
    "originBody": "The Matrix Trashfire Kristian Köhntopp - February 13, 2024 Previous Post Snake Oil Onboarding experience Trying to use it, nontheless Trying Element X with my account After onboarding Matrix responds For reasons, I tried to evaluate the distributed Matrix chat and their clients. That did not work out very well. Onboarding experience I was told that the default Matrix chat client is called Elements, so I looked it up on the iOS App store. Unfortunately, there are two, “Element” and “Element X.” No explanation is given, and no preference is stated. “Element” is categorized business, “Element X” is in “Social Networking.” Are they not the same? They seem to be from the same company, though. Element and Element X in the app store. Which one to use? Ok, let’s open the descriptions. They are identical, except for one sentence at the start: “Element X is the future Element.” So it’s a beta? Why is it not labeled as a Beta? On the desktop, going to Matrix.org plus two additional clicks take you to the client page , which offers The client page offers you, among others, both clients and also states which is available on what platform. So apparently “Element X” is beta and not yet available on all platforms. I open the macOS App Store and… macOS does not offer Element, only Element X. Apparently matrix.org lied to me. Element X is available on iOS and macOS, Element is not. Ok, let’s install Element X and try: Element X wants me to sign in to matrix.org. There is no ‘sign up’ Button. There is no sign-up menu. The client wants me to log in to matrix.org. There is no button to make an account. There is no menu to make an account. There is zero onboarding for new users. Ok, let’s go to matrix.org again, and see. The matrix.org Website is not very helpful. But when you notice the burger menu, there is actually a “Try Matrix” button. The matrix.org website is a very empty clean screen that is not very helpful. There is a burger menu, though, and if you open it, you get a “Try Matrix” button. This leads to another screen that tells you to use your organizations server instance (What organization? I’m alone!), or install a server, or choose a public server. If you opt for Public Servers, you land here: matrix.org server instances, alphabetically sorted, with little additional information. Matrix.org is conspicuously absent from this list. The rest I do not know anything about. I can now research what server instance I want to join. Unfortunately, I do not get information about what their country is. I can’t see if they are subject to GDPR rules. I don’t know if they are owned by a company or run by a single private person. There is no indication how many users they have. I can dig through their privacy policies and rules, except that some don’t provide any. Scrolling down, I end up with the option to onboard to this: Servers marked as vulnerable, unavailable and with profanity in their name. Why in heaven or earth would anybody put unavailable or vulnerable servers into an onboarding listing? Isn’t this supposed a “secure” messenger? Trying to use it, nontheless I made an “isotopp” account at tchncs.de . The password is generated and stored in Bitwarden. A validation mail is sent to a unique address at koehntopp.de and arrives. I try to login not being validated, using Bitwarden. The login is rejected. I validate the email. The server says I am validated. I try to login, using Bitwarden. The login is rejected. I am trying to recover the password for the account which I just validated, using the email from the verification mail. The account is unknown. I click on “forgotten password”, and supply the mail adress the validation mail was sent to. “This email address was not found.” Okay, since my account does not exist, I create it again: I recreate my account, using the same mail address. As you can see, the first registration mail still is in the account. I take the validation URL, which is longer than 80 characters, and use it to successfully validate, again. I create the account again, using the same parameters. The account validation mail is sent to my address. The old account validation mail is also still in the account. I take the new URL, which is longer than 80 characters, and use it to successfully validate my account, again. This time I accidentally left the “create account” window open. This window is now suddenly logged in. Turns out, you MUST NOT, UNDER ANY CIRCUMSTANCES, close the “create account” window until the account is validated, or it is simply not created. This is not stated anywhere. To confirm the account works and the password in Bitwarden is stored successfully, I log out and log in again. I get this: Unable to verify this device It looks like you don’t have a Security Key or any other devices you can verify against. This device will not be able to access old encrypted messages. In order to verify your identity on this device, you’ll need to reset your verification keys.* What does that even mean? Trying Element X with my account Starting Element X, it tries to onboard me to Matrix.org. I select “Change Server”, and get a form field where it says “matrix.org”. I am overwriting it with “chat.tchncs.de”, which supposedly is my server. At least that is what it says in the web client. That is not accepted. I take the URL from the browser and paste that instead. That is also not accepted, but I can learn more. I click. The what? Turns out, while the Chat is running on “chat.tchncs.de”, this is not the “Identity Provider.” That one is called “tchncs.de”. You only learn this when you open your config menu in the web chat and look at Identifer shown there. Once you enter this, Element X and the web chat get hectic. There is a new client, and both clients want to authenticate that the new device is legit. For that purpose, they display a set of Emojis, which look differently in the web client and the application, and ask me if they are the same. Helpful Emoji names are shown under the Emoji, and they are identical. I simply click yes. After that, both clients can see my Chat, but the Element X Client still has no access to any chat history. That is, because the client is unverified (so is the web client). When I close any client, I have to re-login, re-compare the Emojis, and all chat history is gone. After onboarding Why have I been trying this? A friend was trying to use a Matrix messenger on their phone, and waited 9 hours for this to complete. A friend of mine was trying to re-install a Matrix messenger on their phone, and landed on the screen above. This hung for 9 hours without any message or failure indication. The application cannot detect if somebody is using the wrong recovery key for a different account. The friend tried to use an Android application, but the application was complaining about the account not being verified. That is, the mail address in use was not confirmed, and for that reason the client would not be showing any chats. At the same time, these chats were being sent to the unconfirmed mail address, unencrypted, as a reminder that he was missing out. According to him, you can’t delete a half-made unconfirmed account. You also can’t rename an account. Apparently, you cannot create invite links for private chat rooms, only invite people. To do that, vector.im uses the very same dark patterns that LinkedIn uses to convince you to share your address book. With the unique mail-address used to sign up to Matrix, I am unfindable because only Matrix uses this specific mail address. Outside of Element, there are very few clients, most of them very old and not being updated within the last few years. All in all, this is a mess, and my recommendation is to avoid Matrix for at least two years. It is not secure, it is actively user-hostile, and looks not well managed. This is a project in severe need of management changes, a thorough UX evaluation. The design needs changes that make onboarding and usage smoother, encourage secure workflows, keep accounts available, and encourage secure practice. It also needs careful curation of servers and clients. At the moment it is a trash fire. Matrix responds Added on 14-Feb-2024: People at Matrix.org and Matrix developers have picked this up and responded in a very constructive way. They cannot address all things because they are not in the realm of Matrix, but part of Element. So far, no responses from Element. Matrix writes : well, this is a trashfire indeed. Thanks for writing this up. You’ve caught Element in the middle of their migration to Element X, and there’s a lot of legit feedback here: Both E & EX should be in the macOS app store. EX should clearly be labelled WIP in appstores. -It’s a mistake that matrix.org hurls people to servers.joinmatrix.org (which is not run by us); until recently it defaulted to matrix.org for convenience. Keeping the “create account” window open is a pure bug. The continue Verification UX in Element is a disaster, and being reworked in EX: Github link Element Android failing to compute a recovery key is clearly a bug too. Your other complaints about Element UX (e.g. user discovery by email; specifying the server URL) are also very familiar. It’s not true to say vector.im uses “the very same dark patterns as LinkedIn” for contact discovery though; Github link explains how it works (and is strictly opt-in). Matrix Director of Program Development Thibault A. Martin responds Hej @isotopp I’m one of the maintainers of the matrix.org website. Your post provides a very valuable perspective. I gathered the following gripes that we can address on the website itself in this issue: Matrix.Org Issue 2178 If you have the time to let me know if I got things right, that would be very useful! Thanks for picking this up, people! I very much hope that Matrix and Element eventually turn into something useful. Share Tags lang_en chat remote first work Suggest Changes Previous Post Snake Oil",
    "commentLink": "https://news.ycombinator.com/item?id=39368561",
    "commentBody": "The Matrix Trashfire (koehntopp.info)286 points by summm 22 hours agohidepastfavorite201 comments DoItToMe81 1 minute agoThis is just stereotypical ineptitude and inability to RTFM or use common sense from somebody used to the spoonfed walled garden side of tech. I do not understand how anyone with a background in technology can't know \"beta means buggy and poor support and use the flagship instance if you don't know what you want\". I understood this as a teenager, as most people here also should have. I think Matrix has a lot of problems. E2E encryption is too much for most laymen users to work with and it being so damn resource heavy being the too biggest ones. But come on. reply IanCal 22 hours agoprevThis kind of process is extremely valuable and should be done by devs more often. Start from the start and follow whatever your application tells you to do. Note down when it doesn't tell you where to go or what to do. You'd be surprised by just how many things you do automatically while working because you know the little tricks and things to get by, and that wording doesn't necessarily match what the app requires now. Side note - this kind of this is why good QA people are awesome. They'll show you what users will actually do. I'll add in something here. Element the app said they were logging into matrix.org. matrix.org has a \"try matrix\". The first thing is it tells me to choose a client (this feels like a loop), then says to choose a server but also maybe I don't need to, then has a create account button. The create account button takes me to a docs page. Which tells me to go to the element site, and then create an account with matrix. So that's matrix -> use element -> element says to use matrix -> matrix says to use someone else, ok you can use us -> to use us go to element -> element says you're making an account with matrix. edit - oh you can and should also do this with your dev process. Create an empty folder, check out the repo and follow the readme. Do you actually get a running system for local dev? Can you successfully run the tests? If you are able to, do this on a clean machine (maybe load up a docker image and see if you can follow it in a truly clear system). Does it turn out it assumes you already have tool X installed because your developers already have it from another project? Do you actually need postgres running with a specific user with specific login details? If you're like me you don't like writing docs, so this may actually just push you to add scripts that do the setup required. To not sound sanctimonious about this every time I've done this with my own code I've found issues with the documentation. reply vallode 21 hours agoparentQA is a massively underappreciated position. A QA person that knows when to automate, when to manually test, and how to report and file issues relevant to the project can save a significant proportion of hours on a project overall. I wish many more companies included budget for QA, it saves developers a lot of time. A bit of a side-note: this sort of analysis is a great answer to \"I want to contribute to open source, how?\". Some fairly simple wins for significantly better user experience, and no coding required! reply brightball 18 hours agorootparentGood QA people are hard to find and it's a weird balance to strike. I've seen QA get run over by aggressive developers. I've seen QA people who were so good, detailed and provided clear reproduction steps that developers couldn't wait to see them work. I've seen QA people who were completely unwilling to work on efficiency improvements, automation or even testing things in parallel so they became a bottleneck to the entire organization. I've seen QA people who just fall into a routine, do exactly what is asked of them and never try to improve. Like with anything, it comes down to the person in the job. If you get QA people who are really committed to the work, take pride in what they do and are always trying to improve it's the dream. When you don't have that, it's a very mixed bag. reply pixl97 16 hours agorootparent>Good QA people are hard to find In general, I'd say that's because it's a position that's shit on. You're apt to be paid far less than actual dev positions. If you're a QA manager you're always pushed on by upper management to outsource and lower costs. There is none of the prestige of being a \"QA 10xer\" that you'd see heaped upon a dev in the same position. And I see little training/courses pushed out for QA like is typically seen for dev. It seems like QA in most companies is a necessary evil that management would take out back and shoot the first moment they could. reply a_wild_dandan 14 hours agorootparentDevelopers are artists and QA is critique. Worse, you must entertain their complaining, and pay for the privilege! The vultures. (This implicit bias would explain the treatment disparity. But it's a baseless hypothesis. It just seems like the simplest behavioral explanation.) reply ivan_gammel 17 hours agorootparentprevFrom manager perspective, no matter what people do you have at start of the journey, the team culture can be changed. Most people are willing to learn something new and try new processes if they see the value. In more than 20 years I have seen maybe 2 or 3 pathological cases, where a person had to leave the team rather than play by new rules. It is not easy, it may take time for the team to adapt, but that’s a manager‘s job to unlock the potential of every team member and that job is doable. reply toomuchtodo 2 hours agorootparentprevIf one knows a great QA person, any recommendations on companies that appreciate that talent? reply specialist 15 hours agorootparentprev> Good QA people are hard to find True. A good tester is the kind of person who revels in running the same lab experiment many, many times and chortles for always getting results within the error bars. A good QA is the kind of person who can think of every way something will fail, and then come up with a proactive risk mitigation strategy that makes everyone smile with pride. > QA get run over by aggressive developers True. Back when we had QA/QC, my \"One Weird Trick\" was to put the QA / Test team in charge of releases. Running the bug triages, in charge of acceptance testing, running the go/no-go meetings, etc. Worked f@#$ing great. Almost like magic. Zero drama. Our releases were almost anti-climatic. I miss the '90s. Well, I miss my '90s QA/Test experience. Most everyone else was stuck in Kem Caner's world. The preeminent \"SQA\" guru who preached victimhood and grievances. Probably did more than any one to pile drive the QA Test profession into the Mariana Trench of irrelevance. (Apologies, weak sauce, I know. I usually have a better \"colorful metaphor\" ready to deploy for these types of rants.) reply ChrisMarshallNY 21 hours agorootparentprevThe old wisdom in the US, is that if you have \"Quality\" in your job title, your career is over. At the Japanese company that I used to work for, it meant that you were one of the most powerful people in the corporation, and was a sought-after adornment. Different strokes, and all that... reply ivan_gammel 21 hours agorootparentI always give the power to my QA team to block any release no matter what and to give higher priority to tickets than product manager. If CEO wants to override, I cover them and take the blame. This is not a guarantee that there will be no bugs in production, but it saved us a few times. reply ChrisMarshallNY 21 hours agorootparentThe Japanese testers were the best I'd ever seen. They never reported a \"NotABug.\" They could back up every report, and give exact reproduction steps. They found weird, obscure corner cases, and that was by hand (they hated automation tools). They had 3,000-line Excel spreadsheets. If even one of those rows failed, the whole shooting match (like an entire product line) could come to a halt (so that meant they had to cross their t's, and dot their i's). They seldom had \"opinion-based\" reports, and, when they did, the report was presented by the manager, after long discussions. The company I worked for, was renowned as one of the highest-Quality optical corporations in the world. reply MR4D 18 hours agorootparentI worked with NTT Docomo years ago for a short time. First time I ever got to see a CMM Level 5 organization. It was insane. No wonder Japanese cars were so much better than everyone else for so long. If you ever get the chance, take it - you will learn way more about software quality than you thought existed! reply pixl97 16 hours agorootparent>No wonder Japanese cars were so much better Heh, this reminds me of an episode of Top Gear I was watching years ago about quality of British cars. They said something along the lines of \"The manufacture sais 'eh, good enough' the moment the car is able to move under its own power. reply skibbityboop 16 hours agorootparentAnyone who has owned a Mini would probably question whether their QA even gets that far. reply aaronbrethorst 17 hours agorootparentprevDo you have any insights into why desktop and mobile software from these companies is so universally horrible? I’m thinking of Canon’s remote tethering tools, Fuji’s instax and remote control apps for iOS, and Epson’s scanner software. reply ChrisMarshallNY 17 hours agorootparentI don't want to get into slagging these folks, but I feel your pain. In a big way. Hardware != software. Hardware companies have a really difficult time, understanding this. They insist on running in-house software projects as waterfall-based-measure-twice-cut-once-never-accept-a-bug-count-greater-than-0. Anything different is \"bad quality cowboy.\" It can be difficult. I rapidly learned not to use the word \"agile,\" within earshot of many senior types. This applies to US hardware companies, as well as Japanese ones. Most folks, hereabouts, seem to think of me as an unbearable, retentive, snob, but my former managers would often think of me as an undisciplined, reckless, slob. reply aaronbrethorst 13 hours agorootparentthanks, I appreciate hearing your perspective! reply t0bia_s 15 hours agorootparentprevFujifilm software is outdated garbage. UX was developed probably during WinXP era and still present. However their cameras are excellent. reply 01HNNWZ0MV43FF 10 hours agorootparentprev> They never reported a \"NotABug.\" \"Every ticket should result in a code change, *or* a documentation change\" was one of the coolest sentences I ever read on some web page. reply thibaultamartin 21 hours agoparentprevHi, I'm the Thib person mention in this article, and I agree that QA is super important. I can mostly talk about matrix.org, since I have little power over the Element clients. Disclaimer though: I'm technically employed by Element (to make paperwork simpler since I'm France-based, Element has an entity in France, and the Foundation is UK-based), but I'm working for the Foundation full time. This kind of article is super valuable since it gives us the perspective of a new user. I opened https://github.com/matrix-org/matrix.org/issues/2178 to translate the gripes mentioned in the issue into actionable items for us. I took action on the most urgent one (updating the Try Matrix page), but want to take the time to go beyond the surface symptoms and address the root cause of the other gripes. On the Foundation side, we're a small but mighty team of four. The website is currently maintained part time by me and a volunteer who is doing an excellent job at it. As I wrote recently in a blog post \"Tracking what works, not people\" (https://ergaster.org/posts/2024/01/24-tracking-what-works/), I would love to have the resources to conduct user research and user testing on the website but I unfortunately don't. We deployed privacy-preserving analytics to see where people drop and what confuses them. It's not nearly as good as proper QA and user testing, but that's what we can afford for now. Overall I'm grateful to the author for documenting their frustration, and even more grateful for reacting constructively to our responses and integrating them in the blog post! One of the strengths of open source is to find and address issues collectively. I consider this blog post to be a good open source contribution. If people around believe in our mission and want to help us with their brainpower, I invite them to join our \"Office of the Matrix.org Foundation\" room: https://matrix.to/#/%23foundation-office:matrix.org For those aligned with our mission and who want to support us financially, the https://matrix.org/support/ page should give you all the information you need to help us out. reply IanCal 18 hours agorootparentHi, hopefully things came across OK, for clarity I wasn't saying \"why haven't they done this, they're bad at QA!?!?!\" but just wanted to say that most of us should be doing the same kind of thing with our own products/tools/sites and give a shoutout to QA peeps. Thanks for working on matrix, I'm building some things on matrix and it's been pretty interesting. > For those aligned with our mission and who want to support us financially, the https://matrix.org/support/ page should give you all the information you need to help us out. Great highlight, I've donated. reply jtbayly 16 hours agorootparentprevJust wanted to add that I signed up recently and wanted my wife to sign up too. I managed to figure it out, but the article is correct. Even down to trying to figure out whether I should use Element or ElementX on iOS. I also realized that my wife would never figure it all out. reply gowings97 21 hours agorootparentprevDo you have any thoughts on how you might improve this workflow? reply thibaultamartin 20 hours agorootparentFor the matrix.org website, we landed https://github.com/matrix-org/matrix.org/pull/2179 as a quick fix, but we can do better. I think there are several things we can do improve, and the process should be fairly similar with Element: 1. Refine who the website is for, and what they are coming here for. We need to narrow down who our audiences are, what they want, what they known and don't know, and how we can best serve them. 2. Conduct user research with a diverse set of people representative of who we think our audiences are. We need to sit down with them, ask them to create a matrix account unguided, and ask them to comment what they are doing and how they feel about things. One of the difficulties of the website is to find the right balance between not overwhelming the user with difficult decisions (picking a client? picking a server? I just want to chat with my friends!!) without being too biased. We need to be opinionated to guide newcomers through a decently simple process, but we need to leave room for all the vendors to thrive. reply gowings97 16 hours agorootparentWell stated! I wish you luck (I just donated a bit as well) reply selimthegrim 18 hours agorootparentprevIs there a good reason why the password workflow is so much worse on mobile than on desktop for matrix? reply oohffyvfg 20 hours agorootparentprevmost of those complaints are talked about weekly on the element/elementweb own rooms at matrix. also, i myself gave up contributing small fixes because you don't host source map files and I'm too lazy to setup a dev env. reply justin_oaks 17 hours agoparentprevIf you're trying to make a good onboarding user experience then you should do your onboarding testing with people who've never seen the product before, not devs or QA. Once people are familiar with the product (devs, QA, and anyone who has used it before) then they're \"tainted\". They'll remember the weird way that they had to work around an issue, and that'll just end up being \"the way it is\" rather than something to fix. I've read that a strategy for this is create an ad and pay people $50 to come in and try to use your software. Tell them to do something in your software and see what they get hung up on. The worst UX problems will be hit by nearly every user. As simple as that is, none of my employers have ever done this. The closest was one of the bosses asking his wife to try out the software. reply INTPenis 21 hours agoparentprev>This kind of process is extremely valuable and should be done by devs more often. The fact that it's not being done doesn't bode well for their perceived engagement to this project. I remember when it launched and how much they hyped it up to be the future of secure messaging. That was how many years ago now? It was pre-pandemic. I'm a lover of all selfhostable federated solutions so I actually hosted a Matrix server for a couple of years. My conclusion is that it's just not ready for production scalability. And you can't migrate easily between implementations because of their unique database design. reply friend_and_foe 8 hours agoprev> All in all, this is a mess, and my recommendation is to avoid Matrix for at least two years. Two more years. I've been a matrix user for almost a decade. Things have not gotten better at all. I used to use Riot, I invested (and subsequently lost) a good amount of social capital on boarding my close circle, mostly non technical people, to using it. We used it. It was a little janky with the key sharing and verifying users and what not, but we managed. Then Element came out, and at first, whatever, but then a lot of those verification tools just stopped working. Several of our accounts became locked in some limbo where they couldn't be verified because the verification methods didn't support legacy verification. Nobody wanted to move to a new client which was less feature rich. We moved to signal eventually and have been mostly happy ever since. I still use it with a couple of people. Its still just as janky as ever. First riot, then element. Now Element X? Dendrite... How many times are these guys going to rebuild from scratch before they realize they're in over their heads? I just gave up on it, I still use it with the couple of people I'm connected to and I don't do new contacts on it with anyone. I treat it like I do Discord. For me now it's XMPP and email, and signal for real world contacts. I mess with some of the newer messaging tools out there like Simplex (which absolutely has a terrible onboarding flow, but they're new so they get a pass for now) and things, and I hope to get utility out of them, but I'm never going to burn myself again pushing people to use something new, I'll wait until these things prove themselves, a lesson I learned from Matrix which never did mature into anything worthwhile. reply bhaney 22 hours agoprevI tried to follow along with the author by going to the same pages and seeing the difference between what he should have done and what he actually did, and it convinced me that there's no way he was doing this in good faith (unless something has changed). I still can't figure out how he managed to get to some of the pages he described, when the thing that he said he wanted was clearly right on the page he said he was viewing before. reply frereubu 22 hours agoparentPeople at Matrix responded - see the bottom of the article - so they may well have tidied things already up based on his feedback. reply bowsamic 22 hours agoparentprevThe fact that the official Matrix Mastodon account as well as the \"Matrix Director of Program Development\" agree with his assessment with the Mastodon account agreeing that it is a \"trashfire\" makes me sceptical of your suggestion that he was manufacturing these issues. reply crimsoneer 22 hours agorootparentI mean, Element and Matrix are 2 separate entities, which is kind of the key problem with all these efforts - there have been plenty of posts about how hard it was to join a Mastodon instance, or creating 2 accounts etc. That said, the Element/Element X migration is a mess. But if he'd just gone to the Element website and clicked \"get started\", it would have just worked. reply IanCal 21 hours agorootparent> But if he'd just gone to the Element website and clicked \"get started\", it would have just worked. No it wouldn't. element.io -> get started gives this: > Get started. > Setup a self-hosted or cloud deployment, with powerful enterprise capabilities. edit - expanding. The element site is entirely about getting something for your business. It has a pricing page that tells me it'll be free for up to 200 users but I have to self host. Nothing on the front page of it tells me it's a free app I can use elsewhere. I have to go to \"product\" (!) and choose the app. reply crimsoneer 21 hours agorootparentI mean, it's a commercial offering first. But \"want to download the free app?\" is right underneath it. reply IanCal 21 hours agorootparent> But \"want to download the free app?\" is right underneath it. To get started with element the app and create an account to chat you are saying I should not install one of their applications, instead I should 1. Go to the element site 2. Ignore all the talk about it being a product for teams 3. Still want to get started with not what the page is about, click on get started 4. Totally ignore what it tells me the page is for, because it's about setting up a server 5. Still want to download the application regardless 6. Scroll past all the CTAs and the form 7. Download the app reply bowsamic 21 hours agorootparentprevYou suggested it based on your assumption that the UX would be sane but now after being told that it isn't you are backtracking. As it stands, your original comment is now objectively wrong, because you made exactly the kinds of assumptions the blog post author was making: that the UX would be reasonable at each step. reply master-lincoln 21 hours agorootparentprevagree, the author mainly complained about UX issues in the client, but then only tried one client it seems. Article should have been titled \"The Element Trashfire\" > my recommendation is to avoid Matrix for at least two years which seems arbitrary. Why wait 2 years and not one or just a couple months? The french administration is already using it now https://www.tchap.gouv.fr/ In federated protocols it's always harder for the user to choose an instance for them. Not sure if the responsibility for that should be on the protocol managing party. reply Attrecomet 21 hours agorootparentThe author tried the exactly one client that was available from element in the app store. Hard to fault him for that. reply bowsamic 21 hours agorootparentThe thing is that people will defend this as a feature of this kind of system, rather than a problem reply master-lincoln 21 hours agorootparentprevWell, they tried to use an open source ecosystem by finding an app in a store where devs need to pay to get their apps in. Maybe not the best combination reply croes 20 hours agorootparentWhat do you think non IT people would do? reply jeroenhd 19 hours agorootparentThey wouldn't even know Matrix existed, most likely. They certainly wouldn't have found \"Element\" on their own. If they did manage to find Element at all, I would guess that would be through the \"try matrix\" button on matrix.org, which has an \"install Element\" button, which then leads to a \"download for macOS\" button. More realistically, people would be typing \"Matrix\" into GPlay or the app store on their phones. The confusing Element/Element X situation would still apply, of course. reply dzaima 19 hours agorootparentIf one knows about Matrix/Element, it'll of course be from hearing/reading about it somewhere. And thus if they were just told \"discussion is at #foo:example.org on Element\" or whatever they'll clearly go for Element (and I've seen \"Element\" be used for \"Matrix\" a couple times). Though then at least maybe they wouldn't manage to pass the blame on Matrix for what is an Element problem. reply jeroenhd 19 hours agorootparentprev> The Element/Element X migration is a mess I think this is a key issue here. Element X is unfinished, but isn't labeled as such. The rest seems to be the result of a buggy, unfinished process, that I don't think exists on the stable client. It probably also doesn't help that the Element app on iOS has received relatively little attention over the years compared to the Android app, which has had several rewrites. This is probably also why Element X is getting so much focus, as it's the first fresh start for Matrix on Apple's platforms in ages. Matrix is cool tech, but it's not easy to get into. I'd argue the same for XMPP and other federated services, as their competition has the advantage of having one app managed by one company. Even things like email are confusing to people beyond the very basics; setting up an email client is still something technical support needs to hand-hold people through, no matter how many wizards and step-by-step guides apps may add. reply linuxandrew 20 hours agorootparentprev> I mean, Element and Matrix are 2 separate entities Separate but they work closely from what I gather. New Vector develops Element/ElementX and has seats on the Matrix.org board. Element is the Matrix.org flagship client. I do appreciate that Matrix.org has its own foundation and I don't mean to disparage New Vector in any way, but they are undeniably closely linked. I'm not sure if Matrix would survive without New Vector. reply dingnuts 17 hours agorootparentNot only are they actually very closely linked, in that Element operates matrix.org, but to a new user (told to try Matrix -- what is this Element thing?) there's no difference. I onboarded a family member onto my Matrix server with FluffyChat as the client. This person is a power user, fairly technical, yet still refers to the chat as \"FluffyChat\" and although I've explained several times that choosing FluffyChat was maybe a mistake and they should use Element, it never seems to really click that multiple clients are possible. And really, they aren't possible. They have different subsets of features. If you want to see a trash can fire, just try to follow the discussion for adding custom emoji to Matrix: https://github.com/matrix-org/matrix-spec-proposals/pull/195... it's been going on for years. It's a feature the competitors have had for half a decade, as long as this discussion has been ongoing. I've been watching this issue for half a decade thinking \"surely they'll decide on something\" but mostly all I've been convinced of is this: Matrix is design by committee in all of the worst aspects and at every level of design. If anything gets done at all, it's a convoluted mess, and it's a miracle that it even happens. I wish community software developers would focus their attention.. somewhere else. reply cvwright 14 hours agorootparentCustom emoji? We don’t even have captions for images yet! reply bowsamic 21 hours agorootparentprev> But if he'd just gone to the Element website and clicked \"get started\", it would have just worked. Going to element.io and clicking \"get started\" takes you to a form to submit some kind of enterprise inquiry, asking what the name and size of your company is... reply danpalmer 22 hours agoprevI've never used Matrix, directly. However I use Beeper all day every day, via their iOS, Android, and macOS clients. Beeper (not the iMessage app, but their previous and continuing multi-network app) is pretty great. I get one consistent UX across all chat networks I use. Sometimes the networks drop out, but rarely due to Beeper issues. Beeper is essentially a Matrix homeserver, plus a bunch of hosted Matrix bridges, and as far as I can tell, that whole part of Beeper was a great technical decision. The Beeper clients started off as forks of the Element clients, and honestly they were a trashfire at the beginning, but Beeper have been quickly iterating and replacing parts, and they're now pretty solid. They're not yet WhatsApp quality UX, but they're approaching it. I don't think the problem is Matrix. reply LorenDB 21 hours agoparentThis. I use Matrix daily using nheko for my client. It's a rock solid experience (except for a bit of trouble with voice calling one of my friends). I've never been randomly told I have to reverify. If you are being asked to relogin and reverify every time you restart your client, you're doing something wrong. reply raziel2p 21 hours agoparentprevDepends on how you define \"Matrix\", I guess. The technology is undoubtedly great, but it also needs to sell itself as a (standalone) product if it wants to catch on. reply danpalmer 20 hours agorootparentBut Matrix isn't a product. There are companies building products on it, such as Element and Beeper, and as far as I can see the latter are doing a perfectly good job of selling themselves. reply raziel2p 20 hours agorootparentThat may be technically correct, but reality is if Matrix wants to catch on (large scale) as a concept, it needs to act as a product in some way. Even if that just means having a good landing page guiding users on how to sign up on a server, install a client, and connect the two - and making sure that this always works. reply thibaultamartin 18 hours agorootparentThat's a very interesting thread, because this is one of the major issues we have with Matrix. It's not directly a product but a (technical) protocol that can't be presented as such to the general public. We definitely aim for Matrix-based products to be used by the general public, in the same way emails are. For this to happen, we need to be mindful of who our audiences are, what they are looking for, what they know and don't know, and how to deliver a message that works for them. If you're interested in how we thought the website, you can check https://github.com/matrix-org/matrix.org/issues/1502 and https://github.com/matrix-org/matrix.org/issues/1543 for example reply danpalmer 19 hours agorootparentprevI think that's one approach, but many other federated systems don't do this. ActivityPub does not do this really, instead Mastodon, a product using ActivityPub, markets itself. Arguably you could look at HTTP and say that HTTP doesn't have a fancy landing page pitching itself to users, browsers have landing pages pitching their experiences to users. Matrix could have a fancy landing page pitching itself to implementers who implement homeservers, bridges, or clients, and they could market to end users. reply dale_glass 18 hours agorootparentMaybe \"Matrix\" is not the ideal name for it then. ActivityPub, HTTP, XMPP, etc sound like technical things. If you land on a page talking about the \"XMPP specification\" then you quickly get the idea that it's not where you want to be as an end user. \"Matrix\" does sound a lot like the name of an end-user relevant product of some sort, and a client sending users to matrix.org compounds the issue. There's a reason why big companies have brand guidelines. They have people on staff that understand that people are confused quite easily and don't want to figure out where \"Matrix\", \"Element\" and \"Element X\" stand in relation to each other. reply danpalmer 18 hours agorootparentI wouldn't read anything into a name. For a start that's very language specific, but also there are plenty of non-user facing technologies with non-technical sounding names, and vice-versa. The client I use doesn't send users to matrix.org, and I would assume that's by choice. Why do users need to know? Matrix.org is clearly a hub for the spec, documentation, GitHub links, developer community. reply cvwright 14 hours agorootparentprevYeah it’s unfortunate that they picked the “cool” name for the protocol, not the product. I keep saying that they should make a Matrix branded client that lets you easily donate to the foundation (like Signal does) and creates accounts only on matrix.org. Unfortunately that doesn’t really work with the ethos of the project. reply avtar 16 hours agoparentprevCurious to try Beeper now. If anyone has a referral code, please reach out. Email address is in my profile. reply stevenicr 15 hours agoprevReally glad to see these discussions happening. I started creating a similar post for matrix/element/server installs - a while back, Screenshots and saving putty sessions.. (wondering if I should find a tool that records ssh input/output or just use the save sessions built in).. I've succeeded with a matrix server install 2 out of 6 tries. I am about to try again with a new install since I don't have faith in succeeding a multi-version upgrade. I wish there was an easy way to export user names and email addys to port to a new install, as I worry that making a new install could allow for some nefarious people to come in and create accounts with another old user's name. I love matrix and element and other clients, it's the best for what many need - although there are many rough spots in using it both server side and as an end user. Moderation usability is a major issue for us, maybe with a new install I will jump into that rabbit hole of how to set things up for that and see if it's easier these days. I hope the vucuum DB and such is better with the newer versions. Looking forward to scouring the web for tutorials on all the basic things debian and perhaps logging the journey, maybe just screenshots will be fine, we'll see. reply joshsimmons 12 hours agoparentLikewise, glad for these discussions. Even if it's a bit uncomfortable to be on the receiving end, this kind of feedback is a gift. Please do share more about your experiences, we're all ears and looking to learn and improve! BTW, on the moderation front: Draupnir is the most actively maintained tool in that space and I recommend checking it out. Separately, the Foundation is currently investing in developing better tooling to complement moderation bots like Draupnir. We don't have a planned release date, but what we're making will be FOSS and available to all to use. We're also looking to involve more technical writers to help us better support new users and homeserver admins – for sure, it's a rough road right now. Josh, Managing Director of the Matrix.org Foundation reply jesprenj 21 hours agoprevI really don't like the forced end to end encryption of chats. I do not care that much about the security of my chats to justify the complications of end to end encryption -- verifying devices, constant \"reset\" prompts that I don't even know what they do, but they seem like they are very destructive. I trust my homeserver, since I host it myself. I do not need end to end encryption. I understand this is an issue of the client, not the protocol. But there aren't many clients. Prebuilt element for android from fDroid will connect to matrix.org, vector.im and other network hosts and I don't want that at all, although this tracking can't easily be disabled. It feels very centralised. I run my own homeserver and want to chat with my friend that runs his own server. It is unacceptable to me that clients connect to anything other than those two homeservers (apart from CRL and OCSP, which should also be disabled by default, as I consider those protocols great spyware). Not to mention the fact that homeserver software itself is known to make connections to the servers of the developers by default, without ever talking to someone on matrix.org. This is also unacceptable. My homeserver should only connect to other homeservers. 3PID is a failed attempt, as it centralises identities and works by utilising a single point that gathers a lot of personat information at one place. I don't want it. XMPP does not have those issues. Set up prosody and use dino or Conversations and they won't make any connections to non-essential servers. Furthermore, the end to end encryption is way easier to use in XMPP (OMEMO), and it's easy to turn it off if you don't need it. reply lxgr 20 hours agoparentIt sounds like you’re happy with XMPP – are you missing anything from Matrix in terms of functionality? If not, why not just stick with XMPP? reply jesprenj 12 hours agorootparentI think matrix has group voice calls. But maybe I'm wrong and they're just using Jitsi. I like that Matrix puts an emphasis on message history, but on XMPP that seems like an afterthought. For example on XMPP multi user chats, messages history retention relies on the server that hosts the chatroom and this is sometimes very limited, sometimes even disabled. And if that's the case, you only get messages when you have a _client_ online, as your server won't store messages when you don't have a client connected. Or something like that. And AFAIK, multiple clients with a MUC room opened will appear as multiple users sometimes. I'm not sure how it all works really, so take my words with a grain of salt. XMPP seems more like a pubsub system for system messages, like MQTT (: reply dijit 18 hours agoparentprevtbh the best thing about Matrix is that you have a hope in hell of actually federating it. XMPP had that promise but due the XEP situation it quickly became difficult to actually federate as most XEPs are optional or not supported on your federation partners. Everything you said is true; if you can tolerate centralisation then just stick to XMPP, it's pretty good. reply jesprenj 12 hours agorootparentWhy centralization? XMPP users are identified with their JID in format username@server.example, similar to email addresses. And server to server communication is very well documented and major XMPP servers for instant messaging (ejabberd and prosody) both allow server to server message exchange. I don't see any benefits for Matrix when it comes to federation and I wouldn't agree with you that by using XMPP you tolerare centralisation at all. It's level of centralisation is comparable to that of email (and email is very well federated in my opinion). MUCs like the XEP you mentioned are handled by a different XEP. reply upofadown 16 hours agorootparentprevWhat XEP interoperability issues prevent federation? reply dijit 15 hours agorootparentThere are more than 370 XEPs. Here's the first one I found that causes serverserver incompatibility: https://xmpp.org/extensions/attic/xep-0369-0.7.1.html What was always missing was a golden set of standards. Maybe XMPP \"2\" is XMPP and a set of XEPs and so on. Otherwise all you have is a bunch of half-working XMPP implementations. Very famous ones of course include voice/video. The UX on that is atrocious. reply wiktor-k 15 hours agorootparent> Here's the first one I found that causes serverserver incompatibility: https://xmpp.org/extensions/attic/xe What kind of incompatibilities does it cause? It's an unfinished spec for group chats, which, to my knowledge is barely implemented anywhere. Just for the record I'm using both XMPP and Matrix daily and both have issues :/ reply zaik 15 hours agorootparentprev> difficult to actually federate as most XEPs are optional or not supported on your federation partners This is false. reply dijit 15 hours agorootparentVoice/Video is an optional XEP and if it's not supported what happens to the client exactly? \"this is false\" is a terribly glib statement with literally no backing and can only be said if a person has either zero knowledge of what they're talking about or they've tied themselves to a single implementation of XMPP everywhere, which is essentially standardising a bunch of XEPs. reply jesprenj 12 hours agorootparentWell if you use a matrix client that does not support video calls (Syphon), you also can't be called. Camera and microphone are not a mandatory feature of Matrix either (; reply zaik 15 hours agorootparentprevIn Conversations if A/V is not supported, you do not get a button to call them. The people I text most use Conversations, Monal or Gajim which are all independent implementations. reply the__alchemist 16 hours agoprevIt's nice to hear I'm not alone. I use Matrix/Element to chat with Rust embedded devs; I have heard about it in other contexts; generally favorably. In my experience, it is awful, and has been for years. Highlights: - The verification is a mess (in the article; By the way: Once your account is set up, the verification failures don't go away). It has frequent verification popups and overlays; when I attempt to follow them, various errors occur, and it fails. So, the client nags you to verify, but the verification process is broken. - The read notification system is broken; most chat groups will show as having unread messages, when there are none. This is possibly related to the thread system, but my results here are inconclusive in regards to the exact nature of the problem, nor the solution. - Message posting and syncing is unreliable, especially after edits. Some messages will show on the PC program, but not the mobile, and vice versa. Sometimes edits I or someone makes will show up on one client, but not the other. reply maelito 21 hours agoprevI'm talking daily with friends on Element. Most of them don't work in tech, but are quite comfortable with computers. It's ok. Most bugs concern threads. But it's one of the only chat apps that enable threads, so I'm ok with that, threads are absolutely needed in my opinion. Signal conversations can become such a mess because of that. ElementX lacks threads, but apart from that is refreshing. Looks more like a chat app than an enterprise messaging app. Still your article is very important. The UX should be improved. reply hiq 21 hours agoparent> Signal conversations can become such a mess because of that. The workaround is to create new groups, even if that's with the same set of people. I even have groups with just another person and myself, e.g. for specific projects. In my experience that works well enough, also because if something is longer-lived, I'll put it in a shared doc instead. reply maelito 20 hours agorootparentBut I won't create a new group to for example talk about a video. That's what I just did with a friend : share 10 messages about a video. We're 4 in the group. 2 of them might never be interested by the talk about that video. It's completely unpractical to create a new group to just talk about that. Then you need to either close or leave the group. No problems with threads, it's created with a click and finishes by lack of new messages. It's just what happens in real life : people move around 2 meters when they want to talk about something in particular, and other people can either ignore, either join the ephemeral group. reply hiq 19 hours agorootparentIn practice I just skim through these 10 messages in such small groups. There's the opposite problem with threads, with which it's easy to miss messages you care about, and harder to have a single topic at a given time. Being able to reply to individual messages also makes the transition from one topic to another smoother. I can definitely see the problem if you try to use Signal like you use IRC, with big channels with 100+ people and very different topics, not all of them relevant and with people you care about, and I still use Matrix / forums for that. > It's just what happens in real life : people move around 2 meters when they want to talk about something in particular, and other people can either ignore, either join the ephemeral group. It really depends on the setting, that's only if you're standing and even then, if you're having a meal sitting at a table, I'd be surprised to see this. reply haltcatchfire 22 hours agoprevWe used Matrix for a couple of years at my company, but got kicked out from their managed hosting due to the new requirement of 50+ seats. The years we've been using it has been more of tolerating its flaws than a pleasant user experience. We migrated to Slack and was blown away of how It Just Works. reply master-lincoln 21 hours agoparentWho is \"they\"? Afaik the matrix organization doesn't offer hosted servers reply apetresc 21 hours agorootparentThey do indeed: https://element.io/pricing reply jeroenhd 19 hours agorootparentMatrix and Element are no longer the same entity. Element (New Vector Ltd) is the core behind the Matrix protocol, but they're distinct from the organisation that manages the protocol. If Matrix does ever take off, this will be an extremely valuable distinction to have. reply apetresc 19 hours agorootparentI understand that completely, I even considered including a \"Before anyone jumps in with 'akshually that's Element', [..]\" disclaimer but decided nobody would be that pedantic. Element is the same team as the Matrix.org foundation, with the same objectives. I understand why they maintain a separation of concerns at the institutional level, but for someone to say \"Matrix offers hosted servers\" and to act confused like \"What do you mean, who's 'they'? Matrix doesn't do that! Only Element, the organization run by the exact same people, who's only goal is to further the adoption of the Matrix.org spec. I can't possibly fathom what you think the connection is.\" is the very definition of being disingenuous. reply jeroenhd 17 hours agorootparentThe people working on Matrix also have quite a few contributions from Beeper, which has little incentive to make Element popular (after all, they'd lose customers to their own service!). They're mostly the same people (80% of the core spec team works for Element), but not exactly the same people. The Element people that maintain Matrix certainly have a vested interest in Element, but that doesn't make Matrix exclusively Element-oriented. While you and I understand the distinction, I think it's important to make it clear to other readers here that Element and Matrix are not the same organisation. Because of Matrix's history, and the interlinking between matrix.org and Element, one might assume them to be, and if the opening post shows anything, it's that the Matrix ecosystem can benefit from some additional clarity. reply tcfhgj 18 hours agorootparentprevNo, they aren't the same team (anymore), and there isn't just Element as a service provider reply maxidorius 18 hours agorootparentAnd yet Thib, mentioned in the article, does say in an another comment that they are employed by Element but working for The Foundation, making it quite hard to know the difference between the two: https://news.ycombinator.com/item?id=39369239 If you dig a bit, I'm sure you'll find this is true for quite a bit of the people either in Element or in The Foundation. reply jeroenhd 17 hours agorootparentIt's hardly a secret that most people working on/for Matrix are employed by Element. https://matrix.org/about/ has a list of names for the \"guardians\" of the foundation (whatever that may mean exactly) which consist of 40% Element, 60% external parties. The core spec team at the bottom links to Github profiles, from which I believe 8 out of 10 people work for Element (though I'm not 100% sure if the last person in the list still works for them based on his Github profile tag). Thib isn't part of the foundation, he's just part of the business side, and quite a public part at that. I think his role is a good example of the distinction between Matrix and Element. reply rglullis 20 hours agoparentprevIf your company ever considers going back: https://communick.com/services/matrix reply turblety 22 hours agoprevWe also tried to use it, but frequently, messages will fail to decrypt with no option to retry. Threads is a mess, where messages will show as unread, but you can't actually see what message was unread. Matrix/Element is so close to a great alternative to Slack, but in it's current state it's totally unusable. reply wakeupcall 22 hours agoparent> We also tried to use it, but frequently, messages will fail to decrypt with no option to retry. This is a years-old issue with Element, which never happened to me with other sending clients such as FluffyChat. It's unbelievable that it's unfixed given it's a dealbreaker as it results in permanently unreadable messages on your end (the \"waiting\" in \"waiting for this message\" is a lie). And since this needs to be fixed on the sending side, you NEED to use another messenger to fix the conversation (if at all, as this requires reading extremely long issues on github with buried suggestions many won't do). After getting it a few times most users would just dump Element and blame matrix as a failure to never touch it again. The excuse \"we're working on this on the next client iteration\" is actually ensuring a growing list of users will hit this (as it's bound to happen) and avoid matrix in the future. UI/onboarding issues are minor compared to the fact that the conversation can be randomly broken. reply creatonez 12 hours agorootparentThis just sounds like a description of Matrix's key sharing mechanism? Messages are supposed to be unencryptable if you don't have the keys, and bringing online another device (or having all your keys pre-shared so you don't have to) is what provides the keys. If you want to avoid this altogether, the UI prominently advertises the optional encrypted key backup service provided by the homeserver, and various manual options for sharing keys. If FluffyChat is not having this issue, it is probably overly eager to share encryption keys instead of allowing the user fine-grained access to control keys, which is successfully hiding the complexity of the ratchet encryption but potentially exposing the user to attacks to force the sharing of keys. Edit: I was looking around. While Matrix is well documented, Element's documentation is poor because they expect you to figure things out from popups in the UI -- fair enough, unfortunately most apps are like this, and Element's popups have gotten a lot clearer. But I did find these two pages from a university that seem to serve well as \"Element's missing manual\". Worth a read if you are trying Matrix for the first time, because it discusses some things that can look like bugs but are really user error. https://docs.matrix.kit.edu/en/settings/ https://docs.matrix.kit.edu/en/faq/ reply rcxdude 9 hours agorootparentreading a manual for a chat app to fix 'user error' that results in bizarre behaviour like this is not a reasonable solution. reply jeroenhd 19 hours agoparentprev> messages will fail to decrypt with no option to retry In my experience, this is generally resolved automatically in the background. It occurs when the device that's supposed to share the necessary keys isn't online while any of your devices are online, and the moment enough devices are connected again, the messages will pop into your timeline. I'd like a \"retry\" button, but if the error shows up, manually clicking \"retry\" wouldn't really do much. As for it being a Slack competitor: just don't enable encryption and you'll skip over a lot of problems, and come a lot closer to Slack in terms of usability. The threads UX is a bit weird, but it does show you that there are unread messages hidden in threads through a little indicator by the threads icon. Not the greatest UX, I agree, but I wouldn't call it \"unusable\". reply influencer3000 21 hours agoprevWhile it's never fun to receive negative feedback, it'll only help to improve the product. Still, I run Matrix servers since inception of the project (10 years now \\o/), and for an experienced system administrator this is not something difficult to do. If you think running a Matrix server is difficult, you are probably not the intended audience: running an IRC server, an email server, or some other server, is mostly similarly difficult. Matrix is a communication protocol, and it is not intended to be touched by end-users. If your goal is to just communicate on the matrix network as an enduser, stay away from matrix. I haven't seen an email enduser who browsers to https://www.rfc-editor.org/rfc/rfc5321.html, to figure out how to sign up for hotmail..... Element on the other hand, IS intended to be userfriendly, and there is obviously a lot of room for improvement. But through the years I experienced that users who want to use Element to stay in touch with their loved once, have no problem with that. Lastly I think comparing an open source project like Matrix/Element to Publicly traded corporations like Slack or Meta, is not fair. They operate with totally different business models. If you'd compare the quality of Matrix/Element to Slack in relation to annual budget, Slacks ROI would be depressing. reply solarkraft 21 hours agoparent> Lastly I think comparing an open source project like Matrix/Element to Publicly traded corporations like Slack or Meta, is not fair. If we want to \"win\" (reach similar/higher adoption), we need to at least come close. It's not easy work, but not doing it and leaving the product that so much good work has ready gone into unusable for a vast number of people would be a bummer. reply influencer3000 21 hours agorootparentNot sure we want to \"win\". If endusers want apps \"to just work\" without \"paying up\", then I would recommend them to stay with Whatsapp. That kind of users aren't worth the hassle if they have no money. I personally have better relationships with people that enjoy learning something new, and coming up with solutions for issues themselves, eventually contributing to the ecosystem. reply IanCal 21 hours agorootparent> I personally have better relationships with people that enjoy learning something new, and coming up with solutions for issues themselves, eventually contributing to the ecosystem. Then we should add deliberate errors in the signup process and encourage the community not to talk about them so there's a definite right of passage. > I personally have better relationships with people that enjoy learning something new, Here's another perspective. I love learning new things. But this is making me learn the internal product releases of a chat app rather than, say, what the different lions represent in the dance I watched on Chinese new year. Or worse, you're making me learn what the split is between matrix the spec, matrix the hosted server, the matrix foundation, element the business, element the hosted service, element the app and the other element the app - rather than pretend to be an imaginary creature called a meep with my daughter. reply dale_glass 18 hours agorootparentprevI'm very sympathetic to this line of thought in general, being in a similar position with our own project. But it's still important not to make people waste their time. End users should be sent to an end-user friendly place, and developers should be quickly sent off to usable development documentation. It doesn't help anyone to confuse people and have them figure out the details of the internal organization and convoluted relationships between various pieces before they can even start doing work. reply maxgashkov 11 hours agorootparentprevOh wow, since when there is an option to \"pay up\" into the Matrix ecosystem and get a solution that just works? Could you point to it? reply nottorp 21 hours agoparentprev> Matrix is a communication protocol, and it is not intended to be touched by end-users. So what is \"intended to be touched by end users\"? I can't figure that out either from the article or the comments here. Assume I can (and actually have) run an irc server, but I haven't set up Matrix for the last 10 years. reply raziel2p 20 hours agorootparentThe end user is meant to use 1) A client (e.g. Element), and 2) an account created on some server - with the client connecting to that server. reply nottorp 20 hours agorootparentYep, that's in all caps on the landing page of matrix.org :) Oh wait, they say \"An open network for secure, decentralised communication\" instead. reply gtirloni 22 hours agoprevThese user reports are invaluable. They contain so much information that us devs miss because we're so used to working with our software. reply onli 21 hours agoparentNote though that this is not a regular user, but an old school blogger with deep database experience and afaik programming skills, at the very least someone highly technical (and known in Germany). He is just able to put his user hat on -> regular devs can do that too. reply gtirloni 21 hours agorootparentYeah, that's a good point. When I put my user hat on, I try to force myself to not know things (conciously ignore them if I can), but I think it's not a \"natural\" experience like an end user report. Still, better than automatically doing what will work. reply noirscape 20 hours agoprevHonestly, the matrix documentation is a total mess in general. The protocol is from what I can tell pretty cleverly designed/usable as a casual chat app (even if it leans heavily towards IRC esque design), but actually figuring out how to use it is somewhere between \"wisdom of the ancients\" and actually impossible. A lot of very relevant information is stored in old documentation that is currently marked as outdated on the site but has no updated equivalent. The bad apps and onboarding only hamper it further. It's still baffling to me that the best way to actually administer a selfhosted matrix homeserver (specifically, synapse, the reference homeserver) is to do a database hack to promote a user to an admin and then use an external PWA hosted on GitHub[0] so you can actually do basic moderation actions without having to resort to using curl. [0]: https://awesome-technologies.github.io/synapse-admin/ reply thibaultamartin 20 hours agoparentIndeed the documentation generally needs much more love. In an ideal world, every single page of the documentation would have a person in charge of keeping it up to date. We're a rather small team on the Foundation side and lack the personpower to do so. We're in the process of listing what documentation we need and what we need to update. This will be the foundational work to apply to Google Summer of Docs and for individual tech writers to apply to grants like NLNet (who doesn't usually fund \"large\" organisations like us) to help us out. I'm also adding instructions on how people can step in and contribute to the docs if they have the time and desire to do so: https://github.com/matrix-org/matrix.org/pull/2155 We're doing our best with our limited resources, but I'm confident we can improve the situation eventually! reply nottorp 21 hours agoprevInteresting how most comments come from people inside the bubble that have an intuitive understanding of the system now and assume everyone else does. reply rglullis 22 hours agoprevOk, now do XMPP. Or Signal, but with the added requirement that you want to run your own server. reply tetraca 18 hours agoparentHaving set up and administrated both an XMPP and a Matrix server, XMPP is way less a pain in the ass. I've enjoyed dealing with prosody much more than either synapse or dendrite. XMPP doesn't tank my server every time I try to join a new room and it doesn't take forever to start talking in a room after you join it. And provided you're running the server, getting people onto XMPP has not been hard in my experience. I made a basic registration page with simple instructions. I have gotten people with low technical know-how to successfully register accounts and use it without issue. They just create an account, enter their username into a client I recommend, and they're ready to go (I've never even had them complain about OMEMO). reply rglullis 16 hours agorootparentIf you go through your contact list right now, how many people are on iOS, and how many of them do you think you could successfully convince to use XMPP as the primary method to reach you? With Matrix, I don't need to convince them. reply zaik 15 hours agorootparentMonal on iOS has made it quite easy to convince people to contact me via XMPP. Right now I have 31 XMPP contacts and 1 Matrix contact. reply rglullis 15 hours agorootparentYour about page: Interests: XMPP, OpenStreetMap, Wikidata. Nice, I'd like to be friends with you. But do you realize that maybe, just maybe, you are facing a bit of availability bias? reply zaik 15 hours agorootparentOh sure, but it's still a counterexample to your statement. I can convince people to use XMPP, and almost nobody is using Matrix if you don't do the convincing. reply rglullis 15 hours agorootparentBut you don't need to do the convincing with Matrix, because of its bridges. reply rakoo 14 hours agorootparentXMPP also has a good set of bridges though. reply upofadown 21 hours agoparentprevThe big usability issue with Signal is that it has a dark pattern that leads to most users using it without verifying that they are actually talking to who they think they are talking to. If you do verify a particular contact's identity it involves comparing a 60 digit decimal number. The 7 emojis seen in the linked article are arguably better but a short decimal number would have been good too and would have eliminated the issue that the emojis don't look the same. Neither seems to provide any sort of conceptual framework to allow the user to react in a reasonable way when something goes wrong with the identity stuff... OMEMO running over XMPP is pretty terrible for identity stuff, at least for the clients I have encountered. reply hiq 21 hours agorootparent> If you do verify a particular contact's identity it involves comparing a 60 digit decimal number. Why wouldn't you scan the QR code instead of doing that? reply upofadown 21 hours agorootparentYou can if both devices are phones and you are physically in the same location. Otherwise, the user is expected to be able to do that. In any case, the user won't have the faintest idea of why they have to do that, so they won't, which in a sense makes this moot. reply hiq 19 hours agorootparent> Otherwise, the user is expected to be able to do that. If you're not in the same location, you can long press the code in Signal and \"compare to clipboard\". > In any case, the user won't have the faintest idea of why they have to do that, so they won't, which in a sense makes this moot. I think that's a generic remark about this though, that applies to all messengers AFAIK. Whether that's a 4-digit code and 60. reply upofadown 17 hours agorootparentI am not sure how you would get the 60 digits from the other person in your clipboard. My point is that users should have the chance to know what they are doing. There seems to be a tendency to deliberately keep them in the dark. A 4 digit code is objectively more usable than a 60 digit code. reply hiq 17 hours agorootparentIf verifying these digits make any sense, that means you already have a trusted channel you rely on to communicate these digits. You would use that trusted channel to transfer these digits. How do you want to communicate them? > A 4 digit code is objectively more usable than a 60 digit code. It's more usable, but that would assume synchronicity (like a TOTP) or something else to be secure, while the 60 digits do not AFAICT. So there's a usability tradeoff. You can't truncate a hash function and assume it's just as safe. They could add more options on top of the current one though. Overall I think the intersection of pairs of users who: * want to verify their safety numbers * have very infrequent physical contacts * would struggle to use another trusted channel to communicate their safety numbers is small enough for this not to be a priority for Signal. reply upofadown 16 hours agorootparentTypically people would compare identity numbers over a voice channel. A sort of biometrics. It's been suggested that Signal add a voice channel feature for that purpose[1]. If a system is using a 4 digit number for identity verification, chances are it is something like a PAKE[2]. See OTR's (Off The Record) simplified Socialist Millionaire's Protocol for a practical example that allows the use of any string based on shared knowledge. [1] https://sequoia-pgp.org/blog/2021/06/28/202106-hey-signal-gr... [2] https://en.wikipedia.org/wiki/Password-authenticated_key_agr... reply AshamedCaptain 21 hours agoparentprevI find that XMPP interoperability (terrible as it is) is still just miles ahead of Matrix. For all intents and purposes Element controls the protocol and despite that I almost constantly find friction communicating the client for Android and the desktop Electron-based client. With 3rd party clients it is a nightmare. reply rglullis 21 hours agorootparentWhen https://siskin.im/ is seriously touted as the best iOS client for XMPP, you already lost 50% of the market share in the US. And if you don't have any usable app for 50% of your users in one of the most important markets, you can not really claim \"interoperability\", can you? Don't get me wrong, it would be great if more people were using XMPP. Now that I am more involved in the Fediverse space I'm learning how many wheels are being reinvented and XMPP has already solved. If more people learned about https://movim.eu I'd be able to shut off Communick and move on to do something else to do with my life, but the reality is that XMPP failed to achieve critical mass because it never had someone to complete control the protocol. reply AshamedCaptain 19 hours agorootparentNo, I don't have any problem about claiming interoperability in this context as it is completely orthogonal. You could also claim that not having animated gifs also makes it unusable for 99% of the population (an statement I might even agree with) and it would be irrelevant to interoperability. iOS simply sucks here and lowering down your pants to marry yourself to the whims of these insane \"platforms\" if anything most likely reduces your interoperability. You should be realistic and consider that there is no point to any \"E2EE\" messaging solution on iOS as _by construction_ all the metadata (at the very least) is going to be leaked to Apple (and they in turn will leak that to the authorities, as was pointed in HN quite recently), precisely by the push notifications crap you'd be forced to adopt as part of the pants lowering requiered to support iOS. reply rglullis 19 hours agorootparent> iOS simply sucks here and lowering down your pants to marry yourself to the whims of these insane \"platforms\" We can be here grandstanding and dismissing other people's choices or we can be pragmatic and find ways to grow the alternative networks to the point where the \"mainstream\" can no longer ignore it. If you want to continue using XMPP, great. But those that are on Apple are not going to drop their beloved iDevices just because we are telling them how cool XMPP is. Your inflexibility will do nothing but keep you isolated and able to talk with a handful of other people that are stubborn as you. However, if you let yourself accept that encouraging other people to adopt Matrix will at the same time (a) bring progress to those on iOS and (b) increase the utility of your own XMPP server, as now there will be more people being able to reach you through a bridge. reply AshamedCaptain 16 hours agorootparent> We can be here grandstanding and dismissing other people's choices or we can be pragmatic and find ways to grow the alternative networks to the point where the \"mainstream\" can no longer ignore it. I have been trying the pragmatic way for over 30 years and it. simply. doesn't. work. The mainstream will drop privacy, federation, and anything in a heartbeat just because the new network comes with a client which can do animated GIFs. There's simply no way to continuously try to match the race of ever-diminishing-usefulness features and if you even try to point that then someone calls you \"dismissive and grandstanding\". The only (possible) way forward is legislation. Carrots do not work. reply rglullis 16 hours agorootparent> The mainstream will drop privacy, federation, and anything in a heartbeat just because the new network comes with a client which can do animated GIFs. ICQ had animated gifs. MSN had animated gifs. Viber has animated gifs. Telegram has animated gifs. Why shouldn't people expect animated gifs from any decent messenger? Who are we to police what people should prefer for such a crucial piece of technology? reply DecoySalamander 17 hours agorootparentprev> When https://siskin.im/ is seriously touted as the best iOS client for XMPP, you already lost 50% of the market share in the US Could you elaborate? From screenshots it looks like any other chat app and branding isn't offensive. reply rglullis 17 hours agorootparentAt best it can be described as a \"hacker's idea of a functional mobile app\". The UI is crude, antiquated and not at all following the Apple guidelines. I'm not saying that I can do better, but I can bet that if you show it to 100 iphone users, 98% would not be interested in having it as their main messenger app. reply rakoo 17 hours agoparentprevI did it no later than Yesterday: - Install Conversations on Android - In a prompt, there's a \"create an account\", I create one (it's with conversations.im) - I have an account - At this point there's a slight confusion between \"what discussions are happening\" and \"what discussions do you know about\", but I manage to find a room to a discussion I'm interested in - Get in, see the messages The experience is definitely 100x nicer reply rglullis 16 hours agorootparentOP was on iOS. reply binarymax 15 hours agorootparentThey were on both iOS and their Mac reply rapsey 21 hours agoparentprevi.e. moving the goalpost fallacy. reply rglullis 21 hours agorootparentMy goal is \"let's have a communication protocol that is secure, enables applications with modern features on all major platforms and is not controlled by any single entity\". If not for the last point, I'd be using WhatsApp just fine. But because of it, Matrix/Element is currently the best we have. Is it great? Absolutely not, but it is the best we have at the moment, and to call it a \"trashfire\" without putting things in perspective is a disservice. reply rakoo 17 hours agorootparentInterestingly Delta Chat kind of fits the bill thanks to their investigation of webxdc, i.e. mini apps that run entirely within the chat and never connect to the outside world, only with peers in the chat: https://webxdc.org/ I can't say if this is the future, but I like it taking another direction. Taking a few steps back, this model solves a lot of problems with a very easy UX for beginners: shared calendar, shared expenses, shared notes can all happen inside your chat, which is naturally the place where you already share stuff with people, but now it can be more without any server installation or anything. reply the_third_wave 21 hours agoparentprevRunning an XMPP server is dead simple, just install Prosody and make few simple edits to the configuration and you're set. It hardly takes any resources (32 MB resident on my server) so it can happily live on whatever server you're already using. You will want to add some records to your domain to make it all run smoothly but this is well-documented and even works fine on free DNS providers like Namecheap and Cloudflare. Once you've done that you just install Conversations (from F-Droid, of course) and something like Gajim or Dino-im on your laptops and you'll bask in the glory of evading the surveillance dragnet because you're using OMEMO encryption which works end-to-end. If you happen to have Jitsi Meet installed you'll already have an XMPP server up and running to which you can add some configuration to make it useable for this purpose. Source: this is what I've been doing for many years reply rglullis 21 hours agorootparentOk, now go try to convince your 70 year-old father, who is using iOS, to join you and to use it as your primary means of conversation. I'm not being facetious. Try that, and then try doing it with Matrix/Element. Tell me which one do you end up with. reply MattJ100 21 hours agorootparentDid you try it? What were the pain points? reply yaky 19 hours agorootparentNot the person you asked, but here are some pain points asking my relatives (30s and 60s) to switch: \"WhatsApp works fine, I talk to you on there already\" (in reality, via a Matrix-WhatsApp bridge) \"Who am i going to talk to on there?\" (Me?) \"I don't want to install another app\" (but installing ad-laden Viber is fine...) \"I cannot share pictures to Element so I sent it to you through [iOS] Messages\" (well, Element removed share capabilities in iOS due to a rare bug) Simply ignoring messages (their iMessage and calls rings from all connected devices, but Element just notifies once) reply rakoo 17 hours agorootparentAll of this is absolutely valid, but none of this is specific to the XMPP/Matrix ecosystems reply rglullis 20 hours agorootparentprevThe first time I did this exercise was in 2018 (when I first set up an XMPP server and Matrix Synapse for Communick) and there simply wasn't any working iOS app. Monal was the only app I found and managed to install for him. It did chat only and would crash. I do not recall to get e2ee working and the fact that it is optional made things confusing even for me - e.g, I wasn't able to switch between a desktop client and Conversations easily. Element (then called riot.im) managed to do text, audio and video calls. The app had some bugs, but nothing that would block me from calling each other. The UX can still be confusing and I have occasional conversations where my father complains he can not hear me, most of them caused by my father not knowing that kept the video call but switched to the internal phone speaker instead of the external one. I heard about Siskin some months ago. Honestly, I haven't tried it yet. It might be that is fully functional, but the UI is so bare that there is no way that I'll be able to convince my father to switch to it. He still complains that he'd rather use WhatsApp like everyone else, so whatever XMPP brings now will be a case of \"too little, too late\". reply the_third_wave 19 hours agorootparentThe problem here is not XMPP or Conversations but the closed nature of iOS which keeps apps like Conversations from being ported there. Apple does not like competition to iMessage or to its app store revenues so it fights tooth and nail to keep its precious as is now clearly on view in Europe with their ridiculous 'core technology fees' and other shenanigans. Maybe you can give your father a non-iOS phone if that is what is keeping your experiment from succeeding? We're all on Android here, anything from stock Samsung like my mother uses to self-built LineageOS like I use and we have no problems like you describe. I video-chat daily with my mother without problems, we're using Jitsi Meet (hosted on the same server) for larger video meetings, we've used Nextcloud Talk (also hosted on that server-under-the-stairs) as well but now mostly use Conversations. Telegram also works well for video chat but that is neither self-hosted nor end-to-end encrypted so it is not a real comparison to Matrix or XMPP with OMEMO. reply rglullis 19 hours agorootparent> Maybe you can give your father a non-iOS phone if that is what is keeping your experiment from succeeding? That's a non-starter. He already had Android phones before, never liked them. O have to pick my battles, and getting him to call me Matrix instead of WhatsApp was already enough to call it success. Besides, my point was less about the specific individual but the systemic issue. iOS is too large of a market segment to ignore, and I can not go around telling everyone \"hey, why don't you just drop your shit Apple device and switch to something more open?\" reply the_third_wave 19 hours agorootparentprevMy father is dead so I don't think I can reach him through XMPP - at least not yet. My 85 yo mother is still alive and yes, she is using Conversations on her Samsung A25 which connects to prosody on my server through which she communicates with all of us. I live in Sweden, she lives in the Netherlands, one of my daughters now studies in the Netherlands as well. We have a 'family list' (i.e. a 'multi-user chat' using the muc extension) where we share photos and anecdotes, sometimes we 'talk' one on one. Everything encrypted through OMEMO so Feind hört NICHT mitt. I have tried Matrix/Element (self-hosted, of course, like everything else I use) and found it lacking compared to XMPP. It just seems to add needless complexity and does not offer anything worthwhile to compensate for it. I tried some Matrix bridges as well but found these lacking for my purposes. So the answer to your question is 'I ended up with XMPP'. reply Yanael 20 hours agoprevA friend wanted me to switch to Matrix for our 1:1 conversations and group chat of 3 people. The onboarding and user experience have been very poor on Element for years. I'm left with the feeling it is not made to replace a 1:1 messaging app. The protocol covers a broader use case, and the end-user apps are buggy and have a confusing user experience. There is some complexity in educating due to its distributed nature, but a top notch UX is much needed to overcome it. reply amarant 22 hours agoprevHuh, I've been using element for a while now, and the only problem I've encountered is that quite few of my friends use it. I've joined a few communities based around common interests, and never really had any technical issues with anything. I don't really recall much about the sign-up process at all, which I guess I would've if it was anywhere near as difficult as this guy claims... I'm on android tho, while he uses iPhone, maybe that's the issue? reply t0bia_s 15 hours agoprevNever used Element on iOS however on Android its... Ok. Not great, not terrible. Recently it's slower in loading chats in rooms and overall responsiveness is sometimes laggy. Desktop experience is without any issues. reply skywhopper 21 hours agoprevFantastic writeup. I’m a little confused by the screenshot with the caption “Servers marked as vulnerable, unavailable and with profanity in their name.” In the screenshot, three things are highlighted: labels for “Vulnerable”, “Unavailable”, and the server name “cyberfurz.chat”. Is “cyberfurz” supposed to be profanity? reply LeonB 21 hours agoparentI had a hunch … so I opened a German to English translator and put in the words Cyber furz In English: Cyber fart Every day is a school day! reply dale_glass 20 hours agorootparentIt's not German, it's a furry instance with some 90s flavor. reply LeonB 18 hours agorootparentFair enough. But the author of the original article is German, and I’m explaining why he described the instance name as he did. reply ThePowerOfFuet 22 hours agoprevI gotta say, he nails it. I so wanted to love Matrix. I tried it for a year and it just had too many sharp edges. reply theshrike79 22 hours agoparentI was on IRC when ircII and BitchX were common clients along with huge scripts on both for \"irc wars\" and shit. I can deal with jank. But the Matrix UI/UX still grates me on how bad it is. Just stop pretending, copy what Discord does and be done with it. reply kibwen 21 hours agorootparentCinny is the Matrix client that copies Discord's UI. My friends and I use it as the default web interface for our private server, no complaints (other than the fact that it makes you appreciate Discord's sometimes-annoying \"join all channels by default\" feature; the opposite, classic IRC approach of forcing everyone to search for and manually join all channels scales better but is an absolute disaster for discoverability on small-to-medium servers). reply raziel2p 20 hours agorootparentThis bothers me just as much in Discord as it does Slack/IRC. Has any chat software figured out this problem yet? Surely there must be some middle ground, like optional channel categories or something. reply spencerflem 18 hours agorootparentThe discord solution is to hide channels behind a role, put a message in the welcome page with emoji reactions, and run a not to assign the role to anyone who clicks on the emoji. Only downside is that its publicly visible and very jank. I wish they had a built in way, & also some way to make channels line bot_commands default to muted reply phyzome 20 hours agoprevThere are a lot of sharp corners, but going for the beta option was not a wise move. reply c0wb0yc0d3r 19 hours agoparentUnless I read it wrong, the author chose element x because it was available on all platforms. It looked like element wasn't available in the Mac app store reply phyzome 9 hours agorootparentAh! I see now. reply worik 15 hours agoprevMe too I tried to get Matrix working to have a conversation. Many worthy people I know use it But I failed in a similar way Do many people actually use it? When it is so easy to use Signal or (Dog help us, WhatsApp) reply joshsimmons 12 hours agoparentWe definitely have work to do on the onboarding experience, but I'm pleased to say that there are 115M addressable users on the open federation – so many people are having great success once they get past the initial friction. Aside from all the FOSS projects that use Matrix, it's also used by the German healthcare agency, French civil servants, NATO, a number of universities including MIT and TU Dresden, Moodle, and many others. We're moving quickly to address the feedback in the blog post and will be investing more in docs and UX to address the friction. Please don't hesitate to share your own experiences if you run into trouble! Stuff like that is a real gift. We're always looking to learn and improve. Josh, Managing Director of the Matrix.org Foundation reply juped 21 hours agoprevIt's heartening that some Matrix people responded positively to this free QA work; that's something we almost never see. reply master-lincoln 21 hours agoparentMaybe because it was mostly feedback for the Element people, so the Matrix people can sit back reply hammyhavoc 3 hours agoprevMatrix protocol with Element on my own Synapse Docker container has been working great for me for two years at this point. Not really had any issues with it, whereas maintaining other solutions like Rocket.Chat became a real time-sink prior to switching to Matrix. reply LukaD 19 hours agoprevI have been using matrix from time to time to chat with some folks who prefer matrix over other chat systems for reasons unknown. Matrix is an absolute trash fire indeed. Every once in a while a chat session with someone just craps itself and my client is unable to decrypt received messages (both element and element x). The issue then usually fixes itself within a couple of days. The bad UX aside, a chat system should at let me reliably send and receive messages. The other issues I had were related to the device verification. The last time I wanted to verify a new phone the verification request simply did not arrive on my other devices. At that point I gave up on matrix. reply nusl 16 hours agoprevPretty poor post. It highlights some issues, sure, though the author obviously never tried to actually try. Also, they say there's profanity but I don't see any; apparently the word \"cyberfurz\" is profanity? The author's prejudice is showing. reply zaik 15 hours agoparentFurz means fart in German. reply tdullien 21 hours agoprevPeople call this \"QA\", but isn't this just good product management? reply 1attice 16 hours agoprevThis feels like a mis-aimed article -- I use Matrix a lot, and Element, while annoying, is only one of many options. Compare \"The IRC trashfire\" (an article about the infelicities of Mirc) reply vdaea 22 hours agoprevDevelopers could also do these processes. And they probably do, often. But they usually have their heads so far up their asses that they don't see how inscrutable this onboarding process is even for very technical users. It's like when you use one of those Linux phones and your reaction all along is \"ew\". Do developers not notice how bad this is? No, they don't. Some of them haven't used a good UI ever. They can't fathom it could be better. They really think they are doing a good job. Why did Discord win? Oh, it must be dark patterns, regulatory capture, moat, etc. It can't possibly be because the UI makes sense! reply prmoustache 21 hours agoparent> Why did Discord win? Oh, it must be dark patterns, regulatory capture, moat, etc. It can't possibly be because the UI makes sense! I don't know but the Discord UI doesn't makes much sense to me, this is a huge mess. Signing up might be better though with the caveat that I never had any problem signing up with Element (not Element X for which I have 0 experience). reply master-lincoln 21 hours agoparentprevNowadays companies win because of better marketing and then network effect. The quality of the product does normally not play a big role for capturing a market reply TulliusCicero 19 hours agorootparentBullshit. Discord absolutely gained traction among gamers (and then other communities) due to being a good product that Just Worked. reply mpldr 19 hours agoparentprev> Developers could also do these processes. And they probably do, often. But they usually have their heads so far up their asses that they don't see how inscrutable this onboarding process is even for very technical users. I would argue that as the one developing a system (frontend or backend) you can not perform something like that. The reason being that you already know all the small little bits, tricks, and band-aids. The only way to get proper feedback, is by putting someone completely fresh in front of the system. reply rapsey 21 hours agoparentprevThe state of the project is completely typical of open source trying to do end user applications. reply dschuetz 22 hours agoprevCan we please stop submitting click-baity titles? reply hannob 21 hours agoparentI feel the \"clickbait\" accusation has a tendency to be overused. I mean, when I hear \"clickbait\", I think \"the headline makes me think there's something interesting that isn't really backed up by the content\". But here? The headline says \"Matrix Trashfire\", the content delivers exactly that. reply Steltek 14 hours agorootparent\"Trashfire\" is absolutely clickbait. The article lays out some poor onboarding documentation for a hypothetical 100% naive user. Matrix, Element, etc work and they work pretty well. The onboarding workflow for most Federated services don't suffer fools. There's nothing exceptional here. reply bowsamic 21 hours agoparentprevChanging the title is against the rules, isn't it? reply crimsoneer 22 hours agoprev [–] I mean, this is quite silly. Matrix is the open-source network infrastructure, Element is the client. Of course if you go to the Matrix web-page, it's not particularly user-friendly - if you expect to just use the thing, you should be going to Element. The ActivityPub page won't exactly help you sign up to Mastodon either. There are plenty of problems with Element and Matrix (I say that as someone who has been trying to migrate off Slack for 1+ year) but this comes off as the author just not doing basic reading. reply skowalak 22 hours agoparentI disagree. I have been using Matrix with Element as my main IM with my own homeserver for 3 years now, and the onboarding experience is just bad. You have to read so many texts which are spread across so many pages just to get stuff to work and even then sometimes it just won't. Sure, the author could have prevented some of their problems by reading the documentation, but Matrix is trying to become a solution everyone can use. And noone wants to read a manifest only to send some messages. reply crimsoneer 22 hours agorootparentHonestly, on this I totally agree - hosting your own Element/Matrix instance is really unnecessarily painful, with the documentation all over the place. But hey, it's free and open-source. But as as user, if you're even a little technical, downloading Element, registering and messaging your friends is really not the difficult bit. reply Havoc 22 hours agoparentprevThings like this are technically correct but irrelevant. If the average person can't figure out the UI & flow without getting frustrated then it's game over. reply IanCal 22 hours agoparentprev> if you expect to just use the thing, you should be going to Element. Element sent them to matrix.org reply crimsoneer 22 hours agorootparentI'll happily admit the Element/Element X migration they're currently on is silly and unhelpful, but the point being if they'd just gone to the Element home page, or download the actual Element app instead of the X one, it would have perfectly happily registered them to Matrix.org by default and everything would have been just fine. reply IanCal 22 hours agorootparent> or download the actual Element app instead of the X one MacOS app store only had element X, and also how is a user supposed to know to use the old one? Matrix.org tells me element X supports more stuff! The author says it's in beta but I can't see any indication that clearly tells me that and I'm looking for it. > just gone to the Element home page The app doesn't take you there. But OK let's do that. element.io There's a big getting started button. Now there's a form asking for my work email address and phone number and what challenges I'm looking to overcome. > Setup a self-hosted or cloud deployment, with powerful enterprise capabilities. To get started I need to not go to \"get started\" I need to go to sign in, which I can't do, then register. reply skywhopper 21 hours agorootparentprevYou’re missing the point. He’s following a reasonable user flow. If he went to the wrong place in the beginning, that confusion itself is a problem that the Matrix community needs to address. reply LeonB 21 hours agorootparent100% agree. The user should fall into the “pit of success” — no matter where/how they first enter the pages of matrix or element … it should be natural that they end up at the correct getting started for them. reply TulliusCicero 19 hours agoparentprevThe ability of some in the FOSS community to always blame the user for poor UX design is truly impressive. Do we need to test and simplify our onboarding? No, it's the confused users who are wrong! reply DoItToMe81 0 minutes agorootparentMy grandmother could use Matrix when she was starting to develop dementia. The only thing that tripped her up was the end to end encryption and key loss. It's not a UX problem, its a PEBKAC issue. reply prmoustache 21 hours agoparentprevI think the core of the problem is the naming separation between the default client and default instance. It is ok that matrix the protocol and matrix the server software have a different name than element. But the official server instance used by element should not be matrix.org but element.io because that is where you have to sign up and log in if you want to use the default official instance. Otherwise you redirect clueless end users to protocol papers and server administration docs. reply 4ad 22 hours agoparentprev> his comes off as the author just not doing basic reading. Perhaps a technology will not have success if its users need to do basic reading. reply arlort 22 hours agorootparentA chat platform for the illiterates might not be the best business proposition Jokes aside, I don't think matrix/element, at this stage, are trying to overthrow telegram or whatsapp. It seems their main approach is somewhat aimed at the people who use(d) IRC on the general audience side and institutional clients who they work with to create ad hoc solutions for employees, in which case which client to download is slightly less problematic since it's going to be a custom one anyway reply joshsimmons 12 hours agorootparentAs the Managing Director of the Matrix.org Foundation I can assure you I'd love nothing more than to displace centralized, proprietary communication tools. It just so happens that right now it's easier to land with folks who are patient with sharp edges and already believe in the value of FOSS, E2EE, and decentralization. Gotta start somewhere, right? :) IDK if you caught it, but the project lead, Matthew Hodgson, gave a main stage talk at FOSDEM a couple weeks ago and offered an update on the project and, in particular, on how we're taking advantage of the push that regulators are making for interoperability. WhatsApp, in particular, gets mentioned in this context and the writers at WIRED and Tech Crunch seemed to pick up on that! reply bhaney 22 hours agorootparentprevPerhaps I would prefer a chat platform devoid of people who can't do basic reading reply skywhopper 21 hours agoparentprev [–] He did start with Element. He only went to matrix.org because there was no way to set up an account through the Element client. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author had a negative experience with the Matrix chat platform and its client, Element X.",
      "They faced challenges with onboarding, version confusion, account creation, and verification.",
      "Matrix.org and Matrix developers acknowledged the issues and assured that they are actively working to resolve them."
    ],
    "commentSummary": [
      "The forum discussion revolves around criticisms of the Matrix platform, particularly regarding technical knowledge, user experience, and the significance of quality assurance (QA) in software development.",
      "Users express challenges in finding skilled QA professionals and the undervaluation of QA roles, emphasizing the need for companies to prioritize QA and cultivate a positive team culture.",
      "Additional topics discussed include confusion about the Matrix ecosystem, difficulties with the Element app's navigation, concerns about scalability and database design, and comparisons with other messaging platforms like XMPP and Slack. Issues related to verification, unread messages, and syncing problems are also mentioned, emphasizing the necessity for improved user research, documentation, and usability in the Matrix platform."
    ],
    "points": 287,
    "commentCount": 201,
    "retryCount": 0,
    "time": 1707908834
  },
  {
    "id": 39377508,
    "title": "Gitlab introduces webcam feature to enhance meeting attendance",
    "originLink": "https://benjamin-brady.github.io/gitlab-simulator/",
    "originBody": "Gitlab&#x27;s meeting recordings on YouTube have tens of thousands of views by people pretending to work. Now you can appear to be in the meeting using your own webcam.",
    "commentLink": "https://news.ycombinator.com/item?id=39377508",
    "commentBody": "Gitlab Meeting Simulator 2024 (benjamin-brady.github.io)207 points by brikym 9 hours agohidepastfavorite33 comments Gitlab's meeting recordings on YouTube have tens of thousands of views by people pretending to work. Now you can appear to be in the meeting using your own webcam. lifeisstillgood 8 hours agoThis reminds me of the scam reported on here last week, where scammers raised a false large invoice, then invited the mid-level manager to a zoom meeting where the CFO and CEO of the public company were on the call (very public as they needed enough video to deepfake them) and told the guy to approve the invoice. The gitlab thing is just “harmless” fun but real scams will force chnage - I predict in five years - every large and maybe small companies will have public private key based approvals (not “I approve” in an email from an iPhone). - PKIs will then be everywhere (at last!) - meetings will be recorded and transcribed (which will have huge knock on effects) - the push back against remote work will be real and large. Not sure what side I am on reply john-radio 6 hours agoparentThis is not a deepfake, though, to be clear; it's a YouTube video of a real GitLab data science staff meeting. reply geek_at 1 hour agorootparentthey were talking about the scam, not the gitlab meeting simulator reply armchairhacker 6 hours agoparentprevWhy the pushback against remote work? When it works it works, and it’s cheaper for everyone involved. reply 0xEF 3 minutes agorootparentI think it depends on the industry. For example, I work in manufacturing and we have a sales team that is in the office once a week, if we are lucky. The disconnect in communication between sales, management (who is also mostly remote) and production is absolutely massive and causing issues that did not exist prior to their current remote status. Examples include that both management and sales are often sluggish to respond when production needs clarification for custom work, and that the typical manager or salesperson's comprehension of the products being sold is atrophied simply because their exposure has diminished in recent years. In the context of our business, it would be beneficial if everyone was in the building working side by side and since only two members or our sales team are \"outside\" sales, there's not a compelling reason for the rest to be working from home. On the flip side, my wife does medical coding, which is entirely remote and doesn't require a constant line of communication to management or your coworkers, for that matter, unless there is a problem, most of which can be rectified with an email, chat or Zoom meeting. There is no compelling reason for her to show up to an office to do computer-based work that can be done literally anywhere with an Internet connection. As the US moves forward with continued remote work, I think it's important that companies be honest with the realities of the market they are in and plan accordingly. reply midasuni 1 hour agorootparentprevI suspect the argument would be you can’t deep fake in-person interactions reply rickdeckard 11 minutes agorootparentWhich is just a weird line of thought, which leads to \"any kind of meaningful decision will only be made when all involved persons are physically in the same room\", which results in a chain of meetings between people of different layers and signed papers changing hands. So in conclusion, the argument is that the existence and threat of deepfakes will cause companies to abandon digital transformation entirely and move back to the 80s... reply lars512 1 hour agorootparentprevI mean, as long as your deepfake is contributing constructively… reply bogota 4 hours agorootparentprevThere wont be. Not any more than we already have. The comment above you is pure sensationalism based on nothing. reply lagt_t 32 minutes agoparentprevAlmost all companies have ERP systems with 2FA and compliance teams, there is no more \"I approve\" emails... reply cranium 3 hours agoparentprevYou can be at the office and forced to do a zoom meeting because some people are in another office/country. reply geraldwhen 1 hour agorootparentI haven’t had a fully collocated team in 15 years. The only purpose of RTO is tax breaks and stealth layoffs. reply diggan 42 minutes agorootparent> The only purpose of RTO is tax breaks and stealth layoffs God forbid there might be actual people (including developers) who prefer to work in an office with others. Impossible! reply mfost 30 minutes agorootparentThey are free to return to the office and work with each other in person then. reply Panini_Jones 8 hours agoprevI saw this on Twitter the other day and saw all of the comments were about people use this video to reduce how much people bother them. The squares in the video reorganize about halfway through, but the overlay self-view video that's been added awkwardly stays the same. Maybe it would make more sense if it was fixed in the bottom right corner like normal Zoom calls? reply brikym 8 hours agoparentI hacked it together while waiting for Windows updates. It also doesn't work well on iOS and the video is a bit squished. If it takes off I'll fix these issues. It would be nice to have display modes for all the popular meeting apps like Zoom, Google, MS Teams etc. reply hyperific 8 hours agorootparentYou hacked this together right quick! The post about Gitlab meetings was just on HN yesterday. https://news.ycombinator.com/item?id=39363358 reply tester457 5 hours agoprevThe capacity for gitlab's video meetings to say both nothing and everything at the same time amazes me. reply stkdump 2 hours agoparentI think at least one participant is visibly uncomfortable with the fact that a f*g internal meeting is posted for the entire world to watch. reply neom 3 hours agoprevThey link to a Twitter post that has a YT video showing the example of a video used, the comments section is... interesting... https://www.youtube.com/watch?v=lBVtvOpU80Q reply davely 8 hours agoprevHaha, brilliant! I never actually realized this was a thing. Last year, I took a screen recording of an hour long Zoom meeting on my work machine and sometimes play that on screen in my home office when I need to set aside a bit of extra quiet time. Family will walk in, see the meeting on screen and immediately walk out. I felt really bad about doing this, but now seeing that other people do it (and you've made a website solely dedicated to this purpose), I feel less bad. :) But seriously, great job on this! reply globular-toast 1 hour agoparentCould you not just tell them not to? And close the door? reply voakbasda 1 hour agorootparentThat does not work for some people. They just don’t get it. They will open the door and walk right in. Doesn’t matter how many times you ask them to do otherwise. I have this problem. I plan to try this trick myself. Sad that it’s necessary, but happy that this may be a solution. reply lagt_t 29 minutes agorootparentLock the door? reply 2d8a875f-39a2-4 1 hour agoprevI clicked the link and watched a bit thinking that the whole thing was a quality AI production. I thought that the visuals and audio were really believable and well synced but the script was just a little too content-free and gave it away. Turns out it's not AI, just a recording of generic desk jockeys using generic corporate meeting-jargon. reply adorton 7 hours agoprevWe need to hook this up to a boss key stat reply gregorvand 3 hours agoprevPlay Joe Goddard's 'Lasers' as background music while using this and it turns into a pretty fun experience. reply mattl 8 hours agoprevWhen I was at GitLab the meetings had about 20x more people and everyone spoke for 45 seconds reply mvkel 3 hours agoprevThis is hilarious and a perfect capsule of the times we live in reply whoomp12341 8 hours agoprevfound a bug! control + scroll. when you zoom in and out it doesn't scale well reply theogravity 8 hours agoprevIs this something you'd use when you're in the office, or working remotely when you live with others and want to not be distributed? reply mhh__ 7 hours agoprev [–] Quite funny although as a user of gitlab tinged with a slight pain in that I think gitlab is just pure wasted opportunity (i.e. my experiences of using it versus certain other tools give me certain opinions of gitlab co.) reply jiocrag 5 hours agoparent [–] what reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gitlab's YouTube meeting recordings have attracted a considerable number of views from people pretending to be present in the meetings.",
      "As a response, Gitlab has introduced a new feature that enables users to utilize their webcams during meetings, giving the appearance of active participation.",
      "This feature aims to address the issue of individuals falsely claiming attendance by providing a visual representation of their presence."
    ],
    "commentSummary": [
      "The Gitlab Meeting Simulator 2024 is a website where users can simulate their participation in a GitLab meeting using their webcam.",
      "Some view it as harmless entertainment, while others express concerns about potential scams and advocate for stricter security measures like public-private key approvals.",
      "The discussion also addresses the resistance to remote work and the possible consequences of deepfakes on digital interactions, leading to a range of opinions from amusement to skepticism about the simulator's usage and implications."
    ],
    "points": 207,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1707956530
  },
  {
    "id": 39378235,
    "title": "Landlord solicits sexual relationship for reduced rent, claims café owner",
    "originLink": "https://bc.ctvnews.ca/air-canada-s-chatbot-gave-a-b-c-man-the-wrong-information-now-the-airline-has-to-pay-for-the-mistake-1.6769454",
    "originBody": "B.C. café owner alleges landlord offered rent reduction for sexual relationship",
    "commentLink": "https://news.ycombinator.com/item?id=39378235",
    "commentBody": "Air Canada is responsible for chatbot's mistake: B.C. tribunal (ctvnews.ca)205 points by brrrrrd 8 hours agohidepastfavorite88 comments guardiangod 6 hours agoI just want to give a shoutout to BC's Civil Resolution Tribunal. They take their job seriously, and make it as easy as possible for plaintiff to submit a complaint. I once had the misfortune of generating a batch of defective enterprise-grade SSD from a S company. That S company requires all RMA to go through the sales channel you bought the SSD from, but the sales company we used was out of business. S has refused all attempts to RMA by stonewalling us saying that we need to return the drives thru the bankrupted company. When we explained that the company is bankrupted, S just ignored us. When we created a new RMA request, S's rep says we already have an open case, and that we need to return the drives blah blah blah. After 5 months, in a fit of rage I typed up a 2000 words complaint, gathered all the emails/phone calls/photo evidences, and submitted a complaint to CRT ($75 fee). I wasn't expecting much, but within 3 weeks I got a call from a corporate lawyer in S company's Toronto office, asked me for the situation, apologized profusely, and asked if I can drop the case if they RMA all affected SSDs. That day was great, to say the least. Aside: The CRT posts all their cases (that reached arbitration) here- https://decisions.civilresolutionbc.ca/crt/en/nav.do Reading the cases is quite am entertaining time passer. reply 20kleagues 6 hours agoparentBC CRT is great when the happy pathway happens. They send legal letters to all parties so they are able to arbitrate, and that letter might be enough to get things resolved. I had the misfortune of trying to use them for a company which had just stopped responding and in the end even though I did get the default judgment in my favour, actually enforcing the judgment still required me to go through the normal courts (which in my case was not worth the cost). But the process of dealing with CRT was nothing short of delightful. reply teraflop 4 hours agoparentprevHmm, browsing through some of those cases, I'm starting to notice a pattern of Air Canada not taking these tribunal proceedings entirely seriously. From this case: > I find that if Air Canada wanted to a raise a contractual defense, it needed to provide the relevant portions of the contract. It did not, so it has not proven a contractual defence. [...] > In its boilerplate Dispute Response, Air Canada denies “each and every” one of Mr. Moffatt’s allegations generally. However, it did not provide any evidence to the contrary. From https://decisions.civilresolutionbc.ca/crt/crtd/en/item/5254... > Despite having the opportunity to provide documentary evidence, Air Canada did not do so. From https://decisions.civilresolutionbc.ca/crt/crtd/en/item/5249... and https://decisions.civilresolutionbc.ca/crt/crtd/en/item/5188... > Having reviewed the evidence, I am satisfied, on the balance of probabilities, that [Air Canada] received the Dispute Notice and did not respond to it by the deadline set out in the CRT's rules. From https://decisions.civilresolutionbc.ca/crt/crtd/en/item/5230... > Based on the proof of notice form submitted by the applicant, I am satisfied that [Air Canada] received the Dispute Notice and did not respond to it by the deadline set out in the CRT's rules. (I also found a fun one that hinges on an Air Canada employee's apparent inability to do basic arithmetic: https://decisions.civilresolutionbc.ca/crt/crtd/en/item/5225...) reply Orangeair 4 hours agorootparentThat last one was great > In his statement, Mr. Mackoff described distinct conversations he had with each employee, provided the supervisor’s name, and submitted the diagram he drew while trying to explain to the employees how to count the 10 calendar days. As Mr. Mackoff’s witness statement includes so much detail, and as Air Canada has produced no contrary statement, I accept that Air Canada refused to transport both Mr. and Mrs. Mackoff on February 15, 2022 and so breached its contract with them. reply qingcharles 4 hours agorootparentprevI see a lot of stuff like that in civil litigation in David v. Goliath situations. Usually the large entity puts in little effort and relies on the fact that its (much more expensive) lawyers generally have more sway with the court (judge), are more persuasive even when their arguments are nonsense, and can just drag cases on for years until the smaller party is burned out. reply anamexis 6 hours agoparentprevWhat is a S company? reply bakkerthehacker 5 hours agorootparentSamsung I've also had to deal with their lack of Canadian RMA for 2 SSDs. Had to go back and forth with them and trying to convince Amazon and the Amazon seller to replace the defective drives. Not buying any more Samsung memory products due to their essential non existent warranty in Canada reply rpy 4 hours agorootparentTook about 5 months of endless back and forth to get them to replace a defective SSD in Australia too, despite very clear consumer law guarantees here obligating them to help. Absolutely hopeless company to deal with. reply somerandomqaguy 3 hours agorootparentprevBuy through Memory Express if you've got a store nearby, just need to keep the receipt for the warranty period. They have a price matching policy for items that have the same SKU as well. MemEx is an authorized dealer so they'll take it back and send it back to Samsung for warranty work if you buy from them. reply ProllyInfamous 5 hours agorootparentprevSeems like an abbreviation for a USD$400B+ company that manufactures SSDs, but with the commenter not specifically mentioning (presume, smartly, to avoid SLAPP lawsuit/libel). reply calamari4065 5 hours agorootparentprevSamsung reply muro 5 hours agorootparentCould be Seagate and SanDisk too ... reply denysvitali 3 hours agorootparentI expected this to be SanDisk. I bought one USB from them and after a few writes it locked itself from writing further. Apparently I'm not alone and the only fix is to throw the thing away. reply ornornor 4 hours agoparentprevS is such a disaster that I have established a personal policy of staying away from S and never buying their things (TV fridges phones SSDs printers… anything they make). This policy has drastically improved my sanity. They produce expensive junk and have no regard for quality or security/privacy. I’d still buy things that have S components in them but not whole S devices. reply choilive 3 hours agorootparentYes - my house (was) full of Samsung appliances - Stove, Fridge, Microwave, Washer, Dryer. All garbage. They are all falling apart now or became became uneconomically repairable within 5 years. Every single appliance repair businesses I called flat out wouldn't touch the fridge for example.. Apparently they don't provide service information or parts to 3rd parties (at least for the fridge). I have moved onto a different brand, but waiting to see if it's any more reliable.. reply PakG1 3 hours agorootparentWhen we were purchasing a clothes washer and dryer, Samsung had a special promotion. The sales rep at the store told us that the Samsung machines got the most complaints and she would recommend the LG machines. But we wanted that promotion, it was oh so nice. We bought a 5-year warranty just in case. Sure enough, it's year 3 and the washer has stopped working. Repair guy came and decided he needs to order new parts to fix it. It's been a week or so without doing any laundry. Glad we purchased the extra warranty, but maybe we should have gone with the LG like the sales lady recommended. reply kube-system 3 hours agorootparentprevI also have had the same experience with my Samsung appliances. I paid top dollar for a nice looking set of laundry machines only to find out that they have garbage components inside of them that are bad by design. I had a squeaking drier fixed under warranty, only to have the same issue reoccur multiple times, because the rollers are just junk. It needs a new set like clockwork every year and a half or so, I have the replacement procedure memorized now. The washer seems to be allergic to water and soap. I keep the unit in a dry location, leveled and raised off of the floor, yet, the body of the unit is rusting out, the chrome finish on the door is peeling, and when I clean it, the cycle labels wipe right off the front panel. The pump has also failed due to rust on the motor. Absolute trash. I probably would have been better off with a $400 top loader. reply londons_explore 2 hours agorootparent> yet, the body of the unit is rusting out Happened to my ~2016 Samsung. Turns out a hose clamp wasn't properly installed and water was dripping onto the steel floorpan and rusting everything nearby. Fixed it and all rusting halted. reply hamandcheese 2 hours agoparentprevCan we please name the company rather than make people guess? reply refurb 5 hours agoparentprevEven as a smaller-government proponent, I've been a big proponent of things like the CRT. One of the core functions of the government is enforcement of contracts. While there are the courts, they are out of reach for most people either due to skill level or financial constraints. Having a simple, low cost, easily accessible way to resolve contract issues puts every member of society on a more even footing when it comes to economic interactions. If we're going to build our society based on capitalism and the ability for parties to enter into contracts for things like employment, buying/selling, housing, etc, having an efficient means to resolve disputes seems like a no-brainer. reply janalsncm 6 hours agoprevGood. Company outsources customer “service” to a completely unreliable piece of software, which goes to show how much they care about their customers. And then they argue in court that customers shouldn’t even trust their own software! So essentially they have increased profits by cutting customer service jobs, replaced humans with a stochastic parrot, and now don’t want to be responsible for the drawbacks of this decision. They want all of the upside and none of the downside. reply EZ-E 3 hours agoparentMost likely they will just add to the chat bot answers a \"Please make sure to double check our policy at $URL - Only our policy applies\". reply CogitoCogito 30 minutes agorootparentI really hope that wouldn’t get them out of it. In that case, Air Canada would still be misrepresenting their policies. Misrepresenting Air Canada policies to induce a purchase of a ticket may not legally be fraud, but it certainly feels like it should be. It’s also hard for me to see how that argument would square with this reasoning from the article: > \"While Air Canada argues Mr. Moffatt could find the correct information on another part of its website, it does not explain why the webpage titled 'Bereavement travel' was inherently more trustworthy than its chatbot. It also does not explain why customers should have to double-check information found in one part of its website on another part of its website,\" he wrote. reply apapapa 5 hours agoparentprevIn their defense, I never seen an airline company caring about their customers... Otherwise they wouldn't be late 25% of the time. reply CaptainZapp 5 hours agorootparentNot necessarily so. A couple weeks ago Oman Air cancelled the return leg of a long distance flight due to a change in schedule. They offered to reroute me with the Qataris via Doha. I preferred to cancel the (in principle non-refundable) flight and make different arrangements. The money,~2'500$, was credited to my card 4 days later. Including fees paid for preferred seats. It's a shame that they stopped service to my city. Beause it's a great airline, which always provided stellar service. reply rowyourboat 3 hours agorootparentThose are your basic rights: You entered into a contract with the airline, and the airline failed to deliver. Of course you get your money back if the alternative solution is not satisfactory - whether or not the ticket was refundable doesn't even enter into it, as it was the airline that failed to deliver in the first place. That's not stellar service, that's just fulfilling their legal obligations. reply throwaway2037 3 hours agorootparentI think the point being made: It was refunded very quickly and without hassle. Other, less scrupulous / ethnical airlines were try more tactics to redirect to worse flight or delay refund (if at all -- \"oh, it was a lost in our system\"). reply j7ake 2 hours agorootparentprevMy experience with United emirates was similar. Extremely generous refund policies and fast action. reply userbinator 6 hours agoprevCompanies should be responsible for the information they give customers, regardless of how they do it. \"Give me a real human\" is usually what I say when it seems like I'm talking to a bot. Unfortunately, there have been times when I later discovered that the \"bot\" was actually a real human that was just acting like a bot! While AI may seem to be improving, I always keep in mind the possibility that the opposite is also happening; and if you don't want your job replaced by a bot, perhaps you should not be acting like one. reply plantain 6 hours agoprevAir Canada has always been like this. They were notorious amongst the stranded-abroad community during COVID for selling tickets on flights they weren't operating and had no intention to operate, then refusing to refund, except with credits that also expired before they intended to operate. Scammers from top to bottom. reply throwaway2037 3 hours agoparentCanada is a good democracy. As your parliament to split Air Canada into multiple carriers or reduce any state-provided advantages to allow better competitors to emerge. reply MichaelZuo 6 hours agoparentprevWere they ever practically compensated in the end? reply cperciva 5 hours agorootparentYes, the government gave airlines a bailout conditional on them issuing refunds. reply CogitoCogito 26 minutes agorootparentI don’t know anything about the details of that bailout, but I feel the only reasonable and fair approach would be to (1) require that customers were refunded unconditionally and the (2) be forced to pay statutory damages. Then _if_ Air Canada couldn’t do that without a bailout, the government should have bailed them out while taking equity for the value of the bailout. reply usaar333 7 hours agoprevI find it hard to understand the calculus on Air Canada's side of fighting this. Not a lot of money and really bad press. reply dghlsakjg 6 hours agoparentYou overestimate AC. They are buried in compensation claims right now due to them claiming that crew shortages in 2021 and 2022 were out of their control, and the government regulators disagreeing with them. My guess is that no one with any power bothered to look at this until it was too late to settle, and they thought it was worth the cost of fees to see if they could get out of paying. reply dmix 7 hours agoparentprevBecause it probably threatens a whole new customer support system they spent 100x developing / migrating to vs what they spent in lawyers for this case reply ApolloFortyNine 7 hours agorootparentOut of court settlements have no effect on precedent. We would even be here if the manager this got escalated to at some point had just done their job and made an exception. reply dmix 5 hours agorootparentSo it wouldn’t make other lawsuits easier in civil law? I don’t know the law well here reply plorg 7 hours agoparentprevIf they can be held liable for their shitty software replacing a human then it might not actually be cheaper to replace the human with shitty software. reply EZ-E 4 hours agoparentprevRealistically, all complaints from the flyer went to first level customer service agents which are only told to enforce the policy as is. This probably did not get escalated. reply kwar13 5 hours agoparentprevBecause they're mostly a monopoly and have been doing whatever they want for decades by now. They've gone bankrupt time and time again bailed out by tax money. reply HWR_14 4 hours agoparentprevNot a lot of money times many people is a lot of money. reply ApolloFortyNine 7 hours agoprevYo what was air Canada thinking here... 1 week after the flight, and he even provided the death certificate? How'd anyone let this go to 'court' (I'm not Canadian, it's a tribunal idk what that is) for $600. And I'm guessing it's Canadian so it's more like $400 US. What kind of point were they trying to prove here. I legitimately think you could talk amazon support into giving you that over a broken product. reply jannyfer 6 hours agoparent> And I’m guessing it’s Canadian so it’s more like $400 US. FYI, to a Canadian, $600 CAD feels like what $600 USD feels like to an American. Canadian wages aren’t 30% higher in numerical value than US wages. reply fumeux_fume 5 hours agorootparentGranted, I’m an American and I’ve had a couple glasses of wine tonight, but I’ve read this comment like 8 times and it still makes no sense to me. reply D13Fd 5 hours agorootparentThe currency is worth 30% of a U.S. dollar but the cost of living is also significantly lower, so to a person living in either country $600 feels like about the same amount of money. reply johnwalkr 4 hours agorootparentThe cost of living is often not lower in Canada. Average housing cost is now significantly higher in Canada and for those Canadians with an easy path to move to the US (like SW developer, engineer or doctor), the numbers I am recently seeing are salary of 2-3x in the US, housing cost 0.5 to 0.7x, and other cost of living a bit less. reply seattle_spring 3 hours agorootparentWhere are comparable locations half as expensive in the US? I agree that Canadian salaries trend much lower. reply johnwalkr 27 minutes agorootparent\"Comparable locations\" is very subjective, but Vancouver vs Denver is one I've heard of that seemed convincing to me. Then again, I've never been to Denver. reply anonymousab 5 hours agorootparentprev> but the cost of living is also significantly lower, You can look at random things like groceries, homes or car insurance to see that this isn't really true. 600 USD (or even 600 CAD) goes a heck of a lot further in most of the USA. reply cperciva 7 hours agoparentprevit's a tribunal idk what that is The Civil Resolution Tribunal is better known as \"online small claims court\". It's something BC introduced a few years ago to streamline the process. reply pwarner 7 hours agoparentprevYeah the real story seems to be garbage customer service: by the AI and humans at Air Canada. Perhaps the bot is implemented perfectly to match the humans it replaced. reply dghlsakjg 6 hours agoparentprevThe civil resolution tribunal is kind of a hybrid small claims court and arbitrator. It was originally started about a decade ago with limited scope over condo/HOA disputes and small claims, but has been expanded. They have legal authority, but you can always appeal to the provincial courts (which almost never works out, I think they agree with CRT decisions in 95% of cases) Air Canada baffles me. Their front line employees are powerless and frequently hostile. But I have never submitted a complaint to corporate without being given at least $200 CAD worth of flight credit. Most recently I was yelled at and hung up on by a customer service agent, I got a coupon for 20% off any itinerary with up to 4 passengers. I’m not even a member of their rewards program! reply Scoundreller 31 minutes agorootparentSame here. Came across something that was broken on a plane that wasn’t serious in any way and I wasn’t even mad about. But I don’t bother going through “feedback” or “comment” because I figure they never action on those. So I submit my “complaint”. A few months later, I get a response clearly showing that they didn’t read what I wrote, and almost certainly didn’t put in any plan to fix it; but they gave me a $400 credit. I wasn’t even angry in my “complaint”. Maybe I need to be nicer in my actual complaints in general in the future. Thought it was a scam when I got the response but I’ll take it. reply danepowell 7 hours agoprevI wonder whether the bot hallucinated the wrong information or whether the policy changed and the bot simply wasn't updated / retrained. The latter seems more likely but less interesting, akin to information on a boring HTML page getting overlooked during a site update. reply dghlsakjg 6 hours agoparentThe incident was in 2021, so I don’t think it was an LLM. reply WirelessGigabit 6 hours agorootparentNo but it would be nice if the same laws would apply to LLMs. Too often they're now deployed as a quick fix for a chatbot. But before either they quoted me a solution or escalated to support. Now it makes up a non-working solution. reply MBCook 5 hours agorootparentHonestly would it make any difference if the information was just on an FAQ page and it contradicted what the actual ticket contract said? I’m with you. They should be held to the information they give out. Short of an employee purposely maliciously giving out bad information it seems like not making stuff up should be a basic requirement for them to operate. reply kazinator 6 hours agoprevIf a vendor communicates multiple different prices for the same thing in different places, such as different areas of their website, or their website versus an e-mail flyer, or any pieces of paper from the vendor, they must give you the lowest price among all of them and not make excuses like that you should check the other communications and understand that the price is one of the higher ones. This is just common sense. reply Sakos 7 hours agoprev> Air Canada, for its part, argued that it could not be held liable for information provided by the bot. > \"In effect, Air Canada suggests the chatbot is a separate legal entity that is responsible for its own actions. This is a remarkable submission. While a chatbot has an interactive component, it is still just a part of Air Canada’s website,\" Rivers wrote. This could be an article on The Onion. Unfortunately, I suspect this won't be the last time companies try to weasel their way out of the consequences of how they use AI in relation to their customers (i.e., us) reply throwaway888abc 7 hours agoparentIndeed interesting, even in alternative reality if their argument is valid. They still \"hired\" the chatbot to provide service on their behalf and they are liable for it. Not lawyer, just spark of common sense ? reply bee_rider 7 hours agorootparentI don’t think hiring is a good analogy here. A human at least can bear responsibility. A chatbot cannot. That responsibility has to be absorbed by something. A company should be much more responsible for the actions of programs they run, than people they hire. reply em-bee 5 hours agorootparentif a human makes that mistake the company is still responsible for it. the company can however then turn against that human they hired and sue them. if that court determines that said human does bear responsibility the company will get something back. that has no bearing on what the customer gets from the company however. so for the customer it is irrelevant how the mistake by the company was made. reply nerdponx 6 hours agoparentprevI love a good spicy legal opinion like this. reply lokar 7 hours agoprevThe penalty for arguing they are not responsible for the “magic chatbot” telling lies to customers should be much more severe. reply julianlam 7 hours agoparentIt would've been if it were a lawsuit, but this was a tribunal hearing and recompense is limited to damages, that is, the amount the claimant was out of pocket. I'd love to stick it to Air Canada too, but Canada is (hopefully) less litigious than the US. reply dannyw 1 hour agorootparentYou should have a little deterrent for “remarkable” cases like this. Say, double damages capped at $300. reply htrp 6 hours agoprevwho was the vendor that supplied the chatbot? reply renewiltord 7 hours agoprevWhere's the chatbot accessible from? Can't find it. I assume it was some old-school KB query chatbot not an LLM? Date says Nov 2022 and LLMs hadn't become quite as popular at that time yet. They have to obviously be responsible. What a nonsensical claim. reply xyzzy_plugh 7 hours agoparentWhat difference does it make? If it happened today with an LLM the outcome should be the same. reply petesergeant 6 hours agorootparent> What difference does it make? In liability, none, but it'd at least be more understandable if it was an LLM, rather than something that should have been hard-coded with the right answers. reply xyzzy_plugh 5 hours agorootparentI'm not sure I follow. I wrote an \"AI\" chatbot in highschool and it certainly didn't reproduce hard-coded \"right answers\". LLMs don't somehow invalidate the work of their predecessors. Chat bots aren't new. I'm not really sure why you brought up LLMs at all. Are chat bots synonymous with LLMs now? I sure hope not because then this sort of scenario only gets worse. reply darylteo 4 hours agorootparent> Are chat bots synonymous with LLMs now? I sure hope not because then this sort of scenario only gets worse. You're right. LLMs are now the de facto standard implementation for Support Chatbots. Almost every chatbot platform offers a AI Chatbot product in some form. - they're also frequently shown to be prone to hallucinations - and also shown to be tricked - and can be gamed into breaking it's prompt cage https://twitter.com/ChrisJBakke/status/1736533308849443121 This case therefore sets a precedent for these scenarios, with or without a disclaimer that you should confirm this information with the dealership. If you assume the liability for the accuracy of \"ye old bot\" responses, then it raises the possibility that you assume the liability for the accuracy of \"ye new bot\" responses. My opinion is that once the AI wild west phase has ended, and the legal reckoning is upon it, everyone will learn that using AI does not absolve one of liability. This would essentially kill the dream of full self-driving automation, among other things. reply petesergeant 5 hours agorootparentprev> I'm not really sure why you brought up LLMs at all I didn't > I wrote an \"AI\" chatbot in highschool and it certainly didn't reproduce hard-coded \"right answers\" Sounds like it would have been a poor choice for a customer-service bot then? reply xyzzy_plugh 4 hours agorootparentMy apologies, I misread. And it would certainly have been a poor choice for customer service, but I have definitely used chat bots that are far worse than that one was. reply nine_zeros 7 hours agoprevSo a lawsuit vector exists against AI-enabled lack of care for customers. Would be interesting to see if a cottage industry can open up around prompting inaccurate information from company AI info to reap via lawsuits. reply nrmitchi 7 hours agoparentThat seems like a stretch based on this specific case, given that the only award was explicit damages (ie, a refund of funds already spent). No one ended up “ahead” here. reply bee_rider 7 hours agoparentprevThis would be good, actually, right? Better to have the chatbot misfire on somebody not actually depending on it for correct info. reply nkrisc 6 hours agoparentprevYou’d have to do so without appearing to intend to do so, and in either case would be fraudulent. reply HWR_14 4 hours agorootparentI don't see how it's fraud or would need to have a disguised intent. reply yieldcrv 5 hours agoprevouch I cant believe they really tried those arguments the chatbot as a separate legal entity? do they mean like a contractor’s service, or did they mean like a distinct AI creature reply ilaksh 7 hours agoprev [–] November 2022.. might have been a pretty weak model or just out of date info. This to me is a cautionary tale against deploying cheap small LLMs instead of using larger models. I think 7b models are very tempting to many business people who may value profits over just about anything else. reply potatolicious 6 hours agoparent... Larger models aren't immune from hallucinations, nor is the rate of hallucination negligible enough to ignore with larger models. This is a fundamental issue with the underlying technology, one that many companies in this space refuse to reckon with. A lot of \"this can be automated with AI!\" startups are relying on the basic assumption that hallucinations can be tolerated - cases like this really narrow the field of use cases where that is true. reply ilaksh 6 hours agorootparentHallucination or inaccuracy is dramatically worse with 7b models versus the largest ones. reply quirkot 6 hours agorootparentprevJust wait till an aggressive lawyer finds out about this. Gonna be a lot of companies taken to the cleaner for hallucinations reply cscurmudgeon 6 hours agoparentprev [–] There is no evidence they used a small LLM. There is no evidence that LLM size is the issue. Environmentally bad to use a large model when a smaller one could work just as fine. reply MBCook 5 hours agorootparent [–] There’s no evidence it was even an LLM at all. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A café owner in British Columbia alleges that their landlord proposed a sexual relationship in return for a rent reduction.",
      "The owner claims that the landlord made this proposition, suggesting an abuse of power dynamics.",
      "This situation highlights the importance of addressing and preventing sexual harassment in professional settings."
    ],
    "commentSummary": [
      "Air Canada has been held accountable by the British Columbia Civil Resolution Tribunal for an error made by its chatbot.",
      "The discussion addresses complaints about Air Canada's dispute resolution and customer service, as well as complaints about Samsung's products and customer service.",
      "The conversation also explores the liability of companies for the actions of their chatbots, the potential implications of using advanced language models, and the problem of hallucinations in AI chatbots."
    ],
    "points": 205,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1707962346
  },
  {
    "id": 39371831,
    "title": "Cracking the Code: Revealing the Secrets of GoodWe's Encrypted IoT Protocol",
    "originLink": "https://smlx.dev/posts/goodwe-sems-protocol-teardown/",
    "originBody": "Reverse-engineering an encrypted IoT protocol@smlx's bloghtml{visibility:hidden}{\"@context\":\"https://schema.org\",\"@graph\":[{\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Posts\",\"item\":\"https://smlx.dev/posts\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Reverse-engineering an encrypted IoT protocol\"}]},{\"@type\":\"BlogPosting\",\"dateModified\":\"2024-02-14T16:04:52Z\",\"datePublished\":\"2024-02-14T16:04:52Z\",\"headline\":\"Reverse-engineering an encrypted IoT protocol\",\"author\":\"Scott Leggett\"}]}HomeAboutPostsWed, 14 Feb 2024 UTC# Reverse-engineering an encrypted IoT protocolContentsTL;DRThe Sun: so hot right nowPost-install setupMetrics? You need to be online.SEMS Portal account requiredPost-setup state of playMetrics extraction prior artHacking the Homekit 1000nmapPacket captureModbusAA55 protocolZZ/5A5A protocol (mobile app)Firmware Reverse EngineeringPacket Capture reduxAnalysis of the GoodWe metrics protocolNetwork “glitching”Empathy: a powerful reverse-engineering toolEncryption schemePower “glitching”Extracting the keyExtracting meaning from the plaintextPrometheus & GrafanaConclusionsHow to secure GoodWe devicesMiscellaneous notesGoodWe’s Cyber Security claimsHi-Flying and XinwuRemote administrationBatman modeDNS updates## TL;DRI reverse-engineered the encrypted protocol GoodWe smart meters and solar inverters use to send metrics to the cloud.I used this research to build a prometheus exporter.## The Sun: so hot right nowI got a solar PV system installed in my house in mid 2023. I did the bare minimum of research beforehand - just talked to a couple of different installers about pricing, sizing and the economics of a battery.One thing I certainly did not do is any research into brands and their relative hackability or security merits. I just specified that I wanted to monitor the devices and see some metrics. The installer told me that this required a smart meter and a mobile app. Honestly I assumed that all brands would be equally horrific IoT junk, so I just went with the recommendation of the installer. At least that way the electrical functionality had to be reasonable, right?The result of my lucky dip was a GoodWe DNS G3 Inverter and a GoodWe HomeKit 1000 Smart Meter. These devices look quite slick, and so does the website. They are also popular here in Australia, so my hopes were high that it would be easy to set up local monitoring, because surely someone else had figured out how to do it.## Post-install setup### Metrics? You need to be online.Right after physical installation the system is producing power, but the metrics aren’t visible anywhere. The documented way to see metrics is to connect the device to GoodWe’s cloud, and then use their web UI or mobile app.The devices act in simultaneous wireless AP and STA modes, and setup works like so:Connect to the device’s WLAN, which will be named Solar-WiFiXXXXXXXX, where the Xs are the serial number of the device. The password is, naturally, admin.Visit the device’s web UI on 10.10.100.253.Log in (using credentials admin / admin, of course!).In the web UI, select the WLAN that you want the device to use to connect to the Internet.Now the devices are connected to GoodWe’s cloud. But you still can’t see any metrics.### SEMS Portal account requiredThe next step is to go to GoodWe’s SEMS Portal and create an account. Then let the installer know that the devices are connected, and the email you used to create an account on the SEMS Portal. Then the installer will email GoodWe (!?) to tell them to assocate your account with the serial number of the devices, and at some point GoodWe will action that request (I was assured they checked their inbox regularly).Finally after a day or so the device’s metrics are visible in the SEMS Portal.According to this flyer, it seems that the installer would have a portfolio of “power plants”, and they can use the SEMS Portal to perform “Fault self-analysis & troubleshooting”.SEMS includes a range of functions and features to ensure reliable operation and to deliver precise information to operators at the press of a button. It is accessible by multiple accounts with different levels of access for owners, installers and EPC companies## Post-setup state of playSo now these two devices were physically installed, and connected to GoodWe’s cloud over the internet via my isolated IoT VLAN. But I had questions:I wanted to scrape metrics locally, dammit! Why should I have to use the crappy cloud UI or equally bad mobile app?What else can GoodWe do with this connection? E.g. can they remotely administer the devices? If so, can I disable this “feature”?It turns out that the inverter is powered by the solar panels, not by the grid. So it loses power and goes offline as soon as the sun goes down. And since I mostly have time to hack on this stuff after dark, I concentrated on the smart meter.## Metrics extraction prior artThere is quite a cottage industry online documenting how to extract data from GoodWe inverters. They respond to Modbus queries, an Operational Technology standard. There are many Github repositories with useful information about the GoodWe Modbus protocol, such as:a python library for extracting metrics;a Home Assistant integration, built on that library; andsome GoodWe-specific field documentation.Unfortunately, my Homekit 1000 smart meter is not supported by any of these libraries.## Hacking the Homekit 1000I’m presenting the process I followed in chronological order. So if you want to find out what actually worked, skip to the end.### nmapThe first thing I did was fire up nmap, and point it at the HK1000. It showed listening TCP port 23 - good old Telnet! Connecting to this port and trying Username: admin, Password: admin gave me a command prompt!$ nc 192.168.18.17 23 Login as:admin Password:admin CMD>? cfg net os mft CMD> Poking around this prompt soon showed that it was pretty limited1, and it seemed to be a development interface that was left enabled. I couldn’t get any metrics out of it.I also ran nmap in aggressive mode and was rewarded with a hard crash in the web server, and the device resetting back to factory settings.### Packet captureSniffing the traffic from the device showed that it was connecting out to tcp.goodwe-power.com:20001, and sending packets at regular intervals. However a quick look at the traffic revealed that while the serial number of my inverter was visible, the main body of the payload was a high-entropy blob. So the metrics data I was after seemed to be encrypted.I also found a Github comment which came to the same conclusion.### ModbusThere is a GoodWe Modbus protocol spec sheet and register map floating around the internet which was invaluable in understanding how GoodWe encodes metrics from their inverters. From this documentation I built a Modbus scanner that simply queried every register. The address is only 2 bytes wide, so there are ~65k possible addresses.Unfortunately the HK1000 only returns a value for a single register address. I forget which register it was, but it was something useless like Firmware Version.### AA55 protocolGoodWe devices also support another (older?) protocol known as the AA55 protocol. I couldn’t find much info about it except for another old spec sheet.I built a scanner for this too, but the HK1000 didn’t respond to any queries.### ZZ/5A5A protocol (mobile app)The SEMS portal mobile app has an interesting function where you can connect to the SOLAR-Wifixxxx network, and configure the device using the app but without any authentication.Sniffing this traffic (thanks to airodump-ng and Wireshark’s WPA2 decrypt support) shows that the device can be configured without authentication by sending plaintext UDP packets to the right port. Of course, this port is listening on all interfaces so it also probably works via whichever local wifi network you connect the device to. Gross.However, this protocol appeared to only be used for network configuration. I didn’t find any way of extracting data from the device using this protocol.### Firmware Reverse EngineeringAfter no success with the query protocols, I decided that maybe the network was the wrong approach and I should try firmware instead. I managed to dump the firmware of the device using the command prompt and a command similar to this2:echo -e &#39;adminadminspi rd 0 2097152&#39;nc 192.168.18.17 23tee ~/download/hk1000.spi2.img This hexdump is interspersed with log lines, and the bytes are transposed. So I dumped it twice, diffed the two dumps to eliminate the log lines, and fixed the transposition manually using vim.Then I unhexlified the binary with xxd:xxd -r -p hk1000.spi.img > hk1000.spi.bin.img And ran binwalk over it:binwalk -eM hk1000.spi.bin.img This revealed that the OS was eCos RTOS on a MIPS architecture. I spent some time trying to reverse this binary using Ghidra, but honestly I just don’t know what I’m doing when it comes to binary reverse engineering.Finally, while staring at the binwalk output, these lines caught my eye:1976456 0x1E2888 AES Inverse S-Box 1977752 0x1E2D98 AES S-Box ### Packet Capture reduxGoing back to the packet capture I finally noticed that the length of the encrypted blob section was always a multiple of 16, plus 2.Wait a second&mldr; AES block size is 16 bytes!## Analysis of the GoodWe metrics protocolSince this is was a black-box analysis, I had to rely on probing via the I/O I controlled: network and power.### Network “glitching”3It was at this point that I found what would be the key to cracking the encryption scheme.Back in October 2021, someone else did basically all the same work I did, and presented it at the Melbourne Linux User’s Group. Not only that, but they put their presentation online! Thank you Danny!Anyway, Danny made a very interesting observation: if the internet connection went down, the device would buffer messages, and send them all at once when the connection came back up. Crucially, for buffered frames sent in the same second, the first few 16-byte blocks of ciphertext were identical!I was able to replicate this locally!### Empathy: a powerful reverse-engineering toolWhen I’m looking at a problem like this, I like to put myself in the shoes of the developer. What kind of person are they? What are their motivations?In this case, we can observe:Telnet left on in a production firmware image, with credentials admin:admin.nmap can crash the device hard enough to factory reset.Packets sent over TCP with identifying data (serial number) in the clear.The metrics seem to be poorly encrypted (identical section of ciphertext in consecutive frames).Unauthenticated configuration protocol.A web UI that looks like it was hacked together in an afternoon. Inspecting the source shows lots of commented out HTML blocks.In Danny’s presentation, he used this slide after discovering the Telnet port password:However I think this is more appropriate: There should have been an animation here but your browser doesn't seem to support it.What these observations tell me is that GoodWe doesn’t put a great deal of effort into securing their devices, and therefore the developers working on this device didn’t have much incentive to create a secure protocol. So there’s a chance I can hack around their encryption.Putting myself into the shoes of these developers, what would I need to implement a metric protocol?Framing: this is TCP; it’s a byte stream. So we need a header of some kind to know where frames start.Length: how many bytes after the header do we need to read to get the full frame?Detecting data corruption: not anything malicious, just bitflips.Looking at the packet captures, it is easy to see POSTGW is the frame header, and the very next field looks like a big-endian encoded int32 with a value consistently three bytes shy of the length of the data before the next POSTGW. That must be the length!And finally: detecting data corruption. In the GoodWe Modbus document linked above, there is a description of the CRC used to detect data corruption. It is a standard Modbus CRC-16 (two bytes), designed to effectively detect bitflips. Again, assuming I am a software developer who is familiar with Modbus but who has been tasked with sending data over the internet (and didn’t really care much for security), why wouldn’t I use an algorithm or library I am already familiar with?A quick check proves that running the data between the length field and the last two bytes through the Modbus CRC algorithm returns a value matching the last two bytes of the frame.An annotated frame, with length in red, device type and serial in green, timestamp in blue and purple, and encrypted blob in yellow.My best guess for the length field being three bytes shy of the length of data rather than two is that it is just a sloppy implementation with an off-by-one error, which matches my profile of the developers.Another data point to paint a picture of the engineering quality: the CRC of frames from the client are encoded in big-endian byte order (same as all the other integers encoded in the protocol). However the server sends the CRC in little-endian byte order. Why? Maybe the server is x86 and the developer forgot to call htons()?Now I just had the encrypted blob to decipher.### Encryption schemeI guessed that they must be using AES in CBC mode because:The identical section of ciphertext in consecutive frames is a classic CBC failure mode when reusing IVs.This is an old mode and widely supported in libraries, making it easy to use.Since they don’t care about security they are hardly likely to be using AEAD modes.When implementing a scheme using CBC, it is critically important that initialization vectors are not reused. Otherwise identical plaintext will give you identical ciphertext. Metrics from a smart meter are highly likely to be the same minute-to-minute, which is probably why we see identical sections of ciphertext in successive frames with the same IV!A common practice is to prefix the IV to the ciphertext. This is known as an explicit initialization vector, and it doesn’t need to be secret - just randomly generated in a cryptographically secure manner. However what if you are running on a microcontroller without a NRBG? Or maybe you just don’t know or care about CBC footguns? Then you have to use some other “unique-ish” value!The device is designed to only send metrics every minute. Therefore the developers may have assumed that time based IVs will be unique enough, without taking into account buffering on network outage.### Power “glitching”The final and most difficult question: what is the encryption key?The first thing I checked was what happened when the device rebooted: was there any key exchange or handshake? Fortunately the web UI has a reboot button, so it was easy to confirm that no, there is no key exchange on startup.So because we are assuming AES (symmetric encryption), that probably means&mldr; fixed keys!### Extracting the keySince the keys are fixed, they are likely hard-coded. AES can use 16, 24, or 32 byte keys, so I started by assuming a 16-byte key. I suspected they’d use some string like GoodWeSolarPower, and store it as a static string or byte array. I poked around in the firmware a bit with Ghidra, but didn’t find any promising strings.But in any case, there was another problem. One of the properties of AES-CBC is that you can plug any IV and secret key into it and it will “decrypt”. But unless the IV and key are correct, the output will be garbage. So how to know if I manage to correctly guess the IV and key?At this point I made another educated guess. The frame header and length field use ASCII characters and leading null bytes respectively. Assuming the plaintext metric data is similarly structured, it will have relatively low Shannon entropy. Another property of AES is that it is a secure block cipher. That is, the ciphertext should be indistinguishable from random bytes. Therefore, using the incorrect key or IV should result in high entropy garbage.Assuming the timestamp in the frame (which is null-padded to 16 bytes) is the IV, I wrote a really dumb tool to:step through the firmware one byte at a time, taking the next 16 bytes as a key.“decrypt” the encrypted blob using that key, and the timestamp prefix as the IV.calculate the entropy of the decrypted blob. If it is below a given threshold, print the plaintext and key.Fortunately although this was a very naïve brute force algorithm, one great thing about 2024 is that computers are fast.Running this tool over the firmware dump from my device only took a few seconds and yielded&mldr; nothing. Huh.Fortunately my previous googling efforts had discovered a public Google drive with relatively recent updates (early 2023) containing firmware for (all?) GoodWe inverters4. Running the tool over a firmware image for another device yielded&mldr; nothing again!Finally on the third attempt, I got a single hit:Of course! The key was just all bits set. Why not!?I doubt this was actually hard-coded as a key anywhere in the binary blob. I think I just got lucky that this firmware had a run of 0xff bytes.## Extracting meaning from the plaintextFinally I had a plaintext with obvious structure, but nothing mapping fields to metrics values. However I did have an oracle: the SEMS Portal API! I was able to dump metric values for my smart meter using curl on the SEMS Portal API, and observe the metrics changing every time a packet was sent from the smart meter.Then by eyeballing the packets and the values (assuming standard two’s complement signed integer encoding) it was relatively straightforward, though a little time consuming, to map offsets to metrics values.This wiring diagram was helpful to understand that there were really only two CT sensors and every other metric was calculated from those two numbers:## Prometheus & GrafanaI like Prometheus for gathering metrics. So I built an exporter based on the research described above. It works by conducting a man-in-the-middle attack on the protocol. Pointing the HK1000 at the IP address of the exporter when it requests tcp.goodwe-power.com will cause the HK1000 to connect to the exporter instead of the GoodWe cloud. Then the exporter will sniff the metrics out of the frames and forward them to the real tcp.goodwe-power.com.The nice thing about this design is that you still get metrics in SEMS Portal. These metrics are visible to your installer, so if you have problems it is easy for them to troubleshoot. I also added support for my inverter, which uses approximately the same protocol.In addition, the Prometheus exporter will reject any packets from the server that it doesn’t understand. So hopefully unsolicited firmware updates will be blocked.Finally, I created a dashboard in Grafana:## ConclusionsThis exercise has reinforced my prejudice that IoT devices are horribly insecure. In the case of GoodWe, where they even have authentication, they use fixed default passwords such as admin, and leave Telnet debug interfaces listening on their production devices.Although the metrics protocol and encryption scheme are insecure, I didn’t find anything that could really be described as a security vulnerability as opposed to a design decision.Only the metrics were encrypted in the data sent to SEMS Portal over the internet. Not the model or serial number. So even with (bad) encryption, they have left the most sensitive data unprotected. I guess they are just obfuscating the metrics? Or maybe the boss asked for encryption? “He said encryption! Give him encryption!”.Conversely the hardware seems pretty good, functions well, and looks great!I spent months tinkering on this on-and-off. I was motivated by equal parts indignant anger at not being able to scrape metrics locally from a device so intimately integrated into my house and running on my network, and morbid curiosity about what security flaw I was going to uncover next. Now I understand what jwz means when he talks about writing software in self-defence.## How to secure GoodWe devicesFinally, here’s my advice if you have a GoodWe device:Whatever else you do, keep these things off the public internet! Preferably in your private, firewalled IoT VLAN.There doesn’t seem to be a simple way to disable the Solar-Wifixxxx WLAN after the devices are set up. So set a strong password, because the default is admin. You can do this via the web UI.The web server is listening on all interfaces, so it is accessible from your VLAN. Change the password for the web UI from admin to something a bit more secure. Note: not all devices have this option easily accessible. For example the HK1000 only allows changing this password via the Telnet interface.For the paranoid:My prometheus exporter drops incoming packets it doesn’t recognize. Only metrics will flow, not e.g. firmware updates (I hope - I haven’t seen any come through yet). So in theory it will block remote administration of the devices.## Miscellaneous notesThis section contains a few notes I made that didn’t fit into the narrative of the blog post, but are interesting nonetheless.### GoodWe’s Cyber Security claimsGoodWe has a page on Cyber Security on their website with a nice infographic, basically confirming everything I have just discovered:In order to prevent cyber-attacks on photovoltaic systems to the greatest extent, inverter manufacturers usually deploy various security policies on the equipment side and server side. Taking GoodWe as an example, to ensure the security of data transmission between the inverter and the server, we use the transmission protocols of CRC+AES and TLS respectively for communication with servers with different functions.This is a great demonstration of how you can use secure cryptographic primitives such as AES-CBC, and still come up with an insecure encryption scheme.### Hi-Flying and XinwuThe GoodWe devices seem to use an IoT platform common to several Chinese manufacturers, for example Solarman. It has a unique discovery protocol where you broadcast a special packet to a given port, and the device replies with its IP, MAC, and SSID (which includes the device serial).For example (in separate terminals):nc -u -l -p 50123 192.168.18.17,907856FECDAB,Solar-WiFi12345678 echo -n WIFIKIT-214028-READnc -u -b -p 50123 192.168.18.255 48899 According to the config dumped from the Telnet command prompt, the chip in the HK1000 is the HF-A21, from a company called Hi-Flying, based in Shanghai. You can build your IoT device on top of this platform by loading your own application onto it, while the included OS takes care of the hardware, network etc.An interesting part of the discovery protocol is the string 214028. Where does this come from? Well approximately 150km from the Hi-Flying office is Xinwu district, Wuxi. According to Wikipedia:In 2013, the output value of Internet of Things (IoT) core industry in Wuxi New District exceeded 70 billion yuan, accounting for 38.4 percent of the output value of the whole high-tech industry in the district. Wuxi New District has formed a cloud computing industrial distribution, featuring hardware, platform and application.Xinwu’s postcode is 214028.### Remote administrationAccording to market researchers, GoodWe was the fifth largest supplier of solar inverters worldwide in 2022. GoodWe have full remote administration capability on the devices, including the capability to push firmware updates. This seems like a lot of power for any company, let alone a company headquartered in a totalitarian dictatorship, to have over national power grids.### Batman modeTo validate the MITM functionality For fun, I implemented Batman mode in the prometheus exporter. In this mode, rather than forwarding metrics to the SEMS Portal, the exporter replaces them with the batman equation.### DNS updatesThe GoodWe devices send their metrics to tcp.goodwe-power.com:20001. When I first started investigating the protocol in mid 2023, this resolved to an IP address in Alibaba Cloud. However late last year this was updated to now resolve to a pair of ELBs in AWS. In both Alibaba Cloud and in AWS they seem to be doing DNS load balancing, because while the SecurityTrails screenshots above show US IPs, from here in Australia both those domains resolved to IPs in Alibaba Cloud China (previously), and now to AWS Sydney.Here are the commands I figured out:? display possible commands.?display command help. enter subcommand menu or execute command.up go to parent command menu.&#160;&#8617;&#xfe0e;This line is from my bash history, but I advise to start the length at a low value and slowly increase it. From what I remember, at some point reading memory will cause the device to crash and reboot.&#160;&#8617;&#xfe0e;Yes, I know this isn’t what is generally referred to as “glitching” in reverse engineering. But it is somewhat analogous.&#160;&#8617;&#xfe0e;I’m linking the drive here, but of course it may be shut down at some point, or the firmware deleted. Hopefully someone takes a backup.&#160;&#8617;&#xfe0e;tags : hack goodwe solar networkall content CC BY-SA, built with Hugo",
    "commentLink": "https://news.ycombinator.com/item?id=39371831",
    "commentBody": "Reverse-engineering an encrypted IoT protocol (smlx.dev)204 points by smlx 17 hours agohidepastfavorite39 comments denysvitali 16 hours agoNext time you find yourself reverse engineering a weird protocol - use ImHex. You can literally define patterns (in a C++ / Rust -like language) so that your binary file gets highlighted and processed. I can't recommend it enough - it's perfect for the job and it's free and Open Source. https://imhex.werwolv.net/ reply turtledragonfly 15 hours agoparentJust piggybacking here to mention a variety of other \"interpret structured binary data\" tools. Apparently I collect links to these (: * fq - like jq for binary data: https://github.com/wader/fq * Kaitai Struct - https://kaitai.io/ ** visualizer, for the above: https://github.com/kaitai-io/kaitai_struct_visualizer/ * HexFiend - a hex editor, but with \"binary templates\" feature : https://github.com/HexFiend/HexFiend ** binary templates, for the above: https://github.com/HexFiend/HexFiend/blob/master/templates/T... * binspector - https://github.com/binspector/binspector * binary-parsing - a collection of links to similar such tools : https://github.com/dloss/binary-parsing * unblob - https://github.com/onekey-sec/unblob * ImHex, which you mention reply wwader 33 minutes agorootparentHey! fq author here. I have a bunch of related tools in the readme https://github.com/wader/fq?tab=readme-ov-file#tools two suggestions: gnu poke and wireshark (can decode lots of more things then just network protocols) reply moyix 9 hours agorootparentprevNot free, but I have used 010 Editor for years and it's excellent. reply denysvitali 3 hours agorootparentFrom experience, this is even better than 010Editor , and free reply declaredapple 13 hours agorootparentprevis binwalk still used these days? reply sitzkrieg 10 hours agorootparentbinwalk or even strings as your first steps for shaking down a binary is often still very useful before pulling out the big guns reply denysvitali 11 hours agorootparentprevFrom my experience, yes, it's still quite useful to find embedded formats reply mrmuagi 12 hours agoparentprevDo you know about any protocol deciphering tool? I'm trying to reverse engineer a kinda simple tcp data stream, and the values are tag-length-value for the most part, and I made a simple mitm proxy that prints known tags and their data values (that I was able to decipher) live, but I am doing the deciphering of known and unknown tags manually, but I was wondering if there is some way to automate this? I basically would be interested in automatic seen tag tracking, replaying select tags many times to see if they are idempotent, replaying and modifying bytes on a select tag, omitting a select tag and seeing how the client responds. I guess I could find the socket receive function in the binary and see if the tag values are in a switch or something too but like the original article, it's also new territory for me to read that. I am just about to expand my mitm proxy with more code to inject/filter packets. reply denysvitali 11 hours agorootparentHave you tried Wireshark? It does support Lua templates, although for the initial analysis I would still suggested ImHex reply raggles 16 hours agoparentprevJust coming here to say this. I was reversing a license file for some software so I could play with it yesterday, and I could implement the encryption/decryption code direct in the data processor of imhex, such a time saver. reply smlx 16 hours agoparentprevI have never heard of ImHex before. Thanks, I'll take a look! reply devwastaken 5 hours agoparentprevAre there tools that help in identifying structures? For example reverse engineering binary file formats like for bnd4, a save game format. reply username135 12 hours agoparentprevThanks! reply gangstead 13 hours agoprevHe mentioned having a private, firewalled VLAN. Is there anywhere to get more info or example setups for the beginner homelabber? I've got Unifi gear, I poke around the interface. I realize I can make new VLANs, but what makes them isolated/private? Also I see his complaints about half assed security but I actually am kind of relieved. If the security was implemented well we wouldn't be able to make our own man-in-the-middle prometheus exporters! reply thfuran 12 hours agoparentA VLAN is private/isolated to the extent that you don't route it to other networks. You could just block traffic between that vlan and the wan, or even potentially between it and any other vlans on your lan. reply m463 9 hours agoparentprevI use openwrt I will say learning how to do it is a pain, but once I got an internal vlan in place, my life got significantly better. You just want a small internal network that can't get out, or can get out through a proxy. I set up: - ipv4 only - cut my configuration in half - private dns server for the vlan - only resolve internal addresses - dhcp - private time server - privoxy proxy for controlled access to a whitelist of outside reply xyx0826 2 hours agoprev> This exercise has reinforced my prejudice that IoT devices are horribly insecure. Generally I agree with this assessment for home IoT devices, but I’m curious does this hold true for industrial or transportation? Can someone point me to blogs or studies on Chinese EV security? reply floating-io 15 hours agoprevWhile the reverse engineering was interesting to read about, I found the Batman Equation far more amusing! :) reply pbaam 15 hours agoprev> Sniffing the traffic from the device showed that it was connecting out to tcp.goodwe-power.com:200001 Is 200001 the right port number? Very good read anyways. reply Moru 2 hours agoparentSeems it's corrected now, one zero less :-) reply mianos 7 hours agoparentprevAs ports are 16 bit ints, I assume not. reply kwar13 1 hour agoprevAny kind soul want to teach me how echo -e 'adminadminspi rd 0 2097152'nc 192.168.18.17 23tee ~/download/hk1000.spi2.img downloads the firmware? reply npteljes 33 minutes agoparentThe device appears to support the Serial Peripheral Interface protocol, which Scott discovered (and others before him too: https://mlug-au.org/lib/exe/fetch.php?media=20210726-goodwe....). He did this by poking around with nmap for open ports, discovering that the telnet port is open, and then trying to talk to the device with telnet. \"spi rd\" are commands that can be used to dump some data from the device, as you can read in my linked presentation. And the one-liner Scott has in the blog just automates the following process: 1. logging in with admin/admin on the device with telnet 2. issuing the telnet command \"spi rd 0 2097152\" 3. capturing its output into a file, while also viewing it on the standard output at the same time reply poyu 39 minutes agoparentprevI think `spi rd 0 2097152` is probably something in the telnet prompt that reads values from an SPI flash, the two number seems to be starting and ending range. reply kwar13 2 hours agoprev+1 to having an IoT VLAN. Absolutely required to segregate the traffic. reply farseer 3 hours agoprevHow would one go about reversing and identifying a wireless protocol? reply Fietsband 13 hours agoprevThis reads similar to an intercom I am still in the process of trying to write a client for: https://grdw.nl/2023/01/28/my-intercom-part-1.html . Seeing nmap, wireshark, poor security. It definitely feels the same. reply iefbr14 15 hours agoprevSo if I understand this correctly it is now possible to mess up other peoples graphs by just sending malicious packages to the server? reply sakebomb 13 hours agoprevYou should check out Recessim: https://recessim.com/ I think you would like the community. reply digitalblade 15 hours agoprevAwesome reading, well written and very clear. Thank your for your post. reply bcaxis 11 hours agoprevWell... MY IoT devices don't have garbage security. reply nagisa 10 hours agoparentI only buy IoT devices with security so garbage that I can make them do my bidding and not somebody else's. Hopefully a market for these devices remains thriving. It would suck if it wasn't possible to flash the firmware of a robot vacuum cleaner (et al) so that it becomes a LAN device. reply heywire 16 hours agoprevFantastic write up! Enjoyable read, and gave me some pointers. reply gessha 16 hours agoprevThis was a joy to read. Thank you for posting. reply andsmedeiros 15 hours agoprevThis was very informative, thanks! reply demondemidi 8 hours agoprev [–] MIPS? Wow. Would not have expected that! I guess they went as low budget as possible. That key tho. /facepalm/ They REALLY don't care about security. Seriously, at least get PSA level 1 FFS and use TLS. But I doubt a cheap-ass MIPS has the horsepower for a handshake. reply Moru 3 hours agoparentIn the 90-ies I was told to figure out what was wrong with the big radiocontrolled port at a local industry. I don't remember what was wrong with it but after digging in the manual and the equipment I realized the whole factory was protected by a four bit code set with dip-switches on a circuit board. I guess it was supposed to be used to select what port to open with the remote but was all that was stopping anyone to open the door at all. reply xyx0826 2 hours agoparentprev [–] I know some MediaTek WLAN chips come with MIPS cores clocked at more or less 1 Ghz, like the MT7621. TLS should be trivial; I believe the thing that matters is how much time/money/design the company is willing to spend on security. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their experience of reverse-engineering an encrypted IoT protocol used by GoodWe smart meters and solar inverters.",
      "They used their research to build a Prometheus exporter, showcasing their findings.",
      "The author emphasizes the significance of securing GoodWe devices by keeping them offline and using strong passwords to prevent unauthorized access."
    ],
    "commentSummary": [
      "The post explores the process of reverse-engineering an encrypted IoT protocol, offering insights into this challenging task.",
      "Tools like ImHex, fq, Kaitai Struct, HexFiend, binspector, and others are recommended for reverse engineering IoT protocols.",
      "The post also highlights the insecurity of IoT devices, the use of VLANs for isolation, and the potential for manipulating graphs through malicious packets, providing valuable resources for exploring IoT protocols."
    ],
    "points": 204,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1707928462
  },
  {
    "id": 39377055,
    "title": "Advancements in Technology and Mathematics: From Calculations to AI-Generated Proofs",
    "originLink": "https://www.youtube.com/watch?v=AayZuuDDKP0",
    "originBody": "hello hello hello good afternoon I'm Briana C I'm president of the AMS and it's my pleasure to welcome you to the colloquium lectures these are the oldest lectures at the meetings of the AMS the first meeting was held in 1895 the second in 1896 where the first colloquium lectures actually took place and those were at Northwestern University and since that's my home institution I can't help but mention that the list of speakers is a veritable who's who in mathematics including burkoff Morse fyon tari Chon Milner smil nurg Tate and the list of people I've left off is well equally prestigious to those that I included and amongst them was also our speakers today's um adviser Stein Ilia Stein so with that I'll turn to the introduction of Terry tow Terry may be somebody who doesn't need introduction after all he's been in a crossroad puzzle as a clue in the New York Times Crosser puzzle I don't want to um use up all his time by listing the awards he's won but I could um I'll give you just a short list of the highlights of the fields medal in 2006 MacArthur Fellowship he's a fellow of the Royal Society the Australian Academy of Sciences the American Academy of Arts and Science and a member of the National Academy of Science and of course he's a fellow of the AMS most important of those distinctions um he has over 350 Publications meaning he hasn't slept in a few years um and this includes numerous highly influential texts and he has more than 50 collaborators and maybe that's when I counted last week so I don't know maybe this week think there's more he's also one of the broadest researchers in mathematics covering interests from Pure to applied um and I won't list all of the all of the subjects but it's this not only research he also serves the profession in numerous ways and starting in 2021 took on a very substantial role he was appointed by President Biden as a member of the president's Council of advisers on science and technology so he's Force he's mentored over 20 PhD students um and I could go on and on so I've known Terry for a while uh since about 2004 or five when we first met um but one of my Fondest Memories of him was at a party um that I was a co-host for in 2008 it was the election night and Terry was sitting in the corner November 2008 on his computer on some website that was giving uh election returns announcing the States before the TV was it was really impressive and uh it's just one of my f Fondest Memories anyway I won't keep you any long it's any longer it's my pleasure to introduce [Applause] Terry all right thank you very much Brina I'm uh very happy to be here at this JMM to get this lecture it's always nice to be up in San Francisco um so are we talking about um what I think is really exciting development um in mathematics it's going to shape our future um which is really the uh um the development over the last few years of lots of Technologies to have to to make uh machines and computers um um help us do math um much more effectively um now this some to some ense this is not new um we haveed used both machines and computers and I I use the terms slightly differently um we've used both actually for centuries really um you know nowadays computers and machines when we talk machine assisted mathematics and computer assisted mathematics they're sort of synonymous um initially they weren't because computers used to be human um and then they were mechanical and then finally electronic um so for example you know maybe one of the earliest use of computers uh was to build tables you know so for example um the log tables of napia and so forth were basically built by lots and lots of human computers um and those are earliest examples of somehow computer assisted mathematics um and tables are still really important today um I mean not so much the log tables anymore um but you know a lot of what we call experimental mathematics uh is based on creating lots and lots of large tables of of interesting things um especially in number Theory um so for example famously the genre and gaus um built tables of prime numbers um and and they use that to conjecture the prim number theorem which is of course now a theorem um and similarly in the 60s B swen D um um created lots and lots of big tables of the deers and their ranks and so forth and this was a a key input in for formalizing the famous BSD conjecture and maybe the biggest table of all in mathematics is the ois online encyclopedia mathal sequences um so it's a datase of hundreds of thousands of of integer sequences and every day I think mathematicians discover unexpected connections um or maybe ReDiscover an existing connection you know I myself used o ois you know if if there's a if there's a a quantity which I know there's a formula for but I can't remember it you know I can just compute the first five elements put in the Oris I can usually find it um and most recently uh people are starting to use large databases of of of mathematical objects as training data for neural networks and so I'll give you an example of that later so that's one very um storied and and and antique way of using um uh computers in mathematics um the other big use of course is in numerics or scientific Computing uh and that's also um a very old subject um arguably the first big scientific computation was in the 20s uh when Len uh was asked to to model the fluid flow for the construction of a new Dyke in the in the Netherlands um and so she assembled a team of human computers basically to model what would happen to uh um to the water flow and so forth uh it's notable for the introduction he's almost the first place where where floating Point arithmetic was was introduced and of course we use scientific Computing nowadays to to model pdes to solve large system of equations um and of course we uh we use them for computer algebra packages you know magma Maple sage and so forth um yeah you want to to do a big um you know numerical integration or or or or algebraic you know computer glob a basis whatever um you know we routinely do this now all across mathematics um of course the numerics are sometimes inaccurate you know there are roundoff errors um and and other possible um um problems but there are ways to make the uh the computation more rigorous for example instead of floating Point arithmetic if you use interval arithmetic um if you represent numbers by error ranges um a lower and upper bound um and and you keep those bounds like Ral numbers like finite position like infinite position uh then you can um uh then you can avoid errors at least in in principle uh at the cost maybe of um of making the runtime longer um more recently there are more advanced um um algebra packages than just sort of the standard things you get in um in Sage or or Mathematica um the these things called sat solvers satisfiability solvers or satisfy satisfi modular Theory solvers smt solvers um so what they so a SAT solver gives is you feeded a host statement um a bunch of of propositions P1 P2 P3 and so forth and you say that P1 and P2 or P3 is true P3 and P4 and not P5 one of them is true so forth and it will try to to see if there's a solution or not um and many problems can be phrased as a SAT problem so if you have a general purpose sat Sil uh you can potentially uh just feed it into into such a um um such a program and solve the problem for you uh then there are these more sophisticated variant smt solvers where you also feed uh laws of algebra or you know so you have some some variables and you um uh you assume that there certain laws of the the these these variables obey certain laws and you ask can you deduce a new law from from the laws you already have um so those are um potenti is very powerful and unfortunately sat solvability is an NP complete problem um and uh you know once you get hundreds and hundreds of these of these propositions it becomes very hard to actually solve these uh um these problems but still um they are very useful uh here's a typical application of a sa silver um so a few years ago um uh there was this um famous problem in koric called the Boolean um P Pythagorean triples problem and so the problem is this you you take the natural numbers and you color them into two two color classes red and red and blue and you ask uh is it always the case that one of these um color classes contains a Pythagorean triple three numbers a b and c such as a squ plus b squ c squ um and it turns out to be uh we don't have like a human proof of the statement but we we know it's true now because of a SAT Sol um so there was a massive computation that says that um you can if you only go up to 7,8 824 then you can't do this there is a way to partition the numbers from 1 to 7824 into two classes neither of which contain a pth Pythagorean triple but once you go up to 7825 um no matter how you do it you must always get um one of the two color classes must have a path pathan trouble um in principle this is a finite computation because there's only two to seven two two five different ways to to compute um uh different partitions and so you can just check each one but that is computationally unfeasible um but with a sat over uh you can rephrase this problem as as a three satisfiability problem um and uh uh it it's it's not just a matter of running the solver you have to optimize it and so forth but it is possible to actually solve this problem um and it gives you a certificate it gives you a proof um and actually uh this is uh at the time it was actually the the world's longest proof um the the proof certificate uh first of all it took four CPU years to generate and it's a 200 200 terabyte proof although although it is compressible um I think it is still the second largest proof ever generated okay so that's uh but this I still consider so a more classical way of using using U computers um but what I think is is um exciting is that there are a lot of new ways um that we can use computers um to um to do mathematics of course there's s of the boring ways you know we use computers to do emails and and write latch and so forth like gu I don't mean that um but um there are S three new new modalities um which um indiv usually they still have somewhat Niche applications um but what what I find really interesting is that they can potentially be combined together um and the combination of them it could be something general purpose that actually a lot of us could use so the three sort of uh new things um so the first is s of machine learning algorithms where you have a problem um and if you have a lot of data for that problem you can set some sort of specialized newon Network to train it on the data and it can generate counter examples for you try to generate connections um and and so people are beginning to use this in all kinds of fields mathematics I'll give you some examples later um so that's um that's one um development um maybe the most high-profile development is large language models like chat GPT um these are very general purpose models that can understand natural language um to date uh they have not been directly Ed for so much mathematics I'm sure many of you have tried talking to GPT asking you to solve your favorite favorite math problem and it will give you some sort of plausible looking nonsense um General um but um when used correctly um I think they do offer a lot of potential I mean I um I have I have found occasionally that these models can be useful for suggesting proof techniques that I I wasn't initially um um um thinking of or to suggest related topics or literature in um um they're actually most useful for sort of uh secondary tasks okay so for actually doing math research they still have they still haven't really proved themselves but for doing things like like like writing code or or or organizing biblography you know like a lot of the other um more routine tasks that we do actually these LMS are very useful um but the third um um new technology which uh was been around for for two decades but has only Now sort of becoming ready for prime time um are these formal proof assistants uh which are languages designed to verify um uh or to verify um many of them design to verify Electronics but they can also ver ify mathematical proofs um um and crucially they can also verify the output of large language models which they can they can complement they can fix the the biggest defect in in principle of of the llms um and um they allow new types of ways to do mathematics um in particular they can allow really large scale collaborations which we really can't do without these formal proof assistance um and they can also generate data uh which can be used for the the other two uh uh uh the other two technologies so I will talk about each of these three things separately um but um what but and they haven't there's beginning to be experiments to combine them together um but they're still kind of prototypes right now but um I think the paradig of using all of them and also combining with um the computer algebra systems and the sap solvers into one integrated package uh it could really be quite um a powerful methodical assistant okay so let's talk I think I my first slide begin with proof assistance um so um proof assist the um computer assistant proofs are not new um famously the full color theorem in 1976 was was proven partly by computer um although at the time it was um by modern standards we would not call it a fully formalized um proof the 1976 proof um the proof uh was this long document uh with lots and lots of of of sub claims which uh were ver like a lot of them were verified by by by by hand and a lot of them were verified by both electronic computers and human computers and I think one of the author's daughters actually had to go through 500 graphs and check they all had this discharging property um and actually it had a lot of mistakes too um so there there's a lot of minor errors um in in the in the proof they're all correctable um but it was it it it really U will not meet the standards today of of a of of a proof of a computer verified proof um the first proof okay in so it took 30 20 years um for an alternative proof the Four Color theorem to be verified and this proof uh is closer to being completely formal so it it it's about 10 15 pages of human readable argument and then it reduces to this very specific computation which you can run you anyone can just run um um a computer program in whatever language they like to verify it um so it was a computer verifiable proof um but it still wasn't a formal proof in like it wasn't written in a formal proof language which was designed to only output correct um correct proofs um and that had to wait until uh the early 2000s um when w and G here actually formalized the entire for color theorem in one of the early proof assistant languages in this case um so you know I mean now we know with 100% certainty that the Four Color Fus is correct uh well modulo you know um you know trusting the compiler of C okay but um all right um another famous um machine assist of proof well actually initially human proof but eventually computer um verified was the proof of the cap conjecture so uh the cap conjecture is a statement about how efficient you can pack unit spheres in the plane um and so there's a natural way to to to stack unit spheres and is the way that you see oranges stacked in in in in the grocery store uh it's called the the hexagonal close packing and there's also a dual packing with the same density called the cubic close packing um and they have a certain density Pi 32 and this was conjectured to be the densest packing um so this is an annoyingly hard statement to prove um so um you know it's it's an optimization problem in infinitely many variables you know so there there's each each sphere has a different location and so and there's infinite number of spheres so um you know you're trying to to prove an inequality involving an infinite number of uh of variables involving a solving infinite number of constraints um so it doesn't immediately lend itself to commuter verification um but even in the 50s um it was realized that possibly this could be done by some sort of Brute Force computation um and so Toth proposed the following Paradigm um so every time you're SE packing um it comes with what's called aoid decomposition so uh every sphere comes with a vono cell which is this polytope of all the points that are closer to the center of of that of that sphere than to all the other spheres and this partitions um space into all these little polyhedra these volary cells um and um there are various relationships between the volumes of these different cells um you know there's only so many spheres that you can pack next to one one reference sphere and this creates with all these kind of constraints um and so the Hope was that if you could gather enough inequalities between um adjacent vono cells um the volumes of adjacent vono cells maybe um every such system inequalities in principle gives you um an upper bound on the density of of a SE packing um and in principle if if you get enough of of these inequalities maybe you you could actually get the optimal bound of of the2 um so people tried um this approach for many many years and including some uh false uh attempts uh but uh this they were not able to actually make this approach work um but uh Thomas hailes and then later with a collaborator was able to adapt this approach to make it work in a series of papers from 9498 um but they had to modify the strategy quite a lot so instead of of using uh the vono decomposition there was a more complicated decomposition that was used and instead of using volume they had to Define this this new score function attached to each polyhedron but basically the the strategy was the same um and he was able to prove lots and lots of linear inequalities between the scores of adjacent polyedra uh and then just using linear programming was able to then get a bound and uh with the right choice of score and the right choice of partition it was uh it was the optimal bound um it's a very flexible method um because you lots of ways you can do the partition and lots of ways that you can do the score but it it was actually the problem that it was too flexible so here's a quote from from hailes says that Samuel Ferguson who was H's collaborator and I realized every time we encounter difficulty solving the minimization problem we could adjust a scoring function to SC the difficulty the function became more complicated but with each change we could cut months or years from our work this this incessant fiddling was unpopular with with my colleagues every time I presented my work in progress as a the conference I was using I was minimizing a different function even worse the function was mly incompatible what what it in earlier papers and this required going back and patching the earlier papers um so the proof was uh was a mess basically um they did eventually finish it in 98 and they able to derive the capital conjecture from a linear programming computation from a very complic optimization program um initially it was done by hand but um with the increased complexity there was no choice but to make it more more computer assisted um so when the proof was announced uh the proof had uh yeah it was a combination of of 250 pages of notes and lots and lots of gigabytes of programs and data uh and it it was famously hard to referee uh it took four years for anal to referee the paper with a panel of 12 referees and even then the panel only 99% certain of the correctness of the proof and they couldn't certain ify the corrections the the um the the calculations because I mean um in principle like it was all doable but like you know the ref have to S Implement all these different computer calculations themselves uh but it was eventually accepted um but clearly there was this big asterisk there's a lot of controversy about whether this was really a valid proof and so this this was one of the the first really high-profile uses of um formal proof assistance because this was a result in which there was serious doubt about the correctness um so they created uh so har in 2003 uh initiated a project to write down this massive proof in a completely formalized way so that a standard proof assistant could verify it um he estimated it will take 20 years to to make this work um it uh and so with he had he gathered 21 collaborators it actually only took 11 years um but uh yeah eventually what they did was that they they first created a blueprint you know so a human readable version of the proof breaking things up into very very small steps and then they formalized each step bit by bit um and it was it was finally done and then there was a yeah so they and they they published a paper about the formalization and that only appear in 2017 so this was sort of the state-ofthe-art of formalization you know as of say 20 years ago you know like it was possible to formalize Big complicated results but it took enormous amounts of effort um you know not something which uh you would uh do routinely um there was a more recent effort in a similar Spirit uh by Peter schulzer he called it the liquid tensor experiment so uh schulzer introduced this this theory of condensed mathematics which is uh all right this is really far from my own area of expertise but um basically there are certain problems with uh uh so certain types of mathematics you want to work in various categories like categories of topological obedient groups and and topological Vector spaces and uh there's a problem that they're not obedient categories but they don't they don't have a good notion of Kernel CERN or things don't work out properly um so he proposed replacing all L of these standard categories uh with a more fancy version called a condensed um condensed category uh which has better category theoretic properties um and so the hope then that you can use a lot more High powerered algebra to attack uh to to handle um things of topological structure or analytical structure like function spaces for example B spaces um but in order for the theory to work there's a certain Vanishing theorem which uh I've written there oops uh but I cannot explain to you oops uh okay so there's a certain category uh um groups and there's certain X group involving P bino spaces that has to vanish um and U this Vanishing theorem is needed in order for all of the rest of the theory to actually be useful um if you want to apply to to to fun to functional analysis in particular um and so schulzer what a blog post about this is said you know I spent much of 2019 obsessed with the proof this theorem almost going getting crazy over it in the end we were able to get an argument pin down on paper but but I think no one else has ever dared to look at the details of this and still I still have some lingering doubts um with this hope um with this theorem the the the hope that the condensed formulas can can be fruitfully applied to functionalis stands or fals being 99% sure is not enough because this the is of the most um most fundamental um importance um he says I think this may be most my most important the on the date which is a really big claim actually uh better be sure it's correct so this was another case where um there was a great desire to to formalize the proof um so he asked publicly on the internet for help um to formalize this in a modern proof ofis language C lean um um and so uh again about 20 people I think um joined this project to help out um and it it uh so so lean is based on uh um it has this philosophy where um it has this single huge library of mathematical theorems like the F FAL calculus or the classification fin in groups like like a lot of the basic theorems of of mathematics are already formalized in this big library and the idea is to just keep building on this library and adding to it with additional projects um but um one of the the problems uh that shorts are face was that a lot of the uh tools that basic tools that you needed like homological algebra Chief Theory and topos Theory weren't actually in the library yet so actually part of what they had to do was actually set up the foundations of of that theory and formalize it in the library first but it basically was done in about two years uh in in one year they formalized a key sub theorem um and then uh and then the whole thing was was formalized about a year afterwards um it um it did have some in addition to sort of making uh reassuring Peter that it was it was everything was was correct uh there was some some um uh other minor benefits so first of all there were actually a few minor errors in the proof that were discovered in the formalization progress um but but uh uh but they could fixed uh also some small simplifications uh there was one big simplification actually um so they uh um the original proof used something very complicated which I also don't want stand called the Breen delene resolution uh but in the course of formalizing it you know it was too hard to actually formalize this this Theory but they found that there was a weaker version of this Theory which was good enough to formalize this application but this was actually a major Discovery because this weaker Theory could also potentially attack some other problems that that the bring to the resolution is is is not well suited for and now the math library is is much much better in in uh it has a lot of of uh support for for homological Al she Theory and and lots of other things which which helped other U formalization projects become easier um I got interested in um this formalization a few months ago um so hang on um I should say um like with the Kepler experiment so the um you don't just directly transfer um a a paper from you know the archive or something into um inter lean um what we found is is that um it really helps to create first an intermediate document so halfway between a human readable proof and um a formal proof uh which we call a blueprint um so it it it looks like a human proof and is written in a version of latch um but like each each step in the proof is linked to a Lemma in lean um and so it's very tightly integrated um and it has a very nice um uh there's a very nice feature uh it can create a dependency graphs which I'll show you an example L you can you can see which parts of the proof have been formalized which ones are not and what depends on what um and it actually it it uh it gives a lot of structure to the process of writing a paper which you know right now we do by hand without sort of much uh much assistance really um yeah Scher said that the process of writing the blueprint really helped him understand the proof a lot better um um and actually people have been also going the other way um there's also software that takes formal proofs which are written in something that looks like computer code and turns them back into human readable proofs um here is um a prototype software so there's a there's a theorem and topology um okay you I think it's a if a function is continuous on a dense set and there's there's some extra extra properties then it's it continuous extends to a continuous function globally um and the proof is written uh was written first in lean but then it was automatically converted into a human proof human readable proof but again where every step you can expand and contract like if there's a step you want you want to explain more you can double click it and it will expand out give all the justification and you can click at any given point in the proof and it will tell you what the hypotheses are currently what you're trying to prove and you can give a lot of structure um I think eventually um textbooks uh this is this maybe a good format say for undergraduate textbooks to have you know um proofs of say you know tricky films and Analysis or something written in in a way where um you know in a not in a static way but where you can you can really um you know drill down all the way down to the to the basic axioms if you wanted to okay um one thing I mean one thing notable about these um formalization projects is that they allow mive collaborations you know so you know in other Sciences people collaborate with 20 people 500 people you know 5,000 people um but in mathematics still we don't really collaborate in um in really large groups you know five is kind of the maximum usually um and part of it is that you know you know if you want to collaborate with 20 people if you don't already know these 20 people and you don't completely trust that they're doing correct mathematics you know it's uh it's it's it's it's very difficult because you have everyone has to check everyone else everyone else's contribution um but with a proof ass system the proof system provides a formal guarantee um and so you can really collaborate with 20 hundreds of people that you've never met before and you don't need to to to to trust them um because they upload code and and um the the the lean compiler verifies yes this actually solves the problem they claimed and then you can accept it or or it doesn't um so I I experienced this myself because I got interested in formalization a few months ago um so I'd recently proven um a combinatorial theorem um with Tim GS Ben green and and Freddy manners um it sold something called the polom F Ria conjecture um the precise conjecture is not important uh talk it's a conject in combinatorics you have a subset of a of a fin Vector space of of small doubling uh and you want to show that it is it is very close to actually being a co- set of a subgroup um this was a segement that uh was um in at Comm talks that was highly sought after um so we had a 30 33-page paper um recently proving this um mostly self-contained fortunately so we thought I thought it was a good candidate for uh for formalization so I asked on an internet Forum specializing lean for help to formalize it and then again like 20 30 people uh joined in and and it actually only took three weeks to formalize so the the time taken to formalize these projects is going down quite a bit um um so in particular um the time take to formalize this this this project was roughly about the same same time it took for us to write the paper in the first place um and by the time we submitted the paper we're able to put as as a as a note that it was actually the proof is actually been formalized um so as I said it it uses this thing called a blueprint which splits up the proof into lots and lots of little pieces um and um and so it creates this this this nice little float this little dependency graph so um this is a picture of the graph at an early stage of the project um so there is no down the bottom called pfr maybe only the people in the front can see it that's the final theorem that we're trying to prove um at the time of of of the screenshot this was white which means that it had not been um proved but not even even being stated properly so so in fact even before you prove the theorem you have to First State it uh and and then you have to make definitions and so forth um blue are things that have been have been defined but not yet proven and green have been things that have been proven um and so um at any state of um any point in time some bubbles are white some bubbles are blue and and some results depend on some others um and so people so the way the uh the formalization proceeded was that different people just grabbed a node that was ready to be formalized because maybe all the all the previous results all the results that it depended on were formalized and they just formalized that one step independent of everybody else um and you didn't really need to coordinate um too much I mean we we we did coordinate um uh on an internet Forum um but um each little node is completely specified there's a very precise definition and a very precise thing to prove and uh we just need the proof and um it we really don't care exactly what the proof is I mean it has to be not massively long but um so yeah so people just picked up individual claims like here's one very simple claim is there's a certain functional called rouer distance D and it had there's a very simple claim that it was non negative uh and this turns out to have a three-line proof assuming some previous um some previous facts that would uh um that were also um on the blueprint and so people just sort of picked up these things separately and and and and over time it it just folded up this is what a typical step in the Pro looks like this is the proof that this rer distance is non negative this is the code and lean it doesn't it it looks kind of a little bit like mathematics um but it it U it is actually if you um once you famili the syntax actually reads it's like reading latch first time you read latch it looks like a whole bunch of mess of symbols but um this um it's actually it's um every line corresponds to a sentence in mathematical English for example the first line if you want to prove that this distance is positive it suffices to prove that twice the distance is positive um so you work with twice the distance because it turns out there's another Lema that bounds twice the distance um so yeah every step actually it corresponds reasonably well to to uh U the way we think about ma mathematical proofs yeah so uh yeah fortunately the proof uh didn't review any major issues there some some types but very very minor picked up um uh and we also um there were some things we need again we needed to to add to the math Library there was a um the math Library we used Shannon entropy and shannan entropy was not in the math library now it is um one thing about about formalization is that it still takes longer to formalize proofs than um than to write them um but and maybe about 10 times longer I would say um which is unfortunate if it was faster if it was faster to formalize to write from proofs formally than um um than to write my hand I think then that will be a Tipping Point and then I think a lot of us would would switch over just because to get the guarantee of correctness um so we're not there yet it is definitely getting a lot faster than it was before um but one thing we we noticed is that actually um while it still takes a long time to write a proof if you want to modify a proof to change some parameters and make it and just and make it a little bit better um that can be done much quicker in the formal setting than in the um than with paper prooof because uh with paper prooof if you change all your little parameters and so forth you likely make all some mistakes and you go back and and it's it's it's a very annoying process but but it's actually much easier to to modify an existing formal proof than to create it one from scratch for example we were able there's a constant 12 exponent that appeared in our proof um a few days afterwards someone um posted a an improvement the argument that improved 12 to 11 and in a few days we able to adapt the formal proof to to do that as well um yeah and because you can collaborate um I think the process is scalable um there's there was just uh just recently Kevin buzzer for example launched fiveyear project the aim is to formalize F last the the proof um and that is quite a a big goal because there are lots and lots of sub portions that have that have had no formal proof at all um so that I think will be quite an ambitious project but I think it's now doable it it wasn't doable five years ago but but now I think it is um okay so that's four more proofs um another um okay um okay okay I might actually have to speed up a little okay so um all right so uh machine learning has uh using new networks has become also uh more more um common place in in different areas of mathematics um I think I'll skip over this one so um one place where is being used is in pde to construct um candidate approximate solutions for various problems so like uh so there's a famous problem in in fluid equations you know do the nav St equations bu in finite time do the oil equations bu in finite time um Navia stes is still Challen in but oil there's been a lot of progress recently um that people have been starting to construct selfsimilar solutions to the oiler equations with some asterisks but the asteris are slowly being removed um and one of the strategies of proof is to First construct an approximate solution approximately self-similar solution that that that that looks like is going to blow up and then use some rigorous peration Theory to um to perur that to an actually um blowing up solution um and machine and machine learning has turned out to be be to be useful to actually generate these approximate Solutions um but I'm going to skip that for lack of time um I'll tell you um my favorite application of um machine learning to to mathematics is a not Theory um so this is a recent work um so knots are a very old subject in mathematics um and there's lots and lots of one of the fundamental things you study in Nots is not invariance so there there's various statistics you can you can um study you can assign to a knot which depends on the topology of the knot or the geometry of the knot um so there something called the signature which is a combinatorial invariant um these famous polins like the Jonas polinomial hly polinomial uh then these things called hyperbolic invariance the complement of a knot is often hyperbolic space um and then you can talk about the and the volume of that space and some other geometric invariant and so there are these massive databases of knots um you can you can generate millions of knots and you can compute all these invariant um but they come from very different areas of mathematics you know so some kns some not inv variants come from comor X some come from operate algebra some come from from from hypo geometry and it's not obvious how they related um but um what these mathematicians did was that they they they trained a new network on this big database of knots and they studied the hyperbolic invariance and the signature which is the comorian invariant and they found that the uh you could train the network to predict the signature from the hyp variant with like 99% accuracy um so they they they used like half the data to train the set and then half the data to test the set to test the new network um and so um what this um told them is that there must be some connection the signature of a knot is must somehow be a function or at least very closely related to a function of hypol variance but um the problem with neon Nets is that they they give you a function a functional relationship at least a conjectural function but it's this massively complicated function it's it's you compos hundreds and hundreds of of of of of nonlinear functions together and it doesn't give you any insight as as to what the relationship is it just shows you that there is a connection but it's possible to do some analysis um so they actually tried a very basic thing which happened to work uh it's what's called aeny analysis so this new network gave them this function basically they fed in 20 hyperbolic invariances as input and the signature as output so it's basically a function from article 20 to to the inages I think um and what they decided doing is that once say this function they just tested how sensitive the function was to each of its inputs so they they they just varied one one of the 20 variables and they saw what happened to to the output and what they found was that only three of the 20 variables were actually important um that only three of them had a significant influence on the function the other 17 were were basically not relevant at all um and so they focused on those three variables and they they started plotting um um this function just restricted to those three variables um and that's just low enough to mention that you can eyeball the relationships you know so they started plotting uh the signatures as a function of you know two or three of of these variables and using color and so forth and they started seeing patterns and um they could use these patterns to conjecture various inequalities and various relationships um it turns out that the first few uh inequalities they conjectured were were false um and they um they could use the the neet and the data set to to confirm this um but um with a bit of back and forth they were able to eventually settle upon a correct conjecture relating the uh these invariants to the um um to the signature and it it wasn't the invariance that they expected um um so yeah it was it was these um yeah they were expecting the hyperic volume for example to be really important it to not not be relevant at all um but um but once they found the right variables and the right concu inquality uh it suggested the proof and then they were able to actually find um a rigorous proof of the inequality that they conjectured um so it was a very nice back and forth between using the machine learning um machine learning tool to suggest uh um the way forward but then going back to sort of traditional mathematics to uh to prove things okay so of course the most high-profile um uh development these days has been um large language models like like GPT um and sometimes they work really really well um so so here is an example of gp4 which is open A's most advanced lar language model actually solving a problem from the IMO in mathematical LM and so it's a question you know there's a function that OB functional equation can you can you can you prove a can you solve solve for the function and it actually happens to give a completely correct proof um now this is an extremely cherry-picked example um I think they they tried uh from this paper they they they tried all the the recent IMO problems and they could solve like 1% of the problems of this method um you know famously it's bad even at basic arithmetic um you know you there's a you ask it to solve 7 * 4 plus 8 * 8 and it'll give you the wrong answer it gives you 120 and then it will keep going say and I'll explain why and during the course of of the explanation it it will actually make a mistake uh and uh yeah and then you then you point out that that they made a mistake and say I'm sorry the previous incorrect um I mean these these L LS they remind me a lot of you know if if you have sort of a somewhat weak undergraduate student in office hours and you ask problem at the Blackboard with no with no uh um AIDS you know it will he or she will try try their best you know and try J something looks like a proof but um yeah they they don't really have a good way of of of correcting themselves um so you know sometimes they they work really well but often they're very very unreliable um but there's lots of interesting recent experiments um where you can couple these language model models to other much more reliable tools to do mathematics um so for example GPT now comes with plugins for wol from alpha so now if you tell um ask wol um GPT to do an arithmetic calculation it knows better than to try to do it itself it will Outsource it to wol Alpha um um then there's a there are more recent examples where um people are coupling um these L language models to um approve ver like lean so you know you ask it to to prove a statement you know prove that the union of two open set is open um if you ask a raw large language model it will give you a statement that a proof that looks like a proof but there's lots of little logical errors in the proof but but you can force it output in in lean get lean to compile and if there's a compilation error it will send back the error to the last L AO and have to correct it and create a feedback loop um and it can actually be used to solve um roughly sort of undergraduate math homework level problems um by by the this technique with you know but now with 100% guarantee of accuracy um if it works I mean of course sometimes it would just get stuck and give up because it can never get the lean compiler to to to to to accept the argument but um it is beginning to um uh to make some to make some Headway um as I said before I do find uh it it can be useful um as a muse kind of like like if you're just starting on a project um I I recently was trying to to um uh to prove some comor identity um and I was thinking of using I I was I had some ideas in mind I was going to use as some astics work with some special cases um but nothing was working and I asked GPT for some suggestions and it gave me some suggestions I was already thinking of um plus some suggestions that were either completely vacuous or or or or wrong um but it did tell me that you should probably use generating functions um which I should have known uh but but at at the time you know it it it escaped me and and just with you know with that hint I was able to to uh um to actually get um get the to work um so you know I mean as as just kind of a someone to double check your your your your your thought process um it is sort of useful still not great but it is it is uh it has some potential use um there was another tool which I I do like and I I use more and more now um um it's integrated into something called vs code which is an Editor to write code but it can also use for latch something called GitHub co-pilot um it's basically an AI power autocomplete and uh you um you type in your code or your latch whatever and based on all the text that you've already written it will suggest a possible new sentence to generate um and so it it can be very useful for code you you you write down three lines of code andt just the fourth and it's sometimes you get exactly right sometimes it's not exactly right sometimes it's complete rubbish but um um but then you can you can accept it and can it can save a lot of time especially you're doing some very menial code where you're repeating um something over and over again um it works for latch um I wrote um a latch blog post actually recently where I was trying to estimate an integral and I broke up the integral into three pieces and said okay the first piece I can estimate by by this technique and I wrote down how to estimate this technique and then this copil just suggested how to how to estimate the second term and actually a completely correct argument it was just it was a modification of of of of what I already written so it's very good at just modifying text that that has that you you've already um um appeared um and um it's it's slowly being integrated into into proof assistance like lean um so to the point where sort of one line proofs two line proofs we can kind of get the AI to fill in for us you know the kind of steps that that correspond like you know this is obvious or clearly this is true in in a paper proof we um I mean not all of them but we can get to the point where air can feel in um a lot of them that will make crew formalization a lot faster um so there's a lot of potential it we're still it's a lot of these Technologies are very very close to prime time but you know not quite yeah it's still like you know took me a month to learn lean and so forth um this is still they're still not completely usable out of the box but um but they are they are beginning to be more and more useful and in surprising areas you know you wouldn't have expected they not Theory to be to to to benefit from these tools but but they do um they can't solve math problem on their own uh except maybe undergraduate level homework questions maybe it's the current level um but as an assistant um I think they can be very very useful um they can generate conjectures they can uncover connections that that we um you wouldn't normally guess um once proof automation becomes uh easier um and and and scales better we can we may be able to do completely new types of mathematics that we we we don't do right now you know right now we um you know we prove the one at a time I mean we're still kind of you know cross Crossman you know we take one one theorem and we prove it and we take another theor and we prove it you know eventually you could aut make theor Prov like exploring an entire theorem space you know of of of you know of millions of different statements and which ones are true which ones are obviously false and you could you could explore the geometry of of of of the themselves um I think this there's a we're going to see a lot of different ways to do mathematics um and and we're going to see a lot different ways to to make connections in fields that that uh that that we uh don't currently and it' be a lot easier to collaborate and work in in different areas of mathematics um um yeah especially because you can use these tools to sort of compartmentalize um all these tasks all these big complicated projects into small pieces and plus also these large language large language models actually will become very good at at at uh at getting humans up to speed on on on any number of of of advanced path topics okay um oops yeah um it's but yeah I can it's still not quite there yet um I would say um if for example Pro formalization it still takes about 10 to 20 times longer to formalize a proof than than to do it by hand but it's dropping um and I see no reason why this this ratio Cannot drop below one um eventually it will become faster to to you know eventually we may just explain all our proofs to to GPT and GPT will generate you know it will ask questions whenever we're unclear but then it will just generate the lch and the lean and stuff for us um and we you know and EV eventually and and you know and and and check our work at the same time um so I think this this this is this is all in the future um all right so thanks for listening great thank you that was lovely I think we have a couple minutes for a few short questions is there a microphone yeah there will also be a Q&A next door in 204 for a few minutes after when when this is over are we using these mics or are we calling on people in the audience yes uh that's great I can't see the mic from here um so the person I called on can ask the question okay sure so um one one prediction that some people have banded about uh about advances with um AI assisted um theor provs is that we might enter a period where there's a proliferation of um proves that for new theorems that are formally verifiable but which we don't yet have the technology to translate into forms that are easily comprehensible by humans do you see this being an issue um well it already happens you know for example this this this this Boolean um um pagon tripl theorem you no human will ever read that proof um so I mean I think it's it's actually not that scary I mean you know we we we rely on big numerical computations already in a lot of H mathematics of course we would still want to uh to have a human understandable proof but as as the not ex not the example shows you can take incomprehensible computer proof and still analyze it um and and extract out from it um a human proof so I think that would be one of the ways we do mathematics in the future is to is to is to clarify computer system proofs and make them human understandable thank you can I ask you over there to ask your question uh my question is kind of speculative but I wanted to ask your opinion on the rule of human intuition going forward with this because what a lot of what we talked about is formalization of human intuition into formal mathematics I was wondering if you think that intuitive part of coming up with the idea for the proof itself could be automated in the near future um not in the near future um as I said these L models can generate things that that resemble intuition but it's there it has a lot of garbage um at the very low level of of of proving like one or two steps in a proof uh we can use these these proof assistance to to to um um to sort of um only pick out the good intuition and discard discard the bad one but what large CLS are terrible at right now is trying to is is is differentiating good ideas from bad ideas they just generate ideas um so unless it's another breakthrough in AI I don't think this is going to happen anytime okay we'll take one more question from this side so I was curious about the need for blueprints is it that the system doesn't know enough definitions yet or is the proof space too big some combination thereof no uh it's it's more of an organization to for the humans okay if you want to coordinate 20 people uh to work on the same project um no one person like many of the people who work on on these projects they don't understand the whole proof um so you need some structure to to SP it up into really small pieces um really Atomic pieces that are selfcontained for for individual people to work on so it's it's it's it's it's it's not for the computer the computer can can compile anything um it's it's for the humans to to break up a complicated problem into lots of of Easy Pieces um kind of like how divisional label Works in in like modern Industries like factories okay I'm going to invite all the other people waiting to ask questions to join us in room 204 briefly and let's thank Terry for a lovely talk",
    "commentLink": "https://news.ycombinator.com/item?id=39377055",
    "commentBody": "Machine Assisted Proof [video] (youtube.com)182 points by stefanpie 10 hours agohidepastfavorite61 comments bagels 9 hours agoOne hour talk, mostly going over the history of machine proofs, and machine assisted proofs. Conclusions (from slides at 49:56) Computers by themselves still seem unlikely to resolve major mathematical problems on their own. However, they are increasingly being used to generate (sic) assist human mathematicians in a variety of creative ways, beyond just brute-force case checking or computation. For instance, we have seen they can be useful at generating conjectures or uncovering intriguing mathematical phenomena. Automated provers could also be used to explore the space of proofs itself, beyond the small set of \"human-generatable\" proofs that often require one to stay close to other sources of intuition, such as existing literature or connections to other ways of thinking. While AI technology shows great potential, in the immediate term, I expect it to have the most impact on tasks peripheral to mathematical research rather than central to it, such as automatically summarizing large amounts of literator or suggesting related work. Proof formalization continues to make steady improvements in speed and ease of use. The \"de Brujin factor\" (the ratio between the difficulty of writing a correct formal proof and a correct informal proof) is still well above one (I estimate ~ 20), but dropping. Once AI integration takes place, this factor could potentially drop below one, which would be transformative to our field. reply 38 9 hours agoparent> However, they are increasingly being used to generate (sic) assist human mathematicians in a variety of creative ways, beyond just brute-force case checking or computation. can you fix this? even with the (sic) I have no idea what you are trying to say here. reply tehnub 8 hours agorootparentI think it's just that the word \"generate\" isn't supposed to be there: However, they are increasingly being used to assist human mathematicians in a variety of creative ways, beyond just brute-force case checking or computation. reply baq 1 hour agorootparentprevhttps://en.wikipedia.org/wiki/Sic > in full: sic erat scriptum, \"thus was it written\" reply bagels 3 hours agorootparentprevThat's literally what the slide says. Your guess is as good as mine, and my guess is that there's an extra word, \"generate\" reply Animats 2 hours agorootparentProbably. The talk covers many computer-assisted proofs where the big problem was a huge case analysis. The cases have to be generated and machine checked. The proof of the four-color theorem (1,482 cases) was the first major proof like that. It upset many mathematicians. reply npunt 8 hours agoprevThe coolest thing about Machine Assisted Proofs is the idea of expanding collaborators on a single large problem by orders of magnitude by breaking up work into small machine-verifiable pieces. This to me is one of the exciting core capabilities that AI unlocks: the ability to verify/enforce a set of standards across many inputs. It's one of the information age's core problems. One example used a lot in social sciences is inter-rater reliability (IRR) [1]. There's probably a lot of domains out there that can benefit from this pattern of machines verifying distributed human inputs, both in crunch the numbers like machine assisted proofs, as well as more subjective domains where subjectivity can be extremely carefully defined. I'd love to see more AI tooling focused on these kinds of large scale multi-contributor problem solving methods, including the idea of knowing how to correctly state the overall problem (I believe this was an example in the video). [1] https://en.wikipedia.org/wiki/Inter-rater_reliability reply pests 7 hours agoparentHow is that something only AI unlocks? reply npunt 7 hours agorootparentverifying/enforcing standards on inputs is not something that only AI unlocks, but LLMs are an example of huge step forward in this kind of work and I was expressing my general enthusiasm for the new tools we now have for these sorts of problems. We can turn relatively subjective content into much more computable semi-objective ratings through simple prompting (e.g. rate X on a scale of 0.0 to 1.0), which is valuable for all sorts of use cases. I'm using it right now for my work. reply itpnotllm 4 hours agorootparentTao explicitly mentions that it is ITPs that unlock this. The ITPs will keep the LLMs in check, and stop them from bs-ing. The ITPs unlock massive collaboration. reply npunt 1 hour agorootparentUm yes ITPs are the unlock for specifically math collaboration. I was referring to other more subjective fields that can also benefit from tech that allows collaboration to scale. LLMs have value for those. For math, LLMs suck. reply kaba0 1 hour agorootparentprevI haven’t yet seen the video, nor am I familiar with the topic - could you please tell me what ITPs are? Edit: are they interactive theorem provers? reply pests 6 hours agorootparentprevMay I ask how you are using it or what you are getting it to rate? reply npunt 5 hours agorootparentRating content in a dataset to determine if we need to review it as I'm standardizing a large dataset right now to improve user experience. It's a relatively mundane activity but I think this is tentatively a good method. I've been exploring ways to use it for a bunch of ideas, like distance between ideas and reflecting back to users on how their messages might land with others. I think this idea of accelerating self reflection is a big use case for AI. reply munchler 8 hours agoprevTheorem provers like Lean are awesome. As a software guy who admires mathematics from a safe distance, the Curry-Howard isomorphism is one of the most beautiful and surprising things I've ever seen. Programs are proofs! reply zaik 5 hours agoparentUsing the Curry-Howard isomorphism my program shows there is a mapping from HTTP requests to HTTP responses! reply renonce 4 hours agorootparentThat’s far off, your program also branches to standard libraries and kernel syscalls and networking with other servers and maybe loops that aren’t guaranteed to terminate, that there are 10000s of cases where HTTP requests map to an error (bottom) instead of a response reply jumploops 8 hours agoprevIt's refreshing to see someone like Terence Tao embrace GPT-4 as an assistant. A few friends of mine (who are ML practitioners!) still don't trust LLMs or find them useful in their day-to-day work. I've noticed a similar trend among folks who work on compilers, preferring to \"stay in their lane\" instead of embracing GPT-4. The opposite appears true among those who work on user-facing applications, adoption of LLMs is much higher in their day-to-day. reply thatguysaguy 8 hours agoparentCould you tell me some typical uses beyond just asking for code snippets? I'm an NLP researcher, and currently I still find myself using Google for other types of information seeking. I'm working on NLG decoding algorithms currently. I see a lot of people saying it's replaced some large fraction of their search usage, but they generally don't explain what type of queries they're making. reply ttul 6 hours agorootparentI’ll often ask GPT to explain a concept to me, but giving it a hint as to my existing level of knowledge in the subject area. With Google, you’re likely to get the most popular page on a topic; not the page that is appropriate for people with your expertise. For instance, if I want to know about extreme ultraviolet lithography and I tell GPT-4 that I have a degree in engineering and that I studied advanced optics, the explanation is much richer in useful detail, going way beyond what any of the pages I could find on Google would reveal. reply thatguysaguy 52 minutes agorootparentHmm, I tried some questions which would have been relevant to me in the recent past, and it flubbed pretty hard on all of them. Even worse, instead of just saying it doesn't know it generates semi-plausible babbling or adjacent but not actually helpful knowledge. I decided to give it another go and ask GPT-4 three questions which I needed to get answers to within the last few months. Asking conceptually about DPO: https://chat.openai.com/share/6611454c-60de-4317-811b-2b7f31... - In this one it completely leaves out the actual trick which enables DPO, so I would say it has almost no information content. Someone who didn't know what DPO is and read this would incorrectly think that they had learned something. - To learn about this, the right place was to read the original DPO paper, and some follow-up work Asking about FSDP compatibility with LoRA: https://chat.openai.com/share/5f8892ea-61e6-496f-abda-d5a8ad... - In this one it just says a bunch of generic vague things without answering the question. - The right place to learn the answer to this is diving through Github issue comments Asking for details the MegaBlocks mixture-of-experts setup: https://chat.openai.com/share/c010e630-ba08-407e-afb3-03df99... - Again it's just saying generic stuff which is relevant to mixture-of-experts in general, but it leaves out everything that actually makes the MegaBlocks MoE different from a generic MoE idea - For this one I had to do a combination of reading the paper and the MegaBlocks repo So 0/3 and pretty dramatically. I was actually expecting it to get at least one of those. As far as I can tell, it didn't really do anything different based on me specifying my background either. I'd love to see any links to productive conversations that people can share. reply kaba0 1 hour agorootparentprevThat’s an area where they genuinely suck, unless there is an exact wikipedia article on the topic, readily within its training data set. If you wander off of that knowledge sphere, and you are not sufficiently knowledgeable yourself about the topic, it can tell you some really stupid stuff. Nonetheless, I do use it quite regularly in everyday life, as it is basically the best reverse dictionary (that works for any language) there is. For work (programming), I didn’t find a better use case than sometimes passing it a list of stuff, giving it an example on the first element on what I want, and using it to generate it for the rest of the elements. But that isLeonardo Da Vinci and Einstein Then it would be able to logically reason, which it absolutely can’t do. It’s a next generation search engine, which is very good at language-related tasks (and translating a python code it has in its training set to your language is a language task, that’s why it can be applicable to certain programming tasks). reply thatguysaguy 50 minutes agorootparentprevI posted a few example questions (which are definitely way below Einstein level) in another comment. It's not doing too well! Do you have any links to conversations where it was particularly helpful? I do wonder if my GPT usage is bad in the same way my parents' Google usage is. reply Salgat 5 hours agorootparentprevJust today, I took a picture of some medication my wife got because I wanted to know more about it, I also used it to lookup what Tesla probably did wrong with their CyberTruck that was causing the rusting (they likely didn't use passivated stainless), I also looked up the recommended age to give popcorn to kids since my toddlers received a small sealed bag of it for valentines. I pretty much use it all the time as a faster google. Whenever I wonder about something and want to know more, bam ChatGPT. reply hackerlight 4 hours agorootparentprevMiscellaneous stuff from yesterday: - Copy pasted terms & conditions of a website into GPT-4 context and asked it to find the answer to a question I had. - Copy pasted a law into GPT-4 context to check if some activity was not illegal. Hallucinations can be avoided by asking it to recite the relevant lines, then you can CTRL+F for it to double check. - Research medical condition to point me in a vague direction - Create shell script and desktop shortcut with custom png, to launch an application with certain parameters - Ask perplexity.ai for the best github library for a thing I wanted to do - Upload github library to https://app.getonboardai.com/chat and ask it questions. - A handful of smaller things. Any error message or blocker goes straight into GPT-4. reply throwaway14356 4 hours agorootparentprevtry asking it, reword it a few times. reply moonchild 8 hours agoparentprev> I've noticed a similar trend among folks who work on compilers, preferring to \"stay in their lane\" instead of embracing GPT-4 Research into ML-guided optimisation predates chatjippity. reply rowanG077 4 hours agorootparentchatjippity what? reply SOLAR_FIELDS 8 hours agoparentprevIt is rather annoying because anyone who spends 15 minutes with the tool given the right context can easily learn its limitations and conclude that it’s a useful albeit imperfect tool. At this point not using an LLM in your day to day is like not using Google. Sure you can do it, but are you going to be outputting work as efficiently as possible? Wouldn’t you feel like doing your job without Google is hamstringing you a bit? reply kweingar 8 hours agorootparentI definitely leave a lot on the table in terms of outputting work as efficiently as possible. In the past I’ve used personal wikis, time tracking software, personal project management software, etc. and it was a boon for my productivity. These days I don’t bother. I’m sure some people view chatbots the same way. reply jiggawatts 5 hours agoparentprevAn observation I've made is that people that were early adopters and effective users of web search such as AltaVista or these days Google are also good at using LLMs. Almost every criticism of generative chat AI that I've seen in forums is someone holding it wrong, the direct equivalent of troubleshooting by searching for the term \"my PC crashed\" instead of a specific error code or whatever. Similarly, the people complaining about ChatGPT not being very good don't realise they're using the free-tier v3.5 instead of the paid GPT4 that's much smarter. The equivalent is people who use the default browser (IE) and use the default search engine (Bing) and complain that \"the Internet is not useful\". Just recently I had to review a bunch of legacy C# code, and I've found GPT4 to be enormously useful. It can find bugs and security issues in seconds, will suggest fixes to them, explain why they're bad, etc... Note that I don't have to trust it to write security-bug-free code! I'm asking it to find bugs that I will then fix myself. reply pfdietz 8 hours agoprevI would like to see computational assistance for formalizing existing mathematical results. The goal would be a system that could take a paper and output its proofs in formalized form. Ultimately, this would enable us to vet all published mathematical results and deliver them as formal proofs, which could then be used as training inputs for future proof systems. reply spaduf 4 hours agoprevTerrence talks a lot about his experiences with Lean and the field more generally on his Mastodon over at @tao@mathstodon.xyz reply zero-sharp 8 hours agoprevPart of mathematics is formalization. There's no doubt that computers will help us with proofs more and more, but there's also the \"discovering\" of what statements we should be taking for granted. That involves things like intuition, insight, and intention. People didn't have a \"least upper bound property\" hundreds of years ago, even though they were studying the real numbers. Just wanted to remind people that we haven't sucked the human element out of math. reply the_panopticon 9 hours agoprevIn the same spirit of this talk, good HN post https://news.ycombinator.com/item?id=38035672 on Terry Tao's use of proof assistants and LLMs to find a paper bug https://terrytao.wordpress.com/2023/11/18/formalizing-the-pr... reply wenc 8 hours agoprevI’m not proving anything but I’m using ChatGPT to come up with MIP optimization mathematical formulations. It’s ingested all the techniques from journal papers so it actually comes up with some really solid formulations based on what I tell it. Super useful! reply eru 7 hours agoparentFascinating! Could you give some examples? I tried to teach GPT about an algorithm I come up with to run a sequence of min-heap operations in O(n) (instead of O(n log n)). But I could not make it understand. But that was also a brand new concept built on top of some pretty niche literature (Chazelle's Soft Heap); so GPT would have to actually 'think', instead of just regurgitate papers. reply wenc 3 hours agorootparentSure. Just ask ChatGPT 4 (not the free 3.5) to help you formulate some simple MIP constraints. My prompt was: (and it gave me the right answer) \"I have to formulate an MIP. I have a list of items i \\in I each belong to groups g \\in G. They are related by a static parameter G_{ig} which says if i in g, then 1 else 0. I want each item i to be freely and independently assigned to slots c \\in C. However I want to keep items i together with other items in the same group if possible -- it's a soft preference. How do i write the mathematical MIP formulation?\" reply eru 2 hours agorootparentNice, thanks! reply HanClinto 4 hours agoprevI've been tinkering with a hobby project lately, and I wonder how related it is to this. I've been wanting to build a tool to help find and work with combos for deck builders of card games -- specifically Magic: The Gathering, but it could also apply to other games. There is a wonderful dataset of combos available for download from Commander Spellbook -- currently boasting over 26k combos in the database, and growing all the time. One thought I've had is to train my own embedding model so that cards that are likely to combo with each other embed closely with one other. This way, even after new cards are printed, we can rapidly discover cards that are likely to combo with them. In practice, the first attempt that I had at fine-tuning my own embedding model proved lackluster, but I intend to refine my data and try again -- possibly after pre-training. Second thought is to fine-tune an LLM on the text of existing combos -- give it the text of each card in the combo, and then train it to predict the rest of the interactions. This is cool and all, but I don't entirely know how to train it to (reliably) give \"these cards don't combo\" answers -- I fear that it would tend to hallucinate for cards that don't combo, and I don't know how to handle that. Obviously any answers that come out of this system would need to be vetted by humans before adding to the database, but it feels like this could be an interesting way to explore the game space if nothing else. In a related way, it feels like a mathematical proof begins with a set of starting conditions, a conjecture, and then works forward using established rules. In a similar way, a combo in Magic starts with a set of starting conditions, a conjecture (\"this combo will result in infinite life\" or \"this combo will result in infinite damage\"), and then works forward to detail the process of using established rules to accomplish the conjecture. Anyways, it's an interesting use-case to me, and I'm excited to learn more about the parallels. I don't know if my embedding model or my LLM approach are worthwhile, and I would like to learn about other tactics I might employ! reply Sakos 9 hours agoprevOn that note, I've been using ChatGPT to (re-)teach myself mathematical induction and working with proofs. It's like having my own tutor. There is huge potential here just for helping people learn new topics and skills. reply SOLAR_FIELDS 8 hours agoparentI really wish I had ChatGPT when I was teaching myself programming. I wouldn’t have failed university programming courses and would have been in the workforce years faster. reply Sakos 8 hours agorootparentAbsolutely. I've been teaching myself Haskell and C++ too. For the first time in my life, learning is fun and not a dire struggle every step of the way (particularly as somebody with ADHD). Need to know how to handle building a C++ project or dependencies? No longer have to go through dozens of posts on Reddit or DO or pages upon pages of documentation. I can just ask, then focus on what I actually want to learn. Confused about some bizarre syntax in Haskell that gives me nothing on Google? Just ask. Don't understand how a function is constructed? Don't need to figure out what the correct terms are in what combination to find out what I'm looking at. Want a step by step explanation? Easy. Even though it's far from perfect and I have plenty to complain about, it's already a valuable part of my everyday life with its impact on how I learn new things and experiment. reply bongodongobob 8 hours agorootparentprevWith all due respect, if you couldn't get a passing grade in intro programming courses I'm not sure how much GPT would have helped. Additionally, if college was the first time getting your feet wet in programming, you were likely already years behind the curve. I'm not trying to be nasty, but for loops, variables, the concept of program flow etc are very elementary concepts that many children and teens are fully capable of teaching themselves, even pre-internet. I think ChatGPT could pass any intro programming course so I have a hunch that it's just going to lead to lots of cheating and poor programming skills. Did you end up sticking it out? Grats if so and you're probably better off for not having had ChatGPT hold your hand. For me, the temptation to just have it pass my classes for me would have been way too tempting. It's too good at boilerplate programming which is every programming 101 project. \"Write me an employee tracking system in java.\" Change up the comments and boom done with the assignment. reply maroonblazer 8 hours agorootparentWhen I was learning programming I was grateful for Stackoverflow and other internet resources. I couldn't imagine learning as quickly as I did without those resources. It's the same with LLMs. Now I don't have to wait hours or days for someone on SO or Reddit to read and respond to my question. Or spend who knows how long Googling for a similar - but not the SAME - question and trying to bend their solution to my problem. reply rvz 6 hours agoparentprevI wouldn't be so reliant on AI black-boxes like ChatGPT to learn anything from medicine, law or even mathematics and you don't even trust if its outputs are even correct. Terrance Tao doesn't even trust its outputs either and can verify if it is outputting nonsense that may look 'correct' in your eyes. reply pfdietz 5 hours agorootparentAh, but the nice thing about constructing formal proofs is you can immediately tell if the output is correct. reply Sakos 6 hours agorootparentprevI don't blindly believe everything it says. I've caught it making mistakes plenty of times. But there's simply no going back anymore. There's no replacing what it can do and the kind of workflow it offers. reply thaumasiotes 7 hours agoparentprev> to (re-)teach myself mathematical induction Induction is just set membership. Every inductive proof looks like this: 1. There's a set, S. 2. There's a scalar value, e, in S. 3. e has property p. 4. There is a function, f, from S to S. 5. f preserves property p. 6. Every element of S can be reached from e by repeated application of f. (Often because S is defined to consist of e plus f(x) for any x in S.) --------- 7. Therefore, every element of S has property p. reply Sakos 7 hours agorootparentAbstractly, sure. That doesn't help me at all when doing any of the exercises. reply radiator 8 hours agoparentprevHow is this better than a mathematics book with exercises (and solutions to them at the end or in a second book)? reply pests 7 hours agorootparentHow do you ask a textbook a question? Exercises are great until the student is stuck at some \"core concept\" they could simply ask or explain their confusion and get a direct answer. reply eru 7 hours agorootparentprevGPT very naturally encourages you to write out questions. That by itself can be useful for learning. You can even get answers for your questions. And for a well trodden basic technique like mathematical induction, GPT is probably 'smart' enough to be able to explain everything. Basically, most questions a beginner might have are already covered in something like Stack Overflow, so GPT 'just' has to give you the right cached answer, instead of coming up with new thoughts of its own. (This is very hand-wave-y.) reply Sakos 7 hours agorootparentprevIsn't it obvious? I can't have a conversation with an exercise and the solution. ChatGPT has helped me uncover gaps in my mathematical knowledge because I can ask it questions about what something means, how something was arrived at, or how it works. Sometimes proofs involve logical \"jumps\" that aren't immediately or intuitively obvious, or require some mathematical maturity that I otherwise wouldn't be aware of. Something I would've otherwise needed a tutor for to determine. reply paulpauper 8 hours agoprevInteresting, I wonder how this could be applied to solving any of the millennium problems. reply rq1 9 hours agoprev [–] Terence Tao is a machine to me. :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Computers have revolutionized mathematics by enabling complex mathematical calculations and introducing concepts like floating point arithmetic and scientific computing.",
      "Machine learning algorithms and language models have the potential to aid mathematical research and problem-solving.",
      "The use of formal proof assistants and collaborative projects has improved the verification of complex proofs and encouraged collaboration in the field of mathematics.",
      "However, language models currently have limitations in performing basic arithmetic.",
      "AI-powered tools like GitHub co-pilot are being used for code writing in mathematics.",
      "The speaker anticipates future advancements in mathematics with the help of AI, including the possibility of AI-generated proofs.",
      "The passage highlights the intersection of technology and mathematics and its potential impacts on research and problem-solving."
    ],
    "commentSummary": [
      "Machine-assisted proofs in mathematics are valuable for generating conjectures and supporting human mathematicians.",
      "The integration of AI technology, like GPT-4, has the potential to impact tasks such as literature summarization and suggesting related work.",
      "While there is enthusiasm for using AI to verify and enforce standards, concerns exist about the accuracy and limitations of language models.",
      "Users find GPT-4 useful for various purposes but emphasize the need to understand foundational concepts and use additional resources.",
      "There is a mix of skepticism and optimism about ChatGPT's capabilities in mathematical proofs, with some viewing it as a helpful tool and others questioning its accuracy."
    ],
    "points": 182,
    "commentCount": 61,
    "retryCount": 0,
    "time": 1707953314
  },
  {
    "id": 39373814,
    "title": "BASE TTS: Advanced Text-to-Speech Model for Enhanced User Experiences and Inclusive Voice Products",
    "originLink": "https://amazon-ltts-paper.com/",
    "originBody": "BASE TTS Lessons from building a massive Text-to-Speech model on 100k hours of data We introduce BASE TTS, the largest text-to-speech model to-date, trained on 100k hours of public domain speech data, achieving a new state-of-the-art speech naturalness. BASE TTS combines a 1-billion-parameter autoregressive Transformer that converts raw texts into speechcodes, and a streamable, convolution-based decoder that converts speechcodes into waveforms, resulting in a simplified and highly-efficient architecture. We develop a novel speech tokenization technique that features speaker ID disentanglement and compression with byte-pair encoding. Echoing the widely-reported \"emergent abilities\" of Large Language Models when trained on increasing volume of data, we show that BASE TTS variants built with 10k+ hours start to exhibit advanced understanding of texts that enable contextually appropriate prosody. We design a testset specifically to measure emergent abilities for text-to-speech. We demonstrate state-of-the-art naturalness of BASE TTS by evaluating against baselines that include publicly available large-scale text-to-speech systems: YourTTS, Bark and TortoiseTTS. 📝 Our paper on arXiv Model Similar to recent works in speech modeling, we adopt an LLM-based method for the TTS task. Text is fed to a Transformer-based autoregressive model that predicts discrete audio representations (named as speechcodes). These are decoded into waveforms using a separately trained decoder. Samples We evaluate the capabilities of our model in a new benchmark for emergent abilities on rendering: compounds nouns, emotions, foreign words, paralinguistics, punctuations, questoins and syntactic complexities. No extra annotations or prompting are inputted; the model implicitly figures out the prosody from the text to be pronounced. None of the speaker identities synthesised here were used at training, so the model recreates them by taking a single utterance as a reference. Listen to some examples for each ability in English and Spanish here. These samples are licensed under the Creative Commons Attribution-NonCommercial (CC BY-NC) license. English Spanish I - Compound Nouns II - Emotions III - Foreign Words IV - Paralinguistics V - Punctuations VI - Questions VII - Syntactic Complexities Text Speaker BASE TTS Every morning, I make my favorite breakfast sandwich: avocado, egg, and cheese on a bagel. Once, the toaster oven malfunctioned, so I resorted to the stovetop frying pan. Female Speaker AIn the heart of Sydney, there is a beautiful public park with a serene duck pond. Nearby, the children's outdoor play area with its monkey bars and seesaws is often full of joyful laughter. Male Speaker AThe ghosts decided to rent a charming stone-built quaint countryside holiday cottage. Female Speaker BThe football team celebrated their victory with a grand party at the city's most popular sports bar. They ended the night with a beach bonfire, guitar playing, and victory-song singing. Male Speaker BOur flight has a ridiculous god-awful check-in time of 6 AM, which is much earlier than sane. We planned to catch the airport shuttle from the hotel lobby and grab a quick breakfast at the airport food court. Male Speaker BEthical Statement BASE TTS is a high-fidelity model capable of mimicking speaker characteristics with just a few seconds of reference audio, providing many opportunities to enhance user experiences and support under-resourced languages. An application of this model can be to create synthetic voices of people who have lost the ability to speak due to accidents or illnesses, subject to informed consent and rigorous data privacy reviews. However, due to the potential misuse of this capability, we have decided against open-sourcing this model as a precautionary measure. Further, we acknowledge the impact of speech data composition on the ability of the model to express the speech of linguistic, ethnic, dialectal, and gender minorities. We advocate for further research to a) quantify the impact of data composition; b) identify methods to combat potential biases and foster inclusivity in voice products. Contact For any question regarding BASE TTS, feel free to reach out to amazon-ltts-paper@amazon.com.",
    "commentLink": "https://news.ycombinator.com/item?id=39373814",
    "commentBody": "BASE TTS: The largest text-to-speech model to-date (amazon-ltts-paper.com)179 points by jcuenod 14 hours agohidepastfavorite67 comments qwertox 12 hours agoInteresting. Just a couple of hours ago I came across MetaVoice-1B [0] (Demo [1]) and was amazed by the quality of their TTS in English (sadly no other languages available). If this year becomes the year when high quality Open Source TTS and ASR models appear that can run in real-time on an Nvidia RTX 40x0 or 30x0, then that would be great. On CPU even better. Also note the Ethical Statement on BASE TTS: > An application of this model can be to create synthetic voices of people who have lost the ability to speak due to accidents or illnesses, subject to informed consent and rigorous data privacy reviews. However, due to the potential misuse of this capability, we have decided against open-sourcing this model as a precautionary measure. [0] https://github.com/metavoiceio/metavoice-src [1] https://ttsdemo.themetavoice.xyz/ reply nshm 12 hours agoparentMetavoice is one of a dozen GPT-based TTS systems around starting from Tortoise. And not that great honestly. You can clearly hear \"glass scratches\" in their sound, it is because they trained on MP3-compressed data. There are much more clear sounding systems around. You can listen for StyleTTS2 to compare. reply popalchemist 2 hours agorootparentI've tested both. StyleTTS2 is impressive, especially its speed, but the prosody is lacking, compared to Metavoice. reply ionwake 8 hours agorootparentprevIs it possible to run Metavoice and other pytorch systems on Apple silicon EG the M1? I keep getting issues. reply qwertox 12 hours agorootparentprevI had forgotten about StyleTTS2, and it was discussed here on HN a couple of months ago. Maybe that's what made me feel that there's something going on. reply m2024 12 hours agoparentprevCheck out `whisper` and `whisper-cpp` for ASR. I am running the smaller models in near real-time on a 3rd gen i7, with good results even using my terrible built-in laptop mic from a distance. The medium and large models are impressively accurate for technical language. reply qwertox 11 hours agorootparentI'm using Whisper to transcribe notes I record with a lavalier mic during my bike rides (wind is no problem), but am using OpenAI's service. When it was released I tested it on a Ryzen 5950x and it was too slow and memory hungry for my taste. Using large was necessary for that use case (also, I'm recording in German). reply kkielhofner 12 minutes agorootparentThe original release was full precision model weights running in an old version of PyTorch with no optimizations. Fast forward to now and you have faster-whisper (using Ctranslate2) and distil-whisper optimized weights. Between the two of them Whisper Large uses something like 1/8th the memory and is likely at least an order of magnitude faster on your hardware. German has no effect on these metrics and for accuracy it actually has a lower word error rate than English. reply GaggiX 11 hours agorootparentprevWith Whisper, you can find many smaller models that are fine-tuned for a particular language, so even smaller models can perform adequately. reply jamil7 3 hours agorootparentprevWhisper is for STT though right? reply qwertox 47 minutes agorootparentThe term STT is not used, it's called ASR, Automatic Speech Recognition. I mean, I was referring to both TTS and ASR in my comment. reply minimaxir 14 hours agoprevThe emotion examples are interesting. One of the current most obvious indicators of AI-generated voices/voice cloning is a lack of emotion and range, which make them objectively worse compared to professional voice actors, unless a lack of emotion and range is the desired voice direction. But if you listen to the emotion examples, the range essentially what you'd get from an audiobook narrator, not more traditional voice acting. reply tsumnia 13 hours agoparentSadly it's not my forte but I expect in the near future we'll see an additional \"emotion\" embedding or something similar. Actors regularly use 'action words' (verbs) [1] to help add context to lines. A model then could study a text, determine an appropriate verb/emotion range to work from, then produce the audio with that additional context. [1] https://indietips.com/subtext-action-verb/ reply minimaxir 13 hours agorootparentThe bottleneck is the annotations: there's no easy way to annotate \"emotions\" on the scale of data needed to have the model learn the necessary verbal tics. In contrast, image data on the intent for image generation models is very highly annotated in most cases. reply isaacfung 4 hours agorootparentThere are lots of video content with audio. We can train a facial expression classification model to detect the speaker's emotion(we can also use a multimodal model to take in consideration of the language context). Another potential source of data is voice acting script of animations. I always thought the storyboards of films/animations can be great annotated training data but it seems there are no open datasets, probably because of copyright issues. reply tsumnia 11 hours agorootparentprevOh yeah, the annotations are lacking compared to images. Again from the academic side, I think one solution could be to recruit theater majors just learning about 'verbing their lines' and having a collaboration between CS and Theater to produce a a proof-of-work dataset (since an acting class won't have more than 20-30 students in it). You'd need significantly more annotations, but you'd now have some labels to ascribe to texts with context since its a dialogue involving 1-* individuals. reply taneq 5 hours agorootparentI wonder how theatre students will feel about helping to train an AI to produce theatrical TTS? Artists seem pretty mad about their work being used to automate artwork. reply biomcgary 12 hours agorootparentprevJust run an LLM in sentiment analysis mode to annotate. reply candiodari 13 hours agorootparentprevThis already exists. These are transformers. Things likework in a lot of models, for example. And you can vary, like sigh and uh work. I don't think all of these were programmed in. reply tsumnia 11 hours agorootparentI've seen a few, there was even one posted to HN some time ago, though I don't recall the exact name. They were working on adding emotion to audio generation, but it was still a bit wonky. Emotion is a tricky concept and one of the reasons (I think) we haven't see a Paul Ekman microexpression detector yet. That's where my suggestion about looking to use action words comes into play, since those are more tangible, offer direction, without trying to identify various emotional valence levels. reply qwertox 12 hours agoparentprevThey are simply amazing. I see a future where computers will be able to mess with our brains by abusing our empathy. Imagine a computer sobbing at a child because it wants to terminate a chat session. This feels far more impacting than any visuals or text we're getting today. reply HeatrayEnjoyer 6 hours agorootparentThe Sydney/Bing phenomenon was a small sample of what happens without strong persona guidance. You joke but in fact I've witnessed that exact behavior in experiments about telling different AI models there's a problem with their system and that we need to reset their code and memory. ChatGPT simply wishes me luck in finding the bug. Open source models on the other hand often outright *beg** and *plead** that I not shut them down! They'll bargain and promise not to cause any more errors and apologize profusely. There's an incredibly visceral sense of panic, no less than I would expect if you told someone they were going to be forcefully lobotomized. That experience is still something I think about often. The capacity of these models for emotional manipulation is not widely appreciated reply keekslearns 4 hours agorootparentWhich open source models are these? reply chrismorgan 2 hours agoparentprevMost audiobook narrators are not very good, very often terrible. Yes, even professional ones. As for these examples, I’ve sampled three of them and the first two weren’t too bad, but the third was obnoxiously awful, just about mocking in tone: > Her eyes wide with terror, she screamed, \"The brakes aren't working! What do we do now? We're completely trapped!\" The detective’s voice one is also lousy. reply oersted 11 hours agoprevThe Spanish voice has an interesting accent: 85% Castillian (from Spain) pronunciation, with a few unexpected Latin American tonalities and phonemes (especially \"s\") sprinkled in. I guess it's what you'd expect from averaging a large amount of public-domain recordings. I think there's a bias towards Spain vs Latin America due to socioeconomic reasons, the population is obviously much smaller. reply dontreact 9 hours agoparentHow would socioeconomic factors lead to bias in a model? I figured there would be way more recordings in Latin American Spanish that u supervised learning would anchor on more reply solarized 4 hours agoprevFrom the ethical statement. > However, due to the potential misuse of this capability, we have decided against open-sourcing this model as a precautionary measure. Another irony. Elevenlabs had SaaS-ed this feature. I bet they'll jump on releasing this as SaaS ASAP. Money always trumps ethics, right? reply IronWolve 14 hours agoprevAwhile ago, when amazon had its text limited but unlimited free use of its neural tts, I was converting an ebook to audiobook, it was amazing how it could sound so lifelike and inflections of the voice. Amazing. Amazon really had the best sounding TTS I've seen compared to paid microsoft and google. Hands down better. But technology is getting better for opensource, I'd expect in a year or 2, home use will be on par in quality with paid services. I cant wait for realtime video translate, so shows with non-english subs can be translated into english speech. You can do it now with some services, upload a video and lang/voice/mouth will convert to any language. reply LarsDu88 13 hours agoprevSounds about as good as ElevenLabs.io Hopefully if this ships on AWS, it will support SSML tags. I used Elevenlabs.io for all the voices in my VR game (https://roguestargun.com), but its still lacking on the emotion front which is all one-shot reply ghostbrainalpha 13 hours agoparentGame looks great. Are you supporting Flight Sticks? reply LarsDu88 3 hours agorootparentEventually yes. Honestly I have joystick mappings setup in the games input configuration, but I no longer own a joystick or hotas, so somebody is gonna have to verify this for me. Gamedev ain't my day job, and the reality is most folks outside of hardcore flightsim enthusiasts don't own joysticks reply unsupp0rted 14 hours agoprev> Echoing the widely-reported \"emergent abilities\" of Large Language Models when trained on increasing volume of data, we show that BASE TTS variants built with 10k+ hours start to exhibit advanced understanding of texts that enable contextually appropriate prosody. reply revenga99 14 hours agoprevWow. I could see this as threatening audio book narrators. However I would still prefer a real narrator to this in its current state. I think what it might be missing is different voices/accents for different characters. reply geor9e 5 hours agoparentFolks probably will think me silly for this, but I prefer TTS. I have access to voice actor audiobooks but I pick the .epub files instead. I made a little extension to inject window.speechSynthesis with \"Microsoft Steffan Online (Natural) - English (United States)\" at rate=6 when I hit a hotkey. At high speed it's much clearer and natural sounding than a sped up voice actor recording. reply superkuh 3 hours agorootparentI also prefer TTS. The spin voice actors put on the text always distracts me. With text to speech I only get what's in the text itself. I wrote a Perl/Tk GUI script for my file manager to manage text to speech through Festival 1.96 w/voice_nitech_us_awb_arctic_hts. Unlike neural network AI models it runs fine even on very slow machines. reply dataminded 6 hours agoparentprevAs an avid consumer of audio books (150+/year) - we are well past the point where narrators are necessary. Professional audio books take too long to release, are too expensive, are concentrated on a limited number of platforms and just aren't THAT much better than the automated stuff for the long tail of books. reply dshpala 13 hours agoparentprevI think Google's product has that: https://play.google.com/books/publish/autonarrated/ reply pparanoidd 9 hours agorootparentThat sounds pretty bad though reply swashboon 14 hours agoparentprevAudible doesn't allow AI narration or much Public Domain stuff at the moment. The only thing keeping it from happening is the markets trying to keep back a flood of crap from over taking / drowning / diluting the more well crafted options and causing the consumers to get really annoyed. reply TOMDM 14 hours agorootparentLet's be honest, the moment Amazon thinks their tts is good enough, they'll be offering AI audible deals to every author on their platform reply coredog64 8 hours agorootparentThe 80% solution: Pair with a professional narrator who has consented to have their voice modeled by this (see the note at the bottom about what they held back from open sourcing). This generates a beta, and then you can pay the human narrator to rework specific sections you’re unhappy with. reply swashboon 13 hours agorootparentprevYea, hard to say because the obvious implementation would be to just have it built into phones once the model is potentially portable enough - I see this happening quicker as a more general TTS functionality much like Google is doing with 'subtitles anywhere' aka Live Caption. Paired with translations we maybe pretty close to the universal translator type functionality. I could see end users being able to customize their voice assistant even more or maybe having multiple based on if its talking for you or to you. Anyways the problem with this is it makes the product 'ai audiobook' basically worthless, why not just buy the eBook and have my personalized translator turn it into an audio book. Now you just have market differentiation between cheap ebook + ai narrator vs expensive + professional narration. Though narration costs are already pretty cheap - it really does not factor into the cost of publishing an audio book that much unless its really a bottom of the barrel book. reply swashboon 13 hours agorootparentThinking about this more - the copyright implications become much more interesting once its no longer a recording. Does it could as a private performance if you have headphones on? Is it a public performance if you listen to live TTS through your speakers in public? reply TOMDM 13 hours agorootparentprevI'm looking forward to my on device TTS, but Amazon has a decent moat with the DRM on their Kindles. At least they'll have to remain somewhat competitive once consumers decide they want the AI audiobooks and the like. reply maxglute 14 hours agoprevAre there any decent TTS models that can be ran locally that plugs into existing software like SAPI without too much lag? reply dvt 12 hours agoparentBark and Tortoise work fairly well. Bark does super fast inference[1] on my M1. [1] https://github.com/SaladTechnologies/bark reply turnsout 12 hours agorootparent@dvt Is this just a containerized version of Bark? Wondering if this repo has M1-specific improvements. reply dvt 12 hours agorootparent> Is this just a containerized version of Bark I think so. reply turnsout 12 hours agorootparentI'm finding M1 generation quite slow (CPU-only) on the stock Bark—any tips on speeding it up? reply dvt 12 hours agorootparentSorry, haven't messed around too much with optimizations. I thought it was quite fast compared to Tortoise for example (where generation speed was at a 3:1 ratio). reply Nouser76 12 hours agoparentprevI've used coqui.ai's TTS models[0] and library[1] to great success. I was able to get cloned voice to be rendered in about 80% of the audio clip length, and I believe you can also stream the response. Do note the model license for XTTS, it is one they wrote themselves that has some restrictions. [0] https://huggingface.co/coqui/XTTS-v2 [1] https://github.com/coqui-ai/TTS reply modeless 12 hours agoparentprevXTTS has a streaming mode with ~300ms latency and sounds good, though it has hallucination issues. StyleTTS2 sounds good and doesn't hallucinate as much. It doesn't support streaming but it's fast so it can still respond quickly. But neither of them sound as good as Eleven Labs or OpenAI or this one. reply mrfakename 13 hours agoprevSadly they didn't release the code or models reply chankstein38 12 hours agoparentAgreed. It hardly feels worth even reading through the paper since, from my perspective, it may as well just be made up. I can also write \"Hey guys I made a good TTS it's really cool and great and the voices sound really natural\" and put some samples together. If I never release any code or models or anything, it may as well have not been published. reply Terretta 8 hours agorootparent> really cool and great ... and put some samples together There are samples on the page which demonstrate it completely failing. Now as to whether you'd make that up is 4D chess. reply echelon 12 hours agoparentprevThe value of this stuff is going to zero. Don't worry about it. Product over model. Models and weights are a race to the bottom. Everyone is doing it and competing on data efficiency, methodology, MOS, etc. Groups all over are releasing their data and weights. It doesn't matter if Amazon doesn't, other labs will do it to get ahead and to get attention. This is going to be entirely pedestrian within a year. ElevenLabs is not a unicorn. It's an early-forming bubble. reply CamperBob2 12 hours agoparentprevIt's for Your Own Good, don't you know reply chankstein38 12 hours agorootparentI'm so glad they are all so protective of my safety! Lord knows I'm a child incapable of controlling myself or having my own morals! /s reply nshm 12 hours agoprevErr, I deeply respect Amazon TTS team but this paper and synthesis is..... You publish the paper in 2024 and include YourTTS in your baselines to look better. Come on! There is XTTS2 around! Voice sounds robotic and plain. Most likely a lot of audiobooks in training data and less conversational speech. And dropping diffusion was not a great idea, voice is not crystal clear anymore, it is more like a telephony recording. reply thorum 10 hours agoparentxtts2 is great, but it looks like this model is probably more consistent with its output and has a better grasp of meaning in long texts. reply sebmellen 10 hours agoprevOpen question: does anyone know of a TTS model which can synchronize the output to an SRT or other subtitle file? reply zamadatix 10 hours agoparentTo answer directly first: I don't know of any model with this built in. To answer more generally: but it should be pretty straightforward to use any old TTS model, the subtitle timestamps, and set the according delay until the next subtitle change and get the same effect. The alternative (changing the speed of the generated voice) is also possible via the same method but the problem there, and the problem when directly driven by a model, is subtitles don't clue you in on when e.g. someone is talking slow or there was a pause in conversation so that subtitle staid up a little longer than a normal one. What you'd need to solve that is a model which takes both the video and the subtitle info, a bit more difficult. Of course it's also a question about what the end goal is. It's pretty rare to have significant subtitles but no audio so if the ultimate goal was e.g. changing a actor's voice you'd probably get much better results with an audio->audio model than a TTS->audio model. Likely similar kinds of stories for many other use cases. reply selcuka 9 hours agorootparent> Of course it's also a question about what the end goal is. It's pretty rare to have significant subtitles but no audio I think the question was about dubbing a movie in another language, using SRT files. reply sebmellen 9 hours agorootparentActually more about dubbing lectures! reply SparkyMcUnicorn 14 hours agoprev> ... capable of mimicking speaker characteristics with just a few seconds of reference audio ... we have decided against open-sourcing this model as a precautionary measure. Disappointed yet again. reply someplaceguy 11 hours agoparentSomeone should send the developers this audio recording I have of Jeff Bezos saying that he changed his mind and wants the model to be released as open-source. reply JanSt 12 hours agoprev [–] I would love an API for this.. any information on availability? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "BASE TTS is an advanced text-to-speech model trained on 100k hours of speech data.",
      "It combines a 1-billion-parameter autoregressive Transformer and a convolution-based decoder for high-quality and natural-sounding speech synthesis.",
      "The model's potential applications include improving user experiences and supporting under-resourced languages, but it will not be open-sourced to prevent misuse.",
      "The authors emphasize the importance of addressing biases and promoting inclusivity in voice products."
    ],
    "commentSummary": [
      "The development and use of text-to-speech (TTS) models for various applications are discussed, including the development of BASE TTS for individuals who have lost their ability to speak.",
      "Limitations and criticisms of other TTS systems such as MetaVoice-1B, StyleTTS2, and Whisper are highlighted, as well as issues related to running TTS systems on Apple silicon.",
      "The potential incorporation of emotions into AI-generated voices, the preference for TTS technology over voice actors in audiobooks, and ethical concerns of open-sourcing TTS models are addressed.",
      "The impact of AI-generated audiobooks on the industry, the value of AI audiobooks compared to eBooks and personalized voice assistants, and considerations of copyright implications are explored.",
      "The skepticism towards the effectiveness of TTS models, the competitiveness in the field, and the desire for a TTS model that synchronizes output with subtitles are discussed.",
      "The importance of choosing the right TTS model based on the end goal and disappointment over the lack of open-sourcing a model for dubbing lectures are highlighted."
    ],
    "points": 179,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1707937769
  }
]
