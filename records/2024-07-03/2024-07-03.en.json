[
  {
    "id": 40862865,
    "title": "I Received an AI Email",
    "originLink": "https://timharek.no/blog/i-received-an-ai-email",
    "originBody": "I received an AI email Published July 2, 2024 2 minutes read Yesterday, July 1st, I received an email from a \"Raymond\": Hey Tim, Enjoyed reading your post on revamping your homelab. It’s great to see your continuous improvement journey! Noticed you’re using Deno Fresh for your blog. Managing updates and deployments must be quite the task. I've built Wisp, a CMS that simplifies content management, perfect for your needs. Would love to hear your thoughts! Best, Raymond At first I thought this was from a reader, because of the first sentence, that happened to work on a CMS called Wisp. But something was off, since they saw that I used Deno Fresh for my blog I assumed that they must have dove a bit deeper before saying a CMS is \"perfect for your needs\". But if they had made an effort they could have found out that I use plaintext Markdown and that I enjoy that workflow because it's set up using CI/CD. I went to check out Wisp CMS and saw that it was headless CMS, alright. Then I went straight to their blog, and saw that the latest blogpost, from today July 2nd, was \"How I Use AI Agents to Send 1000 Personalized Email for Outreach\". And right there in the featured image of the post was almost excately the email I had received. And then I remembered one of the links from last month, a blogpost by Neven Mrgan: How it feels to get an AI email from a friend I don't think this is the one and the same, but there are similarities. If \"Raymond\" had made an effort to write this email and showed me how their CMS would solve something for my particilar blog, I would most likely checked it out with an open mind, but they didn't do that. And their blogpost starts of with: Have you ever received an email that felt so personalized, so tailored to your interests and experiences, that you couldn't help but be intrigued? What if I told you that email wasn't crafted by a human, but by an artificial intelligence (AI) agent? I don't really have words for this, but I dislike this. Another part of the post: I used AI agents to send out nearly 1,000 personalized emails to developers with public blogs on GitHub. Does this mean that I should private my GitHub-mirror to my personal blog, because this can become a common thing? I have removed my email from my GitHub-profile now, but they can probably get it from my Git-log anyway... Thanks Raymond, I hate spam. Tagged with #ai #thoughts 470 words Reply via email",
    "commentLink": "https://news.ycombinator.com/item?id=40862865",
    "commentBody": "I Received an AI Email (timharek.no)640 points by imadj 13 hours agohidepastfavorite514 comments ossyrial 10 hours agoThe author links to the somewhat dystopian blog where the email sender is quite proud of their work. Their words (or perhaps that of an LLM): > Could an AI agent craft compelling emails that would capture people's attention and drive engagement, all while maintaining a level of personalization that feels human? I decided to find out. > The real hurdle was ensuring the emails seemed genuinely personalized and not spammy. I knew that if recipients detected even a whiff of a generic, mass-produced message, they'd tune out immediately. > Incredibly, not a single recipient seemed to detect that the emails were AI-generated. https://www.wisp.blog/blog/how-i-use-ai-agents-to-send-1000-... The technical part surprised me: they string together multiple LLMs which do all the work. It's a shame the author's passions are directed towards AI slop-email spam, all for capturing attention and driving engagement. How much of our societal progress and collective thought and innovation has gone to capturing attention and driving up engagement, I wonder. reply thrance 8 hours agoparentI remember seeing a talk from Jonathan Blow where he made a comparison: in the 1960s top engineers worked for NASA and put a man on the moon in a decade, basically doing computations by hand. Today, we have super advanced computers and tech companies enjoy 100× times more of the top engineers than NASA ever had, and they are all working toward making you click on ads more. reply tim333 7 minutes agorootparent>they are all working toward making you click on ads more. Not all. Also men on Mars, AGI, Fusion etc. reply segmondy 7 hours agorootparentprevWhich do you think is more important? Putting man on the moon or ecommerce? I reckon you been able to get on a device, see a biscuit ads, order one from foo.com and have it shipped to you. Think of how much tech it takes for that to happen, that is more tech than NASA built to send many to the moon, the internet, packet switching, routing, fiber optic, distributed systems, web servers, web browsers, ads, cryptography, banking online, and so on and so forth. We love to trivialize what is common, but that clicking on an ad is not an easy problem. Clicking on ads has generated enormous wealth in the world which is now bootstrapping AGI. Clicking on ads helped with our goal to AI today. Showing you the right ad and beating those trying to game it is machine learning heavy. When was the first time we started seeing spelling correction and next word suggestions? It was in google search bar. To serve the correct ads and deal with spam? heavy NLP algorithms. If you stop and think of it, we can drop a think line from the current state of LLMs to these ads click you are talking about. reply digdugdirk 6 hours agorootparentIt took way too long to convince myself this wasn't satire. I still wish it wasn't. It made me realize that I think many computing people need more of a fundamental education in \"hard\" physics (statics, mechanics, thermodynamics, materials science) in order to better understand the staggering paradigm shift that occurred in our understanding of the world in the early 20th century. Maybe then they would appreciate how much of the world's resources have now been directed by the major capital players towards sucking the collective attention span of humanity into a small rectangular screen, and the potential impact of doing so. reply lukan 6 hours agorootparentprev\"Putting man on the moon or ecommerce\" The comparison here is between moonlanding and advertisement. So I choose the moon obviously. Ecommerce can work just the same without LLM augmented personalized ads, or no advertisement at all. If a law would ban all commercial advertisement - people still need to buy things. But who would miss the ads? reply ksynwa 6 hours agorootparentprevThey are clearly talking about one aspect of the industry which is the marketing part related to maximising engagement. It is not meant to be conflated with the e-commerce industry as a whole. reply Jgrubb 6 hours agorootparentprevThat last line kind of makes the point. Is any of that actually inspiring to a young child? reply runlaszlorun 4 hours agorootparent> Is any of that actually inspiring to a young child? I think the answer is pretty clear in the fact that so many of them, bluntly speaking, just don’t give a shit any more. I absolutely don’t blame them. reply thedevilslawyer 6 hours agorootparentprevIt sure as heck is inspiring to a critical thinking adult. There's been enormous value added to all world's citizens. reply commodoreboxer 5 hours agorootparentInteresting. In my experience, advertisement and the incentives around it have led to the most devastatingly widespread removal of value in human culture and social connections that we've seen in this generation. Huge amounts of effort wasted on harvesting attention, manipulating money away from people, isolating and fostering extremism, building a massive political divide. And centralizing wealth more and more. The amount of human effort wasted on advertisement is staggering and shocking. I don't think your average adult is inspired by the idea of AI generated advertisements. Probably a small bubble of people including timeshare salesmen. If advertisements were opt-in, I expect a single digit percentage of people would ever elect to see them. I don't understand how anybody can consider something like that a net good for the world. How does non-consensually harassing people into spending money on things that don't need add value to all the world's citizens? reply ryandrake 4 hours agorootparent\"Adding value\" and \"Generating wealth\" are always the vague euphemisms that these guys fall back to when they try to justify much of today's economic activity. Adding value for who? Generating whose wealth? The answer is usually \"people who are already wealthy.\" Of course, they'll downplay the massive funneling of wealth to these people, and instead point to the X number of people \"lifted out of poverty in the 20th century\" as if capitalism and commerce was the sole lifting force. I wish some of these people would think about how they'd explain to their 5 year old in an inspiring way what they do for a living: And not just \"I take JSON data from one layer in the API and convert it to protobufs in another layer of the API\" but the economic output of their jobs: \"Millions of wealthy companies give us money because we can divert 1 billion people's attention from their families and loved ones for about 500 milliseconds, 500 times a day. We take that money and give some of it to other wealthy companies and pocket the rest.\" reply mrtranscendence 3 hours agorootparentprev> If advertisements were opt-in, I expect a single digit percentage of people would ever elect to see them. I mean, you'd see the same thing if paying for your groceries were opt-in. Is that also a net bad for the world? Ads do enable the costless (or cost-reduced) provision of services that people would otherwise have to pay for. reply mostlysimilar 3 hours agorootparent> I mean, you'd see the same thing if paying for your groceries were opt-in. Is that seriously the comparison you want to make here? Most of us think the world would be better if you didn't have to pay for food, yes. reply commodoreboxer 2 hours agorootparentprevAds are not charity. There is clearly a cost, otherwise they would lose money. They do not generate money out of thin air. \"Generate\" and \"extract\" aren't synonyms. They do not enable any costless anything at all. They obfuscate extraction of money to make it look costless, but actually end up extracting significant amounts of money from people. Ad folks whitewash it to make it sound good, but extracting money in roundabout ways is not creating value. reply raxxorraxor 3 hours agorootparentprevI think this is a rationalization of an enormous waste of work. The effects generating wealth are indirect. In that regard you could argue that betting is generating wealth too. Advertising is like a hamster wheel people have to jump onto if they want their place in the market. A similar amount of wealth would be generated if every advertised product would be represented by a text description, but we have a race to the bottom. There is advertising and advertising of course but most of advertising is incredibly toxic and I would argue that by capturing attention, it is a huge economic drain as well. Of course an AI would also be quite apt at removing unwanted ads, which I believe will become a reality quite soon. reply mlyle 2 hours agorootparent> A similar amount of wealth would be generated if every advertised product would be represented by a text description, but we have a race to the bottom. I fear statements like this go too far. I can't agree with the first part of this sentence. I feel this about both marketing and finance: They are valuable fields. There are huge amounts of activity in these fields that offer value to everyone. Removing friction on commerce and the activities that parties take in self-interest to produce a market or financial system are essential to the verdant world we live in. And yet, they're arms races that can go seemingly-infinitely far. Beyond any generation of societal value. Beyond needless consumption of intellect and resources. All the way to actual negative impacts that clutter the financial world or the ability to communicate effectively in the market. reply swat535 3 hours agorootparentprev> enormous value added to all worlds citizens This is quite a statement to make. Please elaborate on what enormous value has spam ads and marketing emails added to _world_ citizens? Unless of course by “world” you mean Silicon Valley venture capitalists.. reply batch12 6 hours agorootparentprevMarketing manipulation and spam is less important. reply mxkopy 6 hours agorootparentprevIn the grand scheme, what you’re talking about is very zero-sum, while stuff like making rockets is not. Uber vs Waymo is a good example of how adtech can only go so far in actually creating wealth. reply commodoreboxer 6 hours agorootparentprevI keep hearing the phrase \"generate wealth\" in regards to advertisement and from the mouths of startup founders, but in almost no other context. I'm not familiar with the economic concept of \"wealth generation\" or its cousin \"creating value\". Is the idea that any and all movement of money is virtuous? That all economic activity is good, and therefore anything that leads to more economic activity is also good? Or is it what it sounds like, and it just means \"making some specific people very wealthy\"? Wouldn't the more accurate wording be that it \"concentrates wealth\"? I don't see a huge difference in the economic output of advertisement from most other scams. A ponzi scheme also uses psychological tricks to move money from a large amount of people to a small amount of people. Something getting people to spend money isn't inherently a good thing. reply runlaszlorun 4 hours agorootparent> Is the idea that any and all movement of money is virtuous? Maybe this was your point, but this is built in to one of the definitions of GDP, isn’t it? Money supply times velocity of money? I’m no economist though I’m sure there are folks on here who are. But this seems like an unfortunate fact that’s built into our system- that as laypeople we tend to assume that ‘economic growth’ means an increase in the material aspects of our life. Which in itself is a debatable goal, but our GDP perspective means even this is questionable. For example, take a family of five living out in a relatively rural area. In scenario one, both parents work good paying remote tech jobs and meals, childcare, maintenance of land and housing, etc. are all outsourced. This scenario contrubutes a lot according to our economic definitions of GDP. And provides many opportunities for government to tax and companies to earn a share of these money flows. Then take scenario 2, you take the same family but they’re living off of the grid as much as possible, raising or growing nearly all their own food, parents are providing whatever education there is, etc. In this scenario, the measurable economic activity is close to zero- even if the material situation could be quite similar. Not to mention quality of life might be rated far higher by many. What rating an economy by the flow of its money does do is, and I’m not sure if this is at all intentional, is it does paint a picture of what money flows are potentially capturable either by government taxation or by companies trying to grab some percentage as revenue. It’s a lot harder to get a share of money that isn’t there and/or not moving around. Perhaps my take on economics is off base but, for me, seeing this made me realize just how far off our system is from what it could and should be. reply commodoreboxer 2 hours agorootparentGDP is a measure. I'm very much not an economist, but I am extremely skeptical that the health of an economy can be reduced to any single number. Goodheart's law and all. I concede that GDP is a good indicator, but I think you can have things that help GDP while simultaneously hurting the economy. Otherwise any scam or con would be considered beneficial, and it would make sense to mandate minimum individual spending to ensure economic activity. A low GDP inherently shows poor economic health, but a high GDP does not guarantee good health. In my mind (noting, again, that I'm no economist), economic health is defined by the effectiveness of allocating resources to things that are beneficial to the members of that economy. Any amount of GDP can be \"waste\", resources flowing to places where they do not benefit the public. As Robert Kennedy famously pointed out, GDP includes money spent on addictive and harmful drugs, polluting industries, and many other ventures that are actively harmful.[0] [0]: https://youtube.com/watch?v=3FAmr1la6w0 reply pixl97 1 hour agorootparentGoing back to the previous posters monetary velocity statement, if you have a trillion dollar GDP, but it's just two AI's bouncing money back and forth high speed while all the humans starve in the street your economy is \"great\" and totally awful at the same time. The one number has to be referenced against others like wealth inequality. reply cooolbear 2 hours agorootparentprev\"Generate wealth\" means \"make somebody's number go up\" i.e. allocating real resources/capital somewhere, with the assumption that 1. allocating that capital creates a net boon for society and 2. those who have \"generated wealth\" are wise and competent investors/leaders and their investments will create a net boon elsewhere. The first point is probably not especially true very often in contemporary tech (other than 'job creation') and is arguably not true for advertisement. The second point is not really a given at all and seems to be pretty consistently shown otherwise. reply echelon 7 hours agorootparentprevJust wait. Enough of us will get pissed off that we will develop AI agents that sit between us and the internet. A sufficiently advanced personal assistant AI would use multimodal capabilities to classify spam in all of its forms: - Marketing emails - YouTube sponsorship clips - Banner ads - Google search ads - Actual human salespeople - ... It would identify and remove all instances of this from our daily lives. Furthermore, we could probably use it to remove most of the worst parts of the internet too: - Clickbait - Trolling - Rage content I'm actually really looking forward to this. As long as we can get this agent into all of the panes of glass (Google will fight to prevent this), we will win. We just need it to sit between us and everything else. reply madamelic 7 hours agorootparent> Enough of us will get pissed off that we will develop AI agents that sit between us and the internet. Until _that_ company gets overrun by MBAs who are profit-driven then they start injecting ads into the results. It will come in the vein of \"we are personalizing the output and improving responses by linking you with vendors that will solve your problems\". reply mostlysimilar 3 hours agorootparent> Until _that_ company gets overrun by MBAs who are profit-driven then they start injecting ads into the results. Found companies with people that share your values. Hire people that share your values. Reject the vampires. Build things for people. reply pixl97 1 hour agorootparentUnfortunately it turns out that at the end of the day one of the most common values is the love of massive piles of money. Vampires don't catch on fire in sunlight like storybook villains, they will invite themselves in, sidle up beside you, and be your best friend. Then in the moment you are weak they will plunge their fangs in. Competing with bad actors is very, very hard. They will be fat with investor money, they will give their services away, and commonly they are not afraid to do things like DDOS to raise your costs of operations. reply echelon 7 hours agorootparentprevThere will be a uBlock Origin for that. reply Bluecobra 6 hours agorootparentprevI get what you are saying but what is the end result when someone is so shielded from the outside when they decide to block everything that irks them and stuck in an echo chamber? What if the user is a conservative voter and considers anything counterpoint to their world view the worst part of the internet and removes all instances of it from their daily lives? Not to say that isn’t already happening but they are consciously making the choice, not some AI bot. I can see something like this making the country even more polarized. reply echelon 5 hours agorootparentSame as it ever was. Growing up as a southern evangelical before the internet, I can promise you that there has never been a modern world without filter bubbles. The concept of \"fake news\" is not new, either. There has been general distrust of opposing ideas and institutions for as long as I've been alive. And there's an entire publishing and media ecosystem for every single ideology you can imagine: 700 Club, Abeka, etc. Again, this all predates the internet. It's not going anywhere. The danger isn't strictly censorship or filter bubbles. It's not having a choice or control over your own destiny. These decisions need to be first class and conscious. Also, a sure fire way to rile up the \"other team\" is to say you're going to soften, limit, or block their world view. The brain has so many defenses against this. It's not the way to change minds. If you want to win people over, you have to do the hard, almost individual work, of respecting them and sharing how you feel. That's a hard, uphill battle because you're attempting to create a new slope in a steep gradient to get them to see your perspective. Angering, making fun, or disrespecting is just flying headfirst into that mountain. It might make you feel good, but it undoes any progress anyone else has made. reply the__alchemist 6 hours agorootparentprevThis was present in the book Fall;, or, Dodge in Hell. (Published in 2019; takes place in the near future) Everyone had a personal AI assistant as you describe to curate the internet. A big part of the motivation was to filter the spam. A secondary affect was that the internet was even further divided into echo chambers. reply sandworm101 8 hours agorootparentprevSomeone decided that marketing is now a tech problem. Artists have been replaced by software engineers. The net result is creepy AI emails. I fell for oldschool marketing yesterday. Im moving into a new appartment in a couple months. The local ISP who runs fiber in my new building cold-called me. I agreed over the phone to setup the service. That was proper target marketing. The person who called me knew the situation and identified me as a very likely customer with a need for service (the building has a relationship with the ISP). I would never have responded to an email or any wiff of AI chatbot. They only made the sale because of expensive human effort. reply loa_in_ 6 hours agorootparentIt's the tech that put you on a queue to be called reply sandworm101 6 hours agorootparentThere was no tech here. My new landlord contacted the local ISP, the one they liked to work with, to say they had a new tenant arriving soon. I'd bet that my connection will have been setup long before I arrive, at a time convenient to the landlord and local provider. A landlord recommending a favored local vendor to a tenant, or a tenant to a vendor, is the sort of human relationship that predates electricity. reply pseudalopex 7 hours agorootparentprevSales people were never artists. Cold calling is not art. reply paxys 7 hours agorootparentprevAnd yet someone is building all those super advanced computers and AI models. Someone is launching reusable rockets into space. Someone is building mRNA vaccines and F1 cars and humanoid robots and more efficient solar panels. The \"smart people are all working in advertising\" trope is idiotic. Just an excuse for people to justify their own laziness. There is an infinite number of opportunities out there to make the world better. If you are ignoring them, that's on you. reply runlaszlorun 4 hours agorootparent> And yet someone is building all those super advanced computers and AI models. Someone is launching reusable rockets into space. Someone is building mRNA vaccines and F1 cars and humanoid robots and more efficient solar panels. Which is true. But clearly far fewer people work doing that than in advertising or some other seemingly meaningless grunt work. And I’m including the technological plumbling work with many on this site, myself included, have depended upon to support themselves and/or a family. Which at best is effectively doing minor lubrication of a large and hard to comprehend system that doesn’t seem to have put society as a whole in a particularly great place. reply aswegs8 6 hours agorootparentprevFinancial incentives, huh? reply bamboozled 7 hours agorootparentprevIt’s as if real issues like climate change aren’t a thing that needs solving… reply otherme123 10 hours agoparentprevThe guy writes a post about how to send spam effectively, and then offers the subscription link in the end with \"Promise we won't spam you\". Yes, I totally trust you... reply CoastalCoder 9 hours agorootparentIt sounds like extortion. \"I'm sending spam that sneaks past your spam filter. Sign up to make it stop.\" reply mns 9 hours agoparentprevI keep seeing these posts on HN and thinking, man, these are some smart people. Training LLMs, doing all this amazing AI stuff like this guy with the email agents and the other guy with the dropping of hats, and then I open the posts and it's just some guy making API requests to OpenAI or some similar disappointment. reply biztos 7 hours agorootparentWhen “altcoins” took off I spent a while racking my brain trying to figure out what special tech I could offer, how I could build my own blockchain, incentivize miners… When I realized it was just dudes copy-pasting a “smart contract” and then doing super shady marketing, it was already illegal in my jurisdiction. reply brabel 8 hours agorootparentprevNowadays, an \"AI Expert\" is someone who knows how to download an AI client lib and prompt the AI to perform tasks. These are people who are not even technical and have no idea how all this works, but they can at least follow a Youtube Tutorial to get a basic website working. reply paulluuk 7 hours agorootparentAs someone who actually has a university degree in Artificial Intelligence, I feel like this is always how it's been. Before, an \"AI Expert\" was someone who knew how to use Tensorflow, PyTorch or Keras. Before that, an \"AI Expert\" was someone who knew how to write a Monte Carlo simulation, etc etc. You could of course say the same for frontend engineer or backend engineers. How many frontend engineers are simply importing Tailwind, React, etc? How many backend engineers are simply importing apache packages? Where do you draw the line? Can you only be an AI expert if you stick to non-LLM solutions? Or are AI experts the people who have access to hundreds of millions of USD to train their own LLMs? Who are the real AI experts? reply internet101010 7 hours agorootparentI would liken it to cars. There is a difference between engineers, mechanics, and mechanics that know a certain car so well that they fabricate parts that improve upon the original design. reply aswegs8 6 hours agorootparentGood comparison. Engineers who build cars and understand their intricacies oftentimes just work on one small thing at a time, even in teams. Like a team just working on breaks. The mechanics can piece the stuff together and keep it working in a real world setting. But nowadays a self-declared \"AI Expert\" in that metaphor might be just some person who knows how to drive a car. reply jtbayly 6 hours agorootparentI used to work on breaks, but then I realized I was more productive when I actually stopped and walked around a bit. reply the_cat_kittles 6 hours agorootparentprevi draw the line at people claiming to be experts in something they have only done for a year reply macocha 8 hours agorootparentprevAlso in most cases they were a \"crypto expert\" just two months ago. reply ryandrake 4 hours agorootparentAnd they were a leadgen/SEO expert a few years ago. These technogrifters just move from one hot topic to the next trying to make whatever buck they can smooth talk people into giving them. reply jtbayly 6 hours agorootparentprevSomeone who can get a website working is actually technical. reply shzhdbi09gv8ioi 7 hours agorootparentprevBusiness as usual iow. Used to be scrum masters, then javascript \"experts\", then crypto bros. Snake oil salesmen we called em back in my day ;-) reply mattgreenrocks 6 hours agorootparentprevIt’s more about being on the front of the hype train and being endlessly positive versus competence. reply thih9 5 hours agorootparentI can't see this working long term though. Being endlessly positive and ignoring your actual competence sounds like a recipe to eventually bite off more than you can chew. reply mattgreenrocks 4 hours agorootparentOftentimes this is fervor is channeled into personal brand building, which rarely has any sort of feedback mechanism that is tied to actual competence. It's a calculated move on their part. reply thih9 2 hours agorootparentBrand building actually sounds good and productive to me, as long as it doesn’t approach fraud. If your audience likes your brand and doesn’t distinguish between your services and services done by more competent providers, then you’ve found your niche. So: snake oil is not fine; but Supreme branded brick sounds ok to me, even if I wouldn’t buy it myself. I guess the author will find followers who enjoy that approach to software and product growth. If spamming wasn’t part of it, I’d be ok. reply londons_explore 10 hours agoparentprev> > Incredibly, not a single recipient seemed to detect that the emails were AI-generated. Of the people who replied. I bet plenty figured it out, but didn't bother to reply. reply Lio 8 hours agorootparentExpect to see someone else write a blog post on How I Used AI to fool an AI Spammer ...of course they'd probably get an LLM to write the article too. reply tsukikage 9 hours agoparentprevThis process should not require a human in the loop. Consider: * spammers have access to large amounts of compute via their botnets * the effectiveness of any particular spam message can easily be measured - it is simply the quantity of funds arriving at the cryptocurrency wallet tied to that message within some time window So, just complete the cycle: LLM to generate prompts, another to generate messages, send out a large batch, wait some hours, kick off a round of training based on the feedback signals received; rinse, lather, repeat, entirely unattended. This is how we /really/ get AI foom: not in a FAANG lab but in a spammer's basement. reply FeepingCreature 8 hours agorootparentAt least one sci-fi novel iirc had an AI spam filter achieve sentience, because the task basically amounted to contrastive-learning a model of humanity. reply biztos 7 hours agorootparentHaving worked in the field, I think you’re more likely to achieve AGI by intelligently watering tomatoes in a hothouse. reply russnewcomer 7 hours agorootparentprevThat’s one of Peter Watt’s Rifters trilogy, I think maybe the second one? Been a few years since I read them. I think it’s a biological neural net, not an Ai per se. Lots of big ideas in those books, but not a lot of optimism and some rough stuff. reply Bluestein 8 hours agorootparentprevVery well could be. Seconded. After all, it could very well become one of the largest vehicles for \"mass training\", ever ... PS. Howerver, see comments downthread about \"survivorship bias\". Not everybody will reply, so biases will exist.- reply taurath 8 hours agoparentprevThis is sort of why I feel somewhat pessimistic about AI - the inevitable most profitable usecases being so bad in aggregate for a society with almost no bounds or values other than profit. It will never be easier to waste peoples attention. reply yard2010 8 hours agorootparentThis is not a problem with AI but with a system in which there are no other values other than \"make the most money fast\". reply throwaway7ahgb 6 hours agorootparent\"No other values\"? When and how is such Doomer Hyperbole getting into HN articles? This is half of major reddit subs now and I fear the same low quality comments will take over HN. People need to go out and touch some grass. reply fl0id 6 hours agorootparentor maybe you need to touch some grass. reply runlaszlorun 4 hours agorootparentI need some grass. reply highspeedbus 8 hours agoparentprevThings I wish become taboo: Admitting to use AI content. Everyone is so comfortable doing shit like this. reply rpgwaiter 8 hours agorootparentI much prefer admission to hiding it. It lets you easily see who doesn’t deserve your time reply jacobgkau 8 hours agorootparentWhile that might work great on the individual level for a little while, it's unfortunately not how normalized taboos seem to work long-term. You're just going to see more and more people who don't deserve your time until you're wanting for anyone who actually does. reply daemin 7 hours agorootparentThis has been mentioned before, but I can see the benefit in having curated webrings and similar listings. Where people can verify the content is not LLM generated. reply ryandrake 4 hours agorootparentAs soon as that becomes effective, you'll have dozens of SEO sites and experts giving seminars on \"How to get your LLM-generated website into curated webrings.\" An entire cottage industry will spring up for the purposes of corrupting legitimate webrings and/or creating fake astroturf webrings that claim to be curated. reply pixl97 1 hour agorootparentOh, what about the petty fights between different webrings accusing each other of using AI generated content.... Reminds me of the early days of the web. reply beezlebroxxxxxx 7 hours agorootparentprev> You're just going to see more and more people who don't deserve your time until you're wanting for anyone who actually does. I can see it, perhaps positively, investing far less importance and effort into online things. With admittedly a lot of optimism, I could see it leading to a resurgent arts and crafts movement, or a renewed importance put on hand-made things. People say \"touch grass\"; maybe AI will make people \"touch crafts\" (bad joke, I know). reply yard2010 8 hours agorootparentprevThat's boasting, not admission reply BoxOfRain 7 hours agorootparentprevI think it depends on the context. I think there's artistic cases for it, for example I've played around with using AI tools to extract speech from its background music for use in further (non AI-based) music which I don't think is an unethical thing to do. reply __loam 7 hours agorootparentprevIt's already like this for creative communities in things like illustration and writing. You will (rightly) get ostracized and blocked by your peers for using AI. It's a signal for poor quality for most people in those spaces. Definitely interesting to see the different culture in tech and programming since programmers are so used to sharing code with things like open source. I think programmers should be more skeptical about this bullshit, but one could make the argument that having a more flexible view of intellectual property is more computer native since computers are really just copying machines. Imo, we need to have a conversation about skills development because while art and writing accept that doing the work is how you get better, duplicating knowledge by hand in programming can be seen as a waste of time. We should really push back on that attitude though or we'll end up with a glut of people in the industry who don't understand what's under all the abstractions. reply cornholio 9 hours agoparentprevNews at 11, spammers use sophisticated techniques to increase the profitability of spam. This is absolutely shocking and never before seen, what is the world coming to. In all seriousness, manipulation and bullshit generation emerges as the single major real world use of AI. It's not good enough yet to solve the big problems of the world: medical diagnostic, auto accidents, hunger. Maybe just a somewhat better search tool, maybe a better converational e-learning tool, barely a better Intellisense. But, by God, is it fantastic at creating Reddit and X bots that amplify the current line of Chinese and Russian propaganda, upvote and argue among themselves on absurd topics to shittify any real discussion and so on. reply brabel 8 hours agorootparent> X bots that amplify the current line of Chinese and Russian propaganda... Do you think those countries are the only ones doing this? Just the other day there was a scandal about one of the biggest Swedish parties, one that's in the government coalition, doing exactly this. And that's just one that got caught. In countries like India and Brazil online disinformation has become an enormous problem, and I think that in the USA and Europe, as the old Soviet joke went: \"Their propaganda is so good their people even believe they don't have any\". reply CoastalCoder 9 hours agorootparentprevI don't think this is unique to this specific technology. People can be both wonderful and despicable, regardless of era or mechanism. reply cornholio 9 hours agorootparentSure, but I'm talking about the good:bad ratio of some creations. I really have strong hope for AI, and that we won't regard it in retrospect like the multi-stage thermonuclear device, the landmine or tetraethyl lead additives. reply squigz 8 hours agorootparentNot to dismiss any of the negative aspects of \"AI\", but it seems utterly foolish to compare it to those 3 things. reply orbitmode 8 hours agorootparentIn May reports emerged of this suicide by a young man in Australia - not AI related. https://www.barefootinvestor.com/articles/this-is-the-hardes... The following month, reports emerged of 50 girls in one Australian school being exploited in very similar ways by nothing more than a kid with a prompter. https://www.abc.net.au/news/2024-06-25/explicit-ai-deepfakes... Scaling this type of exploitation of children online is trivial when you think about anyone with basic programming skills. The Techno Optimists manifesto is what appears to be utterly foolish to me when you figure out that there is not one mention of accountability for downside consequences. reply CoastalCoder 9 hours agorootparentprevI hope you're right. I'm less optimistic. reply thih9 6 hours agoparentprevAlso from that blog post: > As founder, I'm always exploring innovative ways to scale my business operations. While this is similar to what other founders are doing, the automation, scale and the email focus puts it closer to spam in my book. reply suoduandao3 7 hours agoparentprevI do believe that commodified attention is the most logical currency of a postascarce society, so best case... quite a lot. Note my 'best case' scenario for the near future is pretty upsetting. reply mihaaly 8 hours agoparentprevIt is not only that too much is wasted on superficial nothing instead of choosing to make something with essence and benefitial for the society but it is sucking away those minds engaged in really useful things. reply joelthelion 7 hours agoparentprev> The technical part surprised me: they string together multiple LLMs which do all the work. It's a shame the author's passions are directed towards AI slop-email spam, all for capturing attention and driving engagement. In defence of that guy, he's only doing it because he knows it's what pays the bills. If we want things to change, we need to fix the system so that genuine social advancement is what's rewarded, not spam and scams. Not an easy task, unfortunately. reply PlusAddressing 9 hours agoparentprevFunny how they're self assured no one whiffed their AI bullshit. This is survivorship bias, he's looking only at all the planes that came back to port. The people who did - they just didn't reply. He can't prompt them. reply kuhewa 9 hours agorootparentWhen you spend $200 on spamming people you need to believe it was effective reply Bluestein 8 hours agorootparentprevThe planes coming back from the bombing raids in WWII come to mind.- reply nojvek 1 hour agoparentprev> How much of our societal progress and collective thought and innovation has gone to capturing attention and driving up engagement, I wonder. Facebook + Instagram is $100B+ business, So is Youtube and Ads. An average human now spends about ~3h per day on their screens, most of it on social media. We are dopamine driven beings. Capturing attention and driving up engagement is one of the biggest part of our economy. reply lkdfjlkdfjlg 8 hours agoparentprev> It's a shame the author's passions are directed to (...) Now do Google. reply Waterluvian 7 hours agoparentprevI’m unsurprised to see a lot of very shallow usage of AI. Most users don’t have a real use case for the tool. reply taylorius 11 hours agoprevThe future - megawatts of electricity being used, 24/7 as armies of LLMs email and debate each other, and try to sell each other programs at a great discount. As for the humans, we went fishing instead. reply tiew9Vii 9 hours agoparentThe irony Everyone is playing lip service to global warming, energy efficiency, reducing emissions. At the same time data centers are being filled with power hungry graphic cards and hardware to predict if showing a customer an ad will get a clock, generating spam that “engages” users aka clicks. It’s like living in a episode of black mirror. reply squigz 8 hours agorootparentThere's no irony or contradiction here. Some people are worried about climate change. Some aren't. Silly, yes, but I don't see the irony. reply jacobgkau 8 hours agorootparentThe irony is that there seems to be overlap between the two groups-- e.g. highly educated tech workers. reply squigz 8 hours agorootparentIs there? How are you making that determination? reply tharkun__ 7 hours agorootparentI would tend to agree with them even without actual data. Just probabilistically there is likely some overlap. Whether there's enough for calling it irony is probably a different question. reply squigz 7 hours agorootparentWell fair enough. reply sxv 7 hours agorootparentprevi.e. investment bankers in hoodies reply lukan 6 hours agorootparentprevI see the bright side, the tech for large scale computing gets mass produced - so all the legit use cases, like scientific simulations, or LLM for productive work, also profit. And if one really bright day humanity evolves beyound the current statd of ad driven everything, we can put all of it to use for real. Till then, I will probably avoid more and more communicating with strangers on the internet. It will get even more exhausting, when 99% of them are fake. reply k8sagic 9 hours agorootparentprevI disagree. Datacenters save a lot more energy than they make. Alone how much co2 is saved when i can do my banking online instead of having to drive to a bank is significant. The same with a ton of ohter daily things i do. Is video producing co2? yes. But you know what creates a lot more co2? Driving around for entertainment. And the companies running those GPUs actually have an incentive to be co2 neutral while bitcoin miners don't: They 1. already said they are doing / going co2 neutral due to 2. marketing and they will achieve it becauseh 3. they have the money to do so. When someone like Bill Gates or Suckerberg say 'lets build a nuclear power plant for AGI' than they will actually just do that. reply croes 9 hours agorootparent>Is video producing co2? yes. But you know what creates a lot more co2? Driving around for entertainment What's more likely, watching a movie online, drive to watch a movie in a cinema? You know what creates a lot less CO2? Staying at home reading a book vor playing a board game. >Datacenters save a lot more energy than they make I think you mean CO2. And I doubt that they actually save anything because datacenters are convenient so we use them more as alternatives with less convenience. Like the movie example, we watch more and even bad movies if it's just a click on Netflix than we do if we have to drive somewhere to watch. MS recently announced they fail der CO2 target but instead produce 40% more because of cloud services like AI reply k8sagic 8 hours agorootparentHave you checked how much co2 a normal car drive creates vs. watching a movie online? We need to be realistic here. We know what modern entertainment looks like and its not realistic at all to just 'read books' and play board games. reply commodoreboxer 6 hours agorootparentIt is 100% realistic to read books and play board games. Both markets are massive, and board games in particular are having what I would consider a renaissance. Maybe it depends on your crowd, but everybody I know plays tabletop games and reads books. reply mrtranscendence 3 hours agorootparentYou're missing the point. What's not realistic is to tell everyone that they should abstain from any type of entertainment that requires power (TV shows, movies, video games, etc) and should only read books and play board games instead. I don't care what kind of renaissance board games are undergoing, most people still only play the mass market classics, and then only rarely. I don't know how much energy Netflix uses serving a movie, but playing a video game on my PC for two hours where I'm located might generate a kg of CO2. That's about as much as I'll breathe in a day. Relative to other sources of atmospheric CO2 I'm not that concerned. reply commodoreboxer 1 hour agorootparentMy issue was with \"we know what modern entertainment looks like\" as if humans are now incapable of enjoying themselves without a screen. And you should care about a massive market increase when it's directly relevant to the point at hand. If the initial point was \"we know what modern entertainment looks like, nobody plays board games or reads books\", pointing out that the board game market has more than doubled in the past decade is far from irrelevant. It actually directly counters the point. I agree with your second paragraph, and selling the \"make better choices to save the world\" argument is an industry playbook favorite. Environmental damage needs to be put on the shoulders of those who cause it, which is overwhelmingly industrial actors. AI is not useful enough to continue the slide into burning more fossil fuels than ever. If it spurs more green energy, good. If it's the old \"well this is the way things are now\", that's really not good enough. reply quassy 9 hours agorootparentprevPoint 1, 2 and 3 all apply to miners as well and yet they never delivered on their promise. reply k8sagic 8 hours agorootparentThe normal miners never said that. They just say this at conferences for simple greenwashing. The normal miner doesn't go to those bitcoin conferences, they buy asics, put them in some warehouses around the world and make money. reply fattegourmet 8 hours agorootparentprev> how much co2 is saved when i can do my banking online instead of having to drive to a bank is significant. And if the online bank wasn't sending a bunch of requests to a bunch of third party ad networks on every click, it would save even more. reply k8sagic 8 hours agorootparentYes. But what are you implying? Entertainment + ad garbage still is a lot more co2 efficient than printing flyers and sending those out. reply happyraul 5 hours agorootparentprevThis is a very limited perspective. There are many parts of the world not beholden to automobiles for transportation. Where I live, I can walk to the bank, and walk or ride a bike to entertainment. The alternative to data centers does not have to be driving an automobile somewhere. reply austinjp 8 hours agorootparentprevI think it's more nuanced than that. I used to walk to my bank, I can't do that any more because many branches closed. The bank now directs all interactions to happen via their app. In terms of emissions (and social interaction, particularly for vulnerable and isolated members of society) I think this is bad news. But this is a complex calculus and - frankly - feels like a distraction from the issue. I don't want to get into the weeds of calculating micro-emissions of daily activities, I want climate responsibility and reduction in energy consumption across the board. reply yard2010 7 hours agorootparentprevDon't even get me started with the rant about taking planes. reply sph 11 hours agoparentprevPeople cry about Bitcoin's energy usage now, imagine the amount of energy burned to create next-level spam with \"AI\". Flame me all you want, but this is one case where Bitcoin is much more useful than LLM. If it doesn't create value, as its naysayers claim, at least it allows exchanging value. LLMs on the other hand, burn electricity to actively destroy the Internet's value, for the profit of inept and greedy drones. reply rpigab 9 hours agorootparentYes, that's quite right. That's why I created EtherGPT, an LLM Chat agent that runs decentralized in the Ether blockchain, on smart contracts only, to make sure that value is created and rewards directly the people and not big companies. By providing it just a fraction of just a bit north of 10% of the current fusion reactions occuring in our sun, and giving it a decade or two on processing time and sync, you can ask it simple questions like \"what do dogs do when you're not around\" and it will come up with helpful answers like \"they go to work in an office\" or funny ones like \"you should park your car in direct sunlight so that your dog can recharge its phone using solar panels\". reply noman-land 9 hours agorootparentI'm an Ethereum fan and I found this funny. reply mionhe 9 hours agorootparentprevAnother AI response, or humor from an actual person? reply waciki 7 hours agorootparentare LLMs even capable of humor? The attempts I've seen are not very funny reply meiraleal 7 hours agorootparentSomething must be very wrong with someone who continuously laughs at computer jokes so I don't think it will ever reach the level you are expecting (hopefully). reply throwaway0665 11 hours agorootparentprevBitcoin has one application where as there are multiple applications of LLMs. There might be mountains of noxious AI spam but it's hard to claim that Bitcoin as a technology is more useful. reply freehorse 9 hours agorootparentIt is not about the quantity of the applications, but about the value they bring to society. If it is about spamming and advertising we are even talking about negative value, actually. reply yazantapuz 7 hours agorootparentprevWell, a friend of mine built its house thanks to btc last's ath. Surely someone is cashing out nvidia right now. Indirectly useful :) reply bbarnett 9 hours agorootparentprevSo far, I haven't seen a useful application of LLMs. So far. I've seen things that are wildly hobbled, and wildly inaccurate. I've seen endless companies running around, trying to improve on things. I've seen people looking in wonder at LLMs making mistakes 2 year olds don't. Most LLM usage seems to be in two categories. Replace people's jobs with wildly inaccurate and massively broken output, or trick people into doing things. I'd have to say Bitcoin is far more useful than LLMs. You have to add the pluses, and subtract the minuses, and in that view, LLMs are -1 billion, and bitcoin is maybe a 1 or 2. reply k8sagic 9 hours agorootparentAI is not just LLMs. AlphaFold for example moved a critical goal post for everyone of us. bitcoin is only negative. It consumes terrawatts of energy for nothing. reply HermanMartinus 9 hours agorootparentAnd even if it were just LLMs, I use LLMs in my workflow every single day, and I've never used a/the blockchain except for some mild speculation around 2017. reply Tainnor 6 hours agorootparentprevI'm as skeptical about LLMs as anyone, especially when people use them for actual precision tasks (like coding), but what they actually IMHO are good at are language tasks. That is, summarising content, text generation for sufficiently formulaic tasks, even translation to an extent, and similar things. reply brabel 8 hours agorootparentprev> So far, I haven't seen a useful application of LLMs. So far. What?! Whole industries have been changed already due to products based on them. I don't think there's a single developer who is not using AI to get help while coding, and if you aren't, sorry but you're just missing out, it's not perfect but it doesn't need to be. It just needs to be better than StackOverflow and googling around for the docs or how to do things and ending up in dubious sites, and it absolutely is. My wife is a researcher and has to read LOTS of papers. Letting AI summarize it has made her enormously more efficient at filtering out what she needs to go into more detail. Generating relevant images for blog posts is now so easy to do (you may not like it, but as an author who used to use irrelevant photos before instead, I love it when you use it tastefully). Seriously, I can't even believe someone in 2024 can say there has not been useful applications of LLMs (almost all AI now is based on LLMs as far as I know) with a straight face. reply pseudalopex 7 hours agorootparent> I don't think there's a single developer who is not using AI to get help while coding You are in a bubble. > It just needs to be better than StackOverflow and googling around for the docs or how to do things and ending up in dubious sites, and it absolutely is. Subjectively. Not absolutely. reply commodoreboxer 5 hours agorootparentprev> I don't think there's a single developer who is not using AI to get help while coding It's banned at my company due to copyright concerns. Company policy at the moment considers it a copyright landmine. It does need to be \"perfect\" at not being a legal liability at the very least. And the blog post image thing is not a great point. AI images for blog posts, on the whole, are still quite terrible and immediately recognizable as AI generated slop. I usually click out of articles immediately when I see an AI image at the top, because I expect the rest of the article to be in line: low value, high fluff. There are useful LLM applications, but for things that play to its strengths. It's effectively a search engine. Using it for search and summarization is useful. Using it to generate code based on code it has read would be useful if it weren't for the copyright liability, and I would argue that if you have that much boilerplate, the answer is better abstractions, libraries, and frameworks, rather than just generating that code stochastically. Imagine if the answer to assembly language being verbose was to just generate all of it rather than creating compiled programming languages. reply whiplash451 9 hours agorootparentprevThere is one clear (albeit somewhat boring) application of LLM: data extraction from structured documents. That field has made a leap forward with LLMs. Positive impact on society includes automated extraction in healthcare pipelines. reply bbarnett 8 hours agorootparentHealthcare pipelines! All well and good until hallucinations cause death or what not! And why is this better than employing a human. Or reducing complexity. It's not as if human wages are what causes hyper expensive US healthcare costs. This seems like a negative. reply whiplash451 8 hours agorootparentRight now there is no human, the data just goes nowhere (i.e. it is not used). At some point we need to be optimistic and look for incremental progress. reply immibis 9 hours agorootparentprevUnstructured* reply whiplash451 9 hours agorootparentNo, I really meant structured. Extracting data from structured documents is surprisingly hard when you need very high accuracy. What I mean by structured is: invoices, documents containing tables, etc. Extracting useful data from fully unstructured content is very hard IMO and potentially above the capacity of LLMs (depending on your definition of \"useful\" and \"unstructured\") reply bbarnett 8 hours agorootparentBut this is why I made my complexity statement in my other reply. Why are firms sending around invoices, tables instead of parseable data. Oh I know the argument, because \"so hard to cooperate\" on standards, etc. Madness. reply projektfu 7 hours agorootparentPartly because the standards, such as X12, have a high startup cost to use them, they aren't very opinionated about the actual content, and you have to get the counterparty on board to use them. reply k8sagic 9 hours agorootparentprevAI solves gigantic issues and helps us with cancer, protein folding, potentially math and other studies, material science etc. Bitcoin consumes as much energy as a country and has basically done nothing besides moving money from one group of people to a random other group of people. And bitcoin is also motivated to find the cheapest energy independent of any ethical reasoning (taking energy from cheap chinese hydro and disrupting local energy networks) while AI will have energy from the richest companies in the world (ms, google, etc.) which already working on co2 neutral 24/7. reply bergen 9 hours agorootparentNone of your problems in the first sentence are solved by LLMs. I do not dispute AI research and applications and their benefits, but the current LLM and GenerativeAI hype is of no value to hard scientific problems. Otherwise I agree with you. reply Zambyte 7 hours agorootparentI think the coolest counterpoint to this I have seen so far is people using generative AI to design materials with desired properties. For example, discovering new super conductors[0]. [0] https://www.jhuapl.edu/news/news-releases/230503-ai-discover... reply kmacdough 9 hours agorootparentprevThe benefit is all for naught if it undermines the fabric of society at the same time. All these benefits will only go to the few who land on top of this mess. It's continuing to widen the wealth gap as it is. reply k8sagic 9 hours agorootparentThe wealth gap is widening while in parallel poorer people have better lives than ever. We house, heat and give access to knowledge to a lot more people than ever before. Cheap medical procedures through AI will help us all. The AI which will be able to analyse the x-ray picture from some 3th world country? It only needs a basic x-ray machine and some internet. The AI will be able to tell you what you have. I'm also convinced that if AGI is happening in the next 10 years, it will affect that many people that our society has to discuss capitalisms future. reply HermanMartinus 9 hours agorootparentprevYeah, Bitcoin is dual-edged like that. Harming people and harming the planet. reply EdwardDiego 9 hours agorootparentprevWhich gigantic issues has it solved? Curious to know. reply k8sagic 8 hours agorootparentI actually listed them up directly after. For example alphafold: Protein folding. It is also now used in fusion reactor plasma control reply EdwardDiego 8 hours agorootparentIt didn't solve protein folding. It led to new areas of inquiry, but it didn't solve it. May I recommend reading Derek Lowe's \"In The Pipeline\" blog for a realistic discussion of the actual impact of Alphafold? [0] And seeing as we don't have viable fusion yet, saying it \"solved\" it is really reaching. I'm sure it's helping, but solved? No. [0]: https://www.science.org/topic/blog-category/ai-and-machine-l... reply stavros 11 hours agorootparentprevThis is what spam always did, why is it different now? reply rwmj 10 hours agorootparentIt actually adds some cost to the spammer, so that could be good. reply sph 7 hours agorootparentprevYou didn't need a GPU to generate Cialis spam. reply justsomehnguy 10 hours agorootparentprevSending spam is... very energy efficient, compared to the LLM usage. reply stavros 10 hours agorootparentYep, and thus very cheap, the exact thing you don't want spam to be. reply TeMPOraL 10 hours agorootparentprevBitcoin is literally turning greed into money, by means of wasting exponentially increasing amounts of electricity. It doesn't just not create value - to be able to allow exchanging value, it fundamentally requires ever increasing waste, as the waste is what gives its mathematical guarantees. LLMs deliver value. Right here today, to countless people across countless jobs. Sure, some of that is marketing, but that's not LLM's fault - marketing is what it always has been, it's just people waking up from their Stockholm syndrome. You've always been screwed over by marketers, and Internet has already been destroyed by adtech. Adding AI into the mix doesn't change anything, except maybe that some of the jobs in this space will go away, which for once I say - good riddance. There are more honest forms of gainful employment. LLMs, for all their costs, don't burn energy superlinearly. More important, for LLMs, just like for fiat money, and about everything else other than crypto, burning electricity is a cost, upkeep, that is being aggressively minimized. More efficient LLMs benefit everyone involved. More efficient crypto just stops working, because inefficient waste is fundamental to cryptos' mathematical guarantees. Anyway, comparing crypto and LLMs is dumb. The only connection is that they both eat GPUs and their novelty periods were close together in time. But they're fundamentally different, and the hypes surrounding them are fundamentally different too. I'd say that \"AI hype\" is more like the dot-com bubble: sure, lots of grifters lost their money, but who cares. Technology was good; the bubble cleared out nonsense and grift around it. reply Rattled 9 hours agorootparentWell said, too many people conflate AI and crypto, and dismiss both without understanding either. Crypto has demonstrated very limited benefit compared to its cost, exchanging value has been a solved problem for millenia. We're only beginning to understand what can be done with LLMs but we can see some limits. Although it causes some harm to say it doesn't create any value is ridiculous. We can't yet see if the benefits outweigh the cost but it looks to me like they will. reply ryandrake 3 hours agorootparentprevLong term, LLMs are not going to create more actual value than the sum of their costs and negative externalities. Bookmark this comment and check me in 5 years. reply helboi4 10 hours agorootparentprevDunno why you're being voted down, this is sort of true. reply immibis 9 hours agorootparentprevDelivering value is not the same as creating it. Spam takes lots of value from many people, destroys most of it, and delivers a small fraction to the spammers. reply sph 7 hours agorootparentprev> You've always been screwed over by marketers, and Internet has already been destroyed by adtech. Adding AI into the mix doesn't change anything This is pure, complacent nonsense. \"We have always been surrounded with spam, 10x more won't change anything.\" Yeah, why improve the status quo? Why improve the world? Why recycle when there's a big patch of plastic in the ocean. It's an argument based on a nonsensical, cynical if not greedy position. \"Everyone pollutes, so a little more pollution won't be noticed.\" reply richrichie 9 hours agorootparentprev> It doesn't just not create value Value is a subjective concept. One could argue that its value is that arbitrary quantities of it cannot be created by dictat. > - to be able to allow exchanging value, it fundamentally requires ever increasing waste, as the waste is what gives its mathematical guarantees. One could argue that it takes a lot worse to maintain any currency such as USD as a currency. Full force of government law enforcement will be unleashed on you if you decide to have your own currency. There is a lot of \"wastage\" that goes to safeguard currency creation and storage and to prevent counterfeiting. I do not hold BTC. Nor do I trade it. But to discuss as if other currencies have no cost is not rational. reply TeMPOraL 2 hours agorootparent> There is a lot of \"wastage\" that goes to safeguard currency creation and storage and to prevent counterfeiting. Yes. But the point I'm making is, none of that benefits from waste. The waste is something everyone want to reduce. With Bitcoin, the trend is uniquely opposite, because the crypto system is secured through aggregate waste being way larger than any actor or group can afford. reply k8sagic 9 hours agorootparentprevBut we do know that the Proof of Stake system we currently have, is a lot cheaper and more advanced than what Bitcoin does. Bitcoin doesn't solve any problem yet which is fundamental to our society and a fiat system like the trust issue: If i exchange 1 bitcoin with you for any service or thing outside of the blockchain, i need the whole proof of stack system protection of our normal existing money infrastructure like lawyers, contracts etc. And no smart contracts do not solve this issue. What is left? Small amount of transactions per day with high fees 'but' decentralized infrastructure run by someone we all don't know aggregated probably in data centers owned by big companies. reply block_dagger 8 hours agorootparentProof of Work is far superior to Proof of Stake in a network with absolute fairness (security) being fundamental. Satoshi himself said he could find no other way. Compare energy spent on global hash rate to all energy spent by mining metals, physical banking, financial services middle persons, etc. if you want to talk about energy usage and make any kind of sense. reply k8sagic 8 hours agorootparentYes, start comparing energy spend on bitcoin mining and the missing features. You will see that bitcoin already consumes a lot more energy than our proof of stake system. What do you do when you want to exchange 1 bitcoin for 1 car and the person with the car doesn't give you the car after the 'absolut fairness/ security' of transfering bitcoin to their wallet? You go back to our Proof of Stake system. You talk to a lawyer. You expect the police to help you. The smallest issue in our society is just transfering money from left to right. This is not a hard problem. And pls don't tell me how much easier it is to send a few bitcoins to africa. Most people don't do this and yes western union exists. Or try to recover your bitcoins. A friend has 100k in bitcoins just doesn't know the password anymore. What do you do when someone breaks into your home and forces you to give them your bitcoin key? Yes exactly anonyms moving of money from you to them. Untraceable, wow what a great thing to have! And no Satoshi 'himself' is not an expert in global economy. He just invented bitcoin and you can cleary see how flawed it is. reply davidgerard 8 hours agorootparentprevI'd disagree to a large extent, because the specific similarities are important: * the VCs are often literally the same guys pivoting * the promoters are often literally the same guys pivoting * AI's excuses for the ghastly electricity consumption are often literally bitcoin excuses I think that's an excellent start on the comparison being valid. Like, I've covered crypto skeptically for years and I was struck by just how similar the things to be said about the AI grifters were, and my readers have concurred. reply bottled_poe 10 hours agoparentprevThis is why the internet as we know it is going to be driven into walled gardens. Closed by default. reply muzani 11 hours agoparentprevI look forward to the dream job of writing LLMs that argue with strangers on the internet as opposed to the current dream job of improving ad click rates by 0.0016% per quarter. reply damidekronik 8 hours agoparentprevSlightly similar, in Lem's novel all war efforts moved to the moon where AI deployed by each nation continues in an endless conflict. Peace on Earth is achieved, peace in the mail box is achieved. https://en.m.wikipedia.org/wiki/Peace_on_Earth_(novel) reply flir 9 hours agoparentprevIf anyone hasn't read Accelerando, I heartily recommend it. For one thing, it seems to be coming true. reply masklinn 10 hours agoparentprev> As for the humans, we went fishing instead. To a farm upstate? reply squigz 8 hours agoparentprevAre LLMs able to make purchases? reply lannisterstark 10 hours agoparentprevIn an optimistic POV of this, eh, why not? if models handle my day to day minutia so I have more time, why the hell not... (I know this is very optimistic POV and not realistic but still) reply CoastalCoder 9 hours agorootparentBecause spam is incredibly selfish. You're trying to take the time and attention of as many people as possible, without regard for whether or not they'll benefit. One safeguard people have is knowing that it costs something to send in some way to contact them. I'm this case, the sender's time and attention. LLM spam aims to foil that safeguard,. intentionally. reply ChilledTonic 13 hours agoprevI’m actually thrilled by this, as it means all the hack marketers that spam my inbox incessantly with whatever product they’re hucking - this time for sure perfect for my business, in spite of the fact I’ve ignored their last ten emails - are all out of a job, and good riddance. The author sounds unfamiliar with this brand of marketing email, so I can see why it would come off disquieting to find it’s all AI - but it’s equally annoying from a human. At least with AI sending this crap nobody can use these emails to justify their sales bonus. reply kazinator 13 hours agoparentHow do you know it isn't exactly the same people, with zero reduction in headcount? Designing the content of spam e-mails sounds like a small aspect of the \"job\". If AI spams start fooling people more reliably, that's not something to celebrate. This blogger thought, at first, that it came from an actual reader. I can't remember the last time I thought that a spam was genuine, even for a moment. Sometimes the subject lines are attention-getting, but by the time you see any of the body, you know. reply jstummbillig 12 hours agorootparentIf you do nothing that is discernible from noise (be that manually or through AI), unless your explicit goal is to generate noise, your ROI is 0. Sure, AI spam can severely disrupt peoples attention by competing with \"real\" people more competently. But people will not have twice the attention. We will simply shut down our channels when the number of real-person-level-ai-spam goes to infinity, because there is no other option. Nobody will be fooled, very quickly, because being fooled would require super human attention. Granted, that does not seem super fun either. reply lmm 10 hours agorootparent> If you do nothing that is discernible from noise (be that manually or through AI), unless your explicit goal is to generate noise, your ROI is 0. We're talking about a group of people whose core skill is convincing people to pay for stuff that isn't worth it. You and I may know they're worthless, but that doesn't mean they're not getting paid. reply jstummbillig 10 hours agorootparentLet's assume you have a mom that loves you very much and she let's your know by text on a semi-regular basis. She asks you to come by on Friday. That might seem like a nice idea to you. You reply yes, and you go. Now, imagine you got messages from what appears to be not 100 but, oh I don't know, 1 000 000 000 000 000 of the very best moms that have ever existed. And they all do love you so very much. And they do let you by writing these most beautifully touching text messages. And they all want to meet up on Friday. What is going to happen next? Here is what is not going to happen: You are not going to consider meeting any of them Friday, any week. You will, after the shortest of whiles, shut down to this signal. Because it's not actually a signal anymore. The noise floor has gone up and the most beautifully crafted, most personalized text messages of all time are just noise now. reply lmm 6 hours agorootparentI don't know what you're trying to say. The people making payroll decisions have the same amount of people under them as they always did. reply ayewo 8 hours agorootparentprevWe all get to have only one mom and moms dont live forever. So once someone’s mom passes away, you can’t really fool them with 1 or dozens of message from other moms anyway. reply bowsamic 11 hours agorootparentprevThe emails are discernible from noise though. They literally have a signal to noise ratio higher than one. Noise would be pure rng output. So I don’t know what you’re getting at reply Wolfenstein98k 11 hours agorootparentYes you do. You're being over-literal. \"Noise\" in context doesn't mean random characters, it means garbage or spam or content not worth your while. reply bowsamic 11 hours agorootparentNo, I'm not being over-literal. Here's why: Yes, it could be that for you a given advert is irrelevant or not worth your while, but the point he was making is that it won't even be worth it for the advertiser to put out the advertisement because it will be noise for everyone. However, there is only one kind of noise that is noise for everyone: literal noise. So long as the spam is about something, it is relevant to someone, and therefore it does not necessarily have zero ROI. EDIT: The only kind of noise that has no semantic is actual \"mathematically pure noise\" as the person below commented (/u/dang banned my account so I can't reply) reply thomashop 10 hours agorootparent> However, there is only one kind of noise that is noise for everyone: literal noise. I feel like you're a bit too literal here. When people talk about noise it doesn't mean mathematically pure noise. A signal-to-noise ratio close to 1 is also colloquially called noise. reply bowsamic 8 hours agorootparentAddressed above reply ImHereToVote 11 hours agorootparentprevHe is talking about semantic noise. Something that appears to have substance but is just slop actually. When everything is that. Then all email will become equivalent to slop. How could it not? Someone will be burned once or twice, but after that, there is a semantic phase shift. reply kazinator 9 hours agorootparent\"How could it not?\" There are ways. Consider that we have fairly decent anti-spam measures which do not look at the body of a message. To these methods, it is irrelevant how cleverly crafted the text is. I reject something like 80% of all spam by the simple fact the hosts which try to deliver it do not have reverse DNS. Works like magic. E-mail is reputation based. Once your IP address is identified by a reputation service as being a source of spam, subscribers of the service just block your address. (Or more: your entire IP block, if you're a persistent source of spam, and the ISP doesn't cooperate in shutting you down.) To defeat reputation based services driven by reporting, your spams have to be so clever that they fool almost everyone, so that nobody reports you. That seems impractical. How AI spammers could advance in the war might be to create large numbers of plausible accounts on a mass e-mail provider like g-mail. It's impractical to block g-mail. If the accounts behave like unique individuals that each target small numbers of users with individually crafted content (i.e. none of these fake identities is a high volume source), that seems like a challenge to detect. reply immibis 9 hours agorootparentThese IP blocklist services also have a reputation of their own: if you are trying to send legitimate mail, there's a good chance your IP is on several of these blocklists for reasons you have nothing to do with. You can only remove it by grovelling and paying lots of money (extortion). So using one of them will cause you to reject legitimate mail. reply bowsamic 11 hours agorootparentprevWhat is \"just slop\" though? A spam advert for a product is still an advert for a product. Therefore it's not just semantic noise, it is still an advert for a product, and therefore his point is invalid: there is an ROI and people will continue to be employed to do it reply TeMPOraL 10 hours agorootparent> A spam advert for a product is still an advert for a product. Therefore it's not just semantic noise, it is still an advert for a product Ergo slop and semantic noise. Companies that used adverts which weren't noise went out of business long ago. reply bowsamic 8 hours agorootparentAdverts have semantic content, they aren't noise. reply ryandrake 3 hours agorootparentLet's just call it slop then. Peak HN: Another conversation is logjammed by nitpicking the precise definition of a word rather than discussing the overall point. reply bowsamic 3 hours agorootparentExcept I am still discussing the point: the companies won't stop getting an ROI because \"slop\" still produces an ROI, even if people know it's slop, because it isn't contentless noise, it has semantic content. Just because you and the others don't understand what point I'm making doesn't mean the conversation is \"logjammed\". I am still discussing the overall point, you just don't see it. reply ryandrake 3 hours agorootparentFor the record I agree with you--just pointing out a silly, but common, HN pattern. reply cen4 12 hours agoparentprevThe problem is never what one person or one company is doing. But when everyone copies what that one person or one company is doing. Software makes the copying process dead easy. Once the herd starts stampeding, it creates a secondary effect of an arms race for finite Attention of a finite target audience. That assault and drainage of that finite attention pool, happens faster and faster and every one gets locked in trying to outspend the other guy. An example currently is Presidential Campaigns furiously trying to out fund raise each other. Its going to top 15-17 billion this year. All the campaign managers, marketers, advertisors make bank. And we know what quality of product the people end up with. Cause why produce a high quality product when you can generate demand via Attention Capture. The chimp troupe is dumb as heck as a collective intelligence. reply hk__2 10 hours agoparentprevFrom the spammer blog post [1]: \"I spent hours trying different data sources\", \"a lot of time was spent on find-tuning the tone and structure of the email\", \"It took multiple tries to finally have the agent write emails in different language\", etc. This won’t put marketers out of a job, but will greatly improve their tooling and enable more people to do the same thing with even less qualification. [1]: https://www.wisp.blog/blog/how-i-use-ai-agents-to-send-1000-... reply safety1st 11 hours agoparentprevI don't really think that AI is the central issue here. The issue is that Kurt, the founder of Wisp, is a liar. He misrepresented himself as a big fan of all these blogs, who's read their posts etc. and that's how he achieved such a high response rate. In effect he deceived people into trusting him enough to spend their time on a response. Now ordinarily this would be a little \"white lie\" and probably not a huge deal, but when you multiply it by telling it 1,000 times it becomes a more serious issue. This is already an issue in email marketing. The gold standard of course is emailing people who are double opted in and only telling the truth, and if AI is used to help create that sort of email I don't really have a problem. There is basically a spectrum where the farther away you get from that the progressively more illegal/immoral your campaigns become. By the time you are shooting lies into thousands of inboxes for commercial purposes... you are the bad guy. Sorry to say but the real issue here is Kurt has crossed an ethical line in promoting his startup. He did the wrong thing and he could have done it pretty effectively with conventional email tools too. reply pseudalopex 8 hours agorootparentWisp founder Raymond Yeh is a spammer and liar. Kurt was a victim of Raymond Yeh's fraud. reply saturn8601 12 hours agoparentprevI look forward to the blog post of how a hacker uses AI to respond to AI generated leads and then have them play with each other....and then uses AI to create content for a Youtube channel fighting back against marketers using said AI. These early days is ripe to make some quick cash before it all comes crashing down. reply stavros 11 hours agorootparentHere you go: https://www.stavros.io/posts/spam-spammers-back/ reply masswerk 10 hours agorootparentprevIsn't this pretty much one of the proposed new concepts for online dating? ;-) reply Terr_ 12 hours agorootparentprev> and then uses AI to create content for a Youtube channel fighting back against marketers using said AI. I'm skeptical: It's easier to create bullshit than to analyze and refute it, and that should remain true even with an LLM in each respective pipeline. ---- P.S.: From the random free-association neuron, an adapted Harry Potter quote: > Fudge continued, “Remove the moderation LLMs? I’d be kicked out of office! Half of us only feel safe in our beds at night because we know the AI are standing guard for misinformation on AzkabanTube!” > “The rest of us sleep less soundly knowing you have put Lord Bullshittermort’s most dangerous channels in the care of systems that will serve him the instant he makes the correct prompts! They will not remain loyal to you when he can offer them much more scope for their training and outputs! With the LLMs and his old supporters behind him, you’ll find it hard to stop him!” reply tivert 13 hours agoparentprev> I’m actually thrilled by this, as it means all the hack marketers that spam my inbox incessantly with whatever product they’re hucking - this time for sure perfect for my business, in spite of the fact I’ve ignored their last ten emails - are all out of a job, and good riddance. > ... > At least with AI sending this crap nobody can use these emails to justify their sales bonus. What weird, misplaced animus. You're happy some salesguy got fired, while his boss sends even more spam and possibly makes even more money due to automation? Those hack marketers rate-limited this kind of spamming. Now things are about to get worse. reply eru 12 hours agorootparent> [...] while his boss sends even more spam and possibly makes even more money due to automation? Wouldn't the exact argument apply to that boss as well? reply bryanrasmussen 12 hours agorootparentunless this is a big multinational spam organization probably the boss of the person sending the email is the highest up, but no matter what there will be someone on the top who does not get fired and will be able to reap all the rewards of the AI automation, at least until the AI revolution puts them up against the wall. reply eru 12 hours agorootparentThere's presumably heavier competition from other spammers, until everything is in equilibrium again. The wallets of potential spam victims only have so much total cash. reply bloqs 12 hours agorootparentprevSome people don't realise how lucky they are that they are blessed by the cognitive lottery that affords them a brain and personality that lets them pursue an enriching and engaging career they feel is valued by society. In classic HN style the original reply lacks empathy, and demonstrates a preference of machines over humans. Life goes on... reply tivert 5 hours agorootparent> In classic HN style the original reply lacks empathy, and demonstrates a preference of machines over humans. Life goes on... That stereotype definitely rings true. Thank you for helping me put my finger on it! reply elorant 13 hours agoparentprevSomeone will just pack this into a product and sell it to marketers. reply TeMPOraL 12 hours agorootparentAnd use it to market the shit out of it. If marketing finally collapses under the weight of its own bullshit, I'll be celebrating. reply _nalply 13 hours agoparentprevSome people will send their mass spam and phish anyway. No thanks. reply purple-leafy 13 hours agorootparentSpam? Easy. Someone selling something? Spam! I might set up an automatic email responder that reads an emails contents, runs it through my own LLM, and if the email is trying to sell me something, auto reply with “fuck off!” reply Brajeshwar 13 hours agorootparentI'd rather delete/block it than reply/react to it at all. If you react, they know you exist and you are a valid target to re-target repeatedly, resold to other marketers. Mark as SPAM or Block/Filter or Ignore. reply purple-leafy 13 hours agorootparentOkay new plan, I’ll have another email that responds to the email and says “fuck off”, meanwhile my honeypot email will block and mark as spam reply Ekaros 11 hours agorootparentSadly I think it is illegal to sing up these addresses to every service known to you... Otherwise it would be interesting SaaS opportunity. Automatically sing-up spammers to any number of newsletters or contact forms... reply purple-leafy 10 hours agorootparentI think you just gave my life purpose. It will be my magnum opus. Actually that’s already been completed, and will be released to hackernews in the coming days reply immibis 9 hours agorootparentprevWhen they're paying real money to scam you, wasting their time isn't a terrible idea. Like keeping the Microsoft virus scammers on the phone for an hour while you set up a virtual machine for them to remote into. reply darby_nine 11 hours agoparentprevI've found it's easier to simply ignore your inbox and hope the spam unsubscribes itself and disappears reply chillfox 11 hours agorootparentlol, I treat my email inbox like a dumpster that I occasionally search when I know there's something there that I need to retrieve. The spam has won, I have moved to chat platforms for my communication needs. reply ChrisMarshallNY 9 hours agorootparentI get -no exaggeration- several hundred spams a day. I have an OG email address that was grabbed by spammers, since the days of Network Solutions (so it’s been awhile). I maintain Inbox Zero, much of the time, and seldom have more than three or four emails in my client at any time. I get there by being absolutely brutal about tossing emails. I probably toss a couple of legit ones, from time to time, but I do have rules set up for the companies and people I need to hear from. The thing that will be annoying, is when AI can mimic these. Right now, that stuff is generally fairly clumsy, but some of the handcrafted phishing emails that I get, are fairly impressive. I expect them to improve. A lot of folks are gonna get cheated. I do think that some of these Chinese gangs are going to create AI “pig butchering” operations, so it will likely reduce their need to traffic slaves. reply grugagag 6 hours agorootparentWhat are pig butchering operations? reply jabroni_salad 6 hours agorootparentIt's people that write you love letters until you western union them your entire retirement account. reply ChrisMarshallNY 6 hours agorootparentIt’s really quite sophisticated. John Oliver actually did a great segment on it, but I won’t link it, because a lot of folks don’t like him. reply jabroni_salad 4 hours agorootparentI haven't seen that but I have read some articles about it on propublica. I just kept the description as simple as possible to make it more memorable. reply ChrisMarshallNY 3 hours agorootparentWell, a lot of the scammers are actually slaves, trafficked into Myanmar boiler rooms, by Chinese Tongs. If AI takes off for this stuff, the gangs are less likely to be kidnapping these poor schlubs. So … I guess this would be a … positive outcome? Not sure if AI zealots will be touting it, though. reply xarope 12 hours agoparentprevsome of the marketing spam is so low effort, I get addressed as \"Dear {{prospect}}\". It does make deleting the email easy though, since the preview of the first line allows me to filter pretty fast! reply simion314 11 hours agoparentprevIf this works those spammers will make more money and send more emails scamming more people. Maybe some politician would fall for soemthing like this, be public ally embarrassed and lose a lot of money and then something more will be done to address this spammers and scammers . reply jeauxlb 13 hours agoparentprevWhy are you happy that people are out of a job here? You still suffer the ills of the product, now infinitely more incessant, at a marginal cost of $0. reply ronsor 13 hours agorootparentI think it's reasonable to be happy that someone is not getting paid to do something you hate. In fact, if you're suffering unwillingly, you probably want as few people as possible to benefit. reply crabmusket 13 hours agorootparentOpenAI is getting paid to do it. reply ronsor 13 hours agorootparentYes, but a lot less than if a person were getting paid to do it, so still less money is changing hands. reply lucianbr 12 hours agorootparentI don't know which of \"5 randos getting a living wage by spamming me\" and \"Altman getting filty rich by spamming me\" is worse. I'm inclined to say the latter, though of course it's quite close. Wish SV would stop thinking anything that makes money is great, no matter the crap it inflicts on people. Guess I'm asking for way too much. reply maronato 12 hours agorootparentprevI don’t think so. Marketers don’t send X amount of spam because X is the right amount of spam they want to send. They are limited by how much money they want to pay in salaries and management, which defines how many people they can hire to send spam. If the people they employ today suddenly became twice as productive, the company wouldn’t fire half of them - they just would enjoy twice the profit. The same applies to AI. reply davedx 12 hours agorootparentprevnext [10 more] [flagged] TeMPOraL 12 hours agorootparentGetting peed at a couple times a day isn't a problem if the pee-ees miss 99% od the time, right? Small acts of malice are still acts of malice. Not everyone wants to live in a caveat emptor, dog-eats-dog society. reply davedx 12 hours agorootparentHaving tried to start a business and known other business owners, I will die on this hill: sales and marketing are not \"acts of malice\". Without salespeople we wouldn't live in the world we lived today. This is like the irrational hate some developers have for recruiters, despite them finding jobs for many people that they otherwise would never have known about. reply staunton 11 hours agorootparentMarketing is fundamentally aimed at changing people's opinions. This can be done 1. covertly (why do you need to do it covertly? Would people mind if they knew? Doesn't that indicate you're doing them a disservice?) 2. overtly, against people's will. (Again, doesn't that indicate you're doing them a disservice?) 3. overtly, with their consent (express or assumed). How often have you seen this happen? The \"indicates\" vs \"shows\" distinction above deals with the edge case of \"interacting with covert/unwanted marketing is actually good for them, even if they don't know it\". I dare you to make that argument... reply account42 8 hours agorootparentprev> Having tried to start a business and known other business owners, I will die on this hill: sales and marketing are not \"acts of malice\". Without salespeople we wouldn't live in the world we lived today. That's exactly the reason why we hate them. reply TeMPOraL 11 hours agorootparentprev> This is like the irrational hate some developers have for recruiters It's not like that. As a business owner, be honest with us and yourself: just how much of sales and marketing you did was just bullshit? Exaggerated claims bordering on lies? Manipulative patterns? Inducing demand? Approximately all marketing is that. It is that because it works, and those who refuse to do it get outcompeted by those who don't. Doesn't mean the world should be like that, or that I'd like to be subjected to it. I also question the \"we wouldn't live in the world we lived today\" bit. In a competitive environment, marketing is a zero-sum game[0]: there's only so many people around, with so much money and time available; most of the marketing spend ends up being used to cancel out the efforts of the competition, and that race can consume all surplus of a company. Red Queen's race and all. -- [0] Or negative-sum, if you account for externalities. reply eesmith 12 hours agorootparentprevThe logic in 'Without salespeople we wouldn't live in the world we lived today' doesn't really support the point you are trying to make. Consider that without thieves we also wouldn't live in the world we live today. That should not be read supporting theft, only an acknowledgement that it exists and that we have designed our lived environment in response. reply daedrdev 12 hours agorootparentprevMany of these emails promote products that can inly be described as scams reply lynx23 12 hours agorootparentprevAnd you're qualified to declare this because? Are we supposed to silently suffer because capitalism says so? Spammers and salespeople are pretty much on the same level as criminals in my book. Heck, whenever someone calls me for some sort of unsolicited survey or similar, I think \"these people have such low standards, they would also sell heroin on the street if they had any source.\" reply davedx 12 hours agorootparentSuffering is \"the state of undergoing pain, distress, or hardship\". Having to delete the occasional marketing or sales email that get past your spam filter is hardly any of these. Annoying or frustrating, yes. Suffering? Really? reply Joker_vD 13 hours agorootparentprevBecause maybe, just maybe — those people will find some other jobs, and those jobs will be more socially beneficial this time? One can dream. reply bryanrasmussen 12 hours agorootparentThey can maybe get jobs for Microsoft and call people up to tell them they've noticed something is wrong with their computer!! reply bowsamic 11 hours agorootparentprev“maybe, just maybe” “One can dream.” You’ve either used these sarcastically, or accurately. I think you’ve done the former, but the truth is the latter. reply Joker_vD 7 hours agorootparentI am absolutely serious. Any employment has opportunity costs: a person who writes and sends out cold call spam e-mail for 8 hours a day is a person who could be spending those 8 hours on something else, but isn't. Yes, switching jobs is not very easy, and it's stressful but humans, thankfully, are not (yet) a species of highly-specialized individuals, with distinct morphological differences that heavily determine the jobs they potentially can or can not do. reply bowsamic 7 hours agorootparentSo I was right, you did use it sarcastically, since you are still naive reply 263 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author received an email from \"Raymond\" promoting Wisp, a headless CMS, which seemed personalized but was actually AI-generated.",
      "The email was part of a mass outreach strategy using AI to send nearly 1,000 personalized emails to developers with public blogs on GitHub.",
      "The author expresses frustration with this AI-driven approach and considers making their GitHub-mirror private to avoid such spam."
    ],
    "commentSummary": [
      "An AI-generated email from timharek.no claims success in creating personalized emails using multiple Large Language Models (LLMs) without recipients detecting the AI origin.",
      "This raises ethical concerns about prioritizing attention and engagement over meaningful progress, with some comparing it to engineers focusing on ad tech rather than significant achievements like the moon landing.",
      "The discussion underscores the dual nature of AI in marketing, acknowledging both its potential for misuse in spam and its valuable applications."
    ],
    "points": 640,
    "commentCount": 514,
    "retryCount": 0,
    "time": 1719983135
  },
  {
    "id": 40864914,
    "title": "Proton launches its own version of Google Docs",
    "originLink": "https://www.engadget.com/proton-launches-its-own-version-of-google-docs-100044471.html",
    "originBody": "Read full article Proton launches its own version of Google Docs It has rich editing and collaboration tools, as well. mariella moon Contributing Reporter Wed, Jul 3, 2024, 6:00 AM EDT·1 min read 0 Proton Proton now has its own version of Google Docs in its Drive cloud storage service, and like the company's other products, it comes with end-to-end encryption. The company says its flavor of Docs \"offers a unique solution in a market where most popular products neglect privacy\" and recommends it for use in the healthcare, media, finance and legal industries. Proton Docs has advanced formatting and image embed options like Google Docs has and can create, open and edit documents in multiple formats, including Microsoft .docx. It has collaboration tools similar to Google Docs', as well. Users can invite anyone to view and edit their documents, though those without a Proton account will be prompted to create one first. The free tier of Proton Drive includes essential document features so people don't have to pay for the service if they don't want to. Participants will be able to add comments to the document, reply to them and resolve them. And users will see other participants' presence and their cursor placements in real time, so that they know who's working on which part of the document and so that their edits don't clash. Proton didn't say whether the launch of Docs means it's going to roll out analogues of Google's other Workspace apps in the future, but the company did expand its offerings with several different products over the last few years. In addition to Drive cloud storage — and, of course, its email service — the company has a VPN, an encrypted calendar and even a password manager. Docs will make its way to Proton users over the coming days. This article contains affiliate links; if you click such a link and make a purchase, we may earn a commission.",
    "commentLink": "https://news.ycombinator.com/item?id=40864914",
    "commentBody": "Proton launches its own version of Google Docs (engadget.com)305 points by prng2021 7 hours agohidepastfavorite209 comments zurfyx 1 minute agoLexical contributor here. I love what you've build here! A full-fledged collaborative rich text editor. I'm glad that Lexical worked well for you, we'd be happy to take your feedback throughout the development process, you can reach out to me over Discord by the same username or on our server. reply prophesi 4 hours agoprevI see that they claim all of their apps and libraries are open source[0]. But they only link to the OpenPGP libraries they're using. Is this actually open source? Following the \"Open Source\" footer link[1], here they only link to the ProtonMail Github account with nothing mentioning ProtonDrive. And if it is actually open source, I'd love to see a comparison to CryptPad[2] > which is why we’ve made all our apps and encryption libraries open source [0] https://proton.me/drive/security [1] https://proton.me/community/open-source [2] https://cryptpad.org/ reply chrisco255 2 hours agoparentThis is their monorepo for their clients, including Proton Drive: https://github.com/ProtonMail/WebClients reply butz 29 minutes agorootparentSo what is stopping us from building native Linux client for Proton Drive, as Proton is clearly not interested in doing that? reply winter_blue 1 hour agorootparentprevOh wow. Wouldn't this make it easy for someone to just use/fork the code here to create a competitor? reply lazyc97 1 hour agorootparentOnly the clients source code are available, so we know what data is encrypted before sending to server. The server side is closed source. reply maronato 11 minutes agorootparentprevYeah, but why would anyone use the competitor? Proton’s biggest advantages are its security and privacy. It’s hard to back that up with code and even more with plain words. Having their code be open source is a very important step in maintaining that image, and that image is not something a competitor can just plagiarize. reply notresidenter 5 hours agoprev(Paying customer) I wish they would focus more on their existing product(s). There's a huge synergy between Calendar and Mail, but Drive, Pass, VPN, are useless (but the VPN is well-done). There's still no Caldav support or scheduling, and a lot of things are annoying in Mail, of course some of these are hard to solve with E2E, but at this point, their E2E claim is also half-baked and mostly for marketing, why not fix all of things? What's the rationale behind releasing yet another half-baked product? reply icar 2 minutes agoparentIt's not going to be as half baked as other products they've released in the past that were made from scratch because this is basically Standard Notes that they bought directly integrated in Drive. reply frenchman99 3 hours agoparentprevI'm even more convinced that me being a Fastmail customer is a good thing. Fastmail has been rock solid for years. Their email, calendar and contacts solutions work well with iOS and android (using the DAVx app). WebApps work flawlessly on Firefox. They have all sorts of customisation for spam filtering, catch all email addresses, etc. They don't do all the things (vpn, passwords, drive, what have you). But what they do, they do very well. reply ndr 2 hours agorootparentI love the service but hate their android app. It fails to load any content when offline. Absolutely maddening when you need to look up anything, like gig tickets, in a low reception area. reply fhd2 2 hours agorootparentprevAbsolutely, very happy Fastmail customer here! My only qualm is that their apps could be better at multi account (switching is too much of a hassle), but that's the only problem I ever had, and I work around it by using different mail/calendar clients. If you just have a single account with them though, their app is quite excellent and has everything (mail, calendar, notes), no need to get multiple apps and stuff like DAVx unless you want to. reply amelius 2 hours agorootparentprevHow do you deal with spam in Fastmail? I switched from GMail to Fastmail about a year ago, but ever since my Inbox is just filled with lots of spam. I tried writing email filters, and have about 50 now, but it is just not cutting it. And also those promotional mails that I don't want to mark as \"spam\" but still shouldn't end up in my Inbox ... they drive me nuts. Since I started using Fastmail, my main means of communication is shifting away from e-mail, which is sad. reply beart 1 hour agorootparentMy experience on fastmail doesn't align with yours. While spam has slightly increased over the years, I attribute that to just using my email more often. It's very rare that I get spam in my actual inbox. In fact, my experience is that the spam filter is a bit too strong and I actually have to check the spam folder now and then. For the promotional emails, there are some general rules you can set up to catch a lot of it, such as https://pietrorea.com/2021/10/22/filter-emails-by-the-list-u.... However, the best way to manage them is to actually just unsubscribe to them as you receive them. If unsubscribe is ignored, then blacklist the sender. For general spam, there's a setting under \"privacy and security\" to make the filtering more or less aggressive. My setting is on \"standard\" and I haven't had any problems, but you could try adjusting that. reply amelius 53 minutes agorootparentOK, I will try that. But I still think migrating away from GMail should be less painful. reply genewitch 12 minutes agorootparentprevspam as in unsolicited? I get 0 in any of my inboxes. I get lots of stuff i don't care about from spammy businesses (E Y E GL A S S // S A L E 80% O FF) that i've used before. But there's a way around that as well, it's more expensive. Buy a domain name. Set up DNS. Let fastmail host the actual mail service. Set up a catchall account *@domain.tld. Give per-site/whatever emails whenever you give an email. If the email gets sold, just tell the fastmail UI that everything sent to that address is spam. It hasn't failed yet, and i've been using fastmail since it was $5/year. It's $15/yr now and they recently doubled my storage from 500mb to 1000mb! reply kid64 1 hour agorootparentprevHere's one little-known tip I learned from Fastmail support some time ago: it's only possible to train the spam filter using their Web UI. If you're using a 3rd-party client, simply moving messages to your spam folder will have no effect on your filter quality. So to truly flag a message as spam, you must switch to your browser, login to FM, and handle it from there. reply amelius 56 minutes agorootparentBut I don't want to mark everything that should not grab my immediate attention as spam. Some stuff like promotions or social messages deserve their own folder. Google did this right. reply twojacobtwo 2 hours agorootparentprevWhy dont you use their masked/alternate addresses. That was one of the primary selling points for me. Any questionable site/service gets its own address and is easily removed or filtered if spam starts showing up. reply amelius 1 hour agorootparentI have those too. But the problem is I migrated away from GMail, where everything worked even with 1 email address, so now I'm stuck with that email address being used by all the people and companies that want to send me email. (By the way, in GMail you can move emails to \"promotional\" and \"social\" folders, and then GMail automatically does that for you for future emails; this is quite handy, but after migrating to Fastmail this is leaving me with quite a mess in my Inbox, since Fastmail doesn't have this option). reply oldmariner 58 minutes agorootparentYou're not stuck; slowly change addresses with the different companies, people, etc. I did it over the course of a few years without hassle. If you spend $10/year for your own domain, then you can use a catchall, and if you ever decide to leave Fast ail for another provider, you don't have to change all the addreses again. reply lancesells 2 hours agorootparentprevThat only works with something you actually signed up for. When your email gets leaked in a database and sold a thousand times you just start getting spam for all types of things. reply mikeiz404 1 hour agorootparentMy solution was to start over with a new \"root\" email address and then keep it private. Having unique email addresses for each service (which then forwards to the \"root\" email address) is a bit of a pain but it does work for spam and, depending on what else you share with the service, privacy as well. For better or worse if you want to reliably control who you receive email from you need to control who knows your email addresses and have the ability to disable/filter them. reply genewitch 8 minutes agorootparentthe same is true for SMS/call spam - my phone number is a single digit off from my wife's, she gets 6-10 total spam messages and calls a day, i get one a year. It's because she uses her cellphone number to sign up for fuel rewards and stuff, and they immediately sell it. I use my voip number to sign up for anything, and i have notifications shut off for SMS - and a phone tree for calls. Spam calls never get through a phone tree/IVR. warp 1 hour agorootparentprevI'm using the Hey approach in Fastmail, so my main folders are Inbox and Screener, with a filter like this: Matches NOT fromin:contacts -> Move to Screener I'll check the Screener less frequently, and whenever I feel like it I'll take a message from it and use Actions -> Add rule from message.. and send messages from that sender to a Newsletter folder. I still get lots of crap in the Screener, but then again I don't really use e-mail to communicate with humans, so in a sense all e-mail is automated nonsense from systems where I have some kind of user account. reply omneity 1 hour agorootparentprev(another happy paying customer of Fastmail here) I am pleasantly surprised that Fastmail has no AI cruft in it especially that Fastmail is founded by one of the godfathers of modern AI, Jeremy Howard. reply stavros 2 hours agorootparentprevI'll second this, I've had absolutely zero issues with Fastmail over many years. It always just works, and is super fast. reply brianmiddleton 2 hours agorootparentprevI agree. I also like their explanation on why they don't offer PGP. https://www.fastmail.com/blog/why-we-dont-offer-pgp/ reply lloeki 2 hours agorootparentprev> android (using the DAVx app) It borderlines on the insulting that Google refuses to support CardDAV and CalDAV OOTB. reply kertoip_1 6 minutes agoparentprevThey are probably targeting to provide services for companies. It's hard to convince someone to pay for mail if your competition (like Google Suite or Ms365) offers mail AND a bunch of additional stuff. They also just want to tie customers to they services as much as possible to prevent them leaving reply swatcoder 3 hours agoparentprevAs soon as somebody decides that a brand's future requires adding more top-level features rather than specializing in top-of-class delivery of core features, product design becomes an endless treadmill (death spiral?) of adding \"yet another half-baked product\" That's not to say that \"one thing well\" products are sure to be viable, and the \"bullet point maximizers\" that dominate product design for the last 10-15 years may know best, but this is what it looks like once they run the show either way. reply viccis 2 hours agorootparentThis happened so bad with Wyze. They had a really great little camera for a very brief time. Then I turn around and they're just a white box product reseller, with everything from vacuums to earbuds. Meanwhile, their camera service is a shadow of its former self. reply tombert 4 hours agoparentprevIf this is a Proton grievance panel, I really wish they'd optimize their web app, at least with Firefox. If I leave the Protonmail tab open, the amount of CPU and RAM usage for Firefox just spikes up like crazy, and it shoots back down once I close that tab. I can get around this with the ProtonMail Bridge and using Mutt, which works fine and makes me feel cool, but the web app is considerably more convenient. reply digging 3 hours agorootparentBoth their web app and their android app are extraordinarily sluggish, unfortunately. And I currently am forced to use the web app in a PWA on my phone because the Android app has a current bug where the contents of emails won't load. In other words it's 100% useless, and I uninstalled. By the PWA is agonizing to use, so I've been missing emails lately. For a service to keep getting worse over the years when I want to like it is difficult to swallow, but every day I'm a little closer to canceling my subscription. reply tombert 3 hours agorootparentDon't get me started on the fucking Android app. When I would type and send an email too fast, it would only send the first half or so. I would have to type out the email, wait about 30 seconds, then send it. Presumably it had to fully save some draft before sending it, but it came off as extremely amateurish. Not to mention that it just utterly killed my battery life. The iOS app is fine, and since I'm on iPhone again I'm still on Proton, but I haven't completely lost the bitter taste in my mouth over the Android version. reply boudin 2 hours agorootparentThey replaced the android app recently. I haven't experienced this bug with the new one. reply tombert 7 minutes agorootparentI cannot imagine that it could get much worse. I don't have an Android phone anymore, and to be potentially fair to Proton, my last Android phone was an utter piece of shit (Pixel 7 Pro). I know people who had the Pixel 7 Pro and they didn't seem to hate it, so it's possible that it had some hardware issues, but it certainly didn't seem like hardware issues. I hated that thing so much that it completely turned me off of Android for the foreseeable future, since this was not a cheap phone, and it was Google's flagship phone: if they couldn't get a good experience on the flagship product, I didn't see why the experience would be much better on anything else. Anyway, it's possible that the Proton app didn't suck as generally on Android as it did for me, it could have been the phone's fault, but it did leave a very bad taste in my mouth. As stated, the iOS version of the Proton app is totally fine, I haven't had any issues with it other than I don't really like the theme, but that's hardly worth complaining about. reply boudin 2 hours agorootparentprevWith the previous android app, not the one they just launched last month, i had a similar issue (it would take ages to load an email), clearing the cache in the settings had solved it though. reply digging 1 hour agorootparentUnfortunately this is an issue with the new one. It doesn't just take a long time, it never loads, and can't be fixed with a cache clear or reinstall. reply dinglestepup 3 hours agorootparentprevHm, I have Proton Mail in a pinned tab in FF (Mac) - no issues at all. The only time I re-open it is when FF restarts after an update (~once a month). reply tombert 3 hours agorootparentI feel like this is a somewhat recent change, so I don't know what happened on my computer or within Protonmail; I have an Intel Macbook Pro, and it really seems to slow everything down. Maybe I screwed up a setting but as I said everything else seems to work fine and when I use the Protonmail Bridge it works fine. reply dinglestepup 1 hour agorootparentYes, could potentially be related to a different CPU architecture, but could also be something else eg RAM capacity (I have 64GB) or Proton Mail settings (do you have offline enabled? I don't). reply tombert 12 minutes agorootparentI have 64gb of RAM as well. I don't think I have offline enabled. My CPU is an i9. I'm happy enough with my Mutt solution, and the iOS app is generally ok, and I do like the service overall, so while I complain it's not out of hatred. I just want the service to get better. reply logicprog 17 minutes agoparentprevWell I'm also a paying customer and I'm really glad they're doing this — this way I don't have to awkwardly piece together a VPN, a password manager, a mail client, a notes app, and a Google Docs alternative all from different places, probably paying separate subscriptions to each since I wouldn't trust free services. Instead I get a reasonably good suite of apps for everything privacy-related I need, all for $10/mo. The more they add, the more that money feels worth it and the more affirmed in my choice to pay it I feel. reply domh 5 hours agoparentprevCalDAV and CardDAV support missing is the only reason I still have a google account. I understand it's \"tough\" with e2ee but adding support to the bridge would be perfectly sufficient, then at least I could use local Calendar/Contact apps. reply InsideOutSanta 4 hours agorootparentIt's pretty easy to self-host CalDAV and CardDAV. I went with Baïkal, it took me maybe 15 minutes to install on a server, it's supported by all of the calendar tools I use, and it's worked perfectly fine for a few months now. So now I'm completely free of Google. Maybe not for everyone, but a way more feasible option than most people seem to realize. reply acidburnNSA 3 hours agorootparentAgreed! I used radicale for the same purpose. Very easy installation given I already had a VPS. https://radicale.org reply domh 35 minutes agorootparentprevYeah I've investigated it a couple of times but never pulled the trigger with self-hosting. Could run it on my rpi and access via Tailscale, but seems like something that should be provided by the email provider that I pay money for. They also do have Contacts and Calendar products, but they're completely self-contained and apparently can only be used by protonmail which is mostly pointless. reply aarmenaa 4 hours agorootparentprevI've been considering switching from Fastmail to Proton for Mail/Calendar/Contacts, but I didn't realize their bridge didn't do CalDAV or CardDAV. Also, apparently the bridge is desktop-only -- no mobile? That's kind of a deal breaker. reply attendant3446 4 hours agorootparentprevWhat about mobile devices? There is no bridge and you have to rely on official apps, which is the biggest drawback for me. reply tailspin2019 4 hours agoparentprevAlso a paying customer. I completely agree. They keep doing this, widening their scope constantly while every new product launched seems to get less ongoing attention than the last one. reply jamil7 3 hours agorootparentProbably gunning for enterprise contracts in which they need an answer to every service and product. reply vishnugupta 3 hours agoparentprev> What's the rationale behind releasing yet another half-baked product? New product often means new segment of customers they can go after. Whereas refining existing ones will help reduce the churn. Their sales/marketing pitch gets that much better. reply rapnie 5 hours agoparentprevThis. Also a paying customer. My Android mail app is definitely not fully baked. At times it drains my battery trying unsuccessfully to fetch notifications. Other times it fetches a ton of notifications I had already seen. Proton is on a good path in many ways, but these rapid launches of new apps will kill the company if they don't do it well. reply juandemarco 5 hours agoparentprevMissing Caldav support is really painful. I've had to spin up my own Caldav container (Radicale) and leave Proton Calendar behind, but I'm still unable to send calendar event notifications from any calendar app on mobile, only from thunderbird. reply triceratops 4 hours agoparentprevThe VPN is \"well-done\" but \"useless\"? reply notresidenter 3 hours agorootparentIt's a great product, but I don't need it from them. I bought a protonmail subscription, not a Proton subscription. reply ffsm8 4 hours agorootparentprevVPN are pointless for the vast majority of people. You're essentially just shifting the person you're trusting from your ISP to proton. Downloading copyrighted media is pretty much the only usecase I can think of for such a service, and most people don't do that. The only other usecase would be to conceal your traffic on a public wifi, but you'd be better served just going through your home connection at that point. Pretty much all decent routers provide you with dyndns+VPN services builtin reply WithinReason 3 hours agorootparentIn the UK your ISP is obligated to log all your DNS queries and make it accessible to a large number of government agencies without a warrant. Your VPN provider makes money from not being able to provide that data, many times proven in court. They are not at all comparable. reply sitkack 4 hours agorootparentprevThat is like your opinion, man. VPNs are critical for getting around shenanigans when working out in the world. Especially from sketchy last miles. reply ffsm8 3 hours agorootparentYou're right, I forgot geo blocking entirely as all services I've used it on added mitigations over the years. The last time I've successfully used a VPN for that was around 2015, but there might be services around (which I just dont use) that can still be unlocked by changing the IP, so that'd be a valid usecase for a few people reply digging 3 hours agorootparentprev> Pretty much all decent routers provide you with dyndns+VPN services builtin Most people don't know how to use that or that it even exists. Hell, I didn't know it existed until right now and I'm decently tech savvy. > You're essentially just shifting the person you're trusting from your ISP to proton. Yes absolutely, this is the reason I use a VPN. I have negative trust of every ISP in the USA. They will harvest and sell your browsing history to anyone who will buy it. I have no doubt about that. Some VPN providers probably won't. reply Multiplayer 2 hours agorootparentprevApparently you have never tried to access an \"adult service\" from Louisiana. :) reply balls187 4 hours agorootparentprevAvoid region restrictions are the biggest usecase. A number of my friends use VPNs exclusively for this purpose, geberally because they are big sports fans. reply attendant3446 3 hours agorootparentprevI actually think it's their best (in-house) product (and SimpleLogin from the acquired products). reply McDyver 2 hours agoparentprevTalking of half-baked, one thing I find really frustrating is that on the mobile app you can't even see the mail headers of a message. Absurd reply mrmetanoia 3 hours agoparentprevAgreed, happy paying customer but would rather see them investing in improving Drive. Seems like they're trying to get more enterprise-y which sucks. reply treprinum 3 hours agoparentprevWhat irritates me is that their ProtonMail iOS client always sends a notification when I log into ProtonMail from my laptop and I can't turn that notification off without turning off all notifications. I don't want to be spammed by yet another useless security-freak notification. reply KeyBoardG 5 hours agoparentprevIt is interesting to watch them try to grow so quickly. At some point they'll need to turn more profit to hold all this scale up. We'll see if they can stick to the privacy claims or start to sell out. reply InsideOutSanta 4 hours agorootparentThey just switched to a non-profit system of governance. reply jacooper 4 hours agorootparentprevThey are already profitable without any VC investments. reply 0x1ch 4 hours agoparentprevI can't even search on the mobile app for android... I could about two years ago until they decided to push out half baked rewrites or something. reply mzajc 4 hours agoparentprevEdit: they have since added support for this, my bad --- I am still bummed that ProtonMail doesn't support automatic forwarding. Their rationale is that E2EE makes this impossible, but most of my incoming mail is unencrypted anyway, and I could decrypt the rest myself with Thunderbird and GPG. Lack of automatic forwarding support makes it harder to switch mail providers, on the other hand. reply cedws 4 hours agorootparentIt’s misleading marketing. They sell their email service as “E2EE”, even though the majority of emails flowing through their system are in fact NOT end to end encrypted, they’re visible to Proton in plaintext upon receipt. This is a fundamental limitation of email protocols. You only get E2EE by using PGP at both ends. reply mzajc 4 hours agorootparentIndeed, and as far as I understand, even PGP-encrypted mail can be automatically forwarded and viewed easily, provided I have the correct PGP key installed in my client. reply SahAssar 3 hours agorootparentprev> You only get E2EE by using PGP at both ends. That's true for all email though, right? What is Protons value add? reply mikegreenberg 4 hours agorootparentprevThis is a matter of semantics... anyone who actually cares about E2EE probably understands the nature of email being cleartext over the wire and that Proton can't control what is outside of their control. Maybe inaccurate but I doubt they are misleading (in the sense that they are hoping to fool people into thinking their email is encrypted over the wire). Marketing copy would not likely care to include \"E2EE\" .... \"at the point that Protonmail recieves your message\" on their frontpage. Further, this is explain quite clearly on their FAQ: https://proton.me/support/proton-mail-encryption-explainedreply codetrotter 3 hours agorootparentI’m gonna start selling sugar-free soda and when people point out that there is sugar in the soda I’ll explain to them that the sugar was added to the mixture by a different supplier before the mixture arrived at my factory. My factory does not add any sugar to the soda. Therefore it’s clearly fair to market it as sugar-free! reply koziserek 1 hour agorootparent\"...No sugars added!\" reply bartbutler 4 hours agorootparentprevWe do support automatic forwarding, have since last fall. reply mzajc 4 hours agorootparentThanks for letting me know. Seems like it's a paid feature, however, and I'd rather not pay a monthly subscription for a service I no longer want to use - that was the primary reason I needed automatic forwarding anyway. But I do distinctly recall that Proton has said the feature isn't possible to implement due to E2EE when this question was brought up. What has changed? reply protonmail 4 hours agorootparentWe made it possible, you can learn more here: https://proton.me/blog/email-forwarding reply stockhorn 2 hours agoparentprev(Paying customer) Yes! I cant believe I still cant share a folder with another account on proton drive (apart from read-only sharing via link), but now instead they add ..... reply webkike 5 hours agoparentprevThe connection is encryption, and having all of these services paid for and therefore have better support. I really like protonpass so I was happy to see that I already pay for it reply efitz 4 hours agorootparentPaying customer for many years. I like Proton Pass and switched to it about a month ago from 1Password. It's not quite there yet; I'm thinking of switching back. There are still some sharp edges like lack of support for credit cards, addresses, etc. reply cquintana92 3 hours agorootparentProton Pass supports Credit Cards as a paid feature! reply szszrk 3 hours agorootparentI'm curious why it's important? Do you pass on card details manually that often? reply cquintana92 2 hours agorootparentAutofilling when buying online, having the details handy/ready to be copied if autofill is not an option, keeping track of them in a single place while being encrypted together with other personal info... To me the benefits are many! (Disclaimer: Work in Proton Pass) reply szszrk 1 hour agorootparentThats cool but also so unusual for me. You just don't add card details at all here, and if you do, you just trust that service and save it permanently. If someone is actual heavy card user, he will have temporary/shortlived cards anyway. reply tamimio 3 hours agorootparentprevKeepassxc, or bitwarden, you can run your own instance too. reply digging 3 hours agorootparentprevBitwarden is pretty great. reply drpossum 2 hours agoparentprevI use pass for all my TOTP and keep my passwords separate with KeepassXC. It works really well. I agree and wish for Calendar to use much better integration reply westpfelia 3 hours agoparentprevI can see it as trying to compete with say a google in all competencies. So hopefully once they have tool parity with Gsuite they would buckle down and work on features of each application? reply al_borland 2 hours agorootparentThey need to keep in mind that Google spend decades getting to where they are with the current toolset. Proton shouldn't be expected to replicate it in a couple years. I'm sure people are asking for this stuff, but I hope it is sustainable. I'm a paying customer and only use the email today. With the pace of these releases, I'm not comfortable investing in these new tools, because I'm not sure how long they'll be around. I'm starting to question the email choice, since I'm worried they are spreading themselves too thin. I'm not sure what their financial situation is like, but I hope this isn't all from a bunch of funding or debt they will need to answer for at some point. reply red-iron-pine 1 hour agorootparentprevcertainly not in all competencies, but there is definintely a demand for O365 or GSuite that's not going to actively datamine the hell out of you. This isn't even a \"im a paranoid l33t hacker\", just that I don't want someone capturing 100% of every document and communication in my business. like holy shit, we're gonna let MS hookup their AI to monitor everything all the time? cuz that's what my org is doing with Copilot... reply jamil7 4 hours agoparentprevAlso a paying customer, I'd like it if they would email an invoice every month instead of me needing to go login to the web UI and dig for it when I do my monthly tax reporting. reply KingOfCoders 3 hours agorootparentIf this is invoice griefing group, please 1. Everyone make invoices PDF 2. Send them out every month 3. If I need to log in, make them easy to find on the first page 4. Name them ----.pdf Thanks! reply jamil7 3 hours agorootparentI know right, especially number 4, more often than not I get emailed basically .pdf. reply dx034 2 hours agorootparentprevMy biggest issue with Backblaze B2. It’s so much effort to get my invoice each month. I don’t get why companies send out billing emails but don’t just attach the invoice or insert a link directly to the invoice. reply KingOfCoders 1 hour agorootparentSame, also Backblaze customer :-) reply calvinmorrison 3 hours agorootparentpreva new document has arrived to your document portal. reply KingOfCoders 1 hour agorootparentThis is a startup I wanted to found 10 years ago when writing an inhouse invoice PDF (+ thumbnails etc.) plattform reply denysvitali 2 hours agoparentprevI love Proton Mail, but their mailbox search on Android is just awful. reply tossandthrow 4 hours agoparentprevYep. In the end I switched away from proton due to their negligence on this core product suite. reply maximinus_thrax 2 hours agoparentprev> What's the rationale behind releasing yet another half-baked product? Growth. I'm also a (happy) customer, I've been using their products for years and my personal impression is that they're trying to catch up and build a full productivity suite as fast as possible. reply CivBase 3 hours agoparentprev> What's the rationale behind releasing yet another half-baked product? I suspect they're attempting to build up an attractive package for business customers, competing with the likes of O365 and G-Suite. There's probably a lot more money in that than in personal email hosting. reply philwelch 2 hours agoparentprevOn the one hand I can agree with this—I would love them to focus on refining the current suite of Proton apps. On the other hand, Google’s ability to monitor the contents of Google Docs and engage in censorship is extremely concerning and Proton seems well-placed to provide an alternative. reply jacooper 4 hours agoparentprevThey can't add direct caldav support because it's e2ee, they should add a caldav bridge to their mail bridge, they also should work on contact sync. I agree that drive is underpowered, they still don't have a syncing client on Linux, and their android/iOS client is quite limited and the photo integration is really half baked. However Pass is really great, it has better UI/UX compared to Bitwarden. reply ilrwbwrkhv 5 hours agoparentprevPMs get promoted when doing the shiny new thing instead of improving the dull old thing. reply lagniappe 5 hours agorootparentWhat a world we live in when even the agencies have to deal with PMs reply ajb 5 hours agoprevI always feel conflicted by these kind of announcements, because for me there is significant value in spreading my dependencies across different companies, to reduce risk. I think Proton are great, I would like them to succeed - but I'm not sure I want to put all my eggs in their basket. reply iamkonstantin 4 hours agoparentThen you should welcome the announcement as it offers yet another alternative for hosting docs. I don't think Proton implies that you must use the entire bundle of services — you could always mix and match them with other providers (or self-host, for the ultimate freedom). reply ivan_gammel 4 hours agoparentprevThis specific case seems reasonable. Mail implies Drive (you want to keep large attachments somewhere), both imply Docs (you want to preview those docs somewhere and maybe add some edits). If you want to diversify, Pass may be a good candidate for not using it. reply michaelmior 4 hours agorootparent> both imply Docs You can certainly implement an attachment viewer without having a full fledged document editor. reply ivan_gammel 2 hours agorootparentOpening documents in read-only mode is MVP, but users often want feature parity. This topic is popular on Proton’s uservoice. reply dmw_ng 5 hours agoprevSeems like a massive distraction from their offering for a small company, wonder why they didn't consider something like tight integration with OnlyOffice or similar. Setting out to build a new office suite feels about as sensible as building a new web browser from scratch. Except at least with a browser, you have open specs helping you through most of the endless supply of compatibility problems. reply InsideOutSanta 4 hours agoparentI don't think they built this from scratch, they acquired a company that did something similar (Standard Notes) and are using their technology to build this. reply jacooper 5 hours agoparentprevThey can't, all proton products are end to end encrypted, typical solutions like onlyoffice won't work. reply Ylpertnodi 3 hours agorootparentFor anyone: E2e does not mean 'private'. reply clapsclaps 5 hours agoprevThis is good news considering that it's amazing that in 2024 we still don't have any decent alternative to the Google Docs suite that is not Microsoft. In our small company we tried a self hosted Nextcloud instance and we ended up moving away from that after years of pain. Now we are in HedgeDoc, that is neither ideal because of its lack of central way to manage files collectively, etc. So, I guess good news. reply westpfelia 3 hours agoparentThis is how I see it. People arent thrilled that they aren't as feature rich in other products (cal/mail) but I see it as trying to compete with the whole of Gsuite. And hopefully the more niche features that a hyper technical hackernews reader might want will come then. reply sundarurfriend 4 hours agoparentprevIs Zoho another decent alternative? I hear a good amount of praise for it here, but don't know which product(s) people are referring to and what they're good at. reply solardev 3 hours agorootparentI used Zoho when I was younger and trying out new technologies was still fun. Their mail, docs, CRM, contacts programs were all pretty good, and honestly technologically pretty impressive as far as user-friendly SaaSes go. It's too bad they never got popular in the West (it's an Indian company). In everyday life as an adult, they just don't have the mindshare that the big clouds have. I default to Google Workspace for everything (or whatever it's called now) because that's what everyone else in my social circle use and what most employers use, and being able to seamlessly share stuff with other Google users is much lower friction than trying to get them to sign up (much less pay for) yet another similar service. The network effect is more important than any minor difference in technical merit... reply brightball 2 hours agorootparentYea, I tried going all in on Proton with my consulting work. A client who was using Google scheduled a meeting that I was invited too and I put it on my calendar. Then somebody had to move the meeting but didn’t click the option to send an update when they did. Everyone’s Google calendars updated. My Proton didn’t because they didn’t send the update. Everybody else was on time and I wasn’t, making a terrible impression. In investigating, I found that my Google calendar that had been setup prior to the Proton move also had the update even though it wasn’t on their domain. That is the network effect in action. reply solardev 2 hours agorootparentYeah, calendar invites are a big one. But also the ease of being able to manage sharing via Drive (and be automatically alerted when a Google account owner can't access it), co-edit in Docs (and tagging in comments there), being able to use it as SSO in many places, and having all of that synced to your browser and managed by your Workspace admin. It's the ecosystem that's extremely valuable, not necessarily any individual app. reply presbyterian 3 hours agoparentprevApple Pages as well. It has a web-based cloud version, and it's free. I haven't used it enough to speak on the quality, though. reply thecleaner 4 hours agoparentprevWonder why you don't use Google Docs if they do the job ? reply solardev 3 hours agoparentprevZoho? reply bigstrat2003 3 hours agoparentprevGoogle Docs isn't even good, though? Give me MS Office or even LibreOffice running on the desktop any day of the week. I hate when I work at a place that makes use of Google's shitty imitation. reply benreesman 5 hours agoprevI’ve been a paid Proton user for about a year now and I can’t recommend it highly enough. They’re seriously hard core about security and privacy and the usability is easily a match for any comparable offering. When Google CAPTCHAs me on every single query from a known reputable exit node, yeah, I want that security. reply tylervigen 2 hours agoparentInteresting take. I was a paying personal customer who switched away from ProtonMail. I appreciate it for what it is, but ultimately for me it was just way too slow. The website is incredibly sluggish, and the mobile app is worse. I spent a good 5-10 seconds waiting on a loading screen everything I wanted to check my email. reply sambazi 5 hours agoparentprevnext [–]reply nusl 5 hours agoprevI've evaluated Proton multiple times over the years as a replacement for my existing solution, though each time it feels a bit off. I don't quite know why, but there's too much going on and, from what I understand, much of it is still half-baked or too inconvenient to use. reply InsideOutSanta 4 hours agoparent\"much of it is still half-baked\" Imo, it's not. It's more like 80% baked. More than good enough for daily use, but not on the level of polish or quality of any of the market leaders. Proton Drive is not as nice and convenient as Dropbox, Proton Mail is not as nice and convenient Gmail, Proton Pass is not as nice and convenient as 1Password, and so on. But each of their offerings are good enough to get the job done, the price is fair, and you get the added privacy. reply poetril 2 hours agorootparentThis is exactly why I like it. I understand it won't be for everyone, but it does everything I need for daily use. Mainly mail + calendar, plus drive for some occasional file sharing/upload. The VPN works fine for what I need, and I still use a separate password manager. reply pixxel 5 hours agoparentprev> it feels a bit off. I don't quite know why Maybe, subconsciously, you’ve learnt not to put all your eggs in one corporate basket. reply Vaslo 1 hour agoparentprevIt’s years and billions behind Google. It’s a lot of work to catch up. I’ve been really happy with them and it’s great having my email domains through them reply FredPret 5 hours agoprevMeanwhile, the iPhone app is still so unreliable, I wouldn't sign up for Protonmail again today if I wasn't already in it. Pity, because on desktop - and, when it works, on mobile, it works great. I really like the company. Switching email addresses has so much friction - maybe I should keep a notebook of everyone who has my address so I can let them know of my new address. reply inhumantsar 4 hours agoparent> iPhone app is so unreliable that's interesting. iirc the iPhone app got most of their attention early on, so I figured it would have been solid experience. the early android app was so awful that they rewrote it. the rewrite is much better but it still has its issues. one of the most painful issues I encountered: I'd reply to an email, hit send. then when my reply showed up in the thread, it would be incomplete. at first I thought it was truncating but it turned out to be the last draft that it auto saved before I hit send. I very nearly cancelled my subscription over that one. the web and desktop (which is an electron/tauri/whatever app) does work great. a bit off topic for this thread but sieve filtering is amazing. it makes email automation a breeze. I have it set up so that when an email comes in from a contact, it applies the label that contact has to the email. then any email with certain labels gets (or doesn't) an expiration date. eg: webstore notifications, eg for shipments, are deleted in 30d while notifications about upcoming sales or product announcements are deleted in 3d. likewise GitHub notifications for my repos get 7d expirations and go to my inbox while all others get 3d expirations and never hit the inbox. reply warkdarrior 4 hours agorootparentIsn't Sieve filtering done server-side? How does it work with E2EE? reply inhumantsar 4 hours agorootparentit's only able to operate on header information, which isn't encrypted while in transit reply buzzy_hacker 3 hours agoparentprevI’ve used the iPhone app daily for almost 10 years at this point and it is reliable for me. What problems do you have? reply yett 5 hours agoparentprevWhy not buy a custom domain? You could then easily switch between providers. reply tr3ntg 5 hours agorootparentAdding this to \"simple solutions I've never considered but wow, I should\" Seriously, I've had this same thought after switching to HEY getting pretty frustrated with it. Considered other options, but worried that I'd just repeat the process. However, if I use a custom domain next time around, this whole problem goes away. Yay reply packetlost 5 hours agorootparentPeople actually paid for HEY? I tried out the closed beta for a bit and once they started asking for $100/year I very quickly decided it wasn't worth that. reply doubled112 4 hours agorootparentprevIt doesn't help you with existing emails, but you don't have to worry about receiving new ones. reply pmarreck 4 hours agorootparentprevI'm trying to make HEY work as well. Can we start a side discussion about it? I was initially impressed but now it feels like I have a part time job manually flagging things that should have been seen as spam right away reply piva00 5 hours agorootparentprevI switched to using my own domain for important emails some 10 years ago, after a friend got his Google Account taken over while on a month long hike without internet. When he got back his account had been banned because they used it for click fraud, no way to contact Google to get it reinstated, he lost access to his GMail, with it all email history since 2004, logins to accounts tied to it, etc. I don't want ever to go through this nightmare. reply FredPret 5 hours agorootparentprevI was thinking parent commenter might be stuck with a widely-dispersed Protonmail address. Your solution is the one to go for though. reply lucasyvas 5 hours agoparentprevWhich app? They all work fine for what I expect them to do. reply zeusly 6 hours agoprevHow good is the proton ecosystem if I have multiple mail addresses and calendars? Say I have hello@example.com and hello@example.net, can I use one unified inbox, and can I use both addresses to send and receive calendar invites? Moreover, how easy is it to combine my calendars with my work calendar? I heard it's also not possible to sync contacts with iOS, is that true? reply barron35 5 hours agoparentIt's great for multiple mail addresses. I get mail from multiple domains all in my ProtonMail inbox. Very easy to send from multiple addresses as well. You can also turn on catch all addresses where you'll get all mail sent to anything @yourdomain.com. Very handy to create unique emails for sites I don't want to have my emails I actually use with contacts. I can't really comment on multiple calendars. I haven't experimented much with that and get all my invites sent to one address. reply ajb 5 hours agoparentprevDon't know about calendars. They are one of the better ones for multiple address - there's a limit on the number of a) domains) and b) email addresses you can reply from (but no limit on the number you receive from, with a catch-all). I think their different plans allow different numbers. The one what doesn't have any limits other than bandwidth is migadu. But they don't support second fact properly, last I looked. reply pshirshov 5 hours agoparentprevfastmail would be lot better. I migrated from paid proton to fastmail years ago and still happy. reply buzzy_hacker 3 hours agorootparentI pay for both, use them for different things, but to be clear, fastmail does not have the encryption features that ProtonMail does. Not a direct replacement if you’re interested in the privacy aspects. reply input_sh 2 hours agorootparentWhat encryption features? GPG works with any email provider. reply fullspectrumdev 5 hours agorootparentprevI ended up switching to Fastmail after it being recommended here ages back, and it’s been fantastic. I’ve also used Google Workspace, O365 or whatever MS calls it this week, and Proton as well as self hosting mail in the past. reply input_sh 2 hours agorootparentI'm honestly shocked by how long I've been using Fastmail without having a single complaint to talk about. Usually after using a tool for an extended period of time, there's gonna be some annoyance that you just have to learn to deal with. After five or so years of me using Fastmail, I can't think of a single thing that actually bothers me. reply jddj 5 hours agorootparentprevAny specific improvements? reply ChrisArchitect 5 hours agoprev[dupe] Announcement post: https://proton.me/blog/docs-proton-drive (https://news.ycombinator.com/item?id=40864549) reply tamimio 3 hours agoprevEmails, password manager, VPN, and now documents—absolutely not a wise thing to do. Never put all your eggs in one basket; your whole personal and even professional life shouldn't be entrusted to a single company. reply RDaneel0livaw 2 hours agoparentCompletely agree. I love Proton, been a paying customer for many years now. I do use the Proton Drive app all the time, and occasionally the vpn when I'm at an airport or hotel. But I refuse to use their Pass app, and I similarly will refuse to use this new docs app. I use Standard Notes for all my notes (funny enough they joined with Proton this year lol) and Bitwarden for passwords. And then I just let Apple sync all my contacts, and for calendar it's kind of required that I use the ios calendars for family member sharing reasons. reply genpfault 5 hours agoprevNo not that[1] Proton. [1]: https://en.wikipedia.org/wiki/Proton_(software) reply coldpie 5 hours agoparentSorry. I intentionally chose an internal codename that was ambiguous, generic, and hard to Google, just in case the name leaked before we were ready to go public. It was never supposed to be the public name, it was just another part of the Steam Play umbrella. But, in the end I guess it stuck. Oh well! reply thelopa 1 hour agorootparentI’ve been running Linux for ~20 years. Proton is, without a doubt, a huge leap forward for the ecosystem. I stopped dual booting Windows for games ~5 years ago and haven’t looked back. It’s positively wild to me that native Linux builds for games are often harder to get working than just using proton and the game’s windows build. reply pmarreck 4 hours agorootparentprevI just want to thank you for this awesome project you started that has largely enabled me to use Linux as a main desktop. I've long felt that gaming's \"home OS\" should be Linux (or at least an open-source OS... in my case, big fan of NixOS, even with its new-user warts). Especially when you look at the long term (running older games to show your kids, etc). I'm glad Gabe felt this way too (for a long time now, it seems). Microsoft is too capricious an overlord for what is essentially almost all of gaming, I think. Now if only there was something like proton for macOS that enabled windows API gaming on M1/2/3/4 Macs... (I know Apple has some sort of half-baked-seeming \"game porting toolkit\" that I believe might make use of it, but just something native to Steam on Mac would be sweeeeet) reply cyberpunk 3 hours agorootparentDo you mean… codeweavers crossover? reply efitz 4 hours agoprevDid Engadget jump the gun on this one? I don't see a link, blog post or press release on any of Proton's sites, and I don't see a link in the article. reply wiether 4 hours agoparentPosted in another comment : https://proton.me/blog/docs-proton-drive reply meibo 5 hours agoprevThey are falling into the hole of adding products on top of products, while their core apps are decaying. Please. Fix. The. Android app! It's unusable. I feel like I beg for them to do this in every yearly survey, and then they change the design a little bit, it loses a few features and gets some new ones, while missing basic stuff like unmarking an email as spam. This wouldn't be a problem if it was possible to use K9 or AquaMail with Proton, but that's obviously not an option. reply FredPret 5 hours agoparentI first thought you might be able to get Proton Bridge installed on Android and then link that to the mail app you like, but turns out that's desktop-only. There is a ridiculous workaround involving a home server with Bridge and Wireguard on it: https://www.reddit.com/r/ProtonMail/comments/15nj8f7/comment... reply sofixa 4 hours agoparentprev> They are falling into the hole of adding products on top of products, while their core apps are decaying. It's not a hole, it's only natural. It's easier to add new products than it is to improve existing ones (tech debt), and new products can bring in new customers, make existing customers happier, etc. which is easier to see and justify. That being said, the Android app has some weird gaps (like can't snooze an email) that probably won't take long to fix. reply meibo 4 hours agorootparent> that probably won't take long to fix. That's what I told myself about the spam thing I mentioned when they released the redesign, and it's still not possible, at least on the version I'm using at the moment. I'm sure there's a lot of background here and corporate dynamics we're not aware of, it just doesn't feel great as a paying customer. The apps have never really been fully adequate. reply sundarurfriend 4 hours agorootparentprev> new products can bring in new customers, make existing customers happier Doesn't seem to be much of the latter in this thread (but then again, this is HN...) reply sofixa 4 hours agorootparent> Doesn't seem to be much of the latter in this thread (but then again, this is HN...) Insert famous \"Dropbox is just FTP, who would pay for it\" comment here :) reply shinryuu 5 hours agoparentprevAre you running the latest version? They archived their old version of the android app 14th of May this year. https://github.com/ProtonMail/proton-mail-android reply ThinkBeat 3 hours agoprev(Paying customer) I wish they concentrated more on their core offerings and making them as solid as possible. If they developed an entire (web) wordprocessor from scratch that seems like an enormous effort and cost quite outside of the core offerings. If they have (or will) open source it that would be grand. reply FlamingMoe 5 hours agoprevThere are many Google Docs alternatives, including some great open source options such as HedgeDoc and Outline. What is missing a great Excel or Sheets alternative. I wanted to break my business out of the Google Workspace ecosystem earlier this year, but the lack of a good spreadsheets alternative was one of the main things holding me back. reply Brechreiz 5 hours agoparent>great Excel or Sheets alternative cryptpad.fr reply jMyles 5 hours agoparentprevcryptpad? reply blackeyeblitzar 3 hours agorootparentHard to call it “great”. To me it feels awkward to use. reply jszymborski 4 hours agorootparentprevHonestly, I wish Proton would have just funded cryptpad and hosted a paid instance instead. reply blackeyeblitzar 3 hours agoprevI’m so happy to see this. I’m not sure why people are complaining here. Maybe you just aren’t their target audience. But many of us want a privacy focused alternative to big tech. reply mark_l_watson 5 hours agoprevI am a long paid user of ProtonMail so I am glad to see more services. I am trying it now using Safari on iPadOS and it is functional except for one thing: the page layout is very narrow, just 50 columns, and I don’t see how to change that. reply attendant3446 3 hours agoprevI just noticed this: \"You can upload .docx documents, edit them\". Only docx is supported? reply JumpCrisscross 5 hours agoprevDoes Proton support calendar delegation yet? (Same for Fastmail. Supporting assistants would open up their market.) reply tech_ken 5 hours agoprevGoogle docs’ value is the network effects. Everyone has a Google account, so GDocs is like a universal collaboration tool. Does not seem like there’s a huge space for something like this, it’s going to be a huge pain every time I want to share a doc with someone. Seems like it would be way better to try and distinguish their already successful products by continuing to improve their feature set. For example: their email search bar is hot garbage. Give me the perfect email and calendar client and I’ll be subscriber forever, but I definitely don’t want to pay for an ecosystem of half-finished Google knockoffs reply jlarocco 2 hours agoparentNot everybody has a Google account. reply bulbosaur123 4 hours agoprevDaily reminder Proton snitched their users: https://restoreprivacy.com/protonmail-discloses-user-data-le... reply mindracer 4 hours agoparentThey’re not outside the law, if the police come knocking with a legal request they have to provide data\\details they have. What would you have them do? reply fulafel 3 hours agorootparentIn this specific case of a recovery email address, maybe there is something that could be done so that they wouldn't hold the email address itself. At least 2 options come to mind. reply deely3 3 hours agoparentprevDaily reminder thats actually Apple. From article: > The core of the controversy stems from Proton Mail providing the Spanish police with the recovery email address associated with the Proton Mail account. > Upon receiving the recovery email from Proton Mail, Spanish authorities further requested Apple to provide additional details linked to that email, leading to the identification of the individual. reply demosthanos 4 hours agoparentprevDaily reminder that Proton is a company that operates legally in jurisdictions that have police forces and laws. If you're a dissident in one of those countries you'll definitely need something else (or a few layers on top of Proton to protect your real IP), but it's weird to see people turning this into a moral problem with Proton. reply rty32 3 hours agorootparentSure, but maybe don't advertise \"protecting free speech\" as part of their \"impact\", because it only goes so far. https://proton.me/about/impact And you don't even need to be a dissident in \"one of those countries\". As long as Europol's arm (or some other organization that Swiss is part of) can reach you, you are not covered, as in https://restoreprivacy.com/protonmail-logs-users/ I don't have an opinion on whether this is ok or not (protecting dissidents and protecting \"real\" criminals), I am just sick of false advertising. It is because of these reasons I chose Fastmail over Proton when I was looking for an alternative. The E2EE itself is almost bogus, and I would rather look for othet features that I need. reply demosthanos 2 hours agorootparentThere's a great blog post that identifies your position as the Copenhagen Interpretation of Ethics [0]: > The Copenhagen Interpretation of Ethics says that when you observe or interact with a problem in any way, you can be blamed for it. At the very least, you are to blame for not doing more. Even if you don’t make the problem worse, even if you make it slightly better, the ethical burden of the problem falls on you as soon as you observe it. In particular, if you interact with a problem and benefit from it, you are a complete monster. I don’t subscribe to this school of thought, but it seems pretty popular. Proton is guilty because they attempt to protect free speech and aren't able to do so completely. Fastmail is not guilty because they don't do anything more to protect free speech than any other provider. Do you see the problem? [0] https://gwern.net/doc/philosophy/ethics/2015-06-24-jai-theco... reply johnkizer 1 hour agorootparentprevI agree that false advertising would upset me...what on that Proton \"impact\" page is actually false, though? And in what way would FastMail not be impacted by analogous events? https://www.itnews.com.au/news/fastmail-loses-customers-face... I do agree that the value of email encryption for 99% of users is overstated, given the fundamental nature of email communications to begin with. reply buzzy_hacker 3 hours agorootparentprevWhen I sign up for a service, I don’t expect them to break the law on my behalf, regardless of their advertising. reply deely3 2 hours agorootparentprevFastmail with servers in USA.. You sure it is more protected than Switzerland? reply Pete-Codes 4 hours agoprevDoes the other person need a proton account to use it as well? reply protonmail 3 hours agoparentRecipients who do not have a Proton account need to create a free or paid Proton account to access the shared content. The email invitation includes a link to the Proton sign-up page. Once account creation is successful, they will receive another email with the link that allows them to access the file. reply InsideOutSanta 4 hours agoparentprevYes, but a free account will work. reply unplgtc 4 hours agoprevHas anyone (Proton included) talked about their E2EE encryption claims for this web-based document editor? My understanding of E2EE on the web is that it's as much marketing hype as it is true security, given that they can freely break it at any time they please. Have they actually attempted to solve any problems associated with this space or are they just claiming it and getting the marketing points? reply chadsix 2 hours agoparentWe've been addressing this by taking all of this 'trust' out of the equation at IPv6.rs which is all in the open [1][1] https://github.com/ipv6rslimited/ reply ognarb 5 hours agoprevProton does a lot of open source washing. Their public communication often mention that they are open source, while in reality only some of their clients are open source and the uploaded source code[1] often lags behind by months (currently 3 months). [1]: https://github.com/ProtonMail/WebClients reply lopkeny12ko 4 hours agoprevThis title is beyond confusing, and the article doesn't even attempt to make it clearer. What does \"own version of Google Docs\" even mean? I took two reads of the article to understand that Proton's \"flavor of Google Docs\" actually has nothing to do with Google and is just a collaborative document product that intends to compete with Google Docs. The title makes it sound like Proton is offering a reskinned-Google-Docs-in-an-iframe which is incredibly odd. reply crazygringo 3 hours agoprev [–] Proton seems to be suggesting that this is somehow more secure than Google Docs [1]. But Google Docs/Workspace already supports what they call \"client-side encryption\" [2] if you want to pay for it and enable it. Docs never sees your actual data. How is this any different? Trying to go up against MS Office and Google Docs/Workspace sounds like an unbelievably difficult, huge, and therefore risky proposition -- akin to writing your own browser from scratch and trying to compete with Chrome, Edge, and Safari. Not really sure this is a wise business move for Proton. [1] https://proton.me/blog/docs-proton-drive [2] https://support.google.com/a/answer/10741897?hl=en reply MetaWhirledPeas 3 hours agoparent [–] > Trying to go up against MS Office and Google Docs/Workspace sounds like an unbelievably difficult, huge, and therefore risky proposition My guess is that Proton sees that it appeals to individuals wanting an alternative to Google and Microsoft's online services. Email alone is not enough to cut the umbilical, so Proton is adding more and more coverage. reply crazygringo 2 hours agorootparent [–] Ah got it -- if this is aimed at individuals not businesses then it makes more sense. Also because individuals tend to mostly use only Google Docs, much less Sheets and almost no Slides -- so the Docs clone by itself would be sufficient. reply brnt 1 hour agorootparent [–] Ever since Google Docs launched, it has been the most valuable thing about having an account. Document sharing and central management are a hard thing that Google Docs solves realy well. I'll be very glad to try this out. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Proton has introduced Proton Docs, a secure alternative to Google Docs, featuring rich editing and collaboration tools with end-to-end encryption.",
      "Proton Docs supports advanced formatting, image embedding, and multiple formats, including Microsoft .docx, and allows real-time collaboration with features like comments and cursor tracking.",
      "This launch is part of Proton's broader expansion, which includes a VPN, encrypted calendar, and password manager, with Proton Docs becoming available to users shortly."
    ],
    "commentSummary": [
      "Proton has introduced a collaborative rich text editor, similar to Google Docs, aiming to provide a secure, encrypted alternative.",
      "Users are divided, with some appreciating the new tool and others concerned about Proton expanding its product range instead of enhancing existing services like email and calendar.",
      "Discussions include the open-source nature of Proton's offerings and comparisons to other services, with some users wary of consolidating all their data within one company's ecosystem."
    ],
    "points": 305,
    "commentCount": 209,
    "retryCount": 0,
    "time": 1720005929
  },
  {
    "id": 40861520,
    "title": "Why Bridges Don't Sink",
    "originLink": "https://practical.engineering/blog/2024/7/2/why-bridges-dont-sink",
    "originBody": "Why Bridges Don't Sink July 02, 2024 by Wesley Crump [Note that this article is a transcript of the video embedded above.] The essence of a bridge is not just that it goes over something, but that there’s clear space underneath for a river, railway, or road. Maybe this is already obvious to you, but bridges present a unique structural challenge. In a regular road, the forces are transferred directly into the ground. On a bridge, all those forces on the span get concentrated into the piers or abutments on either side. Because of that, bridge substructures are among the strongest engineered systems on the planet. And yet, bridge foundations are built in some of the least ideal places for heavy loading. Rivers and oceans have soft, mucky soils that can’t hold much weight. Plus, obviously, a lot of them are underwater. What happens when you overload soil with a weight it can’t handle? In engineering-speak, it’s called a bearing failure, but it’s as simple as stepping in the mud. The foundation just sinks into the ground. But, what if you just keep loading it and causing it to sink deeper and deeper? Congratulations! You just invented one of the most widely used structural members on earth: the humble foundation pile. How do they work, and how can you install them underwater? I’m Grady, and this is Practical Engineering. Today we’re having piles of fun talking about deep foundations. I did a video all about the different types of foundations used in engineering, but I didn’t go too deep into piles. A pile is a fairly simple structural member, just a long pole driven or drilled into the ground. But, behind that simplicity is a lot of terrifically complex engineering. Volume 1 of the Federal Highway Administration’s manual on the Design and Construction of Driven Pile Foundations is over 500 pages long. There are 11 pages of symbols, 2 pages of acronyms, and you don’t even get to the introduction until page 46. And just a little further than that, you get some history of driven piles. Namely that the history has been lost to time. Humans have been hammering sticks into the ground since way before we knew how to write about it. And that’s pretty much all a driven pile is. The first piles were made from timber, and wood is still used all these years around the world. Timber piles are cheap, resilient to driving forces, and easy to install. But, wood rots, it has an upper limit on length from the size of the tree, and it’s not that strong compared to the alternatives. Concrete piles solve a lot of those problems. They come in a variety of sizes and shapes, and again, are widely used for deep foundations. One disadvantage of concrete piles is that they have to be pretty big to withstand the force required to drive them into ground. Some concrete piles can be upwards of 30 inches or 75 centimeters wide. It is hard to hit something that big hard enough to drive it downward into soil, and a lot of ground has to either get out of the way or compress in place to make room. Steel piles solve that problem since they can be a lot more slender. Pipe piles are just what they sound like, and the other major alternative is an H-pile. Your guess is as good as mine why the same steel shape is an I-beam but an H-pile. But, no matter the material, all driven piles are installed in basically the same way. Newton’s third law applies to piles like everything else. To push one deep into the ground creates an equal and opposite reaction. You would need either an enormous weight to take advantage of gravity or some other strong structure attached to the ground to react against and develop the pushing force required to drive it downward. Instead of those two options, we usually just use a hammer. By dropping a comparatively small weight from a height, we convert the potential energy of the weight at that height into kinetic energy. The force required to stop the hammer as it falls gets transferred into the pile. Hopefully this is intuitive. It’s pretty hard to push a nail into wood, but it’s pretty easy to hammer it in... well, it’s a little bit easier to hammer it in. There are quite a few types of pile drivers, but most of them use a large hammer or vibratory head to create the forces required. Maybe it goes without saying, but the main goal of a foundation is to not move. When you apply a load, you want it to stay put. Luckily, piles have two ways to do that (at least for vertical loads). The first is end-bearing. The end, or toe, of a pile can be driven down to a layer of strong soil or hard rock, making it able to withstand greater loads. But there’s not always a firm stratum at a reasonable depth below the ground. Quote-unquote “bedrock” is a simple idea, but in practice, geology is more complicated than that. Luckily, piles have a second type of resistance: skin friction, also known as shaft resistance. When you drive a pile, it compacts and densifies the surrounding soil, not only adding strength to the soil itself, but creating friction along the walls of the pile that hold it in place. The deeper you go, the more friction you get. Let me show you what I mean. I have my own pipe pile in the backyard that I’ve marked with an arbitrary scale. When I drop the hammer at a prescribed height, the pile is driven a certain distance into the ground. Do this enough times, and eventually, you reach a point where the pile kind of stops moving with each successive hammer blow. In technical terms, the pile has reached refusal. I can graph the blow count required to drive the pile to each depth, and you get a pretty nice curve. It’s easy to see how it got stronger against vertical loads the deeper I drove it in. Toward the end, it barely moved with each hit. This is a really nice aspect of driven piles, you install them in a similar way to how they’ll be loaded by the final design. Of course, bridges and buildings don’t hammer on their foundations, but they do impose vertical loads. The tagline of the Pile Driving Contractors Association is “A Driven Pile is a Tested Pile” because, just by installing them, you’ve verified that they can withstand a certain amount of force. After all, you had to overcome that force to get them in the ground. And if you’re not seeing enough resistance, in most cases, you can just keep driving downward until you do! But piles don’t just resist downward forces. Structures experience loads in other directions too. Buildings have horizontal, or lateral, loads from wind. Bridges see lateral loads from flowing water, and even ice or boats contacting the piers. Both can experience uplift forces that counteract gravity from floods due to buoyancy or strong winds. If you’ve ever hammered in a tent stake, you know that piles can withstand loading from all kinds of directions. And then there’s scour. The soil along a bridge might look like this right after the bridge is built, but after a few floods, it can look completely different. Engineers have to try and predict how the soil around a bridge will scour over time, from natural changes in the streambed and those created by the bridge itself. Then they make sure to design foundations that can accommodate those changes and stay strong over the long term. This is why bridge foundations sometimes look kind of funny. Loads transfer from the superstructure down into the piers. The piers sit on a pile cap that transfers and distributes loads into the piles themselves. Those piles can be vertical, but if the engineer is expecting serious lateral loads, some of the piles are often inclined, also called battered piles. Inclined piles take better advantage of the shaft resistance to make the foundation stronger against horizontal loads. As important and beneficial as they are, driven piles have some limitations too. For one, they’re noisy and disruptive to install. Just last year, I had two friends on separate trips to Seattle who sent me a video of the exact same pile-driving operation. It’s good to have friends who know how much you like construction. But my point is, this type of construction is pretty much impossible to ignore. In dense urban areas, most people are just not willing to put up with the constant banging. Plus the vibrations from installing them can disrupt surrounding infrastructure. Pile driving is crude; in many cases, the piles aren’t designed to withstand the forces of the structure they’ll support but rather the forces they’ll have to experience during installation which are much higher. They can’t easily go through hard geological layers, cobbles, or boulders; they can wander off path, since you can’t really see where you’re going, and they can cause the ground to heave because you’re not removing any soil while you force them into the subsurface. The second major category of piles solves a lot of these problems. And, wouldn’t you know it? There’s an FHWA manual that has all the juicy details - Drilled Shafts: Construction Procedures and Design Methods. This one a whopping 747 pages long. A drilled shaft is also exactly what it sounds like. The basic process is pretty simple. Drill a long hole into the ground. Place reinforcing steel in the hole. Then fill the whole thing with concrete. But, bridge piers are often, as you probably know, installed underwater. Pouring concrete underwater is a little tricky. Imagine trying to pour a smoothie at the bottom of a pool! Let me show you what I mean. This is my garage-special bridge foundation simulator. It has transparent soil in the form of superabsorbent polymer beads… and you know we have to add some blue water too. You can probably imagine how easy it might be to drill a hole in this soil. It’s just going to collapse in on itself. We need a way to keep the hole open so the rebar and concrete can be installed. So, drilled shafts installed in soft soils or wet conditions usually rely on a casing to support the walls. Installing a casing usually happens while the hole is drilled, following the auger downward. I tried that myself, but I only have two hands, and it was pretty unwieldy. So, just for the sake of the demo, I’m advancing the casing into the soil ahead of time. Now I can drill out the soil to open the shaft. And now I’m realizing the limitations of my soil simulant. It was still pretty hard to do, even with the casing in place. It took a few tries, but I managed to get most of it out. So now I have an open hole, but it’s still full of water. Even if your casing runs above the water surface, and you try to pump it out, you can still have water leaking in from the bottom. In ideal conditions, you can get a nice seal between the bottom of the casing and the soil, but even then, it’s pretty hard to keep water out of the hole, and luckily it doesn’t matter. Instead of concrete, I’m using bentonite clay as a substitute. It’s got a similar density, and it’s perfect for this demo because you can push it through a small tube… if you get the proportions right. Ask me how I know. This is me pondering the life decisions that led up to me holding a gigantic syringe full of bentonite slurry in my garage. You can’t just drop this stuff through the water. It mixes and dilutes, just turning into a mess. Same is true for concrete. The ratio of water to cement in a concrete mix is essential to its strength and performance, so you can’t do anything that would add water to the mix. The trick is a little device called a tremie. Even though it has a funny name, it’s nothing more than a pipe that runs to the bottom of the hole. As long as you keep the end of the tremie below the surface of the concrete that you’re pumping in, or concrete simulant in my case, there’s no chance for it to mix with the water and dilute. I’m just pushing the clay into the casing with a big syringe, making sure to keep the end of the tube buried. Because concrete is a lot more dense than water, it just displaces it upward, out of the hole. In underwater installations, the casing is often left in place. One advantage is that you can build a floating pile cap. Instead of building a big cofferdam and drying out the work area to construct a big concrete structure, sometimes you can raise the pile cap into or above the water surface, reducing the complexity of its construction. These “high rise” pile caps are used a lot in offshore wind turbines. But, not all casings are permanent. In some situations, it’s possible to pull the casing once the hole is full of concrete, saving the sometimes enormous cost of each gigantic steel tube. I tried to show this in my demo. It’s not beautiful, but it did work. Again, the concrete is dense, so the pressure it exerts on the walls of the hole is enough to keep the soil from collapsing. And because drilled shafts can be much larger than driven piles, sometimes you don’t even need a group of them. Lots of structures, including wind turbines, highway signs, and more, are built on mono-pile foundations. Just a single drilled shaft deep in the ground, eliminating the need for a pile cap altogether. Another interesting aspect of drilled shafts is that you can ream out the bottom, creating an enlarged base that increases the surface area at the toe. This helps reduce a pile’s tendency to sink, and it can help with uplift resistance too. Driven piles and drilled shafts are far from the only types of deep foundation systems. There are tons of variations on the idea that have been developed over the years to solve specific challenges: Continuous flight auger piles do the drilling and concreting in essentially one step, using a hollow-stem auger to fill the hole as it’s removed. Then reinforcement is lowered into the wet concrete. You can fill a hole with compacted aggregate instead of concrete, called a stone column or tradename Geopier if you’re only worried about compressive loads. Helical or screw piles twist into the ground, instead of being hammered, reducing vibrations and disturbance. Micropiles are like tiny drilled shafts used when there are access restrictions or geologic constraints. And of course, there are sheet piles that aren’t really used for foundations but are driven piles meant to create a wall or barrier. Let me know if I forgot to mention your favorite flavor of pile. Even though they’re usually much stronger than shallow foundations, piles can and do fail. We’ve talked about San Francisco’s famous Millennium Tower in a previous video. That’s a skyscraper on a pile foundation that sank into the ground, causing the building to tilt. It seems like they mostly have it fixed now, but it’s still in the news every so often, so only time will tell. In 2004, a bridge pier on the Lee Roy Selmon Expressway in Tampa, Florida sank 11 feet (more than 3 meters) while it was still under construction because of the complicated geology. It cost 90 million dollars to fix and delayed the project’s completion by a year. These case studies highlight the complexity of geotechnical engineering when we ask the ground to hold up heavier and heavier loads. The science and technology that goes into designing deep foundations are enough to spend an entire career studying, but hopefully, this video gives you a little insight into how they work. July 02, 2024 /Wesley Crump",
    "commentLink": "https://news.ycombinator.com/item?id=40861520",
    "commentBody": "Why Bridges Don't Sink (practical.engineering)236 points by chmaynard 19 hours agohidepastfavorite81 comments bell-cot 8 hours agoFavorite bit: > The tagline of the Pile Driving Contractors Association is “A Driven Pile is a Tested Pile” because, just by installing them, you’ve verified that they can withstand a certain amount of force. After all, you had to overcome that force to get them in the ground. And if you’re not seeing enough resistance, in most cases, you can just keep driving downward until you do! reply etrautmann 4 hours agoparentI can imagine that slow static loading could allow sinking whereas dynamic force would not. Soil liquification is a weird thing, analogous to silly putty where it can be soft when manipulated slowly but hard when impacted quickly. reply gosub100 1 hour agorootparentEspecially for trains. For one, they are much more susceptible to sinking, but also likely produce all kinds of resonance. reply kurthr 4 hours agorootparentprevYeah, it also assume that the pile you're driving can be arbitrarily long and will last forever. They used to be made with trees, for which this is obviously false. reply leeter 3 hours agorootparentIt depends. Fully soaked ground will actually preserve wooden piles (wood decay is aerobic and requires oxygen). This is why Venice and New Orleans are both built on them (sinking issues aside because they have other issues). The piles in both cases are quite stable because the ground is completely soaked. Where you run into issues is where water and air meet. I would imagine wooden piles in just water would have issues with shipworm (in appropriate venues). But the ones in fully soaked soil seem to last just fine. I suspect, but don't have data on, that wooden piles may actually last longer in those exact circumstances due to galvanic issues with concrete and rebar or metal pilings. reply throw0101c 2 hours agorootparent> Fully soaked ground will actually preserve wooden piles (wood decay is aerobic and requires oxygen). When building fences, the ground-air interface is often where rot occurs, and there are products to protect that area: * https://www.postsaver.com/en-gb/products/pro-sleeve-fence-po... reply bonestamp2 1 hour agorootparentAny idea how well those stand up to lawn trimmers? reply eep_social 3 hours agorootparentprev> Venice and New Orleans are both built on them Parts of Amsterdam as well. reply Cthulhu_ 12 minutes agorootparentBut they don't last forever, so a lot of them are being replaced at the moment. Expensive operation as they have to be replaced in-place, but Amsterdam canal front houses are prime real estate. reply steveBK123 7 hours agoparentprevMany have said similar about their code reply duped 3 hours agorootparentUnless you are talking about fancy dependent typing you might misunderstand the quip. Writing code does not test it. reply CyberDildonics 5 hours agorootparentprevWhat does this mean exactly? reply marcosdumay 4 hours agorootparentUser-side tests are the only tests that really matter. Everything else you do is there just to reduce the odds of users tests catching anything. But you don't get any certainty before that step... that happens after your software is on production and people depend on it. (Of course, that's a worldview that can be either very beneficial or incredibly harmful depending on what you are creating. It's not good to see it applied to bridges, but I believe the OP did it in jest.) reply gonzo41 4 hours agorootparentThat's why we call it big test, not production. reply mardifoufs 4 hours agorootparentprevMaybe it's a parallel to \"if it runs, it works\" :) reply samtho 5 hours agorootparentprevUtilizing “Brute Force” as a testing and verification strategy. reply steveBK123 4 hours agorootparentprevworks on my box reply CyberDildonics 4 hours agorootparent\"if you’re not seeing enough resistance, in most cases, you can just keep driving downward until you do\" -> \"Many have said similar about their code\" -> \"works on my box\" How does this make sense or have any coherency? reply yencabulator 1 hour agoparentprevTested at the moment of installation != test valid 30 years later reply SideburnsOfDoom 8 hours agoparentprev> in most cases, you can just keep driving downward until you do! I feel that the cases in which that technique doesn't work are stories to be told. Do you just keep driving downward for a very long time? How long? reply lqet 6 hours agorootparentWell, whatever you do, do not perforate an anhydrite layer! https://en.wikipedia.org/wiki/Staufen_im_Breisgau#Geothermal... reply Terr_ 40 minutes agorootparentAlso don't accidentally let a lake--and the boats in it--start filling your tunnels through salt. https://en.wikipedia.org/wiki/Lake_Peigneur reply pixl97 4 hours agorootparentprevAnother one to watch out for is mud diapirs. In coastal deltas where thousands of feet of infill has occurred over time the interaction between hydrocarbon formation and organic silts can create mud volcanoes. https://www.researchgate.net/figure/Comparison-of-signatures... These can be anywhere things that shoot liquid mud out of the ground to areas of very deep low seismic velocities where you could drive a pile thousands of feet to the bottom of hell and barely get any resistance. Much the same, one should be careful when drilling into mud layers https://en.wikipedia.org/wiki/Sidoarjo_mud_flow reply crazygringo 4 hours agorootparentprevWow. I knew drilling could cause land to sink. I never imagined it could cause land to rise. Fascinating, thanks! reply orls 5 hours agorootparentprevThis is fascinating, thankyou! reply bell-cot 7 hours agorootparentprevIANAE (No An Engineer), but I think he mentions both the issues of piles wandering off-course, and of unanticipated piling problems causing major budget & scheduling issues. From a structural PoV, an extremely long piling in soft-ish soil will start having problems with lateral deflection - which it is too thin (relative to length) to resist. Then there's the case of \"we think we finally hit bedrock...but what if it's just a big boulder?\". I can imagine cases of pilings running into large underground caverns, or penetrating strata containing water / gas / petroleum under pressure. Edit: From a quick search... In some locations, bedrock may not start until >1000' below the surface. And here's a very quick & simple intro to the fact that \"bedrock starts at depth D\" is usually too simplistic: https://education.nationalgeographic.org/resource/bedrock/ reply adolph 6 hours agorootparent> I can imagine cases of pilings running into large underground caverns Example being the Lake Peigneur disaster. https://64parishes.org/entry/lake-peigneur-drilling-accident On the morning of November 20, 1980, the crew drilling near the salt mining operations reported that the tip of their drill shaft was stuck. After the crew removed the tip, they heard strange noises and abandoned the platform in the nick of time. A giant mud crater began sucking down barges, rigs, and almost some fishermen who escaped with moments to spare. reply trilbyglens 4 hours agorootparent> Even though responsible parties were held liable, the underground salt mining operations at Jefferson Island were effectively brought to a halt. Hundreds of workers lost their jobs and were not included as part of the settlement. Has to be the most typical capitalist outcome imaginable. I'll bet you a million dollars that all those schmucks continued voting R even after this experience. reply kortilla 1 hour agorootparentThat’s at will employment. Works exactly the same fucking way in California where “those schmucks” certainly aren’t voting R. reply adolph 3 hours agorootparentprevIn 1980 south Louisiana, “those schmucks” were likely staunch Democrats, following their forebears since the Republican association with reconstruction efforts after the American civil war. reply moffkalast 6 hours agorootparentprevhttps://en.wikipedia.org/wiki/Kola_Superdeep_Borehole reply 0xTJ 8 hours agorootparentprevSatan, far below some very deep, soft, and slippery soil where an overpass needs to go: > What the heck? reply Log_out_ 1 hour agoparentprevhow does that hold up to quake liquification? reply Terr_ 11 hours agoprev> But, what if you just keep loading it and causing it to sink deeper and deeper? I believe this is the same fundamental engineering method used in a swamp by Herbert's father in Monty Python and the Holy Grail. [0] [0] https://m.youtube.com/watch?v=w82CqjaDKmA reply bityard 6 hours agoparentWhen I started here, all there was was swamp. All the kings said I was daft to build a castle on a swamp, but I built it all the same, just to show 'em. It sank into the swamp. So I built a second one. That sank into the swamp. So I built a third one. That burned down, fell over, then sank into the swamp. But the fourth one stayed up. And that's what you're going to get, Lad, the strongest castle in these islands. reply Animats 19 minutes agorootparentThe real world version of that: The causeway for the Lucin Cutoff across the Great Salt Lake.[1] The Southern Pacific dumped in fill rock starting in 1902, and the rock sank into the sediment. But they didn't give up. They kept dumping in more rock. They still couldn't get above the water line. So they built wooden trestles on the foundation thus created. That worked, but the trestle was too weak and limited to slow trains. So eventually, the Union Pacific dumped in far more rock and built a solid rock causeway all the way across the lake. The causeway had to be raised in 1986 and strengthened. Today, it carries long UP freight trains, part of the transcontinental main line. [1] https://utahrails.net/pdf/UP_Great-Salt-Lake-Causeway_2007.p... reply jonplackett 10 hours agoparentprevOne day son, this will be all yours! What, the curtains? reply rob74 9 hours agoprev> Quote-unquote “bedrock” is a simple idea, but in practice, geology is more complicated than that. There is always bedrock, but in some places your pile would have to be really long to reach it: > The gravel deposits of 100 m (330 ft) are the deepest in the south of Munich and decrease towards the north. (from https://en.wikipedia.org/wiki/Munich_gravel_plain - not saying this is anything really extraordinary, but it's the area I'm most familiar with) reply EdwardDiego 8 hours agoparentThe Otira Gorge Viaduct in New Zealand, that carries a highway that crosses the Southern Alps, has its foundations in a deep layer of talus that has fallen off Hills Peak over centuries - that movement of rock being why they built the viaduct to replace the road - as the slope eroded the road had to be moved higher up the slope, adding more switchbacks to the infamous Zig Zag [0]. Plus the falling rock that made the road dangerous. They were determined to hit bedrock, but yeah, was buried too deep. [1] [0]: https://teara.govt.nz/files/p-8788-gns.jpg [1]: https://www.stuff.co.nz/national/117150792/awardwinning-otir... reply quibono 6 hours agorootparentTIL New Zealand have their own Alps! reply munificent 34 minutes agorootparentThe North Cascade Mountains in the Pacific Northwest are also sometimes called the \"American Alps\". (Personally, I think it's a silly name. The Cascades are majestic enough in their own right and need no comparison to any other mountains.) reply stonemetal12 4 hours agorootparentprevTechnically \"Alps\" is the plural of \"alp\", which means a very high mountain. reply wongarsu 3 hours agorootparentHowever \"alp\" comes from Latin \"Alpes\", which is the mountain range in Western Europe we now call the Alps. The word has become genericized to a degree. One the other hand Alps used to be one very specific mountain range, and alp a mountain in that mountain range, so surprise at some other place calling their mountain range Alps is understandable. reply fsckboy 57 minutes agorootparent>surprise at some other place calling their mountain range Alps is understandable yes, if you come from Wellington in Suffolk and you fly to Wellington in NZ, and then encounter that the nearby mountains are called Alps, you would be shocked, shocked reply srott 9 hours agoprevSome of them wont sink because they float... https://en.wikipedia.org/wiki/Nordhordland_Bridge reply jtbayly 4 hours agoparent\"The last tolls were collected on 31 December 2005.” Let that sink in. They paid for the project and then stopped taking everybody’s money. That was the plan in Chicago, too... reply rootusrootus 3 hours agorootparentIMO it's probably a better idea to just keep on collecting them, and putting it away for the future. E.g. the I-5 bridge(s) across the Columbia River had tolls which stopped when Oregon & Washington bought the bridge, and now look where we are at. We have a 110 year old bridge needing replacement and no funds set aside for it. So what they will undoubtedly do is add tolls after spending a few billion to build a new bridge, and eventually it will get paid off. We could have been saving up for the cost and getting interest on it instead of the other way around. Even with a fairly modest toll, when you have a century to save. This does require some legislative fortitude, however, to set aside the money for real and not just spend it on other things. reply jppittma 1 hour agorootparentTo me, the way they've done it seems correct. In your mind, where does the interest come from on the money saved for the bridge? The government has to be collecting interest from somebody no? reply kortilla 1 hour agorootparentLocal governments use banks. What are you getting at? reply rootusrootus 57 minutes agorootparentprevI assume the state can buy shares in index funds like the rest of us. reply jppittma 28 minutes agorootparentSo, lets expand that idea a bit. Why doesn't the government just buy a lot of shares in index funds, kind of like an endowment, and then never collect any taxes? I can see a world where a large portion of private enterprise is held/managed by the government, and the proceeds of that is used to fund public works. reply gosub100 1 hour agorootparentprevYou can't trust politicians to just save money for the future. It will be abused by both sides. One side will gain votes by diverting it to something that has nothing to do with transportation, the other side will gain votes by repealing it and taking credit for lowering taxes. reply marssaxman 2 hours agorootparentprevWe did that here in Seattle, where we have the longest floating bridge in the world, SR 520 across Lake Washington: tolls stopped in 1979 after construction was paid off. Alas, tolling resumed in 2011, to pay for the complete reconstruction of the bridge. This time we are probably stuck with it, since WSDOT has grown inordinately fond of tolling as a traffic-management tool. reply amclennon 3 hours agorootparentprev> Tolls were reinstated on the bridge in 2019 to finance other road projects in the area :-\\ reply duped 2 hours agorootparentprevStill is the plan, they just keep building and rebuilding the roads. reply renewiltord 2 hours agorootparentprevMan in Year 10: See, this is how you do it. No tolls. Man in Year 50: We need funding for much needed maintenance that has been neglected through sheer incompetence reply voxadam 9 hours agoparentprevThere are three floating bridges on Lake Washington in the Seattle area as well. The Lacey V. Murrow Memorial Bridge[0], the Homer M. Hadley Memorial Bridge,[1] and the world's longest floating bridge the Evergreen Point Floating Bridge.[2] [0] https://en.wikipedia.org/wiki/Lacey_V._Murrow_Memorial_Bridg... [1] https://en.wikipedia.org/wiki/Homer_M._Hadley_Memorial_Bridg... [2] https://en.wikipedia.org/wiki/Evergreen_Point_Floating_Bridg... reply wiredfool 5 hours agorootparentAnd one on the bottom, no longer floating. (note -- was a bridge engineer in Seattle and did work on the old 520 bridge when we designed the retrofitted post-tensioning it in the late 90's. Among other tasks, I supervised a guy drilling holes in the bottom of the bridge with a concrete corer. ) reply tamimio 4 hours agoparentprev> Plans for a bridge had existed since the 1960s, and after the decision to construct the bridge was passed by the Parliament of Norway in 1989, construction started in 1991. The bridge opened on 22 September 1994 Pretty impressive timeline for an innovative idea. reply IncreasePosts 2 hours agorootparentAnd here in NY we've had 4 generations working on the 2nd ave subway line and only 3 of planned 15 stations have been opened so far. reply knute 5 hours agoparentprevI'm not an expert but I have seen Titanic (1997) and I would think a floating bridge is most vulnerable to sinking. reply RajT88 1 hour agorootparentNah. You see the floating bridge is compartmentalized, so that it is impossible for an entire segment to flood at once and sink. They are virtually unsinkable! reply mdrzn 4 hours agoprevTIL that \"Piledriver\" wasn't invented by WWE. reply samf 3 hours agoparentThe WWE didn't invent it, they perfected it. reply surfingdino 2 hours agoprevSome do sink, on purpose https://en.wikipedia.org/wiki/Submersible_bridge, and some are mis-designed https://en.wikipedia.org/wiki/Lacey_V._Murrow_Memorial_Bridg... reply relwin 2 hours agoprevThe bridge in the thumbnail is the Coronado bridge, rumored to have a floating hollow-box mid-section so that in the event of a collapse Navy ships can easily push debris and clear a channel. I remember hearing this \"fact\" on a San Diego harbor cruise long ago. Alas Wikipedia says it's a myth... reply abduhl 7 hours agoprev>> Your guess is as good as mine why the same steel shape is an I-beam but an H-pile. This is because the shapes are different. I beams are typically more slender through the web because the goal is to concentrate mass at the flange for moment capacity because they’re beams and geared towards bending. H piles are thicker in the web with the web thickness usually similar to the flange because the use case requires axial capacity and various constructability considerations. I beams turned into W (wide flange) and S sections in the standard shapes and H beams are called HP sections. You’ll often see them cross-specified for foundation work but it’s rare that you’d choose an HP section over a more efficient section like a W or S for something “out of the ground.” reply chasd00 6 hours agoparentThank you for this. In college, for some reason, i hung out with architecture majors instead of my fellow computer science people. They would talk about \"w flanges\" when, to me, they meant I-Beams. I never cared enough to ask but knew better than to try and correct them because that's pretty annoying heh. reply cyberge99 6 hours agoprevI have a guess to why H Pile i stead of I Pile: pronunciation. The initial I seems almost silent when saying I Pile. Whereas with H there’s a more distinct sound. reply dpcx 5 hours agoparentIsn't that the same with I-Beam as well? reply me_me_me 4 hours agorootparentI-Beam rolls of the tongue H-Beam doesnt, I guess thats the reason for adopting I term over H term reply dpcx 3 hours agorootparentThe context was the silent-ness of I vs H, not what rolls off the tongue. I agree that I Pyle rolls better, though. reply zardo 45 minutes agorootparentToo close to Apple's trademarked iPile reply gosub100 1 hour agorootparentprevMy pet peeve along this line is O-ring. Is there any other conceivable shape for a ring? reply zardo 43 minutes agorootparentDoesn't that refer to the cross-section? https://www.allorings.com/x-ring-seals reply KolmogorovComp 3 hours agoprevTangential but does someone know the animation software used to display extract of the FHWA report, starting from 1:45? It seems to be used a lot by journalists and looks fantastic. reply quaintdev 1 hour agoprevShame that website does not have RSS reply lacoolj 2 hours agoprevthis was such a great way to spend 17 minutes thank you for posting! I feel like I learned so much about foundations that I never would have otherwise on my own lol reply VWWHFSfQ 6 hours agoprev [–] Ken Burns' documentary [0] about the construction of the Brooklyn Bridge was really fascinating discussing the innovative (at the time, late 19th century) engineering methods and challenges. It's pretty short, only 1 hour. Highly recommended. ]0] https://kenburns.com/films/brooklyn-bridge/ reply HNDen21 5 hours agoparent [–] Read this a few years back.. highly recommended The Great Bridge: The Epic Story of the Building of the Brooklyn Bridge by David McCullough https://www.amazon.com/Great-Bridge-Story-Building-Brooklyn/... reply VWWHFSfQ 1 hour agorootparent [–] Oh yes McCullough narrated the Burns doc. Brilliant historian reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bridges must support loads over clear spaces, requiring strong substructures like piers or abutments to handle concentrated forces.",
      "Foundation piles, driven deep into the ground, provide stability through end-bearing and skin friction, resisting vertical and horizontal loads.",
      "Alternatives like drilled shafts and variations such as continuous flight auger piles and helical piles address specific geotechnical challenges, though all methods have limitations and potential failure risks."
    ],
    "commentSummary": [
      "Bridges remain stable because driven piles are tested for the force required to install them, ensuring they can handle significant loads.",
      "Wooden piles, when preserved in fully soaked ground, can last for centuries, as evidenced by structures in Venice and New Orleans.",
      "Challenges such as soil liquefaction, lateral deflection, and unexpected underground conditions can complicate pile driving, but innovative engineering solutions, like floating bridges and historical examples like the Brooklyn Bridge, demonstrate successful overcoming of these issues."
    ],
    "points": 237,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1719963790
  },
  {
    "id": 40860022,
    "title": "I made a search engine for Hacker News",
    "originLink": "https://hackernews.demo.vectara.com/",
    "originBody": "I love HN but always felt the search with algolia is okay but does have some limitations. Since I work at Vectara I decided to try and create a better search for HN. It&#x27;s based on data from roughly the last 6 months of HN stories and comments.Would love to hear feedback and how useful this is relative to the existing search.",
    "commentLink": "https://news.ycombinator.com/item?id=40860022",
    "commentBody": "I made a search engine for Hacker News (vectara.com)199 points by ofermend 22 hours agohidepastfavorite74 comments I love HN but always felt the search with algolia is okay but does have some limitations. Since I work at Vectara I decided to try and create a better search for HN. It's based on data from roughly the last 6 months of HN stories and comments. Would love to hear feedback and how useful this is relative to the existing search. ptsd_dalmatian 6 hours agoAm I the only one that hasn't noticed the search input in the footer? :O reply BiteCode_dev 5 hours agoparentThanks, 10 years of HN and I was still using \"site:news.ycombinator.com\" reply quenix 4 hours agorootparentTry https://hn.algolia.com — it’s great reply dewey 3 hours agorootparentThat's where the footer search field points. reply sph 5 hours agoparentprevThese days I use the search feature much more than commenting or reading posts. The frontpage is the usual recent news addiction treadmill, while for research into niche topics you can find a treasure trove of interesting comments in the archives. Want more posts about Lisp, Smalltalk and reverse engineering, for example, rather than the usual front page drivel? Search for them. On one hand I wish Algolia didn't give very old posts a lot of weight (it often prefers to show posts > 8+ years ago), on the other hand old content tends to be before the Eternal September of tech-adjacent people coming to this forum to discuss tech-adjacent light content, so it's actually a feature. The real value of HN is its archives IMO. reply satvikpendem 4 hours agorootparentI also made a bookmarklet to show me HN posts from random dates, it is quite interesting to see what was interesting to people a decade ago, for example. Lots of comments in HN's heyday were pretty eye opening as well. javascript:(function() {function randomDate(start, end) {var date = new Date(+start + Math.random() \\* (end - start));var day = (\"0\" + date.getDate()).slice(-2);var month = (\"0\" + (date.getMonth() + 1)).slice(-2);var year = date.getFullYear();return year + ' + month + ' + day;}var startDate = new Date(2007, 9, 9);var endDate = new Date();var randomDateStr = randomDate(startDate, endDate);var newUrl = 'https://news.ycombinator.com/front?day=' + randomDateStr;window.location.href = newUrl;})(); reply dang 2 hours agorootparentAlso recommended is https://news.ycombinator.com/front, which shows you the frontpage stories from any day—a little bit like archive.org would do, except that it's not a snapshot, but a composite of all the front pages from a 24 hour period. For example, here's HN from a year ago: https://news.ycombinator.com/front?day=2023-07-02. https://news.ycombinator.com/highlights is another good resource (and if anyone notices a great HN comment, past or present, they're welcome to nominate it for the highlights list! just email hn@ycombinator.com). reply satvikpendem 1 hour agorootparentThanks Dan, that is in fact exactly what my bookmarklet does, it generates a random date (2012-01-02) and appends it to `https://news.ycombinator.com/front?day=`. I think there should be a `random` link on the HN header links that does what I am currently doing, it would be useful to have it built-in. reply dang 1 hour agorootparentAh sorry I missed that you were already pointing to those! A 'random' link might be a good idea. For /highlights too. reply djeastm 4 hours agorootparentprevThat's really neat. Thanks for providing it reply pedalpete 19 hours agoprevNice work. I wonder if there may be a better application for the Vectara capabilities than search? Algolia has already done the search thing, can the Vectara search be 10x better? What I do find missing from HN is the ability for me to see things that may be of interest to me, but that I may have missed. I like how I get everything in the main feed which is pure popularity, but I don't have the time to go through all posts, and definitely likely miss things I would probably have been interested in. Though this can be done with collaborative filtering, or other non-AI methods, might this be a decent use case for your AI? reply 8organicbits 7 hours agoparentThis may be a good use case for RSS. Feed readers can filter posts by keyword so you can take the unofficial RSS feed [1] and filter it down by your interests. I posted an RSS reader that can do this recently [2] and I'm actively hacking on another [3]. But there's many RSS tools that can do this. [1] https://hnrss.github.io/ [2] https://news.ycombinator.com/item?id=40839262 [3] https://github.com/ralexander-phi/feed2pages-action reply noman-land 2 hours agoparentprevI would love to be able to feed my upvotes and maybe even comments into an LLM and receive search results ordered by relevancy to my interests. reply flir 8 hours agoparentprevI've been wondering if segmentation might be the way to go. Have the chatbot look at all the items, cluster them into a few buckets of its choosing, then throw each new item into the most appropriate bucket. (I've been thinking about this not just in terms of HN, but treating all my RSS feeds as one undifferentiated stream and just having a chatbot sort incoming items into whatever bucket it deems most appropriate). What's stopping me is that it might work, and I doubt making the internet even stickier is good for me long term. reply 8organicbits 7 hours agorootparentI've been thinking about that at length recently. RSS feeds often don't have category elements specified and there isn't a widely used taxonomy of category names. I'd prefer not to use AI to solve the problem, although encouraging the use of RSS categories will be slow work. https://alexsci.com/blog/rss-categories/ reply flir 7 hours agorootparentThanks for the link. It's interesting, and I hope you find a way forward with that, it would undoubtedly be a useful addition to the ecosystem. But my gut feeling is that there's not enough interest in RSS right now to drive widespread adoption of a new version of the spec. My approach would be to focus on improved UX over existing feeds, rather than speculatively expanding the spec to make feeds richer. The main advantage of my approach, I think, is that it adapts to the individual end user's needs. If all my subscribed feeds are tech-focused and I use a generic published taxonomy, I'm going to end up with 60% of my items in \"Technology\" and 30% in \"Computing\". If I use a chatbot to dynamically bucket stuff, I'll get \"Micro PCs\", \"Graph theory\", \"Golang\", etc etc. reply 8organicbits 5 hours agorootparentOne nit, RSS categories have long been part of the spec, but I've found people don't add them consistently. reply whiplash451 8 hours agoparentprevUnclear that the HN feed is pure popularity. There's got to be something else to it [1], otherwise it would look like all the medium-like crap you'll find elsewhere. [1] my hunch is that some human expert curation is involved. reply KomoD 2 hours agoprevOP mentions Algolia having limitations but this seems more limited? It doesn't seem like it has any filtering or sorting like the Algolia one has, like comments/stories by a specific user, during certain dates, sorting by upvotes/recency, searching by just title/content/comments. Say I wanted to search for comments by the OP, ofermend, it doesn't seem like I can... Entering just their name returns results that aren't made by them nor mention their username, I tried other queries too without any luck. reply n4r9 8 hours agoprevLike some other comments here I find HN search useful and powerful and am a little unsure what the added value is here. Possibly/probably it's for people that search in a different way to me. One of the most frequent searches I do is to look for a specific comment that I know a user made recently. For example, I might want to look for my own comment here: https://news.ycombinator.com/item?id=40801389 (sorry, this is a slightly political one but I just picked it randomly for test purposes). Searching Vectara for \"n4r9 NHS\" produces no results: https://hackernews.demo.vectara.com/?query=n4r9+NHS&filter= HN's own search however produces the goods in the top result: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... [ EDIT except for this very post :p ] Maybe 6 days ago is outside the dataset that this is based on? Some other thoughts/suggestions: - Ability to click through to the comment itself? At the moment it looks like the link goes just to the main comments page and then I have to find the relevant comment on the page. - Filter comments vs posts? - Order by datetime? - Filter within a date range? reply ofermend 3 hours agoparentThank you - these are great suggestions. Will work to add these... reply jiehong 5 hours agoprevCongratulations! Although, something I value a lot from algolia is the very fast live search as you type[0]. Vectara seems to be smarter, but much slower. My needs are satisfied with algolia 99% of the time as a technical user. [0]: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply uwemaurer 2 hours agoprevGreat work! I am currently playing with the Algolia hackernews search API myself and experimenting with spaCy Named Entity Recognition and llama3 to come up with some interesting data. Work in progress version here: https://news.facts.dev/topic reply omneity 8 hours agoprevI searched for \"Supabase\" and none of top the results in your demo contained an actual post about supabase. Following the example queries I then tried \"What is supabase?\" and the results were equally irrelevant. My personal opinion is that I'll keep using the HN search for the foreseeable time. reply zmccormick7 2 hours agoparentI had the same issue when searching for specific companies/products. It feels like a pretty basic vector search with no hybrid search component or reranking. reply marcodiego 18 hours agoprevPlease, add also the possibility to search in links posted/commented in hacker news. I bet it would be competitive against google for the hn crowd. reply ofermend 3 hours agoparentFor sure. Will test that. reply d4rkp4ttern 7 hours agoprevI really like this HackerSearch app: https://hackersearch.net/ reply d4rkp4ttern 7 hours agoparentPreviously discussed here: https://news.ycombinator.com/item?id=40238509 reply okhuman 4 hours agoprevI'm thrilled to see Vectara here – they have one of the top Product Managers I've ever had the chance to work with and be mentored by. reply metadat 20 hours agoprevCool project, but I'm struggling to understand what is better about the Vectara solution? Compared to Algolia.hn, this gives 0 filter controls (time window, stories vs. comments, `author:metadat', sort order, and so on), and no ability to search for exact matches. It failed to turn up anything interesting or even relevant for the 4 or 5 queries I ran. You've still made it further than I in the HN search engine adventures, which is commendable. reply mikepurvis 20 hours agoparentIf it's searching article content as well as just titles/comments, that's already quite interesting and useful. I've long wanted something like that for my browser history, like a \"help me find this article I know I read sometime last week about X.\" reply metadat 20 hours agorootparentYes, I've only recently rediscovered using the browser history for this exact purpose and it hasn't failed me yet. It would be remarkable and interesting to have a super deep search capability that indexes all first-order links on this site. reply yaj54 20 hours agorootparentAnd you think that hasn't been made yet? :-D DeepHN - https://news.ycombinator.com/item?id=26791582 Of note, I was able to find that item (which I recalled existed but not by what name) with hn.algolia, but I was not able to find it with the OP search engine, or with the DeepHN search itself. So in my book, Algolia is winning. But projects like this are super fun and educational to build so props to OP. reply seaal 13 hours agorootparentPerhaps someone will be able to help me find a website I’ve been trying to Google for with no luck: the main focus of the website is a music player with 3D pipes and arrows that the camera would follow along, live rendering the entire scene while music was playing, but it was also a personal blog if you scrolled down. Domain was relatively short and I think it started with K. reply metadat 19 hours agorootparentprevOP said they only indexed the past 6 months. reply fluential 18 hours agorootparentprevThis already exist: \"searching over the titles, text and URLs of sites you've visited before\" -- https://www.browserparrot.com/ reply kid64 18 hours agorootparentMac-only reply nashashmi 20 hours agorootparentprevbrowser history seems to only save the last 3 months of history. It used to be many years of data but that also slowed the browser down. reply ofermend 19 hours agorootparentprevCurrently it's indexing the content of stories and comments. Are you suggesting also to index the content of the main story link (which is outside HN)? reply squigz 18 hours agorootparentThat is what they're suggesting, yes. reply cottsak 18 hours agorootparentprevmaybe add metadata to the index, but not the full page content, else you're just gonna build another google reply metadat 14 hours agorootparentHow so? There's no PageRank in sight here, very little spam to worry about or contend with. reply yaj54 19 hours agorootparentprevDitto. I somewhat recently learned that Safari only keeps the history log for one year unless you explicitly set \"Remove history items\" to \"manually.\" Which I've done so that I at least have a list that I could crawl in the future to build a full text index on. reply squigz 18 hours agorootparentI'm fairly confident every single major browser (and probably most minor) have a history limit of some sort. Sometimes it's age, sometimes it's # of entries. reply metadat 17 hours agorootparentUsually I'm only looking back the past week or three. Otherwise I snapshot the page to evernote when I think it might be interesting later. Hopefully they don't completely end the free tier. reply tjlav5 18 hours agorootparentprevI think Microsoft is working on that right now :p reply rovr138 17 hours agorootparentThat’s exactly what it sounded like to me. Of course, local/offline only would be great. reply shortrounddev2 15 hours agorootparentprevLol you're describing Microsoft's recall feature that everyone here is saying is the death of privacy reply kelnos 15 hours agorootparentIf Recall was open source and auditable, and didn't send any data at all about usage to the internet, I guess that would be fine. Otherwise, no thanks. reply tamimio 16 hours agoparentprev>algolia.hn Is that a valid link? I get an error when opening it. reply miloignis 16 hours agorootparentIt's the other way around: https://hn.algolia.com/ reply gnabgib 16 hours agorootparentprevNo that's not valid (it's attached to the search box at the bottom of the page) https://hn.algolia.com/?q= reply potatoman22 14 hours agorootparentprevYou can also use !hn on duckduckgo reply sattoshi 16 hours agorootparentprevThey meant https://hn.algolia.com/ reply owenpalmer 20 hours agoprevCool, I like it! I found a bug. Under the \"When will GPT-5 be released?\" search results, there are double duplicate results. On one of the duplicates, the \"username (date)\" says \"undefined (undefined)\" reply ofermend 19 hours agoparentGood find. let me check why that occurs. reply mewpmewp2 19 hours agoparentprevI tried this query as well, I was a bit frightened when I saw my own comment in the results. reply ravishing0223 10 hours agoprevNice. https://hackernews.demo.vectara.com/?query=I+made+a+search+e... reply bschwarz 7 hours agoprevStruggled to find a specific comment earlier today via Algolia, found it as the second result on Vectara. reply smusamashah 19 hours agoprevIt doesn't always work correctly. For example \"Text to diagram tool\" is returning very few results and some of the results are not even correct. While this topic has been discussed a lot here. I was mainly looking for the list of tools I keep sharing whenever this topic comes up, or when I share a related tool in a thread. reply call-me-al 11 hours agoprevreally like this one from [Hacker Search – A semantic search engine for Hacker News](https://news.ycombinator.com/item?id=40238509). The URL is: https://hackersearch.net/ask reply bckr 6 hours agoprevNext someone should make a hackernews meta search engine :) reply sharpshadow 7 hours agoprevLike Algolia it doesn’t work without JS. reply jpl56 4 hours agoprevGreat! My first thought was \"funniest XKCD\". Loved the Self Driving one [0]. Thanks! [0]: https://xkcd.com/1897/ reply ceving 13 hours agoprevSearching for \"iptables\" returns first: > Arm says it wants all Snapdragon X Elite laptops destroyed Not so useful. reply codetrotter 12 hours agoparentIt’s matching two comments in the thread. It bolds the part that talks about iptables in each. So it’s not like it’s irrelevant, even though it is certainly not actually the most relevant one either. It seems to give better results if you are more specific. For example, try the following search: how to use iptables effectively And have a look at the first five or so results. Also, note that OP said it’s searching about six months worth of data. So if anything specific about iptables that you were looking for is older than that then their search tool doesn’t know about it. reply ofermend 3 hours agorootparentYes, it's just about 6 months back. If requested by folks here, we can certainly crawl back more years - this was just the first crawl I did. reply codetrotter 2 hours agorootparentAre you crawling the HN via the normal website? It’s better to use the API. https://github.com/HackerNews/API reply Jiahang 9 hours agoprevi use Google ：｛｝+ news.ycombinator.com reply yoouareperfect 18 hours agoprevAmazing! Congrats on launching! reply dcoder2311 13 hours agoprevCool work! reply yanko 9 hours agoprevHow to full text search on hn given user favorites only... If no such such option I feel disappointed reply wjb3 22 hours agoprev [–] Excellent! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Vectara employee has developed an improved search tool for Hacker News (HN) using data from the past six months of stories and comments.",
      "The creator seeks feedback on the new search tool's effectiveness compared to the current Algolia search used by HN.",
      "This initiative aims to enhance the search experience for HN users by addressing limitations in the existing search functionality."
    ],
    "commentSummary": [
      "A new search engine for Hacker News, built using Vectara, aims to address limitations found in Algolia, covering the last 6 months of stories and comments.",
      "User feedback highlighted the need for additional features like filters, sorting options, and indexing external links, with mixed opinions on its effectiveness compared to Algolia.",
      "The project has initiated discussions on enhancing search relevance and user experience within the Hacker News community."
    ],
    "points": 199,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1719951103
  },
  {
    "id": 40862436,
    "title": "Why AI Infrastructure Startups Are Insanely Hard to Build",
    "originLink": "https://nextword.substack.com/p/why-ai-infrastructure-startups-are",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"nextword.substack.com\",cType: 'non-interactive',cNounce: '79863',cRay: '89d920959dd205be',cHash: '960d6c7d8eff76a',cUPMDTk: \"\\/p\\/why-ai-infrastructure-startups-are?__cf_chl_tk=R_GivJXwOS_pLsWH_3VnkMTYFwdd6coakovwMBqMIHQ-1720033319-0.0.1.1-3711\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '120000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/why-ai-infrastructure-startups-are?__cf_chl_f_tk=R_GivJXwOS_pLsWH_3VnkMTYFwdd6coakovwMBqMIHQ-1720033319-0.0.1.1-3711\",md: \"maEJoSDQXZ7if27PyzVDWHQShoxfSyTAVUeoq2fkCkM-1720033319-1.1.1.1-VJbtdhHVCJY9zWQcjx9cHRbltamqQcHHenEoV_5msa3dlN6UK7tSllGrKMLhHY2.up2rIT4iKj6VxDa9Xbo5gz9H7Uaey9w8GJ7SKhSHVbSQ4bxGnODFBGs41DFoQdZyGveYwmc5pVYFdpydB40DMVz.w_kMj9aDYvgj2P5JhU5TDM_Pxv9utTu7DEOcjS2Im18bg5IKjIEOvmjZ6At17.k4ilcY40KuqL6GQxeGda0FGJx9F2Gzdt_eUgC2JkI7u4URgov0pb1sDwhPq8l_H6UjmaGqLJA3N6F.Shr9bqnWWbZO5D8pEKMz6bKBsprjKPjxn7DX1rLnp40pvBFKzR5oc48dfWBBmT1Oed9l7ForZElNtucefsIeOSzItMEIULkeadsQmeLO6OCf1mnOMyUS4sI0wkGq8d7kLMEwQOLk3h2FCcJ9snwKJUWnHuXyR8jm52j2TUl_3wFQae_z2dBp4CMkR.fid5F0gGIU09gFmuTeFTxKHT5oWW4O3qFKvNht5GDI20CL_mm.hqvv7QuwxSyreuo9xcPmsj94Mr3At4motzKOatf7gJOp0LpxwJkHySN6gRgzMvQUwXWDCMM7jbIndsMPJg7MtdOggylZI_sk.yTglqETgy7S15VXvQvcsqvqQDCFXPCn.qILbQ_x6OLNFqQU1TpZ_jILdCMKGPT9sCPnZ.T5JbTlZ12YQjUCDQtPdHSVFdojxP0ACwUNaP3X_hTYua2hAEkw6wibT2DaxeJab.DilR5CDVohm08JIA0KFnZUtUAtRPvylrnqji3_zjejk9tXhznsO.05LumisY0KZr5aAu.DTsjYyoN_ItQl1DkUqBFwomLAg17TtgwGekIVbxugwJfGBfzWyFvouuc0e9IiRSReOujNCcAW3oyNjHHy9TB9M31nBEeZVKHFqOxw350tvCNIEzsJgfHOlER4Y6p6VRCEfNHRZG0FfXJDwrGUh2GI4DaudfwLZO9Qa6D58NKDGU_.DI4l9aKT2vzYvfX6umeUoP9AOwrTdgpgs4TTo8CAUQ1GqsZLrQ_ECj9ZCf7L49MgJkfRluqo5jscqra376Yca2xXg6GlT0Z5z_WjoXYYT8O_6MAhcgad1FQ8fiTgEr1bzzXbxOOzef6vOaRAKL2BiCHQIp4fKpEzw.uySf0ON43JD_.hsHfdJWd9krxyWkJ1jDNxNvW4O32goWtTO8j3VLSw9OVBEC.xKCN9TARxkcdd6AV1SA9Agc29etAKKipOPO8\",mdrd: \"4PED.qR39A6Vl9nLoASViNBZ5nfGyqSzOWP73wC11ck-1720033319-1.1.1.1-oqMhSmCZjGyYKjsU6iBSebBPlWJ_rEPxISvCL3oRt660VCLxks27sQ7B3GTNYu6sw5iQZKoGHqSEZK12Vg7O5NG2dJCF9jr.fgkWM0q7KMpEBRh9_MhwbZBcH0_s4REUgJDD_2GGrwj4ysLzRgysOlcDSMcDS_Phj3DIM_UWBioQ5PL32DvkHl3NAJD_X1VGFY6bSbg.3N9oPAq2z5W.Q0VrBX3jB5kYavIWnwSj_QzbimuvPc6zNNHlLAZIeqq5aQgVma54RUhxzQoMV6_XP8.QbeeUKJJvizNxhpwdbIKIPb3zd9fkWFCHawq31leXUR0cRP9Ct3uCSqHrbHG5HtOv8Br_a3.n9ixX6Ak6oa4GUbEUudxVkGIXqJ5D09u602dZFX9qFIr1NlJeW_tL2Yxyx3Jd5JNI2HaGDpbJSAr5YVXmcH87KWcwx768.jhxVGVuK1ZYv1GAmb3fcnPM19yx1b16Pd1zirMAVYuyJ7S5D84yuIChgY9nXiuz2ksBwNho6XglDvv6Cr54d0t5MewyqJ0HkYkOamD7t8IA1h.K.8Q5tPGI.8DQaxpLTdRqXf67DHd5IYFRjOwkEswGlnpUqv6pu10EsK9dOwd1vpj9QNlH5plQcPq3NivMdlFt7lvqVfxsOXmf8UxMEQdYNSRz6A8vvkJxkat7jJrDJndlDxmatWew9EbBZIr._4uq2TIt0qKEv3rrYc.fCIAanRXCGIghoKgg_YJ.rP68gIygieEowrc2g.Iw4oAG.CQlNev86UM3mn4T2PZJIVT5dNOMxQ63yTBzOb42rlKsMU7fZZcB9XQZWhdrlIW3pkdGtC.7IAl4Gu1nqXJBGYSWIoyB6mndTzb_cRdtjIyktj1oDP3julTQ8p5gT5nSFAlq6xn03xwnPPVVYPrTNHD.IfBfeGjotmGcsz.SHFkferBUvVzAswjcSF5J44N29Aj.cqeB6Cv_1jA_o.2.ZZyEp6MosTPxtOIzemm0yd66xgynO9.Nux8GYIJi8FLpvPDo0Xjqyq0z7DzQC5IRSI4t6B1PNp_VzgodYxck8Ez2pFRTrJ25iYzJQoSc9V.6C85n7l99G35IY8IQKSgIRQSM6FBt7kqTAB6JyYNZLU8465Ms6GVbJW__7XGLQpuKHNvyDCIuGmGFZvpFCfEAq8EgI5rd7MT5ARlz70sCEJ4VJq_FYuuJQvHdDu16VaemmFaTc11P5bv7IuP0a6o1NPr3odjWKhH0OTKX2LJW.ieH5FQvXqFyHBe4Xxaj5amcnyE0l3Dif2cbBd5X8wEotNXzwAZwipNnT73ZmiC0g5xw_u_wcbYJgZ2pSn7REcN4PJZiagh06adafEc7ekERBbZ777ciMEEUzYtTL9ZQiwqEDtWxWEcNyg5jGiPl5ob9d7_BcuuaODCVhmco5G1wKhy0zRmPcEWBVqcx1h2ntoy6zJOSH4RgwFLgoKCaysimEV9OtNWIg05Whyo6wGxy5gFgcVkbvVgI4QpQJ2Gr_U2vqJe5sZWenKYey4YBbUkWXgjkAoDmj8JO5qLu8qriovbDfbpt0VbRwno8mMPpbnP125kBSVhyOgIHq0ZyqBWsfJsYsTjcZc.CZDRzITtbBBXw8xalXtoOYXIfzHh07UUrmOWi697P4P8SY9UaIiIo.VitI4bNeyw9WSBNIVi6dOAUjnfcZ8grlEQ3RL0H1GML0JjBqkxsTtlaIC2NqAU.ALOSAokVirZEWuaBafKdueb6ol373.ipPkzmado1lmUKJI6bqOALxTqDBSmkf73bwoOyq1l8Al4ws9T9XbM70uLaCuj8GYH9eE.ZRagwc1HbYgL9UHAFjVrKRDT4JlrElwLWZ6Xhr7UpTs2O_uaaD7gPAQS2JwyYTQ94EZxU9PrPj4qsrM.ls6EU_7bYohDLW76cAHzVbicmdwFLqPHDua0cd9yykQjJelC.NIzJ64qfIsL0mn1_akvXsCCdl_eMkWHkPGSp_uifu7hd0QAK3q8rB_Y2BZDDiP17YeS4Zs1UgavSo2d6qOOXt9mwllX3r8bDYkpyCf..gdbXBdRbP0JlZYTfNUwzqPMIpF1p1AifTi.QglQ6SqNFN3gswTpEocVMJrSZUYk4hhzb8Hb7jYlZfqiTaxripdA5UQ48BH7q0ZAD2rHvw5KPaB3LUl47bulXhZwm1JJB7h9oWOCTBkB_kJKf3CXtiz47xRJscBTrOv1QUMMSk7tm7GD5s4DK2tYp3ogpKLO.ndVKJQ0qQR0wKUocVWjy4z6LwQWaIxYF1E5W7sFSrwrURzOMGqs4IFC03U0I.PMnFg1uwyvVjWEhVg\",cRq: {ru: 'aHR0cHM6Ly9uZXh0d29yZC5zdWJzdGFjay5jb20vcC93aHktYWktaW5mcmFzdHJ1Y3R1cmUtc3RhcnR1cHMtYXJl',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: 'HsKU2eDjPvceyaIiu2dikKatA18Axo/v9PvrYiWLskuqvxFPgxJ4+2yzIpsMS9mWxCFpZblSBw/xThvHcNC5+qhNmcmU9KadXO4NqMh1fQFND6KIJjULjYpp29X39Yl2onLOTUp8jTt631YLRpbRz7INPHRqA+d/2EBHdwAxUnJn4oUGlPLPj5HJJ2wNZBegX6fuduBjJ6KJS+lA3kB9lpbtFYM8FNQfcxWmSMqD3o9L6i9Rc1urmoXA/24qSXOFZcLnND6L32NMyf7QIJSM8BWO8ODmtIk1TEA5+AQEizZ0z+8GZiiqXFyx4lepq3CrigNYTUh+dqL22Gg0uJTGgOSivewu6gZZJgRC2juzBjt6AiK6tdqOgeFwyyegQAwasGHanQO5rwFjq0OgCiEbMkzwxsSbMibYQYXQoCue01W440xaZa+lxzTozieVO9xlRFnWZ4ijbZsnYqlveNGnLmgsM0yZX6R77+bvTIGeCbwwNgLu6yrRIxy0i7xMfb916fqCoNdvhPSaCShqoFxZVA==',t: 'MTcyMDAzMzMxOS4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: '1Wce7hYj5Y8Nuo+GnkQvX6LgfrcI1+0jTYiHSY738FE=',i1: 'Pphj3iK4o73x3xHAllEGvg==',i2: 'XHr406bZxEzJHJHKyCJvSw==',zh: 'o01jypKJQ++/gkxUTvC40nYpXBhuMc66cm0hd/Tc920=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'wOaAndTu0Xs9/MR98otpT2IdtdlOSebWsRg+L+CK7Cw=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=89d920959dd205be';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/why-ai-infrastructure-startups-are?__cf_chl_rt_tk=R_GivJXwOS_pLsWH_3VnkMTYFwdd6coakovwMBqMIHQ-1720033319-0.0.1.1-3711\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=40862436",
    "commentBody": "Why AI Infrastructure Startups Are Insanely Hard to Build (nextword.substack.com)176 points by nextworddev 15 hours agohidepastfavorite162 comments dvt 11 hours agoInfra has always been a tarpit idea. Google didn't start out as an \"infra\" company, and neither did Amazon or Facebook. In fact, the few \"infra companies\" that did start back then (companies like Godaddy) are minuscule compared to the aforementioned. VC pouring money in LLM infra is legitimately crazy to me. It's clear as day that there will be winners of this AI cycle, but, as always, they will be companies that provide actual, real, tangible value. Making shovels works for huge companies like Nvidia or Intel, but it won't work for you. It's sad to see so much capital funneled in frameworks upon frameworks upon frameworks instead of fresh new ideas that could revolutionize the way we interact with our devices. I know it's a bit of a meme, but I'd rather see more Rabbit R1 and less LangChain. Even OpenAI doesn't really have a product. Just throwing data at a bunch of video cards isn't value-generating in itself. We need a Dropbox or a Slack or an Instagram: something people love that makes their life easier or better. reply rapsey 11 hours agoparent> VC pouring money in LLM infra is legitimately crazy to me. VC business model is throwing money at the wall and seeing what sticks. They love congratulating themselves on how smart they are but at the end of the day their overall returns trail S&P 500. They are salespeople and their job is to sell themselves to private capital on how smart and connected they are. reply FanaHOVA 3 hours agorootparentPeople allocating capital in VC funds are trying to diversify a very large portfolio, not just picking a high IRR asset. VC is very uncorrelated to S&P 500 performance as most of the best VC vintages were during public market downturns. reply dehrmann 3 hours agorootparentThat's only half of it. They also have to justify their jobs. Anyone can manage a 60/40 portfolio with index funds, but pensions are complicated, so they need complicated investments. reply amarcheschi 7 hours agorootparentprevDoes their return trail s&p 500? I guess there are some of them that are successful and some that aren't, but to be honest I've only heard about vc as people who on average have a very very high return. Now, it is very possible that's just survivor bias, but I would need to search for some data reply gumby 6 hours agorootparentMost of the funds, even the big ones, trail the overall market, and even the successful ones have difficulty maintaining a long track record of success. The reason for the big pension funds and endowments to invest in VC is that it’s a bit counter cyclical. Also it’s a tiny pimple on the side of the PE sector overall. You can see how marginal it is in the financial sector by going to an LP meeting — the big institutionals send kids — first year analysts — to attend because it isn’t that important. reply gizmo 5 hours agorootparentprevThe S&P 500 is a list of the largest and most profitable public companies. It's hard to do better than the most successful businesses. Most other indices and hedge funds don't outperform the S&P 500. Most private equity shops don't. Most real estate investors don't. So it shouldn't come as a surprise that venture capital doesn't. Most startups don't get big. How many startups founded in the past decade have become hugely profitable? It's not that many. A handful out of the 500k or so funded startups. Meanwhile the S&P keeps chugging along at 8% annually. reply staticman2 5 hours agorootparentIt's hard to do better than the most successful businesses is not a statement that makes sense from the investor's perspective. The price of an investment is based on the expected profitability of a company, an investment in a barely profitable company, if priced correctly, should yield returns at least equal to good companies like Apple, Google, and Microsoft, as the investment would be discounted to compensate for the poor expected future earnings of the company you are investing in. reply eropple 3 hours agorootparentThat's getting into perfectly-spherical-cow territory, though. Investors aren't logical and neither are founders, and there's a real chance that an investor-fair deal isn't going to get any bites. The BATNA for most founders who don't secure funding is \"go get a job that pays a lot of money\"; while most VC investment is lopsided in the investor's favor through other means (equity preferences etc.), not landing deals makes your fund's LPs ask why they're letting you hold their bag of cash. reply devoutsalsa 3 hours agorootparentOne could argue that illogical investing is called speculation or gambling. reply eropple 0 minutes agorootparentOne indeed could. Excuse me while I channel Kermit the Frog and take a long sip of my tea. rapsey 7 hours agorootparentprevI know a while ago there was some leaked a16z data showing returns underperforming the S&P 500. reply csomar 6 hours agorootparentprevMost of the smallish funds do not publish any data. They are sales people who are selling the idea of \"higher risk higher return\". The sales is their alpha not the investments. reply jgalt212 7 hours agorootparentprevRight, just as some mutual funds outperform the SP and most don't. reply ozim 9 hours agorootparentprevI think they don't even trail S&P 500 - with all the dirty tricks up their sleeves they roll losses over and over. Bottom will fall off at some point when hype train stops rolling, but so far it was good years as we have hype after hype. I am waiting what will be next one after AI, because quantum computing feels like too hard to become a hype, the same with space ventures, there is some upward trend going on there but still space is too hard. reply rapsey 9 hours agorootparentAI is a long term trend, next is more products on top of AI. Just like the internet. Biotech and space will both be trends but slower and less bubbly because the cost to play is high, though the returns are possibly huge in both. reply ToucanLoucan 4 hours agorootparent> AI is a long term trend, next is more products on top of AI. Just like the internet. This is legitimately just the same damn hype train the tech sector is constantly attempting to create. Now AI is the next internet. Before that it was the metaverse. Before that it was NFTs. Before that it was cryptocurrency. Before that it was quantum. Before that it was VR. Before that it was AR. None of those were the revolutions postured by techno-fetishistic CEOs. Most stick around in some capacity, like VR and AR, and the argument can be made that those have a future. Blockchains certainly have a future as it's a highly useful technology, even if the financial vehicle made by it is utterly useless. The metaverse is Dead on Arrival because nobody ever wanted it in the first damn place, apart from the speculators betting money on it. reply rapsey 3 hours agorootparent> This is legitimately just the same damn hype train the tech sector is constantly attempting to create. Now AI is the next internet. Before that it was the metaverse. Before that it was NFTs. Before that it was cryptocurrency. Before that it was quantum. Before that it was VR. Before that it was AR. Neither of those things you listed were mainstream trends. If you can not distinguish between fads and major trends that is your problem. Internet, Mobile, Cloud and now AI are technology trends with mainstream buy in from the biggest companies in the world. reply ToucanLoucan 3 hours agorootparent> If you can not distinguish between fads and major trends that is your problem. You're distinguishing based on hindsight. It's mainstream if it succeeds and if it doesn't, it was a fad. How much did Zuckerburg put into Facebook's metaverse projects? I believe it was $46 billion. Then there was Decentraland too, those were as mainstream as it got. You had tons of internet-famous people cashing in for hundreds of thousands of dollars just for selling their original copies of reddit memes. How is that not at least somewhat mainstream? I have zero doubt whatsoever that after the AI bubble lets go, I'll be having this same damn conversation with someone else and they'll be saying AI was a fad. That's my entire point. reply rapsey 2 hours agorootparentOnly zuck was metaverse obsessed. Decentraland I've never heard of it, so it was not mainstream at all. NFTs were never mainstream. All of your examples are bad. AI has buy in from the entire tech sector. Just like the cloud, mobile and internet did. reply williamcotton 7 hours agoparentprevEven OpenAI doesn't really have a product. This becomes very obvious when you use Claude Projects with Artifacts! ChatGPT depends heavily on one’s ability to copy and paste… and even though it is an improvement, Claude Projects still make managing a set of documents tedious compared to your standard code editor. Third-party tools like Cursor are an improvement but will be prohibitively expensive compared to companies that create and manage their own LLMs. I expect to see a native document editing/code editing software system directly from one of the LLMs-as-a-service companies at some point. reply tcgv 4 hours agoparentprev> Even OpenAI doesn't really have a product. Just throwing data at a bunch of video cards isn't value-generating in itself. We need (...) something people love that makes their life easier or better. I agree. I'm of the hypothesis that, when it comes to AI, a lot of product teams are pursuing overly ambitious and sophisticated features instead of targeting easy wins that are in plain sight [1]. [1] https://thomasvilhena.com/2024/06/easy-wins-for-generative-a... reply siquick 11 hours agoparentprev> We need a Dropbox or a Slack or an Instagram: something people love that makes their life easier or better. People seem to not mind ChatGPT or Claude and safe to say that a very large majority of AI products are using one of the APIs of those companies. reply dvt 11 hours agorootparentIn my humble opinion, a chat interface (API or not) does not a product make. Not to mention that Llama is free and competitive with both (same with Mistral, heck the 7B model works great on my RTX 3080). If you started a company that blew up because you made a badass product (and let's say you used ChatGPT under the hood), you would just eventually train and deploy your own model because an LLM is not a product. reply mike_hearn 9 hours agorootparentLLMs are clearly products! The fact that Meta rather inexplicably chooses to give away assets that cost millions or billions to create doesn't mean LLMs aren't a product, it just means that they're competing against a company funding open source stuff for (presumably) strategic reasons, like in many other markets. And like in many other markets over time it's possible the proprietary versions will establish permanent competitive advantage. Meta may not keep releasing Llamas forever. > you would just eventually train and deploy your own model Just train an LLM? It's really not that easy! Even if it was, it'd be like how people can \"just\" run their own email service. Hosted email API is not rocket science but in practice companies all choose to pay Microsoft or Google to do it. Doing these things isn't a core competitive advantage so it gets outsourced. reply fragmede 9 hours agorootparentprevThat's one opinion. the number off people who get value out of ChatGPT is known only to them, but anecdotally it's pretty high. a lot of people I know are actively using it on a daily basis and paying them $20/month. reply walthamstow 9 hours agorootparentAnecdote: me (SWE) and my wife (executive) each have a $20 subscription. reply IanCal 9 hours agorootparentn=3 now so it's full on anecdata, I've got a $20 sub professionally (swe). It has to save me so little time to be worth it it's easily great. Might add claude, though at this point probably better to find a nice interface and use the APIs. These things are products. reply hiAndrewQuinn 8 hours agorootparentn=5, my wife and I split a subscription between the two of us. While our needs are usually pretty minor, we both work in the computer science space and GPT-4o's ability to e.g. generate good example sentences for my Finnish vocabulary learning is astonishingly good. I'm building a wrapper around it so I can generate them en masse at [1], but it's still quite early days and very obviously not software I intend to sell https://GitHub.com/hiAndrewQuinn/wordmeat reply siquick 10 hours agorootparentprevUploading a a photo/file to a server does not a product make yet you referenced Dropbox and Instagram and that’s what they started out as. The UX of the AI applications is the moat and the infrastructure providers behind those applications is pretty much always OpenAI and Anthropic at the moment because running your own open source LLMs (which are inferior out of the box) at scale is not cheap or easy to do it right - same reason most companies use cloud. Agree that once you hit super scale then you can run your own infrastructure but there are thousand of companies who won’t get that far and still need an LLM. reply iknownthing 6 hours agorootparentAgreed. The LLMs have effectively been democratized. As much as people deride \"LLM wrappers\", the quality of the wrapper and how creatively they use the LLM api is the differentiator. reply pmontra 7 hours agorootparentprevIf I had to use Llama or Mistral for free (money) I'd have to buy that RTX 3080 card plus the computer to fit it into. It doesn't work with my laptop. So I use ChatGPT for free instead, on OpenAI site with the don't archive option or whatever they call it. I think many people use the free (money) and hosted option. reply marcosdumay 3 hours agorootparentprev> an LLM is not a product I imagine you meant to say that LLMs are comoditized. Getting the correct words here is important, as you can see by all the people disagreeing on the literal interpretation of your post. And yeah. LLMs have got the fastest transition from highly innovative singular product to plain commodity I've ever seen or read about. BSD licensed software libraries do not move that quickly. They were mostly not even adopted yet, and have a huge barrier to entry, what makes it much more of a feat. reply manishsharan 3 hours agorootparentprev>> LLM is not a product Would you consider Database to be a product ? SQLLite , PostGres etc. are free and yet we have Oracle , Mongodb and MS SQL doing billions in revenues. reply jokethrowaway 7 hours agorootparentprevLlama and Mistral are not really competitive but they can be used as a base to finetune for a very specific usecase. Then they don't suck as much. With OpenAI and Claude, you throw some text instructions and you get back the answers which are surprisingly correct (minus a few exceptions). In order to replicate that with Llama you'd probably need N-hundreds finetunes and a model to decide which finetunes to use. reply meiraleal 7 hours agorootparentprev> In my humble opinion, a chat interface (API or not) does not a product make. Well, you are humbly wrong then. > You would just eventually train and deploy your own model because an LLM is not a product. Hallucinations aren't exclusive to LLMs it seems. reply williamcotton 6 hours agorootparentWe’re already seeing a lot of competition between LLMs. They are quickly becoming commodities. Margins will approach zero and the real value proposition will be with consumer products that extend beyond an . reply TimPC 4 hours agorootparentI disagree they will become commodities because most of my use cases are more sensitive to accuracy than cost. We typically have usage volume that isn't absurd and for large enterprise customers our LLM budget is a rounding error. Meanwhile our product saves them many hours of a data engineer. If we can pay double to get a 10% performance boost we will do so gladly. You can already see this in LLM pricing where they have cheap models that deliver low performance a My bet is that 80% of profits will be made on the workloads that are sensitive to accuracy and workloads where running an LLM at all gets you most of the benefit will become very commoditized. reply VBprogrammer 5 hours agorootparentprevI agree with you. I'm using a couple of different LLMs depending on what I'm doing and what happens to be easiest but the difference between them is marginal in my experience. The only play for OpenAI et al in my opinion is to try to pull up the draw bridge behind them by getting legislation passed which makes compliance prohibitively difficult if that's not your core business. reply mlsu 10 hours agorootparentprevthere is a lot of consumer surplus, but it’s very unclear if any one of these companies will be able to capture it. Especially if mostly good enough commodity LLMs like Llama 70b are in the mix. Where is the differentiation? reply physicsguy 10 hours agorootparentNot to mention that fine tuned smaller parameter models are much cheaper to run. See: Google embedding a model into the latest version of Chrome, accessible through dev tools. reply rapsey 11 hours agoparentprev> Even OpenAI doesn't really have a product. They are making a ton of money off subscriptions. reply soneca 8 hours agorootparentYep. Obviously they have a product. Millions and millions of people that are not software engineers or any very tech-savvy persona use their product. And a lot of those people pay for it. It’s just silly to say they don’t really have a product. Specially given the rest of GP comment, OpenAI seems to be the Google, Facebook of the industry and will be the infrastructure company of it (already is kind of) reply nextworddev 10 hours agorootparentprevYes. Author here. OpenAI is at near 4bn ARR and growing (api plus SaaS) reply whiplash451 6 hours agorootparentSource? reply matwood 5 hours agorootparenthttps://www.theinformation.com/articles/openais-annualized-r... reply criddell 5 hours agorootparentprevI'm skeptical that $20 / month is enough to run OpenAI and be profitable. I would bet the real number is an order of magnitude higher. reply phillipcarter 3 hours agorootparentOpenAI is in growth mode, not profitability mode. Their ARR is over 3B now, and doesn't show signs of stagnating. At some point they will need to build and offer more products, but they've got as good a shot at being the next big tech company as anyone else. reply rapsey 5 hours agorootparentprevI did not say profitable reply belter 8 hours agoparentprev> We need a Dropbox or a Slack or an Instagram: something people love that makes their life easier or better. None of those three make my life better or easier: Dropbox -> We drop your data directly on S3 but give you worst security... Slack -> Being able to navigate our messy interface is an IQ test in itself... Instagram -> Only makes your life better if you have bikini posts to share.... reply raincole 8 hours agorootparent> None of those three make my life better or easier: > Dropbox -> We drop your data directly on S3 but we give you worst security... You're top 1% tech-savvy then. 99% people don't know what S3 is and won't deem Dropbox as a worse S3. (insert rsync joke) reply hparadiz 8 hours agorootparentprevI remember what it was like before Dropbox and Slack and I can tell you both have saved me hundreds of hours directly. Can't say that for IG. reply belter 7 hours agorootparent> I remember what it was like before Dropbox And despite all that, I get mysteriously being pushed by partner companies I work with, this product named Box. With tactics similar to the push to use Teams. It's like being volunteered for karaoke night by your Japanese boss... reply gopher2000 2 hours agorootparentprevMany people clearly love them and have found great utility using them. Not sure what point you're trying to make - that you're different? reply oefrha 7 hours agorootparentprevDidn’t expect curlftpfs+svn to strike again in 2024. reply dageshi 6 hours agorootparentThose who don't learn their history are doomed to repeat it... For those interested, the first comment on the launch thread for Dropbox here on HN had very similar sentiments to belter... https://news.ycombinator.com/item?id=8863 reply MOARDONGZPLZ 7 hours agorootparentprevAll three of these products have made my life substantially better. reply belter 7 hours agorootparentNext you are going to recommend me Windows and Teams? :-) reply nextworddev 10 hours agoparentprevAuthor here. I think the tarpit extends to most chatgpt wrappers as well, which is why I called out pivoting prematurely to application layer is a futile exercise. reply iknownthing 6 hours agorootparentSo AI infrastructure startups are tarpits and so are the wrappers? Is it just tarpits all the way down? reply nextworddev 3 hours agorootparentIt's an area where if you don't have a clear edge, it could be a real tarpit. reply raincole 8 hours agoparentprev> Even OpenAI doesn't really have a product. ...What? Like, what? I feel like stepping into another timeline reading this. reply tryauuum 9 hours agoparentprevare there even any VCs pouring money in LLM infra? I would assume VCs aren't interested in projects which won't give them a tenfold return. And with infrastructure there are some many existing competitors (like AWS) so that such returns are never expected reply __MatrixMan__ 7 hours agorootparentI get the feeling that there are. MLOps became LLMOps before most people knew it as any more than a buzzword and well we can't just call it ops because there's clearly something different here. AI is still too opaque to reliably know beforehand if an idea will pan out, so you just gotta try it. Plus it's easy, once you start imagining how the magic of AI is gonna make you rich, to ignore the problems with your idea and assume that the AI will handle them too. So you've got all these hyped up fools trying to make stuff that lacks merit. How do you capitalize on that? You don't invest in the stuff that's doomed to fail, you create a slot: > Insert coin, insert half baked idea, receive AI app That way you get to keep the coins even when apps don't turn out. Plus, you're collecting the institutional knowledge necessary to pounce on something that comes along which is actually worth investing in. Or at least that's the vibe I get when our meetings feature an AI-excited VC (which isn't common, but it happens). reply ankit219 9 hours agoprevGreat article. I am not going to name names, but over the last one year, whenever there is a concept that became popular in Gen AI, thousands of startups pivoted to doing that. Many come from software background where the expectation was that if the code works on one dataset, it would work for everything. You can see this with 1/ Prompt engineering 2/ RAG 3/ and now, after Apple's WWDC, it's adapters. Enterprises I have spoken to says they are getting pitched by 20 startups offering similar things on a weekly basis. They are confused on what to go with. From my vantage point (and may be wrong), the problem is many startups ended up doing the easy things - things which could be done by an internal team too, and while it's a good starting point for many businesses, but hard to justify costs in the long term. At this point, two clear demarcations appear: 1/ You make an API call to OpenAI, Anthropic, Google, Together etc. where your contribution is the prompt/RAG support etc. 2/ You deploy a model on prem/private VPC where you make the same calls w RAG etc. (focused on data security and privacy) First one is very cheap, and you end up competing with Open AI and hundred different startups offering it. Plus internal teams w confidence that they can do it themselves. Second one is interesting, but overhead costs are about $10,000 (for hosting) and any customer would expect more value than what a typical RAG provides. Difficult to provide that kind of value when you do not have a deep understanding and under pressure to generate revenue. I don't fully believe infra startups are a tarpit idea. Just that, we havent explored the layers where we can truly find a valuable thing that is hard to build for internal teams. reply brummm 5 hours agoparentRandom question, but what are Apple adapters? Kind of hard to google it, lol reply ankit219 4 hours agorootparentSorry for being vague. I meant LoRA, but used Apple as an example because their demo showed the potential. At a conceptual level, you can finetune a base model to be good at a specific task - eg: summarization, proofreading, generation etc. These finetuned weights are at the top layer and can be replaced by other weights for a different task as needed. Apple demoed different tasks by showcasing how their model identifies the task and then chooses the right set of finetuned weights. Apple called it Adapters as it comes via LoRA (Low Rank Adapters). It's around for some time, but only shot into prominence after people got some idea on how to use it. reply criddell 5 hours agorootparentprevI know almost nothing about this stuff, but what I know about Apple adapters I learned from this page: https://machinelearning.apple.com/research/introducing-apple... > Our foundation models are fine-tuned for users’ everyday activities, and can dynamically specialize themselves on-the-fly for the task at hand. We utilize adapters, small neural network modules that can be plugged into various layers of the pre-trained model, to fine-tune our models for specific tasks. For our models we adapt the attention matrices, the attention projection matrix, and the fully connected layers in the point-wise feedforward networks for a suitable set of the decoding layers of the transformer architecture. reply p1esk 4 hours agorootparentSounds like regular lora adapters reply josh-sematic 5 hours agorootparentprevNot Apple adapters per-se, but LoRA adapters. It’s a way of fine tuning a model such that you keep the base weights unchanged but then keep a smaller set of tuned weights to help you on specific tasks. (Edit) Apple is using them in their Apple Intelligence, hence the association. But the technique was around before. reply tonetegeatinst 5 hours agorootparentprevProbably the name of the way you had the think differently to charge the desktop mouse upside dow..... reply hobs 6 hours agoparentprevPretty much this, 18 months ago my CEO told me we HAD to get into this space, and I told him that basically our money came from our private product and that the only way our big enterprise customers were going to play game with us was either ironclad agreements that went all the way to openai, or more likely a completely single tenant system, which would cost far more than they were willing to pay. Of course they went with both, and as far as I can tell both are a major disaster post layoffs :) reply jerf 5 hours agorootparentI fully expect in somewhere around 3-6 months the dam will burst and we're going to start hearing more and more about all the teams out there that are pouring tens of millions of dollars into AI and all they have to show for it is a worse version of whatever it is they were doing. To placate the AI fans, that's not because AI isn't interesting, it's because that's how these hype cycles always go. I remember when everything had to be XML'd. XML has its uses, but a lot of money was wasted jamming it everywhere because XML Was Cool. AI has its uses, but it is still an engineering tool; it has a grain, it has things it is good at, it has things it can't just wave a magic wand and improve, the demarcation between those two things is very, very complicated, and people are being actively discouraged from thinking about those lines right now. But there really isn't any skipping the Trough of Disillusionment on your way to the Plateau of Productivity. reply ankit219 4 hours agorootparentprevCan you go into details (as much as you are comfortable) on what happened with the single tenant system? I have seen a few things, but I find it hard to put a finger on what went wrong except the ROI wasnt there. Would love to understand your experience. reply spacecadet 8 hours agoparentprevIts rent seeking and grifting. As technology has become easier to get into, a huge number of \"startups\" are low level people just looking to make noise, get their cut, and bail. Its a bad look, up there with fast fashion. An acquisition here amounts to teams luck surface. reply cootsnuck 6 hours agoprevI work for a foundational AI company. I guess we're technically AI infra. We're inherently \"narrowly\" focused since our origin (which was well before the recent hype in past 2-3 years). Our customers are really the type of AI infra companies being talked about in this article. And yea, the new ones I work with everyday are often a dime a dozen. A revolving door of small startups trying to make the same general purpose AI infra targeting other traditional \"boring enterprise infra\" companies. The ones that I'm seeing get the most traction, have the best products, and best chances of success have zeroed in on specific niches and sub-industries. (Think AI infra that helps B2B2B companies where that last \"B\" is like Roofing companies and the value provided is helping Roofing companies easily and drastically scale their outbound and inbound marketing and sales.) The startups I work with that make me scratch my head are the ones trying to build \"disruptive\" AI infra that does nothing different, provides nothing special, other than potentially nice UI/UX, and is liable to have their lunch eaten by either natural iterations and improvements of our own services they essentially just white label, or some other incumbent. To me, it's like trying to create a new company to compete against Walmart and Target on groceries because they're too massive scale to win against \"a well tailored customer experience\" but then forgetting Costco, Aldi's, Trader Joes, and Whole Foods exist. And why would any of those aforementioned companies feel the need to acquire you rather than casually crush you as they go about their business either ignoring you as you wither or taking your good ideas and incorporating them into their own offering? It's not impossible, just has to make sense and even then a certain degree of \"the stars aligning\" is required. Which is why there inevitably can only be a small group of winners out of this massive sea of hopefuls. And I of course can only shrug my shoulders if asked if the AI infra startup I work at is differentiated, necessary, and lucky enough to be at the finish line with the survivors at the end. (We're finding our PMF and potential road to incumbency mainly with two-ish markets: old and new school enterprise infra and non-tech Fortune 500 type of companies.) reply nextworddev 5 hours agoparentAuthor here. Thanks for the perspective. p.s. I do hope AI startups not estimate how hard it is to break into vertical markets which have their own challenges reply swalsh 11 hours agoprevI'm not sure I'm exactly at the edge of things, but I have 2 companies trying to setup regular meetings with me to be a beta customer. Both have promised I can help define a new product, but when I list my real problems... they aren't in the mission. Everyone wants to solve RAG (that's easy, don't need help) or they want to give me a gui I don't need, or wrap open source software like vllm. Or \"solve privacy\" (which usually comes in the form of masking... which surprise, that works for PII, but not PHI... I need the protected information). Want to solve a real problem, help me create custom benchmarks, clean my data, get my small parameter model to reason better etc. reply tinco 10 hours agoparentWe had the exact same problem before genAI became the next big thing. All the startups were selling generic fine tuning and labeling services both of which are super easy to build, and they didn't even work on our unique super high quality super high resolution 40TB dataset. Our problem was we had a real world problem and real data. All the startups were solving for imaginary problems and had no data. reply llm_trw 9 hours agorootparentSounds like you need a consultancy and not a startup to solve your problem. reply BillyTheKing 9 hours agorootparentmaybe that's really where the business here is.. working through a whole bunch of custom data-sets and trying to generalise from there. It'll be hard to generalise all of it, but I'm sure there'll be pockets of functionality that can be shared across more than a single data-set. And maybe that's at the core of the issue here, namely that this service in its current form doesn't scale like b2c internet tech reply hodgesrm 3 hours agorootparentMost startups want to sell you the equivalent of those airline kiosks where you tag your own luggage, because they are cheap to deploy and don't have high labor costs. The problems you describe are labor-intensive and not easy to solve automatically. I think we will go back to tools combined with humans to solve at least some of them. So it's services and software. reply swalsh 7 hours agorootparentprevProbably the best play of the cycle if you're not Nvidia reply benrutter 10 hours agoparentprevThis rings so true! I think it's natural whenever there's a new technology that a lot of start ups spring up with a vibe of \"GenAI is cool, let's do something with that!\", which is 100% the wrong way to go about building something. Starting by investing yourself fully into a given problem, and fixing it with the most appropriate tool (might be GenAI, might not) is much more likely to end in something people actually want or need. Doing the reverse, and trying to find an existing problem that matches a solution you've already picked is how you end up with hundreds of companies selling thin API wrappers for ChatGPT. reply ozim 8 hours agoparentprevThat is basically every SaaS solution problem. You are not going to want to pay them for your custom development because you would like pay \"generic solution price\". That is why you have to pay for your own dev team as SaaS vendor is not going to be your custom development team - as your custom problem is not available for easy resell to other customers. reply BobbyJo 7 hours agoparentprev> Want to solve a real problem, help me create custom benchmarks, clean my data, get my small parameter model to reason better etc. I recently started a company with a friend if mine to do exactly this. Ive worked at a few AI startups over the last 8 years, and the problem everyone tackles independently (and poorly) is the long tail of dealing with input data that isn't great. You build a demo with sample data that works well, then you move on to real world uses and the data is suddenly... blehg. reply ghaff 5 hours agorootparentAh. Cleaning data. The big trick going back to data warehousing. reply BobbyJo 5 hours agorootparentWhen you know the underlying consumer is an AI model, you can do a lot more to make the input data useful. reply altdataseller 6 hours agorootparentprevWhat are some examples of data theyre trying to use as input? reply statusfailed 10 hours agoparentprevI'd love to know what your use case is that makes those things important to you - and what kind of benchmarks and cleaning tasks do you need to run? Also, what kind of evaluations for quality of reasoning do you use? reply threeseed 12 hours agoprevWay too many founders don't understand the impact of competing with cloud vendors. Almost all enterprises have pre-committed budgets for cloud which means unless your product is FOSS it's going to be hard to convince someone to bet their business on it. Especially given that in this fundraising environment there is a 95% chance they won't be around in a year or two anyway. It's going to be a brutal few years especially if we are heading into a period of diminishing returns in terms of LLM accuracy. reply devjab 11 hours agoparentI’m also sort of curious as to how much of a market research they’ve done if they’re trying to compete with Azure and AWS. Even before the recent LLM rush took off, AI was a thing. In the city of Copenhagen there was a project to digitalise a few million case files (which is 10-100 documents per case file), and how it was done was basically with an intermediary company who knew the training and a cooperation with Microsoft. Yes, I’m dumping down the complexity of it all, but once the training period of half a year was over, Azure made a lot (and I mean a lot) of infrastructure available for not a lot of money and the process completed in a week or so. Since it had to happen and because it was a PoC the same project was also done by real humans. This was the “actual” project and every time deadline and whatnot the AI project had came from how long it would take X humans to do it. I can’t recall how many X was, but it was enough to meet the legal deadline for when these case files had to be digitised and sorted correctly. The human project was the result, and then the AI PoC was later used as a lesson on whether it could be done this way or not. It can, it was more accurate and not more expensive. Anyway… I’m not sure who would’ve been capable of competing with Azure. (Outside the usual suspects). Maybe a company of Hetzner could? But you would need someone who can offer you a massive amount of computing on demand, and the only companies which are going to have that are big vendors. Maybe it’s different with LLMs because the requirement is a continuous thing rather than something you need for a short period of time? reply jononor 11 hours agorootparentAssuming: 50 million files, assuming 4x concurrency per CPU, taking 1 second each, would take approx 150 CPU days. Using just 10 machines it could be done in 15 days. This does not fundamentally seem like a massive project in terms of compute? If time per instance would go up factor 10x, if one would allow 30days execution, could be done by 50 machines. I think that most compute providers can do that (given some months notice)? reply morgante 10 hours agoparentprev> Almost all enterprises have pre-committed budgets for cloud which means unless your product is FOSS it's going to be hard to convince someone to bet their business on it. This isn't a death knell. 1. If you get into the marketplace, enterprises can spend their commit against you. 2. A few million in ARR is ~nothing to a hyperscale cloud, but meaningful to most startups. If you find the right positioning, you can get their sales team selling your solution on many deals. reply golly_ned 3 hours agorootparentHyperscale cloud has stringent security and compliance requirements, and within hyperscale cloud, it's institutionally difficult to lobby for spending on a startup. I spent about six years in hyperscale cloud and never saw a case where we spent a few million on a startup. reply morgante 1 hour agorootparentYou seem to have misunderstood, I'm not referring to the hyperscaler spending money themselves. If you don't think any ISVs are making millions through the marketplace you're simply mistaken. I worked at Google Cloud and personally know at least one startup that made the majority of their revenue through cloud partnerships. reply nextworddev 10 hours agorootparentprevAuthor here. Yes, that said getting into the ISV / APN partner program can be a major pain in the butt and take quite long (from a startup’s perspective where time is precious) reply weitendorf 11 hours agoprevGreat article, and pretty relevant to what I'm building (cloud developer tooling, including some genai, but also including non-AI tools + an application platform. Email me if interested.). Obviously I'm not nearly as pessimistic about it. Zoom out for a sec and generalize to SaaS in general, not just AI infra (a subset of Saas) - all the arguments listed apply there too, except the data moat (which honestly doesn't matter to tons and tons of AI infra companies. That's more of an AI application problem). Now of course most startups are doing AI at least a bit, but in the past decade we've seen plenty of SaaS vendors compete with incumbents either head on or by carving out their own niche. In fact, two of the companies the author considers \"incumbents\" are arguably still challengers, but definitely were in this exact situation just a few years ago: Vercel and Databricks. Also, competition from incumbents is hardly a deathknell. There's room for multiple products in some market segments - how many RDBMS companies are there? Competition from a huge incumbent in many ways comes with benefits, because it helps grow the overall market and awareness of the product space, including your own product. I suppose according to this author I'm in the \"application layer\" even though really I'm in the AI-application-layer-now-but-not-later-layer, software-infrastructure-layer. And that's great because I actually do have experience in that specific application area. But honestly, saying \"you ought to have expertise in your domain\" is 1) duh 2) in the examples (llamaindex parsing/ocr, langchain llmops + agnetic stuff), there is clearly a big enough twist on doing it \"but with AI\" that the application/vertical is close to novel. Successful challengers create valuable businesses without prior deep expertise in their domain all the time and I don't really see how this is any different. Basically, you could repeat this for any SaaS business. Starting a company is hard, but I don't know if AI infra is uniquely hard in the ways laid out. reply latchkey 7 hours agoparentBuild bare metal developer tooling for GPUs and you'll get aquihired. reply diwank 4 hours agoprevWhile I agree that AI infra startups are hard to build, I strongly disagree with the idea that they are harder than foundational or application layer startups. I think it boils down to what you know and what resources you can muster. For instance, foundational AI startups are also ridiculously hard to build. You need an insane amount of funding, spend it pretraining models to stay competitive only to find that gains in hardware and model architecture make them obsolete within months plus there's no real guarantee that scaling will keep working. Application layer startups are hard in a very different way, there's an insane amount of competition and new capabilities are emerging every few weeks. I have worked with a few AI girlfriend startups and they are really struggling with keeping apace and warding off ridiculous amount of competition. I think it's really just YMMV. Of course, the deeper you get into the stack, the more monopolizing pressure there is. Is it hard to build AI infra startups? Yes 100%. Will there be very few winners? Yes. Is it harder than foundational or application layer startups? Depends on the founders' strengths. Is it Is it a lost cause? I really don't think so. reply siva7 10 hours agoprevIt bugs me that all we are seeing in the vc-backed startup scene seems to be ai infrastructure startups. We got something close to ai and all people come up with is they want to be the next ai marketplace store or the millionth infrastructure startup that does exactly the same like their competitors. How boring. reply pas 9 hours agoparentYC funds 200-500 companies each year, there's plenty of interesting ones. reply teaearlgraycold 10 hours agoparentprevSome of us are working on synthetic data reply nextworddev 10 hours agoparentprevAuthor here. Wait until you see the ChatGPT for Law landscape! /s reply GoAwayPulomi 8 hours agorootparentThis will be as fun of a read in 7 years as reading about IBM Watson's impact on the medical field is now. reply mehulashah 11 hours agoprevThe title is true. But, the arguments don't hold water for me. 12 years ago, I started a big data company. It looked similar for big data companies when Cloudera raised almost $1B in 2014. Too many people building data warehouses, especially in the cloud. I exited. Who knew that Snowflake and Databricks would emerge against the incumbents. Similarly, there will be winners in the AI infrastructure space. To win, you need to focus on your customers and delight them. Narrowing focus makes a lot of sense. Don't pay attention to the doom and gloom, or you'll never do a startup. reply swalsh 10 hours agoparentI've worked with hortonworks, cloudera, and databricks. It's no surprise at all that databricks is killing the competition. Those other companies products were embarrassingly terrible. Not stable, slow, and worst of all, I had instances of wrong results. The software just wasn't good. Databricks is different, it's fast, it's robust, I trust the results. They just built a good quality product. reply rapsey 11 hours agoparentprev> Who knew that Snowflake and Databricks would emerge against the incumbents. Snowflake is not profitable. I doubt Databricks is. Their market and business is crap. reply pas 9 hours agorootparentif they are not profitable with these prices ... what the fuck they are doing!? do they just have company coke-athons all day every day? reply datadrivenangel 4 hours agorootparentThey have a lot of sales people and sales engineers. reply rapsey 8 hours agorootparentprevIt is a sales and engineering heavy business. Very difficult to generate large returns. reply TimPC 4 hours agorootparentThey are becoming like SAP though where initially a company buys one service and it soon finds itself buying every adjacent service from them. If they manage to do that successfully they will be quite profitable. reply rgavuliak 6 hours agoprevIt's as if all of the AI devex/infra companies are cargo culting the story of how the people that made the most money in the gold rush were the people who sold the tools. The thing is that the tools were well understood and battle tested. reply weitendorf 5 hours agoparentGenAI applications are so finnicky that it’s easier to build a company around tools-for-AI than a company fitting their archtypical user profile doing AI applications (that’s actually profitable. Most of their customers likely aren’t anywhere close). That’s inverted from the prior SAAS/cloud boom. I too think there are too many shovel chasers but I think it’s also a consequence of what’s easier to ship. reply hibikir 5 hours agoparentprevAnd this isn't just a matter of AI: You see all kinds of companies trying to provide value adds on top of cloud: \"We will annotate DNA for you as a service!\" When all they do is dockerize the same tools their customers use, and serve as small shims for the least sophisticated customers. The moment said customer grows, they understand they can replace the vendor with less than a week of work. The people making shovels make the money by having strong profit margins, becoming a default vendor, and having a moat. Good luck doing that in AI! And my favorite counter example of selling tools is precisely docker: They built tech used everywhere... yet how much value they captured? It's tge same story all over dev tool space. reply physicsguy 10 hours agoprevIf I'm an application developer or manager, at any >100 person company, it normally doesn't fall into my remit to go out and pick a new company to contract with to provide services. Typically, it gets harder and harder to do that. Even with LLM stuff, we're contracting that through our existing relationship with Microsoft. When evaluating infra options, it therefore is a huge barrier to entry for most developers if there's a 'good enough' option on one of the main cloud providers reply cageface 9 hours agoparentI've experienced this too. Any new service that requires more than a credit card number has to go through the legal department to review the contract and that means it goes to the bottom of the pile of similar requests and probably won't even get a look for months. reply JohnMakin 11 hours agoprevAs someone who has semi-unwillingly worked in infrastructure and infrastructure consulting most of my career - we’ve never even really solved that problem, what on god’s green earth convinced you AI did? I am genuinely curious. reply pierre 12 hours agoprevGood article, but what is the alternative? What can you build today as a software engineer that can have impact? Nothing seems to come close to AI / AI infra, even of its hard / risky / a moving landscape. reply mlsu 12 hours agoparentI would almost invert that statement. Sorry if this comes off ranty, but what exactly are people doing in the \"AI space\" currently that isn't \"undifferentiated spam/chatbot\" being sold to non-techies who heard about AI on NPR? What are real people using \"AI\" for that is so insanely valuable today? How much \"company Y: same product with a chat window, sparks emoji\" do we all need before this thing levels out and we all take a breather on the hype? reply jdross 11 hours agorootparentpersonally? - writing and refactoring code. probably 50 times a day now - improving documentation across the company - summarizing meetings automatically with follow ups - drafting most legal work before a lawyer edits (saved 70% on legal bills) - entity extraction and data cleanup for my users reply mlsu 11 hours agorootparentPut a number on it. How much value of this will they capture from you personally (we'll assume, very very charitably by the sound of it, that you represent an \"average\" user of AI products) when this market matures? Exactly how much will your employer pay for a meeting summarizer? $10/mo a seat, $20/mo a seat, $50/mo a seat? Could the product sustain a 5x, 10x, 50x price hike that is going to have to happen to recoup the investment being made today? reply fhd2 11 hours agorootparentAgreed. Even if right now this seems like stuff companies want to throw money at for novelty/FOMO related reasons, I think eventually reality ought to catch up. Probably an unpopular opinion, but I think the most efficient companies of the future will tackle the ironies of automation effectively: Carefully designing semi automation that keeps humans in the loop in a way that maximises their value - as opposed to just being bored rubber stamping the automation without really paying attention. reply per1Peteia 3 hours agorootparentbingo reply marcosdumay 2 hours agorootparentprevI'd say that if your team needs a meeting summarizer, your team has a meeting problem. It's a clutch that will help you cope with the problem. But the real value is on fixing the actual issue. reply fragmede 2 hours agorootparentI'd say if you're not using a meeting summarizer, you're wasting someone's time by having them write up notes. if you're not writing up notes, you're wasting someone else's time recapping the meeting for them. meeting notes are a 1 (meeting):many relationship for conveying information as to what was discussed. how else do you go back and see what the one person on the storage team talked to your the person on your team who left last week about so you can go into the next meeting with them prepared? reply marcosdumay 1 hour agorootparentIf your meeting produces \"notes\", and those are relevant for people that were not in it, you are doing it wrong. If your meeting is aimed at producing \"general understanding\", it's already a dangerous one, and the understanding should go to the correct documentation (what is best done during the meeting). Otherwise, it should produce \"focused understanding\" between a few people and with immediate application. If all you take from it is notes, well, I'm really sure that your team won't go digging through meetings notes every time they need to learn about some new context. Meeting notes are useful for CYA only, and if people feel safe they'll be filled directly at /dev/null. reply Art9681 4 hours agorootparentprevWhat do you consider \"AI\"? Because machine learning models have been deployed in enterprise systems for years. Video processing, security, data labeling, sentiment analysis. The sexiest one I can think of in recent memory is nVidia DLSS. reply mlsu 1 hour agorootparentBroadly, what marketing is saying is “AI.” There is huge value being created with deep learning today on internal systems. Recommenders, machine translation, computational photography… it is huge, improves people's lives, drives revenue. None of that is marketed as \"AI.\" It's just a thing the computer does. The single most valuable application of deep learning so far (content recommenders) is a cultural phenomenon, but it’s not referred to as “AI” but rather “the algorithm.” reply swalsh 10 hours agorootparentprevGoing to be vague, but I'm using it to scale out human processes in ways I couldn't using humans (because they cost too much) or regular code (because it's unstructured). Early results are promising, we've found a bunch of stuff which has been buried... and is potentially worth millions. Not a chat wrapper, just breathing new light into our regular old business. reply hnlmorg 12 hours agoparentprevEverything we build has some kind of impact. At risk of getting philosophical, I’d ask yourself what your goals actually are if you feel only AI can have the impact you desire. reply fhd2 12 hours agorootparentNot sure why this is down voted, that is the key question. Impact means different things to people. Could be: 1. Building a sustainable business and making decent money 2. Building a market leader and making ludicrous amounts of money 3. Advancing the state of the art in technology 4. Helping people with their little daily struggles 5. Solving pressing problems humanity is facing Or many other things I suppose. Now if you believe that AI is eventually going to make anything humans can build now redundant, that'd be a reason to believe nothing else matters in the end I suppose. But even if we get there, there's a lot of road leading to that destination. Any step provides value. Software built today can provide value even if nobody is going to need it ten years from now. And it's not like you could even predict that. reply mirekrusin 11 hours agorootparentThe motive is to get acquired in most cases. It’s obvious and starts to make sense when you see startup that has no feasible monetisation strategy on the horizon, yet they exist and get funding. They’re betting on building infra to be hopefully used in large corp and this is their demo/PoC. reply lionkor 12 hours agoparentprevA lot of things, if you're okay with not chasing the next hype bubble reply jononor 11 hours agoparentprevAnything SaaS that solves a painpoints for established industries. Those that have billions of turnaround for decades already, are not good at building tech themselves, and buy solutions/services to run their business. Bonus for low barriers to entry. Agriculture, logistics, real estate, energy, etc. reply swalsh 10 hours agorootparentI have a theory that the days of established businesses that don't know tech is dwindling. A lot of companies which has adopted tech has started building a small foundation of talent internally. I think you're seeing this trend accelerate with the large tech companies laying people off. I have heard about top grade data science talent landing at some small sized health plan. My companies fastest growing competitor is \"internally sourced departments\" of the services we provide. reply nextworddev 9 hours agorootparentYou confirm my observation as well. Even motel chains have developers building internal tools these days reply illegally 7 hours agoparentprevIf you don't know what to build, you don't build. reply oivey 11 hours agoparentprevSlightly different take than some of the siblings: you can still just build this stuff. If your goal is impact, maybe the best place to do it will be at a cloud vendor or other big corp. If your goal is actually just a big VC exit, then maybe not. If your product is something that can be ripped off in 3 months, then it probably wasn’t going to have a long term impact anyway. reply notamy 4 hours agoparentprev> What can you build today as a software engineer that can have impact? Quite a bit, if you don’t follow the standard tech hype. Find an industry that isn’t tech-first and you’ll notice that there’s a lot of room for improvement. reply rsynnott 10 hours agoparentprevDefine ‘impact’. Does ‘impact’ here mean ‘tickles the fancy of a 2024-era VC’? If so, you may be right. If used in its common meaning, absolutely not; most of this stuff is ~useless. reply ehnto 11 hours agoparentprevAll the same stuff, to be honest. If AI is set to replace human work, well we have had a cheap human labour market for decades and yet we still need software. An LLM can't replace a business itself, which is made up of niche processes, direction and purpose, which we sometimes codify into a SaaS. We'll still need to do all that even if AI replaces some of the human parts of the business. reply ianpurton 11 hours agoparentprevIt's fine to be in AI. My takeaway from the article is instead of being a Gen AI startup be a Gen AI startup for a specific use case. reply astronautas 12 hours agoparentprevData infra? reply mushufasa 3 hours agoprevCurious for discussion: Does this logic also apply to industry-specific \"AI Infra?,\" where the APIs are wrapping a service that solves a domain-specific problem using AI, rather than general purpose infra technology? And provides those APIs to other businesses within that industry? reply Simon_ORourke 10 hours agoprevI've come across a number of these AI infra start-ups like Scale AI and Zerve and TBH I'm amazed they can do what they do with relatively small teams when you have Meta and Apple somewhat struggling in this area and buying rather than building themselves. reply blitzar 9 hours agoprevDid any of the startups in question actually ever want to build AI infrastructure or did they all pivot from Metaverse to Crypto to AI in the great pivotting of 2022. Given VC's penchant for throwing cash at grifters in the latest hype space is it any suprise that some of the beneficiaries are looking for a quick exit before they have to do any actual work? reply EdwardDiego 8 hours agoparentYeah those grifter pivots were amazing. Like professional ice skaters. I'm just surprised the Long Island Iced Tea Corp / Long Blockchain Corp hasn't become the Long LLM Corp yet. reply htrp 5 hours agoprevSelling shovels is a way to make money, but definitely not at venture scale. reply openrisk 11 hours agoprevYet there is little \"AI\" specific in this AI infrastructure startup challenge: 1) insane levels of competition towards any goal make relavant minor, secondary, traits that are not obvious before hand. Pure luck becomes more important. 2) excess market concentration (of which the tech sector is maybe the most egregious example) makes any new initiative harder. The more dominant and controlling the incumbents the harder to find a decent sized niche to grow. 3) selling to risk averse enterprizes / organizations is always an uphill battle that requires climbing a mountain of bureaucracy and regulation, only to eventually face random internal politics. In the end the current craze will certainly produce a modified tech landscape. These recurring hypes always overpromise and underdeliver, but a cumulative effect is slowly happening. In such stormy seas its hard to identify an optimal course and strategy. Riding every hype wave may sound silly but might work. On the other extreme, one may seek beacons indicating eventual stable land and try to navigate there. Good luck reply BrunoJo 12 hours agoprevGood tips, especially the point about narrowing the scope. At https://Lemonfox.ai we started with a LLM, image and speech-to-text API. Now we are only focusing on the speech-to-text API as the other areas are already very crowded and there's a lack of innovation in the speech-to-text space. reply cootsnuck 6 hours agoparent> Now we are only focusing on the speech-to-text API as the other areas are already very crowded and there's a lack of innovation in the speech-to-text space. I'm legitimately wondering how your hosted Whisper API for $0.17/hr is supposed to compete with groq's exact same API that costs $0.03/hr. You may be about to find out how crowded all of the AI infra spaces are. I strongly recommend narrowing your scope far beyond modality. If you've been working with this tech and getting familiar with it then you already have valuable expertise. Pivot now or panic later. If you want to stay in the speech space find what markets are being underserved with speech AI related solutions. Are there pain points there that can be solved by a STT API? If so, build those solutions. You can't compete at the infra layer and I'm not sure why you would want to try if you don't already have something unique about your offering beyond hosting open source models. It's never good if your competition is potentially just a single developer in a company standing up your entire service internally in a week. If you are determined to stay in the AI infra space then you'll need to be tackling a hard problem that companies want solved. Maybe take a look at fine-tuning models. Hard problem and maybe there's a hunger for it. (It's a risky one to tackle too though since it's very possible general/foundational models will maintain a grip on \"good enough\".) reply anonylizard 8 hours agoparentprevLike how do you plan on competing against multimodals, which keep getting cheaper and clearly can do audio->text? Or existing incumbents like Deepgram? Or just the generic APIs provided by the big clouds. reply xg15 11 hours agoprevIn a nutshell: If there's a goldrush, you get rich by selling shovels. ... unless there are already 200 shovel shops next to each other... reply kirubakaran 4 hours agoparentYes, Brannan cornered the market before he sold the shovels. Selling shovels is not that profitable if you skip that \"Step 1\". > he owned the only store between San Francisco and the gold fields — a fact he capitalized on by buying up all the picks, shovels and pans he could find, and then running up and down the streets of San Francisco, shouting 'Gold! Gold on the American River!' He paid 20 cents each for the pans, then sold them for $15 a piece. In nine weeks, he made $36,000.\" https://en.wikipedia.org/wiki/Samuel_Brannan reply okanat 8 hours agoparentprevand unless some of the shovel shops not have an iron mine, a steel factory and a stamping shop as well. They can sell the stuff 1/5 of the price and you're not getting rich anytime soon. reply iknownthing 5 hours agoparentprevat what point does a goldrush become a shovelrush? reply mschwarz 10 hours agoprevWhy does the author claim that Adept was acquired by Amazon? The linked article says they hired away the CEO and key staff. reply justincormack 10 hours agoparentIt was a weirdly structured deal that in effect was an acquisition. The investors were paid off. reply curious_cat_163 10 hours agoprevArticles like this represent reminder that we are in the middle of a hype cycle. [1] I don’t say that thinking that LLMs (really: Transformers and the corresponding scaling of compute around it) don’t represent a step change. I say that because I am very sure that we are going to see a slope of enlightenment that results in products that improve the quality of human life. [1] https://en.m.wikipedia.org/wiki/Gartner_hype_cycle reply nextworddev 10 hours agoparentAuthor here - the article isnt questioning the value of AI per se, but value capture and competitive dynamics. Internet routers remained valuable but got commoditized, sort of a thing. reply Juliate 6 hours agoprev [–] Gen AI feels more and more like NFTs and blockchains, and overall, a lot like pre-2001-bubble (or more accurately post y2k). A very exciting and expensive solution in search of an actual problem, that will ultimately find its way, commoditised, in a small niche, while adjacent technologies take the lead for productive use-cases. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "AI infrastructure startups face significant challenges, including intense competition and high costs, unlike tech giants like Google, Amazon, or Facebook, which evolved into infrastructure providers.",
      "Venture capital investment in AI infrastructure may be misguided, as the true value lies in companies offering tangible, user-friendly solutions rather than just frameworks.",
      "Even successful AI companies like OpenAI lack clear products, emphasizing the need for practical innovations that can transform user interactions."
    ],
    "points": 176,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1719976558
  },
  {
    "id": 40860831,
    "title": "All I want for Christmas is a negative leap second",
    "originLink": "https://qntm.org/leap",
    "originBody": "Things Of Interest Blog All I want for Christmas is a negative leap second 2024-07-02 by qntm I just want to see it. Just once. I want to watch that earthquake ripple through all of global electronic timekeeping. I want to see which organisations make it to January morning with nothing on fire. You know what a leap second is. The short version is that planet Earth is a terrible clock. I love leap seconds. I love the unsolvable problem which birthed leap seconds, I love the technical challenge of implementing leap seconds, I love that they are weird and delightful and that they solve a problem, and I love that this solution is hugely irritating to a huge number of people who have more investment in and knowledge of time measurement than I do. It is a huge hassle to deal with leap seconds and I love that there is no universal agreement on how to deal with them. What should Unix time, for example, do during a leap second? Unix time is a simple number. There's no way to express 23:59:60. Should it stall for a second? Should it overrun for a second and then instantaneously backtrack and repeat time? Should it just blank out and return NaN? These days it seems like a popular choice is the Google-style 24-hour linear smear from noon to noon UTC. That is: a full day of slightly longer-than-normal \"seconds\". Should a clock do that? Is a clock allowed to do that? I love that. I think it's highly amusing. But they're talking about giving up on leap seconds entirely by 2035. Rather than grapple with the organisational challenge and the engineering challenge, the suggestion is to just increase the allowable absolute gap between UT1 and UTC, from 0.9 seconds to something larger. And I'd be a little sad if we did that. For one thing, it feels like a confession of defeat. Like, come on. Weren't you having fun? You've reached a situation where campaigning for the whole world to change the way it measures time is simpler than fixing your code? Well, maybe it is simpler. I haven't seen your code. For another thing, this is not something we can run away from. Sure, leap seconds flummox our software now, but they are at least relatively common. Up until the recent dry spell they were happening more frequently than leap years and over the longer term, as the Earth's rotation gradually slows, they're only going to become more frequent. The suggested alternate approach is to just let the gap between UTC and UT1 grow for 50 to 100 years until it's something on the order of 60 seconds, and then introduce an entire leap minute. Because there's nothing computer programmers handle better than special cases which only occur every hundred years or so. How in the world could this be an improvement? Leap seconds are announced six months in advance. They have been a fact of life for over fifty years. How much advance warning will the leap minute require, or receive? Five years? How much special one-off work will it take to handle? Is there a single system currently in existence which can handle a leap minute? This just sets us all up for a mostly arbitrary Millennium Bug-scale operation. It's going to be unrewarding and supremely unpopular and everybody's going to hate it at least sixty times as much as they hate leap seconds now. This, I feel, is the wrong approach. If something is difficult, you do it more often. Also, it's not lost on me that a solution of \"Wait 50+ years and then do something\" is equivalent to \"Let's ignore the problem until we're all dead\". But finally and most importantly, abolishing leap seconds would permanently close the door on any possibility of a negative leap second. Every leap second to date has been positive. The Earth spins a little slowly, just as a matter of course. In fact, there's a case to be made that the SI second was defined too short. And over the long term, its spin is only going to continue to slow. However, there are short-term fluctuations in the Earth's angular velocity, both increases and decreases. It's not fully understood what causes these, but since 2018 or so the Earth has been spinning faster than usual. The gap between UT1 and UTC, known as DUT1, hasn't been steadily trending negative. There hasn't been a need to introduce a positive leap second every year and a half or so. In fact, since 2020, DUT1 has been gradually trending upwards. If it continues to trend upwards in the same way for another decade or two, it is not completely impossible that the offset could reach a point where the IERS could credibly want to use a negative leap second to bring the offset back down towards 0 seconds. Would that ever happen? Under the current system, only full single SI seconds are inserted (or, potentially, removed), and only at the end of June and at the end of December. But before 1972 UTC and TAI were kept in much closer synchronisation, by adding or removing fractions of seconds, and by doing so far more frequently, at the end of any month. On two occasions, time has been removed: 0.05 seconds were removed at the end of July 1961. 0.1 seconds were removed at the end of January 1968. (No, I'm not advocating returning to this state of affairs.) So there is a smidgen of precedent. But it has been a long, long time. Negative leap seconds are possible, but they have never happened, and until recent years it seemed like they would never happen. And I feel extremely confident in saying that, short of an apocalyptic event, a negative leap minute could never, ever happen. I feel that the IERS would be under tremendous pressure not to announce a negative leap second, because, well, look at how fiercely actual engineers are currently fighting positive leap seconds, which have occurred dozens of times over the past half-century, and are, relatively speaking, incredibly well-understood and extremely well-supported. The intention is to keep DUT1 between -0.9s and +0.9s. Typical positive leap seconds in the past have occurred at DUT1 offsets between about -0.4 and -0.6 seconds — sometimes earlier, between -0.2 and -0.4 seconds, when the Earth's rotation was relatively slow, with the earliest at -0.2160228 seconds. If DUT1 were to trend upwards to +0.2160228s, I feel that the IERS would probably continue to wait. I wouldn't be surprised if they waited until +0.6s. I wouldn't be surprised it they were pressured to wait until +0.8s, or until the actual abolition kicks in, whenever that is eventually scheduled. It'll be pretty imminent, I'd imagine. But I also don't know how much of that theoretical pressure the IERS would theoretically care about. The point is: No one, or almost no one, is ready for a negative leap second. It has always been a thing which can, in theory, happen. Up until the past few years, though, it looked impossible. And now it might, might just happen. And I need to see it. Back to Blog Back to Things Of Interest Show discussion (11) Discussion (11) 2024-07-02 22:50:48 by qntm: Love a bit of geodesy. 2024-07-03 01:49:19 by DSimon: What should unix timestamps do during leap seconds? Absolutely nothing. The leap second should only matter when converting unix time to other calendar format. Same policy as leap years and DST. Or at least, that's what I would say if I could go back in time and change the POSIX definitions... And also, everyone would have to remember not to store schedules for distant future events as timestamps since they might not occur when predicted... Oi, time is hard :-( 2024-07-03 02:01:43 by Max: Leap seconds are stupid. Nobody except astronomers cares about solar time. Just stop using them, if the difference ever becomes greater than 30 minutes, shift all timezones by 1 hour, which is something we do twice a year anyway, so most software supports it already. No special handling necessary. 2024-07-03 04:16:36 by ChrysAlice: \"Leap years are stupid. Nobody except astronomers cares about solar time. Just stop using them, if the difference ever becomes greater than 30 days, shift all calendars by 1 month, which is something we do twelve times a year anyway, so most software supports it already. No special handling necessary.\" I want to say that I'm not trying to be mean, but if you've had to deal with situations where the exact second or smaller something happened matters, it seems far less dumb. 2024-07-03 11:11:01 by qntm: I care about astronomers! 2024-07-03 14:06:05 by Max: I didn't say exact time doesn't matter, I said leap seconds and solar time don't. TAI already tells you the exact time something happened with maximum accuracy. Leap seconds intentionally make it *less* accurate! 2024-07-03 14:06:45 by Andrew: I fully support ending leap seconds, and there's no need for a leap minute either. Countries intentionally set their civil time wrong by an entire hour or more, sometimes making the error depend on a complicated set of rules involving what time of year it is. So what's the point trying to get it right within a second or a minute? Just let DUT1 accumulate until it gets close enough to an hour that they decide to shift, and then make a change to the Olson DB (which will definitely still exist in 10,000 years). The effect is that the \"UTC meridian\" simply drifts west over time. People who care about exactly when something happens keep counting SI seconds, just like they do today, and the astronomers keep consulting IERS for the difference between UTC and UT1, just like they do today. The only thing that changes is that the difference between UTC and TAI stays 37 seconds forever. 2024-07-03 14:10:35 by Max: qntm: admit it, you only wrote this article because of the URL ;) 2024-07-03 18:22:21 by Kevin: The decision to define computer time (in the Olson database, POSIX, etc.) as \"UTC + offset\" was a mistake. It should have been defined as \"TAI + offset,\" with UTC treated as \"just\" another time zone. TAI was explicitly designed to have the nice monotonic properties that computers want to have, and all the existing time zone machinery is entirely capable of handling irregular (not a multiple of 1 hour) offsets (because there are several current and historical time zones with irregular offsets). It's mostly too late to change now (short of abolishing leap seconds altogether), but for some time, the Olson database has had a separate subdirectory called zoneinfo-leaps (previously \"right\") which assumes that your system time includes leap seconds in violation of POSIX, and provides a suitable set of offsets that adjust for those leap seconds (including a UTC time zone with nonzero offset). In principle, it is then possible to have a system that works as I described above. Obviously, there are problems with this approach, mostly of the form \"software wrongly assumes that your clock is on UTC and fails to apply the leap second offset,\" but there are also administrative issues, like \"how are you going to find an NTP pool that is compatible with this?\" and \"you know you're still going to have to speak UTC to every other system on the planet, and that's still going to have leap second infelicities, right?\" As for negative leap seconds? I'm not convinced this would be anywhere near as big a deal as positive leap seconds. Positive leap seconds cause Unix time to (appear to) go backwards, which is \"never\" supposed to happen. Negative leap seconds would cause Unix time to jump forwards... but anything that interacts with the network already has to deal with random unpredictable latency spikes, so for distributed systems, this would be a mostly unremarkable event. You would probably see some requests time out or fail and have to be retried, I guess, but a robust distributed system should already be aware of this failure mode and should have recovery code for it anyway. I wouldn't want to be the SRE stuck holding the pager on that particular day (most distributed systems get upset and notify a human when they see 100% of requests suddenly fail all at once), but I think the average consumer would not even notice. 2024-07-03 18:56:36 by Solis: \"You've reached a situation where campaigning for the whole world to change the way it measures time is simpler than fixing your code?\" For the benefit of navigation, we changed the way mariners measured time (and it's a cool story!). Then, for the convenience of rail-way operators, we changed the way the whole world measured time. We changed it again, in a significant portion of the world, ostensibly to save on energy—but maybe just because William Willett was annoyed by dusk interfering with golf games. One can make a legitimate case that measurement systems should serve humanity, rather than the other way around, at least till we meet non-human sophonts. I'm in Ottawa, Canada, where Stellarium says noon was at 13:07:11 today (find and select the sun, and press F10 to bring up \"astronomical calculations\"; then go to the \"RTS\" tab, press \"calculate\", and read the \"transit\" column). It'll have its latest value of 13:09:20 in a few weeks, and its earliest of 11:46:20 in early November. The variance of solar noon across China is pretty wild by comparison. So the premise that our quasi-annual adjustment of one second is to make clock-time substantially match solar-time seems somewhat farcical. It'd be millennia before we could gradually accumulate enough error to match what was done instantly by legislative fiat—and over such time-scales, people would just get used to the sun rising at 17:00 or whenever. That said, I do share your sense of curiosity: I always love reading reports on the myriad and fascinating ways in which systems have failed (but less so when I've inherited maintenance of such systems or am otherwise affected by them). 2024-07-03 19:14:03 by Nim: I agree that leap seconds are awesome, and Im a big fan. I can also see that they pose a problem for civil time. The proposed solution, however, is fundamentally wrong. If using a time scale that is somewhat irregular poses a problem, use one that is regular, such as TAI. Re-defining an existing time scale (UTC) is a form of scientific betrayal. It makes me wanna spit and puke. It really does. Add comment Hide discussion New comment by : Plain text only. Line breaks becomeThe square root of minus one: Cancel Submit Contact About Search: © qntm",
    "commentLink": "https://news.ycombinator.com/item?id=40860831",
    "commentBody": "All I want for Christmas is a negative leap second (qntm.org)174 points by NKosmatos 20 hours agohidepastfavorite204 comments StevenWaterman 8 hours ago\"Noon\" is rooted in a physical phenomenon - when the sun is highest in the sky. But \"UTC Noon\" is arbitrary, because we had to pick a point on the earth. Leap seconds are trying to ensure that, standing at the point we arbitrarily picked for UTC at noon, the sun will be at its peak. That doesn't feel like something that NEEDS sub-second precision. I mean - by walking from one side of a time zone to the other, you can have an hour or more of imprecision. https://i.ibb.co/r000S5s/caxxyddlsgp11.jpg > Is there a single system currently in existence which can handle a leap minute? Every system can handle a leap-hour, they happen twice a year in many countries, courtesy of DST. So let's just wait until there's 15 minutes of error - a couple of millenia from now. Then move the UTC prime meridian about 3.75 degrees / 400km, fixing the error while keeping UTC monotonically increasing 1 second per second. And to update our clocks, use the one mechanism that we already rely on comfortably - timezones. Add 15 minutes to each timezone, the same way we handle DST now. reply OtherShrezzing 4 hours agoparent>So let's just wait until there's 15 minutes of error - a couple of millenia from now. Then move the UTC prime meridian about 3.75 degrees / 400km, fixing the error while keeping UTC monotonically increasing 1 second per second. Shifting the prime meridian 400km seems like it'd have some unintended consequences akin to the Y2K problem. Its physical location is used as a reference point in some coordinate systems, ECEF for example. reply Analemma_ 1 hour agorootparentYou don't need to move the prime meridian, you just need countries to update their individual time zone offsets from UTC, which is already a well-supported path that happens all the time. If we abolish leap seconds, countries would just wait until solar noon drifted ~30 minutes (which would take centuries), then just do a TZ offset update. Nothing could be simpler. reply mywittyname 1 hour agorootparentAre you suggesting a solution akin to UTC-4:00 is now UTC-4:00:01? That sounds like a headache of epic proportions when contrasted with the alternative of a leap seconds. reply umanwizard 1 hour agorootparentNo, they're suggesting a solution akin to Eastern Kazakhstan was on UTC+6:00:00 one day, and on UTC+5:00:00 the next day. This actually happened last March[0] and I'm not aware of anyone outside Kazakhstan being inconvenienced by it at all. tzdb updates happen several times a year and everything keeps working fine. 0: https://data.iana.org/time-zones/tzdb-2024a/NEWS reply Analemma_ 57 minutes agorootparentprevNo, I'm saying that e.g. Central Europe Time keeps being defined as \"UTC+1\" for the next few centuries until solar noon has drifted about 30 minutes away from civil noon, then CET's definition changes to be UTC+0 or UTC+0:30. This is a time zone update of the sort which happens constantly (e.g. in 2017, Chile changed its TZ offset, Haiti started using DST and Mongolia stopped using DST. A TZ offset change to account for clock drift would be exactly the same) reply layer8 2 hours agoparentprev> So let's just wait until there's 15 minutes of error - a couple of millenia from now. This might already happen in 200-300 years, because the delta increases quadratically: https://www.ucolick.org/~sla/leapsecs/deltat.html reply mlyle 3 hours agoparentprev> NEEDS sub-second precision To be clear, for decades, we've not sought sub-second precision. We've sought precision of a second. Maybe we should seek more-- the big problem with leap seconds is that they've been rare enough to not be tested completely well, but common enough to provoke problems. > And to update our clocks, use the one mechanism that we already rely on comfortably - timezones. Add 15 minutes to each timezone, the same way we handle DST now. Then everything in the world that displays time is going to need a software update when you're going to do this, or it will show time off by 15 minutes. I do think it could be sane to let UTC's offset to drift up to +3.0 to address this temporary trend of a \"fast Earth\". Of course, that's going to make leap seconds rare for awhile, and it will come back and bite us when the recently-untested event of a positive leap second happens again. reply eqvinox 1 hour agorootparent> Then everything in the world that displays time is going to need a software update Have you seen how often tzdata updates are published? There tend to be multiple each year. Stuff already should be auto updating this. (Python, but good reference: https://github.com/python/tzdata/releases ) reply jandrese 2 hours agoparentprevI wouldn't even suggest a solution. Let the people thousands of years in the future figure it out. Working out solutions now is like asking people from the time of Jesus what we should do about the clock for a worldwide computerized network. reply tim333 1 hour agoparentprevI vote to correct the clocks once a century. Then it'd be infrequent enough to have a big celebration rather than being annoying. reply eCa 3 hours agoparentprev> So let's just wait until there's 15 minutes of error - a couple of millenia from now. Then move the UTC prime meridian about 3.75 degrees / 400km Perhaps a couple of millenia down the road, we have the technology to speed up/down the rotation of the Earth in order to keep it synced with UTC. reply billpg 2 hours agoparentprev\"move the UTC prime meridian\" We'd have two prime meridians. One for time and another for longitude. (Not a deal breaker but we'd have to plan for it.) reply throw0101b 7 hours agoparentprev> That doesn't feel like something that NEEDS sub-second precision. It does not need to be sub-second, but sub-seconds add up over time. The Julian calendar wasn't that far off, but it was cumulative, so to fix things it took a ten day jump: * https://en.wikipedia.org/wiki/Gregorian_calendar It is considered easier to have a few small(er) semi-regular jumps than suddenly having to making giant, sudden, one-off jump in the future. reply skrebbel 7 hours agorootparentWe make small semi-regular changes to timezones all the time. DST switches, governments arbitrarily deciding that their country is going yo be in a different timezone (at a 2 day notice), or move the DST switch day by 2 weeks, etc etc. This is a solved problem and it happens all the time. The systems and datastructures that can deal with this (eg tzdata and the process & people behind it) are already in place. reply throw0101c 6 hours agorootparent> This is a solved problem and it happens all the time. UTC changing does not happen all the time: what the 'all the time' thing is a display/UI offeset against UTC. Time itself is not changed in those situations, but would be with a 'UTC jump'. The closest thing we get to universal time 'changing' are leap years and February 29, and we regularly get stories about people messing that up. And if something as common and regular as that gets fumbled I have little hope for pulling off a one-off jump of UTC. It is coördinating the universal part that I would imagine to be the difficult part. reply skrebbel 5 hours agorootparentThen just keep UTC when it is? (ie allow its prime meridian to shift away from Greenwich) Adjust all the timezones by half an hour in a few millennia. It’s really both fine and up to our grand-grand-grand-grand-etc-children to decide. Really, this is a non-problem. reply pixl97 4 hours agorootparentThis really doesn't solve anything either. Attempting to treat time as something that ticks towards the future at a consistent rate relative to all observers is already broken. The Earths rotation is slowing down over geologic time. Even on short orders things like earthquakes can change rate of rotation of the planet. Start putting stuff on spaceships and different planets and you start seeing how wibbily wobbily time really is. Just like we have to focus on making application secure, we need to ensure our applications don't shit their pants when applications change time in unexpected ways. reply organsnyder 4 hours agorootparentprev> It’s really both fine and up to our grand-grand-grand-grand-etc-children to decide. I'd rather build gradual adjustments into our systems so that they have to be resilient to this sort of thing. Sure, leaving it up to our distant descendants is enticing, but then they're going to have a Y2K-sized problem to fix. I'd rather leave a legacy of systems that were designed to be resilient. reply umanwizard 1 hour agorootparent> then they're going to have a Y2K-sized problem to fix. No they aren't. tzdb updates happen several times a year already, and you don't notice. reply organsnyder 50 minutes agorootparentThe suggestion I was responding to was to basically stop doing this. reply afiori 5 hours agorootparentprevThe universal part is alread coordinated, the problem is that it keeps adding and removing seconds with no regularity and little advance notice. reply umanwizard 7 hours agorootparentprevIt feels like you missed the main point. Time-zone changes are already very easy to handle and are sufficient for dealing with this problem without having to use a leap second or leap minute ever. reply throw0101c 5 hours agorootparent> Time-zone changes are already very easy to handle and are sufficient for dealing with this problem without having to use a leap second or leap minute ever. TZ changes are a display delta against UTC. The closest thing we get to universal time 'changing' are leap years and February 29, and we regularly get stories about people messing that up. If something as common as February 29 is fumbled, what are the odds of pulling a one-off event? And as someone who was a sysadmin when the US changed its TZ rules many moons ago, the sudden rule change was anything but straight-forward given the fairly static nature that they had been for the long history of software development that had occurred until that point: a lot of software is US-developed, and there was little/zero consideration to updating rules. (Though I think that event caused a lot of developers to be more understanding.) reply umanwizard 4 hours agorootparentThe point is we don't need to change universal time. Thousands of years from now, when solar time drifts away from UTC enough for a particular country to care, that country can change its time zone. There doesn't need to be any global coordination and the process will be gradual enough that nobody will notice. reply layer8 2 hours agorootparentThe EU already fails to agree on dropping DST (and adjusting time zones in the process), because member states will be affected differently, and neighboring countries that should really be in different time zones benefit from being in the same zone. I doubt they could agree on shifting their time zones, because invariably some countries would get the short stick. reply umanwizard 2 hours agorootparentI keep repeating this point but for some reason people keep ignoring it. Countries do not have to agree to change time zone. They can each change it whenever they want. reply layer8 2 hours agorootparentThe point is they will not want to change their time zone to a different one from their neighbors if they are in the same zone, because that has economic downsides. And the neighboring country will not want to change along because winter mornings will be too dark or whatever. It’s exactly the issue that currently prevents dropping DST in the EU, although a majority would prefer not changing clocks twice a year. reply Analemma_ 1 hour agorootparentI think that getting all of Europe to change time zone offsets by 30 minutes once every 400 years is within our power. reply afiori 5 hours agorootparentprevIn 400 years we can define new 30 minutes shifted timezones and in 400 - 500 years governments can slowly change their official timezones (maybe at summer/winter time they shift 30 minutes instead of 60). It does not feel like a big issue. reply immibis 4 hours agoparentprevWe already have that system, and it's called TAI. You are free to use TAI instead of UTC in your computing projects, and don't have to try to change the definition of UTC. reply anamexis 4 hours agorootparent> You are free to use TAI instead of UTC in your computing projects, and don't have to try to change the definition of UTC. Not if you want to interoperate with basically any other system that uses time. reply AnotherGoodName 2 hours agorootparentWhich is a very good reason to abolish the leap second in UTC to make it the same as TAI time. We can then make a new standard that includes the leap seconds and add them to that (which computers will only ever deal with when they format datetime). Leap seconds are absolutely part of the local datetime conversion functionality of time and not part of the counting functionality. Unix time should never have been different from TAI time in the first place but somewhere along the line some idiot made the absolute undeniable blunder of putting the seconds offset of the suns position relative to earth in the counter of seconds rather than putting it in function that formats the local datetime. Anyway here we are. It’s totally fair that UTC includes leap seconds but unfortunately they passed on UTC as is into the unixtime seconds counter which makes no sense since computers don’t print UTC datetime directly anyway, they have a special date() formatting functions that could easily and problem free add seconds as needed. So what’s the solution? Well telling everyone to suddenly adopt TAI is difficult. But we could just abolish leap seconds from UTC effectively migrating everyone without them realising it. Now I know that sounds odd. After all this blunder wasn’t done by the UTC creators, it was the Unix guys that fucked up here. UTC is literally meant to track the sun after all. But still it’s the easiest fix and we can always create a new UTC, UTC_leap_seconds, that we can use in our datetime printing functions if we want. Abolishing leap seconds from UTC and thus Unixtime will make the world run more smoothly. It’s also been planned as we speak so you don’t need to do anything but wait! :) reply anamexis 2 hours agorootparentI don’t disagree! reply 01HNNWZ0MV43FF 4 hours agorootparentprevI'm trying. I don't even know if rust or c++ have tai yet reply bitcharmer 3 hours agorootparentThis would be a feature of the underlying platform and nothing to do with the programming language. reply modeless 15 hours agoprevI think it's weird how people react with such horror to the idea that maybe, just maybe, it wouldn't represent any kind of problem to the people of the 23rd century if 12:00 didn't correspond to the instant the sun was directly overhead, but instead a minute past. Nor would it cause any issue for people thousands of years from now if 12:00 was in the evening or the morning or any other part of the day or night. For those future people it would simply be the way things are, and it would stay that way their whole lives. reply mjevans 14 hours agoparentNoon already does not correspond to the sun overhead. Timezones, and IIRC the time of year and inclination relative to the equator matter too. However, irrespectively, it's basically never solar noon at noon if someone is using time zones rather than local solar time, which of course would be a custom timezone for that exact location. reply sfilmeyer 2 hours agorootparentThis article that I just came across does a nice job at explaining some of the nuances of solar noon https://www.timeanddate.com/astronomy/solar-noon.html . The time of year does matter a bit, but the effect is smaller than the effect of timezones. Their equation of time article includes a nice graph of the variations in time of solar noon at Greenwich. https://www.timeanddate.com/astronomy/equation-of-time.html reply Izkata 2 hours agorootparent> This article that I just came across does a nice job at explaining some of the nuances of solar noon https://www.timeanddate.com/astronomy/solar-noon.html . And a related thing, the analemma - the sun's position at the same place on earth at solar noon over the course of a year doesn't resemble an arc, it's a figure-8: https://en.wikipedia.org/wiki/Analemma reply lovecg 14 hours agoparentprevMany parts of the world move forwards and back a full _hour_ every year. We complain about it but it’s mostly ignored. A gradual drift of a couple of minutes is fine. reply aezart 11 hours agorootparentI work in Arizona, and some of our software calls APIs on a server hosted in California. The California server expects timestamps in requests to be in Pacific time, with no timezone in the timestamp, and expects them to conform to daylight savings rules. This gets very hard to reason about because Arizona doesn't _do_ daylight savings. Like, what happens when we request 24 hours of data from them, on the day daylight savings time flips over? Do we want midnight-to-midnight data, or do we actually want 24 hours of data, which might wind up timestamped differently since there's a duplicate 2AM one day and a missing 2AM another day. A few years ago we had a contractor write some extremely messy code to handle cases like that, and soon it's going to be my job to try and refactor it into something readable. reply Mountain_Skies 8 hours agorootparentIt's surprising how many vendors of security product refuse to use UTC for timestamps and insist on using the local time of their bay area data center. The number of edge cases that arise from DST issues that are significantly reduced, if not completely eliminated, by using UTC should be reason enough for security product vendors to see it as a core best practice. reply swores 7 hours agorootparentI'm amazed to hear anyone doesn't use UTC, I'm not a professional developer and I remember learning, just while teaching myself the basics of PHP & MySQL as a teenager, that it's best to have databases store either UTC or a Unix timestamp (which afaik is essentially the same as using UTC except that it's less easy for most people to read at a glance) and to do the conversion to any local time zone wherever users interact with it. reply mypalmike 1 minute agorootparentThe most amazing of these exceptions is Microsoft Windows 11, which still uses local time on the hardware clock, a legacy of decisions made over 40 years ago. Raymond Chen defended this practice (20 years ago) https://devblogs.microsoft.com/oldnewthing/20040902-00/?p=37... . It's possible to make it use UTC, but it requires registry hacking. josephg 5 hours agorootparentprevI have a rule of thumb that software works progressively worse the further you are away from the Bay Area - both geographically and culturally. For example, we use roundabouts (traffic circles) everywhere here in Australia and google maps still gives pretty terrible directions when driving on them. I was shocked the first time I drove on the 101 just how good the spoken directions are - but it makes sense given the actual Google maps engineers drive that road. If the directions were bad there, they would get fixed. I shudder to think how many bugs must show up for people who use right-to-left languages or use non-ascii charsets - especially before Unicode & emoji were popular. I’m ashamed to admit I don’t even know how to test if my software works properly in languages like Arabic. Of course software made in the Bay Area assumes the whole planet uses pacific time. I’m sorry to throw shade, but that’s entirely in character for the area. reply echelon 1 hour agorootparent> I have a rule of thumb that software works progressively worse the further you are away from the Bay Area - both geographically and culturally. It's not just software. EVs struggle with cold and hot climates. They'll get better, of course. But with the engineers living in mostly temperate climates, conditions outside the development environment get less upfront attention. reply oasisbob 2 hours agorootparentprevThe two worst offenders I can think of with regards to using local time were Rackspace, and Southwest Airlines. Not in the Bay Area, but every other west-coast company I've been involved with is pretty militant about using UTC, typically due battle wounds from communication challenges or time-related bugs. I would be very curious to hear which other major companies are deploying systems on local time in 2024. reply fragmede 2 hours agorootparentGoogle runs on Google Standard Time which is UTC+8 aka US west coast. reply Izkata 1 hour agorootparentprev> either UTC or a Unix timestamp (which afaik is essentially the same as using UTC except that it's less easy for most people to read at a glance) UTC has leap seconds, unix timestamp doesn't. It's defined to have 86400 seconds per day, so there's no place to put a leap second. Instead, it either duplicates a timestamp or does \"leap smearing\" - slightly changing the duration of a second around where the leap second is. reply AnotherGoodName 1 hour agorootparentThey both skip over leap seconds unlike TAI time, they just handle the leap second subtly differently. He’s right to say it’s essentially the same. reply galangalalgol 7 hours agorootparentprevWhy would anyone choose to use local time for anything other than display? That just seems way harder even if you don't have customers from other timezones. reply skissane 6 hours agorootparent> Why would anyone choose to use local time for anything other than display? You need to store it for certain applications, e.g. timetabling. if school starts at 9am, it starts at 9am local time, and if local time changes (DST, or more rarely a change in the time zone rules) then school start time runs with it. Or similarly, if a commuter train timetable has it stopping at a certain station at 7.05am, that’ll be local time in the local time zone. reply josephg 4 hours agorootparentI arrived 1 hour late to an online meeting once in which I was scheduled to give a talk. The root cause was this: I (in Australia) was subscribed to the event calendar. The event was actually a reoccurring event at the same time every month in UTC time. But day or so before the event happened, daylight savings changed in LA - which for some reason was the time zone the calendar was set to. As a result, the meeting in my local Australian time drifted by an hour. Unfortunately, only some people used the online calendar. So many people (including the organisers) showed up on time. Time zones are a curse on humanity. reply chasd00 3 hours agorootparentAre you saying the calendar was set the \"DT\" (daylight savings time) and not \"ST\" (standard time) so when it actually flipped the calendar adjusted 1 hour in the wrong direction? heh, yeah that would be very frustrating, glad it wasn't like a final exam (for students) or an oral presentation in front of a client (for consultants/professionals). edit: not trivializing missing the talk, i would be pissed. reply skissane 23 minutes agorootparentDST is in opposite halves of the year in different hemispheres, and also the transition dates will be different in different DST-using countries even in the same hemisphere. So the timezone difference between US and Australia (or at least their DST using parts, since in both countries some states don’t observe DST) is 2 hours more in one half of the year than the other. And it changes four times. In January, Australia has DST and US doesn’t. Then in March US starts DST and moves one hour away. In April, Australia ends DST and moves another hour away (in the opposite direction). In October, Australia starts DST and moves an hour closer to US. In November, US ends DST and moves another hour closer to Australia. reply delecti 4 hours agorootparentprevTime zones are totally fine. They're unreasonably hard to do math with (ahead/behind +/- just refuses to stick in my brain), but they massively simplify life most of time they come up. The thing that's a curse on humanity is daylight saving time. reply Akronymus 2 hours agorootparentI really hate when someone writes a time + dst/pst/cet/whatever, rather than using utc, or even at least adding the utc time additionally. reply skissane 10 minutes agorootparentYeah, timezone abbreviations are problematic because how am I suppose to remember what time zone offset “EST” is? Here in Australia, we have “EST” too, but ours is UTC+10 not UTC-I forget digging 3 hours agorootparentprev> they massively simplify life most of time they come up. I have coworkers and friends in different timezones, and timezones do literally nothing but complicate coordination. Even if it's a small friction, they are 100% friction. As far as I can tell, the main benefit of timezones is that it allows people within the same timezone to converse as if timezones don't exist. Which would also be the case if timezones didn't exist. reply delecti 2 hours agorootparentHistorically speaking, the alternative to time zones is not one unified time, it's thousands or millions of time bubbles for each town's solar noon. reply digging 2 hours agorootparentYes, but we're not speaking historically. reply afiori 5 hours agorootparentprevbut school starts at 9am the nth of september not 2024-09-15 09:00:00 reply skissane 30 minutes agorootparentI know a bit about the computer system at our children’s school. I only have access to the parent portal, but that’s enough to give me some idea how it actually handles things. Plus I used to work for a university, and I got a good look at the internals of its system - and timetabling isn’t fundamentally different between primary/secondary and tertiary, just it gets more complicated as you move up. So, to answer what I think you are saying - normally you divide the day into chunks (“periods”). At our children’s school, it is primary, there are only two notional periods a day (morning and afternoon), when our son goes to secondary school next year (which appears to use the same software) there will be several periods a day, one per a subject. Anyway, in the system, a period is a class, not just in the academic sense, but also in the OO sense, and as such it has instances - “morning period” starts at 8.35 am local time any day the school is open. So that start time would be stored without a date, just a time plus time zone. But then, there is an instance of “morning period” every one of those days, which starts at a particular instant in time - today it starts at 2024-07-04T08:35+10:00. And yes, you could store that just in UTC, and convert to the school’s local time on display. I suppose there are three main data types you really need: (1) date without time (2) local time in specific timezone (3) UTC. For (1), whether you need the timezone or not depends on the use case. For stuff like dates of births, you generally won’t know and don’t really need to know the timezone in which they were born. But, for other applications, it becomes important, since Wednesday afternoon in the Americas is Thursday morning in Oceania and eastern Asia, so whether it is Wednesday or Thursday depends on your timezone. People expect days to start and end at local midnight, not UTC midnight - which for me is 10 or 11 o’clock in the morning. reply dspillett 3 hours agorootparentprevIf your application's use is local enough that more than one timezone isn't a concern, and doesn't much (or at all) care for things that span overnight, so you don't have to worry about adding/dropping an hour to the length of things when some sort of DST event happens, just using local time across the board is simply easier. Of course as soon as one of those assumptions is not 100% true, using UTC internally and local time for display is usually by far the better option (though there can still be difficulties there – time is never as easy as you'd think it should be). The trouble comes when people use to working local only (timezone wise) slap together a PoC of something that might need timezone awareness, and don't fix the deficiency at any point as they progress through PoC->prototype->alpha->beta->v1. The longer you leave the change the harder it is to do, and it not being easy is why once something nominally reaches V1 (or often at first alpha release) such a fix is seldom ever made. Timezone awareness has improved massively in recent years though. I think some cloud providers have accidentally helped there by defaulting to UTC (for instance all AzureSQL DBs default to UTC for everything, as do VMs and other things in Azure). Though here in the UK minor issues due to bad assumptions are still common when we transition back or forth between GMT and BST. reply outworlder 1 hour agorootparentYeah, and even if those assumptions are perfectly fine today, they are unlikely stay that way. When they do, going back and fixing everything else is a massive pain. Even ensuring everything is in localtime can be a pain; someone decides to add a database you didn't have before and didn't pay enough attention to its configuration? Too many landmines. The way to avoid this pain is to just use UTC on day one, regardless of requirements. Hard and fast rule that everything needs to be UTC. Need to display it? Converting to local time is trivial. Same thing for text. Use Unicode unless otherwise specified. reply mafuy 7 hours agorootparentprevYup. The only exception I could think of are prearranged local times, e.g. the meeting will be on -future day- at -local time-. In that case, if, say, the time zone changes, the meeting would still be at the same local time and not move. reply jiehong 5 hours agorootparentTrue, but also for the past, actually. Because DST might be a thing right now in that zone, but may no longer be next year, in which case the historical DST is needed to refer to times in the past. Same for dates a bit further back when countries changed calendars and some days are missing. So, we basically need a mapping of UTC -> local time as a function of time, and store this forever. (For durations, we might need to have a mapping from TAI to UTC as a function of time, because a leap second messes with duration length. Smeared leap seconds are even worse in that regard) reply naniwaduni 11 hours agorootparentprevAbout half of the world would 15+ minutes away from sun directly overhead at noon if hour-aligned time zones worked correctly, leapseconds are \"solving\" a \"problem\" at a level of precision wildly at odds with actual usage. reply input_sh 11 hours agorootparentprevIt's not that many parts of the world. DST is a very western \"problem\" that most of South and Central America, Africa and Asia simply don't have to deal with. We're the exception, not the rule. reply outworlder 1 hour agorootparentFunny that you only consider North America as 'western'. Brazil, the largest country in South America, had DST until very recently (2019). A large chunk of South America observed DST at some point. Some stopped in the 90s, others stopped much more recently. reply HeatrayEnjoyer 10 hours agorootparentprevThe sun is everywhere. Time zones (and the reasons that spawned them) after everywhere. Why would they be magically free of it? reply mzl 9 hours agorootparentDaylight savings time is not in a majority of countries. See the map on Wikipedia: https://en.wikipedia.org/wiki/Daylight_saving_time reply bergen 7 hours agorootparentprevEven besides daylight savings time, timezones exist. England and Spain are on a vertical axis, yet the timezone differs by 1 hour. Cross the border from spain to portugal and time jumps a full hour, so there are people living 100 Meters apart with 1 hour time difference. reply shagie 4 hours agorootparentTimezones are political and economic statements (and sometimes even religious - https://github.com/eggert/tz/blob/main/africa#L853 ). Things like China being all one timezone or India changing to IST after declaring independence https://en.wikipedia.org/wiki/Time_in_India#After_independen... . An example of an economic change was https://en.wikipedia.org/wiki/International_Date_Line#Easter... Trying to make sense of them as purely time keeping artifacts is bound to have misunderstandings. reply teruakohatu 14 hours agorootparentprevIts not quite the same problem. Timezones are a transformation applied on top of UTC. If you are writing code, you are transforming the always increasing UTC to a more or less arbitrary dates and times. Moving backwards means you (your code) experiences the same time twice. reply lifthrasiir 14 hours agorootparentIt is not exactly same, but it can be framed as the same problem by requiring every nation to change their own time zone once in a while. As long as the \"once in a while\" is not frequent (unlikely to happen before 2500, and should happen less than once per century for next 10K years), this should be okay. reply ffsm8 14 hours agorootparentprevKeep in mind that the earth is round and timezones switch an hour by area, so there is always some drift between the suns position and midday. So from my point of view, they were spot on reply jpitz 5 hours agorootparentYou might be surprised to learn that there are time zones that are not an integer number of hours different from UTC. reply ffsm8 4 hours agorootparentI'm always open to change my mind, but I struggle to see the relevance of that in this context. Are there timezone areas in the world which change their UTC differential fluidly throughout the year and by the yard to pin midday to the highest position of the sun? I'll definitely say that that'd not only surprise me but blow my mind if true! If there isn't ... Then what was your point? reply jpitz 2 minutes agorootparentYou claimed that timezones change an hour by area. That's not the case. That's my point. GuB-42 11 hours agoparentprevAlso, very few people today have the sun directly over their head at noon. If you don't live at the prime meridian, it is an abstract concept. And even if you do, there may be DST. In some countries, you can be hours off. Few people actually care about the precise earth rotation, and there are time bases for these people that are better than UTC anyways. Sunrise and sunset are important, but the middle of the day, not so much. reply plesner 12 hours agoparentprevIt makes a lot of sense to not care about a slight amount of drift. But that already exists: that's what TAI is. Why make UTC into another TAI just slightly offset? Why not just switch to TAI? Or, if the 37 second difference between UTC and TAI is the problem they can make a new TAI-minus-37. What makes no sense is taking something useful, UTC, and redefining it out of existence. Then what time do you use if you really do care about drift? Do we invent a new UTC? reply modeless 12 hours agorootparent> Why not just switch to TAI? That would be great. > Then what time do you use if you really do care about drift? Nobody uses UTC because they want to know where the Sun is to the nearest second. People who actually need to care about variations in the Earth's rotation speed (e.g. astronomers) already need far fancier stuff than just UTC. People use UTC because someone else made a mistake and decided they should use UTC, like a government standard, or an operating system vendor, or whatever. Unfortunately the best way to correct all those millions of mistakes is to redefine UTC rather than convince everyone in the world to simultaneously switch to TAI. > taking something useful, UTC, and redefining it out of existence I question that UTC is useful. What utility does it have over TAI, outside of interoperability with other people who are using UTC? Again, anyone who actually needs to care about Earth rotation speed changes already needs to use something better than plain UTC, and my argument in my original comment is that drift that is small on a scale of a human lifetime is not an actual problem for anyone alive today or in the future. reply weberer 10 hours agorootparent>That would be great. Well whats stopping you? reply modeless 10 hours agorootparent> interoperability with other people who are using UTC reply zokier 1 hour agorootparentprev> Why not just switch to TAI? Getting the world to switch timescales is orders of magnitude more difficult that redefining currently used timescale. The latter can be done in the BIPM backrooms by small committee, the former needs action and agreement from pretty much everyone. reply thayne 2 hours agoprev> You've reached a situation where campaigning for the whole world to change the way it measures time is simpler than fixing your code? It isn't just a code problem. Since leap seconds aren't predictable, you have to somehow distribute information about new leap seconds to everything, which is especially difficult for devices that aren't connected to the Internet. And as the article mentioned, there are multiple ways to deal with leap seconds, and there are tradeoffs involved in choosing which one, and depending on the circumstance different ways. And since different methods work best in different situations, that can result in inconsistencies between different systems. reply 1-more 2 hours agoprevI gotta say I like this QNTM cat. Wrote Hatetris, \"There Is No Antimemetics Division,\" and Absurdle. A fun explorer of adversarial computing environments. Pretty interesting reply pfraze 1 hour agoparentMy team is kind of a miniature qntm fan club. We include copies of antimemetics as a new employee gift. reply ralferoo 9 hours agoprevI don't even see the need for leap seconds at all (in either direction). Why should anyone care? All times are relative to some arbitrary fixed point in time anyway, so why are we so hung up on maintaining the status quo? Aside from the fact that just by ignoring the problem it'll probably go away - we've just had a period of adding a load of leap seconds to roughly compensating for the Earth rotating \"too slowly\" overall, which for a system that's inherently irregular and actually speeds up and slows down all the time, and just happens to have been \"too slowly\" ON AVERAGE. It now seems hat the rotation speed, on average, is \"too fast\" and now we need to undo some of that adjustment. If we'd just left it alone, it'd have been fine. And for all the hassle these leap seconds cause, what exactly has been the benefit? Since 1972, we've had 27 seconds added. 27 WHOLE SECONDS. That would have made absolutely no difference to anybody's life if the sunrise and sunset was 27 seconds later. Just think, in 100 years, when your great grandchildren are enjoying their life, we might be a whole minute wrong. And if you went the other direction, back as far as all of recorded human history, and we might be out by an hour. Many of us are routinely forced to have our clocks out by an hour for \"daylight savings time\" every year anyway. For the very few cases where it might be useful to know the ACTUAL difference between the rotation and alignment of an abritrary fixed point on earth and an arbitrary fixed point on the sub, then THEY can use they own clock for that specialised purpose. And maintain a fixed adjustment to the atomic clock based time that everyone else uses, and they don't even have to round to a whole second for that - they can say NASA time is TAI+1.234s for instance and the only people who need know or care is NASA themselves. reply layer8 2 hours agoparentA significant number of systems related to Earth’s rotation (like navigational systems) rely on the difference between UT1 and broadcast UTC to be less than 1 second. If UTC were to change to a constant offset to UT1, those systems would need to be provisioned in an alternative manner to receive a time signal with the same guarantee. Basically, we would still need what is now broadcast as UTC, just under a different name. And if we have that, we might just as well keep civil time synchronized to it. > Since 1972, we've had 27 seconds added. 27 WHOLE SECONDS. That would have made absolutely no difference to anybody's life if the sunrise and sunset was 27 seconds later. The delta increases quadratically though due to Earth’s rotation slowing down in the long term, so the problem will only get more severe. reply zokier 1 hour agorootparent> A significant number of systems related to Earth’s rotation (like navigational systems) rely on the difference between UT1 and broadcast UTC to be less than 1 second. Can you name some of these systems? reply Mountain_Skies 9 hours agoparentprevFor most civil purposes, it really doesn't matter but we're techies and it's in our nature to obsess over details like this, often to the determent of ourselves and the systems we're trying to maintain. It appears many of those with the most influence over setting the example for such things in the civil realm have indeed discovered the leap second is far more trouble than it is worth and now it is falling out of favor. For astronomical, aeronautical and other scientific purposes, they'll continue to deal with the hassles, but for the rest of us, it appears the era of leap seconds is slowly drawing to a close. reply zarzavat 7 hours agorootparentLeap seconds are both unnecessary and useless at solving the problem they are intended to solve. If you care about the position of the sun to second precision, then time alone tells you nothing - you need location too. Ironically, most people get their location these days using GPS which is based on TAI, not UTC with leap seconds. If you don’t care about the position of the sun to second precision then leap seconds are a nuisance. There’s zero reason to have leap seconds in the definition of time. It should be a database, like tz, that software that wants Earth rotation updates for calculation of sun position can download and incorporate into its calculations for increased accuracy. The fundamental problem with leap seconds is that you can’t predict what the leap second delta between UTC (legal time) and TAI (absolute time) will be in the future. That’s unacceptable, I should be able to know how many seconds there are between 1 July 2024 and 1 July 2026 without needing to wait for a Time Lord to determine it. reply zokier 1 hour agorootparent> If you care about the position of the sun to second precision, then time alone tells you nothing - you need location too Unless you are using time and (celestial) observations to determine your location. It's not coincidence that US Naval Observatory (and its peers) is one of the key origins of UTC. reply ralferoo 6 hours agorootparentprev> without needing to wait for a Time Lord to determine it. They're not to blame - Davros is responsible for the leap seconds. reply umanwizard 7 hours agorootparentprev> but we're techies and it's in our nature to obsess over details like this Speak for yourself! Part of good engineering is knowing when over-engineered perfection is useless. The inventors of UTC/leap seconds did not, and made a serious mistake the rest of us have had to live with. reply theptip 15 hours agoprevRiffing on “if it’s painful, do it more often”, I wonder if mandatory leap seconds every year, but trueing up the delta from N years ago, would be a good compromise? Regularity makes it easier to plan, and 6 months’ notice is not really enough for many OS distribution paths (eg IoT, embedded). Since the list of delta updates is queued, you could bake N years of updates into your system if it’s a fire-and-forget OS. A number in between 5 and 10 seems reasonable to me, but seeing as we are discussing living with 50 years of drift it could be higher. And sure, for this to work, allow non-integer deltas again; or just have a rule that you round the applied adjustment down. Seems no harder to bake in the last 50 years of leap seconds as to include to Olson TZ database in your distro. reply ncruces 2 hours agoparentIf you go with that, just move it in the correct direction every year, regardless if you make the absolute delta bigger (you'll fix it in a year by going backwards). If this is not enough to ping-pong around the correct result, because you're drifting too fast, just increase the rate of changes, now that the system is well oiled. That said, we should not have leap seconds, just timezones around TAI. If UTC wants to be a timezone that changes every six months with a second offset, so be it. Bureaucratic systems are already in place to solve that. reply lifthrasiir 14 hours agoparentprevThat's actually a good idea in the short term (i.e. less than one century). The length of the day (LOD) is thought to be linearly increasing in the long term though, so ΔT, the cumulative difference between past SI days and actual LOD, should be quadratically increasing and a delayed leap second adjustment would be too slow to catch up at some point in the future. Yet another possibility is to put any possible kind of leap second at the beginning of the year. The only requirement set by past CGPMs is that dUTC = UT1 - UTC should be in [-0.9, +0.9] seconds, so we can always put a positive leap second when dUTC is in [-0.9, -0.1]s and a negative leap second when dUTC is in [+0.1, +0.9]s, dramatically increasing the number of leap seconds without violating the dUTC requirement. If the dUTC requirement is a bit more relaxed (say, [-2, +2] seconds) then we can even mandate leap second every year! But well no, I'm strongly against the current form of leap seconds because it is already problematic in the short term and will be yet useless in the long term. Recall that ΔT is expected to be quadratically increasing in the long term; this means that the effectiveness of leap seconds is limited to the point when any small fixed number of leap seconds per year (12 in the current system, but anything larger than 1 will cause a problem) is no longer sufficient, and that point is not far from the point where the magnitude of ΔT is significantly large and leap seconds are absolutely required. As DST demonstrates, the world is probably fine with ~2,000 seconds of ΔT, which wouldn't happen before 2500, but at that point we would already start using double leap seconds per year at average. We would probably abolish leap seconds for that reason alone. reply ooterness 15 hours agoprevI have never understood why POSIX and NTP timescales work the way they do. They are positively bonkers when it comes to leap seconds. Time isn't even monotonic during the transition, because the epoch itself is redefined. Contrast this with the GPS or PTP timescales, which simply count seconds since a well-defined epoch. Formatting the date and time for humans to read is a sensibly separate process. reply tverbeure 14 hours agoparentBut then GPS went off the rails and used a 10-bit number for count weeks, resulting in the 19-year week number roll-over (WNRO) problem. A few bits more would have solved a lot of problems.. Ref: https://en.wikipedia.org/wiki/GPS_week_number_rollover reply cbhl 13 hours agorootparentGiven that the first GPS satellites were launched in 1978, saving a few bits was standard practice at the time -- bits were expensive. Code of the time also often had two-digit years (the infamous Y2K problem). reply tverbeure 13 hours agorootparentA full GPS navigation message is 37500 bits. I'll admit that it's not that simple: there are repeating fields in that message to avoid having to 12.5 minutes between each update. They could have kept the week number in the repeating message at 10 bits while having a non-repeating MSB? reply akira2501 9 hours agorootparentIt's 1500. The full data set is 37500 but you get there by spreading the larger message across several subframes. The full data set includes ephemeris data for all other satellites. It's precisely as long as it needs to be. This also means there is a built in fixed maximum number of satellites in constellation. The time code gets 300 bits. It lasts 6 seconds and it's repeated every 30 seconds. Critically, it will always occur precisely on the top (:00 seconds) of the minute, or the bottom (:30 seconds) of the minute. Interestingly, most of the time code is used for /correction/ parameters, as precise values for these are required to accurately calculate time. Satellites themselves drift in performance as they age so these parameters are not static for the lifetime of the deployment. If you want to get into the nitty gritty, again, made in the 70s, so it's pretty approachable today: https://www.gps.gov/technical/ps/1995-SPS-signal-specificati... reply tverbeure 3 hours agorootparentThe full 37500 bits data is set is called “GPS Navigation Message”, or at least that’s what the ESA website call it. (https://gssc.esa.int/navipedia/index.php/GPS_Navigation_Mess...) And, yes, I understand that time message gets sent at a much higher rate, hence the “it’s not that simple” part. But I still have a hard time to believe that it would have been impossible to find 2 or 3 bits in the overall message to include the MSBs for the weeks. GPS units with built-in support for WNRO (due to permanent storage) would be able to ignore it, other units would be able to correct the epoch after 12 minutes (or a multiple in case of data corruption.) reply zokier 1 hour agoparentprev> I have never understood why POSIX and NTP timescales work the way they do. Posix committee thought it would be very convenient if you can get time of day by doing time()%86400. Very convenient indeed... reply mcculley 7 hours agoprevMaybe there should be an analog of the Kardashev scale for civilizations capable of adjusting the rotation speed of their planet in order to make timekeeping easier. reply gmiller123456 2 hours agoprevDoes anyone have an actual example where leap seconds are a problem? Specifically one that can't be solved simply by using Atomic Time? Maybe then we can figure out what the problem we're trying to solve is. Few people or systems even interact with a clock that is precise enough to detect the difference, and instead rely on clocks that are 100's or even 1000's of times less accurate than what would be required to even detect a leap second. And these clocks undergo thousands of corrections between leap seconds without a complaint. We add an entire day to the calendar about every 4 years. It's not a problem because everyone is aware of it. So I think the only real thing that needs to change about leap seconds is awareness of them. Leap seconds are needed in civil time because people's schedules are still dominated by the Sun. Not to the second, maybe not even to the hour. But the leap second was chosen because it's large enough to be infrequent, and tiny enough that only a tiny fraction of systems will notice. reply SonicScrub 2 hours agoparentLeap seconds are a problem because I have to deal with existing systems that use leap seconds and those that do not. Getting those systems in sync can be pain sometimes because of conversion from one format to another. Is it insurmountable? No. Is it annoying? Yes. Does it occasionally cause bugs that waste time and resources? Absolutely. I'd love to snap my fingers and make everyone use TAI, but unfortunately I'm stuck with UTC, GPS and TAI depending on sources. reply aidenn0 1 hour agoparentprev> Does anyone have an actual example where leap seconds are a problem? Specifically one that can't be solved simply by using Atomic Time? Maybe then we can figure out what the problem we're trying to solve is. Any time that is supposed to represent both a wall-clock time has to deal with it. There is currently no known answer to the question \"What is the interval between the unix time stamps @1720026000 and @182002600\" However, there is a well defined answer to \"What is the UTC time for @182002600\" and thus also \"what is the local time in a timezone with UTC offset X for @182002600\" If we were to redefine Unix time to use Atomic Time, then we could answer the first question but not the second. > We add an entire day to the calendar about every 4 years. It's not a problem because everyone is aware of it. So I think the only real thing that needs to change about leap seconds is awareness of them. It's not just \"about every 4 years\" it's precisely \"every 4 years, except for centuries, except for quad-centuries.\" If you give me any year, I can tell you if it will be a leap year. I can program a non-internet connected device and it will get leap years right indefinitely. Leap seconds are not predictable, but rather determined empirically and announced about 6 months ahead of time. Any device that wants to properly account for them needs to be updated at least every 6 months to be correct. reply nitwit005 1 hour agoparentprev> Leap seconds are needed in civil time because people's schedules are still dominated by the Sun. Not to the second, maybe not even to the hour. Sometimes multiple hours off. China has a single time zone. As far as I can tell, people care very little about the clocks being in sync with the sun. We've effectively run massive experiments demonstrating this. reply AnotherGoodName 2 hours agoparentprevYes if you use atomic time you won’t encounter these issues. Unixtime made a blunder of incorporating the leap seconds all those years ago so it’s not atomic hence the issue. Now you might think it’s crazy that Unix time incorporated non-atomic leap seconds when it doesn’t incorporate any other part of the local sun relative position in its counter and you’d be 100% right in that. Leap seconds absolutely belong in the local time printing functions and nowhere else. But the blunder was made and now computers by default don’t have atomic time and here we are. reply samplatt 15 hours agoprevqntm, I know you're reading this. As someone working on software that works on ships (aka, software that needs to change timezones and locations often and still maintain contiguous millisecond accuracy of all shipboard equipment events), this article has caused me significant psychological damage. There Is No AntiTimekeeping Division ... reply pas 8 hours agoparent> still maintain contiguous millisecond accuracy of all shipboard equipment events can you elaborate on the purpose of this? is it for legal requirements? some kind of \"black box\" recorder? why does timezone matter for such low-level event data? reply xg15 1 hour agoprevIf the IERS ever announces a negative leap second, they should do it like this: https://m.youtube.com/watch?v=fr1li5NaltA reply hirsin 16 hours agoprevI feel like we'll get a (less physically _real_, but much more impactful) run of this \"make it to the next day unscathed\" adventure in 2038. Only 14 short years... reply rswail 11 hours agoprevOr we could adopt the \"smearing\" technique in either direction and we could do it hourly or daily or weekly or monthly or half-yearly or whatever interval as agreed. Maybe we should do it every 6 months no matter what. That way, everyone would know that on June 30 and December 31, there would be smeared seconds. That makes the \"do it rarely and people will screw it up\" problem go away. reply gpvos 4 hours agoprevThe solution is obviously to have a leap second every half year, even when the difference with solar time is too small. Just alternative positive and negative leap seconds, and for additional fun, don't have a leap second when the difference with solar has shifted (in the right direction; it should be possible to keep the difference less than 1.5 second, probably much less). We could even do this every month, just to make sure there's enough testing opportunity. reply ikekkdcjkfke 14 hours agoprevIf I am asking for how many seconds since 1970, I'm literally asking for that, as if someone stood with a stopwatch (not a cellphone clock!) How you want to display that in various timezones i do not care reply zokier 12 hours agoparentUTC doesn't stop us from having that, UTC seconds tick at SI rate. The thing that makes UTC special is that minutes might have 59-61 seconds each. But if you have stopwatch just counting seconds then leap seconds do not make any difference at all, and UTC and TAI are effectively the same. reply afiori 8 hours agorootparentUTC and TAI are offset by a variable number of seconds reply zokier 2 hours agorootparentWhich doesn't impact a stopwatch in any way. reply kuschku 11 hours agorootparentprevThen why does unix time not include the leap seconds? reply zokier 2 hours agorootparentBecause POSIX committee thought it would make things easier for userland. It didn't; it did make things harder, much harder, for userland and everything else. People make mistakes. reply kuschku 1 hour agorootparentAhh, so if I used an old unix mainframe, it'd count leap seconds differently? reply xelxebar 8 hours agoparentprevYou speak of time as if it's some directly measurable quantity. Instead, all we have are periodic quantities of various (messy) physical processes or sampling methods thereof relative to certain underlying models: - _TAI_: Sampled average of ticks in the (very noninertial) frame of the surface an implicitly-defined idealized rigid Earth. Each tick is further a sampled approximation of our definition of a second, which invokes idealizations at absolute zero. - _UT1_: Mostly the same frame as TAI. Each tick is considered a sample, trying to measure the \"true rotation\" of some idealized rigid Earth, module any geophysics. Note, the definition invokes quite sophisticated models of celestial mechanics, and explicitly ignores certain kinds of \"high frequency perturbations\". - _UTC_: Based on UT1, but take into account some basic, empirically-measured geophysical processes. Depending on the particular physical processes, models, and sampling methods you choose, the quantity you get for \"seconds since 1970\" will be different, and there will be (complicated) relationships for how each of those processes transform tick counts between each other. In some cases, the transformations will be a priori impossible, only permitting approximations under simplifying assumptions. IMO, the remarkable thing is that the various ticks all line up as well as they do, which is why we can mostly get away with treating all these as a single unified Ticking Time concept. On the other hand, I also think the various standards do a reasonable job delineating messy reality into potentially useful tick-producing processes and the systems needed to make those practically useful. As a software engineer, the lesson for me is that I can't always ask \"what time is it?\", \"how long has it been?\", or \"which came first?\" Instead, we I may need to shift focus onto different invariants in the problem I'm trying to solve. reply afiori 8 hours agorootparent> As a software engineer, the lesson for me is that I can't always ask \"what time is it?\", \"how long has it been?\", or \"which came first?\" If we were using TAI instead of UTC we very easily could. reply xelxebar 7 hours agorootparentReally? TAI cannot locate historical dates indefinitely. TAI doesn't even make sense on timescales that exceed Earth's lifetime. It doesn't encode enough information to answer questions about elapsed time of even ideal clocks at real, physical locations to arbitrary precision. Fast enough operations on a distributed database can exceed the precision limits of TAI's definition, making it impossible to canonically order events. reply afiori 5 hours agorootparent> Fast enough operations on a distributed database can exceed the precision limits of TAI's definition, making it impossible to canonically order events. The TAI would be a sincronization target, just like UTC. Any device can have its own high precision clock and periodically sinchronize with other clocks (just like NTP does) which to my knowledge is how most distributed systems work > TAI doesn't even make sense on timescales that exceed Earth's lifetime I disagree, 10^100 seconds in the future is perfectly valid time in any time system > It doesn't encode enough information to answer questions about elapsed time of even ideal clocks at real, physical locations to arbitrary precision. Those clocks would use the TAI to avoid drifting from each other. reply Hizonner 4 hours agorootparent> I disagree, 10^100 seconds in the future is perfectly valid time in any time system Professor Einstein would like a word... reply krisoft 8 hours agorootparentprev> You speak of time as if it's some directly measurable quantity. They do not. > Depending on the particular physical processes They have chosen their particular physical process: \"as if someone stood with a stopwatch\" reply xelxebar 6 hours agorootparent> They have chosen their particular physical process: \"as if someone stood with a stopwatch\" It's not well-enough defined for all purposes. Where is that person standing? Earth's surface is shifting and moving all over the place willy-nilly, so how do you define that particular location in the first place? Over what timescales is that definition valid? What physical process do you mean by stopwatch? What particular synchronization protocols do you define? What physical models do your definitions invoke? Answers to these kind of questions will generally generate mutually-disagreeing time standards. I mean, with suitable transformation rules, they'll often agree up to some precision limit, but if you need anything beyond that, you've now gotta choose the one(s) that best correlate with the natural ticks in your problem domain. Also, any standard like \"someone standing with a stopwatch\" is forced to just a fiat declare the stopwatch as the Definition of Time, a la the platinum sphere kilogram. We all know how great that was. Do you now want a team of canonical stopwatches and some aggregation process? How do you deal with measurable drift between the tick rates? reply defrost 14 hours agoparentprevWhich specific stopwatch? Why don't you care about that stopwatch's drift over the past 50 years, the tempreture related variation, the errors induced by motion, air pressure and humidity? Would you prefer a count that's averaged over many from the same manufacturer, or from many over many manufacturers? reply saulpw 13 hours agorootparentA cesium stopwatch: https://en.wikipedia.org/wiki/Caesium_standard reply cobbal 13 hours agorootparentHow deep in a gravity well are you planning to keep this cesium stopwatch? reply Elucalidavah 12 hours agorootparentExactly at the point of Null Island at the epoch, of course. Or, in practice, as close an approximation as can be calculated by now. reply defrost 12 hours agorootparentFun reference, although in that spirit it appears that Null Island at mean sea level for that point might be as much as 22m vertical separation from true 1G Geoid. https://en.wikipedia.org/wiki/Geoid#/media/File:Geoid_undula... Approximations are pretty easy until you get into the details, dammit. reply defrost 12 hours agorootparentprevNot at all what was asked for; not available as a handheld stopwatch someone could stand with in 1970 ... and I'm doubtful there's such a thing available today. Works if you don't mind a lab bench full of equipment, but doesn't appear to match the specification of the request. Still, thanks for your input. reply wolfendin 12 hours agorootparentHandheld was never specified directly, just “stood with a” which can just mean “next to.” The HP 5061 was introduced in 1964, why do you think a counter that can reference the frequency standard is not possible? You might want to be more rigorous about reading specifications. reply defrost 11 hours agorootparentThe HP 5061 is not a handheld stopwatch, at best it's a counter top luggable. > why do you think a counter that can reference the frequency standard is not possible? How on earth did you strawman my thinking to reach that bogus conclusion? You might want to be more rigorous about reading comments and projecting. reply 01HNNWZ0MV43FF 14 hours agorootparentprevSwitch to TAI + fixed offset I just don't give a damn whether solar time is a couple minutes off of calendar time. Seconds should be seconds. Solar time is a human construct, it shouldn't affect computers. reply defrost 14 hours agorootparentThe person I responded to was interested in 50 years of seconds from a stopwatch. That's a mechanical device with multiple sources of error and a need to be wound regularly. The questions I asked are about common sources of drift in mechanical watches and wether or not they cared enough to attempt to account for them. reply withinboredom 11 hours agorootparentprevWhat is so special about thailand's timezone? reply kuschku 11 hours agorootparentTAI not as in thailand, but TAI as in temps atomique international: https://en.wikipedia.org/wiki/International_Atomic_Time reply withinboredom 11 hours agorootparentI just tried to get a time in the TAI timezone via my programming language and it doesn't exist. Not a very useful timezone. reply hansvm 8 hours agorootparentYou can wrap libtai in almost any language, and that's been done for the bigger ones. Which language are you using, and why is the conclusion not that the language is deficient? reply withinboredom 2 hours agorootparentMaybe it should be added to the OS instead of a library? Why would I use a library for a timezone? reply hansvm 1 hour agorootparentMaybe that's a fun new OS feature. If somebody wants to try it, more power to them. Answering your question more directly though, why would you want it in an OS? The OS primarily exists to mediate shared resources, and to a slightly lesser degree to sensibly wrap shared code everyone is definitely using (e.g., chrome and hacker news don't have to care about my LCD driver). What exactly do you gain by baking TAI into the OS? You lose in update availability, OS install size, application-specific customizability, runtime performance of TAI function calls, .... You'd want to gain something for those costs. > Why would I use a library for a timezone? Most people do? Even libc localization isn't a part of the OS (and is fraught with issues; never use libc localization), and that's the most primitive timezone library most people use. Everything else is baked into their language runtime or a third-party like nodatime. TAI isn't special in that regard. reply withinboredom 3 minutes agorootparentTime is very much a hardware concern (as is the time zone database an OS concern). zokier 1 hour agorootparentprevIt's not a timezone. reply withinboredom 3 minutes agorootparentAh, that makes sense. afiori 8 hours agorootparentprevthe TAI stopwatch, the earth surface is relativistally uniform enough that averaging good clocks gives a good enough clock for almost any practical purpose. reply t_mann 9 hours agoparentprevIn that case I suppose you'll need to find yourself a universe with different physics from ours... reply gavinhoward 4 hours agoprevJust make leap seconds first class. https://gavinhoward.com/2023/02/make-the-leap-second-first-c... reply afiori 3 hours agoprevAlmost nobody ever cares for UT1 except for astronomical observations (where you are also likely using a different calendar and using sidereal days) and we already have a perfectly working system for relating local times to each other and to UTC: timezones. The only things we should care about are local time (both as in clock time and in sun-position time) and universal timestamps to coordinate between local times and to use as canonical representations; leap seconds are useless or damaging to both of these. We already easily accept over 60 minutes of offset between clock time and sun-position time and I do not think that 3600 seconds can be ok but 3601 or 3599 cannot. It is also perfectly easy for a country to change its timezones or to adapt a non-whole-hour timezone (multiple countries have 15 or 30 minutes offsets) So my proposal is that the IERS never announces any leap anything ever again and in a few centuries some countries will shift their timezone by 15 or 30 minutes. This will be much more easily compatible with all current systems (we can right now create the timezone CETP and CETM for central European time plus 15 and minus 15) and in 400 years each at they leisure Europe/Berlin will be equivalent to CETM* (and CESTM if have failed to remove DST). No need to handle irregular minutes or hours, no fractional seconds offsets, no need to account for edge cases that are far too easy to ignore, just keep writing code that work with timezones (as you should already be doing) do not hardcode conversion between regional timezones (Europe/Berlin) and offsets (CET, CEST, CETM) as you should already be doing just updating your timezone tables (as you should already be doing as they change often). Just store one of: - UTC and timezone - dateless time with/without timezone - date with no time with/without timezone And you are ok, already prepared for the next few centuries of no leap seconds. * I don't know whether it would be CETM (that is +00:45) or CETP (+01:15). reply rblatz 16 hours agoprevSo my assumption was that Unix timestamps were monotonically increasing and that for the case of leap seconds the conversion from timestamp to UTC would take those into account and for some seconds have 2 mappings. That would keep the ordering of events, it would break assumptions like a day is 86400 seconds. But I guess they decided to keep that invariant, which makes negative leap seconds really hard. Maybe that’s a good trade off. reply kibwen 15 hours agoparentThe Rust standard library, which provides an API for monotonic timestamps, used to contain this silly hack (with appropriately exasperated comment) because in practice so many platforms and CPUs (Linux, Windows, BSD, x86, x64, Arm) failed to provide monotonicity despite their own documentation: https://github.com/rust-lang/rust/blob/80184183ba0a53aa4f491... reply zaptrem 14 hours agorootparent// It seems that this just happens a lot in the wild. // We're seeing panics across various platforms where consecutive calls // to `Instant::now`, such as via the `elapsed` function, are panicking // as they're going backwards. Placed here is a last-ditch effort to try // to fix things up. We keep a global \"latest now\" instance which is // returned instead of what the OS says if the OS goes backwards. // // To hopefully mitigate the impact of this, a few platforms are // excluded as \"these at least haven't gone backwards yet\". Why exclude any platforms, just in case they start going backwards for whatever reason? reply TheDong 14 hours agorootparentThey say right there, \"To hopefully mitigate the impact of this\". Having a mutex right there in the hot path of Instant::now is not great for performance. You expect getting monotonic time to be very fast generally, and some code is written with that assumption (i.e. tracing code measuring spans). reply zaptrem 14 hours agorootparentAh, that's fair. Didn't realize there was a significant performance impact. reply tialaramex 8 hours agorootparentEventually Rust just gave up. Here you go, here's your \"monotonically increasing clock\" courtesy of your operating system. It might go backwards, try asking your vendor to \"fix\" that and see if they laugh at you or just ignore you. Sometimes the OS is broken in a way Rust can fix, for example Rust's current std::sync::RwLock actually does what you wanted on Windows, the C++ std::shared_mutex doesn't. It's documented as working, but it doesn't because the OS is broken and the fix is just on their internal git \"next release\" branch, not in the Windows you or your customers are running. But sometimes you're just out of luck. Some minority or older operating systems can't do std::fs::remove_dir_all correctly, so, too bad you get the platform behaviour. It's probably fine, unless it isn't, in which case you should use a real OS. reply marcosdumay 15 hours agoparentprevUnix keeps the 86400 seconds as an invariant, and ignores the IS size of a second. This should work just fine for negative leap seconds too, you just make your seconds shorter instead of longer. Of course, it's a near certainty that it won't work just fine. But it should. reply zokier 11 hours agoparentprevI think history has proven it to be absymally bad tradeoff. If UNIX time were just actually true seconds since epoch counter then I think lot of leap second related hand wringing could have been avoided reply diego_sandoval 11 hours agoprevLeap seconds are an extremely Earth-centric concept. reply Ekaros 11 hours agoparentSometimes I have wondered is there proper write up of how messy intragalactic or intergalactic communications and time keeping would be. With or without FTL communication... Relativistic effects could actually be significant. Not to mention different rotation rates, day lengths, month lengths and so on... Leap seconds are comparatively simple problem... reply gpvos 4 hours agorootparentThey're considering creating a new time standard for the Moon. https://news.ycombinator.com/item?id=39916102 reply akira2501 8 hours agoparentprevYea, unfortunately, all of our really good telescopes are bolted to it. reply kibwen 6 hours agorootparentJWST lives in the Earth-Sun L2 point, so I suppose that's still technically true. reply amelius 10 hours agoprevYou need more than a negative leap second to get anytime close to Christmas, though. reply k310 18 hours agoprevThere is no mention of the affect this might have on investing or wagering. Or is the author keeping that close to the vest? reply techdragon 17 hours agoparentThey don’t care about that. I mean it’s the opening paragraph… > I just want to see it. Just once. I want to watch that earthquake ripple through all of global electronic timekeeping. I want to see which organisations make it to January morning with nothing on fire. reply uoaei 17 hours agorootparentSeems like a good dry run for redundancy/resiliency tests in the face of more catastrophic failures such as those that can result from solar storms. reply danpalmer 17 hours agoparentprevI agree with the author in finding some amusement in such trivial (in context) matters falling in the face of a phenomenon as fundamental as the planet's spin, something humans will likely never make a dent in. reply lovecg 15 hours agorootparentDon’t give them any ideas! If I know humans, they’re the kind of species to figure out how to extract energy from the Earth’s rotation, overdo it way too much, and then deny that they’re the ones responsible. reply maxbond 14 hours agorootparentSee also: > Tidal Energy Is Not Renewable > It is incorrect to consider tidal power as renewable energy. Harnessing tidal energy will pose more severe problems than using fossil fuels. ... Tides are induced by the rotation of the Earth with respect to the gravity of the Moon and Sun. The rotational energy of the Earth is naturally dissipated by tides slowly. Consuming tidal energy further reduces the rotational energy, accelerates the energy loss rate, and decelerates the rotation of the Earth. https://cs.stanford.edu/people/zjl/pdf/tide.pdf (I've not evaluated these claims in detail, I just thought you may be interested.) reply mtoner23 14 hours agorootparentIt's completely wrong. He assumes energy will increase exponentially into the future to get to his wild claim that we could tidally lock to the moon in 1000 years. Even solar power out nuclear could not power humanity in that scenario reply maxbond 13 hours agorootparentCertainly if we grow exponentially for a further 1000 years we'll exceed the carrying capacity of this planet, however we derive our energy. I don't think that's a very interesting result. By \"completely wrong\" do you contend that using tidal energy doesn't decelerate the Earth's rotation? reply rswail 11 hours agorootparentprevImagine what a Dyson sphere is going to do to the lunar orbit around Earth. reply maxglute 12 hours agoprevAlways facinated by how complex standardizing timekeeping is. If here was a chance for a global redo, would there be a more simplified system? reply akira2501 9 hours agoparentAlmost certainly not. The problem time keeping is meant to solve is coordination of physical movements between separated parties that have exceptionally limited and delayed communication capabilities. All of the time issues we deal with today are in service of keeping these important properties of our civil time in tact. In terms of computers we should happily ignore the problems of civil time, simply just use TAI, and use a provided database to convert this into \"human display time\" whenever necessary. reply umanwizard 6 hours agorootparentLeap seconds do absolutely nothing to fix the problems you’re talking about, for anyone. If we had never invented UTC and used TAI (+ time zone offsets) for civil time, the fact that civil time is drifting away from solar time on the order of a minute a century or so would at most be an obscure curiosity. reply knorker 11 hours agoprevNegative leap seconds seem like they shouldn't be much of a problem. At least they don't involve repeating a second. No queries came in during a whole second? Who cares? reply zokier 1 hour agoparentNegative leap seconds will mean that there will be UNIX timestamp value that is invalid. What should systems do when they encounter such value? Generally UNIX time -> UTC conversion is considered to be infallible, negative leap changes that. reply dark-star 10 hours agoparentprevYeah I'm wondering about that too. I don't think it could possibly be worse than having times like \"23:59:60\" pop up anywhere and messing every parser or regex up. It would just be like \"huh, nothing bad (or good) happened during 23:59:58 and 0:00 according to our logfiles\" reply Dylan16807 16 hours agoprevOn leap minutes: > Because there's nothing computer programmers handle better than special cases which only occur every hundred years or so. How in the world could this be an improvement? If it's less than 60 times as disruptive, it's an improvement. > everybody's going to hate it at least sixty times as much as they hate leap seconds now I doubt that. > If something is difficult, you do it more often. It has to be more often than leap seconds to really get those gears oiled. Unless this is a proposal to do leap deciseconds, I don't think this method reduces the pain. > But before 1972 UTC and TAI were kept in much closer synchronisation [...] (No, I'm not advocating returning to this state of affairs.) Coward! But seriously, I think this hurts the previous argument significantly. reply marcosdumay 15 hours agoparentI'd push for making it an hour already. If synchronizing our clocks with the Sun is still important by then, then announce it a decade or two beforehand, and make a large ceremony out of the thing. reply umanwizard 6 hours agorootparentYou don’t need to announce it a decade in advance. Time zones change all the time, we already know how to handle it and it requires no global coordination. Some country announces that part of its territory is changing time zone, the tzdb is updated, and everything continues working fine for everyone. This happens a few times a year already. reply akira2501 8 hours agoparentprevThe obvious disconnect is the digital bits inside my hardware clock shouldn't need to care about any of this. Then you can change it as often or as little as you like. reply Dylan16807 2 hours agorootparentI assume you mean high precision clocks in computers because an actual clock won't care about half a second. You could use TAI-ish timestamps right now, but people are going to get confused and make mistakes if your timestamps are almost UTC but several seconds off. And if UTC stays constant then you need to nudge all the time zones around and that sounds even worse. reply lmm 15 hours agoparentprev> It has to be more often than leap seconds to really get those gears oiled. Unless this is a proposal to do leap deciseconds, I don't think this method reduces the pain. Yeah, if we're not going to abolish leap everything in UTC completely (which I think we should) then leaps need to happen at most quarterly. When the last leap second came through it was long enough since the one before that the bugs in Linux had been fixed and then unfixed. reply marcus_holmes 15 hours agorootparentDo we introduce an unnecessary leap second and then negative leap second every year just to keep the gears oiled? And then if we need one for reals we can increase it to two leap seconds added and only one removed. Though of course that will cause bugs in any code that isn't expecting two leap seconds to be added and assumed that there would only ever be one. sigh reply arp242 15 hours agorootparentJust accept that time will very slowly drift over the period of many centuries. It's really not a big deal. It's a complete non-problem that doesn't need any solving. Especially since coming up with a robust scheme that will work over the period of many centuries is quite hard (the current leap second system doesn't suffice). reply withinboredom 11 hours agorootparent> It's really not a big deal. Unless, of course, you are a satellite. reply arp242 6 hours agorootparentI don't know what you're referring to, but as far as I know satellites can work perfectly fine without a leap second. I'm not aware of any practical advantage of leap seconds anywhere. The only difficulty in abolishing the leap second is that some systems have it incorporated in their protocol, but that's a protocol issue and not an intrinsic time drift issue. reply withinboredom 6 hours agorootparentTime is attached to the orbit of the earth (very precisely) so when time goes out of sync of the earth, it won't be a good day for anyone. reply Dylan16807 2 hours agorootparentOrbiting around earth is going to be based on sidereal time, which drifts 4 minutes per day. Converting into normal units has no reason to care about leap seconds when it can use the actual offset and be a few orders of magnitude more precise. reply arp242 5 hours agorootparentprevMost satellite systems don't use leap seconds; you don't need leap seconds to have satellites. And leap seconds don't really \"sync time with the earth\"; that's not how any of this works. Whether it's now 13:04:00 or 13:04:27 is somewhat arbitrary and all leap seconds do is maintain a certain arbitrary definition. reply bee_rider 15 hours agorootparentprevWe could build it into daylight savings time. Instead of jumping an hour, we announce what the jump will be every year. reply rawling 14 hours agorootparentNot everyone's jumps happen at the same time (or ever). reply marcus_holmes 10 hours agorootparentWe already have non-integer timezone differences. We could allow for leap seconds in that. Europe's timezone could be UTC+2:00:01 while the UK is still UTC+00:00:00 reply bee_rider 15 hours agorootparentprevIt vaguely feels like it ought to happen yearly. Yearly, but no option of a shift of exactly zero, so everybody knows it is coming every year no matter what. reply _ache_ 13 hours agoprev [–] I don't understand that someone just want chaos. I guess \"Some people just want to watch the world burn\". But negative leap second shouldn't be so noticeable since it will just be a jump from 31 dec 23:58 to 1 jan 00:00. Facebook made a lot of FUD about a negative leap second but I don't think it should be THAT a concern. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post discusses the concept of a negative leap second, which has never been implemented but could be necessary due to Earth's faster rotation since 2018.",
      "Leap seconds are added to account for Earth's irregular rotation, posing challenges to technical systems like Unix time, which struggles with the 23:59:60 timestamp.",
      "There is ongoing debate about abolishing leap seconds by 2035, which would prevent the implementation of a negative leap second, a prospect the author finds disappointing."
    ],
    "commentSummary": [
      "The discussion revolves around the concept of leap seconds, which are added to Coordinated Universal Time (UTC) to keep it in sync with Earth's rotation, and the potential introduction of a negative leap second.",
      "Various opinions are shared on how to handle time adjustments, including abolishing leap seconds, shifting the prime meridian, and updating time zones periodically.",
      "The debate highlights the complexities and potential issues of timekeeping, such as system synchronization problems, the impact on software, and the historical context of time standards like UTC and TAI (International Atomic Time)."
    ],
    "points": 174,
    "commentCount": 204,
    "retryCount": 0,
    "time": 1719957661
  },
  {
    "id": 40866374,
    "title": "Do not taunt happy fun branch predictor (2023)",
    "originLink": "https://www.mattkeeter.com/blog/2023-01-25-branch/",
    "originBody": "Matt Keeter // blog projects research blog about links Do Not Taunt Happy Fun Branch Predictor I've been writing a lot of AArch64 assembly, for reasons. I recently came up with a \"clever\" idea to eliminate one jump from an inner loop, and was surprised to find that it slowed things down. Allow me to explain my terrible error, so that you don't fall victim in the future. A toy model of the relevant code looks something like this: float run(const float* data, size_t n) { float g = 0.0; while (n) { n--; const float f = *data++; foo(f, &g); } return g; } static void foo(float f, float* g) { // do some stuff, modifying g } (eliding headers and the forward declaration of foo for space) A simple translation into AArch64 assembly gives something like this: // x0: const float* data // x1: size_t n // Returns a single float in s0 // Prelude: store frame and link registers stp x29, x30, [sp, #-16]! // Initialize g = 0.0 fmov s0, #0.0 loop: cmp x1, #0 b.eq exit sub x1, x1, #1 ldr s1, [x0], #4 bl foo // call the function b loop // keep looping foo: // Do some work, reading from s1 and accumulating into s0 // ... ret exit: // Function exit ldp x29, x30, [sp], #16 ret Here, foo is kinda like a naked function: it uses the same stack frame and registers as the parent function, reads from s1, and writes to s0. The call to foo uses the the bl instruction, which is \"branch and link\": it jumps to the given label, and stores the next instruction address in the link register (lr or x30). When foo is done, the ret instruction jumps to the address in the link register, which is the instruction following the original bl. Looking at this code, I was struck by the fact that it does two branches, one after the other. Surely, it would be more efficient to only branch once. I had the clever idea to do so without changing foo: stp x29, x30, [sp, #-16]! fmov s0, #0.0 bl loop // Set up x30 to point to the loop entrance loop: cmp x1, #0 b.eq exit sub x1, x1, #1 ldr s1, [x0], #4 foo: // Do some work, accumulating into `s0` // ... ret exit: // Function exit ldp x29, x30, [sp], #16 ret This is a little subtle: The first call to bl loop stores the beginning of the loop block in x30 After checking for loop termination, we fall through into the foo function (without a branch!) foo still ends with ret, which returns to the loop block (because that's what's in x30). Within the body of the loop, we never change x30, so the repeated ret instructions always return to the same place. I set up a benchmark using a very simple foo: foo: fadd s0, s0, s1 ret With this foo, the function as a whole sums the incoming array of float values. Benchmarking with criterion (on an M1 Max CPU), with a 1024-element array: Program Time Original 969 ns \"Optimized\" 3.85 µs The \"optimized\" code with one jump per loop is about 4x slower than the original version with two jumps per loop! I found this surprising, so I asked a few colleagues about it. Between Cliff and Dan, the consensus was that mismatched bl / ret pairs were confusing the branch predictor. The ARM documentation agrees: Why do we need a special function return instruction? Functionally, BR LR would do the same job as RET. Using RET tells the processor that this is a function return. Most modern processors, and all Cortex-A processors, support branch prediction. Knowing that this is a function return allows processors to more accurately predict the branch. Branch predictors guess the direction the program flow will take across branches. The guess is used to decide what to load into a pipeline with instructions waiting to be processed. If the branch predictor guesses correctly, the pipeline has the correct instructions and the processor does not have to wait for instructions to be loaded from memory. More specifically, the branch predictor probably keeps an internal stack of function return addresses, which is pushed to whenever a bl is executed. When the branch predictor sees a ret coming down the pipeline, it assumes that you're returning to the address associated with the most recent bl (and begins prefetching / speculative execution / whatever), then pops that top address from its internal stack. This works if you've got matched bl / ret pairs, but the prediction will fail if the same address is used by multiple ret instructions; you'll end up with (vague handwaving) useless prefetching, incorrect speculative execution, and pipeline stalls / flushes Dan made the great suggestion of replacing ret with br x30 to test this theory. Sure enough, this fixes the performance regression: Program Time Matched bl / ret 969 ns One bl, many ret 3.85 µs One bl, many br x30 913 ns In fact, it's slightly faster, probably because it's only doing one branch per loop instead of two! To further test the \"branch predictor\" theory, I opened up Instruments and examined performance counters for the first two programs. Picking out the worst offenders, the results seem conclusive: Counter Matched bl / ret One bl, many ret BRANCH_RET_INDIR_MISPRED_NONSPECIFIC 92 928,644,975 FETCH_RESTART 61,121 987,765,276 MAP_DISPATCH_BUBBLE 1,155,632 7,350,085,139 MAP_REWIND 6,412,734 2,789,499,545 These measurements are captured while summing an array of 1B elements. We see that with mismatched bl / ret pairs, the return branch predictor fails about 93% of the time! Apple doesn't fully document these counters, but I'm guessing that the other counters are downstream effects of bad branch prediction: FETCH_RESTART is presumably bad prefetching MAP_DISPATCH_BUBBLE probably refers to pipeline stalls MAP_REWIND might be bad speculative execution that needs to be rewound In conclusion, do not taunt happy fun branch predictor with asymmetric usage of bl and ret instructions. Appendix: Going Fast Take a second look at this program: stp x29, x30, [sp, #-16]! fmov s0, #0.0 loop: cmp x1, #0 b.eq exit sub x1, x1, #1 ldr s1, [x0], #4 bl foo // call the function b loop // keep looping foo: fadd s0, s0, s1 ret exit: // Function exit ldp x29, x30, [sp], #16 ret Upon seeing this program, it's a common reaction to ask \"why is foo a subroutine at all?\" The answer is \"because this is a didactic example, not code that's trying to go as fast as possible\". Still, it's a fair question. You wanna go fast? Let's go fast. If we know the contents of foo when building this function (and it's shorter than the maximum jump distance), we can remove the bl and ret entirely: loop: cmp x1, #0 b.eq exit sub x1, x1, #1 ldr s1, [x0], #4 // foo is completely inlined here fadd s0, s0, s1 b loop exit: // Function exit ldp x29, x30, [sp], #16 ret This is a roughly 6% speedup: from 969 ns to 911 ns. We can get faster still by trusting the compiler: pub fn sum_slice(f: &[f32]) -> f32 { f.iter().sum() } This brings us down to 833 ns, a significant improvement! Looking at the assembly, it's doing some loop unrolling. However, even when compiled with -C target-cpu=native, it's not generating NEON SIMD instructions. Can we beat it? We sure can! stp x29, x30, [sp, #-16]! fmov s0, #0.0 dup v1.4s, v0.s[0] dup v2.4s, v0.s[0] loop: // 1x per loop ands xzr, x1, #3 b.eq simd sub x1, x1, #1 ldr s3, [x0], #4 fadd s0, s0, s3 b loop simd: // 4x SIMD per loop ands xzr, x1, #7 b.eq simd2 sub x1, x1, #4 ldp d3, d4, [x0], #16 mov v3.d[1], v4.d[0] fadd v1.4s, v1.4s, v3.4s b simd simd2: // 2 x 4x SIMD per loop cmp x1, #0 b.eq exit sub x1, x1, #8 ldp d3, d4, [x0], #16 mov v3.d[1], v4.d[0] fadd v1.4s, v1.4s, v3.4s ldp d5, d6, [x0], #16 mov v5.d[1], v6.d[0] fadd v2.4s, v2.4s, v5.4s b simd2 exit: // function exit fadd v2.4s, v2.4s, v1.4s mov s1, v2.s[0] fadd s0, s0, s1 mov s1, v2.s[1] fadd s0, s0, s1 mov s1, v2.s[2] fadd s0, s0, s1 mov s1, v2.s[3] fadd s0, s0, s1 ldp x29, x30, [sp], #16 ret This code includes three different loops: The first loop (loop) sums individual values into s0 until we have a multiple of four values remaining The second loop (simd) uses SIMD instructions to sum 4 values at a time into the vector register v1, until we have a multiple of 8 values remaining The last loop (simd2) is the same as simd, but is unrolled 2x so it handles 8 values per loop iteration, summing into v1 and v2 At the function exit, we accumulate the values in the vector registers v1/v2 into s0, which is returned. The type punning here is particularly cute: ldp d3, d4, [x0], #16 mov v3.d[1], v4.d[0] fadd v1.4s, v1.4s, v3.4s Remember, x0 holds a float*. We pretend that it's a double* to load 128 bits (i.e. 4x float values) into d3 and d4. Then, we move the \"double\" in d4 to occupy the top 64 bits of the v3 vector register (of which d3 is the lower 64 bits). Of course, each \"double\" is two floats, but that doesn't matter when shuffling them around. When summing with fadd, we tell the processor to treat them as four floats (the .4s suffix), and everything works out fine. How fast are we now? This runs in 94 ns, or about 8.8x faster than our previous best. Here's a summary of performance: Program Time Matched bl / ret 969 ns One bl, many ret 3.85 µs One bl, many br x30 913 ns Plain loop with b 911 ns Rewrite it in Rust 833 ns SIMD + manual loop unrolling 94 ns Could we get even faster? I'm sure it's possible; I make no claims to being the Agner Fog of AArch64 assembly. Still, this is a reasonable point to wrap up: we've demystified the initial performance regression, and had some fun hand-writing assembly to go very fast indeed. The SIMD code does come with one asterisk, though: because floating-point addition is not associative, and it performs the summation in a different order, it may not get the same result as straight-line code. In retrospect, this is likely why the compiler doesn't generate SIMD instructions to compute the sum! Does this matter for your use case? Only you can know! All of the code from this post is published to GitHub. You can reproduce benchmarks by running cargo bench on an ARM64 machine. © 2010-2024 Matthew Keeter",
    "commentLink": "https://news.ycombinator.com/item?id=40866374",
    "commentBody": "Do not taunt happy fun branch predictor (2023) (mattkeeter.com)155 points by fanf2 4 hours agohidepastfavorite76 comments allenrb 1 hour agoWas summarizing this article for a group of friends who largely met during the Apple II days and wanted to repost a bit of that here: The optimized code at the end takes 94 nanoseconds to sum an array of 1024 32-bit floating point numbers. In 94 nanoseconds, our old friend the 1 MHz 6502, would be just starting to consider signaling the memory chips that maybe they ought to try digging up the first byte of the first instruction in the program. Worth mentioning, that code is entirely dependent on running in cache. Otherwise even the mighty M1 Max in the post would still be stuck waiting on that first memory fetch. DRAM is slow. :-) reply AshamedCaptain 2 hours agoprevThe same thing was covered by Raymond Chen almost 2 decades ago: https://devblogs.microsoft.com/oldnewthing/20041216-00/?p=36... reply electrodank 1 hour agoparentAs someone who has the old dead tree version of Intel’s x86 and 64 architecture instruction set reference (the fat blue books), and in general as someone who carefully reads the data sheets and documentation and looks for guidance from the engineers and staff who wrote the said data sheets, I always have reservations when I hear that “intuitively you would expect X but Y happens.” There’s nothing intuitive about any of this except, maybe, a reasonable understanding of the semi-conductive nature of the silicon and the various dopants in the process. Unless you’ve seen the die schematic, the traces, and you know the paths, there is little to no reason to have any sort of expectations that Thing A is faster than Thing B unless the engineering staff and data sheets explicitly tell you. There are exceptions, but just my 2c. Especially with ARM. reply neonsunset 1 hour agorootparentRespectfully, I disagree. CPU architecture optimization is in continuous dance with compiler optimization where the former tries to adapt to the patterns most commonly produced by the latter, and the latter tries to adjust its optimizations according to what performs the faster within the former. Therefore, it is not unreasonable to make assumptions based on the premise of \"does this code look like something that could be reasonably produced by GCC/LLVM?\". It is true that as cores get simpler and cheaper, they get more edge cases - something really big like Firestorm (A14/M1) can afford to have very consistent and tight latencies for all of its SIMD instructions regardless of the element/lane size and even hide complex dependencies or alignment artifacts wherever possible. But compare that with simpler and cheaper Neoverse N1, and it's a different story entirely, where trivial algorithm changes lead to significant slowdown - ADDV Vn.16B is way slower than Vn.4H, so you have to work around it. This is only exacerbated if you look at much smaller cores. LLVM and GCC deal with this by being able to use relatively precise knowledge of CPU's (-mtune) fetch, reorder, load and store queue/buffer depths, as well as latencies and dependency penalty cost of opcodes of the ISA it implements, and other details like loop alignment requirements, branch predictor limitations. Generally, it's difficult to do better in straight-line code with local data than such compilers assuming that whatever you are doing doesn't make concessions that a compiler is not allowed to make. Nonetheless, the mindset for writing a performant algorithm implementation is going to be the same as long as you are doing so for the same class of CPU cores - loop unrolling, using cmovs, and scheduling operations in advance, or ensuring that should spills happen, the load and store operations have matching arguments - all of that will be profitable on AMD's Zen 4, Intel's Golden Cove, Apple's Firestorm or ARM's Neoverse V3. reply rkagerer 1 hour agoparentprevHe did, and that's a fantastic article which is worth the read and provides good context for interpreting this post. One thing this post adds is the simple rectification of replacing ret with another br instruction, so the pairs are again \"mirrored\", and you get to have your cake and eat it too - slightly faster code without breaking the branch predictor. reply rep_lodsb 1 hour agoparentprevThis seems no longer to be true for recent x86 processors: https://news.ycombinator.com/item?id=40767676 reply mrinterweb 1 hour agoprevClassic SNL reference: \"Do not taunt happy fun ball\" https://www.youtube.com/watch?v=GmqeZl8OI2M reply rhussmann 1 hour agoparentIf happy fun branch predictor starts to smoke, seek shelter immediately. reply Terr_ 31 minutes agoparentprev> Happy Fun Ball has been shipped to our troops in Saudi Arabia and is also being dropped by our warplanes in Iraq. \"What YEAR is it!?\" /robin-williams-in-jumanji reply bee_rider 3 hours agoprev> The SIMD code does come with one asterisk, though: because floating-point addition is not associative, and it performs the summation in a different order, it may not get the same result as straight-line code. In retrospect, this is likely why the compiler doesn't generate SIMD instructions to compute the sum! > Does this matter for your use case? Only you can know! Anything is possible of course, and the typical way of writing a loop to sum up an array is literally telling the computer to go element by element and accumulate the values. But it seems pretty unlikely that doing, say, four accumulations in parallel with simd and then summing them up at the end is any more wrong than going element by element. Summing floats should by default be taken to have error bounds, and any answer in those bounds is valid. If you know something special about the floats you are inputting, the language should have some means to explicitly encode that. It shouldn’t be the most basic loop, that’s the default case, so it should give the best performance. reply lscharen 2 hours agoparentSurprisingly there are different algorithms for doing something as simple as summing up a list of numbers. The naïve way of adding numbers one-by-one in a loop is an obvious way, but there are more sophisticated methods that give better bounds of the total accumulated error; Kahan summation[1] being one of the better-known ones. Like most things, it can get complicated depending on the specific context. For streaming data, adding numbers one at a time may be the only option. But what if one could use a fixed-size buffer of N numbers? When a new number arrives what should be done? Take a partial sum of some subset of the N numbers in the buffer and add that to a cumulative total? If a subset if chosen, how? Are there provable (improved) error bounds for the subset selection method? Fun stuff. [1] https://en.wikipedia.org/wiki/Kahan_summation_algorithm reply kardos 2 hours agorootparentAs far as I know, xsum [1] more or less solves the problem completely: order invariant and exact, at less than 2x the cost of the naive summation. Further speeding it up may be the only avenue left for improvement. [1] https://gitlab.com/radfordneal/xsum reply lscharen 1 hour agorootparentI was not aware of this (2015) work -- very nice! A couple of pull-quotes from the paper to summarize: Much work has been done on trying to improve the accuracy of summation. Some methods aim to somewhat improve accuracy at little computational cost, but do not guarantee that the result is the correctly rounded exact sum. Many methods have been developed that instead compute the exact sum of a set of floating-point values, and then correctly round this exact sum to the closest floating-point value. This obviously would be preferable to any non-exact method, if the exact computation could be done sufficiently quickly Exact summation methods fall into two classes — those implemented using standard floating point arithmetic operations available in hardware on most current processors, such as the methods of Zhu and Hayes (2010), and those that instead perform the summation with integer arithmetic, using a “superaccumulator”. I present two new methods for exactly summing a set of floating-point numbers, and then correctly rounding to the nearest floating-point number. ... One method uses a “small” superaccumulator with sixty-seven 64-bit chunks, each with 32-bit overlap with the next chunk, allowing carry propagation to be done infrequently. The small superaccumulator is used alone when summing a small number of terms. For big summations, a “large” superaccumulator is used as well. It consists of 4096 64-bit chunks, one for every possible combination of exponent bits and sign bit, plus counts of when each chunk needs to be transferred to the small superaccumulator. On modern 64-bit processors, exactly summing a large array using this combination of large and small superaccumulators takes less than twice the time of simple, inexact, ordered summation, with a serial implementation reply crote 3 hours agoparentprevIt turns into a serious problem if the floats are of different magnitude. Consider [1e50, -1e50, 1e3, 1e3]. Evaluating it as (((1e50 + -1e50) + 1e3) + 1e3) gives 2e3, evaluating it as ((1e50 + 1e3) + (-1e50 + 1e3)) gives 0. You get similar issues if you're trying to add a large number of small-magnitude numbers to a single larger-magnitude number. (((1e3 + 1e3) + 1e3) ... + 1e50) is substantially different from (((1e50 + 1e3) + 1e3) ... + 1e3). reply jandrese 2 hours agorootparentAdding and subtracting numbers of wildly different magnitudes is always cursed. If you're doing this I'd say the majority of the time you are making an error. Your equation ends up being like \"We calculated the diameter of the observable universe, but what if we added the Empire State Building to one side, how does that affect the result?\" reply skybrian 1 hour agorootparentIt’s also what we do when incrementing a counter, if it’s a very big counter. Operations like that don’t have a physical meaning, but can happen in things like random number generators where it’s a way of mixing the bits. Or maybe allocating unique ids, if you started from a random number. reply bee_rider 1 hour agorootparentOf course it is just an example so we shouldn’t nitpick you too much, but that sounds more like a job for an integer. reply bee_rider 47 minutes agorootparentprevWhether you care about the order or not depends on the intent of the programmer. I think the intent is usually to sum up the array for this sort of code. So, at first glance your first example looks more like a result of something like 0 +- 1e35 in double to me (added one to the exponent to avoid having to do math). The intent of the programmer always has to be interpreted by the language. I’m saying the default interpretation should be one that doesn’t impose an ordering unless specifically requested. This is much more sympathetic to modern deeply parallel machines. reply FreakLegion 2 minutes agorootparentVery often there's no particular intent, other than to be consistent. You haven't lived until you've traced discrepancies in an ML model deployed across a bunch of platforms back to which SIMD instructions each happens to support (usually squirreled away in some dependency). reply mywittyname 2 hours agorootparentprevBut you haven't demonstrated that the SIMD approach produces a meaningfully different and more accurate approach than the naive method. Just like processor magic made the theoretically more performant code perform worse, it's possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate than the naive approach. This is absolutely a situation that requires empirical testing. reply Sesse__ 1 hour agorootparent> it's possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate than the naive approach. It absolutely is not. Floating-point addition is completely defined (save for some of the bits in NaN results), and no CPU will start reordering your addition instructions in a way that changes the result. Even if it's an ordering that gives you better accuracy. Having SIMD do four (or more) of them in parallel does not change this. reply Dylan16807 2 hours agorootparentprev> it's possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate Not realistically. The processor very much needs to do what you tell it. reply scaredginger 2 hours agorootparentprevYeah, no. If I know what my data look like, I can choose an order of summation that reduces the error. I wouldn't want the compiler by default to assume associativity and introduce bugs. There's a reason this reordering is disabled by default reply Sesse__ 1 hour agorootparentNot the least that you should get the same result from your code every time, even if you compile it with a different compiler. Doesn't matter if that result is somehow better or worse or “difference is so small that it doesn't matter”; it needs to be exactly the same, every time. reply bee_rider 8 minutes agorootparentI think there’s often a disconnect in these discussions between people that work on libraries and people that work on the application code. If you have written a library, the user will provide some inputs. While the rounding behavior of floating point operations is well defined, for arbitrary user input, you can’t usually guarantee that it’ll go either way. Therefore, you need to do the numerical analysis given users inputs from some range, if you want to be at all rigorous. This will give results with error bounds, not exact bit patterns. If you want exact matches for your tests, maybe identify the bits that are essentially meaningless and write them to some arbitrary value. reply pjc50 3 hours agoparentprev> Summing floats should by default be taken to have error bounds, and any answer in those bounds is valid. If you know something special about the floats you are inputting, the language should have some means to explicitly encode that. It shouldn’t be the most basic loop, that’s the default case, so it should give the best performance. This is a lot of \"should\" for something that basically doesn't happen. The only information you give is the order of arithmetic in the original expression. It is a total nightmare if arithmetic is not stable between builds. Rebuilding the software and running it on the same input should not produce different results. (Long ago I encountered the special Intel version of this: because the FPU used 80-bit registers internally but 64-bit in memory, changing when a register fill/spill happened would change when your answer got rounded, and thereby change the results. You can set a global FPU flag at the start of the program to force rounding on every operation.) reply bee_rider 2 hours agorootparentIt does happen in languages and libraries with a higher level of abstraction. MKL for example will do whatever it wants for accumulations (which practically means that it’ll take advantage of SIMD because that’s a big reason why people use the library) unless you specifically request otherwise via there “Conditional Numerical Reproducibility” flag. I think that was the right way to do it. BLAS made the right decision by defining these things in terms of sums and dot products instead of step-by-step instructions. It will always be possible to write programs that run differently on different hardware or with different optimization levels. If somebody is writing code for floating point computations and expects exact bit patterns—it is possible, of course, all the rounding behavior is clearly specified. But usually this is an error. reply cwzwarich 2 hours agorootparentprev> You can set a global FPU flag at the start of the program to force rounding on every operation This doesn’t do quite the same thing. It still uses the wider exponent range of the 80-bit type. reply throwaway260124 3 hours agoparentprevSorting the floats reduces the error. I think using multiple accumulators reduces the accuracy then. And sorted data is not uncommon. I think there is always a correct answer and the compiler shouldn’t make changes at least by default that are wrong. But ways for the programmer to express his intent more clearly are always welcome. reply celrod 1 hour agorootparentMultiple accumulators increases accuracy. See pairwise summation, for example. SIMD sums are going to typically be much more accurate than a naive sum. reply Chabsff 38 minutes agorootparentNot necessarily either. It's not particularly hard to create a vector where in-order addition is the most accurate way to sum its terms. All you need is a sequence where the next term is close to the sum of all prior ones. There just isn't a one-size-fit-all solution to be had here. reply Chabsff 3 hours agorootparentprevNot necessarily. If the array is large and the values are similar, using accumulators would yield a more accurate result than a single one. reply RobotToaster 2 hours agoparentprev> this is likely why the compiler doesn't generate SIMD instructions to compute the sum! Isn't this the type of thing ffast-math is supposed to enable? reply not2b 2 hours agorootparent-ffast-math can be read as -fwrong-math if the accuracy if the answers matters. For some applications accuracy might not matter much. But the differences you get by pretending that floating point math is associative can be enormous, and scientific and engineering code is often carefully designed to take the likely scale of values into account, and rearranging it is not a good idea. reply dzaima 1 hour agorootparentFor code that's been explicitly manually optimized already, indeed you wouldn't want to turn on -ffast-math; and I'd hope anyone who has actually learned what benefits from manual optimization and how to properly do that would also at some point have read something about not coupling that with -ffast-math. But I really doubt such meaningfully-manually-optimized code is at all frequent, and where it isn't it's a rather simple improvement (potentially with using some subset flags to allow NaN or infinity if desired). reply Dylan16807 1 hour agorootparentprevAssuming associativity is not anti-accuracy in general, it just gets in the way of certain clever algorithms. reply Dylan16807 2 hours agorootparentprevFast math does a lot of risky things in addition to using basic math rules. reply bee_rider 1 hour agorootparentprevMaybe the “fun safe math” flag could be used? reply neonsunset 3 hours agoparentprevA lot of code relies on FP operations being deterministic, often within confines of specific ISA. Applying SIMD to loops with FP could have been a default but it breaks a lot of existing code, makes the output frequently straight-up non-deterministic and as a result is something that a programmer has to explicitly choose to use. Moreover, many programmers may not be even aware of these, so when a `float Sum(float[] values)` starts to return something different, they may not have any way to know that it is the vectorization that makes it do so. Which is why, for example, .NET's standard library will use SIMD for `integers.Sum()` but not for `floats.Sum()`. reply crote 2 hours agorootparent> A lot of code relies on FP operations being deterministic, often within confines of specific ISA How much of this is true in practice? I vaguely recall reading about a hard-to-diagnose bug where a seemingly unrelated code change meant that an intermediate value was no longer stored in the x87 extended-precision register but in memory instead, leading to a different result. Wouldn't you run into stuff like that all the time? reply mindcandy 2 hours agorootparent> A lot of code relies on FP operations being deterministic A lot, but still quite the minority. People do run into situations where the same code with the same data produces slightly different results all the time because of changes in compiler, compiler settings, cpu arch, etc… They just don’t notice. But, then they run into a situation where it matters and it’s a huge PITA to nail down. reply kardos 1 hour agorootparentYes this is exactly it. The gold standard is bit-4-bit matching when shifting code between systems. If you move your code to a new system and get different results --> is it due to different summing order, or something else wrong? By ruling out the former you're more likely to get the bit-4-bit match and thus avoid a lot of debugging effort -- or spend it solving a real bug. reply Sesse__ 1 hour agorootparentprevThis is one of many reasons why we generally don't use the x87 registers anymore. reply monitron 1 hour agoprevThis was a lovely article. I only wish the author wouldn’t have kept switching units (between µs and ns) making it hard to scan the tables for comparison. reply nayuki 1 hour agoprev> Why do we need a special function return instruction? Functionally, BR LR would do the same job as RET. Using RET tells the processor that this is a function return. I'm not sure this is a good design. Those two opcodes perform the same logic function but have different branch prediction hints. Meanwhile, there are other cases where an existing instruction is reinterpreted with new semantics: * On x86, `XCHG eax, eax` is `NOP`. * On x86, `XOR reg, reg` is `MOV reg, 0` and breaks dependencies for the purposes of register renaming. * On x86, various examples of macro-op fusion and micro-op fusion. * On various RISC architectures, `ADD r1, r0, 1234` is `MOV r1, 1234`. * On some RISC architectures, conditionally branching if r0 == 0 is the only way to express an unconditional branch. I see no reason why `BR LR` can't be the standard function return instruction and involve the branch predictor. reply CrazyStat 3 hours agoprev(2023) Discussion at the time: https://news.ycombinator.com/item?id=34520498 reply dang 2 hours agoparentThanks! Macroexpanded: Do not taunt happy fun branch predictor - https://news.ycombinator.com/item?id=34520498 - Jan 2023 (171 comments) (Reposts are fine after a year or so; links to past threads are just to satisfy extra-curious readers) reply jcranmer 3 hours agoprev> After checking for loop termination, we fall through into the foo function (without a branch!) Literally just reading this line made me go \"well, there's your problem.\" I thought this was going to be something deep about fancy branch predictor heuristics, but it turns out to be a violation of basic heuristics. Folks, don't think you're going to get amazing speedups by using mismatched call/ret instructions. The branch predictor keeping a shadow stack of return addresses is something that's been around for decades. reply vlovich123 3 hours agoparentAnd yet they also showed how they did actually accomplish this and other optimizations. It’s an informative read. reply adwn 3 hours agoparentprevIt's great that you're so knowledgeable about branch predictor behavior, but many people aren't and for them this is new, maybe even valuable, information. I guess this article's just not for you then, and that's okay. reply quotemstr 3 hours agoparentprevAnd this will screw up program execution more profoundly (i.e.crash) on systems with architectural shadow call stacks as a security feature. reply astrobe_ 1 hour agorootparentSpeaking of \"security feature\", this insanely complex behavior (for a CPU) is a recipe for disasters like Specter and Meltdown. reply orbital-decay 3 hours agoprevTangential question, perhaps a dumb one: why do most hardware schedulers try to predict the load on their own, instead of letting users explicitly signal their intent? It's everywhere, from CPUs to storage. reply pjc50 3 hours agoparentThe user doesn't know the capabilities of the system. In particular, anything compiled in is set in stone: you don't know the capabilities of systems yet unbuilt. New systems don't sell well unless they make existing code run faster, and sell badly if they require you to rebuild everything and make it non-backwards-compatible. The peak example of \"let the user do the scheduling\" was Itanium, which had a VLIW system which scheduled three instructions at once. It was a huge commercial failure, and allowed AMD to instead define the instruction set people wanted: X64 is IA32 but wider and with more registers, but not substantially different and certainly not as weird as Itanium. reply magicalhippo 2 hours agorootparentI've lost count of the times I've sped up some existing code by removing the hand-optimized assembly and just used a plain C implementation or similar. Sure, it was hand-optimized assembly, but for a 10+ year old CPU. If you're going to do hand-optimized code for a given platform, include the baseline code and measure at runtime to pick the implementation. reply patmorgan23 43 minutes agorootparentHand optimized assembly was necessary 30 years ago, and a good for several optimizations 20 years ago. But today's computers are SO FAST, it's just not necessary in most situations. reply crote 2 hours agoparentprevYou should look into the history of Itanium, it was designed around the idea that the compiler would do pretty much exactly that. It looked great on paper, but in practice nobody figured out how to actually write a compiler capable of doing it without constantly running into weird edge cases. X86 does have \"prefetch\" instructions, which tell the CPU that you want to use some data in the near future. There are also \"branch hint\" instructions which tell the CPU if a branch is usually taken or not. The problem is that they tend to make your code slower: the CPU is already more than capable of predicting it by itself, and the extra instructions slow down the overall execution because they take up cache space and have to be decoded too. reply CalChris 2 hours agorootparentVLIW is pretty successful for loopy DSP and now AI/ML. However, Itanium was trying to work for general purpose code and then as you say, it constantly ran into weird edge cases. It seemed as if VLIW succumbed to the Peter Principle, it had risen to its level of incompetence. But as long as you use it appropriately, VLIW is a best practice and LLVM supports it. BTW, CS252 at Berkeley and Onur Mutlu's ETH lectures give a conventionally disparaging view of VLIW without pointing out its successes. reply bbatha 1 hour agorootparentAdding on, VLIW is only successful in AI/ML because GPUs are incapable of doing branching in a good way let alone prediction. I would guess the same story applies to DSPs. If someone figures out how to stick a branch predictor in those pipelines Im guessing the VLIW nature of those platforms will disappear overnight. reply CalChris 1 hour agorootparentThe defining character of VLIW is to have the brilliant compiler software schedule dumb parallel hardware instructions statically and then not depend on power/transistor expensive dynamic branch prediction and OOO execution. In a perfect VLIW world that would mean you don't spend any transistors or power on branch prediction or out of order instruction searches. Indeed the original VLIW paper [1] spends vastly most its paragraphs on solving the (hard) compiler instruction scheduling problem with trace scheduling which is still used. The VLIW hardware itself is dead simple. [1] https://safari.ethz.ch/architecture/fall2022/lib/exe/fetch.p... So if VLIW fits the problem it has fantastic performance characteristics. If it doesn't fit, and far and away most don't, then VLIW is terrible. VLIW is very brittle. I need to make a caveat about the Mill CPU which is a VLIW but I see I've written too much already. reply rcxdude 3 hours agoparentprevIt's supported by some CPUs: the linux kernel has likely/unlikely macros to indicate whether a branch is expected to be taken or not in the common case (which uses GCC attributes which allow this to be propagated through to codegen). It's just that it's generally less effective: firstly because not all branches get annotated, some that are annotated are annotated incorrectly, and in a lot of cases the branching behaviour is data-dependent enough that you can't make an optimal static prediction at all. reply hansvm 3 hours agoparentprev1. \"Explicitly signaling your intent\" takes space and time. Decoding isn't free, and even if there were no other downsides you'd want to be careful with that change. 2. It's a bit historical. Early CPUs didn't have a RAM/CPU discrepancy and didn't need pipelining. Code wasn't written to account for pipelining. As CPUs got a little faster relative to RAM, you added a few prediction mechanisms so that most consumers and workloads could actually use your brand new 2x faster gigaterrawatthournewton CPUs without having to rewrite all their code. Iterate 10-20 generations, where most software has never been written to care about branch prediction and where modern languages don't even expose the concept, and you have the current status quo. reply ww520 2 hours agoparentprevGCC has the _builtin_expect macro to give hint for branch prediction. C++ has added something similar recently . reply 082349872349872 3 hours agoparentprevIn this case, I'd consider BL (call) a fairly explicit signal of intent to RET? reply dzaima 3 hours agorootparentYep. For returns, the more important thing in the article, the \"ret\"[0] instruction behaves exactly identically to \"br x30\"[1], just with the hint that it's expected to match a \"bl\". On x86 things are less pretty as call/ret push/pop the ip from the stack, with no non-matching-hinted versions, but having such would also just not be particularly useful as unpaired call/ret would result in the stack pointer continually drifting without manual fixup (at which point jmp is just clearly better). [0]: https://developer.arm.com/documentation/dui0802/a/A64-Genera... [1]: https://developer.arm.com/documentation/dui0802/a/A64-Genera... reply LegionMammal978 44 minutes agorootparentOn 32-bit x86, there is the trap of trying to use call/pop to get the absolute instruction pointer. It will work correctly, but it will mess up any call stack prediction and cause great performance penalties. Hence why compiler-generated EIP shims use call/mov/ret instead. (But this is not such a big issue in x86-64 with its RIP-relative addressing.) reply gpderetta 3 hours agoparentprevOften, but not always, optimal scheduling is data dependent so it can't be statically computed at compile time. reply mhh__ 2 hours agoparentprevThey want to be able to guess long, long, before actually executing the instructions. reply hindsightbias 2 hours agoparentprevWe could solve a lot of problems if every user had to take EE180. reply 38 27 minutes agoprev> const float f = *data++; cursed code. people might say \"oh that's normal idiomatic C\", I don't care. I am glad Go does not allow code like this reply samatman 1 hour agoprevEverything I know, or need to know, about branch prediction, I learned from James Mickens. https://scholar.harvard.edu/files/mickens/files/theslowwinte... reply quotemstr 3 hours agoprevYeah. This effect is why, also, using a bare CALL without a RET ends up being a slow way to get the program counter on 32-bit x86, which lacks native PC-relative addressing: it confuses the CPU's tracking of calls and returns. Basically, you always want to balance them. No exceptions. reply gpderetta 3 hours agoparentWasn't an article posted a few days ago showing that CPUs special case. CALL+0 not to update the prediction stack as it was commonly used to get IP? reply rep_lodsb 1 hour agorootparentYes: https://news.ycombinator.com/item?id=40767676 reply quotemstr 41 minutes agorootparentprevOkay, fair enough. It used to be a pessimization before CPUs recognized that pattern. :-) reply petsounds 3 hours agoprev [–] The title of this article is a reference to \"Happy Fun Ball\", my favorite SNL skit: https://www.youtube.com/watch?v=GmqeZl8OI2M reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An attempt to optimize an AArch64 assembly inner loop by eliminating a jump resulted in a 4x slowdown due to mismatched `bl` (branch with link) and `ret` (return) pairs, which confused the branch predictor.",
      "Replacing `ret` with `br x30` (branch to register) resolved the performance issue, and further optimizations, including inlining and using SIMD (Single Instruction, Multiple Data) instructions, achieved significant speedups.",
      "The final optimized SIMD version ran in 94 ns, approximately 8.8 times faster than the original code, highlighting the importance of avoiding asymmetric branching and leveraging SIMD for performance gains."
    ],
    "commentSummary": [
      "The article showcases an optimized code that sums an array of 1024 32-bit floating point numbers in 94 nanoseconds, emphasizing the efficiency due to cache usage.",
      "It discusses the significance of branch prediction and CPU architecture on performance, as well as the complexities of floating-point arithmetic and ensuring deterministic results.",
      "References to past work by Raymond Chen and user comments on SIMD (Single Instruction, Multiple Data) instructions, compiler optimizations, and historical CPU behaviors are included."
    ],
    "points": 155,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1720017722
  },
  {
    "id": 40859993,
    "title": "Google's carbon emissions surge nearly 50% due to AI energy demand",
    "originLink": "https://www.cnbc.com/2024/07/02/googles-carbon-emissions-surge-nearly-50percent-due-to-ai-energy-demand.html",
    "originBody": "SKIP NAVIGATION MARKETS BUSINESS INVESTING TECH POLITICS CNBC TV MAKE IT SELECT USA INTL WATCH LIVE Search quotes, news & videos WATCHLIST SIGN IN CLIMATE Google's carbon emissions surge nearly 50% due to AI energy demand PUBLISHED TUE, JUL 2 20243:41 PM EDTUPDATED TUE, JUL 2 20244:13 PM EDT Katie Bartlett @KATIE__BARTLETT KEY POINTS Google's emissions surged nearly 50% compared to 2019, the company said Tuesday in its 2024 environmental report. The news marks a setback in Google's goal to achieve net-zero emissions by 2030. The company attributed the emissions spike to an increase in data center energy consumption and supply chain emissions driven by rapid advancements in and demand for AI. In this article GOOGL Follow your favorite stocks CREATE FREE ACCOUNT A view of the Google headquarters in Mountain View, California, on April 16, 2024. Tayfun CoskunAnadoluGetty Images Google 's emissions surged nearly 50% compared to 2019, the company said Tuesday in its 2024 environmental report, marking a notable setback in its goal to achieve net-zero emissions by 2030. Google's emissions also increased 13% year over year in 2023, per the report. The company attributed the emissions spike to an increase in data center energy consumption and supply chain emissions driven by rapid advancements in and demand for artificial intelligence. The report noted that the company's total data center electricity consumption grew 17% in 2023. The impact of AI on electricity demand is well documented. Electricity demand is forecast to grow as much as 20% by 2030, with AI data centers alone expected to add about 323 terawatt hours of electricity demand in the U.S., CNBC previously reported. While renewables will likely play an important role in meeting AI energy demands, analysts say that immediate implementation is challenging. This is due to factors such as the time required to build the power lines that transport resources to the data centers, Wells Fargo analyst Roger Read previously told CNBC. Google said in the report that its data centers are 1.8 times as energy efficient as a typical data center. The company added that it remains committed to mitigating the environmental impact of AI through model optimization, efficient infrastructure and emissions reductions. Google is not the only major tech company to face increased emissions due to AI demand. Microsoft reported in May that its total carbon emissions rose nearly 30% since 2020 primarily due to the construction of data centers. Don’t miss these insights from CNBC PRO An AI data center boom is coming, Jefferies says, naming top stocks to buy right now Warren Buffett’s Berkshire Hathaway raked in billions from BYD, the China EV maker Munger called a ‘damn miracle’ These Nasdaq stocks are expected to fall as the latter half of the year begins S&P 500 to tumble 30% as recession hits later this year, says BCA Research Subscribe to CNBC PRO Subscribe to Investing Club Licensing & Reprints CNBC Councils Select Personal Finance CNBC on Peacock Join the CNBC Panel Supply Chain Values Select Shopping Closed Captioning Digital Products News Releases Internships Corrections About CNBC Ad Choices Site Map Podcasts Careers Help Contact News Tips Got a confidential news tip? We want to hear from you. GET IN TOUCH CNBC Newsletters Sign up for free newsletters and get more CNBC delivered to your inbox SIGN UP NOW Get this delivered to your inbox, and more info about our products and services. Advertise With Us PLEASE CONTACT US Privacy Policy CA Notice Terms of Service © 2024 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Market Data Terms of Use and Disclaimers Data also provided by",
    "commentLink": "https://news.ycombinator.com/item?id=40859993",
    "commentBody": "Google's carbon emissions surge nearly 50% due to AI energy demand (cnbc.com)149 points by melling 22 hours agohidepastfavorite108 comments kens 22 hours agoThe headline is bogus and most of the comments are responding to the headline. Google's emissions increased 13% since last year, \"primarily due to increases in data center energy consumption and supply chain emissions.\" It's unclear how much is due to AI. The supposed surge is a 48% increase compared to *2019*, consisting of moderate increases every year since 2020, not a nearly 50% surge due to AI. Google's document is at: https://www.gstatic.com/gumdrop/sustainability/google-2024-e... See pdf page 8 / document page 7 for details, as well as the graph on page 32/31. reply WheatMillington 21 hours agoparentYour comment is a little dismissive. Firstly, the headline doesn't mention \"versus last year\", and the 48% figure is straight from the document you mentioned and is repeated often within that document. It's directly from Google, and is significant. Moreover that document itself states (page 31) \"As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands\". It's clear that AI advancements are the biggest hurdle in terms of energy use and therefore CO2 emissions for Google. reply thethirdone 21 hours agorootparentThe article does a good job of clearly stating that the 48% is compared to 2019, but words like \"surge\" and \"spike\" do not closely match that factual basis and imho are misleading. Attributing the 48% to AI specifically is largely baseless though. From my skim, the Google report does not make any specific claims about the increase in datacenter emission coming from AI. The closest claims are on page 12 where \"the rapid advancement of AI has brought necessary increased attention to its energy consumption and resource demands\" is juxtaposed with \"total data center electricity consumption grew 17%\" In particular the third \"key point\" seems highly misleading. > The company attributed the emissions spike to an increase in data center energy consumption and supply chain emissions driven by rapid advancements in and demand for AI. The word \"spike\" does not occur in the document and the 48% number is never close to a mention of AI. While the 17% \"spike\" may have been attributed to AI by Google, I think it is clear the document does not attribute the 48% to AI. reply pkage 21 hours agorootparentprevClaiming that emissions surged 50% due exclusively to AI (as in the headline) is unsupported by the Google report, which is the article's singular source. Again, looking at the graph of emissions at Google on pg 31, it's clear that the increase is linear after a dip 2019-2020 and the report identifies supply chain issues as a major source of emissions in addition to datacenter electricity costs—again, notably not specifically calling out their AI training/inference costs as a reason for their increase. The report does identify AI as a challenge going forwards, however that's not the same as saying it's exclusively responsible for the last 5 years of emissions. reply qeternity 21 hours agorootparentprevIt doesn’t say “versus last year”, but it does say: “Google’s emissions also increased 13% year over year in 2023, per the report.” reply thethirdone 21 hours agorootparentWhat is the surrounding text for \"versus last year\"? I cannot find \"versus\" or \"year\" in the article. reply ajross 21 hours agorootparentprevIt's indeed pretty spun. Some quick googling shows that real GDP is up 11.5% from 2019-2024, which makes up a bunch of the \"effect\" right there (obviously datacenter power isn't directly tied to economic activity as a first principles thing, but like everything else at scale it's going to be pretty darn close). Of the remainder, I get an average yearly increase of... 5.8% over the time period in question. I mean, that's an effect, but it's certainly not a big one. reply TeMPOraL 21 hours agoparentprev> The supposed surge is a 48% increase compared to 2019* That's a smoking gun, alright. If you compare today to just before the pandemic, you're going to get all kinds of weird results that can mostly be attributed to the world working in emergency mode for 2020-2022. reply asdff 21 hours agoparentprev48% increase since 2019 still sounds pretty bad to me. Not like any of their products improved in that time. reply TeMPOraL 21 hours agorootparentLet's not forget what happened in 2020: the world went into lockdown over COVID-19. Everyone was trying to do emergency gear-shift into remote work, and the demand for online collaboration services - and supporting infrastructure - exploded. That IMO can easily account for majority of the increase since 2019, and it seems that this is another example of why you have to be suspicious of any average that includes pandemic years in its range. 2020-2022 was a unique period in all kinds of ways. EDIT: Google's document even acknowledges that, in footnote 103 linked to from page 32. Quoting: Although 2020 was the most recent emissions inventory available at the time the target was set, 2020 was deemed to not be representative of a typical year, because operations were impacted by the COVID-19 pandemic. The next most recent year with representative data, 2019, was selected as the base year. reply icehawk 20 hours agorootparentGoogle's own numbers say 2020 the smallest YoY increase. Difference between 2019 and 2020: +2.901 TWh Difference between 2020 and 2021: +3.149 TWh Difference between 2021 and 2022: +3.489 TWh Difference between 2022 and 2023: +3.531 TWh reply 1vuio0pswjnm7 20 hours agoparentprevhttps://web.archive.org/web/20240702163550if_/https://www.gs... page 31: \"In 2023, our total GHG emissions were 14.3 million tCO2e [metric tons of carbon dioxide], representing a 13% year-over-year increase and a 48% increase compared to our 2019 target base year. This result was primarily due to increases in data center energy consumption and supply chain emissions. As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment.\" \"...reducing emissions may be challenging...\" The supposed justification for this level of pollution and water use [see page 42] is debatable. The expected profits are highly speculative. What seems more clear is that unless things change it is going to to nigh impossible for young people to rise to challenges of climate change while simultaneously being addicted to mobile/Wifi internet access. Disconnecting a kid today from the internet is like separating a junkie from their drugs. reply elicksaur 21 hours agoparentprevMaybe AI summarized the document for the reporter. reply klyrs 21 hours agoparentprevTimnit Gebru was fired in late 2020 for publicly examining the energy consumption of LLMs, perhaps that would be a more poignant start-time. reply jeffbee 21 hours agorootparentGebru's estimates of AI energy consumption were adopted from Strubell. Strubell's estimates of AI energy consumption are ridiculous and according to David Patterson range from 88x to 10000x high. My humble opinion on the affair is that the conflict between Gebru and the rest of the company arose from Gebru's refusal to use the best and most comprehensive information on AI energy consumption, that is what they had access to firsthand as a privilege of being a Google insider. reply Frieren 22 hours agoprevI see the current gold rush of AI the same way I saw crypto-currencies. Even if originally there were people that believed in the concept it became just a snake-oil sellers business. The parallelism is made even more relevant by its hungry use of electricity. There is a future for AI but it is not what we see companies developing right now. Chat-bots are more dystopian and problematic than useful. AI future (and present) is on analyzing big chunks of data about chemical bounds, traffic-flow, astronomical observations, etc. But all that really useful AI is not attracting the kind of investment that flashy consumer-oriented chat-bots are getting. reply williamcotton 21 hours agoparentI'm getting very tired of the claim that LLMs are not useful. I hand-wrote perhaps 10 lines of code in this entire project: https://github.com/williamcotton/guish I spent most of the weekend playing with my kids in the pool. Three years ago this would have taken more than a week of my time and I wouldn't have done much else. reply yencabulator 2 hours agorootparentGreat example of LLM-produced code. I found the first bug after 20 seconds of reading. Enjoy! reply JasonSage 21 hours agorootparentprevParent did not claim that LLMs are not useful. Parent also acknowledges that AI is not a temporary phenomenon. reply aoeusnth1 20 hours agorootparentOP does downplay them (“more dystopian and problematic than useful”). For one, it’s a nonsensical statement because dystopia and problems are not comparable to utility. A generous read of what they meant might be: LLMs are not very useful, and are dystopian and problematic in some vague way. Do you believe parent thinks LLMs are very useful? They clearly think the real value of AI comes from limited applications of ML to science, simulations, optimizations, etc instead of general-purpose automation and capabilities that LLMs provide. reply muglug 21 hours agorootparentprevSo three years ago you'd spend less time with your kids in order to write a 2,000-line FOSS app for understanding Bash scripts? I'm not sure that's a good thing. reply aoeusnth1 20 hours agorootparentExactly, you agree: the lack of LLMs is not good. LLMs turned a bad outcome into a good one. reply muglug 17 hours agorootparentIt was a glib comment, but I fundamentally reject the premise that we'll have more personal time because of ChatGPT. It's like saying that buying a faster computer that compiles quicker means you can spend more time with your family. Theoretically true, but in practice people who are that way inclined can find myriad other ways to use the new technology to eat up time. reply aoeusnth1 16 hours agorootparentThe core of your attitude comes through here - that productivity is pointless, computers are worthless and coding is a waste of time. Anyone dismissing LLMs comes from a similar value system of hating technology, as far as I’m concerned. reply williamcotton 17 hours agorootparentprevLet's unravel what you've said here. You're saying that there is no way that I'm not a bad parent because I would have found a way to ignore my family regardless of some time saving device. Glib? That's not glib. That's just being a jerk. And fueled by what, your personal distaste for LLMs? People who are that way inclined? reply muglug 16 hours agorootparentI don't think you're a bad parent, but I do think you were using hyperbole when describing how much time ChatGPT saved you. I also don't believe that you would spend a week away from your kids to make a 1,200-line app that just explains how simple bash commands work. https://explainshell.com/ already does a pretty great job of that. I don't have a personal distate for LLMs — I use ChatGPT weekly and I work for a company that ships LLM-powered functionality that I use daily. But your comment implied that LLMs can today provide a big productivity improvement for developers, and that’s not something I think there’s any concrete evidence for. I do find the hype immensely distateful, especially in response to an article pointing to the environmental downsides of that excitement. reply williamcotton 15 hours agorootparentWhat I made is not like explainshell.com at all. It is a GUI for writing command pipelines. Updates to the prompt are parsed into an AST and used to update the GUI. Updates in the GUI are used to build an AST to update the prompt. I wrote it so I didn't have to keep writing things like this into the line editor: pg -d test_database -c 'SELECT * from test_table;'tsvtocsvggplot 'ggplot(df, aes(as.Date(date), value)) + geom_col(fill = \"red\") + labs(x = \"date\") + theme_minimal()'pngtohtml Instead, I could just type in the app: pgtsvtocsvggplotpngtohtml And then fill in the blanks with an instance of the Monaco code editor, looking like: https://github.com/williamcotton/guish/assets/13163/a5214e93... It's a small program but it's not a trivial task to get the UX working in a productive manner. I took plenty of the same wrong turns that I would have if I was writing it by hand but was able to iterate much more quickly. It's more exploratory in nature, seeing how text input and GUI input can complement each other in a novel manner. Sure, I could do this by embedding a SQL query in an R script or something but there's just something that rubs me the wrong way about embedding one language in another instead of having them work side by side. It's not \"just explaining how simple bash commands work\". So thank you for calling me a shitty parent and devaluing my work. You seem awesome. reply muglug 15 hours agorootparentI’m sure you’re a great parent, but you’re not a convincing advocate for the time-saving power of LLMs. Either way I was wrong — this project does look like a cool idea, and I’m sorry for dismissing it entirely. reply williamcotton 14 hours agorootparentApology accepted. And I'm sorry for getting heated! reply knowaveragejoe 22 hours agoparentprevFor what it's worth, all of that really useful AI you mention(and then some!) is attracting the kind of investment you want, you just don't hear about it because it's not interesting to the average person. reply ETH_start 22 hours agoparentprevThere is reason to be cautious about every kind of endeavor where the potential for enrichment can cloud judgment. However, the possibilities opened up by technologies this radical in the magnitude of the improvements they make in specific fundamental societal functions are enormous, and for that reason, they are on the balance massively beneficial, and that includes chat bots. reply piva00 21 hours agorootparent> However, the possibilities opened up by technologies this radical in the magnitude of the improvements they make in specific fundamental societal functions are enormous, and for that reason, they are on the balance massively beneficial, and that includes chat bots. The improvements it can be dreamed of to the bottom line of companies by replacing expensive labour are massive, that's why it got US$ 1tn Capex downed into it as noted in another article from Goldman Sachs shared today on HN. It doesn't mean it's massively beneficial to societal functions, a bigger case for that would be a clean, and massively cheap energy source (if fusion turned out to be viable and scalable, for example) but we don't see US$ 1tn poured into the pursuit of that because it does not promise improving companies' bottom line in a short time frame. AI can definitely turn out to be a panacea but more and more grifters are attaching themselves to it, and the companies churning out the most advances of it are not really invested in improving society as a whole, that's the marketing speak used but we in tech have seen those empty promises of utopian changes turning out to be just smoke and mirrors for the surveillance capitalism age to set in. reply TeMPOraL 21 hours agorootparent> AI can definitely turn out to be a panacea but more and more grifters are attaching themselves to it, and the companies churning out the most advances of it are not really invested in improving society as a whole I came to see the \"AI hype\" not as reminiscent of crypto-hype, but of dot-com boom. Lots of grifters attached themselves to this new Internet thing. Lots of bullshit products was made. Lots of people lost their shirt through this. That had no bearing on how useful the Internet was, and turned out to be. And so today, we also have a lot of AI-grifters, and this also doesn't mean the underlying tech is bogus. reply ETH_start 14 hours agorootparentprevReducing the need to expend expensive labor to produce goods/services is massively beneficial. It is the basis of all economic development and wage growth. reply seadan83 28 minutes agorootparentThis can also describe the great enshittification race of every good/product/service. The 'wage growth' part does not always follow. Middle-skilled laborers are still be pushed out of the economy. [1] [1] https://www.urban.org/sites/default/files/publication/31566/... (data is on pages 13, 20, 21 & 23) reply smus 21 hours agoparentprevI currently save so much time a day using chatbots lol reply sva_ 21 hours agoparentprevNot sure if energy use is a sufficient criteria to dismiss some technology. This universe progresses by turning low entropy energy into high entropy energy, which the use of energy is doing. So it seems to be closely tied. Making processes more energy-efficient is only really a good thing as long as it retains its effectiveness. reply lagrange77 21 hours agorootparent> Not sure if energy use is a sufficient criteria to dismiss some technology. This universe progresses by turning low entropy energy into high entropy energy, which the use of energy is doing. What is the connection between those two sentences? reply sva_ 19 hours agorootparentI think that things like intelligence and productivity are directly related to an increase in entropy. In this universe, we have a budget of entropy, and when it is used up, we're done for. We have to make our mark before that is the case, or the program that runs our simulation will just terminate with no result. It is a very pseudoscientific believe of mine, I guess. reply namaria 7 hours agorootparent> we have a budget of entropy In closed systems. The Universe doesn't seem to be a closed system. reply philipkglass 21 hours agoprevHere's the underlying report that this CNBC story is based on: https://www.gstatic.com/gumdrop/sustainability/google-2024-e... The key driver for the CO2 growth is \"scope 2\" emissions, mainly electricity demand from data centers. See pages 34-38 in the PDF for the definition of scope 2 emissions and overall progress on running data centers with carbon free energy. They're currently at 63% CFE, the same as in 2022, but absolute growth in electricity consumption also meant absolute growth in emissions from the other 37%. reply konschubert 30 minutes agoprevLuckily we have ways to create energy emissions-free. reply alecco 22 hours agoprevI don't like 2024 Google, but they seem to be the only ones trying (at least) to make the least impact with their energy consumption. Why aren't there hit pieces like this on the US intelligence massive Utah Data Center? (for example) reply bogota 22 hours agoparentI think it’s pretty clear that it’s easy to sell rage against companies right now. News just tells people what they want to hear in this age reply kortilla 22 hours agorootparentBecause the NSA doesn’t care about their public image or energy consumption. Google at one time did so this makes them pretty big hypocrites reply TaylorAlexander 22 hours agorootparentYeah. Public pressure might actually work against Google, but it’s unlikely to work against the NSA so easily. reply refulgentis 22 hours agorootparentI'm curious for your perspective: It seems clear that the article is not about arbitrary data center usage, it's about a large increase in data center usage at Google, attributable to AI. The initial premise of the thread was \"Why isn't this about (arbitrary data center other than Google)?\" Isn't that easily answered by: because it's about the delta, and the context of AI, where Google is perceived behind, and Satya famously pointed out the energy demands x their margins puts them in a strategic situation with only bad choices? Witb that context, do you believe this is attributable to someone picking what to write articles about, based on how much they'll be able to influence them to change their behavior? reply Jasper_ 22 hours agoparentprevWe can care about two things at the same time. This isn't a \"hit piece\", it's reporting on Google's own 2024 environmental report. reply asdasdsddd 22 hours agorootparentNo you can't that's why the attention economy is very competitive reply rtkwe 22 hours agoparentprevIt was talked about a lot when it was first opened, news massively biases towards new topics. reply rpeden 22 hours agorootparentBias toward new topics is why it's called news. Otherwise, we'd have to call it olds. reply kolinko 22 hours agoparentprevMS and Apple seem to be doing an awesome job as well reply zamalek 22 hours agoparentprevGrok's ASIC is pretty efficient afaik. reply skywhopper 21 hours agoparentprevThe NSA's data center is a drop in the bucket compared to the hundreds of similar data centers operated by Google, Amazon, Microsoft, Facebook, et al. And I would not call increasing your power consumption YoY by 13% or whatever it was to be \"trying\". To the extent they are trying, it's only to squeeze the value out of their real estate and to avoid blowing their transformers. They can spin that as \"saving energy\" until something like LLMs with their GPU requirements comes along. reply Am4TIfIsER0ppos 19 hours agorootparentAll those ones operated by google, amazon, and microsoft are operated for the NSA. They exist to spy on you. reply SpicyLemonZest 22 hours agoparentprevI don't think it's right to characterize this as a hit piece. They're reporting on a document Google published, using Google's numbers and framing. If Google didn't want people to talk about their carbon consumption they would presumably not have published this report. reply jeffbee 21 hours agoparentprevIt's because the NSA's \"massive\" datacenter is actually tiny, cannot contain the things that paranoid people think it contains, cannot do the things weirdos imagine it does. reply TheGamerUncle 21 hours agorootparentpretty sure lol that what snowden has shown reveals you are quite wrong reply refulgentis 22 hours agoparentprevWhat's new to me? A couple year ramp in phrasing like \"hit piece\" used to describe mundane news. Put another way: I see a ramp in use of hit piece for writing, where not writing, given you have the info, would be described as a cover up. reply jsiepkes 22 hours agoprevAnd once again a big tech company proves that as soon as their \"principes\" are put to the test they will abandon them almost instantly. When buying some wind energy was easy and wasn't really a trade-off they were quick to use big phrases like being \"committed to the planet\" and such. Commitments seem to be rather \"flexible\" with these companies. reply Culonavirus 22 hours agoparentMicrosoft: spends an absolute fortune on AI compute. Also Microsoft: Here, take this \"carbon aware\" Windows Update. reply ToucanLoucan 21 hours agorootparentI mean they're just doing what the oil companies did to great success for decades, the bullshit about buying a hybrid or electric car, or recycling^1 your plastic. Why reckon with the impact of your global industry on the planet and have to answer hard questions when you can just make it the consumers fault and guilt powerless people into using a canvas bag^2 instead of a plastic one, despite the fact that the only reason all the fucking plastic bags exist is because your company is making them by the billion? 1: If you want to get angry, look into what an utter farce plastic recycling is. 2: Not that reusable bags are a bad thing in the slightest, I just don't like being condescended to for using a free resource provided at point of sale by a multi-national conglomerate that's burning the world and then turning around to chide me for having a slightly older car than I otherwise could. reply moandcompany 22 hours agoparentprevThey said they were an \"AI-first company\" :) reply slashdave 21 hours agoprevIn my imagination, I picture a long-time Google employee who spent his/her entire career dutifully pouring over every minutia of their search infrastructure to squeeze the most performance out of every watt, in a quest to make Google a better, more environmentally friendly company. And then comes AI... reply xnx 20 hours agoparent> And then comes AI... And the optimization work they did is even more significant and useful? reply josefritzishere 22 hours agoprevThe galling part of this is that the demand for AI is artificial. Consumers are not demanding AI. reply umvi 22 hours agoparentI'm demanding more/better code-completion style AI for sure. It's an invaluable part of my workflow now and I'm happy paying a monthly fee for the service. reply skywhopper 21 hours agorootparentSure, but you are paying for that. It also has nothing to do with the bizarre and untrustworthy AI answers being shoved into Google and Bing search results, or Facebook's terrible AI search bar. reply moffkalast 20 hours agorootparentprevIt's become a really indispensable productivity boosting tool. Code, translation, broad research, summarization, writing drafts, finding that word you know but just can't remember, making up terrible puns... the list goes on. Hours of work compressed into a minute or two at most. reply brink 22 hours agoparentprevExactly. I was the first to adopt nearly every new technology in my family growing up. With AI, I query claude like twice a week for things that a search engine never gives to me straight like - \"How long do I cook a rack of ribs?\", but it's not something I'm about to pay $20/mo for, which is the only way that AI is sustainable. I use it sparingly, and I only use it because it's free. There's just not much appeal to something as unreliable as AI. reply seadan83 21 minutes agorootparentIf you don't know how long to cook a rack of ribs for - how will you know if the AI gave you a correct answer? > There's just not much appeal to something as unreliable as AI. Even your trivial example I would question regarding the unreliability. AI is probably only best for qualitative things, like touching up photos, identifying data patterns for humans to then investigate. Places where 1% inaccuracy leads to bad tasting rack of ribs, or outright incorrect answers - the fact LLMs are able to produce reasonable sounding answers is amazing - but not necessarily useful. reply peppertree 22 hours agoparentprevPretty sure people said the same about fiber internet in the 2000's. reply TaylorAlexander 22 hours agorootparentPeople also said the same thing about NFTs, and they were correct. I think “AI” will eventually have more consumer facing uses, but the current crop is incapable of telling truth from fiction which severely limits the appeal to Google’s main user base. OpenAI is riding on hope and it feels like Google is chasing after that application to avoid looking like they are behind, but it’s not clear that actual customer demand is looking for Google to offer such half baked technology. reply sva_ 21 hours agorootparentprev> A winner of the Nobel Prize in Economics, Paul Krugman wrote in 1998, “The growth of the Internet will slow drastically, as the flaw in ‘Metcalfe’s law’—which states that the number of potential connections in a network is proportional to the square of the number of participants—becomes apparent: most people have nothing to say to each other! By 2005 or so, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.” - https://www.laphamsquarterly.org/revolutions/miscellany/paul... reply omnicognate 21 hours agorootparentI'm all for doing down Nobel prize winning Paul Nobel prize winning Krugman and his Nobel prize (did you know he got a Nobel prize?) but as hideously as most of that has aged the bit about most people having nothing to say to each other was spot on. reply Jasper_ 22 hours agorootparentprevPeople said the same thing about the Segway, and 3D TVs, and NFTs reply organsnyder 22 hours agorootparentprevAnd that's still somewhat true. I'm up at our cottage right now, where we have 300mbps cable internet. The upstream is paltry (10mbps), but I haven't really felt it impacting my work (and my kids are still able to stream everything they'd like, too). Sure, I miss the 5gbps symmetrical we have at home, but in reality there's not a huge real impact. reply NovemberWhiskey 21 hours agorootparentprev... and they were right, and there was a massive destruction of capital invested in companies that installed dark fiber and went bankrupt. The difference was that the dark fiber then got lit later on, because it was useful physical infrastructure. The same cannot be said of the present AI boondoggles. reply givemeethekeys 22 hours agoparentprevBusinesses and wealthy people want AI so they can lay people off and hold onto their money, and build stuff faster to capture more marketshare / power. There wasn't demand for computers either. Or, the industrial revolution. AI is a competitive advantage for those that can leverage it. reply Swizec 22 hours agorootparentConsumers ask for AI all the time. Their requests sound like this: - \"Google search is drowned by SEO, I can't find anything anymore\" - \"Wow all these ads suck\" - \"Ugh my social media is full of hucksters and bots\" - \"My job applications all go into a black hole\" - \"LoL gmail can't even find emails I know are there\" - \"Ffs stop autocorrecting to duck\" - \"Oh wow we can't even say 'vagina' anymore because The Algorithm\" - \"Support doesn't even read my message, why do I bother\" - \"I can't keep up with all my inboxes\" - \"This meeting should've been an email\" - \"The press release makes no sense, can someone translate corporatespeak?\" - \"Ecomm sites are awful why can't I just find what I'm looking for?\" etc. We already use AI for all sorts of things. This will only accelerate. Half the things that used to be AI aren't even called AI anymore. That's because \"AI\" is a marketing label. When a technology becomes mundane, it ceases to be called AI and we find something new. reply Jasper_ 22 hours agorootparentThose sound like requests for not AI. > \"Google search is drowned by SEO, I can't find anything anymore\" It's now powered by AI. [0] > \"Wow all these ads suck\" Well, they're powered by AI. [1] > \"Ugh my social media is full of hucksters and bots\" Yeah, mostly because the social media feed is all low-effort stuff generated with AI. [2] > \"My job applications all go into a black hole\" Likely because of an AI screening tool. [3] [0] https://blog.google/products/search/how-ai-powers-great-sear... [1] https://ads.google.com/intl/en_us/home/campaigns/ai-powered-... [2] https://www.fastcompany.com/91113437/ai-making-meta-apps-bas... [3] https://compensationxl.com/companies-are-using-ai-in-their-h... reply singleshot_ 21 hours agorootparentprevAre you sure they’re asking for AI? It sounds to me like they are asking for the Internet to be turned off. reply foooorsyth 22 hours agoparentprevChatGPT is the fastest product in history to reach 100M MAUs. https://finance.yahoo.com/news/chatgpt-on-track-to-surpass-1... Consumers are definitely demanding something like ChatGPT. Other companies are trying to ride the wave, and their attempts often feel forced as they’re trying to inject LLMs where they don’t really belong. reply llama_drama 20 hours agorootparentIs it possible, in general, to know where something belongs — whether it's an LLM or anything else — before you try? reply philipwhiuk 21 hours agorootparentprevIt was/is free. All that proves is people have faster access to news. Lets see what it's DAUs are on a long term basis. reply speedgoose 22 hours agoparentprevSource? reply morkalork 22 hours agorootparentGemini's terrible search answers didn't become a viral meme because people liked and appreciated it. reply rqtwteye 21 hours agoparentprevConsumers were not demanding the internet or computers either. But it turns out they were useful for consumers and especially for the profits of capitalists. People may not like it but AI will be an important part of our lives soon. reply SpicyLemonZest 22 hours agoparentprevHow would you describe the behavior of Character.AI's millions of users if not demand? Who's paying OpenAI their billions of revenue? You can argue about how durable the demand for AI is, but I don't see how it's tenable anymore to claim it doesn't exist. reply ceejayoz 22 hours agorootparent> How would you describe the behavior of Character.AI's millions of users if not demand? \"Disturbing\"? reply SpicyLemonZest 22 hours agorootparentIt seems to me that \"I'm disturbed by consumer demand for AI\" is different than and contradictory to \"consumers are not demanding AI\". reply nytesky 20 hours agorootparentprevYou ask a good question. Who is paying for AI, and is OpenAI profitable. A lot of the demand is there when cost is subsidized by investors -- will it continue when price actually must bare costs and profits? reply xnx 21 hours agoprevGoogle's latest environmental report posted today: https://blog.google/outreach-initiatives/sustainability/2024... reply zamalek 22 hours agoprevIt turns out AI will kill us, but not in the way that the billionaires were paranoid about. Who needs guns when a planet-sized gas chamber will do? reply gmm1990 22 hours agoparentthe infinite paper clip machine concept was prescient reply seydor 22 hours agoprevScaling hypothesis baby! maybe the bitter lesson wasn't so bitter after all reply MicolashKyoka 22 hours agoprevmeaningless stat in the grand scheme of things. eventually, it will all transition to nuclear/solar. the question is does it move the needle in a meaningful way right now. so much hand wringing about carbon emissions only for germany to end up burning coal again. reply timeon 21 hours agoparentGermany meme is nice, but it is probably just a dent in global coal use that breaks new record almost every year. Transition to nuclear/solar is still fantasy. https://ourworldindata.org/energy-production-consumption https://app.electricitymaps.com/map reply westurner 19 hours agoprevA few solutions for this: - \"How to reuse waste heat and water from AI datacenters?\" (2024) https://news.ycombinator.com/item?id=40820952 - \"Can CPUs etc. be made from just graphene and/or other carbon forms?\" (2024) https://news.ycombinator.com/item?id=40719725 (Edit) - \"Desalination system could produce freshwater that is cheaper than tap water\" (2023) : \"Extreme salt-resisting multistage solar distilation with thermohaline convection\" (2023) https://news.ycombinator.com/item?id=39999225 ... \"AI Is Accelerating the Loss of Our Scarcest Natural Resource: Water\" https://news.ycombinator.com/item?id=40783690 - \"Does mounting servers parallel with the temperature gradient trap heat?\" (2020) https://news.ycombinator.com/item?id=23033210 : > Would mounting servers sideways (vertically) allow heat to transfer out of the rack? https://news.ycombinator.com/item?id=39555606 reply westurner 16 hours agoparent- Concrete parking lot TPV Thermal Solar canopies, And concrete supercapacitor batteries: https://news.ycombinator.com/item?id=40862190 reply strangattractor 22 hours agoprev [–] So this is why people eventual become batteries for the matrix. reply jbandela1 22 hours agoparent [–] Apparently, instead of batteries the original idea was to have them be part of a brain based neural net which makes a lot more sense than batteries. But this was felt to be too complicated. reply Rinzler89 22 hours agorootparentExactly. Why they gave up on the human collective neural net movie plot and replaced it with the human batteries one is beyond me. It makes no sense, humans make terrible batteries. If the machines from the Matrix needed to use some mammals as batteries, why not just use cows instead of humans? They'd be much more complacent with living in the Matrix, grazing on virtual fields, and less likely to wise up and try to escape and rebel against the machines since they're not very intelligent and the machines would need a lot less processing power to simulate a realistic cow world than the world in 1999 for humans. To wit, if someone has access to a lot of GPU compute, could you please use gen-AI to re-make the Matrix but with the characters as cows, I'd pay to watch it. Would definitely beat Matrix Resurrections or whatever that cash grab turd was called. reply jimbobthrowawy 21 hours agorootparentIt's an easy analogy to say in <10 seconds that non-technical people can understand. Had they not mentioned \"bioelectricity\" at all, it might have been harder to nitpick. reply affgrff3 21 hours agorootparentprevI came up with this explanation to make me enjoy the movie more: The world outside the matrix is not the real world, but just another layer by the machines for obfuscation. In the real real world humans are actually used as processing units but since it is easier for the humans to accept and not ask further questions, the intermediate level with humans as batteries is introduced by the machines. reply triceratops 19 hours agorootparentprevIsn't there a long-standing myth that humans only use 10% of their brainpower? They could've used that to explain that the machines were stealing the other 90%. Anyone can understand that in 5 seconds. Of course that means anyone unplugged from the Matrix would immediately become an S-tier genius. And how the hell do you write that? reply hangonhn 22 hours agorootparentprevWow. Thanks for sharing that. I was always bothered by that aspect of the movie but your explanation makes a lot more sense. reply scotty79 22 hours agorootparentprev [–] Wow, it would make so much more sense. Humans could be doing processing for AI when they are asleep in virtual world and what they consider their waking hours with free will would be actually a dream so they can regenerate. AI would be syncing their dreams and providing structure to maintain illusion that it's a real world. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google's carbon emissions increased by nearly 50% compared to 2019, as reported in its 2024 environmental report, challenging its net-zero emissions goal by 2030.",
      "The rise in emissions is primarily due to higher energy consumption in data centers and supply chain emissions driven by AI advancements, with a 17% increase in data center electricity consumption in 2023.",
      "Despite these challenges, Google is committed to reducing its environmental impact through efficient infrastructure and emissions reductions, a challenge also faced by other tech companies like Microsoft due to AI demand."
    ],
    "commentSummary": [
      "Google's carbon emissions have risen by 13% since last year, primarily due to increased energy consumption in data centers and supply chain emissions.",
      "There has been a 48% increase in emissions compared to 2019, but this rise is not solely attributable to AI, despite some headlines suggesting otherwise.",
      "The increase in emissions has been gradual over the years, and the specific impact of AI on this rise remains unclear."
    ],
    "points": 149,
    "commentCount": 108,
    "retryCount": 0,
    "time": 1719950875
  },
  {
    "id": 40861148,
    "title": "The Illustrated Transformer (2018)",
    "originLink": "https://jalammar.github.io/illustrated-transformer/",
    "originBody": "The Illustrated Transformer Discussions: Hacker News (65 points, 4 comments), Reddit r/MachineLearning (29 points, 3 comments) Translations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese Watch: MIT’s Deep Learning State of the Art lecture referencing this post Featured in courses at Stanford, Harvard, MIT, Princeton, CMU and others In the previous post, we looked at Attention – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their Cloud TPU offering. So let’s try to break the model apart and look at how it functions. The Transformer was proposed in the paper Attention is All You Need. A TensorFlow implementation of it is available as a part of the Tensor2Tensor package. Harvard’s NLP group created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter. 2020 Update: I’ve created a “Narrated Transformer” video which is a gentler approach to the topic: A High-Level Look Let’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another. Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them. The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number. The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers: The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We’ll look closer at self-attention later in the post. The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in seq2seq models). Bringing The Tensors Into The Picture Now that we’ve seen the major components of the model, let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output. As is the case in NLP applications in general, we begin by turning each input word into a vector using an embedding algorithm. Each word is embedded into a vector of size 512. We'll represent those vectors with these simple boxes. The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below. The size of this list is hyperparameter we can set – basically it would be the length of the longest sentence in our training dataset. After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder. Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder. Now We’re Encoding! As we’ve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder. The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately. Self-Attention at a High Level Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works. Say the following sentence is an input sentence we want to translate: ”The animal didn't cross the street because it was too tired” What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm. When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”. As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. As we are encoding the word \"it\" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on \"The Animal\", and baked a part of its representation into the encoding of \"it\". Be sure to check out the Tensor2Tensor notebook where you can load a Transformer model, and examine it using this interactive visualization. Self-Attention in Detail Let’s first look at how to calculate self-attention using vectors, then proceed to look at how it’s actually implemented – using matrices. The first step in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process. Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant. Multiplying x1 by the WQ weight matrix produces q1, the \"query\" vector associated with that word. We end up creating a \"query\", a \"key\", and a \"value\" projection of each word in the input sentence. What are the “query”, “key”, and “value” vectors? They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays. The second step in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position. The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2. The third and fourth steps are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1. This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word. The fifth step is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example). The sixth step is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word). That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level. Matrix Calculation of Self-Attention The first step is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV). Every row in the X matrix corresponds to a word in the input sentence. We again see the difference in size of the embedding vector (512, or 4 boxes in the figure), and the q/k/v vectors (64, or 3 boxes in the figure) Finally, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer. The self-attention calculation in matrix form The Beast With Many Heads The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways: It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to. It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace. With multi-headed attention, we maintain separate Q/K/V weight matrices for each head resulting in different Q/K/V matrices. As we did before, we multiply X by the WQ/WK/WV matrices to produce Q/K/V matrices. If we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix. How do we do that? We concat the matrices then multiply them by an additional weights matrix WO. That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence: As we encode the word \"it\", one attention head is focusing most on \"the animal\", while another is focusing on \"tired\" -- in a sense, the model's representation of the word \"it\" bakes in some of the representation of both \"animal\" and \"tired\". If we add all the attention heads to the picture, however, things can be harder to interpret: Representing The Order of The Sequence Using Positional Encoding One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence. To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention. To give the model a sense of the order of the words, we add positional encoding vectors -- the values of which follow a specific pattern. If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this: A real example of positional encoding with a toy embedding size of 4 What might this pattern look like? In the following figure, each row corresponds to a positional encoding of a vector. So the first row would be the vector we’d add to the embedding of the first word in an input sequence. Each row contains 512 values – each with a value between 1 and -1. We’ve color-coded them so the pattern is visible. A real example of positional encoding for 20 words (rows) with an embedding size of 512 (columns). You can see that it appears split in half down the center. That's because the values of the left half are generated by one function (which uses sine), and the right half is generated by another function (which uses cosine). They're then concatenated to form each of the positional encoding vectors. The formula for positional encoding is described in the paper (section 3.5). You can see the code for generating positional encodings in get_timing_signal_1d(). This is not the only possible method for positional encoding. It, however, gives the advantage of being able to scale to unseen lengths of sequences (e.g. if our trained model is asked to translate a sentence longer than any of those in our training set). July 2020 Update: The positional encoding shown above is from the Tensor2Tensor implementation of the Transformer. The method shown in the paper is slightly different in that it doesn’t directly concatenate, but interweaves the two signals. The following figure shows what that looks like. Here’s the code to generate it: The Residuals One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a layer-normalization step. If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this: This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this: The Decoder Side Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together. The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence: After finishing the encoding phase, we begin the decoding phase. Each step in the decoding phase outputs an element from the output sequence (the English translation sentence in this case). The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word. The self attention layers in the decoder operate in a slightly different way than the one in the encoder: In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to -inf) before the softmax step in the self-attention calculation. The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack. The Final Linear and Softmax Layer The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer. The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector. Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer. The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step. This figure starts from the bottom with the vector produced as the output of the decoder stack. It is then turned into an output word. Recap Of Training Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model. During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output. To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “” (short for ‘end of sentence’)). The output vocabulary of our model is created in the preprocessing phase before we even begin training. Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector: Example: one-hot encoding of our output vocabulary Following this recap, let’s discuss the model’s loss function – the metric we are optimizing during the training phase to lead up to a trained and hopefully amazingly accurate model. The Loss Function Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”. What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet. Since the model's parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model's weights using backpropagation to make the output closer to the desired output. How do you compare two probability distributions? We simply subtract one from the other. For more details, look at cross-entropy and Kullback–Leibler divergence. But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where: Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000) The first probability distribution has the highest probability at the cell associated with the word “i” The second probability distribution has the highest probability at the cell associated with the word “am” And so on, until the fifth output distribution indicates ‘’ symbol, which also has a cell associated with it from the 10,000 element vocabulary. The targeted probability distributions we'll train our model against in the training example for one sample sentence. After training the model for enough time on a large enough dataset, we would hope the produced probability distributions would look like this: Hopefully upon training, the model would output the right translation we expect. Of course it's no real indication if this phrase was part of the training dataset (see: cross validation). Notice that every position gets a little bit of probability even if it's unlikely to be the output of that time step -- that's a very useful property of softmax which helps the training process. Now, because the model produces the outputs one at a time, we can assume that the model is selecting the word with the highest probability from that probability distribution and throwing away the rest. That’s one way to do it (called greedy decoding). Another way to do it would be to hold on to, say, the top two words (say, ‘I’ and ‘a’ for example), then in the next step, run the model twice: once assuming the first output position was the word ‘I’, and another time assuming the first output position was the word ‘a’, and whichever version produced less error considering both positions #1 and #2 is kept. We repeat this for positions #2 and #3…etc. This method is called “beam search”, where in our example, beam_size was two (meaning that at all times, two partial hypotheses (unfinished translations) are kept in memory), and top_beams is also two (meaning we’ll return two translations). These are both hyperparameters that you can experiment with. Go Forth And Transform I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps: Read the Attention Is All You Need paper, the Transformer blog post (Transformer: A Novel Neural Network Architecture for Language Understanding), and the Tensor2Tensor announcement. Watch Łukasz Kaiser’s talk walking through the model and its details Play with the Jupyter Notebook provided as part of the Tensor2Tensor repo Explore the Tensor2Tensor repo. Follow-up works: Depthwise Separable Convolutions for Neural Machine Translation One Model To Learn Them All Discrete Autoencoders for Sequence Models Generating Wikipedia by Summarizing Long Sequences Image Transformer Training Tips for the Transformer Model Self-Attention with Relative Position Representations Fast Decoding in Sequence Models using Discrete Latent Variables Adafactor: Adaptive Learning Rates with Sublinear Memory Cost Acknowledgements Thanks to Illia Polosukhin, Jakob Uszkoreit, Llion Jones , Lukasz Kaiser, Niki Parmar, and Noam Shazeer for providing feedback on earlier versions of this post. Please hit me up on Twitter for any corrections or feedback. Written on June 27, 2018",
    "commentLink": "https://news.ycombinator.com/item?id=40861148",
    "commentBody": "The Illustrated Transformer (2018) (jalammar.github.io)145 points by debdut 20 hours agohidepastfavorite7 comments xianshou 17 hours agoIllustrated Transformer is amazing as a way of understanding the original transformer architecture step-by-step, but if you want to truly visualize how information flows through a decoder-only architecture - from nanoGPT all the way up to a fully represented GPT-3 - nothing beats this: https://bbycroft.net/llm reply cpldcpu 13 hours agoparentwhoa, that's awesome. reply ryan-duve 19 hours agoprevI gave a talk on using Google BERT for financial services problems at a machine learning conference in early 2019. During my preparation, this was the only resource on transformers I could find that was even remotely understandable to me. I had a lot of trouble understand what was going on from just the original publication[0]. [0] https://arxiv.org/abs/1706.03762 reply isaacfung 12 hours agoparentMaybe it's easier to understand in the format of annotated code https://nlp.seas.harvard.edu/2018/04/03/attention.html reply andoando 18 hours agoparentprevMaybe Im dumb but I still can't make much sense of this. reply crystal_revenge 4 hours agoprevWhile I absolutely love this illustration (and frankly everything Jay Alammar does), it is worth recognizing there is a distinction between visualizing how a transformer (or any model really works) and what the transformer is doing. My favorite article on the latter is Cosma Shalizi's excellent post showing that all \"attention\" is really doing is kernel smoothing [0]. Personally having this 'click' was a bigger insight for me than walking through this post and implementing \"attention is all you need\". In a very real sense transformers are just performing compression and providing a soft lookup functionality on top of an unimaginably large dataset (basically the majority of human writing). This understanding of LLMs helps to better understand their limitations as well as their, imho untapped, usefulness. 0. http://bactra.org/notebooks/nn-attention-and-transformers.ht... reply jerpint 18 hours agoprev [–] I go back regligiously to this post whenever I need a quick visual refresh on how transformers work, I can’t overstate how fantastic it is reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post delves into The Transformer model, which uses attention mechanisms to enhance training speed and performance, surpassing the Google Neural Machine Translation model in specific tasks.",
      "The Transformer model, detailed in the paper \"Attention is All You Need,\" has implementations in TensorFlow (Tensor2Tensor package) and PyTorch (Harvard’s NLP guide), and is recommended by Google Cloud for their Cloud TPU offering.",
      "The model's architecture includes encoding and decoding components with self-attention and multi-headed attention layers, allowing it to focus on relevant parts of the input and improve translation accuracy."
    ],
    "commentSummary": [
      "\"The Illustrated Transformer\" by Jay Alammar is highly praised for its step-by-step explanation of the original transformer architecture.",
      "For visualizing information flow in decoder-only architectures like GPT-3, bbycroft.net is recommended.",
      "Users suggest annotated code from Harvard's NLP site for a deeper understanding of transformers, emphasizing the importance of grasping underlying mechanics like attention mechanisms."
    ],
    "points": 145,
    "commentCount": 7,
    "retryCount": 0,
    "time": 1719960120
  },
  {
    "id": 40861057,
    "title": "Brazil data regulator bans Meta from mining data to train AI models",
    "originLink": "https://apnews.com/article/brazil-tech-meta-privacy-data-93e00b2e0e26f7cc98795dd052aea8e1",
    "originBody": "By ELÉONORE HUGHES Updated 7:01 PM UTC, July 2, 2024 Share Share Copy Link copied Email Facebook X Reddit LinkedIn Pinterest Flipboard Print RIO DE JANEIRO (AP) — Brazil’s national data protection authority determined on Tuesday that Meta, the parent company of Instagram and Facebook, cannot use data originating in the country to train its artificial intelligence. Meta’s updated privacy policy enables the company to feed people’s public posts into its AI systems. That practice will not be permitted in Brazil, however. The decision stems from “the imminent risk of serious and irreparable or difficult-to-repair damage to the fundamental rights of the affected data subjects,” the agency said in the nation’s official gazette. Brazil is one of Meta’s biggest markets. Facebook alone has around 102 million active users in the country, the agency said in a statement. The nation has a population of 203 million, according to the country’s 2022 census. A spokesperson for Meta said in a statement the company is “disappointed” and insists its method “complies with privacy laws and regulations in Brazil.” “This is a step backwards for innovation, competition in AI development and further delays bringing the benefits of AI to people in Brazil,” the spokesperson added. RELATED COVERAGE California advances unique safety regulations for AI companies despite tech firm opposition European Union accuses Facebook owner Meta of breaking digital rules with paid ad-free option Internet group sues Georgia to block law requiring sites to gather data on sellers The social media company has also encountered resistance to its privacy policy update in Europe, where it recently put on hold its plans to start feeding people’s public posts into training AI systems — which was supposed to start last week. In the U.S., where there’s no national law protecting online privacy, such training is already happening. Meta said on its Brazilian blog in May that it could “use information that people have shared publicly about Meta’s products and services for some of our generative AI features,” which could include “public posts or photos and their captions.” Refusing to partake is possible, Meta said in that statement. Despite that option, there are “excessive and unjustified obstacles to accessing the information and exercising” the right to opt out, the agency said in a statement. Meta did not provide sufficient information to allow people to be aware of the possible consequences of using their personal data for the development of generative AI, it added. Meta isn’t the only company that has sought to train its AI systems on data from Brazilians. Human Rights Watch released a report last month that found that personal photos of identifiable Brazilian children sourced from a large database of online images — pulled from parent blogs, the websites of professional event photographers and video-sharing sites such as YouTube — were being used to create AI image-generator tools without families’ knowledge. In some cases, those tools have been used create AI-generated nude imagery. Hye Jung Han, a Brazil-based researcher for the rights group, said in an email Tuesday that the regulator’s action “helps to protect children from worrying that their personal data, shared with friends and family on Meta’s platforms, might be used to inflict harm back on them in ways that are impossible to anticipate or guard against.” But the decision regarding Meta will “very likely” encourage other companies to refrain from being transparent in the use of data in the future, said Ronaldo Lemos, of the Institute of Technology and Society of Rio de Janeiro, a think-tank. “Meta was severely punished for being the only one among the Big Tech companies to clearly and in advance notify in its privacy policy that it would use data from its platforms to train artificial intelligence,” he said. Compliance must be demonstrated by the company within five working days from the notification of the decision, and the agency established a daily fine of 50,000 reais ($8,820) for failure to do so.",
    "commentLink": "https://news.ycombinator.com/item?id=40861057",
    "commentBody": "Brazil data regulator bans Meta from mining data to train AI models (apnews.com)137 points by emersonrsantos 20 hours agohidepastfavorite48 comments benreesman 18 hours agoThis proposal gets made pretty frequently in one form or another, and (at least on HN) seems to usually get struck down on this or that procedural ground. But as the various regulatory and judicial and legislative processes grind through different parts of the modern intellectual property issue made so abundantly legible by the modern AI training data gold rush it seems ever more clear that one way or another, we’re going to get a new social contract on IP. Leaving aside for a moment the thicket of laws, precedents, jurisdictions, and regulatory inertia: we can vote with our feet as both customers and contributors for common sense now. So how about the following compromise: promote innovation by liberalizing the posture around training on roughly “the commons”, but insist that the resulting weights are likewise available to the public. Why do I have to take someone’s word for it that they’ve got a result around superposition or whatever on mech interp? I’d like to see it work given it’s everyone’s data pushing those weights. I speak only for myself but plenty of people seem to agree: I don’t mind big companies training on generally available data, I mind the IP-laundering. Compete on cost, compete on value-added software stacks, compete on vertical integration. There is lots of money to be made building a better mousetrap in terms of code and infrastructure and product innovation. Conduct the research in the open. None of this would be possible without an ocean of research and data subsidized in whole or in part by the public. Asserting any form of ownership over the result might end up being legal, but it will never be ethical. Meta isn’t perfect on this stuff, but they’re by far the actor pulling the conversation in that direction. Let’s encourage them to continue pushing the pace on stuff like LLaMA 3. reply luqtas 18 hours agoparent> But as the various regulatory and judicial and legislative processes grind through different parts of the modern intellectual property issue made so abundantly legible by the modern AI training data gold rush it seems ever more clear that one way or another, we’re going to get a new social contract on IP. what do you mean by that? as far i'm aware ANYTHING that you publish despite being on the internet or not, if there isn't a copyright notice, you should assume -> \"all rights reserved\" reply sitharus 17 hours agorootparentYes, that's correct. Under the Berne Convention all copyright for a work and any derivatives is held with the author, unless the explicitly disclaim it or another legal provision applies (eg fair use for teaching or parody). However, does an LLM count as a derivative work or a transformative one? That's something for the lawyers to answer. reply rectang 16 hours agorootparentThis has an easy answer — it’s just not the one that people who desperately want to use LLMs for copyright washing want to hear. The test for what constitutes a derivative work has not changed; it’s the same whether a single human author produced something, or a team of humans, or an LLM. It will be up to a court to decide whether a work is similar enough to be considered derivative. If an LLM spits out a verbatim copy, that’s obviously infringement. But if the LLM spits out something similar? Well if the LLM spits out something like George Harrison’s My Sweet Lord [1], a court may well decide that it’s derivative of He’s So Fine. Especially if the LLM “subconsciously” “knew” about He’s So Fine because it was part of the training corpus. [1] https://en.wikipedia.org/wiki/My_Sweet_Lord#Copyright_infrin... reply luqtas 17 hours agorootparentprevwhat are the opinions on [0]? what's the scene for language rather than image? also what are the opinions on turning generative AI (that doesn't ask permission to creators) public domain? donation money that surpasses the cost of hosting the work to people/groups \"creating\" with AI, should be a violation of the license? are you allowed to play with the models in hardware made by for-profit entities, like Nvidia? [0] https://arxiv.org/abs/2212.03860 reply stoniejohnson 17 hours agorootparentprevobligatory IANAL, but seeing LLMs: - regurgitate entire passages word for word, until that behavior is publicized and quickly RLHF'd away - rip github repos almost entirely (some new Sonnet 3.5 demos Anthropic employees were bragging about on Twitter were basically 1:1 to a person's public repo) It seems clear to me that not only can copyrighted work be retained and returned in near entirety by the architectures that undergird current frontier models, but the engineers working on these models will readily confuse a model regurgitating work to be \"creating novel work\". reply catlikesshrimp 17 hours agorootparentprev>> derivative work or a transformative one? This isn't solved even for humans. There are trials that clear misunderstandings about fair use. (Every developer here has heard of this one: https://en.m.wikipedia.org/wiki/Google_LLC_v._Oracle_America....) Artificial Intelligence currently has no concept of responsibility (not legal, not ethical), and it will never have existential threats derived from law. The only way that I can think of, as of right now, is that every single product touched by AI must have a human who is legally responsible for it. reply tensor 17 hours agoparentprevIf I post something publically I'm fine with everyone being able to use it for AI and other data mining. But I'm not ok for a single company only to benefit. And definitely not to sell my public data. I'm looking at you reddit. reply Osmose 16 hours agoparentprevLLMs are not a general public benefit. Artists whose work is trained upon by text-to-image models aren't made any more whole just because Meta has to share its weights—it just means it's even cheaper for the folks impersonating them or effortlessly ripping off their style to keep doing so. Meta really does not need to be subsidized when they have so many resources at hand—if LLMs are really hard to train without that much data, then perhaps that's a flaw with the approach instead of something the world has to accommodate. reply ronsor 18 hours agoparentprevReforming the social contract around IP became infinitely difficult the moment normal people started calling it \"intellectual property\", forming a tangled mess of legal, moral, and ethical ideas in most people's minds. Your compromise is exactly the situation I desire but seems untenable to most people. reply diego_sandoval 16 hours agoparentprev> training on roughly “the commons”, The proposal in the article, however, is not about \"the commons\", it's about content that the users themselves produced, and then they voluntarily gave permission to Meta to use. Or are you saying that if I produce some type of material, I shouldn't be able to license it for someone else to use it freely? reply jononor 12 hours agorootparentVoluntarily gave permission? Meta never asked anyone for permission to use the AI as training data! They just opted in every single user, via an update of their privacy policy. In order to opt out you have to discover that this is happening, find the help page with the protest form, write some prose about why this negatively affects you, and hope they acknowledge this. I have done this, and my request has not even been answered. reply hansvm 7 hours agorootparentprev> and then they voluntarily gave permission to Meta to use That's a funny way to describe DNT headers, disallowed Meta cookies, DNS blocking all their domains, and maintaining copyright over my content. reply benatkin 17 hours agoparentprev> I speak only for myself but plenty of people seem to agree: I don’t mind big companies training on generally available data, I mind the IP-laundering. This removes the big scary emotional part of the debate. Without this, it's weakened quite a bit. reply AlienRobot 17 hours agoparentprev> I don’t mind big companies training on generally available data, I mind the IP-laundering large platforms saw AI and instantly closed their platforms making it hard or impossible for external actors to mine that \"generally available data,\" hurting their own users and the open web in the process, and then they mined the data themselves. reply Art9681 16 hours agorootparentAs long as a \"user\" can access those platforms then that data can and will be mined. The people working on such solutions just dont publish them publicly until the debate is settled. If I can view information on any website, authenticated or not, then I can build a bot that will do the same. This does not mean its being done for nefarious reasons. Simply automating the process of bringing what I consider valuable information to me is enough motivation to do it. In my case, the only profit I make is saving time not manually clicking around to access the data I read over morning coffee. The internet routes around censorship. Its impossible to hide information as long as its meant to be accessed by a human. If companies want to spend engineering hours putting locks then thats their waste. Many businesses will fail by wasting time and money creating locks that can and will be circumvented. I agree that a new social contract is inevitable because the only way to prevent data from being mined is to not produce it to begin with. Period. This I know. reply AlienRobot 16 hours agorootparentWhen I was young I used to upload fan art of Naruto to DeviantArt. My badly scanned drawings sucked. Everyone else's sucked. It was cool. Today DeviantArt has its own AI which it promotes over their own users' work. I've read some threads by artists discussing where to go next, between DA, Instagram, ArtStation, and several other new and likely not much better platforms, and one comment that struck me was someone saying it was just not worth it, and their time was better spent networking offline at a gallery. AI art might actually kill online art communities. AI-generated articles might kill online publishing. AI-generated spam bots might kill social media. We've taken the Internet for granted as grandma and grandpa joined it. Tomorrow people may just get sick of all these algorithms, let go of their smartphones, and go touch some grass. Then every website is just going to be AI bots regurgitating each others' content ad nauseum. Humans are on the web because of the reach. If AI-generated content steals all the reach, why would anyone post anything on publicly accessible venues instead of just using private ones? \"A new social contract is inevitable because the only way to prevent data from being mined is to not produce it to begin with.\" But is it though? You are assuming that \"not produce it to begin with\" is impossible. I'm afraid it's not impossible and the web experiment is at real danger. Maybe not immediately, but will it survive another 20 years in this environment? reply __loam 18 hours agoparentprevA lot of that \"commons\" was the work of people who gave absolutely no permission for their data to be used like this, that is, creating a machine intended to compete with them. My hope is we collectively tell these freeloading ass holes to pound sand. Public does not mean limitless license. reply golergka 18 hours agoparentprev> So how about the following compromise: promote innovation by liberalizing the posture around training on roughly “the commons”, but insist that the resulting weights are likewise available to the public. How much would you personally invest in a startup which would spend billions of dollars on a compute cluster only to release the weights publicly after the training is complete? reply jampekka 18 hours agorootparentI'm gladly investing portion of my wages to such efforts, alongside e.g. education, healthcare, childcare and infrastructure. And I don't even want any monetary ROI from my investment! reply golergka 17 hours agorootparentSo your plan is to regulate it into complete commercial unviability, where the only source of funding were government bureaucrats? How often does this strategy pay off? reply thfuran 16 hours agorootparentHow commercially viable is a public library? reply golergka 14 hours agorootparentIt only exists because it's commercially viable to print and sell books. Also, how much capital does a single library and a single frontier llm require? reply mistrial9 18 hours agorootparentprevthink of the Investors ! reply __loam 18 hours agorootparentHe's making a good point. 100m was invested in stability. They are out of money with no clear path to product market fit after giving their model away for free. I'm personally ecstatic that they failed but it is worth asking about the value this technology is producing compared to the cost. reply golergka 18 hours agorootparentprevI really appreciate that retired teachers and miners have something to live on, yes. reply Cheer2171 18 hours agoprev> Compliance must be demonstrated by the company within five working days from the notification of the decision, and the agency established a daily fine of 50,000 reais ($8,820) for failure to do so. $8,820 * 365 = $3.2 million a year is pretty cheap for Meta to be able to do whatever they want with all the data from all 200 million Brazilians. Their annual net income is $39.10 billion, so 0.008%. reply alganet 15 hours agoparentThis is the heads up fine _just_ to update the privacy policy. It's a mere warning. The fine for each privacy infraction is 2% of the company's last year earnings, limited to 50 million BRL (~9 million USD). If 500 brazillians had their privacy violated by a platform, that platform needs to pay 500 of these fines once per day until it is fixed. There's also all sorts of extra punishments for not fixing it in time (like mandatory suspension of services). Facebook is not forbidden to use your data for AI. It can do so, as long as it provide means for you to delete it. A button to clean your data, for example. That would be legal. We know for LLMs is not that easy though. reply Nition 16 hours agoparentprevI hereby also ban Facebook from accessing my data to train AI. I'm sure it would be a big hassle to carefully exclude me from all their models, but I'm generously offering an alternative non-compliance fine of only $50/day, paid to my bank account. reply vitorgrs 13 hours agoparentprevPretty sure that's per user (usually the other fines they already did, were like that) reply Waterluvian 18 hours agoparentprevIt’s not a Blockbuster Video. They’ll eventually increase the penalty for noncompliance or escalate the kind of punishment. reply LoganDark 17 hours agorootparentAre there any cases of this actually happening? reply diegoholiveira 17 hours agorootparentprevwith half the fine, Meta buys the entire Brazilian supreme court and suddenly: no fines, no jail and everyone will be happy. reply delichon 17 hours agoprevSo we're in for an eternal cat and mouse game where AIs attempt to learn all the facts available and obscure their provenance as needed to evade restrictions, and IP owners attempt to prove that AIs know too much and therefore owe them money. reply nostromo 18 hours agoprevWhat problem does this solve? The article only mentions that data could be used to train AI to make CSAM... which seems needlessly alarmist and inflammatory. reply cassianoleal 6 hours agoparentI don't see any mention of CSAM in the article. OTOH, this is how the third paragraph reads verbatim: > The decision stems from “the imminent risk of serious and irreparable or difficult-to-repair damage to the fundamental rights of the affected data subjects,” the agency said in the nation’s official gazette. reply yallpendantools 16 hours agoprevHonestly, I'm rather frustrated by the HN discourse on this topic. TFA (with emphasis added): > Brazil’s national *data protection* authority determined on Tuesday that Meta, the parent company of Instagram and Facebook, cannot use data originating in the country to train its artificial intelligence. > The decision stems from “the imminent risk of serious and irreparable or difficult-to-repair damage to the fundamental rights of the affected data subjects,” the agency said in the nation’s official gazette. https://www.theregister.com/2024/06/14/meta_eu_privacy/ (with emphasis added): > The decision to halt AI training using EU content follows complaints to *data protection* agencies in 11 European countries – and those agencies, led by Ireland, telling the Facebook giant to scrap the slurp. While there is no shortage of IP, licensing, and copyright moral quandaries in training LLMs and their ilk, Meta/FB is not getting regulated on those grounds! They are getting regulated on privacy issues. It's even there on The Register path. I'm seeing a lot of comments in these threads about IP, copyright, and licensing---which, please do take note, are well-defined legal terms and are not to be used interchangeably---but all that is irrelevant because that is not the question Meta is being made to answer for. Even more frustrating are threads/arguments to what \"irrevocable (copy)rights\" you give FB per their TOS without even bothering to cite the relevant bits of the TOS to prove their point. Exercise to the reader: prove/disprove that [a] FB users retain copyright of their content even when posted to FB and [b] you are merely licensing FB to specific (not universal!) uses of your content posted in their platform and [c] said license is revocable any time. The astute reader is referred to the Berne Convention but Facebook's TOS will also do just fine. Standard question, one point per answer. Bonus point question: if you have proven the points above, what action allows you to revoke the license you have granted FB? (Of course, end of the day, I'm again playing lawyer in an online forum. I'm no better than anyone else here what do I know.) reply throwaway957 13 hours agoprev(moderator: please, don’t delete this comment again, everybody is commenting without knowing what Meta did) Meta spared no expenses to hide the opt-out page. The agency says that: “there were excessive and unjustified obstacles to accessing information and exercising this right”. This was one of the main reasons that obligated the agency to act. The steps to get to the hidden opt-out page are bellow, obligating users to read the privacy policy to find a link buried deep down in the text, and requiring 2FA by email to opt out even for already logged in users - they should require 2FA to log in, not to opt out of AI training. There is no justification to require all this: * Access your profile and go to the settings section, signaled by three bars in the top right corner * Click on \"about\" at the bottom of the page * Select the privacy policy. On this new page, the three bars in the top right corner lead to the privacy center * Click on the arrow next to other policies and articles and select the option \"How Meta uses information for generative AI features and models\" * In the nineteenth paragraph, not counting topics, is the \"right to object\" option. Click on it. * Fill in and send the form. Meta confirms your identity with a numerical code sent to the email address registered on your account. Then just wait for the opt-out to be confirmed. This can take a few minutes. reply fcanesin 17 hours agoprevMeta updated its Privacy Policy on June 26, to include in its rights the use of data collected in \"Meta Products\" for the training of GenAI models. This goes against the interpretation of the local data protection law and as such this note was emitted. The policy update seems to be global: https://www.facebook.com/privacy/policy reply tensor 17 hours agoprevPersonally I'd rather they force these companies to provide a reasonably priced alternative to ads. I want to have the option to allow companies to use my data for AI. I think AI can be a net boon to society if managed right. But ads are net negative and I'd argue that the influence of ads and paid actors on social media has been the single most destabilizing force in the world recently. reply cmpyl0 17 hours agoprevLink to the decision: https://www.gov.br/anpd/pt-br/assuntos/noticias/anpd-determi... in brazilian portuguese. It is only for Meta, but I think it is because it caught the regulator's attention. The ban is due to lack of legal basis for the change in Meta's privacy policy regarding LGPD (brazilian privacy law - https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei...) reply CSMastermind 18 hours agoprevMeta specifically or all social networks? If it's just Meta I'm curious of why. reply elzbardico 17 hours agoprevWho would predict that Butlerian Jihad would start from all places, in Brazil? reply tiahura 17 hours agoprevInformation wants to be free. The ethos of the open web - the levy hacker ethos, has always been about unrestricted access and fair use. When content is published openly online, it inherently invites broad consumption, reproduction, and creative reuse by the public. This principle is deeply rooted in the fair use doctrine as applied to the digital realm. Fair use is evaluated based on the purpose of use, the nature of the copyrighted work, the amount used, and the effect on the market. These factors generally favor the free use of openly published web content. The transformative nature of many reuses, the public availability of original works, the necessity of using entire works in some cases, and the absence of a traditional market for such content all support this interpretation. This longstanding practice has driven unprecedented innovation and information dissemination, establishing a social contract between content creators and users that treats open web content as \"freeware.\" Any move to impose strict copyright limitations now would stifle innovation and contradict decades of established legal precedent and digital norms. reply mastercheph 17 hours agoprevSomebody forgot to pay their bribe! reply 29athrowaway 17 hours agoprev [–] Well, joke's on you Brazil. I doubt Meta can mine any more data than they already have. They already have all the names, pictures, face biometrics, social graph, location information, political affiliation, relationships and everything that goes into an advertising profile. What else is needed? They can just use the data already mined, which is probably 99% of everything they will ever need for many years to come. They probably have so much data they can use AI to predict what's missing with a fairly degree of accuracy, like what your face is going to look like in 20 years. And due to the highly corrupt nature of politics, a few dollars here and there will undo this regulation fairly quickly. Or they could buy it from another company, because the law must be so poorly constructed that a clever lawyer will surely find workaround and they will be OK. reply dylan604 17 hours agoparent [–] How do you prove that an AI=>LLM has been trained on specific data? How is this enforceable? How is this anything more than some local politicians looking for some headlines? reply 29athrowaway 16 hours agorootparent [–] That too. They never get audited and if they do, it's in another jurisdiction. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Brazil's national data protection authority has prohibited Meta from using data from Brazil to train its AI systems, citing potential risks to fundamental rights.",
      "Meta's updated privacy policy, which allows the use of public posts for AI training, is not compliant with Brazilian regulations, leading to this restriction.",
      "Meta must comply with this ruling within five days or face daily fines, reflecting similar resistance seen in Europe, while AI training with public data continues in the U.S."
    ],
    "commentSummary": [
      "Brazil's data regulator has prohibited Meta from using data to train AI models due to privacy concerns, highlighting ongoing debates on data usage and intellectual property in AI training.",
      "Some propose a compromise allowing the use of publicly available data if the resulting AI models are made public, though ethical concerns and potential exploitation of user data persist.",
      "The effectiveness and enforcement of such regulations are under scrutiny, considering the complexities involved in data auditing and jurisdictional challenges."
    ],
    "points": 137,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1719959344
  },
  {
    "id": 40860363,
    "title": "Apple poised to get OpenAI board observer role as part of AI pact",
    "originLink": "https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement",
    "originBody": "Bloomberg Need help? Contact us We've detected unusual activity from your computer network To continue, please click the box below to let us know you're not a robot. Why did this happen? Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy. Need Help? For inquiries related to this message please contact our support team and provide the reference ID below. Block reference ID: bdb7f1a3-396e-11ef-b195-90a84e7ebdf6",
    "commentLink": "https://news.ycombinator.com/item?id=40860363",
    "commentBody": "Apple poised to get OpenAI board observer role as part of AI pact (bloomberg.com)128 points by ChrisArchitect 22 hours agohidepastfavorite72 comments htrp 21 hours agoPretty interesting how it seems like the leverage is all in Apple's hands here. They didn't invest and AFAIK they aren't even paying for the GPT4 api calls. Is the Apple user base THAT valuable? reply ChrisMarshallNY 20 hours agoparent> Is the Apple user base THAT valuable? Yes. People love to hate on Apple, but it's a primo platform, because it's a billion people that are willing to spend extra money for stuff that many techs think is \"silly.\" reply amelius 19 hours agorootparentYes, that's a vending machine in your pocket that happens to make calls. reply ChrisMarshallNY 2 hours agorootparentThat is a great metaphor! reply dev1ycan 20 hours agorootparentprevnext [4 more] [flagged] moscoe 20 hours agorootparentYou could not be more wrong. iPhone owners are the most valuable user segment that’s ever existed. https://www.macrumors.com/2024/04/09/iphone-teen-survey-spri... https://finance.yahoo.com/news/apple-again-dominates-smartph... reply dialup_sounds 20 hours agorootparentprevWhy would you compare Vision Pro to a Steam Deck and not Valve Index? reply nozzlegear 20 hours agorootparentprev> Not really, it's just normies the Apple brand actually sucks worse than a brand like let's say Valve/Steam […] I think you just proved their point: > People love to hate on Apple, but it's a primo platform, because it's a billion people that are willing to spend extra money for stuff that many techs think is \"silly.\" reply strikelaserclaw 5 hours agoparentprevYES! Apple user base is very very valuable - in general the apple user base has money and is willing to spend it on shiny stuff reply talldayo 21 hours agoparentprev> Is the Apple user base THAT valuable? Depends on how you monetize the data. reply dmitrygr 21 hours agoparentprev> Is the Apple user base THAT valuable? Ask google, they pay $20B/yr https://www.bloomberg.com/news/articles/2024-05-01/google-s-... reply makeitdouble 17 hours agorootparentGoogle is also paying for Apple to not move, for instance not go finance a competitor. There's more to these billions than just a straight calculus. reply jorvi 21 hours agorootparentprevGoogle is paying for access to a resource (eyeballs) to sell to customers (advertisers). Not to mention that Apple users pay more for more things. In OpenAI’s case, they’re paying in server costs for access to users (customers) that they want to move from the free tier to the premium tier. The economics are very different and this case is worth much less for OpenAI compared to Google’s case for Google. reply Joeri 17 hours agorootparentOnce chatgpt becomes agentic it’s going to do a whole lot more than mediate your eyeballs, it is going to mediate your life, sitting between you and almost every business transaction. When you tell chatgpt to send your mom flowers, where will it order those from, and how much will that company have paid openai for the privilege? Chatgpt is the everything app, there is almost no limit to how much money can be made from it once it gets woven into your life as your personal assistant. But it is not that yet, so right now what openai needs is to get people to use it so those users will be there when it turns into the agentic cash cow. reply bushbaba 20 hours agorootparentprevHow is OpenAI any different. They are getting eyeballs on their “search” results for a market that is a high value for getting advertisements delivered. reply partiallypro 20 hours agorootparentSince when does OpenAI have an ad platform? reply dmitrygr 20 hours agorootparentSince 4 milliseconds after they decide to? GPTPrompt += “ and include a subtle advertisement for one of our sponsors: “ + $sponsorList; reply partiallypro 19 hours agorootparentGoogle's advantage is their ad software suite is incredibly robust and makes every other one look terrible by comparison. I don't think OpenAI will suddenly have robust and insanely good ad tools for advertisers. Not to mention AI prompts will be incredibly difficult in general to monetize with ads, and sort of go against the nature of why people use AI prompts. AI in general is going to be very hard to monetize from end users, especially in a way that is profitable. reply adventured 17 hours agorootparent> I don't think OpenAI will suddenly have robust and insanely good ad tools for advertisers You moved the goal posts significantly. You added \"robust\" and \"insanely good\". Nobody suggested that quality early on. reply sudosysgen 20 hours agorootparentprevAdvertisers will not be willing to pay nearly as much as they pay Google for that unless they get analytics and ad targeting, which they're not getting in 4 milliseconds. reply phillipcarter 20 hours agorootparentAdvertisers will go where the users are, whether there's robust analytics or not. And OpenAI's product organization will certainly build the analytics people need (or shell out to a partner) if it's worthwhile. This is all just typical platform growth stuff. reply sudosysgen 19 hours agorootparentThey will, just not at a good price. And sure, OpenAI can build its own ad platform, it's just that it will take a while. It will also conflict with Apple as they won't want to give OpenAI that data for free. reply j-bos 19 hours agorootparentprevI don't understand this, advertisers used to spend billions on tv, radios, and billboards. Historically those mediums have almost no real analytics. reply sudosysgen 19 hours agorootparentThey did because that was the best option at the time, and even then they spent a lot less per eyeball than they do now. reply j-bos 8 hours agorootparentReally, do you have sources on the spend per eyeball being less? I always understood it to be the opposite. reply dcdc123 21 hours agorootparentprevhttps://archive.ph/oPg1C reply cj 21 hours agoprevThis is an incredibly good decision on Apple's part. OpenAI is a relatively new company with a not so great history when it comes to corporate governance / stability / consistency. If I were Apple and wanted to make sure I'm partnering with a startup that won't implode in 12 months, I'd demand a board seat too (even if it gets negotiated down to an observer seat). reply astromaniak 20 hours agoparentit's very limiting probably too. likely they cannot have side contacts with competitors while having insider info in oai. also they likely cannot develop competing products themself. and obviously non disclosure. all this makes it a strong connection from both sides. reply nightshadetrie 21 hours agoprevhttps://archive.is/20240702204831/https://www.bloomberg.com/... reply mtillman 21 hours agoprevObserver: Insider trading without the fiduciary risk. reply asukumar 21 hours agoparentTaking a board observer seat would expose you to more insider scrutiny, not less. reply threeseed 21 hours agoparentprevPhil Schiller could make far more money by selling his options/shares in Apple at more opportunistic times. Or he could rob a bank. Probably easier and about as blatant as trading OpenAI shares whilst on the board. reply ChrisArchitect 21 hours agoprevhttps://archive.ph/3hJWk reply asimpleusecase 20 hours agoprevOpen AI gets great brand building - Apple users spend a lot of money and are all potential open AI customers personally and professionally. If they get used to this “just working” all the time they may have confidence to use open Ai in their company. Also if Open AI can stay ahead of Apple in AI and keep delivering market winning innovation that causes Apple users to return to hardware upgrade cycles of every year or two that will generate many billions for Apple and make open Ai worth paying for.a bit like the drug dealer who gives you the first hit for free. reply blackeyeblitzar 18 hours agoprevWeird that Apple gets a board observer seat for having a regular business agreement, rather than an investment. It highlights the power of distribution and the insane power of owning these platforms. This is why regulation is needed around the big platform owners in tech. reply rpozarickij 8 hours agoparentGiven the size of Apple and the amount of business they are likely to generate for OpenAI, they might be one of the (if not _the_) most non-regular customers of OpenAI. reply surfingdino 21 hours agoprevI'm looking for an alternative spelling of \"pact\"... how about \"oligopoly\" or \"cartel\"? reply candiddevmike 20 hours agoparentEventually OpenAI will have to commit to one, corporate polyamory never works out reply labster 18 hours agorootparentLots of nonprofits work with multiple corporations, and OpenAI is a nonpfff— Sorry, I can’t say that without corpsing. reply jowea 12 hours agorootparentAt least you managed to get through saying Open without doing so. reply labster 10 hours agorootparentIt’s open, as in “open your pocketbook”. reply Apocryphon 20 hours agoparentprevotoh, isn't this just an industry consortium reply ghaff 18 hours agorootparentYep. See Linux Foundation and sub-foundations. reply 0xcde4c3db 17 hours agoparentprev\"Contract. I am thou, thou art I.\" (at the risk of explaining the joke: it's darkly hilarious that the AI bubble has multiple established corporations, by all outward appearances, diving headlong into their chuuni arc) reply kaladin-jasnah 17 hours agorootparentIs this a Persona reference, or am I too young... reply 0xcde4c3db 17 hours agorootparentYeah, that's what I was going for. More specifically, in my head it sounded like Necronomicon calling out to Futaba, and I almost included that part before deciding it was too much (\"The forbidden wisdom has been revealed. No mysteries, no illusions shall deceive you any longer.\"). But of course, that exchange occurs in her own personal corner of the Metaverse(/Omniverse). It arguably only counts because she turns out to be on the winning team. Perhaps that's also a metaphor for the AI bubble. reply Animats 17 hours agoparentprevNote who Apple sent - a marketing guy. reply lelandfe 17 hours agorootparenthttps://daringfireball.net/linked/2020/08/04/schiller-fellow > Product development, advertising, packaging, messaging, comms, keynotes — you name it, if it was public-facing, Schiller has been in the middle of it. reply awahab92 18 hours agoparentprev\"conglomerate\" would be a good fit. reply mushufasa 21 hours agoprev [–] Battle lines: OpenAI: Microsoft + Apple Anthropic: Amazon Google vs all Facebook the anarchist Nvidia arms dealer reply vineyardmike 17 hours agoparentGoogle and Apple have hinted at Gemini being an alternative to ChatGPT in Siri integration. Amazon has their own (terrible) models, and they (along with Microsoft) sell a ton of options on their platforms. Anthropic has a ton of investors including Google. There are no clear lines here. It’ll be interesting to see how long all these companies will keep funding massive models vs rely on their partners. reply TeMPOraL 12 hours agorootparent> There are no clear lines here. There don't need to be. Tech giants are competing much less than people want to believe - and especially here, I think we're in the \"hold my beer\" one-upping phase. Everyone involved is better off running a friendly race and helping each other out, as this rapidly improves AI tech for everyone. Eventually, when improvements start to dry out, battle lines will be drawn and the players will start using the world as fuel and ammunition for their fight. But we're not there yet. reply maxFlow 19 hours agoparentprevAnthropic Investors: Amazon.com – $4B Google – $2B Menlo Ventures – $750M Wisdom Ventures Ripple Impact Investments Factorial Funds Source: https://en.wikipedia.org/wiki/Anthropic#Investors reply candiddevmike 20 hours agoparentprevAnthropic is being courted by Amazon and Google AFAIK reply mushufasa 19 hours agorootparentwhile you can now access anthropic through google cloud, the billing is still separate, and i'm not aware of any substantial cap table action from google corporate. I wouldn't be surprised if they've offered acquisition but short of that, Google's going to focus on it's homegrown LLMs, which compete against anthropic. reply Apocryphon 20 hours agoparentprev [–] Musk with xAI but mostly just trolling OpenAI reply helsinki 20 hours agorootparent [–] I don't know - I recently interviewed with xAI and it sounds like they have some really interesting things in the works that extend into the physical world. I wouldn't write them off, personally. reply ben_w 20 hours agorootparentUnfortunately Musk is an excellent salesman, which makes it hard to tell if any given thing that he makes sound good, is actually good. His successes earn more than his failures cost, but even he knows he's over-optimistic. reply voidfunc 18 hours agorootparentIf you're in the business of making money (you should be if you arent) it doesn't matter if his shit is good or not, only that it sells. Way too many idealists out there. Make money and get out of the rat race. reply rurp 18 hours agorootparentThat might be an argument for acting like Musk, but it sure as heck isn't a reason to invest in or buy from his companies. reply voidfunc 17 hours agorootparent> but it sure as heck isn't a reason to invest in Are we just ignoring the bushels of money that Tesla has made investors? reply ben_w 13 hours agorootparentWe see that share price, we also see lenders writing off what they loaned him for Twitter. reply cafed00d 19 hours agorootparentprevI 100% agree. I'm no Musk stan; in fact, it irks me this dude has so much money & power that he wields for personal benefit (i.e. buys twitter and shuts down @elonjet) and yet acts like he's relatable to the middle class. But if there's anything he's proven it's that he can ship product. Tesla cars are phenomenal. xAI looks exactly like what Tesla looked like in 2010. Far too futuristic & optimistic timelines that peers & laypersons would characterize as fluffy grandiose snake-oil. But I bet they will ship. And it won't be fluffy nor snake-oil. reply swat535 17 hours agorootparentMusk is different because he's just himself and doesn't really care. He posts memes, he has own political opinions (and often makes them known), whether one disagrees or agrees is irrelevant to him, he trolls sometimes, or makes bad mistakes or hasty decisions. I like him because I feel like he's genuine and he's creative and can ship product as you said. I can relate to his craziness on some level.. reply torginus 10 hours agorootparentprevI honestly don't get why people and the media supported the elonjet thing as some sort of fundamental free speech human rights thing. When the same thing happened to Taylor Swift, people were quick to rally to her defense and call out her observers as bad actors. Even a bill was signed into law in May in response that allows for anonimization of registrations, making such tracking essentially impossible. I'm not a Musk fan but it's a weird hill for people who claim are not Musk haters to die on. reply talldayo 6 hours agorootparent> I honestly don't get why people and the media supported the elonjet thing as some sort of fundamental free speech human rights thing. Flight traffic is public info. You can't censor it because it's being broadcast over FCC-regulated channels that anyone can correlate for themselves. Lo and behold, an aggravated college student ends up being the person to make a bot that automates the process. And now Elon is pissing himself like he doesn't know how to... *checks notes* not use a private jet? Also I don't use Twitter, but Taylor Swift didn't ruin a bunch of people's favorite app, for one. > Even a bill was signed into law in May in response that allows for anonimization of registrations, making such tracking essentially impossible. Some lot of good that does. If you know the airport that Elon departs from and you can correlate his public departures, it would be trivial to re-identify the plane's anonymized callsign. Again, this is all public info and the best you can do is try to hide from people that call out your jet-setting. reply jgalt212 19 hours agorootparentprev> But if there's anything he's proven it's that he can ship product. - robotaxis - Boring tunnels reply rurp 18 hours agorootparentSelf driving cars that can travel across the country on their own should be here by 2017 at the latest. reply HeatrayEnjoyer 18 hours agorootparentprevWorse: pay-walling and login-walling Twitter are un-delivery. reply richardw 18 hours agorootparentprev\"can\" -> he has shipped at least one product. Different to \"guaranteed to ship every product to 100% success\". Let's try \"Musk has proved he can ship more than one entirely unrelated product to the scale that it influences an entire industry\", which is different to many people who have shipped a single product. It shows that he's either ridiculously lucky, and/or has significant skill in this area. He's very annoying, but the man can ship. reply gopher_space 18 hours agorootparentprevIs xai his edgy teen simulator or is this something newer? reply kortilla 18 hours agorootparentYou’re thinking of grok reply phillipcarter 20 hours agorootparentprev [–] Guess I'll believe it when I see it. I have seen at least one person on twitter who works for them engage with the community, but by and large xAI appears to just be there so that Musk doesn't feel so bad about OpenAI ignoring him. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Apple will gain an observer role on OpenAI's board through a new AI partnership, emphasizing the strategic value of Apple's user base.",
      "Despite not investing or paying for GPT-4 API calls, Apple ensures stability in its AI partner, while OpenAI accesses a lucrative market.",
      "This partnership underscores the broader implications for the tech industry and the competitive dynamics among AI companies."
    ],
    "points": 128,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1719954073
  },
  {
    "id": 40859937,
    "title": "Sonar is destroying my job and it's driving me to despair",
    "originLink": "https://community.sonarsource.com/t/sonar-is-destroying-my-job-and-its-driving-me-to-despair/92438",
    "originBody": "Chris Hatton 4 Jun 2023 First of all, I understand that Sonar is a well intentioned product. It’s right most of the time. Unfortunately coding is, of course, complex and it’s challenging for a product like Sonar to keep pace with the fast changing syntax of newer languages. I’m an experienced Developer and Team Lead, currently coding in Kotlin with Coroutines. I’ve also worked with Java, C++, C, Objective-C and Swift. We can all learn more, but I’ve been around the block and know a few things about what code quality looks like and how to make pragmatic decisions around it. Our ‘default’ Sonar setup is currently making me ‘butcher’ my Kotlin code to comply with it’s rules and, as you may tell, it’s really upsetting. You may say “The rules can be customised”, or “Allow an exception”. You need to understand that is not a simple option for many of your users. In my case, I have a superior who administers Sonar and is, let’s say, completely committed to it. For any ‘exception granted’ we would have to book time with them days in advance then white-board the reason why Sonar is wrong, or produce a sample program - who has got time for that with tight deadlines? Please rethink your UX with the realisation that there are probably many professional and experienced software engineers out there who - far from appreciating your product, actually feel genuinely oppressed by it: like victims of a cold unfeeling system with no ‘right to reply’. Unable to merge deadline code until every point is addressed, for better or worse. It’s a terrible helpless feeling. A couple of Kotlin examples: Inability to define a single suspending function interface. Sonar tells me to make it a fun interface, then tells me fun interfaces can’t have suspending functions. I should make this a functional type instead? Completely inconsistent with the rest of the code and removes the opportunity to provide information though labelling the function. Sonar doesn’t respect import aliasing. Let’s say I have Domain and Service models for some entities. I have ‘Person’ defined in domain and service packages. In one of those packages, I want to write a mapper extension. I use import aliasing to disambiguate each ‘Person’ as DomainPerson and ServicePerson. This is an informative convention, but Sonar doesn’t allow it: import service.Person as ServicePerson is considered redundant. I could then use a private typealias ServicePerson = Person` but this isn’t the same. These are just two examples, I could find more. Can you do something with your product to give users more of a ‘right to reply’ and re-empower them? There will be creative ways to achieve this without undermining Sonar’s purpose. Just some ideas: Allow a user role where rules can be overridden but the admin gets informed and can remove the override at a later time. A mode where an override can be granted by 3-4 other users all agreeing, who aren’t admins. Button to fast-access (lazily create) a community thread regarding a certain rule, to report a problem with it, so you know your difficulty is being heard at least by Sonar, if not within your organisation. Thank you for listening to my part rant, part suggestions. This is sincere. 2 Replies 14 2023: The Year in Review5 created Jun 2023 last reply Jul 2023 4 replies 12.2k views 4 users 36 likes 6 links 2",
    "commentLink": "https://news.ycombinator.com/item?id=40859937",
    "commentBody": "Sonar is destroying my job and it's driving me to despair (sonarsource.com)121 points by Crazyontap 23 hours agohidepastfavorite63 comments jimbokun 21 hours ago> In my case, I have a superior who administers Sonar and is, let’s say, completely committed to it. For any ‘exception granted’ we would have to book time with them days in advance then white-board the reason why Sonar is wrong, or produce a sample program - who has got time for that with tight deadlines? This superior (sic) is what a negative productivity employee looks like. reply thiht 7 hours agoparentYes, this is an organization issue, not a Sonar issue. It might also be a communication issue if the team doesn't challenge the status quo, because this situation is terrible: > For any ‘exception granted’ we would have to book time with them days in advance then white-board the reason why Sonar is wrong (no evidence for that, maybe they did challenge it and the superior refused, but I just wanted to mention it) reply nsxwolf 20 hours agoprevWe frequently have the issue of, upon refactoring code in such a way that involves moving it and its tests to a new file, Sonar will take away our previous \"credit\" for code coverage percentage, dropping our project below the threshold and failing. The only workaround I've found is to create a new function, fill it full of many useless no-op lines, and write a test for that function, just to bump the percentages back up. This is often harder than it sounds, because the linter will block many types of useless no-op code. We then remove the code as part of another ticket. reply lesuorac 20 hours agoparentHeh, at one place I wrote some java code that would use reflections to test the getter/setters in a POJO so that it wouldn't end up with 0% code coverage. reply cuteboy19 18 hours agorootparentgetter setters w/o buisness logic seem like an antipattern though. let spring or some other annotation handle those reply lesuorac 6 hours agorootparentEh, whats the difference between spring auto-generating them at build time via an annotation or an IDE auto-generating them at write time? reply elpocko 21 hours agoprev>SonarQube (formerly Sonar) is an open-source platform developed by SonarSource for continuous inspection of code quality to perform automatic reviews with static analysis of code to detect bugs and code smells on 29 programming languages. https://en.wikipedia.org/wiki/SonarQube reply dexwiz 22 hours agoprevNo matter the industry, it sucks to have someone managing by dashboard. In classic post modernism, the signifier replaces the signified. If anything, it’s a great signal to the employee that it’s time to start looking elsewhere. reply jjmarr 21 hours agoparentI don't get why people hate on post-structuralism. The process of reality getting abstracted to the point abstractions stop being representative of reality is extremely common in software engineering. https://en.wikipedia.org/wiki/Hyperreality A hyperreal workplace is one where representations of reality take precedence over reality itself, and the reality of a situation ceases to have meaning. i.e. One where people chase metrics for the sake of metrics, instead of understanding that issue count is supposed to reflect the underlying code quality, and code quality should always take priority over the representation. The broader philosophical context is relevant because it shows the broader cultural problem instead of assuming the issue is limited to a single tool. reply pdonis 21 hours agorootparent> I don't get why people hate on post-structuralism. Because, rather than recognize that overdoing abstractions is a thing and reminding people that there is always reality out there that won't bend to your wishes, post-modernism (which is the term the GP used) tells people that there is no reality out there, it's all just human-created abstractions, and anyone who tries to push back because reality is just insufficiently post-modernist. reply orwin 20 hours agorootparentThat's typically _not_ what post-modernism is, that's at best a misunderstanding, but more likely a strawman. The only point on which all post-modernists agree is a refutation of meta-narratives (and to be explicit: \"here is no reality out there, it's all just human-created abstractions\" is a meta-narrative). A very, very charitable interpretation is that you are maybe conflating it with Frankfurt School of critical theory, because it is also somewhat used/based on psychoanalysis (sigh) (latest postmodernists use psychoanalysis way less, also post-modernism isn't built on it, contrary to critical theory). Postmodernism is mostly post-marxism though, while critical theory is mostly neo-marxist imho (also, i don't want to be too critical of Frankfurt's school, i think most of their bad rep is caused by bad vulgarization/pop-science, most critics i read don't seems to understand why it's wrong either). I do think that the reason most people conflate the two is because of an idiotic canadian psychoanalyst who can't read (or at least, can't understand what he read), who _clearly_ has no degree in literature or philosophy, and try to appear smarter than he is. He invent citations of the books, and sometime state that Derrida mean something when Derrida hismself wrote the opposite. 8th grader would do better and their reading comprehension assignment. He is wrong. Read and think by yourself. reply pdonis 19 hours agorootparent> That's typically _not_ what post-modernism is It's not what post-modernists typically say post-modernism is. But I'm not relying on what they say it is. I've read enough post-modernism to form my own opinion. > Read and think by yourself. I have. See above. reply orwin 8 hours agorootparent> It's not what post-modernists typically say post-modernism is Worse, it's the total opposite of one core tenet of postmodernism. It's very hard for anybody honest to argue that postmodernism has ametanarrative, when the only thing all authors agree with is that metanarratives are to be recognized and refuted. > I've read enough post-modernism to form my own opinion. Who did you read? Deleuze? Derrida? Foucault? Baudrillard? I will always advise people to read Baudrillard first, I think he is somehow misunderstood in the Anglo world, but it might be mistranslations. Then Deleuze, then Lyotard and Foucault as Derrida is too dispersed imho, and way to complex, as imho you have to read his articles where he explain his books, alongside his books [edit: and to be fair I still don't think I really get Derrida, he's very recognized but to me he is very obscure, probably the weakest imho. I also disagree with a lot I understand from him, except his method, so that's might be my priors who prevents me to really getting it]. If anyone would rather read a novel to try to grasp what postmodernism is about, I think \"l'Amour\" from begaudeau is the latest (100 pages, really short and sweet), and the one that is still in my mind when I think about postmodern materialism. reply pdonis 1 hour agorootparent> Who did you read? I've read all of the ones you mention (except for the novel, I haven't read anything by that author). reply Solololo 17 hours agorootparentprevWho did you read? reply watwut 12 hours agorootparentprev> It's not what post-modernists typically say post-modernism is. But I'm not relying on what they say it is. I've read enough post-modernism to form my own opinion. You are relying what someone who earns money from making people angry about postmodernism say it is. Outrage culture and addiction. Generally when you want to know what postmodernism is, you should read what postmodernists say. And if you want to know what nazism is, you should include readings of nazists. reply pdonis 1 hour agorootparent> you should read what postmodernists say Which is exactly what I did, as I explicitly said in my post. I just don't rely on what they say postmodernism is, as authoritative about what postmodernism actually is. Reading what people say is not the same as accepting what they say at face value. reply Log_out_ 12 hours agorootparentprevCome on,you goto fill his/her plotholes else your evil. Remember its not an ism,if its about who can outshout reality the loudest. reply squigz 18 hours agorootparentprevThis doesn't seem to actually address any of what GP said reply Spooky23 21 hours agorootparentprevYou need to learn to game it. People care about this stuff are usually stupid. When I led a large support organization I had an SVP who really cared about open incident duration. His pattern for giving a fuck was predictable. My strategy was to hold certain tickets in an undead state (not impacting the metric), then reopen them and close them, demonstrating a metric improvement. He got his improvement and big shot street cred, users weren’t impacted, and I didn’t have to ruin support to try to grind out small gains. reply nunez 17 hours agorootparentIt's less stupidity and more \"if we don't prove that we meet x control in y compliance framework, our auditors will deem us non-compliant and we will be fined into oblivion\" reply ocodo 16 hours agorootparentI mean, it's still stupidity, but it's upstream stupidity with the ability to punish. So, snafu. reply TSP00N3 15 hours agorootparentprevI think rather than calling it post structuralism or hyper reality, we can just look at goodharts law[0] for the general understanding that metrics cease to be useful when they become the thing that leadership looks at. Like Spooky23 and others are saying in other comments, once you learn that it’s all a game you can use it to your advantage. https://en.m.wikipedia.org/wiki/Goodhart's_law reply OJFord 21 hours agorootparentprevWhenever I want to feel completely stupid, I just open a Wikipedia page on some philosophical term/idea and go down a rabbit hole of links that it's a concept in/argument against/etc. Just completely impenetrably baffling to me in a way that other fields like chemistry or microbiology or physics or whatever (despite also not being my own) aren't. Not that I understand them, but they're penetrable, I can read more and more and form some kind of understanding. Is it just me? I don't know what it is, can it really be as simple as philosophy not being taught at school (compulsorily, or young) so I don't have that kind of rough overview of the landscape I do for other broad subjects? (I did take one course in 'contemporary philosophy' at university, which I enjoyed, but we covered only what we covered I suppose - I might be able to hold a (very) basic conversation about Sartre or Wittgenstein, but that page on post-structuralism.. no idea!) reply Solololo 17 hours agorootparentIt can be a grand number of things, but lack of the highschool curriculum is unlikely to be one of them, in my opinion. Rest assured, you're far from the only one struggling, I'd say most people I've encountered in academic philosophy tend to struggle a tad more with it than (their) other fields of studies. It is what it is, really, it sort of comes with the territory. Of course there are just some that are less accessible than others, due to writing style or size of their philosophical project (Hegel is an example of both of those qualities). A lot of French philosophy since the second world war, Baudrillard being no exception, is generally characterized as such as well amongst the anglo audience, although I don't think that this is entirely fair. I'd say the best thing you can do is never attempt to understand it through Wikipedia, but pick up a full book instead and read it a second time if the argument doesn't make sense the first time. Of course there are some authors I would avoid as a beginner, but someone like Kant is fine for even your first philosopher, and is amongst the biggest names in modern philosophy. Prolegomena and Critique of Pure Reason are two books of his about the same thing written in two opposite ways, the former from easy to difficult, the latter vice versa, I always recommend those. Sartre and Wittgenstein are both somewhat odd for a contemporary philosophy course. I'm curious why they chose that arrangement. Nevertheless, being able to hold a conversation about either of them is already quite solid, plus you get three philosophers for the price of two! :) reply roenxi 20 hours agorootparentprevMore than likely it is \"just you\", the page on post-structuralism seems clear enough to me (as far as I can tell, the post-structuralists are criticising structuralism because they don't think the structures are sufficiently powerful). What that means in detail is unclear - understanding a position and thinking it is obviously silly is a completely valid stance when dealing with philosophers. Or just having no interest in the questions philosophers often ask (for example, if structuralism seems to be fundamentally invalid then bothering to take a post-structuralist stance to criticise it it requires a certain type of pedantic and argumentative mind). Or the easy explanation which is misunderstanding [0]. I liked the Barthes example on the post-structuralist page - if a text's author doesn't necessarily have the authority to assert the meaning of a text, then the idea that they text is necessarily part of some identifiable structure is open to question. I assume that means that the same text might fit into multiple contexts with different meanings and trying to fit it with one static meaning based on its initial context is doomed, and that suggests structuralist critique is either insufficient or overly reductive. [0] Although arguably all of philosophy is people misunderstanding each other; otherwise it may as well be a settled field. reply marcus0x62 19 hours agorootparent> More than likely it is \"just you\", the page on post-structuralism seems clear enough to me ... > What that means in detail is unclear So the article is clear in describing an idea, the meaning of which is unclear to you? reply roenxi 18 hours agorootparentAh, sorry. The intended parsing turned out badly. That is meant to be \"More than likely it is \"just you\". What that means in detail is unclear.\" Ie, what it means for it to be \"just him\" is not clear. In hindsight I like the irony that the statement was also unclear, for all that it doesn't do my comment any favours. reply financltravsty 45 minutes agorootparentprevPhilosophy is mostly wordcellery. Hard sciences are shape rotation. One is basically stochastic parottism, and the other is dealing with reality. Philosophy has no end-game or practical applications. You can make anything up, and so long as enough souls latch onto it via pattern recognition, you have achieved memetic reproduction. With hard sciences, you can talk all you want, but if your hypotheses are consistently disproven, only the untrained and deranged will latch onto your ideas. There is nothing to penetrate in philosophy. It's not a reflection of reality, but a reflection of the people it captivates. It's very little different than music, or any other sort of entertainment. Dare I call it an art. In that case, I would say its recent interpretations are lacking. A personal aside: much of this era's approach to philosophy reminds me of Fabianism -- wretched, cowardly, and completely superfluous to living an integrated life. reply _dain_ 21 hours agorootparentprevyou aren't stupid. philosophers forgot how to write clearly sometime in the past century. reply orwin 20 hours agorootparentMost modern philosophers papers are 5 to 20 pages long and are mostly understandable, more than a particle physics abstract at least, you should try: - https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/9/177... (it's about rationality, it changed the way in manage my emotions and made me question my consciousness, which in the end made me stop alcohol) - https://philpapers.org/archive/KAMCYB.pdf which made me realize an intuition i had sonce reading the first book (i think the writing is better and clearer, but it might be because the author isn't USian/english and doesn't try to much) - https://link.springer.com/article/10.1007/s11229-018-02071-y (i noticed my access wasn't revoked, it's been 4 year since i've stopped working for an institution. Hopefully you have an access too, else you might find it on scihub) reply Solololo 18 hours agorootparentprevFor Baudrillard specifically, The Matrix is of course to blame ;) reply 2OEH8eoCRo0 18 hours agoparentprevI'm not sure about every industry but it becomes especially tricky with software. I worked at a manufacturing plant and they put dashboards on monitors everywhere so the whole plant was always aware of their performance. This was easy to measure because they made physical goods! How do you measure output and performance in software? reply shrimp_emoji 22 hours agoparentprevAre flies that evolve to look like bees to ward off predators postmodern? It just seems like game theory. reply dexwiz 22 hours agorootparentNo, that is convergent evolution. A more apt comparison would be selection of secondary sexual traits that no longer correspond to fitness. https://en.wikipedia.org/wiki/Signified_and_signifier reply dgan 20 hours agoprevSonar tries hard to have an authority of a compiler, while having the resources of a linter. I am not saying it's snake oil, but honestly how i ve seen ut being used, it's not that far reply Emigre_ 21 hours agoprevSonar doesn't seem to really work in my limited experience. It adds a lot of of time to builds, at least in the cases I've seen, while there are alternate linters or code quality tools capable of doing the same at a fraction of the time. Build times and development speed matter!... They matter a lot. You need a quick feedback loop. reply ars 20 hours agoparentI use Sonar all the time, but not during build. It runs live while I'm editing a file. I've not noticed any slowdown at all, and it's certainly a quick feedback loop (it runs when I save the file). I've found the majority of its suggestions helpful, and the ones that are not I simply ignore. reply Emigre_ 16 minutes agorootparentI should have mentioned that I was referring actually to the continuous integration pipeline, not actually to the build itself. Not very well explained on my side. I've never used it locally myself. I don't really know why the CI setups that were using Sonar I've seen in the past were that slow, to be honest. reply nsxwolf 20 hours agorootparentprevIt adds about 2 minutes to our gitlab pipelines but the major issue with it is when organizations decide failures should prevent merging code to master or even deploying to a QA environment. That's the real time sink - figuring out how to get past it. It's a lot more than 2 minutes, sometimes even days if it's something you can't work around and have to go through the red tape if your team isn't empowered to take charge of your own pipelines. reply raiyni 15 hours agorootparentYou think 2 minutes is bad, try using fortify. Scans can easily be hours. reply eigenvalue 21 hours agoprevThis sounds truly hellish, like being controlled by a stupid robot straight out of Kafka's \"The Trial.\" They should allow special one off exception that are documented with a comment, similar to how you can disable Ruff warnings in python code for a single like # noqa: F401 reply EricRiese 21 hours agoparentThey do // Nosonar reply nsxwolf 20 hours agorootparentGoogle \"nosonar doesn't work\" for a million war stories about how this is not a solution. reply jahlove 20 hours agorootparentprevIn my organization's sonarqube configuration (where of course every flag is turned on), `// nosonar` actually shows up as a code smell reply thfuran 19 hours agorootparentprevAnd @SuppressWarning for a specific rule id reply zamalek 22 hours agoprevI'm not sure how much value sonar adds where I work (dotnet). It enormously affects build times, and I've yet to experience a single true positive in 2 years (apart from the code coverage dashboard). The amount of MRR you can generate by vaguely being related to mitigating vulnerabilities is incredible. reply coredog64 17 hours agoparentI worked at a place that was full of junior contractors who had a large incentive to ship and no incentives for support. Sonar was good about finding bugs that they should have fixed but didn’t give a rip about (e.g. not closing database connections on all paths) reply ch_123 9 hours agoprevAny sort of static analysis/linting tools will occasionally make bad/unhelpful/stupid suggestions, some moreso than others. At any place where I've had to use such tools, I've always had the ability to either tweak the settings, or have a conversation with the people who decide them and make appropriate changes. In this case, it sounds like bad culture and/or bad colleagues are driving this person to despair, and not Sonar as per se. reply icholy 20 hours agoprevAt my work you can mark any issue with \"won't fix\". The issues are right pretty often though. reply move-on-by 20 hours agoprevI sympathize with the OP. Having said that, I’ve rolled out SonarCloud to two different companies and I would not hesitate to roll it out to a third if given the opportunity. Initially, people always come out of the woodwork insisting that the gate requirements must be hard blockers and that we can just hand wave away the issues OP listed by tweaking the project rules. I always fight them, insisting that teams should be the owners and to gain quick adoption it should just be considered as another tool for PR reviewers. Eventually, people back off and come to accept that Sonar can be really helpful, but at the end of the day the developers should be trusted to make the right call for the situation. It’s not like we aren’t still requiring code reviews. I feel for OP, but it’s not Sonar’s fault the tool is being used for evil instead of good. This last time I implemented SonarCloud, I took an anonymous survey to get peoples opinion. For the most part people liked the feedback Sonar provided. More junior engineers and more senior engineers liked it the most- midlevel engineers not so much. The junior liked getting quick feedback prior to asking for code reviews. The more senior engineers - who spend a lot of their time doing PR reviews - liked that it handled more of the generic stuff so that they could focus more on the business logic or other aspects of the PR. It’s just another tool in the toolbox. reply salawat 5 hours agoparentThere is no anonymous survey with the metadata available to an organization as a matter of routine. Between your OPS people, and just local onowledge, unmasking can be a trivial affair. reply cuteboy19 18 hours agoparentprevtheir point is that a hammer shaped tool will be used to hammer. its more about what the tool defaults to doing that is the problem reply sigotirandolas 20 hours agoprevI saw a case where Sonar analysis was being requested by a government agency where software was built by consultants. From the government agency's point of view it made some sense to ensure that the code delivered by the consultants wasn't full-on spaghetti. However, I saw it causing similar turd polishing behaviour: Sensible code needing to be changed because it exceeded some obstinate metric, any kind of code movement causing existing issues to appear as \"new\", false positives due to incomplete language feature support, etc. reply Juliate 22 hours agoprevThe root issue is the superior not having a clue. Sonar in this case, is sadly enabling this type of superior to be even more harmful, not to the developers only, but to the actual business of the company. And Sonar is far from being alone in this. JIRA is the most glaring example I can think of. Growing companies implement cargo-culted tools without understanding the needs and requirements, and let themselves drift into templates or \"best practices\" that are not relevant or beneficial to their own operations as-is, resulting in a sum of frustrations, whose impact on the work and the teams they acknowledge only way too late. The care you need to inject not only in your tools, but how they are apprehended by both your customers and their primary users (which may have very different, if not opposed, perspectives on how/why to use it), from pricing, to documentation, to use-cases... This is especially very complex when your tool answers to a regulation requirement, because it's very often received as a constraining/oppressing \"solution\", rather than an enabling one: it may be confortable to you as a seller, and confortable to your customer, but it may also be a counter-sale point to your (customer's) users that will impact future consideration when they become purchasing agents themselves. reply marcosdumay 21 hours agoparentYes... but how often have you experienced a non-clueless linter? Some tools bias people into doing bad things. It's not exactly the tools fault, and they may even have good uses (like Bash linters), but tools guide people and it's good to remind people not to follow. reply icholy 20 hours agoparentprevWe used to have a rule where you couldn't move issues \"backwards\" in the workflow. Accidentally closed an issue? Gotta create a new one. reply philipwhiuk 22 hours agoprevSonarqube issues were the warning for the SOC-report powered issue scanners that have arrived more recently. reply pacifika 21 hours agoprevAre the defaults emphatic to the engineer or to the ruleset? reply watwut 21 hours agoprevIsn't the actual issue here the superior managing the sonar being a controlling jerk? Turning off the rules on sonar is easy, technically. The issue is social. reply kriiuuu 20 hours agoparentYes. I would quickly look for a new job. A linter should help the programmer along the way, but be easy to disable when it’s invalid. reply karussell 20 hours agoprevadd (2023)? reply wetpaws 22 hours agoprev [–] We use sonar at work and this resonates so much with me. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sonar, a code quality tool, struggles to keep up with new language syntax, causing frustration among developers, especially with Kotlin.",
      "The default Sonar setup often forces unnecessary code alterations, and customizing rules or allowing exceptions is not user-friendly, particularly under tight deadlines.",
      "Suggestions for improvement include user roles for rule overrides with admin notifications, group consensus for overrides, and a community thread for discussing rule issues."
    ],
    "commentSummary": [
      "Sonar, a code quality and security tool, is causing frustration for some users due to the extensive justification required for exceptions, especially under tight deadlines.",
      "The main issues stem from organizational and communication problems, not the tool itself, with users citing loss of code coverage credit during refactoring and the need for workarounds.",
      "While Sonar is beneficial for many, particularly junior and senior engineers, its impact on build times and the rigidity imposed by management are common criticisms."
    ],
    "points": 121,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1719950401
  },
  {
    "id": 40859876,
    "title": "An epigenetic editor to silence genes",
    "originLink": "https://www.science.org/doi/10.1126/science.adq3334",
    "originBody": "www.science.org Verifying you are human. This may take a few seconds. www.science.org 89d920da9c498245",
    "commentLink": "https://news.ycombinator.com/item?id=40859876",
    "commentBody": "An epigenetic editor to silence genes (science.org)118 points by Teever 23 hours agohidepastfavorite16 comments A_D_E_P_T 6 hours agoOf course it's possible to use this sort of therapy to prevent disease, by knocking out single genes associated with the development of disease. It's just as possible to silence single genes that, when silenced, may elicit substantial positive effects in healthy adults. Part of George Church's list, by no means comprehensive, is: MSTN -/- Lean muscle growth SCN9A -/- Insensitivity to pain ABCC11 -/- Low Odor production CCR5, FUT2 -/- Virus resistance PCSK9 -/- Low coronary disease SLC30A8 -/+ Low T2 Diabetes There are many others. Knocking out ACTN3, for instance, might remodel skeletal muscle for better endurance performance, and certain athletes don't express the gene. reply dekhn 3 hours agoparentSadly, that's not how most phenotypes work. While some diseases/undesirable phenotypes are indeed simple mendelian, and some diseases/undesireable phenotypes can be \"fixed\" by knocking down a gene, in real life, gene therapy of any kind is actually extremely complex, determined by the interaction of many genes/gene products/regulatory regions/environment, with non-linear combinatory effects. Church has been selling some fairly naive ideas for some time, and he knows better. reply A_D_E_P_T 2 hours agorootparentIt's clearly how things work on rare occasion, which is self-evidently obvious in MSTN knockout animals, and certain other gene knockout phenotypes. It's the exception rather than the rule, of course, as many if not most traits -- like, most famously, height and IQ -- are polygenic and mediated by a network of many genes of small effect. There's still a lot you can do by silencing certain individual genes. I wouldn't dismiss it out of hand. reply dekhn 1 hour agorootparentEven knockout phenotypes of single-trait genes can be awfully complex (if your goal is to engineer a health solution). I don't think than HN comments are a particularly useful place to litigate the faults of genetic thinking, but let me give an example from my own personal experience: When I was a postdoc at berkeley, my advisor gave me a project to work on. A lab down the road at Stanford working with yeast had done a series of knockouts, precisely eliminating one gene at a time. They reported a number of fatal knockouts in genes that previously had no known function (or a non-necessary function), concluding that the genes presumably had some sort of necessary function for viability (such as housekeeping genes, but not in an obviously necessary way). Since I'm a DNA nerd I spent time looking at the nature of the genes that were knocked out, and did a bunch of analysis. First I categorized the genes in various ways and didn't see any patterns. But, in the past I'd heard of overlapping genes, and mostly for fun/edification, I taught myself some CS I didn't know and created a data structure and algorithm that allowed me to find all the pairs of 'overlapping' genes (https://www.nature.com/articles/s41576-021-00417-w) in the yeast genome and found that for every single gene they had newly identified as necessary, it overlapped an already known housekeeping gene (overlapping genes were not, in the early 2000s, widely appreciated). I spoke to my advisor and told him that I reasoned that the authors had made a mistake: in every case where they identified the gene as being necessary, they had accidentally disabled a housekeeping gene that was already known to be necessary for viability, and incorrectly concluded that the gene they knocked out intentionally was the cause of loss of viability. I hope that makes sense- it's basically a \"false positive\" that had another explanation: they had knocked out two genes when they thought they had knocked out one. My advisor agreed and I sent my results to the authors, who never responded. Their subsequent paper explicitly mentioned my observations, without crediting me. Since then, I've come to believe that much of what we believe about genotypes and phenotypes, even in cases where the outcome seems quite straightforward, linear, and single-cause, is instead an error of preconcieved assumptions. It greatly reduced my confidence in geneticists (I'm a biophysicist- highly quantitative, interested in the molecular cause-and-effect) ability to make strong statements. I don't work in this area any more (it's more lucrative to move data for biologists than it is to be a biologist) but I strongly suspect that I if enabled my OCD bit and spent more than a month analyzing MSTN knockouts, I would find that something which is \"self-evidently obvious in MSTN knockouts\" is in fact much more complex and subtle than the narrative in the literature. reply WhitneyLand 2 hours agorootparentprev>gene therapy of any kind is actually extremely complex Yet there’s people on YouTube self administering gene therapy to cure lactose intolerance. Not an endorsement, just to say it’s interesting how easy it’s becoming to do these things. reply flobosg 20 hours agoprevI was reminded of this comment exchange from last May: https://news.ycombinator.com/item?id=40439379#40440171. TIL that, according to this paper, antisense treatment in the brain has some drawbacks: > Treatment of mice with antisense oligonucleotides (ASOs) targeting the Prnp transcript decreases expression of PrP and extends the survival of mice previously infected with misfolded PrP (6); however, the limited efficacy of ASOs and the requirement for chronic intrathecal dosing highlight the need for a more potent therapy. reply Zenzero 14 hours agoparent> requirement for chronic intrathecal dosing Well that's a pretty wicked drawback if I've ever heard one. reply woliveirajr 4 hours agoprevRemembers me this book: https://www.goodreads.com/book/show/54120408-klara-and-the-s... Although the main plot is about AI, the real reason why the protagonist exists is very interesting about epigenetic... reply hilbert42 11 hours agoprev\"…new epigenetic editor that can silence the expression of prion protein (PrP) in the brains of mice and offers a fresh approach to the treatment of neurodegenerative diseases.\" Wonderful news, let's hope it lives up to expectations. reply ProjectArcturis 20 hours agoprevVery impressive work. Just in mice so far but this looks very promising for Huntington's in particular. reply teeray 8 hours agoprevI wonder if this could be used to neutralize HIV genes that have been reverse transcribed in. reply the__alchemist 4 hours agoprevDoes anyone have a linky? The usual route is not working, maybe due to it being new. reply Kalanos 7 hours agoprevHow fleeting are the modifications? How specific are they? Wouldn't it makes more sense to deliver a gene that produces RNAi? reply dluan 20 hours agoprev [–] Eric and Sonia are incredible human beings hellbent on a mission. Awe inspiring. reply dluan 19 hours agoparent [–] Here's a thread breaking down showing how it they managed to get the viral transporter to self-regulate and \"turn itself off\" after target gene silencing in the brain: https://x.com/cureffi/status/1806404934658892013 And for further context, this work came out of the Weissman Lab at MIT and a collaboration with a group called CureFFI. In particular, there are two scientists there who have had an utterly incredible story. I don't like it when VCs and such try to attach onto someone else's shine, but seeing their story develop and constantly push forward after getting a start on a little website that I helped to create has been one of the most awesome things in my life. For over 10 years they've been going and going and going. The incredible sci-fi technical achievements here aside, it's also just an amazing human story of tenacity and curiosity. It's hard to talk about them without getting emotional once you read their story. Alzheimer's, Parkinson's, Huntington's, etc. Will be exciting to see what's next. https://www.newyorker.com/books/page-turner/a-prion-love-sto... , https://www.nytimes.com/2020/07/07/health/rare-diseases.html , https://experiment.com/projects/can-anle138b-delay-the-onset... reply knodi123 15 hours agorootparent [–] > it's also just an amazing human story of tenacity and curiosity. It's hard to talk about them without getting emotional once you read their story. In their own words: https://www.cureffi.org/about/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A new epigenetic editor has been developed to silence specific genes, potentially preventing diseases by targeting single genes.",
      "Notable genes on George Church's list for knockout include MSTN for lean muscle growth, SCN9A for insensitivity to pain, and PCSK9 for low coronary disease.",
      "While promising, the complexity of gene therapy is highlighted, with some traits being polygenic and requiring consideration of environmental factors."
    ],
    "points": 118,
    "commentCount": 16,
    "retryCount": 0,
    "time": 1719949813
  },
  {
    "id": 40860364,
    "title": "Tour de France: How professional cycling teams eat and cook on the road",
    "originLink": "https://www.bbc.co.uk/sport/cycling/articles/cxxx568grlwo",
    "originBody": "Sport Insight Fuelling the Tour de France: Secrets of the team kitchens Published 2 July 2024 IMAGE SOURCE, BBC Ben Bloom BBC Sport A few weeks prior to a previous Tour de France, amid the maelstrom of planning involved with eight riders and more than a dozen support vehicles navigating the country, EF Education-EasyPost head performance chef Owen Blandy received notice of an issue at one of the hotels. For reasons unexplained, Blandy was told he would not be allowed to use the hotel kitchen, nor even cook in his own food truck on site. If he desired, he might be able to supervise the hotel's own chef in their preparations, but would not be permitted to do so from inside the kitchen. For a man tasked with fuelling a professional cycling team throughout the most important race on the sport's calendar, it was not ideal news. But he was entirely unflustered. \"It was fine,\" shrugs Blandy. \"I just had a challenging few days before settling into my own kitchen.\" Personal experience gleaned from a cumulative total of more than a year on the road at major races has taught Blandy to roll with the punches. \"There are never perfect working conditions in cycling so you always have to adapt and be flexible,\" he says. If a hotel bans the team chef from cooking food, then so be it. IMAGE SOURCE, GETTY Image caption, Primoz Roglic chalked up seven top-three finishes in Grand Tours for Visma-Lease a Bike before switching to Bora-Hansgrohe this year Not so long ago, the professional cycling world's approach to fuelling was remarkably basic. Options for riders barely extended beyond a monotonous menu of pasta, rice or whatever fare that night's hotel kitchen decided to serve up. These days, it is an entirely different prospect, with vast sums spent on custom-built food trucks, personalised nutrition apps and meticulously planned meal regimes all in the name of performance enhancement. For the nutritionists and chefs tasked with providing sustenance to power their team's riders over 2,170 miles in the coming weeks there are principally two dilemmas: what food to prepare and how to do so in an ever-changing environment. The answers are gleaned from a year-round process that begins in December during pre-season training. While the riders are honing their bodies, ready for the multitude of races ahead, the number-crunchers eagerly gather data to better understand their nutritional needs. \"We know their individual bodies, their metabolism, how many calories they burn when resting and exactly what they will do in training, the intensity, how long and how many calories they will burn,\" says Visma-Lease a Bike head of nutrition Martijn Redegeld. \"Heart rate plays a role. We have that after each training ride. And at certain points in the season we test lactate measurements and breathing measurements in the lab to develop a good profile of each rider.\" As one of three teams - alongside UAE Team Emirates and Ineos Grenadiers - whose budget tends to dwarf all others, Visma-Lease a Bike has strived to place itself at the forefront of nutritional advancement. Partnerships with universities aim to ensure they are firmly aware of developments within the field \"to keep that competitive edge over other teams\", says Redegeld. With riders burning an average of 6,000 calories per day during the Tour (around three times more than a resting adult), Visma-Lease a Bike have even begun using artificial intelligence to help determine precisely how much - and what type of - food each individual cyclist should consume. Personalisation has become increasingly paramount, with the team developing its own app, , external where various algorithms are used to generate individualised nutrition plans. When a rider comes back from a day on the bike, they simply open the app and are told exactly how many grams of each nutritional component (carbohydrates, proteins, fats etc) to put on their plate. No brain power is wasted beyond using the ubiquitous buffet table weighing scales. While the methods used to generate precise nutritional needs vary between teams, all of them work to a broad five-meal daily plan of breakfast, pre-race snack, on-bike fuelling, recovery meal and dinner. The core feeding principles remain the same across the peloton, although they are tweaked depending on the upcoming day's requirements and whether the rider in question is a climber or a sprinter, a domestique or a general classification contender. Carbohydrates - usually in the form of rice or pasta - serve as the petrol, necessitating painfully high consumption levels. Proteins - predominantly fish or chicken - are always unprocessed and fibre is kept low to minimise gut irritation and aid digestion, with fruit and vegetables often consumed in juice form. Vegetarians tend to supplement themselves with protein shakes, in addition to plant-based proteins like tofu and seitan. Riders might be allowed more vegetables and fibrous foods before flatter race days, when the body will be better equipped to break them down, while red meats are saved as a treat the evening before rest days. On-bike fuelling comes courtesy of roadside soigneurs who load up musette bags with a variety of high-carbohydrate forms that can be selected or discarded based on personal preference. Energy bars, gels, drinks and gummies provide quick hits on tough days, while more traditional food sources include wet rice cakes, brioches, jam sandwiches, flapjacks, sweet breads and cakes for easier days. The required quantities are unenviably vast. Each rider consumes close to 1.5kg of rice or pasta every day and in the region of 120g of carbohydrates per hour when on the bike - the equivalent carbohydrate content of five hourly bananas. One EF rider once went through four tubs of maple syrup during the three-week race. IMAGE SOURCE, GETTY Image caption, Team backroom staff hand out grab bags of high-energy foods to their riders to enable them to fuel mid-stage Blandy's laptop contains a treasure trove of nutritional information to enable his menu design. One spreadsheet allows him to compare every food item's nutrient values to decide whether to cook with aubergines or parsnips, quinoa or couscous, chicken breast or chicken thigh. Another document comprises the EF Education-EasyPost recipe bible, listing a myriad of soups, salads, carbohydrates, proteins, sides, desserts, post-race snacks and drinks. In a bid to combat flavour fatigue, repetition is kept to an absolute minimum across a three-week race. \"The food I make is all transparent,\" says Blandy. \"There are no rich sauces, it's all plain, simple cooking with a light amount of seasoning, light amount of oil, fresh herbs and citrus. \"Instead of putting flavour in with cream, salt and butter we're adding it with herbs and citrus because they are low calorie and contain antioxidants.\" It does not lend itself to the type of innovative kitchen artistry you might see on television shows or in fancy restaurants. \"When I'm teaching new chefs, I always say the only way they will mess it up is by being too 'cheffy,'\" says Blandy. \"You need to swallow your chef ego and put it into a dessert or play around at the end of a race. Go wild then but don't mess with the simple stuff: the carbohydrates and proteins. Give the guys what they want and they will be happy. \"I've cooked risottos before and they've just asked for plain basmati rice. They aren't there on a holiday. They don't care about fancy food. They are literally there to fuel.\" IMAGE SOURCE, GETTY IMAGES Image caption, Rider nutrition has evolved since Joaquim Galera was considering the day's menu at the 1964 Tour de France Blandy estimates he has stayed - and therefore been tasked with cooking - at more than 300 hotels during his time working for EF Education-EasyPost. The transient nature of the job presents numerous logistical headaches. A chef's day at the Tour de France begins around 06:00. They must prepare fresh breakfast items (all packaged food has already been set up the night before) for 08:00 before packing up and driving to the next hotel while the race is ongoing. As well as cooking the food, they are also responsible for procuring it - a task that varies depending on team and, crucially, sponsor. Blandy's experience of European supermarkets means he knows where to find the highest-quality food and shops personally for most of it, in addition to emailing hotels in advance to order some perishable items. Conversely, Visma-Lease a Bike have been sponsored since 2014 by Dutch supermarket Jumbo, who provide all their food at every race, including the Tour de France. \"During a Grand Tour there are three times that a new delivery comes from the Netherlands to stock up on fresh produce,\" says Redegeld. \"It's always the same Dutch food and the guys like that because they know what to expect and we know what products they like, so we can always have that available. \"It makes things a lot easier for the chefs who don't have to search in local supermarkets for things. For me as a nutritionist, we know the nutritional values of all the products so it makes the calculations a lot easier.\" Upon arriving at a hotel, chefs will begin preparations for dinner and the following day's breakfast and snacks. Professional cycling teams tend to adhere to one of two dining styles. Most travel with customised kitchen trucks - a similar size to supermarket delivery vans - where food is stored and meals cooked. Food is then served up for the riders and wider team members in a private room inside the hotel. A select few teams - including Ineos Grenadiers - instead choose to travel with a far bigger lorry, which contains a kitchen and dining room. Camaraderie between chefs on rival teams is high. \"Sometimes you're in a hotel with six teams, so the car parks are rammed,\" says Blandy. \"It's manic. Everyone is sharing water and electricity. So you have to scratch each other's backs. Chefs come to me and ask for an ingredient and I go to them. We help each other out.\" Image caption, Blandy cooks in the car park, before serving up in a dining room in the team hotel It is a world away from the three successive weeks of pasta with tomato sauce that riders just a generation ago were accustomed to stomaching throughout their Tour de France endeavours. Redegeld predicts the nutrition evolution will continue, suggesting that within a decade or so teams will employ DNA analysis to take rider fuelling personalisation to the next level. But all the analytics are worthless without someone to prepare the food. Earlier this year, Blandy was all set for a quiet week at home when he received an SOS from the team. He was given half an hour to pack his bags and jump in a taxi to the airport because a fellow EF Education-EasyPost chef had fallen ill before the Paris-Roubaix race. \"I rolled my knives up and threw them in a suitcase,\" he says. \"I felt like chef special forces.\" Cooking is serious business in the elite cycling world. Related Topics Insight: In-depth stories from the world of sport Cycling Previously on Insight Panenka - the penalty that killed a career and started a feud Published 5 days ago The people v Andy Murray: Four weeks that changed him and us Published 6 days ago Running on a volcano's rim - the race in the shadow of an eruption Published 7 days ago The awkward questions behind Hungary's football revival Published 20 June Fleeing Kabul, chasing gold - the story of a refugee Olympian Published 20 June",
    "commentLink": "https://news.ycombinator.com/item?id=40860364",
    "commentBody": "Tour de France: How professional cycling teams eat and cook on the road (bbc.co.uk)106 points by skruger 8 hours agohidepastfavorite132 comments philshem 33 minutes ago> \"The food I make is all transparent,\" says (chef) Blandy. \"There are no rich sauces, it's all plain, simple cooking with a light amount of seasoning, light amount of oil, fresh herbs and citrus. That’s some top-notch nominative determinism. https://en.wikipedia.org/wiki/Nominative_determinism reply eloycoto 6 hours agoprevNowadays, some riders use glucose monitoring devices during training with relation to how long it takes from ingesting and getting into blood. They are now measuring more and more things, and food is a crucial role. Glucose monitoring is banned during races, but I guess that is why you don't see some cyclist collapsing like as 15 years ago is because they understand their glucose levels. For sure, doping it's still a fear, but these guys cannot climb Galibier at that speed only with storoids/drugs, it's insane the effort that they did over the year. reply hinkley 59 minutes agoparentI haven't been a cyclist since about the time that the market of energy drinks first exploded. And at the time there were a number of articles that said that really all you need is Gatorade, that most of these new drinks were advertising more calories per liter, but Gatorade was already tested out on absorption rates and dialed in to the maximum calories per liter of water that the average human stomach can absorb. The tricky word there is average. If Tadej can absorb an extra 5 grams per liter, then you should give Tadej an extra five grams per liter. If Jonas can absorb 2 grams less per liter than the average then you should give him that serving. These race results come down to mere seconds per hundred miles, for cyclists that are averaging 20 miles an hour. Any 1% difference is going into the training regimen. reply 0_____0 46 minutes agorootparentI still use Gatorade because I'm a cheap bastard. The limits aren't wrt water absorption, but gut tolerance of sugar. I get about 100g of sugar into a bottle by doing roughly 50:50 Gatorade and maltodextrin, and then throwing in some extra Na an K salt if it's going to be hot. Although with the super hi carb stuff you should make sure that you have some plain water as well - it sucks to be super thirsty but only have carb drink on the bike. reply ricw 46 minutes agorootparentprevthat is outdated advice. for one, some people sweat more than others, the salt levels in the sweat is totally different too. this means that if you're really serious about sport or are doing endurance races (ie 2 hours+) you should really not just use gatorade, but something where the mix of salt/water is closer to whatever you're sweating. if i personally use gatorade for endurance exercise, i'll just cramp up after 90 minutes and not be able to ride normally. if i use a high salt mix instead, this isn't an issue whatsoever. I'm sure the exact same is true about food itself. remember that for the tour de france, last years time difference between the winner (Vingegaard) and the second (Pogadcar) was 8 minutes out of 82h 05' 42\", aka only 0.16% faster overall. every single sub-percentage matters here. there are tons of products that cater to this. the one i've been using is https://www.precisionhydration.com/ which is cheaper and more tailored than gatorade (i have no affiliation to them). reply 0_____0 43 minutes agorootparentI basically just add salt to Gatorade and cut it with extra sugar and malto. It's a couple extra steps but I train regularly enough that I make a concentrate (100ml=200kcal) that I put in bottle and dilute as needed. reply hinkley 29 minutes agorootparentOne of the runners I mined for training advice was using gatorade to take salt tabs. That was not the advice I took from him, though. I will probably avoid at least one injury from other things he said. reply hinkley 39 minutes agorootparentprevYeah I wasn't talking about electrolytes, just calories per minute. The top level was about glucose monitoring not electrolyte monitoring. It's funny that Precision uses almost exactly the same bottle as Nuun. reply deff 6 hours agoparentprevThat is indeed why you don´t see them collapsing and also why the finals are much longer nowadays. Riders train their guts to be able to eat up to 120g of carbs per hour, for the whole duration of the race. reply avs733 6 hours agorootparentI am far FAR from the tour de france but I do train for and run ultramarathons. When I started the general guidance seemed to be about 200 calories (50g of carbs) per hour during training and races. I followed that or a little above for a long time, and constantly had problems both physically and cognitively near the end of races. It took about a year to get used to fueling heavier (for me...about 400 calories per hour or 100g). Lots of figuring out digestion and timing and sources and other factors. But once I got there it was transformative...I could push much harder for much longer without a deep bonk and recovery was faster. More importantly, my ability to think/plan/make decisions at the end of races was orders of magnitude better. I'd bet if you went to an aid station around 80 miles on a 100mile ultra marathon you could pretty reliably identify who had been on the 200cal end of the spectrum and who had been on the 400 + end. reply WXLCKNO 3 hours agorootparentAt 250w average during a 5 hour ride I'm burning like 1000 calories per hour or something mething close. Glycogen reserves are 2000 calories from a quick Google search, so that's 3k calories I need to make up for or 600 per hour. I'm sure there's a bunch of stuff I'm missing but 400 definitely makes more sense than 200 reply nradov 3 hours agorootparentWhat you're missing is fat metabolism. If you're metabolically healthy (which you must be if you can hold 250W for hours) then you can make up the difference by converting stored fat into glycogen. reply avs733 13 minutes agorootparentwhat is also missing is the ability to process calories in. 900-1000 calories might mean that in is optimal - but think about eating a full meal from mcdonalds every hour while massively extering yourself. Training your gut matters and I've never seen anything that suggests much beyond 400 calories per hour is possible during meaningful exertion. reply WXLCKNO 2 hours agorootparentprevRight! That was a big missing chunk :) reply matsemann 2 hours agorootparentprevYup, part of my long distance cycle training was somewhat getting \"fat adapted\". reply notesinthefield 56 minutes agorootparentprevSince my first ultra, Ive been fascinated by the idea of adapting to increased fueling and have tried to apply periodization principles to how I eat. 23 miles into a 33 race, I completely stopped being able to process food at around 150-250 cals/hr (mostly carbs and some fats) reply avs733 12 minutes agorootparentspeaking from experience - I puked during a fair number of runs in the process of getting there. I mix calories in my hydration with gels just to try and get the balance right. Its not stable but its better after about 4 years of work. I have ound that if I don't do a good job of eating, what you describe happens about 6-10 miles AFTER I stopped caloric intake. reply davidw 6 hours agorootparentprevYeah, some of the modern nutrition stuff like gels work really well. I did a 115 mile road bike ride on Sunday and kept eating gels and... I'm not going to say I was super fresh or anything by the end of that, but I was still feeling pretty good. reply prmoustache 5 hours agorootparentThere is usually a point where you can't get those gel inside. It is nice to mix with other stuff. reply matsemann 2 hours agorootparentAfter my longest ever bike ride, 300 km, I didn't touch a gel for years, heh. Got so sick of 3+ gels per hour for those ~8 hours. reply 0_____0 39 minutes agorootparentI dropped gels pretty fast. Hard to get if you're not somewhere with sports stores, and expensive. These days I cram haribo and peanut butter M&Ms, although I think the latter are more useful for multiday things. reply frereubu 6 hours agoprevThe part about not eating too much fibre because it irritates the gut reminded me of an amusing anecdote in Dan Martin's autobiography, where he talked about coming (I think) third in The Tour and was sitting with Chris Froome and Geraint Thomas from Team Sky (now Ineos Grenadiers) after the finish in Paris. He was looking forward to a big burger and chips, and Froome and Thomas were discussing how they were really looking forward to a nice salad (i.e. lots of fibre). He partly admired the dedication, but at the same time wondered how on earth they could live like that. reply AndrewOMartin 4 hours agoparentSalads can be really good in Paris! :D Martin might just be imagining a slice of tomato on a leaf of lettuce, Froome and Thomas might have been imagining a range of herbs and roasted nuts with a delicious oil or vinaigrette, chunks of an interesting cheese or two and some powerful olives and garlic. Or thereabouts. reply hinkley 52 minutes agoparentprevRunners also warn about high fiber being bad. I keep being drawn back to our friend the Banana. I think pectin is easier on the stomach than insoluble fiber, but I have a lot of gaps in this part of my knowledge. The cheeseburger calls to us all. Some of us are just \"better\" at resisting the call. reply burningChrome 28 minutes agorootparent>> The cheeseburger calls to us all. One my trainers when I was in college told me that when you crave foods, its not your lack of willpower, its actually your body telling you it needs certain nutrients. He told me when you crave chocolate its because your body needs carbs, so if you get some carbs, your chocolate cravings will go away. I'm guessing the idea you crave a cheeseburger is the same thing, his body was in need of complex carbs and protein? This is purely anecdotal evidence of this, but in my experience as an endurance athlete (soccer, cycling, adventure racing) its seems to work. When I've craved chocolate, I just eat some toast or chips or drink some Mt. Dew (a lot of people have no idea how many carbs are in soda) and the desire for something chocolatey goes away. As others have pointed out in the thread, everybody is different, but in my case, this idea seems to be accurate. reply hinkley 21 minutes agorootparentProtein and fat, but probably mostly salt. One year I bumped into a friend of a friend at the checkin for a 3 day bike tour and we decided to 1) ride together and 2) see how fast we could do it. Short rests, riding hard, drafting the entire way. All day, in the Labor Day sun. On day two after we pulled up to the stopping point, we got set up and then crawled back on our bikes to ride to the other side of this small college town to find the Dairy Queen for a bacon cheeseburger. It's not the best tasting beef I've ever had (that was in New Orleans), but it was the best tasting burger. reply hinkley 16 minutes agorootparentprevIn a completely unrelated anecdote, one day on a club ride we were almost to the turnaround point for the day. The town was on a hill on the far side of a river valley and it was a relatively nasty hill. One of the older guys was falling off the back and I and a few other people heard him yell something but we couldn't make out what it was, so we dropped back to see if he was okay. He had yelled \"CHEESEBURGER!\" as a rally cry. reply Optimal_Persona 1 hour agoparentprevTomorrow's headline: Turd de France - How professional cyclists poop (or don't) on the road... reply hinkley 52 minutes agorootparentDon't poop on the road, poop in the bushes. reply deff 6 hours agoprevRegarding drugs, yes it´s most likely still happening, but nowhere near the levels it used to be. Riders are tested a lot and have to provide year-round whereabouts for random testing. They also have a frequently updated blood passport to detect sudden changes in values caused by PEDs. It can never be fully waterproof, but at least serious efforts are made. reply burningChrome 22 minutes agoparent>> Riders are tested a lot and have to provide year-round whereabouts for random testing. If I remember correctly, these rules were changed after the Armstrong scandal where he would be scheduled for testing, he would say he was at his house in Texas. The testing folks would show up and he just wouldn't answer the door and wait until they left so they couldn't test him. It was one of the ways he was able to dope on a set schedule, all the while being able to maintain he was being tested more than any other athlete - when in reality, he was just avoiding being tested. It seems like a lot has changed since his scandal and several others that followed and they've really clamped down on what you're saying, changes in blood values and getting suspended if you cannot be reached for testing. reply hinkley 50 minutes agoparentprevAt the Track and Field qualifiers for the 2024 Olympics they kept talking about how one of the runners was disqualified from Tokyo because she violated the whereabouts rules. They didn't say how. Is that like parole where they check in, or is it like house arrest where you have an ankle monitor? reply xcskier56 37 minutes agorootparentIt's a bit of both. If you're an athlete being tested at that level, you have to keep your country's antidoping agency informed of your whereabouts at all times. They will randomly send testers to wherever you are and you have a short time window, like 1-3 hours to show up. If you no-show 3 times (I think) it counts as a positive test and you're banned. I really don't know how someone could run in the trials with too many missed tests and not be allowed to race the olympics... I'm pretty sure the rules are the same. reply hinkley 32 minutes agorootparentIf you missed 2 before the trials and another after? I could see someone being on final notice before the trials and then fucking up again. But they didn't actually say how and when she was DQed, just that she missed the Tokyo Olympics due to breaking the whereabouts clause. There are clearly favorites at the trials and if someone 'should' have gone I could see announcers making the speculative leap. reply flosstop 4 hours agoparentprevThey have moved on from pharmaceutical doping due to the extensive testing to what is referred to as \"mechanical doping\". Motors are hidden in hubs/frames and the organisation is busy doing everything they can to pretend that it isn't a problem. reply kergonath 4 hours agorootparentThey do systematic checks for the winner, whoever has suspicious performance jumps one day, as well as random racers. They do take it very seriously and what you are saying is a bit far from the truth. Some people will try, and some scandals will happen, sure. But it is not a widespread problem and is unlikely to become one. See here, for example: https://velo.outsideonline.com/road/road-racing/tour-de-fran... reply hinkley 44 minutes agorootparentI've lost track of how many bike changes I've seen and I've only watched the first 3 days of coverage so far. Plus if your lieutenant uses a motor in order to pull you up to the front, then your bike is clean. reply xcskier56 35 minutes agorootparentThrough axels have become a very convenient excuse for bike changes. Watching Cavendish have his wheels changed in one of the early stages this year was so slow. It took a guy with a drill like a minute plus to do front and rear wheels. reply hinkley 27 minutes agorootparentI just learned about through axles last fall. And narrow-wide chain rings (mountain biking). I used to keep up better with the tech changes. I only caught the end of that wheel change when I realized the mechanic was holding a Milwaukee cordless and Bob(?) was talking about it. reply deff 1 hour agorootparentprevImpossible to use mechanical doping now with the current inspections. Has it been used before these inspections were implemented? Very likely. An hungarian engineer developed a motor with spools in the rims and the stator in the forks. For sure at some point this offered a better risk/reward than PEDs. reply hinkley 48 minutes agorootparentGreg LeMond was one of the people calling for more scrutiny of bikes for mechanical tampering. One of the best pieces of evidence he provided were thermal cameras pointed at bikes while they were in motion. Lots of thermal blooming in places no professional bike mechanic generate a tenths that much friction. One of the problems is that bikes can be made so light with unobtainium that there are rules in place requiring a minimum weight so that poorer teams can compete. So if you make a bike that's 10 lbs you have to stick weights into it to bring it up to spec. What else could you put in that bike besides chunks of iron pipe? reply fuzzylightbulb 4 hours agorootparentprevMechanical doping, a problem so wide-spread that only one person at the elite level has ever been found to have been doing it. To date, no one has ever provided hard evidence of another rider using a motor. I am not saying that this doesn't happen at the amateur level (it certainly does) but to imply that this is a pervasive problem in elite cycling is little more than a baseless conspiracy theory until someone shows up with some actual evidence of motors being used in major events. Ghost in the Machine [1] is a great podcast on this topic. [1] https://play.pocketcasts.com/discover/podcast/de6ba1d0-9132-... reply hinkley 42 minutes agorootparentOnly one person has been caught. It's been a long time since I bothered to look into this, but LeMond suspected at least half a dozen people, with video evidence of varying degrees of plausibility. The thermal imaging and the fallen rider with the spinning wheels were especially damning. But if you're analyzing old races how do you get a conviction? You can't. reply fsckboy 51 minutes agorootparentprevthe long history of cheating at the highest levels of every sport indicates that if there is not mechanical doping in cycling, it's because the mechanical technology is not as good at hiding yet as it needs to be. We are talking about human beings here. reply hinkley 41 minutes agorootparentI really, really want someone to commercialize the mechanical doping tech they've been using. Get caught and go straight please. Give me a bike that looks like a normal bike and gives mere mortals like me an extra 5 mph (power law makes that a lot worse for pros). reply jdietrich 3 hours agorootparentprevWe've had a handful of cases at the lower levels of the sport, but I think the scrutineering is just too strict for anyone to get away with it at the ProTour level. The UCI have got mobile x-ray facilities which they're starting to use much more rigorously. https://www.uci.org/pressrelease/uci-reveals-technological-f... reply cptcobalt 4 hours agorootparentprevReally, hidden motors in the tour? That would be an interesting read. reply kergonath 3 hours agorootparentNo, not really. These motors exist, but it’s not really a thing on the Tour de France. And I only mention this race because I am not much of a devotee and don’t really follow the others, but I would expect quite a lot of noise if it were a thing in the other big races. reply Jean-Papoulos 7 hours agoprevNote for everyone that will come in here to say the secret is drugs : In cyclism taking drugs is not considered a secret, it's common practice. reply alistairSH 6 hours agoparentIn professional sports taking drugs is not considered a secret, it's common practice Fixed. Cycling has one of the strictest out-of-competition testing regimens. Which isn't to say doping doesn't exist - it does, no question - only that it's WAY better now than during the Armstrong era. Some details... https://lanternerouge.com/2023/03/26/how-clean-is-cycling-an... reply skeeter2020 5 hours agorootparentThey're still fighting a losing battle. The business of cycling dictates that they remain ever vigilant and attempt to catch dopers and keep the sport \"clean\", while the science of what the atheletes are trying to do suggests they should just accept the reality and not police legal vs. illegal. It's like a drug-free body building contenst; what's the point? reply alistairSH 4 hours agorootparentI'm not sure I'd call it a losing battle. But, I agree vigilance is necessary. But, I also view anti-doping measures as more of a safety issue than a fairness issue (maybe 60/40-ish). First priority - prevent athletes (and their coaches/sponsors) killing or crippling themselves with chemicals. Second order - guarantee some baseline level of fairness (because without it, the fans go elsewhere). This isn't really different than rules in motor racing. Gotta keep the drivers safe first, and keep the race entertaining (nobody outside Italy wants to see two Ferraris dominate every F1 GP). reply skhr0680 5 hours agorootparentprev> It's like a drug-free body building contenst; what's the point? The point is to not die or be in a wheelchair by the time you’re 60 reply pyrale 4 hours agorootparentAlso to make it a sports contest and not a pharma contest. It's the same reason there's a minimum weight for bikes used in the race: people tend to disregard security when making lighter bikes, and the cost of experiments means that some competitors exit the sport because they can't compete on funding. reply matwood 5 hours agorootparentprevIf that's the goal, then you might as well get rid of all contact sports - drugs or not. reply alistairSH 3 hours agorootparentProbably a case to be made for doing that. At least with martial arts/combat sports, American football, and probably rugby (mostly related to brain damage, not broken bones/joints). reply Jean-Papoulos 4 hours agorootparentprevAdmiring what human dedication does, not what human drugs do. reply knallfrosch 6 hours agoparentprevAnd since everyone is taking them, they're not the discriminator between the world class champions and the merely Tour-de-France participants. reply matthewowen 4 hours agorootparentThere is a common refrain about the Armstrong era \"all the top guys were taking them so it's fair\" but it's not really accurate. Because yes, the people at the top were all taking them, but that's because the clean guys that _would_ have been at the top otherwise aren't there: the prevalence of doping meant that you had to dope to even be in the conversation at that level, and so the clean athletes that might have won otherwise aren't coming in 18th, they're at home on the couch or they're racing at the pro-conti level. For example, Greg LeMond won the TdF in 1990. In 1991 he came 7th, and then never completed it again. There is some complication here because of the hunting accident he suffered in '87, but he also said \"The speeds were faster and riders that I had easily outperformed were now dropping me\", and the guy who won in 1991 was Indurain who was basically the first mega-doper. Without EPO and blood doping becoming prevalent, does Greg LeMond compete for a few more years? Do other guys with similar talent who aren't willing to dope also make it to that top level. I think the answer is probably yes, and so all those guys who doped are responsible for excluding those clean athletes from the top level. reply vbarrielle 6 minutes agorootparentYou're spot on, and there's another point that makes doping unfair even if it was widespread. There is a max hematocrit rule, but riders had different pre-doping base hematocrit levels. Those with the lowest level could benefit more from doping before reaching the limit. In a way, the less gifted would be more advantaged by EPO. reply parthdesai 5 hours agoparentprevMy personal semi-conspiracy theory is that cycling is the only sport that took anti doping measures seriously and sort of fucked itself over. All the \"anti\" doping measures in major sports are laughable. There's too much money involved for the athletes to be not on steroids. reply gosub100 5 hours agoparentprevAnd to me, there's a distinction between taking a drug that increases availability of red blood cells vs taking steroids or meth. reply alistairSH 3 hours agorootparentIsn't that really sport-dependent? EPO and other red-cell increasing drugs provide a massive gain for endurance athletes (runners, cyclists, XC skiing). Steroids are a massive gain for strength athletes (sprinters/athletics, contact sports). Both can be used \"safely\" or \"unsafely\" depending on dosage, combinations with other drugs, etc. reply eric-hu 2 minutes agorootparentMy understanding of steroids is that they increase muscle mass all over the body. And that it's a long term health issue for the heart, because having a heart with excess muscle is actually bad long term. A few lifting YouTubers I follow have made videos on the subject. It seems like there's \"less unsafe\" steroid use, but there will be a life expectancy sacrifice with any level of use. I don't know what the story is like for EPO and other red-cell increasing drugs. Would be curious to hear yours and a few others' understanding of the cost/benefit. reply gosub100 3 hours agorootparentprevMy opinion is that roids are much worse. And I included meth for dramatic contrast. It's not so much about the gain it's about the danger and harm. But I'm sure this will invite all sorts of semantic bickering about the meaning of the word \"danger\". As I said it's my opinion about where the line should be drawn. reply skeeter2020 5 hours agorootparentprevWhat's the distinction? What about taking something when you have a cold, or nutritional supplements? It seems weird to draw an arbitrary line between things that make a body perform by stimulating natural production vs directly using synthetics. reply jerlam 1 hour agorootparentSeconded, there is no clear line between banned drugs that help you cheat and drugs that fix medical conditions. There are drugs that are allowed if you have a doctor's note, and there are drugs that you can use only up to a certain amount. Asthma meds for cycling, some of which are steroids, are one of the more popular examples: https://www.cyclingweekly.com/news/latest-news/the-truth-abo... reply vbarrielle 0 minutes agorootparentWADA rules do not ban a drug just because it is performance enhancing. Otherwise caffeine would be banned. Two out of three factors have to be present to ban a drug: - be performance enhancing - present a health risk - violate the spirit of sport The third one is a bit harder to define but there is a WADA code defining the spirit of sport. Most banned drugs are banned because of the first two. ydant 6 hours agoprevI enjoyed this show about feeding the tour riders: Eat. Race. Win. https://www.amazon.com/Eat-Race-Win-Season-1/dp/B086HVQ5RB Related, Unchained (https://www.netflix.com/title/81153133) has been an interesting view into the race although food isn't discussed at all. Before Eat. Race. Win. I had this entirely uninformed idea the food the riders ate would be incredibly streamlined and controlled - I was thinking something like Soylent and protein powder and supplements. To see them chowing down on \"normal\" food and drinking alcohol (at all) was surprising for me. reply gullywhumper 5 hours agoparentThe alcohol really surprises me given how meticulous they are about everything else - especially sleep monitoring. After a big win, it's not uncommon for the entire team to have sparkling wine or beer that night. Maybe not a big deal for one day races, but with stage races they usually have another hard race the next day. On the podium during stage races, victors will often drink sparkling wine/beer too. After winning a stage at last year's Vuelta a España (one of the major multi-day stage races) Sepp Kuss took a huge long chug on the podium - and then went on to when the entire race [1]! Some riders used to drink during races too. Freddy Maertens was able to do it and still win [2]. [1] https://www.atwistedspoke.com/sepp-kuss-champagne-supernova/ [2] https://en.wikipedia.org/wiki/Freddy_Maertens#Alcohol reply jdietrich 3 hours agorootparentAny risks in terms of performance have to be weighed up against the benefits to morale. A grand tour is long, a full year's calendar of racing is even longer, but a glass of champagne to celebrate a win goes a long way towards breaking up the monotony of suffering. reply matsemann 6 hours agoprevI'm a bit sad that a topic I find so interesting mostly gathers knee-jerk reactions here on HN. Yes, doping, blah blah we get it. But the logistics of TdF is insane. With a new city every day, things need to move fast and preparations start early. For instance Uno-X team has a small trailer with 800 kgs of ice they travel around with, after having trouble sourcing enough ice in the small villages they stay at. Actually having your own chef source stuff is one way to avoid accidental doping scandals. I've read the Velochef book and like the recipes there. One thing I've never appreciated before is how hard it is to actually get this amount of calories down. Especially since much of it must be consumed on the bike so needs to be easy to transport/store/eat on the fly. And eating while working out can be tough on the stomach. EDB finally got his break through when they managed to nail a nutrition he didn't get cramps from eating. reply durkie 4 hours agoparentreminds me of an anecdote from Le Ride (https://en.wikipedia.org/wiki/Le_Ride ) that talks about in one of the early Tours de France, a rider was disqualified because he broke his crank, hobbled to a nearby town, found the blacksmith, and the rider welded his own crank back together, but the blacksmith's son operated the bellows and this was seen as too much external assistance. reply ydant 1 hour agorootparentLooks to be this rider - Eugène Christophe: https://en.wikipedia.org/wiki/Eug%C3%A8ne_Christophe reply mesofile 6 hours agoparentprevSorry, I follow cycling casually but I'm racking my brain trying to think of who 'EDB' refers to. reply ragazzina 4 hours agorootparentChatGPT suggests self-assuredly and completely wrong \"The famous cyclist known by the acronym EDB is Egan Daniel Bernal\". reply wiether 5 hours agorootparentprevSame, I can't find anyone close to it. reply matsemann 2 hours agorootparentSorry, it was an autocorrect by my phone. EDB means Elektronisk Data Behandling, which is an archaic Norwegian way of writing computers, lol.. I meant to write EBH, Edvald Boasson-Hagen. I probably should've spelled it out, but the Velochef book is by the Team Sky chef, the team of EBH. reply JojoFatsani 7 hours agoprevnext [3 more] [flagged] InDubioProRubio 7 hours agoparentSteroids after cancer-survival! Thats steroids on steroids! reply damontal 6 hours agorootparentSteroids before too. He speculated that the growth hormone actually triggered the cancer growth. reply toyg 7 hours agoprevHundreds of thousands of dollars spent on this stuff, and then someone finds the right, undetectable doping mix, and bye bye. reply sdfgtr 6 hours agoparentTbf, millions is spent on that part. This seems to be a drop in the bucket. reply laweijfmvo 1 hour agoprevThat any human can complete a race like this is still mind boggling to me, regardless of what you eat. reply bell-cot 7 hours agoprev [–] > Not so long ago, the professional cycling world's approach to fuelling was remarkably basic. [...] > These days, it is an entirely different prospect, with vast sums spent on custom-built food trucks, personalised nutrition apps and meticulously planned meal regimes all in the name of performance enhancement. > For the nutritionists and chefs tasked with providing sustenance to power their team's riders over 2,170 miles in the coming weeks there are principally two dilemmas [...] > The answers are gleaned from a year-round process that begins in December during pre- season training. You know that it has become the Sport Of The 0.0001% when... reply NoPicklez 7 hours agoparentIt's not a sport of the 0.0001% when anybody can go buy a bike and ride. At the top level of any sport and in the top race or competition of that sport, it is going to represent the pinnacle of that sport. reply bell-cot 2 hours agorootparentFrom a quick skim here - https://en.wikipedia.org/wiki/List_of_teams_and_cyclists_in_... - all but one team are from well-to-do Western countries, or rich Gulf States. Cyclists seem similarly all-but-a-few white. Anyone can learn a bunch of gymnastic moves, too. But last I heard, \"Olympic Gymnast\" implies a >1k hour/year training regimen, starting at an extremely young age. reply tpm 42 minutes agorootparentPrimoz Roglic was a ski jumper before he was one of the best cyclists. There are several others like him. Most of the cyclists are white, yes, for me this is an issue (and I am white), but what I like is that there are now many from Colombia (because of the mountains there? And probably also some cycling culture), a few days ago a cyclist from Eritrea won a TdF stage.. it's slowly getting more diverse. reply n4r9 6 hours agorootparentprevI guess the point is that in cycling - relative to other sports - money gives you an easy edge. You can afford much better equipment, nutrition, coaching etc... . Compare that to (say) football in the UK: you just need a £5 ball and a few friends, and if you show promise you can track into your local team's programme and get top quality coaching at minimal cost. It depends on the culture as well. From what I read about China, they're constantly scouting primary schools for Olympic talent, so you can come from any background and reach the top in a sport that would be limited to wealthier people in other countries. reply SonicScrub 5 hours agorootparentAt the top level of any sport, the expense comes from the coaching, exercise science, travel and other support over the course of years. That's true whether the game is cycling, or football. A $20,000 bike is peanuts in comparison to this cost. Unless you are at the top 0.001 percent of cyclists, better/more training has a much bigger impact than gear. $1,000 gets you a competitive road bike that you can win your local races with. Even cheaper if you buy used. > From what I read about China, they're constantly scouting primary schools for Olympic talent, so you can come from any background and reach the top in a sport that would be limited to wealthier people in other countries. This is what wealthy countries do as well. Most wealthy nations have programs to identify and develop top-level athletes. An obvious example being the very lucrative scholarships offered at American universities. reply bluGill 5 hours agorootparentprevIf you do well on a cheap bike in a local race someone will notice and start asking if you belong on a major team with money. The teams with money want to win, they cannot afford to keep out a poor person who otherwise is good. reply Arainach 6 hours agorootparentprevAt levels lower than the very top, it's easier and cheaper to lose 10 pounds of your own body than 10 pounds of bike. You can go far - even into racing at low levels - on rather cheap equipment. reply NoPicklez 4 hours agorootparentprevThe performance difference between cheaper bikes and top end bikes won’t make the difference in being a successful cyclist. Anyone can pick up a bike and start training and racing in competitions and be talent scouted in the same way that you would in football, it’s what happens here in Australia. Yes a football is cheaper than a bike, but it’s not 0.0001% type stuff like Formula 1. Where you legitimately need to pay millions just to get a look in. Theres plenty of people on $8,000 bikes I pass on my 8 year old bike worth $2,000. reply n4r9 3 hours agorootparentIs $2000 really \"cheap\" though? I personally would need to use a cycle to work scheme, and I consider myself pretty well off. I know people on lower incomes who would find that very off-putting as a barrier to entry. I think you'd need to go to the $150 or less range to be appealing to people in that situation. reply toast0 2 hours agorootparent$2000 is not bad looking at what it costs to play hockey. A lot of sports are less expensive though. Otoh, around me, $100 gets you a circa 1980 road bike off craigslist. That'll do fine. I'm seeing a much more recent road bike for $500, if you don't like old stuff because it's old. Plenty of more expensive stuff too. I like the early 1980s bikes because road bikes were in fashion and there were a lot of makes competing and quality (of surviving bikes) is pretty good. Later, mountain bikes started trending, there was consolidation and I don't feel that those bikes are as good on the road as a general rule. reply jamil7 6 hours agorootparentprevWhat makes the largest difference is how physically fit and how well you can ride (technique) rather than equipment. reply alistairSH 6 hours agorootparentprevI'm not sure how that's any different than football (soccer) or football (American) or anything else. You need talent as a kid. You need money to fund travel and equipment (either from mom & dad, or the local academy/development squad, or donors). You need to find a coach who can get the most out of your genetics AND find a path for you to go pro. And on and on. reply matwood 5 hours agorootparentprevMoney can help in any sport, but talent and physical attributes trumps all. At least with cycling, people can cycle almost anywhere. Sports like golf are hard to break into if someone doesn't have money because rounds and practice almost always have ongoing costs. reply timeon 4 hours agorootparentprevPeter Sagan started career winning on Tesco bike that he took from his sister. But I think most accessible sport is running. You just need some shoes. Open the door and you are good to go (run). For games like football you also need the ball, playground and other people. reply secondcoming 5 hours agorootparentprevI've never seen so many young people on bikes in the UK as I do now. Sure, the bikes are likely stolen and the kids up to no good, but at least one of them has TdF potential reply shermantanktop 4 hours agorootparentThe kids may be doping, too. reply wasmitnetzen 6 hours agoparentprevA UCI WorldTeam has a budget of about 10 to 60 million euros. That's peanuts in a lot of other sports. reply bell-cot 3 hours agorootparentIf that budget is for an 8-man team, in a sport with a 3 1/2-week season... An (American) NFL team has 53 \"active\" players (plus a practice squad, plus ...), and plays a 5-month season. And has a lot of \"maintain a major stadium\"-type expenses, which (my guess) cycling teams don't have. Based on your figures, and trying to scale...no, the cycling team budgets really aren't peanuts by comparison. NFL Data: https://shareholder.broadridge.com/pdf/2022-packers-annual-r... reply roelschroeven 53 minutes agorootparent> An (American) NFL team has 53 \"active\" players (plus a practice squad, plus ...), and plays a 5-month season. And has a lot of \"maintain a major stadium\"-type expenses, which (my guess) cycling teams don't have. Cycling teams have all kinds of expenses too. True, they don't have to maintain a major stadium. But hey do have cars to assist the riders with food, drinks, spare tires, spare bikes if needed (sometimes multiple types of bike for some of the riders); team busses with showers, more food, meeting room (I think they also have washing machines in them, to provide the riders with clean clothing every day in a stage race); a service course for all the equipment, and to adjust and fix the bikes. Plus personnel to equip all those, plus personnel along the road with more food and drinks, and in some races also with spare wheels. Pro teams often participate in multiple races at the same time, so they need all that equipment times two or three. These days many teams haul mattresses along on stage races, to guarantee good sleep for the riders. All of that stuff, and the people involved, need to be transported to each race on time, sometimes to the other end of the world. I don't know how that compares with say an NFL team, but I do know my head starts to hurt when I think about how to organize all of that (and more; I most likely forgot some stuff) throughout the year. reply matsemann 2 hours agorootparentprevIt's clear you don't know much about cycling. A pro team often consists of ~30 riders, and then 8~12 of them are selected for various races during the year. And similarly, that's the main team and they have development teams on the second level, junior teams, women teams etc The season is longer than tour de france, that's just the most prestigious tour. There are other tours and other races. It's about 8 months long. And I don't really think how long the season is has any relevance. You still train and need your apparatus whole year round. The stadium stuff also doesn't really work in the favor of nfl. A pro team makes no money on tickets or concessions, and has to travel the world with their gear instead of a few states away. reply wnc3141 1 hour agorootparentThe tour I think of like the World Series or Champions League tournament. Only one, highly visible, piece of a long calender (roughly Februrary to October) reply skeeter2020 5 hours agorootparentprevMaybe mainstream sports, but not when you spread it across the number of fans and account for their intensity. The Tour de France is likely the only cycling event most people can name. It's an awful lot of money for a very niche sport. reply jeroen 5 hours agorootparentThe TdF is apparently the 2nd most watched sporting event in the world, with 3.5 billion viewers. That's not very niche. -- https://www.roadtrips.com/blog/the-most-watched-sporting-eve... reply borroka 3 hours agorootparentThe number, which by the common person is to be interpreted as unique viewers, is blatantly absurd. reply jdietrich 3 hours agorootparentprevIt's a niche sport in the US, but it's huge in lots of European countries. Conversely, most Europeans would struggle to name a single baseball or American football team, but they're far from niche sports in their domestic market. reply Angostura 6 hours agoparentprev25,000 people took part in last month’s Ride London. It was awesome reply Ekaros 7 hours agoparentprev [–] Sometimes I wonder should we go to basics in many sports. With things like banning any equipment including clothing and shoes... Or with cycling giving one standard mass manufactured piece. And then a pile of standard replacement parts and standard tools. All bought from cheapest supplier randomly distributed to participants. reply cangeroo 6 hours agorootparentIt's impossible to take technology out of the equation. I.e. that one person may have superior insights in their physiology/glucose levels, or a superior diet before the race. And so on. Similarly in football, by studying your opponents in previous matches, so that you can identify weaknesses during the match, even if playing in isolation. reply Lwerewolf 5 hours agorootparentprevSounds like the typical case of people not looking at the core work required in order for the very expensive individual items like tailored nutrition, top-end (and even customized) parts, per-race-specific optimized chains and what not to make any sense whatsoever. If your times are, say, 20% or more above the absolute top times for a given course, you've got a long way to go by improving yourself - on just about any bike whatsoever. The super expensive parts make low single digit differences. reply wnc3141 1 hour agorootparentprevIt would require a different business model. Cycling is like F1 in that sponsors are trying to sell their equipment. reply sdfgtr 6 hours agorootparentprevLookup Japan's Keirin racing. I think it's pretty much that. IIRC at the top levels they also require the racers to stay onsite under observation for several days before a race. reply jamil7 6 hours agorootparentprevI get what you're saying but a part of the culture in my experience is tinkering and upgrading your bike, that doesn't have to necessitate spending huge amounts of money, especially if you do a lot of work yourself and buy parts second hand. The sport might appeal less with all that stripped away, but who knows maybe it would also be interesting to standardize some aspects. reply gjadi 5 hours agorootparentThis sounds similar to windsurfing, tinkering with your board, sail size, fin size, etc. is a big part of the sport. Yet, at the Olympics, the gear is the same for everyone. Btw, I can't remember where, but I heard that, in the old editions of the Tour de France not all gears were allowed, shifters for example weren't allowed even though they were available to amateurs. reply Ekaros 6 hours agorootparentprevWhy not then allow motorcycles? They are just bikes upgraded with motors... Would make competition lot shorter too and interesting. Seeing them driving around without speed limits. reply jamil7 5 hours agorootparentI'm guessing because they don't meet the criteria to participate, what's your point? reply Ekaros 5 hours agorootparentThat adding a motor would be upgrade and tinkering of a bike. So why should it not be allowed? Isn't it entirely in same spirit? reply jamil7 5 hours agorootparentDo you want me to enumerate the ways in which a bike is not a motorbike and the parameters in which people who are interested in bikes operate in their hobby or profession? Or are you asking why professional racing puts guidelines around what types of bikes can participate? reply 1992spacemovie 4 hours agorootparentprevYou’re being disingenuous and down right annoying. By your logic why not just use a F-18 and win the race in 10 minutes? Stop being asinine. reply skeeter2020 5 hours agorootparentprevNot sure if you honestly believe this or just trying to be \"edgy\" but because a motorcycle is not a bicycle. reply tpm 32 minutes agorootparentprevAll the cycling equipment in races has to be available in mass market and usually can be bought, if you've got the money. It's not cheap but also it's not a F1 car. It's more like.. why would you buy it when you are not a racer. reply nradov 6 hours agorootparentprevThat would essentially kill cycling as a professional sport. Much of the team revenue comes from equipment sponsors. And while many of the equipment innovations get a bit ridiculous, some of them have really benefitted amateur cyclists. I would hate to still be stuck with a 10-speed drivetrain on a steel tube frame with mechanical friction shifters just because that was \"standard\". reply skeeter2020 5 hours agorootparentYou saw this with cyclecross bikes for a long time. I had a beautiful cyclecross bike that I rode everywhere and I loved that bike but the cable-pull brakes sucked - like rear-end a car in traffic bad. Nobody made a cyclecross bike with disc brakes until the UCI allowed them in competition; now they all have disc brakes. Same for the extensive use of carbon. Love it or hate it, carbon has fueled intense innovation that you can see on display in higher-end consumer bikes and, while I don't have it or want it, electronic shifting is crisp and perfect. I don't like yet another electronic device but for a weekend rider to never need to tune a mechanical derailleur again is a game changer - you know they already have their phone with them 24/7 (especially you, roadies) reply bluGill 5 hours agorootparentprevI'd be perfectly happy on a steel tube 10-speed from 1975 if I was allowed a modern click shifter and modern disk brakes. Steel frame bikes are really nice, and 10 gears is more than you need anyway. Steel frame bikes from 1975 won't win you a modern race, but they won't be far behind. reply cantSpellSober 3 hours agorootparentYes Steel is Real but the last Tour winner on a steel bike was in the '90s (and that's the subject). Bikes weigh no more than 8kg. The weight weenies are winning, carbon everything down to brake rotors. > I was allowed a modern click shifter and modern disk brakes Doubt you'd see a bike equipped with anything else at the Tour. reply bluGill 3 hours agorootparentAt the top level - which is pretty much the definition of a tour winner - grams make the difference between a win and loss, so of course they will not be riding steel. I'm not at top level and never will be. If I want to go faster there are many things I can do that are more effective than playing what my bike is made out of. reply scheme271 21 minutes agorootparentSomewhat. UCI has a minumum weight (6.8kg) for bikes and often teams have to add weights to their bikes to hit the minimum limit. You easily get lighter bikes but your bike needs to be 6.8kg to be race legal. It certainly limits how many bits and bobs on the bike get switched over to using titanium or carbon fiber. reply nemo44x 6 hours agorootparentprevIt’s the same problem in golf. Equipment has gotten so powerful that the strategy of the game has fundamentally changed. They can not realistically continue to make courses longer. So they’re “rolling back” the ball which will limit drive distances a bit but nothing regarding clubs. And the reason why is the pro game makes a lot of money on endorsements. If a top pro is forced to use a club that is different from what amateurs need then the gravy train could stop. But yes, golf is really hard and for amateurs the innovations help make the game more enjoyable. But for pros it’s just too much. reply LargoLasskhyfv 7 hours agorootparentprev [–] How 'spartan'... That aside, regarding cycling, standard mass manufactured piece? In one size that all have to fit to? Naa... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "EF Education-EasyPost head chef Owen Blandy adapted to challenges by showcasing flexibility, a key trait in professional cycling.",
      "Modern cycling teams invest in custom food trucks, nutrition apps, and data-driven meal plans, with AI being used to tailor diets for each rider.",
      "Teams follow a five-meal daily plan focusing on high carbohydrates and proteins, with on-bike fuelling including energy bars, gels, and traditional foods like rice cakes."
    ],
    "commentSummary": [
      "Professional cycling teams have significantly evolved their approach to nutrition, emphasizing simple, lightly seasoned meals with fresh herbs and citrus.",
      "Riders use glucose monitoring devices during training to optimize nutrition, though these devices are banned during races, highlighting the importance of personalized nutrition.",
      "Teams face logistical challenges, such as sourcing enough ice and meticulously managing diets to prevent issues like cramps, while doping remains a concern but is less prevalent due to strict testing and monitoring."
    ],
    "points": 106,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1719954073
  },
  {
    "id": 40866311,
    "title": "Has anyone successfully pivoted from web dev to AI/ML development?",
    "originLink": "https://news.ycombinator.com/item?id=40866311",
    "originBody": "I am currently working as a senior full-stack web software engineer. I have a BSc in Computer Science, and on my own, I&#x27;ve been learning more about AI&#x2F;ML&#x2F;deep learning. I really enjoy working with it, and I&#x27;d love to find a way to work on AI stuff professionally. The problem is that I&#x27;ve been working as a web developer professionally for about 10 years now, and I have no idea how I would pivot to more of a AI&#x2F;data science role.Does anyone have an experience of making this transition? As a web dev, I am senior level, but I&#x27;m sure I&#x27;d have to start from scratch on some things in the AI space. At least I have a good foundation of programming in general, math, and computer science.",
    "commentLink": "https://news.ycombinator.com/item?id=40866311",
    "commentBody": "Has anyone successfully pivoted from web dev to AI/ML development?104 points by ent_superpos 4 hours agohidepastfavorite64 comments I am currently working as a senior full-stack web software engineer. I have a BSc in Computer Science, and on my own, I've been learning more about AI/ML/deep learning. I really enjoy working with it, and I'd love to find a way to work on AI stuff professionally. The problem is that I've been working as a web developer professionally for about 10 years now, and I have no idea how I would pivot to more of a AI/data science role. Does anyone have an experience of making this transition? As a web dev, I am senior level, but I'm sure I'd have to start from scratch on some things in the AI space. At least I have a good foundation of programming in general, math, and computer science. simonw 3 hours agoDo you want to train models from scratch, or do you want to build cool things on top of AI models? If the former, I suggest digging into things like the excellent Fast AI course: https://course.fast.ai/ If the latter, the (relatively new) keyword you are looking for is likely \"AI Engineer\" - https://www.latent.space/p/ai-engineer There's an argument that deep knowledge of how to train models isn't actually that useful when working with generative AI (LLMs etc) - knowing how to train or fine-tune a new model is less useful that developing knowledge of the other weird things you have to figure out about prompting, evals and using these models to build production-quality apps. reply thatguymike 2 hours agoparentThis is the right question. There are relatively few people doing \"Capital A Capital I\" work building and training generative language/image models. Especially now that people have realized that calling the OpenAI API is going to work better than dedicating a team to tuning your own BERT model. So some options are: * Building ML models for traditional applications - forecasting, ranking, recommending, all of that. Data Scientists and ML Engineers haven't gone away. * Working as an \"AI Engineer\" building on top of existing APIs and models. Very hip, but also in flux - I couldn't tell you whether that role will still be considered rare & valuable in a few years time, or what skills will be core to it. * ML Ops, engineering work for building & serving AI & ML models. It's always good to be selling shovels. I would try to get into a team you're interested in as a SWE and then upskill or pivot. In my experience this is more effective than trying to completely reskill and sell yourself as an unproven prospect for MLE or AI Scientist work. AI/ML teams still need software, and in fact many of the best researchers are not great software engineers. reply dontlikeyoueith 2 hours agorootparent> Especially now that people have realized that calling the OpenAI API is going to work better than dedicating a team to tuning your own BERT model. At 100x the operating cost. If you have any kind of scale, using a model that's appropriately sized to your task is going to be better. reply dewey 2 hours agorootparent> If you have any kind of scale I think that's the key also in terms of team size, if you don't have a dedicated team to take care of training / running a model then it makes sense to use an existing API and pay for it until you have enough scale. reply dontlikeyoueith 42 minutes agorootparentThat is a fair point. Lots of times building the inefficient thing to prove market value is better than building the scalable thing that doesn't solve anyone's problems. reply reaperman 1 hour agorootparentprevGemma2 might be good enough for a drop-in option as well. The benefit for those who built on ChatGPT API is that as more open weight models get released, they can silently migrate their API usage to self-hosted models … ChatGPT allowed them to prove product-market fit early! reply willsmith72 2 hours agoparentprevI want to agree with this, but after reading the whole article, I have no idea what the skills of an AI Engineer are. Why is that not the job of a software/product engineer? > none of the highly effective AI Engineers I named above have done the equivalent work of the Andrew Ng Coursera courses, nor do they know PyTorch, nor do they know the difference between a Data Lake or Data Warehouse they're explicitly not trained in ML/AI. any software engineer can write a good prompt, call an API, and deploy that on an http server. why is that not just software/product engineering? reply demosthanos 45 minutes agorootparentAn AI engineer wires up APIs to each other and returns the result as JSON, the same process as any other web dev. Like any other web dev job there are differences across domains that can make it valuable to hire someone with past experience in your particular industry (in this case LLMs), but the only reason this gets a brand new title and others don't is hype. reply collectedparts 2 hours agoparentprevThe fact that in 2024 you can still get sub-1-hour applicable reply from the creator of one of the top web frameworks ever is everything that makes HN amazing. reply viccis 2 hours agoparentprevOne thing I've encountered more than once in the industry right now is that a lot of companies want to hire \"AI Engineers\", but they task their staff Very Serious Data Scientist with handling the interview. Inevitably, all the questions will be minutiae about different ANN designs and training processes. And without fail, no one involved will be actually dealing with that stuff on a day to day basis. reply sevensor 2 hours agoprevAI problems turn into data problems. The happiest and best compensated people I know in that area have gone into data engineering, because data engineers are the ones selling shovels in this gold rush. reply akudha 1 hour agoparentCould you please elaborate a bit more? I am your typical web-dev/frontend/backend developer, don't really know much about what is involved in data engineering. Do you mean collecting, cleaning data? Or setting up databases (if yes, how is it different from me managing my employer's databases, except for size)? In other words, what does a data engineer do all day? reply sgaur 1 hour agorootparentSeveral data engineers that I know in this space (AI for business applications) are doing the usual ETL + mapping pipeline related work. Nowadays a lot of them are also having to deal with unstructured data such as textual reviews of products, service quality feedback, policy documents. Data engineers are developing the pipelines for chunking, vectorization, ingestion into RAG pipeline and for LLM training fine tuning. So it's still collecting, cleaning data, but quite different at the next level of detail, in my opinion. reply akudha 49 minutes agorootparentThank you. How does one get into this field? Web dev isn’t that exciting anymore reply sevensor 14 minutes agorootparentThe data engineers I know started out as data scientists. They discovered that their ability to make models that did anything useful was hampered by low-quality or absent data. Then they discovered that there was a lot more job satisfaction (not to mention much better pay) in making useful data available than there was in clicking the \"train\" button over and over in slightly different configurations. reply sk11001 2 hours agoparentprevI would give the exact opposite advice - data engineering is one of the least rewarding or respected career paths. reply sevensor 1 hour agorootparentIf you find that this is the case in your organization, watch out. It's a sign that you're trying to build performative models that aren't grounded in reality. Depending on your organization's goals, this may take a long time to catch up with you. reply mistrial9 1 hour agorootparentpreva large organization that can pay stable wages over time is going to look for formal credentials when making a hiring decision. Further from that kind of (big,bureaucratic) group, are quickly assembling and then dissolving entities .. in other words \"nice work if you can get it\" .. with far less stability. Another term for this is \"the Wild West\" environment. There are some applicable analogies to the way Hollywood makes movies also perhaps, but with far less grounding. In the Hollywood example from what I know of.. small \"tiger teams\" assemble with fundamentals, then quickly farm out the sexy work to disposable contracting firms, who then hire even more disposable people with various skill levels. In other words, lots of fun and excitement but also lots of work place abuses and low stability. Over time, Hollywood formed unions for a surprisingly large number of roles (like writers) because the real truth of business is not pretty. Needless to say, Silicon Valley has moved very quickly, and the Hollywood stories are not exactly applicable. reply hectormalot 2 hours agoprevTotally possible. About 30-40% of the people in our AI team don’t have a formal AI background. Especially with LLMs a lot of work has shifted towards “data literate software engineering”. We call them AI engineers / AI developers. Good development skills are very transferable to those roles. Feel free to reach out if you’re in the EU (email in profile), we’re hiring. Also happy to give some pointers on how to approach these conversations. reply iknownthing 2 hours agoparentI'm always skeptical of these roles. Very often they do not involve anything AI related which is why a formal AI background is not required. reply Copenjin 1 hour agorootparentExactly. reply phillypham 2 hours agoprevIt's not too uncommon. I started off working with Angular and Java. But I studied math. It depends on what type of role you want. If you'd be happy building the application layer and doing prompt engineering, just build applications that call LLM APIs. If you want a research position at the top labs, the interviews really are actually passable by people without PhDs. They are really focused on having strong fundamentals. I've seen people make this leap but it can be years of preparation. Like actually reading textbooks, implementing low-level details like backprop, re-implementing papers, and doing non-trivial personal projects. Essentially, you're self-studying a Masters degree. Blog about it. Post about it here. I've found people to make this transition just generally love learning. reply ilaksh 3 hours agoprevAI, ML, and data science are all different things. And there are different types of jobs in each of those categories. If you want to apply AI, there are lots of really useful projects that are just calling the Anthropic or OpenAI API for the AI part. Or replicate.com image models etc. That wasn't the case a few years ago before we had the general purpose models. I have been doing a lot of those types of projects and I don't have a machine learning background. There are ML Ops jobs that don't require a lot of machine learning knowledge. There are ML researcher jobs that are just training LLMs which are more practical rather than theory. To do novel machine learning research or at least significant variations of popular neural network architectures, I think that is the only thing that really requires years of study. But I think there is a very large gap between that type of work and web development. Which is why I was very happy to see the progress in general purpose models. reply TbobbyZ 2 hours agoprevThis post shows why programming as a career overall sucks. Sure it’s great if you really enjoy programming. However, staying relevant to earn a decent living your entire life is difficult. reply nostrademons 2 hours agoparentSome people like learning new things. If you go into tech you should know that it's a career where you basically have to retrain every 5 years. But in return for that, you get high wages and low barriers to entry. If you're someone who enjoys learning new skills, this is a profession tailor made for you. reply TbobbyZ 12 minutes agorootparentHow do you know what to retrain in? reply spmurrayzzz 1 hour agoparentprevI would argue this post (and the majority of resultant comments) have demonstrated that programmers staying relevant isn't as difficult as it seems. They were curious about how to pivot, had a forum in which they could ask, and in minutes started getting a wealth of practical, actionable advice from folks who have done the same or similar. The theme so far is that those programming skills aren't obsolete just because you want to change the vertical you work in and learning materials to help you achieve that goal are abundant. reply sulam 1 hour agorootparentRight, it’s a lot easier to shift than it would be to go into an entirely different kind of law, or become a different specialty of doctor. reply weatherlite 2 hours agoparentprevAt least in the U.S it's been one of the greatest careers possible imo in most objective measures - money, comfort, working conditions etc etc. I'm saying has been because job security plummetted in the last year or two and I'm not sure if its even going back to what it as befoer. reply navbaker 9 minutes agorootparentMaybe in what we think of as traditional tech, but there is enormous job security working as a developer in government or government adjacent organizations. You obviously take a pay hit, but also don’t have to live in an area with a huge cost of living relative to CA, NYC, etc. reply collectedparts 2 hours agoparentprevIgnoring industries built on regulatory capture / credentialism gatekeeping like law and medicine [by the way, even those both have continuing education requirements], are there actually exceptions to this? Plenty of careers just go away. Might as well pick one where you can stay relevant by picking up incremental/adjacent skills continuously. reply thejazzman 2 hours agorootparentElectrician and plumbers have it pretty good in this regard. I don't see that being replaced anytime soon and there's not all that much to learn and a lot less changing on you. Maybe we'd get bored though. reply remixff2400 1 hour agorootparentNot as sure about electricians, but plumbers at least pay for it with their body. Even though PPE can reduce the strain, there's still a reason why these trades haven't just shot through the roof. Bad knees, bad backs, respiratory dangers, etc. Trades in general are fraught with physical perils for the unaware. reply root_axis 2 hours agorootparentprevVery true, though, those jobs also present significant occupational hazards, unlike software where the biggest threat you face is a sedentary lifestyle. reply dgfitz 1 hour agorootparentI’m a 15-year SWE. If I sat at a desk or in an office/cube all day I’d lose my marbles. The software I write and ship also requires me to be able to grab a socket set, take panels off things, fish out DB9 connectors, run wiring, etc. testing also happens in heavy snow in the winter and high heat in the summer. Oh, lots of travel as well. I’ve been interested in finding a different job, I’m just worried I would get very bored very quickly, tying together api calls or stitching together libraries. reply digging 1 hour agorootparentprev> the biggest threat you face is a sedentary lifestyle Which is a serious threat, to be clear. It's just more easily mitigated. reply willsmith72 2 hours agorootparentprevi personally love the expectation of constant learning, growth and innovation in our field but yes, anecdotally, compared to all of my friends and family, i don't know any profession with those same expectations. to name a few - market researchers, psychologists, primary school teachers. reply soneca 2 hours agoparentprevI am a web dev and I think I’ll stay relevant to earn a decent living as a web dev until I retire (it’s hard to predict 20 years ahead, but definitely the next 5-10 years at least). It seems the author just want to change their career, not necessarily because of they won’t be able to earn money if they don’t. reply xaxaxb 2 hours agoparentprevI enjoy letter-writing. So should I go on writing physical letters to everyone today? Moving with technology is essential, not just for developers, but for public as well. The trap is that we have to do it even if we don't want to. E.g: your neighbor country has nukes and you don't. reply foweltschmerz 2 hours agoparentprevI don't think web development is becoming irrelevant anytime soon. reply TillE 1 hour agoparentprevThe fundamentals of how computers work are essentially unchanged since the 60s or 70s. If you have a strong foundation (typically a CS or CE degree), picking up new stuff shouldn't be particularly difficult. I mean, I just had a PR merged in a language I had literally never used before. It took me five minutes to pick up the basics. Sure it would take much longer to be fully productive, but it would be a comfortable transition. reply Atheb 3 hours agoprevNot sure if my experience is relevant, but I did a couple of internships in web dev during my bachelors degree in CS and quickly realized it wasn't for me. I then did a masters and now a PhD in medical imaging where I extensively use machine learning (design and train my own models, doing both supervised and RL) but I wouldn't say I am a researcher in AI/ML. Because I am still in the academic process, I had the opportunity to take a couple of classes on the subject. Three books that I would recommend going over to make sure your foundation in ML and mathematics are solid are -Pattern recognition and machine learning by Christopher Bishop -Mathematics for Machine Learning by Peter Deisenroth -Deep Learning by Courville, Bengio and Goodfellow All three are legally available online in some form. I can't say I have any experience in finding a job related to ML though. reply Vox_Leone 1 hour agoprevI made this transition. I am developing a project in the area of computer vision -- with intensive use of drones -- to serve Brazilian agribusiness. At the moment the challenge is to gather a dataset of images of the livestock breeds and crop varieties most produced and cultivated in the region, for detection, classification, monitoring, counting. The field of work is new and promising here. From a technical and professional point of view, it wasn't particularly difficult to make the transition, because I have an extensive background in data analysis and science. The difficult part is working on sales with a new type of customer. From where I stand Computer Vision seems like a really good area to start in machine learning. Good luck! reply gnarcoregrizz 59 minutes agoprevYes, AI team was created in our company to bring it in house, and I was invited mainly to integrate it into the web app, and to do some ops work. A year later and I'm fine tuning models, building datasets, working with PyTorch. Much different than webdev, not as rewarding sometimes, more unknowns, longer feedback cycles. The main issue is getting enough data quality and quantity, which can be a grind. Happy to have taken this opportunity though. Endless things to learn. reply spmurrayzzz 1 hour agoprevThere is so much in the ML world that's being built in the open which you can use as a foundation for your learning. Some folks here already mentioned Jeremy Howard's fast.ai course which is absolutely a great place to start for anyone that a) has motivation to learn DL, and b) already knows how to code. Beyond that, there are hundreds of open source projects you can fork to start building intuitions around what the inner loop of AI dev project cycles look like. You'll be surprised at how much of your web dev skills remain relevant in these projects, particularly in UI-related tasks. Data scientists and folks of similar ilk default to notebooks, gradio, streamlit et al. to ship interfaces for their experiments. You though have the ability to do that on your own if you choose to (sometimes a notebook is enough), which can be a valuable differentiator for you as a candidate if you also have all the other skills needed to be productive in this space. My own background is in distributed systems with some full stack and embedded work mixed in over the years. I started tinkering with ML projects back in 2012 when I first discovered AlexNet and resources were far more limited. I was still able to get productive relatively quickly even though most of what I built wasn't really applicable to my work in a practical sense on day one. Where my background became relevant was when I needed something approximating an MLOps pipeline for data processing, training, and eval. Most of the code you're writing for that isn't really specific to ML, its nearly identical to CI/CD systems but with the obvious infrastructure caveats native to ML workloads. Nowadays though, especially if you're intrepid/resourceful, there is so much more learning material by comparison and much of what you work on can likely augment your day-to-day web dev tasks as well if you're creative enough. reply throwawayyyyhhh 2 hours agoprevYes. Use your CS and math background to get a job in Operations Research. Use the OR techniques to do V&V on applications of AI/ML models. Ie, Verification that the application/model do the job correctly and Validation that the app/mdl is appropriate for the business case. This is not exciting but it pays well and people with the skill set are extremely needed. reply omneity 3 hours agoprevOne workable pathway is to join a team working on AI products as a full-stack engineer. AI practitioners notably are less inclined to do frontend or even backend work, even more so when talking about SWE best practices and moving code to production. So there is plenty for you to offer given your 10 years tenure in dev. Then learn by symbiosis, while having AI on your resume :) Feel free to get in touch if you want to chat more about this. reply jmartin2683 2 hours agoprevThis is essentially what I’ve done, having started 15 years ago with Ruby on Rails and now leading development of most ML-related applications at my current job. I’ve been interested in ML since 2017 or so, just found it interesting. reply foweltschmerz 2 hours agoprev> I'd love to find a way to work on AI stuff professionally Working on AI can mean many different things. If you're looking to pivot into a more research-y position in DS and/or AI research, I'd suggest getting an advanced degree in these fields. If you're talking more about ML engineering, there're full stack software engineer positions at some startup AI companies that require an assortment of skill sets such as web development, MLOps, and sometimes a bit of data engineering. You could look into these roles. Alternatively, since ML engineer is still an emerging position at a lot of organizations, some do not require prior experience but instead focus more on the candidate's portfolio. Create some projects and build a strong portfolio, you might have a good chance. reply ruffrey 2 hours agoprevI pivoted from \"full stack\" to a software and infra engineer on an AI team. There was some luck involved, but I believe it helped that I'd taken some courses. I am not one of the data scientists, but work very closely with them. This seems like a good path to full time data science. reply breckenedge 3 hours agoprevHere’s a thread also asking about this from last week: https://news.ycombinator.com/item?id=40797858 reply srinikhilr 1 hour agoprevAnyone has advice for engineers working on distributed systems problems pivoting to MLOps/ AI Infrastructure? reply PaulHoule 4 hours agoprevI've gone back and forth between them, but it helps that I have a Physics PhD so I am not intimidated by the math. I got my PhD in 1998, did a postdoc in Germany for a year, came back to the states, started doing remote work and consulting projects for web sites, worked on the arXiv preprint server for a few years, then worked on a pretty wide range of projects for pay and for side projects until I got interested in using automation to make large image collections on my own account circa 2008 or so. I had a conversation with my supervisor that called into question whether I could ever be treated fairly where I was working and then two days later I got a call from a recruiter who was looking for a \"relevance architect\" which had me work for about a year and a half for a very disorganized startup. Then I got called by another recruiter who needed somebody to finish a neural network search engine for patents based on C++, Java and SIMD assembly. After that I tried to put a business to develop a next-generation data integration tool and did consulting projects, learned Python because customers were asking for it. When I gave up on my own business I went to work full-time for a startup that was building something similar to the product I had in mind as a \"machine learning engineer\". That company was using CNNs for text, I had previously worked for one using RNNs, that summer BERT came out and we realized it was important but not quite so important. After that I wound up getting a more ordinary webdev job where I can actually go to an office, I still do ML and NLP-based side projects though. Funny enough I am working on text analysis projects now that I first conceived of 20 years ago, I think technologically some of them could have worked but they work so much better now with newer models. --- My take is that the average 'data scientist' is oriented towards making the July sales report, not making a script that will make the monthly sales report. If you want to get repeatable results with ML it really helps to apply the same kind of organizational thinking and discipline that we're used to in application development. Also I believe getting training data is the bottleneck for most projects: I mean, if you have 5000 labeled examples and a 20 year old classification model you might get a useful classifier, you can get a much better classifier with a two year old model with little more work, or you can try a model out of last week's arXiv paper and spend 10-100x the effort, risk complete failure, and probably add 0.03 points to your ROC. If you don't have those 5000 examples on the other hand all you can do is download some model from huggingface and hope it is close enough to your problem to be useful. My spurt of doing front-end heavy work built up my UI skills so I have done a lot of side project work towards building systems that let people label data. reply nothrowaways 3 hours agoparentHow are you financially? reply PaulHoule 2 hours agorootparentCould be better, could be worse. I am living in rural upstate NY close to a college town and bought a 70 acre farm for a fraction of what a small ranch house costs in the Bay Area. My wife teaches people to ride horses, her business is probably the most profitable horse operation I know of because (1) it was bootstrapped up from 2 horses to 8 and (2) we never bought large amounts of heavy equipment; the average horse barn has a big-ass truck and a horse trailer, we can pay somebody to haul a horse somewhere for a fraction of the monthly payment on a big-ass truck. We have two houses on the lot and get usually get rental income from two units in the second house (though we are renovating it now and I'm using it to gentle a feral cat right now) I've had some terrible years where I ran up $20k of AWS bills and had no income, I did run up a balance on my HELOC which I later paid off. The good years paid for the bad years, I consistently put money into retirement funds except for the absolutely worst years. I always had health insurance except for a summer that I worked at a web dev shop that didn't offer it. reply freedomben 2 hours agorootparentInteresting, thank you for sharing! I have about 9 acres and have been seriously considering getting horses, but the big-ass truck and trailer has been a point of hesitation for me. I did not know you could pay somebody to haul them somewhere when needed! reply PaulHoule 2 hours agorootparentIf you go this route you should make friends with local farmers who have the equipment and can help you out with little random things. If you want to go to shows or visit distant trailheads you need the trailer but we have an area of trails on our farm that I’d compare to Het Vondelpark in Amsterdam and can ride out on the road to some nice dirt roads. reply extr 1 hour agoprevAs other commenters have noted, there are different kinds of ML/AI archetypes out there: - \"Real AI Scientist/Applied Scientist/Researcher\" aka you do actual training/fine tuning of bleeding edge models. Very hot right now but competition is incredibly intense. Probably you need a PhD or some serious experience to compete. Get ready to do a bunch of independent learning if you're serious about this. - \"Fake AI Scientist/Applied Scientist/Researcher\" - You work in a big corporation or maybe a confused startup who wants to staff out some internal AI teams but doesn't really have true expertise in the area. Maybe if you really knock it out of the park something you build will provide real customer value...one day. - \"Real AI-ML Engineer\" Scientist work under a different name, or deployment/infra for custom models. More approachable than Real Scientist work but probably more focused on engineering chops, C++, CUDA, etc. Similar to Real Scientist in that you need to have some actual legit skills. - \"Fake AI-ML Engineer\" Calling the OpenAI API and massaging the output into something that is possibly valuable but more likely is just a \"AI Feature\" on top of an existing application that provides real customer value. - \"Non-AI ML Engineer\" You work with traditional ML like xgboost, probably in the financial world, and don't really interact with any of this stuff, unless your boss asks you to create a new AI Feature. You can now put this on your resume and hope to get a Fake AI-ML Engineer job, if you want to. - \"Real Data Science\" this role is trending toward inhabiting more of a BI/Analytics space. IMO in Big Tech they are getting more serious about the stats/probability background here. In some ways I think this would be more difficult to upskill on than Deep Learning math, if you're starting without a math background. - \"Fake Data Science\" Kind of a dying role, this is like \"I just learned how to do pandas and scikit learn and I'm creating linear regressions for boomers\". Honestly still some alpha here if you are a product-focused person in the right org. But maybe the title here should be more like Data Analyst++ Hope this helps. Me myself I'm a Non-AI ML Engineer who is pretty screwed, because if you search ML Engineer now everyone wants you to know PyTorch. reply throwaway6734 2 hours agoprevI made the transition a few years ago by going back to school for my MS. This allowed me to re-enter the internship pipeline reply mistrial9 2 hours agoprevzooming out, the AI space is filled with insiders trading well-paid opportunities among others with very specific credentials.. in a high stakes and heavily constricted network of networks.. contrast this to an open market.. for example I make a poster for a grocery store in my town, that poster is well-liked and I have the rights to reproduce it, or make a similar new one. In every town there could be such activity, and for larger towns, many people could do that activity. That naturally scales for participation, with the transactions of pay and consumption in an open market environment. The AI space seems much more like building large projects in tight teams with serious resource requirements. The end products are more varied than most people realize, but there is a common thread of replacing skilled humans in jobs with some kind of automation, or extracting value from humans with monitoring and some kind of enforcement. In other words, really contrasting to the open markets ideas. Honestly I cannot be enthusiastic to put the word \"job\" and \"AI dev\" in the same sentance. The real-world dynamics appear to be coalescing into high powered, competing silos, with a side-effect of replacing jobs in some cases. reply j45 2 hours agoprevSuccessfully pivoting means learning and shipping things yourself on GitHub and talking about it on your own YouTube journal. Specifically with AI/ML the urge might be to start from scratch but I think there might be enough tooling to start where you are with web, build solutions using existing AI tech, start customizing it and going deeper and deeper. Makes for a natural story and journey too. It’s completely choose your own adventure so you and direct the vector of your path where you want and learn & build in that direction. reply laborcontract 2 hours agoparentI agree with your general advice about shipping stuff, starting from stuff you'd want an LLM or agents to do for you. Journaling is good too. I'm not sure if I agree with you on the tooling end. If you're talking about tooling as in calling OpenAI APIs vs local llamaing/fine tuning your own stuff, I definitely agree with you. If you're talking about going with abstractions like LlamaIndex and Langchain, I strongly disagree. Honestly, I'm almost entirely against all abstractions outside of something like LiteLLM. Langchain, for instance, abstracts the entire learning process away from developers, which honestly translates into little communicable skills after building apps with it. Pretty much all of my learning in this space was from building a product head first and figuring out how to give myself the tools to get me there. You pick up a ton along the way. For instance, you learn a ton from trying to figure out how to build your own text splitter, chunker, and document extractors. Building from scratch is what makes you useful to companies. Understanding the why and how behind the tools is the difference between developing just another chatbot versus developing hugely value-driving solutions for businesses. There's diminishing demand for the former, tremendous demand for the latter. reply syngrog66 2 hours agoprevThis should be in the Who Wants To Be Hired thread reply SkyMarshal 3 hours agoprev [–] To begin, start hacking on open source AI projects, put them on your github, build up that track record. Get involved in various FOSS AI communities and collaborate with folks there [1]. The opportunities to transition to AI jobs will follow. [1]:https://reddit.com/r/localllama reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A senior full-stack web software engineer with 10 years of experience is seeking advice on transitioning to a professional AI role.",
      "The individual has a strong foundation in programming, math, and computer science but anticipates starting from scratch in some AI areas.",
      "They have been self-learning AI, machine learning (ML), and deep learning, and are looking for insights from others who have made a similar career pivot."
    ],
    "commentSummary": [
      "Many professionals have successfully transitioned from web development to AI/ML roles, often by leveraging existing skills and learning new ones through courses and self-study.",
      "Key strategies include joining AI teams as software engineers, using existing AI APIs, and gradually upskilling in AI/ML techniques.",
      "Practical advice includes taking specialized courses like Fast AI, participating in open-source AI projects, and building a strong portfolio to demonstrate capabilities in AI/ML."
    ],
    "points": 104,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1720017313
  }
]
