[
  {
    "id": 40508278,
    "title": "AI Headphones Isolate Single Speaker in Crowds by Gaze Detection",
    "originLink": "https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/",
    "originBody": "Search UW All the UW Current site Search scope All the UWCurrent site Skip to main content MyUW Calendar Directories Libraries UW Medicine Maps UW News Helpful Links Computing/IT Workday HCM Husky Card UW Bothell UW Tacoma UW Facebook UW Twitter University of Washington University of Washington Students Parents Faculty & Staff Alumni Quick Links About Stories All stories News releases UW News blog UW Notebook For Washington Official notices UW in the media Multimedia Video stories Podcasts Soundbites/b-roll Interactives Experts Directory Expert quotes COVID-19 experts Speakers Bureau Media contacts For Journalists For researchers Media Training UW News Menu About Stories All stories News releases UW News blog UW Notebook For Washington Official notices UW in the media Multimedia Video stories Podcasts Soundbites/b-roll Interactives Experts Directory Expert quotes COVID-19 experts Speakers Bureau Media contacts For Journalists For researchers Media Training Home UW News Engineering AI headphones let wearer listen to a single person in a crowd, by looking at them just once EngineeringNews releasesResearchTechnology May 23, 2024 AI headphones let wearer listen to a single person in a crowd, by looking at them just once Stefan Milne and Kiyomi Taguchi UW News Noise-canceling headphones have gotten very good at creating an auditory blank slate. But allowing certain sounds from a wearer’s environment through the erasure still challenges researchers. The latest edition of Apple’s AirPods Pro, for instance, automatically adjusts sound levels for wearers — sensing when they’re in conversation, for instance — but the user has little control over whom to listen to or when this happens. A University of Washington team has developed an artificial intelligence system that lets a user wearing headphones look at a person speaking for three to five seconds to “enroll” them. The system, called “Target Speech Hearing,” then cancels all other sounds in the environment and plays just the enrolled speaker’s voice in real time even as the listener moves around in noisy places and no longer faces the speaker. The team presented its findings May 14 in Honolulu at the ACM CHI Conference on Human Factors in Computing Systems. The code for the proof-of-concept device is available for others to build on. The system is not commercially available. “We tend to think of AI now as web-based chatbots that answer questions,” said senior author Shyam Gollakota, a UW professor in the Paul G. Allen School of Computer Science & Engineering. “But in this project, we develop AI to modify the auditory perception of anyone wearing headphones, given their preferences. With our devices you can now hear a single speaker clearly even if you are in a noisy environment with lots of other people talking.” To use the system, a person wearing off-the-shelf headphones fitted with microphones taps a button while directing their head at someone talking. The sound waves from that speaker’s voice then should reach the microphones on both sides of the headset simultaneously; there’s a 16-degree margin of error. The headphones send that signal to an on-board embedded computer, where the team’s machine learning software learns the desired speaker’s vocal patterns. The system latches onto that speaker’s voice and continues to play it back to the listener, even as the pair moves around. The system’s ability to focus on the enrolled voice improves as the speaker keeps talking, giving the system more training data. Related: For more information, see the team’s website Stories from MIT Technology Review and GeekWire The team tested its system on 21 subjects, who rated the clarity of the enrolled speaker’s voice nearly twice as high as the unfiltered audio on average. This work builds on the team’s previous “semantic hearing” research, which allowed users to select specific sound classes — such as birds or voices — that they wanted to hear and canceled other sounds in the environment. Currently the TSH system can enroll only one speaker at a time, and it’s only able to enroll a speaker when there is not another loud voice coming from the same direction as the target speaker’s voice. If a user isn’t happy with the sound quality, they can run another enrollment on the speaker to improve the clarity. The team is working to expand the system to earbuds and hearing aids in the future. Additional co-authors on the paper were Bandhav Veluri, Malek Itani and Tuochao Chen, UW doctoral students in the Allen School, and Takuya Yoshioka, director of research at AssemblyAI. This research was funded by a Moore Inventor Fellow award, a Thomas J. Cabel Endowed Professorship and a UW CoMotion Innovation Gap Fund. For more information, contact tsh@cs.washington.edu. Tag(s): Bandhav Veluri • College of Engineering • Department of Electrical & Computer Engineering • Malek Itani • Paul G. Allen School of Computer Science & Engineering • Shyam Gollakota • Tuochao Chen News releases Read more news releases More Search UW News Search for: UW Experts Weather Artificial intelligence Wildfires and Smoke Full directory Categories Browse Administrative affairs Arts and entertainment Buildings and grounds Education Engineering Environment For UW employees Health and medicine Honors and awards Interactive Learning News releases News roundups Official notices Politics and government Population Health Profiles Research Science Social science Technology UW and the community UW Notebook UW Today blog Latest news releases Q&A: How AI affects kids’ creativity 3 hours ago UW’s Larry Dalton and wife, Nicole Boand, make $10 million bequest to the School of Nursing for scholarships and clinical education 19 hours ago AI headphones let wearer listen to a single person in a crowd, by looking at them just once 6 days ago More Connect UW Today Newsletter Subscribe UW Today Daily UW Today Week in Review For UW employees Submission guidelines Submission form University of Washington Be boundless Connect with us: Facebook Twitter Instagram YouTube LinkedIn Pinterest Accessibility Contact Us Jobs Campus Safety My UW Rules Docket Privacy Terms Newsletter © 2024 University of WashingtonSeattle, WA",
    "commentLink": "https://news.ycombinator.com/item?id=40508278",
    "commentBody": "AI headphones let wearer listen to a single person in a crowd by looking at them (washington.edu)791 points by keploy 15 hours agohidepastfavorite358 comments serial_dev 7 hours agoIf the size could shrink to the size of a small earplug, I'd love to use this as a person who is not hearing-impaired (at least they couldn't diagnose me with it, so now I'm not sure if their diagnostics sucks, or I'm just a normal person and others pretend better that they hear everything well). In groups and with friends, it's inevitable that you end up in a busy restaurant or a bar, and it always frustrates me that I don't hear something, I ask the person to repeat only to not hear it again, usually because they repeat it at the same low level (considering the circumstances). Missing jokes and throwaway comments is even worse (\"hey what are you all laughing about, I didn't hear it, could you repeat it for me like three times until I hear it\"). reply superultra 7 hours agoparentI could not hear anyone in any crowded situation. At middle age I thought my hearing was leaving. Yet every audiologist I went to said my hearing was fine. So I found the best audiologist in my fairly large metro area, and scheduled a year in advance (the wait list was that long). After a whole day of tests the audiologist comes in and says I have good news and bad news and good bad news. The good news is that my hearing was beyond great, it was at the level of a 5 year old. The bad news: I could hear so well I was unable to differentiate sound; my hearing hadn’t gotten worse, my brain’s ability to separate sound had. The good bad news is that my hearing would inevitably deteriorate, as all ours does, and for several years I’d be able hear in public places! I think part of what has made this worse is that restaurant and public space designers have stopped thinking about sound. Most bars opened in the last 15 years have cement floors, very little sound insulation, and they’re based on the idea that you’re not having a good time unless your ears are ringing. I’ve stopped patronizing these places if only because I literally cannot maintain conversations. reply floatrock 5 hours agorootparent> restaurant and public space designers have stopped thinking about sound. Most bars opened in the last 15 years have cement floors, very little sound insulation, and they’re based on the idea that you’re not having a good time unless your ears are ringing. Recently listened to a really good podcast about this phenomenon https://podcasts.apple.com/us/podcast/gastropod/id918896288?... (or pick your favorite podcast app) Couple takeaways I remember: - \"Silence is the new luxury\" -- restaurants can have good sound design, but it doesn't come cheap. Upscale restaurants are starting to differentiate themselves with sound design - The modern clean aesthetic (glass, concrete, stainless steel, minimalism) promotes loud, echo'ey spaces - \"You're not having a good time unless your ears are ringing\" was an intentional design choice popularized by some restaurant guru in the 90's. Growing awareness of the problems is starting to create a backlash - Loud restaurants are damaging for the waitstaff's health. You can work for hours in an environment so loud that OSHA would demand hearing protection. - The luxury sound design studios can be so good at isolating ambient noise that they also sell an \"anti-noise-cancelling\" sound system that actually selectively re-amplifies crowd noise for when you do want to tune up some sense of busy-ness (with too much sound dampening in an unfilled room, it starts to feel too isolated... being \"out and about\" is some of the reason people go out dining) reply roughly 2 hours agorootparentIf you’re near Berkeley, CA, one of the owners of the restaurant Comal also owns a sound company that builds that kind of system, and they use Comal as a showplace. The effect is astounding - it’s an industrial-style design, and it’s got auditory “ambiance”, but you can have a full conversation at normal speaking volumes with everyone at the table. It’s the kind of thing where once you experience it, you’ll judge the hell out of any other “fancy” restaurant you go to that doesn’t have it. reply dekhn 1 hour agorootparentOh neat: https://www.popsci.com/technology/article/2012-08/restaurant... Meyer Sound which did the sound install for the space is a long-time well-known innovator in sound tech- for example, establishing vertical line arrays. Years ago the son of the founder was doing advanced space modelling for the best sound (basically, entering the room geometry and simulating with helmholtz equations). I will go there just for the experience. reply floatrock 1 hour agorootparentprevComal is one of the subjects of that podcast episode reply Aaronstotle 2 hours agorootparentprevBeen to Comal a few times, need to go again and pay closer attention reply countvonbalzac 4 hours agorootparentprevAren't there some cheap ways to muffle sound? Wood floors, rugs, curtains, artwork, acoustic panels, etc. reply chefandy 2 hours agorootparentStuff that works well in homes often is a lot more complicated to implement in restaurants, where you're: a) constantly fighting grease buildup and hard-to-remove dust that clings to greasy or damp surfaces, b) often have a profit margin of like 2% if you're one of the successful ones, c) aside from looking clean, you have to worry about pest control, fire codes, health codes (you can't have built-up dust falling in people's food, d) etc etc etc etc. Also, how restaurants look is as, or in some cases more important than the quality of the food. A good, attractive, practical restaurant design is one of the things that can steer you towards success or failure. Much to many chefs chagrin, hip and attractive restaurants with shitty boring food are often more profitable than ones that only focus on the food. Marketing is annoyingly important. With, floors hardwood is a hard surface (so only mildly sound damping) so they're not too bad for cleaning and health stuff, but are expensive to install and take a lot to maintain if the worn-in look doesn't fit the aesthetic. Low-pile carpets can be shampood inexpensively for medium-term maintenance and replaced comparatively cheaply in the long run, but take a lot more effort to keep clean when someone drops a catering tray full of crème caramel and something with a port wine reduction. Artwork: anything that you'd want hanging on your walls is either going to need to be a print or covered with glass or plastic because it will get ruined otherwise. Acoustic panels are usually pretty ugly, difficult to clean, not resistant to pests, are a fire liability if coated in grease, etc. Curtains definitely are definitely viable, but if you've got enough of them to really impact the sound level, they probably need to be expensive ones, and expensive curtains can't just be tossed in the wash and pressed on an ironing board. It's not like they aren't effective, they're just not nearly as easy to deploy or maintain as they are in homes or offices. reply chefandy 49 minutes agorootparentUnrelated blathering because a lot of folks in tech don't have much exposure to this stuff and I always enjoy seeing a slice of someone else's life: In general a lot of people are understandably perplexed by seemingly simple, avoidable problems that they encounter in restaurants-- you can chalk almost all of them up to misinformation, or deliberately obfuscated factors. Firstly, there's a ton of inaccurate folk knowledge about the way restaurants work... (most infuriatingly to me is the food safety stuff. Look up the incubation time for most foodborne illnesses and consider how many people blame some lower GI symptoms the meal that met their stomach lining 3 hours earlier.) Also, a big part of the restaurant mystique is making it all seem sort of easy, uncomplicated, and fun, even for regulars and the 'friends and family' crowd; underneath that thin veneer, it's absolute insanity. I've worked in tech and the restaurant business extensively. Most days, the pressure level is \"we just discovered a possible active intruder in our production systems\" for at least a few hours. It's exhausting, and one of the reasons drug and alcohol addiction is so prevalent. Knowing that an entire staff is breaking their back so you can have a fun cozy bite to eat makes the experience palpably worse, but it's true. That's why you'll usually find people who've worked in the service industry are serious over-tippers. You have to give up a lot of your humanity to do that work, and a lot of people you encounter respect you less instead of more for having made that sacrifice. I've proudly convinced so many people to not go into that business, though I've also convinced a few people to give it a shot. It's not a good choice for most people, but some people can't really do much else and be happy. In many ways, its especially tolerant to neurodivergent folks with different skillsets being downright useful in different roles. It's hard as hell though. There's a good reason that CIA (the school, not the spies) requires 6 months of full-time back-of-the-house restaurant work to get admitted to their degree program. reply abeisgreat 4 hours agorootparentprevThere definitely are but, perhaps by definition, items soft enough to dampen sound are often easily damaged so they aren’t great fits for most commercial locations. They are also out of vogue as was mentioned, unless you’re a coffee shop then these “cozy” items just aren’t as common right now. reply duped 39 minutes agorootparentprevHonestly the cheapest way to muffle sound is to not create it in the first place. Guests make noise to hear themselves over other guests and the din of the room, the quieter the room, the quieter the guests, etc. Essentially, the louder the noise floor, the louder the signal has to get to be intelligible at every table, which raises the noise floor, creating a feedback loop. Good acoustic design in a space accounts for this by minimizing how much acoustic energy is present in the room - both by removing it (with acoustic treatment), spreading it away from sources (by isolating tables/booths, using hard surfaces to reflect sound away, etc), and preventing it from being created in the first place. For example, keeping bus stations behind galley doors and training staff not to clink silverware/glasses/dishes when filling bus bins and avoid playing loud music, etc. In my experience, most restaurants fail at this because all the people who do it well are in the high-end restaurant business, which most restaurants are not. If the key to a space that isn't too loud is to limit the number of patrons, have dining room space allocated to treatment between tables, have highly trained staff with consistent management, and a big enough kitchen space with heavy enough doors to isolate the sound within - your only option is to be a high end restaurant. But the high end places fail at it because they don't care and want to maximize the guest throughput because their margins still suck. reply gitinit 2 hours agorootparentprevSound dampening artwork actually seems really interesting. reply dingnuts 4 hours agorootparentprevyes, really any soft surfaces will damp[0] (not \"dampen\") sound, but the techniques and materials can get very advanced (and expensive, and effective) 0 https://en.wikipedia.org/wiki/Damping reply oaktowner 3 hours agorootparentWhoa! Thanks for the clarification. As a word aficionado, I did not realize the correct form of this one. reply 93po 1 hour agorootparentas a fellow pedant, i also really appreciated this clarification. i love it when i learn i've been saying something wrong! reply oldkinglog 3 hours agorootparentprevWhy can't \"dampen\" be applied to oscillators? It means \"To lessen; to dull; to make less intense\" in this case. reply 93po 1 hour agorootparenti think the point is that it's one of those words misused so widely that dictionaries updated the definition to include the incorrect use. dampen means to make something wet, or at least originally that's what it meant reply zerd 54 minutes agorootparentAccording to https://www.etymonline.com/word/dampen it's meant \"to dull or deaden, make weak\" from 1630s and \"to moisten, make humid\" from 1827. reply londons_explore 1 hour agorootparentprev> restaurants can have good sound design, but it doesn't come cheap. Carpet the ceiling and the walls. Super cheap, super effective. Ideally carpet the floor too - and if you use carpet tiles then when a customer spills something uncleanable on a tile it's a 5 minute non-expert job to pull up a tile and put in a new one. reply duped 56 minutes agorootparent> Carpet the ceiling and the walls. Super cheap, super effective. Super dangerous and illegal, too. The reason that professionals don't do this is because no one will permit it, not because there's some scam on acoustic foam and diffusers... well there is but it's not the acousticians' fault. It's a massive fire hazard. reply itsoktocry 32 minutes agorootparent>It's a massive fire hazard. You mean we haven't figured out a material that both dampens sound and is fire resistant? Being as how the former quality is pretty easy, I find this hard to believe. reply duped 24 minutes agorootparentNo we have this, it just isn't as cheap as floor carpeting. In fact, if you ever DIY some acoustic gobos or panels, rockwool insulation is about the best material you can find at the hardware store. But like another comment mentioned there are other concerns in commercial spaces, like cleaning/dusting. reply brulard 39 minutes agorootparentprevsource? Seems like with this logic, wood, wallpapers etc. would be illegal as well. Doesn't make sense to me reply buildsjets 4 minutes agorootparentDoes one hundred dead bodies count as a source? https://en.wikipedia.org/wiki/The_Station_nightclub_fire duped 29 minutes agorootparentprevMy source is the IBC section 803 (1), which I only know about because I've had the misfortune of needing to know about getting building permits for acoustically treating an office space in my career (which itself is a long and boring story about a failed startup). The way the building code is written doesn't explicitly ban any material from walls/ceilings, but rather sets the constraints on the performance of the material when exposed to heat. There are higher limits for walls/ceilings than for floors because flames climb. Wall coverings (including wall paper and its glue) have to be flame retardant to meet code. There have been some infamous fires in the past, which is why this code exists (building codes are written in blood, as they say). Most carpet doesn't go on walls, so it doesn't meet code, unlike wallpaper. And building inspectors are conservative people that are unlikely to permit you to do anything weird, even if you can prove by the letter of the IBC that some material is up to snuff. (1) https://codes.iccsafe.org/content/IBC2021P2/chapter-8-interi... Scroll down to see the details on wall textiles, specifically. reply treflop 4 hours agorootparentprevThere’s something called Auditory Processing Disorder where you are not able to able to differentiate sound and it supposedly can develop later in life. I’ve had it since I was a kid because I always passed the hearing tests but every other kid had no trouble listening to music and understanding the words and so on so I put two and two together. Anyway, I have never been able to understand anyone in any loud public space which absolutely blows when you’re not a home body. See https://en.m.wikipedia.org/wiki/Auditory_processing_disorder reply simmons 1 hour agorootparentThank you for the name of this disorder and link! I've also had this my whole life, and I knew it was a thing that wasn't terribly rare (based on reading comments from others in the past, here on HN and elsewhere), but I think this is the first time I've seen a name for this condition. The Wikipedia page seems to really describe my condition, except for the potential overlap with ADHD. For example, the \"difficulty following oral instructions\". I can read something and retain it forever, but if someone speaks to me, it will often go in one ear and out the other. I sometimes wonder if this could be a result of being a very introverted child who started reading at around 3 or 4 years old. (Because reading is so awesome, why bother listening to people -- and improving your auditory neurology -- after that?) I think I've probably just adapted to the condition. It doesn't seem like any sort of problem or disability. But I suspect others around me find it much more annoying than I do. ;) reply albert_e 44 minutes agorootparentOne thing I feel in my personal experience -- while I am doing something -- inability to switch attention to someone speaking to me if they do not first ask for my attention (excuse me / hello / myname / cough / knock) before diving into speaking in sentences. very often by the time i start paying attention to them speaking -- they are 4-5 words into their sentence and I have missed the context of what they are talking about and i have to ask them to stop and repeat from start This has happened with me in multiple settings (work and personal life) Not sure if this is a common thing along with APD - which i recognize some symptoms of in myself reply wanderingstan 6 hours agorootparentprev> ...restaurant and public space designers have stopped thinking about sound. Theory: The bars and restaurants want young patrons, so the poor acoustics are a selection mechanism. Only young people can converse there, so older folks stay away. The place gets reputation as “young and hip.” Whether by conscious design or “natural selection” for establishments, this seems to be the case. reply RhysU 5 hours agorootparentDesigners for bars and clubs will take the clientele into account in subtle sensory ways. One once told me how he designed a club known to cater to those having trysts-- it had many isolated booths where the lighting prevented seeing into the booths from the main areas. reply kdfjgbdfkjgb 5 hours agorootparentthe club was already known for that before it was designed? reply vidarh 6 hours agorootparentprevI resorted to wearing earplugs for several years when I was going out more. I felt it did very little to reduce my ability to hear conversations, and it made the whole experience overall so much more pleasant. reply UI_at_80x24 5 hours agorootparentI've done this too and it helps tremendously. reply 0_____0 6 hours agorootparentprevIf the SNR is already low enough that you're having issues discerning speech, lowering the volume won't help. reply LeifCarrotson 6 hours agorootparentLowering the volume can help with the SNR, because neither the signal, the noise, nor the lowering effect caused by earplugs are consistent with respect to frequency. Highly objectionable, harsh 4-8 kHz noise that might echo around a concrete and steel venue is blocked well by good earplugs, while low-frequency 100-400 Hz speech is ineffectively blocked. reply kk6mrp 4 hours agorootparentDo you have a good earplug recommendation? reply jefurii 3 hours agorootparentI like Etymotic (https://www.etymotic.com). The design lowers the decibels without affecting the sound too much. I used to play in a band with a drummer who always wore their high-end plugs which you have to have molded to your ear canals, but they also make cheaper standardized ones that do a good job. reply tripzilch 4 hours agorootparentprevI have some of these https://www.loopearplugs.com/ They're super comfortable and they don't look weird like the neon yellow foam ones :) Before I always disliked wearing earplugs when I have to at concerts, but the ones from Loop I just wear anywhere I like that is too loud reply rangestransform 54 minutes agorootparentprevI go to live music a lot so I invested in some custom molded earplugs from 1of1custom.com reply swader999 4 hours agorootparentprevI like these best for low cost plugs. Howard Leight LL-1 Laser LiteUncorded Foam Earplugs Box, 200 Pair https://a.co/d/3REDT7l reply LeifCarrotson 3 hours agorootparentHa! I bought the same box literally a month ago, this listing ships Prime and costs a little less: https://www.amazon.com/dp/B0007XJOLG Those are great for the workshop, but they're flourescent green and pink. That makes it easy to see when someone's wearing them, which is good in a shop but usually bad in social settings. reply Spoom 3 hours agorootparentprevLoops are great as a sibling comment mentioned but I had to have very loud dehumidifiers in my house all weekend; I've been walking around with my Sennheiser Momentum True Wireless 3s in transparency mode (i.e. uses microphones to play sound from the outside into the headphone), and it's been amazing. It cut the audio to a maximum level and let me discern conversations more easily than folks not wearing anything. reply vidarh 5 hours agorootparentprevIt didn't help much with the signal, but it also didn't make it worse, and it made the overall experience far more pleasant. reply CuriouslyC 5 hours agorootparentprevThat's not entirely true, if you're selectively lowering the volume of different frequencies it might solve the problem. The only problem with that is that earplugs tend to reduce high frequencies more than low frequencies, but background noise is mostly low frequencies. Earplugs might help you hear people in a machine shop with a lot of high frequency noises though. reply cs02rm0 6 hours agorootparentprevIt won't help you discern speech, but it'll stop your ears ringing. reply pc86 5 hours agorootparentExcept it absolutely will help you discern speech. The sound blocking is not uniform across all frequencies and most speech is not blocked very well. So earplugs will make speech 20% quieter but will also make all the nonsense going on around you 70% quieter. So the speech will be easier to hear assuming you don't have $3 Wish earplugs. reply cqqxo4zV46cp 3 hours agorootparentprevHa. Classic techie parachuting in and incorrectly intuiting how something works. Show me earplugs that REDUCE equally across all frequencies and I’ll invest every dollar I have to my name. reply ceejayoz 7 hours agorootparentprevI've got a similar thing; I can't pull most song lyrics out of the song, and any significant amount of background noise means lip reading for me. Hearing's all fine, it's the processing that doesn't work quite right. https://en.wikipedia.org/wiki/Auditory_processing_disorder reply nosecreek 3 hours agorootparentInteresting. I suspect I may have the same thing. I also have poor vision without glasses, and I’ve always found that when I go swimming (and can’t wear my glasses) my hearing also gets significantly worse. Or at least the cocktail party problem gets worse, as my brain seems to get overwhelmed by every single background noise. I think some of this is explained by many indoor pools being big echoey spaces, but it still happens at outdoor pools as well. I suspect that when one sense (sight) is degraded, my brain tries to compensate by focusing on another sense (hearing), and the end result is even worse due to APD. reply dekhn 1 hour agorootparentprevThis is why I turn on closed captioning even when I'm watching alone with headphones on. reply pavel_lishin 6 hours agorootparentprevDitto here. An audiologist recommended something called LACE therapy, but it wasn't cheap so at the time I didn't go for it - I need to look into it, and see if it's a legitimate treatment for this, or snake-oil. reply 1123581321 4 hours agorootparentI would not say it's snake oil, but it will only help if you've learned some helplessness or are bad at thinking about what someone is saying while they are speaking. A hearing aid or filter is always going to be more helpful if you only can pick one treatment. reply pavel_lishin 3 hours agorootparentBut that's the thing, I'm in the similar position to others in the chain - last week, an audiologist said my hearing was tremendously good. But if there's noise around me, I cannot process what people are saying. I'm not sure what you mean by \"only if you've learned some helplessness.\" I'm not a complete idiot, I can generally guess what someone is saying based on context, but if I'm having a conversation with Group A in a loud environment, and someone from group B turns to me and says something, I don't have much context as to what they're saying. (Also, a PSA: if someone who didn't hear you says, \"what\", or \"can you say that again?\", don't just repeat the last three words you said. Please repeat the entire sentence. I know that usually, the last few words provide enough context to reconstruct the sentence, but if you just tell me \"this Sunday?\" it's usually not enough, you have to just say, \"Are you still planning on reconfiguring the encambulator this Sunday?\") reply simmons 1 hour agorootparent> if someone who didn't hear you says, \"what\", or \"can you say that again?\", don't just repeat the last three words you said. My pet peeve about asking people to repeat isn't that they won't repeat enough, but that they'll repeat in exact the same volume and enunciation as they originally spoke. I'm not sure why they expect to do the same thing again and get different results. The only thing that I've found that works is to tell them what it sounds like they said, no matter how crazy (\"Did you say, 'the elephant is painting the room'?\") and only then will they speak loud and clear. (Which I'm sure is annoying for the other person, but what else am I to do?) reply jwagenet 1 hour agorootparentprevThe parent poster’s word choice was perhaps uncharitable, but my read is helplessness is not equitable to idiocy. To me, it’s more the difference between actively trying to understand the conversation vs letting it tune out as a default. I find that I have trouble focusing on one conversation if others are happening around me, but that has much to do with where my focus lies as my brain being overwhelmed. reply s0rce 2 hours agorootparentprevThere are some restaurants we don't often go to because they are too loud to be enjoyable. Luckily its patio weather most of the year here in California so eating outside is generally much quieter and enjoyable. I also have trouble discerning sounds in crowded spaces. Thanks for sharing your diagnosis, really interesting to think about. reply mozman 6 hours agorootparentprevI don’t go to bars very often anymore but I absolutely detest live music. I go with friends to talk. Not to have loud music prevent a conversation. reply wintermutestwin 6 hours agorootparentIronically, I think most of my hearing loss is from people trying to talk to me while I was listening to a band. If the band is playing zip it! reply Aeolun 5 hours agorootparentDunno whether you really need more than your hands to communicate when listening to a band in that situation. At least until you get to more than 10 people that need a beer. reply instagib 2 hours agorootparentprevMy hearing aids have a custom directional hearing section I can modify. I’ll give this a try next time I’m in a crowded area. reply UI_at_80x24 5 hours agorootparentprevNot to act like an arm-chair doctor but have you ever considered that you may be on the ASD spectrum? That function of being able to mentally 'filter out' specific voices within a crowd is (semi?) common signal of autism. More accurately; I'm like that and I am autistic, I've read that it happens to a lot of others. reply kayodelycaon 4 hours agorootparentIt can also happen with ADHD. I seem to have difficulty integrating sensory information and thinking at the same time. If it’s noisy, it causes a series of buffer overflows at every level of cognition. reply mrandish 3 hours agorootparentYep, I have ADHD and have always needed to put more effort toward parsing a particular sound in a dense sound field than other people. I've also always had trouble quickly identifying a particular object in a dense visual field. My wife jokes I'm \"the world's worst 'Where's Waldo' player\". I can still manage to do these things but it takes longer, requires more effort and I'm generally never as good at it as others seem to be. I've always suspected these two things are related to each other and to my ADHD. There's a related audio issue I suspect is also tied to ADHD. When I'm mentally focused on a task, if someone interrupts me, I often miss the first couple words they say. Fortunately, when it happens I can usually derive the missing context from the rest of the content. Interestingly, it's not that I didn't hear the sound of the words, it feels more like a lag in mental context switching to parse the sounds into meaning. reply kayodelycaon 2 hours agorootparent> I've also always had trouble quickly identifying a particular object in a dense visual field. I never considered ADHD affecting my visual processing but it very well could be. > Interestingly, it's not that I didn't hear the sound of the words, it feels more like a lag in mental context switching to parse the sounds into meaning. Happens to me all the time, I'm listening but sometimes my brain blips. I hear the words, but I no longer remember them by the time I'm trying to understand them. reply jives 58 minutes agorootparentprevI'm recently diagnosed, and I'm this way with auditory and visual input. If I go to a crowded sports bar with TVs, I'm basically useless. reply micromacrofoot 5 hours agorootparentprevThe one thing that annoys me about restaurants and other crowded places... is the insistence on playing music to attempt(?) to cover the sound! I simply don't understand it, why the hell would I want a noisy place where I can barely hear anyone to have MORE noise!? it's not even good quality noise, it's usually top 40 from 10 years ago being blasted over shit speakers. reply RobotToaster 6 hours agorootparentprevAuditory processing disorder? reply MisterBastahrd 3 hours agorootparentprevI'm one of those annoying ADHD people who will hear everything you're saying, ask \"What?,\" and then a second later I've finished processing the audio in my head and am ready to continue the conversation. Similarly, I can't readily differentiate voices from melody in songs. Far too many songs don't have strong enough vocal tracks and the songs might as well just be mud to me. I suppose it's why I gravitated towards rap and R&B growing up. reply follower 1 hour agorootparent> [...] ADHD people who will hear everything you're saying, ask \"What?,\" and then a second later I've finished processing the audio in my head and am ready to continue the conversation. You know, until you mentioned it, I'd never thought that that experience might have an ADHD-related component to it. Interesting. reply j33zusjuice 4 hours agorootparentprevHave you tried earplugs like Loop or Eargasm? I’ve considered them for a while, but never pulled the trigger. Reddit seemed to prefer Loops to Eargasms. I actually find foam earplugs make voices easier to hear. I can have conversations during concerts with them somehow, in fact. So I figure if foam earplugs can do that for me, then earplugs designed to block only unwanted noise are probably even better. Case in point, I was recently at a Swans concert—-they play very long sets, like 3 hours—-and my back got tight, so I started stretching. I heard someone 20 ft away talking shit! They said, “yeah, I guess you can do your Pilates here.” I finished the stretch and then heard, “oh, I guess he was just stretching.” reply exe34 4 hours agorootparentprevI patronize them - from a distance. reply wruza 6 hours agoparentprevThis isn't your issue though. A group chooses to talk in an environment where they can barely hear each other. Rather than using a device for it, I'd recommend to perceive the problem as it is and solve it in a conventional way. E.g. by saying \"I couldn't hear shit, and you too probably. That's stupid, let's goinstead\" unless it's hard to do. Generally these places are designed for you to suffer unless you're screaming all the time and are indifferent to surroundings. I don't get why people go there and leave money, cause I wouldn't go there even for that money. You don't want an AI device that replaces respect for each others limits. reply pavel_lishin 6 hours agorootparentIt's certainly their issue if they want to continue spending time with the group doing what most of the group prefers. > I don't get why people go there and leave money, cause I wouldn't go there even for that money. That's a problem with lack of empathy and understanding on your part, not with the group dynanimcs of that person's friends. reply wruza 5 hours agorootparentGroup dynamics are hard, see Abilene paradox. https://en.wikipedia.org/wiki/Abilene_paradox reply boringg 5 hours agorootparentAlways suspected this - didn't know there was an actual term for it. Thanks! reply drewg123 3 hours agorootparentprevYou don't always have a choice. Sometimes there are loud places where you just have to be (airports, train stations, etc). My most frustrating time is transiting airports with my wife, who is a very quiet talker. reply ghaff 6 hours agorootparentprevIt's sort of inevitable in crowded situations. My main objection is when there's also loud music when that really isn't the purpose of the gathering. reply ljf 33 minutes agoparentprevAs an older adult I've realised I most likely have ADHD - I've always struggled to focus in busy places, unless the person has my attention - as soon as we are in a group or people all talking or pitching in, and I can't focus on one face, I'm lost. My hearing is fine (I assume) - but I've come to realise I can't process information when there is too much going on. My family will often have the TV on, games playing on phones, and talking too - I just can't hack it. Equally the option to work from home has revolutionised my productivity - without having 10 things to filter out, I can just focus on getting the task in hand done. In an office I often get lost and distracted, and have to power through the noise. reply ricardobeat 7 hours agoparentprevI’m in the same boat. My hearing has a dip around the 2-4khz range which makes speech unintelligible in many situations. Otherwise it seems normal and I still hear details in music that others can’t. Using Sony headphones in voice mode helps but I don’t carry them all day… reply totetsu 7 hours agoparentprevThere are these passive directional earplugs https://www.flareaudio.com/pages/earhd reply j1elo 6 hours agorootparentThe prospect of an earplug that eases focusing audio got me interested... but no thanks, I won't go out to socialize with basically two mini trumpets coming out of my ears. It looks funny, reminiscing of classic b&w pictures with deaf people carrying ear trumpets everywhere with them during 18th century. reply SamBam 6 hours agorootparentI was agreeing with you, but then I watched the video of Stephen Fry and I felt that they just looked like beats earbuds, which people have normalized wearing. reply cs02rm0 6 hours agorootparentprevYeah, I like the concept, not a fan of the implementation. reply instagib 2 hours agorootparentprevI responded to another comment but after reading this thread noticed my hearing aids have a custom directional hearing section I can modify. reply dghughes 6 hours agoparentprevPeople with some hearing loss can't hear consonants but vowels can be heard. I think that's why some people may assume they don't have a hearing problem. My Mother has had poor hearing for decades. She listened to a radio as a kid she held it next to her ear at a loud volume. Now she often says she \"can't stand noise\" but it's because she can't hear in loud environments anymore due to hear hearing problems. I've noticed she misses the start of a sentences like if I said \"I'm going to get some milk\" she heard \"got some milk\" (as in I just got it). Or she interrupts people because she can't hear the first part of someone starting to speak most people tend to speak low at the start of a sentence. reply ddmf 5 hours agoparentprevI have issues with auditory processing disorder which means my hearing is actually really good, but someone talking to me seems to get a much lower decode priority than some random noise around me - if I can see the lips, even though I can't lipread, it helps me decode the speech with a much greater accuracy. Every time I looked into this, it seemed to push the link with autism and/or adhd - back in 2008 I wasn't diagnosed so I poo-pooed the idea somewhat. Now I'm diagnosed as AuDHD. reply jives 1 hour agorootparentI'm recently diagnosed and I experience the same. Listening to someone in a crowded room takes a ton of effort because my brain wants to track all of the other conversations and noises. reply foobarian 5 hours agoparentprevI happened to go out with a group of workers from a deaf school. It was a particularly loud and annoying bar and it didn't bother them one bit. :-) reply vidarh 6 hours agoparentprevYeah, same. My hearing is absolutely not great, but \"good enough\", but in noisy environments I struggle. Given I'm fairly introvert to start with, on one hand, I'm perfectly at ease just checking out and sitting with my own thoughts if I can't hear a conversation, but when I do decide to come out with someone I'd prefer it to be easier to be more social instead of resorting to checking out. reply dnpls 5 hours agoparentprevThe article mentions \"The team is working to expand the system to earbuds and hearing aids in the future.\" reply nashashmi 4 hours agoparentprevTip for anyone trying to communicate in noisy room: 1. Don't speak fast. Speak slow. Enunciate and articulate all the consonants. And do it very slowly. Give the vowels lots of room to be noticed. 2. Don't speak lightly. 3. Don't mumble. Aayyeee hHHaaaVVE TTOOO GOOO NNAAAoooUUU reply carlosjobim 5 hours agoparentprev> In groups and with friends, it's inevitable that you end up in a busy restaurant or a bar, and it always frustrates me that I don't hear something, I ask the person to repeat only to not hear it again That's so you can lean in and get a little bit more friendly. Or go out for some fresh air together. reply Pxtl 5 hours agoparentprevMy favorite case of this awkwardness: Other person: *mumble mumble* SOMETHING CLEARLY SPOKEN Me: I'm sorry, what? Them: \"clearly spoken?\" Me: No, the first part. Them: \"something?\" Me, giving up: *smiles and nods* Yeah! (quietly hopes I didn't just agree that putting hamsters in blenders or something is a cool idea) reply Pxtl 5 hours agoparentprevI've taken to wearing bone-conductors waaaaay to much, and I'm impressed with their flexibility for stuff like this. They keep my ears open, but when I need to hear the headset more clearly (like if I'm in a crowded area and taking a call) I can plug my ear with my finger and that both improves the audio quality of the bone conductor (it creates a speaker cabinet in your ear for a much fuller sound) and blocks out the outside noise. If you need full headphone-quality you put in ear-plugs. And they're pretty small and discrete. They're not perfect, but the fact that I can move smoothly from \"I need my ears open but still want to hear my headset\" to \"I need to block out sound and hear my headset perfectly clearly\" with just a finger or a pair of earplugs is great. Stick a shotgun mic (that's the term for a mic with tight directional cone, right? Not an audio guy) on the side and this would be really cool. reply solarengineer 4 hours agorootparentShokz has these bone conductor headsets with mics. reply tmtvl 1 hour agorootparentI had Shokz bone-conducting headphones (openmove or something like that?), but unfortunately the battery died after a single charge. It was a shame 'cause I was really fond of them. If/when my headphones give the ghost I'll give them another shot. reply nolongerthere 7 hours agoparentprev> I'm not sure if their diagnostics sucks, or I'm just a normal person and others pretend better that they hear everything well This is one of those frustrating gaslighting things that is half true in that half the time I also pretend to hear what someone else is saying even though I couldn’t just because it’s not really important and making a big deal about it (ie asking them to repeat it at continuously louder decibels) can get awkward. reply abcdefg_ 6 hours agorootparentSo I'm not alone. I'm in my mid-forties and have experienced a significant decline over the last few years. Now I can rarely distinguish one voice in moderate background noise (conversations, music) without leaning towards them, cupping my ears. Sometimes I just have to give up and try to nod or smile at the right time as the conversation goes on around me. I recently had a test at an ENT doctor who told me my hearing is fine and insinuated I was wasting his time. The test was listening to high-pitched beeps over white noise, which isn't representative of the problem. Distinguishing one particular tone over several similar ones would be more like it. reply boringg 5 hours agorootparentSame thing. Did a test and the audiologists comment was that I would be the best hearing tested all day or all month and come back in twenty years. reply glenngillen 5 hours agorootparentprevHey, there's dozens of us! :P I wrote about my experience with this last year: https://news.ycombinator.com/item?id=35897515 I did exactly the type of diagnosis you're talking about. It was quite good at how it simulated a noisy environment with a bunch of background chatter and then a single voice you were meant to listen to that would repeat various patterns of words with various combinations of lower speaking volume and/or higher background noise. One thing I wish I'd made a point of at the time was the fact that, despite being an apparently soundproof booth with headphones on, I could definitely hear people talking in the waiting room and another audiologist in an adjacent room. Though I'm not sure it would have materially changed their lack of diagnosis (they'd already detected I could hear into negative decibels). I still don't have a diagnosis, but I'm increasingly coming around to the idea that maybe it's not that my hearing is bad but that I actually hear too much. What I'd previously thought was my unability to hear people speaking on the radio in the car when everyone else clearly could wasn't because I couldn't hear the radio, it's that I can't hear it over the top of all the tyre and wind noise I'm also hearing and trying to process out. I don't think the other passengers in the car hear the rest of the noise, they only hear the radio. I bought various types of Loop earplugs and have found them fantastic for live music events. I can now hear my friends when they're talking to me! Unfortunately they greatly amplify my perception of the volume of my own voice when I talk which has the undesirable side-effect of making me talk even quieter so I feel like I'm having to yell when I want to talk to people. I've also not found them as useful as I'd hoped in restaurant-type settings. reply KaiserPro 11 hours agoprevOne thing that the HN crowd should appreciate is just how expensive and shit hearing aids are. go and look the up the price, they are deeply expensive, even for basic \"make it louder\" type aids. Worse still, because they interfere with your ear, you tend to loose the ability to \"steer\" your hearing. This means that you can't tune out other conversations/noises or stuff. The one good side effect of facebook spending billions on its (probably) futile search for practical and popular AR is https://www.projectaria.com/glasses/ Which is a (cheap) platform to do experimentation for AR type actions. However it has eye tracking, microphone array and front facing cameras, so it can be fairly easily modified into being a steerable microphone. reply andrelaszlo 10 hours agoparentModern hearing aids are pretty cool. They've crammed in an amazing amount of features in a super tiny form factor, with a battery that lasts for a week even when using bluetooth. My Phonaks have the ability to automatically switch programs to some extent, and to fine tune the program using a companion app. I can function and even have conversations to some extent in noisy environments, something that would have been impossible for me with hearing aids from a decade or so ago. I'm very grateful for this of course. The pair costs roughly $2000. Luckily, it's covered by the national healthcare system[0] (which I of course pay for through my taxes) so I end up paying $50 every five years or so. I hope the advances in \"AI\" will make it possible to not just amplify and filter (even if it's in very clever ways) but to isolate and enhance/reconstruct voices in noisy environments. Meanwhile, I hope the trend of playing louder and louder music in cafes, restaurants and bars dies out. It's an accessibility nightmare, especially (but not only) for people with hearing loss.[1] 0: https://www.socialstyrelsen.se/en/about-us/healthcare-for-vi... 1: https://www.vox.com/2018/4/18/17168504/restaurants-noise-lev... reply gravescale 8 hours agorootparent> Meanwhile, I hope the trend of playing louder and louder music in cafes, restaurants and bars dies out. I don't hold out much hope because as far as I can tell it's done to make everyone \"shut up and drink\". I could believe it adds at least 50% to sales because when you can't hear a word anyone says, all you can do is smile and nod and take a swig. And if the place is already full anyway, they don't care if you leave, you'll be replaced. What matters is whoever is in there taking up a space is drinking as fast as possible. Of course, people who get substantially drunk (which is to say, customers who spend) also don't care because they're not really listening closely or making conversational sense anyway and their pain tolerance is way up, so it's just a good time to them. Even more cynically, it also keeps the place \"cool\" because all the old, past-it fogeys like me don't even bother going in. From this sample of one, someone who thinks the music is too loud is un-hip, isn't adding to any hookup appeal (either not in the market or pushing the creepy end of the age range) and won't even spend much because they can't get really hammered because the hangover will take them out for two days and they can't afford to lose a weekend. reply HPsquared 8 hours agorootparentIt's depressing to think of the different ways people are treated like livestock on a factory farm. reply 100721 6 hours agorootparentIt's depressing to think of the different ways livestock are treated like livestock on a factory farm, too. Factory farms are hell on earth. reply rayrey 5 hours agorootparentI need to find the article about the multistory pig farm in China. The whole lifecycle from piglet to fattening up and slaughter all in one convenient location. reply throwup238 6 hours agorootparentprevAt least livestock gets to grow up in pasture before they’re sent to the feedlots. reply BeFlatXIII 3 hours agorootparentNot all livestock is so lucky to have been born a cow. reply noSyncCloud 4 hours agorootparentprevThis is, in fact, not always common. I guess it probably depends on the country/region to some extent. reply throwup238 4 hours agorootparentI was thinking of cattle but totally forgot about pigs and chickens. reply thsksbd 5 hours agorootparentprevNot just restaurants and bars. Artificial sounds is everywhere. There was a musician (fairly accomplished in his field) who woke up one day and started hating all music because he realized you cannot escape it. He wrote a book about it but I forget his name. reply consp 9 hours agorootparentprev> It's an accessibility nightmare, especially (but not only) for people with hearing loss. I can't make out any conversation in a noisy environment so usually switch to try-to-filter-noise-and-fail plus some amateur form of lip reading which works ok for a casual conversation but not for a more serious one. Hearing is \"ok\" enough though when testing, so no clue what it is. It helps a lot when the ambient noise level reduced by a few db and tuning down the music helps a lot. reply darkwater 9 hours agorootparentSame here. I have a (I think) very good ear in silent environments,for example I can hear a very faint sound at night, but I always struggled following conversations in music clubs or bar with high music volumes. I always end up nodding and saying \"yeah yeah\" even if I have no remote idea of what the other person is saying. Edit: but OTOH I see people having actual conversations in those same environments, so I guess it doesn't affect everyone in the same way, and it's not either something fully related to how my eardrums are capable of working... reply follower 1 hour agorootparentThese have been mentioned elsewhere in the comments but in case it's helpful: * https://en.wikipedia.org/wiki/Selective_auditory_attention * https://en.wikipedia.org/wiki/Auditory_processing_disorder * https://en.wikipedia.org/wiki/Cocktail_party_effect reply nkrisc 9 hours agorootparentprevMy experience is exactly the same. I doubt everyone is simply pretending they have any idea what everyone else is saying, so it must be something wrong with me. I’ve had my hearing tested. It’s within normal ranges across all frequencies tested. I have to assume it’s some kind of discrimination or processing difficulty in my brain. I’ve noticed the same effect can be triggered even in a white environment by only two or three people trying to talk to me at the same time. I can’t understand anything any of them are saying and can’t listen to just one. reply maeil 8 hours agorootparentI'm the same, and no, others are not pretending. It makes sense that our increased ability to recognize non-speech sounds may come at a cost of reduced ability to recognize speech. reply wccrawford 8 hours agorootparentprevI also have a problem with \"background noise\" and being unable to understand what people are saying in noisy environments. Most people definitely do not have it as badly as I do, or they'd never go to a noisy bar and try to talk. It's simply impossible for me to do anything but pay full attention to the person talking, and even then I often have to guess many of the words. I even went and got my hearing checked (and my wife did at the same time), but the clerk assured me that we don't definitely have hearing problems and joked that we needed marriage counseling instead. :/ It's funny now, but I was a little pissed at the time. Anyhow, my point is that some of us do indeed \"hear\" worse in noisy environments, even if our ears are amazing when it's quiet. reply maeil 8 hours agorootparentprevInteresting, I'm the exact same, but so far hadn't come across anyone else with this issue. I think the two aspects might be related. Possibly the average brain is more finetuned to recognize speech specifically, which comes at the cost of recognizing other sounds, but improves speech recognition. Ours are less finetuned, with the opposite effect. reply deadbunny 9 hours agorootparentprevHaving worked (and frequented) loud bars and clubs for decades no one can hear anyone and just nods along. reply cjrp 9 hours agorootparentprevI'm exactly the same, end up doing a lot of nod-and-smile which isn't ideal! My hearing isn't great in the high frequencies, but nothing major. reply TeMPOraL 8 hours agorootparentprev> Meanwhile, I hope the trend of playing louder and louder music in cafes, restaurants and bars dies out. It's an accessibility nightmare, especially (but not only) for people with hearing loss. I thought it's well established that they're doing it entirely on purpose. Restaurants, cafes and bars don't make money on you chilling out and having a good time with friends; they make money on you buying food and drinks. They want you to order and consume ASAP until you're full and leave, freeing the table for the next group of customers. Loud music that prevents you from having conversations is how they make this happen. reply mhb 6 hours agorootparentThis explanation doesn't really work for the cafes that allow people to take up space at tables for long periods just guilt-ordering a minimal amount. reply bowsamic 8 hours agorootparentprevI've been to quite empty restaurants doing the same thing though. The thing is, a lot of people seem to love it, even though they're struggling to talk to the people next to them. I don't understand it at all personally reply lathiat 4 hours agorootparentprevApple AirPods Pro are doing all of this now. They’ll isolate people in front of you, can reject background noise but allow voice, etc. They can also correct both music audio and “transparency” audio using your Audiogram. Unfortunately for me, they average both ears and perform the same correction on both ears and I have notable hearing loss only on one side. I don’t see any reason proper hearing aids can’t already be doing it now though I am sure some of them are but probably the even more ridiculously priced $8k+ models. Nuheara is also in this space but marketed and designed more specifically to be a low budget hearing aid replacement. With a similar pride to AirPods Pro. reply gertlex 5 hours agorootparentprevCurious, is that your first pair of phonaks? If not, is the use use of bluetooth + app hurting your soul? My current pair are about 6 years old, working fine still, thankfully... But in a recent visit to audiologist, they had me test out a newer pair... but they had a single button instead of rocker + button, and bluetooth/app was touted. I dread the touchscreen phase of HA as a young person with functional fingers (vs elders with dexterity issues) and a preference for physical buttons (a la my 2009 car). The idea of autoswitching the programs outside limited cases (direct audio input cables and increasingly-rare telecoil situations are the only things I would accept) also doesn't sound great! :) reply andrelaszlo 3 hours agorootparentSecond, but first with BT. Connecting to the app takes forever and frequently fails. It seems to clash with the Android device pairing somehow. It's not great. The only workaround I've found (if restarting the things by opening/closing the battery compartment doesn't work) is to remove the pairing and set them up again. I also would prefer to set up the programs once and then switch them with physical buttons. I had my audiologist do something like that with my old pair. New audiologist now that doesn't seem as flexible, or maybe it's not possible. The bad app experience is honestly a reason for me to look at other brands for my next pair. I'd like to think that a bit of a learning curve is okay for something that's basically an extension of your body, but everything seems to be getting stevejobsified these days. (I'll be driving my 2006 Saab until my mechanic either retires or runs out of spare parts!) reply follower 1 hour agorootparent> I also would prefer to set up the programs once and then switch them with physical buttons. [...] The bad app experience is honestly a reason for me to look at other brands for my next pair. While the latter is probably the preferred approach for dealing with the issue, I'll admit my mind first went to: If you've got time for a side-project maybe consider reverse engineering the Android app's Bluetooth support... and, you know, \"just\" re-implement the same thing in some stand alone hardware. :) There may even already be a project related to your device--I'm aware of multiple health/medical-tech/device related reverse engineering projects that were primarily driven people with programming/hardware experience wanting to avoid crappy vendor apps & have control of very personally relevant devices. reply yard2010 9 hours agorootparentprev> On the way out, I tried to mention the tough acoustics to someone at the restaurant’s front desk. I don’t think he heard me. It's funny how for some problems the path to the solution is blocked by deadlock reply boringg 4 hours agorootparentprevId say the hearing aids are impressive tech but also not as good as I would have thought them to be. My mother uses phonaks and they constantly give feedback or are scratchy sounds and has to go get the audiologist to adjust them. Shes older so that might be part of the technical challenge with them but i would have expected better given the huge price tag. Feels a bit like a monopoly running the development but that is merely a hunch. reply KaiserPro 10 hours agorootparentprevThose do look good, and in the last 3 years the price has dropped significantly. in the uk those cost about $3k, so not much difference. alas, they are not covered by the health service, only lesser ones. reply unsupp0rted 10 hours agorootparentprev> I hope the advances in \"AI\" will make it possible to not just amplify and filter (even if it's in very clever ways) but to isolate and enhance/reconstruct voices in noisy environments. I often see AI hopes expressed in this format. I would put it another way: > I hope the advances in \"AI\" will make it possible to restore hearing to baseline average human level Wishful thinking would be to enhance it beyond baseline. It's perfectly reasonable to think AI-advances can help researchers restore hearing in most cases, and reasonably within 10 years or so. reply passwordoops 7 hours agoparentprevThe expense isn't a tech problem, but an anti trust problem. A small cartel controls the supply, so the only incentive is to maximize profits, not out compete with better tech (0) (0) https://www.thebignewsletter.com/p/silencing-the-competition... reply bongodongobob 5 hours agorootparentYup, in the US this was because they were classified as medical devices which made barrier to entry extremely high. However, the laws regulating this got looser over the last year so we will be seeing more competition now that they can be sold OTC. reply singingfish 10 hours agoparentprevThe only advice on hearing aids is if you need them, get it diagnosed and intervened early. That way you get the cheapest and most reliable hearing aid that's going to work well for you. Otherwise the stuff you described in your comment around attention filtering starts to happen because of the sensory loss. Therefore the longer you avoid hearing correction once your hearing starts to become impaired, the more complex and expensive a hearing aid you need to re-do. This is because these expensive hearing aids do a poor approximation of the things your brain/auditory cortex was doing prior to the sensory loss. BRB - better go book a hearing test. reply randlet 4 hours agoparentprev\"One thing that the HN crowd should appreciate is just how expensive and shit hearing aids are.\" Expensive, yes. My hearing aids cost ~$2500CAD each but \"how shit hearing aids are\" is not my experience at all. My hearing aids (Widex) are awesome! The quality of audio in normal situations is fantastic. My only real complaint is that they're not completely waterproof so I have to plan ahead a bit if I'm going to be outdoors in the rain. reply rock_artist 10 hours agoparentprevYep. My grandma (may she rest in peace) had all those. I've actually thought of doing something like they did when she was alive and I've tried communicating with her at family events or in-public. I guess they're expensive because of relations with medical / health companies being complaint makes things expensive (eg. the same display but with certification to use in a medical facility would cost many times more). reply angra_mainyu 7 hours agorootparentI recall being a student in the biomedical electronics/biomedical devices lab and was curious about one piece of equipment that cost about ~10k EUR. The device is relatively simple to make so I asked my teacher why were they so expensive. He said that yeah, the engineering/manufacturing side of it is about 200 EUR, the remaining 9.8k EUR is spent on certifications/paperwork. Obviously, wages factor into this but over time I've come to see how paperwork and paying lawyers do in fact account for the majority of the cost. reply OkGoDoIt 2 hours agoparentprevAre those project aria glasses actually available for purchase? You say cheap, that implies there’s a price somewhere. Looks like an internal experiment. I would love to be able to buy something like this, but all of the commercially available wearable computers are pretty crappy in my experience. reply ChrisMarshallNY 8 hours agoparentprev> they are deeply expensive Like, $50,000. I'm hoping that removing the need for prescription ones, will allow the price to go down significantly. As an older person, I have noticed that my hearing has gotten \"louder,\" over the years. I still hear dB levels fine. The problem is that I hear all the noise. I used to be able to hold conversations in loud environments (like bar/restaurants), being able to hear the other person, despite the background noise. Not that long ago, I was at dinner in a noisy restaurant. I was sitting directly across a narrow table from someone (about 30 inches -max). I couldn't hear a word they said. They could hear me fine (they were younger). If this works out, it might give the folks currently collecting $50K a pop, another way to charge eye-watering money. reply Dma54rhs 6 hours agorootparentThey are not anywhere at that price. The ones europeans tend to get go for $1,806 retail I checked. I've noticed Americans like to bs their medical costs as bad as the system is, you can't compare some newest luxury devices to what an average person is using all around the world. reply m-s-y 6 hours agorootparentIn fairness to op, the out of date pricing may not be that out of date. recent legislation in the US was meant to bring down hearing aid cost and to break the monopoly on devices. It’s seemingly worked so well that TV commercials for individual brands have started to show up for low cost aids (sub-$5k) reply wl 5 hours agorootparentHearing aids (ignoring implantable ones like BAHA and cochlear) weren’t going for anywhere near $50,000 in the US. reply vidarh 4 hours agorootparentprevThat's utterly insane, and I suspect probably some outlier particularly expensive ones. You can book a fitting, and buy a choice of hearing aids, get trained, follow up, and 5 years worth of checks ups and appointments in London privately with no insurance ranging from ca $1300 to $5000. I've not even found any higher than $5k when I searched for prices in London, though I'm sure some of the Harley Street clinics will be willing to overcharge at ridiculous rates too. reply ChrisMarshallNY 4 hours agorootparentYou are correct. I was thinking of cochlear aids. reply criddell 8 hours agorootparentprevWhat kind of hearing aids cost $50k? reply ChrisMarshallNY 8 hours agorootparentI suspect many of them. I was shocked, when I found out. Of course, you aren’t just paying for the hardware. You are also paying for all the medical stuff surrounding the kit. You can understand why vested interests fought so hard to prevent making hearing aids OTC. Like I said, I suspect that gravy train may have derailed. reply gertlex 5 hours agorootparentMaybe you're thinking about the costs of getting a cochlear implant? Having worn hearing aids for 3 decades (in the US), and not going cheap, the high end name-brand ones have always been about 4-6k for a pair. (and most of the time growing up, health insurance didn't cover it) From everything I've ever seen or in any conversation online, 50k is either a misremembered or made up number for BTE or in-the-canal hearing aids. reply ChrisMarshallNY 4 hours agorootparentYou are correct. I have a profoundly deaf friend with cochlear aids. They are a lot more expensive. Thanks so much for the comment. reply gertlex 4 hours agorootparentGlad to help! At my recent audiologist appointment, it escalated to being suggested that I go for a cochlear implant consultation for one of my ears (I figured why not, despite not personally thinking this was something I'd do any time soon). Apparently it's actually quite possibly mostly covered by my health insurance due to showing medical necessity... I'm fortunate that I could reasonably plan to pay for it myself... the bigger hold-up/concern/issue has been the drastic change in \"how I hear\" that it would involve. (experiences are widely variable it sounds like, but loosely about a year for the brain to gradually learn and improve how it uses the new input?) I haven't even opened the manufacturers' books given to me, or done more research on the possibility since that appointment though... reply newaccount74 6 hours agorootparentprevThey don't cost 50k. They cost at least an order of magnitude less. My moms hearing aids cost 3000€. They support bluetooth so she can use them with her iPhone. The price includes hearing tests, getting molds of the hearing canal, all the setup and configuration performed by skilled technicians. Sure they are expensive, but there really isn't much of an opportunity for disruption. Customized hardware is expensive, there's no way around that. reply ChrisMarshallNY 6 hours agorootparentI live in the US. I noticed that someone else posted a comment, saying that Americans exaggerate medical costs. We don't. Our doctors drive Bentleys. I'm really glad that they have broken the monopoly. Maybe some politicians retrieved their souls. It's absolutely insane how expensive healthcare is in the US. But THANK GOD we don't have socialism! /s reply fn-mote 5 hours agorootparent> I noticed that someone else posted a comment, saying that Americans exaggerate medical costs. In this case, I agree that your earlier post exaggerates the cost of hearing aids in the US. For example, [1] quotes a top price of $3500/ear. That makes $7000 total. A page full of search results [2] will tell you that prices are in ranges like $1-6k each. Even the hearing aid producers are quoting those prices. [3] [1] https://www.hearinglife.com/hearing-aids/prices [2] https://www.google.com/search?q=united+states+hearing+aid+pr... [3] https://www.miracle-ear.com/hearing-aids/cost reply ChrisMarshallNY 5 hours agorootparentOK. I cede the point. It's likely I'm wrong, as I am not deaf, and don't have a hearing aid, so I am not speaking from experience. I have a freind that is deaf, and has the magnetic cochlear ones. It's not worth arguing about. This is not an area I'm anywhere near expert in, as I suspect, many other commenters are. reply citizen_friend 5 hours agorootparentprevThis is a low quality comment, that was already debunked by a google search in a comment below. reply ChrisMarshallNY 5 hours agorootparentWhat Google search? You mean the specific hearing aid searches? It was a general comment on the state of health care in the US (not just hearing aids). Before the new legislation, we couldn't just go to the corner drug store, and buy a hearing aid off the shelf. It needed to come as part of a package, including many tests and appointments with ENT folks. But I cede the point. It was a low-quality comment that is likely to trigger folks with certain political views, and I apologize. Won't happen again. reply s1artibartfast 4 hours agorootparentI feel like you are still exaggerating the difficulty. Costco has sold them for at least 10 years. You just need to make an appointment and they take care of the rest. reply ChrisMarshallNY 4 hours agorootparentprevJust to be clear. Looks like I’m wrong, making a general statement, based on anecdotal information. We’ll have to see what the future holds for us. reply josefresco 5 hours agorootparentprevMy dad just got hearing aids (US) about 3 weeks ago. They cost him $1600 with no insurance coverage. reply Lio 8 hours agoparentprevLooking at Apple's Airpods Pro, they're starting to get some of the features of hearing aids. E.g. features to allow doorbells through the noise cancelling. I don't think anyone would suggest them as a realistic choice today but I could see Apple going after that market and where Apple goes others follow. Much like the market for prescription reading glasses has been eroded by off the self glasses. reply thsksbd 5 hours agoparentprevInstead of fancy shmancy AI, could a pupil tracker on eyeglasses be used to estimate where a person wants to hear and use phasing to amplify the signal from there? You have two microphones already, spaced about 30 cm apart... reply KaiserPro 3 hours agorootparentYup thats basically what most AR glasses are capable of (or in the case of the linked aria glasses, research device that does have all the sensors.) but you don't need eye tracking all the time, as most you can latch on to the location of the speaker without looking at them continuously. The possibilities are rather good, but it needs someone willing to fund the research reply gertlex 5 hours agorootparentprevMicrophones are cheap right? Just have multiple on each ear while you're squeezing in the AI features too :) reply eek2121 8 hours agoparentprevI don’t have hearing aids, but I do suffer from hearing loss. That being said, the Apple Airpods do a wonderful job of helping with that in the adaptive or transparency modes. Apple was working taking the platform even further at one point and I would not be surprised if we see some new announcements eventually. Imagine if a $200 set of airpod pros outperformed top hearing aids. reply eek2121 7 hours agorootparentLink to an article about it: https://www.techradar.com/how-to/how-to-use-your-apple-airpo... reply micromacrofoot 5 hours agorootparentprevI too suspect they're looking into it beyond existing prevention features, they've had some opt-in studies for airpods: https://www.apple.com/newsroom/2024/05/apple-hearing-study-s... reply moffkalast 9 hours agoparentprev> you tend to loose the ability to \"steer\" your hearing Do people genuinely have that ability, to listen to a specific person and ignore the rest? Asking because no matter how hard I try I can never understand a fucking thing if there's many people talking loudly in the background, it all mixes together into an incoherent whole. reply andrelaszlo 8 hours agorootparent\"Selective auditory attention is a normal sensory process of the brain, and there can be abnormalities related to this process in people with sensory processing disorders such as autism, attention deficit hyperactive disorder,[30] post traumatic stress disorder,[31] schizophrenia,[30] selective mutism,[32] and in stand-alone auditory processing disorders.[33]\" https://en.m.wikipedia.org/wiki/Selective_auditory_attention reply moffkalast 8 hours agorootparentAh interesting, I must have dis or that order then. reply nolongerthere 7 hours agorootparentYup I have mild ADHD and as the day wears on I find it harder to do this subconsciously. I need to start making a conscious effort to focus only on the person I’m speaking with and not the cross conversation happening at the same table. reply KaiserPro 6 hours agorootparentprev> Do people genuinely have that ability Indeed! however like visual depth perception, not everyone has it. The human ear has a load of bits that allow removing noise from the signal. (I don't have a block diagram, sorry!) In theory one should be able to locate a noise in 3D. You can test this by getting someone to hide your phone and then ring it. if you have 3d sound perception you should be able to work out if the phone is behind/front/up/down.That forms part of the \"steering\" ability. Then there is filtering the noises that you don't want. Music is can be a good test for this, how many instruments played on this track, what instruments were they, what were the lyrics, etc. Being able to do this requires that you be able to filter out noises that you don't like. Again like all human senses, there are levels of ability, and in some cases can be improved with \"exercise\" But, hearing what people are saying against a loud background is really really hard, so don't worry too much. Plus voices have specific human social encoding, so they can be affected disproportionally reply glandium 7 hours agorootparentprevI can sometimes do that with instruments in music. Never for people. reply wazoox 11 hours agoparentprevThe French youtuber Deus Ex silicium made a through analysis. Basically, hearing aids are slightly worse than ordinary wireless headphones, but 10 times more expensive. https://www.youtube.com/watch?v=QPmwfbLPHG8 reply PoignardAzur 7 hours agorootparentFrom what the video says, it sounds like you could get a much better price by buying the devices directly from the constructor, even without the healthcare subsidies. But doing so means you need to calibrate them yourself. I wonder if some constructors could target this use-case by making aids that are very easy to self-calibrate. On the other hand, the median hearing aid user is pretty old, has lots of disposable money and has never watched a youtube tutorial in their life, so it might be a small market. reply abdullahkhalids 9 hours agorootparentprevI doubt that is true. The hearing aids sold as medical devices, have to satisfy regulatory standards. So a lot of incentive to use older reliable tech. Not to mention, it probably takes a couple of years to get the certification for a device. So, any device to market is easily 2-3 years old tech by definition. reply eequah9L 9 hours agorootparentI think you meant \"I don't doubt\"? Because none of what you said sounds like a counterargument to what the parent said. reply datpiff 9 hours agorootparentprev> Not to mention, it probably takes a couple of years to get the certification for a device. So, any device to market is easily 2-3 years old tech by definition. Approval can be quicker for hearing aids as there are already works-alike devices on the market. 510(k) clearance takes less than 6 months. reply OkGoDoIt 2 hours agoprevThe open source code is at https://github.com/vb000/LookOnceToHear and the research paper is at https://arxiv.org/abs/2405.06289 So perhaps this is not as out of reach as many pop-science articles. I’d love to hear if anyone is able to get this working independently. reply CodeCompost 14 hours agoprevAs somebody who is hearing impaired, a feature like this would be a Godsend for me! This feature should be integrated into hearing-aids ASAP! Shut up - no, actually - keep talking and take my money! reply stubish 13 hours agoparentAnd we almost all will be where you are now, if we live long enough. If you can pick out audio from individuals, you could also send it through speech recognition and subtitle real world conversations for when hearing is worse or not there at all. But it really needs mobile devices capable of doing the processing locally, as I think round trips to the cloud would make it less useful or potentially useless. reply fragmede 12 hours agorootparentHow much latency is acceptable? If you're off in the woods somewhere far from the cloud, sure, but it's less than 10ms to ping Google.com for me, and if the speech-to-text engine runs faster than realtime, I don't see why processing remotely is a problem. 10 ms is nothing. Still, the transcription part is already here today. The Google Translate app has a transcribe app that does this (runs locally; does not do magic AI \"pick voice out from crowd\"). My father-in-law has been using it for years. When I'm in a loud environment, the app I use on iOS is called Big, which just displays large text on the screen. https://apps.apple.com/us/app/make-it-big/id479282584 reply RussianCow 12 hours agorootparent10ms on a wifi connection is exceptional; on a cellular connection it's unheard of. I normally get 70-80ms on 5G, which is well past the threshold for realtime—and that's with a solid connection. reply withinboredom 11 hours agorootparentprev> If you're off in the woods somewhere far from the cloud, sure, but it's less than 10ms to ping Google.com for me I'm in one of the biggest cities of my current country, and the RTT to google from me is 87-91ms. Well over 4 million people live within 100km of me, so I suspect they see similar latencies. On my cell, I see 191-207ms. reply jeffhuys 6 hours agorootparentThat’s a shockingly high latency for a major city! Getting 3ms to google.com here, big city in the Netherlands. Probably close to a data center. reply withinboredom 4 hours agorootparentAlso in a big city in the Netherlands, but I just blame ziggo. We're getting fiber in my neighborhood ... \"soon\" ... so we'll see how it is once that happens. Looks like a good 60ms is nothing but buffer-bloat in the router, as when pinging directly from the router, the RTT is much less. reply jiehong 11 hours agorootparentprevLatency or not, for privacy reasons. reply giantg2 8 hours agorootparentprev\"But it really needs mobile devices capable of doing the processing locally\" I would think this shouldn't be a problem as the correct hardware gets adopted in phones. As it stands now, you could probably run it on a Coral USB accelerator and battery run Pi (just an example of hardware, obviously we don't have the code). reply thfuran 7 hours agorootparentprev>and subtitle real world conversations for when hearing is worse or not there at all. Or for when you don't speak that language. reply Terr_ 10 hours agorootparentprev> And we almost all will be where you are now, if we live long enough. And given the US healthcare system, somebody is gonna take all our money too, one way or another. :P reply gedy 13 hours agoparentprevI have sensoneural hearing loss as well and fyi Bose Hearphones do have something a little like this with directional noise cancellation that helps a lot. They are discontinued but you can find them refurbished. reply gertlex 13 hours agorootparentMy phonak HAs have some directional noise cancellation (or biasing at least; I don't have rigorous definitions for these terms)... It helps but isn't great. Has a problem that I think the AI headphones wouldn't solve either: in a (non-quiet) group setting you still need to anticipate who's going to speak when and look at them for best results. The direction bit is just biasing to preferring forward stuff (via two mics on each ear's HA). Sadly, no backwards bias option for overhearing people behind you ;) reply Angostura 12 hours agorootparentVersion 3 will be able to analyse a room for interesting conversation and then control where you are looking via neuralink. reply richrichardsson 11 hours agorootparentprev> Sadly, no backwards bias option for overhearing people behind you ;) Put them on \"backwards\"; left cup on right ear and vice versa: forward facing mics now face backwards ;) reply gertlex 3 hours agorootparentIt's a bit physically trickier than that due to curved tubing and ear molds... but I could totally \"try\" it with friends, e.g. rotating the BTE hearing aid 180 so it's forward, and they'd have fun too. reply gedy 7 hours agorootparentprevThe Bose have 2 settings for this, 180 degrees frontal, and a much narrow directly in front of you. reply esperent 10 hours agorootparentprevMy Sony's have a \"focus on voice\" setting in the noise cancelling section of their app. Is it similar? reply gedy 7 hours agorootparentI haven't tried those but sounds like possibly just adjusts frequencies vs using directional mics. Might be same as Airpods Pro which I should try. reply camillomiller 11 hours agoparentprevYou should look into Luxottica's efforts in this category. Wearable glasses are quite promising for the use case you mentioned, as they avoid the bulk and impoliteness of wearing headphones while talking to someone. >> https://www.cnet.com/health/medical/what-did-you-say-these-e... reply anonzzzies 13 hours agoprevThis but more advanced would quite nicely help with my tinnitus. I hear fine when one person is speaking (even softly and at a distance), but multiple or with music, I hear nothing. reply snorremd 12 hours agoparentIn the same boat. I have some tinnitus (low frequency, radio static like noise) and struggle with conversation in loud places with lots of background noise and conversation. If I sit in a loud bar it is hopeless hearing what anyone but the closest two persons are saying. Conversation in normal settings are mostly no issue. So something that would enhance the speech of whomever I'm looking at would be super cool. Apple AirPods already have some sound shaping abilities to react to environment and mode. They also support specific voice enhancement if you put your phone down in front of the person speaking. If they ever support directional voice enhancement, like in this research, directly in the AirPods it would help me so much with social interactions in loud places. reply cushychicken 7 hours agoprevI used to work at Sonos, long before their current app update debacle and headphone debut. During the first aborted product effort to develop headphones, we were looking at a conceptual feature similar to this - selectively allowing people’s voices through the ANC chipset. I don’t recall the exact approach the DSP folks were using (I was closer to the hardware for ANC) but they were really only able to figure out how to isolate the wearer’s voice by virtue of that signal having more power than all the others. This is terribly cool. I wonder what other kinds of fun you could have with headphones. ANC chipsets are incredibly powerful and I’d wager their capabilities are not even close to fully tapped. reply polartx 4 hours agoparentAbout once a year I waste about a day shopping for earbuds that would allow me to work in a noisy environment without projecting that noise into my phone calls/conference calls. Never found an adequate product. Seems like noise cancelling has been solved for the listener (isolation + ANC) but I would sure love a hardware/software combo to come along and allow me to work truly remotely by blocking out noise/isolating my voice to the recipient. reply fennecfoxy 6 hours agoparentprevI wouldn't ever want Sonos hearing aids. Universally Sonos units have basic functionality problems such as not reconnecting to Wifi that has gone down and come back up, especially if the Wifi has changed channel during that time. The \"technical\" solution is to pull the plug and reboot it (which you can't even do remotely, even if it's connected to Wifi and you want to reboot because Spotify connect on Sonos can be buggy as hell). I can keep a wifi connection up myself and always reconnect using an esp or similar TI etc module...is it so hard for the Sonos firmware devs to do something so basic? reply richwater 4 hours agorootparentSpotify connect on most devices is buggy as hell. reply ttpphd 4 hours agoparentprevIf you read the paper, nothing has changed. They still depend on the target talker not having competing co located sounds or voice. reply foreigner 11 hours agoprevI'll bet they achieve commercial success with the reverse application. Imagine being able to mute that one obnoxiously loud person with an annoying voice at a party! reply nolok 9 hours agoparentFor something that you could actually sell in volume, you may not be thinking large enough in terms of \"party\". It's common to wear ear plugs at concerts, to avoid destroying your ears. Not imagine replacing those ear plugs with in-ear headphones that filter everything except your family/friends and the concert, while regulating the volume (if your SO talks to you make that one voice loud over the rest), maybe keep the \"crowd noise\" going with the flow but remove normal conversations for people around, etc ... I'm not in ML/AI/etc ... At all but my understanding is that none of that is actually impossible with current tech ? Sure the battery and power limits exists, but this is a concert those headphone with a \"band\" going behind your head to keep them in place / not lose them if it falls makes sense. Would need some training for \"your voice\" but if alexa can do it in 10 seconds then a phone app can do that too. Hell, if it existed for movies theater at below 200€ I would probably buy one right now and maybe go to the movies again. reply nickjj 8 hours agorootparent> I'm not in ML/AI/etc ... At all but my understanding is that none of that is actually impossible with current tech? Over 4 years ago nvidia released a feature that lets you remove arbitrary background noise in real-time. Here's a video where a guy put a fan, vacuum cleaner and leaf blower right next to his microphone: https://youtu.be/Q-mETIjcIV0?t=535 It definitely chopped out a bunch of his natural frequency but it was clear enough to hear him without issues. Earlier in the video he did more normal tests like removing the sound of his keyboard in which case his voice's frequencies were mostly left untouched. He also banged a hammer on his desk while talking. reply genewitch 7 hours agorootparenti have an Asus microphone adapter which does this noise cancelling in the dongle. It was marketed as \"AI\" but i'm sure it's just fancy DSP in the ADC onboard. i use it with a $5 no-name clip on lav mic. I don't sound fantastic on it, but i sound better than people using cellphone microphones and thrift store microphones. It also works if i talk loudly from another room, but won't pick up normal volume conversations in the same room, which means there's a noise gate in there, too. I've heard a very abrasive sneeze sounds like \"chew!\", like a cartoon sneeze or something. I couldn't tell the difference in a blind test between a cellphone's noise cancelling with the sound recorder and the asus device vis a vis overall quality, but the gating on the asus is more aggressive. It also works better than the default discord noise reduction, but is about equal to the Krisp (iirc) implementation. Its gate is faster than discord if you have both krisp and the normal noise cancelling on. I think they're discontinued. If i ever see one in the wild i'll be sure and buy it. I have never tried it with a decent microphone - and i do have a couple, including shure and marantz - because there's no need. I wouldn't use it for podcasting or doing anything where the overall quality would be noticed; but for discord / in game / PC telephony it works great. reply spi 8 hours agorootparentprevI'm into AI but not into sound, so I might be saying something stupid here, but I think using something like this for very high volume like concerts would be possibly outright impossible, but, even if not, certainly quite dangerous and therefore not commercializable. My understanding is that to \"mute\" a sound, you need to inject another wave that is exactly the opposite, with the exact same volume and in perfect sync, so that the two waves interfere destructively. However, in general but especially in AI, you can never guarantee 100% accuracy. If you use this technology to \"silence\" a background fountain, and something goes wrong, at worst you get a lot of noise that make you grimace and remove them. If at a concert with 100+ dB of music you get an error and your headphones start producing a similarly loud, but not perfectly aligned noise right into your ears, you probably won't have the time to remove them before damaging your hearing system. In general, I think that having a tool that drives 100+ dB straight into your head is probably not a wise idea :-) reply tech2 6 hours agorootparentYou could probably achieve the same outcome by combining two approaches though. Use traditional timing and phase management that existing noise cancelling headphones do. Then, using the data from that same set of microphones use AI to extract the conversation of interest (maybe using timing differences from left/right to determine who's \"in front\" of you) and inject that as the thing to overlay on top of the inversion. This way there's no risk of AI error on the noise cancellation and you can rely on existing solutions. reply spacebanana7 5 hours agorootparentprevEven putting 50db of sound in the opposite direction might help take something from the volume of a nightclub to the volume of a refrigerator [1]. Not perfectly muting it, but perhaps good enough for many scenarios. Disclaimer - I also have no technical experience of sound [1] Going by the sounds levels in this post: https://lexiehearing.com/us/library/decibel-examples-noise-l... reply giantg2 8 hours agorootparentprevIt probably wouldn't work for in-ear setups. However, I'd you have over the ear headphones with good passive noise canceling (35db) then you would need less of the active canceling (65db) to make it quiet and safe. reply thfuran 7 hours agorootparentprevYou can get earplugs with ~30 dB reduction and builtin in-ear monitors. Slap some microphones and such on the outside, and you can probably work with it. reply bdowling 11 hours agoparentprevBeing able to selectively mute people was an element in a couple of Black Mirror episodes. reply latexr 10 hours agorootparenthttps://en.wikipedia.org/wiki/White_Christmas_(Black_Mirror) reply devjab 11 hours agoparentprevI think this is the wildest “I guess I’m” old moment I’ve experienced… Do people wear headphones at parties? reply funki 9 hours agorootparentI know a few people on the spectrum using ANR headphones or earbuds in social or loud settings (party/bar/restaurant/subway) to lower the ambient noise, just as you would wear a pear of sunglasses in the sun or on a brightly-lit stage. To them, it is a welcome fix to the alternative they had before: be exhausted by the stimulation, or stay home. The tendency of \"the young\" to do it too is a bonus: now they don't stand out so much. reply aqme28 10 hours agorootparentprevI guess you’re not old enough. This sounds like a feature for hearing aids. reply resolutebat 10 hours agorootparentprevPeople (well, teenagers) wil.wear headphones to the dinner table if you let them. reply balfirevic 7 hours agorootparentThat makes much more sense than wearing them at the party. reply SllX 11 hours agorootparentprevNot unless it’s a silent disco or you’re the DJ. reply swiftcoder 9 hours agorootparentprevFolks who are hearing impaired do. And that's increasingly more of us as we age. reply kortilla 11 hours agorootparentprevNo? reply foobiekr 3 hours agoparentprevThere's also a pretty useful criminal application of listening in on people without them knowing. reply toomuchtodo 14 hours agoprevCode: https://github.com/vb000/LookOnceToHear reply jmugan 27 minutes agoprevI want to filter out all non-nature sounds. I dream of walking through the airport or the park in peace. AI seems the way to go with that since you have to predict the sound to counteract it. Good to see we are finally making progress. reply glial 46 minutes agoprevThis is pretty amazing -- and a practical application of a solution to a notoriously tricky problem called the \"cocktail party problem.\"[1] For a small subset of researchers, writing an algorithm to isolate a voice in a crowd is on par with e.g. writing an AI to play Go. [1] https://en.wikipedia.org/wiki/Cocktail_party_effect reply chabad360 14 hours agoprevThis could actually be really helpful to me, as I have trouble hearing someone speaking in a busy room because my mind is trying to pick up everything (I think this is because of my ADHD). Having a way to significantly quiet out other noises aside for the voice of the person I'm speaking with would be amazing. reply whimsicalism 1 hour agoparenti don't know much about adhd/autism, but i'm pretty sure i'm somewhat autistic and have this problem really really bad. i score fine on hearing tests where i just have to listen for quiet beeps but have a lot of trouble processing what people are saying especially in a crowded setting. my dad also has this issue reply nsypteras 2 hours agoparentprevDitto. I would pay big money for this if it came in an inconspicuous form factor like airpods. Hopefully it's just a matter of time before Airpods themselves can do this. reply misja111 11 hours agoparentprevI'm having the same problem, my hearing is fine but talking to people in busy clubs or cafe's is next to impossible for me. This feature would be a blessing for me! reply maxglute 14 hours agoprevA potential feature I didn't know I needed. Have headphones with ANC on around home all the time, would be really useful if it auto passthrough my partners voice. reply __MatrixMan__ 14 hours agoparentThe opposite would be nice too. Silence specifically this source (probably not your partner, though maybe....) reply surfingdino 13 hours agorootparentEvery teen's dream of muting their yakking mother would finally come true. reply DoingIsLearning 13 hours agorootparentprevI would be happy with ANC with a doorbell passthrough. Missed a few package deliveries this way. But maybe that could also be achieved with a desktop notification. reply ikari_pl 13 hours agorootparentyou can enable doorbell sound notification in Android reply aspenmayer 13 hours agorootparentYou can also do this on iOS and iPadOS as well as AVP with support for training custom sound recognition. https://support.apple.com/guide/iphone/use-sound-recognition... reply pyeri 14 hours agorootparentprev\"Just block or mute their account, eh..\" would be carried to a whole new level - in actual life! reply pests 13 hours agorootparentThis is close to a Black Mirror episode. Z-Eyes anyone? Z-Ears? reply latentsea 13 hours agorootparentBlack Mirror was a documentary. reply seoulmetro 13 hours agorootparentMost episodes are just slightly more invasive and unrealistic versions of technology we have had for ages rather than the usual \"they saw the future\". reply pests 13 hours agorootparentI think you are being too dismissive. We watch ads, not by force, but voluntarily for free services or currencies in mobile games. Politicians can do basically whatever they want. We have cameras and even glasses that record everything we do. V-Tubers are more popular by the minute. People get blackmailed for their online activities, wrong as they might be. Kids walk around with parent-forced app's to track their location and online life. Robot dogs are being sold to the public and being used by the military. People care more about filming something or the documentary than the event itself. reply voidUpdate 11 hours agorootparentJust to nitpick one point, I personally think we've passed the peak of popularity for vtubers and it will settle down to a slightly lower level. Having been one myself, I've seen the other side and I think a combination of lockdown and the launch of Holo-EN made a lot of people try it, before realising it didn't work for them reply bubblebeard 13 hours agorootparentprevHaha yeah that would certainly be useful in some situations xD reply xeromal 13 hours agorootparentprevlol. My partner and I share a home office and I've worn ear plugs + my range headphones (or my bose 700s) and I can still hear her clacking away and talking on meetings. I'm sure I'm some kind of spaz but god I wish I had something that could completely mute all sounds except my rain sounds. lol reply skydhash 11 hours agorootparentYou want iems. The same kind of earphones musicians wear on sets. The cons is that they can be uncomfortable for long periods. I’m right next to a night club and I’m glad I have a pair lying around. reply xeromal 2 hours agorootparentThank you, I'll check these out. I'm willing to pay a pretty penny at this point. reply flakeoil 11 hours agoparentprevANC does not block voices. It's probably passive sound protection in your headphones that causes your partner's voice to sound weak and not go through to your ear. Or plain and simple, just the music you listen to that masks the voice. The only case ANC would block your partners voice would be if it is about as high/low level as the background noise/sound so that it is all mixed into a white or colored noise which ANC can suppress. reply seoulmetro 13 hours agoparentprevI feel like overuse of ANC is going to come with some sort of physical or physiological drawback soon or too late. reply ffsm8 13 hours agorootparentHighly doubtful, it's just a microphones and the speakers that emit inverted sound waves. This is one of the safest technologies I can imagine. It's more likely that the radio waves from wireless communication (phones, Bluetooth headphones etc) will have negative impact, but even that's unlikely at this point, considering how widespread their use is and no statistically significant link exists. reply flakeoil 11 hours agorootparentprevPhysically/physiological I doubt there are any issues, but maybe psychologically or sociologically. reply maxglute 12 hours agorootparentprevI thought so, but I live in pretty quiet neighbourhood with ~8 hours of ANC which enables quietter playback volume, versus growing up in a very loud metropolis where bustle was non stop and blasting headphones in before ANC days. TBH at this point, I wouldn't even object to losing my hearing to have forever ANC (hearing loss) and turning up the hearing aid. E: no offense to those with hearing loss in this thread reply doctor_eval 12 hours agorootparentYeah I recently lost a chunk of hearing and all I can say is, you will miss it. Much better to wear headphones than to need hearing aids (also: some forms of hearing loss aren’t helped by hearing aids. Mine, for example). reply 104 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The University of Washington (UW) has developed an AI system named \"Target Speech Hearing\" that helps users focus on a single speaker in noisy environments by looking at them for three to five seconds.",
      "Presented at the ACM CHI Conference, this system uses machine learning to isolate and amplify the desired speaker's voice in real-time, even as the user moves.",
      "Currently in the proof-of-concept stage, the technology was tested on 21 subjects who reported significantly improved clarity, with future plans to expand to earbuds and hearing aids."
    ],
    "commentSummary": [
      "The text explores strategies and technologies to improve auditory experiences in noisy environments, focusing on AI headphones, advanced sound design, and noise-canceling technologies.",
      "It highlights the challenges of modern restaurant materials contributing to noise and the use of sound-dampening techniques despite maintenance and aesthetic issues.",
      "Technological advancements such as directional microphones, real-time speech recognition, and selective sound filtering are discussed, along with concerns about privacy and potential misuse."
    ],
    "points": 792,
    "commentCount": 358,
    "retryCount": 0,
    "time": 1716954756
  },
  {
    "id": 40506582,
    "title": "Ex-OpenAI Board Member Reveals Lies and Misconduct Behind Sam Altman's Brief Ousting",
    "originLink": "https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5",
    "originBody": "AI Ex-OpenAI board member reveals what led to Sam Altman's brief ousting Jyoti Mann 2024-05-28T21:29:23Z Share Facebook Email Twitter LinkedIn Copy Link Save Read in app Helen Toner was an OpenAI board member. Jerod Harris/Getty Images An ex-OpenAI board member disclosed new details about Sam Altman's brief ousting as CEO. Helen Toner said Altman lied to the board \"multiple\" times and was \"withholding information.\" She said he didn't tell board members about ChatGPT's release, adding that they found out on Twitter. Advertisement The former OpenAI board member Helen Toner has shared explosive new details about what led to CEO Sam Altman's brief ousting in November. In an interview with Bilawal Sidhu on \"The TED AI Show\" that aired Tuesday, Toner said Altman lied to the board \"multiple\" times. One example Toner cited was that OpenAI's board learned about the release of ChatGPT on Twitter. She said Altman was \"withholding information\" and \"misrepresenting things that were happening in the company\" for years. Toner — one of the board members who voted to kick Altman out — alleged that Altman also lied to the board by keeping them in the dark about the company's ownership structure. \"Sam didn't inform the board that he owned the OpenAI startup fund, even though he constantly was claiming to be an independent board member with no financial interest in the company,\" she said. Related stories She said that Altman keeping that from the board \"really damaged our ability to trust him\" and that the board was \"already talking pretty seriously about whether we needed to fire him\" in October. Advertisement OpenAI didn't immediately respond to a request for comment from Business Insider. Toner, who's a director of strategy at the Centre for Security and Emerging Technology at Georgetown, alleged that the OpenAI chief also gave board members \"inaccurate information about the small number of formal safety processes\" OpenAI had in place. She said that made it \"basically impossible\" for the board to understand whether the safety measures were sufficient or whether any changes were needed. She said that there were other individual examples but that ultimately, \"we just couldn't believe things that Sam was telling us, and that's a completely unworkable place to be in as a board.\" Toner added that it was \"totally impossible\" for the board to trust Altman's word. The role of the board, she said, was to have independent oversight of OpenAI and \"not just helping the CEO to raise more money.\" But then, last October, the board had several conversations in which two executives detailed their own experiences with Altman and used the phrase \"psychological abuse,\" Toner said. She said the executives told the board that they \"didn't think he was the right person to lead the company to AGI\" and that \"they had no belief that he could or would change, no point in giving him feedback, no point in trying to work through these issues.\" By the time the board realized Altman needed replacing, Toner said, it was clear that Altman would \"pull out all the stops\" to block the board from going against him if he found out. She added that he \"started lying to other board members in order to try and push me off the board.\" \"We were very careful, very deliberate about who we told, which was essentially almost no one in advance, other than obviously our legal team, and so that's kind of what took us to to November 17,\" she said. Advertisement But Altman's ouster didn't last long. As staff threatened to quit and speculation swirled that Microsoft might poach Altman's team from OpenAI and hire him directly, the company's board brought back Altman as CEO less than a week later. Toner resigned from her role as an OpenAI board member less than two weeks after Altman returned as CEO. Do you work for OpenAI? Do you have insights to share? Contact the reporter at jmann@businessinsider.com or reach out via Signal at jyotimann.11 Axel Springer, Business Insider's parent company, has a global deal to allow OpenAI to train its models on its media brands' reporting. Read next OpenAI Advertisement",
    "commentLink": "https://news.ycombinator.com/item?id=40506582",
    "commentBody": "Ex-OpenAI board member reveals what led to Sam Altman's brief ousting (businessinsider.com)699 points by blackmanta 19 hours agohidepastfavorite585 comments mathattack 19 hours agohttps://archive.is/LpDuJ jeda96 12 hours agoparentnext [1 more] Thanks light_triad 16 hours agoprevThe whole saga is an interesting case study for theoretical versus real power. On paper the board has the power and it’s their job to monitor and hire/fire the execs. But they’re dependent on the execs for info. Also having one investor own half, plus the founders guiding the roadmap and having sway over key hires leaving is where the real power is… reply huevosabio 16 hours agoparentFrom A Song of Ice and Fire: ``` Varys smiled. “Here, then. Power resides where men believe it resides. No more and no less.” “So power is a mummer’s trick?” “A shadow on the wall,” Varys murmured, “yet shadows can kill. And ofttimes a very small man can cast a very large shadow.” ``` reply jeffrallen 6 hours agorootparentIf you have ever been responsible for managing the security of your team in the face of rumors, this conversation rings of truth. The humanitarian organization I worked for eradicated every last small-head US dollar from circulation in our salary payments in 24 hours because the staff brought us a rumour that was circulating in the market that small-head dollars would not be accepted by the banks anymore. Rumors can kill (literally, or maybe if you're lucky, only morale). reply trogdor 21 minutes agorootparentWhat humanitarian organization did you work for that pays its employees in cash? reply edmundsauto 2 hours agorootparentprevWhat is a small head dollar? Coins versus bills? reply yencabulator 2 hours agorootparentI think they mean a $100 bill printed before 1993. https://en.wikipedia.org/wiki/File:US100DollarBills-Old%2620... reply jdminhbg 14 hours agoparentprev> On paper the board has the power and it’s their job to monitor and hire/fire the execs. But they’re dependent on the execs for info. It's way worse for the OpenAI board position in this case, because the company is basically just an assemblage of researchers, engineers, and Microsoft Azure credits. They can replace the CEO if they want, but all the value of the company can walk away if they don't like it. reply habitue 13 hours agorootparent> the company is basically just an assemblage ofand . They can replace the CEO if they want, but all the value of the company can walk away if they don't like it. This is generally true of any company reply jdminhbg 4 hours agorootparentOpenAI is substantially different from other companies in that the capital part is almost totally ephemeral (the Azure credits). Amazon employees can’t just walk across the street and start a new company because they’d be leaving all the warehouses and trucks behind. reply red-iron-pine 4 hours agorootparentto put a yet finer point on it, Microsoft owns the infrastructure, and can afford to throw vast sums of money at the researchers to get them hired, if needed, assuming the GOOG or other big players don't get at them first. reply underdeserver 11 hours agorootparentprevNot really. There are long term contracts, IP, infrastructure and product moats. OpenAI has virtually none of that. reply cvalka 16 hours agoparentprevThey just folded. They were not the right people for the task. They would have prevailed with a bit more persistence and better PR. reply esafak 16 hours agoparentprevPositional- vs relational power, to be more accurate. reply Aunche 17 hours agoprevI think there is a very good chance this is true, but it also paints the picture of the board being incompetent and incapable of confrontation. They could have filed formal complaints, mandated increased scrutiny, handed off Sam's responsibilities to other people, or threatened legal action. Instead, they attempted a secret coup, which of course makes Sam look like the underdog reply hn_throwaway_99 14 hours agoparent> They could have filed formal complaints, mandated increased scrutiny, handed off Sam's responsibilities to other people, or threatened legal action. I think you fundamentally misunderstand the role of the board of directors. It's often been said that the board (of any company) has basically one job: to hire (and fire) the CEO. While that may be a slight exaggeration, the wisdom behind that quote is that things turn out badly when the board meddles in decisions of a company's executive leadership - if they don't like the decisions being made, they should replace the CEO, and that's where their power lies. You talk about \"filing formal complaints\" - what does this even mean?? They're the board, who else would they file formal complaints to? \"Hand off Sam's responsibilities to other people\"?? Again, any corporate governance expert would say that's a recipe for disaster, never mind not even feasible the way corporate hierarchies work. I've commented many times before that I think the way the board handled the Altman's filing was, at best, woefully naive, and their communication at the time (even after he was fired) abysmal. But neither do I think it was some sort of \"coup\", and your recommendations simply don't make sense. reply GeorgeTirebiter 13 hours agorootparentThis precisely correct. The board hires & fires the CEO. End of story. When the board is unhappy how the company is being run, their recourse is to...fire the CEO. What is unusual here is the wellspring of support from \"the troops\", such that if they stuck with their firing the CEO, there would be hardly any company left to be BoD of! The board didn't understand the depth of employee allegiance to sama. reply jprete 7 hours agorootparentI saw a claim at the time that a handful of employees rallied everyone else to sign the letter and post support on Twitter. Between that and Altman reportedly having a vindictive streak, I'm thinking the actual employee support was paper-thin. reply Rastonbury 3 hours agorootparentPrisoner's dilemma and/or social pressure when million in profit share units hang in the balance. Joining MS was a way to stop their compensation being at risk by being stuck on a sinking ship reply Aunche 13 hours agorootparentprev> the board (of any company) has basically one job: to hire (and fire) the CEO Yes. In a formal board meeting, not in an secretive one behind Altman and Brockman's back. That's what makes it seem more like a coup. > They're the board, who else would they file formal complaints to? Like I said in other comments. It's always useful to have a paper trail. > \"Hand off Sam's responsibilities to other people\"?? Again, any corporate governance expert would say that's a recipe for disaster, never mind not even feasible the way corporate hierarchies work. If Altman is neglecting and being opaque about AI safety, as Toner claims, then the board should appoint someone to lead this effort and be fully transparent with them. I don't see how this is so far fetched. reply hn_throwaway_99 13 hours agorootparent> If Altman is neglecting and being opaque about AI safety, as Toner claims, then the board should appoint someone to lead this effort and be fully transparent with them. No, that is absolutely not the role of the board (and I mean any board, not just OpenAI's), and that's the point I was trying to make. It is the CEO's role to define the org structure of the company. If the board feels that this structure doesn't meet their corporate goals, they don't go in and say \"No, actually, we demand you create this AI safety group with a separate head that reports directly to us.\" Their option is instead to fire the current CEO and hire a different one who they believe is more aligned with their values. reply Aunche 12 hours agorootparentIt's not typical for the board to directly intervene with the affairs for the company, but it's still far less unprecedented than making the most important decision in their history while deliberately excluding a third of the members. For example, a year before Yahoo fired Marissa Mayer, the board appointed a committee to explore \"strategic alternatives\" with management. https://www.businessinsider.com/marissa-mayer-yahoo-meeting-... reply hn_throwaway_99 4 hours agorootparentAs the other comment said, the strategic alternatives plan had nothing to do with firing Mayer. It was specifically about how they could unload their Alibaba equity without triggering a huge tax bill. But regardless, the board had six members. Altman was actively trying to grow the board (and would presumably add loyal allies), and had previously tried to kick Toner off the board. So just by sheer numbers it's obvious they had to move quietly before they acted. And you saying this is \"unprecedented\" is just weird - CEOs are fired with little warning all the time, and if they also have board seats, the board members who want to fire them usually figure out if they have enough support before hand. I think the thing we're probably agreeing on is that the board just handled the communication abysmally. I don't know how they thought they could fire Altman without a detailed explanation, especially to their partners like MS. reply Gud 6 hours agorootparentprevWhich is absolutely different than changing the corporate structure. What the Yahoo Board was doing was essentially bringing in their own set of advisers. reply akozak 17 hours agoparentprevI've seen the \"coup\" framing a lot I just don't see how that's justified. They're the board of directors! Hiring and firing the CEO is core to the job (as is maintaining mission alignment, in the nonprofit world). reply tivert 14 hours agorootparent> I've seen the \"coup\" framing a lot I just don't see how that's justified. They're the board of directors! Hiring and firing the CEO is core to the job (as is maintaining mission alignment, in the nonprofit world). It isn't justified, it's just misleading propaganda. Unfortunately through repetition and the enthusiasms of various fandoms, it's gotten lodged in the public mind. reply Aunche 16 hours agorootparentprevIt's very unusual to vote to fire a CEO without all members being present. Doing so made it seem like they were stabbing him in the back reply dragonwriter 8 hours agorootparent> It's very unusual to vote to fire a CEO without all members being present. It's not unusual to exclude people with conflicts from a decision. That's a typical part of a corporate conflict of interest policy, and for a charity nonprofit board (as the OpenAI board is) it's even more critical, since failute to do so risks the tax-exempt status. reply datavirtue 16 hours agorootparentprevI have witnessed at least one board that was made up of friends of the founder. A doe-eyed rubber stamp brigade. This was enough to fool some serious investors into parking their money there. Of course, they eventually realized what was going on and launched an all out offensive to affect change. (They didn't get anywhere despite owning 15%.) I know this because the investors published a website where they detailed the situation. reply HDThoreaun 17 hours agorootparentprevVince Mcmahon literally owns WWE but the board fired him. Of course he voted in a new board at the next election but I dont think it's unheard of boards to vote against their founders. Sam is a founder of openAI even if he never controlled the board, and they tried to take control from him. reply mark212 16 hours agorootparentBad analogy. Sam has no stock in OpenAI or any sort of formal controlling interest. His power is solely informal: his own talents and abilities and the loyalty of the other employees. Regardless of the truth of the matters, the episode is a perfect example of the limits of formal authority and how informal or \"soft\" power can be even more effective in shaping events reply HDThoreaun 1 hour agorootparentThe point is that board coups are a concept that people are already familiar with, so its not surprising that they thought of it when this similar situation happened. reply strunz 16 hours agorootparentprevDid you read the article which points out specifically that he is financially incentivized? reply mbonnet 4 hours agorootparentOnly in the innovation fund thing, not the company at large (going solely off the article) reply fastball 16 hours agorootparentprevI think the \"coup\" framing is supported at least by Helen Toner's claims in this article. > \"We were very careful, very deliberate about who we told, which was essentially almost no one in advance, other than obviously our legal team and so that's kind of what took us to to November 17.\" If that doesn't sound like a secret coup, I don't know what does. Like, yes, it is their job to hire and fire the CEO so it's not really a coup, but when you do your \"job\" in secret instead of in the open that's the vibe you give off. reply fnordpiglet 16 hours agorootparentWhen a board is about to fire a CEO do you think they typically discuss it publicly first? It’s usually treated as highly sensitive information at every company. Likewise if any company is about to fire anyone they also don’t typically advertise this to anyone other than HR, legal, and maybe the manager. For the CEO the manager -is- the board. I’d be curious if you believe differently how you feel boards usually advertise such an action? reply fastball 9 hours agorootparentWho said publicly? There is a lot of room between \"discuss publicly\" and \"We were very careful, very deliberate about who we told, which was essentially almost no one in advance\". For example, a lot of the pressure that caused them to reverse course came from Microsoft. Maybe if the board had discussed such a big decision without OpenAI's biggest investor, Microsoft would've been on board with the firing. reply insane_dreamer 8 hours agorootparentWho would they be telling? Board members don’t and shouldn’t discuss matters with employees. Please show me the case where employees were told in advance that the board was going to fire the CEO. reply fastball 7 hours agorootparentI literally said in my last comment who they could've told that would've made the whole thing probably go over better. reply insane_dreamer 3 hours agorootparentI don't think you understand how boards operate, especially in this case. It was the board of the OpenAI __non-profit__, of which Microsoft was _not_ an investor. In this case, their fiduciary duty was not to their shareholders, but rather to the company charter. reply JohnFen 4 hours agorootparentprevA \"coup\" is a usurpation of the existing power structure. This was the power structure exercising its legitimate power. It's not even remotely similar to a coup. That the board held its hand close to its chest doesn't enter into it and wasn't improper in any case. reply lamename 16 hours agorootparentprevEmployees are quite often given no notice of firing or layoff, despite it being discussed by managers or executives ahead of time without the employee present. Is a Board firing the CEO typically conducted differently? reply dragonwriter 8 hours agorootparentprevSo, they observed the ususl confidentiality of personnel matters and didn't discuss them with people off the board or conflicted out of the decision? Any thing else would have been grossly unprofessional and irresponsible. reply rst 17 hours agoparentprev\"Filed a formal complaint\" with whom? The board itself is the final authority, empowered to investigate and act. If its members have concerns, they either do something or don't. There's nowhere else to pass the buck. reply Aunche 16 hours agorootparent> \"Filed a formal complaint\" with whom? For their own records. They can use it for justification for disciplinary action or legal ammunition. It is always useful to document things in writing. It's the same reason why companies will put you on PIP. reply florean 15 hours agorootparentWhy would you think this stuff wasn't in writing? Do you think the investigation OAI did into the board's actions was just relayed orally?[1] That the board's discussions where all done in conference calls and not in e-mail? Do you think that this documentation gets routinely released to the public or even employees? Before you throw around accusations of incompetence, you should probably have some shred of evidence. This is the type of stuff that is typically considered extremely confidential and even now they say they are unable to reveal details. Why do you think that is? What is preventing them from doing something they apparently want to? Legal agreements such as NDAs, the same ones that would have prevented them from going public with details last years. The board's mistake was not figuring out a way to go public with their case against Sam when or before they fired him. They obviously misjudged how he would respond. But even there we don't know the full context and constraints they were under. Hopefully, one of them will answer that question of why they didn't at some point, but until we know more, we would be wise to reserve judgement. [1] https://archive.is/wbwC2 reply Aunche 14 hours agorootparent> Before you throw around accusations of incompetence, you should probably have some shred of evidence. The evidence is in this interview. It sounded like the board basically let Altman walk all over them until they suddenly decided that they wanted to fire him, but by then it was too late. For example, if they had a thorough paper trail documenting all of his lies, they could threaten a lawsuit pressuring him to resign. If YC fired him, they likely would have used a similar strategy to pressure him to step down without any blowback. reply comp_throw7 13 hours agorootparent> they could threaten a lawsuit pressuring him to resign This is extremely confused about the board's responsiblities and powers. A court would laugh this case out of court because the board _can just fire him_. reply Aunche 12 hours agorootparentThis has nothing to do with the board's power. Simply firing him doesn't stop him from taking all his employees with him. The lawsuit would be for the damage of Altman's lies, and would prevent him from simply starting another AI company. reply cdchn 16 hours agorootparentprevLie to your boss and see if they put you on a pip \"Please improve your inability to tell the truth.\" reply blitzar 11 hours agorootparentprevDocumenting their actions is a duty of board members reply preommr 17 hours agoparentprevWhat would be the point of having him as CEO if they mistrusted him so much that they would have to put a metaphorical straightjacket on him to make sure he behaved well? Not to mention that if he was vengeful, it would be much easier to do damage from within and from a position of power. reply pdonis 17 hours agoparentprev> it also paints the picture of the board being incompetent and incapable of confrontation Yes. Nobody involved in this comes out looking very good IMO. reply dylan604 17 hours agorootparentRarely does anyone in situations like this have no fault. It's all degrees of wrong really reply tbrownaw 15 hours agoparentprevI believe the standard advice for dealing with abusive people in personal relationships is to GTFO. Because it's generally unrealistic to think they can be fixed. Does the same reasoning not apply to supposed-to-be-trusting business relationships? reply surfingdino 12 hours agoparentprevIgnoring for a moment the board's responsibilities and ability to implement the measures you suggest, read what you wrote again and think of it from the practical point of view. If you had a person that needed all that oversight would it not be cheaper and more practical to replace him? reply whimsicalism 14 hours agoparentprevnah the issue was that they pay employees in PPU which is tied to Sam Altman's ability to raise capital, not to the board. the board effectively did not control the pay of its employees, whereas Sam did reply _giorgio_ 8 hours agoparentprevObviously. They were just waiting for an excuse to fire him, and by chance they accused him of the same \"errors\" the had him fired before. reply refulgentis 16 hours agoparentprevThis doesn't make any sense, it's attempting to carve out imaginary middle ground where there is none. Who reviews the \"formal complaints\" a director files about a CEO? Where have you ever worked that HR takes \"formal complaints\" about vaguely unethical behavior seriously? You want to pretend it was some huge surprise delivered to Sam without warning, for power's sake, because then there is middle ground. That wasn't the case. reply MrSkelter 8 hours agoparentprevThe board is working with the assumption the CEO isn’t a liar. Altman is a classic sociopath, a T-1000 to Musk’s clunky T-800. OpenAI is fated to implode in scandal. His 7 trillion dollar funding round ambition is a blaring siren to anyone with a working brain that he’s out of control and capable of doing real damage. He wants a sum of money that could crash the world economy. He thinks he should have the power of the world’s most powerful government. Solely dictated by his whim. He makes Napoleon and Hitler look like pikers. He is Musk in 2016, when some of us knew who he was, and the fans were still enthralled. You will look back and say “No one knew” and this comment will be there. We knew. Musk will end up the Bush to his Trump. We will fondly recall the crimes of a guy who just wasn’t as bad as what followed. Why do you think Musk hates him so much? He’s a better Musk than Musk. He’s the guy who took OpenAI out from under him. It’s envy. reply admissionsguy 8 hours agorootparentJust to be clear - Musk’s crimes are single-handedly turning the US into the leader in EV and space industries, calling one guy a „pedo” and standing trial for it, and supporting the political side that you don’t like? reply bookaway 6 hours agorootparent> calling one guy a „pedo” Yes, and just to be clear -- That one guy was a diver who put his life at risk to save trapped children from an underwater cave, a rescue operation in the span of which a Thai Navy Seal actually died. Furthermore, Musk went on record stating that he had took a further step of hiring a private investigator to dig up dirt on the guy, not before he called the guy a pedo, but after when the reality of getting sued began to sink in. reply tim333 1 hour agorootparentAnd a guy who insulted Musk first. reply red-iron-pine 3 hours agorootparentprevThe US dominance in EV is about to be eaten up by the Chinese, and Musk is in the process of making the company implode, e.g. the cybertruck failure. The US was already a leader in aerospace, by a lot. He called someone a pedo who didn't deserve it on Twitter, and then bought and managed to tank said platform, to the point where it is the go-to for nazis and propagandists. reply belter 6 hours agorootparentprevHe called a guy a pedo but was impersonating a child on twitter... https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.... reply protastus 17 hours agoprevTelling almost no one in advance was intended to protect the board from Altman's interference but put them in an indefensible situation. Alone against very rich, well connected people, without even a narrative to offer. reply jfoster 15 hours agoparentIt feels like one press release may have changed the outcome entirely. Shouldn't the board be capable of agreeing on a press release among themselves? reply hn_throwaway_99 14 hours agorootparentTotally agree. The initial press release made it sound like Altman was guilty of borderline illegal malfeasance, which wasn't true. Without any more information, the world was left to speculate about what happened, and it came across to many as more of a \"power struggle\" or grudge match than fundamental concerns about the direction of OpenAI. While in retrospect I think the board's actions may have been warranted, their communication was absolutely atrocious. reply rl3 14 hours agorootparent>Totally agree. The initial press release made it sound like Altman was guilty of borderline illegal malfeasance, which wasn't true. This sounds bad enough to my layperson ears: \"Sam didn't inform the board that he owned the OpenAI startup fund, even though he constantly was claiming to be an independent board member with no financial interest in the company,\" she said. I'm not a lawyer. Anyone with expertise care to clarify? Also, wow: https://medium.com/@leagueplayer220/sam-altman-may-have-comm... reply mindslight 5 hours agorootparentprevBingo. I think the public conversation would have gone much differently if the board had laid out how Altman's behavior was essentially making OpenAI LLC ungovernable per OpenAI-the-nonprofit's charter. Presumably that public understanding was leading much of the thoughts around employees signing the open letter demanding reinstatement of Altman. I'd guess the board relied on some generally-bad legal advice from their attorneys about how they could get personally sued for libel for airing dirty laundry etc. Not having huge financial stakes, and seemingly having been picked for being conservative rather than risk takers, they followed this to their detriment. Staying quiet let Altman build a following and lead the whole situation, something Altman is seemingly fantastic at doing. So ultimately what was a pivotal moment in governance of following the nonprofit charter, played quite poorly, ended up being a coup by Altman to escape that one layer of \"boxing\". Which given how poorly we've done so far at \"aligning\" centralized capitalism to the needs of most individuals (of which this seems to be a subproblem) wasn't terribly surprising! reply kyrra 15 hours agoparentprevI think this is the big thing, they did this and were unable to publicly explain why they did it. If you are going to do something like this, you should have your ducks in a row and be ready to defend it. reply tbrownaw 16 hours agoprev> She said, \"We were very careful, very deliberate about who we told, which was essentially almost no one in advance, other than obviously our legal team and so that's kind of what took us to to November 17.\" Did they not at least have a briefing packet or something prepared to give to major investors (ie, Microsoft) day-of if they were so worried about leaks that they couldn't get the major investors (ie, their own bosses) on board ahead of time? reply zucker42 14 hours agoparentMajor investors aren't the board's boss in this case because OpenAI is a nonprofit. Microsoft is incentivized to act against the goals nonprofit's charter (and in fact they did in this case). reply rPlayer6554 14 hours agorootparentAs much as on paper they aren't the board's boss, based on how events turned out they effectively were. They had leverage over the board to get what they want. reply tempaccount420 9 hours agorootparentI think it's not as much that Microsoft is their boss or not, it's that no one considered the board to be the boss of OpenAI. That's why we saw so many employees wish to leave when they fired Sam Altman. reply barbariangrunge 4 hours agorootparentprev“Non profit” reply bmitc 17 hours agoprevWhat is still bizarre is how the board brought him back. I just don't understand that from any angle. It is very clear that he lied and schemed. So why was there any issue? He had no power once fired. If another company wants to hire him, fine. If he wants to make platitudes on Twitter, who cares? Employees threatened to leave? Let them. I imagine many of them wouldn't, and if they did, you could just rehire and find a proper CEO. It's likely that the employees who would have stayed would have been the ones you want to keep anyway. So why would you rehire him and then resign? Why not leave him fired and resign? Why did Microsoft care so much about Altman? They didn't have a board seat, so too bad so sad. They should have had no sway. If they want OpenAI, then they can buy it. Why would they even want Altman to come to their company? What possible value could Altman bring to Microsoft? Just none of it makes any sense. In fact, the most clear thing is Altman's negative behavior and mode of operation. I remember his very loud, awshucks pronouncements of having no shares in OpenAI. Yea, right. A career VC setup a new company structure or structures where he wouldn't benefit at all financially. In another timeline, OpenAI firing him, naming an interim CEO, ignoring all else, and then hiring a new CEO would have all gone just fine. I don't know why Microsoft and others made a huge kerfuffle over it. And I also don't know why the board released such a cryptic press release when they could have provided details. I just can't wrap my head around any of it, even letting in conspiracy theory lines. Lol. It just makes no sense and gives me a feeling that no one involved has any clue about anything, including Satya Nadella. reply tibbar 16 hours agoparentYou had the answer there before you dismissed it -- the board agreed to bring Sam Altman back before resigning because of massive pressure campaign that involved 90%+ of employees threatening to resign, and Microsoft (which has OpenAI's IP rights) offering to hire them all immediately. This included the company's key leadership. The organization was unraveling overnight. This was far past the tipping point of \"a few disgruntled employees might leave\" - there would have been no OpenAI left to preside over. reply gorgoiler 15 hours agorootparentWhen the board fires you for wrongdoing it is like being deported from a foreign country for breaking that country’s laws. You can’t just go against that decision. It would be like telling the government that no, in fact they are the ones who are wrong and no, I didn’t break the law it is in fact their laws which are broken. When you have irreconcilable differences with the board you could theoretically jump ship and start a rival company. Usually, in practice, that’s impossibly hard and yet Microsoft announced that they intended to do exactly that with funding and stock matching. For some reason that was turned down in favor of staging the equivalent of an in-country coup. If you get caught breaking the law on vacation abroad and your response to being arrested is to take control of the country in retaliation then you are a very powerful, persuasive, or threatening person indeed. reply tibbar 14 hours agorootparentIndeed, it was stunning. The Board outranked the CEO and had the right to replace him. What they didn't reckon on was that technically, if the entire company is willing to quit on behalf of the CEO, then they as a body outrank the board. And that was that, pretty much. reply makeitdouble 14 hours agorootparentprev> It would be like telling the government that no, in fact they are the ones who are wrong and no, I didn’t break the law it is in fact their laws which are broken. You know a number of people are in that position though. My first thought went to Samsung's chairman who will break the law and go to prison, but the country will have him back, bending over backwards to somewhat have it make sense. reply mac-attack 7 hours agorootparent> It would be like telling the government that no, in fact they are the ones who are wrong and no, I didn’t break the law it is in fact their laws which are broken. Reminds me of the Wirecard scandal doc on Netflix. Wirecard was so powerful that the financial regulators (BaFin) started targeting journalists and actively defending a publicly traded company. reply jfoster 15 hours agorootparentprevIf the board had shared something equivalent to this article at the time, perhaps there wouldn't have been such an intense internal pressure campaign. Instead, they did not even attempt to communicate any rationale behind their actions. reply mikeryan 15 hours agorootparentIt’s not good form to bad mouth someone you’ve fired. They did, in fact, release a statement which aligns (in PR speak) with what Toner is claiming now. Mr. Altman’s departure follows a deliberative review process by the board, which concluded that he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities. The board no longer has confidence in his ability to continue leading OpenAI. https://openai.com/index/openai-announces-leadership-transit... reply jdminhbg 14 hours agorootparentWhat they didn't realize is that they were going to have to convince the rank-and-file employees of that. Without a communication strategy to do that, they had basically no leverage. reply mikeryan 4 hours agorootparentI agree with this 100% I even said so at the time. https://news.ycombinator.com/item?id=38372451#38373194 reply jfoster 14 hours agorootparentprev> It’s not good form to bad mouth someone you’ve fired. Instead, it's good form to wait 6 months and then do a Business Insider interview on the topic? Also, \"bad mouthing\" suggests putting a spin on it. Based on the article, they should have been able to list out several objective facts that supported their decision. Instead, they opened it all up to intense speculation by providing a vague justification and by remaining tight lipped even once it became clear that a lot of clarification was needed. reply bmitc 15 hours agorootparentprevI answered that scenario though. I'm fine, as a board, letting employees who want to hold the company hostage over a CEO that the board fired walk. The board's major mistake was not communicating why he was let go. My guess is that the likely reason why employees threatened to go was that they felt Altman had the best chances of making the for-profit arm's shares skyrocket. As a non-profit company's board, I'd be fine letting those people walk out the front door along with the CEO that was just fired. It is my understanding that the key personnel who developed the actual technology were not part of the group threatening to leave. It was mainly the group in the for-profit arm that Altman had trojan-horsed into the company structure. > This included the company's key leadership. I'm not aware of the machine learning researchers responsible for the core technology threatening to leave. Who were they? reply tibbar 15 hours agorootparentWait, are you simply unaware of the widely reported circumstances in the company at that time? 95% of employees signed a letter to the board stating that they would leave the company if Sam was not brought back [1]. Ilya Sutskever, who was on the board and voted to remove Sam, changed his mind and signed the letter. The board named Mira Murati interim CEO; then she signed the letter, the board fired her, and hired another outside CEO. Several key researchers resigned outright before letter even went out, including Jakub Pachoki, who replaced Ilya after he left [2] . I would challenge you to name a researcher who didn't resign or threaten to resign. Remember, they all had a plausible landing spot: They could simply show up at Microsoft with all the same leadership, coworkers, salary, compute, and IP the next day. OpenAI as we know it was over unless and until the board gave in. [1] https://www.wired.com/story/95-percent-of-openai-employees-t... [2] https://www.theinformation.com/articles/three-senior-openai-... reply bmitc 14 hours agorootparentNo, I am not simply unaware. I said my understanding, which appears to be wrong. Thanks for the details. However, I am still confused on which employees of which company. There is the non-profit OpenAI and for-profit OpenAI. Are these articles talking about everything or just the for-profit branch? I still wager that things would have been different had the board clearly stated their reasons. Doesn't make any sense that they did it months later. The signing of the petition seems mostly group think and political. I would guess that the majority of employees would have followed through. Lastly, I still can't say any of this makes any sense. Why did the employees even care about Altman? It still seems all very strange to leave your job for someone who doesn't seem to have ever said anything meaningful. reply jonas21 15 hours agorootparentprev> I'm not aware of the machine learning researchers responsible for the core technology threatening to leave. Who were they? Ilya Sutskever, Alec Radford, Wojciech Zaremba, Nick Ryder, Mark Chen, ... how many names do you want? >90% of the company threatened to leave. reply int_19h 13 hours agorootparentSutskever was one of the people who fired Altman to begin with. Him joining the pile-on when it was already clear how big it is was pretty much surrendering to the mob, and was perceived as such even at the time. reply tibbar 11 hours agorootparentIt’s so much weirder than that. Reportedly, Greg Brockman’s wife begged him in tears to change his mind. Ilya presided over their wedding. reply bjornsing 9 hours agorootparentSource? reply tibbar 4 hours agorootparenthttps://www.wsj.com/tech/openai-employees-threaten-to-quit-u... reply Wissenschafter 4 hours agorootparentprev>I'd be fine letting those people walk out the front door along with the CEO that was just fired. Guess you'd be fine being the board over a company that now only consists of a board. Thumbs up. reply JeremyNT 5 hours agorootparentprev> This was far past the tipping point of \"a few disgruntled employees might leave\" - there would have been no OpenAI left to preside over. But if they had the moral conviction, it seems like this would have been the right choice to make, because it would have diluted Altman's power (unless they trust Nadella even less than they trust Altman?) reply cvalka 16 hours agorootparentprevThey should have called their bluff. reply kaliqt 15 hours agorootparentThere's not many who have the balls to do that left in the country, let alone California or SF. reply unclebucknasty 14 hours agorootparentprev>the board agreed to bring Sam Altman back before resigning because of massive pressure campaign that involved 90%+ of employees threatening to resign, and Microsoft... But, what kind of Wild West is this? It's all so unhinged and strange. There are no NDAs, non-competes or other impediments? MS just guts OpenAI at its whim? >there would have been no OpenAI left to preside over. ...If MS can do this, then there's already no OpenAI left to preside over. reply lotsofpulp 5 hours agorootparentThe beauty of California is that there are no non competes, for anyone, ever. It is a very pro employee policy, hence attractive to the best and brightest. reply unclebucknasty 5 hours agorootparentGood to see someone positive about California, given all of the politically-motivated negativity. It's a great state for many reasons. I mentioned non-competes as one of a universe of things that makes this unusual; including its original non-profit status becoming substantially for-profit, and the apparent ease with which MS can now gut the supposedly controlling non-profit and walk away with everything. And, I'm guessing even the CA policy on non-competes wasn't conceived with the idea of one company simply \"taking\" another company at-will, even if that scenario is technically covered. reply lotsofpulp 5 hours agorootparentI am not clear about the intent of your comment. People should be free to sell their labor to whoever they want. And people should be able to buy labor from whoever they want. All businesses at all times are subject to losing their employees to another employer who is willing to pay enough for them. reply bitcharmer 8 hours agorootparentprevYeah, sadly it looks like it was employees' greed that brought Altman back. reply unyttigfjelltol 17 hours agoparentprevAnd where does this leave the current board? The CEO gave no mea culpa, and even if he did, actively thwarting board oversight is a clear no-no. How in the world do they expect to perform their duties with a CEO who demonstrated himself to refuse to even provide them the information they need to discharge their duties? As long as they keep this CEO in a position to block their access to information, the board has no credibility. reply nullspace 17 hours agoparentprev100% agree. I don’t care about OpenAI or the members of its board at all, one bit. What I did see was so much incompetence at the one thing I expect a board to be at least okay at. Hiring and firing. For that alone, I think the board reshuffle was good. Regardless of who you support in all of this. reply juped 17 hours agorootparentIt clearly wasn't good; the Altman-control system failed, and was replaced with not even the pretense of an Altman-control system. Sure, the rectification of names is an improvement in a sense; what is actually needed is a working Altman-control system. reply mr_toad 16 hours agoparentprev> I don't know why Microsoft and others made a huge kerfuffle over it. Microsoft needs the sold-out version of OpenAI so they can make as much money as possible without anyone making pesky noises about ethics and safety. reply red-iron-pine 1 hour agorootparentyeah MS wants the shield that OpenAI provides. Outsource all of the risk to a non-profit, but still be able to run it, and snag up all of the researchers if/when something gets ugly. reply Tyr42 17 hours agoparentprevBetter at OpenAi then a private team at Microsoft??? I don't know what they were thinking either reply cma 15 hours agoparentprevIn deciding to hire him back, Helen Toner said OpenAI lawyers said she and other members of the board could be personally liable if the company lost a lot of money over keeping him out. reply bmitc 14 hours agorootparentI suppose that would be a reasonable reason on a practical level. However, how is a board liable for that? The CEO lies and intentionally withholds information, employees strangely hold the company hostage, and yet it's the board held liable? The board governed the non-profit OpenAI. reply jononor 9 hours agorootparentI am pretty sure a lawyer could be found that would happily take that case against the board. And that Altman would be quite willing to go that far. At least I would not have staked my professional life and personal economy on it not happening. PG called it over 15 years ago: \"You could parachute him [Sam Altman] into an island full of cannibals and come back in 5 years and he'd be the king\". reply gwern 5 hours agorootparentprevWhich should have been a bluff (board members typically have \"director's insurance\" to cover exactly this scenario - trying to control a company by threatening to pierce the corporate veil and sue board members individually) but shows you what sort of tactics were being employed by the Altman side. cf. Sutskever's flipping reply stale2002 16 hours agoparentprevEmployees are not replacable like that. Almost the entire company was threatening to quit. If it was possible to simply replace all of openAI, then you could just do that now, as an outside party. So the boards choice was to either bring back Sam or watch the entire company go under. reply brandon272 16 hours agorootparent> Almost the entire company was threatening to quit. This is the part that perplexes me. A CEO being fired is not an unusual occurrence. What about Sam Altman led such a huge number of employees to threaten to follow him out the door? Was it that the board's actions were viewed as internally unjust? Was it Altman's power of persuasion? Was/is Altman viewed by the staff as bringing something irreplaceable to the table in terms of talent, skill or ability? reply jcranmer 15 hours agorootparent> What about Sam Altman led such a huge number of employees to threaten to follow him out the door? My understanding is that a fair amount of it was essentially peer pressure. If you're an employee whose CEO has just been fired for unclear reasons, and someone hands you a chain letter saying \"restate him or everyone will quit\" and you're told everyone's signing that letter and there's already someone who promised to hire everyone who quits into their current role at equal pay, would you sign it? reply tptacek 15 hours agorootparentMy understanding is that it was not so much peer pressure so much as an explicitly coordinated worker action, based on a rational assessment of what their comp packages would look like if the board's plan played out completely. reply gorbypark 10 hours agorootparentIn my opinion this is most likely. Scenario A, Sam Altman continues as CEO and the for profit arm of OpenAI continues to call the shots, growth and market share continue to be priority number one. Scenario B, Sam Altman is fired, OpenAI non-profit board (re?)-asserts more control. Safety, alignment and other things like that take priority over growth and market share. x% of Employees are Sam believers, and when the remaining x% of ambiguous/non-Sam believers realize the first x% might leave, their PSUs would be worth significantly less, so they sign the letter as well. There is also the peer pressure / fear of retribution factor as well once it becomes likely there is even a chance of Sam being reinstated. Many employees choose scenario A because it is likely their \"profit sharing units\" will be worth more than with scenario B. There's a non-zero chance that OpenAI (the for profit arm) eventually joins the ranks of the \"FAANG\" companies. Those PSUs might be worth millions today, but in the future could be worth \"fuck you\" levels of money. reply tptacek 2 hours agorootparentYeah, for what it's worth, I'm not guessing about the comment I wrote; could be totally wrong, but it's something I heard from two different people close to the story. reply insane_dreamer 8 hours agorootparentprevIt’s important to understand that the board oversaw the nonprofit, and their job essentially was to protect the nonprofits mission. Most of the employees were hired by the for-profit company whose mission it is to make money. In theory the for profit was owned and subservient to the non profit but the engineers financial future was tied to the for profit and thus their loyalty. reply blihp 15 hours agorootparentprevI suspect it was all about the money. Those following him viewed him as their best bet for a good financial outcome for themselves. reply CLiED 6 hours agorootparentprevThe equity offering was nearing and then the board just fired Altman out of nowhere and had no credible reasons or a narrative to sell to the employees, then they quickly caught on that their comp would go to smokes with this clueless lot at the helm who can't even justify a firing without making a pig's breakfast of the whole affair and demanded the reinstatement of the CEO for their pocket's sake, simple as that. reply Atotalnoob 15 hours agorootparentprevIt’s covered in the podcast that the article is about. Summarizing, essentially the employees were under the impression either Sama comes back OR OpenAI dissolves and they lose their job. reply fifticon 9 hours agorootparentprevI would argue it is a demonstration of what Altman is capable of bringing about. He can make things like this 'happen' for him. Caesar, Napoleon, Alexander, and now, our current batch. reply jonas21 15 hours agorootparentprevA CEO being fired, without explanation, at a company that is doing well is highly unusual. reply imperfect_light 16 hours agorootparentprevThe board should have been transparent about the dishonesty, especially around financial stakes, and I suspect the OpenAI employees and MSFT would have reacted differently. reply stale2002 16 hours agorootparentThe dishonesty regarding the ChatGPT release sounds like the best decision that Sam or anyone could have made in the history of the company. The ChatGPT release is what made the AI movement go mainstream. It is why OpenAI is worth ~80 billion dollars. By Gods am I glad that the board wasn't able to stop ChatGPT from being released. reply joquarky 15 hours agorootparentI thought it wasn't \"released\" initially in a manner that was meant to be a product. I seem to recall that the release in late November 2022 was only intended to be a way for volunteers on the Internet to experiment with it and provide feedback. reply mr_toad 16 hours agorootparentprev> It is why OpenAI is worth ~80 billion dollars. Worth to who? reply tibbar 15 hours agorootparentWell, that was the valuation of their last fund raising round, which included a tender offer to employees. So it was worth that much to investors and to its current employees. reply stale2002 15 hours agorootparentprevWorth is determined in the same way that it is for every single other thing in the world. It is \"worth\" what someone else is willing to pay for it. reply juped 17 hours agoparentprevand aligning ai is even harder... reply zooq_ai 17 hours agoparentprevSam Altman made openAI possible. A true CEO like Satya knows without Sam, the rate of progress at OpenAI will be determined by decels like Helen/Jan aka ZERO. It's a disaster for product development, especially when you have openly invited Google to dance. I know HN leans engineering/safety/reliability/labor/pedantic (like chasing the absolute truth), but at the end of the day, company scales from the likes of Jobs/Musk/Sam/Zuck even it involves deceit or reality distortion field. Sometimes people just can't handle the truth or don't believe in the vision of visionaries. So, they have to fib a little to the decels and normies. Even Larry / Sergey 'lied' to Eric during Google's growth phase. It's only when they bought normie Sundar that Google became risk averse. And look where it got Google to. If I have to bet my last $, I'd bet on Elon/Sam/Zuck/Jobs than Helen/Jan/Sundar. reply imperfect_light 16 hours agorootparentThis isn't lying about product philosophy, lying about your financial stake in an OpenAI VC group would be grounds for dismissal from any company. reply zooq_ai 13 hours agorootparentYes for normies/mids. I guess you also think Self-Driving Cars should come to full stop at STOP signs reply NikolaNovak 1 hour agorootparentAt this point I assume this is a troll comment, as nobody could hold views THAT extreme and be THAT snidey in real life (I assume/hope :O ) reply imperfect_light 57 minutes agorootparentprevIt should determine your adherence to traffic laws based on your social score. Musk, Thiel, Altman, Andreessen? Do whatever the hell you want, laws don't apply to you. /s reply NikolaNovak 16 hours agorootparentprevHad to look up the jargon : https://www.standard.co.uk/news/tech/what-is-a-decel-dueling... reply Terr_ 16 hours agorootparent> “Decel” is used as a dismissive term for tech doomsayers by those who see themselves as members of the burgeoning E/Acc community. [... Who have] the belief that in our current technological age, the powers of innovation and capitalism should be exploited to their extremes to drive radical social change - even at the cost of today’s social order. I'm sure that--in practice--there will be extremely strong correlation to social-order changes that leave the C-suite richer than before. :p reply mateus1 16 hours agorootparentprevThis is the literal definition of a slippery slope. Letting billionaires, who already wield extreme power, break laws and skirt regulations is the opposite of a free market. reply adamtaylor_13 16 hours agorootparentWhere do you get this idea that we have a free market? Money begets money, and as the commenter above pointed out, those who have money know how to make it and know that it's the Musk/Zuck/Altmans of the world who get it done. We don't necessarily have to like it to acknowledge it's very much reality. reply hnfong 15 hours agorootparentprevThe \"free market\" literally means free of government interference and regulation... So it actually implies allowing capitalists to wield extreme power, skirt laws and regulations. I understand the term has gone through some kind of whitewashing to mean \"this is the good system (unlike the bad system)\", so one might be inclined to think it means something more equitable, but seriously, that was the original meaning. reply throw310822 14 hours agoprevAnyway, it's fun that the CEO of the company closer to AGI is super-smart but has a clear alignment problem. reply snowwrestler 17 hours agoprevKind of ironic that people are jumping in here to defend Sam Altman on the message board of Y Combinator, which also fired him from an executive leadership role for similar reasons. reply ben_w 9 hours agoparentMy own opinion on Altman is the same as with GPT-2 getting a slow roll-out for safety: regardless of the reality, it is best to have a system and process which assumes the worst and can cope with that possibility being a reality. reply benreesman 16 hours agoparentprevIt’s utterly mundane, completely common knowledge for those who have been around long enough to have watched both the start and end on Loopt that Altman is a dark-triad sociopath with one marketable skill: (in pg’s words) “becoming powerful”. Guy can’t code, can’t design, can’t publish, can’t climb a traditional corporate ladder with even modest guardrails against fraud, can’t keep his hand out of the cookie jar. Can lie, threaten, cajole, manipulate, bribe with zero hesitation or remorse. I’ve been short this nonsense for a decade, and it’s done no favors to me on remaining solvent, but when the market gets rational, it usually gets rational all at once. Karpathy, Ilya, Yoon right off the top of my head, countless others. LeCun woke up the other day and chose violence on X. Insiders are getting short like Goldman dealing with Burry. Guy has nine lives, already been fired for fraud like three times and he’s still living that crime life, so who knows, maybe he lasts long enough to put Ice Nine in my glass after all, but this can only happen so many times. reply viking123 14 hours agorootparentI always get the Sam Bankman-Fried vibes from him reply benreesman 14 hours agorootparentSBF is dramatically less scary than Altman. Which is why he’s doing 30+ for being likewise a crook but dramatically less dangerous to Enlightenment civilization in the large. SBF was trying to pocket the difference on a regionally lax regulatory climate. Felon? Sure thing. By all means, hand down a sentence. It’s fraud. Altman has blown straight past the “personal financial gain” fraud line multiple times and has amassed enough fear of retribution to now be at the “manipulate both potential executive orders and plausible legislation to arrogate de facto regulator status to myself” stage of the conquest of Arrakis. Both bad. One far scarier. reply lll-o-lll 11 hours agorootparentDammit, why are monsters lurking under all my cool tech rocks? reply benreesman 10 hours agorootparentIt comes and goes. This is the twilight of this era of mediocre technologists known by sight by the bouncers at the Battery. reply ocodo 10 hours agorootparentprevBecause a purely competitive operating environment favors the sociopath. reply karma_pharmer 5 hours agorootparentOh right that's why there are zero sociopaths at NGOs... reply portaouflop 12 hours agorootparentprevDamn sounds like he will take over the world any day now reply tim333 10 hours agorootparentJust wait for the AGI robots! reply whateveracct 14 hours agorootparentprevSam Altman wouldn't get caught reply thaumaturgy 15 hours agorootparentprevI think it might be time to turn back the clock a bit and revisit some of the things pg said way back when he was pitching Sam Altman to lead YC and the general reaction was \"...who?\" 2008: \"You could parachute [Sam Altman] into an island full of cannibals and come back in 5 years and he'd be the king. If you're Sam Altman, you don't have to be profitable to convey to investors that you'll succeed with or without them. (He wasn't, and he did.) Not everyone has Sam's deal-making ability. I myself don't. But if you don't, you can let the numbers speak for you.\" https://paulgraham.com/fundraising.html 2014: \"Of all the people we’ve met in the 9 years we’ve been working on YC, Jessica and I both feel Sam is the best suited for that task. He’s one of those rare people who manage to be both fearsomely effective and yet fundamentally benevolent...\" https://www.ycombinator.com/blog/sam-altman-for-president Now, this isn't about pg specifically. Maybe he had reservations at the time but still thought he was making the right decision, maybe he's since changed his mind, maybe he hasn't but has pretty well moved on from this scene. Not interesting. I'm more interested in whether Altman, and Musk, and Zuckerberg, and Bezos, and Ellison, and all the other amoral wealth-hoarders, are finally becoming obvious enough now that people might finally begin to see them as the yucky byproducts of a yucky system. Maybe a moralistic, basically decent person couldn't get ChatGPT launched and turned in to the household topic of discussion it is today; maybe nice people can't build cheap rockets. Maybe in the future, when making an endorsement for a leadership position in some company, someone might be brazen enough to say aloud, \"I believe this person is sufficiently nasty to make us all more successful.\" And so then the question is, does society net benefit more from the moralists or more from the capitalists? Do we accept that Sam Altmans are necessary for cool technology? How many Altmans can we have before something goes horribly, irreversibly wrong? reply ryukoposting 15 hours agorootparent> Do we accept that Sam Altmans are necessary for cool technology? Zooming out a bit, do we accept \"cool technology\" as a virtue? Should it factor into my evaluation of a person at all? reply margalabargala 13 hours agorootparent\"Cool technology\" here means things like dishwashers, or MRI machines, which pretty much strictly improve people's lives, not slightly better advertisement algorithms. reply garte 12 hours agorootparentI don't think you need to be an asshole to invent a dishwasher or an MRI machine. The usefulness alone lets you sell these. AI on the other hand... reply benterix 11 hours agorootparentThere is more than usefulness to it. Take what became social media later but what at the beginning was just a means for friends to have many-to-many async conversations instead of only 1:1 in an easy way. This was useful, I have no doubt about this. Yet the final product sold is something quite different, and in some cases can hurt people instead of benefiting them. reply margalabargala 3 hours agorootparentprevFor sure. I think I expressed myself poorly; I very much do not think being an asshole is a necessity for cool technology. I do think that \"cool technology\" such as dishwashers and MRI machines is a virtue and we're better of with those than without. reply thefounder 12 hours agorootparentprevInvention is one thing, a product to sell is almost an entirely different thing. The more I see the more I realise that being technical is almost all the time the least important part. You need to get people around you to succeed. In practice that means investors so that you can hire and people with the right connections so you can get sweet deals. You need people skills not inventions. And a bit more fake it until you make it rather than correct/technical information. reply Fanmade 11 hours agorootparentI think that this is true, and I hate it. In a previous job, I had to work with the worst (shop)-framework I have ever seen. It is very expensive, over-engineered in the worst ways, very slow and awful to use. The blatant misunderstanding of software architecture principles in that software is hard to put into words. For example: It took an experienced developer two weeks and more than 2000 LoC in more than 40 files to add a new label to a product. But the company creating this mess is good at marketing, and their events are great. A few weeks ago one of the guys (a freelancer) who stayed in that project was on an event of a competitor to this shop framework. After that event, he said that their software was way better, but it wasn't interesting enough for him to invest in learning that system. In his opinion, their marketing is not good enough, and they won't be able to sell it to important companies. So we are stuck with bad products because they apparently sell better than the good ones. The developers in the company I mentioned first even knew beforehand that the software was bad. They were \"included\" in the decision process, and they all voted against the bad software and preferred another solution (it was before my time, and I don't remember if they told me what they actually wanted to use). But the manager who made the ultimate decision had such a good time with the guys from the bad product that he decided to go with it. I know a lot of good developers and people who can sell themselves really well. Sadly, these two groups hardly overlap. reply ativzzz 5 hours agorootparent> I know a lot of good developers and people who can sell themselves really well. Sadly, these two groups hardly overlap. Because the best marketers and salespeople are plainly people who lie. People who lie about the capability of the product they are selling to get their customer to buy more of it. Good marketers and salespeople cripple their financial gain by being truthful. So liars get more money, so they get more customers, so they get more power. So it goes. Software development, being somewhere between a craft, an art, and a science, is fundamentally grounded in truth. You can't bullshit your way to quality software. You can't lie to the computer like you can to a human (maybe with AI you can). So \"success\" in these two fields is diametrically different. Though I bet you'll get the opposite answer on a sales/marketing forum. reply pas 10 hours agorootparentprevthat's not a manager, that's an internal client from hell. and yes, the world is full of these dysfunctional groups flush with money. (you might euphemistically call it this or that VC/startup scene) on one hand it's great that there's plenty of room for technical improvement, on the other it needs the right socioeconomic circumstances. sometimes FOSS helps with this. (developers who spend their career working on products based on FOSS stuff at least have some chance of knowing that their efforts can might be valuable for a wider audience.) reply tarsinge 11 hours agorootparentprevThat's only the VC angle. Plenty of revolutionary products will find adoption without playing the SV startup playbook. I think it's time to reevaluate the startup business \"wisdom\" of these past 15 years in the light of the companies and founders \"role models\" it has produced over that time frame. Good at making money, obviously. Holding the promise of making society better? I'll let you judge. As for me since I've read from Zero to One I have a sense I have been duped. I was once grateful for HN for opening my eyes on marketing. Now I'm hangover at how it perverted everything. reply fragmede 12 hours agorootparentprevPlenty of people are finding AI to be useful. I don't know what you're hinting at. reply TeMPOraL 11 hours agorootparentprevYou don't need to be an asshole, but if you win big enough to end up in the spotlight, you might eventually get painted as an asshole. reply bergen 12 hours agorootparentprevPretty sure Paul Lauterbur was no douchebag and good products and inventions can come from good people. reply tim333 10 hours agorootparentprevHas Sam actually caused any cool technology? It seems Loopt was kind of meh, he's just an investor in Helion. OpenAI was largely funded by Musk and would have happened without Sam and it may have actually lived up to the Open bit if he hadn't been there which would have been cooler. Now it's just another corporate. reply benterix 11 hours agorootparentprevI think your premise is false. Yes, you can give examples of people that weren't very ethical and built successful products (like Gates and Jobs), but there are numerous examples of the opposite - many wonderful products done by people and teams who did nothing wrong (yet!). I even think believing this idea (you need to be ruthless to succeed) is dangerous. And if you behave like a boss from the 90s at some point you will be exposed. I've seen places where these people rule and they only have high turnover with the exception of these few shops where investors are funneling tons of money so employees just stopped caring. reply benreesman 14 hours agorootparentprevI’m no huge fan of the bond villains in general, but this thread isn’t about Musk or whoever being a dick. And even if it were, Musk builds the best rockets ever and stuff like that and to a first approximation knows how they work. Mark at a minimum is the Corp Dev CEO of a generation and I’d argue more. I’d argue he is the first person to create an accurate-ish mental model mapping IRL human mechanism design into a high-fidelity digital analogy. Bezos was at DE Shaw and called the Internet as a vehicle for commerce on the early side, to put it mildly. Ellison saw that what we now call RDBMS was going to Be Big and substantially implemented the early versions personally. Now this isn’t a license for any of the icky shit any of these folks have done since, but all of them put some of the points their character class rolled into “actually build something”. Altman put all his points into manipulate if not blackmail people around me until the machine coughs up the next stair on the ladder. I’m generally in favor of “less bond villains”, but that’s not the topic of the thread and neatly bypasses another key point which is that all the other bond villains you mentioned (and I’ve met a few of them) have some redeeming quality as opposed to, Jesus, could a fucking Kennedy get away with a farce like this? Stop changing the subject. I know all those essays by heart. I was synthesizing them with inside YC baseball the day they were published. reply smackay 12 hours agorootparentIt's Gwynne Shotwell, COO of SpaceX, who makes the rockets fly. reply mike_hearn 8 hours agorootparentAnd yet Shotwell didn't create SpaceX, define its mission, establish its products, create Starlink or recruit the core team. Musk did all of that and tons more as well. It's fascinating how nobody was making this claim of a non-technical Musk up until the moment he stopped being loyal to one particular wing of US politics. Now we see a concerted effort to diminish his achievements. Do you people really think this will work? There is endless testimony from people - independent of Musk and in the space industry - saying that the dude is an honest to god rocket scientist who single-handedly made SpaceX happen through sheer force of will, engineering ability and personal investment. He routinely displays a fluent understanding of orbital mechanics well beyond what any normal CEO would be expected to display. Anyone can read his bio or the testimony of people who work in the space industry and understand that Musk was (and still is) intimately involved in every aspect of SpaceX, down to detailed engineering decisions. Shotwell meanwhile is regularly described as managing the business development side. She negotiates with customers and oversees day to day operations. This is critical work that she clearly does very well, and she has an engineering background. But I can't find examples of people claiming that she drives product development or overall strategy for SpaceX. reply tarsinge 8 hours agorootparentHe is diminishing his achievements all by myself on Twitter. Like before there was doubts he was technical. Now it's clear he is not and was acting (at least regarding software). If Steve Jobs was claiming he also did the iPhone engineering don't you think people would challenge that? He lies, he gets caught up, that's it. Look at his recent exchange with LeCun, is it really politics or has he simply too much ego and lost touch and people are calling it? reply insane_dreamer 7 hours agorootparentprevIt’s not his politics but his takeover and self-sabotage of Twitter. I think most people when they get that much wealth and power turn into assholes because they think they are indestructible (and in a way they are). reply nradov 5 hours agorootparentWhy does anyone here care what happens to Twitter? It's just another social network. We have lots of them. Even if Elon Musk bought it just to burn it down, so what? Anyone who cares can build a replacement. And as a casual Twitter/X user who doesn't give a damn about Musk one way or the other, I don't see the sabotage. The web site and mobile app seem to be working fine. Community Notes is great. I understand that advertising revenue is down but that has no impact on users. reply insane_dreamer 2 hours agorootparentI don't care what happened to Twitter now that I'm off it, but having an egomaniac not only owning but actively controlling, answerable to no one but himself, the most important digital public square in the world, is very problematic from a democratic (not the party) standpoint. > Anyone who cares can build a replacement. Technologically, sure; nothing special about it. But in terms of adoption and reach, no, Twitter is unique and extremely difficult to replace. reply raverbashing 10 hours agorootparentprevI hadn't noticed that particular nominative determinism before, interesting reply davidguetta 8 hours agorootparentprevIsnt altman the architect of chatgpt as a product. He seems on par on that genius at the others on tech reply wuschel 10 hours agorootparentprev> mental model mapping IRL human mechanism design into a high-fidelity digital analogy Could you please elaborate what you mean by that? reply benreesman 10 hours agorootparentMechanism design is broadly the study (with a practical as opposed to theoretical emphasis) of the way that incentives shape human behavior. For better or worse Mark was/is able to see some deep minimal structure that allows what used to be a web page and is now a mobile app to elicit responses that bear an uncanny resemblance to the way human beings behave and interact in a setting unmediated by either a priest or a protocol. On the properties he runs people act a hell of a lot like they do in a bar or any other place where sapiens mix and match. I’m not sure that turbocharging spinal-reflex humanity via computer networks is going all that well, which is one of the main reasons I parted ways with the endeavor once the true scope for mechanical advantage became clear, but he clearly sees things about what motivates people that Freud was throwing darts at. I might have been one of the few true assassins he sent after people like Vic Gunderotta or Evan Spiegel and certainly he knows how to delegate the mechanics of leaving would-be adversaries on the scrap heap of history, but he knew who to send the hitters after and when. reply chipdart 11 hours agorootparentprev> And even if it were, Musk builds the best rockets ever and stuff like that and to a first approximation knows how they work. Being fed the tour guide's summary and high-level overview of an event is not the same thing as knowing how they work. Elon Musk's virtues start and stop at the way projects were funded. He comes in, buys existing companies, pays people to continue doing the work, and that's it. It's well established that his takes are merely performative and with a substance of a pre-pubrescent edgy rant. If there was any value in Elon Musk's takeover of Twitter, and the hot mess that his tenure has been, is to put the spotlight on how incidental the success of companies like SpaceX is regarding Elon Musk's influence. You're talking about the guy behind stunts like the \"pedo guy\" incident and yanking live servers out of their sockets as a cost-cutting measure. reply tim333 10 hours agorootparent>He comes in, buys existing companies, pays people to continue doing the work, and that's it. Apart from Zip2 which he started from scratch and wrote the early code for, SpaceX which he stated from scratch, Neuralink likewise, OpenAI which he co founded and was the biggest early funder for and probably some others. reply bergen 12 hours agorootparentprevNo Musk builds nothing. There is a huge team he leads, consisting of engineers and scientists and they develop technology that Musk then sells. He's a glorified cars salesman. Maybe he was essential to get the rockets built, but neither did he build them, nor contribute essential technical details, so that it would be uniquely him who could do it given same financial backing. reply thepasswordis 12 hours agorootparentThis image should just get autoreplied any time somebody tries to (incorrectly) claim that Elon Musk is just a salesman: https://www.reddit.com/r/SpaceXMasterrace/comments/ub1yav/bu... reply marxisttemp 9 hours agorootparentlol I met Josh Boehm years ago, didn’t realize he had crawled so far up the ladder at SpaceX. I tried talking with him about programming but he struck me as one of those insufferable managerial types with no passion for the craft that had fully bought into his personality cult. I seem to recall his handle on some social media being “Baron Boehm”, which is probably a telling indication of his ego. reply azinman2 12 hours agorootparentprevMeanwhile the competitors are failing. He’s doing something right that’s beyond just car salesman. reply Log_out_ 5 hours agorootparentIn the realm of invisible monopolies and quasi-state owned the privately owned individual is only half blind. reply azinman2 5 hours agorootparentWhat does that even mean? Your structural setting changed your success potential? China would disagree. Besides… Blue origin? Boeing? These are not state owned or “invisible” yet are failing. reply thaumaturgy 14 hours agorootparentprevnext [2 more] [flagged] benreesman 14 hours agorootparentI don’t think that studying the history of the technology business makes one a tabloid journalist. I apologize if my remark came off smartass, I can see how it could. If you feel I could be more constructive I’m legitimately (no sarcasm whatsoever) open to suggestions: it’s a tricky topic and I strike the wrong note more often than the right one. Certainly I intended no personal offense to someone I haven’t met. reply ben_w 12 hours agorootparentprev> Zuckerberg He started off looking like a Lore from Star Trek, and then took the criticism seriously enough to learn to present as a genuine human. Might have been around the time FB was getting named by the UN as bearing some responsibility for a genocide though. So if anything, for him at least, the opposite. reply berniedurfee 7 hours agorootparentprev> Altman, and Musk, and Zuckerberg, and Bezos, and Ellison, and Edison reply WalterBright 14 hours agorootparentprev> amoral wealth-hoarders They're not hoarding wealth. They don't have any Scrooge McDuck cash faults. Their money is all invested, i.e. put to work creating things that people want. > moralists ... capitalists History shows us that societies based on morals (religious, ideological) fare extremely poorly compared with societies based on rights (free markets). Like it or not, for a large, prosperous society you must have big business. reply seanhunter 13 hours agorootparent> History shows us that societies based on morals (religious, ideological) fare extremely poorly compared with societies based on rights (free markets). Adam Smith saw \"Theory of Moral Sentiments\" as the foundation of his later work on \"Wealth of Nations\", right? ie that morals were a necessary prerequisite to markets etc. reply bergen 12 hours agorootparentprevMesopothemia was based on morals as far as we know, and they lay the foundation for many technical and scientific advances. And your rights are based on religious and ideological morals. Why do you believe the debate about Roe v. Wade exists? Why do we consider infidelity so bad it can break a contract of marriage? What is marriage? Those are not laws of nature. reply WalterBright 12 hours agorootparentYour right to not be attacked, robbed, or defrauded by others is inherent, not something conferred by religion or morality. As for abortion, the debate there rests on a conflict of the rights of two people, and there isn't any clear answer to it based on rights. Marriage is tangled up with the rights of children. Children are not fully formed humans and we allot them a subset of the rights of adults. Marriage without children is an issue of morality, not rights. I don't know what mesopothemia is. reply bergen 12 hours agorootparent>Marriage without children is an issue of morality, not rights. It was historically an issue of rights And children rights are a fairly new thing. And no, you are wrong - your right not be attacked is based on morality, you say \"attacking someone is wrong\" - there is no law in nature preventing this. But you made no point for your argument - just stepping through mine with comments. reply zaat 8 hours agorootparent> And no, you are wrong - your right not be attacked is based on morality, you say \"attacking someone is wrong\" You are mixing morality with justice, which (in the modern world) is based on rights. \"Attacking someone is wrong\" is a moral statement, it puts the focus and the obligation of individuals to keep moral behavior. My right not to be attacked is not based on moral and not dependent on the morality or the beliefs of any other people, it is based on justice, a social contract that declare a set of a societal or universal rights granted to every individual. reply WalterBright 11 hours agorootparentprev> your right not be attacked is based on morality The very first thing a group does when organized is to protect themselves from attack. They do this because it works. We've evolved that way, which makes it a law of nature for humans. Communist rights, however, are not laws of nature because they do not work with humans. Humans are not beehives. But the most compelling argument for \"natural rights\" is observing how well societies work that enforce them, and how well they work when other systems of rights are tried. The evidence is pretty clear. reply bergen 10 hours agorootparentOf course you defend yourself and your kind from harm. But that is completely separate from the fact if it is allowed. There is no law in nature preventing this. Sometimes internal conflict is solved by violence and accepted. Your first paragraph describes a group sharing a common will and organisation based on natural instinct (like a hive of bees), your second paragraph disputes this organisation as a group for humans, decide for one it can’t be both ways. reply WalterBright 3 hours agorootparent> decide for one it can’t be both ways Oh, it can be both ways and is both ways. See my last sentence again, about the compelling evidence that humans thrive with their rights being protected, while a beehive thrives from being a perfect communist society. Communism requires people to behave like bees in a beehive, and that will never work no matter how fervently one believes in communism and no matter how much coercion is used to force people to be good communists. reply Kbelicius 9 hours agorootparentprev> But the most compelling argument for \"natural rights\" is observing how well societies work that enforce them, and how well they work when other systems of rights are tried. The evidence is pretty clear. We did not evolve with private property rights thus, by your reasoning, those are not \"natural rights\". I am at a loss in trying to understand what you are saying. It seem like you are trying to argue for capitalism but arguments that you give seem to favor socialism. reply zaat 7 hours agorootparentNatural and legal rights are well established terms that are being used, discussed and evaluated since ancient times. The term natural right precede our discovery of evolution by 2 millennia. Whether the right to property is natural right or not is a separate point and debatable. https://en.wikipedia.org/wiki/Natural_rights_and_legal_right... https://en.wikipedia.org/wiki/Right_to_property reply sudosysgen 5 hours agorootparentThe term natural right since ancient times was a religious construct that has little or nothing to do with the modern, post-Renaissance understanding of the term, so tracing a lineage here is a definitional error. In any case, what a natural right is isn't (and cannot be) a well established term, and indeed the rise in atheism is a fundamental threat to the doctrine, as most all ideas of natural law have to rely on a God to avoid the naturalistic fallacy. reply zaat 4 hours agorootparentGod is of very little help (here), as pointed by Plato/Socrates in the Uthyphro dilemma. The naturalistic fallacy is not limited to natural rights, as Hume's is-ought is applicable to legal rights just the same - you can't logically deduce from the fact that there are laws that mandate rights a conclusion that one ought to abide by them. Natural or universal rights does not require theism. Robert Nozick is famous proponent of the secular based position that property is a natural right. reply sudosysgen 3 hours agorootparentNatural rights do really require theism to be truly natural, ie, independent of morality and society. Theism avoids the is-ought problem by forgoing the ought, with theism natural law can simply be, and whether you decide you ought to abide them is no longer so important. Nozick's position on the existence natural rights is simply not grounded. He appeals to intuition and to the reader's morality to appeal for their existence, but he doesn't (and cannot) actually deduce their existence once he forgoes theism. He makes a few appeals to Kant, but they obviously cannot be sufficient, Kant's conditions are merely necessary. I'm very confused by your reference to Nozick on a discussion about the grounding of natural rights when Nozick himself admits that he cannot justify them - he simply assumes Locke, which himself uses a theistic argument, in ASU. If you want, I can get the quote, but I don't have time to skim it until I'm home from work. At the end of the day, secular natural rights is an intuitive and appealing but ungrounded position that cannot be logically justified, hence why it is threatened by theism. It is no wonder that positive rights and social right theory only really emerged after the Renaissance. reply zaat 3 hours agorootparent> Natural rights do really require theism to be truly natural, ie, independent of morality and society. Theism avoids the is-ought problem by forgoing the ought, with theism natural law can simply be, and whether you decide you ought to abide them is no longer so important. Hume's original text describing the is-ought problem is specifically targeting justification of ethics on god. Laws that no one is ought to abide by are no laws but nonsense. Is murder immoral because god hate murder, or do god hate murder because it is immoral? > At the end of the day, secular natural rights is an intuitive and appealing but ungrounded position that cannot be logically justified Many will argue that no moral theory can be logically justified, and that the search for logical justification is category error reply sudosysgen 2 hours agorootparent> Hume's original text describing the is-ought problem is specifically targeting justification of ethics on god. Laws that no one is ought to abide by are no laws but nonsense. > Is murder immoral because god hate murder, or do god hate murder because it is immoral? We agree here, but that isn't how religion solves the problem. Religious laws are also enforced by threats in the afterlife and violence in the present life, not merely by reason, so they do not need to solve the is-ought problem like secular laws do. Of course, religious law has other problems. > Many will argue that no moral theory can be logically justified, and that the search for logical justification is category error I agree completely, hence why it is impossible to derive rights that are logically justified without an appeal to God. The comment I was replying to claimed there were logically justified rights which have to follow from logically justified moral theories unless they are decreed from beyond reason, and since the latter is a category error, so is the former. reply WalterBright 1 hour agorootparent> hence why it is impossible to derive rights that are logically justified without an appeal to God All attempts at changing human nature have failed, and it is human nature from whence rights are derived. Parents with zero or one child believe that human nature is conferred from the parents. Those with 2+ children know that it is inherent. reply WalterBright 1 hour agorootparentprev> We did not evolve with private property rights Yeah, we did. The concept of \"mine\" appears very early in children. Attempts to raise children from birth as good communists have never worked. Nobody has ever managed to indoctrinate people into communal behavior. Even the die hard communists in the USSR still participated in the black market - this was tolerated because even the elites used it. It turns out that human nature is not very malleable. reply Kbelicius 1 hour agorootparent> Yeah, we did. No we did not. > The concept of \"mine\" appears very early in children. The concept of \"mine\" also exists in socialism. How have you come to the conclusion that when a child says \"mine\" that it is referring to the capitalist notion of private property? > Nobody has ever managed to indoctrinate people into communal behavior. Are you denying the existence of families now? Humans evolved and spread in small familial groups which practiced communal behavior. > Even the die hard communists in the USSR still participated in the black market - this was tolerated because even the elites used it. What point are you trying to make whit this? > It turns out that human nature is not very malleable. If it wasn't malleable we wouldn't have capitalism as evidenced by early human history. While you at it why don't you tell us what human nature is, because there doesn't seem to be any consensus on it and you seem so confident in using it that you must have a ready definition of it. reply sudosysgen 6 hours agorootparentprev> Communist rights, however, are not laws of nature because they do not work with humans. Humans are not beehives. The laws of nature do not include any rights, unless there's some new physics I'm not aware of. > But the most compelling argument for \"natural rights\" is observing how well societies work that enforce them, and how well they work when other systems of rights are tried. The evidence is pretty clear. This is an argument from morality. You start with the premise that a good societal outcome is morally good and then use that to justify the rights you advocate for. You fundamentally cannot make an argument for what something should be like without resorting to morality. Without it, you can only make arguments on what things are. reply WalterBright 3 hours agorootparent> You start with the premise that a good societal outcome is morally good I said how well societies work, and have also used words like \"thrive\" and \"prosperous\". We have evolved to be that way, it's our local optima just like beehives have evolved a different local optima. > you can only make arguments on what things are. And that's exactly what I did. Humans starve to death under communism - every time it has been tried. Nobody starves due to loose morals. reply sudosysgen 5 hours agorootparentprev> Your right to not be attacked, robbed, or defrauded by others is inherent, not something conferred by religion or morality. It most certainly isn't. Inherent from where or what? In nature, I have no right not to be attacked by a lion or a pack of wolves, so surely this right cannot exist outside society, and then how can it derive from something outside society? Without a God, man in nature has no rights, though you can follow Hobbes and assert some principles from an idea of universal morality. I'm not aware of any serious philosopher who pretends to be able to derive any right at all without religion or morality. reply zaat 3 hours agorootparentRights is well developed subject in modern ethics, and it doesn't require God or morality in the sense of \"Doing X is bad and therefore immoral\". But any discussion of rights is discussion of moral theory. Modern ethical philosophers have developed ethic theories that propose secular basis for universal rights, moral theory that doesn't rely on God (Rawls is a famous example, https://en.wikipedia.org/wiki/A_Theory_of_Justice) reply sudosysgen 2 hours agorootparentNothing I am saying is at odds with modern ethics. I am literally presenting what is basically hetheredoxy. Rights can be natural or artifical (social, legal, etc...). For rights to be natural, you need to appeal to a God, or to natural morality. If you are looking for rights that aren't necessarily natural, you can derive them from a moral theory. There are moral theories that are not derived from an appeal to divinity or metaphysics, but they cannot claim to be naturally and objectively true. So I still do not understand how we aren't saying the same thing. Rawls proposes a system of universal rights based on a particular moral theory, he does not prove that his system of rights is natural, it is artificial. In fact, Rawls is not a proponent of natural rights, he is a proponent of socially determined rights, hence his theory of the Veil that allows us to socially evaluate proposed rules. reply zaat 19 minutes agorootparentWe seem to disagree on the definition of natural rights. For a right to be natural you require that it will be granted by God or that it will be based on human nature, and by human nature you mean to say that it is a direct product of the evolution biology that have created our species. While I would grant you that it's a definition that you can find in many philosophers, following Moore, but in the current context I think that the natural/artificial distinction isn't useful for defining natural rights. I would argue that this definition is very narrow and limiting, it introduce weird dependency on our current scientific knowledge, and isn't very useful. For instance, when Hobbes proposed the social contract theory he was discussing natural rights but today we know that his natural science knowledge was incorrect and therefore he was actually describing artificial rights. To me this makes no sense. Instead, I will propose, that rights that are derived by reason, that are universal, and that do not depend on a specific state law or the social norms of a specific society are natural rights. They are natural in the sense that they are not dependent on any state or law but are inherent. Those rights are not granted by god, and they are not artificial law propositions. They are based on universal principals of reason and the reality of human existence. This view and this definition of natural rights is not my invention. It's reflected in the language of the universal declaration of human rights - which recognizes a set of universal rights. The declaration isn't a legal document that legislate a binding law. It recognize rights that are not (let's hope, are not yet) generally accepted by all nations. Nevertheless those rights are not based on God or born by the act of composing and publishing the declaration, those are natural rights. They are natural despite being in opposition to humans natural behavior, despite their consistent violation. It is because those rights are natural that they can serve as basis and justification for international law and justice. Rawls theory of rights is universal, it isn't about specific social norms, it discuss human society in principle. One might say that his ethics are based on theory of the human nature. WalterBright 3 hours agorootparentprevThen how do you explain the universal fact that the communist notion of rights always fails? There are clearly some system of rights that are better than others, for humans. BTW, we kill wolves that attack us. reply sudosysgen 2 hours agorootparentI don't need to, there simply isn't a universally true notion of rights, it has to be socially defined, whether you're a communist or a capitalist. > There are clearly some system of rights that are better than others, for humans. I certainly agree with you : but \"better for humans\" is a morally grounded position. > BTW, we kill wolves that attack us. Sure. How is that a problem? reply torginus 10 hours agorootparentprevQue? First of all, Mesopothamia is a geographical region, not a culture or society. Second, places like Babylon had a very sophisticated legal, financial and administrative system, with tons of written evidence preserved in the form of clay tables surviving. The Code of Hammurabi being cited as one of the most important pieces of written evidence of a code of laws in ancient times. reply bryanrasmussen 13 hours agorootparentprevevery society is based on a set of morals, the rights societies are ones that have rights in that set, it seems somewhat to be skipping a wide inductive gap to blithely say that free markets need be a part of rights based societies (assuming that by \"free market\" something like the modern American conception of that term is meant) reply WalterBright 12 hours agorootparentMorals and rights are different things, though they are often conflated. The Constitution, for example, enumerates a series of rights, not morals. Free markets are based on the rights to life, liberty, and the pursuit of happiness (and property). A morality based system could be, for example, you do not have the right to the fruits of your labor, you automatically owe those fruits to others. I'm sad that our K-12 schools never bother to explain what a free market is, given that our nation was founded on free markets. > a wide inductive gap A book could be easily written about it. reply bryanrasmussen 11 hours agorootparent>Morals and rights are different things, I guess you didn't understand the point, I did not say that rights and morals were the same things, I said that a rights society would still have the moral opinion that its rights were morally good to have, and that respecting those rights was the moral thing to do. You can, I'm sure, recall many discussions on HN where people who come from a society with the right to free speech discussing this as a moral good and castigating other societies that are rights based, but without that particular right, as being bad for not having it. >Free markets are based on the rights to life, liberty, and the pursuit of happiness (and property). I seldom hear that particular basis given for free markets however, the basis seems tenuous. >I'm sad that our K-12 schools never bother to explain what a free market is, given that our nation was founded on free markets. there may be differences of opinion as to what a free market is/requires, and as to whether the free market was really fundamental to the founding of your country. It might be that your country could not really sustain too close a focus on those questions in its K-12 system of education though, best to leave it for later. reply WalterBright 3 hours agorootparent> I seldom hear that particular basis given for free markets however, the basis seems tenuous. You seldom hear it because it is not taught in schools and is rarely discussed. Leftist ideology is taught instead. > there may be differences of opinion as to what a free market is/requires, and as to whether the free market was really fundamental to the founding of your country There are differences of opinion about everything, even math, and even about the Earth being a sphere. Some of those opinions are simply wrong. I did not invent the definition of a free market, you can google it. > It might be that your country could not really sustain too close a focus on those questions in its K-12 system of education though, best to leave it for later. Really? The poor dears cannot understand notions of rights? Research shows that kids develop a sense of \"mine\" long before kindergarten - nobody has to teach it to them. My father, a college professor of business in his later years, said students would come up to him and say \"I didn't think there was a case for free markets! I've never heard of one!\" But they do hear a case in K-12 for collectivism. reply nickpp 12 hours agorootparentprevWhose morals though? In my life time I've seen being gay or smoking weed (for example) turn from immoral to widely accepted. Kind of hard to consider these shifting sentiments as a solid foundation for anything. reply WalterBright 12 hours agorootparentMorals do indeed change with the times. Our rights, however, are immutable (inalienable). reply immibis 11 hours agorootparentSo you still have the right to an abortion in Texas? reply WalterBright 3 hours agorootparentI addressed the issue of abortion wrt rights elsewhere in this thread. reply benreesman 14 hours agorootparentprevWalter, as you know I respect your point of view on the merits of the market in this business: God knows you’ve got about double my experience in it (and the multiple on impact is some larger coefficient I can’t even eyeball) and your opinion is logically robust, as we’ve debated before. You’ve previously argued for the merits of e.g. the Gates fortune, and as someone who went head-to-head with MSFT in the springtime of its excellence and I’m inclined to believe the guy who was there. In your opinion, which you know I respect as much as any hacker living, did Altman build anything or do anything of value to be a billionaire off AirBnB stock certainly less than 3, probably less than one year after Loopt was sold at a loss with Conway’s finger on the scales? reply WalterBright 12 hours agorootparentThank you for the kind words! I do appreciate them. I'm sorry to say I don't know enough about Altman to form any kind of opinion on him. reply benreesman 10 hours agorootparentUltimately it’s pg who owes this community locally and humanity globally for inflicting Altman on the world, but as much as I likewise respect pg on 99/100 things, he seems to be digging his heels in on this one, so I’m not holding my breath. I gather anoxia is a bad way to go. Absent that, a few other recognized OG legends like yourself looking into the matter and rendering an opinion might represent the daylight between the status quo and disaster. Certainly he’s nothing to do with your honestly-held convictions about merit prevailing in efficient markets oriented to novel contribution. I know you believe in markets, but I think we agree there’s nothing capitalist or meritocratic about failing up repeatedly until manifestly unqualified and ill-intentioned people wield arbitrary power off an unbroken litany of failures punctuated by the occasional success in taking credit for the efforts and achievements of others via PR and powerful friends. reply WalterBright 3 hours agorootparentIf Altman has achieved success through force, fraud, or theft, then I oppose him. If it's through selfish behavior, or hard-nosed behavior, it's ok with me. Just like there's nothing wrong with a football team who plays hard to win, as long as they stay within the rules. Microsoft eventually defeated me in the C++ business. I don't fault them for that. They are hard-nose players, and I knew what the game was when I got into it. I'm actually friends with a few of their players. Taking credit for what other people do is immoral, but leaders always do that, all the way up to the President. reply bmitc 14 hours agorootparentprevThat's all very generous. Who actually needs greater than 90% of the startups coming out of Silicon Valley and the surrounding areas? Their products just get hyped up and shoved down peoples' throat. And you're wrong. These people do have cash vaults, but they're other peoples' cash vaults. How else do you think they buy things? And they're living in their multi-million dollar mansions and yachts out of benevolence? Please. reply WalterBright 12 hours agorootparentUnfortunately, history provides us with exa",
    "originSummary": [
      "Former OpenAI board member Helen Toner disclosed that Sam Altman was briefly removed as CEO due to multiple instances of dishonesty and withholding information from the board.",
      "Examples included the board learning about ChatGPT's release via Twitter and Altman not disclosing his financial interest in the company, along with accusations of providing inaccurate safety information and \"psychological abuse\" by two executives.",
      "Altman was reinstated as CEO less than a week later after staff threatened to quit and Microsoft expressed interest in hiring his team; Toner resigned shortly after his return."
    ],
    "commentSummary": [
      "OpenAI CEO Sam Altman was briefly ousted and then rehired, exposing tensions between the board's authority and the influence of key investors and founders.",
      "The board's mishandling of Altman's firing led to significant employee backlash and threats of mass resignation, underscoring the complex dynamics of corporate governance, employee influence, and financial interests.",
      "The incident sparked broader discussions on leadership in tech, ethical implications of ruthless behavior, and the role of communication and ethics in corporate governance."
    ],
    "points": 699,
    "commentCount": 585,
    "retryCount": 0,
    "time": 1716938013
  },
  {
    "id": 40504756,
    "title": "Reconsidering HTTP-to-HTTPS Redirection for APIs to Enhance Security",
    "originLink": "https://jviide.iki.fi/http-redirects",
    "originBody": "Background When an user directs their web browser to an HTTP URL, it's a common practice for the service to redirect the request to a corresponding HTTPS page. This unencrypted part of the communication flow has its flaws. Third parties in shared networks, as well as network intermediaries, could sniff passwords and other secrets from the initial HTTP traffic or even impersonate the web server with a MITM attack. Nevertheless, redirection has been an useful first step in the transition from the largely unencrypted early web to the largely encrypted web of today. Later techniques tightened the security story further. Servers can now send HSTS along with the initial HTTP-to-HTTPS redirection response, telling the user's browser to use only HTTPS for that domain from then on. This limits the window of opportunity for trivial sniffing and MITM attacks to the first request. Browsers then added HSTS preload lists and HTTPS-Only modes that allow skipping the initial unencrypted request altogether. From the perspective of usability-security tradeoff it all makes sense for user-facing sites. But interestingly, the redirection approach also appears to be widely adopted for APIs. APIs are mostly consumed by other software so the same usability arguments don't apply there. Moreover, many programmatic API clients don't tend to keep browser-like state of things like HSTS headers they have seen. This post argues that, due to these factors, the common practice of redirecting API calls from HTTP to HTTPS should be reconsidered. While the post mostly refers to REST APIs, its points also apply to other styles of APIs that use HTTP(S) as a transport mechanism. A Simple Typo Is Enugh At work, we were building a new integration against a third-party API. The initial code commit contained a mistyped API base URL \"http://...\" instead of \"https://...\". A pretty easy mistake to make. The error was essentially masked during runtime: The third-party API responded to every request with a 301 redirect to their HTTPS side. Node.js's built-in fetch happily and quietly followed those redirects to the HTTPS endpoint. Every single one of our API requests now sent the API keys over the network in plaintext, before then sending them again to the encrypted endpoint. The one letter omission could have exposed the used API keys to third parties without us realizing it. As the integration would have worked, there's a good chance that code would have leaked any secrets in the API calls for years. In the long run, the probabilities for malice tend to accumulate. Luckily we spotted the error during the code review before the error could propagate to production or even testing. We also realized that our own API also did similar HTTP-to-HTTPS redirects. The Fail-fast Principle When an API redirect HTTP requests to HTTPS - and the API client silently follows those redirects - it tends to hide mistyped URLs like in the case described above. A simple one-letter omission can easily be ignored, end up in production, and compromise the entire system's confidentiality. In most cases, it's better to adhere to the fail-fast principle: unencrypted API calls should fail in a spectacular and visible way so that the developer can easily spot and fix the typo as early as possible during the development process. A great solution for failing fast would be to disable the API server's HTTP interface altogether and not even answer to connections attempts to port 80. If the initial unencrypted connection is never established then the API keys aren't sent, mitigating sniffing attacks and limiting the window of opportunity for MITM attacks to an extremely small time window. This approach is viable for APIs hosted under their own domains like api.example.com. Our own API was served under the /api path on the same domain as our service's web UI. As such we didn't feel confident completely disabling the HTTP interface, so we picked the second option: All unencrypted HTTP requests made under /api path now return a descriptive error message along with the HTTP status code 403. Some initial plaintext requests might be made during development, but they're much easier for developers to notice. After the initial publication of this post, Hacker News user u/zepton made a great point: The Stack Exchange API used to revoke API keys sent over HTTP (and return an error message), which is my favorite way to handle this. Indeed! Any API keys sent unencrypted over the public internet should be considered compromised and get automatically revoked on the spot. An error message in the API response is a great place to inform the API consumer both to fix their URL and get new keys after that. Who Else? That took care of our own API. We also pinged the third-party API provider and a couple of friends that they might want to check their APIs. And who knows, maybe there were some commonly used APIs that accept API keys (or other credentials) and also redirect from HTTP to HTTPS? I listed a bunch of well-known APIs from the top of my head and did a little survey. Several of them returned HTTP errors or declined to connections altogether. They're listed here with cURL spells for checking out their detailed responses: Stripe API: Responds with 403 (\"Forbidden\") and a descriptive error message. curl -i http://api.stripe.com Google Cloud API: Responds with 403 and a descriptive error message. curl -i http://compute.googleapis.com/compute/v1/projects/project/regions/region/addresses Shopify API: Responds with 403 and a descriptive error message. curl -i http://shop.myshopify.com/admin/api/2021-07/shop.json NPM Registry API: Responds with 426 (\"Upgrade Required\") and a descriptive error message. curl -i -X PUT -H 'content-type: application/json' -d '{}' 'http://registry.npmjs.org/-/user/org.couchdb.user:npm' Fastmail JMAP API: The whole HTTP interface seems to be disabled. curl -i -H 'Authorization: Bearer foo' http://api.fastmail.com/jmap/session Mailjet: The socket responds with completely empty payload. curl -i -X POST --user \"user:pass\" http://api.mailjet.com/v3.1/send -H 'Content-Type: application/json' -d '{}' However, the following APIs did respond with HTTP-to-HTTPS redirects: ActiveCampaign API curl -i -H \"Api-Token: 123abc-def-ghi\" http://123456demo.api-us1.com/api/3/accounts Atlassian Jira REST API curl -i http://jira.atlassian.com/rest/api/latest/issue/JRA-9 Anthropic API curl -i http://api.anthropic.com/v1/messages --header \"x-api-key: 1\" --header \"anthropic-version: 2023-06-01\" --header \"content-type: application/json\" --data '{}' Auth0 curl -i 'http://login.auth0.com/api/v2/organizations' -H 'Accept: application/json' -H 'Authorization: Bearer foo' Cloudflare API curl -i http://api.cloudflare.com/client/v4/accounts/abf9b32d38c5f572afde3336ec0ce302/rulesets Datadog curl -i http://api.datadoghq.com/api/v2/integration/gcp/accounts Deno Subhosting API curl -i http://api.deno.com/v1/organizations/11111111-2222-3333-4444-555555555555/projects DigitalOcean curl -i -X GET \"http://api.digitalocean.com/v2/actions\" -H \"Authorization: Bearer foo\" Facebook Graph API curl -i 'http://graph.facebook.com/me?access_token=foo' Fastly API curl -i -H \"Fastly-Key: foo\" \"http://api.fastly.com/current_customer\" Figma API curl -i -H 'X-FIGMA-TOKEN: 123' 'http://api.figma.com/v1/me' GitHub API curl -i http://api.github.com/user Gitlab API curl -i http://gitlab.com/api/v4/audit_events HackerOne API curl -i \"http://api.hackerone.com/v1/me/organizations\" -X GET -u \"user:token\" -H 'Accept: application/json' Hetzner Cloud API curl -i -H \"Authorization: Bearer 123\" \"http://api.hetzner.cloud/v1/certificates\" Hubspot API curl -i --request GET --url http://api.hubapi.com/account-info/v3/api-usage/daily/private-apps --header 'authorization: Bearer YOUR_ACCESS_TOKEN' IBM Cloud API curl -i \"http://iam.cloud.ibm.com/identity/token\" -d \"apikey=YOUR_API_KEY_HERE&grant_type=urn%3Aibm%3Aparams%3Aoauth%3Agrant-type%3Aapikey\" -H \"Content-Type: application/x-www-form-urlencoded\" -H \"Authorization: Basic Yng6Yng=\" Instagram Basic Display API curl -i 'http://graph.instagram.com/me/media?fields=id,caption&access_token=foo' Linear API curl -i -X POST -H \"Content-Type: application/json\" http://api.linear.app/graphql Mastodon API (on mastodon.social) curl -i http://mastodon.social/api/v1/timelines/home Microsoft Graph API curl -i http://graph.microsoft.com/v1.0/me/messages Netlify API curl -i -H \"User-Agent: foo\" -H \"Authorization: Bearer foo\" http://api.netlify.com/api/v1/sites OpenAI API — Updated to return errors since 2024-05-28. curl -i -H \"Content-Type: application/json\" -H \"Authorization: Bearer 123\" -d '{}' http://api.openai.com/v1/chat/completions OVHCloud API curl -i http://api.us.ovhcloud.com/1.0/auth/details Resend curl -i -X GET 'http://api.resend.com/domains' -H 'Authorization: Bearer re_123456789' -H 'Content-Type: application/json' Shodan API curl -i 'http://api.shodan.io/org?key=12345' Slack API curl -i -X POST -H \"Content-Type: application/json\" http://slack.com/api/conversations.create Tailscale API curl -i -H \"Authorization: Bearer tskey-api-xxxxx\" http://api.tailscale.com/api/v2/user-invites/1 Twitter curl -i http://api.twitter.com/2/users/by/username/jack Uber API curl -i -F client_secret=1 -F client_id=1 -F grant_type=authorization_code -F redirect_uri=1 -F code=1 http://auth.uber.com/oauth/v2/token UpCloud API curl -i -H 'Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=' http://api.upcloud.com/1.3/account Vercel API curl -i -H 'Authorization: Bearer foo' http://api.vercel.com/v5/user/tokens/5d9f2ebd38ddca62e5d51e9c1704c72530bdc8bfdd41e782a6687c48399e8391 Vultr API curl -i \"http://api.vultr.com/v2/account\" -H \"Authorization: Bearer 123\" I didn't report these findings separately to all of these API providers. There were some outliers not listed here that I did contact, with varying results. More on that later. Take each individual result with a grain of salt: I had to test some of these APIs without valid credentials, or with credentials used in documentation examples. But the overall pattern indicates that the habit of APIs redirecting HTTP requests to HTTPS is quite widespread. Why is that? Best Practices Need Practice Too When speaking with people about this topic, many have noted that HTTP-to-HTTPS redirects from APIs have obvious downsides - in hindsight. Redirects for user-facing applications are often mentioned in lists best practices and cheat sheets, like the ones published by OWASP (The Open Worldwide Application Security Project). Recommendations specifically aimed for APIs seem rare in contrast. I found just few mentions, for example an excellent PDF slideset called \"Common API Security Pitfalls\" by Philippe De Ryck, buried deep within the OWASP website: Slide 8 of \"Common API Security Pitfalls\". Emphasis added to highlight the relevant section. My Google-fu might just be bad. But maybe each best practice item recommending HTTP-to-HTTPS redirects for user-facing sites should have an explicit caveat attached, prominently advising against such redirects for APIs. Therefore I opened an issue that suggests amending OWASP's Transport Layer Security Cheat Sheet accordingly. Bonus Round: Popular APIs That Respond In Plaintext While reviewing the list of APIs, I bumped into some popular ones that neither redirected nor failed unencrypted requests. They just responded to unencrypted HTTP requests with unencrypted HTTP responses, without enforcing HTTPS at any stage. Maybe they had their reasons, or maybe they had just accidentally misconfigured their reverse proxies. Regardless, seeing that they all handle potentially sensitive data, I contacted these API providers through their respective security channels and explained the problem. The providers are listed below in the order of reporting. I'll unredact their names and details when they've given a definite response, or otherwise after a reasonable amount of time has passed. Provider A: Reported on 2024-05-17 through their vulnerability reporting email address. Awaiting response. Provider B: Reported on 2024-05-21 through their HackerOne program. Got a prompt triage response, stating that attacks requiring MITM (or physical access to a user's device) are outside the scope of the program. Sent back a response explaining that MITM or physical access was not required for sniffing. Awaiting response. Provider C: Reported on 2024-05-21 through their security email address. Awaiting response. VirusTotal API: Reported on 2024-05-21 through Google's Bug Hunters site (VirusTotal is owned by a Google subsidiary that got merged into Google Cloud). The API responds in plaintext to requests like for example this (where $API_KEY is a valid API key): curl -i -H 'x-apikey: $API_KEY' http://www.virustotal.com/api/v3/ip_addresses/1.1.1.1 The report got promptly triaged. Received a response on 2024-05-24, cited in part below: We've decided that the issue you reported is not severe enough for us to track it as a security bug. When we file a security vulnerability to product teams, we impose monitoring and escalation processes for teams to follow, and the security risk described in this report does not meet the threshold that we require for this type of escalation on behalf of the security team. Conclusion Redirecting HTTP to HTTPS for APIs can be more harmful than helpful due to the nature of APIs. Unlike user-facing web pages, APIs are primarily consumed by other software. API clients often follow redirects automatically and do not maintain state or support security headers like HSTS. This can lead to silent failures where sensitive data in each API request is initially transmitted in plaintext over the network, unencrypted. Let's adopt a fail-fast approach and disable the HTTP interface entirely or return clear error responses for unencrypted requests. This ensures that developers can quickly notice and fix accidental http:// URLs to https://. We should consider API credentials sent over unencrypted connections compromised and revoke them on the spot, automatically. Several well-known and popular APIs did redirect HTTP requests to HTTPS at the time of writing this post. This behavior seems to be widespread. Maybe it's time we amend best practices to explicitly recommend that APIs flat out refuse to handle unencrypted requests. Huge thanks to Juhani Eronen (NCSC-FI) and Marko Laakso (OUSPG) for their help and guidance during writing this post.",
    "commentLink": "https://news.ycombinator.com/item?id=40504756",
    "commentBody": "API Shouldn't Redirect HTTP to HTTPS (jviide.iki.fi)626 points by oherrala 23 hours agohidepastfavorite276 comments zepton 22 hours agoThe Stack Exchange API used to revoke API keys sent over HTTP (and return an error message), which is my favorite way to handle this. reply Eduard 19 hours agoparentthat's more secure, but still not bulletproof: A MITM (e.g. a router along a multi-hop route between the victim client and StackExchange) could silently drop the unsafe HTTP requests and maliciously repackage it as an HTTPS request, thereby circumventing the revocation. Also: even if an insecure HTTP request isn't dropped / makes it through to StackExchange's endpoint eventually (and thereby triggering the API key revocation), a MITM with a shorter trip time to SE's servers could race for wrecking havoc until the revocation happens. Nevertheless, SE's revocation tactic contributes positively to a defense in depth strategy. reply UncleMeat 6 hours agorootparentNothing could possibly be bulletproof. You sent a key over the wire unencrypted. You were in trouble before the data even got to the server to do anything about it. This approach is a practical choice based on the reality that the bulk of unencrypted traffic is not being actively mitmed and is at most being passively collected. Outside of actually developing cryptosystems, security tends to be a practical affair where we are happy building systems that improve security posture even if they don't fix everything. reply tessierashpool 1 hour agorootparentas an old-school reader of the cypherpunks email list from before HTTPS existed, I'm still mad about this part: Outside of actually developing cryptosystems, security tends to be a practical affair where we are happy building systems that improve security posture even if they don't fix everything. there was a time in the 1990s when cryptography geeks were blind to this reality and thought we'd build a very different internet. it sure didn't happen, but it would have been better. we had (and still have today) all the technology required to build genuinely secure systems. we all knew passwords were a shitty alternative. but the people with power were the corrupt, useless \"series of tubes!\" political class and the VCs, who obviously are always going to favor onboarding and growth over technical validity. it's basically an entire online economy founded on security theater at this point. reply JohnFen 1 hour agorootparent> we had (and still have today) all the technology required to build genuinely secure systems. True, but if we actually did that, it would make those systems very unpleasant to use. The age-old tradeoff of security vs convenience is still as much a force today as is always has been. Having technically the tightest possible security is not always the right answer. The right answer is whatever balance people are willing to work with for a particular use case. There's a reason that most people don't secure their houses by removing all windows and installing vault doors. reply Titan2189 18 hours agorootparentprevI'd argue your reasoning is incorrect. By the time your service is developed you would have already changed it to https, as during development every time you tried your API keys sent via http got disabled. So an in-the-wild MITM would never get to see your http request reply fl0ki 4 hours agorootparentI agree from a developer point of view, but the people configuring and deploying the application aren't always the same people developing it. As a developer I like to make many options available for debugging in various situations, including disabling TLS. This isn't controversial, every Go and Rust library I've ever seen defaults to no TLS, preferring to make it easy rather than required, so reflecting those defaults in the service's configuration is natural and intuitive. I make sure my example configurations are as close to what will be needed in production as possible, including not just TLS but at least one \"mutual TLS\" validation. I even sync these back from production if it turns out something had to be changed, so the examples in the repository and built artifact are in line with production. Yet I routinely find at least some of these disabled in at least some production deployments, presumably because the operator saw a shortcut and took it. Let's rework Murphy's original law: if there are multiple ways to deploy something and one of those will be a security disaster, someone will do it that way. reply sfn42 3 hours agorootparentWon't those people have the same experience? The app won't work until they configure it securely reply ljm 2 hours agorootparentThere is a non-zero number of developers out there who would sooner deploy a proxy that upgrades http to https because the thought of changing the application code wouldn’t spring to mind reply fl0ki 3 hours agorootparentprevIt appears the trick they've found is to disable TLS on both ends :) reply throw__away7391 14 hours agorootparentprevThat's a very good point, I agree. You're always going to run a service at least once. reply fwip 3 hours agorootparentprevThe MITM can be between the developer's machine and Stack Overflow, e.g: the classic Evil Cafe Wifi. reply lofenfew 18 hours agorootparentprevThere's absolutely nothing you can do to prevent an active MITM attack over HTTP reply fulafel 10 hours agorootparentI think the CONNECT proxy protocol carrying TLS over HTTP/1 is a counterexample. ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/CO... reply amscanne 17 hours agorootparentprevHave the authentication header effectively be a signed hash of relevant headers and the full URL, rather than a simple bearer token? reply grantism 16 hours agorootparentWhat's stopping the MITM just copying that header? reply gruez 15 hours agorootparentThere's complicated authentication schemes around hmac that tries to do this, but if you're putting that much effort into it you might as well give up and use https. reply dcow 12 hours agorootparentSome of these include a nonce and/or are deployed over TLS to prevent replay attacks and avoid sending bearer tokens over the wire. AWS sig v4 and RFC7616 come to mind. reply 4death4 14 hours agorootparentprevEven if the copy the header, they can only perform a replay attack, which is an improvement over leaking an API key. Also, you could include a timestamp in the signature to limit the amount of time it could be replayed. reply dcow 13 hours agorootparentSign a nonce. reply dotancohen 10 hours agorootparentprev> that's more secure, but still not bulletproof I've never heard of bulletproof ever actually being achieved in IT security. Not even air gaps. reply adrianN 10 hours agorootparentYou tend to only hear about the systems where security was successfully broken, not the systems nobody managed to penetrate. reply vitiral 6 hours agorootparentprevThe thing about bullet proof is that nothing is bulletproof when you have a big or fast enough bullet reply lukan 5 hours agorootparentYes, but what is meant, that it provides protection against common calibers. So you can have bullet proof security in IT. That does not mean it is blast proof, or acid resistant, or prevents someone using a backup key on the second entrance. It is just a metapher saying this security is very solid. Might be true, or not, but that nothing is 100% secure is quite known. reply beeboobaa3 6 hours agoparentprevUsed to? Did they stop? Did they give a reason why? reply ChrisTorng 10 hours agoparentprevThe client-side library should disable HTTP by default to ensure that raw data never leaves the local environment, thereby avoiding any leakage. reply gpvos 3 hours agorootparentIt should, but additional server-side mitigations are good for defense in depth. There may be people using a different client-side library, maybe because they use a different programming language. reply ljm 2 hours agorootparentprevWhat about things like unencrypted websockets? Or raw TCP/UDP connections? reply znpy 21 hours agoparentprevI've been thinking for about 5 minutes about this comment and what to write but i've come to the conclusion that this is really not the best thing to do, but the correct thing to do. It's not different levels of good or bad... everything else is wrong. reply comex 21 hours agorootparentOne of the approaches mentioned in the article is to just not listen on port 80. Supposedly that’s equally good because the connection should get aborted before the client has the chance to actually send any API keys. But is that actually true? With TCP Fast Open, a client can send initial TCP data before actually learning whether the port is open. It needs a cookie previously received from the server to do so, but the cookie is not port-specific, so – assuming the server supports Fast Open – the client could have obtained the cookie from a prior connection over HTTPS or any other valid port. That’s the impression I get from reading the RFC, anyway. The RFC does mention that clients should distinguish between different server ports when caching refusals by the server to support Fast Open, but by that point it’s too late; the data may have already been leaked. reply andrewaylett 20 hours agorootparentIf you're serving web traffic and API traffic on the same domain, which many services are, then not listening on port 80 may not be possible. Even if you do use a different domain, if you're behind a CDN then you probably can't avoid an open port 80. I do keep port 80 closed for those of my services I can do so for, but I don't have anything else that needs port 80 to be open on those IPs. I think Stack Exchange's solution is probably the right one in that case -- and hopefully anyone who hits it will do so with dev keys rather than in production. reply xnorswap 12 hours agorootparentI always thought it was bad practice to use the same domain for API and non-API traffic. In the browser there'll be a ton of wasted context (cookies) attached to the API request that isn't needed. So it's better to have \"api.example.com\" and \"www.example.com\" kept separate, rather than using \"www.example.com/api/\", where API requests will have inflated headers. reply wichert 11 hours agorootparentWhat matters is that there is nothing listening on port 80 on the same IP address. That may be hard to control if you are using an environment with shared ingress. reply pixl97 20 hours agorootparentprevIf someone is in your path they can just fake listen to 80 and intercept, then forward your call to 443. Probably best to listen on 80 and trash the token right then as the majority of the time there won't be a MITM and breaking the application will force the developer to change to https reply jedberg 19 hours agorootparent> If someone is in your path they can just fake listen to 80 and intercept, then forward your call to 443. They can do that whether or not you are listening on port 80 though. reply rocqua 14 hours agorootparentThat was OPs point. Not listening on port 80 won't help against an active MitM. reply zeroimpl 6 hours agorootparentBut listening on port 80 and revoking the key also won’t help either as the active MitM would have been smart enough to internally proxy to port 443 or return some other fake response. The real point is to break the application during development before the first MitM. Either approach does that equally well. reply comex 20 hours agorootparentprevBut not listening on port 80 will also usually break the application. Though I suppose the same API key may be used by multiple applications, or multiple copies of an application configured differently. edit: and even if there's only one application, yet for whatever reason it doesn't get taken down despite being broken, revoking the key now still prevents against a MITM later. reply gbalduzzi 5 hours agorootparentprevThe point in the article is that APIs are used by developers, not end users. Returning an error (and/or blocking the port entirely) allows the developer to understand he is using the wrong protocol and fix it. In this scenario, the end user never actually performs an http request, because the protocol was fixed by the service developer. reply cryptonector 19 hours agorootparentprevWell, nothing you do on the server side will protect a client willing to use http: when an MITM is present: the client can still connect to the MITIM, give away its credentials, and your server won't know. Still, I agree that this is a very good way to teach your users to not start with http:! And that this is what one should do. reply mid-kid 8 hours agoparentprevThis sounds like a great way to cause Denial-of-Service attacks. reply Thiez 6 hours agorootparentDenial of service by blocking API keys is really your happy case when someone malevolent has your API keys. reply mrmanner 8 hours agorootparentprevYou need to actually send them the API key, so not really. reply afiori 8 hours agorootparentprevTo do that you need to guess or steal the API keys. reply vitiral 6 hours agoparentprevCareful, someone might use that as an API! https://xkcd.com/1172/ reply ajsnigrutin 6 hours agorootparentI mean... it is a lot easier to do, than to program a procedure to revoke an api key. reply vitiral 5 hours agorootparentExactly. Easier but actually terrible for security since a MitM can intercept and use the key (and never actually revoke it) reply op00to 21 hours agoparentprevI love this. reply paulddraper 21 hours agoparentprevTechnically correct. reply freehorse 18 hours agorootparentBest kind of correct. reply makeitdouble 15 hours agoparentprevWouldn't this open the door to revoking random API keys sent maliciously ? reply Townley 15 hours agorootparentIf a malicious party has access to the API key, it should be revoked regardless reply bruce511 14 hours agorootparentOf course. But I think the poster above was referring to just posting random keys to the server. In other words I don't have your key, or any key, but I have \"all of them\". The correct response to this though is that \"there are lots of keys, and valid keys are sparse.\" In other words the jumper of valid keys that could be invalidated in this way is massively smaller than the list of invalid keys. Think trillions of trillions to 1. reply ncallaway 13 hours agorootparentWhich, like, if posting random keys has any realistic plausibility of collision, malicious revoking of keys is the least of your concerns. People could just hit important data fetch endpoints with random keys, until they find one that’s good, and then have a compromised account. reply makeitdouble 11 hours agorootparentGood point. Presented that way I am seeing more positives to their policies, in particular if a vulnerability was unearthed by the invalidation quirk it's a way better way to find out than any other way. reply numpad0 13 hours agorootparentprevIt's wrong that clients are authenticated with just the random generated username. But it's also what everyone do. reply Cthulhu_ 6 hours agorootparentprevIf the API key is a UUID or similar in complexity, they'd have to send 5.3 undecillion API keys to make sure all of them were invalidated. So yes, it would open the door to revoking random API keys, but that's not a bad thing; when using an API key, you should be ready to rotate it at any point for any reason. reply CGamesPlay 14 hours agorootparentprevThis is just a run-of-the-mill DoS attack, with the astronomically unlikely jackpot of additionally invaliding a random unknown user's API key when you get a hit. reply vitiral 6 hours agorootparentAstronomically is an understatement. If they made 1000 requests per second they might have a 1% chance of revoking a key before the heat death of the universe. Cracking hashing requires large parallel processing, something you can't do if you're API limited reply athyuttamre 20 hours agoprevGreat article! We've updated the OpenAI API to 403 on HTTP requests instead of redirecting. $ curl http://api.openai.com/v1/chat/completions \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer 123\" \\ -d '{}' { \"error\": { \"type\": \"invalid_request_error\", \"code\": \"http_unsupported\", \"message\": \"The OpenAI API is only accessible over HTTPS. Ensure the URL starts with 'https://' and not 'http://'.\", \"param\": null } } reply bhawks 15 hours agoparentYou may want to disable path resolution as well. http://api.openai.com/v1/chat/completions/../bar responds with error messages about http://api.openai.com/v1/chat/bar which might suggest some path traversal vulnerability that could be exploited. Generally an API client is not going to need .. to be resolved in a path. It should return 400 - Bad Request (deceptive routing). reply alberth 18 hours agoparentprevDoesn’t returning a 403 on HTTP break HSTS? https://security.stackexchange.com/questions/122441/should-h... Doesn’t HSTS require only responding to a user via HTTPS (even for error codes). reply mc10 18 hours agorootparentHSTS is intended for browsers. For API clients the correct behavior (following curl's lead) is probably to never follow/make any redirects by default. reply LinAGKar 12 hours agorootparentprevThe HSTS header is only effective when it's received over HTTPS. And if it has taken effect, the client won't try to access HTTP anymore, so it won't even know what response it would have gotten from HTTP. reply josephcsible 13 hours agorootparentprevWhat about this then? When the request is made over insecure HTTP, revoke the API key used, but then send the usual redirect response for HSTS. Then, when/if the request gets repeated over HTTPS, notice the key is revoked and so respond to that one with 403. reply freedomben 3 hours agorootparentIf your goal is to waste people's time, cause them to question their sanity, and guarantee that they're way too pissed off when they finally figure out what happened that instead of teaching others about how important it is too use HTTPS from the start, they talk about how awful your API is and how much they hate your company for a terrible design, then yes this sounds like a good plan. reply josephcsible 1 hour agorootparentIf it were a generic 403, sure. But if the 403 message said something to the effect of \"this API key is no longer valid because it has previously been observed over insecure HTTP\", then wouldn't that be fine? reply freedomben 25 minutes agorootparentYes agreed, I think that would improve it, although depending on the situation it may still cause substantial pain. Also apologies, after re-reading my previous comment it seemed unnecessarily harsh toward you, though that wasn't my intention! On the subject though, an example of how it could cause a lot of pain, many bigger corps don't allow developers to have \"real\" API keys, and they certainly can't generate new ones themselves, so this might mean one slip-up with curl results in at best a ticket with another team. It also might end up bringing down production in a horrible way, for example if the dev or an ops person is debugging and curls the endpoint from a pod in prod and forgets to explicitly put the https, curl will default to http which would then immediately cause the prod key to be revoked with no second chances. That could even happen on a GET request, which normally GETs are supposed to be safe/side-effect free! If you're operating at a big scale, that could be utterly disastrous, causing a widespread production outage immediately. If it's a dev that is just testing a key locally that isn't used anywhere else, then it's obviously less of an issue, but taking that into account starts to balloon the complexity around your token revocation code. reply gerdesj 18 hours agorootparentprevHSTS is a note to the browser to insist on TLS when hitting a website. It is sent as a header, with a timescale, regardless of http/https. reply freedomben 3 hours agoparentprevThank you for sharing! I think this sort of thing is what makes HN great. Have you rolled this out to prod yet? Did you check how many users this might effect? I can imagine some (probably amateur) apps are going to break when this hits, so some notice might be nice. I'm not asking those questions critically, mainly wanting to facilitate a full discussion around the pros and cons (I think the pros are are much stronger personally). reply Hizonner 17 hours agoparentprevWhy not just stop listening on port 80, period? reply Pesthuf 16 hours agorootparentIt’s a good option, but you can’t give users a reason for the failure. They might even assume your service is broken. reply booi 15 hours agorootparentI stopped listening on port 80 for everything… nobody’s complained yet! Maybe because they can’t find the service though. reply inopinatus 14 hours agorootparentprevI think it's fair to assume j. random user isn't typing \"http://api.example.net\" into their web browser. leading www perhaps, leading api no. reply tracker1 2 hours agorootparentYou'd be surprised... generally if there's a dedicated hostname for the API, I would expect / to either display or redirect to API docs. Also, doesn't help when you're reverse proxying /api to $API/api reply freedomben 3 hours agorootparentprevI've done that myself and have consumed many others who have done it, and I don't think it's better. Much better to get a response that tells you to use https for the API. (for browser also a redirect is a must for UX, though our context here is API) reply ikiris 10 hours agorootparentprevBecause the whole point is a mitm can compromise it, and the mitm can listen on 80 regardless if you turn yours off. reply from-nibly 18 hours agoparentprevThis is better as it allow you to immediately notice that there's an issue. However it still facilitates api key exposing on the initial request. reply NotYourLawyer 17 hours agorootparentHow would the endpoint prevent that? reply TheDong 16 hours agorootparentNot listening on port 80, such that the user gets a connection refused, would result in the client not sending the api key over the wire at all. I personally think listening, accepting that user mistakes can expose API keys to MITMs, and returning the user-facing error is better than a \"connection refused\" error, but it is a tradeoff. reply marcosdumay 18 hours agoparentprevIf anybody is looking to copy in a public API, please return 400 and don't misuse a standard code. reply hn_throwaway_99 14 hours agorootparentWhy do you think 403 is the wrong error code? Based on the spec it seems entirely appropriate to me: > HTTP 403 provides a distinct error case from HTTP 401; while HTTP 401 is returned when the client has not authenticated, and implies that a successful response may be returned following valid authentication, HTTP 403 is returned when the client is not permitted access to the resource despite providing authentication such as insufficient permissions of the authenticated account.[a] > Error 403: \"The server understood the request, but is refusing to authorize it.\" (RFC 7231) reply marcosdumay 2 hours agorootparentBecause it's not an authorization error. You do not throw 403 if the client is authorized to access whatever resource it's trying to. The 426 on the sibling comment is great, though. But if you don't find an error code for your case, you don't go and redefined a well defined one. You use 400 (or 500). reply samatman 3 hours agorootparentprevI thought the best response from the article was the 426 Upgrade Required. That way you can throw in an Upgrade: https field in the response. It makes it immediately clear that something weird is going on. 403s are common, my first thought would be a badly-configured API key which lacks the expected permissions. reply ants_everywhere 17 hours agorootparentprev400 is usually for a malformed request. It seems like in this case the request is well formed, it's just not allowed. 403 seems reasonable if the user isn't authorized to make a request to the URL, which they aren't. Some APIs return redirects which also seems pretty reasonable. reply mbreese 15 hours agorootparentBut that also implies that some user would be authorized to make a request to the HTTP port (or that the resource does exist, which in this case it doesn’t). IMO, 400 is more accurate, but really either could be acceptable, so long as the client is notified of the error. But, I wouldn’t automatically redirect the client. That’s what we are trying to avoid. reply ants_everywhere 4 hours agorootparentGood point. I guess this might depend a little on the implementation. In some cases the http endpoint may exist but may only be accessible to a sidecar container via localhost. For example, if the sidecar terminates https. reply kijin 17 hours agorootparentprev404 would also work, since the resource does not exist at the http: address. reply bruce511 14 hours agorootparentTrue, but 404 has trained us to look hard at the URL part, not the protocol part. Whereas 403 or 400 are less likely to have so automated built-in handling on the client side. reply endofreach 17 hours agorootparentprevWell in that case really anything is a 403. reply CGamesPlay 14 hours agorootparentprevNot sure how I feel about this (extremely arbitrary) distinction. 400 Bad Request maybe implies that no matter how many times you retry the request, it will never succeed. 403 Forbidden maybe implies that some external change in the authentication system could perhaps allow the same request to succeed in the future? So I guess in that lens I can see the logic, but again, seems extremely arbitrary. reply justin_oaks 22 hours agoprevI appreciate the author calling this out because creating an HTTP-redirect-to-HTTPS is something I'll do almost without thinking about it. \"If it has HTTPS, I'll set up an HTTP redirect.\" Now I know that I need to think about it before setting that up. It also made me realize that cURL's default to not redirect automatically is probably intentional and is a good default. Praise be to Daniel Stenberg for this choice when implementing cURL. reply tracker1 2 hours agoparentI tend to use Caddy as a reverse proxy for personal projects... The default behavior is to redirect to https. May have to make a special rule for API instances. reply tootie 22 hours agoparentprevUsing Cloudfront, the redirect was the only built-in option for a long time. They only added pushbutton HSTS recently. But I'd say author is correct that if you're hosting an API there's no reason to support http at all. Just send a 400 on all requests and let the client developers use common sense. reply tracker1 2 hours agorootparentYou can still return a response... 400 - HTTP is unsupported, use HTTPS. reply koromak 5 hours agoparentprevYeah I completely missed this as a security flaw. Time to go deploy a fix... reply 1vuio0pswjnm7 15 hours agoprevAs a non-developer, ordinary computer user \"providing service\" for one user (yours truly) it's easy for me to configure the TLS forward proxy listening on the loopback to send _all_ HTTP requests, from _any_ application, including ones sent to port 80, via HTTPS. This I find preferable to letting a browser try to convert HTTP to HTTPS, e.g., \"HTTPS Everywhere\", or letting a developer do it with a redirect. Personally, I compile clients without linking to a TLS library. They are smaller without it and I do not have to worry about every author having correctly added TLS support. When SSL/TLS changes, applications using it often need to be updated, and some authors have made mistakes, socat being one example that comes to mind. I do 100% of TLS negotiation using a single program: the proxy. Every HTTP request on the home network goes to the proxy. reply jagger27 8 hours agoparentThere’s absolutely nothing ordinary or easy about that setup, but I admire it. I’ve only seen that level of paranoia at a three letter agency. Do applications with pinned certificates break? A bunch of mobile apps do that to get in the way of Wireshark. reply dfabulich 22 hours agoprevThe author includes a surprising response from \"Provider B\" to the HackerOne report. > Provider B: Reported on 2024-05-21 through their HackerOne program. Got a prompt triage response, stating that attacks requiring MITM (or physical access to a user's device) are outside the scope of the program. Sent back a response explaining that MITM or physical access was not required for sniffing. Awaiting response. I think Provider B morally should require HTTPS, but it really surprises me that the author would say \"MITM or physical access is not required for sniffing.\" Is that true? Isn't HTTP sniffing an example of a MITM attack, by definition? Am I using the words \"MITM\" or \"sniffing\" differently from the author? I'm familiar with the following attacks, all of which I'd call \"MITM\": 1. Public unencrypted (or weakly WEP encrypted) wifi, with clients connecting to HTTP websites. Other clients on the same wifi network can read the unencrypted HTTP packets over the air. 2. Public encrypted wifi, where the attacker controls the wifi network (or runs a proxy wifi with the same/similar SSID,) tricking the client into connecting to the attacker over non-TLS HTTP. 3. ISP-level attacks where the ISP reads the packets between you and the HTTP website. Aren't all of these MITM attacks, or at the very least \"physical access\" attacks? How could anyone possibly perform HTTP sniffing without MITM or physical access?? reply HL33tibCe7 21 hours agoparentMITM generally refers to someone who can intercept and modify traffic, i.e. they sit “in the middle”, between you and your recipient, reading/modifying/relaying traffic. “Passive eavesdropper” is often used to describe what you talk about. Someone on an unencrypted WiFi network sniffing your traffic isn’t really “in the middle” at all, after all. reply Control8894 20 hours agorootparentI disagree. So does Wikipedia (\"where the attacker secretly relays and possibly alters the communications between two parties who believe that they are directly communicating with each other, as the attacker has inserted themselves between the two parties ... for example, an attacker within range of an Wi-Fi access point hosting a network without encryption could insert themselves as a man in the middle\") and so I believe do most people. \"Active MITM\" would be how you describe someone who does modify traffic. And an attacker in each of the scenarios GP mentioned can modify traffic. (For ISP/attacker-controlled networks it's trivial; for other networks you just need to ARP spoof) reply dTP90pN 20 hours agorootparentThere's no \"relaying\" when the the attacker just captures unencrypted WiFi packets from the air, or more traditionally, splits some light out of the fiber line. reply Brian_K_White 19 hours agorootparentI hate to agree but they are right. Endpoint-spoofing and relaying between two spoofed endpoinbts is just one of the possible forms of mitm attack that just happens to be required if you happen need to open and re-pack encryption in order to evesdrop, or if you need to modify the data. Spoofing the two endpoints to decrypt and re-encrypt, just so that you can evesdrop without modifying the data (other than the encryption) is certainly still \"mitm\". Yet all the man in the middle did was evesdrop. Becoming two endpoints in the middle was only an implimentetion detail required because of the encryption. If you are admin of one of the mail servers along the way between sender and recipient and and can read all the plain smtp messages that pass through your hands like postcards without having to decrypt or spoof endpoints, that is still mitm. So listening to wifi is no less. There is nothing substantive that makes it any different. For endpoint-spoofing to be required for mitm, you would have to say that mitm only applies to modifying the data, which I don't think is so. Several purely evesdropping applications are still called mitm. reply Control8894 20 hours agorootparentprev> for example, an attacker within range of an Wi-Fi access point hosting a network without encryption The monkey in the middle doesn't get to \"relay\" anything either, but he can sure see it going over his head. reply chaorace 5 hours agorootparentprevIt's just semantics... but I'll throw my hat into the ring nevertheless: The \"eavesdropping\" attack happens when you capture unecrypted packets. From there, you could either try to hijack the session by inserting yourself into the local conversation (effectively launching a \"MITM\" attack) or completely independently of the local conversation attempt to impersonate the login session (effectively launching an \"impersonation\" attack). reply cricketlover 31 minutes agorootparentHow fan we capture unencrypted packets from the network? I thought you had to run tcpdump or something like that to be able to do that. But you won't be able to run tcpdump if you don't have access to the interface (source or destination), no? reply syncsynchalt 18 hours agorootparentprevEve and Mallory are both MITM, in my opinion. reply tsimionescu 20 hours agorootparentprevI agree that's not a case of MITM, but I do think it's fair to call sitting in range of the same Wi-Fi access point \"physical access\". reply joveian 2 hours agoparentprevConsider: 4. Someone else logs unencrypted traffic for whatever reason and the attacker gets access to the log later. MITM means that you need to be in the middle at the time of the attack and so is more limited than an attack that works on logs. reply tsimionescu 20 hours agoparentprevI don't think people would consider 1 or 3 to be MITM. MITM requires someone who is, well, in the middle: you connect to the MITM, and they connect to your destination. 2 is clearly a MITM. Also, while 1 is arguably a case of \"physical access\", I don't think 3 is. If you have a tap in an ISP, you don't have \"physical access\" to any of the endpoints of the HTTP connection. Otherwise, you could say you have \"physical access\" to literally every machine on the internet, since there is some physical path between you and that machine. For another example, Kubernetes started as IPv4-only, and there are still plenty of plugins that have IPv4-only features. reply CGamesPlay 11 hours agoparentprevAt the end of the day it doesn't matter how you define \"MITM\". HTTPS means that even if I control a network hop in between the two endpoints, I can't get the key. Provider B says \"we are OK with any hop on your route gaining access to your keys\" (e.g. via owning a wifi router and giving customers access, or via being a customer and sniffing other customer's traffic, or the industrial-level equivalents of this). reply Aachen 22 hours agoparentprevDefinition question. I can see your reasoning and I can see the author's, where they define MITM as requiring an active component being in the middle to actually tamper with it and not just some far-off device receiving backscatter with a high-gain antenna, or a read-only mirror port on a switch or whatever is technically not \"in the middle\" but in a cul-de-sac. I'm not sure I've got a strong opinion, claiming one or the other is the only correct definition might just be nitpicking They may have chosen this wording (\"it's not MITM\") to get the team into action rather than dismissing the risk Edit: another legitimate-sounding question downvoted in this thread without further comment (since I'm the only comment still after it got downvoted). Can people maybe just explain what's wrong with a post when it's not a personal attack, not off topic, not answered in the article, or any other obvious downvote reason? Everyone would appreciate the author learning from the problem if there is one reply thaumasiotes 21 hours agoparentprev> Public unencrypted (or weakly WEP encrypted) wifi, with clients connecting to HTTP websites. Other clients on the same wifi network can read the unencrypted HTTP packets over the air. That's sniffing. The other two are MITM. The sniffer isn't in the middle of anything; you never speak to him. reply Brian_K_White 19 hours agorootparentYou have to mitm in order to evesdrop on an encrypted channel. If you do nothing but evesdrop, isn't it still mitm? You had to actively replace & spoof the two endpoints, but that is just a technicality required by the encryption, in the end you still only evesdropped, yet it was still called mitm. So, mere evesdropping is mitm. So, how is evesdropping on unencrypted traffic or wifi traffic meaningfully different than evesdropping by decrypt & reencrypt? I don't think the term mitm includes a requirement that you aren't talking to who you thought you were talking to, because generally you do still talk to who you thought you were, just not directly. The traffic may be modified along the way rather than merely copied, or one or the other endpoint may be wholly faked rather than merely relayed, but they also may not be, the attacker may simply relay everything verbatim in both directions, IE pure evesdropping, and the attack would still be called mitm. Then again, I guess a keylogger is evesdropping and not called mitm. reply danparsonson 19 hours agorootparent> You have to mitm in order to evesdrop on an encrypted channel. OK but we're talking about evesdropping HTTP, which is unencrypted. reply Brian_K_White 14 hours agorootparentSo what? My point was the encryption doesn't matter, it's just the reason you have to impersonate in order to merely evesdrop sometimes. reply danparsonson 8 hours agorootparentThe point is that you don't need to be 'in the middle' to evesdrop unencrypted data - you can sniff traffic without either end being any the wiser, but if the data is TLS encrypted then you can only decrypt it if you interpose yourself. reply Brian_K_White 5 hours agorootparentI said that already. What are you trying to contest or expand? One of us has not understood the others purpose, because I don't understand the point of your response to my first comment. Nothing is making sense after that. My initial point was to show that mere evesdropping on an encrypted link is still mitm, and so the full interposition is merely an implimentation detail, required by the encryption. If mere evesdropping is still mitm, then as far as I'm concerned any other evesdropping is also mitm. But then I also add that a keylogger is an evesdropper and I wouldn't call that mitm so maybe the argument is missing something. Maybe the way I should think of it is \"Yeah. It's an implimentation detail. An implimentation detail called man in the middle. Evesdropping on an encrypted link requires mitm, but not all evesdropping is mitm the way all beef is meat but not all meat is beef.\" IE the fact that you chose not to do anything with the mitm but merely evesdrop isn't really significant the way I argued at first. That particular example of \"mere evesdropping\" is still called mitm not because \"therefor evesdropping is a form of mitm\", but because that instance of evesdropping required mitm to do it. Allll that said, I now actually think all those other examples of evesdropping like even a keylogger should be considered mitm. Because they are all examples of you're not talking to who you thought you were talking to. In the case of a passive observer like a wifi or keylogger or phone tap, you thought you were talking to a certain listener, but in fact you were talking to them plus other listeners. It's perfectly logically arguable both ways. reply thaumasiotes 14 hours agorootparentprev> because generally you do still talk to who you thought you were, just not directly. ...that's the requirement. The indirection of someone interposing themselves between you and the party you're trying to speak to is what is referred to by the phrase \"man in the middle\". There is no phrase \"man to the side\". If you don't represent yourself as being the party they want to talk to, you aren't performing a man-in-the-middle attack. reply xyst 18 hours agoprevRevoking an API key upon a single http request assumes you have a competent team. Have worked with people that have committed sensitive credentials into public repositories, used PRODUCTION secrets for testing, and of course sharing secrets in plain text over IM and group chats. The number of times I have had to deal with password or secret key resets because of this is way too high. I remember working with a guy that thought sharing a demo of an internal application on YouTube was okay. Of course it had snippets of company secrets and development API keys clearly visible in the demo. reply loa_in_ 15 hours agoparentIt assumes nothing like that. It provides you and your team with a safe opportunity to learn and grow. Revoking a key like this is a problem that's solution is at worst a dozen clicks away fix. The alternative, leaking keys can be much worse. So go and reset those creds for the guy who made a mistake happily and be grateful. He had an opportunity to learn. reply xyst 6 hours agorootparentThere’s the guy that made _a_ mistake. Then there’s the guy who continues to make the same mistake over and over again. That second person is way to common in companies that hire from the bottom of the barrel. reply loa_in_ 3 hours agorootparentThe thing with these kinds of mistakes is that if the service doesn't revoke the key and \"cause problems\" immediately, then there's no feedback to learn from. It's a fail-fast situation that's usually a better outcome anyway. reply rocqua 14 hours agorootparentprevIt might be optimistic to say that rolling over to a new key is 'at most a dozen clicks'. Hardcoded keys are a big one. But even just hunting down all config where the key needs to change can be a major hassle. Is there some ci yaml that expects a runner to have the key in a .env file that only runs on major release? Good chance you won't realize that key exists. Still a great idea to revoke those keys. But it will damage some customers in the short term. And they will be angry, as people often are when you demonstrate their mistake. reply snowwrestler 22 hours agoprevHTTPS and SVCB DNS records will hopefully make it more feasible over time to drop the traditional HTTP server-side redirect. The client agent will be able to read the DNS record and upgrade to the highest available protocol prior to sending the first request. reply quectophoton 8 hours agoparentSeeing how web browsers haven't added support for SRV in decades, I'm not holding my breath. I'm guessing there's some (?) advantage of SVCB and HTTPS records that can't be achieved with SRV[1] and TXT records, but I haven't read the RFC yet to know what that advantage is. [1]: `_https._tcp` or `_http3._udp` or whatever. reply ikisusi 21 hours agoprevI hope that providers whose APIs responded and interacted fully over unencrypted HTTP would go back to their historical access logs and check how widespread using plaintext HTTP is. If they don't have access logs for their API then they could just sample next 24 hours for API accesses. Popular providers have so many API users today that even a rare mistake could expose quite many users in absolute numbers. Would rather have providers to check this out rather than have this poor practice abused by the next DNS hijacking malware affecting home routers. reply mikeocool 5 hours agoparentI wouldn’t hold my breath. As I recall a similar article appeared a few years ago, and the author called out a major SaaS provider as having this issue. The provider ultimately decided not to do anything about it, because it would break too many clients. If you make a breaking API change like this, some portion of clients are just never going to update. If you’re a usage-based billing SaaS provider, that means lost revenue. Likely the only way this issue is fixed widely is if it ends up on a security audit checklist. reply chrismorgan 16 hours agoprevnpm is misusing 426 Upgrade Required. https://httpwg.org/specs/rfc9110.html#status.426: > The server MUST send an Upgrade header field in a 426 response to indicate the required protocol(s) (Section 7.8). https://httpwg.org/specs/rfc9110.html#field.upgrade: > The Upgrade header field only applies to switching protocols on top of the existing connection; it cannot be used to switch the underlying connection (transport) protocol, nor to switch the existing communication to a different connection. For those purposes, it is more appropriate to use a 3xx (Redirection) response (Section 15.4). If you’re going to talk cleartext HTTP and issue a client error rather than redirecting, 403 Forbidden or 410 Gone are the two most clearly correct codes to use. Ignoring the mandated semantics and requirements of status codes is sadly not as rare as it should be. A few I’ve encountered more than once or twice: 401 Unauthorized without using WWW-Authenticate and Authorization; 405 Method Not Allowed without providing Allow; 412 Precondition Failed for business logic preconditions rather than HTTP preconditions; 417 Expectation Failed for something other than an Expect header. I think it only ever really happens with 4xx client errors. reply notpushkin 13 hours agoparentTLS is in fact a valid protocol to use in an Upgrade header: HTTP/1.1 426 Upgrade Required Upgrade: TLS/1.0, HTTP/1.1 Connection: Upgrade So you can use 426 Upgrade Required here, and I'd argue it's the most correct code to use in such a case. npm doesn't send the Upgrade header though, so that's a mistake. https://www.iana.org/assignments/http-upgrade-tokens/http-up... https://www.rfc-editor.org/rfc/rfc2817.html#section-4.2 reply chrismorgan 10 hours agorootparentThat’s something different: that’s for upgrading to TLS within the same connection. As in, approximately http://example.com/ → https://example.com:80/ (but without the URL’s scheme actually being allowed to change), whereas https://example.com/ is https://example.com:443/. I was only a child when RFC 2817 was published, but I’ve never heard of any software that supported it, other than the Internet Printing Protocol which can use it for ipp: URLs, kinda like SMTP has STARTTLS. As for the motivations of RFC 2817, they’re long obsolete: encryption should no longer be optional on these sorts of things so that the parallel secure port problem is gone (not sure when this became actual IETF policy, but I’m going to guess towards ten years ago), and the virtual hosting problem is solved by SNI (supported by everything that matters for well over a decade). reply Titan2189 15 hours agoparentprevHow is this not more upvoted? HTTP Code 426 sounds like the best code to send? reply fl0ki 4 hours agoprevThis makes sense, and I wondered for a moment why I hadn't noticed the issue in any of our projects. I realized it's because we just don't expose HTTP in the first place, whether for API or UI purposes. However, that doesn't mean there's no danger. I believe it's still possible for a client to leak its credentials if it makes a bare HTTP/1 call to an actual HTTPS endpoint. The server only gets a chance to reject its invalid TLS handshake after it's already sent headers that may contain sensitive information. After all, the TCP negotiation did go through, and the first layer 7 packet is the bare HTTP headers. Of course the port numbers should help here, but that's not guaranteed in an environment where port numbers are assigned dynamically and rely on service discovery. Serving exclusively HTTP/3 should close this gap but requires all clients to be ready for that. I know many internal deployments do this, but it's not a universal solution yet. reply amanzi 21 hours agoprevInteresting - I hadn't considered this before, but makes perfect sense. Feels like it's something that's easy to miss, as lots of APIs are hosted behind generic web application firewalls that often have automatic HTTPS redirection as a base rule. reply sdsd 22 hours agoprevMy personal website (darigo.su) doesn't have HTTPS. I just deployed it a few months ago and haven't really done much with it yet. I guess I'll have to get around to it eventually, but I find charm in small old sites that haven't implemented modern protocol stuff. My site also usesandtags all over the place. Maybe I'll do some more quirky anachronisms, like only serve the site via HTTP 1.0 or something. Who knows. Since my site has very little functionality, it doesn't really matter, it's just for fun. reply HL33tibCe7 20 hours agoparentTo me, HTTPS is worth it alone to eliminate the possibility of the ISPs of people reading my site from injecting shit (ads, trackers, etc.) into the responses I send to them. It’s completely trivial to set up, there’s really no downside at this point. reply samatman 2 hours agorootparentThis is the somewhat depressing but accurate answer. HTTPS doesn't mean you are communicating sensitive or private data, it means you want the client to see what you send them, and not something else. reply bruce511 14 hours agoparentprevI see this a lot. You've just made a small non-interactive site, and there's nothing secret. So why bother either https? Well, firstly, I'd say, make ot https for fun. It's pretty simple to do, makes itself automatic, and costs no money. Just exploring this route can be very illuminating. Secondly it prevents your site from being altered by the outside. There's a lot of equipment between your site and the client. Being HTTP allows it to be altered along the way. Gor example, and thd least serious, is that your ISP can inject adverts onto your page. Most ISPs don't do this, but quite a few do. Second, a malicious user could inject additional text onto upur pages, proclaiming your love for a political party, some racial or misogynistic slur, or whatever. Third, you're sending a signal to all that you either don't understand the security risks, or don't care about them. This can have consequences (reputationally) if you are in, or going into, a computing career. Making it HTTPS can be fun too! reply foobiekr 12 hours agorootparentThe bigger issue is that a malicious interceptor could inject javascript. The site may not use javascript, but the users almost certainly have it turned on, and accessing a non-https site means that any man in the middle can inject malicious javascript. HTTPS is about protecting the client. reply Thorrez 11 hours agorootparentE.g. China's great firewall sometimes inserts malicious Javascript that causes the client to launch a DDoS attack against Github or other sites China doesn't like. https://en.wikipedia.org/wiki/Great_Cannon reply noirscape 10 hours agorootparentprevHonestly, hard disagree. I get the push for HTTPS, but setting up HTTPS nowadays isn't fun. It's more or less 4 steps; 1. Install and run certbot (+the DNS plugin for your DNS provider). 2. Find an nginx config file on the internet that only includes the necessary ciphers to work on modern devices. Then include that config file + lines to your cert paths that certbot spits out into your nginx config. 3. Set up a generic redirect server block to send everything on port 80 to port 443. 4. Reboot nginx. It's at least better than fiddling with openssl directly, but this isn't fun, it's busywork. reply bruce511 5 hours agorootparentI'm not sure if you're being sarcastic here or not? I mean you listed \"reboot\" as a whole step... which suggests sarcasm (at least to me)... Anyway, all the steps together take what - all of 5 minutes? - that's if you do DNS Challenges. If you do HTTP challenges it doesn't even take that. So you're saying this 5 minutes isn't worth the effort? That it's somehow too hard? reply noirscape 4 hours agorootparentIt's worth the effort, I just wouldn't use the descriptor of it being \"fun\". It's busywork equivalent to pointing nginx at your PHP socket. It's not fun, you're just wrangling a config file until it does what you want and the modern browsing landscape disproportionately demands HTTPS everywhere even for sites that arguably aren't really helped by it. reply layer8 22 hours agoparentprevThat’s fine, but rather unrelated to the article, which is about the situation that you have an API served via HTTPS, and the question of whether you should also have a redirect from HTTP to HTTPS in that case, or rather return an HTTP error. reply sdsd 21 hours agorootparentYeah, I should have clarified. Nothing to do with the article really, just a random thought. Sorry if too off-topic! reply OJFord 19 hours agoparentprevWhen a user visits your site with a modern browser in default configuration they'll get an error page along the lines of: Secure site not available Most likely, the web site simply does not support HTTPS. However, it’s also possible that an attacker is involved. If you continue to the web site, you should not enter any sensitive info. If you continue, HTTPS-Only mode will be turned off temporarily for the site. [Continue to HTTP site] (Copied from Firefox on Android) Personally I think that's reason to do it alone, for the price of a free Let's Encrypt cert you can deliver much better UX. You presumably want people to visit your site. reply sdsd 19 hours agorootparent>When a user visits your site with a modern browser in default configuration they'll get an error page along the lines of: Neither desktop firefox nor chrome seem to do this by default, at least on my Mac (actually I think I'm wrong about Firefox on desktop as well, thanks to a guestbook signer!). Maybe it's a Firefox mobile thing, rather than a modernity thing? >for the price of a free Let's Encrypt cert you can deliver much better UX I'm going to get around to it, I promise haha. Btw if anyone does visit the site, please do sign my guestbook: http://darigo.su/33chan (but be warned, a MITM might intercept and alter your comment!!) reply prettymuchnoone 19 hours agorootparent> Neither desktop firefox nor chrome seem to do this by default they do, you probably just checked the \"i'm sure this is safe\" button posted a pic on the imageboard hehe reply sdsd 19 hours agorootparentThanks for visiting! Receiving guestbook comments is such a delight. Does Chrome also give you this warning on desktop? reply prettymuchnoone 18 hours agorootparentnope reply Aachen 22 hours agoparentprevI can appreciate this and also run a service that is neither meant to be commonly visited (imagine a tor exit node landing page explaining what this IP address is doing, but for a different service) nor will produce or ingest sensitive information For a personal website that people might commonly want to visit, though, consider the second point made in this other comment: https://news.ycombinator.com/item?id=40505294 (someone else mentioned this in the thread slightly sooner than me but I don't see it anymore) reply npsimons 18 hours agoparentprevHonestly, for public facing read-only websites, it's perfectly fine to redirect HTTP to HTTPS. There's just too many cases where you aren't going to get everyone to put \"https://\" on the front of URIs when they put them in docs, flyers, etc. You're lucky if you get \"http://\"! The API security thing, yes, that makes sense. Personally, I run a number of servers for small groups where the sensitive stuff is SSL only - you won't even get an error going to port 80, other than the eventual timeout. But for reasons above, I cannot just turn port 80 off, and it's perfectly safe redirecting to 443. reply cqqxo4zV46cp 21 hours agoparentprevA HTTP website presents an opportunity for an attacker to MITM a payload that is ultimately executed in a user’s browser. Beyond ‘getting a moustache tattoo on your finger’ quirkiness, HTTP-only websites are really inexcusable beyond some very niche cases. reply sdsd 21 hours agorootparent>Beyond ‘getting a moustache tattoo on your finger’ quirkiness In that case, seems totally worth it. I, like moustache finger tattoos, am aggressively opposed to worrying about being perceived as cool. I will just have to live with being inexcusable. reply valec 20 hours agorootparentprevnot my problem! reply jensenbox 4 hours agoprevAfter all this chatter, I am considering blocking all outgoing traffic to port 80 in my local firewall This would prevent my fat fingers from ever even making the mistake. BLOCK outgoing port 80 How bad would that be? Would I be shooting myself in the foot somehow? Perhaps I would do it on the egress rule for where my requesting service is running like in ECS. reply brobinson 3 hours agoparentIt would block requests to OCSP responders, for one. reply medellin 22 hours agoprevI fully support this and have always pushed for this. One because it becomes a huge mess to maintain over time but also because it long term will lower traffic through the LB. Unfortunately what i see happen all the time is quick fixes are pushed to the infra. For example they deploy and typo the URL. Now we have a prod outage and infra is pulled in to fix this asap. No time to wait for that 10 minute deploy pipeline that requires all the tests to run and a deploy to dev. This happens once and then infra is asked why we don’t already redirect all URLs. Management doesn’t care about security and they just lost money. Guess what you are doing now. This is the world we live in. reply blowski 22 hours agoparentIndeed. It’s probably why so many APIs accept the api key in the URL. reply barryrandall 21 hours agoprevI agree that APIs shouldn't automatically redirect HTTP to HTTPS, but I also think that client libraries shouldn't follow redirects by default. reply bradley13 2 hours agoprevhttps is great, and I'm glad most web traffic uses it. However, sometimes you want http. Example: when teaching low-level socket programming, plain http is the easiest place to start. Example: when providing simple, nonsensitive, read-only info via API, the overhead of https and certificate management seems unnecessary. reply tk90 2 hours agoprevIf you want to implement this in a AWS/ALB (Load Balancer) setup, you have to: - Remove the ALB's HTTP listener - Remove port 80 from the ALB's security group reply lxgr 22 hours agoprevCompletely agree, and arguably why stop at API servers? Depending on server-side HTTP -> HTTPS redirects for security reinforces/rewards bad practices (linking to HTTP, users directly entering HTTP etc.), in a way that makes users vulnerable to one of the few remaining attack vectors of \"scary public Wi-Fis\". reply nimih 22 hours agoparent> arguably why stop at API servers? I think this is pretty convincingly argued in TFA, honestly: modern browsers understand and respect HSTS headers, maintain enough local state that such headers are meaningful, and HSTS preloading is easy enough to set up that it should be achievable by most website operators. Furthermore, it is actually quite hard to concoct a scenario where a user clicking an HTTP link and getting immediately redirected constitutes a danger to their security: unlike with API endpoints, people clicking links (and in particular, links which were typed out by hand, which is how you get the HTTP protocol in the first place) are generally not making requests that contain sensitive information (with the exception of cookies, but I would argue that getting someone to have a sane configuration for their cookies and HSTS headers is a far easier ask than telling them to stop responding to all port 80 traffic). reply Aachen 22 hours agoparentprevWe are. Slowly, due to lots of legacy, but surely getting there. See the small steps over the years where it was first an add-on to force https-only mode (HttpsEverywhere, 2011), then browsers started showing insecure symbols for http connections (e.g. in 2019: https://blog.mozilla.org/security/2019/10/15/improved-securi...), and more recently I think browsers are starting to try https before http when you don't specify the protocol. I've also seen a mention of strict https mode or something, not sure if that's a private navigation feature or something yet to come, but warning screens equivalent to insecure certificate pages are getting there reply Dylan16807 21 hours agorootparentChrome's version of trying https first sure is annoying though. If a site is down entirely, when chrome can't connect to port 443 it confidently declares that \"the connection is not secure because this site does not support https\" and gives a \"continue\" button. Then when you click \"continue\" nothing happens for a while before it finally admits there's nothing responding at all. So it gives a misleading error and takes longer to figure out if a site is actually down. reply plorkyeran 18 hours agorootparentI have never seen this happen in Chrome. I just tried it to make sure I wasn't crazy and it did indeed go straight to telling my that the connection timed out without showing a security error first. reply hirsin 14 hours agorootparentprevThis is only enabled for a small percent of people at random, otherwise just folks in the advanced protection program. reply jraph 21 hours agorootparentprevI'm highly surprised by this. It seems very dumb and I have never seen anything like this, though I never use Chrome and very rarely fire Chromium for testing something. Is there something to read about this, like a dev ticket? reply Dylan16807 21 hours agorootparentThere might be but I'm not aware of any tickets. But if you open chrome and navigate to 192.168.20.20 you should see it. Or any domain that resolves to a non-responsive IP, if you have one in mind. reply jraph 7 hours agorootparentJust tried on Chromium, I get ERR_ADDRESS_UNREACHABLE as I would expect. reply o11c 20 hours agorootparentprevFirefox has a similar bug, but for DNS rather than connection. reply bigstrat2003 21 hours agoparentprevThe push for \"TLS all the things\" was already a massive overreach that actively made security worse overall, because it further ingrained the user tendency to click through scary browser warnings (all for the sake of encrypting things that were fine in plaintext). And you want to go even further? No thank you. reply lxgr 19 hours agorootparentWhat scary browser warnings do you regularly get when visiting HTTPS sites? It’s also not just about avoiding transmitting HTML etc. in plaintext; somebody being able to inject arbitrary scripts into sites you otherwise trust is bad as well. But as I've said above, I think the HTTP -> HTTPS redirect should have never happened at the HTTP level. If we'd done it in DNS or at least as a new HTTP header (\"optional TLS available\" or whatnot), we could have avoided locking out legacy clients. reply zzo38computer 12 hours agorootparentScripts other than those that the user had specifically allowed, can also be a problem, whether or not it is with TLS. With TLS, only the server operator can add malicious scripts; without TLS, spies can also do so; either way, it can do so. Specifying availability of TLS (and, perhaps, which ciphers are usable, in order to avoid the use of insecure ciphers) by DNS would do, if you can (at the client's option) acquire DNS records securely and can know that they have not been tampered with (including by removing parts of them). (This is independent of whether it is HTTP or other protocols that can optionally use TLS.) (Actually, I think that using DNS in this way, would also solve \"Gopher with TLS\"; the format of gopher menus makes it difficult to use TLS, but knowing if TLS is available by looking at DNS records would make it work. Gopher servers can still accept non-TLS requests without a problem, if none of the valid selector strings on that server begin with character code 0x16 (which is always the first byte of any TLS connection, and is very unlikely to be a part of any Gopher selector string).) It would also help to make cookies unable to cross between secure and insecure connections in either direction (always, rather than needing a \"secure cookies\" flag). reply UncleMeat 6 hours agorootparentIf you are saying that people click through certificate warnings then people definitely would just permit whatever script. The number of people who will say \"yeah its okay that this is a self-signed cert\" and also say \"no, I have a strict allowlist of verified scripts from this server that I allow to run\" is miniscule. reply tomsmeding 20 hours agorootparentprev> because it further ingrained the user tendency to click through scary browser warnings (all for the sake of encrypting things that were fine in plaintext). Why should there be more scary warnings when more websites use TLS? Sure, you get more scary warnings if you set your browser to \"warn if it's http\", but then you're asking for it. reply xboxnolifes 20 hours agorootparent> Sure, you get more scary warnings if you set your browser to \"warn if it's http\", but then you're asking for it. Defaults. They matter. reply xvector 12 hours agorootparentprev> all for the sake of encrypting things that were fine in plaintext What was fine in plaintext? reply jagger27 8 hours agorootparentWho cares how many of the n-dozen routers and switches between you and your favourite blog got to inject a few tags for your convenience? Encryption is for more than secrecy, folks. reply dramm 19 hours agoprevYes, great article. And now can we convince folks with http+https websites to shut down http access and only offer https. I've seen simple mistakes like only partial redirects happening. Large numbers of internal links that still go to the http site, and some of those not redirect, etc. (you would think they are simple to find and just clean up), etc. And it is frustrating when sites like some online forums may be interesting targets for password theft. reply tgma 11 hours agoprevIf you are paying the cost of a TLS handshake, which you will have to anyway, why not just use client certificates to authenticate (mTLS) instead of hand rolled and rudimentary auth tokens on top. gRPC has built-in support for mTLS and it could be a good time to modernize your endpoints if you are looking to invest time to improve your API security. reply andrewaylett 20 hours agoprevI've stopped opening port 80 at all for some of my web services. The parent domain is in the HSTS preload list, so no modern browser should ever be trying to connect to port 80. And (as the fine article intimates) API calls shouldn't be available on port 80 anyway. reply akira2501 22 hours agoprev> Servers can now send HSTS along with the initial HTTP-to-HTTPS redirection response > Node.js's built-in fetch happily and quietly followed those redirects to the HTTPS endpoint. Okay.. does nodejs fetch respect HSTS? reply NewJazz 22 hours agoparentI'm not aware of any general programming language http clients that honor HSTS. reply pzmarzly 21 hours agorootparentlibcurl supports HSTS, but the client has to specify a file where the state should be stored https://curl.se/docs/hsts.html Many languages/libraries use libcurl in some shape or form, but whether they set up an on-disk HSTS store or not - I don't know either. reply Aachen 22 hours agoparentprevI'm not even sure I'd find it desirable for nodejs fetch() to quietly store state somewhere on my server without asking me: I wouldn't know to back that file up, it may be trashed regularly depending on the infrastructure, it could mess with version control by creating a local working directory change, or it might run into an error condition if it is on a read-only filesystem (either crashing or being unable to use this security feature, neither is great). Config file writes are to be expected for user-facing software, but for developers it should error out so they can just choose what it needs to do E.g., \"Error: HSTS response received after a redirect from HTTP, but no storage location specified for security states. Use the https:// protocol, specify a file location, or set insecure_ignore_hsts=true.\" Edit: but it's a very legitimate question?! Just saw you got downvoted, I have no idea why reply hn_throwaway_99 22 hours agorootparentI think the original question \"Okay.. does nodejs fetch respect HSTS?\" goes into the \"not even wrong\" bucket, for the reasons you point out. HSTS really only makes sense from a browser perspective (or, rather, a \"permanently installed, stateful client\" perspective). For an API like fetch it doesn't even make sense as a question IMO. reply Aachen 22 hours agorootparentI would say it does make sense as a nice upgrade path for services that don't yet support https but you'd like to switch as soon as they enable it, or if you're forgetful or lazy and didn't type https:// in front of the link you were given or so Whether that's still common enough to warrant the extra complexity in the fetch function is not something I'm qualified to judge reply moralestapia 22 hours agorootparentprev>For an API like fetch it doesn't even make sense as a question IMO. Why not? reply hn_throwaway_99 22 hours agorootparentBecause the way HSTS works fundamentally implies a stateful client, and because it was fundamentally created to solve a human problem (i.e. humans entering in URLs directly in the address bar). It really doesn't make sense with a non-stateful client, and it isn't intended for cases where someone isn't manually entering in the URL to hit. E.g. fetch is often loaded in transient situations - it really shouldn't be updating its own config because of responses it gets. Also, based on the other comment I was originally thinking it would be good if fetch would just error out if it gets a redirect from http -> https AND also a Strict-Transport-Security header, but in that case it would still mean it was dependent on the server setting up the STS header, and if they could do that they should just go ahead and get rid of the http -> https redirect in the first place. reply moralestapia 21 hours agorootparentI agree with you on things like CORS, but HSTS would actually solve the problem stated in this thread quite gracefully. Client fetches http, notices the header, retries https then ... ok no, lol. But I guess it's still of some use to let clients know \"this should always happen through https\" and make them fail if that's not the case. Edit: yeah I got it, client fetches http, notices the header and then explicitly fails because HSTS is there. reply moralestapia 22 hours agorootparentprev>Just saw you got downvoted, I have no idea why I've noticed a gradual increase in this behavior during the past ... year maybe? I think for a lot of new people, downvoting equates disagreeing, which is not ideal. Although, I also have no idea why someone would disagree with a neutral question like GPs, lol. Hopefully, it's not the beginning of the end for HN as it is a great website. reply iJohnDoe 22 hours agorootparentThese types of downvotes also discourage discussions. I’ll upvote a comment when it has been downvoted if it has a constructive discussion thread. reply g15jv2dp 22 hours agoparentprevHow would that even work? It's up to the developer to consider the response and act correctly on it. reply akira2501 20 hours agorootparentSo if you occasionally forget and use http when you meant https and are worried about the consequences of that, you should just implement your own HSTS checking layer? Why not just implement your own fetch wrapper that throws if it's not an https connection? reply g15jv2dp 12 hours agorootparent> So if you occasionally forget and use http when you meant https and are worried about the consequences of that, you should just implement your own HSTS checking layer? Or use a library to do it. The core fetch functionality shouldn't have to deal with HSTS. There may be legitimate reasons to fetch over HTTP even after you received an HSTS header - for testing purposes, for example. > Why not just implement your own fetch wrapper that throws if it's not an https connection? That's the developer dealing with HSTS. reply Aachen 22 hours agorootparentprevSame way as TLS session resumption can be handled by libraries without you having to touch it, or perhaps requiring you to specify a storage file and taking it from there reply andersa 22 hours agorootparentprevJust do it like a web browser - when you install Chrome it comes with a list of many tens of thousands of domains that had HSTS set when GoogleBot visited it. reply ac130kz 14 hours agoprevThere is a limited number of cases, where unencrypted http is still applicable, e.g. verifiable packages. In general though, it feels wrong even to think about putting such a glaring useless hole. reply croes 21 hours agoprevMaybe shttp would have been better than https to reduce typo errors or maybe even something completely different from http. reply jimbobthrowawy 13 hours agoparentI'm sure it was added to the end following a pattern of other protocols doing the same for their ssl-wrapped version. Right now, shttp reads like http over ssh to me. reply toomim 21 hours agoparentprevAh... you know, that idea sounds not too shtty to me. reply kgeist 13 hours agoprevI think a good approach would be for developers to always use a custom HTTPClient class which throws an error if HTTP is used. I.e. you MUST opt in to use HTTP. reply tonymet 14 hours agoprevYou can’t make this decision until you know how many customers are on http and how lucrative they are . Breaking an API because you read a blog post is a bad idea reply notpushkin 13 hours agoparentYou can only do it for new customers, though. Just save the list of API keys used over HTTP, then whitelist those who earn more than $xxx/year. Then you can work with those customers to help them upgrade their clients to HTTPS. reply smashface 3 hours agoprevHeadline reads like a hot take. Actual recommendation is rather useful. Click-bait used for good. reply winddude 22 hours agoprevThat's an excellent point, and definitely something I've done without thinking about it. I'm going to stop, and disable those. Thanks! reply eddd-ddde 22 hours agoprevNow that I think about it, interfaces such as Js fetch should make it an error to use http without explicitly allowing in an option. It seems to easy to make an error and end up in a situation like the post explains. reply smaudet 21 hours agoparentHmm. I think, perhaps, release versions should need this, without a flag. For testing/prototyping, it is invaluable to turn off all the security to rule out security misconfiguration instead of application error. If your API is non-sensitive/relies on out of band security (like large files with checksums), you may still not want https, so there should be some configuration to turn it off. And for \"integrations\" like jsdelivr, perhaps https libraries should follow this rule, while http ones can have the flag off... Then, if you mix the two (http and https) perhaps they can provide an noticeable alert to the user rather than failing silently... reply usrbinbash 10 hours agoprev> and revoke API keys sent over the unencrypted connection. Excuse me, short question: If I am not offering a non-TLS endpoint in the first place, and the client, for some reason, decides to take something that is literally called \"SECRET\", and decides to shout it across the open internet unencrypted... ...how is that my problem again? Why should my setup be more complex than it needs to be, to make up for an obvious mistake made by the client? reply zeeb0t 16 hours agoprevHard to argue against this. reply GauntletWizard 22 hours agoprevI do redirect APIs to HTTPS, but I'd prefer not to. There's a simple reason - My APIs are hosted on the same IP as the public website, behind the same load balancer, so something has to be on the HTTP port. I would prefer to separate them, and my larger customers do - But for smaller customers, it's an unnecessary added expense and complication that doesn't make sense. reply victorbjorklund 19 hours agoprevMakes sense. reply zzo38computer 13 hours agoprevI think that it would be better to allow both as much as possible. One way to handle authentication is to use HMAC; you can do that even without needing TLS (and HMAC won't leak the keys if one of the systems (e.g. a reverse proxy or something else) is compromised). If you do not want to do that, then don't accept connections on port 80, at least when version 6 internet is being used. (For version 4 internet, it is possible that you might use the same IP address for domain names that do want to accept connections on port 80, so you cannot easily block them in such a case.) And, if you want to avoid compromising authentication data, then TLS is not good enough anyways. The client will need to know that the server certificates have not been compromised. HMAC will avoid that problem, even without TLS. There is also the payload data. TLS will encrypt that, but the URL will be unencrypted if TLS is not used, whether or not the API key is revoked; the URL and headers may contain stuff other than API keys. Some APIs also might not need keys; e.g. read-only functions for public data often should not need any kind of API keys (and should not have mandatory TLS either, although allowing optional TLS is helpful, since it does provide some security, even though it doesn't solve everything). HSTS is even worse. TLS prevents spies from reading and tampering with your messages, but does not prevent the server from doing so (although in this case it might be unimportant, depending on the specific file being accessed). It also is complicated and wastes energy, and there are sometimes security vulnerabilities in some implementations so does not necessarily improve security. Of course, these ideas will not, by itself, improve security, and neither will TLS; their combination also won't do. You will have to be more careful to actually improve security properly. Some people think that, if you add TLS and HTTPS, and insist on using it, then it is secure. Well, it is very wrong!!! TLS will improve security in some ways as described in the previous paragraph, but does not solve everything. It is also problematic if a client does not have an option to disable TLS (or use unencrypted proxies), since if you deliberately want to do MITM on your own computer, you will then have to effectively decrypt and encrypt the data twice. (If the client uses TLS by default, that would work, although if it is according to the URL then it might be by the configurable URL instead; however, the URLs do not always come from the configuration file, and even if it does, and if you want to avoid typographical errors (although even if \"https\" is specified, typographical errors are still possible (e.g. in the domain name), so just checking for \"https\" won't even necessarily help anyways; specifying what certificates to expect might sometimes help), then you might have your program to display a warning message, perhaps.) Another problem is if the client and server require different versions of TLS and it is difficult to change the software (there are reasons you might want to change only some parts of it, and that can be difficult); using a local unencrypted proxy which connects to the server using TLS, can also avoid problems like this, too. reply kccqzy 13 hours agoparentHMAC is a fine suggestion but let's be practical. These days you can tell a junior engineer to go use TLS, but you can't tell a junior engineer to implement HMAC to sign API requests. > The client will need to know that the server certificates have not been compromised. HMAC will avoid that problem, even without TLS. HMAC doesn't solve the problem: the client still doesn't know that the shared key isn't compromised. What does it even mean for either a client or server to know something is compromised? If Alice and Bob have a shared key, what can they do to ensure Mallory doesn't also have the shared key? reply zzo38computer 13 hours agorootparent> the client still doesn't know that the shared key isn't compromised. What does it even mean for either a client or server to know something is compromised? If Alice and Bob have a shared key, what can they do to ensure Mallory doesn't also have the shared key? Of course, that is true, but TLS doesn't help with that, either. However, if a reverse proxy (especially if run by a third party) or something else like that is compromised, then HMAC won't allow you to compromise the shared key if the reverse proxy does not know the shared key (unless they can somehow trick the server into revealing it, but that is a separate issue). An additional issue arises if it is compromised even before the client receives the key for the first time, if it is sent using the same communication channels; in that case, of course neither TLS nor HMAC will help (although certificate revocation may do in this case, but some other method will then be needed to be able to correctly trust the new certificate). However, different services may require different levels of security (sometimes, hiding the key isn't enough; and, sometimes, encrypting the data isn't enough). How you will handle that depends on what security you require. reply superkuh 22 hours agoprevOr better: actually provide the API on HTTP and HTTPS if your use case allows it (ie, non-commercial/institutional, just something for human people). reply x86a 22 hours agoparentI don't think this is ever a good idea. Even for non-enterprise use cases, you wouldn't want some public hotspot to be able to inject random garbage into responses, even if not done with malicious intent. reply smaudet 21 hours agorootparent> Even for non-enterprise use cases I don't think non-enterprise, non machine use cases should be automatically handles, though. Attempting client upgrade is better than not, but we should be more clear about whether our devices are acting safely, i.e. calling out the change, and in the case of http local usage, reminding to use visible, out of band verification methods. Of course this only works if the default is secure, but I am glad that browser still let me go unencrypted when I really need to, I prefer the giant warning banners... reply Wowfunhappy 21 hours agorootparentprev• It allows retro computers to connect. • It allows very low power embedded devices to connect without extra overhead. • It's not a real security concern if you're on a private network. reply rascul 21 hours agorootparent> • It's not a real security concern if you're on a private network. I'm not convinced that private networks should be assumed secure by default. reply TeMPOraL 21 hours agorootparentIt's definitely not improving security when, in order for a website to interact with an API that both are hosted on my private network, possibly even on the same machine, I need to set up publicly accessible DNS entries and/or hosting my own resolver. That and CORS makes local-first anything a huge PITA. reply Jach 18 hours agorootparentprevI setup a photo viewing web service running locally on my home computer, now I can access my photos over HTTP from my phone when I'm out and about. Both devices are on the same Tailscale network. If I can't trust in the security of that, HTTPS isn't going to help me, and the security of viewing my photos is the least of my concerns. But sure, in other contexts (like an enterprise company), some thought should be given to what's possible when the attacker is inside the corporate VPN since that's all too easy. reply Control8894 20 hours agorootparentprevPerhaps, but the other realistic option is a self-signed cert. Since browsers refuse to implement any kind of TOFU or otherwise 'trust history', a self-signed cert is pretty much exactly equivalent to no TLS at all. reply justin_oaks 22 hours agoparentprevI'll disagree on these grounds: 1) HTTP can be modified by a man in the middle 2) It's better to default to requests and responses being private, even if you're only using a non-commercial/institutional service. You could say \"The person chose to send requests to HTTP instead of HTTPS\" and assume that the consumer of the API didn't care about privacy but, as the article points out, it's easy to typo http instead of https. reply codepoet80 22 hours agoparentprevYou’ve already been shouted down, but thank you for daring to suggest this. I maintain APIs and proxies for APIs for legacy devices, and will continue to suggest that some kinds of APIs remain appropriate for HTTP access. Never do your banking this way, obviously, but where is the harm in allowing older devices to access content in a read-only fashion? reply taftster 21 hours agorootparentHypothetically speaking, plain HTTP transport even for \"read only\" content, can be a problem if it can be manipulated in transit. Let's take a weather service. Seems like weather information is a read-only immutable fact and should not be something that needs protection from MITM attacks. You want to reach the largest audience possible and your authoritative weather information is used throughout the world. One day, an intermediary system is hijacked which carries your traffic, and your weather information can be rewritten in transit. Your credibility for providing outstanding data is compromised when you start serving up weather information that predicts sunny skies when a tornado watch is in effect. Additionally, you have now leaked information related to the traffic of your users. Even if the request is just vanilla HTTP-only, an adversary can see that your users from one region are interested in the weather and can start building a map of that traffic. They also inject a javascript payload into your traffic that starts computing bitcoin hashes and you are blamed for spreading malware. In general, HTTPS protects both your interests and those of your users, even for benign data that doesn't necessarily need to sit behind \"an account\" or a \"web login\". reply jkrejcha 20 hours agorootparent> Additionally, you have now leaked information related to the traffic of your users. Even if the request is just vanilla HTTP-only, an adversary can see that your users from one region are interested in the weather and can start building a map of that traffic. One thing to note is that nothing about HTTPS protects against this type of attack. Assuming your API doesn't have much else going on (most services, probably), an adversary can easily see that you visited mycoolweatherapi.example regardless of if HTTPS is being used or not. What TLS protects is higher on the network layer cake reply Control8894 20 hours agorootparentprev> One day, an intermediary system is hijacked which carries your traffic, and your weather information can be rewritten in transit. Your credibility for providing outstanding data is compromised when you start serving up weather information that predicts sunny skies when a tornado watch is in effect. Why would they want to do that? Is your weatherman always right? > Additionally, you have now leaked information related to the traffic of your users. Even if the request is just vanilla HTTP-only, an adversary can see that your users from one region are interested in the weather and can start building a map of that traffic. Ah, yes, people are interested in the weather. Wow! Of course, they could get the same info from observing that users are connecting to the IP address of a weather API provider. > They also inject a javascript payload into your traffic that starts computing bitcoin hashes and you are blamed for spreading malware. Got there eventually. Crappy ISPs. reply taftster 18 hours agorootparentI mean, weather was just an arbitrary and silly made up example. You're reading it a bit too literally there. reply smaudet 20 hours agorootparentprev> an adversary can see that your users from one region are interested in the weather and can start building a map of that traffic I think this is the most convincing argument, but, I think that some data doesn't care if it is not confidential. The weather is perhaps more pointed, but I think for large protected binaries (either executable or inscrutable, e.g. encrypted or sig protected archives), its a bit moot and possibly only worse performing. However, also remember that https does not protect all data, just the application portion - adversaries can still see, map, and measure traffic to bobthebaker.com and sallyswidgets.biz. To truly protect that information, https is the wrong protocol, you need something like Tor or similar bit mixing. reply ozim 22 hours agoparentprevThat is an awful idea - in post Snowden world you encrypt all traffic period. Then you have post Jia Tan world - if there is even slightest remote possibility, you just don't want to be exposed. Just like washing hands after peeing, just do HTTPS and don't argue. reply bigstrat2003 20 hours agorootparentDogma is how religion works, not engineering. If someone doesn't believe the benefit is worth the cost, they can and should question the practice. Blind obedience to a dogma of \"just do HTTPS\" is not a reasonable approach. reply HL33tibCe7 20 hours agorootparent“Rules of thumb” form many of the fundamental tenets of engineering practice. Using HTTPS everywhere is one such rule of thumb. It’s just not worth expending the mental energy considering every single edge case (while likely forgetting about some) in order to try and work out whether you can cut the corner to use HTTP rather than HTTPS, when using HTTPS is so easy. reply ozim 12 hours agorootparentprevYou cannot call out something dogma if you don’t understand reasons. Injecting ads by ISPs into http is documented and known - they can inject anything on transit of HTTP it can be done automatically and basically with 0 cost. ISP is one the other all kind of free WiFi. It is not only “NSA will get me” or only financial transactions. There are new known exploits in browsers and systems found on daily basis. So reasoning is someone has to be of interest - not true because it is cheap and automated tls is making cost higher for simply scooping stuff. reply superkuh 21 hours agorootparentprevIf that's your threat model then CA TLS is going to make things even worse for you because now the nation state pressure can be centralized and directed through the CA. There are trade-offs but HTTP has it's place. HTTP is far easier to set up, more robust, far more decentralized, supports far more other software, and has a longer lifetime. For humans who aren't dealing with nation state threat models those attributes make it very attractive and useful. We should not cargo cult the requirements for a multi-national business that does monetary transactions and sends private information with a website run by a human person for recreation and other humans. There is more to the web than commerce and we should design for human persons as well as corporate persons. reply ozim 4 hours agorootparentWere you familiar with Snowden revelations? How NSA was just putting gear in ISPs or nodes where are internet gateways to pass all traffic through their automated tooling? It was not monetary or business it is not “threat model” thing. Having all traffic encrypted is a must for basic human freedom. reply superkuh 3 hours agorootparentIt is a human freedom thing. Having to get continued permission to host a visit-able website from a CA is very un-free. That's why HTTP+HTTPS is so good. The best of both worlds with the downsides of neither. Passive massive surveillance is by definition not doing active MITM targeting. reply cqqxo4zV46cp 21 hours agoparentprevHow is this better in literally any way other than it makes things (in 2024, only very slightly) easier from an ops perspective, and panders to some nerdy fetish for simple ‘read it over wireshark’ protocols? HTTPS-only should be the default. Plain-text information delivery protocols that can easily be MITMd are unsuitable for almost all uses. This just feels like contrarianism. reply superkuh 6 hours agorootparentI guess I have to respond with the same thing over and over because there are so many people saying the same thing without reading the replies. HTTP is better because: it lasts forever without mantainence, it's easier to learn set up with no third parties required, all software can access a HTTP website, it's low resource requirements, and HTTP+HTTPS is perfectly fine. Whereas CA TLS only lasts a year or two without mantainence, is so complex to set up and keep running that a literal ecosystem of programs (acme, acme2, etc) exist to hide that complexity, only software within the last ~few years can access CA TLS websites because of TLS version sunsetting and root cert expirations and the like, and everyone centralizing in the same CA makes it extremely easy to apply political/social pressures for censorship in a CA TLS only browser world. Additionally requiring third party participating to set up a website makes it harder for people to learn how to run their own and it requires more compute resources. CA TLS only feels like it should be \"required\" when the person can't imagine a web browser that doesn't automatically run all untrusted code sent to it. When the only types of websites the person can image are commercial or institutional rather than personal and the person believes all the web should cargo cult the requirements of commerce. Personal websites involving no monetary or private information transactions don't actually need to worry about targeted MITM and there's no such thing as open wireless access points anymore. reply moralestapia 22 hours agoparentprevNo, HTTP would expose any sensitive information. It's just clear text. reply iJohnDoe 22 hours agorootparentDoes HTTPS also hide the URL request in most logging systems? You can always see the domain (api.example.com) but you cannot see the URL? The benefit being it hides an API key if included in the URL? reply Aachen 22 hours agorootparentThe benefit is that it: 1. hides any private information anywhere in the request, URL or otherwise, API key or otherwise. Maybe you're fine if someone knows you used Bing (revealed through DNS lookups), but not what query you entered (encrypted to be decryptable only by Bing servers). An API key is obviously secret but something as oft-innocuous as search queries can also be private. 2. disallows someone on the network path from injecting extra content into the page. This can be an ISP inserting ads or tracking (mobile carriers have been playing with extra HTTP headers containing an identifier for you for advertising reasons iirc) or a local Machine-in-the-Middle attack where someone is trying to attack another website you've visited that used https. reply yjftsjthsd-h 22 hours agorootparentprevYes, it hides the URL, although sadly not the domain. reply taftster 21 hours agorootparentIt hides the domain too, in the literal HTTP request. What it doesn't hide is the DNS lookup for that domain. You still have to translate a hostname into an IP address. This might be a concern for certain uses. But at least it's on another port and protocol and not directly related to the HTTP request itself. reply yjftsjthsd-h 21 hours agorootparentNo, HTTPS has the domain in plaintext. There is a plan to fix this (Encrypted Client Hello), but AFAIK it's not widely used yet. reply taftster 20 hours agorootparentAh yes, apologies. Again, it's not strictly part of the HTTP request, but part of the TLS handshake around it. And only part of the TLS handshake as part of SNI, if supported (which is true by default). > \"Server Name Indication payload is not encrypted, thus the hostname of the server the client tries to connect to is visible to a passive eavesdropper.\" https://en.wikipedia.org/wiki/Server_Name_Indication So you're right, this is more aligned to the HTTP request than the DNS resolution of hostname that I mentioned. Strictly speaking, it's not part of HTTP per se (it's part of TLS), but still, it's in the same request in the most common definition, as you are saying. reply iJohnDoe 22 hours agoprevSort of off-topic. What is a recommended way to sell access to a one-off data API? Low code method to control access and facilitate payment? reply Aachen 22 hours agoparentAs in, selling API keys? Not sure what you're asking for. Are you looking for a webshop that has API key sales as a default item type or something? reply iJohnDoe 22 hours agorootparentYes, more like a SaaS. Maybe a solution that is tailored to selling API access. Generates a unique URL to the user, or API key, after they sign up for the API service. reply 25 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "HTTP-to-HTTPS redirection can expose sensitive data or enable Man-In-The-Middle (MITM) attacks, especially for APIs accessed by software that may not handle security headers.",
      "Techniques like HSTS (HTTP Strict Transport Security) and HTTPS-Only modes improve security but may not be sufficient for APIs, highlighting the need for a fail-fast approach to catch errors early.",
      "Best practices should be updated to recommend that APIs reject unencrypted requests entirely and revoke API credentials sent over unencrypted connections to prevent security risks."
    ],
    "commentSummary": [
      "The discussion emphasizes enhancing API security by redirecting HTTP to HTTPS and revoking API keys sent over HTTP to prevent Man-in-the-Middle (MITM) attacks.",
      "It highlights the importance of proper API key management, using signed hashes, nonces, and timestamps for authentication, and the necessity of HTTPS for data integrity and privacy.",
      "The conversation critiques the reliance on Certificate Authorities and suggests practical solutions like unique URLs or API keys for secure access control in specific contexts."
    ],
    "points": 626,
    "commentCount": 276,
    "retryCount": 0,
    "time": 1716925354
  },
  {
    "id": 40505099,
    "title": "Llama3-V: A $500 Multimodal Model Rivals GPT-4V in Performance",
    "originLink": "https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee",
    "originBody": "Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars Aksh Garg · Follow 7 min read · 1 day ago -- Overview Llama3 took the world by storm, outperforming GPT3.5 in almost all benchmarks and GPT4 on several. And then GPT4o came out, reclaiming the throne with its multimodal finesse. Today, we’re releasing something to change that: Llama3-V, the first-ever multimodal model built on top of Llama3. As a bonus, we train everything in under $500. How are the benchmarks you ask? We’ll let the tables speak for themselves. We have a 10–20% boost over Llava, the current SOTA and most popular model for multimodal understanding. Additionally, we fair very comparably to the closed source models of 100x the size on all metrics except MMMU. Check us out on: • 🤗: https://huggingface.co/mustafaaljadery/llama3v/ • Github: https://github.com/mustafaaljadery/llama3v The rest of the article covers Model Architecture Training Framework Systems Optimizations Summary Model Architecture The bulk of our engineering efforts go into making Llama3 understand visual information. To do so, we take an input image and embed it into a series of patch embeddings using the SigLIP model. These embeddings are then aligned with the textual tokens via a projection block, which applies two self-attention blocks to put the textual and visual embeddings in the same plane. Finally, the visual tokens from the projection block are prepended to the textual tokens and the joint representation is passed into Llama3, just as it normally would. Llama3-V Architecture: We use SigLIP to embed our input image in patches. Then we train a projection block with two self-attention blocks to align our textual and visual tokens. The diagram above illustrates at a high-level how everything works. Now, let’s dive into each stage in detail. SigLIP: SigLIP (Sigmoid Loss for Language Image Pre-Training) is an image embedding model that is similar to CLIP as we see in the figure below. However, unlike CLIP which uses a contrastive loss with softmax normalization, SigLIP utilizes a pairwise sigmoid loss, which allows the model to operate independently on each image-text pair, without requiring a global view across all pairs in a batch. At a high-level, SigLIP’s vision encoder splits the image into a sequence of non-overlapping image patches and projects them into a lower-dimensional linear embedding space, producing a sequence of patch embeddings. These patch embeddings then go through a vision encoder, which applies self-attention to capture long-range dependencies and extract higher-level visual features. For our purposes, we directly use the original SigLIP model trained by Google DeepMind. Illustration of how SigLIP embeddings work. We train an image and text decoder concurrently but in our case the text encoding module is kept fixed. Unlike CLIP, we minimize a sigmoid loss instead of a softmax loss but most other things stay the same. Image from twitter post by Merve Alignment with textual embeddings: To save computational resources, we keep SigLIP fixed. However, to align the output image embeddings with the textual embeddings used in Llama3, we use an extra projection module. Unlike Llava, which applies a single linear layer to the original image embeddings, we instead train two self-attention blocks to better capture patterns in the input embeddings, producing the final image embedding vector. Prepending image tokens: For the textual inputs, we first tokenize the text using a Byte Pair Encoding (BPE) vocabulary, producing a sequence of textual tokens. We demarcate these tokens by enclosing them within specialandtags. As for the image embeddings from the projection block, we treat each vector as a separate “visual token” and demarcate them usingandtags. Finally, we prepend the sequence of visual tokens to the sequence of textual tokens, forming the joint input representation that is passed into Llama3 for processing. Inference Optimizations Training these models is expensive. To optimize for computation resources, we make two major optimizations. The first is a simple caching mechanism and the second is on the MPS/MLX front. Caching: The SigLIP model is much smaller than Llama3. Therefore, if we run everything serially, we have very little GPU utilization when SigLIP is running. Moreover, we can’t push the utilization up by increasing the batch size up on SigLIP as then Llama runs into OOM errors. Instead we observed that our SigLIP model stays the same and instead pre-compute the image embeddings. Then, for both pre-training and SFT, we directly pass in these precomputed image embeddings instead of re-running the SigLIP module. Not only does this allow us to increase the batch size and maximally use our GPUs for running the SigLIP modules, it also saves us training/inference time as the two parts of the pipeline can occur separately. MPS/MLX Optimizations: Our second optimization was again driven by SigLIP’s smaller size relative to Llama. Specifically, since SigLIP fit on our Macbooks, we ran inference on an MPS optimized SigLIP model, which allowed us to attain a throughput of 32 images/second — allowing our caching step happen relatively quickly. How it was trained Precompute the embeddings from SigLIP: let’s now dive into the first step of our pre-training process: precomputing the image embeddings via SigLIP. In this step, our goal is to essentially pass in images into the SigLIP embedding model to obtain a vector representation or embedding of the image. One technical detail: due to higher resolutions, we follow the approach taken by LLaVA-UHD and perform image-splitting. The purpose of image-splitting is to divide the image into variable-sized patches or segments for more efficient encoding. These split images are processed concurrently in batches. Now let’s dive into how exactly we use the SigLIP embedding. We first load the SigLIP model and processor/tokenizer. We then preprocess the provided input image using the processor. We then pass the preprocessed image to the model. Following this, the model outputs logits for the image-text pairs. We now proceed to apply the sigmoid activation function to the logits to get the probabilities. We now see that the image embedding is contained within these probabilities. So far this embedding captures the visual information in the image. Following the computation of the image embedding via SigLIP, we now proceed to learn a projection matrix — you can also think of this as the projection layer, which is typically a linear or feed-forward layer. As described above in the ingredients section, the projection layer maps the vision embedding from its original space into a joint multimodal embedding space. Specifically, the projection layer applies a learned weight matrix W_v to the vision embedding v to get the projected multimodal vision embedding W_v * v. So after this projection step, the vision and text embeddings are essentially aligned into a common multimodal embedding space, allowing their representations to interact and be combined for multimodal modeling tasks like visual question answering, image captioning, etc. More specifically, the result of the projection layer is the generated “latents.” Once the latents are computed, we then prepend them as image tokens before the text tokens. The reason for the prepending is that having the image before the text makes it easier for the model to learn during pretraining. Think of it as having tokens representing the actual image and then tokens representing the contents of the image in text: almost like a caption paired with an image. Our architecture is nearly identical to that of LLaVA-UHD (they choose CLIP-ViT while we use SigLIP and they work with Vicuna-13B) so we provide their illustration as reference below: Now that we’ve established the data needed for pretraining, we can dive into what that actually looks like. In pre-training, we then use 600,000 examples of prepended images to text. In this step we keep the main weights of the Llama-3 architecture frozen. The key is that we want to only update the gradients of the projection matrix. Crucially, we keep the rest of the weights frozen. And with that, we’ve wrapped up our intuition and process for the pretraining step. The key here was aligning the embedded images (latents) with their text in a joint representation and then pretraining LLaMA-3 to focus on updating the projection matrix based on the examples encountered. Supervised Finetuning Following pretraining, we perform supervised finetuning to enhance the performance of our model. In this step, we are freezing our computed embeddings (from the projection layer) and we keep everything except the vision and projection matrices frozen. In other words, if you look at the image below, the red components are unfrozen while the blue components are frozen. This is meant to serve as “instruction” finetuning — in other words making the model stronger for a multimodal text output. In this stage, we use 1M examples (7M split images). In Summary We add a vision encoder to Llama3 8B Our model offers 10–20% performance boosts over Llava the current open-source SOTA vision language model. We offer comparable vision abilities of models close to 100x* larger in size like GPT4v, Gemini Ultra, and Claude Opus. We describe an efficient pipeline to pretrain and instruction finetune the model in under $500.",
    "commentLink": "https://news.ycombinator.com/item?id=40505099",
    "commentBody": "Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars (aksh-garg.medium.com)444 points by minimaxir 22 hours agohidepastfavorite73 comments lanceflt 21 hours ago- Llava is not the SOTA open VLM, InternVL-1.5 is https://huggingface.co/spaces/opencompass/open_vlm_leaderboa... You need to compare the evals to strong open VLMs including this and CogVLM - This is not \"first-ever multimodal model built on top of Llama3\", there's already a Llava on Llama3-8b https://huggingface.co/lmms-lab reply valine 20 hours agoparentVery curious how it performs on OCR tasks compared to InternVL. To be competitive at reading text you need tiling support, and InternVL does tiles exceptionally well. reply hovering_nox 11 hours agorootparentI think CogVLM2 is even better than Intern at OCR (my usecase is extracting information from an invoice) reply mkesper 6 hours agorootparentAfter some superficial testing I with bad quality scans you can find on kaggle I can not confirm that. CogVLM2 refuses to handle scans that InternVL-V1.5 still can comprehend. reply abrichr 16 hours agoparentprevThank you for the link! Our initial testing suggests MiniCPM outperforms InternVL for GUI understanding: https://github.com/OpenAdaptAI/OpenAdapt/issues/637#issuecom... (InternVL appears to hallucinate more.) reply gigel82 20 hours agoparentprevLike InternVL, no llama.cpp support severely limits its applications. Close to GPT4v performance level and runnable locally on any machine (no need for a GPU) would be huge for the accessibility community. reply yieldcrv 18 hours agoparentprevI’m going to be saying First Ever AI something for the next 15 years for clout and capital, not going to be listening to anybody’s complicated ten step funnel if they’re not doing the obvious reply vikrantrathore 16 hours agoprevHow does it compare with MiniCPM-Llama3-V 2.5 [0]? Based on what I see it seems much better than Llama 3-V on the benchmarks. Also it can directly be tried on Huggingface Spaces to check the performance [1]. It has the dataset, code and fine-tuning details with screenshots of it running on Xiaomi 14 pro. It has strong OCR performance and supports 30+ languages. [0] https://github.com/OpenBMB/MiniCPM-V [1] https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5 reply cpursley 7 hours agoparentWoah, this actually did quite well on table data extraction. I wonder how this could be used for long documents. Maybe paired with some kind of hybrid rag approach. reply arnaudsm 19 hours agoprevTangential question : did anyone ever use GPT4-V in production in visual tasks? It's never consistent enough for me to be useful reply abrichr 16 hours agoparentIt's very reliable for GUI segment understanding; see e.g. https://github.com/OpenAdaptAI/OpenAdapt/pull/610 (scroll down to `gpt-4-vision-preview`). reply amelius 7 hours agorootparentCan it be used for automatic annotation? As in: you tell it that these and these parts should be masked such and such, and then it does that? reply abrichr 5 hours agorootparentWe have not had success with that unfortunately. reply amelius 4 hours agorootparentThank you, your comment will save me some trouble ;) reply serjester 17 hours agoparentprevDon’t use it for anything OCR related that needs perfect accuracy. Stuff where some errors are ok, we’ve had great success. Depending on your budget, you can also run it multiple times to catch errors. reply nomel 17 hours agorootparent> you can also run it multiple times to catch errors. Does this require a slight offset and/or rotation to the image, or just literal rerun, with seed seed/whatever giving a different result? reply toomuchtodo 17 hours agorootparentprevHow does it compare to Tesseract? Edit: Thank you! reply elanning 17 hours agorootparentI’ve done a lot of OCR work and tesseract is nearly a decade out of date at this point. It is not a serious technology for anything requiring good accuracy or minor complexity. From what I’ve seen, GPT-4V completely smokes tesseract, but then again, most modern OCR systems do. If you want fast and pretty powerful OCR, check out paddle. If you want slower but higher accuracy, check out transformer based models such as TrOCR. reply nh2 15 hours agorootparentSee this for a comparison of PaddleOCR, TrOCR, and various cloud ones (note: on documents of typed and handwritten text): https://news.ycombinator.com/item?id=32077375 reply authorfly 8 hours agorootparentCaveat that being from 2022, the Tesseract version used was almost certainly v4 (if Linux), rather than v5 which is much better (and widely available on Windows in 2022, but not Linux yet). However Tesseract is quite behind still as you note, even with v5. reply authorfly 8 hours agorootparentprevRunning PaddleOCR in production now, I would suggest contrasting Tesseract v4 and v5, since v5 is a lot better(but until recently has not been available on Linux) - PaddleOCR does still smoke it though, you are right (especially for concurrency and fairly easily just setting different workers to different GPUs for best concurrent batching). reply cpursley 7 hours agorootparentHow is Paddle on complex data tables? This is my biggest challenge at the moment. reply authorfly 5 hours agorootparentWhat format? The entire data table in one image, or a PDF for example printed off with 8 pages where the user choose to only put the header on the first page etc? Or decent formatting, font size 8+ on an image with decent resolution? With the latter you are probably fine although you will need some manual implementation for parsing the output. You get bounding boxes at word level. One thing if I started nowadays I would do is use basic columns (x coordinates) to add '|' inbetween the outputs(including detecting empty span positions), keep items with similarish y coordinates together on lines, and put it into ChatGPT to format as desired, I suspect this would avoid misreading. I would say PaddleOCR is good in general for tables - it's much better (in terms of recall rate) at recognising numerical digits / symbols than Tesseract although I notice it often misrecognises \"l\" in \"Lullaby/ml/million\" etc as \"1\" sometimes. The cloud providers have better table extraction iff you can guarantee the same format each time for the document. reply cpursley 5 hours agorootparentA wide variety of PDFs (both in length and content) that can have a variety of different tables, real estate related with a lot of financial content. And I need to be able to run on local models / software (no parsing as a service, no OpenAI, etc). Here's just one example: https://www.totalflood.com/samples/residential.pdf (I struggle getting accurate data out of the Sales Comp section - basically all approaches mix up the properties. reply Zuiii 15 hours agorootparentprevTesseract's true value is being one apt-get command away (i.e. opensource). Does Debian host more modern OCR systems in their repos? reply nunez 13 hours agorootparentTesseract the tool is one apt-get away but the trained models are not, and I've found that they are a starting point, not a final destination. You still have to do more training on top of them for anything that isn't black text on a crisp white background. reply elanning 14 hours agorootparentprevBig mistake on my part; I should clarify I fine-tuned both PaddleOCR and TrOCR on large amounts of data specific to my domain. I cannot speak on the best out of the box “ready to go” solutions (besides cloud ones, which were quite good with the right pre and post processing). reply alexcnwy 12 hours agoparentprevthe coolest use case i've seen is this https://github.com/ddupont808/GPT-4V-Act reply nucleative 11 hours agorootparentI feel like this is the beginning of the end for all captchas reply jorvi 6 hours agorootparentTwitter / X has a very interesting captcha: you get to see 10 objects that have weird colors and are slightly deformed, and then you have to match them (1 at a time) with another row that has the same objects but seen from a different angle. Of course eventually this will be defeated too, but for now it seems to work pretty well. reply udev4096 11 hours agorootparentprevImage based or any kind of visual captchas will never be extremely effective. I think we will see more of PoW captchas in the upcoming years (just like cloudflare's turnstile captcha) reply fennecfoxy 6 hours agorootparentI'm not suer about that, can't you give GPT4 a math problem in an image already and have it solve it correctly most of the time? And these haven't even been trained to defeat captchas/logic problem captchas yet, if it was fine tuned on the general pattern of them I imagine any form of captcha is bust. reply zacmps 18 hours agoparentprevNope, I tried it for graph and diagram understanding and it wasn't good enough. Planning to repeat the evaluation with 4o when I have time. reply SparkyMcUnicorn 18 hours agorootparentI'm using 4o to convert visual diagrams into mermaid, and it's been almost perfectly accurate in my experience. reply cuu508 12 hours agorootparentThis is the out of the box thinking I love about HN. What do you do with the mermaid? reply SparkyMcUnicorn 4 hours agorootparentThe resulting mermaid is used for... more LLM processing. Converting to mermaid first is more cost-effective, consistent, and accurate for my purposes. reply KTibow 20 hours agoprevIs there a reason Phi Vision is omitted? reply cadence- 20 hours agoparentIs there any place that currently hosts phi3 Vision and provides API access to it? I cannot run it on my local machine, unfortunately. reply ai_what 19 hours agorootparentNvidia has a 1000 free credits API for phi3 vision. You only need an email address. https://build.nvidia.com/microsoft/phi-3-vision-128k-instruc... reply trog 18 hours agorootparentWas also looking for something like this - I can't find pricing listed anywhere for their API usage, only the free 1,000 credits - or am I completely misunderstanding how this works? reply cpursley 7 hours agorootparentI can’t find the pricing either. I’m interested, the demo worked well. reply cadence- 19 hours agorootparentprevBeautiful. Thank you. reply KTibow 19 hours agorootparentprevAzure has a playground, I haven't tried to use it with an API though. https://ai.azure.com/explore/models/Phi-3-vision-128k-instru... reply behnamoh 20 hours agoprevThis \"matching gpt-4\" catchy phrase has lost its meaning to me. Everytime an article like this pops up, I see marketing buzz and unrealistic results in practice. reply mpalmer 20 hours agoparentFor me it's become a signal the person making the claim is unserious. reply moffkalast 8 hours agorootparentIf \"beats GPT 4\" is in the title it's almost a guarantee that it's a bold faced lie that includes benchmark overfitting. The first time a model that actually matched GPT 4 launched (i.e. Command-R+) there was no mention of it at all. If your results speak for themselves, there's no need to shout. reply Mo3 20 hours agoparentprevOf course, it's nothing else. Who could possibly believe that OpenAI and others would dump billions into development and training and aren't smart enough to figure out they could also do it with $500. reply nomel 20 hours agorootparentIt's llama 3 training cost + their cost. Meta \"kindly\" covered the first $700M. > We add a vision encoder to Llama3 8B reply lanceflt 17 hours agorootparentThey didn't train the vision encoder either, it's unchanged SigLIP by Google. reply qeternity 7 hours agorootparent“We finetuned billions of dollars of research by Google and Meta.” reply whimsicalism 20 hours agorootparentprevit would have been a lot cheaper for oai if they had access to llama3 in 2018 reply nickpsecurity 19 hours agorootparentprevWhile that may be true, the opposite has also happened to hundreds of companies in other areas: https://news.ycombinator.com/item?id=39136472 Many companies also optimize for tools, like Python, that have boost productivity more than price/performance ratio. OpenAI had billions of other people's money. They might just keep using tools which worked before. Lastly, there are tons of papers published on techniques that claim to reduce cost. Most of them aren't good. Their benchmarks aren't good. Even reviewing most of them is more time than a lot of AI researchers have. Those that make it to established communities usually have gotchas that come with the benefits. So, they could also simply miss a needle in a large haystack. I think you're right that they'd be using whatever really worked with no loss in model performance. It's just that they might not for a number of reasons. The rational choice is for others to keep experimenting with those things in case they get a competitive advantage. reply KorematsuFredt 20 hours agorootparentprevYou have clearly not read the article. $500 is the cost of fine tuning. reply selcuka 17 hours agorootparentFair enough. Is it now safe to say that OpenAI could have done with a 8B model + $500 of fine tuning instead of running a (much) larger model on their GPU cluster? reply wrycoder 17 hours agorootparentMaybe they did reply bilbo0s 20 hours agorootparentprevWho could possibly believe that OpenAI and others would dump billions into development and training and aren't smart enough to figure out they could also do it with $500. People upvoting the post?? Not really sure? But PT Barnum said there's always a lot of them out there. Pretty sure they mean fine tuning though? But even that is total tripe. These guys are snake oil salesmen. (Or Sylvester McMonkey McBean is behind it.) reply alfalfasprout 18 hours agoparentprevSadly the front page is often riddled with posts like these. reply nbk_2000 17 hours agoparentprevStarting to sound like the \"iPhone Killer\" we've all heard about... for the past 15+ years reply anais9 7 hours agoprevWould love to see Ollama support for this - seems promising given my experience with LLaVA so far and would love to get some hands on head to head experience reply Havoc 19 hours agoprevOh wow. I was expecting it to be the 70B one as base given those stats reply yeldarb 20 hours agoprevDon't see a license listed in the repo; presumably needs to be the same as Meta's Llama 3 license? reply doctorpangloss 21 hours agoprevShouldn't CogAgent be in this comparison? reply m00x 21 hours agoparentCogVLM should be, not sure how CogAgent plays into this. This isn't an agent. reply doctorpangloss 20 hours agorootparentYou would use CogAgent in VQA mode. Why would someone downvote suggesting to test one of the most powerful multimodal LLMs? Because it doesn't have \"V\" in its name? CogAgent is improved on many tasks compared to CogVLM. reply m00x 16 hours agorootparentI didn't downvote, only replied. CogAgent is also CogVLM modified to handle documents and larger images. CogVLM is better for VQA. reply 2Gkashmiri 15 hours agoprevIs there a local small llm that can OCR images or haabdwritten invoices ? Traditional OCR do not handle multiple invoice formats or handwritten ones. I would like to train one locally with as many invoices it wants reply dcreater 16 hours agoprev [–] If I had a nickel for every outrageous \"matches/beats GPT-x\" claim, I'd have more money than the capital these projects raise from VC. This absolutely is not the first Llama3 vision model. They even quote it's performance compared to Llava. Hard to take anything they say seriously with such obviously false claims reply qeternity 13 hours agoparent> This absolutely is not the first Llama3 vision model. They even quote it's performance compared to Llava. Although this is true, there have been earlier Llama3 based vision releases, none of the latest Llava releases are Llama3 based. reply abbaselmas 9 hours agorootparenthttps://ollama.com/library/llava-llama3 llava-llama3 reply qeternity 6 hours agorootparentThat is someone else who has just used the Llava name. It is not by the original group who have published a series of models under the Llava name. reply CGamesPlay 8 hours agorootparentprevThis appears to be a Llava model which was then fine-tuned using outputs from Llama 3. If I understand correctly, that would make it Llama-2-based. reply GaggiX 8 hours agorootparent>fine-tuned using outputs from Llama 3. Llama 3 outputs text and can only see text, this is a vision model. >that would make it Llama-2-based. It's based on Llama 3, Llama 2 has nothing to do with it. They took Llama 3 Instruct and CLIP-ViT-Large-patch14-336, train the projection layer first and then later finetuned the Llama 3 checkpoint and train a LoRA for the ViT. reply vixen99 12 hours agoparentprev [–] All models surely write 'its performance'. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Llama3-V is a new multimodal model based on Llama3, designed to rival larger models like GPT-4V but at a significantly lower cost (under $500).",
      "It surpasses the current state-of-the-art model, Llava, by 10-20% in multimodal understanding benchmarks, using SigLIP for image embedding and aligning visual and textual tokens through a projection block with self-attention layers.",
      "Key optimizations include precomputing image embeddings and leveraging MPS/MLX for efficient training, with a training process involving pretraining on 600,000 examples and supervised finetuning on 1 million examples."
    ],
    "commentSummary": [
      "The article compares various multimodal AI models, focusing on Llama 3-V, which aims to match GPT-4V's performance but is smaller and cheaper.",
      "It highlights that models like InternVL-1.5 and CogVLM outperform Llava, with specific models excelling in tasks like OCR (Optical Character Recognition) and GUI (Graphical User Interface) understanding.",
      "Users discuss practical applications, limitations, and the cost-effectiveness of these models, including the use of GPT-4V in production for visual tasks and the effectiveness of modern OCR tools like PaddleOCR and TrOCR."
    ],
    "points": 444,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1716927379
  },
  {
    "id": 40512250,
    "title": "Mistral AI Unveils Codestral: A Powerful Generative AI for Code Generation",
    "originLink": "https://mistral.ai/news/codestral/",
    "originBody": "May 29, 2024 Mistral AI team We introduce Codestral, our first-ever code model. Codestral is an open-weight generative AI model explicitly designed for code generation tasks. It helps developers write and interact with code through a shared instruction and completion API endpoint. As it masters code and English, it can be used to design advanced AI applications for software developers. A model fluent in 80+ programming languages Codestral is trained on a diverse dataset of 80+ programming languages, including the most popular ones, such as Python, Java, C, C++, JavaScript, and Bash. It also performs well on more specific ones like Swift and Fortran. This broad language base ensures Codestral can assist developers in various coding environments and projects. Codestral saves developers time and effort: it can complete coding functions, write tests, and complete any partial code using a fill-in-the-middle mechanism. Interacting with Codestral will help level up the developer’s coding game and reduce the risk of errors and bugs. Setting the Bar for Code Generation Performance Performance. As a 22B model, Codestral sets a new standard on the performance/latency space for code generation compared to previous models used for coding. Figure 1: With its larger context window of 32k (compared to 4k, 8k or 16k for competitors), Codestral outperforms all other models in RepoBench, a long-range eval for code generation.. We compare Codestral to existing code-specific models with higher hardware requirements. Python. We use four benchmarks: HumanEval pass@1, MBPP sanitised pass@1 to evaluate Codestral’s Python code generation ability, CruxEval to evaluate Python output prediction, and RepoBench EM to evaluate Codestral’s Long-Range Repository-Level Code Completion. SQL. To evaluate Codestral’s performance in SQL, we used the Spider benchmark. Additional languages. Additionally, we evaluated Codestral's performance in multiple HumanEval pass@1 across six different languages in addition to Python: C++, bash, Java, PHP, Typescript, and C#, and calculated the average of these evaluations. FIM benchmarks. Codestral's Fill-in-the-middle performance was assessed using HumanEval pass@1 in Python, JavaScript, and Java and compared to DeepSeek Coder 33B, whose fill-in-the-middle capacity is immediately usable. Get started with Codestral Download and test Codestral. Codestral is a 22B open-weight model licensed under the new Mistral AI Non-Production License, which means that you can use it for research and testing purposes. Codestral can be downloaded on HuggingFace. Use Codestral via its dedicated endpoint With this release, comes the addition of a new endpoint: codestral.mistral.ai. This endpoint should be preferred by users who use our Instruct or Fill-In-the-Middle routes inside their IDE. The API Key for this endpoint is managed at the personal level and isn’t bound by the usual organization rate limits. We’re allowing use of this endpoint for free during a beta period of 8 weeks and are gating it behind a waitlist to ensure a good quality of service. This endpoint should be preferred by developers implementing IDE plugins or applications where customers are expected to bring their own API keys. Build with Codestral on La Plateforme Codestral is also immediately available on the usual API endpoint: api.mistral.ai where queries are billed per tokens. This endpoint and integrations are better suited for research, batch queries or third-party application development that exposes results directly to users without them bringing their own API keys. You can create your account on La Plateforme and start building your applications with Codestral by following this guide. Like all our other models, Codestral is available in our self-deployment offering starting today: contact sales. Talk to Codestral on le Chat We’re exposing an instructed version of Codestral, which is accessible today through Le Chat, our free conversational interface. Developers can interact with Codestral naturally and intuitively to leverage the model's capabilities. We see Codestral as a new stepping stone towards empowering everyone with code generation and understanding. Use Codestral in your favourite coding and building environment. We worked with community partners to expose Codestral to popular tools for developer productivity and AI application-making. Application frameworks. Codestral is integrated into LlamaIndex and LangChain starting today, which allows users to build agentic applications with Codestral easily VSCode/JetBrains integration. Continue.dev and Tabnine are empowering developers to use Codestral within the VSCode and JetBrains environments and now enable them to generate and chat with the code using Codestral. Here is how you can use the Continue.dev VSCode plugin for code generation, interactive conversation, and inline editing with Codestral, and here is how users can use the Tabnine VSCode plugin to chat with Codestral. For detailed information on how various integrations work with Codestral, please check our documentation for set-up instructions and examples. Developer community feedbacks “A public autocomplete model with this combination of speed and quality hadn’t existed before, and it’s going to be a phase shift for developers everywhere.” – Nate Sesti, CTO and co-founder of Continue.dev “We are excited about the capabilities that Mistral unveils and delighted to see a strong focus on code and development assistance, an area that JetBrains cares deeply about.” – Vladislav Tankov, Head of JetBrains AI “We used Codestral to run a test on our Kotlin-HumanEval benchmark and were impressed with the results. For instance, in the case of the pass rate for T=0.2, Codestral achieved a score of 73.75, surpassing GPT-4-Turbo’s score of 72.05 and GPT-3.5-Turbo’s score of 54.66.” – Mikhail Evtikhiev, Researcher at JetBrains “As a researcher at the company that created the first developer focused GenAI tool, I've had the pleasure of integrating Mistal's new code model into our chat product. I am thoroughly impressed by its performance. Despite its relatively compact size, it delivers results on par with much larger models we offer to customers. We tested several key features, including code generation, test generation, documentation, onboarding processes, and more. In each case, the model exceeded our expectations. The speed and accuracy of the model will significantly impact our product's efficiency vs the previous Mistral model, allowing us to provide quick and precise assistance to our users. This model stands out as a powerful tool among the models we support, and I highly recommend it to others seeking high-quality performance.” – Meital Zilberstein, R&D Lead @ Tabnine “Cody speeds up the inner loop of software development, and developers use features like autocomplete to alleviate some of the day-to-day toil that comes with writing code. Our internal evaluations show that Mistral’s new Codestral model significantly reduces the latency of Cody autocomplete while maintaining the quality of the suggested code. This makes it an excellent model choice for autocomplete where milliseconds of latency translate to real value for developers.” – Quinn Slack, CEO and co-founder of Sourcegraph “I've been incredibly impressed with Mistral's new Codestral model for AI code generation. In my testing so far, it has consistently produced highly accurate and functional code, even for complex tasks. For example, when I asked it to complete a nontrivial function to create a new LlamaIndex query engine, it generated code that worked seamlessly, despite being based on an older codebase.” – Jerry Liu, CEO and co-founder of LlamaIndex “Code generation is one of the most popular LLM use-cases, so we are really excited about the Codestral release. From our initial testing, it's a great option for code generation workflows because it's fast, has favorable context window, and the instruct version supports tool use. We tested with LangGraph for self-corrective code generation using the instruct Codestral tool use for output, and it worked really well out-of-the-box (see our video detailing this).” – Harrison Chase, CEO and co-founder of LangChain",
    "commentLink": "https://news.ycombinator.com/item?id=40512250",
    "commentBody": "Codestral: Mistral's Code Model (mistral.ai)265 points by alexmolas 4 hours agohidepastfavorite123 comments analyte123 3 hours agoThe license for this [1] prohibits use of the model and its outputs for any commercial activity, or even any \"live\" (whatever that means) conditions, commercial or not. There seems to be an exclusion for using the code outputs as part of \"development\". But wait! It also prohibits \"any internal usage by employees in the context of the company's business activities\". However you interpret these clauses, this puts their claims and comparisons on completely unequal ground. They only compare to other open-weight models, not GPT-4 or Opus, but a normal company or individual can do whatever they want with the Llama weights and outputs. LangChain? \"Your favourite coding and building environment\"? Who cares? It seems you're not allowed to integrate this with anything else and show it to anyone, even as an art project. [1] https://mistral.ai/licenses/MNPL-0.1.md reply foobiekr 3 hours agoparentThere's some irony in the fact that people will ignore this license in exactly the same way Mistral and all the other LLM guys ignore the copyright and licensing on the works they ingest. reply belter 1 hour agorootparentAnd nobody will sue anybody because suing means...discovery.... reply nicce 2 hours agorootparentprevIn many countries you even can't claim copyright for the output of the AI to use license like this. reply hannasanarion 1 hour agorootparentCopyright on the software that produces something isn't the same as copyright on the output. The library's copyright is intact, as normal, and they can control who uses it and how just like any other software. The output of AI systems is not copyrightable, but the systems themselves are, and associated EULAs are valid. reply nicce 48 minutes agorootparentIs that so certain? To be able to make claims for what you can use the output, can you do it without making any claims for about control and ownership of the output? Of course, they can revoke your right to use the software, but if it goes to court, that would be interesting case. reply isoprophlex 2 hours agoparentprevSo, it's almost entirely useless with that license, because the average pack of corpo beancounters will never let you use it over whatever Microsoft has already sold them. reply croes 3 hours agoparentprevIt's more like a demo version you can evaluate before you need to buy a commercial license. On whose code is Mistral trained? reply rvnx 2 hours agorootparentYour code, my code, etc. But there is a common case with law; copyright do not apply when you have billions. Examples: recurring infringement from Microsoft on open-source projects, Google scraping content to build their own database, etc... reply rohansood15 2 hours agoparentprevThat license is just hilarious. reply das_keyboard 2 hours agorootparentOT, but 7.2 reads like the description of some Yu-Gi-Oh card or something: > Mistral AI may terminate this Agreement at any time [...]. Sections 5, 6, 7 and 8 shall survive the termination of this Agreement. reply behnamoh 2 hours agoparentprevFrom the website: > licensed under the new Mistral AI Non-Production License, which means that you can use it for research and testing purposes. ... Which basically means \"we give you this model. Go find its weaknesses and report on r/locallama. Then we'll use that to improve our commercial model which we won't open-source.\" I'm sick of abusing the word \"open-source\" in this field. reply JimDabell 2 hours agorootparent> I'm sick of abusing the word \"open-source\" in this field. They don’t call this open source anywhere, do they? As far as I can see, they only say it’s open weights and that it’s available under their Mistral AI Non-Production License for research and testing. That doesn’t scream “open source” to me. reply demosthanos 2 hours agorootparentThey do say \"open-weight\", which is I think still very misleading in this context. Open-weight sounds like it should be the same as open-source, just for weights instead of the full source (for example, training data and the code used to generate the weights may not be released). This isn't really \"open\" in any meaningful sense. reply Zambyte 2 hours agorootparentThe fact that I can downloaded it and run it myself is a pretty meaningful amount of openness to me. I can easily ignore their bogus claims about what I'm allowed to do with it due to their distribution model. I can't necessarily do the same with a propriety service, as they can cut me off if the way I use the output makes them sad :( reply demosthanos 12 minutes agorootparent> I can easily ignore their bogus claims about what I'm allowed to do with it due to their distribution model. If you're talking about exclusively personally use, sure. If you're talking about a business setting in a jurisdiction that Mistral can sue in, not so much. Being able to use it in a business setting is a pretty darn important part of what Open Source has always meant (it's why it exists as a term at all). reply TeMPOraL 1 hour agorootparentprev> The fact that I can downloaded it and run it myself is a pretty meaningful amount of openness to me That's typically called freeware, though. reply Zambyte 26 minutes agorootparentThe inference engine that I use to run open weight language models is fully free software. The model itself isn't really software in the traditional sense. So calling it ____ware seems inaccurate. reply gyudin 2 hours agorootparentprevAll their other models are “open source” and it was the selling point they built their brand on. I doubt they made their new model completely different from previous ones so it’s supposed be open source too, unless they found some juridical loophole lol reply Rastonbury 2 hours agorootparentprevNo but they do say \"empowering developers\" and \"democratising coding\" as the subtitle, I guess only those who pay reply meiraleal 2 hours agoparentprev> Who cares? It seems you're not allowed to integrate this with anything else and show it to anyone, even as an art project. Now they just lack the means to enforce it. reply localfirst 1 hour agorootparentimpossible to enforce reply ddavis 3 hours agoprevMy favorite thing to ask the models designed for programming is: \"Using Python write a pure ASGI middleware that intercepts the request body, response headers, and response body, stores that information in a dict, and then JSON encodes it to be sent to an external program using a function called transmit.\" None of them ever get it right :) reply JimDabell 2 hours agoparentI normally ask about building a multi-tenant system using async SQLAlchemy 2 ORM where some tables are shared between tenants in a global PostgreSQL schema and some are in a per-tenant schema. Nothing gets it right first time, but when ChatGPT 4 first came out, I could talk to it more and it would eventually get it right. Not long after that though, ChatGPT degraded. It would get it wrong on the first try, but with every subsequent follow up it would forget one of the constraints. Then when it was prompted to fix that one, it forgot a different one. And eventually it would cycle through all of the constraints, getting at least one wrong each time. Since then benchmarks came out showing that ChatGPT “didn’t really degrade”, but all of the benchmarks seemed focused on single question/answer pairs and not actual multi-turn chat. For this kind of thing, ChatGPT 4 has never managed to recover to as good as it was when it was first released in my experience. It’s been months since I’ve had to deal with that kind of code, so I might be forgetting something, but I just tried it with Codestral and it spat out something that looked reasonable very quickly on its first try. reply checkyoursudo 25 minutes agorootparentI had a similar experience. I was trying to get GPT 4 to write some R/Stan code for a bit of bayesian modelling. It would get the model wrong, and then I would walk it through how to do it right, and by the end it would almost get it right, but on the next step, it would be like, oh, this is what you want, and the output was identical to the first wrong attempt, which would start the loop over again. reply gyudin 2 hours agoparentprevI ask software developers to do the same thing and give them the same amount of time. None of them ever write a single line of code :) reply dieortin 1 hour agorootparentGive an LLM all the time you want, and they will still not get it right. In fact, they most likely will give worse and worse answers with time. That’s a big difference with a software developer. reply nicce 3 hours agoparentprevI usually through some complex Rust code with lifetime requirements. And ask them to fix it. LLMs aren't capable on providing much help for that in general, other than some very basic cases. The best way to get your work done is still to look into Rust forums. reply meiraleal 2 hours agorootparentIt works amazingly well for the ones that never coded in Rust, at least in my experience. It took me a couple hours and 120 lines of code to set up a WebRTC signaling server. reply sanex 3 hours agoparentprevCan you get it right without an IDE? reply ddavis 3 hours agorootparentNope, I don't know how to do it at all- that's why I have to ask AI! reply shepardrtc 38 minutes agoparentprevgpt-4o gets it right on the first try for me. Just ran it and tested it. reply meiraleal 3 hours agoparentprevInteresting. My favorite thing to ask the models is to refactor code I've not touched for too long and this works very well. reply bongodongobob 3 hours agoparentprevCool, you've identified that your prompt is inadequate for the task. 'Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?' reply TechDebtDevin 3 hours agorootparentDamn, show us your brilliant prompt then. LLMs cannot do this, not even in python, of which there are libraries like Blacksheep that honestly make it a trivial task. reply ben_w 3 hours agorootparentPrompts like yours (I ask them for a fluid dynamics simulator which also doesn't succeed) inform us of the level they have reached. A useful benchmark, given how many of the formal ones they breeze through. I'm glad they can't quite manage this yet. Means I still have a job. reply Closi 3 hours agorootparentprevBreak your prompt up into smaller pieces and it can. reply qeternity 2 hours agorootparentTaken to the extreme, a sufficiently broken down prompt is simply the code itself. The whole point is to prompt less? reply Closi 1 hour agorootparentMore practically, the whole point is to prompt enough to generate valid code. reply meiraleal 2 hours agorootparentprev> Taken to the extreme, a sufficiently broken down prompt is simply the code itself it is not. But the artifacts generated through the steps will be code. The last prompt will have most of the code supplied to it as the context. reply achierius 1 hour agorootparentA prompt is just a specification for an output. Code is just what we call a sufficiently detailed specification. reply bongodongobob 3 hours agorootparentprevMy point is that you shouldn't expect to one shot everything. Have it start by writing a spec, then outline classes and methods, then write the code, and feed it debug stuff. reply TechDebtDevin 3 hours agorootparentI see your point but hand holding isn't really a good way to benchmark a models coding capabilities. reply Closi 3 hours agorootparentDepends if benchmarking is the aim, rather than decreasing the time it takes to build things. reply TechDebtDevin 2 hours agorootparentWell sure, but that wasn't what we were discussing. The original comment says they use that as their benchmark. While their coding task is a bit complex compared to other benchmarking prompts, it's not that crazy. Here is an example of prompts used for benchmarking with Python for reference: https://huggingface.co/datasets/mbpp?row=98 At the end of the day LLMs in their current iteration aren't intended to do even moderately difficult tasks on their own but it's fun to query them to see progress when new claims are made. reply Closi 2 hours agorootparentThe original comment says nothing about benchmarking, they just say that an AI can’t one shot their complex task? reply amne 34 minutes agorootparentWhen I read \"My favorite thing to ask the models designed for programming is ....... None of them ever get it right\" I read \"benchmark\". reply bottom999mottob 3 hours agorootparentprevExactly, expecting one shot 100% working code with one prompt is ridiculous at this point. It's why libraries like Aider are so useful, because you can iteratively diff generated code until it's useable. reply TechDebtDevin 2 hours agorootparentSure it's impossible at this point, but the point of a benchmark isn't to complete the task it's to test it's efficacy overall and to see progress. None of them are 100% at even the simplistic python benchmarks, doesn't mean we shouldn't measure that capability. But sure, I get it. That's not how they are intended to be used but that's also not the point the commenter was laying out. reply ddavis 3 hours agorootparentprevIt's something I know how to do after figuring it out myself and discovering the potential sharp edges, so I've made it into a fun game to test the models. I'd argue that it's a great prompt (to keep using consistently over time) to see the evolution of this wildly accelerating field. reply kergonath 2 hours agorootparentDo you notice any progress over time? reply AnimalMuppet 2 hours agorootparentprevHow is that \"putting in wrong figures\"? It's a perfectly valid prompt, written in clear, proper English. reply swyx 3 hours agoprevi've been noticing that there's a divergence in philosophy between Llama style LLMs (Mistral are Meta alums so I'm counting them in tehre) and OpenAI/GPT style LLMs when it comes to code. GPT3.5+ prioritized code very heavily - there's no CodeGPT, its just GPT4, and every version is better than the last. Whereas the Llama/Mistral models are now shipping the general language model first, then adding CodeLlama/Codestral with additional pretraining (it seems like we don't know how much more tokens are on this one, but CodeLLama was 500B-1T extra tokens of code). Zuck has mentioned recently that he doesnt see coding ability as important for his usecases, whereas obviously OpenAI is betting heavily on code as a way to improve LLM reasoning for AGI. reply memothon 3 hours agoparent>Zuck has mentioned recently That's a really surprising thing to hear, where did you see that? The only quote I've seen is this one: >“One hypothesis was that coding isn’t that important because it’s not like a lot of people are going to ask coding questions in WhatsApp,” he says. “It turns out that coding is actually really important structurally for having the LLMs be able to understand the rigor and hierarchical structure of knowledge, and just generally have more of an intuitive sense of logic.” https://www.theverge.com/2024/1/18/24042354/mark-zuckerberg-... reply whoami_nr 1 hour agorootparentHe mentioned it on the Dwarkesh podcast: https://www.youtube.com/watch?v=bc6uFV9CJGg reply imachine1980_ 3 hours agorootparentprevMake Sense, they want better interaction whit users for Whatsapp, Instagram and Facebook marketers, content creation and moderation,and their glasses(ai /ar) I don't see in that context why the should push more effort into llm coding, is sad anyways reply guyomes 3 hours agoparentprev> OpenAI is betting heavily on code as a way to improve LLM reasoning for AGI. And researchers from Google Deepmind, University of Wisconsin-Madison and Laboratoire de l’Informatique du Parallélisme, University of Lyon, actually publish some of their results in that direction [1,2]. [1]: https://deepmind.google/discover/blog/funsearch-making-new-d... [2]: https://www.nature.com/articles/s41586-023-06924-6 reply tkellogg 3 hours agoparentprevThe OpenAI philosophy is that adding modes improves everything. Sure, it’s astronomically expensive, but I tend to think they’re on to something. reply Rastonbury 3 hours agoparentprevI thought that was the idea, open source small specific models that most people can run vs general purpose ones that require a massive amount of GPUs reply behnamoh 2 hours agoparentprev> Zuck No, if anything he said Meta realized coding abilities make the model overall better, so they focused on those more than before. reply IMTDb 3 hours agoprevIs there a way to use this within VSCode like copilot , meaning having the \"shadow code\" appear while you code instead of having to tho back-and-forth between the editor and a chat-like interface ? For me, a significant component of the quality of these tools resides on the \"client\" side; being able to engineer a prompt that will yield to accurate code being generated by the model. The prompt needs to find and embed the right chunks from the user current workspace, or even from his entire org repos. The model is \"just\" one piece of the puzzle. reply pyepye 3 hours agoparentNot using Codestral (yet) but check out Continue.dev[1] with Ollama[2] running llama3:latest and starcoder2:3b. It gives you a locally running chat and edit via llama3 and autocomplete via starcoder2. It's not perfect but it's getting better and better. [1] https://www.continue.dev/ [2] https://ollama.com/ reply sa-code 53 minutes agorootparentThis doesn't give the \"shadow text\" that the user specifically mentioned reply jmorgan 2 hours agorootparentprevCodestral was just published here as well: https://ollama.com/library/codestral reply jdoss 3 hours agoparentprevI have been using Ollama to run the Llama3 model and I chat with it via Obsidian using https://github.com/logancyang/obsidian-copilot and I hook VSCode into it with https://github.com/ex3ndr/llama-coder Having the chats in Obsidian lets me save them to reference them later in my notes. When I first started using it in VSCode when programming in Python it felt like a lot of noise at first. It kept generating a lot of useless recommendations, but recently it has been super helpful. I think my only gripe is I sometimes forget to turn off my ollama systemd unit and I get some noticeable video lag when playing games on my workstation. I think for my next video card upgrade, I am going to build a new home server that can fit my current NVIDIA RTX 3090 Ti and use that as a dedicated server for running ollama. reply croes 3 hours agoparentprevYou mean like in their example VS code integration shown here?: https://m.youtube.com/watch?v=mjltGOJMJZA reply jacekm 3 hours agoparentprevThe article says that the model is available in Tabnine, a direct competitor to Copilot. reply meiraleal 3 hours agoparentprevI created a simple CLI app that does this in my workspace, which is under source control so after the LLM execution all the changes are highlighted by diff and the LLM also creates a COMMIT_EDITMSG file describing what it changed. Now I don't use chatgpt anymore, only this cli tool. I never saw something like this integrated directly on VSCode tho (and isn't my preferred workflow anyway, command line works better). reply andruby 3 hours agoprevThis is an open weights 22B model. The download on Huggingface is 44GB. Is there a rule-of-thumb estimate for how much RAM this would need to be used locally? Is the RAM requirement the same for a GPU and \"unified\" RAM like Apple silicon? reply mauricio 3 hours agoparent22B params * 2 bytes (FP16) = 44GB just for the weights. Doesn't include KV cache and other things. When the model gets quantized to say 4bit ints, it'll be 22B params * 0.5 bytes = 11GB for example. reply tosh 3 hours agoparentprevB × Q / 8 B: number of parameters Q: quantization (16 = no quantization) via https://news.ycombinator.com/item?id=40090566 reply fnbr 3 hours agoparentprevThe rule of thumb is roughly 44gb, as most models are trained in bf16, and require 16 bits per parameter, so 2 bytes. You need a bit more for activations, so maybe 50GB? you need enough RAM and HBM (GPU RAM) so it’s a constraint on both. reply Novosell 3 hours agorootparentMost GPUs still use GDDR I'm pretty sure, not HBM. Do you mean VRAM? reply sharbloop 3 hours agorootparentprevWhich GPU card can I buy to run this model? Can it run on commercial RTX3090 or does it need a custom GPU? reply Havoc 3 hours agorootparent3090 or 4090 will be able to run quantized 22B models. Though realistically for code completion smaller models will be better due to speed reply TechDebtDevin 3 hours agorootparentprevEasy.. reply wing-_-nuts 3 hours agoparentprevWait for a gguf release of this and it will fit neatly into a 3090 with a decent quant. I'm excited for this model and I'll be adding it to my collection. reply TechDebtDevin 3 hours agoparentprevI'm honestly not sure on how to measure the amount of vRAM required for these models but I suspect this would run relatively fast, depending on your use case, on a mid to high end 20 or 30 series card. No idea about Apple unified RAM. I get a lot out of performance out of even older cards such as a 1080ti but haven't tested this model. reply resource_waste 3 hours agoparentprevnext [3 more] [flagged] kblissett 3 hours agorootparentRather than teasing it might be more productive to explain why it is you think unified memory isn't relevant in this case. reply resource_waste 1 hour agorootparentJust call it RAM. No need to use Apple marketing. reply Zambyte 4 hours agoprevLink to the huggingface page: https://huggingface.co/mistralai/Codestral-22B-v0.1 reply croes 3 hours agoprev>Usage Limitation - You shall only use the Mistral Models and Derivatives (whether or not created by Mistral AI) for testing, research, Personal, or evaluation purposes in Non-Production Environments; - Subject to the foregoing, You shall not supply the Mistral Models, Derivatives, or Outputs in the course of a commercial activity, whether in return for payment or free of charge, in any medium or form, including but not limited to through a hosted or managed service (e.g. SaaS, cloud instances, etc.), or behind a software layer reply asadm 2 hours agoprevHow do people do infilling these days? In olden times models used to provide a way to provide suffix separately. reply artninja1988 1 hour agoprevThis is a business model I can get behind. The model is under a non-commercial license, but it's open weights and they have their official API for it reply esafak 2 hours agoprevAre there any IDE plugins that index your entire code base in order to provide contextual responses AND let you pick between the latest models? If not, consider it a product idea ;) reply elmariachi 18 minutes agoparentCody by Sourcegraph allows you to do this. It doesn't have Codestral yet but probably will soon. reply pmmucsd 1 hour agoparentprevThere are plugins for various IDEs that operate like copilot but let you select model you want to use, just supply your key. CodeGPT for JetBrains/Android Studio is pretty good. I think you can even use a model running locally. reply saturatedfat 1 hour agoparentprevSupermaven, but you don’t get model choice. reply sebzim4500 3 hours agoprevVery impressed with it based on a short live chat, feels insanely fast considering its capability. chat.mistral.ai reply kergonath 2 hours agoparentWe'll see how fast it is on consumer hardware once decent quantisations are available. reply jhonatan08 3 hours agoprevDo we have a list of the 80+ languages it was trained on? I couldn't find it reply mousetree 4 hours agoprevHow does this compare to Github Copilot? It's not shown in their comparison reply nkozyra 3 hours agoparentNot sure how much current Copilot varies from the original Codex, but another set of benchmarks here: https://paperswithcode.com/sota/code-generation-on-humaneval reply ramon156 3 hours agoparentprevKnowing the training data GH has I doubt it's comparable, then again I don't have the benchmarks reply ramon156 3 hours agorootparentAfter typing this I tried the live chat out and it honestly seems a lot more promising than current GH Copilot, very nice! reply ssgodderidge 3 hours agorootparentprevAre you saying GH has more than Codestral and therefore GH has a better model? Or that Codestral would be better because Codestral is not littered with \"bad\" code? reply nkozyra 3 hours agorootparentBad code is obviously very subjective, but I would wager that GH places a much higher value on feedback mechanisms like stars, issues, PRs, velocity, etc. Their ubiquity likely allows them to automatically cherry-pick less \"bad code.\" reply rohansood15 3 hours agoparentprevCopilot primarily uses GPT-3.5, which is outclassed by Llama3-70B. And this model claims to be slightly better than Llama3-70B. Edit: For those who don't believe me, https://github.com/microsoft/vscode-copilot-release/issues/6.... Gpt-4 for chat, 3.5 for code. reply jasonjmcghee 3 hours agorootparentGitHub Copilot uses GPT-3.5? I was under the impression it was a custom codex model with a surrogate local model as per https://github.blog/2023-02-14-github-copilot-now-has-a-bett... When did this change? reply Rastonbury 3 hours agorootparentWhen it first launched it, I too didn't know they had changed the model from the original codex which came similar time as gpt-3.5 reply jasonjmcghee 2 hours agorootparentprev> Gpt-4 for chat, 3.5 for code That thread is comparing sidebar chat to inline chat. Doesn't discuss code completions afaict. reply isoprophlex 2 hours agoprevDoes it do SQL, and if so, which dialects? I am having a hard time figuring out what it is actually trained on reply sebzim4500 2 hours agoparentThey claim good results in a SQL benchmark but they don't specify what dialects it knows. reply bloopernova 3 hours agoprevDoes anyone know of a link to a codegen comparison page? In other words, you write your request, and it's submitted to multiple codegen engines, so you can compare the output. reply rohansood15 3 hours agoparentNot the same, but we evaluated how good LLMs are at fixing code and just posted it on HN: https://news.ycombinator.com/item?id=40511689 reply jstummbillig 3 hours agoprevHow I interact with new model reports at this point: Open the page, ctrl + f, \"gpt-4\" and skip the rest. reply sashank_1509 3 hours agoprevSeems nice but some preliminary testing against GPT-4o shows it’s lacking a bit. It does a pretty good job for easy questions though reply jasonjmcghee 3 hours agoparentGPT-4o is really oddly hit or miss for code. Sometimes it outperforms GPT-4 in quality by a fair amount, and other times it starts repeating itself. Duplicating function definitions, even misremembering what things are named. It seems to have to do with length. If the output exceeds a few thousand tokens, it seems to experience some pretty bad failure modes. reply afro88 58 minutes agorootparent4o can only output 4k tokens. So the training to complete an answer within 4k tokens is probably kicking in and nerfing the quality reply YetAnotherNick 1 hour agoprevWhat's the business model for semi open source models like these? Is it just because they can't be fully closed as they have to then compare with OpenAI. Who would pay for these model if better is available for cheaper from Anthropic or Google. reply colesantiago 3 hours agoprevI'm so happy now LLMs are democratising access to programming, especially open models like what Meta with Llama and Mistral is doing with Codestral are doing. The abundance of programming is going to allow almost everyone to become a great programmer. This is so exciting to see and each day programming is becoming a solved problem so we can focus on other things. reply huygens6363 30 minutes agoparentThis enables everyone to be great programmers like how easily available power tools enables everyone to be a great carpenter and general craftsman. You’ll get a lot of shitty stuff and the profession will get hollowed out losing attraction of the smart people. We’ll be left with low-quality, disposable bullshit while wondering where all the programmers went. reply maskil 2 hours agoparentprevI would argue the opposite is true. My experience with coding with LLMs is that the only thing it's really good at is generating boilerplate that it has more-or-less seen before (essentially a library, even if is somewhat adapted), however it is incapable of the creative thinking that developers regularly need to engage in when architecting a solution for their use case. reply Kiro 1 hour agorootparentMy experience is the opposite. When I started using Copilot I thought it would only be good at standard boilerplate but I'm constantly surprised how well it understands my completely convoluted legacy architecture that barely I understand myself even though I'm the only contributor. reply smokel 3 hours agoparentprevIn my experience these tools amplify the quality of a programmer. I have seen good programmers dramatically increase their productivity, but I've also seen others copy-pasting for loops inside other for loops where one loop would definitely suffice. We're not quite there yet. reply bubbleRefuge 42 minutes agorootparentAbsolutely it amplifies. Complex and esoteric configuration of frameworks, for example, entails so much reading and Googling and can be very time consuming without AI. AI can help to bring custom software to the markets that could not otherwise afford to pay for it. reply croes 2 hours agorootparentprevI'm curious for the long-term effect. I observe a certain laziness in myself when it comes to certain problems. It's easier to ask a LLM and debug provided code, but I ask myself if I'm losing some problem solving capabilities in the long run because of this. Similar to the loss of speed in doing mental arithmetic because of calculators on the smartphone. reply croes 2 hours agoparentprev>The abundance of programming is going to allow almost everyone to become a great programmer. How do you become a great programmer if you don't really program? reply skydhash 3 hours agoparentprevShadow libraries did more to democratize anything than LLMs. And following a book like Elixir in Action (Manning) will get you there faster than chatting with LLMs or copilot generating code for you. reply icedchai 3 hours agoparentprevI'm skeptical. I've run into people who used LLMs to code, then can't debug it without someone else's help. It may get you 80% there though. reply whiplash451 2 hours agorootparentIt does not get you 80% there if it achieves what you described. It rather gets you 100% into trouble. reply croes 2 hours agorootparentProgrammer view vs management view. 100% of nothing vs 80% of enough. That's the risk of AI. Not that AI outperforms humans already but that managers believe it does. That and that code writing is the main work of programmers. reply resource_waste 3 hours agoprev [–] Given Llama is significantly better.. is the usecase that Mistral can be used for illegal and immoral activities? I was doing AI Dev and had to pick a model. You'd never use Mistral unless you were violating the llama license. The license is pretty permissive. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "On May 29, 2024, Mistral AI launched Codestral, an open-weight generative AI model for code generation, trained on over 80 programming languages.",
      "Codestral features a 22B model size and a 32k context window, outperforming competitors in benchmarks such as RepoBench and HumanEval.",
      "Available under the Mistral AI Non-Production License, Codestral can be accessed via a dedicated endpoint or integrated into tools like VSCode and JetBrains, with developers praising its speed, accuracy, and productivity impact."
    ],
    "commentSummary": [
      "Mistral's Code Model, released by mistral.ai, has a restrictive license prohibiting commercial use, live conditions, and internal company usage, limiting its practical applications and drawing criticism.",
      "The debate around Mistral's license highlights broader issues of copyright and licensing in AI-generated content and the misuse of the term \"open-source\" in AI.",
      "Users express frustration with AI's inconsistent code generation, particularly in complex tasks, and discuss the limitations and capabilities of various AI models, including Meta's Llama and OpenAI's GPT models."
    ],
    "points": 266,
    "commentCount": 123,
    "retryCount": 0,
    "time": 1716992170
  },
  {
    "id": 40508390,
    "title": "Key Lessons from a Year of Building with Large Language Models (Part I)",
    "originLink": "https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/",
    "originBody": "Radar / AI & ML What We Learned from a Year of Building with LLMs (Part I) By Eugene Yan, Bryan Bischof, Charles Frye, Hamel Husain, Jason Liu and Shreya Shankar May 28, 2024 To hear directly from the authors on this topic, sign up for the upcoming virtual event on June 20th, and the Generative AI Success Stories Superstream on the O’Reilly Media learning platform. Parts II and III of this series are forthcoming. Stay tuned. Learn faster. Dig deeper. See farther. Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful. Learn more It’s an exciting time to build with large language models (LLMs). Over the past year, LLMs have become “good enough” for real-world applications. The pace of improvements in LLMs, coupled with a parade of demos on social media, will fuel an estimated $200B investment in AI by 2025. LLMs are also broadly accessible, allowing everyone, not just ML engineers and scientists, to build intelligence into their products. While the barrier to entry for building AI products has been lowered, creating those effective beyond a demo remains a deceptively difficult endeavor. We’ve identified some crucial, yet often neglected, lessons and methodologies informed by machine learning that are essential for developing products based on LLMs. Awareness of these concepts can give you a competitive advantage against most others in the field without requiring ML expertise! Over the past year, the six of us have been building real-world applications on top of LLMs. We realized that there was a need to distill these lessons in one place for the benefit of the community. We come from a variety of backgrounds and serve in different roles, but we’ve all experienced firsthand the challenges that come with using this new technology. Two of us are independent consultants who’ve helped numerous clients take LLM projects from initial concept to successful product, seeing the patterns determining success or failure. One of us is a researcher studying how ML/AI teams work and how to improve their workflows. Two of us are leaders on applied AI teams: one at a tech giant and one at a startup. Finally, one of us has taught deep learning to thousands and now works on making AI tooling and infrastructure easier to use. Despite our different experiences, we were struck by the consistent themes in the lessons we’ve learned, and we’re surprised that these insights aren’t more widely discussed. Our goal is to make this a practical guide to building successful products around LLMs, drawing from our own experiences and pointing to examples from around the industry. We’ve spent the past year getting our hands dirty and gaining valuable lessons, often the hard way. While we don’t claim to speak for the entire industry, here we share some advice and lessons for anyone building products with LLMs. This work is organized into three sections: tactical, operational, and strategic. This is the first of three pieces. It dives into the tactical nuts and bolts of working with LLMs. We share best practices and common pitfalls around prompting, setting up retrieval-augmented generation, applying flow engineering, and evaluation and monitoring. Whether you’re a practitioner building with LLMs or a hacker working on weekend projects, this section was written for you. Look out for the operational and strategic sections in the coming weeks. Ready to dive delve in? Let’s go. Tactical In this section, we share best practices for the core components of the emerging LLM stack: prompting tips to improve quality and reliability, evaluation strategies to assess output, retrieval-augmented generation ideas to improve grounding, and more. We also explore how to design human-in-the-loop workflows. While the technology is still rapidly developing, we hope these lessons, the by-product of countless experiments we’ve collectively run, will stand the test of time and help you build and ship robust LLM applications. Prompting We recommend starting with prompting when developing new applications. It’s easy to both underestimate and overestimate its importance. It’s underestimated because the right prompting techniques, when used correctly, can get us very far. It’s overestimated because even prompt-based applications require significant engineering around the prompt to work well. Focus on getting the most out of fundamental prompting techniques A few prompting techniques have consistently helped improve performance across various models and tasks: n-shot prompts + in-context learning, chain-of-thought, and providing relevant resources. The idea of in-context learning via n-shot prompts is to provide the LLM with a few examples that demonstrate the task and align outputs to our expectations. A few tips: If n is too low, the model may over-anchor on those specific examples, hurting its ability to generalize. As a rule of thumb, aim for n ≥ 5. Don’t be afraid to go as high as a few dozen. Examples should be representative of the expected input distribution. If you’re building a movie summarizer, include samples from different genres in roughly the proportion you expect to see in practice. You don’t necessarily need to provide the full input-output pairs. In many cases, examples of desired outputs are sufficient. If you are using an LLM that supports tool use, your n-shot examples should also use the tools you want the agent to use. In chain-of-thought (CoT) prompting, we encourage the LLM to explain its thought process before returning the final answer. Think of it as providing the LLM with a sketchpad so it doesn’t have to do it all in memory. The original approach was to simply add the phrase “Let’s think step-by-step” as part of the instructions. However, we’ve found it helpful to make the CoT more specific, where adding specificity via an extra sentence or two often reduces hallucination rates significantly. For example, when asking an LLM to summarize a meeting transcript, we can be explicit about the steps, such as: First, list the key decisions, follow-up items, and associated owners in a sketchpad. Then, check that the details in the sketchpad are factually consistent with the transcript. Finally, synthesize the key points into a concise summary. Recently, some doubt has been cast on whether this technique is as powerful as believed. Additionally, there’s significant debate about exactly what happens during inference when chain-of-thought is used. Regardless, this technique is one to experiment with when possible. Providing relevant resources is a powerful mechanism to expand the model’s knowledge base, reduce hallucinations, and increase the user’s trust. Often accomplished via retrieval augmented generation (RAG), providing the model with snippets of text that it can directly utilize in its response is an essential technique. When providing the relevant resources, it’s not enough to merely include them; don’t forget to tell the model to prioritize their use, refer to them directly, and sometimes to mention when none of the resources are sufficient. These help “ground” agent responses to a corpus of resources. Structure your inputs and outputs Structured input and output help models better understand the input as well as return output that can reliably integrate with downstream systems. Adding serialization formatting to your inputs can help provide more clues to the model as to the relationships between tokens in the context, additional metadata to specific tokens (like types), or relate the request to similar examples in the model’s training data. As an example, many questions on the internet about writing SQL begin by specifying the SQL schema. Thus, you may expect that effective prompting for Text-to-SQL should include structured schema definitions; indeed. Structured output serves a similar purpose, but it also simplifies integration into downstream components of your system. Instructor and Outlines work well for structured output. (If you’re importing an LLM API SDK, use Instructor; if you’re importing Huggingface for a self-hosted model, use Outlines.) Structured input expresses tasks clearly and resembles how the training data is formatted, increasing the probability of better output. When using structured input, be aware that each LLM family has their own preferences. Claude prefers xml while GPT favors Markdown and JSON. With XML, you can even pre-fill Claude’s responses by providing a response tag like so. python messages=[ { \"role\": \"user\", \"content\": \"\"\"Extract the , , , andfrom this product description into your . The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices. \"\"\" }, { \"role\": \"assistant\", \"content\": \"\" } ] Have small prompts that do one thing, and only one thing, well A common anti-pattern/code smell in software is the “God Object,” where we have a single class or function that does everything. The same applies to prompts too. A prompt typically starts simple: A few sentences of instruction, a couple of examples, and we’re good to go. But as we try to improve performance and handle more edge cases, complexity creeps in. More instructions. Multi-step reasoning. Dozens of examples. Before we know it, our initially simple prompt is now a 2,000 token frankenstein. And to add injury to insult, it has worse performance on the more common and straightforward inputs! GoDaddy shared this challenge as their No. 1 lesson from building with LLMs. Just like how we strive (read: struggle) to keep our systems and code simple, so should we for our prompts. Instead of having a single, catch-all prompt for the meeting transcript summarizer, we can break it into steps to: Extract key decisions, action items, and owners into structured format Check extracted details against the original transcription for consistency Generate a concise summary from the structured details As a result, we’ve split our single prompt into multiple prompts that are each simple, focused, and easy to understand. And by breaking them up, we can now iterate and eval each prompt individually. Craft your context tokens Rethink, and challenge your assumptions about how much context you actually need to send to the agent. Be like Michaelangelo, do not build up your context sculpture—chisel away the superfluous material until the sculpture is revealed. RAG is a popular way to collate all of the potentially relevant blocks of marble, but what are you doing to extract what’s necessary? We’ve found that taking the final prompt sent to the model—with all of the context construction, and meta-prompting, and RAG results—putting it on a blank page and just reading it, really helps you rethink your context. We have found redundancy, self-contradictory language, and poor formatting using this method. The other key optimization is the structure of your context. Your bag-of-docs representation isn’t helpful for humans, don’t assume it’s any good for agents. Think carefully about how you structure your context to underscore the relationships between parts of it, and make extraction as simple as possible. Information Retrieval/RAG Beyond prompting, another effective way to steer an LLM is by providing knowledge as part of the prompt. This grounds the LLM on the provided context which is then used for in-context learning. This is known as retrieval-augmented generation (RAG). Practitioners have found RAG effective at providing knowledge and improving output, while requiring far less effort and cost compared to finetuning.RAG is only as good as the retrieved documents’ relevance, density, and detail The quality of your RAG’s output is dependent on the quality of retrieved documents, which in turn can be considered along a few factors. The first and most obvious metric is relevance. This is typically quantified via ranking metrics such as Mean Reciprocal Rank (MRR) or Normalized Discounted Cumulative Gain (NDCG). MRR evaluates how well a system places the first relevant result in a ranked list while NDCG considers the relevance of all the results and their positions. They measure how good the system is at ranking relevant documents higher and irrelevant documents lower. For example, if we’re retrieving user summaries to generate movie review summaries, we’ll want to rank reviews for the specific movie higher while excluding reviews for other movies. Like traditional recommendation systems, the rank of retrieved items will have a significant impact on how the LLM performs on downstream tasks. To measure the impact, run a RAG-based task but with the retrieved items shuffled—how does the RAG output perform? Second, we also want to consider information density. If two documents are equally relevant, we should prefer one that’s more concise and has lesser extraneous details. Returning to our movie example, we might consider the movie transcript and all user reviews to be relevant in a broad sense. Nonetheless, the top-rated reviews and editorial reviews will likely be more dense in information. Finally, consider the level of detail provided in the document. Imagine we’re building a RAG system to generate SQL queries from natural language. We could simply provide table schemas with column names as context. But, what if we include column descriptions and some representative values? The additional detail could help the LLM better understand the semantics of the table and thus generate more correct SQL. Don’t forget keyword search; use it as a baseline and in hybrid search. Given how prevalent the embedding-based RAG demo is, it’s easy to forget or overlook the decades of research and solutions in information retrieval. Nonetheless, while embeddings are undoubtedly a powerful tool, they are not the be all and end all. First, while they excel at capturing high-level semantic similarity, they may struggle with more specific, keyword-based queries, like when users search for names (e.g., Ilya), acronyms (e.g., RAG), or IDs (e.g., claude-3-sonnet). Keyword-based search, such as BM25, are explicitly designed for this. And after years of keyword-based search, users have likely taken it for granted and may get frustrated if the document they expect to retrieve isn’t being returned. Vector embeddings do not magically solve search. In fact, the heavy lifting is in the step before you re-rank with semantic similarity search. Making a genuine improvement over BM25 or full-text search is hard. — Aravind Srinivas, CEO Perplexity.ai We’ve been communicating this to our customers and partners for months now. Nearest Neighbor Search with naive embeddings yields very noisy results and you’re likely better off starting with a keyword-based approach. — Beyang Liu, CTO Sourcegraph Second, it’s more straightforward to understand why a document was retrieved with keyword search—we can look at the keywords that match the query. In contrast, embedding-based retrieval is less interpretable. Finally, thanks to systems like Lucene and OpenSearch that have been optimized and battle-tested over decades, keyword search is usually more computationally efficient. In most cases, a hybrid will work best: keyword matching for the obvious matches, and embeddings for synonyms, hypernyms, and spelling errors, as well as multimodality (e.g., images and text). Shortwave shared how they built their RAG pipeline, including query rewriting, keyword + embedding retrieval, and ranking. Prefer RAG over fine-tuning for new knowledge Both RAG and fine-tuning can be used to incorporate new information into LLMs and increase performance on specific tasks. Thus, which should we try first? Recent research suggests that RAG may have an edge. One study compared RAG against unsupervised fine-tuning (a.k.a. continued pre-training), evaluating both on a subset of MMLU and current events. They found that RAG consistently outperformed fine-tuning for knowledge encountered during training as well as entirely new knowledge. In another paper, they compared RAG against supervised fine-tuning on an agricultural dataset. Similarly, the performance boost from RAG was greater than fine-tuning, especially for GPT-4 (see Table 20 of the paper). Beyond improved performance, RAG comes with several practical advantages too. First, compared to continuous pretraining or fine-tuning, it’s easier—and cheaper!—to keep retrieval indices up-to-date. Second, if our retrieval indices have problematic documents that contain toxic or biased content, we can easily drop or modify the offending documents. In addition, the R in RAG provides finer grained control over how we retrieve documents. For example, if we’re hosting a RAG system for multiple organizations, by partitioning the retrieval indices, we can ensure that each organization can only retrieve documents from their own index. This ensures that we don’t inadvertently expose information from one organization to another. Long-context models won’t make RAG obsolete With Gemini 1.5 providing context windows of up to 10M tokens in size, some have begun to question the future of RAG. I tend to believe that Gemini 1.5 is significantly overhyped by Sora. A context window of 10M tokens effectively makes most of existing RAG frameworks unnecessary—you simply put whatever your data into the context and talk to the model like usual. Imagine how it does to all the startups/agents/LangChain projects where most of the engineering efforts goes to RAG 😅 Or in one sentence: the 10m context kills RAG. Nice work Gemini. — Yao Fu While it’s true that long contexts will be a game-changer for use cases such as analyzing multiple documents or chatting with PDFs, the rumors of RAG’s demise are greatly exaggerated. First, even with a context window of 10M tokens, we’d still need a way to select information to feed into the model. Second, beyond the narrow needle-in-a-haystack eval, we’ve yet to see convincing data that models can effectively reason over such a large context. Thus, without good retrieval (and ranking), we risk overwhelming the model with distractors, or may even fill the context window with completely irrelevant information. Finally, there’s cost. The Transformer’s inference cost scales quadratically (or linearly in both space and time) with context length. Just because there exists a model that could read your organization’s entire Google Drive contents before answering each question doesn’t mean that’s a good idea. Consider an analogy to how we use RAM: we still read and write from disk, even though there exist compute instances with RAM running into the tens of terabytes. So don’t throw your RAGs in the trash just yet. This pattern will remain useful even as context windows grow in size. Tuning and optimizing workflows Prompting an LLM is just the beginning. To get the most juice out of them, we need to think beyond a single prompt and embrace workflows. For example, how could we split a single complex task into multiple simpler tasks? When is finetuning or caching helpful with increasing performance and reducing latency/cost? In this section, we share proven strategies and real-world examples to help you optimize and build reliable LLM workflows. Step-by-step, multi-turn “flows” can give large boosts. We already know that by decomposing a single big prompt into multiple smaller prompts, we can achieve better results. An example of this is AlphaCodium: By switching from a single prompt to a multi-step workflow, they increased GPT-4 accuracy (pass@5) on CodeContests from 19% to 44%. The workflow includes: Reflecting on the problem Reasoning on the public tests Generating possible solutions Ranking possible solutions Generating synthetic tests Iterating on the solutions on public and synthetic tests. Small tasks with clear objectives make for the best agent or flow prompts. It’s not required that every agent prompt requests structured output, but structured outputs help a lot to interface with whatever system is orchestrating the agent’s interactions with the environment. Some things to try An explicit planning step, as tightly specified as possible. Consider having predefined plans to choose from (c.f. https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del). Rewriting the original user prompts into agent prompts. Be careful, this process is lossy! Agent behaviors as linear chains, DAGs, and State-Machines; different dependency and logic relationships can be more and less appropriate for different scales. Can you squeeze performance optimization out of different task architectures? Planning validations; your planning can include instructions on how to evaluate the responses from other agents to make sure the final assembly works well together. Prompt engineering with fixed upstream state—make sure your agent prompts are evaluated against a collection of variants of what may happen before. Prioritize deterministic workflows for now While AI agents can dynamically react to user requests and the environment, their non-deterministic nature makes them a challenge to deploy. Each step an agent takes has a chance of failing, and the chances of recovering from the error are poor. Thus, the likelihood that an agent completes a multi-step task successfully decreases exponentially as the number of steps increases. As a result, teams building agents find it difficult to deploy reliable agents. A promising approach is to have agent systems that produce deterministic plans which are then executed in a structured, reproducible way. In the first step, given a high-level goal or prompt, the agent generates a plan. Then, the plan is executed deterministically. This allows each step to be more predictable and reliable. Benefits include: Generated plans can serve as few-shot samples to prompt or finetune an agent. Deterministic execution makes the system more reliable, and thus easier to test and debug. Furthermore, failures can be traced to the specific steps in the plan. Generated plans can be represented as directed acyclic graphs (DAGs) which are easier, relative to a static prompt, to understand and adapt to new situations. The most successful agent builders may be those with strong experience managing junior engineers because the process of generating plans is similar to how we instruct and manage juniors. We give juniors clear goals and concrete plans, instead of vague open-ended directions, and we should do the same for our agents too. In the end, the key to reliable, working agents will likely be found in adopting more structured, deterministic approaches, as well as collecting data to refine prompts and finetune models. Without this, we’ll build agents that may work exceptionally well some of the time, but on average, disappoint users which leads to poor retention. Getting more diverse outputs beyond temperature Suppose your task requires diversity in an LLM’s output. Maybe you’re writing an LLM pipeline to suggest products to buy from your catalog given a list of products the user bought previously. When running your prompt multiple times, you might notice that the resulting recommendations are too similar—so you might increase the temperature parameter in your LLM requests. Briefly, increasing the temperature parameter makes LLM responses more varied. At sampling time, the probability distributions of the next token become flatter, meaning that tokens which are usually less likely get chosen more often. Still, when increasing temperature, you may notice some failure modes related to output diversity. For example,Some products from the catalog that could be a good fit may never be output by the LLM.The same handful of products might be overrepresented in outputs, if they are highly likely to follow the prompt based on what the LLM has learned at training time.If the temperature is too high, you may get outputs that reference nonexistent products (or gibberish!) In other words, increasing temperature does not guarantee that the LLM will sample outputs from the probability distribution you expect (e.g., uniform random). Nonetheless, we have other tricks to increase output diversity. The simplest way is to adjust elements within the prompt. For example, if the prompt template includes a list of items, such as historical purchases, shuffling the order of these items each time they’re inserted into the prompt can make a significant difference. Additionally, keeping a short list of recent outputs can help prevent redundancy. In our recommended products example, by instructing the LLM to avoid suggesting items from this recent list, or by rejecting and resampling outputs that are similar to recent suggestions, we can further diversify the responses. Another effective strategy is to vary the phrasing used in the prompts. For instance, incorporating phrases like “pick an item that the user would love using regularly” or “select a product that the user would likely recommend to friends” can shift the focus and thereby influence the variety of recommended products. Caching is underrated. Caching saves cost and eliminates generation latency by removing the need to recompute responses for the same input. Furthermore, if a response has previously been guardrailed, we can serve these vetted responses and reduce the risk of serving harmful or inappropriate content. One straightforward approach to caching is to use unique IDs for the items being processed, such as if we’re summarizing new articles or product reviews. When a request comes in, we can check to see if a summary already exists in the cache. If so, we can return it immediately; if not, we generate, guardrail, and serve it, and then store it in the cache for future requests. For more open-ended queries, we can borrow techniques from the field of search, which also leverages caching for open-ended inputs. Features like autocomplete and spelling correction also help normalize user input and thus increase the cache hit rate. When to fine-tune We may have some tasks where even the most cleverly designed prompts fall short. For example, even after significant prompt engineering, our system may still be a ways from returning reliable, high-quality output. If so, then it may be necessary to finetune a model for your specific task. Successful examples include: Honeycomb’s Natural Language Query Assistant: Initially, the “programming manual” was provided in the prompt together with n-shot examples for in-context learning. While this worked decently, fine-tuning the model led to better output on the syntax and rules of the domain-specific language. ReChat’s Lucy: The LLM needed to generate responses in a very specific format that combined structured and unstructured data for the frontend to render correctly. Fine-tuning was essential to get it to work consistently. Nonetheless, while fine-tuning can be effective, it comes with significant costs. We have to annotate fine-tuning data, finetune and evaluate models, and eventually self-host them. Thus, consider if the higher upfront cost is worth it. If prompting gets you 90% of the way there, then fine-tuning may not be worth the investment. However, if we do decide to fine-tune, to reduce the cost of collecting human annotated data, we can generate and finetune on synthetic data, or bootstrap on open-source data. Evaluation & Monitoring Evaluating LLMs can be a minefield. The inputs and the outputs of LLMs are arbitrary text, and the tasks we set them to are varied. Nonetheless, rigorous and thoughtful evals are critical—it’s no coincidence that technical leaders at OpenAI work on evaluation and give feedback on individual evals. Evaluating LLM applications invites a diversity of definitions and reductions: it’s simply unit testing, or it’s more like observability, or maybe it’s just data science. We have found all of these perspectives useful. In the following section, we provide some lessons we’ve learned about what is important in building evals and monitoring pipelines. Create a few assertion-based unit tests from real input/output samples Create unit tests (i.e., assertions) consisting of samples of inputs and outputs from production, with expectations for outputs based on at least three criteria. While three criteria might seem arbitrary, it’s a practical number to start with; fewer might indicate that your task isn’t sufficiently defined or is too open-ended, like a general-purpose chatbot. These unit tests, or assertions, should be triggered by any changes to the pipeline, whether it’s editing a prompt, adding new context via RAG, or other modifications. This write-up has an example of an assertion-based test for an actual use case. Consider beginning with assertions that specify phrases or ideas to either include or exclude in all responses. Also consider checks to ensure that word, item, or sentence counts lie within a range. For other kinds of generation, assertions can look different. Execution-evaluation is a powerful method for evaluating code-generation, wherein you run the generated code and determine that the state of runtime is sufficient for the user-request. As an example, if the user asks for a new function named foo; then after executing the agent’s generated code, foo should be callable! One challenge in execution-evaluation is that the agent code frequently leaves the runtime in slightly different form than the target code. It can be effective to “relax” assertions to the absolute most weak assumptions that any viable answer would satisfy. Finally, using your product as intended for customers (i.e., “dogfooding”) can provide insight into failure modes on real-world data. This approach not only helps identify potential weaknesses, but also provides a useful source of production samples that can be converted into evals. LLM-as-Judge can work (somewhat), but it’s not a silver bullet LLM-as-Judge, where we use a strong LLM to evaluate the output of other LLMs, has been met with skepticism by some. (Some of us were initially huge skeptics.) Nonetheless, when implemented well, LLM-as-Judge achieves decent correlation with human judgements, and can at least help build priors about how a new prompt or technique may perform. Specifically, when doing pairwise comparisons (e.g., control vs. treatment), LLM-as-Judge typically gets the direction right though the magnitude of the win/loss may be noisy. Here are some suggestions to get the most out of LLM-as-Judge: Use pairwise comparisons: Instead of asking the LLM to score a single output on a Likert scale, present it with two options and ask it to select the better one. This tends to lead to more stable results. Control for position bias: The order of options presented can bias the LLM’s decision. To mitigate this, do each pairwise comparison twice, swapping the order of pairs each time. Just be sure to attribute wins to the right option after swapping! Allow for ties: In some cases, both options may be equally good. Thus, allow the LLM to declare a tie so it doesn’t have to arbitrarily pick a winner. Use Chain-of-Thought: Asking the LLM to explain its decision before giving a final preference can increase eval reliability. As a bonus, this allows you to use a weaker but faster LLM and still achieve similar results. Because frequently this part of the pipeline is in batch mode, the extra latency from CoT isn’t a problem. Control for response length: LLMs tend to bias toward longer responses. To mitigate this, ensure response pairs are similar in length. One particularly powerful application of LLM-as-Judge is checking a new prompting strategy against regression. If you have tracked a collection of production results, sometimes you can rerun those production examples with a new prompting strategy, and use LLM-as-Judge to quickly assess where the new strategy may suffer. Here’s an example of a simple but effective approach to iterate on LLM-as-Judge, where we simply log the LLM response, judge’s critique (i.e., CoT), and final outcome. They are then reviewed with stakeholders to identify areas for improvement. Over three iterations, agreement with human and LLM improved from 68% to 94%! LLM-as-Judge is not a silver bullet though. There are subtle aspects of language where even the strongest models fail to evaluate reliably. In addition, we’ve found that conventional classifiers and reward models can achieve higher accuracy than LLM-as-Judge, and with lower cost and latency. For code generation, LLM-as-Judge can be weaker than more direct evaluation strategies like execution-evaluation. The “intern test” for evaluating generations We like to use the following “intern test” when evaluating generations: If you took the exact input to the language model, including the context, and gave it to an average college student in the relevant major as a task, could they succeed? How long would it take? If the answer is no because the LLM lacks the required knowledge, consider ways to enrich the context. If the answer is no and we simply can’t improve the context to fix it, then we may have hit a task that’s too hard for contemporary LLMs. If the answer is yes, but it would take a while, we can try to reduce the complexity of the task. Is it decomposable? Are there aspects of the task that can be made more templatized? If the answer is yes, they would get it quickly, then it’s time to dig into the data. What’s the model doing wrong? Can we find a pattern of failures? Try asking the model to explain itself before or after it responds, to help you build a theory of mind. Overemphasizing certain evals can hurt overall performance “When a measure becomes a target, it ceases to be a good measure.” — Goodhart’s Law An example of this is the Needle-in-a-Haystack (NIAH) eval. The original eval helped quantify model recall as context sizes grew, as well as how recall is affected by needle position. However, it’s been so overemphasized that it’s featured as Figure 1 for Gemini 1.5’s report. The eval involves inserting a specific phrase (“The special magic {city} number is: {number}”) into a long document which repeats the essays of Paul Graham, and then prompting the model to recall the magic number. While some models achieve near-perfect recall, it’s questionable whether NIAH truly reflects the reasoning and recall abilities needed in real-world applications. Consider a more practical scenario: Given the transcript of an hour-long meeting, can the LLM summarize the key decisions and next steps, as well as correctly attribute each item to the relevant person? This task is more realistic, going beyond rote memorization and also considering the ability to parse complex discussions, identify relevant information, and synthesize summaries. Here’s an example of a practical NIAH eval. Using transcripts of doctor-patient video calls, the LLM is queried about the patient’s medication. It also includes a more challenging NIAH, inserting a phrase for random ingredients for pizza toppings, such as “The secret ingredients needed to build the perfect pizza are: Espresso-soaked dates, Lemon and Goat cheese.” Recall was around 80% on the medication task and 30% on the pizza task. Tangentially, an overemphasis on NIAH evals can lead to lower performance on extraction and summarization tasks. Because these LLMs are so finetuned to attend to every sentence, they may start to treat irrelevant details and distractors as important, thus including them in the final output (when they shouldn’t!) This could also apply to other evals and use cases. For example, summarization. An emphasis on factual consistency could lead to summaries that are less specific (and thus less likely to be factually inconsistent) and possibly less relevant. Conversely, an emphasis on writing style and eloquence could lead to more flowery, marketing-type language that could introduce factual inconsistencies. Simplify annotation to binary tasks or pairwise comparisons Providing open-ended feedback or ratings for model output on a Likert scale is cognitively demanding. As a result, the data collected is more noisy—due to variability among human raters—and thus less useful. A more effective approach is to simplify the task and reduce the cognitive burden on annotators. Two tasks that work well are binary classifications and pairwise comparisons. In binary classifications, annotators are asked to make a simple yes-or-no judgment on the model’s output. They might be asked whether the generated summary is factually consistent with the source document, or whether the proposed response is relevant, or if it contains toxicity. Compared to the Likert scale, binary decisions are more precise, have higher consistency among raters, and lead to higher throughput. This was how Doordash setup their labeling queues for tagging menu items though a tree of yes-no questions. In pairwise comparisons, the annotator is presented with a pair of model responses and asked which is better. Because it’s easier for humans to say “A is better than B” than to assign an individual score to either A or B individually, this leads to faster and more reliable annotations (over Likert scales). At a Llama2 meetup, Thomas Scialom, an author on the Llama2 paper, confirmed that pairwise-comparisons were faster and cheaper than collecting supervised finetuning data such as written responses. The former’s cost is $3.5 per unit while the latter’s cost is $25 per unit. If you’re starting to write labeling guidelines, here are some reference guidelines from Google and Bing Search. (Reference-free) evals and guardrails can be used interchangeably Guardrails help to catch inappropriate or harmful content while evals help to measure the quality and accuracy of the model’s output. In the case of reference-free evals, they may be considered two sides of the same coin. Reference-free evals are evaluations that don’t rely on a “golden” reference, such as a human-written answer, and can assess the quality of output based solely on the input prompt and the model’s response. Some examples of these are summarization evals, where we only have to consider the input document to evaluate the summary on factual consistency and relevance. If the summary scores poorly on these metrics, we can choose not to display it to the user, effectively using the eval as a guardrail. Similarly, reference-free translation evals can assess the quality of a translation without needing a human-translated reference, again allowing us to use it as a guardrail. LLMs will return output even when they shouldn’t A key challenge when working with LLMs is that they’ll often generate output even when they shouldn’t. This can lead to harmless but nonsensical responses, or more egregious defects like toxicity or dangerous content. For example, when asked to extract specific attributes or metadata from a document, an LLM may confidently return values even when those values don’t actually exist. Alternatively, the model may respond in a language other than English because we provided non-English documents in the context. While we can try to prompt the LLM to return a “not applicable” or “unknown” response, it’s not foolproof. Even when the log probabilities are available, they’re a poor indicator of output quality. While log probs indicate the likelihood of a token appearing in the output, they don’t necessarily reflect the correctness of the generated text. On the contrary, for instruction-tuned models that are trained to respond to queries and generate coherent response, log probabilities may not be well-calibrated. Thus, while a high log probability may indicate that the output is fluent and coherent, it doesn’t mean it’s accurate or relevant. While careful prompt engineering can help to some extent, we should complement it with robust guardrails that detect and filter/regenerate undesired output. For example, OpenAI provides a content moderation API that can identify unsafe responses such as hate speech, self-harm, or sexual output. Similarly, there are numerous packages for detecting personally identifiable information (PII). One benefit is that guardrails are largely agnostic of the use case and can thus be applied broadly to all output in a given language. In addition, with precise retrieval, our system can deterministically respond “I don’t know” if there are no relevant documents. A corollary here is that LLMs may fail to produce outputs when they are expected to. This can happen for various reasons, from straightforward issues like long tail latencies from API providers to more complex ones such as outputs being blocked by content moderation filters. As such, it’s important to consistently log inputs and (potentially a lack of) outputs for debugging and monitoring. Hallucinations are a stubborn problem. Unlike content safety or PII defects which have a lot of attention and thus seldom occur, factual inconsistencies are stubbornly persistent and more challenging to detect. They’re more common and occur at a baseline rate of 5 – 10%, and from what we’ve learned from LLM providers, it can be challenging to get it below 2%, even on simple tasks such as summarization. To address this, we can combine prompt engineering (upstream of generation) and factual inconsistency guardrails (downstream of generation). For prompt engineering, techniques like CoT help reduce hallucination by getting the LLM to explain its reasoning before finally returning the output. Then, we can apply a factual inconsistency guardrail to assess the factuality of summaries and filter or regenerate hallucinations. In some cases, hallucinations can be deterministically detected. When using resources from RAG retrieval, if the output is structured and identifies what the resources are, you should be able to manually verify they’re sourced from the input context. About the authors Eugene Yan designs, builds, and operates machine learning systems that serve customers at scale. He’s currently a Senior Applied Scientist at Amazon where he builds RecSys serving millions of customers worldwide RecSys 2022 keynote and applies LLMs to serve customers better AI Eng Summit 2023 keynote. Previously, he led machine learning at Lazada (acquired by Alibaba) and a Healthtech Series A. He writes & speaks about ML, RecSys, LLMs, and engineering at eugeneyan.com and ApplyingML.com. Bryan Bischof is the Head of AI at Hex, where he leads the team of engineers building Magic—the data science and analytics copilot. Bryan has worked all over the data stack leading teams in analytics, machine learning engineering, data platform engineering, and AI engineering. He started the data team at Blue Bottle Coffee, led several projects at Stitch Fix, and built the data teams at Weights and Biases. Bryan previously co-authored the book Building Production Recommendation Systems with O’Reilly, and teaches Data Science and Analytics in the graduate school at Rutgers. His Ph.D. is in pure mathematics. Charles Frye teaches people to build AI applications. After publishing research in psychopharmacology and neurobiology, he got his Ph.D. at the University of California, Berkeley, for dissertation work on neural network optimization. He has taught thousands the entire stack of AI application development, from linear algebra fundamentals to GPU arcana and building defensible businesses, through educational and consulting work at Weights and Biases, Full Stack Deep Learning, and Modal. Hamel Husain is a machine learning engineer with over 25 years of experience. He has worked with innovative companies such as Airbnb and GitHub, which included early LLM research used by OpenAI for code understanding. He has also led and contributed to numerous popular open-source machine-learning tools. Hamel is currently an independent consultant helping companies operationalize Large Language Models (LLMs) to accelerate their AI product journey. Jason Liu is a distinguished machine learning consultant known for leading teams to successfully ship AI products. Jason’s technical expertise covers personalization algorithms, search optimization, synthetic data generation, and MLOps systems. His experience includes companies like Stitchfix, where he created a recommendation framework and observability tools that handled 350 million daily requests. Additional roles have included Meta, NYU, and startups such as Limitless AI and Trunk Tools. Shreya Shankar is an ML engineer and PhD student in computer science at UC Berkeley. She was the first ML engineer at 2 startups, building AI-powered products from scratch that serve thousands of users daily. As a researcher, her work focuses on addressing data challenges in production ML systems through a human-centered approach. Her work has appeared in top data management and human-computer interaction venues like VLDB, SIGMOD, CIDR, and CSCW. Contact Us We would love to hear your thoughts on this post. You can contact us at contact@applied-llms.org. Many of us are open to various forms of consulting and advisory. We will route you to the correct expert(s) upon contact with us if appropriate. Acknowledgements This series started as a conversation in a group chat, where Bryan quipped that he was inspired to write “A Year of AI Engineering.” Then, ✨magic✨ happened in the group chat, and we were all inspired to chip in and share what we’ve learned so far. The authors would like to thank Eugene for leading the bulk of the document integration and overall structure in addition to a large proportion of the lessons. Additionally, for primary editing responsibilities and document direction. The authors would like to thank Bryan for the spark that led to this writeup, restructuring the write-up into tactical, operational, and strategic sections and their intros, and for pushing us to think bigger on how we could reach and help the community. The authors would like to thank Charles for his deep dives on cost and LLMOps, as well as weaving the lessons to make them more coherent and tighter—you have him to thank for this being 30 instead of 40 pages! The authors appreciate Hamel and Jason for their insights from advising clients and being on the front lines, for their broad generalizable learnings from clients, and for deep knowledge of tools. And finally, thank you Shreya for reminding us of the importance of evals and rigorous production practices and for bringing her research and original results to this piece. Finally, the authors would like to thank all the teams who so generously shared your challenges and lessons in your own write-ups which we’ve referenced throughout this series, along with the AI communities for your vibrant participation and engagement with this group. Post topics: AI & ML, Artificial Intelligence Post tags: Deep Dive Share: Tweet Share Get the O’Reilly Radar Trends to Watch newsletter Tracking need-to-know trends at the intersection of business and technology. Your email Country - Select country - United States Afghanistan Albania Algeria Andorra Angola Antigua and Barbuda Argentina Armenia Aruba Australia Austria Azerbaijan The Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bosnia and Herzegovina Botswana Brazil Brunei Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Central African Republic Chad Chile People's Republic of China Colombia Comoros Congo, Republic of the Congo, Democratic Republic of the Cook Islands Costa Rica Côte d'Ivoire (Ivory Coast) Croatia Cuba Cyprus Czechia Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Eswatini (formerly Swaziland) Ethiopia Federated States of Micronesia Fiji Finland France Gabon The Gambia Georgia Germany Ghana Greece Grenada Guatemala Guinea Guinea-Bissau Guyana Haiti Honduras Hungary Iceland India Indonesia Iran Iraq Ireland Israel Italy Jamaica Japan Jordan Kazakhstan Kenya Kiribati Korea, Democratic People's Republic of Korea, Republic of Kuwait Kyrgyzstan Laos Latvia Lebanon Lesotho Liberia Libya Liechtenstein Lithuania Luxembourg Macedonia, Republic of Madagascar Malawi Malaysia Maldives Mali Malta Mauritania Mauritius Mexico Moldova Monaco Mongolia Montenegro Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands New Zealand Nicaragua Niger Nigeria Niue Norway Oman Pakistan Palestine, State of Panama Papua New Guinea Paraguay Peru Philippines Poland Portugal Qatar Romania Russia Rwanda Saint Kitts and Nevis Saint Lucia Saint Vincent and the Grenadines Samoa San Marino São Tomé and Príncipe Saudi Arabia Senegal Serbia Seychelles Sierra Leone Singapore Slovakia Slovenia Solomon Islands Somalia South Africa South Sudan Spain Sri Lanka Sudan Suriname Sweden Switzerland Syria Taiwan Tajikistan Tanzania Thailand Timor-Leste (East Timor) Togo Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States Uruguay Uzbekistan Vanuatu Vatican City Venezuela Vietnam Yemen Zambia Zimbabwe Subscribe Please read our privacy policy. Thank you for subscribing.",
    "commentLink": "https://news.ycombinator.com/item?id=40508390",
    "commentBody": "What We Learned from a Year of Building with LLMs (oreilly.com)259 points by 7d7n 14 hours agohidepastfavorite77 comments wokwokwok 10 hours agoMildly surprised to see no mention of my top 2 LLM fails: 1) you’re sampling a distribution; if you only sample once, your sample is not representative of the distribution. For evaluating prompts and running in production; your hallucination rate is inversely proportional to the number of times you sample. Sample many times and vote is a highly effective (but slow) strategy. There is almost zero value in evaluating a prompt by only running it once. 2) Sequences are generated in order. Asking an LLM to make a decision and justify its decision in that order is literally meaningless. Once the “decision” tokens are generated; the justification does not influence them. It’s not like they happen “all at once” there is a specific sequence to generating output where the later output cannot magically influence the output which has already been generated. This is true for sequential outputs from an LLM (obviously), but it is also true inside single outputs. The sequence of tokens in the output is a sequence. If you’re generating structured output (eg json, xml) which is not sequenced, and your output is something like {decision: …, reason:…} it literally does nothing. …but, it is valuable to “show the working out” when, as above, you then evaluate multiple solutions to a single request and pick the best one(s). reply refibrillator 3 hours agoparentThere’s a few subtle misconceptions being spread here: 1) Hallucination rate is not inversely proportional to number of samples, unless you assume statistical independence. As you’re sampling from the same generative process each time, any inherent bias of the LLM could affect every sample (eg see golden gate Claude). Naively calculating hallucination rate as P^N is going to be a massive underestimate of the true error rate for many tasks requiring factual accuracy. 2) You’re right that output tokens are generated autoregressively, but you are thinking like a human. Transformer attention layers are permutation invariant. The ordering of output (eg decision first then justification later) is inconsequential, either can be derived from input context and hidden state where there is no causal masking of attention. reply bunderbunder 3 hours agorootparentJustification before decision still works out better in practice, though, because of chain of thought [1]. You'll tend to get more accurate and better-justified decisions. With decision before justification, you tend to have a greater risk of the output being a wrong decision followed by convincing BS justifying it. (edit: Another way you could think of it is, LLMs still can't violate causality. Attention heads' ability to look in both directions with respect to a particular token's position in the sequence does not enable them to see into the future and observe tokens that don't exist yet.) 1: https://arxiv.org/abs/2201.11903 reply wtarreau 3 hours agorootparentI totally agree, that's what I had to do with my patchbot that evaluates haproxy patches to be backported ( https://github.com/haproxy/haproxy/tree/master/dev/patchbot/ ). Originally it would just provide a verdict and justify it and it worked extremely poorly, often with a justification that directly contradicted the verdict. I swapped that by asking the analysis and the final verdict and now the success rate is totally amazing (particularly with mistral that remains unbeatable at this task by obeying extremely well to instructions). reply BeefySwain 2 hours agorootparentYou find Mistral to be the best \"open\"/local model? Or you find it to be the best model period? reply olooney 6 hours agoparentprev> Sample many times and vote is a highly effective (but slow) strategy. Beam search[1] has long been a great way to sample from language models, even before transformers. Essentially you keep track of the top N most promising threads and sample randomly from those. OpenAI doesn't offer beam search yet, just temperature and top_k, but I hope they add support for it because it's far more efficient than just starting over each time. [1]: https://www.width.ai/post/what-is-beam-search reply CuriouslyC 7 hours agoparentprevYou don't need to hit a LLM multiple times to get multiple distributions, just provide a list of perspectives and ask the model to answer the question from each of them in turn, then combine the results right there in the prompt. I have tested this approach a bunch, it works. reply 1minusp 2 hours agorootparentWhat are some good metrics to evaluate LLM output performance in general? Or is it too hard to quantify at this stage (or not understood well enough). Perhaps the latter, or else those could be in the loss function itself.. reply wokwokwok 6 hours agorootparentprev> You don't need to hit a LLM multiple times to get multiple distributions This isn't correct. You're just sampling a different distribution. You can adjust the shape of the distribution with your prompt; certainly... and if you make a good prompt, perhaps, you can narrow the 'solution space' that you sample into. ...but, you're still sampling randomly into a distribution, and the N'th token relies on the (N-1)'th token as an input; that means that a random deviance to a bad solution is incrementally responsible for a bad solution, regardless of your prompt. ... Consider the prompt \"Your name is Pete. What is your name?\" Seems like a fairly narrow distribution right? However, there's a small chance that the first generated token is 'D'; it's small, but non-zero. That means it happens from time to time. The higher the temperature, the higher the randomization of the output tokens. How do you imagine that completion runs when it happens? Doug? Dane? Danial? Dave? Don't know? I tell you what it is not; it's not Pete. That's the issue here; when you sample, the solution space is wide, and any single sample has a P chance of being a stupid hallucination. When you sample multiple times, the chance of that hallucination is P * P * P * P, etc. by the number of time you sample. You can therefore control your error rate this way, because, you can calculate the chance of failure as P^N. Yes, obviously, if your P(good answer)There is almost zero value in evaluating a prompt by only running it once. To the user But these tools are marketed as if you do only need to run them once to get a good result; The companies behind them would really want you to stop hammering the button that deletes their money. As an aside: > For evaluating prompts and running in production; your hallucination rate is inversely proportional to the number of times you sample. This isn't really true, and requires you to fuzz the prompt itself for best effect. Making the \"spam the LLM with requests\" problem much worse. reply piloto_ciego 2 hours agoparentprev> There is almost zero value in evaluating a prompt by only running it once. This is crazy town banana pants. reply altdataseller 7 hours agoparentprev>> If you’re generating structured output (eg json, xml) which is not sequenced, and your output is something like {decision: …, reason:…} it literally does nothing. Is this true if you are using RAG too? reply Imanari 6 hours agorootparentThe core issue that parent is talking about is that the decision-tokens should built on the reasoning-tokens vs the reasoning-tokens are generated according to the decison-tokens. RAG just provides the context the LLM should reason about. reply elicksaur 5 hours agoprevUpon loading the site, a chat bubble pops up and auto-plays a loud ding. Is the innovation of LLMs really a regression to 2000s spam sites? Can’t say I’m excited. reply mloncode 13 hours agoprevHello this is Hamel, one of the authors (among the list of other amazing authors). Happy to answer any questions as well as tag any of my colleagues to answer any questions! (Note: this is only Part 1 of 3 of a series that has already been written and the other 2 parts will be released shortly) reply dejobaan 4 hours agoparentThe breadth and (for lack of a better term) concreteness are just fantastic. Thank you for writing this! reply sieszpak 12 hours agoparentprevI would like to know your opinion about grafRAG and the ontology. Knowledge Graphs (KG) are a game changer for companies with a lot of unstructured data in the context of applying them with LLM reply bbischof 12 hours agorootparentBryan here, one of the authors. Sure. Ultimately, you want to use KG to increase your ability to do great retrieval. Why do graphs help with retrieval? Well, don’t overlook the classic pageant example: graphs provide signal about the interconnectivity of the docs. Also, sometimes the graph itself are a kind of object you want to retrieve over. reply umangrathi 12 hours agoparentprevIt was a great read, aligned on many thought processes from our own tinkering in breaking down tasks for LLM. Eagerly look forward to the next 2 parts, this one has been educational. reply rasmus1610 11 hours agoparentprevJust wanted to say Thank you for publishing something so valuable. So many great tips in there! reply Havoc 10 hours agoprevSurely step one is carefully consider whether LLMs are the solution to you problem? That to me is the part where this is likely to go wrong for most people reply bootsmann 10 hours agoparentEnforcing a BM25 baseline for every RAG project will keep so many \"talk to your pdf\" projects off your plate. reply Havoc 10 hours agorootparentDo you mean as an additional step to determine whether the content the rag wants to pull is actually relevant? Or as a filter of sorts as to hat projects to work on? reply l5870uoo9y 12 hours agoprev> Thus, you may expect that effective prompting for Text-to-SQL should include structured schema definitions; indeed. I found that the simpler the better, when testing lots of different SQL schema formats on https://www.sqlai.ai/. CSV (table name, table column, data type) outperformed both a JSON formatted and SQL schema dump. And not to mention consumed fewer tokens. If you need the database schema in a consistent format (e.g. CSV) just have LLM extract data and convert whatever the user provides into CSV. It shines at this. reply FrostKiwi 11 hours agoparentInteresting, thanks for sharing! I was wondering about this. When starting out with feeding Tabular data, I instinctively went with CSV, but always worried: What if there is a better choice? What if longer tables, the LLMs forgets the column order? reply firejake308 11 hours agorootparentThat's exactly what happened to me when I tried to get the open-source models to extract a CSV from textual data with a lot of yes/no fields; i.e., the model forgot the column order and started confusing the cell values. I found I had to use more powerful models like Mistral Large or ChatGPT. So I think that is a valid thing to worry about with smaller models, but maybe less of a concern with larger ones. reply a_bonobo 8 hours agorootparentHave you ever figured out a way to annotate the CSV columns to the model? Or do you write a long prefix explaining the columns? I found that similarly-named columns easily confused GPTs reply 7thpower 7 hours agoprevThis is excellent and matches with my experience, especially the part about prioritizing deterministic outputs. They are not as sexy as agentic chain of thought, but they actually work. reply surfingdino 13 hours agoprevOne thing I am getting from this is that you need to be able to write prompts using well-structured English. That may be a challenge to a significant percentage of the population. I am curious to know if the authors tried to build LLMs in languages other than English and what did they learn while doing so? An excellent post reminding me of the best O'Reilly articles from the past. Looking forward to parts 2 and 3. reply azinman2 12 hours agoparent> that you need to be able to write prompts using well-structured English. That may be a challenge to a significant percentage of the population. I didn’t realize at first you meant to highlight a language barrier — being well structured is a challenge for most in their native tongue! reply surfingdino 12 hours agorootparentWell, it's early in the morning and I have not had my coffee, yet. English being my second language doesn't help either :-) Probably best for me to wait until I wake up before writing a prompt. reply BOOSTERHIDROGEN 8 hours agorootparentDo you have custom prompts for improving writing? reply surfingdino 6 hours agorootparentNo reply empiko 12 hours agoparentprev\"fix the English in the following prompt: {prompt}\" reply CuriouslyC 6 hours agoprevOne thing that wasn't mentioned that works pretty well - if you have a RAG process running async rather than in a REPL loop, you can retrieve documents then perform a pass with another LLM to do summarization/extraction first. This saves input token costs for expensive LLMs, and lets you cram more information in the context, you just have to deal with additional latency. reply mark_l_watson 4 hours agoprevFantastic advice. While reading the article I kept running across advice I had seen before or figured out myself, then forgot about. I am going to summarize this article and add the summary to my own Apple Notes (there are better tools, but I just use Apple Notes to act as a pile-of-text for reach notes.) reply anon373839 10 hours agoprevIs anyone using DSPy? It seems like a really interesting project, but I haven’t heard much from people building with it. reply hugobowne 13 hours agoprevhey there, Hugo here and big fan of this work. Such a fan I'm actually doing a livestream podcast recording with all the authors here, if you're interested in hearing more from them: https://lu.ma/e8huz3s6?utm_source=hn should be fun! reply hubraumhugo 13 hours agoprevComprehensive and practical write-up that aligns with most of my experiences. One controversial point that has led to discussions in my team is this: > A common anti-pattern/code smell in software is the “God Object,” where we have a single class or function that does everything. The same applies to prompts too. In theory, a monolithic agent/prompt with infinite context size, a large toolset, and perfect attention would be ideal. Multi-agent systems will always be less effective and more error-prone than monolithic systems on a given problem because of less context of the overall problem. Individual agents work best when they have entirely different functionalities. I wrote down my thoughts about agent architectures here: https://www.kadoa.com/blog/ai-agents-hype-vs-reality reply tedsanders 12 hours agoparentAs an OpenAI employee who has worked with dozens of API customers, I mostly agree with the article's tip to break up tasks into smaller, more reliable subtasks. If each step of your task requires knowledge of the big picture, then yeah it ought to help to put all your context into a single API call. But if you can decompose your task into relatively independent subtasks, then it helps to use a custom prompt/custom model for each of those steps. Extraneous context and complexity are just opportunities for the model to make mistakes, and the more you can strip those out, the better. 3 steps with 99% reliability are better than 1 step with 90% reliability. Of course, it all depends on what you're trying to do. I'd say single, big API calls are better when: - Much of the information/substeps are interrelated - You want immediate output for a user-facing app, without having to wait for intermediate steps Multiple, sequenced API calls are better when: - You can decompose the task into smaller steps, each of which do not require full context - There's a tree or graph of steps, and you want to prune irrelevant branches as you proceed from the root - You want to have some 100% reliabile logic live outside of the LLM in parsing/routing code - You want to customize the prompts based on results from previous steps reply 7d7n 12 hours agorootparent100% agree with Ted's take. One of the authors wrote about splitting up prompts here too: https://eugeneyan.com/writing/prompting/#split-catch-all-pro... reply hubraumhugo 12 hours agorootparentprevAgree, that's a very good summary. Would love to see some benchmarks for the two approaches. reply umangrathi 12 hours agorootparentprevsmaller tasks also helps in choosing smaller models to work with, instead of waiting for a large model to respond (really not usable when doing customer facing work) reply sjducb 10 hours agoparentprevI wonder how helpful “prompt unit tests” would be here? Write the initial prompt, and write some tests to validate the output of the prompt. Then as the prompt grows you can observe the decline in performance at the initial task. Then you can decide if the new larger prompt is worth the decline in performance at it’s initial task. It might not work for all tasks, but a good candidate would be - write SQL queries from natural language. reply lagrange77 9 hours agoprevCan anyone recommend resources, preferably books, on this whole topic of building applications around LLMs? It feels like running after an accelerating train to hop on. reply msp26 9 hours agoprevThanks for sharing, I've followed these authors for a while and they're great. Some notes from my own experience on LLMs for NLP problems: 1) The output schema is usually more impactful than the text part of a prompt. a) Field order matters a lot. At inference, the earlier tokens generated influence the next tokens. b) Just have the CoT as a field in the schema too. c) PotentialField and ActualField allow the LLM to create some broad options and then select the best. This mitigates the fact that they can't backtrack a bit. If you have human evaluation in your process, this also makes it easier for them to correct mistakes. `'PotentialThemes': ['Surreal Worlds', 'Alternate History', 'Post-Apocalyptic'], 'FinalThemes': ['Surreal Worlds']` d) Most well definined problems should be possible zero-shot on a frontier model. Before rushing off to add examples really check that you're solving the correct problem in the most ideal way. 2) Defining the schema as typescript types is flexible and reliable and takes up minimal tokens. The output JSON structure is pretty much always correct (as long as the it fits in the context window) the only issue is that the language model can pick values outside the schema but that's easy to validate in post. 3) \"Evaluating LLMs can be a minefield.\" yeah it's a pain in the ass. 4) Adding too many examples increases the token costs per item a lot. I've found that it's possible to process several items in one prompt and, despite it being seemingly silly and inefficient, it works reliably and cheaply. 5) Example selection is not trivial and can cause very subtle errors. 6) Structuring your inputs with XML is very good. Even if you're trying to get JSON output, XML input seems to work better. (Haven't extensively tested this because eval is hard). reply goldemerald 13 hours agoprev\"Ready to -dive- delve in?\" is an amazingly hilarious reference. For those who don't know, LLMs (especially ChatGPT) use the word delve significantly more often than human created content. It's a primary tell-tale sign that someone used an LLM to write the text. Keep an eye out for delving, and you'll see it everywhere. reply threeseed 12 hours agoparentI believe this was debunked as just a US-centric view. In places that grew up learning UK English we use delve not that dissimilar to ChatGPT. reply 7d7n 12 hours agoparentprevhaha I'm glad you noticed! it's originally \"Ready to ~~delve~~ dive in?\" but something got lost in translation reply DubiousPusher 13 hours agoprevPretty good. Despite my high scepticism of the technology I have spent the last year working with LLMs myself. I would add a few things. The LLM is like another user. And it can surprise you just like a user can. All the things you've done over the years to sanitize user input apply to LLM responses. There is power beyond the conversational aspects of LLMs. Always ask, do you need to pass the actual text back to your user or can you leverage the LLM and constrain what you return? LLMs are the best tool we've ever had for understanding user intent. They obsolete the hierarchies of decision trees and spaghetti logic we've written for years to classify user input into discrete tasks (realizing this and throwing away so much code has been the joy of the last year of my work). Being concise is key and these things suck at it. If you leave a user alone with the LLM, some users will break it. No matter what you do. reply Terr_ 10 hours agoparent> The LLM is like another user. I like to think of LLMs as client-side code, at least in terms of their risk-profile. No data you put into them (whether training or prompt) is reliably hidden from a persistent user, and they can also force it to output what they want. reply umangrathi 12 hours agoparentprevThis has been really interesting read. Aligned that if you leave a user along with LLM, some one will break. Hence we choose to use large number of templates wherever suitable as compared to a free reign for LLM to respond with. reply distalx 11 hours agorootparentIn my opinion, using templates can help keep responses reliable. But it can also make interactions feel robotic, diminishing the \"wow\" factor of LLMs. There might be better options out there that we haven't found yet. reply DubiousPusher 1 hour agorootparentAbsolutely. This is a huge trade-off. The constraints you place on the model output is all about how much your app and user experience can tolerate bad LLM behavior. reply __loam 12 hours agoprev [–] I feel like an insane person everytime I look at the LLM development space and see what the state of the art is. If I'm understanding this correctly, the standard way to get structured output seems to be to retry the query until the stochastic language model produces expected output. RAG also seems like a hilariously thin wrapper over traditional search systems, and it still might hallucinate in that tiny distance between the search result and the user. Like we're talking about writing sentences and coaching what amounts to an auto complete system to magically give us something we want. How is this industry getting hundreds of billions of dollars in investment? Also the error rate is about 5-10% according to this article. That's pretty bad! reply yaantc 11 hours agoparent> [...] the standard way to get structured output seems to be to retry the query until the stochastic language model produces expected output. No, that would be very inefficient. At each token generation step, the LLM provides a likelihood for all the defined token based on the past context. The structured output is defined by a grammar, which defines the legal tokens for the next step. You can then take the intersection of both (ignore any token not allowed by the grammar), and then select among the authorized token based on the LLM likelihood for them in the usual way. So it's a direct constraint, and it's efficient. reply __loam 11 hours agorootparentYeah that sounds way better. I saw one of the python libraries they recommended mention retries and I thought, this can't be that awful can it? reply Kiro 11 hours agoparentprev> Also the error rate is about 5-10% according to this article. That's pretty bad! Having 90-95% success rate on something that was previously impossible is acceptable. Without LLMs the success rate would be 0% for the things I'm doing. reply __loam 9 hours agorootparentI think the problem here is that that is often still not that acceptable. Let's imagine a system with say, 100 million users making 25 queries a day, just to give us some contrived numbers to examine. At a 10% error rate that's 250 million mistakes a day, or 75 million if we're generous and say there's a 3% error rate. Then you have to think about your application, how easily you can detect issues, how much money you're willing to pay your ops staff (and how big you want to expand it), the cost of the mistakes themselves as well as the legal and retutational costs of having an unreliable system. Take those costs, add it to the cost to run this system (probably considerable), and you're coming up on a heuristic for figuring out if possible equates worth doing. 75 million times any dollar amount (plus 2.5 billion total queries you need to run the infrastructure for) is still a lot of capital. If each mistake costs you $0.20 (I made this number up), then maybe $5.5b a year is worth the cost? I'm not sure. It's probable that Google is in the middle of doing this napkin math given all the embarrassing stuff we saw last week. So it's cool that we're closer to solving these really hard problems but whether they're acceptable is a more complicated question than just it used to not be possible. Maybe that math works out in your favor for your application. reply palata 12 hours agoparentprev> How is this industry getting hundreds of billions of dollars in investment? FOMO? To me it's the Gold Rush, except that it's not clear if anyone wants that kind of gold at the end :-). reply __loam 11 hours agorootparentGoogle is so terrified that someone is threatening their market position, the one in which they have over $100b in cash and get something like $20b in profit quarterly, that they're willing to shove this technology into some of the most important infrastructure on the internet so they can get fucksmith to tell everyone to put glue in their pizza sauce. I'll never understand how a company in maybe one of the most secure financial situations in all of human history has leadership that is this afraid. reply oispakaljaa 10 hours agorootparentLine must go up. reply rcarmo 11 hours agoparentprevVia APIs, yes. But if you have direct access to the model you can use libraries like https://github.com/guidance-ai/guidance to manipulate the output structure directly. reply __loam 11 hours agorootparentThis seems like it could do some cool code completion stuff with local models. reply rtb 6 hours agoparentprevVery much agree. Also, what's it for? None of these articles point to anything worthwhile that it's useful for. reply sensanaty 8 hours agoparentprevI've been building out an AI/LLM-based feature at work for a while now and, yeah, from my POV it's completely useless bullshit that only exists because our CTO is hyped by the technology and our investors need to see \"AI\" plastered somewhere on our marketing page, regardless of how useful it is in real use. Likewise with any of the other LLM products I've seen out in the wild as well, it's all just a hypewave being pushed by corps and clueless C-suites who hear other C-suites fawning over the tech. reply frob 7 hours agorootparentIt's so painful. We have funders come to us saying they love what we do, they want us to do more of it, they have $X million to invest, but only if we use \"AI.\" Investers have their new favorite hammer and, by gosh, you better use it, even if you're trying to weld a pipe. reply freddref 11 hours agoparentprev [–] Humans probably have about the same error rate. It's easy to miss a comma or quote. These systems compete with humans, not with formatters. reply mtsolitary 5 hours agorootparent [–] A system of checks and balances overseen by several humans can have orders of magnitude lower error rates, though. reply Last5Digits 5 hours agorootparent [–] A system of checks and balances also costs orders of magnitude more money. reply jazzyjackson 3 hours agorootparentthis is my fear regarding AI - it doesn't have to be as good as humans, it just has to be cheaper and it will get implemented in business processes. overall quality of service will degrade while profit margins increase. reply __loam 2 hours agorootparentprev [–] You probably also need that for the AI as well though reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article \"What We Learned from a Year of Building with LLMs (Part I)\" by Eugene Yan and colleagues explores the rapid advancements and practical applications of large language models (LLMs), while addressing the challenges in developing effective AI products.",
      "Key lessons include best practices in prompting, retrieval-augmented generation (RAG), flow engineering, and evaluation, with techniques like n-shot prompts and chain-of-thought prompting emphasized.",
      "The article also provides operational advice on managing AI agents, refining prompts, fine-tuning models, and reducing costs and latency through caching, stressing practical evaluations and human-centered approaches."
    ],
    "commentSummary": [
      "Insights from a year of working with Large Language Models (LLMs) highlight the importance of multiple sampling to reduce hallucination rates and generating justifications before decisions for more accurate outcomes.",
      "The article discusses challenges in evaluating LLM outputs, the impact of temperature on output randomness, and misconceptions about sampling, along with experiences using tools like patchbots and beam search.",
      "It addresses industry concerns such as high error rates, FOMO-driven investments, and the aggressive push by companies like Google to integrate AI despite potential service quality issues."
    ],
    "points": 259,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1716956056
  },
  {
    "id": 40509409,
    "title": "Return-to-Office Mandates Risk Losing Top Talent, Warns Expert",
    "originLink": "https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/",
    "originBody": "You can force employees to come back to the office, but not the good ones! Updated / Tuesday, 21 May 2024 09:31 Against all expectations, remote workers appear to work harder and more productively than workers in traditional office. Photo: Getty Images By Professor Kevin Murphy University of Limerick More from UL Analysis: Organisations that impose return-to-office mandates face the catastrophic possibility of losing their most valuable workers The COVID-19 pandemic upended the workplace in many surprising ways. Many organisations were forced to abandon the traditional arrangement of having employees come to the office five days a week in favour of a variety of schemes for remote work or working from home. Against all expectations, remote workers appear to work harder and more productively than workers in traditional offices. Remote workers were not only more productive they were more satisfied with remote work than they had been with working in a traditional office. This finding is not unexpected. Once you let workers do away with the commute to and from the office, office politics, workplace bullying, boring meetings, the need to wear and take care of business suits and other costly and often uncomfortable attire, you should not be surprised that they will feel happier. Since the end of the pandemic, there has been a growing push to encourage, and sometimes compel workers to return to the office. This movement has become so widespread that it has generated the acronym RTO, or Return to the Office. As I have noted in earlier columns, the rationale for RTO mandates is often murky, and it is hard to resist the conclusion that the push to get people back to the office is in part an effort to reduce the embarrassment of executives sitting in near-empty office buildings (building they often purchased or built) with nobody to manage. From RTÉ Radio 1's The Business, Is your boss watching you? There is increasing evidence that RTO mandates can be counterproductive. In particular, several organisations that have attempted to coerce workers back to the office have found that they are losing experienced managers and top performers at disproportionate rates. The dynamic here is clear, and potentially alarming. Organisations that impose RTO mandates face the possibility of losing their most valuable workers. Turnover is often costly for organisations, but turnover of your most experienced and most valuable workers can be catastrophic. I believe the pandemic shook things up in the world of work in ways that are still poorly understood. The great political philosopher Edmund Burke noted that \"custom reconciles us to every thing\", and I think this applies to all sorts of workplace norms and practices. If we were used to the way things were done in organisations, we were willing to put up with all sorts of organisational policies that were burdensome (e.g., dress codes) or even abusive (e.g., the expectation that we should work beyond normal working hours if asked to do this.) Read more: Get back to the office or else! Why bosses want workers back at their desks A year or two away from the office has opened a lot of eyes, and things that were once widely accepted (e.g., office politics) are now barely tolerated, if they are accepted at all. More important, time away from the office seems to have upset the traditional balance of power between employers and employees. Once you realise that you do not need the office and that you do not need to be tightly monitored or supervised, it is hard to go back. Some employees, of course, do go back. First, there are some employees who believe that being in the office will benefit their careers. They are probably right; workers who return to the office are more likely to receive promotions. Whether organisations should promote the careerists who come back to the office in hopes that their loyalty (or submissiveness to RTO mandates) will win them promotions that their performance and effectiveness would not, is an open question. Second, there are employees who are trapped in their jobs, either because of family or community obligations or because they lack the skills, knowledge, and abilities to move to other jobs. Executives who force RTO mandates down the throats of their employees run the risk of changing their organisation into a set of lapdog careerists and people who are stuck working for you, and it is hard to believe that this will benefit their organisation. Read more: Is 'coffee badging' the new return to office/work from home trend? Executives who are pushing employees to come back to the office are most likely to succeed if they can make a convincing case for why coming back to the office benefits employees and the organisation. The typical explanation that coming back to the office is important for the culture of the organisation is unfounded at best, and hogwash at worse. Second, the carrot works better than the stick. If you want employees to come back to the office, recognise that this comes at considerable costs to employees and give them incentives that more than offset these costs. It is time for executives to recognise that the old power balance is unlikely to come back, and that mandates from on high that don't seem to make sense or that impose significant costs on employees will not be accepted by employees who have the skills, knowledge, experience, and abilities that give them ample opportunities to seek employment elsewhere. The RTO movement has, in the end, provided opportunities to executives who are smart enough and willing enough to read the new world of work to poach talent from their competitors. If this trend continues, we could see the old breed of all-powerful executives push themselves toward extinction. I can hardly wait! Follow RTÉ Brainstorm on WhatsApp and Instagram for more stories and updates The views expressed here are those of the author and do not represent or reflect the views of RTÉ More stories on Brainstorm News Business University of Limerick work Work and careers Work From Home",
    "commentLink": "https://news.ycombinator.com/item?id=40509409",
    "commentBody": "Companies with return-to-office mandates face losing their most valuable workers (rte.ie)252 points by ewgfdgdfgdf 11 hours agohidepastfavorite279 comments shoubidouwah 9 hours agoThe discussion here follows well understood battle lines, but I want to add my grain of salt: working from the office comes bundled with commute. And the crux of arguments tends to be where you fall on the [commute is hellworking from home is hard due to circumstances] continuum. Some say that \"commute helps clear the mind / switch context\", but a simple walk does the same IMO; the mandatory presence in a vehicle along with everybody else at the same time, unpaid and very often for hours everyday feels incredibly invasive, wasteful and unjust. Every person then can talk price based on their circumstances, but that's the nub of it for me. reply benterix 8 hours agoparentThat's one of the more popular arguments but not the only one. When WFH, i have enormous freedom of arranging tasks they way I want them executed and it works marvels for my productivity. When I want to go out on my bike for 20 minutes, I do so, and excellent ideas come to my mind them. There is simply no amount of money that would force me back to the office. I routinely pass on job offers where they demand \"just two days a week in the office\". reply AnimalMuppet 3 hours agorootparentWith WFH, I didn't have to listen to my coworkers' conversations in the adjoining cubes. Also, I could take a meeting with the cat on my lap (if she would cooperate). Personally, I like seeing my coworkers in person. But the WFH advantages are real, too... reply bdw5204 8 hours agorootparentprevI doubt you can even get a hybrid position in this market if you clearly prefer remote work but can't find a remote job. Companies generally aren't going to hire somebody who clearly doesn't want to be there so the only people who have a choice are those who are capable of lying. I suspect those \"job offers\" you're getting are probably just recruiters who'd waste your time if you told them you were interested then you'd never hear from them again. That's my experience with most of that \"profession\" anyway. reply CoastalCoder 7 hours agorootparentFWIW, I don't recall ever being asked during interviews if I wanted to come to the office. The policy was simply stated as a fact of the position. So any lying would have been spurious. reply benterix 7 hours agorootparentprevIn my niche, the ratio of not remote (including hybrid) to remote is roughly 3:2. However, the interesting thing is that almost all top offers are remote only. Sometimes with the annotation \"This is a remote position but you are welcome to the office should you wish to come\". reply carschno 8 hours agoparentprev> \"commute helps clear the mind / switch context\", but a simple walk does the same Fully agree. In an ideal world, the commute would _be_ a walk to the office. More realistically: for those who happen to live in an environment that allows them to commute by foot or by bicycle, working in the office is already much more appealing than for others. reply darkwater 8 hours agorootparentAs an European: yes and no, because that (mostly) means living in the heart of a big city and not everyone wants to do that (less living space, higher noise and air pollution) reply asdaq1312512 7 hours agorootparentThe good thing is that cities actively work on reducing noise and air pollution. reply kibwen 5 hours agorootparentAnd the irony is that, in developed nations, almost all of the air pollution in a city comes from cars. reply TheCoelacanth 4 hours agorootparentNoise pollution too. reply snapcaster 6 hours agorootparentprevI moved so I could walk to work and it has made such a huge difference on my quality of life, crazy how much different a 15 minute walk is compared to even a short drive. Not sure exactly why, but for me it's a world of difference reply azemetre 5 hours agorootparentI’ve done a similar thing with the added benefit of also living in a walkable neighborhood (can walk to my doctors, theater, cafes, bars, gym, grocery store). I really wish these neighborhoods weren’t so expensive because they are very desirable. reply yohannparis 6 hours agorootparentprevAs I do, I have a 15 minute bike ride, more like 25 minutes when it's my turn to drop the kids at school. Then I have a full desk full of light and nice colleagues with a great office culture. I like to be able to disconnect from work outside my 9 to 5, which personally I am unable to achieve when I work from home. Kudos to those who can. reply rob74 2 hours agorootparentWell, I have a 60 minute train ride (if I'm lucky and there are no delays), a desk which is less well equipped than the one I have at home, and colleagues which are nice but with whom I don't actually work - the people I actually work with are in other offices, so I have to do video calls regardless where I'm working from. And so does everyone else, and most of them don't bother to go to a conference room or \"phone box\" to do it. I hope you can imagine how good that is for concentration and productivity... reply bluGill 5 hours agorootparentprev> In an ideal world, the commute would _be_ a walk to the office. Geometry would like to have a chat... Most people are living in some form of long term marriage/family relationship, and the other person/people also has a job to get to. Even if we ignore zoning, force everyone into high density apartments, force offices into high rises, and so on: there is only so much space within walking distance and so a populated city will have a lot of people who cannot walk to the best job for them. There are a lot of compromises possible, and we are used to them (I live in the midwest which means I can't take a job in New York city) reply coldpie 5 hours agorootparentprev> for those who happen to live in an environment that allows them to commute by foot or by bicycle, working in the office is already much more appealing than for others I take the bus, but otherwise yeah, agreed. I hate WFH, so I choose to go in every day even though my company doesn't require any office time. I love my time on the bus, gives me a short walk to & from the bus stop, and 45 minutes each way to be offline and read books. On the other hand, if I had to drive, I'd go insane. Driving for a commute is awful. reply lbeltrame 8 hours agoparentprev> Some say that \"commute helps clear the mind / switch context\", but a simple walk does the same IMO No, it doesn't for everyone. Personal experience matters: after a 70-day lockdown including a very stressful work period (dedadlines etc), there's no way I'm going to WFH ever again. But that's just me, of course. For others, priorities may be different. reply gabrielgio 8 hours agorootparentI fail to understand how this is related to WFH? That happened while you were working from home, not because you were working from home. reply lbeltrame 7 hours agorootparentBecause it wasn't just the lockdown: it was a pretty complex affair at the job too (including very tense moments; it would've been bad even in the office, mind you) and there was no way to shut that away from me. FTR, I did WFH in other times (2 years in the 2009-2011 period) and it wasn't like that. reply intended 6 hours agorootparentThis would extrapolate to it being a shit situation in general. Attributing WFH as a causal factor is hard, given your description. reply DoughnutHole 5 hours agorootparentThe lack of distinction between your workspace and reduced socialisation still exists - not OP but personally I’m climbing the walls after a day of working from home. I cope by have social outings and activities outside my home basically 7-nights-a-week. It works but I don’t consider it a positive I’ve that I’m more or less incapable of relaxing in my own home. reply antisthenes 4 hours agorootparentSorry, but this is bordering on some kind of pathology. See a therapist, because you make it sound like you're on the verge of a breakdown just because you do some work at home. Do you have the same reaction to doing household chores? reply DoughnutHole 4 hours agorootparentYou got “verge of a breakdown” from that? Is it that disturbing to you that your preferred working arrangements don’t work for others? Getting out into the outside world and seeing people prevents under-stimulation, and separating my work environment lets me switch off at home. Spending my every waking hour in my apartment doesn’t do it for me. It’s not about “doing some work at home” - it’s about spending 5 days a week working in the same space I’m supposed to eat, relax, and sleep. reply antisthenes 1 hour agorootparent> It’s not about “doing some work at home” - it’s about spending 5 days a week working in the same space I’m supposed to eat, relax, and sleep. Do you have good working habits? E.g. clean separation for working/non-working hours? Do you have friends on Discord that you can engage with in activities post-work? > It’s not about “doing some work at home” - it’s about spending 5 days a week working in the same space I’m supposed to eat, relax, and sleep. It really is though. There shouldn't be much difference if at all between working 8 hours in a home office vs regular office + wasting 1-2 hours on commute. Commute helps some people separate work/leisure, but it shouldn't be a necessity or \"drive you up a wall\" like you said. reply OJFord 8 hours agorootparentprevI read it as that being the point - they have a bad association for it so it's just not appealing now. Likewise you might have a terrible time in one office that puts you off working in any office. reply yxhuvud 7 hours agorootparentprevSame. I can work from home if I have an errand or something, but for me the default is and will continue to be to be in office. And I will actively select work places were that is reasonable. and common. reply bradleyjg 7 hours agoparentprevthe mandatory presence in a vehicle along with everybody else at the same time, unpaid and very often for hours everyday feels incredibly invasive, wasteful and unjust. At least in the U.S. almost all of us in this industry are on salary. In that case I don’t think it makes sense to think of a mandatory commute as unpaid. It’s part of the deal and should be factored in accordingly. reply stevenAthompson 7 hours agorootparentI personally factor it in as a large reduction in total compensation, because it's a huge mandatory cost. Non-remote jobs just aren't competitive unless they offer truly extraordinary pay. reply bradleyjg 6 hours agorootparentThen things will work themselves out without the need for endless jawboning. reply bradleyjg 7 hours agorootparentprevI can’t respond directly—-but at one time many of those things were deductible. Tax cheats are why we can’t have nice things. reply willcipriano 7 hours agorootparentprevI haven't seen the in office jobs offer any premium over remote. So if it's part of the deal those are all worse deals. reply gedy 6 hours agorootparentprevThat's true, but I've then also subtracted commute times from office hours when I was required to come in. I can't do 8 hours in office plus 1.5 commute time on those days. reply barfbagginus 54 minutes agorootparentSubtract 3x commute. Drive 1.5 hours for no reason? Watch YouTube for 4.5 hours, also for no reason. reply willcipriano 0 minutes agorootparentI'd make it a solid 4.5 hours of bullshitting with people and using the amenities. Get my gym time in, go for a walk around the building to be seen. Learn the names of the cleaning staff, ask people if they are \"makin' copies\". Soon enough you'll be promoted and you can use that promotion to go to a competitor and negotiate your previous role, but instead remote. phone8675309 6 hours agoparentprev> [T]he mandatory presence in a vehicle along with everybody else at the same time, unpaid and very often for hours everyday feels incredibly invasive, wasteful and unjust. All of this changes when you consider your commute on the clock. I've been doing this since RTO 3-days a week and it really helps. I've already proven that I can work from home without issue, so heading into the office definitely isn't for my benefit - it's effort that I apply for the benefit of my employer, something they've even admitted by saying working from the office allows for \"spontaneous collaboration and increased efficiency\". As it's for their benefit (and also a detriment for me) then they can pay me for the time I spend doing it. If they don't like it then they can let me WFH. reply readyman 5 hours agorootparent>If they don't like it then they can let me WFH. They can also fire you lol reply mondrian 8 hours agoparentprevThe flip side of spending \"unpaid time\" in commute is having \"unpaid space\" at home in terms of home office. reply benterix 8 hours agorootparentI actually rented separate space for that. So I pay for 50 m2 of private office space where I have two rooms, kitchen, bathroom, a desk with a comfortable chair, a bed, some simple gym equipment and other amenities. And in spite of paying for this every month, I would never ever come to the office where I could use some of these things (an old office chair) for free. It feels like some dark era has ended, at least for a certain type of employees. reply carschno 8 hours agorootparentInteresting. Who pays for that? Sounds like, economically speaking, you are taking over the costs from your employer for providing a usable workspace. reply rlpb 8 hours agorootparentThe same argument could be made about the cost of a commute, though. reply mrweasel 6 hours agorootparentprevI had a co-worker who rented a small office, close to his home. Because he lives far away from any larger towns he was able to rent an office for $200 per month, but he shares the space with his partner who also works from \"home\", so it's effectively $100 per person. Our employer paid for the office space, but not for the cleaning, because it was still cheaper than paying for him being at the office every day (we where short on space). Depending on where you live, and your living situation renting a small office can be really cheap. In my local area I've seen private office rent for as little as $120 per month, but around $200 is more realistic. reply marcosdumay 3 hours agorootparentprevYes. Every type of employment puts undocumented costs at the employees. But not all types of employment puts the same amount of costs. Those vary widely. And the possibility for the employee to optimize them also varies. And all the comments up to now are still ignoring the elephant on the room and didn't touch the opportunity cost of having your entire family work on the same geographic area, and the insane housing costs on the few small areas where a family can do that. reply benterix 8 hours agorootparentprevYes, I pay for that - and I do it gladly. It's roughly 7% of my salary. reply shoubidouwah 8 hours agorootparentprevin other words, \"office space provides him with negative utility\" reply eleveriven 5 hours agorootparentprev> It feels like some dark era has ended, at least for a certain type of employees. My friend was acually depressed by the fact that he had to work from home. At the first opportunity, he ran to the office. reply benterix 5 hours agorootparentI'm very happy for him, really! Also, I enjoy it when I pop into the office one a few weeks, it's an enjoyable experience - and part of this joy comes from the fact that I know I'm not forced to come there every way but it's my own choice. reply cafard 8 hours agorootparentprevI spent most of the pandemic working from my dining room table. Now when I work from home it is from table in the basement. Neither is particularly in anybody's way. reply joncrocks 8 hours agorootparentSo that's your personal experience, but you can imagine that this might be different for different people. The point is that previously you had a choice over the amount of space you need at home, there are requirements for WFH. i.e. You need a place where you can work effectively. reply doktrin 8 hours agorootparentprevThis is going to vary based on geography and circumstance, but some home office expenses are eligible for tax deductions. reply CalRobert 6 hours agoparentprevThis is from an Irish broadcaster and commutes there tend to be hellish, unfortunately. reply exodust 5 hours agoparentprevNot to mention air pollution and energy consumption of commuting. Office mandates run awkwardly against eco-friendly principles. Another aspect is nasty viruses are still a big concern. Offices with more breathing room / less people per square metre, spread less illness. reply armada651 6 hours agoprev> First, there are some employees who believe that being in the office will benefit their careers. They are probably right; workers who return to the office are more likely to receive promotions. Whether organisations should promote the careerists who come back to the office in hopes that their loyalty (or submissiveness to RTO mandates) will win them promotions that their performance and effectiveness would not, is an open question. I take issue with the fact how quickly this is dismissed as simply rewarding loyalty and submissiveness. It completely ignores how much junior employees struggle with WFH. Without an office there is very little opportunity for junior employees to casually talk to senior employees and learn from them. It is also much harder for managers to notice if a junior employee is doing well or not. So it is no surprise it is easier to get promotions with an RTO mandate and it has very little to do with loyalty. reply rightlane 6 hours agoparentMy juniors thrive in a WFH environment. This is a problem with the culture and the seniors not WFH. The promotion issue is real. But let's be honest, promotion in tech mostly happens by changing jobs. The in the office people are the ones who are really slowing down their career growth. reply foobarian 5 hours agorootparentI feel like there is a large selfish component with seniors thriving in WFH; the hidden costs are, for one, less impromptu unaccounted for time helping juniors either with tech questions or mentoring. This maybe works for now, but makes me wonder how this will play out when the current generations of workers who trained pre-COVID retire out and the current juniors get into those roles. Alternatively, what good measures are there to help the current junior roles? I see people saying it's a culture problem but it seems a very new problem with not many publicized solutions. reply jareklupinski 4 hours agorootparent> what good measures are there to help the current junior roles? i always make it very clear that anyone can reach me asynchronously whenever they want, and i will always strive to give a clear answer when i'm able to i think some juniors have been burned by asking the wrong person the wrong thing at the wrong time and believe it was their fault for asking sometimes people just had a bad breakfast reply rimunroe 4 hours agorootparent> i always make it very clear that anyone can reach me asynchronously whenever they want, and i will always strive to give a clear answer when i'm able to This is good, but in my experience being proactive in reaching out to juniors is critical in a remote environment, especially if your company or team doesn't have an obviously healthy culture reply readyman 5 hours agorootparentprevAs a junior employee, I have no patience for your point. Going into office is one thing juniors can do about the \"problem with the culture\" so my stance stays the same until the so-called culture changes. In my experience, the number of seniors who complain sbout RTO and don't hoard knowledge is tiny. reply rimunroe 4 hours agorootparent> In my experience, the number of seniors who complain sbout RTO and don't hoard knowledge is tiny. \"Hoarding knowledge\" makes it sound like they're intentionally trying to keep knowledge to themselves. I don't think the problem with remote leveling is due to seniors intentionally holding onto knowledge. I do see some senior employees try to hold ownership of a specific area of their work for apparently selfish reasons, but they're a minority. I've spent a lot of time talking with other seniors (and juniors!) about ways to make sure we're spending time working with mixes of skill levels, but it's a hard problem. Just advertising that you're available to help if anyone needs anything does basically nothing to encourage most juniors to ask. It takes a lot of juniors a long time to lose inhibitions for asking for help, and I think people can often make it to senior levels without learning how to be proactive about offering help. It does seem easier for most people to ask for help in person. I think one of the causes of this is because even in this field, most people don't grow up doing so much communication and socialization purely using crude text and video calling which have remained mostly unchanged since the 80s or 90s. Most people handle in-person socialization much better, and can read and express cues more naturally there, especially in a work environment. Also, those communication methods have a degree of formality attached to them which feels like a barrier. Personally, I think it might help a bit if telework software would take more cues from video games (proximity-based chat and virtual environments with rooms and doors). There are some programs for this, but the few I've tried haven't been polished enough to use. The few I've used though did seem to make impromptu collaboration easier, but of course there could have been many reasons for that (e.g. novelty). reply vrnvu 6 hours agoparentprevIf a junior struggles with WFH you have an engineering culture problem. Which the junior is not responsible for by the way... It's staff and senior engineers responsability ˆˆ reply mdgrech23 6 hours agorootparentPersonally would put the blame higher up than that. reply HelloNurse 6 hours agorootparentThe aforementioned senior employees and managers should find a way to talk with junior employees instead of assuming that no news is good news. reply giantg2 5 hours agorootparentEven when no news is good news, the juniors would get screwed because the managers don't know what's going on. The people who can just quietly do their job (and the one above it) don't get promoted. Only the ones that say \"look at me\" or where the managers are tracking them closely. reply civilized 6 hours agoparentprevThe lack of communication of potentially valid reasons such as these might contribute to why people view RTO mandates with cynicism. If we knew why we were being asked to RTO, we could solve that problem in the way we thought best, combining in-person and remote time. And those of us with junior team members we care about are already solving for this in the way we think best. reply readyman 5 hours agorootparent>And those of us with junior team members we care about are already solving for this in the way we think best. Solve it in the way the juniors think best if you want to accomplish anything. reply mozman 6 hours agoparentprevI proactively schedule 1:1s with junior staff and reach out. I weed out the ones with potential and ones who lack ambition. reply cqqxo4zV46cp 6 hours agorootparent“Proactively” scheduling 1:1s with juniors is, frankly, the bare minimum. It’s just doing your job. If you think that this solves the problem, you are bad at your job. reply blitzar 5 hours agoparentprevIt completely ignores how much senoir employees struggle with WFH. Without an office there is very little opportunity for senior employees to casually look to see how hard junior employees are staring at their monitor to determine the depth and quality of their work. Instead they have to look at the actual work produced and try to understand it well enough to not look like an idiot when they talk about it. reply jmclnx 5 hours agoparentprevI believe,at least in IT, once you get to a certain age, promotions are really meaningless, especially in large companies. So I think if you are young and you want to be on management track, you probably should go in. reply hmmm-i-wonder 5 hours agorootparentIn any job, once compensation is no longer significant (i.e. close to retirement, reached savings goals etc) then promotions are meaningless sure. But in most fields, IT included, compensation range is linked to role. For most people that means 50-80% of your career promotions and compensation are linked and meaningful. But after some stage when life goals are reached and you're in end of career planning, I agree promotions are largely meaningless to many people (outside of those who's self-image is tied up with their role and job). Ultimately I don't see IT being especially different from any other field here, what is it in IT you see influencing that? reply smugma 4 hours agorootparentIn large tech companies, you might reach a terminal rank (ic5-6) before you’re 40. Total comp might be 400-500k, which is great but you’ve still got 10-20 years to retirement (Bay Area and Tahoe homes are expensive and if you enjoy your job you might not want to retire at 50). So there may not be another promotion, and that’s freeing. You can focus on professional development free of concerns for looking good but grow in ways of interest to you. reply hmmm-i-wonder 2 hours agorootparentIs that really unique to IT? Small to medium companies, academic and govt IT jobs will typically never reach those income levels. I think the Avg software dev salary in the US is around 77k, so a lot of the IT field has to make a lot less. I agree in large tech companies that absolutely exists, but I also see it in legal, medical and some other professions that a subset of them can reach similar income levels. (250k+ by mid to late 30's, 400k+ if in Bay or similar CoL area). Its a nice reality when you can be ~40 and have the freedom to retire whenever you want, but its not one I see as common for the majority of tech workers. reply qzx_pierri 6 hours agoparentprevAre you a manager? reply batch12 5 hours agoparentprevIt also creates new opportunities for employees who enjoy or don't mind working from an office that may not have otherwise been available. reply disambiguation 4 hours agoparentprevjuniors are getting hired in this market? reply unpopularopp 10 hours agoprevThis article doesn't mention people who don't enjoy WFH because of the unification of the workplace and home. Personally I hated that I can never \"leave\" work and it's always with me at home. Also not everyone can afford an office room to \"close out\" work to a separate physical place (which is a typical reply when this topic brought up) and I don't even think it counts. I personally like working in office because it's where I work, and then I go home and that's my home. I don't work at home at all (and it's a company policy everyone knows that). But I live in Europe, work is a 30 min bicycle drive from home which I also enjoy. Considering it's an irish news site I'm surprised that was not mentioned. reply gwd 10 hours agoparentFor reasons I won't get into, after the pandemic our local office ended up with desks for 75% or so of the employees. So if you wanted to come in, you reserved a desk, if you wanted to stay at home, that was fine. Then the diktat came down from corporate headquarters: Everyone must be back in the office, unless their contract specifically said remote work. Pitchforks! Loads of objection from all the people who had gotten used to working from home and quite liked it. And of course there was the problem that we didn't actually have space for everyone. Then an opportunity came up to get rid of our sub-lease on the current property, which could potentially simplify the process of getting a newer, larger office that could accommodate everyone; so word went out that everyone was going to go back to WFH for a period of time. Pitchforks again! This time from all the people who didn't enjoy WFH for all the reasons you mentioned. In the end corporate has had to be satisfied with people coming in at least one day a week; and we're squeezing more people into the current office while still looking for another office to move into. But it's interesting to see the dynamics you mentioned -- lots of people prefer to WFH, lots of people definitely don't. FWIW I've never had much trouble \"turning off\" work, even when I was using the same computer for work and personal things. Now that I've got a corporate laptop, it's even easier -- unplug it from the external monitor, close the lid, and forget about it until it's time to open it again, be that overnight or over the weekend or over the holidays. reply darkwater 8 hours agorootparentAmen to that. That's why the key is NOT FORCING RTO. If you want go to the office because reasons, do it. If you prefer WFH because reasons, do it. You are either a goal-oriented workplace, where this would be natural, or you are a classical \"show me you are committed to work by being there many hours\" place, where then it's just WFO. reply hmmm-i-wonder 5 hours agorootparentprevI found WFH forced a level of personal growth and adaptation for me to handle this, but its growth that I would have definitely benefited from before. Previously while working in an office, I couldn't disconnect even when not home(on call, often called in while not on call to help). I ended up getting my own phone again to be able to leave work at home and go out to be able to disconnect, but mentally I never really did. Now I work from home and that additional always on pressure was amplified that much more, and made me face the fact I had horrible life balance mentally and needed to learn to properly disconnect and compartmentalize. Learning and practicing that has helped me in a lot of cases outside of work, and continues to help me with work. I can easily walk away from work and not think about it for hours/days even without guilt or significant struggles, something I couldn't do the decade before while working in an office. So for those that struggle to disconnect with WFH, I can empathize but strongly suggest through whichever means they prefer (self directed, therapy or otherwise) they take the opportunity to practice and learn disconnecting more. Even if ultimately one prefers the office learning to disconnect is, at least in my experience, a very healthy skill to build. reply leni536 10 hours agoparentprevI appreciate that a barrier is desirable for WFH, but that can be established without having a dedicated physical space for that. A separate work computer that is shut down at 5pm (or whenever you \"leave\" work) and not having company chat/email on your personal phone could go a long way. Having said that this has to go hand-in-hand with company work culture and no expectation that you are available for work throughout the entire day. reply jaketheguy 9 hours agorootparentThere's another side to this: not being able to leave home to work. I, and many of my work colleagues, have small child or children and not enough rooms to dedicate one purely to work. I have my space and my wife does everything she can to help me, but it's really hard to argue with 10 month old child that wants to be held for a few minutes. Due to this, my productivity at home is nowhere near the productivity at the office. I do appreciate the possibility to work from home (I'm actually at my \"home office\" right now), but I use it as a last resort, not my default mode. As for the space, some people don't have enough of it to replicate the \"designed to work\" tools at home. At my office, I have a large eraseable board behind me, printers, fast coffee machines, sometimes lunch is provided, easy access to people for \"quick question\" (chat/email doesn't have the same responsiveness), not to mention two huge screens and way more comfortable chair than I can fit in my home space. If my company will pay me to replicate this environment (which would have to include bigger place), I'll happily move to WFH for as much as possible. At the same time I recognize the different preferences regarding WFH and I don't want my colleagues to be the victims of \"some people prefer to use the desk at work so everyone needs to RTO\". I personally advocate for individual approach, because I can see that many of my colleagues work better from home - overly social office space for them isn't really better than their comfortable home. reply leni536 9 hours agorootparent> I have my space and my wife does everything she can to help me, but it's really hard to argue with 10 month old child that wants to be held for a few minutes. I am sure this is both a positive and a negative. Being available at home while your 10 month old child is at home must be great, and even if it's frustrating when you have to break away from work to hold him/her, this must be great for bonding. There must be a reason that you still work from home, and not, say, from a nearby coffee shop. I am (or was) also in your shoes recently, WFH with a small child at home. She's almost 2 now, still isn't in nursery. I would say that we are very lucky that we can do this and I have no regrets that I am not going into the office to be more productive and potentially earn more. Sure, I do also have the luxury of having a small dedicated office space in the house though, I appreciate that not everyone can have that, and without it it probably doesn't work while a small child stays at home too. reply bentinata 6 hours agorootparentThis is also how it is for me. My son just turned 2, and I love that I am able to observe him napping between long meetings. I could also have a small chat with my teammates after 5 PM, and sometimes our kids hop into conversation and say hi to each other. reply ambrose2 6 hours agorootparentprevWFH is great for life, not always great for work. Depends on your priority at the moment. reply fireflash38 5 hours agorootparentDid you know most people work to live? They don't live to work. reply cqqxo4zV46cp 5 hours agorootparentprevI’m not sure what your personal situation is, but for most people in the real world, being able to be a certain degree of productive at work is a mandatory part ensuring that they can, say, pay their mortgage, or many of the other things that comprise or sustain the “life” part of work-life balance. reply ryandrake 4 hours agorootparentprevWhen I went remote, I went all-in with a dedicated home office. Not a bedroom with an office chair, but an actual separate outbuilding on the property that I had to walk to (even if it was only a few second walk) to \"go to work.\" Comfortable chair, many screens, whiteboard for brainstorming and designing, sound insulation, mini-kitchen with a coffee maker, a bathroom... basically everything I need to pull an entire day of work without \"commuting\" back home to get something. My family knows when I'm out there I'm working, and they don't disturb me. Understood this is extreme, and not everyone is fortunate enough to be able to build something like this, but it is possible to do remote work and have a hard, clear separation between home and work life. reply wepple 9 hours agorootparentprevI disagree. Physical space and distance helps, a lot. I can’t explain why, but the commute home helps establish a different psychological setting. reply bacheaul 9 hours agorootparentFor you. Everyone's different, and I have no problem closing my laptop and psychologically switching from \"at work\" to \"at home\" almost instantly. But I absolutely appreciate that other people need the physical separation and temporal separation to make that switch. I don't begrudge anyone that wants to work from the office and commute each day. Please, do what works for you, but that's not what works for me. reply wepple 8 hours agorootparentExactly my point. “that can be established without having a dedicated physical space for that” … for you. reply croes 10 hours agoparentprev>This article doesn't mention people who don't enjoy WFH because of the unification of the workplace and home Maybe because companies seldom try to force people to work from home. reply vmfunction 9 hours agorootparentExcept for when that big o' pandemic that just happened couple years back. reply croes 9 hours agorootparentTherefore the \"seldom\" Myself wasn't forced, I had already discussed this with my supervisor beforehand. reply nkrisc 9 hours agorootparentprevYes, it was quite an exceptional thing indeed. reply siva7 9 hours agoparentprev> \"I personally like working in office because it's where I work, and then I go home and that's my home. \" Well, that's not how IT nowadays works. On the assembly line, sure. But modern IT professionals usually take their \"work\" with them. I remember the times we had desktop computers and work really stayed in the office when we left, but the default in 2024 is laptop/mobile workplace. reply Cthulhu_ 9 hours agorootparentThat's true (and for valid reasons, e.g. saving on insurance/security at the office), but that doesn't mean you don't get to have a work/life boundary. There's a EU directive (or there will be) colloquially called the right to disconnect: https://www.europarl.europa.eu/topics/en/article/20210121STO... reply dagw 9 hours agorootparentprevmodern IT professionals usually take their \"work\" with them. This only became really prevalent post covid in my experience. Pre-Covid, when coming into the office every day was the norm, a lot of people, at least at places I worked, left their laptops at the office over night. reply PartiallyTyped 9 hours agorootparentprevWe have lockers at work, and I leave the laptop there. It's a simple decision that a) forces me to go to the office every day on foot, b) allows me to separate work and home, and c) allows me to unwind while I walk home from work. reply siva7 9 hours agorootparentThis is a good Idea. Unfortuntely, most people, especially yonger colleagues, don't have the money to buy a separate laptop und usually use the work laptop for private use. reply suddenclarity 8 hours agorootparentMy previous laptop was a $180 Thinkpad that stayed with me for five years. The claim that _most_ IT workers can't afford that and are forced to do their private stuff on a company computer sounds preposterous. reply cqqxo4zV46cp 5 hours agorootparentprevYou’re digging your heels in by cosplaying proletariat. If someone wants a separate computer, they’ll get one. It’s not a matter of not being able to afford it. Maybe their work computer is better than the one they’d buy themselves. Or maybe “afford” in this case (as usual) means that they can’t justify the cost when they could spend the money on something else, and are happy trading the work-life balance. But don’t pretend that this isn’t a consensual arrangement. reply PartiallyTyped 5 hours agorootparentprevI don’t understand why anyone would take issue with my reply. I just shared a perspective/experience. reply closewith 10 hours agoparentprevThis is less of a concern in Ireland due to the Organisation of Working Time Directive and the Right to Disconnect. Most large employers will be at pains to ensure you stop working outside your normal work hours. In general, cycling infrastructure is poor in Ireland and public transport is dire unless you happen to live in specific parts of Dublin, Galway or Cork. Added to the EU's worst housing crisis and highest cost of childcare and remote work is extremely popular here. A deal-breaker for many. reply soco 10 hours agoparentprevThe issue with this, and most of articles on the topic of WFH, is they fail to recognize that different people will have different preferences (the horror!) and different situations. They start by putting everybody in the same bucket whatever that is, then argument from there. Luckily smarter companies don't rely on journalists to decide that the best approach is \"whatever floats your boat\" and keep both options open no questions asked. reply tarsinge 9 hours agoparentprevThis shows why it's important to accommodate both and not impose one way or another. Like for me this unification is exactly what I'm enjoying. I can never \"leave\", but I never have to \"go\" either. Not perfect but as an introvert still a better situation. Also not everyone in Europe live at less than a 30min bicycle drive. Why must it always be 100% one or another? reply anonzzzies 10 hours agoparentprevI guess this article is about good quality workers who don’t want to go (back) to the office. I have seldom been in an office (30 years career) and I wouldn’t, at any price. reply 0xAFFFF 9 hours agoparentprevIt's perfectly fine to not enjoy WFH, the point of the article here is forcing an option onto employees instead of giving them the choice. reply AndyJames 9 hours agoparentprevI work for a big, old-timey, international company. The current policy is WFH or from the office, whatever you like. Some managers have rules that their team members have to show up at the office 1-4 times a month. Our office can hold about 400 employees and this is about the number of employees that could technically commute every day. To my knowledge, there are about 20 people who commute to work daily. No one else is going there unless they have to. It's a very nice, freshly renovated office, with a lot of green plants inside, free coffee, height adjustable desks, ergonomic chairs, relaxation zones, lockers (so you don't have to take your stuff to work every day), etc. located in the city center that is well connected via buses. trams and subway. You can even drive a car to work if you want. And still given that option only about 5% of employees decided to work there daily. People like you exist and their needs have to be filled however most people, if given a chance they'll prefer WFH. reply robertlagrant 9 hours agorootparentI think this is a possible conclusion you could draw, but not the only one. The value of going to the office is the other people. If no one's there, then it's the same as working from home (you need Zoom for all your calls, even if half of you are next to each other) so if more than about 5% of people are remote, it semi-forces everyone else to be, even if they'd prefer to be working with people as a local team. reply AndyJames 9 hours agorootparentMaybe that would bump the people willing to go to the office by another 5-10% but every once in a while we have days when multiple teams happen to be in the office on the same day, and at least half of the desks are occupied. Despite having half of the office dedicated as \"the focus zone\", most people don't really work or like to work on those days. There are much more meetings, and casual chit-chat but an actual output of \"work products\" is close to none. reply robertlagrant 9 hours agorootparent> There are much more meetings, and casual chit-chat but an actual output of \"work products\" is close to none. To me that implies that something that is fairly needed is missing by being remote. I think being a distributed factory outputting \"work products\" might be a net negative, but I could be wrong. reply geraldwhen 9 hours agorootparentprevI’ve worked on international teams my whole career. bigco will never hire everyone in the same spot to save money. It’s zoom no matter what. reply robertlagrant 9 hours agorootparentI've done that a lot as well, but that's not traditionally been seen as the best way to accomplish work as a team. It's just so much cheaper it's worth the pain. reply larater 7 hours agoparentprevI use to agree with this but I work remote and I can go to an office that is about a 15 minute drive away if I want. Once I got use to working remote the motivation to go into the office went away completely. I not only don't have a home office but I just switch the input to my monitor when I log off for the day. The song and dance of the office is just a total waste of time, space and money. It is just absurd this is even still a conversation. reply stringsandchars 10 hours agoparentprev> Personally I hated that I can never \"leave\" work and it's always with me at home. This seems to be more about your own poor self-discipline than about WFH/RTO? reply alistairSH 5 hours agorootparentFWIW, when I stared WFH during COVID, I struggled with the home/work split initially. It took a dedicated space to get back to “normal”. It was just too easy to look at Slack when I went into the kitchen (my first work space). Now that I have a desk is in a spare bedroom, that’s better. But, I’m lucky enough to have a home with 2 extra rooms for work (spouse uses the other). And lucky enough to walk a mile to the office, which I prefer. I’m not an extrovert, but still find it nice to see other people during the day. reply tazjin 10 hours agorootparentprevnext [3 more] [flagged] throwaway8481 10 hours agorootparentI've struggled with ending my shift and mentally checking out of work. However, I wouldn't impose going back to the office on others who can do this effectively. I think the comment is about maintaining a work-from-some-office-space capability. reply kkfx 9 hours agorootparentprevWell, as the others have to realize the same. RTO meaning IMPOSING all return to the office, so imposing the will of some on all. WFH does not means imposing the end of the office if so many want it and they want something doable. I have my wills, of course, some are doable, some are not. I really want to be immortal, never fell ill, find a large plethora of sex-hungry partners and so on, these are just few examples of not really doable personal will. If the office can economically survive because it does work it will, if the slice of those who want WFH is big enough to kill the office that's how democracy works. I do like WFH, I do not pretend imposing others the same, as long as others do not pretend imposing me the office. Of course I observe issues and strong points in both models, so the future will be decided by the majority anyway. We will see, knowing that any imposition tend to last less and less as more and more it's imposing and impacting people life. reply Kichererbsen 10 hours agorootparentprev\"poor self-discipline\" is quite the judgy statement to make dude. reply fmajid 9 hours agorootparentLike \"careerist lapdog\" in the article. I gave up reading after that. After 4 years of WFH, not all due to COVID, I make it a point to go to the office 5 days a week even though my company is hybrid 3 days in, 2 days out. Humans are social animals and even though I am an introvert, postage stamp videoconferencing window s don't cut it. reply geraldwhen 9 hours agorootparentYour coworkers aren’t your friends. They’re paid to be there. Find a life outside of work. reply kaashif 7 hours agorootparentThere's no reason some of your coworkers can't also be your friends. You can tell if your coworkers are your friends if you're still friends and hang out after you leave the job. Having friends at work doesn't mean you don't have other friends, or a life outside work. reply coldpie 5 hours agorootparentprevPeople have been making friends at work since work has existed. It's a place you spend 40 hours a week, very likely with people with similar interests and life experiences. That's a great environment to make friends in and many, many, many people make real friendships through work. It's fine if it doesn't work for you, but telling others it's wrong or bad or unusual to make friends at work is absolute brainworms stuff. reply geraldwhen 1 hour agorootparentHR makes it clear we’re not to hire anyone with similar interests and life experiences. At any rate, my reply is under the context of wanting to go to the office for the social interactions. I am not here to socially amuse or validate anyone. Those seeking social fulfillment at the office are exhausting, and they create active stress for those of us with lives outside work who know that work is a thing you do to get paid. reply coldpie 23 minutes agorootparent> HR makes it clear we’re not to hire anyone with similar interests and life experiences. Huh? If you're in the same industry for a long time, you by definition have history in common, and it's pretty likely you've got similar interests if you both ended up at the same place. I don't see how HR could or would want to have an affect on that. > At any rate, my reply is under the context of wanting to go to the office for the social interactions. I am not here to socially amuse or validate anyone. Those seeking social fulfillment at the office are exhausting, and they create active stress for those of us with lives outside work who know that work is a thing you do to get paid. Indeed, this is a great example of why forced-RTO is a terrible policy for everyone, including folks who like coming in to the office! reply almostnormal 7 hours agorootparentprev> [...] postage stamp videoconferencing window s don't cut it. Where I work almost all meetings are online, because the majority of people WFH. And it's easier to join online than to walk to a common room for those that don't. If anyone enables their camera that's usually causing a short burst of laughter. Not because there's anything particularly funny, but simply because noone is used to see other people's faces anymore. The screen space is used for more important things. reply stringsandchars 10 hours agorootparentprev> \"poor self-discipline\" is quite the judgy statement to make dude. I certainly didn't think it was so extreme that it needed to be flagged. I simply find it an incredible concept that a person needs to physically leave a building before they can mentally adjust to \"being at work\"/\"not being at work\". I don't have a special 'office space' in my home environment. Over the years I've intentionally trained myself to not need anything other than my laptop to program on. In this way _even before the pandemic_ I was able to work under a tree in the park, at a café, on a train, at home or even (the most noisy and distracting place) at the office. Admittedly, when at the office I also needed noise-cancelling headphones - along with every single other programmer employed there because of the constant distraction of people talking, managers making personal phone calls, sales high-fiving each other, and so on. reply OrderlyTiamat 9 hours agorootparent> Admittedly, when at the office I also needed noise-cancelling headphones - along with every single other programmer employed there because of the constant distraction of people talking, managers making personal phone calls, sales high-fiving each other, and so on. Don't you think someone could say to you that those headphones are expensive and unneccesary, and that this problem simply reflects your lack of work focus? Wouldn't that be offputting and annoying if someone were to say that to you? reply stringsandchars 8 hours agorootparent> Wouldn't that be offputting and annoying if someone were to say that to you? There's a very emotionally-loaded tone to this discussion, which I don't think was an element in my original comment. I was struck by the fact that some people seem unable to change their mental state just because they're at an \"office\" or at \"home\". This is totally different to the fact that an open-plan office (all I've ever experienced before the pandemic) is a noisy and disruptive environment, with people talking loudly, making phonecalls, playing ping-pong, eating, and often dogs running around and barking. reply OrderlyTiamat 4 hours agorootparentI think many people did actually read that element into your original comment. I tried to highlight that here from a different perspective, so maybe you'd see what that could come across like if you were on the other side. For full transparency I use the noise cancelling headphones same as you, I think it's very logical and it does help me in the same way. I don't think that would be a reasonable thing to say to you. But the framing and emotionally loaded tone comes across as comparable to your original comment. E: and just in case: You will think those are very different scenarios, and your preference makes sense given the context. That's a valid perspective! But the people you were talking about in your original comment feel the same way! reply disgruntledphd2 9 hours agoparentprev> Considering it's an irish news site I'm surprised that was not mentioned. Ireland is part of the Anglosphere, and suffers from many of the same developmental issues (long commutes, houses in the middle of nowhere, poor public transport) that plague other English speaking countries. That's presumably why they didn't mention it. reply xyst 6 hours agoparentprevThat’s _your_ preference. Yet that is forced/mandated to the rest of us. reply cqqxo4zV46cp 5 hours agorootparentThis is like the first panel on a galaxy brain meme. I can just as easily say that it’s absurd that you demand to only be communicated with through a bloody webcam that you won’t turn on half the time. Don’t play the one-sided victim card. If you can’t find it within yourself to see things from another perspective enough to get out of the mindset of you being the only one that’s hard done by, don’t bother contributing to the conversation. reply globular-toast 9 hours agoparentprevThere's more to this than just work from home vs work from office. I did a PhD and felt similarly: I couldn't ever \"leave\" work. Home was work. My desk at the university was work. When I finished and started a real job I was indeed relieved that I could come home and, for once, not be working. But it was never about the location of my body. During my PhD, my head was work. I had nothing else in my life. I couldn't escape work because it was my entire life. When I returned to working from home (during the pandemic) I couldn't believe how unproductive I'd been for the past several years of working in an office. I would finish a day and think \"wow, I haven't been this productive since my PhD\". This has made me happier than ever. The difference is, unlike during my PhD, I have other things in my life now. It doesn't matter where my desk is. When I decide to \"finish work\" at the end of the day, my partner is normally home. When I'm with her I'm not working. If I decide to continue studying at my desk I'm not working. If I go out and do some exercise or walk by myself I'm not working. I was incredibly stressed during my PhD. I wasn't sure if I was going to be able to complete and lived with impostor syndrome the whole time. Nowadays I have a much more balanced relationship with work. This is something you should strive for too, and then you might find the scales tip in favour of working from home, like me. reply eleveriven 5 hours agorootparentYeah, for me it is still important to distinguish the space reply eleveriven 5 hours agoparentprev> Personally I hated that I can never \"leave\" work and it's always with me at home. Same here. Was difficult to adapt to it reply komali2 10 hours agoparentprev> I don't work at home at all (and it's a company policy everyone knows that) I believe this is a somewhat unique privilege. It seems many people have the worse of both worlds you mentioned: unification of the workplace and home, and needing to go to the office anyway. reply ewgfdgdfgdf 9 hours agorootparentDon't start calling the absence of abusive employer practices a \"privilege\". It should be a \"right\". reply keiferski 10 hours agoparentprevYeah I really don’t like working at home. The best situation IMO is a separate workspace that’s within a 5-10 minute walk, preferably with a cafe or some kind of public space en route. reply prmoustache 9 hours agorootparentThe problem is not liking or not working at home. The problem is being forced to work in an office if it doesn't fit you and other jobs allow you to stay at home. And the impact it has on corps ability to retain those workers. I know I have received a number of offers for work with higher salary in the last 2 years with forced hybrid work from office/home[1] but I won't accept any of that. At least until my youngest daughter is out of primary school. I don't mind going to the office once in a while, or even everyday if it is 5-20 minutes from home (as long as I keep possibility to work from home if a particular need comes). But I will refuse one that forces me to burn co2 for no value, that add stress to my day (commuting by vehicle) or that takes me more than 20 minutes by bicycle or public transport as long as I can find a decent one that doesn't force me to do that. My partner's doesn't work from a computer so she will have priority in our place of living for the foreseeable future. reply keiferski 8 hours agorootparentI agree and I do support companies that allow WFH, as it allows for the situation I mentioned - via coworking in my case. But I was replying to the idea of working at home specifically. reply cess11 10 hours agoparentprevIt's always with you anyway. The contract and the labour relation is there always, even when you sleep. Whether you can shut it out of your conscious mind isn't necessarily about location, though I get that it might help. It's not obvious that you might want to either, many problems in software development require slow, sustained thinking over several days or weeks. What's important to me is to be able to stop people from work to contact me. And if I want to take a half hour stroll because the weather is nice and I enjoy it, I will, and I can stretch it out to an hour if I find something fun to sit and watch, like some birds or something. No one can stop me, and no one will question it, because the only reason they'll know is that I've told them that I was on such a nice little stroll and saw some baby geese the other day. Or played with my kids or went grocery shopping or whatever. To my employer and colleagues the important thing is that the work gets done, with clear communication about whether it'll be done on time and why it won't be if that's the case. We're all full remote, in part because the stuff we do require a fair bit of personal maturity and professional seniority, and with that comes kids, grandkids and long established hobbies and side projects. reply fzeroracer 5 hours agoparentprevI WFH in a small studio apartment where I have two separate spaces for work and for personal stuff. Shutting off from work for the weekend is as simple as turning off my work computer, covering it up and going about my day as normal. You definitely do not need a separate office space. It helps, but what's key is properly setting your own mental boundaries. reply petesergeant 10 hours agoparentprevI think from a utilitarian perspective, getting the minority who want to not work from home to find a cowork space or alternative solution is better than mandating working from the office. Won’t fit everyone, but neither does forcing everyone into the office. reply jowdones 7 hours agorootparentIn the end it's home office guys bending over and taking it up their ass from office loving fanboys or the other way around. I'd say to the office sickos go work something else, be a fishmonger or something that requires physical presence. Otherwise bend over and shut up. reply rojeee 8 hours agoparentprevWhen I was living in London after COVID, at first, I didn't enjoy it. I still came into the office but when no-one else was there I realised \"what's the point?\". The office was exposed as the dull/boring/clinical place it's always been. The people I found going into the office were either those who were young and lived close by and somewhat used work as a social club, or those with nothing else better to do (also me at the time!). Anyone with a family was not there. Meanwhile, I've continuted to work remotely and I moved to the Cotswolds. I swapped a Victorian terrace for a much bigger detatched Cotswold cottage. I have a big garden, a glorious wild flower meadow and sheep grazing adjacent to the garden. There's no traffic on the roads and the nearby countryside is amazing. London is a veritable shithole in comparison. Getting a train to London is like travelling to a different - worse - country. If I still lived in London and commuted to the office, I would never see my young kids. I'd be out the door by 7:30 and back by 7ish. It would also put a lot more stress on my wife, as she would have to do everything during the day. I'd also get about 30 mins or so a day with my kids. That's terrible. Now, I can play with my kids until 9am and then start work. I finish at 5:30pm and get 2 hours with them before bed. I can also go running during the day. Switching off isn't really a problem for me because well... work is work. It pays the bills. So I'm quite happy to shut my laptop and forget about it. We had a cabin built in the garden, so my new commute is about 1 minute down the garden to the \"shed\" during which time I miraciously forget I even have a job in the first place when returning \"home\". I don't have any work apps on my phone for obvious reasons. I appreciate that's not the same for everyone though. Regarding cost of commute We've had it drilled into us over the years (gaslighted, even) that it is acceptable for us to spend hours of our day commuting to work and for us to bear the financial burden. Why should that be the case? I used to spend £10 a day on the commute. Commuting 200 days a year, that's £2,000 of my salary I need to spend on just getting to work. For others it is much more. That's absurd but it's just the monetary cost. The opportunity cost in terms of MY time is huge. It's about 2 weeks of the year sitting on a horrid underground train. I realise, you can do things on the train but I guess my point is that being on a train limits you from doing other things like playing with kids or doing some gardening. When recruiters have been getting in touch about new roles I make it clear up front that if said company wants me to routinely attend the office they must pay me for commuting time and the commute cost, otherwise it's a \"no\" from me. Some companies agree remote is acceptable in that case. I mean, I don't mind paying for the odd trip to the office but on a regular cadence and if it's expected (part of contract), then they must pay. Also, let's not forget the environmental impact of all this mostly pointless travel to work every day for knowledge workers. How much less carbon would we emit if we stopped doing it? Judging by the dip in CO2 emissions during COVID, quite a bit. reply foobarian 5 hours agorootparent> Now, I can play with my kids until 9am and then start work. I finish at 5:30pm and get 2 hours with them before bed. This right here. I'm actually nervous talking about this for fear of jinxing the situation. reply kkfx 9 hours agoparentprevWell, this is honestly a sign of self-discipline and maybe accommodation issue. I WFH and I have \"an office\" (a room) and \"the home\" (the rest). So I know when I enter the office and when I leave. The office have it's desk/softphones, who do not ring outside etc. I live in EU too, but I left the big dense city for the mountains to have such setup. Of course many are still \"panicked\" since if they leave the city they fear it would be hard to came back if the WFH end, but this is not really an issue in practical terms, it's a psychological issue: people MUST understand where we are, where we going and decide, no one have a working crystal ball but certain changes are moderately easy to predict and reasonably certain. Here the choice is between take the risk meaning potentially having a big prize or a big loss, or not take the risk and being SURE to suffer a significant loss. Economically the office model is untenable: we have large, big buildings to \"live\", normally used less than half a day, \"empty\" for most of the days of the year, and others big as well used just less than half a day, \"empty\" for most of the days of the year as well. The rest of the time spent \"commuting\", it's an absurd way to keep people moving to get them \"motivated\" to work instead of the contrary. In the past there was no alternatives, remote work was limited technically, now is like convincing people that a horse is better than a car, he can go in much more places, he can reproduce itself, he eat grass around the world and produce free fertilizer for crops. Oh, all it's true, but we also all know why cars win. WFH is a key of a social change not only for remote worker but for ALL: we know an enormous amount of people will have to relocate due to climate change and human crisis, this alone is an enormous issue. Being able to move keeping our work means opening a way to move to others who do not WFH for the material needs like fill a cavity or buy groceries of the WFH cohort. Similarly WFH we can move where we need to be for climatic, productive needs, it's a needed flexibility in a changing world. WFH also push semi-autonomy witch is another big need because in a changing world we will experience more and more service disruptions and we need to keep living with them. A home can now have p.v. and lithium storage in most part of the world enough to keep a big of appliance working, can have water storage for a week to a month and so on. We can live well even with intermittent services and being able to do so means we are still productive and those who handle services have more slack to evolve them as well. Consider that EU density and propensity of many EU country for dense cities\" https://ec.europa.eu/eurostat/statistics-explained/index.php... is a big part of our current crisis. Irish people live most in homes, only 10.6% are in apartments, but Spain, Germany, Italy are the opposite, and that's why they suffer already and they'll suffer MUCH more in the near future being unable to implement the Green New Deal for most. reply Rinzler89 9 hours agorootparent> Of course many are still \"panicked\" since if they leave the city they fear it would be hard to came back if the WFH end, but this is not really an issue in practical terms May I ask where do you live in EU that WFH is stil in palce? Here in Austria no employer tolerates WFH anymore. Any recruiter I spoke with and I asked them about WFH, they asked \"how many days?\" and when I answered \"well, all of them?\", the conversation ended there. All the managers want butts in seats at least 3 days/week. One company here I interviewed recently told me when I asked about WFH \"we know people love this WFH thing, so to please them, we're offering WFH on Fridays\" lol Managers can't live without seeing butts in seats here. It's either you come to the office or stay unemployed. The market is really bad here and employees have no leverage for WFH, that's why I asked where you live, since I'm planning to get out of this hellhole and I'm checking my options. reply kkfx 8 hours agorootparentFrance, on Sophia-Antipolis living in the Alps, \"nearby\" but still 99% remote. Yes here there is a big RTO push, but at least in IT it find little grip so far. It's easier AFAIK in Scandinavia in general, Finland in particular but I do not consider their future bright enough to suggest them. Honestly so far in large terms the countries I consider most with some future are the USA in the MID term, Russia in the long term, France might have a future thanks to a lower density and still being an \"almost complete\" country where almost anything is or can be produced domestically but it's still uncertain, however having old parents in Italy (north west, so relatively nearby) where I'm from I've choose a near-enough country where I can live well enough and work from remote. In Italy the situation is similar to the one you describe for Austria, aggravated by a higher population density... Edit: typos reply Rinzler89 5 hours agorootparent>France, on Sophia-Antipolis living in the Alps Isn't that region very expensive CoL compared to the local wages? Can you work in France tech sector, without speaking French? reply kkfx 4 hours agorootparent> Isn't that region very expensive CoL compared to the local wages? It's depend, far less expensive than Paris, far more expensive than the rest of France, but a thing is the shore, where anything have touristic prices, another is the inner land where prices are far lower. > Can you work in France tech sector, without speaking French? Maybe it's possible, but it would be definitively hard. France is an ancient ex-empire fully knowing the power of the langue on individuals, so they do not like using foreign languages. Of course even in France in tech most things are in English, but the fact that docs, exterior costumers contacts etc happen in English you still need French for all, starting from the public administration. In salary terms, you normally get FAR less than Luxembourg and still significantly less than Belgium, for a not so lower cost of life, but you still get EU level services, a nice climate, a bit hot now, but with cool nights, with nature around. I'm at 1030m altitude at 7km for the \"main village\" and I still get a 2Gbps/860Mbs FTTH, a small supermarket nearby, a big one at 15' with Drive, various leisure services and few shops. Not at all at the level of a developed big city of course, but still a good level of services, while in nature. So for me the choice was \"higher salary with less nice condition for a period than going somewhere else or less salary but a good quality of life and stability\", I chose this one. reply Rinzler89 3 hours agorootparentThanks for the detailed explanation. reply CalRobert 6 hours agorootparentprevApartments are homes too.... reply kkfx 6 hours agorootparentWell, not yours. I mean, in most countries you can own a flat BUT you own just the unit, not the soil. A home on ground it's your property, you can rebuild it as much as you want (with eventual limitations from local norms, in terms of height, kind of roof, color palette etc but you can), a unit is just a part of something bigger you do not own, so when the building will be ready to get demolished you'll own nothing. You might own some fraction of the building, depending on local laws, but you still can't decide alone. It's by far not the same. When I've built my current home I design it (well, sketched, the architects have done the proper design) after I've decided to add domestic p.v., after an EV charging station, a kiosk (gazebo, not sure the proper name in English a structure open on all sides with a tiled roof and a platform on ground to be outside but a bit protected from rain, Sun etc). I can't do nothing like that in an apartment. I can't get backups in an apartment, for instance I have here a heat-pump domestic hot-water system, it's very simple in principle, but demand a certain amount of space for the hot water reservoir, much bigger than classic water heater. I've decided to stock a bit of clean water (1000+1000l with a pump and pressurized tank system to have a week backup or even more if a day water supply freeze (happen once since I'm here) or there is any other interruption), it's pretty cheap but again it demand space. I have also a diesel car with a 1000l reservoir in garage, topped up once in a while when the diesel cost less than the average. Again pretty cheap, comfy, simple, but demand space. There is no space in an apartment for anything like that. In a home there is room to OWN, in an apartment you do not really own nothing but a shelter and some stuff you put in it. For me it's the prototype of the \"in 2030 you'll own nothing\", the service economy where you are forced to rent anything because you simply can't own anymore, and we know from history how devastating is such model once you get trapped in it. reply CalRobert 5 hours agorootparentOk… I really don’t see how that changes the fact many people happily have an apartment as their home. reply jagger27 5 hours agorootparentprevGood for you, sounds like a comfortable place to live. The concepts of the city and the condominium aren’t going anywhere though. What a strange idea, humans living together, right? I get it, I love gardening too, and balconies don’t really cut it for me either. Cities have existed for as long as written history has. They can only get so wide before there’s pressure to build up. What’s the alternative? > When I've built my current home Vanishingly few people have the financial privilege to buy, let alone build, anywhere near a city, I’m sure you’re aware. There simply isn’t a world where every single person can live in a PV-powered, water tank backed up fortress, with ample setbacks to keep your neighbours away. That’s far more dystopian to me than any “you’ll never own anything” boogeyman. reply kkfx 4 hours agorootparent> The concepts of the city and the condominium aren’t going anywhere though I'm not sure of that, at all: I see the green new deal as something happening that's here to last, and I see no chances to \"migrate\" to green new deal condos, electrifying them on scale. Yes, you can build a NEW condo \"A class, all electric\", but there is no chances to transform those built decades ago, and no chances to re-built them as well. Yes, in temperate climate it's still doable to put an air-water heating powerful enough per unit, even a central heating. However the operational cost of such move will be FAR higher than gas at actual prices, not only, if ALL condos switch to such heating setup we simply can't provide enough electricity for them all. Where I'm from (north-west Italy, so not a cold region) a classic apartment have circa 24kW thermal gas or oil heating system. Converted to an air-water heat pump it would be around 6-8kW normal absorption for 6 hours per day at least 4-5 month per year. With ALL units at 6-8kW + the rest there is simply no generation capacity. No chance to electrify. Meanwhile where I'm now, in a much fresh place in winter, 1kW heat a home far bigger than a typical apartment most of the year, with -25℃ outside 4kW suffice. At this absorption rate there is enough generation capacity to be all electric. That's why we need new buildings. Now HOW to made them? In a dense city crushing and rebuilt a condo is hardly feasible, in EU anything was designed at a walk distance, crushing a condo means blocking roads nearby for some months, there is simply no space to do so without big issues. It could be done for ONE condo, definitively not en-masse. Single family homes on contrary are easier to rebuilt end generally have enough space around to put a construction site in place without dramas. Aside we have many cities in places more and more flooded, subjected to dangerous subsidence and so on, again we can't rebuild cities, it's simply too costly. Take a look at the Indian's 100-smart city program, where the ENTIRE COUNTRY resources would be needed to built 100 cities able theoretically to host only a very limited percentage of population. Long story short: modern city, future cities are like the ancient Fordlandia from Henry Ford, equally a failure and a distopic nightmare. > Cities have existed for as long as written history has. They can only get so wide before there’s pressure to build up. What’s the alternative? Yes, because we never have had current TLC/IT and logistics. Today it's cheaper to build a chair in China, with wood from Poland, straw seat from Brazil, metallic connectors from India to sell it in Canada than directly build it in Canada few kilometers away of the final customer. We are in a changing world and that means mass migrations, war, we need flexibility to relocate and cope with countless \"whole country malfunctioning issues\" for a long period of time, in a city it's a nightmare, anyone eat, but all the food came from elsewhere, big infra are need to move food, goods in general, there is little to no room to change, an easy target for bombing during a war, an easy target to spread diseases and so on. The alternative is living in less dense and more geographically distributed ways, so we can relocate easily because number of people to move per single area on earth are not so high, impacted people from extreme weather, war, crisis events far more manageable, there is room for limited autonomy to be resilient, there is space to evolve as the tech change. > Vanishingly few people have the financial privilege to buy, let alone build, anywhere near a city, I’m sure you’re aware. Ignore the current economy: can we MATERIALLY build single family home for almost anyone? In terms of industrial output ability, raw materials availability and so on? I think yes in all western countries and in many other as well. Economy it's just a measure. If we, the people, decide to do something doable materially, the economy will change to make it possible, because the current economic state of things is the byproduct of the current failing democratic model, we are in a kind of economic dictatorship modeled after/well described by the ancient pamphlet The Science Of Government, Founded On Natural Law, by Clinton Roosevelt. If we decide to change our countries without the need of a III world war we can. 99% can. If most prefer stop the history train they will fails as regularly happen in history, ending up in city more and more similar to ghettos with a lower and lower mean income, bigger and bigger criminal activities, desperation and so on, as you can already observe in most USA big and medium cities compared to themselves 20+ years ago. As you can see in most EU cities even if at a slower rate than the USA simply because we have much more social protections that slow down the economical effects of current policies. > There simply isn’t a world where every single person can live in a PV-powered, water tank backed up fortress, with ample setbacks to keep your neighbours away. That’s far more dystopian to me than any “you’ll never own anything” boogeyman. There is no need to keep our neighbors away IF we slowly change from the city model to the spread model with public investments starting from WFH as a key element to allow people flee the city and behind them paving the way for others to build services outside \"now\" that there is a market outside. It's a path doable an year after another with a significant economy boost form such enormous general relocation effort. reply jagger27 4 hours agorootparent> economy boost form such enormous general relocation effort. [citation needed] reply kkfx 1 hour agorootparentActually not really needed: a nation-wide open relocation plan \"all living in too dense areas, flood hit areas too many times, buildings at risk of landslides, submersion and so on can give their own property to the State in exchange of a to-be-built new one. Those interested have at their charge find a suitable ground to built, the part the State will pay is a similar size of the old one, the rest is at Citizen charge, the exchange will happen once the new home is built, residing there is mandatory for 5 years or a significant amount of the benefit need to be given back to the State, the State will ensure urbanization (meaning roads, electricity, water services etc of sufficient grade)\". Such \"bonus\" can ONLY be get from private owner for their old/new main home, and only very few can take it at first because EU job market, specially toady is not as fluid as the USA one, find a new job is not at all that easy and quick, specially if it's not a \"desperate level\" one, so essentially at first only remote workers with not much big family ties and early retired could accept it. Only some of them will do, people fear the change. Meaning only a small cohort of citizen can get the bonus the first year. Not too much to provoke market disruption as many \"eco-bonus\" already provoked here (for instance Italian 110%, meaning the State cover the 110% of costs to improve a building for 2 energy class or the French \"Isolation à 1 euro\" witch lead to an incredible amount of crappy insulation with a gazillion of problems led to significant costs for many who originally spent just 1€ to \"better insulate\" a new home. However this said cohort is still not too small to not count at all. After them successfully settled others will be convinced and another batch of people will took the bonus. After them it's time for many to look for a new \"market\" outside the city, instead of 10 restaurants in 1km in the city center there will be some moving outside to serve spread populations, and that another batch. Since building homes here is far from simple like in the USA, it took MONTHS just to buy the terrain and get a project approved, the speed at a certain point will increase but not too much, meaning a decade at least of steady economic growth led by the real estate. reply koonsolo 8 hours agoparentprevI was exactly looking for this in the article, couldn't find it, and therefore just ignored the whole thing. Either you paint a truthful realistic picture, or you pick some political side. I'm not interested in the 2nd one. I work 1 day at the office, and that's my ideal setup, maybe 2 would be better but I don't work fulltime. I have colleagues that after the pandemic \"Don't want to work a single day at home during their lives\". These guys were locked up alone in their apartment during covid and absolutely hated it. I get it. For me, if I stay weeks at home, it works on my mood and energy. Humans are social animals, with maybe a very few exceptions. Also a European perspective. reply koonsolo 3 hours agorootparentFunny how I'm getting downvoted. Some people really don't like the truth that some people prefer working in the office. reply xchip 10 hours agoparentprevThat's because you have the wrong mindset. And the more beliefs you have like this, the more complicated your life will be. reply Devasta 8 hours agoprev'Nobody on his deathbed ever said, \"I wish I had spent more time at the office.\"' --Paul Tsongas Thanks to the Covid lockdowns we now know this isn't the case, in fact we can be quite confident a fairly large portion will spend their final moments surrounded by family and loved ones while wishing their could see one more time the thing that matters most to them: the shitty office cube farm. reply avh02 6 hours agoparentHenry Royce (of Rolls Royce) disagrees: > I have only one regret … that I have not worked harder. https://en.wikiquote.org/wiki/Henry_Royce reply 0x000xca0xfe 6 hours agorootparentI don't see the word \"office\" in this quote? reply wpguy 5 hours agorootparentI agree with that. I wish worked harder in some of my studies in college or on some self-teaching. None of that has to do with me wasting my time going into an office. reply paulgb 10 hours agoprev> Executives who are pushing employees to come back to the office are most likely to succeed if they can make a convincing case for why coming back to the office benefits employees and the organisation. The typical explanation that coming back to the office is important for the culture of the organisation is unfounded at best, and hogwash at worse. Maybe big organizations are bad at communicating RTO reasons, but isn’t it pretty obvious to everyone who has done both that the biggest advantage of working in person is high-bandwidth communication? I feel like the quality and quantity of information exchanged with my colleagues is much higher on days we work in person than remote. There’s a reason why even fully remote companies usually do some sort of recurring offsite. That’s not to say that the benefits of RTO always outweigh the costs, but I find the trope that RTO is just some pointy-haired boss whim to be silly. reply darreninthenet 10 hours agoparentIn my last job (10,000ish employees at a UK financial services organisation) we worked at home for the whole of the Covid period... apart from one small team in the whole organisation (which soon got dealt with as they were basically just slacking), productivity went up. After Covid, we went into the office one day a month and didn't really achieve anything additional at all, if anything those days were less productive due to the heavy socialising that went on. In my current job, pan-European financial services organisation, I am the only person in my team in London, everyone else is in Brussels. I've never physically met most of them. The one day a week I'm required to spend in the London office is a complete waste of time and money and usually involves me sitting on Teams meetings all day as I very rarely need to interact with anyone else in London. It's my least productive day of the week. I'm also not in a \"mostly lone producer\" role like developer, I'm a project/programme manager and my job is interacting with people all day. I think it just depends if people are able to refocus their mind into a new way of doing things. reply mytailorisrich 9 hours agorootparentI think that few days in office, especially as few as one per month, should really be about socialising. Maybe start with a team meeting for a general update then smaller face-to-face discussions on topics best suited for in-person interaction. Then break for a team lunch and spend the rest of the afternoon on whatever people want to. > The one day a week I'm required to spend in the London office is a complete waste of time and money and usually involves me sitting on Teams meetings all day as I very rarely need to interact with anyone else in London Yes, same here. A mandate to be in office one-two days a week with no thought about the aim, and no planning for others to be there at the same time is a total waste of time and money. reply kisamoto 9 hours agorootparent> I think that few days in office, especially as few as one per month, should really be about socialising. Came here to agree with this. Personally (and there is a heavy personal opinion to this as some people also do prefer the office life) I think a majority work from home but with the occasional mandated office day specifically for socialising is a good hybrid. I acknowledge that more extreme (for lack of a better word) introverts would like to avoid the office all together though. reply darreninthenet 5 hours agorootparentI'm not sure it's an introvert thing... I've no desire or need to go to the office, I have many friends not at work and have no need for the false \"socialising\" you get in the office environment reply stringsandchars 10 hours agoparentprev> high-bandwidth communication This just sounds like some sort of buzzwordy justification for hauling people back to the office. My experience, is that communication propagates better in group-chat environments like Slack, that meetings are faster and more productive on Meet, that my work-focus is magnitudes better in the quiet of my home, and that (if absolutely needed - which is pretty much never) a get-together is more creative and productive if it doesn't happen at the office - but is at another venue altogether. reply vineyardmike 10 hours agorootparent> My experience, is that communication propagates better in group-chat environments like Slack, that meetings are faster and more productive on Meet, that my work-focus is magnitudes better in the quiet of my home I think this is super dependent on the person and circumstances. I found \"meetings\" which are just doc reviews or low involvement group updates are better via slack or meet. Active discussions from a few participants are better in person (esp. if using a whiteboard). I think this speaks to the waste of \"this meeting could have been an email\" culture more than anything. I found that some people are better able to \"focus\" by ignoring junior employees when WFH, increasing their own productivity at the expense of the junior's productivity and growth. Some of my most \"productive\" coworkers are also the least helpful to the team, and the least active on chat too. reply Freedom2 8 hours agorootparent> I think this is super dependent on the person and circumstances. Precisely, which is why this[1] comment from the GP isn't accurate. I think we should try to create less polarizing statements and try to sum up the entire human experience (\"everyone\") about how they feel about WFH. [1]: > pretty obvious to everyone who has done both that the biggest advantage of working in person is high-bandwidth communication reply wildrhythms 7 hours agoparentprev>biggest advantage of working in person is high-bandwidth communication Wrong, it's the tax breaks: >JPMorgan Chase & Co. and RBC Capital Markets are among more than 100 firms that have negotiated billions of dollars worth of agreements under New Jersey’s pre-pandemic programs. None have yet applied for the waiver, Sullivan said, meaning if they want their tax breaks, they’ll have to prove the jobs are being done on site at least three days a week. JPMorgan and RBC declined to comment. https://www.bloomberg.com/news/features/2023-02-21/another-t... reply from-nibly 6 hours agorootparentAlso cutting staff without ending up in the newspaper for laying people off. reply kisamoto 9 hours agoparentprevHigh bandwidth does not equal high quality. I much prefer a well thought out text message rather than someone spamming their thoughts at me through speech. That being said, for discussion points and fast iterations I agree that in-person is hard-to-beat, but for a lot of work this is the minority and doesn't justify forcing people to be there at all times just in case this is needed. reply nehal3m 7 hours agorootparent>spamming their thoughts at me through speech Funny way of saying 'talking to me'. I'm going to work this into my vocabulary for fun and profit. reply marcosdumay 3 hours agorootparentNo, it's not. There's useful communication and there's spam. Those exist on every media. Spoken spam is a really bad problem with offices. reply 0xBDB 3 hours agoparentprev> That’s not to say that the benefits of RTO always outweigh the costs, but I find the trope that RTO is just some pointy-haired boss whim to be silly. Exactly. I prefer to WFH like everybody else, but I accept that I am less valuable to my employer when I do and expect to negotiate accordingly. For people who refuse to believe this, I think you can just link to the history of MIT Building 20 and pretty much drop the mic. https://en.wikipedia.org/wiki/Building_20#:~:text=In%201998%.... reply zith 10 hours agoparentprevThis is my experience in very small companies (think a 100k employees and I don't care what the other million people do, because obvious reasons. I work for remote clients and my team is scattered all over the world, so there's no high bandwidth input possible from them. My local colleagues work in totally unrelated projects so beyond a bit of fun there's no shared information needed or required. I still go in the office for this banter like once a week, but I guarantee you my productivity is like the half - there's always somebody walking around with a coffee interrupting me for some \"high bandwidth information exchange\". Morals? Please stop assuming everybody works like you. reply marcosdumay 3 hours agoparentprev> but isn’t it pretty obvious to everyone who has done both that the biggest advantage of working in person is high-bandwidth communication? High-bandwidth is some forms of communication. While the office environment harms severely other forms of communication. Personally, I've noticed those make for a small share of my work needs. Overall, I communicate much better remotely. reply lordnacho 10 hours agoparentprevHigh bandwidth communicating is also a firehose of noise, though. You may find that the extra capacity to communicate is detrimental as people spend their time talking about marginal issues. If your communication is limited, you will use your time on the most important things. reply witx 8 hours agoparentprev> high-bandwidth communication? For me, absolutely no. I want high quality not high bandwidth. I don't want everyone interrupting me all the time with, relevant or not, questions. I want you to write me an email or message in the chat and I'll check it and answer in due time. I don't want to be interrupted to go to the cafeteria or \"for a smoke\" every 15min by a different person, or to have people standing besides me talking about their weekend or their kids. It's very invasive because I get distracted easily, even with good quality headphones, and it's hard to get back on focus. With this said I don't mind going to the office where I can chat with people and socialize but I want to allocate time for that, not be forced into it. I feel that WFH allows me to balance the time I need to work and the time I need to socialize much better. reply laserlight 8 hours agoparentprevWe come together with remote colleagues to work. I can confidently say that high-bandwidth wears off pretty quickly. High-bandwidth is not essential 90% of the time, and it's easy to compensate the remaining 10% simply by taking more time. In my experience, bandwidth of remote work has been increasing, as people keep organizing themselves around it better. So, the difference will only get smaller. Most important benefit of RTO is the social aspect, in my experience. And, even that wears off rather quickly. Whether there's a “benefit” depends a lot on one's colleagues, in the first place. reply insane_dreamer 7 hours agorootparentYou can have some of the social remotely too. I’ll often open our weekly engineering meeting on Slack with a few minutes of people talking about their weekend or related stuff. It happens in chats as well. Of course we’re a small team who have worked together for years. reply laserlight 1 hour agorootparentDefinitely. I've become close friends with a colleague without meeting once in real life. That being said, physical presence brings a different dimension to social relations. reply xyst 6 hours agoparentprev> I feel like the quality and quantity of information exchanged with my colleagues is much higher on days we work in person than remote. Keyword: “feel” Sounds like a skill issue. reply gilbetron 3 hours agoparentprevIn office isn't higher bandwidth, but it is more fun! I love going traveling to the office and hanging out with people. Hardly any work gets done, but being around people is really entertaining. Bonds definitely form better - whether that is good or bad for business I haven't been able to figure out yet. However, it is better for my social life. All I know is that if I see someone WFH I know they are getting more work done than if I see them in office. 80% of top performers WFH the majority of the time or are remote. Also, being remote and traveling into the office for week-long visits the past 3 years, I can say I almost never see people whiteboarding. I've done it once while in office in a meeting and it wasn't needed at all. People using online diagramming tools during zoom meetings? Definitely. I really miss the social aspects of being in office, but the benefits to Remote work just outweigh those aspects, sadly. Ultimately, what happens to RTO really depends on the market. If the job market heats back up again, RTO will largely go away. If the job market tightens, then it will dominate. That's because the vast majority of executives and owners want to be in office around their domain. What's the fun of being a billionaire and having to be on zoom all the time? reply sys_64738 10 hours agoparentprev> the biggest advantage of working in person is high-bandwidth communication? Pointless meetings, constant interruptions, overhead noise, watercooler talk? Those types of things have zero advantage. reply tehmillhouse 7 hours agorootparentWe have to contend with working with people who are sometimes very hard to work with. Watercooler talk gives you the opportunity to remember that the guy who keeps filing badly written tickets has a wife and kids and hobbies, and is likely filing badly written tickets because he's extremely overworked and doesn't have time to write better tickets. We're social creatures, and having unstructured social interactions greases the wheels when we work together. I'm sure this also depends on the kind of organization you work at, but I find that being on-site makes a huge difference. Yes, even in the quality of the work. reply rrr_oh_man 10 hours agoparentprev> high-bandwidth communication > quality and quantity of information exchanged with my colleagues Can you elaborate? What do you need to exchange throughout the day? I've worked as an IC and as a manager both with remote-first, async-first and very local, traditional enterprise structures. The quality of communication on the former has been excellent most of the time, while in the latter there's always been a 30%-50% loss rate. reply prmoustache 9 hours agoparentprevThat only works for companies that have a single office. Once you are multiple offices, that argument is moot for the most part. Also I think you are mistaking high bandwith with low latency. You can certainly do high bandwith remotely. What you lose is on latency because remote work involve some form of async communication. reply closewith 10 hours agoparentprevIn every organisation I've ever worked in, from military to SAR to healthcare to software, the issue has never been bandwidth. More often the issue is lack of concise communication. All higher bandwidth provides is more noise to signal. reply cess11 9 hours agoparentprevWhat happens with communication \"in person\" is that people talk at the same time. This doesn't fly in remote meetings, so they kind of enforce good meeting hygiene in this regard. Not enough to make meetings great overall but it helps. Management in many corporations want the employees to feel like they are friends, which they typically are not (do you regularly visit co-workers in their homes? no? then you probably aren't actually friends). It's one of many strategies to foster unfounded loyalty to the employer and enabling of corporate hierarchies. reply prmoustache 9 hours agorootparentI hate when people throw corporate bullshit using words like \"family\". It might be true for smallbut it's also important to get some overlap depending on the situation What type of situations are you thinking about? reply johnny99k 7 hours agoprevAfter my first few jobs out of college (15 years ago), I realized I hate working from someone else's office. It feels so constrained and like I'm in school again. Remote work was very rare then with salaried jobs, but not as a contractor. The company I'm working for now had an office pre-pandemic (I would meet with the director once/month), sold the one here locally during the pandemic, and got acquired by a large, international, company where the majority of the employees work remotely and the HQ is in Europe (I'm in the US). The last time I had to go to an office was for a local contract a few years ago (80 miles away from me) that required me to drive-in once/week for a few hours. The project ended after a few months and I found something 100% remote. I used to work from coworking spaces and sometimes the library, but now I have my own home office. Everyone talks about mixing life and work when working from home. It's pretty easy for me to just turn everything off and walk away at 5. reply drewcoo 7 hours agoparent> It feels so constrained and like I'm in school again. When I was in school I did most of my productive work at home. reply steveBK123 7 hours agoprevSome uncommon topics in the WFH/RTO debate.. Many employers slowly expanded the norms of work hours during remote/hybrid, which haven't been walked back now that they demand in-office. Jobs that used to be a 9-6 in office are now getting regularly scheduled 8/8:30am meetings (and still keeping the 5pm ones). Employees are left with more complex working life of waking up extra extra early, or dialing into early calls, then taking a train between meeting breaks to get in before lunch, etc. This includes stressing that they get in early enough for the swipe to count. A side effect is \"statutory swipes\" where others push the limits to w",
    "originSummary": [
      "Professor Kevin Murphy from the University of Limerick claims remote workers are more productive and satisfied compared to those working in offices.",
      "The push for Return to Office (RTO) mandates post-pandemic risks losing top talent, as many employees now reject traditional office norms.",
      "Executives should provide compelling reasons and incentives for returning to the office, acknowledging the shift in power dynamics favoring employees, or risk losing valuable talent to more flexible competitors."
    ],
    "commentSummary": [
      "The debate between remote work and return-to-office (RTO) mandates centers on flexibility, comfort, and the potential loss of employees who prefer remote work.",
      "Commuting offers a mental break for some but presents challenges like pollution, high costs, and blurred boundaries for others, impacting work-life balance and career growth.",
      "Remote work is seen as more efficient and sustainable, offering benefits like increased family time and reduced carbon emissions, but may neglect junior staff and require clear communication of RTO benefits."
    ],
    "points": 252,
    "commentCount": 279,
    "retryCount": 0,
    "time": 1716967736
  },
  {
    "id": 40512509,
    "title": "Canada's Bill C-26: Controversial Powers to Install Network Backdoors for Surveillance",
    "originLink": "https://www.theglobeandmail.com/opinion/article-ottawa-wants-the-power-to-create-secret-backdoors-in-our-networks-to/",
    "originBody": "Comments Share Bookmark Kate Robertson is a senior research associate and Ron Deibert is director at the University of Toronto’s Citizen Lab. A federal cybersecurity bill, slated to advance through Parliament soon, contains secretive, encryption-breaking powers that the government has been loath to talk about. And they threaten the online security of everyone in Canada. Bill C-26 empowers government officials to secretly order telecommunications companies to install backdoors inside encrypted elements in Canada’s networks. This could include requiring telcos to alter the 5G encryption standards that protect mobile communications to facilitate government surveillance. The government’s decision to push the proposed law forward without amending it to remove this encryption-breaking capability has set off alarm bells that these new powers are a feature, not a bug. There are already many insecurities in today’s networks, reaching down to the infrastructure layers of communication technology. The Signalling System No. 7, developed in 1975 to route phone calls, has become a major source of insecurity for cellphones. In 2017, the CBC demonstrated how hackers only needed a Canadian MP’s cell number to intercept his movements, text messages and phone calls. Little has changed since: A 2023 Citizen Lab report details pervasive vulnerabilities at the heart of the world’s mobile networks. So it makes no sense that the Canadian government would itself seek the ability to create more holes, rather than patching them. Yet it is pushing for potential new powers that would infect next-generation cybersecurity tools with old diseases. It’s not as if the government wasn’t warned. Citizen Lab researchers presented the 2023 report’s findings in parliamentary hearings on Bill C-26, and leaders and experts in civil society and in Canada’s telecommunications industry warned that the bill must be narrowed to prevent its broad powers to compel technical changes from being used to compromise the ”confidentiality, integrity, or availability” of telecommunication services. And yet, while government MPs maintained that their intent is not to expand surveillance capabilities, MPs pushed the bill out of committee without this critical amendment last month. In doing so, the government has set itself up to be the sole arbiter of when, and on what conditions, Canadians deserve security for their most confidential communications – personal, business, religious, or otherwise. The new powers would only make people in Canada more vulnerable to malicious threats to the privacy and security of all network users, including Canada’s most senior officials. Encryption of 5G technology safeguards a web of connection points surrounding mobile communications, and protects users from man-in-the-middle attacks that intercept their text and voice communications or location data. The law would also impact cloud-connected smart devices like cars, home CCTV, or pacemakers, and satellite-based services like Starlink – all of which could be compromised by any new vulnerabilities. Unfortunately, history is rife with government backdoors exposing individuals to deep levels of cyber-insecurity. Backdoors can be exploited by law enforcement, criminals and foreign rivals alike. For this reason, past heads of the CIA, the NSA and the U.S. Department of Homeland Security, as well as Britain’s Government Communications Headquarters (GCHQ) and MI5, all oppose measures that would weaken encryption. Interception equipment relied upon by governments has also often been shown to have significant security weaknesses. The bill’s new spy powers also reveal incoherence in the government’s cybersecurity strategy. In 2022, Canada announced it would be blocking telecom equipment from Huawei and ZTE, citing the “cascading economic and security impacts” that a supply-chain breach would engender. The government cited concerns that the Chinese firms might be “compelled to comply with extrajudicial directions from foreign governments.” And yet, Bill C-26 would quietly provide Canada with the same authority that it publicly condemned. If the bill passes as-is, all telecom providers in Canada would be compellable through secret orders to weaken encryption or network equipment. It doesn’t just contradict Canada’s own pro-encryption policy and expert guidance – authoritarian governments abroad would also be able to point to Canada’s law to justify their own repressive security legislation. Now, more than ever, there is no such thing as a safe backdoor. The GCHQ reports that the threat from commercial hacking firms will be “transformational on the cyber landscape,” and that cyber mercenaries wield capabilities rivalling that of state cyber-agencies. If the Canadian government compels telcos to undermine security features to accommodate surveillance, it will pave the way for cyberespionage firms and other adversaries to find more ways into people’s communications. A shortcut that provides a narrow advantage for the few at the expense of us all is no way to secure our complex digital ecosystem. Against this threat landscape, a pivot is crucial. Canada needs cybersecurity laws that explicitly recognize that uncompromised encryption is the backbone of cybersecurity, and it must be mandated and protected by all means possible.",
    "commentLink": "https://news.ycombinator.com/item?id=40512509",
    "commentBody": "Ottawa wants the power to create secret backdoors in networks for surveillance (theglobeandmail.com)221 points by walterbell 4 hours agohidepastfavorite134 comments piltdownman 3 hours agoCanada has the power to backdoor telecom networks for surveillance. All host nations do for their infrastructure as part of the RAN Architecture https://en.wikipedia.org/wiki/Lawful_interception What Canada seems to actually want is a way of doing this without legal oversight or recourse to traditional legal gatekeeping like warrants. reply mrandish 2 hours agoparentGiven the rapidly declining state of individual privacy, when discussing these extensions it helps to be specific about the authorized agency and context. For example, these days, it's pretty much a given that NSA-type spy agencies are already getting all of whatever electronic communications they want with little friction. In the US there are certain supposed safeguards against surveilling US citizens domestically but we've already seen how quickly and easily these have been circumvented by using partner 'five eyes' agencies and commercial data brokers. While this is obviously problematic, to me, it's even worse if domestic law enforcement agencies gain new ways to remove friction like warrant requirements or at least the need to make specific per-instance requests (which are possible to (in theory) be tracked and reviewed to detect over-use and abuse). The idea of domestic law enforcement agencies gaining access to \"full take\" feeds of everything enabling them to retrospectively build massive connection trees of metadata which can be searched is downright terrifying. reply jonny_eh 2 hours agorootparentGood insight. The difference between the NSA and local cops is that the NSA won't be looking for some bullshit to use as an excuse to arrest or harass you. reply somenameforme 2 hours agorootparentNope, but they will be looking for your nudes. [1] [1] - https://www.independent.co.uk/tech/nude-photos-of-strangers-... reply exe34 45 minutes agorootparentif they want pictures of my hairy pucker I can send them any time, hopefully it'll save them the effort. reply sneak 51 minutes agorootparentprevUnless you’re a journalist publishing information about the federal government that they don’t like. Then they’ll imprison you indefinitely without trial. The bar is higher for them to wield “some bullshit” against you, but rest assured, they still will. It’s been more than a decade since Assange has been free. reply sqeaky 2 hours agorootparentprevThere are just fewer of them, I suspect they are harassing someone. reply thsksbd 1 hour agorootparentprevOf course not. The dragnet surveillance is not to bother with your doobie habit. You and I and most of us are irrelevant losers doe the NSA They dragnet surveil to get dirt on the ten thousand or so lawmakers that matter. reply thsksbd 1 hour agoparentprevFurthermore, Canada doesn't have a (real) constitution since the TP they have since 1982 has a \"not withstanding\" clause, meaning parliament can just ignore their equivalent of the Bill of Rights reply peeters 22 minutes agorootparentI know you know this, because you mentioned the Bill of Rights, but just to be more precise, we have a constitution, but our charter of rights is overridable in certain circumstances. The constitution is more than an enumeration in rights in both the US and Canada, it also defines the structure of representation, government, and democracy, none of which is subject to the notwithstanding clause (obviously, because the notwithstanding clause itself is part of the Constitution). reply SECProto 1 hour agorootparentprevNote that the notwithstanding clause has never been used by the federal government (the \"parliament\" you referenced). It's a shitty clause, and should be removed but it was put in at the behest of certain province(s) as the only way to get the Charter of Rights and Freedoms at all, and has only been used by provincial governments (aka legislatures, though a few provinces do call them \"provincial Parliament\"). reply peeters 26 minutes agorootparentThat said, the Conservative Leader has signalled that he will use it to override the Supreme Court on social issues. Now dropping hints in an election runup is obviously different than actually invoking the NWC, but it demonstrates that our Charter is as robust as our politicians' perceived risk of throwing it out. Having the loophole to preserve some level of provincial autonomy is one thing, but having federal parties signal they will use it is an attack on the institution itself. reply glitchc 1 hour agorootparentprevWhat prevents its use by the federal government? If the answer is \"nothing\", then it's only a matter of time. reply Galxeagle 45 minutes agorootparentPolitical blowback has been enough to keep the power in check - it significantly raises the visibility of the attempted action whenever it's invoked(1) and historically has been associated with a political hit. It also has a 5-year sunset/renewal requirement, and can only override certain sections. I think everyone would generally agree a constitution would be stronger without it, but even if 'it's only a matter of time', it's played out as a pretty decent compromise to actually get the charter signed ~45 years earlier than potentially no charter at all. Canada generally relies on trust and good behaviour more than the US system of checks-and-balances - the most obvious difference is that our Prime Minister plays the role of both US president (head of exec) and congress (technically just the House equivalent, but the senate equivalent is much weaker) (1) https://www.cbc.ca/news/politics/notwithstanding-clause-doug... reply kevin_nisbet 2 hours agoparentprevI was going to add the same thing, this isn't only something the telecom providers do, the equipment providers include lawful intercept features as part of the equipment, the telecom just has to setup access. I don't have a chance to check right now, but I think this is even part of the published standards. reply esafak 2 hours agoparentprevWhat's RAN? It's not in the link. reply kevin_nisbet 2 hours agorootparentRadio Access Network - basically think the cell phone towers and the equipment for those towers. reply incomingpain 1 hour agoparentprevCanada already has lawful intercept. This is totally their goal. reply rustcleaner 2 hours agoprevCall me paranoid (I'll fess up to it), but I think client-side scanners like Recall are expressly for defeating E2EE without breaking the math or hardware. With NPU-powered client-side scanning combined with lexical analysis techniques, even if YOU are knowledgeable enough to have privately ditched Apple/Google/Microsoft permanently: your mentally normie-tier anon fren may be using a Copilot+ with Recall, and so Microsoft gets to read the conversation on his machine and then sus you out. reply maxglute 40 minutes agoparentOnly matter of time before OS/recall operators realize they're sitting on stockpile of \"accidentally\" captured critical info and get into the information brokers game. reply rolandog 22 minutes agorootparent\"Microsoft: best Linux salesperson!\" reply achrono 2 hours agoprevIf Snowden and Assange have taught us one thing, it is that state-sponsored surveillance is not a topic you want to have a very high evidence threshold for. The available evidence is always going to lag the actuality and even what we previously thought of as exaggerations/outliers in terms of suspicions of surveillance (e.g. \"NSA knows I hate broccoli\") have turned out to be not so unwarranted after all. reply somenameforme 2 hours agoparentThe NSA was literally spying in World of Warcraft. [1] About the time you have spooks running around in video games as Elves 'for national defense', you know we live in the dumb (but endlessly entertaining) timeline. [1] - https://www.theguardian.com/world/2013/dec/09/nsa-spies-onli... reply mschuster91 9 minutes agorootparentOnline games have historically been quite a way for people to organize beyond the wide Internet. Steam and Discord in particular gained notoriety in recent years [1], but I distinctly remember UT2004 being flooded with Nazi trolls all the time even around 2010. [1] https://www.wired.com/story/far-right-took-over-steam-discor... reply mysterypie 2 hours agoprev> In 2017, the CBC demonstrated how hackers only needed a Canadian MP’s cell number to intercept his movements, text messages and phone calls. > From the linked article: First, the hackers were able to record a conversation between Dubé in his office on Parliament Hill and our Radio-Canada colleague Brigitte Bureau, who was sitting at a café in Berlin. So many questions! Does this still work? On any phone using SS7? Including landlines and mobile phones? From anywhere in the world? To anywhere in the world? What are the limitations of the attack? Why isn't this a vastly bigger problem if anyone can listen in on anyone's calls? reply kevinprince 3 hours agoprevThis keeps coming up in most countries every few years. Everyone seems to forget in nearly every country telecoms are licensed industries and providing legal intercept is a legal obligation of those licenses. reply worewood 2 hours agoparentWhile they have the power to backdoor telecom networks for surveillance, what they actually want is a way of doing this without legal oversight or recourse to traditional legal gatekeeping like warrants. So we should not shrug this off just because \"they already can do it\". reply seanw444 3 hours agoparentprevAh okay, the law says so, so it must be acceptable. reply londons_explore 3 hours agorootparentI just want everyone to be aware of this. Every call or chat conversation that is intercepted should have an audible/text message saying \"beep. beep. Sergeant Tom smith has joined this conversation as allowed by wiretapping regulations for your safety and security\". Followed by \"This conversation is now being recorded by Sergeant Tom Smith\". reply rustcleaner 2 hours agorootparentNo we should ignore the loons in Washington and instead use Session/Briar to communicate privately. What Senator Timmy gonna to do, pass a law? :^) reply jmclnx 2 hours agoprevWell with GNU pg, you can have all the backdoors in networks all you want, but it will do Canada no good. But I sometimes wonder if the M/S push to Windows 11 w/tpm2 allows for a backdoor on Windows. I also think the move of Apple to the [M1-n] chips may allow the same :) But back to reality, I believe 99% of these backdoor pushes are mainly for Cell Phones. Almost no one uses a PC these days for communication. reply markhahn 32 minutes agoparentno one uses a PC for communication? why even would you apparently equate that silly msft with desktop use? that silliness aside, there are serious limits to how much access even bios/TPM/SMM compromises can provide. for instance, if I audit my network, your use of SMM to compromise my machine can be mitigated. the picture may be different if you seize my machine, of course, but we all know that most bets are off with physical access. reply bluefirebrand 2 hours agoparentprev> Almost no one uses a PC these days for communication. Probably quite a lot of the people that governments want to keep a fairly close eye on do still use PCs or laptops though reply rvba 1 hour agoparentprevTons of people use teams/zoom/other to make calls on their PCs. Also emails and chats.. reply seanw444 3 hours agoprevCanada being totalitarian? I'm shocked. reply tomComb 3 hours agoparentI know that opponents of the current gov are enjoying this line recently, but our government is so far from totalitarianism that this seems silly to me. The real problem is oligopoly, not fascism or anything like that. The government puts most of its effort into protecting friendly companies and industries from competition and even funneling taxpayer money to them. In the case of Bell & Rogers this is billions of $ a year. reply nightowl_games 3 hours agorootparentFreezing the bank accounts of the trucker protest and deploying the emergency powers _was_ a bit wild. Even our top court ruled the emergency powers weren't necessary. Opening the windsor bridge, yeah, lets arrest everyone immediately, but clearing the people out of ottawa? That ones not so clear. But no matter how you slice it, the bank account freezing was a precedent that probably shouldn't have been made. reply nahname 2 hours agorootparentOttawa was tricky because the jurisdiction belongs to the OPS, which fumbled the entire situation from beginning to end. It wasn't entirely clear if that was intentional either. The RCMP (federal) was brought in to break up the protests, but there was a lot of stone walling from the conservative provincial government. There is also a world of difference between an organized protest with a specific purpose drawing awareness to a cause and thousands of people using commercial vehicles to hold a city hostage with no purpose or agenda other than a bunch of angry people unleashing their rage on the cities populous. reply idunnoman1222 2 hours agorootparentNo agenda? How many mandated shots before you join the protest? 5..10? these people were just protesting at >1 reply burutthrow1234 3 hours agorootparentprevClearing the people out of Ottawa took far too long. The local police were cozy with the truckers and the entire downtown of a metro area with a million people was shut down for a month. People complain about left-leaning protests taking over a public park - these guys took over multiple public spaces in multiple parts of the city. About a square mile in the middle of the city. reply bluefirebrand 2 hours agorootparentIt wasn't that long ago that protests shut down Canada's entire rail system, for almost twice as long as the Trucker protest lasted. It paralyzed a lot of movement of products across our country and caused shortages in a lot of places. It was much more of an actual problem nation-wide than truckers disrupting the downtown of a single city The rail protests had international implications too So if that wasn't enough to invoke the emergency act then it's hard for me to imagine why the Truckers were reply naasking 17 minutes agorootparent> So if that wasn't enough to invoke the emergency act then it's hard for me to imagine why the Truckers were Possibly because the truckers blocked a bridge to the US, and the US didn't like that. reply poochipie 2 hours agorootparentprevBut none of that was a reason to invoke the Emergencies Act, per the courts. reply graeme 59 minutes agorootparentThe emergencies act is extremely restrictive. The criteria: >There must be an urgent, critical and temporary situation that “seriously endangers” the lives, health and safety of Canadians, and it must be so significant as to exceed the capacity or authority of the provinces to address it. A foreign funded group with heavy vehicles invaded and took over downtown Ottawa and international border crossings. The province wasn't interested in dispersing them. The Emergencies Act definition wouldn't allow you to halt a coup attempt if Ontario could handle it but chose not to. At a certain point you have to analyze things and say that if the law has a massive loophole then the law was poorly drafted. reply tracker1 1 hour agorootparentprevAlmost like some kind of Autonomous Zone or some such.. reply tharmas 2 hours agorootparentprevBut that's what makes a protest effective: it's inconvenient! Otherwise, the protest has no power to change anything. As long as its not violent or blowing things up I think \"the establishment\" should at least concede that. Case in point: look what happened in Israel when the Abraham Accords were signed, Hamas decided to go for the \"nuclear\" option. reply tensor 2 hours agorootparentHarassing people, preventing people sleeping for weeks, this is not \"inconvenience\" it's violence and intimidation against fellow citizens. I have zero sympathy or tolerance for violent occupations that force people out of their home, nor their supporters who try to pretend these things didn't happen. reply whatwhaaaaat 2 hours agorootparentprevYes people complain about “left leaning protests”. People complain about all sorts of protests. I can’t recall a single protest that wasn’t complained about. Exactly when did the left leaning protestors have their bank accounts frozen? Exactly when did the left leaning protests get broken up. All I remember is canadas stupid government supporting the left leaning protests. In the states I remember fancy Nancy wearing an African shawl kneeling in the capital. This sort of stuff is too obvious not to see. Good luck. reply barbazoo 1 hour agorootparentprev> Freezing the bank accounts of the trucker protest Just putting this into context: > Isabelle Jacques, assistant deputy minister of finance, told a committee of MPs that up to 210 bank accounts holding about $7.8 million were frozen under the financial measures contained in the Emergencies Act. > She also said the fact that more than 200 bank accounts were frozen did not necessarily mean that more than 200 people lost access to their funds. Jacques said that individuals may have held more than one account affected by the measures. https://www.cbc.ca/news/politics/emergency-bank-measures-fin... reply richardlblair 2 hours agorootparentprevThere are a lot of problems with making this argument, though. Ultimately our government lacks the necessary powers. Remember, those people travelled to Ottawa with the stated mission of overthrowing the Government. They also used their horns in a densely populated area, which an ENT doctor confirmed exposed the citizens of Downtown Ottawa to volumes that can damage the inner ear. This is without taking into consideration those with disabilities, like Autism, which can make such sensations exceptionally difficult. Then things get super messy when you start to look at how the province deals with indigenous populations, their protests, versus a group of white nationalists attempting to overthrow the Government. The fact the emergency powers were used, to me, are a symptom of a broken system. Either way, opposing political powers are jumping all over the opportunity to leverage the situation for their own gain. I'm so sick of politics. They are all dishonest. No matter what, we lose. reply naasking 15 minutes agorootparent> Remember, those people travelled to Ottawa with the stated mission of overthrowing the Government. No. > versus a group of white nationalists attempting to overthrow the Government. Also no, not white nationalists. reply canadiantim 3 hours agorootparentprevOn the plus side, now the conservatives can use emergency powers to deal with protests too. The cat's out of the bag, and people with left-leaning politics who were okay with the powers being applied to the trucker protest, I'm sure we'll find they're all of the sudden not so okay when it's applied to a protest they favour. reply AlexandrB 3 hours agorootparentI think the truckers were idiots and that their protest made no sense and probably made life for the average Ottawa resident very annoying at the time. I also think that freezing their bank accounts was huge government overreach and I'm sad that the consequence to the government for doing it have been basically non-existent. In both Canada and the US each \"side\" loves ratcheting up government power against what they perceive as their political enemies. It's going to end in tears. reply whatwhaaaaat 2 hours agorootparentnext [6 more] [flagged] sqeaky 1 hour agorootparent> force me to take an untested shot You are simply not operating in reality. It wasn't untested, you weren't forced. You don't know how to model trust and because of that you distrust experts even trustworthy experts. reply tracker1 1 hour agorootparentNot forced, meaning you may be fired and potentially unable to find work. reply sqeaky 22 minutes agorootparentSomehow the people who often take umbrage at this are also the same sorts who are free market absolutists or oppose public health care, and then we are here on a VC discussion board which leans that way frequently. Explain to me how willingness to take disease preventing treatment isn't just a feature of Whatwhaaaaat as an employee, that makes one more or less desirable on the free market? We are able free to work \"at will\" most places and any employer who will have you based on your marketability and desirability. Whatwhaaaaat could even start your own company where you mandated people not be vaccinated (and then die the first time someone sneezes). More seriously, because this is a serious topic even if Whatwhaaaaat isn't a serious person: We should all have a right to be healthy, where such things are within our power to understand and effect. Whatwhaaaaat should have a right to opt out (even if I think it is childishly stupid). The only way to make those both fit in reality is to have those who opt out of the incredibly but not quite perfectly safe and life saving vaccine in contradiction to all the evidence, is to have them opt out of activities where safety is desired by the majority. So you have a choice: opt-out of both the vaccine and some professional activities, or opt-in to both. Note how this isn't a choice that Whatwhaaaaat, as a possible unknowing carrier of covid, is willing or even capable of offering immune compromised people in a work place. This is the only sensible way to structure a society that isn't literally forcing vaccines on people like Whatwhaaaaat. reply wizzwizz4 2 hours agorootparentprevI don't think the \"untested\"* COVID-19 vaccine was given to anyone in the US, so if you \"vote democrat\" you wouldn't have been in any danger – except if you chose not to vaccinate yourself. Are you talking about something else? *: https://en.wikipedia.org/wiki/Oxford%E2%80%93AstraZeneca_COV... actually was tested: they had suspicions it caused blood clots for a few people, then they found some slightly more suspicious data. Even then, taking it was better than taking nothing for the average person – just, there were other, safer vaccines available, so nobody informed would want to take it. Its administration was halted in most countries it was approved in, once there was some evidence of harm. But the correlation's still so weak that we're not really sure it's the vaccine causing it, or even if the effect is real. Blood clot risk is still higher if you get COVID-19 than if you get this vaccine. In general, the worst thing an uncontaminated vaccine can give you is mild symptoms of the disease it protects you against. We are very, very, very cautious about such things (I'd argue, too cautious, but when I take my utilitarian-debate-club hat off, I am similarly paranoid, so I don't begrudge them overmuch). reply Amezarak 1 hour agorootparentBut of course there's different demographics; nobody is the average person. And even people that had already been infected with COVID-19 were required to get the vaccine. But it's also interesting to think about it from the perspective of immune system compartments: the vaccine is effective in preventing severe illness and death because it's injected. But people with mild to asymptomatic cases only ever \"fight it\" in their mucosal immune compartment, which doesn't share antibody recipes, so people who have only received a vaccine can still spread COVID-19, because the mucosal immune compartment is not trained by the vaccine. (Hopefully, there'll be an intranasal vaccine soon.) In general, this may also be related to your general health; the stronger your immune system is overall, the less likely you're going to develop a severe infection (barring a thousand other variables) because the virus never makes it in real numbers to your bloodstream, but if you do get a severe infection the immune reaction by itself is likely to be dangerous. At least, that's why I assume two COVID infections prior to vaccination were barely noticeable, while the vaccination itself knocked me on my ass for days and also gave me a really weird neurological episode. If I had not been required to, I would not have gotten a vaccine, since I already had a verified COVID-19 infection and recovery. So unfortunately, our policy made me pretty sick for basically zero gain, and I knew going into it there was no real upside for me (but I didn't expect the downside.) ed: it's also worth noting that \"in general\" is not very useful; in this case we're talking about vaccines leveraging new technology to deliver their payload. It's not implausible to believe that the LNPs are not safe - it took several years to identify LNPs that were not obviously toxic, and it would not be wild to imagine that years down the line we find the LNPs used in the COVID-19 mRNA vaccines are unsafe in the sense that you might be 20% more likely to develop RARE_CANCER_X 15 years from now. Great article on their development here: https://cen.acs.org/pharmaceuticals/drug-delivery/Without-li... reply tivert 2 hours agorootparentprev> ...now the conservatives can use emergency powers to deal with protests too. The cat's out of the bag, and people with left-leaning politics who were okay with the powers being applied to the trucker protest, I'm sure we'll find they're all of the sudden not so okay when it's applied to a protest they favour. That just means the conservatives can never be allowed to win elections...to protect Democracy! reply AntiEgo 2 hours agorootparentprevUnder the grits, the rcmp have already been extremely aggressive with protestors. Look at land defenders in BC--they are being removed at gunpoint, having property wantonly destroyed, and having masks pulled of their faces to apply pepper spray point blank. The clownvoy got treaded with kidskin gloves. reply AlexandrB 1 hour agorootparentThere's a case to be made that a naked display of force - at least in a democracy - is less authoritarian than quietly destroying someone's financial life. Spraying pepper spray and knocking heads creates some very unsavoury images that the government has to contend with during the next election and stokes outrage. Having a bunch of people's bank accounts frozen doesn't trigger the same visceral reaction. reply rustcleaner 2 hours agorootparentprevI am sure Canada has the progressivist ratchet like the US does: Left moves Overton Window never less than a click, Right moves it never more than a click (while looking like principled plausibly sub-malicious imbeciles in the moment). reply johnny99k 3 hours agorootparentprevHave we forgotten Covid so quickly? People involved in a legal protest had their bank accounts seized. reply richardlblair 2 hours agorootparentThey stated their goal was to overthrow the democratically elected Government. reply naasking 13 minutes agorootparentNo it wasn't. reply transcriptase 3 hours agorootparentprevYeah but they disrupted the paid long-term vacation that federal employees living downtown were enjoying, because the government had near zero WFH capability. How dare a bunch of out-of-province blue collar roughnecks protesting logic-defying mandates being put on them disrupt the white collar workers sitting in their condo getting paid to watch tiger king. reply lupusreal 2 hours agorootparentLet's not forget that honking is literally terrorism because it hurt my ears. reply tensor 2 hours agorootparentDepriving people of sleep for weeks on end is violence. I hope a few trucks honk outside your home for weeks. You'll change your tune in no time. Sleep depravation is literally a torture technique. reply lupusreal 57 minutes agorootparentHow is protest possible if disruption is terrorism? Please get a grip. (That said, thank you for demonstrating that I wasn't exaggerating.) reply HappySweeney 56 minutes agorootparentprevPutting the hurt on 50k people in an attempt to coerce the government into changing policy is terrorism. reply lupusreal 54 minutes agorootparentLighting local shops on fire? \"Firey but mostly peaceful protests\" Honking some horns? Literally terrorism. reply rustcleaner 2 hours agorootparentprevGovernments have figured out they can affect their populations like a rancher affects cattle. Elections are no longer solemn rituals but instead are processes for manufacturing consent to be governed. Only through the magick of the social contract can your neighbors collectively eat you while individually they are prevented. reply poochipie 3 hours agorootparentprev\"The government should solve every problem\" is a totalizing idea the Liberals have implemented though. We see this in the job growth numbers, for example, that show massive federal government hiring and anemic private sector growth. A market solution would have federal incentives create private sector growth to accomplish goals. And, yes: Canada badly needs some kind of antitrust regime. Perhaps the reward for monopolization of a Canadian market should be nationalization. reply Longhanks 3 hours agoparentprevNo need to worry, the EU tries the same every few weeks. https://www.patrick-breyer.de/en/let-yourself-be-monitored-e... reply markhahn 29 minutes agoparentprevThis is pointless and ill-informed cynicism. Canada is not totalitarian. Frankly, I can't imagine claiming so unless you have quite an extreme view of politics (for instance, the appropriateness of blockading downtown Ottawa). There is plenty of MAGA-like conspiratory thinking in Canada, but it's relatively new for Canada, and definitely not widely-accepted. reply chongli 2 hours agoparentprevAuthoritarian. Totalitarianism requires a large mobilization of the population under a single ideology. Putin aspires to be a totalitarian leader but even he has not managed to pull it off. He depends quite heavily on a depoliticized \"silent majority\" of Russians who are too scared/complacent to challenge his security apparatus. If Russia were a totalitarian state then you'd see that majority rushing to join the military and join the government. reply lynx23 2 hours agorootparent> Totalitarianism requires a large mobilization of the population under a single ideology. Either you forgot about COVID or you seem to have a case of Stockholm syndrom.e Those which haven't had an issue with mandates shots seem to totally ignore what a schock the sitaution was for those who didnt approve. reply AlexandrB 1 hour agorootparentI don't get how any of this was a shock. A lot of vaccines are mandated when you're in the public school system. Most people in the US have gotten these \"mandated\" shots without much complaint in the past. So much of this seems like rationalization of a purely reflexive reaction to the idea that there's any kind of social responsibility. Consider the similar backlash to mask mandates. I didn't like wearing a mask, but it's not a huge imposition. Some people treated it like it was greatest injustice they'd ever experienced though. And then they went on to rationalize this emotional reaction by making up shit about masks cutting off their oxygen supply or causing brain damage, etc. All this despite the fact that wearing a mask (or even a respirator) is necessary for a big chunk of the day in many jobs ranging from construction workers to surgeons. reply lynx23 1 hour agorootparentThanks for prooving my point. You have rationalized the way the pandemic was managed in such a strong way that you seem to have lost any empathy for people other then you. Yes, we have mandatory vaccinations, but this simple fact isn't reason enough to accept any random addition to that list. Besides, everyone knows mRNA was (on that scale) a new technology. It is (IMO) totally understandable for individuals to not want to take part in an experiment on such a large scale. Just to try again and whip some empathy into you: I have been subjected to a medical experiment by a left-over nazi doctor in the 80s, and the result was that my eyesight went from 20% to 0%. This is a true story. My parents were not informed about what the doctor was going to try, and it was also explicitly against the explicit advice of another clinic not to touch that eye with any invasive treatment. Given my history, I definitely didn't aproove of being forced into another medical experiment. Social responsibility be damned! reply AlexandrB 56 minutes agorootparentAre you aware of the testing they did before releasing the vaccine? It's not like they cooked it up in the lab on Monday and started injecting the entire population on Friday. Not to mention that it was not even available for individuals outside of high-risk groups for several months after release. I'm sorry to hear about your experiences with the medical system. It's certainly not good at treating patients with respect - even today. But consider that if the vast majority of the population was willing to get the COVID vaccine voluntarily the mandates would not be necessary. People like yourself would likely be able to opt out freely thanks to herd immunity. In a lot of ways my main feeling about COVID is disappointment. COVID was an opportunity for people to come together and make a small sacrifice to contribute to protecting the weakest among us. Instead it turned into an everyone-for-themselves shitshow. I remember visiting Hong Kong in 2008 and I was amazed to see how many people wore surgical masks in public. This was probably carry over from the SARS outbreak in 2003. To me it showed a high level of care and empathy for others that people were willing to set aside their own comfort to try to prevent spreading whatever cold of flu they were carrying. I wish we could adopt some of that attitude here in North America. reply markhahn 26 minutes agorootparentprevif you think newness of a technology, by itself, is a valid argument, you are merely anti-science, anti-rational. however, I'm most curious to hear of \"left-over\" Nazis practicing in the 80s. however, I agree that the medical establishment is an absurd archaism. reply richardlblair 2 hours agorootparentprevnext [2 more] [flagged] lynx23 1 hour agorootparentRape victims aside, what is medical autonomy to some is the right to kill unborn life for rather weak personal reasons to others. Thats how democracy works. People will have different opinions about things... Besides, I totally fail how you create that box. Not every anti-experimental-vaxer is anti abortion. Heck, most people I know who didn't approve of mandatory vaccination were always voting left. But sure, if you like to think that everyone with a different opinion then you can conveniently be put into the right-wing box, go ahead. You're being silly, though. reply TriangleEdge 1 hour agoprevI have some knowledge of the LI (lawful intercept) space. Some USA/Canada agencies/companies uses tools by JSI Telecom to do this. They do deep packet inspection and phone call recording with retention policies set by whatever law the host country has. For calls that are recorded, you cant record chats to lawyers, so a human has to listen to the call and mute it. Some countries don't allow recording, so a human has to listen in on the call live. Blah blah blah. My opinion is that democracy will die in favor of republics where govts do whatever. Seems to me were heading that way anyway. I find the theater of it tiring. reply motohagiography 1 hour agoprevThe problem with these efforts is they aren't for responding to actual crime or safety concerns, but for securing party rule and controlling dissent. Policy attempts like this indicate that given the pace of tech change vs. managerialism, Canada is basically a write off destined for decades of developing nation status the way former powers like Portugal, Greece, Argentina, and Spain were considered poor countries in the late 20th century because of ruling parties similar to the ones in Canada today. When a government switches from growth to managing dissent and capital flight, the writing is on the wall. reply poochipie 3 hours agoprevhttps://archive.is/y6d41 reply johnnyAghands 3 hours agoprevIts almost as if these policy makers don't know anything about anything. reply MathMonkeyMan 3 hours agoparentI've met people who believe that there are good guys and bad guys, that they are the good guys, and that there should be no protections for the bad guys. You can't convince them that to others, or in the future, they might be seen as the bad guys. Because that just isn't true -- they're the good guys. reply lupusreal 2 hours agorootparentTheir crystal ball for telling the future has proven that they are on \"the right side of history [which hasn't yet occurred].\" reply foresto 1 hour agoprevI wonder if it's time for democracies to constitutionally enshrine encryption into our systems of due process (or whatever the correct legal term is). It would seem to align well with the concept of checks and balances, at least. reply croes 2 hours agoprevI think this is the new part additional to existing surveillance >This could include requiring telcos to alter the 5G encryption standards that protect mobile communications to facilitate government surveillance. reply BA_and_bored 3 hours agoprevAre we supposed to believe that 5 eyes aren't doing it already? reply tharmas 2 hours agoparentYes, but they can't use it in court. This, presumably, would enable the info to be used in court. reply moose44 2 hours agoprevI don’t understand the point of attempting to pass a bill and draw attention to the subject if they already do this? Context: https://nationalpost.com/news/canada/canadas-public-health-a... reply h2odragon 3 hours agoprevCan't they just ask the NSA for their backdoors? What are allies for, after all? reply Scoundreller 2 hours agoparentIs that why my Canadian ISP used to route so much local traffic through USA? (I think it has gotten better now, but Bell used to only freely peer in USA, in Canada you had to pay for transit. Most non-big3 Canadian ISPs would route a lot of domestic traffic through Chicago and other peer points). reply rolph 3 hours agoparentprevlets flip the coin over, suppose the NSA, has been nattering at canada to get up to date, and resume fulfilment of obligations to a current standard. reply markus_zhang 3 hours agoprevAll in the name of security. Sure, go ahead, let the curtain fall. reply rustcleaner 2 hours agoprevI wish I could find some old talks by John Quaid (actor Dennis Quaid's father). I remember one entitled \"I don't need no stinking drivers license\" or something. This headline really brings those to mind. reply HeatrayEnjoyer 2 hours agoparentIs he as much of an insane clown as his kid? reply nsxwolf 2 hours agoprevI read this first as \"China\". reply sqeaky 2 hours agoparentThat is what we were told as kids, but at least some of that was deflection for crimes of our fellow citizens. reply lupusreal 2 hours agoprevFor some reason, Canada wants us to believe they don't already have this. reply sandworm101 3 hours agoprevWe have seen these a thousand times. I say bring it on. The pendulum has swung solidly into the hands of users. We have so many privacy tools to counter state surveillance these days. Any country openly conducting mass surveillance will soon see the target population wrap itself in VPNs and encrypted services. Remember when ISPs began throttling torrents? Everyone then flicked the switch and torrent traffic become encrypted. Remember the London riots, what happened to RIM shortly afterwards? Remember Lavabit? Go ahead and tap my SMS or whatsapp text messages. That's the push I need to switch the last of my friends over to Signal. reply burningChrome 2 hours agoparent>> We have so many privacy tools to counter state surveillance these days. Most of the cases you hear and read about, the gov never had to break any encryption protocols to catch people doing bad things. Pedo's on TOR were busted without it. Terrorist rings have been broken up without breaking encryption protocols. There's been rumors the NSA has broken encryption on WhatsApp and Telegram but will never admit it publicly. If you think simply having good encryption will buffer state surveillance, it won't. If the gov wants to get you they will always have a huge advantage. They never sleep and have unlimited resources. Right now, tracking a smartphone, getting the data from your provider and the profile companies like Verizon, Google and others have on you is pretty easy. They don't need to break encryption when there are so many other vectors to get at you. Just having the GPS data Google has on you is enough to give them a roadmap on your life. Unless you're willing to be a hermit like Ted Kaczynski was for years, it will be easy for any state to surveil you. And the gov still got Ted, even after all things he did to cover his tracks and living completely off the grid. reply rustcleaner 1 hour agorootparent>Most of the cases you hear and read about, the gov never had to break any encryption protocols to catch people doing bad things. If you had a god's view, but wanted to keep that classified, you'd construct a parallel path to obtaining the same outcome in court without tipping your hand to the god's view. Parallel Construction. reply sandworm101 2 hours agorootparentprevBut we are not all unibombers. Any security/privacy discussion starts with the level of threat. The average person doesn't want to hide their every detail, nor do they have to. The average person probably wants something like \"I don't want my government to passively scan what I read online\". That's an easy hurdle. Or, \"my brother is addicted to cocaine and I want to talk to him about it without AT&T reporting our conversation the police.\" Again, this is easy. But if you say \"I'm a defense contractor currently under investigation for treason and want to I pass money/information to my handler in North Korea undetected.\" THAT would be a challenge. It is probably still doable, but we should not abandon the basic needs of most people simply because we cannot promise total privacy to the most difficult cases too. (Fyi, I once talked to a defense attorney representing alleged terrorists. His clients lived overseas and the attorney was representing them in the US. That man was one of those hard privacy cases.) reply rangestransform 12 minutes agorootparentThat's why it's important that software and hardware companies ship security that's secure against nation state actors by default, so that those who actually need it can blend into the masses reply rustcleaner 1 hour agorootparentprevIf you know what you're doing it's easy. The hard part is getting from nascent to knowing what to do without inadvertently tripping wires in the process. The surveillance has a major component built around how people behave normally in normie society (specifically, communication and technology habits). reply tharmas 2 hours agorootparentprevGood post. But I believe it was his brother that recognized the hand writing. Otherwise, they probably wouldn't have got him. reply burningChrome 40 minutes agorootparentLittle know trivia about him - he was a suspect for years as the Zodiac Killer. reply rustcleaner 2 hours agoparentprevCISA can analyze flow on backbones and (I presume) the various branches of partner domestic ISP networks. It's one way they track down botnet C2 nodes. What does this mean? It means the fact you accessing a hidden service is no longer hidden from the state. While the content may be encrypted, CISA could tap on the pipe with a wrench at a known HS node and see what pipeline in the mix rings on the other end (my cute way of describing adding delays and interrupts to a stream so those show up as recognizable fingerprints to scan for elsewhere, like a cable finder/tester). Combine in some techniques on analyzing payload sizes and order, and some decent guesses of the content can be formulated. Only way I can think to defeat the analysis is to make a mixnet which asks for a GB/month target and simply transmits either data or padding uniformly in time with all nodes it peered with (a much much smaller subset than the whole network). Padding should be multi-hop so immediate neighbor nodes can't tell what is encrypted traffic and what is encrypted padding. reply poochipie 3 hours agoparentprevAccelerationism[0] FTW. 0: https://en.wikipedia.org/wiki/Accelerationism reply RegnisGnaw 3 hours agoparentprevSee China, most people are totally okay with it and VPNs are rare. reply kredd 2 hours agoparentprevThe reality is super majority of user base don’t care about data privacy or what government can see as long as it doesn’t affect their day to day lives. There was a big outrage when WhatsApp changed their privacy policy, everyone is still using it. Supermajority of people who live in China are not using any of the western social media. Or how nobody cares when there’s a breach of personal data, and it gets leaked online. Again, unless it affects them directly, it really doesn’t matter. We (people in tech and tech-adjacent fields) are in an extremely fringe bubble. And I can’t really blame them, after all who has time to think about all the second order effects of different policy changes. reply rustcleaner 1 hour agorootparent>Again, unless it affects them directly, it really doesn’t matter. It does affect them directly, doesn't anyone know why they're broke all the time (aside from inflation)? Is it possible all that harmless telemetry for harmless marketing purposes actually isn't so harmless, and Terminator is inducing you to buy products you like but really don't need more than the savings you're splurging with? No, can't be! If people woke up to how insideously manipulated they are at large... oh man! reply kredd 21 minutes agorootparentYeah, but it really doesn't matter. Majority of my friends are not in tech space, and not a single would care about it. It's similar to how I don't care about some sports team winning the championship, or Taylor Swift, or a relationship between two reality TV stars. You can call those \"superfluous interests\", but those people would say the same about our interests. And since things you've mentioned doesn't negatively affect the things they care about, it just... doesn't matter to them. I wouldn't even call it an abnormal behaviour, since a person can only think about so many things during the day. reply mikerg87 3 hours agoprevWhat could possible go wrong with this asinine idea. reply blackeyeblitzar 3 hours agoprevI hate this but isn’t this what the US is secretly doing anyways? How did outrage in America die down? reply waynenilsen 3 hours agoparentOur Encryption is still theoretically sound. There was an attempt made to do something very similar called the Clipper Chip back in 1993 but it failed. Snowden revealed massive warrantless data collection of metadata which is also very valuable. https://en.wikipedia.org/wiki/Clipper_chip reply londons_explore 3 hours agorootparentAll the big providers seem to have this odd model of \"We use E2E encryption, but we do unencrypted backups by default\". iMessage and Whatsapp are both this. Since you only need one participant in a conversation to not enable backup encryption, I would guess that law enforcement has cleartext access to over 99% of messages sent by americans. The next question is do they only have access to certain messages on request, or do they get a near real time feed. Things like this[1] suggest they had a real time feed of all messages, and I doubt they would be allowed to lose that ability. [1]: https://blog.encrypt.me/2013/11/05/ssl-added-and-removed-her... reply esafak 2 hours agoparentprevThere's always the next thing to be outraged about. This morning I heard about https://en.wikipedia.org/wiki/Project_2025 reply seanw444 3 hours agoparentprevThe spying is too far removed from the average person's life that people don't care enough. One person sitting in your house watching everything you do would be really spooky, and everyone would be upset. Countless unidentified people watching everything you do, anywhere, from anywhere, is of course not nearly as spooky (/s). I'm still of the opinion that the US proper ceased to exist after the American Civil War. Makes me sad every time I think about it. And no, I'm not including slavery. reply pc86 3 hours agorootparentWhat rights did someone have in 1790 that they didn't have in 1890? reply ImJamal 2 hours agorootparentNot who you are replying to, but there was a shift in opinion about what the US actually was and the powers the states had. One of those shifts was instead of people saying the \"United States are\" people started saying the \"United States is\". This change caused a shift away from the primacy of the 10th amendment. Instead of the US government just handling the military, foreign affairs, etc it started butting into more and more things happening within the country. Look at Wickard v Filburn for example. The 14th amendment also started to be reinterpreted to mean the incorporation of the Bill of Rights. Prior to this reinterpretation the thought was that the Bill of Rights applied to the federal government not to the state governments. The federal government was not allowed to establish a state church, for example, but the states could (and did!). The federal government couldn't ban guns but the sates could. So the states themselves lost a lot of rights and the people did as well (see my example of Wickard v Filburn). reply MeImCounting 32 minutes agorootparentYeah this was definitely an important shift. Before these changes the US wasnt really a country in the same way it is now. Antisocial elements in many states was dragging the rest of the country down and due to increasing federal power we were able to override them. Due to broader application of federal law and the bill of rights we were able to give more and more rights to the people denied them in the past. Due to broader application of federal power we were able to do away with things like state churches and gun bans. This is all good. reply poochipie 3 hours agoprevHow else will $GOVERNING_PARTY find out which of their political opponents' bank accounts they should freeze? reply canadiantim 3 hours agoparentRest assured, they already have their The Liberalist database for that. For those who don't know, that's the Liberal party's voter outreach database... also used for picking judges! It's a great system we have where $CANADAS_NATURAL_GOVERNING_PARTY picks and chooses judges based on their loyalty score in the party database. Source: https://www.cbc.ca/news/politics/liberalist-judicial-appoint... Note: There are no checks and balances regarding whether or not they are still using it. As such, the default assumption must be that they are still using it. reply nvy 2 hours agorootparentAll parties appoint partisan judges. If you think your party of choice doesn't then you need to give your head a shake. reply poochipie 2 hours agorootparentFrom the shared link: \"The Trudeau government has stopped using the Liberal Party's private database to conduct background checks on candidates for judicial appointments, federal sources say.\" This is a specific claim about the Liberals that is not refuted by suppositions about other parties, even if the supposition is likely true. reply nvy 2 hours agorootparentI'm not attempting to refute it. I'm suggesting that the idea that only the Liberals appoint partisan judges is absurd, because they're all corrupt. reply myth_drannon 3 hours agoprev [–] Makes total sense. First, they announced bringing 5000 Hamass families from Gaza (so around 50000 people). Since some of them will start terror campaigns in Canada, the government will need to monitor all communications. They create a problem and then offer a solution to \"protect\" us. reply mistermann 2 hours agoparent [–] Not to worry: I learned in school (from an expert no less) that all people are the same. reply myth_drannon 1 hour agorootparent [–] Humans are born the same, blank slate but raised differently. reply rustcleaner 1 hour agorootparent [–] False. Clean slate is fallacious. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bill C-26, a federal cybersecurity bill in Canada, grants the government powers to force telecom companies to install backdoors in encrypted networks, potentially compromising security.",
      "Critics, including University of Toronto’s Citizen Lab, argue that these measures would weaken 5G encryption and other security features, increasing vulnerability to cyber threats.",
      "Despite expert warnings, the bill has advanced without amendments, contradicting Canada's pro-encryption stance and potentially setting a dangerous precedent for other countries."
    ],
    "commentSummary": [
      "The Canadian government is seeking authority to create secret backdoors in telecom networks for surveillance, bypassing traditional legal oversight, which raises significant privacy concerns and potential for abuse by law enforcement.",
      "Critics argue this could lead to invasive monitoring akin to NSA practices, involving debates on Canada's constitution, the \"notwithstanding clause,\" and lawful intercept capabilities.",
      "The discussion includes historical examples of surveillance, such as during the trucker protests, and broader themes of government overreach, privacy, and societal responses to authority."
    ],
    "points": 221,
    "commentCount": 134,
    "retryCount": 0,
    "time": 1716993817
  },
  {
    "id": 40509572,
    "title": "Three Fundamental Laws Governing the Inevitable Complexity of Software Systems",
    "originLink": "https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html",
    "originBody": "Three Laws of Software Complexity (or: why software engineers are always grumpy) May 8, 2024 I posit that most software engineers (particularly those working on infrastructural systems) are destined to wallow in unnecessary complexity due to three fundamental laws. The First Law of Software Complexity: A well-designed system will degrade into a badly designed system over time. We start with an opinionated definition: a well-designed system is one that is easy to change over time; a badly designed system is one that is difficult to change. Let’s say that a system X is well-designed. Someone comes along and changes it – by definition, quickly and easily – to a different system X’. Now X’ either continues to be well-designed; in which case it can be quickly and easily modified again to a different system X’’; or it will enter a badly designed state and hence be difficult to modify. For example, consider a well-designed database that uses RocksDB behind a clean storage engine API; and someone comes along and adds a getLevelSize call to it; now the database can no longer easily be modified to work over a non-LSM storage engine. It follows that a well-designed system is an unstable, ephemeral state; whereas a badly designed system is a stable, persistent state. Accordingly, the mix of systems in the wild continuously degrades towards poor design. The second derivative of code is always negative in the wild: the rate at which code can change goes down over time. Based on this law, most engineers will work on badly designed systems because most systems turn into badly designed systems over time. The Second Law of Software Complexity: Complexity is a Moat (filled by Leaky Abstractions). Designing a good abstraction is a delicate dance between providing utility to the application while hiding detail about the implementation. When systems compete with each other for market share, delicacy goes out the window and designers often give the application everything it wants. This has the dual effect of increasing market share by attracting application developers; while simultaneously making it difficult for competing systems to substitute different implementations under the hood. Some of the most successful systems on the planet have APIs that are nearly impossible to implement in any other way (ZooKeeper’s stronger-than-linearizable consistency and TCP/IP-based ephemeral node semantics come to mind; as does Kafka’s idempotent produce semantics). Based on this law, most engineers will work on badly designed systems because most successful/popular systems are badly designed systems. The Third Law of Software Complexity: There is no fundamental upper limit on Software Complexity. In real-world systems that are built by large groups of people over time, complexity is limited only by human creativity. The shape of a system is determined by the abilities, philosophies, and idiosyncrasies of dozens of developers, each working within a complex set of real and perceived incentives. For example, why does this replicated database use its own gossip layer to detect failures instead of relying on Kubernetes? Maybe Alice the TL and Bob the developer agreed that gossip-based failure detection was the way to go; but once Bob wrote the code, Alice realized that it was the wrong approach in a containerized environment; but Charlie the manager had already written the promo docs for Bob and Alice didn’t want to take the political risk of blocking the PR. Or maybe the system was initially designed by Bob for a non-containerized environment where gossip actually was a good choice. Or maybe Bob’s PhD was on gossip-based protocols. Maybe Alice then split membership and leader election into different layers to avoid antagonizing Bob and Charlie, which is why your system now has two layers with interesting interactions. Each existing system is a DoS attack on you by dozens of people you may not even know; a booby-trapped palace of ticking complexity time-bombs planted years ahead of your involvement. Based on this law, engineers that work on badly designed systems will particularly suffer since badly designed systems have unbounded complexity. What can we do about this state of affairs? In my career, I have taken a particular approach based on building new systems from scratch (before they succumb to the three laws), but this is a lot harder than it sounds – more on that in a different post.",
    "commentLink": "https://news.ycombinator.com/item?id=40509572",
    "commentBody": "Three Laws of Software Complexity (maheshba.bitbucket.io)206 points by r4um 11 hours agohidepastfavorite112 comments AllegedAlec 10 hours ago> In my career, I have taken a particular approach based on building new systems from scratch (before they succumb to the three laws), but this is a lot harder than it sounds This seems like an infeasible solution in most if not all real world cases I've seen. Especially if you have a system with 15 years of legacy and some thousands of man-years of effort put into them. Now, the obvious \"don't let it get to that point\" is a smug IT nerd answer I often see regarding this, but this seems like the kind of green-field startup thinking that doesn't apply to 90+% of software development. We have an existing system. This needs to be maintained and extended because it's our core business. We cannot just say \"oh it's become too complex. Let's go and spend the next few years creating a new product, so we'll have a multi-year feature freeze\". The only feasible way I see to do anything even close to this is to split up the software into domain-like silos slowly and incrementally. At that point you can start considering rewriting silos as they become too complex/cumbersome/big. However, at that point you're already doing complex, lengthy and generally risky refactoring, and speaking of it being a write from scratch is very obviously not true. reply thefaux 16 minutes agoparentA lot of what you're describing sounds like the innovator's dilemma. One of the things that makes legacy systems so difficult is that everything is there for a reason, but often the reason is to satisfy a small minority of customers. It's easy to look at a component and say, gee this feature is only used by 2% of customers, we should consider dropping it. But that 2% is someone at the company's customer and they will raise hell if you get rid of it. So naturally the system gets filled with all these special cases to handle niche customer use cases none of which can ever be removed. This is when a startup comes along and targets the high value basic use cases and drops most advanced functionality. Then they start acquiring bigger and bigger customers, complexity accretes to meet their needs and then eventually the startup is the legacy company and the cycle repeats. The question as a developer is do I want to work on such a system? For me, the answer is a resounding no. If I agree to work on such a system, I will essentially be enslaved to the bad design decisions made before I joined the company. It will never be truly satisfying to work on that system. I am speaking from experience. But that is why companies pay a salary. The established company mindset is not the startup mindset is not the hobby project mindset. It's up to you to figure out what is best for you at any time and that choice may change as life circumstances change. reply pif 10 hours agoparentprevI agree with you. Too many of us developers tend to forget that the customer only looks at the features. Clean code, unit tests, rigorous processes... they are only as valuable as the rate of features they make possible. Complexity and technical debt are our problem, and the customer could not care less about how we solve it, or even whether we solve it. As long as we are struggling with an old piece of sh*t, that's good for us: it means the product is selling and the effort to maintain it still makes sense! Selling without complexity and technical debt would be much better, I think we all agree on this, but it's a receipt whose success I have never personally witnessed. reply makingstuffs 7 hours agorootparentWhile it is hard to generalise to an absolute I do largely agree with this sentiment. The amount of times I have advised clients to not use something like Wordpress to just end up having to use a page builder like Divi hurts my soul. At the end of the day the majority don’t care about things like carrying bloat/legacy code, rigorous testing patterns, using modern tech stacks or typesafe codebases. They simply want you to “make thing go brr”. I can advise until I am blue in the face but the reality is that at least 90% of all my clients want the quickest and cheapest option, resulting in me barely even scratching the surface of my technical abilities. I guess the main thing from a business perspective is that I’m getting paid but, at the same time, ouch, my feels. reply gwd 4 hours agorootparent> I can advise until I am blue in the face but the reality is that at least 90% of all my clients want the quickest and cheapest option, resulting in me barely even scratching the surface of my technical abilities. I think part of the problem here is the \"market for lemons\" thing: The client can't tell the difference between the short-term-cheap-long-term-expensive option and the short-term-expensive-long-term-cheap option, so can't trust that the expensive option will actually save them money in the long term, rather than being a short-term-expensive-long-term-even-more-expensive option. Consider getting quotes to re-plaster your house. One builder quotes you £2000, another £4000. Now, is the first builder giving you a fair price and the second builder charging you extra because you don't know what a fair price is? Or is the first builder a \"cowboy\" who's going to do a terrible job you're going to regret, and the second a craftsman who's going to do an excellent job you'll be happy you went with? Maybe you happen to know enough, but that's not where I was when we were renovating our house. And consider that the client isn't sure they'll even need a website in 3 years; maybe this new venture will crash and burn well before then. Then we'll be doubly glad they didn't invest in a website with the equivalent of a 10-year guarantee. reply bluGill 5 hours agorootparentprev> I can advise until I am blue in the face but the reality is that at least 90% of all my clients want the quickest and cheapest option, resulting in me barely even scratching the surface of my technical abilities. Until more client gets burned with a cheap option that becomes expensive to maintain they won't care. Many clients (across the whole industry, I don't know your clients which could be very different from average) will not get burned as most problems will never get that complex. However most clients have a lot of small problems that are quick to solve meaning that most developers spend their time on the small minority of clients that have complex problems where this matters. reply abirch 7 hours agorootparentprevI agree with you though I'd state the cheapest upfront option. They tend to cost more in the long run. See Terry Pratchett's boot theory: https://en.m.wikipedia.org/wiki/Boots_theory reply datadrivenangel 3 hours agorootparentThe problem with this theory is that the $50 boot manufacturers sell out to private equity when the founder wants to retire and then the PE firm jacks up the price to $75 and drops the quality below the $10 cardboard boots... so you're out even more money to have wet feet. reply resonious 9 hours agorootparentprevCustomers care a lot about defects, and I've seen defects increase dramatically due to complexity and technical debt. reply kunley 9 hours agorootparentprev\"customer could not care less\". This perspective is too narrow, or even a fallacy, often repeated to justify abandoning some good practices. Oh yeah customer cares. If I leave my car in a workshop, I care whether mechanics have one big mess there or not, I am looking for signs of a good routine, clever process, some smart choices they made for themselves. If they did a fix for me but have a mess, I will never go back to them. Most of customers do such choices. reply jagged-chisel 8 hours agorootparentIn software, all that is hidden from the end customer. How do you look for the smart choices in code made by the team who implemented any of the software you download and install? reply kunley 8 hours agorootparentOh believe me, I use a lot of corporate software where the flaws in development are obvious, without knowing any of the people involved reply karatinversion 6 hours agorootparentDoesn’t the fact you do use it mean the customer (the one who chooses the vendor) did not care, though? reply axus 3 hours agorootparentIf you're in one place for more than a few years, you become the person making these choices, and you don't forget. reply kunley 6 hours agorootparentprevThat's obviously different because at the corp level there are politics involved in choosing one vendor over another, but at the same time wheverer I'm involved in the decision process I care to avoid these products as hell. reply Supermancho 6 hours agorootparentprevChoices of vendor are not binary. There are tradeoffs between available solutions in software. Software Quality is not a linear gradient. If your solution is the best compromise, it is more likely to be selected. reply FroshKiller 8 hours agorootparentprevPoor choices during development reveal themselves in many ways: poor performance, awkward workflows, mandatory upgrades, one-way data conversions, inaccurate documentation, and so on. reply lelanthran 2 hours agorootparent> Poor choices during development reveal themselves in many ways: poor performance, awkward workflows, mandatory upgrades, one-way data conversions, inaccurate documentation, and so on. Not necessarily. Some otherwise good systems might have one bug in each of those categories. And, most other poorly designed and poorly executed systems just chug along fine without the customer realising anything. reply pif 6 hours agorootparentprev> Poor choices during development reveal themselves in many ways: ... All the examples you provided miss the point. Revenues are the point; all the rest is ancillary at best. reply FroshKiller 6 hours agorootparentI'm not sure what you mean. jagged-chisel asked how we look for smart choices in the software we download and install. I gave examples of how poor choices manifest for end users, the idea being that a lack of those issues suggests smart choices. I don't see how revenue is relevant to the question. Revenue for whom? And how did my examples miss the point exactly? reply lelanthran 2 hours agorootparentprev> Oh yeah customer cares. If I leave my car in a workshop, I care whether mechanics have one big mess there or not, I am looking for signs of a good routine, clever process, some smart choices they made for themselves. If they did a fix for me but have a mess, I will never go back to them. In your car, you can tell, in software you cannot. Add in the fact that most times even cowboy-coded systems are once off and will be replaced (and not maintained) down the line, and you really cannot tell if the system was written as a huge mess just waiting to be exploited, or as a well-crafted and resilient system, because the majority of systems are in-house only and face no adverserial threats other than the employees. reply pydry 8 hours agorootparentprevWhat gets forgotten is the thing you can't see. Persistent refactoring is one of those things where the cost is clear and well known (expensive developer time) while the payoff is big, but very diffuse, very hard to explain and often gets attributed to something else - sometimes even by the developers who did it. It's not the only thing like that. Plenty of companies skimp on cost centers and fail spectacularly as a result - sometimes without even ever realizing that skimping on the relevant cost centres was the reason why they failed. reply AndyMcConachie 8 hours agorootparentRefactoring only matters if decision makers care about long term consequences and value. One thing that makes it difficult to make these kinds of decisions wisely is that no one knows how long a piece of software will live in production. If I could know for sure that a piece of software would exist for 50 years in production I could make a better case for refactoring. Likewise, if I knew for sure that a piece of software would get completely replaced in 1 year I would not bother with refactoring. Never in my career have I been able to accurately predict how long software would live in production. I have had throwaway code live for years and things I thought would last forever get replaced almost instantly. reply pydry 6 hours agorootparentRefactoring doesn't just benefit you in 50 years it can benefit within weeks. I agree that it's a waste on throwaway code, throwaway code is common and what ends up being throwaway code is hard to predict, but I don't think it's impossible to get a sense of the likelihood of the code being tossed, and that sense can be used to tweak your refactoring budget. reply Supermancho 6 hours agorootparent> Refactoring doesn't just benefit you in 50 years it can benefit within weeks. Proving the value is the hard problem. It's almost impossible to prove the value of small changes today. Product wants things to do X and they decided the value tradeoff was good, not the engineers who are tasked with making it so. reply pydry 2 hours agorootparent>Proving the value is the hard problem Or impossible, even. Thats why I just do it. If somebody wants proof that my years of experience applied in a particular way will provide a quantifiable benefit that is impossible I will just avoid doing that thing. Or more likely, move somewhere which can appreciate those non quantifiable benefits. reply shepherdjerred 1 hour agorootparent> Or more likely, move somewhere which can appreciate those non quantifiable benefits. How can you find such a place? This definitely resonates with me. There's so much value in doing things right, but it's impossible to prove. I can do things that make my team go faster, but there's no way to say that having a X% better tests resulted in us being able to release Y% more features. reply bluGill 5 hours agorootparentprev> it can benefit within weeks. But if I spend a month refactoring and only get a weeks worth a benefit before the project is scrapped it wasn't worth it. If I get a month back before the project is scrapped it wasn't worth it (I could have been working on something else instead). Unless/until we know how to quantify how much gain will be got back, and how long it will take to get that gain back and so we cannot do a proper economic analysis if it is worth it - but that is what we need. reply pydry 1 hour agorootparentRefactoring is an investment decision. One which, when it pays off, pays off in a nonobvious way. That was my original point. A response of \"but what if my investment decision doesnt pay off??\" kind of suggests you might have missed that point. That happens sometimes when you make investment decisions. You dont know how much you will make back or even if you will make back anything at all. Some people dont invest their savings because they can't stand the uncertainty of not being able to quantify the payoff but I dont. reply marcosdumay 4 hours agorootparentprevHum... If you are already refactoring, it's a very good evidence that you didn't throw the code away. reply astrobe_ 1 hour agoparentprev> This seems like an infeasible solution in most if not all real world cases I've seen. Especially if you have a system with 15 years of legacy and some thousands of man-years of effort put into them. > Now, the obvious \"don't let it get to that point\" is a smug IT nerd answer I often see regarding this, but this seems like the kind of green-field startup thinking that doesn't apply to 90+% of software development. I think that what often happens, is that the manifestation of an old system crumbling under the weight of its complexity is that a \"new kid on the block\" (startup, etc.) eventually takes over. As long as the new thing only forgoes the old cruft very few care about and add stuff many care about, there's a possible takeover. reply vesinisa 9 hours agoparentprevEven systems with 15 years of legacy and eons of manhours behind them get replaced. These projects do not always succeed but I've seen it happen. A rewrite from scratch doesn't need full parity with the old system as long as you can discover, implement and test all the critical business use cases beforehand. That last part is also the most common reason why large system replacement projects fail, go over buddget, or are not even attempted. Often the people controlling the money do not have the technical knowledge how much complexity the old system hides. The safe bet is to keep it going. reply AllegedAlec 6 hours agorootparent> Even systems with 15 years of legacy and eons of manhours behind them get replaced. These projects do not always succeed but I've seen it happen. Yes. It can happen. If you can't do it with a 99.9% succes rate you cannot make it a general business practice. > A rewrite from scratch doesn't need full parity with the old system as long as you can discover, implement and test all the critical business use cases beforehand. Beyond my general disagreement is shouldn't need full parity (man our clients would be pissed off if we cut functionality \"because it was easier to rebuild a system that was functioning quite well on your end\", and they have guns!), I don't think this takes into full account how much can be hidden in years and years of commits and code. We have systems being maintained where the team responsible goes \"look we have a million lines of SQL stored procs. We don't know what all of them do because most of them were written in the mists of time and there's no documentation, or the documentation is so obviously wrong we can ignore it entirely\". This, in spite of all handwringing about how this would never have happened if people maintained proper documentation, will happen in any legacy application. We're talking about a hundred people working side by side over decades. These things will slip through, or 'best practices' change so much that things that were a good idea then are entirely unknown now. Even something as non-intrusive as attempting to stranglevine this will take up a lot of time and effort, if it can be done correctly. reply apantel 4 hours agoparentprevThe issues always enter when a codebase has to be extended in some way that was not part of the original design. You actually have to do ‘the big refactor’ right at that point of extension such that it is as if the new requirements were known up front when the system was originally designed. Otherwise you end up with a complicated mess very quickly. reply kazinator 3 hours agoparentprevWhat seems like an infeasible solution? The article doesn't describe the author's \"particular approach\". You snipped: > [...] a lot harder than it sounds – more on that in a different post. I don't see a newer post in that blog as of now (May 29, 2024). reply AllegedAlec 2 hours agorootparent> What seems like an infeasible solution? The article doesn't describe the author's \"particular approach\". The entire idea of \"well let's rebuild this before it ever gets bad\". That only works in the one tiny niche corner of greenfield development that nearly no one works in. To say \"oh yeah just don't ever let software get complex\" is like saying \"well have you tried excising any oncogenic mutations before they cause cancer\"? reply waynesonfire 2 hours agoparentprevEntropy is a good analogy for software complexity. In that it takes more energy to decrease entropy than to increase it—is fundamental in understanding why in nature, without external intervention, systems tend to evolve towards greater disorder. As a result, a single engineer can wreck such havoc on a system that it's essentially impossible to repair. This seems to be the a key to the issue and it's a people problem. reply davedx 9 hours agoprevThese are definitely not laws but consequences of bad engineering culture. I’ve worked on well designed systems that stayed well designed. For example one I remember that was very solid: How? The team had enough support and autonomy from management to: 1) allow us to hire the right people (no secret sauce - just a mix of not too fast growth and a healthy mix of seniors and juniors) 2) not rush new features, and spend enough time on design and tech debt. It probably helped that the system was a core e-commerce platform. If it descended into chaos it could have had a material negative impact on the top line. When reading articles like this positing “laws” remember many people live in a bubble and may have only worked in dysfunctional orgs. There are tons of counterfactuals out there when the system and complexity was critical to the business. (And also tons of examples where despite that it still descended into chaos- but that isn’t a law) reply twelfthnight 4 hours agoparentMostly agree, although I think \"good\" engineering culture is so incredibly rare that it feels strange to call it \"good\" and everything else \"bad\". It's more like \"regular\" engineering culture vs \"exceptional\" culture. In my experience I think the larger any team gets the more likely the team is to hire \"regular\" engineers and the quality regresses to the mean. So it's only a small set of specialized teams with unusual luck and control over hiring that can become \"exceptional\". reply AllegedAlec 5 hours agoparentprev> bad engineering culture If 99% of projects end up in a way that's not a consequence of a bad engineering culture. reply PhilipRoman 1 hour agorootparentIt could be argued that the entire software industry lacks the \"engineering culture\" of other fields. reply finack 37 minutes agorootparentThe amount of bush-league mistakes I see because people truly don't know any better is shocking. But we've gone from a world where you had to very intimately understand the machine to do your job, to one where a six-month crash course of very specific web technology is enough to net six figures. What did we expect? reply AllegedAlec 32 minutes agorootparentprevTo call any software monkey an engineer is laughable. Engineers are generally responsible for a system catastrophically failing. In IT it's seen as a natural consequence of progression. It'll take another 3-5 generations before we have the proper body of knowledge to even have an engineering culture. Even then though I'm not sure it'll ever really improve. Even beyond the human element I feel like the incremental building approach cannot and will not lend itself to ordered systems. Unless we go back to the ecosystem of objects that Kay talked about back in the 80s we'll always create frankenmonsters, and even if we do: we just create another kind of frankenmonster. reply klysm 4 hours agoparentprevSounds like your company was drowning in money and time. reply fijiaarone 2 hours agorootparentDo you thing that was a coincidence, or do do you believe in effect and cause? reply wavemode 7 hours agoparentprevIt doesn't sound like you disagree with the thesis of this article as much as you think you do. Your argument basically boils down to \"complexity can be controlled if you spend enough time and mental effort on doing so.\" Which, I mean, is exactly the point of this article - software complexity is like entropy, it will always increase over time unless energy is spent to keep it low. Most companies have no economic incentive to spend this energy, therefore most software becomes poorly built over time. It's not because the engineers were bad or because they had bad culture, it's simply because we live in a capitalist world. reply davedx 6 hours agorootparentYeah, on reflection I disagree with the premise these are \"laws\", they're more \"tendencies\". I also don't agree complexity is necessarily a moat. Sometimes it drives customers away to simpler, less expensive solutions; it depends where the complexity is as to whether it creates real lock-in or just friction and annoyance. reply rho4 9 hours agoprev> In my career, I have taken a particular approach based on building new systems from scratch = Software consultants and free lancers. I don't like them because I am jealous that they get to do greenfield projects and make all the architectural decisions but never actually have to maintain their own creations (and therefore never really learn how to design a system for changeability and maintainability). > What can we do about this state of affairs? 1st: be aware of these laws and that keeping a 20 year old system in production is a non-trivial task and to be proud of every additional year I can keep it running. 2nd: Instead of seeing it as a 'DoS attack on myself by previous developers', I try to see it as a neverending Sudoku that challenges and stimulates and pays me every day. reply cess11 7 hours agoparent\"2nd: Instead of seeing it as a 'DoS attack on myself by previous developers', I try to see it as a neverending Sudoku that challenges and stimulates and pays me every day.\" This is how it is for me, I've had a great time with several business systems initiated by amateurs or mediocre developers that took hold and had been going for 5-10 years when I arrived. Yes, the WTF:s are everywhere, changing these systems is really hard and takes a lot of discipline and care, but every time you put something in production you'll also have made other parts of the application better, more robust and faster. To me that is really rewarding, and not even noisy, butterfingered management can stop you from littering the commit log with lovely little improvements that incrementally turns the turd into a much more stable income for them, and possibly yourself (and if not you jump jobs after a while and get the raise then). I don't care whether they appreciate my work, first I care about practicing my craft well, second I care about how it is perceived by my peers in the craft. Of course, this isn't a reason to make crappy software on purpose, but this kind of just happens when you on the cheap test an idea against a market and it flies really well and customers flow in. reply rho4 6 hours agorootparentWell said, I agree so much :) reply nadam 8 hours agoprevI think it is important to discuss the notion of accidental complexity and essential complexity here. If your organization's strength is that you have world class engineering essential complexity is your friend: a problem domain with big essential complexity is really a moat: it keeps the barrier to entry into the market high. If there were less essential complexity in the world there would be much less money in software engineering and much less software engineer jobs would exist. Case in point: markets where barrier to entry regarding technical complexity become too low degrade into a race for the bottom. (like the flood of indie games that do not make money.) On the other hand accidental complexity is not our friend: if you maintain a system with too much accidental complexity there is a great risk that a smarter competitor could create something at least as good with less resources. reply dpc_01234 45 minutes agoprevI disagree with \"a well-designed system is one that is easy to change over time\". To me this is the axis of \"generic\" vs \"specialized\". As systems get increasingly optimized (for anything: resource usage, bandwidth, latency, cost, etc.) they increasingly need to make choices that limit other potential choices. This has nothing to do with being badly or well designed. A well designed system is one that does it job well, which in part includes being able to evolve it over time (or not). This might includes staying more generic, or becoming more specialized. reply williamdclt 10 hours agoprev> a well-designed system is an unstable, ephemeral state; whereas a badly designed system is a stable, persistent state It's kind of entropy: I wouldn't say that a badly designed system is \"stable\", it is just as unstable as a well-designed system and keep evolving, but there are many more ways to be \"badly designed\" than to be \"well designed\" so without actively fighting entropy, it'll be unstable but consistently \"bad\" reply dudeinjapan 10 hours agoparentI think this is a consequence of near-term expedient decisions being taken, and not having the ability/time/confidence/courage to make major refactors when needed. At TableCheck we have a Ruby monolith app we've been working on for 11 years, and TBH it feels better/cleaner today that it did 8 years ago. Granted we haven't had a lot of personnel turnover and spend a lot of time on maintenance tasks. reply SideburnsOfDoom 7 hours agoparentprevI would not say that it's just \"entropy\" in the sense that there are far more disordered states than there are ordered ones. There are. But also in software, the article says that ordered states are \"easy to change\" and disordered ones \"difficult to modify\". So the disordered states have more \"friction\" i.e. from there it is harder to to safely move to an ordered state. But possible to step further into disorder and yet more friction. I have observed this in cases where past a certain point people give up on refactoring and just add code to workaround - they just wrap the code that does most of what they want in a special case for their specific needs. Which in turn makes it harder to understand and refactor. After a while, it's a big pile of nested special cases and workarounds. Fighting that tendency is harder. It is going uphill, against the path of least resistance. reply AnimalMuppet 5 hours agorootparent> So the disordered states have more \"friction\" i.e. from there it is harder to to safely move to an ordered state. But possible to step further into disorder and yet more friction. It's not possible to safely move further into disorder. It's not even all that safe to stay without change. I agree that there's more friction, though... reply lucideer 8 hours agoprevI have a counter-take on the first law that I've seen two examples of within my (20 year) career: > A system that inevitably degrades (to a significant degree) over time was badly architected. Most systems aren't badly architected but most systems that *succeed* are. Good architecture requires time (usually an unprofitable amount) & most successful systems prioritise velocity. In summary: the demands of profit necessitate bad system design. Of the two examples I've seen in my career: one was by a larger-than-needed/accidentally over-resourced team in a very large corp, who were operating on an undervalued background product with no real OKRs. The second was a government-funded contract (these often skew badly in the opposite direction due to corrupt tender processes but barring that there's often breathing room for quality if there's a will). reply rodolphoarruda 40 minutes agoprevI read this piece with great relief. It's easy for anyone to feel offended/frustrated when coworkers, outsourced teams or even customers twist and turn your system's original clean design, making it badly designed over time. I enjoyed reading the three laws because they make me feel part of an universal problem. Software systems are no different from physical matter: it decays. It's the damn entropy. Who of us would dare to fight against it? reply luuurker 6 hours agoprev- https://archive.is/4A53o - https://web.archive.org/web/20240529081236/https://maheshba.... reply samsquire 9 hours agoprevI understand software better from words and diagrams than reading the code. Complexity is aided by having sturdy mental models - what you intuitively understand. And to see the truth clearly. To have humility: my code is probably ugly to other people, but I understand my code faster than reading yours. I can't pretend to know that the system I build would be better than yours. Be wary of pride. reply mbivert 7 hours agoparent> Be wary of pride. It's a good habit in and on itself, but there still are objective heuristics to evaluate software quality. Simplicity for example: if to solve the exact same problem, with no (impacting) performance penalty, one solution is considerably simpler (meaning, more straightforward) than another, then there's a clear winner. The amount of automated tests is another objective way of gauging software quality. reply samsquire 7 hours agorootparentThanks for your reply. I think I am contradictory when it comes to software : I don't enjoy maintaining something that breaks all the time: dependencies, system upgrades, deployment scripts and things that aren't 100% working reliably every time. So my ideal system is to run a simple binary against a file or SQLite database and have it work reliably everytime. Not a complicated micro service architecture with lots of indirection and keep things running on network. But balancing this with my hobby of designing multithreaded software. reply mbivert 4 hours agorootparentLife would be so boring if we made everything flawless, we must find ways to spice it up whenever we feel like it's going too well. I have a friend like that: loves pure functional programming languages; day job? jack of all trades doing buses communication systems ¯\\_(ツ)_/¯ reply lelanthran 2 hours agorootparentprev> Simplicity for example: if to solve the exact same problem, with no (impacting) performance penalty, one solution is considerably simpler (meaning, more straightforward) than another, then there's a clear winner. Not so clear: some people say `foreach` on arrays is simpler than single line map/reduce/comprehensions. Others say the opposite. Some people say a monolith is simpler than microservices. Others say the opposite. Some people say Python is simpler. Others say Java is simpler. I mean, an earlier response to an earlier comment of mine on a different story was from someone who thinks ORMs are simpler than SQL. I think the opposite. Until we can get everyone to agree on what 'simple' means, it's not that useful a metric. reply mbivert 45 minutes agorootparentI should have emphasized considerably, my bad: the goal was to cover the foreach vs. map type of issues, both being essentially equivalent, and more of a matter of style. What I had in mind was things like removing 20/30 lines of literally useless code, or avoiding sophisticated OOP patterns when a few bare functions on ``struct``s are sufficient. I've saw both cases in practice (eh, I'm guilty of it myself as well): they're often the result of overthinking, or \"trying to make code reusable.\" For the micro-service vs. monolith, I don't think they are comparable as-is, with respect to complexity. Once the factual requirements are known, and once the usage of each pattern to fulfill those requirements is known, then we can compare. But before, it's kind of a \"C++ vs. Rust\" type of debate: what is the real situation? Regarding ORMs vs. SQL, I tend to agree with you: we often can't pretend ORMs are perfect (\"non-leaky abstraction\") black box: in some use-cases, it's true, but as soon as you shy away from toys, you tend to have to understand both how SQL and the ORM work. Way more work than just dealing with SQL. Same goes for dependencies in general. But they are also essentially mandatory dependencies (e.g. a TCP stack, disk driver, an HTTP lib, etc.). reply KSteffensen 10 hours agoprevFirst law implies that it is impossible to change a badly designed system into a well-designed system through incremental changes. I disagree with this, it is certainly possible to improve the state of some system without starting from scratch. reply mbivert 8 hours agoparentAgreed. For example, once you have a good grasp of the codebase, and an overview of the future requirements, you can perform low-risks, local refactorings, so as to ease implementing both current and later features/bugfixes/etc. The requirements aren't systematic though. Meaning, as a dev, you're not always, at least explicitly, allowed to get a bird-eye view, nor to act on it. reply bsza 9 hours agoparentprevI don’t think it does - it only says badly designed is a more stable state. You can roll a boulder uphill in very small steps, as long as you can also keep it from rolling back down (analogous with other devs in your team/new requirements to implement). reply pvdoom 10 hours agoparentprevI think we can look into the notion from complexity theory of attractor states. If you want to make a change, you need to shift your system enough that it moves into another state. In more normal words - the codebase will fight your changes. And that means that small incremental changes may not be enough, and you will need at least a few big leaps. reply SideburnsOfDoom 7 hours agoparentprevNot impossible, no. But it it moving uphill, in the opposite direction to the path of least resistance. reply amelius 4 hours agorootparentNot just uphill, but also through thunder and flames. reply etamponi 6 hours agoprevVery interesting article. I feel like these are more laws of culture than laws of software per-se. Said in other ways: \"It only takes a match to burn down a forest\" \"One bad apple spoils the bunch\" Keeping a system well designed requires good engineering culture (as other people have said), and a great alignment across engineering, management, sales... the whole company. In control systems, you typically handle these situations with some sort of feedback mechanism. Said another way: you need to \"feel\" the problem if you want to be able to adjust quickly enough. It'd be interesting to know if this kind of \"feedback loop\" exists for human societies / companies. Or it is just what it is: it exists, but it has a very large delay, which causes the system to eventually collapse and restart... reply Verdex 4 hours agoparent> \"It only takes a match to burn down a forest\" This one is cool to me because (as I understand it) a healthy forest experiences multiple natural minor burn events that clear out underbrush. The resulting ash help regrowth by acting as a fertilizer. However, when people with bad policy get involved, then these minor burn events are prevented until the underbrush accumulates to such an extent that a single match can burn down the entire forest. The analogy to refactoring, bad development methodology, and project failure really speaks for itself. reply 000ooo000 6 hours agoprevThis is a bizarre piece riddled with odd metaphors and attempts at sounding smarter than it is, e.g. through mathematical parlance. >Let’s say that a system X is well-designed. Someone comes along and changes it – by definition, quickly and easily – to a different system X’. Now X’ either continues to be well-designed; in which case it can be quickly and easily modified again to a different system X’’; or it will enter a badly designed state and hence be difficult to modify. ??? reply edflsafoiewq 5 hours agoparentSeems simply stated and correct to me. Nigel Tao expresses the same idea this way > Software has a Peter Principle. If a piece of code is comprehensible, someone will extend it, so they can apply it to their own problem. If it’s incomprehensible, they’ll write their own code instead. Code tends to be extended to its level of incomprehensibility. reply marcosdumay 5 hours agoparentprevOk, I'm about to go read the article yet, but this seems insightful to me. A badly designed system tends to stay badly designed, while a well designed one is free to mutate. And that's inherent. Personally, I have never thought about that. reply wesammikhail 5 hours agoparentprevThe real bizarre piece here is your comment that considers X´ a trademarked math parlance... People like you baffle me not gonna lie. Not only is the author correct about what he said, he expressed it just fine. get off your high horse. reply agentultra 6 hours agoprev> In my career, I have taken a particular approach based on building new systems from scratch This is often what I see junior programmers do. The author has some experience, much in research, and I’m curious what they practice here and how effective it has been. I don’t see poor design as inevitable myself. It can be hard to battle against the tide of developers with good intentions and wrong incentives. All too often we are pushed to accept fast and cheap over good and well done. Update: spelling/grammar. reply SKILNER 3 hours agoprevI think this was more comprehensively described by The (Eight) Laws of Software Evolution: https://en.wikipedia.org/wiki/Lehman%27s_laws_of_software_ev... This subject always reminds me of something someone said, possibly Professor Alain April, \"software is the only system where maintenance tends to degrade it.\" reply djeastm 1 hour agoparent>\"software is the only system where maintenance tends to degrade it.\" Someone hasn't met my shoddy electrician/handyman reply jonahbenton 7 hours agoprevThese \"laws\" are poorly framed. Software \"complexity\" is a function of the natural or artificial intelligences observing and altering the software system, a corollary of- with enough eyes, all bugs are shallow. The classification of \"complexity\" is a function of the observer, not the observee. reply kazinator 3 hours agoprev> When systems compete with each other for market share, delicacy goes out the window and designers often give the application everything it wants. This rings false for established systems that are locked to their APIs. The vendor of a large, complex set of APIs that large, complex applications depend on is not going to give the application users everything in a new API for fear they will migrate to another set of APIs. reply perilunar 9 hours agoprevIf these are the first three \"fundamental\" laws of software complexity, where does Gall's law fit? The zeroth law maybe? Also, the second law: \"complexity is a moat\", seems to be contradicted by \"worse is better\". reply baerrie 6 hours agoprevI think the main thing we have control over is if we are part of a green field app making damn sure it is as dead simple as possible. Im currently working on a redesign of a medium sized app and the powers that be decided they wanted feature flags, which means keeping the old and new versions in the same app, and a giant separate branch for the in progress redesign. One of these would have been sufficient because they actually don’t intend to ever look at the old designs again. Not to mention three different models for the same data in the same domain that I immediately consolidated. Also, I hate feature flags and think they are the worst bandaid for design indecision and business people incompetence ever devised reply vitiral 7 hours agoprevI liked this article. These follow from the basic law that all systems that grow or change eventually decay and die. Death is an inevitable part of life whether that be for animals, societies or even software. This is good. Rebirth brings vibrancy and you cannot have birth if you don't have death. reply pvdoom 10 hours agoprevRe: first law ... one thing I have been thinking a lot lately is just how much like gardening software is. But in gardening we are not afraid to trim the plants and put them in shape as we go. In software we end up just adding stuff on top, without regard for the overall design. There is this bias towards always adding rather than removing things, and the key to keep things in order is to remove things, to say no, etc. reply Etheryte 9 hours agoparentI don't really agree with this take. Similar to knolling [0], refactoring the code you're working on and that around it should be a natural part of every development flow. If you see a design choice that no longer makes sense, restructure. If code is unused, remove. Etc, we have plenty of powerful tools at our disposal in modern times and always cleaning things up as you go is the only way you will ever keep a code base maintainable. There will never be some magical future where you have time to clean up and refactor those thorny bits, the time is now. Similar to gardening, if you're pruning roses and you see a weed taking root, just pull it out, it's right there. You won't get all the weeds this way and sure, it would be nice to have more time to deal with them, but surely it will help a little. [0] https://youtu.be/s-CTkbHnpNQ?si=KYwllK4NJY1bjRa3 reply partomniscient 9 hours agoparentprevI think most of us go through a 'software development is like..' metaphor phase. Back in my day it was via McConnell and the PragProg guys. Jeff Atwood covered it in a blog post from over 15 years ago: https://blog.codinghorror.com/tending-your-software-garden/ reply begueradj 4 hours agorootparentThe top comment of that article is too blatant reply benfortuna 10 hours agoparentprevThis \"trimming\" is not just about features, but more generally to simplify and minimise the codebase (less code = less bugs). Such refactoring is an essential part of maintaining software, regardless of how old or bloated it may be. reply pvdoom 6 hours agorootparentYes, absolutely reply pif 10 hours agoparentprev> the key to keep things in order is to remove things As soon as you are ready to give up the income for those things you want to trim, please go on! reply fedeb95 6 hours agoprevI don't agree with the third law; complexity is bounded by failure. reply arpa 6 hours agoprevAt the root of all this is a philosophical problem that encompasses all we do: unsustainable growth. We're culturally obsessed with the concept of \"more\". More value. More money. More features. More, more, more. This is where it gets us: over the verge of ecological catastrophe. Unsustainable systems prone to breakage. Enshittification of everything. Planned obsolescence and yearly phone upgrades, natural resources be damned! If we are to survive, we need to slow down and instead of making \"more\" make \"better\". Follow Unix philosophy. Embrace \"good enough\" and learn to stop. Who am I kidding, we're doomed. reply DrBazza 1 hour agoprevSoftware complexity is directly proportional to the number of developers that have, are, or will work on the code base. reply wavemode 7 hours agoprevHN hug of death https://archive.ph/4A53o reply Stranger43 7 hours agoprevThe solution is probably going to involve dropping our dangerous utopian ideals about how complexity and deviation from perfection is problems that must be solved by any means necessary. The world is a complex place where nearly nothing fit into an simplistic vision of simplicity and virtually no other engineering discipline shy away from gradual improvements and complexity management the way the IT sector does. There is plenty of examples of real world road, water and sewage infrastructure where the system as a whole have continuity dating back centuries where every problem occurring was fixed in place without anyone ever redesigning the system by wiping and redesigning, and this is a source of pride not shame for the people working with those infrastructures. The sooner we go away from the idea that just one more redesign using X tools in just the right way width the right team will finally crate an system that don't need constant maintenance and refactoring to keep serve the needs of it's users. reply Waterluvian 7 hours agoprevAh the three laws of software complexity. > Rate limit for this resource has been exceeded … nods thoughtfully reply mipsi 7 hours agoparentThe media is the message reply e-dant 6 hours agoprevI once wrote a small piece of software which did everything for everybody in constant time with no dependencies. It was very simple. reply djeastm 1 hour agoparentI'd like to report a bug in that software reply dfgdfg34545456 9 hours agoprev\"Rate limit exceeded.\" It appears another software law has been violated. reply hnben 3 hours agoprevWhen I read the title, I was expecting to find something akin to 3 metrics of software complexity from Ousterhout's Software Design Book. the actual article was kinda disappointing. reply fijiaarone 7 hours agoprevThat hurts a little too deep. Elegant code and clean architecture are no match for the chaos of the human mind. reply bsenftner 6 hours agoprevHow's about the 1 law of software complexity: software developers are not taught how to professionally communicate, so they over talk and ignore, misinform and mislead one another into a clusterfuck of complexity, over and over again. Never dawning on their minds that better communications would solve their repeating nightmare of complex weakly composed mud balls called their work. reply monknomo 2 hours agoparentWhat's a good way to learn how to professionally communicate? reply fijiaarone 7 hours agoprevThat hurts a little too deep. Elegant code and clean architecture are no match for the chaos of the human mind. Note how even the author thinks that nonsensically complex systems like Kubernetes and Zookeeper are the best possible designs. reply bobwaycott 7 hours agoprev [–] I always find myself sitting down to read Out of the Tar Pit[0] at least a couple times per year. It has been—and continues to be—one of the most seminal texts in my career. I still remember the first time I read the following passage on complexity, and how it just turned on all the mental light bulbs: >> Essential Complexity is inherent in, and the essence of, the problem (as seen by the users). >> Accidental Complexity is all the rest — complexity with which the development team would not have to deal in the ideal world (e.g. complexity arising from performance issues and from suboptimal language and infrastructure). >> Note that the definition of essential is deliberately more strict than common usage. Specifically when we use the term essential we will mean strictly essential to the users’ problem (as opposed to — perhaps — essential to some specific, implemented, system, or even — essential to software in general). The best skill I've learned, and continued to practice and improve, is the ability to strip how we talk about problems we want to solve with software down to what's truly essential to the problem. Making a habit of doing so helps clarify the contours of the problem itself, and improves discussions around solving because the boundaries of what's truly essential become clear—and then everyone involved knows that every choice we make from that point is additional, accidental complexity we are adding to the problem ourselves. Far too often I have seen even greenfield software quickly ratchet up the overall complexity because the people making choices don't take the time to really isolate the problem from the software—but instead frame the problem within the context of languages, frameworks, architecture, infrastructure, and so on, and then just start slinging code at the problem. If you haven't yet read Into the Tar Pit, it truly changed the way I look at and think about software and problem complexity. You may find value in it, as well. [0]: https://curtclifton.net/papers/MoseleyMarks06a.pdf reply vitiral 7 hours agoparentIt's comments like this that are the reason I come to hacker news. Now what do we do about it? What I'm doing about it is http:/github.com/civboot/civboot and http:/github.com/civboot/civlua reply mdaniel 1 hour agorootparentfixed: http://github.com/civboot/civboot http://github.com/civboot/civlua (both use Unlicense) reply cmbothwell 4 hours agoparentprev [–] This rings so true. I noticed a consistent level-up in my abilities once I started to seek the essence of the problem. I ask myself: “I start with this information. The desired output is X. What is the essence of the data transformation that takes me from the input to X?” When I boil down the task to its nature as a data transformation, the solution flows from my understanding of the problem, and I’ve found that my choice of tools flows transitively from there pretty easily. The problem is “isolated” from the software as you said which makes it so much easier to reason about things. I sadly have not gotten much traction when I try and advocate for this mindset in our industry. As an aside: It reminds me of a funny point from secondary education. Did you take AP tests in high school? If you did, you might remember as I do a consistent refrain that teachers used to beat into students preparing for the tests: “Answer the question” Over and over we heard this ad nauseam until it became second nature, whether for AP English or AP Physics - and it was good advice! Because the number one mistake students make on those exams is not actually answering the question asked, which even when couched in the most wonderful prose, results in a failing mark. I think software engineering is often pretty similar. Even the best, most sophisticated tools will not produce a working solution if you don’t understand the problem. reply bobwaycott 3 hours agorootparent [–] > I sadly have not gotten much traction when I try and advocate for this mindset in our industry. Yeah, I know what you mean. It's become a bit of a primary signal for how I evaluate a company's engineering culture. I've been lucky to work with some fantastic people who really get it, and I've also struggled and suffered through working with those who do not. > Even the best, most sophisticated tools will not produce a working solution if you don’t understand the problem. I'm sure we've all seen some awful monstrosities—or created them ourselves—that we could call a technically working solution to a given problem ... but it doesn't mean anyone wants to work on it. Keeping complexity at bay requires finding the simplest solutions that isolate essential and accidental complexity. Simplicity is hard, and it requires doing this well, constantly. It is [ahem] essential to spend the time required to isolate the problem and articulate it clearly. If you can't isolate and articulate the problem without referencing your tech stack and tooling, or your explanation gets all muddy and convoluted, you haven't actually identified the essential complexity of a problem. You're still stuck in accidental complexity territory. And that's a horrible place to be designing and architecting your software from. It's also critical to note that over the lifetime of any piece of software, as new things come up—new bugs, new features, etc—you have to keep re-engaging the same process, and evaluating/reflecting on how new things fit (or don't!) within your existing architecture/design. Failing to do so is what drives toward infinite complexity and endless \"tech debt\" in poorly designed software. Well-designed software isolates and encapsulates all the accidental complexity into its own space(s), leaving open avenues to adjust and expand the software. Well-designed interfaces allow you to refactor, reshape, and grow the internals of a problem domain in isolation from its callers. This requires discipline from a software team—and its leadership—to take the time necessary to adjust and refactor as priors change. Such work should always be moving the needle toward greater team velocity and individual productivity. > Did you take AP tests in high school? Yep, sure did! I definitely remember what you're describing here. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses three fundamental laws contributing to unnecessary complexity in software engineering, particularly in infrastructural systems.",
      "**First Law**: Well-designed systems degrade into poorly designed ones over time due to continuous modifications.",
      "**Second Law**: Complexity increases as successful systems prioritize market share over good abstraction design, leading to difficult-to-modify systems.",
      "**Third Law**: There is no upper limit to software complexity, driven by the diverse abilities and philosophies of developers, resulting in intricate designs."
    ],
    "commentSummary": [
      "The discussion addresses the challenges of managing software complexity, especially in legacy systems, and the trade-offs between cost and quality, often leading to technical debt.",
      "It emphasizes the importance of incremental refactoring, maintaining a strong engineering culture, and distinguishing between essential and accidental complexity to manage software effectively.",
      "Participants highlight the necessity of continuous maintenance, the impact of poor development choices, and the role of management support in justifying refactoring efforts."
    ],
    "points": 206,
    "commentCount": 112,
    "retryCount": 0,
    "time": 1716969509
  },
  {
    "id": 40512500,
    "title": "From Startup to Sale: Michael Lynch's Journey with TinyPilot",
    "originLink": "https://mtlynch.io/i-sold-tinypilot/",
    "originBody": "I Sold TinyPilot, My First Successful Business May 29, 2024 16-minute read tinypilot My first two years as a bootstrapped founder went poorly. I could barely find any paying customers, and all of my businesses lost money. I began questioning my decision to quit my cushy Google job. In mid-2020, yet another of my businesses had flopped, and it was only kind of COVID’s fault. Desperate for a distraction, I made a little contraption that controlled my home servers through my web browser. I called it TinyPilot. The prototype of TinyPilot, which allowed me to control computers in my home remotely without installing any software I blogged about creating TinyPilot, and I immediately knew I was onto something. My post reached the #1 spot on Hacker News and several popular subreddits. I started offering pre-packaged kits so my readers could build their own TinyPilots, and they immediately sold out. With every other project, I had to beg and plead with people even to try my product. With TinyPilot, there was so much demand that I struggled for months to keep the product stocked. For the next four years, I focused full-time on building TinyPilot into a business and improving the product. I grew the company to a team of seven people and $1M in annual revenue. A month ago, I sold the company for $600k. Over the next four years, TinyPilot evolved into a more refined product. Details of the sale 🔗︎ Sale price: $598,000 (2.4x annual earnings) Broker commission: $88,900 Legal fees: $18,297 My profit from the sale: $490,803 Payment terms: Full cash payment at closing (no earnout, no seller financing) Seller obligations: 30 days of free consulting (max of 40 hours/week, 80 hours total) 45 days of paid consulting (max of 10 hours/week at $180/hr) Lifetime profit from business (including final sale): $920k over four years What am I allowed to say? 🔗︎ I specifically negotiated in the sale agreement that I could discuss the terms of the sale and the process of selling the business. I can’t say anything disparaging about TinyPilot or reveal anything about TinyPilot that would give its competitors a meaningful advantage. Part 1: Preparing to sell 🔗︎ Why sell? 🔗︎ After years of flops, I was finally earning a consistent profit, selling a product I was proud of, and working with a great team. Wasn’t that exactly what I wanted? I missed writing code. TinyPilot is a hardware business, so there were tons of moving parts beyond the software. I was the sole manager of six people on three distinct teams and managed relationships with our key vendors. I rarely had uninterrupted time for deep focus, and when I did, I felt too exhausted from juggling everything else. My wife and I also wanted to start a family. TinyPilot only occupied about 20% of my time, but it occupied 90% of my stress. I would have done a terrible job juggling founder stress with new parent stress. Who would want to buy such a strange business? 🔗︎ TinyPilot fell into an odd, in-between business category. It was a hardware manufacturer, a software company, and an eCommerce store. How would I find a buyer comfortable with all three? There were larger competitors selling equivalent devices to TinyPilot for twice the price. I considered approaching enterprise competitors and saying, “Give me a million dollars, and I’ll never build another TinyPilot.” TinyPilot’s enterprise competitors sell similar devices for twice the price. But I didn’t want to sell out. I’d asked customers to take a chance on me as a new, unproven hardware manufacturer. Running off with the cash would have felt like a massive betrayal to my customers and the TinyPilot team. I wanted a buyer who would keep investing in the company, not a competitor who would just axe the product or bleed it dry. FE International: The wrong broker for TinyPilot 🔗︎ In October 2022, I reached out to FE International, the only brokerage I’d ever heard of that catered to bootstrapped founders. I wasn’t ready to sell, but I wanted to understand the path to an exit. FE initially seemed interested. Then, after a few email exchanges and seeing my financials, they gave me a soft brushoff: Unfortunately, with the current set up of two main SKUs generating roughly 98% of your revenue, this would not be a good fit for most buyers. Buyers typically want to see that a business has a minimum of 10 SKUs, and that none of these SKUs generate more than 30% of revenue. At this time we would advise, in preparation for a sale to start to consider increasing your product offering. These don’t always have to be completely new products, and this could also be USB-C cables, wall plugs, ethernet cables, servers, display ports, HDMI cables etc, this would also help to increase your AOV. After FE’s rejection, I felt trapped and panicked. I had invested hundreds of thousands of dollars into software and hardware engineering to make just one product, and I was barely scraping by. According to FE, I had no chance of selling unless I did ten times as much as I was currently doing? If you can’t get out, get comfortable 🔗︎ I didn’t want to shut down the company and lay everyone off, but I also didn’t want to carry the stress of running TinyPilot for the rest of my life. So, I looked for ways to make the business less stressful. One of the most difficult parts of TinyPilot was hardware revisions. We were always redesigning TinyPilot’s hardware to make improvements, but that meant constantly finding new suppliers and rethinking our manufacturing pipeline. In 2023, I decided to keep the design we had and stop fiddling with the hardware. The other source of complexity was TinyPilot’s office. We were still doing everything in-house: managing inventory, assembling devices, and fulfilling orders. I worked with TinyPilot’s in-person team to migrate the office’s core functions to external vendors. It was a major challenge to outsource so many delicate processes, but it eliminated an enormous amount of management overhead and stress. The happy side-effect of making TinyPilot easier to manage was that it also made the company more attractive to potential buyers. When I stopped pouring $100k/year into hardware improvements, the company became substantially more profitable. And without an office and custom in-house manufacturing, a prospective owner could run TinyPilot from anywhere in the world. Part 2: Starting the sales process 🔗︎ The strategic acquirer 🔗︎ With the company in stronger shape, I decided to restart my search for a buyer. Going through a broker didn’t work, so I began contacting buyers on my own. In his book The Art of Selling Your Business, John Warrilow encourages founders to seek acquisitions from “strategic buyers,” companies that could use your business as part of their growth strategy. For example, if you’re a salsa company that consistently makes $100k/year, a typical buyer might acquire you for $300k. But a buyer who already manufactures tortilla chips would see obvious synergy between the two businesses, so your salsa company would be worth $400k-600k to them. I emailed the CEOs of five companies that complemented TinyPilot in some way. Most ignored me or gave polite brushoffs, but one company showed immediate interest. I’ll call them ServerCo. ServerCo was an attractive buyer. They were bootstrapped as well, they seemed culturally aligned with TinyPilot, and we sold complementary products to similar customers. Having never participated in an acquisition before, they were cautious but enthusiastic about buying TinyPilot. ServerCo would email me a list of detailed questions about TinyPilot’s finances and risks, I’d answer in a day or two, and then there’d be weeks of silence. Finally, they’d respond with a new round of questions, and we’d start the cycle again. After four months of intermittent discussions, ServerCo finally presented me with an offer: $150k cash $100k employment contract for 12 months of full-time work 25% of TinyPilot’s profit the first year after closing 10% of TinyPilot’s profit the second year after closing They didn’t intend it to be an insultingly bad offer, but it was a pretty bad offer. eCommerce companies typically sell for 2.5-3.5x earnings. The cash portiton of ServerCo’s offer was 0.9x TinyPilot’s earnings. As for the salary, $100k/year is roughly what a software developer makes fresh out of college in the US. And that’s without a 12-month commitment. I politely told ServerCo we were too far apart on price to continue negotiating, but we both agreed to keep the door open in case things changed. Attending Microconf and meeting Quiet Light Brokerage 🔗︎ In 2023, I attended Microconf, a small conference for bootstrapped founders. I hoped that to either find a potential buyer there or at least get advice from other founders about what to do with TinyPilot. One of the sponsors of the conference was a brokerage I’d never heard of, Quiet Light. They piqued my interest because not only did they cater to bootstrapped founders, they worked with a lot of eCommerce companies. At the event, I spoke with Chris Guthrie, an advisor at Quiet Light. He seemed optimistic about selling TinyPilot, so after the conference, he began working with me on a sales package. It was a set of documents and financial reports to show prospective TinyPilot buyers. It included a profit and loss statement for the past two years, a detailed questionnaire about the company, and a brief video interview with me. Chris recommened presenting TinyPilot mainly as an eCommerce business with an asking price of around 3x the last twelve months of earnings. At the time, earnings were $208k, so we agreed to list at $599k, roughly 2.9x earnings. TinyPilot’s listing card on Quiet Light’s website For the first two months, things looked bleak. Chris received a handful of inquiries, but they were from buyers who either wanted me to stay on as a co-founder or wanted me to finance the majority of the purchase. Serious buyers finally appear 🔗︎ Finally, in January, two attractive buyers appeared around the same time. The first buyer was Scott, who worked a corporate job in media production but had grown disilussioned with big company culture, much like I had. He’d read my public retrospectives about building TinyPilot and saw potential to bring the product to a broader customer base. The other offer was from a pair of founders. They were initially TinyPilot customers and had reached out to me about building a managed services company on top of the product. When I told them I was selling the company, they were interested in buying. Soliciting LOIs 🔗︎ The sales process officially starts with the letter of intent (LOI). The LOI lays out the high-level details of the sale, the most important being the purchase price. Crucially, the LOI isn’t binding. The document that really matters is the asset purchase agreement (APA), which you sign when the deal closes. But the LOI officially kicks off due diligence and the drafting of the APA. When we started LOI discussions, I was in an excellent negotiation position. I had two serious buyers competing against each other. Since listing on Quiet Light, TinyPilot’s annual earnings had increased by $10k, and we received pre-qualification for an SBA loan, which meant buyers who didn’t have $599k in cash could now get a government-backed loan to buy the business. Chris told the two prospective buyers that we were planning to re-launch on Quiet Light at $625k but that I’d honor the original price if they made an offer within the next two weeks. Price negotiations 🔗︎ Scott made the first formal offer, but it was for $500k, a steep $99k drop from my asking price. At that point, I had several attractive alternatives, so I declined. We awaited an offer from the founder duo, who had sounded eager to move forward. Two days later, they backed out without making an offer at all. Uh oh. Did I blow the deal? What if $500k was the best I was going to get, and I just rejected it? I still had the option of re-launching on Quiet Light, but seeing both buyers reject the asking price shook my confidence. Fortunately, the next day, Scott sent a new LOI for my $599k asking price, and I accepted. It was great to bump the price by $99k, but that was the last point in the process that felt like I was negotiating from a position of strength. Part 3: Closing 🔗︎ Due diligence makes me weaker by the day 🔗︎ One of the biggest surprises in this process was how much closing time matters. Chris from Quiet Light had recommended selling, if at all possible, to a buyer with cash on hand rather than someone who needs a loan. When the buyer finances the purchase with a bank loan, due diligence takes longer, and there are more decision-makers who can kill the deal. At the time, I thought, “Faster would be better, but I’m a patient person. What’s an extra two months?” I quickly learned that a slower closing isn’t about a few months of patience — it’s about how much additional risk and work the seller absorbs with each passing week of due diligence. When you sell a house, the buyer has to put down a deposit of 1-5% to hold their claim on the house. If financing falls through or the buyer changes their mind, the seller keeps the money as compensation for the time they lost. When you sell a business at TinyPilot’s scale, there’s no deposit. You can invest hundreds of hours into preparing reports for due diligence, reveal all your confidential business secrets, and spend thousands of dollars negotiating legal documents and still walk away with nothing if the buyer backs out. As due diligence stretched on, my negotiating position became markedly weaker. Before signing the LOI, I could easily move on to the next buyer. By month two of due diligence, walking away from the deal meant restarting this costly and time-consuming process from zero. I’d also risk TinyPilot’s sales slipping after so many months being distracted from the business. Closing week 🔗︎ By April, we’d been in due diligence for what felt like a year but was actually just three months. Finally, on April 3rd, Scott’s bank approved the deal. They recommended a closing date of Friday, April 12th. That final week was the longest week of my life. I didn’t know what to do with myself. The only thing I could find motivation for was ruminating about all the things that might go wrong. What if the buyer got cold feet? What if Google announced an identical product and gave it away for free? What if our manufacturer spontaneously went out of business? It felt like I was on my way to my retirement party, but there was a 5% chance that when I got there, my boss would say, “Gotcha! You’re not really retiring. Now, work extra hard to make up for all the time you wasted preparing to leave.” On closing day, I couldn’t focus on anything at all. I woke up at 4 AM and couldn’t fall back to sleep. I couldn’t do anything that required even basic thinking, and I couldn’t relax enough to watch TV, so I started disassembling some old TinyPilot devices while checking my email every 90 seconds. Finally, at 2 PM, I received the email I’d been waiting for all day. The escrow company confirmed that they had the money ready to wire, so I signed the closing documents. TinyPilot was no longer my company. Part 4: After the sale 🔗︎ The first thing I did after I got the money was eat dessert. My wife and I were at dinner the night of the closing, and the email confirmation of the wire transfer arrived right before the server brought over our desserts. The payment is sale price + cost of inventory - broker’s fee. Over the next 48 hours, I had celebratory meals with friends and family in different parts of Massachusetts, during which I ate the following desserts (in order): Chocolate tort and vanilla ice cream Oreo cheesecake Chocolate lava cake and vanilla ice cream Chocolate caramel cheesecake Crème brûlée Pizookie Trio (Strawberry Shortcake, Sugar Cookie, Salted Caramel) Did I feel relief? 🔗︎ When I talked to friends about the sale, the most common question was whether I felt relieved to be done. For the first few weeks, I still felt anxious. Consciously, I knew that the deal had closed, but my body was still stuck in high-alert mode from months of urgent due diligence requests. I felt a bit more relaxed each week and probably felt Officially Relaxed™ by week three. By that point, I’d transferred all of TinyPilot’s accounts to Scott, and he was comfortable taking the reins. I felt like the company was in good hands. Do I feel a loss of identity? 🔗︎ I’ve heard other founders say they struggled with a loss of identity after they sold their business. Others say it feels like they’ve given up their baby. I didn’t feel a change in identity or a sense of deep loss. I always ran TinyPilot like a modest small business rather than a world-changing startup. I’m proud of TinyPilot and put a lot of care into the company, but it was never a blood, sweat, and tears thing for me. Timeline 🔗︎ Oct. 3, 2023 - I sign an engagement letter with Quiet Light. Oct. 17, 2023 - Quiet Light lists TinyPilot on their website. Dec. 15, 2023 - I have my first conversation with Scott. Jan. 16, 2023 - I receive the first LOI. Jan. 23, 2024 - I sign the LOI with target close date of April 16. Feb. 23, 2024 - I get the first draft of the APA. March 7th, 2024 - Lender approves the loan. March 20th, 2024 - Scott and I finalize the APA. March 25th, 2024 - Lender finishes legal review and submits loan package to SBA. April 3rd, 2024 - Lender notifies buyer of SBA approval and suggests a closing date of April 12th. April 12th, 2024 - We sign final legal agreements, and I receive payment. What’s next? 🔗︎ My wife and I are expecting our first child in August, so that’s been the main thing I’m preparing for. I’m trying to keep plans loose until I see what my life is like with a baby. In the short term, I’m looking for simple projects that I can step away from abruptly when the baby arrives. Beyond that, I’d like to find a way to build a virtuous cycle between my blog and my business. I’d love to write about what interests me, then attract cusomers to my product through my writing and fund my writing from the business. If you’re a reader of my blog, let me know what you’re interested in seeing me do next, and maybe I’ll do it: What should Michael do next? As for TinyPilot, Scott plans to keep improving the product and bring it to a wider audience. Everyone on the team received offers to stay on, and they all accepted. The company will continue to publish updates on TinyPilot’s blog, and Scott is continuing my tradition of blogging about TinyPilot’s behind-the-scenes strategy. I've sold TinyPilot, my first successful business as a bootstrapped founder. I grew it from $0 to $1M/yr in revenue in four years, and I'm incredibly proud of the company and product, but it felt like the right time for me to move on. https://t.co/iLd53Cs58o — Michael Lynch (@deliberatecoder) May 29, 2024 Original illustrations by Piotr Letachowicz. Thanks to other founders who shared their acquisition stories, especially Josh Pigford, Kareem Mayan, and Laura Roeder. Be the first to know when I post cool stuff Subscribe to get my latest posts by email. Only blog posts All posts (monthly retrospectives, book reports, etc.) Share on Twitter Facebook LinkedIn Discuss on Hacker News",
    "commentLink": "https://news.ycombinator.com/item?id=40512500",
    "commentBody": "I sold TinyPilot, my first successful business (mtlynch.io)199 points by mtlynch 4 hours agohidepastfavorite52 comments makk 15 minutes ago“I immediately knew I was onto something.” Every successful bootstrapper who I know personally says this. The ultimate success didn’t happen instantly but the product/market fit was obvious on day one. And they didn’t iterate their way to that point. They walked away from whatever they were doing before, restarted with a blank sheet a paper, and the new thing immediately resonated. reply flawn 1 minute agoparentWatch out for survivorship bias though, everybody might think that but a lot more still fail. reply alberth 36 minutes agoprevBroker commission: $88,900 Legal fees: $18,297 This equates to ~18% of total sale price. Most people don't realize how much get eaten up in deal/closing costs. Congrats to him for the successful exit. Reading his blog post over the years should be eye opening to anyone just how hard starting/running a business is. reply ignoramous 6 minutes agoparent> how hard starting/running a business is That it is, but here Michael is explicit that most of the pain [0] was from doing hardware, software, and e-commerce all at once. Surely, there are other relatively easier businesses in tech? [0] Reminds me of Avery Pennarun's A profitable, growing, useful, legal, well-loved... failure (2012), https://news.ycombinator.com/item?id=3754531 reply xyst 30 minutes agoparentprevA broker is just a middleman between the seller and buyer. What’s the value add for sales like this? reply robszumski 12 minutes agorootparentThe broker was advising him on price point, strategy and fielding the interested parties for further discussion. Pretty important for this type of transaction. reply not-my-account 9 minutes agorootparentHow much of this can be learned by reading a couple books? I wonder how much higher profit he actually made compared to if one could self teach these skills. reply ativzzz 1 minute agorootparentI imagine the broker he used is fairly experienced and well compensated, so he'd have to learn a totally different profession from the ground up without any mentors or experienced people helping him, on top of continuing to run the business, which you can easily argue is worth $90k talldatethrow 7 minutes agorootparentprevIf we trust the founder is smart enough to build a business worth x, he's smart enough to decide a fair commission for selling it. reply xyst 32 minutes agoprevWild. I vaguely remember this founder spending an obscene amount of money on some boutique firm to give homepage a small update. Seems he exited the Google grind about 6 years ago. I guess salaries were between $180-250K during that time frame. Google grinder for 6 years: $1,080,000-$1,500,000 Entrepreneur: “$920k over four years (with sale)”, but doesn’t include the 2 bombs he had prior to successful exit. (None of these figures taken into account taxes or benefits) Seems like he took an L, but in the end at least he didn’t end up in the salt mines. The education of learning as you go is truly underrated though. reply shooker435 15 minutes agoparentThis mindset assumes that the only measure of success is monetary. If he left Google to try and get richer than staying at Google, then sure, he probably lost. However, he kept trying again before job hunting or returning to big tech. This tells me the monetary factor was smaller than something else. You mention the underrated educational experience in your last sentence, but there's so much more than that. He was probably never worried about his autonomy, being laid off, working with (or for) people he didn't want to work with, corporate politics, or anything else corporate bureaucracy introduces. This likely freed up his brain to be more creative and actually be used to 100% of its capacity. I believe the obsession with TC in tech is highly problematic and there are a lot of talented folks optimizing for promotions via internal politics, rather than solving real problems for real people. I also wish healthcare wasn't tied to employment, but that's a post for another time. reply talldatethrow 4 minutes agorootparentHow is healthcare tied to employment? Isn't it available to buy on the open market? reply blehn 4 minutes agoparentprevWith promotions, equity, and stock price growth (+220% over the last 5 years), probably closer to 2 or 2.5M of Google income. reply nickjj 17 minutes agoprevYou know it must have been stressful when you were compelled to list your desserts in order. Now that we're almost in June, does it feel like the deal happened a million years ago? I know when stressful things happen and time passes, it always feels like it was so long ago even when it was only a month or 2 back. It was a pleasure having you on a few years ago in the Running in Production podcast: https://runninginproduction.com/podcast/105-tinypilotkvm-let... reply pyb 1 hour agoprevCongrats! Bootstrapping a HW business to good profitability and acquisition is a remarkable achievement, particularly outside of China. reply mtlynch 4 hours agoprevAuthor here. I'm happy to answer any questions about this post, the sale process, or my time running TinyPilot. reply everial 12 minutes agoparentCongrats on the upcoming little one! As someone who also had first infant late last year, consider dialing back your productivity expectations with a newborn (both because it's a wonderful time and because oh-heaven it's so much work). reply mik3y 3 hours agoparentprevLovely read, and great to see a happy ending - I remember your previous blogs here. As a sometime-bootstrapper and having failed at a previous hardware startup, I can relate to many of the emotions you narrated through. It may be too early, but my biggest curiosity is whether you think you will bootstrap something again? (In my case, after the hardware business and some time off, I found that taking a swing at a “pure software” idea was the right balance for me, after the considerable challenges and occasional joys of building physical things..) reply mtlynch 3 hours agorootparentThanks for reading! >you think you will bootstrap something again? Yes, definitely. Not hardware again because I think getting to the scale where you can use external vendors is so difficult and risky that it requires more specialized hardware expertise or VC backing. I'm going to start with educational products because I liked my brief experience with that and never had time during TinyPilot, but I'd eventually like to build a SaaS that I can grow in a calm, sustainable way. reply kohanz 3 hours agoparentprevCongratulations on building something of value and successfully selling it. It's quite the achievement and most don't get to this level. I do have to say, I was somewhat surprised by the low multiple on the valuation, but perhaps that's just what the range is for a business of this nature. We're spoiled in the world of software and recurring revenue. What about the tax implications of the sale. Have you figured out how much of the sale you'll be able to put in your pocket? reply mtlynch 2 hours agorootparentThanks! >I do have to say, I was somewhat surprised by the low multiple on the valuation, but perhaps that's just what the range is for a business of this nature. We're spoiled in the world of software and recurring revenue. Yeah, from what I've heard, SaaS businesses sell for a much higher multiple, often selling as a multiple of revenue rather than earnings. The other thing that's really reduced valuations is interest rates. When interest rates were What about the tax implications of the sale. Have you figured out how much of the sale you'll be able to put in your pocket? Still working out the exact figure with my accountant. His expectation was that I'll keep a pretty large percentage after taxes because of Section 174. I had a large amount of expenses each year in software development from overseas contractors, and with Section 174 changes that went into effect in 2022, I had to amortize them over 15 years.[0] But with the liquidation of the company, I can count those expenses immediately, and they offset the income from the sale. So Section 174 is still a bad deal for software founders, but at least when you liquidate the company, you don't have to wait out the full 15 years of amortized expenses. [0] https://blog.pragmaticengineer.com/section-174/ reply actionfromafar 50 minutes agorootparentI can only assume there must spring up an industry around liquidating software companies in some kind of shell scheme! reply runako 47 minutes agorootparentprevCongratulations! > Yeah, from what I've heard, SaaS businesses sell for a much higher multiple, often selling as a multiple of revenue rather than earnings. Adding some color as I have been through the process of selling a SaaS. Based on what you have written, at that stage of development, multiple on SDE is most common. 2.4x is on the low side for growing SaaS businesses, but this business is hardware with real COGS so the economics and buyers will be different. We also don't know the growth rate of the business, which is important in assigning a multiple. Additionally, full cash payment at closing is a reasonable ask but can lower the overall sale price. (I don't know if it did in this case.) Again, congratulations in taking this big step on your journey! reply duckmysick 1 hour agoparentprevWell done on the sale and congratulations to you and your wife. Best of luck to both of you. I have a question about this part: > I’d also risk TinyPilot’s sales slipping after so many months being distracted from the business. What was the time split between the sale process and running day-to-day operations? I know bigger companies have dedicated teams for that, but I'm curious how does it look like in smaller ones. reply scripper 3 hours agoparentprevHey there, loved the post. What do you think is next for you? Would you do it all over? Thanks for all of the content! reply mtlynch 3 hours agorootparentThanks for reading! >What do you think is next for you? Next is either an educational product or a SaaS business I can build either fully solo or with 1-2 teammates in customer support roles. >Would you do it all over? No, not knowing what I know now about how difficult it is to succeed in hardware. I'm grateful that TinyPilot worked, but there's definitely a reason why there are so few bootstrapped hardware companies. In the first few years, there were so many things that could have clobbered the business, like supply shortages, manufacturing errors, lost shipments, design mistakes. I did a lot of things to mitigate these risks, but a lot of it just came down to being lucky enough to avoid random disasters. For example, there were definitely times in the business where a critical part could have been lost in shipping, and we would have been dead in the water for months if it went missing or got delayed. As the business matured, we were able to mitigate those risks better, but I wouldn't want to go through those first two years again unless I had a huge amount of investment or co-founders with more specialized hardware/manufacturing expertise. reply xiphias2 56 minutes agoparentprevI would be interesting in reading the ,,buying process'' part of the same deal from the buyers. BTW tinypilot.com is down: https://www.isitdownrightnow.com/tinypilot.com.html reply 1-more 37 minutes agorootparenthttps://tinypilotkvm.com/ reply 2c2c 45 minutes agoparentprevdid you have a salary? reply bittwiddle 14 minutes agoprevThanks for sharing! I'm currently trying out a bootstrapped hw project myself, and have enjoyed following along with your progress. You mentioned having trouble working with vendors, was this for ex: having boards assembled? I guess I've probably gotten \"lucky\" with relatively low scale so far, but been happy with the assorted online PCBA services. reply cypherpunks01 15 minutes agoprevI must have missed this product, it seems incredibly useful, especially for providing remote access to legacy devices like NVRs, or random other gear that is a big hassle to remotely administer. reply markusw 25 minutes agoprevReally interesting read, thank you for sharing! You mentioned that building tiny pilot suddenly sparked way more interest than your other attempts. Do you have a plan for your next product? Try out different things and hope you find something that gains similar traction? Or do you have some sort of evaluation criteria for your ideas? reply akudha 1 hour agoprevWow, 15% broker fee! Didn’t know brokers charge that much reply mritchie712 57 minutes agoparentIf they bring you the buyer, that feels fair. But in this case, it seems the buyer found him thru his own content, which is wild. reply pavel_lishin 58 minutes agoprev> I wanted a buyer who would keep investing in the company, not a competitor who would just axe the product or bleed it dry. God, I hope the buyer lives up to your expectations. reply actionfromafar 52 minutes agoparentThe buyer is small, so at least they can’t let the product languish out of apathy. reply djtriptych 54 minutes agoprevKinda scary the lifetime profit is less than what a sr developer might expect at a big tech firm. I agree this was successful and assume it's rewarding in many other ways! But still... reply jpollock 49 minutes agoparentI haven't gotten that far in the post, but won't owners usually take a salary? reply alex_lav 46 minutes agoparentprevWhat's scary about it? reply simonswords82 1 hour agoprevCongratulations. I've been through the DD process and it is a seemingly infinite loop of Q & A that is so exhausting it's almost difficult to celebrate the funds finally hitting! Glad you made time for plenty of desserts. All the best to you and your pending addition to the family. reply JohnCClarke 26 minutes agoprevWell congratulations! That's awesome! reply gigel82 10 minutes agoprevThis is interesting. Once manufacturing (and other tedium) was outsourced, I'd have thought that's \"making it\". More or less \"passive income\" presuming the employees took care of everything else. If the revenue truly was 208k, you'd just need to \"hang in there\" for 2.5 years and you'd make whatever you got in the sale, then everything else coming in later would be just \"extra\". reply jcalabro 45 minutes agoprevCongrats! Extremely impressive and inspiring. I always enjoy your posts. reply cdiamand 49 minutes agoprevDigestively, how did you handle all that dessert in such a short timeframe? reply influx 1 hour agoprevDo you ever calculate your GOOG salary and multiply it by the number of years you've been bootstrapping and have any regrets? reply ksplicer 1 hour agoparentHis full compensation was probably between 300k-500k at Google, so I don't think money was what motivated him... reply prakhar897 58 minutes agoparentprevOP learned the skill of starting up, running and selling a business while taking 30% paycut (and a huge risk tbh). He now has much bigger career paths open to him than \"Senior Software Engineer\". reply ppbjj 1 hour agoprevThis was such an enjoyable read, thank you for taking us through your process. And congrats!! reply djeastm 1 hour agoprevI remember seeing your blog posts. Glad to see you ended up in the black with this business! reply Mgtyalx 54 minutes agoprevI understand wanting to move on, but... from an outsider it looks like you sold just as the company started getting big enough to be interesting. reply wcedmisten 1 hour agoprevCongrats Michael! reply jonathanyc 2 hours agoprev [–] Congratulations on the sale!! I love your blog and have really appreciated your retrospectives. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Michael Lynch created TinyPilot in mid-2020, a device for remote server control, which quickly gained popularity and grew into a business with $1M in annual revenue and a team of seven.",
      "Lynch sold TinyPilot for $600k, netting $490,803 after expenses, due to the stress of managing a hardware business and a desire to return to coding and start a family.",
      "The sale, facilitated by Quiet Light Brokerage, involved challenges such as balancing founder stress, finding a buyer, and managing due diligence; the buyer was Scott, a corporate media professional."
    ],
    "commentSummary": [
      "Michael Lynch sold his business, TinyPilot, and discussed the significant costs involved in the sale, including broker commissions and legal fees, which amounted to around 18% of the sale price.",
      "Lynch's entrepreneurial journey included transitioning from a high-paying job at Google to valuing autonomy and creativity, highlighting the educational value of entrepreneurship and critiquing the tech industry's focus on total compensation.",
      "Lynch plans to bootstrap future ventures, focusing on educational products and Software as a Service (SaaS), avoiding hardware due to its complexities and challenges."
    ],
    "points": 198,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1716993770
  },
  {
    "id": 40509399,
    "title": "Former OpenAI Board Member Reveals Reasons Behind Sam Altman's Firing and Reinstatement",
    "originLink": "https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired",
    "originBody": "OpenAI/ Artificial Intelligence/ Tech Former OpenAI board member explains why they fired Sam Altman Former OpenAI board member explains why they fired Sam Altman / Helen Toner explains last year’s OpenAI coup as the result of ‘outright lying’ that made it impossible to trust the CEO. By Richard Lawler, a senior editor following news across tech, culture, policy, and entertainment. He joined The Verge in 2021 after several years covering news at Engadget. May 29, 2024, 1:36 AM UTC Share this story Illustration: The Verge On November 17th, 2023, OpenAI’s board shocked everyone by suddenly ousting co-founder and CEO Sam Altman. He had been overseeing one of the fastest-growing app launches in history with ChatGPT, so what happened? Former board member Helen Toner is filling in blank spaces in an interview on The TED AI Show podcast, providing her perspective on the events that caused board members to stop trusting Altman as well as how he eventually returned. In her telling, once the board decided they needed to bring in a new CEO, they felt the only way to make it happen was to go behind his back. “It was very clear to all of us that as soon as Sam had any inkling that we might do something that went against him, he would pull out all the stops, do everything in his power to undermine the board, to prevent us from even getting to the point of being able to fire him,” Toner said. Toner says that one reason the board stopped trusting Altman was his failure to tell the board that he owned the OpenAI Startup Fund; another was how he gave inaccurate info about the company’s safety processes “on multiple occasions.” Additionally, Toner says she was personally targeted by the CEO after she published a research paper that angered him. “Sam started lying to other board members in order to try and push me off the board,” she says. After two executives spoke directly to the board about their own experiences with Altman, describing a toxic atmosphere at OpenAI, accusing him of “psychological abuse,” and providing evidence of Altman “lying and being manipulative in different situations,” the board finally made its move. Toner cites the launch of ChatGPT itself as an example of how the board didn’t have real oversight over the company. “When ChatGPT came out November 2022, the board was not informed in advance. We learned about ChatGPT on Twitter,” says Toner. The podcast doesn’t get into the details of what happened in the days following Altman’s firing. OpenAI rapidly shuffled through interim CEOs, employees including at least one of the board members who fired Altman pushed for his return, and OpenAI’s lead investor, Microsoft, put its support behind Altman, too. However, Toner points out three reasons she believes the pressure to restore Altman was so strong. She claims employees were presented with only two options about how things could go (ditching the board to restore Altman or seeing the company destroyed), and since people didn’t want the company to fall apart, they supported the other one. She also says many people were scared of going against Altman after watching him retaliate against others. Her last reason is Altman’s track record prior to OpenAI: I guess the last thing I would say about this is that this actually isn’t a new problem for Sam. And if you look at some of the reporting ... it’s come out that he was actually fired from his previous job at Y Combinator, which was hushed up at the time. And then at, you know, his job before that, which was his only other job in Silicon Valley, his startup Loopt, apparently the management team went to the board there twice and asked the board to fire him for what they called deceptive and chaotic behavior. If you actually look at his track record, he doesn’t exactly have a glowing trail of references. This wasn’t a problem specific to the personalities on the board, as much as he would love to portray it that way. The podcast also includes a response from current OpenAI board chair Bret Taylor: We are disappointed that Ms. Toner continues to revisit these issues. An independent committee of the board worked with the law firm Wilmer Hale, to conduct an extensive review of the events of November. The review concluded that the prior board’s decision was not based on concerns regarding product safety or security, the pace of development, OpenAI’s finances, or its statements to investors, customers, or business partners. Additionally, over 95 percent of employees, including senior leadership, asked for Sam’s reinstatement as CEO and the resignation of the prior board. Our focus remains on moving forward and pursuing OpenAI’s mission to ensure AGI benefits all of humanity. Most Popular Most Popular Google won’t comment on a potentially massive leak of its search algorithm documentation Former OpenAI board member explains why they fired Sam Altman Lego’s first Legend of Zelda set is a 2,500-piece Great Deku Tree This Lego Apple Store design submission is pitch-perfect Vivek Ramaswamy can’t even dunk on Buzzfeed right Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=40509399",
    "commentBody": "[dupe] Former OpenAI board member explains why they fired Sam Altman (theverge.com)196 points by pookieinc 11 hours agohidepastfavorite81 comments leftcenterright 10 hours agoPrior discussion with more comments and points, not on front page at the moment: https://news.ycombinator.com/item?id=40506582 reply kranke155 7 hours agoprevAll evidence points to Altman being lying and duplicitous. I would have fired him too. reply LoKSET 10 hours agoprevBoard found out about ChatGPT on Twitter? Maybe she did but I kinda doubt Ilya was in the dark. reply n2d4 9 hours agoparentIt's likely that Ilya didn't think the launch was anything notable: https://www.businessinsider.com/chatgpt-was-inaccurate-borin... reply sillysaurusx 8 hours agorootparentOne of my most valuable memories is when I dismissed ChatGPT the day it came out. I didn't bother trying it; GPTs were just autocomplete, and OpenAI had already stretched the limits of what autocomplete could do, so this ChatGPT would just be slightly better autocomplete. Much like pg dismissing Facebook as lame when it first launched, I was exponentially mistaken: https://paulgraham.com/swan.html > History tends to get rewritten by big successes, so that in retrospect it seems obvious they were going to make it big. For that reason one of my most valuable memories is how lame Facebook sounded to me when I first heard about it. A site for college students to waste time? It seemed the perfect bad idea: a site (1) for a niche market (2) with no money (3) to do something that didn't matter. > One could have described Microsoft and Apple in exactly the same terms. It's worth remembering that even the big successes often don't realize they're onto something -- you'll be less likely to dismiss the next big wave when you see it forming. reply ignoramous 8 hours agorootparent> One of my most valuable memories is when I dismissed ChatGPT the day it came out. Some were primed to do so by Meta's Galactica: https://news.ycombinator.com/item?id=33611265 reply Nullabillity 8 hours agorootparentprevCalling GPT autocomplete is an insult to autocompleters. reply woliveirajr 7 hours agorootparentprevFunny: > Thanks to Sam Altman (...) for reading drafts of this. reply pas 8 hours agorootparentprevIt is a very fancy autocomplete indeed, but it's not like you missed anything on day 1. The engineering they put around GPT to make it work as a smart translator and eloquent \"brainstormer\" and whatnot is impressive, but so far there's no killer app in sight. (The biggest bang for the buck seems to be Copilot.) reply andybak 7 hours agorootparentIt is the killer app in itself. You might be underestimating it's impact and how much usage it's getting (not always for good things, not always for bad). It's totally permeated many areas of life for people. reply infecto 6 hours agorootparentprevIt definitely is a killer app and light years ahead any competing product. Github copilot is good but different use case to me. If you meant MSFT Copilot, well that I am not sure what benefit if any exists. reply jfoster 9 hours agoparentprevInteresting point. It's either that or Ilya also didn't mention it to the board. Seems unusual whichever it was. reply artninja1988 9 hours agorootparentIlya was Part of the board, same as Sam and Greg brockman reply andy_ppp 7 hours agoprev\"We are disappointed that Ms. Toner continues to revisit these issues. An independent committee of the board worked with the law firm Wilmer Hale, to conduct an extensive review of the events of November.\" It's interesting that the review was never published and no comments from the review were mentioned. The \"summary\" here[1] only reveals a list of things they did and the least possible endorsement of Altman. \"WilmerHale found that the prior Board acted within its broad discretion to terminate Mr. Altman, but also found that his conduct did not mandate removal.\" I find it telling that they did not release the actual report. [1] https://openai.com/index/review-completed-altman-brockman-to... reply ssgodderidge 7 hours agoparent> “his conduct did not mandate removal.” Curious what “mandate” refers to here. He didn’t do anything illegal? Didn’t break bylaws? Or was it that he didn’t do anything to lose the trust? He could have done everything well within his right as the CEO, but still gotten fired for failure to build trust with the board reply ben_w 6 hours agoparentprev> I find it telling that they did not release the actual report. Without opining on the merits of the case: lawyers on the job aren't known for saying more than they have to, nor for advising their clients to do so either. reply light_hue_1 6 hours agoparentprevDon't worry. It wouldn't matter if they released the report. These law firms are charged to find nothing and say nothing. MIT agreed to have a report from a law firm after having secret dealings with Epstein. The law firm very carefully managed to avoid every issue that wasn't already known and every question people actually wanted answers to. reply andy_ppp 3 hours agorootparentIt’s like one of those logic problems isn’t it; if what you say is true (and it likely is) then why hasn’t the report been released? It likely contains information that even at the fantastic fees WilmerHale charge couldn’t be skirt around. reply Havoc 9 hours agoprev> [W]hen ChatGPT came out November 2022, the board was not informed in advance. We learned about ChatGPT on Twitter,” Jikes. Yeah I can see how a board would lose their sht. Boards are generally quite tolerant unless you keep them in the dark on strategic matters or ask them to rubber stamp stuff post fact. reply shawabawa3 9 hours agoparentis that so weird? Aren't board meetings normally once a quarter? ChatGPT may have been built in less than 1 quarter and between board meetings ChatGPT seemed to me like a fun extra product and they didn't anticipate the reaction they would get from the public or that it would completely replace their existing GPT interface reply PeterisP 9 hours agorootparentWhile board meetings normally are relatively sparse, most of board work happens between these meetings (where you effectively perform any voting rituals required to formally approve the decisions the board members made beforehand) and it is very common practice for executives to continuously keep board in the loop - arguably doing this well is one of the primary duties of a CEO. reply Havoc 8 hours agorootparentprevYeah it’s absolutely weird. The board is supposed to be the top governing body - they need sight of future plans. And if something changes in middle of quarter then at a minimum a mail or phone call as a heads up. They probably didn’t expect quite that big of a reaction sure but hard to believe they didn’t know at all that it would be important. reply sackfield 8 hours agoparentprevI would be thrilled, if I were board member I would want the organisation to succeed and ChatGPT can't be described as anything other than an unmitigated success. I wouldn't feel the need to make myself the main character of the story and act like my permission was required for innovation. But that's just me. reply kklisura 6 hours agorootparentI reckon being a board member is more than having a front row seat to a business reply sackfield 6 hours agorootparentIt is. Like I said above I would be concerned about the continuing success of the organisation according to its operating principles. Destroying the company over childish disputes would not be fulfilling that charter. I'm very glad OpenAI got the competent board they deserved after this event. reply threeseed 8 hours agorootparentprevIt is absolutely just you. Almost everyone would prefer not to have repeats of Enron, FTX etc where poor corporate governance and unethical behaviour is tolerated just because the company is making lots of money. reply sackfield 8 hours agorootparentI'm not sure OpenAI compares to Enron or FTX in terms of unethical behaviour or financial fraud. The only similarities might be, funnily enough, disfunctional boards (or in FTX's case, no board). reply threeseed 7 hours agorootparentNo one thought anything was wrong at Enron or FTX until there was. reply ben_w 6 hours agorootparentprevIf OpenAI gets as far with AI as they want to, then it is absolutely imperative that nobody there is accidentally leaning on the scales, let alone actually doing anything (even something minor) with selfish intent. Even if they're \"just another tech firm\", that's still enough for them to be another Facebook with the Cambridge Analytica and Rohingya scandals, and many people would like to make sure such things don't repeat. reply sackfield 6 hours agorootparentWe should feel great that they now have a competent board that will make sure of that. reply threeseed 6 hours agorootparentNobody should feel great about the situation at OpenAI. Especially with all of the people leaving and publicly criticising the companies trust and safety stance. reply ben_w 6 hours agorootparentprevThe models get red-teamed, do the corporate structures? reply borski 7 hours agorootparentprevYet. reply nprateem 9 hours agoprevMaybe they should have mentioned this at the time reply senectus1 10 hours agoprevseems to be fairly large amount of evidence that SA is a bit of an asshole. reply baq 6 hours agoparentHe got fired from loopt and from yc. Asshole is a wrong word. He’s dangerous. reply ZiiS 9 hours agoparentprevFor someone with his amount of power; if you are only 'a bit of an asshole' you may as well be a saint. reply dantyti 9 hours agorootparentI have to say that your comment reads like you are justifying unethical behavior from a major business figure. I mean, saying that a CEO who acts with no qualms re accountability \"a saint\" really begs the question: how does the boot taste like? reply ZiiS 8 hours agorootparentNot at all. I am saying that centralising the amount of power OpenAI has is inherently antisocial. If you have done it so the average person uses the qualifier \"a bit of\" you are extraordinarily gifted. reply ben_w 6 hours agorootparentIronically, the same reason to care about even very minor misalignment in a powerful AI. reply MaKey 8 hours agorootparentprevThat's a bad faith take which doesn't add anything to the discussion. reply moomin 8 hours agorootparentprevOn the contrary, with that amount of power “bit of an asshole” is indistinguishable from “monster”. reply thih9 7 hours agorootparentprevEither you’re fine with powerful assholes, or you suggest stripping autocratic CEOs of power; or perhaps I’m missing your point. reply ZiiS 6 hours agorootparentI am saying most extremely powerful people (CEO of OpenAI is what top 0.0001%) are assholes; qualifying it with \"a bit of\" is a win. reply thih9 7 hours agoprev> It’s come out that he was actually fired from his previous job at Y Combinator, which was hushed up at the time. What is that referring to? reply helsinkiandrew 7 hours agoparenthttps://www.washingtonpost.com/technology/2023/11/22/sam-alt... (archive) https://archive.ph/aru0B > Altman’s polarizing past hints at OpenAI board’s reason for firing him Before OpenAI, Altman was asked to leave by his mentor at the prominent start-up incubator Y Combinator, part of a pattern of clashes that some attribute to his self-serving approach reply rjbwork 7 hours agoparentprevHe used to be the president of YC for a few years. reply thih9 3 hours agorootparentThanks. Until now I thought he still holds that title. Good job with the \"hushed up at the time\" I guess. reply amelius 9 hours agoprevQuestion: has he now been definitely fired? I lost track. reply ttyyzz 9 hours agoparentIn November 2023, he was surprisingly dismissed, but confirmed in office a few days later. He has been in office ever since! The story refers to this \"surprising dismissal\". reply amelius 8 hours agorootparentOkay, that's good to know, thanks. reply ChrisArchitect 8 hours agoprev[dupe] More discussion: https://news.ycombinator.com/item?id=40506582 reply kingkawn 7 hours agoprevThat they had none of this ready to explain when they fired him makes this all feel like bullshit reply ur-whale 9 hours agoprevAnd the pile of evidence that demonstrates Altman is a high-IQ psychopath grows ever taller. reply fy20 7 hours agoparentThe Gervais principle is correct once again. reply robertlagrant 9 hours agoparentprevEvidence that the earth is flat grows ever taller as well. If you have no method for removing things that turn out to not be true, only taller will the pile grow. reply robertlagrant 7 hours agorootparentI don't normally reply for this reason, but it's fascinating. -4 score with no replies. reply parthianshotgun 7 hours agorootparentprevWhat's your basis for cutting? What's the underlying principle here? reply zabzonk 8 hours agoprevnext [2 more] [flagged] ekianjo 7 hours agoparent> Carter Burke now that you mention it, there is definitely a resemblance reply Bengalilol 8 hours agoprevnext [5 more] [flagged] insane_dreamer 8 hours agoparentHow do you instruct ChatGPT to look up the internet? reply phist_mcgee 8 hours agorootparentTell it to search for an up to date answer. reply insane_dreamer 7 hours agorootparentOK but it’s still just relying on its training data, right? Or is it now able to look up live data from the internet? (I thought it was siloed). reply 4ggr0 6 hours agorootparentChatGPT uses the internet since last September. https://news.ycombinator.com/item?id=37999172 reply amelius 9 hours agoprevMaybe Elon Musk has a nice job for him now. Would fit in perfectly with the culture. I wish this was only a bad joke. reply the_real_cher 10 hours agoprevThis seems disingenuous on her part. Almost the entire company was posting hearts on X in support of Sam. The essence if her claim is they were doing that for their stock options? Cynical take to me. reply Lewton 7 hours agoparent> The essence if her claim is they were doing that for their stock options? Wasn't that extremely obvious at the time? reply threeseed 8 hours agoparentprevShe discussed this in the podcast. Apparently, Sam has a vindictive streak and those who were critical of them were scared not to be on the wrong side of him if the situation turned in his favour. And they were right. Which is why the smart move was to keep quiet and then just leave later. Hence all of the resignations. reply the_real_cher 6 hours agorootparenthundreds of employees a voiced their support for Sam. I'm not saying you're wrong but it seems like a little bit of a stretch. reply ur-whale 9 hours agoparentprev> Almost the entire company Almost the entire company is composed of wide-eyed young AI researchers who probably were never confronted in their entire life to the kind of psychopathic predator Altman seems to be. One of the thing these type of folks excel at is winning the hearts of bright yet gullible folks. reply marcinzm 7 hours agorootparentIt's the same as all the revolutionaries and cult leaders that turned into dictators once in power. Those seeking a greater meaning to their lives get drawn to the sweet nectar of lies that tells them their life will have meaning as long as, and only if, they just keep following the leader's every wish. Except this time it's not aliens following Halley's comet but AGI. reply Cthulhu_ 9 hours agorootparentprevPlus they - in theory - have a huge vested financial interest. All the OpenAI employees, assuming they held some kind of stock, became millionaires overnight as ChatGPT took off. reply telltruth 10 hours agoprev [–] While most of the interview is boring and nothing new has been said by Toner, to me, it feels like huge political fight where sama tried to overthrow her first and then Toner went in attack mode trying to overthrow him. It's clear she was the lead instigator and accidently found Illya as sympathetic co-conspirator. Board was obviously ok and took no action when they weren't informed about release of ChatGPT. It also didn't took action when sama didn't told them about startup fund. Only after Toner's paper and sama's move, all these became important. Overall, I genuinely believe that the board needs to get out of way. They are not the founder, they are not even technical. They should do oversight for intentional and significant wrong doings but politics and brewing up secret coups is not their job. reply slg 10 hours agoparent> They should do oversight for intentional and significant wrong doings Would lying to the board not count as \"intentional and significant wrong doings\"? reply sage76 10 hours agoparentprev> they are not even technical Sama is also not technical. reply jfoster 9 hours agorootparentI've seen this mentioned a few times, but is this true? I could swear I've heard him mention that he uses ChatGPT for programming stuff. He might not be a super technical software engineer, but is he \"non-technical\" in that he can't even write some simple python or something equivalent? reply ZiiS 9 hours agorootparentHe did two years computer science at Stanford before dropping out. I don't think \"simple python\" is the benchmark. reply KptMarchewa 8 hours agorootparentSo, probably epitome of Dunning-Kruger. reply doktrin 8 hours agorootparentprev> He might not be a super technical software engineer, but is he \"non-technical\" in that he can't even write some simple python or something equivalent? 1. that's a very low bar, almost to the point of making any distinction meaningless 2. imho, \"technical\" and \"non-technical\" are context dependent, and not intrinsic human qualities. Speaking for myself : I'm a technical individual contributor on my current team, but there are plenty of domains (bleeding edge AI research likely being one of them) where my technical acumen would fall short of expectations for an IC, and hence where my most logical role would be non-technical in nature. reply jfoster 6 hours agorootparentOK, so what's the bar by which Altman would be considered \"non-technical\"? reply doktrin 5 hours agorootparentYou tell me. Did he make meaningful technical contributions to OAI? reply marcinzm 7 hours agoparentprev [–] > They are not the founder, they are not even technical OpenAI can't have it both ways. Either it's not a company owned by it's founders (as Sam claims) or it is. A board that does nothing ever is equivalent to the former. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In November 2023, OpenAI's board unexpectedly fired CEO Sam Altman, citing \"outright lying\" and manipulative behavior, which eroded trust.",
      "Specific issues included Altman's undisclosed ownership of the OpenAI Startup Fund, providing inaccurate safety information, and creating a toxic work environment.",
      "Despite these allegations, internal and external pressures, including support from employees and Microsoft, led to Altman's reinstatement, with an independent review finding no issues with product safety or company operations."
    ],
    "commentSummary": [
      "A former OpenAI board member disclosed that Sam Altman was dismissed due to dishonesty, raising questions about the board's awareness of ChatGPT's launch.",
      "The situation has sparked discussions on organizational transparency, board oversight, and ethical governance, with comparisons to corporate failures like Enron.",
      "There is skepticism about OpenAI's trust and safety practices, with employee departures and criticism of Altman's leadership, alongside debates on technical proficiency and the board's role."
    ],
    "points": 196,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1716967609
  },
  {
    "id": 40510125,
    "title": "Google Search Leak Unveils Secrets of Ranking Algorithm and 2,596 Modules",
    "originLink": "https://searchengineland.com/google-search-document-leak-ranking-442617",
    "originBody": "Search Engine Land » SEO » HUGE Google Search document leak reveals inner workings of ranking algorithm HUGE Google Search document leak reveals inner workings of ranking algorithm The documents reveal how Google Search is using, or has used, clicks, links, content, entities, Chrome data and more for ranking. Danny Goodwin on May 28, 2024 at 9:00 amReading time: 6 minutes Chat with SearchBot Chat with SearchBot Please note that your conversations will be recorded. SearchBot: I am trained with Search Engine Land content. Ask me anything! Powered by Search Engine Land (and love) Close A trove of leaked Google documents has given us an unprecedented look inside Google Search and revealed some of the most important elements Google uses to rank content. What happened. Thousands of documents, which appear to come from Google’s internal Content API Warehouse, were released March 13 on Github by an automated bot called yoshi-code-bot. These documents were shared with Rand Fishkin, SparkToro co-founder, earlier this month. Read on to discover what we’ve learned from Fishkin, as well as Michael King, iPullRank CEO, who also reviewed and analyzed the documents (and plans to provide further analysis for Search Engine Land soon). Why we care. We have been given a glimpse into how Google’s ranking algorithm may work, which is invaluable for SEOs who can understand what it all means. In 2023, we got an unprecedented look at Yandex Search ranking factors via a leak, which was one of the biggest stories of that year. This Google document leak? It will likely be one of the biggest stories in the history of SEO and Google Search. What’s inside. Here’s what we know about the internal documents, thanks to Fishkin and King: Current: The documentation indicates this information is accurate as of March. Ranking features: 2,596 modules are represented in the API documentation with 14,014 attributes. Weighting: The documents did not specify how any of the ranking features are weighted – just that they exist. Twiddlers: These are re-ranking functions that “can adjust the information retrieval score of a document or change the ranking of a document,” according to King. Demotions: Content can be demoted for a variety of reasons, such as: A link doesn’t match the target site. SERP signals indicate user dissatisfaction. Product reviews. Location. Exact match domains. Porn Change history: Google apparently keeps a copy of every version of every page it has ever indexed. Meaning, Google can “remember” every change ever made to a page. However, Google only uses the last 20 changes of a URL when analyzing links. Links matter. Shocking, I know. Link diversity and relevance remain key, the documents show. And PageRank is still very much alive within Google’s ranking features. PageRank for a website’s homepage is considered for every document. This doesn’t prove Google spokespeople have lied about links not being a “top 3 ranking factor” or links mattering less for ranking. Two things can be true at once. Again, we don’t know how any of these features are weighted. Successful clicks matter. This should not be a shocker, but if you want to rank well, you need to keep creating great content and user experiences, based on the documents. Google uses a variety of measurements, including badClicks, goodClicks, lastLongestClicks and unsquashedClicks. Also, longer documents may get truncated, while shorter content gets a score (from 0-512) based on originality. Scores are also given to Your Money Your Life content, like health and news. What does it all mean? According to King: “[Y]ou need to drive more successful clicks using a broader set of queries and earn more link diversity if you want to continue to rank. Conceptually, it makes sense because a very strong piece of content will do that. A focus on driving more qualified traffic to a better user experience will send signals to Google that your page deserves to rank.” Documents and testimony from the U.S. vs. Google antitrust trial confirmed that Google uses clicks in ranking – especially with its Navboost system, “one of the important signals” Google uses for ranking. See more from our coverage: 7 must-see Google Search ranking documents in antitrust trial exhibits How Google Search and ranking works, according to Google’s Pandu Nayak Brand matters. Fishkin’s big takeaway? Brand matters more than anything else: “If there was one universal piece of advice I had for marketers seeking to broadly improve their organic search rankings and traffic, it would be: ‘Build a notable, popular, well-recognized brand in your space, outside of Google search.'” Entities matter. Authorship lives. Google stores author information associated with content and tries to determine whether an entity is the author of the document. SiteAuthority: Google uses something called “siteAuthority”. Google told us something like this existed in 2011, after the Panda update launched, stating publicly that “low quality content on part of a site can impact a site’s ranking as a whole.” However, Google has denied having a website authority score in the years since then. Chrome data. A module called ChromeInTotal indicates that Google uses data from its Chrome browser for ranking. Whitelists. A couple of modules indicate Google whitelist certain domains related to elections and COVID – isElectionAuthority and isCovidLocalAuthority. Though we’ve long known Google (and Bing) have “exception lists” when “specific algorithms inadvertently impact websites.” Small sites. Another feature is smallPersonalSite – for a small personal site or blog. King speculated that Google could boost or demote such sites via a Twiddler. However, that remains an open question. Again, we don’t know for certain how much these features are weighted. Other interesting findings. According to Google’s internal documents: Freshness matters – Google looks at dates in the byline (bylineDate), URL (syntacticDate) and on-page content (semanticDate). To determine whether a document is or isn’t a core topic of the website, Google vectorizes pages and sites, then compares the page embeddings (siteRadius) to the site embeddings (siteFocusScore). Google stores domain registration information (RegistrationInfo). Page titles still matter. Google has a feature called titlematchScore that is believed to measure how well a page title matches a query. Google measures the average weighted font size of terms in documents (avgTermWeight) and anchor text. The articles. Secrets from the Algorithm: Google Search’s Internal Engineering Documentation Has Leaked by King on iPullRank An Anonymous Source Shared Thousands of Leaked Google Search API Documents with Me; Everyone in SEO Should See Them by Fishkin on SparkToro Quick clarification. There is some dispute as to whether these documents were “leaked” or “discovered.” I’ve been told it’s likely the internal documents were accidentally included in a code review and pushed live from Google’s internal code base, where they were then discovered. The source. Erfan Azimi, CEO and director of SEO for digital marketing agency EA Eagle Digital, posted a video, claiming responsibility for sharing the documents with Fishkin. Azimi is not employed by Google. Add Search Engine Land to your Google News feed. Related stories SMX Advanced kicks off in two weeks – secure your spot now! 3 common B2B SEO mistakes sabotaging cost per lead How to build a better remote team at your digital marketing agency Google testing blue visit button for search result snippets The latest jobs in search marketing New on Search Engine Land PayPal launching ad network fueled by user purchase data How to create and configure custom dimensions in GA4 A guide to ad variations in Google Ads Google Business Profile chat and call history going away SMX Advanced kicks off in two weeks – secure your spot now! About the author Staff Danny Goodwin Danny Goodwin has been Managing Editor of Search Engine Land & Search Marketing Expo - SMX since 2022. He joined Search Engine Land in 2022 as Senior Editor. In addition to reporting on the latest search marketing news, he manages Search Engine Land’s SME (Subject Matter Expert) program. He also helps program U.S. SMX events. Goodwin has been editing and writing about the latest developments and trends in search and digital marketing since 2007. He previously was Executive Editor of Search Engine Journal (from 2017 to 2022), managing editor of Momentology (from 2014-2016) and editor of Search Engine Watch (from 2007 to 2014). He has spoken at many major search conferences and virtual events, and has been sourced for his expertise by a wide range of publications and podcasts. Related topics GoogleSEO",
    "commentLink": "https://news.ycombinator.com/item?id=40510125",
    "commentBody": "Google Search document leak reveals inner workings of ranking algorithm (searchengineland.com)166 points by isaacfrond 9 hours agohidepastfavorite122 comments vouaobrasil 7 hours agoSometimes I wonder how much better the internet would be hits on Google weren't directly tied to revenue from Google itself through its ad program. I am certain Google has made the internet and the world a worse place to live. reply eitland 7 hours agoparentAs a user of Kagi and search.marginalia.nu I can tell you: Quite a bit. So much that now that I have what \"everyone\" asked Google for for years - that is blacklists - I hardly use them. Why? Because with Kagi I get much better results out of the box. I am fairly sure Googlers will tell me there are multiple safeguards to prevent the inclusion of Google ads from affecting ranking, to which I just have to say that the results speak for themselves. Please note: I have only used Kagi for two years. I am only one user. But I am a user with 20 years of experience with Google and that got to count for something. reply Nevolihs 7 hours agorootparentI actually use pinning, blocking and raising/lowering the value of individual sites every day. I wish this is the direction search engines went in the first place and it's the direction I hope Kagi continues. I want a personalized search engine that's personalized by me, not by a company trying to profile me and make money off of my clicks. reply the_snooze 5 hours agorootparentWhen each user can personalize the results themselves, you make SEO completely impractical because they can no longer target a single monolithic algorithm controled by one entity. Websites would actually have to have organic appeal to users, who get the final say to hide away bad sites from the results page (looking at you, Quora, Pinterest, and Fandom). reply eitland 5 hours agorootparentprevI am all for Kagi keeping that feature. If for nothing else then to rub it in the face of every googler who have argued that it was impossible. And if you use it I am happy, that gives Kagi an incentive to keep it around. I'm just saying that for me the results are so good out of the box that with a couple of exceptions I never had to block anything. reply scutrell 6 hours agorootparentprevI was excited to try Kagi, but I couldn't justify the cost. I find DDG with the occasional Google search to function almost as well. I'll try Kagi again at some point, but it wasn't the panacea people here made it out to be reply p3rls 5 hours agorootparentprevKagi is the same garbage as google in my niche. Even worse, maybe. It looks like it's weighing backlinks and SEO garbage even higher. Well done. I don't know how people keep talking about it. The results, as you say, speak for themselves. reply eitland 5 hours agorootparentWell, don't use it then. I am happy for alternatives, otherwise I guess Kagi wouldn't improve so fast in areas I care about. reply p3rls 5 hours agorootparentI won't use it. I am pushing back on your belief that it has figured something out about anything, because to me it looks like Kagi takes Google's results and then makes them worse. I have total shit ranking #1 on Kagi and Google. On other pages I am struggling to break into the top 10 where I should be right under wikipedia in a just world. I think many people whose lives don't revolve around these things (as in your finances/mortgage are not dependent on google search) get weird magical views about search engines where it's sorta like a modern delphic oracle where the magic works as long as you believe in it. Of course I have the opposite problem where Google is angry chthonic god to be supplicated/scorned. Oh well, I do know I will not be worshipping a new god that cannot even destroy the abominations sitting at the top of the rankings. reply bitcharmer 3 hours agorootparent> Kagi takes Google's results and then makes them worse And this is how I know you haven't used Kagi at all. reply p3rls 2 hours agorootparent> And this is how I know you haven't used Kagi at all. I guess the identical search results in my niche are an example of convergent enshittification of both Kagi and Google then reply bitcharmer 50 minutes agorootparentOk, if that's the case then I give up. Totally possible for different people to have wildly different experience. reply packetlost 5 hours agorootparentprevI dunno, the first thing I did was blacklist G**ksf*rG**ks from my search results (and others, of course) and I couldn't be happier. reply abhijat 7 hours agorootparentprevI switched to Kagi in June last year. I just realized I tried it initially because I wanted to try out blocking sites in search results, and I have only ever needed to block three domains. reply eitland 7 hours agorootparentThats exactly what I am talking about. Kagi is kind of like Google in 2009, seriously good coverage, good ranking ... but also: - more modern - more features (summarizer, bangs like in DDG, FastGPT and probably a few I forgot) - blocklists for websites (and also options to pin, raise and lower) - with actual support: report a bug and you get an answer from a real engineer, a follow up when it is fixed and a shout out in the relevant release notes - no tracking reply dustincoates 6 hours agorootparentI like Kagi a lot (just look at my comment history), but I'm letting my subscription lapse when it comes time to renew. I've found myself going to Google a lot more often, and I'm finding more and more transparently spammy sites in the Kagin index. Some, for example, are clearly Gen AI created. If I were a rich man, I would probably keep my subscription just to support a Google competitor. Alas, I'm not, and so I'll be going back to Google. reply eitland 5 hours agorootparentI see your point. I was not always this well paid. Did you try blocking the problematic sites and if it didn't work, did you file support requests? reply dustincoates 4 hours agorootparentI didn't block them, because they were rarely the same site repeatedly, so I'm not sure it would help. I didn't on support requests, either, perhaps I should. I have before, and the team did a great job at addressing what wasn't working. reply elorant 6 hours agorootparentprevI use FastGPT quite often although I’m not a subscriber to Kagi itself. For me it’s everything an AI search engine should be. Here is your answer, and here are a bunch of links to research further. Something that works without making the web obsolete. Not like the walled off garden of OpenAi which often hallucinates links, or Google’s “I through everything at the wall to find what sticks” effort. reply nolist_policy 7 hours agorootparentprevIs it only me or do these constant Kagi ads on HN sound fishy? reply ysavir 6 hours agorootparentI wouldn't necessarily call them fishy, but I am very tired of them. They have a very evangelizing tone. But I think they're ultimately just people excited about the tool they're using and wanting to share it with others. reply drpossum 6 hours agorootparentprevMaybe they're not ads but people who genuinely like the service? reply JTyQZSnP3cQGa8B 4 hours agorootparentprevI never say it but here it is: for the price of 2 packs of cookies, I went from being a 1x programmer to a 1.5x programmer without doing anything. If the results are good, it’s good for me and my job which brings me way more money and satisfaction than $10. The alternative is Searx and I may try it sometimes, but so far Kagi is cheap and very efficient for me (C++ coding and other languages). reply tomrod 6 hours agorootparentprevI took a screenshot years ago where 10/14 of the viewable top headlines on my screen where positive Google discussion. From an advertising perspective it was all earned marketing (satisfied customers speaking highly). While these situations could be a pg-style astroturf submarine, or they could be satisfied customers (the best kind of advertising), I wouldn't necessarily say fishy (you can look at the satisfied users' previous contributions to make that judgment yourself! :)). Personally, I've not used Kagi, but I hear positive things from people I trust that use it. So I'll likely try it in the future. reply epr 6 hours agorootparentprevDid we not all evangelize Google in it's early days? Also, none of these accounts saying nice things appear to be bots or kagi-focused in any way, so I think it's safe to assume they do actually just like it. reply orangevelcro 4 hours agorootparentI don't know...my spidey sense has been going off a bit. Kagi has a free trial, but you have to pay, which is the difference between it and early Google. Of course, now we have Google ads instead, so who knows, maybe not bots. reply danielheath 6 hours agorootparentprevIt’s not surprising that folks who pay for a service when there’s a free alternative are pretty serious fans. reply breakfastduck 6 hours agorootparentprevGoogle Search being a bit rubbish has been in the zeitgeist for a while, it's not surprising that people then talk about an alternative they've found that is much better in their experience reply mannycalavera42 6 hours agorootparentprevkagi is the new crossfit reply karma_pharmer 6 hours agorootparentprevKagi is simply reselling google search results. reply ptman 6 hours agorootparentThey have many sources https://help.kagi.com/kagi/search-details/search-sources.htm... reply karma_pharmer 5 hours agorootparent... and 99% of the results come from just one of those. reply super256 6 hours agorootparentprevThey do more than that: https://help.kagi.com/kagi/search-details/search-sources.htm... reply karma_pharmer 5 hours agorootparentThen why does kagi have the same artificially-massive github boost that google does and no other engine (bing, duckduckgo) does? They're just reselling google searches. With maybe 1% salted in from elsewhere for deniability. reply eitland 5 hours agorootparentBecause that is what most of us prefer? Or at least I thought so? But with Kagi you can always lower github results if you want to. Or boost other sites that you prefer. reply beeboobaa3 7 hours agorootparentprevIs kagi good for finding things like old forum posts (not reddit)? I know some of those sites are still up but google seems to ignore them. reply nalinidash 5 hours agorootparentTry search.marginalia.nu From the website about: \"This is an independent DIY search engine that focuses on non-commercial content, and attempts to show you sites you perhaps weren't aware of in favor of the sort of sites you probably already knew existed.\" reply eitland 5 hours agorootparentprevThere is a seperate \"lens\" (think like \"images\", \"videos\" and \"news\" in Google, only there are more and you can create your own) for \"Small Web\" which only includes what they describe as \"Results that favor noncommercial domains and topics\". (Other standard lenses include - Forums - Fediverse forums - Usenet/archive and I think 7 others.) reply stuffoverflow 6 hours agorootparentprevIn my experience kagi is decent, definitely gives more forum results than google. I've found yandex to be the best at finding all kinds of forum /discussion sites. reply esperent 6 hours agorootparentprevKagi is worth the money, but it isn't magic. It's about as good as Google was ~five years ago, before they made all the search operators stop work. There's also a whole bunch of things it's worse at that Google - especially local search and shopping. Plus I still get plenty of blogspam and AI generated crap from Kagi. reply mozman 6 hours agorootparentThe search operators makes big difference in result quality, I also don’t like how Google now returns zero results for something obscure. In the past I could find something peripheral and eventually get to what I was looking for. reply orangevelcro 4 hours agorootparentExactly! It's so frustrating because the results were usually useful enough to at least point me in the right direction or help me figure out what I was doing wrong to find what I wanted. reply amelius 6 hours agorootparentprevHow do you know that Kagi won't become as bad as Google at some point? reply duckmysick 2 hours agorootparentWhat's the argument you're trying to make? That because there's a chance Kagi will become bad, there's no point in using it now and thus we should stick to Google, which is already bad? That doesn't make sense. The same line of thought can be applied to anything. We don't know what will happen in the future, therefore we can't be sure that things won't go bad. Is there even a way to have such a guarantee? Assuming I don't want to use Google (because it's bad) and I won't use Kagi or Perplexity or others (because they might become bad), what's the realistic solution? Roll my own search engine? I don't have resources and I don't trust the future me to maintain it. reply eitland 5 hours agorootparentprevKagi is worth the price every month, unlike a number of other things I have supported it is not an investment for me in the hope that it will one day be worth it but rather a service that I pay a small sum for which in turns removes lots of frustration from my life every month. If they do become bad then at least I have had a fantastic search engine for another few years of my life like I had from 2002 until 2009 ish. And also, already at this point, they and marginalia has proven that it isn't impossible to enter the search engine marked even now. This was long considered impossible, at least here on HN. reply spacebanana7 6 hours agorootparentprevAlso it’s unlikely Kagi will ever become big enough for SEO people to specifically target with manipulative content. Even if they got 100 million active paying users it’d still be a tiny fraction of overall search traffic. reply eitland 5 hours agorootparentIf anything, Kagi has proven that Googles \"SEO ruined it\" argument isn't valid. In the beginning, Kagi was mostly just API calls to Google and Bing AFAIK. Their results were still better for some reason, probably because they didn't have to consider how valuable the ads on garbage site were before throwing the site out of my results. reply spacebanana7 4 hours agorootparentI agree with you to some extent. For example, there's no reason I can think of why Google couldn't allow user selected domain blacklisting or custom bangs. But I fear that if a large search engine copied some of Kagi's filters/lenses for non-commercial blogs & forums then SEO agencies would dedicate immense resources to polluting them. reply Kye 4 hours agorootparentprevIt doesn't have to be big if it's rich. People will target Kagi because it's packed to the brim with people who have $5-10/month to spend on a search engine, and likely have $5-10/month to spend on other things too. reply p3rls 5 hours agorootparentprevWhy would they? The same manipulative techniques that work in my niche on Google seem to work even better on Kagi reply breakfastduck 6 hours agorootparentprevWe don't, but a model where a user pays for a service rather than being free and ad supported is significantly less likely to enact user unfriendly changes. If the way you make money is by convincing people to pay, you are highly incentivised to make the product good, especially where there are many other free competitors who are ad supported. reply glitchc 6 hours agorootparentTell that to cable companies, sports broadcasts and now streaming services. The one incontrovertible fact of modern society is that ads eat everything else. No other revenue source compares. reply karma_pharmer 6 hours agorootparentads eat everything else Well duh. Because it's the only value you're allowed to collect from retail customers without having to deal with either chargebacks or kyc. We've deliberately made every other form of micropayment infeasible. It shouldn't be surprising that the only one left is insanely popular. reply sseagull 5 hours agorootparentPartly. But also because it's just a way to make more money. If you make X from payments, and you can make Y from ads, then X+Y > X. You might lose some people, but probably not many - we've been conditioned to really accept ads everywhere. reply glitchc 4 hours agorootparentAlso because Y>>X. reply Workaccount2 7 hours agoparentprevThe fundamental problem with the Internet is that people don't want to pay for things on it. No matter what, whatever we ended up with was going to be shitty and exploitive. reply eitland 7 hours agorootparentNow you have a chance. Kagi is there. I made my decision two years ago and I would probably do it even if it was just on par with Google, to support competition and to avoid supporting Google. But in hindsight it is just exeptionally much better. There is no going back unless Kagi does something monumentally stupid. reply jacob019 6 hours agorootparentI'm a Kagi user too. I like your enthusiasm, but I can't say it's been all that life changing for me. DuckDuckGo is ok too, I still use it on some machines when I don't feel like logging in. GPT has been more life changing. reply eitland 5 hours agorootparentDon't know what I am doing wrong but except the first few times I really didn't get good results with Kagi. It might be that I rely a lot on precise queries and doublequoted words and also cannot get myself to use the conversational style that at least Google seems to prefer now. reply L-four 7 hours agorootparentprevIt's not that people don't want to pay it's that it's difficult to pay small sums. The web browsers could solve this problem but they make money from ads so it's not in there best interest. reply UI_at_80x24 5 hours agorootparentAnd this was one of the hopes/goals/dreams that crypto offered that I really wish had come true. reply nradov 6 hours agorootparentprevJakob Nielsen's article \"The Case for Micropayments\" from 1998 still seems relevant. Nothing has really changed in 26 years so I'm skeptical whether it could ever work, but in principle it would be great for users and website owners to have that option. https://www.nngroup.com/articles/the-case-for-micropayments/ reply tjpnz 6 hours agorootparentprevHow much of that is due to ad-tech companies like Google conditioning people into thinking that way? What if online payments weren't so god awful and allowed people to throw in a few dollars as easily as they might at a toll booth? That's still an unsolved problem too. Credit card companies have solidified their involvement in every facet of the process and the alternatives are non-starters for frictionless commerce. I'm still happy to put my money where my mouth is and do pay for services which are genuinely useful to me. But this is not the kind of internet I imagined when growing up. reply benterix 7 hours agoparentprevIt's not black and white. There was a lot of junk that was forced on us and that was removed thanks to Google. But I agree the direct relationship is inherently corrupting. reply GTP 7 hours agorootparentLarry Page and Sergei Brin even stated very clearly in their original paper that using ads as revenue source can impact the quality of results returned from the search engine. reply DarkNova6 7 hours agoparentprevYou mean the way Google worked originally? The founders were very careful in creating a barrier between ads and search. A barrier whose erosion has been well documented over the last 10 years. reply vouaobrasil 7 hours agorootparentA barrier whose only purpose was to establish trust so that it could be later taken advantage of. reply DarkNova6 4 hours agorootparentAs much of a cynic I typically am, there is a well established record of events which shows that this is not true. Google search was taken over by an ambitious clique of failed yahoo managers that successfully destroyed their former company for their own financial advantage then did the same at google. Acting as parasites on society at large. reply heresie-dabord 7 hours agoparentprevInstead of a semantic Web of knowledge, we got \"grep the HTML... with ads\". reply josefx 5 hours agorootparentYou dropped the -v . Modern day Google seems fine tuned to return results that contain everything except for the words I searched for. reply greg_V 7 hours agoparentprevI mean... maybe, but not really. The first problem of the internet was that there wasn't that much content specifically. The first internet companies were the broadband providers who were developing content themselves, like AOL. Google and the ad ecosystem they acquired was basically the flywheel that spurred content creation at scale. Anyone could jump in, follow a few guidelines and earn a living by producing content on the internet. The Youtube acquisition and monetization followed the same pattern. Over time the market consolidated and got less and less competitive: less platforms with complete control of traffic and one-sided revenue sharing agreements. The guidelines so to speak on how content should look and feel like were algorithmically made stricter and stricter until everything looks, feels, sounds and reads the same. The problem right now is that the platforms are still tightening their grip, and it's all tied to the approach of using AI to replace the content creators on the platforms from Google to Spotify to Meta, and carving the spared money to shareholders. And while the web has been shitty for a few years now, we're now seeing a sudden drop in quality because the average user has no recourse or alternative, and neither does the average creator have the means of distribution and monetization (not just publishing, that's been solved) to even find, let alone meet the new kinds of demand. I'm certain that in a few years this will even out: new search engines, new aggregators and new feeds will emerge, but the content - money - network problem triangle remains as a fundamental problem of the internet. reply linsomniac 7 hours agoparentprevDid you experience the Internet before google? The idea of a world where Alta Vista won is truly chilling. reply thsksbd 7 hours agorootparentYou mean a world where people still knew how to use a library catalog, still relied on more than one source of information and curious crazy tid bits are still out there? The internet is boring. And the trash is still there. Its just become reputable instead. reply linsomniac 7 hours agorootparentThere's a lot to unpack here... Can you expand on how a card catalog improved the world? As a kid I used the card catalog a lot, both the physical version and the later electronic versions. Full text search definitely leads to pulling in information from a wider selection of sources. I remember a lot of stratification of news sources pre-Google (which news channel you watched, which papers/magazines you read). Did Google cause reliance on one source of information, or does Google simply exist in a world where people tend towards echo chambers? How would Alta Vista have improved that? reply jareklupinski 4 hours agorootparent> how a card catalog improved the world i was lamenting the library recently and remembered how books were organized on shelves using the dewey decimal system this meant that if you knew of one book that has something you're looking for, you can find all the _other_ books about the same topic right next to the first book, even if you knew nothing about the contents of the related books reply staticman2 4 hours agorootparentLibraries still exist and sort books like that, don't they? reply yencabulator 17 minutes agorootparentI believe the point is that the commenter wishes more things operated like that, where adjacent items were related and likely of similar quality, not just boosted with money and SEO trickery. reply badpun 6 hours agorootparentprev> still relied on more than one source of information and curious crazy tid bits are still out there? I think the curious crazy tid bits are still there. reply washadjeffmad 7 hours agorootparentprevI'd be okay with a world in which everyone else in search didn't lose, too. reply msk-lywenn 7 hours agorootparentprevIn some way, didn't Google become Alta Vista? reply linsomniac 7 hours agorootparentHow so? My memory of Alta Vista was so-so search results with a top page littered with garbage. reply eitland 7 hours agorootparentExactly like Google since 2011 +/- 2 years (the so-so search results part) and Google the last few years (the littered with garbage part)? I have used Google since probably 2001-2002 sometime and a number of other search engines before. It is rather obvious to me and I have writing and screenshots from around the time quality took a dive that supports it. reply marginalia_nu 6 hours agorootparentI think over time the story has become that AV and Yahoo were overtaken by Google because the latter had a cleaner design, which if you think about it for more than a moment doesn't really constitute much of a moat. reply eitland 5 hours agorootparentGoogle was also technically better when it released and importantly there was no way to buy ones way to the top. Back then I think people mostly agreed that the results that ranked on top in Google generally were there because of criteria that benefited the end user. I mean, even as crazy as Google results has been the last few years they have still managed to be better than Bing and DDG who both manages to have worse ranking and also like Google completely ignore my doublequotes. reply solardev 7 hours agorootparentprevExactly reply linsomniac 7 hours agorootparentprevReminder: Alta Vista looked like this: https://en.wikipedia.org/wiki/AltaVista#/media/File:Altavist... reply mastercheph 6 hours agorootparentprevGoogle reply vouaobrasil 7 hours agorootparentprevYes, I did! I used to use Yahoo search where the results were more hand-curated and people did not create websties for intensive commercial purposes with useless SEO fluff like it is today. reply linsomniac 7 hours agorootparentI have been thinking a lot about Yahoo (pre yahoo-search, largely) lately. I don't fully understand how we lost the curated catalog, especially considering the success of Wikipedia. The latter demonstrates users willingness to curate knowledge bases... We have \"awesome\" lists, but I rarely seem to use them. reply xnx 6 hours agorootparentYahoo directory was largely pay-to-play and very affected by proto-SEOs trying to game the system for direct traffic or PageRank value. Collaborative directories like dmoz.org suffered the same fate before shutting down. reply A_D_E_P_T 6 hours agorootparentPay-to-play is actually a very decent business model for a directory, though. Pay a one-time fee, establish that you're a legitimate business or website, undergo a quality assessment, and you're in. There's no paying for extra promotion, e.g. with ads, and website owners don't need to warp their sites in anticipation of what they think the search engine wants. (Which often results in a decrease in usability, e.g. all of those recipe sites with low-quality 2000-word essays before they get to the actual recipe.) It's a more level playing field, and it's intrinsically more human-friendly. reply blowski 7 hours agoparentprevI imagine it would be a different flavour to what we have today, but the same intensity. Anything that so deeply penetrates daily life across the globe is going to bring enormous problems with it. reply wslh 7 hours agoparentprevGoogle was really great and revolutionary, they helped zillions of small companies to thrive. It was another cycle. Then, now, it is like media before the 90s: you need to pay a lot of money to be in the center page of the newspaper. But, hopefully we are talking about LLMs now, seems like one of the answers to search engines in general. Beyond AI, I see LLMs as a good evolution from PageRank. A little bit general but lately I use the expression: \"Complexity as Scam\". Google always pointed to their \"algorithms\" and played with this term as if algorithms couldn't be adjusted to whatever you want to be. Initially the coined term was sound because it was based on a scientific paper and eventually it evolution but it seems like the PageRank original idea has detoured from being a \"pure\" graph algorithm. Another context where I use \"Complexity as Scam\" is Web3. It is like Matryoshka dolls where there is always one more step of complexity to probe a point, but it never ends. reply thih9 8 hours agoprev> Thousands of documents, which appear to come from Google’s internal Content API Warehouse, were released March 13 on Github by an automated bot called yoshi-code-bot Does anyone know more about yoshi-code-bot and how were these documents suddenly published? Was it a script misconfiguration? A manual push? Something else? reply chx 7 hours agoparenthttps://github.com/yoshi-code-bot Created 1,891 commits in 19 repositories All 19 is under googleapis This looks like a bot Google uses to publish their stuff on github and so likely it's a misconfiguration. reply BillFranklin 7 hours agoprevFYI, it's much easier to read the linked GitHub code via the published docs at https://hexdocs.pm/google_api_content_warehouse/0.4.0/api-re... reply BillFranklin 7 hours agoparentIn particular, https://hexdocs.pm/google_api_content_warehouse/0.4.0/Google... Notably, for people on HN, it looks like there is indeed an internal initiative to promote small personal blogs :-) > smallPersonalSite (type: number(), default: nil) - Score of small personal site promotion go/promoting-personal-blogs-v1 reply SquareWheel 5 hours agorootparentWell, maybe. It's a factor that a twiddler can influence, but we don't know if that's done positively or negatively. It might also be more conditional, like for specific types of queries. For example, a small, personal blog might be great for solving a specific technical problem (\"my dishwasher of model XXX has YYY problem\"), but might be terrible for something like giving public health advice. reply iamacyborg 6 hours agorootparentprevWe don’t know whether that particular module was used to promote or downgrade small sites in the SERPs. reply isaacfrond 9 hours agoprevMost of the factors in ranking a page are no surprise. But i was surprised that having Product reviews on your site is apparently a demotion? Surely, many people are searching to find just that? reply unnamed76ri 7 hours agoparentYears ago I had a site for deep fryer reviews. The whole thing existed to make money from Amazon’s affiliate program. I hadn’t personally used ANY of the deep fryers. Was just writing reviews based on features and other people’s reviews. In short, I ranked high in Google and added nothing of value to the world with that site. There was a brief period of time where I made decent money with it until Google deranked all the product review websites. reply zeroCalories 6 hours agoparentprevSites spam low quality product reviews with affiliate links to Amazon. This is done by \"reputable\" sites as well. I don't blame Google for down ranking this meta. reply nottorp 7 hours agoparentprevWe are, but I’m not sure there are any real product reviews left on the internet. reply sidewndr46 6 hours agorootparentOther than reviews of Google search itself obviously reply nottorp 4 hours agorootparentAre there? I can't [1] write an objective review, I can just subjectively say that it's been more and more useless to me in the past ... 7-8 years now? [1] Or maybe can't be bothered because I stopped caring ages ago. reply bbarnett 8 hours agoparentprevThis is likely more about reviews with affiliate links. 99.99% of those are people reviewing absolutely nothing, just copying reviews and putting their own affiliate link. reply ren_engineer 6 hours agoparentprevmost of these have been outright publicly denied by Google employees, despite people showing with A/B tests that things like CTR and backlinks impacted rankings reply cqqxo4zV46cp 7 hours agoparentprev“xx,xxx five star reviews” I’ve found is a modern day over-marketed product trope. It feels well within the realm of reasons that this ends up serving as a useful heuristic. reply yieldcrv 8 hours agoparentprevI don’t trust conflicts of interest, if that’s about a site selling it’s own product and having reviews, I’m glad to find that results in a demotion While bigger marketplaces have other ways of driving ranking reply HankB99 5 hours agoprev> Successful clicks matter. I wonder about this. If I click a link and read it and I find that it's garbage (e.g. got ranked based on SEO rather than useful content) does it count as a successful click? Worse yet, some of these sites have blatant errors that are only discovered after examination. This is relative to technical subject matter. Other searches, such as shopping may not suffer this kind of problem (or I have not noticed it.) I also wonder how Google knows a click is successful. If I open a link in another tab, does the browser tell Google how long I lingered on the site? Perhaps Chrome does but I use Firefox. reply EcommerceFlow 5 hours agoparentOnce you get to the top 1-3 results, CTR (click through rate) is a much bigger ranking factor. Google knows how long people stay on pages and whether they click and back out immediately. This is important for E-Commerce, because Google doesn't want Site #1 to be mostly out of stock even though they have better links. reply HankB99 1 hour agorootparent> Google knows how long people stay on pages and whether they click and back out immediately. What if Ito keep the search page open and open the \"found\" page in another tab? reply yencabulator 11 minutes agorootparentCan the on-page javascript detect the difference between click and control-click? If so, you can count just the former, and wait for the back button press, to get a sense of visit duration. I think control-click is a power user feature that they just don't care to track. Average consumer is the target audience of the advertising... reply 9dev 6 hours agoprevI found it interesting that the docs mention \"site2vec\" scores. This implies, I think, a variant of word2vec or document2vec, but for the full site; so probably a vector sum of the doc2vec scores of all individual pages? reply croes 7 hours agoprevRelated https://news.ycombinator.com/item?id=40498076 https://news.ycombinator.com/item?id=40496967 reply badgersnake 7 hours agoprevSomething like this I guess: var words = query.split var results = executeQuery( Select * from AdWords aw where word in query inner join adlinks al on aw.id = al.id return al.url, al.desc) If (results.size < 30) { // todo call search engine } Return results reply StevenNunez 1 hour agoprevWait... There's Elixir to be done at Google?! reply renegade-otter 6 hours agoprevThere are so many Kagi fans on HN that it's a matter of time before the Big G buys it and shuts it down, like hundreds of its products before. reply ChrisArchitect 7 hours agoprev[dupe] Some more discussion: https://news.ycombinator.com/item?id=40496967 reply Aldipower 7 hours agoprev [–] If there are really 14,000 attributes, most of them will have a weight near 0, thus are irrelevant. If they would be all heavy weighted, the ranking would be rendered irrelevant due to the sheer amount of attributes. reply ozehlaw 5 hours agoparentYes, this makes sense. I think the only good thing from the leak for Google is that the scoring values are not present reply beejiu 7 hours agoparentprev [–] Isn't that where deep learning comes into play? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A major leak of internal Google Search documents has unveiled critical aspects of Google's ranking algorithm, including the use of clicks, links, content, entities, and Chrome data.",
      "Industry experts Rand Fishkin and Michael King analyzed the documents, revealing 2,596 ranking modules, the significance of link diversity, relevance, successful clicks, and brand recognition.",
      "The documents also disclose Google's use of author information, site authority, and \"twiddlers\" to adjust rankings, offering valuable insights for SEOs despite the unknown exact weighting of ranking factors."
    ],
    "commentSummary": [
      "A leaked Google Search document has ignited debates about the ranking algorithm and the influence of Google's ad program on search results.",
      "Users are discussing alternatives like Kagi and search.marginalia.nu, with mixed reviews on Kagi's customization, non-commercial focus, and issues with spam and AI-generated content.",
      "The conversation highlights a desire for search engines that prioritize user preferences over ad revenue, touching on SEO manipulation, the potential of Large Language Models (LLMs), and concerns about the authenticity of online reviews and Google's ranking criteria."
    ],
    "points": 166,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1716975374
  },
  {
    "id": 40507039,
    "title": "ChatTTS: Advanced Open-Source TTS Model for Natural Dialogue in English and Chinese",
    "originLink": "https://github.com/2noise/ChatTTS",
    "originBody": "ChatTTS English中文简体 ChatTTS is a text-to-speech model designed specifically for dialogue scenario such as LLM assistant. It supports both English and Chinese languages. Our model is trained with 100,000+ hours composed of chinese and english. The open-source version on HuggingFace is a 40,000 hours pre trained model without SFT. For formal inquiries about model and roadmap, please contact us at open-source@2noise.com. You could join our QQ group: 808364215 for discussion. Adding github issues is always welcomed. Highlights Conversational TTS: ChatTTS is optimized for dialogue-based tasks, enabling natural and expressive speech synthesis. It supports multiple speakers, facilitating interactive conversations. Fine-grained Control: The model could predict and control fine-grained prosodic features, including laughter, pauses, and interjections. Better Prosody: ChatTTS surpasses most of open-source TTS models in terms of prosody. We provide pretrained models to support further research and development. For the detailed description of the model, you can refer to video on Bilibili Disclaimer This repo is for academic purposes only. It is intended for educational and research use, and should not be used for any commercial or legal purposes. The authors do not guarantee the accuracy, completeness, or reliability of the information. The information and data used in this repo, are for academic and research purposes only. The data obtained from publicly available sources, and the authors do not claim any ownership or copyright over the data. ChatTTS is a powerful text-to-speech system. However, it is very important to utilize this technology responsibly and ethically. To limit the use of ChatTTS, we added a small amount of high-frequency noise during the training of the 40,000-hour model, and compressed the audio quality as much as possible using MP3 format, to prevent malicious actors from potentially using it for criminal purposes. At the same time, we have internally trained a detection model and plan to open-source it in the future. Usage basic usage import ChatTTS from IPython.display import Audio chat = ChatTTS.Chat() chat.load_models() texts = [\"\",] wavs = chat.infer(texts, use_decoder=True) Audio(wavs[0], rate=24_000, autoplay=True) advanced usage ################################### # Sample a speaker from Gaussian. import torch std, mean = torch.load('ChatTTS/asset/spk_stat.pt').chunk(2) rand_spk = torch.randn(768) * std + mean params_infer_code = { 'spk_emb': rand_spk, # add sampled speaker 'temperature': .3, # using custom temperature 'top_P': 0.7, # top P decode 'top_K': 20, # top K decode } ################################### # For sentence level manual control. # use oral_(0-9), laugh_(0-2), break_(0-7) # to generate special token in text to synthesize. params_refine_text = { 'prompt': '[oral_2][laugh_0][break_6]' } wav = chat.infer(\"\", params_refine_text=params_refine_text, params_infer_code=params_infer_code) ################################### # For word level manual control. text = 'What is [uv_break]your favorite english food?[laugh][lbreak]' wav = chat.infer(text, skip_refine_text=True, params_infer_code=params_infer_code) Example: self introduction inputs_en = \"\"\" chat T T S is a text to speech model designed for dialogue applications. [uv_break]it supports mixed language input [uv_break]and offers multi speaker capabilities with precise control over prosodic elements [laugh]like like [uv_break]laughter[laugh], [uv_break]pauses, [uv_break]and intonation. [uv_break]it delivers natural and expressive speech,[uv_break]so please [uv_break] use the project responsibly at your own risk.[uv_break] \"\"\".replace('', '') # English is still experimental. params_refine_text = { 'prompt': '[oral_2][laugh_0][break_4]' } audio_array_cn = chat.infer(inputs_cn, params_refine_text=params_refine_text) audio_array_en = chat.infer(inputs_en, params_refine_text=params_refine_text) intro_en_m.webm intro_en_f.webm Roadmap Open-source the 40k hour base model and spk_stats file Open-source VQ encoder and Lora training code Streaming audio generation without refining the text* Open-source the 40k hour version with multi-emotion control ChatTTS.cpp maybe? (PR or new repo are welcomed.) FAQ How much VRAM do I need? How about infer speed? For a 30-second audio clip, at least 4GB of GPU memory is required. For the 4090D GPU, it can generate audio corresponding to approximately 7 semantic tokens per second. The Real-Time Factor (RTF) is around 0.65. model stability is not good enough, with issues such as multi speakers or poor audio quality. This is a problem that typically occurs with autoregressive models(for bark and valle). It's generally difficult to avoid. One can try multiple samples to find a suitable result. Besides laughter, can we control anything else? Can we control other emotions? In the current released model, the only token-level control units are [laugh], [uv_break], and [lbreak]. In future versions, we may open-source models with additional emotional control capabilities. Acknowledgements bark, XTTSv2 and valle demostrate a remarkable TTS result by a autoregressive-style system. fish-speech reveals capability of GVQ as audio tokenizer for LLM modeling. vocos which is used as a pretrained vocoder. Special Appreciation wlu-audio lab for early algorithm experiments.",
    "commentLink": "https://news.ycombinator.com/item?id=40507039",
    "commentBody": "ChatTTS-Best open source TTS Model (github.com/2noise)156 points by informal007 18 hours agohidepastfavorite74 comments camkego 9 hours agoFrom the Readme: “ To limit the use of ChatTTS, we added a small amount of high-frequency noise during the training of the 40,000-hour model, and compressed the audio quality as much as possible using MP3 format, to prevent malicious actors from potentially using it for criminal purposes.” I’m having a hard time understanding why they have degraded the training, audio, and thus the output. It’s not like this is the first or only text to speech system. reply phoronixrly 5 hours agoparentSo that it is more inconvenient to use theirs for such purposes... I would do the same. reply GavCo 9 hours agoprevNot clear based on what criteria OP has determined this is the best OS model. I also don't see that claim being made anywhere in the GitHub repo so I suspect it might be a case of vibe-based benchmarking (VBB). As pointed out by u/modeless, there is an established leaderboard and this model isn't on it (yet) https://news.ycombinator.com/item?id=40508445 reply luyu_wu 14 hours agoprevI have to say the Chinese female voice sounds the most natural. It's really amazing how far these have got! Video with examples: https://b23.tv/uumKPam (bilibili) reply thomasfromcdnjs 12 hours agoprevI hadn't heard any good prosodic laugh implementations yet. In my mind that was the last hurdle to cross before being able to fool people regularly with a non-human voice. Great work! Hook that DSL into a prompt, [uv_break]gg. [laugh] reply rcarmo 9 hours agoprevThis is pretty decent, but a bit slow on my M2 Pro. Runs better on CPU, which is strange. Still, here's a quick guide to getting it to work on Metal: --requirements.txt additions-- torchvision==0.18.0 accelerate==0.30.1 --gpu_utils.py patch-- def select_device(min_memory = 2048): logger = logging.getLogger(__name__) if torch.backends.mps.is_available(): device = torch.device('mps') return device could probably do with support for device_map for multiple backends... Edit: it also seems tho hallucinate/become increasingly unreliable with longer sentences. reply acheong08 11 hours agoprevBeyond a certain level of quality, what is the purpose of improving similarity with human voice other than scamming? I’m asking because I genuinely don’t know. It seems even a rudimentary TTS is usable as long as you can tell what it’s saying. reply follower 2 hours agoparentMy interest in TTS is around \"indie\" game creation, animation and \"radio plays\". A couple of years ago I started development of a tool to help with the generation of game audio such as NPC dialogue, \"barks\" or narration for those without access to/budget for human voice actors: https://rancidbacon.itch.io/dialogue-tool-for-larynx-text-to... One thing I found interesting is that writing a small \"scene\" and then hearing dialogue being spoken by a variety of voices often prompted the writing of further lines of dialogue in response to perceived emotion contained in voices in the generated output. Plus it was just fun. :) The version of the tool on that page is based on Larynx TTS which has continued development more recently as Piper TTS: https://github.com/rhasspy/piper I'm yet to publish my port which uses Piper TTS though: https://gitlab.com/RancidBacon/larynx-dialogue/-/tree/featur... Though I did upload some sample output (including some \"radio announcer\" samples in response to a HN comment :) ): https://rancidbacon.gitlab.io/piper-tts-demos/ Obviously there's variations in voice quality, and ability to control expression is currently limited but beats hearing my own voice. :D reply throwthrowuknow 9 hours agoparentprevI don’t use any TTS at the moment because they all sound weird and it’s distracting when random words or phrases are mispronounced or have odd intonations or misplaced stresses. I would use it a lot more if it sounded entirely natural, I know this because I listen to a lot of audiobooks and podcasts. reply miki123211 4 hours agoparentprevRestoring the voices of people who have lost their ability to speak is one, making audiobooks much cheaper and more widely available, particularly for languages where they're far more rare than in English is another. Overall, this tech is a boon for the disability community. reply edvards 11 hours agoparentprevIn voice assistants, robocalls, e-books, even singing, live voice interpretation/translation... a lot of stuff. reply acheong08 10 hours agorootparentVoice assistants -> Siri sounds just fine Robocalls -> I want to know I’m speaking to a robot Audio books -> reasonable. An accurate tone is pleasant Singing -> ever heard of vocaloids? They’ve existed for at least a decade or two reply Ukv 8 hours agorootparent> Singing -> ever heard of vocaloids? They’ve existed for at least a decade or two That it was technically already possible does not mean there isn't benefit from improved quality. In fact, Vocaloid itself has been improving and now uses AI. Would also add making movies, podcasts, news broadcasts, etc. available automatically in a huge range of languages. You wouldn't want movies dubbed by Microsoft Sam (beyond initial comedic effect). reply miki123211 3 hours agorootparent> You wouldn't want movies dubbed by Microsoft Sam (beyond initial comedic effect). You'd be surprised how common something like this used to be in Poland, though admittedly we used an Ivona voice for this, which was a lot more pleasant. Having a single narrator narrate the entire movie, overlaying the original audio track, is already common here, much more so than dubbing or subtitles. This is for historic reasons, in the communist era, obtaining the raw audio tracks for dubbing was often impossible, all the translators often had was a normal copy of the movie in its original language. In the early 2000's, we had a lot of early / unofficial pirate releases, and they had to be translated into Polish somehow. Subtitles were certainly one method, but as we're all used to the single-narrator style, many people didn't mind listening to a somewhat decent synthetic voice instead. reply kthartic 5 hours agorootparentprevGames -> AI-powered characters that interact with you in realtime Commercials/tutorials/corporate training videos -> Voiceover work TV shows -> Dubbing in various languages Fast food drive-throughs -> Taking customer orders reply lupusreal 10 hours agorootparentprev> robocalls E.g. scamming. For anything that is just about conveying information through audio, like voice assistants, traditional TTS already works fine. reply txdm 6 hours agoparentprevNarration of marketing or educational materials without hiring voice talent. For instance, if an independent developer wants to create a short video that explains key features of their software project. The voice should sound natural enough that the listener doesn't get distracted questioning whether it is real or hear silly mispronunciations. reply qwertox 10 hours agoparentprevThis is why I don't get why OpenAI doesn't open source their TTS. I've read that it is because of the risk of misuse, but if they release it with only two voices, one male and one female voice, and ensure that these voices are recognizable AI voices (in the sense of popular), there shouldn't be any risk? Most of us just need a machine to have the ability to speak to us in a way that sounds halfway human, but not as horrible as old open source TTS systems. reply follower 3 hours agorootparentWould you settle for as \"horrible\" as new open source TTS systems? :D My current go to is Piper TTS: https://github.com/rhasspy/piper It's MIT-licensed, supports ~30 languages and multiple voices[0]/quality/licenses. Voice output samples: https://rhasspy.github.io/piper-samples/ Discovered just now that recently there's also been some efforts to train Public Domain/CC-BY licensed voices specifically for Piper TTS too: https://brycebeattie.com/files/tts/ ---- footnotes ---- [0] e.g. One of the English voice sets has ~900 voices(!). reply kebsup 10 hours agoparentprevI'm always on a lookout for the best TTS for my language learning app. reply rawrawrawrr 9 hours agoparentprevVideo games, for one. reply psychoslave 10 hours agoprevCould it be used to teach me Mandarin? Actually since it's only voice synthesis, I guess it would still miss the voice recognition and capability the quality of my attempt to reproduce tonal language sentences. reply estheryo 17 hours agoprevThe completion level is impressive! I can hardly tell the difference from a human voice, especially with the natural pauses and laughter, which surpasses ChatGPT’s quality. However, there’s a noticeable electric noise at the end of sentences, which feels unnatural. (As a native Chinese speaker, I find the Chinese output even better in comparison.) reply informal007 16 hours agoparentYes, it's just a new born project, looking forward the next verison. reply nshm 12 hours agoparentprevThere is also a glitch in \"dialogue\" reply maxglute 16 hours agoprevSounds natural and intelligible at 3x speed, which is plus. >The Real-Time Factor (RTF) is around 0.65. What is the state of real time tts models? reply regularfry 10 hours agoparent0.65 isn't that big a gap. This is probably less than one jart away from being optimised to real-time. reply c0brac0bra 6 hours agoparentprevAura can stream responses and has a time-to-first-byte around 200-400ms reply cchance 18 hours agoprevSounds good but feel like theirs something slightly off to the cadence of the voice in the sample, but maybe i'm imagining reply informal007 17 hours agoparentI think you are right, It is not the completely same. reply thorum 14 hours agoprevWow - the most impressive thing about this is the control options. I’m not aware of any other TTS systems with the same balance of control, quality and language support. Looking forward to testing this out… reply stakhanov 10 hours agoprevThis is somewhat off-topic, but here goes: It seems to me that English TTS is already extremely good, even if you're looking at implementations that are far from being the best ones for English. ...and sometimes I wonder, if it's really economically efficient for that many players to compete on making English TTS yet another hair's breadth better than the next guy's, while TTS for languages other than English is this vast field of unmet market demand. At least these guys are doing Chinese, so: good for them. Last time I looked into TTS systems for German, Google was the only game in town. What I wouldn't give for a viable alternative! It doesn't even need to be open source, I'd be quite ready to pay top dollar. reply follower 4 hours agoparent> Last time I looked into TTS systems for German, Google was the only game in town. What I wouldn't give for a viable alternative! It doesn't even need to be open source, I'd be quite ready to pay top dollar. Will you still pay top dollar if it is open source though? :D Piper TTS[0] (MIT Licensed; developed by main dev of Larynx TTS, Mimic3 TTS & Rhasspy voice assistant) has support for ~30 languages, at least some of which have multiple voices available--in a range of quality & data licenses. And, particularly fortuitous for your needs, potentially, there's at at least one German voice that was recorded[1] specifically for Piper[2] (with emotion variants and CC0-licensed, no less :) )... Check out `thorsten` & `thorsten_emotional` on the samples page: https://rhasspy.github.io/piper-samples/ I can't speak to the quality of the German voice specifically but for English at least I've found Piper's quality & range of voices of use[3]. ---- footnotes ---- [0] https://github.com/rhasspy/piper [1] https://www.youtube.com/playlist?list=PL19C7uchWZeojjI5FUk3q... [2] In addition to other German voices based on other sources: https://huggingface.co/rhasspy/piper-voices/tree/main/de/de_... [3] Somewhat of an understatement. reply stakhanov 2 hours agorootparentThanks for the pointers! Will look into those. > Will you still pay top dollar if it is open source though? :D There is one OS project that I do support financially. If I get commercial value out of any of the above, I imagine I would do the same. reply DelightOne 7 hours agoparentprevOpenAI's API says they support German? Never tried it though. https://platform.openai.com/docs/guides/text-to-speech reply throwthrowuknow 9 hours agoparentprevhttps://elevenlabs.io/ And choose German for a sample. Not sure if it’s good enough for your needs but they have a wide variety of languages and voices. reply stakhanov 9 hours agorootparentThanks for the pointer. This does indeed look pretty good. Do you happen to know if they're using any APIs underneath the covers? Or are they fully self-contained? reply aprilnya 8 hours agorootparentElevenLabs is their own thing, they make the models themselves reply JoeDeanx 15 hours agoprevWhere is the demo that can be used? reply informal007 13 hours agoparentYou can try to run this code to use https://github.com/2noise/ChatTTS/blob/main/infer.ipynb reply JoeDeanx 5 hours agorootparentI don't know how to code, but I found a website that I can use online,https://chattts.com/ reply rowanG077 12 hours agoprevIs there any good voice2voice open source model? reply ex3ndr 15 hours agoprevLooks like it is yet another xtts fork reply modeless 14 hours agoprevA good time to link the TTS leaderboard: https://huggingface.co/spaces/TTS-AGI/TTS-Arena Eleven Labs is still very far above open source models in quality. But StyleTTS2 (MIT license) is impressively good and quite fast. It'll be interesting to see where this new one ends up. The code-switching ability is quite interesting. Most open source TTS models are strictly one language per sentence, often one language per voice. In general though, TTS as an isolated system is mostly a dead end IMO. The future is in multimodal end-to-end audio-to-audio (or anything-to-audio) models, as demonstrated by OpenAI with GPT-4o's voice mode (though I've been saying this since long before their demo: https://news.ycombinator.com/item?id=38339222). Text is very useful as training data but as a way to represent other modalities like audio or image data it is far too lossy. reply ugh123 13 hours agoparent> In general though, TTS as an isolated system is mostly a dead end IMO Do you mean like as a simple text to speech application? There is a huge need for better quality audiobook output. reply modeless 12 hours agorootparentI don't think recording an audiobook with human-level quality is \"simple\". It's really a kind of acting. TTS models do very poorly at acting because they generally process one sentence at a time, or at most a paragraph, and have very little context or understanding. They just kind of fake it like a newscaster reading an unrehearsed script from a teleprompter. True human-level audiobook reading would require understanding the whole story, which often assumes general cultural knowledge, which you'll only get from a model trained on LLM-scale data. If you asked GPT-4o's new end-to-end voice mode to read an audiobook you'd probably get a better result than any TTS model. I bet it would even do different voices for the characters if you asked it to. reply sandreas 12 hours agorootparentNot only the whole story, but also which character is currently speaking, what place and mood he is in, whether it is sarcasm or irony and many many more aspects. However, in my opinion it would be a huge benefit, if this kind of metadata would be put into the ebook file in some way, so that it would be something extractable and not has to be detected. I think it would be enough to ID the characters and tag a gender and a mood in the book together with citations, so that you could add different speech models for different characters. That would also allow to use different voices for different characters. I wrote a little tool called voicebuilder (which I will open source next year). It's a \"sentence splitter\" which is able to extract an LJSpeech training dataset for an audio file, epub file and length matching. Works pretty accurate for now, although it needs manual polish of the extracted model. Still way faster than doing it manually. This way you can build speech sets of your favorite narrators and although you would never be allowed to publish them, I think for private use they are great! reply dececco 8 hours agorootparentprev> I don't think recording an audiobook with human-level quality is \"simple\" It is, though, I've just done it a few days back. Once you have a clean text extracted from the book (this is actually the difficult part, removing headers, footers, footnote references, etc.), you can feed it into edge-tts (I recommend the Ava voice) and you get something that is, in my opinion, better than most human performers. Not perfect, but humans aren't either (I'm currently listening to a book performed by a human who pronounces GNU like G-N-U). reply sjsdaiuasgdia 8 hours agorootparentSomething tells me one of you is speaking about fiction and one of you is speaking about nonfiction. Inflection, emotion, tone, character-specific affects and all that can really change the audiobook experience for fiction. Your mentioning of footnote references and GNU suggests you're talking about nonfiction, perhaps technical books. For that, a voice that never significantly changes is fine and maybe even a good thing. For fiction it'd be a big step down from a professional human reader who understands the story and the characters' mental states. reply dececco 3 hours agorootparentI'm talking about both. I cannot listen to audiobooks that are acted, in fact, that was the reason I decided to go down the rabbit hole of creating my own. > For fiction it'd be a big step down from a professional human reader who understands the story and the characters' mental states. On the contrary, I don't want the reader to understand anything, I just want the text in audio form and I will do the interpretation of it myself. reply sjsdaiuasgdia 1 hour agorootparentshrug good for you. A lot of people including myself find audiobook fiction really hard to listen to if read with a flat automated voice. I think how you tend to listen might also matter. I mostly use audiobooks when I'm driving or otherwise doing something else that is going to claim a portion of my attention. Following the narrative and dialog is easier when the audio provides cues like vocal tone changes for each speaker / narrator. reply Rodeoclash 6 hours agorootparentprevAgreed. In fact a great example of this is the Blood Meridian audio book where each of the characters seems to get a distinct \"voice\" despite being narrated by a single person. You can find it on YouTube easily if you want an example. reply maxglute 12 hours agorootparentprevMaybe authors can tag sentences/paragraphs with acting directions while they write to facilitate acting. Seems like there's ways for some human input to streamline process. reply modeless 12 hours agorootparentApproaches based on tagging and interpreting metadata are tempting. Building structured human knowledge into the system seems like a good idea. But ultimately it isn't scalable or effective compared to general learning from large amounts of data. It's exactly the famous Bitter Lesson. http://www.incompleteideas.net/IncIdeas/BitterLesson.html To the extent that authors provide supplemental notes or instructions to human actors reading their books, that information would be helpful to provide to an automated audiobook reading model. But there is no reason for it to be in a different form than a human actor would get. Additional structure or detail would be neither necessary nor helpful. reply maxglute 2 hours agorootparentThe difference is production moves from multiple people / skills to potentially one person, the writer, who ideally already knows emotions in scene. Economics makes sense before one click audio book / production as long as it's subtantially labour reducing. reply throwthrowuknow 9 hours agorootparentprevIt would be better to just have a professional director guide the model the same way you would any other actor. reply fhe 11 hours agorootparentprevfor non-fiction books TTS is already good enough. what's needed is the convenience and speed for turning text to audio. if with one click on my ebook app I can start listening, it'll be a darn good feature for me. reply verticalscaler 8 hours agorootparentprevWell, no. This is a reasonable guess turned strangely confidently wrong and opinionated. Voice acting is quite literally done a sentence or at most a paragraph at a time. Often the recording order is completely different from the script. An actor may very well record his final scene on the first day of a project, after the whole character arc has transpired. But you know, acting. They get fed a line with stage direction and do a bunch of takes and somehow it works. Heck you might be a full blown Italian who can't say a word in English but with the right kind of jacket it comes out a banger: https://www.youtube.com/watch?v=-VsmF9m_Nt8 You mention Eleven labs being ahead, check out Suno. There is no LLM-scale anything involved there. The voice in this context is a musical instrument and there are lots of viable ways to tackle this problem domain. reply modeless 4 hours agorootparentWe're taking about audiobooks here. An actor recording an audiobook does not read the sentences or paragraphs in a random order without context. Sure, voice acting for games or movies is done piecemeal. But the actor still gets information about the story ahead of time to inform their acting, along with their general cultural knowledge as a human. Most crucially, when acting is done in this way it is done with a human director in the loop with deep knowledge of the story and a strong vision, coaching the actor as they record each line and selecting takes afterward. When the directing is done poorly, it is pretty easy to tell. Sure, for a movie or game you could direct a TTS system line by line in the same way and select takes manually, but it would be labor intensive and not at all automatic. And to take human direction the model would need more than just the text as input. Either a special annotation language (requiring a bunch of engineering and special annotated training datasets), or preferably a general audio-to-audio model that can understand the same kind of direction a human voice actor gets. reply presentation 7 hours agoparentprevThis one does seem like it does multiple languages in a sentence (at least for its currently supported languages, Chinese and English): https://www.bilibili.com/video/BV1zn4y1o7iV/?share_source=co... But it does seem like the Chinese version is better than the English one for this TTS, which would make the arena not quite as applicable to it as they're all focusing on English. reply insane_dreamer 7 hours agoparentprevPi by Inflection.ai was doing audio-to-audio long before GPT-4o with the most realistic voice ever (human-like imperfections, micro-pauses, etc). I don’t know why it didn’t get more attention. reply GaggiX 6 hours agorootparentWas it end-to-end or it was audio -> speech to text -> LLM -> text to speech -> audio? I imagine it's the latter. reply insane_dreamer 3 hours agorootparentIt's end-to-end audio, in the sense that you speak and it will reply audibly, all without visibly transcribing your words into a prompt and submitting (it may in fact be employing STT->LLM on the backend, I don't know). Works great in the car on speaker with the kids -- endless Harry Potter trivia, science questions, etc. I was completely blown away by the voice. Truly conversational. reply GaggiX 2 hours agorootparentCan it understand how you feel by the intonation of your voice, can it recognize the animal by the sound? If not, then it's probably not end-to-end, ChatGPT already had this mode for months where they simply use a STT and TTS to let you converse with the AI. reply aprilnya 8 hours agoparentprevWhy isn’t Microsoft Azure’s TTS on here? (or am I missing something and it’s called something else) reply dartos 13 hours agoparentprevIsn’t gpt 4o voice not audio to audio, but audio to text to audio? reply modeless 13 hours agorootparentIt isn't released yet, but the new one that they demoed is audio-to-audio. That's why it can do things like sing songs, and detect emotion in voices. The one that you can currently access in the ChatGPT app (with subscription) is the old one which is ASR->LLM->TTS. reply dartos 4 hours agorootparentAre we sure it’s a single model behind the scenes doing that? Practically it doesn’t really matter, but I’d like to know for sure. reply addandsubtract 6 hours agorootparentprevI'm pretty sure you can use the new GPT4o audio-to-audio model already – even without a subscription. You can even use the \"Sky\" model if you didn't update your app. reply NobodyNada 15 hours agoprev [–] > Attribution-NonCommercial-NoDerivatives 4.0 International Strictly speaking, this is not open source, as the commonly accepted definitions of open-source software include freedom of use and modification. But in an industry where \"OpenAI\" is 100% proprietary, I guess \"open-source\" doesn't really mean much. reply abetusk 13 hours agoparent [–] Note that the repo itself doesn't claim it's open source, it's the title of the link that (incorrectly) claims it is. reply follower 3 hours agorootparentThe repo does claim that something is \"open source\" but the only included license text is \"CC-BY-NC-ND\" and the README seems to restrict permissions even further. In addition, the Hugging Face repo[-1] states the license as \"Creative Commons Attribution Non Commercial 4.0\" (lacking the \"ND\"). Unfortunately, this combination of license imprecision and restrictiveness seems par for the course with a lot of academic TTS projects. (And, even for commercial \"Open Source\" TTS projects it's often the case that while code might be OSS licensed, none of the the voice data/models are.) The current version[0] of the README repo states: * \"The open-source version on HuggingFace is a 40,000 hours pre trained model without SFT.\" (Presumably refers to model.) * \"At the same time, we have internally trained a detection model and plan to open-source it in the future.\" (Not directly relevant.) The included \"Roadmap\" indicates related completed & uncompleted tasks: * \"[x] Open-source the 40k hour base model and spk_stats file\" * \"[ ] Open-source VQ encoder and Lora training code\" * \"[ ] Open-source the 40k hour version with multi-emotion control\" However, as noted, the current LICENSE[1] file states: * \"Attribution-NonCommercial-NoDerivatives 4.0 International\" And the README also contradicts the license: * \"This repo is for academic purposes only. It is intended for educational and research use, and should not be used for any commercial or legal purposes.\" * \"The information and data used in this repo, are for academic and research purposes only.\" And this part of the \"disclaimer\" would make me concerned about potential licensing issues in regard to code and or data from other sources: * \"The data obtained from publicly available sources, and the authors do not claim any ownership or copyright over the data.\" The code in the repo itself appears to have no license information contained within it. My go-to actually Open Source licensed Text-To-Speech project (with a range of voice[2] model licenses[3]--including Public Domain & CC-BY[4]) is Piper TTS: https://github.com/rhasspy/piper ---- footnotes ---- [-1] https://huggingface.co/2Noise/ChatTTS [0] https://github.com/2noise/ChatTTS/blob/f4c8329f0d231b272b676... [1] https://github.com/2noise/ChatTTS/blob/f4c8329f0d231b272b676... [2] Voice samples: https://rhasspy.github.io/piper-samples/ [3] Though I would also caution that (at least by my interpretation) some of the voices listed as CC0/PD or CC-BY also note that they've been \"fine-tuned\" on models which have more restrictive licenses and thus probably can't inherit the voice data's more permissive license. [4] However, these Public Domain and/or CC-BY voices do appear specifically created to be data license-compliant: https://brycebeattie.com/files/tts/ reply abetusk 2 hours agorootparentYou're pointing out that their license is not open source. I agree. It's not. My point is that they're not claiming it is. I'll concede that the README is misleading but, as far as I can tell, it's not making any claims that the repo is open source. They may hint at it in an underhanded way, like having \"open-source@20noise.com\" as an email that you should contact them at, or make promises about open sourcing it \"in the future\", but they make no specific claims about their model being open source. I also agree that corporations and many academics do a source of \"open washing\" by claiming \"source available\" is equivalent to \"open source\" but my point remains, this project doesn't actually claim to be open source. And thanks for the link to piper. I do wish there were a list of \"awesome (actual) open source tts/tts/misc.\" list somewhere, so, for those of us that care, can figure out where the actual open source models and data are. reply simonw 12 hours agorootparentprev [–] Yeah, I think the link title should be \"ChatTTS: Best openly licensed TTS model\" instead. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ChatTTS is a text-to-speech (TTS) model optimized for dialogue, supporting both English and Chinese, and trained on over 100,000 hours of data.",
      "The open-source version on HuggingFace includes a 40,000-hour pre-trained model, excelling in natural and expressive speech synthesis with fine-grained prosodic control.",
      "The model is intended for academic use only, with future plans to open-source additional features and improve stability."
    ],
    "commentSummary": [
      "The discussion highlights the development and performance of TTS models like ChatTTS and Piper TTS, noting issues such as slow processing and voice quality challenges.",
      "Users emphasize the need for high-quality TTS in multiple languages and debate the effectiveness of human versus automated voices in audiobooks.",
      "There is a critique of misleading \"open-source\" claims in TTS projects and a call for a comprehensive list of genuinely open-source TTS models and data."
    ],
    "points": 156,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1716943078
  },
  {
    "id": 40505310,
    "title": "Google Silent on Alleged Leak of 2,500 Pages Detailing Search Algorithm",
    "originLink": "https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo",
    "originBody": "Tech/ Google/ Creators Google won’t comment on a potentially massive leak of its search algorithm documentation Google won’t comment on a potentially massive leak of its search algorithm documentation / A purported leak of 2,500 pages of internal documentation from Google sheds light on how Search, the most powerful arbiter of the internet, operates. By Mia Sato, platforms and communities reporter with five years of experience covering the companies that shape technology and the people who use their tools. May 28, 2024, 8:00 PM UTC Share this story Illustration: The Verge Google’s search algorithm is perhaps the most consequential system on the internet, dictating what sites live and die and what content on the web looks like. But how exactly Google ranks websites has long been a mystery, pieced together by journalists, researchers, and people working in search engine optimization. Now, an explosive leak that purports to show thousands of pages of internal documents appears to offer an unprecedented look under the hood of how Search works — and suggests that Google hasn’t been entirely truthful about it for years. So far, Google hasn’t responded to multiple requests for comment on the legitimacy of the documents. Rand Fishkin, who worked in SEO for more than a decade, says a source shared 2,500 pages of documents with him with the hopes that reporting on the leak would counter the “lies” that Google employees had shared about how the search algorithm works. The documents outline Google’s search API and break down what information is available to employees, according to Fishkin. The details shared by Fishkin are dense and technical, likely more legible to developers and SEO experts than the layperson. The contents of the leak are also not necessarily proof that Google uses the specific data and signals it mentions for search rankings. Rather, the leak outlines what data Google collects from webpages, sites, and searchers and offers indirect hints to SEO experts about what Google seems to care about, as SEO expert Mike King wrote in his overview of the documents. The leaked documents touch on topics like what kind of data Google collects and uses, which sites Google elevates for sensitive topics like elections, how Google handles small websites, and more. Some information in the documents appears to be in conflict with public statements by Google representatives, according to Fishkin and King. “‘Lied’ is harsh, but it’s the only accurate word to use here,” King writes. “While I don’t necessarily fault Google’s public representatives for protecting their proprietary information, I do take issue with their efforts to actively discredit people in the marketing, tech, and journalism worlds who have presented reproducible discoveries.” Google has not responded to The Verge’s requests for comment regarding the documents, including a direct request to refute their legitimacy. Fishkin told The Verge in an email that the company has not disputed the veracity of the leak, but that an employee asked him to change some language in the post regarding how an event was characterized. Google’s secretive search algorithm has birthed an entire industry of marketers who closely follow Google’s public guidance and execute it for millions of companies around the world. The pervasive, often annoying tactics have led to a general narrative that Google Search results are getting worse, crowded with junk that website operators feel required to produce to have their sites seen. In response to The Verge’s past reporting on the SEO-driven tactics, Google representatives often fall back to a familiar defense: that’s not what the Google guidelines say. But some details in the leaked documents call into question the accuracy of Google’s public statements regarding how Search works. One example cited by Fishkin and King is whether Google Chrome data is used in ranking at all. Google representatives have repeatedly indicated that it doesn’t use Chrome data to rank pages, but Chrome is specifically mentioned in sections about how websites appear in Search. In the screenshot below, which I captured as an example, the links appearing below the main vogue.com URL may be created in part using Chrome data, according to the documents. Chrome is mentioned in a section about how additional links are created. Image: Google Another question raised is what role, if any, E-E-A-T plays in ranking. E-E-A-T stands for experience, expertise, authoritativeness, and trustworthiness, a Google metric used to evaluate the quality of results. Google representatives have previously said E-E-A-T isn’t a ranking factor. Fishkin notes that he hasn’t found much in the documents mentioning E-E-A-T by name. King, however, detailed how Google appears to collect author data from a page and has a field for whether an entity on the page is the author. A portion of the documents shared by King reads that the field was “mainly developed and tuned for news articles... but is also populated for other content (e.g., scientific articles).” Though this doesn’t confirm that bylines are an explicit ranking metric, it does show that Google is at least keeping track of this attribute. Google representatives have previously insisted that author bylines are something website owners should do for readers, not Google, because it doesn’t impact rankings. Though the documents aren’t exactly a smoking gun, they provide a deep, unfiltered look at a tightly guarded black box system. The US government’s antitrust case against Google — which revolves around Search — has also led to internal documentation becoming public, offering further insights into how the company’s main product works. Google’s general caginess on how Search works has led to websites looking the same as SEO marketers try to outsmart Google based on hints the company offers. Fishkin also calls out the publications credulously propping up Google’s public claims as truth without much further analysis. “Historically, some of the search industry’s loudest voices and most prolific publishers have been happy to uncritically repeat Google’s public statements. They write headlines like ‘Google says XYZ is true,’ rather than ‘Google Claims XYZ; Evidence Suggests Otherwise,’” Fishkin writes. “Please, do better. If this leak and the DOJ trial can create just one change, I hope this is it.” Most Popular Most Popular Google won’t comment on a potentially massive leak of its search algorithm documentation Former OpenAI board member explains why they fired Sam Altman Lego’s first Legend of Zelda set is a 2,500-piece Great Deku Tree This Lego Apple Store design submission is pitch-perfect Vivek Ramaswamy can’t even dunk on Buzzfeed right Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=40505310",
    "commentBody": "Google won’t comment on a leak of its search algorithm documentation (theverge.com)153 points by janandonly 22 hours agohidepastfavorite44 comments sixhobbits 21 hours agoThe Rand Fishkin article that this refers to is a much better source https://sparktoro.com/blog/an-anonymous-source-shared-thousa... reply greenyoda 19 hours agoparentHN discussion of that article: https://news.ycombinator.com/item?id=40496967 reply candiddevmike 21 hours agoprevQuick, have a LLM read it as that magically removes copyright. reply thih9 21 hours agoparentIt should be enough to have it online, soon AIs would pick it up. reply datadrivenangel 21 hours agoparentprevIt was leaked under an open source license. reply HeatrayEnjoyer 21 hours agorootparentI don't believe that was an authorized publishing. reply thih9 20 hours agorootparentFor all we know, it was made by a person/bot/process authorized to publish to an official Google repository[1]. It may have been accidental, sure[2]. But is there a basis to claim unauthorized action? [1]: https://news.ycombinator.com/item?id=40505708 [2]: Reminds me of “Night of the Living Dead”, which accidentally became public domain; source: https://en.m.wikipedia.org/wiki/Night_of_the_Living_Dead reply butler14 21 hours agoprevPerhaps surprisingly to the HN community, a lot of what is coming out confirms what decent SEOs have been saying for years (and appears to contradict a lot of what Google have said publicly via their various talking heads) reply robswc 21 hours agoprevfor someone far removed from SEO, what are the true (non-sensationalist headline) effects of this leak? reply burningChrome 21 hours agoparentLong time dev/designer and part-time SEO person here. The major implications are that a lot of what Google was telling SEO practitioners were a lie or cleverly disguised red herrings wrapped up in semantics. The article that was posted earlier today went through a lot of the stuff they were lying about with examples of Matt Cutts and Gary Ilyes statements that are now directly contradicted with the recent release of this code. Here is the article: https://ipullrank.com/google-algo-leak The premise: What I’ll do here is contextualize some of the most interesting ranking systems and features (at least, those I was able to find in the first few hours of reviewing this massive leak) based on my extensive research and things that Google has told/lied to us about over the years. “Lied” is harsh, but it’s the only accurate word to use here. While I don’t necessarily fault Google’s public representatives for protecting their proprietary information, I do take issue with their efforts to actively discredit people in the marketing, tech, and journalism worlds who have presented reproducible discoveries. reply robswc 20 hours agorootparentMakes sense. I used to have a youtube channel that got a few age-restricted videos (for absolutely silly reasons). Reps from youtube would swear up and down that age-restrictions wouldn't effect your video's ranking in the algorithms but it was so well known in most creator circles how untrue that was. Thank you for that link, I'll have to check it out! reply luma 20 hours agorootparentprevNormally I’m not here to defend the likes of Google, but when it comes to their communications to SEO practitioners, I’m OK with some intentional misdirection and outright lies. reply ahahahahah 6 hours agorootparentprevThe \"lies\" there are such bullshit. They basically consist of \"Google claimed they didn't do X\" now it looks like they probably do X and therefore google lied. They are somewhat circumspect about the fact that each example is actually, 8+ years ago Google made a claim about what they did at the time and now there's evidence that they are currently doing doesn't match that claim. That's not a lie. For example, they link to this tweet from 2016 as such a claim: https://ipullrank.com/wp-content/uploads/2024/05/image21.png Or a later example where they link to this 2016 talk: https://www.youtube.com/watch?v=iJPu4vHETXw Later on, they use claims from 2012: https://www.seroundtable.com/google-chrome-search-usage-1561... reply radicaldreamer 21 hours agoparentprevA lot more spam than usual in your search results. A leak like this (if it’s actually as substantial as people say it is) combined with google’s ham fisted way to insert LLM results into its search could really mean that google search quality will crater in the coming months, potentially opening up space for competitors or reducing usage in a real way. reply robswc 20 hours agorootparentIt has really gotten so bad. I get so much reddit spam lately. In a lot of cases reddit can be a great... but man, the astroturfing has gotten insane. reply HeatrayEnjoyer 21 hours agorootparentprevCrater worse than it already is? reply mdorazio 20 hours agoprevSince this seems to be most relevant to SEO practitioners I might as well ask a loaded question. Given how prevalent spam sites are in search results now and how bad Google seems to be at filtering them out, what's the argument for how SEO is a good thing in aggregate? reply makeitdouble 20 hours agoparent> how SEO is a good thing Are you asking whether people want discoverability for their product/companies ? Or if they're willing to give up agency and leave it to a third party for-profit corporation to dictate what is surfaced in people's generic searches ? reply mdorazio 19 hours agorootparentI'm asking if optimizing for clicks in search results rather than optimizing for quality of content and letting search engines attempt to determine what's worth surfacing was overall a good thing for users. reply makeitdouble 17 hours agorootparentThat's a valid question, but there is no answer to what \"optimizing for quality of content\" means, and every entity involved has a different view of it. We'd have to decide what is quality and what is content first, and I'd expect the heat death of the universe before we ever come to a useful definition that even matches half people's own definitions. reply burningChrome 18 hours agoparentprevDepends on the context. I'm a long time dev/designer and part-time SEO person. Back in the day (early to mid aughts) as an SEO person you really had to work to get your site noticed. You have to develop inbound links, create really good content, set your site up well for Google to index, used other resources like blogs and social media (when it was still in the early stages) to boost your positioning. In short, it was a full time, month-to-month job. The sites I worked on it was a constant battle to get a decent ranking and to maintain it. But you are 100% right. Somewhere in the last 8-10 years, everything has gone from search engines really protecting who they put on the front page, to loading the page with tons of ads (half of the results above the fold are now all ads, followed by more ads below the 10th position) and making it insanely easy to manipulate Google and others to get your site on the front page. Great example: In 2019, I had a medical device company that was a startup. Out of the blue they called me because of my prior relationship with one of the founders parents and the site I built for her. They needed a site designed, built, optimized and 15 pages of content written in less than three months. I gave them some insane price and they didn't even balked and said if I got done sooner, they would send me a bonus. I grabbed a template somewhere online, revamped the home page and the internal content pages and then proceeded to copy/paste content from other well known and not so well known sites in their industry. I did everything you should never do from an SEO standpoint. I figured it was a long shot, but worth the payoff. I got their site released on time, but the majority of the content was copied from other sites. Very little of it was original. I figured it would get buried in the first month. Nope. #3 on the first page for various searches I targeted. It was outranking the sites I copied the content from, it was crazy. To this day, the site remains in the top three places on the first page of Google and other search engines for dozens of searches I targeted. It was outranking huge medical supply companies in the same industry - all as a startup. That experience in 2019 was a huge wakeup call for me. It was blatantly obvious how easy it was to manipulate Google and other search engines. As of today, I have no idea if SEO is really a worthwhile pursuit any more considering how easy it is to do this. If I can do it, then I just assume everybody else is already doing it. If not, then they're missing out. reply magicalist 21 hours agoprev> Though the documents aren’t exactly a smoking gun Smoking gun of what? The article never seems to actually say. The only accusation I see is that SEO grifters were lied to by Google Search docs, but you look at the article like[1] it's over things like \"Google always said Domain Authority isn't a thing, but we found a variable site_authority. We don't know what it's for or what it does, but clearly we were right\". Which, even if true, isn't a thing I care about at all... [1] https://ipullrank.com/google-algo-leak reply Scoundreller 21 hours agoparentI believe for a while that Google didn’t consider Domain Authority much. For a while, I would create pages like “Bank of XYZ Phone Numbers” or “Phone Numbers for $ThatTelecomYouHate” and often rank #1. Which made sense, because my page was just a very parseable page of their actual phone numbers, but obviously risk for harm there. Phone numbers on the actual orgs’ websites were hard to find because, well, they wanted you to do anything but call them because calling cost them money. And the big corp websites were always an SEO mess that I’m not surprised a crawler could not comprehend. Of course the ads were all for competitors, so I enjoyed making money and costing them customers at the same time. After some years, Google would start returning you 10 different results from the orgs’ websites, playing into their hand of having you do anything but call your bank/telco. reply makeitdouble 20 hours agoparentprevPublicly lying about how a core product works is notable, and would be a big deal for any other company. Reminds me of Apple's \"we treat all developers equally\" statements before it was made clear Spotify didn't pay a dime on their in-app subs. You're right that the real impact is limited though, people woun't be moving to another search engine anyway. reply xnx 21 hours agoparentprevSEO discussion is notoriously high noise and low signal. It's mainly conjecture, assumption, and superstition. Like a lot of things, if they knew what worked, they wouldn't be sharing it. reply iamacyborg 21 hours agoparentprevI’m not sure calling folks like Rand Fishkin a grifter is all that accurate, to put it politely. reply fallingsquirrel 21 hours agoprevIt's still online, grab it while you can https://github.com/googleapis/elixir-google-api/commit/078b4... reply winddude 21 hours agoparentI think the repo was also cloned here...and considering the original repo is apache 2... not sure they can legally force them to be removed. reply jart 21 hours agorootparentWhat am I looking at? reply JohnMakin 20 hours agorootparentYou're looking at a commit that contains all of the leaked files/documentation conveniently on the directory view on side of the github page. reply jart 19 hours agorootparentThat tells me literally nothing. This is all machine generated boilerplate code. This isn't executive emails or documents. Since when are comments written by nameless workers an authoritative newsworthy leak on corporate policy? It probably tells us something about what sort of things workers at Google have researched, e.g. csam, scams, racism. If I grep for SEO then I see some database fields for their pagespeed service that mentions accessibility audits and progressive web apps. Looks pretty consistent with what Google has always said publicly. Where's the specific code that's generating all the shock and outrage? reply JohnMakin 19 hours agorootparentThere are plenty of breakdowns of what exactly the technical documents contain, including the stuff I just said. In great detail! Google ironically here is your friend. It confirms what SEO practitioners have been saying for years that Google has actively been discrediting with flat out falsehoods, such as they don’t use domain authority anywhere in their ranking (documentation describes fields named domainAuthority), they track clicks in great detail (which they have vigorously denied), and they use chrome usage data as a factor in their rankings. Hope that helps reply tsimionescu 20 hours agorootparentprevLicenses don't work like that. Accidentally releasing something under a license doesn't mean it will forever carry that license. reply Mathnerd314 19 hours agorootparentRegarding trade secrets, inadvertent or accidental disclosure means it is no longer a trade secret - no protection. And regarding copyright, there is Oracle vs. Google that copying APIs is fair use (Google's argument). So even if the copyright license grant in the leak is held to be invalid (the license states it is perpetual, if it is valid it does forever carry that license), it would be fair use anyway. I think the only IP protection is patents, Google has patents on various parts of the system so if you did actually want to build a Google clone by reverse-engineering their documentation you would run into trouble. reply tsimionescu 19 hours agorootparentI think serving the docs themselves is likely illegal, though. You don't actually have a right to distribute copies just because someone pushed a wrong button and they were made visible in a repo that has a top-level Apache 2 license. Sure, they can't stop people who received a copy from studying it and using or discussing the information in there. But I think they can almost certainly stop them from (legally) distributing that information to others. reply winddude 18 hours agorootparentApache 2 is irrevocable, and you can redistribute it however you wish. I think it's safe to assume as soon as it was pushed public to the original google repo it's was covered under apache 2. that entire repo was distributed by google as Apache 2. So if you pull that commit, as far as I would be concerned everything in it is apache 2 since that's the license it's distributed with. We have no idea why that code was pushed, and it doesn't matter from a public perspective. reply tsimionescu 12 hours agorootparentNone of that matters if the company never intended to publish it as Apache 2, and can show they took immediate steps to correct their mistake. The law is not code, and intent matters. reply winddude 4 hours agorootparentsource or relevant case? Because if someone pulls before it's another commit that removes it... you would have absolutely zero idea why they removed it, or you wouldn't even know it was removed. Or even if you still pull that commit that as of yesterday after over 1 month was still in the google repo, there's no info that it shouldn't be there... And I think pushing code to a public opensource repo, shows intent to publish it... reply ilyazub 9 hours agoparentprevIt was online in 2022 too: https://github.com/googleapis/google-api-php-client-services... reply HyprMusic 19 hours agoprevMaybe I'm missing something but all the document seems to imply is that Google collects this data... Nothing about it being used as ranking factors. It doesn't seem unreasonable for Google to collect and correlate extra data that it may want to use as future ranking factors, experiments, quality analysis etc. reply fouc 21 hours agoprevI didn't know Google used Elixir internally reply wging 20 hours agoparentI don't think this leak shows that they use Elixir. It's open-source code that Google customers are supposed to be able to use to interact with Google APIs. It's natural to provide support for your customers to use the languages they want to use, rather than the ones you've settled on internally; this is important for anyone, let alone restrictive internal environments like Google's is supposed to be. (https://aws.amazon.com/sdk-for-php/ exists, but Amazon famously doesn't allow services to be developed in PHP.) Google is famous for allowing only a few languages for production code. The README also says: > Disclaimer > This is not an officially supported Google product. which, while it doesn't directly indicate that Elixir isn't used internally to Google, would be a surprising mismatch of support if they did use Elixir. Here are their official clients (including some in languages that I doubt they want to be used internally for service development, like PHP, Node.js, and .NET): https://developers.google.com/api-client-library reply Havoc 18 hours agoprevOuch. Some pretty damming stuff there. I can see spokespeople getting something wrong, but multiple points that are seen as highly contentious in SEO land being explicitly denied and the docs say opposite? Not much wiggle room there reply HenryBemis 21 hours agoprev [–] Where money can be made, money will be made. Google lied? Of course they did. And Microsoft, consistently (with their pool of NOBUS). In articles/stories like that my mind wanders to the ST land and the Rules of Acquisition (https://projectsanctuary.com/the_complete_ferengi_rules_of_a...) 125. A lie isn't a lie until someone else knows the truth reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A leak of 2,500 pages of internal Google documents, shared by SEO expert Rand Fishkin, may reveal discrepancies between Google's public statements and its actual practices regarding search algorithms.",
      "The documents suggest the use of Chrome data in rankings and tracking of author information, challenging Google's previous assertions and sparking debate over the company's transparency.",
      "Google has not commented on the legitimacy of the documents, and the incident highlights ongoing concerns about the opaque nature of Google's search operations amid antitrust scrutiny."
    ],
    "commentSummary": [
      "A leak of Google's search algorithm documentation has revealed potential discrepancies between Google's public statements and their actual practices.",
      "The leak suggests that Google's representatives may have discredited accurate findings from the marketing, tech, and journalism communities, raising ethical concerns about SEO manipulation.",
      "Legal discussions on GitHub are debating the significance and legality of the leak, with varying opinions on its impact on trade secret status and copyright protections."
    ],
    "points": 153,
    "commentCount": 44,
    "retryCount": 0,
    "time": 1716928339
  }
]
